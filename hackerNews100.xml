<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>Hacker News 100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 19 Jul 2021 09:43:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Julian Assange Case: Keystone Witness Admits He Lied, US Media Ignores (343 pts)]]></title>
            <link>https://thewire.in/rights/julian-assange-case-key-witness-lied</link>
            <guid>27878902</guid>
            <pubDate>Mon, 19 Jul 2021 03:14:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thewire.in/rights/julian-assange-case-key-witness-lied">https://thewire.in/rights/julian-assange-case-key-witness-lied</a>, See on <a href="https://news.ycombinator.com/item?id=27878902">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>New Delhi:&nbsp;</strong>The United States’ Department of Justice’s case against Wikileaks founder Julian Assange took a serious hit last week after a key witness admitted that he fabricated accusations in order to get immunity. Though these revelations were made public by an Icelandic newspaper on June 26, the mainstream media in the US has largely chosen to ignore them.</p>
<p><a href="https://stundin.is/grein/13627/">According to the bi-weekly <em>Stundin</em></a>, the witness, Sigurdur Ingi Thordarson, “has a documented history with sociopathy and has received several convictions for sexual abuse of minors and wide-ranging financial fraud”. He was recruited by US authorities in order to build a case against Assange, and misled them into believing he was a close associate of the Wikileaks founder. In reality, however, he had only “volunteered on a limited basis to raise money for Wikileaks in 2010 but was found to have used that opportunity to embezzle more than $50,000 from the organisation”, the Icelandic newspaper reports.</p>
<p>The US is currently seeking Assange’s extradition from the UK. If it succeeds, Assange could face up to 175 years in jail because of the charges filed against him. But now, with Thordason accepting that he fabricated his testimony, the veracity of the indictment submitted by American authorities in the UK has come under serious question.</p>
<p>The court documents, according to <em>Stundin</em>, claim that Thordarson (referred to only as ‘Teenager’, because he looks young even though he is 28), was asked by Assange to hack MPs’ computers in Iceland to access certain recordings of them. However, the witness has now said that Assange made no such demand, and instead Thordarson received these recordings from a third party and offered them to Assange without checking them himself. He has also made clear that his earlier allegations, on Assange asking him to hack computers, was false.</p>
<p>There are also other misleading elements in the court documents based on Thordarson’s false testimony, <em>Stundin</em> reports:</p>
<p>“One is a reference to Icelandic bank documents. The magistrate court judgement reads: “It is alleged that Mr. Assange and Teenager failed a joint attempt to decrypt a file stolen from a “NATO country 1” bank”.</p>
<p>Thordarson admits to Stundin that this actually refers to a well publicised event in which an encrypted file was leaked from an Icelandic bank and assumed to contain information about defaulted loans provided by the Icelandic Landsbanki. The bank went under in the fall of 2008, along with almost all other financial institutions in Iceland, and plunged the country into a severe economic crisis. The file was at this time, in summer of 2010, shared by many online who attempted to decrypt it for the public interest purpose of revealing what precipitated the financial crisis. Nothing supports the claim that this file was even “stolen” per se, as it was assumed to have been distributed by whistleblowers from inside the failed bank.”</p>
<p>Thordarson, <em>Stundin</em> has claimed, continued his own criminal activities even while he was in contact with US authorities. “It is as if the offer of immunity, later secured and sealed in a meeting in DC, had encouraged Thordarson to take bolder steps in crime. He started to fleece individuals and companies on a grander scale than ever; usually by either acquiring or forming legal entities he then used to borrow merchandise, rent luxury cars, even order large quantities of goods from wholesalers without any intention to pay for these goods and services,” the report notes.</p>
<p><ins>Also read: <a title="Wikileaks Acted in Public Interest, 'Pentagon Papers' Whistleblower Says at Assange Hearing" href="https://thewire.in/world/wikileaks-acted-in-public-interest-pentagon-papers-whistleblower-says-at-assange-hearing">Wikileaks Acted in Public Interest, ‘Pentagon Papers’ Whistleblower Says at Assange Hearing</a></ins></p>
<p>“This is just the latest revelation of how problematic the United States’ case is against Julian Assange – and, in fact, baseless,” human rights attorney Jennifer Robinson <a href="https://www.democracynow.org/2021/6/28/julian_assange_extradition_case">told <em>Democracy Now</em></a> on the <em>Stundin </em>investigation. “The evidence from Thordarson that was given to the United States and formed the basis of the second, superseding indictment, including allegations of hacking, has now been, on his own admission, demonstrated to have been fabricated. Not only did he misrepresent his access to Julian Assange and to WikiLeaks and his association with Julian Assange, he has now admitted that he made up and falsely misrepresented to the United States that there was any association with WikiLeaks and any association with hacking.”</p>
<p>“…the factual basis for this case has completely fallen apart. And we have been calling for this case to be dropped for a very long time. And this is just the last form of abuse demonstrated in this case that shows why it ought to be dropped,” Robinson continued.</p>
<p><strong>Media silence</strong></p>
<p>While these revelations should have created an uproar, most big, corporate-owned media houses in the US have ignored them FAIR, an American media watchdog, <a href="https://fair.org/home/key-assange-witness-recants-with-zero-corporate-media-coverage/">has pointed out</a> in an article on its website.</p>
<p>“Such a blatant and juicy piece of important news should have made worldwide headlines. But, instead, as of Friday, July 2, there has been literally zero coverage of it in corporate media; not one word in the&nbsp;<em>New York Times,&nbsp;Washington Post</em>,&nbsp;CNN,&nbsp;NBC News,&nbsp;Fox News&nbsp;or&nbsp;NPR. A search online for either “Assange” or “Thordarson” will elicit zero relevant articles from establishment sources, either US or elsewhere in the Anglosphere, even in tech-focused platforms like the&nbsp;<em>Verge</em>,&nbsp;<em>Wired</em>&nbsp;or&nbsp;<em>Gizmodo</em>,” FAIR says.</p>
<p>“It is not that the corporate press are completely uninterested in Assange. A number of outlets have covered the news this week that he and his partner Stella Morris are planning to get married (e.g.,&nbsp;SBS,&nbsp;<a href="https://www.sbs.com.au/news/julian-assange-plans-to-marry-partner-stella-moris-in-prison">6/27/21</a>;&nbsp;<em>Daily Mail</em>,&nbsp;<a href="https://www.dailymail.co.uk/news/article-9732931/Wikileaks-founder-Julian-Assange-plans-marry-inside-Belmarsh.html">6/28/21</a>;&nbsp;<em>Evening Standard</em>,&nbsp;<a href="https://www.standard.co.uk/news/uk/wikileaks-julian-assange-marriage-belmarsh-prison-b942937.html">6/28/21</a>; London&nbsp;<em>Times</em>,&nbsp;<a href="https://www.thetimes.co.uk/article/julian-assange-prison-wedding-lawyer-girlfriend-6nq3hcn5j">6/29/21</a>). Yet none of these articles mentioned the far more consequential news about Thordarson and how it undermines the entire prosecution of Assange,” FAIR continues.</p>
<p>Other independent journalists too have pointed out the one-sided and biased coverage of the Assange case.</p>
<blockquote>
<p dir="ltr" lang="en">This <a href="https://twitter.com/declassifiedUK?ref_src=twsrc%5Etfw">@declassifiedUK</a> story details how as a British judge made rulings against Assange, her husband was closely involved with a right-wing lobby group running a campaign against WikiLeaks founder.</p>
<p>It has never been mentioned in the mainstream media. <a href="https://t.co/yUakZ1ZeRk">https://t.co/yUakZ1ZeRk</a></p>
<p>— Matt Kennard (@kennardmatt) <a href="https://twitter.com/kennardmatt/status/1410516433180807232?ref_src=twsrc%5Etfw">July 1, 2021</a></p></blockquote>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Data leak shatters the lie that the innocent need not fear surveillance (254 pts)]]></title>
            <link>https://www.theguardian.com/news/2021/jul/18/huge-data-leak-shatters-lie-innocent-need-not-fear-surveillance</link>
            <guid>27878659</guid>
            <pubDate>Mon, 19 Jul 2021 02:29:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/news/2021/jul/18/huge-data-leak-shatters-lie-innocent-need-not-fear-surveillance">https://www.theguardian.com/news/2021/jul/18/huge-data-leak-shatters-lie-innocent-need-not-fear-surveillance</a>, See on <a href="https://news.ycombinator.com/item?id=27878659">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="0" id="maincontent"><p>Billions of people are inseparable from their phones. Their devices are within reach – and earshot – for almost every daily experience, from the most mundane to the most intimate.</p><p>Few pause to think that their phones can be transformed into surveillance devices, with someone thousands of miles away silently extracting their messages, photos and location, activating their microphone to record them in real time.</p><p>Such are the capabilities of Pegasus, the spyware manufactured by NSO Group, the Israeli purveyor of weapons of mass surveillance.</p><p><a href="https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments" data-link-name="in body link">NSO rejects</a> this label. It insists only carefully vetted government intelligence and law enforcement agencies can use Pegasus, and only to penetrate the phones of “legitimate criminal or terror group targets”.</p><p>Yet in the coming days the Guardian will be revealing the identities of many innocent people who have been identified as candidates for possible surveillance by NSO clients in a massive leak of data.</p><p>Without forensics on their devices, we cannot know whether governments successfully targeted these people. But the presence of their names on this list indicates the lengths to which governments may go to spy on critics, rivals and opponents.</p><figure id="7ed7dcad-c835-430f-9903-98610bbc38d5"><div data-atom-id="8a29b04b-fdcd-4315-96ee-95603ef0436d" data-atom-type="guide"><details data-atom-id="8a29b04b-fdcd-4315-96ee-95603ef0436d" data-snippet-type="guide"><summary><span>Quick Guide</span><h4>What is in the Pegasus project data? </h4><span><span><span><svg viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.8 16.2l.425 9.8h1.525l.45-9.8 9.8-.45v-1.525l-9.8-.425-.45-9.8h-1.525l-.425 9.8-9.8.425v1.525l9.8.45z"></path></svg></span>Show</span></span></summary><div><p><strong>What is in the data leak?</strong></p><p>The data leak is a list of more than 50,000 phone numbers that, since 2016, are believed to have been selected as those of people of interest by government clients of NSO Group, which sells surveillance software. The data also contains the time and date that numbers were selected, or entered on to a system. Forbidden Stories, a Paris-based nonprofit journalism organisation, and Amnesty International initially had access to the list and shared access with 16 media organisations including the Guardian. More than 80 journalists have worked together over several months as part of the Pegasus project. Amnesty’s Security Lab, a technical partner on the project, did the forensic analyses.</p><p><strong>What does the leak indicate?</strong></p><p>The consortium believes the data indicates the potential targets NSO’s government clients identified in advance of possible surveillance. While the data is an indication of intent, the presence of a number in the data does not reveal whether there was an attempt to infect the phone with spyware&nbsp;such as Pegasus, the company’s signature surveillance tool, or whether any attempt succeeded. The presence in the data of a very small number of landlines and US numbers, which NSO says are “technically impossible” to access with its tools, reveals some targets were selected by NSO clients even though they could not be infected with Pegasus. However, forensic examinations of a small sample of mobile phones with numbers on the list found tight correlations between the time and date of a number in the data and the start of Pegasus activity – in some cases as little as a few seconds.</p><p><strong> What did forensic analysis reveal?</strong></p><p>Amnesty examined 67 smartphones where attacks were suspected. Of those, 23 were successfully infected and 14 showed signs of attempted penetration. For the remaining 30, the tests were inconclusive, in several cases because the handsets had been replaced. Fifteen of the phones were Android devices, none of which showed evidence of successful infection. However, unlike iPhones, phones that use Android do not log the kinds of information required for Amnesty’s detective work. Three Android phones showed&nbsp;signs&nbsp;of targeting, such as Pegasus-linked SMS messages.</p><p>Amnesty shared “backup copies” of four iPhones with Citizen Lab, a research group at the University of Toronto that specialises in studying Pegasus, which confirmed that they showed signs of Pegasus infection. Citizen Lab also conducted a peer review of Amnesty’s forensic methods, and found them to be sound.</p><p><strong>Which NSO clients were selecting numbers?</strong></p><p>While the data is organised into clusters, indicative of individual NSO clients, it does not say which NSO client was responsible for selecting any given number. NSO claims to sell its tools to 60 clients in 40 countries, but refuses to identify them. By closely examining the pattern of targeting by individual clients in the leaked data, media partners were able to identify 10 governments believed to be responsible for selecting the targets: Azerbaijan, Bahrain, Kazakhstan, Mexico, Morocco, Rwanda, Saudi Arabia, Hungary, India, and the United Arab Emirates. Citizen Lab has also found evidence of all 10 being clients of NSO.</p><p><strong>What does NSO Group say?</strong></p><p>You can read NSO Group’s&nbsp;<a href="https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments">full statement here</a>. The company has always said it does not have access to the data of its customers’ targets. Through its lawyers, NSO said the consortium had made “incorrect assumptions” about which clients use the company’s technology. It said the 50,000 number was “exaggerated” and the list could not be a list of numbers “targeted by governments using Pegasus”. The lawyers said NSO had reason to believe the list accessed by the consortium “is not a list of numbers targeted by governments using Pegasus, but instead, may be part of a larger list of numbers that might have been used by NSO Group customers for other purposes”. After further questions, the lawyers said the consortium was basing its findings “on misleading interpretation of leaked data from accessible and overt basic information, such as HLR Lookup services, which have no bearing on the list of the customers' targets of Pegasus or any other NSO products ... we still do not see any correlation of these lists to anything related to use of NSO Group technologies”.</p><p><strong>What is HLR lookup data?</strong></p><p>The term HLR, or home location register, refers to a database that is essential to operating mobile phone networks. Such registers keep records on the networks of phone users and their general locations, along with other identifying information that is used routinely in routing calls and texts. Telecoms and surveillance experts say HLR data can sometimes be used in the early phase of a surveillance attempt, when identifying whether it is possible to connect to a phone. The consortium understands NSO clients have the capability through an interface on the Pegasus system to conduct HLR lookup inquiries.&nbsp;It is unclear whether Pegasus operators are required to conduct HRL lookup inquiries via its interface to use its&nbsp;software; an NSO source stressed its clients&nbsp;may have different reasons – unrelated to Pegasus – for conducting HLR lookups via an NSO system.</p></div></details></div></figure><p>First we reveal how <a href="https://www.theguardian.com/world/2021/jul/18/ft-editor-roula-khalaf-among-180-journalists-targeted-nso-spyware" data-link-name="in body link">journalists across the world were selected</a> as potential targets by these clients prior to a possible hack using NSO surveillance tools.</p><p>Over the coming week we will be revealing the identities of more people whose phone numbers appear in the leak. They include lawyers, human rights defenders, religious figures, academics, businesspeople, diplomats, senior government officials and heads of state.</p><p>Our reporting is rooted in the public interest. We believe the public should know that NSO’s technology is being abused by the governments who license and operate its spyware. But we also believe it is in the public interest to reveal how governments look to spy on their citizens and how seemingly benign processes such as HLR lookups can be exploited in this environment.</p><p>The Pegasus project is a collaborative reporting project led by the French nonprofit organisation Forbidden Stories<strong>, </strong>including the Guardian and 16 other media outlets. For months, our journalists have been working with reporters across the world to establish the identities of people in the leaked data and see if and how this links to NSO’s software.</p><figure id="2d793791-3ab6-44b4-889f-283d33b0f120"><div data-chromatic="ignore" data-component="youtube-atom"><div><iframe title="Pegasus: the spyware technology that threatens democracy - video" width="460" height="259" id="youtube-video-G7H9uo3j5FQ" src="https://www.youtube.com/embed/G7H9uo3j5FQ?embed_config={&quot;adsConfig&quot;:{&quot;adTagParameters&quot;:{&quot;iu&quot;:&quot;/59666047/theguardian.com/news/article/ng&quot;,&quot;cust_params&quot;:&quot;sens%3Df%26si%3Df%26vl%3D0%26cc%3DINT%26s%3Dnews%26inskin%3Df%26se%3Dpegasus-project%26ct%3Darticle%26co%3Dpaullewis%26url%3D%252Fnews%252F2021%252Fjul%252F18%252Fhuge-data-leak-shatters-lie-innocent-need-not-fear-surveillance%26su%3D4%2C5%26edition%3Dint%26tn%3Danalysis%26p%3Dng%26k%3Despionage%2Csurveillance%2Ctechnology%2Cmalware%26sh%3Dhttps%253A%252F%252Fwww.theguardian.com%252Fp%252Ft4dv8%26pa%3Df&quot;}}}&amp;enablejsapi=1&amp;origin=https://www.theguardian.com&amp;widgetid=1&amp;modestbranding=1" allow="autoplay" tabindex="-1" allowfullscreen="" data-atom-id="youtube-video-G7H9uo3j5FQ" data-atom-type="youtube"></iframe><div daya-cy="youtube-overlay" tabindex="0"><picture itemprop="contentUrl"><source srcset="" sizes="(min-width: 660px) 620px, 100vw" media="(-webkit-min-device-pixel-ratio: 1.25), (min-resolution: 120dpi)"><source srcset="https://media.guim.co.uk/7c984f69f4acdb4a3c8449aec1a55c4e621de8b4/0_0_1920_1080/140.jpg 140w,https://media.guim.co.uk/7c984f69f4acdb4a3c8449aec1a55c4e621de8b4/0_0_1920_1080/500.jpg 500w,https://media.guim.co.uk/7c984f69f4acdb4a3c8449aec1a55c4e621de8b4/0_0_1920_1080/1000.jpg 1000w,https://media.guim.co.uk/7c984f69f4acdb4a3c8449aec1a55c4e621de8b4/0_0_1920_1080/1920.jpg 1920w" sizes="(min-width: 660px) 620px, 100vw"></picture><div><p>04:55</p></div></div></div><figcaption><span><svg width="11" height="10" viewBox="0 0 11 10"><path fill-rule="evenodd" d="M5.5 0L11 10H0z"></path></svg></span><span>Pegasus: the spyware technology that threatens democracy - video</span></figcaption></div></figure><p>It is not possible to know without forensic analysis whether the phone of someone whose number appears in the data was actually targeted by a government or whether it was successfully hacked with NSO’s spyware. But when our technical partner, Amnesty International’s Security Lab, conducted forensic analysis on dozens of iPhones that belonged to potential targets at the time they were selected, they found evidence of Pegasus activity in more than half.</p><p>One phone that has contained signs of Pegasus activity belonged to our esteemed Mexican colleague Carmen Aristegui, whose number was in the data leak and who was targeted following her exposé of a corruption scandal involving her country’s former president Enrique Peña Nieto.</p><figure id="7f11e718-74d2-4f79-a501-48ccd03bc409"><div><picture itemprop="contentUrl"><source srcset="https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=620&amp;quality=45&amp;auto=format&amp;fit=max&amp;dpr=2&amp;s=dc35c352ffacb9c73aa18d59c8c55e8b 1240w,https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=605&amp;quality=45&amp;auto=format&amp;fit=max&amp;dpr=2&amp;s=ef1ba82459dad2ae20d729d55aa2a126 1210w,https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=445&amp;quality=45&amp;auto=format&amp;fit=max&amp;dpr=2&amp;s=7038be35faac6e572c8f606150b3d383 890w" sizes="(min-width: 660px) 620px, 100vw" media="(-webkit-min-device-pixel-ratio: 1.25), (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=758be9112a2a80818d86ae8cd171739e 620w,https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=605&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=0e449b406c13a26bef3ac713543fba02 605w,https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=445&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=7b754ee752a94b45f1a2c55451e4ca0c 445w" sizes="(min-width: 660px) 620px, 100vw"><img alt="The Mexican journalist Carmen Aristegui." src="https://i.guim.co.uk/img/media/525d69d79fa3debbdf2632e801d072d1e450a808/0_135_5568_3341/master/5568.jpg?width=445&amp;quality=45&amp;auto=format&amp;fit=max&amp;dpr=2&amp;s=7038be35faac6e572c8f606150b3d383" height="3341" width="5568" loading="lazy"></picture></div><figcaption><span><svg width="11" height="10" viewBox="0 0 11 10"><path fill-rule="evenodd" d="M5.5 0L11 10H0z"></path></svg></span><span>The Mexican journalist Carmen Aristegui.</span> Photograph: EFE News Agency/Alamy</figcaption></figure><p>The data leak suggests that Mexican authorities did not stop at Aristegui. The phone numbers of at least four of her journalist colleagues appear in the leak, as well as her assistant, her sister and her son, who was 16 at the time.</p><p>Investigating software produced and sold by a company as secretive as NSO is not easy. Its business is surveillance, after all. It meant a radical overhaul of our working methods, including a ban on discussing our work with sources, editors or lawyers in the presence of our phones.</p><p>The last time the Guardian adopted such extreme counter-espionage measures was in 2013, when reporting on <a href="https://www.theguardian.com/world/interactive/2013/nov/01/snowden-nsa-files-surveillance-revelations-decoded" data-link-name="in body link">documents leaked by the whistleblower Edward Snowden</a>. Those disclosures pulled back the curtains on the <a href="https://www.theguardian.com/us-news/the-nsa-files" data-link-name="in body link">vast apparatus of mass surveillance</a> created after 9/11 by western intelligence agencies such as the National Security Agency (NSA) and its British partner, GCHQ.</p><p>In doing so, they instigated a global debate about western state surveillance capabilities and led to countries, including the UK, admitting their regulatory regime was out of date and open to potential abuse.</p><p>The Pegasus project may do the same for the privatised government surveillance industry that has turned NSO into a billion-dollar company.</p><p>Companies such as NSO operate in a market that is almost entirely unregulated, enabling tools that can be used as instruments of repression for authoritarian regimes such as those in Saudi Arabia, Kazakhstan and Azerbaijan.</p><p>The market for NSO-style surveillance-on-demand services has boomed post-Snowden<strong>, </strong>whose revelations prompted the mass adoption of encryption across the internet. As a result the internet became far more secure, and mass harvesting of communications much more difficult.</p><p>But that in turn spurred the proliferation of companies such as NSO offering solutions to governments struggling to intercept messages, emails and calls in transit. The NSO answer was to bypass encryption by hacking devices.</p><figure id="39ce8c09-68b1-4233-8493-fe2a598fedad"></figure><p>Two years ago the then UN special rapporteur on freedom of expression, David Kaye, called for a moratorium on the sale of NSO-style spyware to governments until viable export controls could be put in place. He warned of an industry that seemed “out of control, unaccountable and unconstrained in providing governments with relatively low-cost access to the sorts of spying tools that only the most advanced state intelligence services were previously able to use”.</p><p>His warnings were ignored. The sale of surveillance continued unabated. That GCHQ-like surveillance tools are now available for purchase by repressive governments may give some of Snowden’s critics pause for thought.</p><p>In the UK, the whistleblower’s detractors argued breezily that spying was what intelligence agencies were supposed to do. We were assured that innocent citizens in the Five Eyes alliance of intelligence powers, comprising Australia, Canada, New Zealand, the UK and US, were safe from abuse. Some invoked the dictum: “If you have done nothing wrong, you have nothing to fear.”</p><p>The Pegasus project is likely to put an end to any such wishful thinking. Law-abiding people – including citizens and residents of democracies such as the UK, such as editors-in-chief of leading newspapers – are not immune from unwarranted surveillance. And western countries do not have a monopoly on the most invasive surveillance technologies. We’re entering a new surveillance era, and unless protections are put in place, none of us are safe.</p><p><em>On Tuesday 27 July, at 8pm BST, join The Guardian’s head of investigations, Paul Lewis, for a livestreamed Guardian Live event on the implications of the Pegasus project. Book your ticket <a href="https://membership.theguardian.com/event/the-pegasus-project-revealing-a-global-abuse-of-cybersurveillance-163379288851" data-link-name="in body link">here</a>.</em><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple sued by teen wrongly accused of shoplifting by unreliable facial-rec tech (390 pts)]]></title>
            <link>https://www.theregister.com/2021/05/29/apple_sis_lawsuit/</link>
            <guid>27878333</guid>
            <pubDate>Mon, 19 Jul 2021 01:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2021/05/29/apple_sis_lawsuit/">https://www.theregister.com/2021/05/29/apple_sis_lawsuit/</a>, See on <a href="https://news.ycombinator.com/item?id=27878333">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Apple and its security contractor Security Industry Specialists (SIS) were sued on Friday in Massachusetts as part of a multijurisdictional defamation and malicious prosecution complaint brought on behalf of Ousmane Bah, a New York resident <a target="_blank" href="https://www.theregister.com/2019/04/23/apple_facial_recognition_arrest_lawsuit/">misidentified as a shoplifter</a> multiple times in 2018 and 2019.</p>
<p>The lawsuit contends that Apple and SIS exhibited reckless disregard for the truth by misidentifying Bah as the perpetrator of multiple shoplifting crimes at iStores, leading to his unjustified arrest and to his defamation.</p>
<p>The filing [<a target="_blank" rel="nofollow" href="https://regmedia.co.uk/2021/05/29/pacer_bah_apple.pdf">PDF</a>] in US District Court in Massachusetts aims to revive charges relevant to events in Boston that were excluded from related ongoing litigation in New York. A third related case is being heard in New Jersey.</p>

    

<p>Apple and SIS have a qualified law enforcement privilege that allows them to err in store security-related accusations and not be sued for it. However, if they exhibit "reckless disregard for the truth" [<a target="_blank" rel="nofollow" href="https://scholarship.law.duke.edu/cgi/viewcontent.cgi?article=1190&amp;context=alr">PDF</a>] – ignoring obvious facts, for example, they lose that privilege.</p>

        


        

<p>Among the more startling allegations in the case is that an SIS VP falsely claimed that no SIS employee ever identified Bah to the NYPD or to Apple. The complaint points to an exhibit that's been submitted as evidence, an email from an SIS employee to an NYPD detective does in fact identify Bah as a shoplifter.</p>
<p>The lawsuit also claims that Apple and SIS selectively deleted video evidence that would have exposed them to potential criminal and civil liability for filing false complaints with the police.</p>

        

<p>In addition, it asserts Bah's apprehension was in part due to the application of unreliable facial-recognition technology in the shoplifting incidents in New York.</p>
<p>Bah, who is Black, obtained a New York State temporary learner driver's permit in March 2018 at the age of 17, when he was an honors student at Bronx Latin Academy, a New York City high school. The document included his height, weight, date of birth, and eye color, but no photograph.</p>
<p>According to the Massachusetts court filing, he had lost the temporary permit by May that year, but had obtained a permanent laminated copy that included his picture.</p>
<h3>
  <span>ID or not ID</span>
</h3>
<p>In Greenwich, Connecticut in April 2018, Apple allegedly detained an individual for stealing store merchandise and identified the individual as Ousmane Bah based on the examination of the temporary learner's permit he is said to have had on him – this despite the fact that the ID says, "This temporary document is not to be used for identification purposes."</p>
<p>The complaint states that the person detained was not Bah, who is 5'7" but a 6'1" impostor using the lost temporary learner's permit. Nonetheless, Apple personnel are said to have retained some video surveillance evidence and published the record with the name "Ousmane Bah" through an online system to make it available to SIS and Apple Stores in the Northeastern US.</p>

        

<p>On May 24, 2018, SIS, acting in a security capacity for Apple, apprehended and handcuffed the impostor for allegedly stealing merchandise from a Paramus, New Jersey Apple Store. Again, it's claimed the impostor was carrying Bah's lost learner's permit and identified himself as such to authorities or tried to do so – the detained individual is said to have misspelled his stolen name as "Ousama Bah" before correcting the spelling.</p>
<p>Yet the Paramus Police Department apparently did not make any further effort to verify the suspect's identity, content to accept the identification provided by the SIS employee who apprehended the shoplifter. It's also claimed SIS told authorities it had video evidence.</p>
<p>"Without probable cause, SIS began linking prior thefts in the region involving the impostor to the Plaintiff," the complaint says, with SIS representing to police that video of these other thefts, such as one at the Short Hills Apple Store near Millburn, NJ on May 5, 2018.</p>
<p>At this point, it's alleged that SIS, on behalf of Apple, distributed a "Be on the Lookout" (BOLO) notice with the impostor's image but the name "Ousmane Bah" as a "known shoplifter." This is said to have been sent not only to Apple Stores but to police departments in the region.</p>
<p>Then there was the May 31, 2018 theft of a dozen Apple Pencils from an Apple Store in Boston. It's claimed that an SIS employee in his police report accused Ousmane Bah – who was not in Massachusetts at the time – of the thefts and said there was video to back that up.</p>
<ul>

<li><a href="https://www.theregister.com/2021/05/27/clearview_europe/">Facial recog firm Clearview hit with complaints in France, Austria, Italy, Greece and the UK</a></li>

<li><a href="https://www.theregister.com/2021/05/26/ai_insurance_lemonade/">Insurance startup backtracks on running videos of claimants through AI lie detector</a></li>

<li><a href="https://www.theregister.com/2021/05/24/in_brief_ai/">Amazon continues its ban on allowing police to use its facial-recognition software</a></li>

<li><a href="https://www.theregister.com/2021/04/24/in_brief_ai/">Banks across America test facial recognition cameras 'to spy on staff, customers'</a></li>
</ul>
<p>According to the complaint, the video depicted the impostor, not Bah, and Apple and SIS had information at the time that their identification of Bah was unreliable and therefore were reckless in their accusation.</p>
<p>In June 2018, Bah appeared in Boston Municipal Court to answer the charges and his attorney asked Apple and SIS to present the video evidence of the thefts to prove his client's innocence. Apple then told the Suffolk County prosecutor "that the video evidence of the impostor, which would have completely exculpated Ousmane Bah, had been routinely deleted."</p>
<p>The video from an October 2018 theft misattributed to Bah in Rockaway, New Jersey, was also deleted. Apple and SIS are said to have told the New York court that neither firm has any written policy on video retention.</p>
<p>And as it turned out, the video of the Boston incident turned up eventually – Bah's attorneys found it during the discovery process. It showed the impostor, not Bah.</p>
<p>On September 18, 2018, the impostor is said to have struck at an Apple Store in Freehold, New Jersey, and escaped. An SIS employee acting on Apple's behalf again filed a police complaint. The complaint charges that both Apple and SIS knew that identification was unreliable but accused Bah anyway.</p>
<p>The identity of the impostor would be revealed in the following months, the complaint says, when the impostor twice tried to pass himself off as Bah in New York and twice was arrested and booked.</p>
<p>"The arresting officer was able to identify the impostor as Mamadou Barrie, a friend of the Plaintiff, who apparently stole the learner’s permit from the Plaintiff," the complaint says. "These arrests specifically [noted] that Barrie had pretended to be Ousmane Bah."</p>
<p>There were more Apple Store thefts in October 2018, the previously mentioned one in Rockaway, New Jersey, and another incident in Trumbull, Connecticut. Apple and SIS again told authorities that Bah was to blame.</p>
<h3>
  <span>Facial failure</span>
</h3>
<p>Also that month, the impostor is said to have hit an Apple Store in Staten Island, New York. A New York police detective, it's claimed, published details of the crime and a store video screenshot to a reporting service used by the NYPD called MetrORCA.</p>
<p>The detective subsequently submitted an information request "to the NYPD’s Facial Identification Section (FIS), which identified the photograph as potentially depicting two people, one of whom was purportedly Ousmane Bah – and the other was the actual thief, Mamadou Barrie."</p>
<p>The complaint further notes that FIS policy is that automated identification is not sufficient to provide the probable cause necessary to make an arrest. Shortly thereafter, an SIS employee saw the MetrORCA bulletin and emailed the NYPD detective to tell him that Apple and SIS had identified Bah as the Staten Island thief.</p>
<p>Around 0400 ET, on November 29, 2018, Paramus Police Department, under a warrant obtained by NYPD, arrested Bah for the New York thefts.</p>
<p>"The warrant issued for Bah’s arrest contained the photo of the impostor (now known to be Mamadou Barrie)," the complaint says, adding that "Barrie in no way physically resembles the Plaintiff, other than being Black."</p>
<p>Despite the inconsistency noted at the time of the arrest, police took him into custody. This was while Bah was still being wrongfully prosecuted in Boston.</p>
<p>At the New York precinct, police recognized that Bah was not the individual in Apple's images and charges were dropped.</p>
<p>Two days later, on December 1, 2018, SIS employees apprehended the impostor trying to steal merchandise from an Apple Store in Holyoke, Massachusetts. Holyoke police forwarded the suspects fingerprints to the FBI’s National Criminal Identification Center and they were identified as belonging to Mamadou Barrie.</p>
<p>Yet two weeks later, Bah received a mailed notice of a warrant from the Freehold County District Court for his arrest for the Freehold theft based on the information provided by Apple and SIS.</p>
<p>Around that time, with an SIS employee appearing in a New Jersey court to press charges against the Cherry Hill, New Jersey thefts, a different individual with the same name "Ousmane Bah," this one a resident of Willingboro, New Jersey, showed up for the summons. He was not the thief, the complaint says, and the charges against Ousmane Bah from New York were dropped.</p>
<p>Nonetheless, prosecution against Bah continued in multiple states through June 2019.</p>
<p>Presently, the attorneys representing Bah, Daniel Malis and Subhan Tariq, are pursuing lawsuits against Apple and SIS in New York, New Jersey, and now Massachusetts.</p>
<p>Neither Apple nor SIS responded to requests for comment. ®</p>
                    
                                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“Neuroprosthesis” restores words to man with paralysis (217 pts)]]></title>
            <link>https://www.ucsf.edu/news/2021/07/420946/neuroprosthesis-restores-words-man-paralysis</link>
            <guid>27877709</guid>
            <pubDate>Sun, 18 Jul 2021 23:36:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ucsf.edu/news/2021/07/420946/neuroprosthesis-restores-words-man-paralysis">https://www.ucsf.edu/news/2021/07/420946/neuroprosthesis-restores-words-man-paralysis</a>, See on <a href="https://news.ycombinator.com/item?id=27877709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-ucsf-content">
  
    
      


<main>
    <a id="main-content" tabindex="-1"></a>
        
<div data-history-node-id="420946" role="article">
  <figure>
          
                  
            
        
  </figure>


  <header>
    




              <p>Technology Could Lead to More Natural Communication for People Who Have Suffered Speech Loss</p>
      
<p>

                  
      By
  
  Robin Marks  </p>
  </header>
</div>
<div>
      

    <div><p>Researchers at UC San Francisco have successfully developed a “speech neuroprosthesis” that has enabled a man with severe paralysis to communicate in sentences, translating signals from his brain to the vocal tract directly into words that appear as text on a screen.</p>

<p>The achievement, which was developed in collaboration with the first participant of a clinical research trial, builds on more than a decade of effort by UCSF neurosurgeon <a href="https://profiles.ucsf.edu/edward.chang">Edward Chang, MD</a>, to develop a technology that allows people with paralysis to communicate even if they are unable to speak on their own. <a href="https://mediacenteradmin.nejm.org/NEJMoa2027540.pdf?Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9tZWRpYWNlbnRlcmFkbWluLm5lam0ub3JnL05FSk1vYTIwMjc1NDAucGRmIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjI2MzIxNjAwfSwiRGF0ZUdyZWF0ZXJUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2MjU3MDI0MDB9fX1dfQ__&amp;Key-Pair-Id=K4SVLGX2XX4NO&amp;Signature=pZymsP1jGudVshYlKuSIGWGZNiOEl9PIjXoY2qBHChK6VYR02T1wI5EiCX6hcntl~oYDExsXAqDp~IjG1iiOHjJVZ8fVwYa-Qcn~rIW6GR1NGqPGuquk60V2pfYw9mX7zGm-Zzd3Kh2I5Hv7uPX1KdvDvZXqQWL0ZjuP1T-rG9E1HEy1AWNCT4nlhgQr4~iYgD2qsjpgzfOr2oNIbHHLY7q99frp90qDpDiomAOSSzTIp21Hg-pIVF72-JB-Nv~SpwzX~pAGzhzpj4Id9D5yDKg-zKKZZcQZVT4MvPK-twGawX8TQyuSf8Q3A6GMW6589EgkQ~wspeosMm4rjP1FZA__">The study</a> appears July 15 in the New England Journal of Medicine.</p>

<figure><figure data-embed-button="media_assets" data-entity-embed-display="entity_reference:media_thumbnail" data-entity-embed-display-settings="half__image" data-entity-type="media" data-entity-uuid="7699b133-4c5a-4786-9c52-784e5b03a516" data-langcode="en"><picture><img src="https://www.ucsf.edu/sites/default/files/styles/half__image/public/2021-07/eddie-chang-surgery-neural-prosthesis-story.png" width="720" height="720" alt="Eddie Chang reflected in a screen showing activity in the brain during surgery" loading="lazy"></picture></figure><figcaption><p>Eddie Chang performing brain surgery. <em>Photo by&nbsp;Barbara Ries</em></p></figcaption></figure><p>“To our knowledge, this is the first successful demonstration of direct decoding of full words from the brain activity of someone who is paralyzed and cannot speak,” said Chang, the Joan and Sanford Weill Chair of Neurological Surgery at UCSF, Jeanne Robertson Distinguished Professor, and senior author on the study. “It shows strong promise to restore communication by tapping into the brain's natural speech machinery.”</p>

<p>Each year, thousands of people lose the ability to speak due to stroke, accident, or disease. With further development, the approach described in this study could one day enable these people to fully communicate.</p>

<h2>Translating Brain Signals into Speech</h2>

<p>Previously, work in the field of communication neuroprosthetics has focused on restoring communication through spelling-based approaches to type out letters one-by-one in text. Chang’s study differs from these efforts in a critical way: his team is translating signals intended to control muscles of the vocal system for speaking words, rather than signals to move the arm or hand to enable typing. Chang said this approach taps into the natural and fluid aspects of speech and promises more rapid and organic communication.</p>

<p>“With speech, we normally communicate information at a very high rate, up to 150 or 200 words per minute,” he said, noting that spelling-based approaches using typing, writing, and controlling a cursor are considerably slower and more laborious. “Going straight to words, as we’re doing here, has great advantages because it’s closer to how we normally speak.”</p>


  <figure data-embed-button="media_assets" data-entity-embed-display="entity_reference:media_thumbnail" data-entity-type="media" data-entity-uuid="861900df-8c9e-4e94-b4cd-6eebcb95fe60" data-langcode="en"><picture><img src="https://www.ucsf.edu/sites/default/files/2021-07/hello-vs-h-typing.gif" width="850" height="551" alt="An example of neuroprosthesis with wires sticking out of its end next to the words hello vs h with a blinking cursor" loading="lazy"></picture></figure><p>Over the past decade, Chang’s progress toward this goal was facilitated by patients at the UCSF Epilepsy Center who were undergoing neurosurgery to pinpoint the origins of their seizures using electrode arrays placed on the surface of their brains. These patients, all of whom had normal speech, volunteered to have their brain recordings analyzed for speech-related activity. Early success with these patient volunteers paved the way for the current trial in people with paralysis.</p>

<p>Previously, Chang and colleagues in the UCSF Weill Institute for Neurosciences mapped <a href="https://www.ucsf.edu/news/2019/04/414296/synthetic-speech-generated-brain-recordings">the cortical activity patterns associated with vocal tract movements that produce each consonant and vowel</a>. To translate those findings into speech recognition of full words, David Moses, PhD, a postdoctoral engineer in the Chang lab and one of the lead authors of the new study, <a href="https://www.ucsf.edu/news/2019/07/415046/team-ids-spoken-words-and-phrases-real-time-brains-speech-signals">developed new methods for real-time decoding of those patterns</a> and statistical language models to improve accuracy.</p>

<p>But their success in decoding speech in participants who were able to speak didn’t guarantee that the technology would work in a person whose vocal tract is paralyzed. “Our models needed to learn the mapping between complex brain activity patterns and intended speech,” said Moses. “That poses a major challenge when the participant can’t speak.”</p>

<p>In addition, the team didn’t know whether brain signals controlling the vocal tract would still be intact for people who haven’t been able to move their vocal muscles for many years. “The best way to find out whether this could work was to try it,” said Moses.</p>

<h2>The First 50 Words</h2>

<p>To investigate the potential of this technology in patients with paralysis, Chang partnered with colleague <a href="https://profiles.ucsf.edu/karunesh.ganguly">Karunesh Ganguly</a>, MD, PhD, an associate professor of neurology, to launch a study known as “BRAVO” (Brain-Computer Interface Restoration of Arm and Voice). The first participant in the trial is a man in his late 30s who suffered a devastating brainstem stroke more than 15 years ago that severely damaged the connection between his brain and his vocal tract and limbs. Since his injury, he has had extremely limited head, neck, and limb movements, and communicates by using a pointer attached to a baseball cap to poke letters on a screen.</p>
</div>

      

  


  
<div>
  
              <p>The participant, who asked to be referred to as BRAVO1, worked with the researchers to create a 50-word vocabulary that Chang’s team could recognize from brain activity using advanced computer algorithms. The vocabulary – which includes words such as “water,” “family,” and “good” – was sufficient to create hundreds of sentences expressing concepts applicable to BRAVO1’s daily life.</p>
<p>For the study, Chang surgically implanted a high-density electrode array over BRAVO1’s speech motor cortex. After the participant’s full recovery, his team recorded 22 hours of neural activity in this brain region over 48 sessions and several months. In each session, BRAVO1 attempted to say each of the 50 vocabulary words many times while the electrodes recorded brain signals from his speech cortex.</p>


<h2>Translating Attempted Speech into Text</h2>

<p>To translate the patterns of recorded neural activity into specific intended words, the other two lead authors of the study, Sean Metzger, MS and Jessie Liu, BS, both bioengineering doctoral students in the Chang Lab used custom neural network models, which are forms of artificial intelligence. When the participant attempted to speak, these networks distinguished subtle patterns in brain activity to detect speech attempts and identify which words he was trying to say.</p>

<p>To test their approach, the team first presented BRAVO1 with short sentences constructed from the 50 vocabulary words and asked him to try saying them several times. As he made his attempts, the words were decoded from his brain activity, one by one, on a screen.</p>

<p>Then the team switched to prompting him with questions such as “How are you today?” and “Would you like some water?” As before, BRAVO1’s attempted speech appeared on the screen. “I am very good,” and “No, I am not thirsty.”</p>

<p>The team&nbsp;found that the system was able to decode words from brain activity at rate of up to 18 words per minute with up to 93 percent accuracy (75 percent median). Contributing to the success was a language model Moses applied that implemented an “auto-correct” function, similar to what is used by consumer texting and speech recognition software.</p>

<p>Moses characterized the early trial results as a proof of principle. “We were thrilled to see the accurate decoding of a variety of meaningful sentences,” he said. “We’ve shown that it is actually possible to facilitate communication in this way and that it has potential for use in conversational settings.”</p>

<figure><figure data-embed-button="media_assets" data-entity-embed-display="entity_reference:media_thumbnail" data-entity-embed-display-settings="full_bleed__image" data-entity-type="media" data-entity-uuid="44fa74a3-ead9-468f-9b52-2ad4fd6ef198" data-langcode="en"><picture><img src="https://www.ucsf.edu/sites/default/files/styles/full_bleed__image/public/2021-07/researchers-BRAVO-study-black-and-white-v2.jpg" width="1080" height="725" alt="Three researchers who participated in the Bravo study side by side over a neuron background" loading="lazy"></picture></figure><figcaption><p>Jessie Liu, BS,&nbsp;David Moses, PhD,&nbsp;and Sean Metzger, MS.</p></figcaption></figure><p>Looking forward, Chang and Moses said they will expand the trial to include more participants affected by severe paralysis and communication deficits. The team is currently working to increase the number of words in the available vocabulary, as well as improve the rate of speech.</p>

<p>Both said that while the study focused on a single participant and a limited vocabulary, those limitations don’t diminish the accomplishment. “This is an important technological milestone for a person who cannot communicate naturally,” said Moses, “and it demonstrates the potential for this approach to give a voice to people with severe paralysis and speech loss.”</p>

<p><strong>Authors:</strong> The full author list is David A. Moses, PhD*; Sean L. Metzger, MS*; Jessie R. Liu, BS*; Gopala K. Anumanchipalli, PhD; Joseph G. Makin, PhD; Pengfei F. Sun, PhD; Josh Chartier, PhD; Maximilian E. Dougherty, BA; Patricia M. Liu, MA; Gary M. Abrams, MD; Adelyn Tu-Chan, DO; Karunesh Ganguly, MD, PhD; and Edward F. Chang, MD, all of UCSF. Funding sources included National Institutes of Health (U01 NS098971-01), philanthropy, and a sponsored research agreement with Facebook Reality Labs (FRL), which completed in early 2021. * Denotes equal contribution.</p>

<p><strong>Funding:</strong> Supported by a research contract under Facebook’s Sponsored Academic Research Agreement, the National Institutes of Health (grant NIH U01 DC018671-01A1), Joan and Sandy Weill and the Weill Family Foundation, the Bill and Susan Oberndorf Foundation, the William K. Bowes, Jr. Foundation, and the Shurl and Kay Curci Foundation. UCSF researchers conducted all clinical trial design, execution, data analysis and reporting.&nbsp;Research participant data were collected solely by UCSF, are held confidentially, and are not shared with third parties. FRL provided high-level feedback and machine learning advice.</p>

<p><strong>About UCSF:</strong> The University of California, San Francisco (UCSF) is exclusively focused on the health sciences and is dedicated to promoting health worldwide through advanced biomedical research, graduate-level education in the life sciences and health professions, and excellence in patient care. UCSF Health, which serves as UCSF’s primary academic medical center, includes <a href="https://health.usnews.com/best-hospitals/area/ca/ucsf-medical-center-6930043">top-ranked specialty hospitals</a> and other clinical programs,&nbsp;and has affiliations throughout the Bay Area.&nbsp;UCSF School of Medicine also has a regional campus in Fresno. Learn more at&nbsp;ucsf.edu or see our&nbsp;<a href="https://www.ucsf.edu/sites/default/files/UCSF_General_Fact_Sheet.pdf">Fact Sheet</a>.</p>

      
</div>






</div>
  </main>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Coming soon – “Meet the Batch” threads for parallel Launch HNs (200 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=27877280</link>
            <guid>27877280</guid>
            <pubDate>Sun, 18 Jul 2021 22:33:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=27877280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="27877280">
      <td><span></span></td>      <td><center><a id="up_27877280" href="https://news.ycombinator.com/vote?id=27877280&amp;how=up&amp;goto=item%3Fid%3D27877280"></a></center></td><td><a href="https://news.ycombinator.com/item?id=27877280">Tell HN: Coming soon – “Meet the Batch” threads for parallel Launch HNs</a></td></tr><tr><td colspan="2"></td><td>
        <span id="score_27877280">200 points</span> by <a href="https://news.ycombinator.com/user?id=dang">dang</a> <span title="2021-07-18T22:33:56"><a href="https://news.ycombinator.com/item?id=27877280">10 hours ago</a></span> <span id="unv_27877280"></span> | <a href="https://news.ycombinator.com/hide?id=27877280&amp;goto=item%3Fid%3D27877280">hide</a> | <a href="https://hn.algolia.com/?query=Tell%20HN%3A%20Coming%20soon%20%E2%80%93%20%E2%80%9CMeet%20the%20Batch%E2%80%9D%20threads%20for%20parallel%20Launch%20HNs&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=27877280&amp;auth=fe08df5bd17e0338e918dcfc9e902786ce8b0389">favorite</a> | <a href="https://news.ycombinator.com/item?id=27877280">69&nbsp;comments</a>              </td></tr>
      <tr></tr><tr><td colspan="2"></td><td>Each YC startup gets one chance to do a Launch HN thread that gets placed on HN's front page [1]. This is one of the three things that HN gives back to YC in exchange for funding it [2]. We started doing these in 2017 and they've worked out pretty well over the years [3], I think mostly because they're more interesting than job ads. However, they have to be written in a special way for that to work (more on this below).<p>Problem: HN's front page can only accommodate a fixed number of startups while YC keeps funding more (700+ a year and growing). We do two Launch HNs a day during the stampede before each Demo Day, but I think we overdid that in W21, and even 2 per day all year, which is out of the question, still wouldn't be enough.</p><p>Other problem: I work with the startups to edit their launch texts into a form that HN is more likely to find interesting. Mostly this consists of cajoling, persuading, and (when that fails) forcing them not to sound like marketing, sales, or PR. If you'd like to see the instructions we give founders about this, they're at [4].</p><p>Founders are used to talking to customers and investors, and those styles are terrible for HN, so most Launch HNs need a lot of editing. Unlike the front page, this work should be scalable, but it has to be done by someone who's familiar with what HN likes and what its conventions are, and it hasn't (yet) proven easy to train anyone to do it—you sort of have to dip them in the vat of HN over and over until they get steeped, and most people don't want to be dipped in a vat, or at least not this vat. So in practice I still do the editing and am still the bottleneck. 40 startups are currently in the pipe and it's backing up faster than I can process them.</p><p>Hence, new idea time: we're going to try aggregate launch threads for YC startups, tentatively called "Meet the Batch". These will be like Launch HNs, but with more than one startup, and shorter blurbs. Each startup will post its blurb as a comment and then HN readers can discuss and interact with the ones they find interesting.</p><p>Since each of these will be in lieu of a Launch HN, the number of frontpage threads won't go up, but throughput will. We have no idea how well it will work—it's just an experiment. We'll probably start with one per week and do traditional Launch HNs the rest of the time.</p><p>Which startups will get standalone Launch HNs vs. being in the aggregate threads? I'll decide that based mostly on what I think HN is likely to find interesting. That's <i>not</i> the same thing as which startups are good (or I think are good!) so please don't take it as that sort of signal.</p><p>So anyway, that's the plan. I wanted to give you all a heads-up, first so you know what to expect, and second so we can answer any questions and have any meta discussion now, instead of later when comments should really be about the startups. If you have questions, feedback, flames, or hounds to unleash, have at it—also, any ideas about how we can do any of this better are most welcome.</p><p>p.s. Late Sunday is the HN equivalent of a Friday news drop but it's the only spare time I had. We might re-up this thread tomorrow (a la [5]) so others get the info.</p><p>[1] <a href="https://news.ycombinator.com/launches" rel="nofollow">https://news.ycombinator.com/launches</a></p><p>[2] <a href="https://news.ycombinator.com/newsfaq.html#yc" rel="nofollow">https://news.ycombinator.com/newsfaq.html#yc</a> - the other two are job ads and orange usernames.</p><p>[3] Past posts about this: <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=false&amp;query=by%3Adang%20%22launch%20hns%22&amp;sort=byDate&amp;type=comment" rel="nofollow">https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=false&amp;qu...</a></p><p>[4] <a href="https://news.ycombinator.com/yli.html" rel="nofollow">https://news.ycombinator.com/yli.html</a></p><p>[5] <a href="https://news.ycombinator.com/item?id=26998308" rel="nofollow">https://news.ycombinator.com/item?id=26998308</a></p></td></tr>
        <tr></tr><tr><td colspan="2"></td><td>
          <form method="post" action="comment">
                </form>
      </td></tr>
  </tbody></table>
      </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Racket v8.2 (102 pts)]]></title>
            <link>https://blog.racket-lang.org/2021/07/racket-v8-2.html</link>
            <guid>27877203</guid>
            <pubDate>Sun, 18 Jul 2021 22:21:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.racket-lang.org/2021/07/racket-v8-2.html">https://blog.racket-lang.org/2021/07/racket-v8-2.html</a>, See on <a href="https://news.ycombinator.com/item?id=27877203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <header>
  
  </header>

<p><em>posted by John Clements</em></p>

<p>Racket version 8.2 is now available from <a href="https://download.racket-lang.org/">https://download.racket-lang.org</a>.</p>

<ul>
 <li>
  <p>Racket CS improved the performance of large-integer arithmetic.</p></li>
 <li>
  <p>Racket has improved support for layered and tethered installation.</p></li>
 <li>
  <p>Racket CS supports nonatomic allocation via ffi/unsafe.</p></li>
 <li>
  <p>Cross-compilation works fully with the <code>raco cross</code> tool, which is  distributed separately as the “raco-cross” package.</p></li>
 <li>
  <p>DrRacket has performance improvements when editing files with  picts containing large bitmaps.</p></li>
 <li>
  <p>Typed Racket more consistently refines field types of non-polymorphic  structs.</p></li>
 <li>
  <p>Printing of values is unified across the teaching language  implementations and the stepper.</p></li></ul>

<p>The following people contributed to this release:</p>

<p>Alex Harsányi, Alex Knauth, Amirouche, Andrew Mauer-Oats, Bob Burger, Bogdan Popa, Cameron Moy, Crystal Jacobs, Dale Vaillancourt, Diego A. Mundo, Fred Fu, Greg Hendershott, Gustavo Massaccesi, Jack Firth, Jamie Taylor, Jarhmander, Jason Hemann, Jay McCarthy, Jeffrey D. Swan, Jens Axel Søgaard, Jesse Alama, John Clements, Laurent Orseau, Lazerbeak12345, Matthew Flatt, Matthias Felleisen, Mike Sperber, Nada Amin, Noah Ma, Oscar Waddell, Paulo Matos, Pavel Panchekha, Philip McGrath, Ray Racine, Robby Findler, Ryan Culpepper, Sam Tobin-Hochstadt, Shu-Hung You, Sorawee Porncharoenwase, Stephen Chang, Thorsten Blum, Tony Garnock-Jones, WarGrey Gyoudmon Ju, William J. Bowman, Yu Fang, and minor-change.</p>

<p>Feedback Welcome</p>
<col-2>

</col-2></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Word gap: When money’s tight, parents talk less to kids (204 pts)]]></title>
            <link>https://news.berkeley.edu/2021/07/16/word-gap-when-moneys-tight-parents-talk-less-to-kids/</link>
            <guid>27876560</guid>
            <pubDate>Sun, 18 Jul 2021 20:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.berkeley.edu/2021/07/16/word-gap-when-moneys-tight-parents-talk-less-to-kids/">https://news.berkeley.edu/2021/07/16/word-gap-when-moneys-tight-parents-talk-less-to-kids/</a>, See on <a href="https://news.ycombinator.com/item?id=27876560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					
		<div id="attachment_95174"><p><a href="https://news.berkeley.edu/wp-content/uploads/2021/07/Parent-Child-Silence750.jpg"><img aria-describedby="caption-attachment-95174" loading="lazy" src="https://news.berkeley.edu/wp-content/uploads/2021/07/Parent-Child-Silence750.jpg" alt="Adult frowning at smartphone while child sits with arms folded." width="750" height="500" srcset="https://news.berkeley.edu/wp-content/uploads/2021/07/Parent-Child-Silence750.jpg 750w, https://news.berkeley.edu/wp-content/uploads/2021/07/Parent-Child-Silence750-410x273.jpg 410w" sizes="(max-width: 750px) 100vw, 750px"></a></p><p id="caption-attachment-95174">A new study suggests money worries prompt parents to talk less to their kids, exacerbating the “word gap.” (iStockphoto)</p></div>
<p>Three decades ago, child development researchers found that low-income children heard tens of millions fewer words in their homes than their more affluent peers by the time they reached kindergarten. This “word gap” was and continues to be linked to a socioeconomic disparity in academic achievement.</p>
<p>While parenting deficiencies have long been blamed for the word gap, new UC Berkeley research implicates the economic context in which parenting takes place — in other words, the wealth gap.</p>
<p>The findings, published this month in the journal <em>Developmental Science</em>, provide the first evidence that parents may talk less to their kids when experiencing financial scarcity.</p>
<p>“We were interested in what happens when parents think about or experience financial scarcity and found evidence that such strain could suppress their speech to their children,” said study senior author Mahesh Srinivasan, a professor of psychology at UC Berkeley.</p>
<p>“Our results suggest that parenting training may not be sufficient to close the academic achievement gap without addressing the broader issue of income inequality,” Srinivasan added.</p>
<p>The study’s preliminary results lend credence to the developmental and educational benefits of such poverty-cutting government programs as the federal American Rescue Plan’s Child Tax Credit and other supplemental cash payouts for needy families.</p>
<p>“Existing interventions toward eliminating the word gap have often focused on improving parenting skills,” Srinivasan said. “But our findings suggest that relieving parents of their financial burdens, such as through direct cash transfers, could also substantially change the ways they engage with their kids.”</p>
<h3>How they conducted the study</h3>
<p>In the first experiment, researchers sought to observe how parents would interact with their children (in this case, 3-year-olds) after the parents were asked to describe times in which they had recently experienced scarcity. A control group of parents were instead asked to describe other recent activities.</p>
<p>Of the 84 parents in the study, those in the experimental group who described their experiences of financial scarcity spoke less to their 3-year-olds during laboratory observations than parents who reflected on other forms of scarcity (like not having enough fruit), or parents who had not been asked to recollect experiences of resource insecurity.</p>
<p>The second experiment used existing data collected via LENA technology, tiny “talk pedometer” devices worn by children that record their conversations and count the words they hear and say.</p>
<p>As the researchers predicted, analyses revealed that parents engaged in fewer conversational turns with their children at the month’s end, a time that typically coincides with money being tight as parents await paychecks or other sources of income.</p>
<p>“Because we had recordings from the same parents at different times of the month, we could essentially use parents as their own controls,” said study lead author Monica Ellwood-Lowe, a Ph.D. student in psychology at UC Berkeley. “This allowed us to really pinpoint differences in their speech patterns when they were more or less likely to be experiencing financial strain, independent of any of their own personal characteristics.”</p>
<p>The term “word gap” was coined in the early 1990s when University of Kansas researchers Betty Hart and Todd Risley tracked verbal interactions in the homes of 42 families to study early language development in the children’s first three years.</p>
<p>Each day, the researchers recorded an hour of conversation in each household, then counted all the words the children heard during those recording times.</p>
<p>The results were detailed in their 1995 book, <em>Meaningful Differences in the Everyday Experience of Young American Children</em>, and in a 2003 follow-up article, “The Early Catastrophe: The 30 Million Word Gap by Age 3.”</p>
<p>While some have questioned Hart and Risley’s methodology, their basic finding has been replicated many times, prompting calls for approaches to narrow the disparity. Enter Srinivasan and his research team:</p>
<p>“It struck us that what was missing from the conversation about the word gap was the possibility that poverty, and the many difficult experiences associated with it, could itself affect parents’ speech,” Srinivasan said.</p>
<p>Preliminary findings support the researchers’ hypothesis but also call for a deeper dive into the relationship between money worries and parents’ verbal engagement with their children, he said.</p>
<p>“This research doesn’t mean that children whose parents are struggling financially are doomed to have smaller vocabularies,” Ellwood-Lowe said. “The takeaway here is really just the importance of making sure parents have the resources they need to parent.”</p>
<p>“If you are worried about putting food on the table tonight, or scraping together money for that medical bill, or figuring out where to enroll your child in school now that you have been evicted from your neighborhood, you may be less likely to narrate the color of the sky to your child as you ride together on the bus,” the study concludes.</p>
<p><strong><a href="https://psyarxiv.com/byp4k">Click here to read a copy of the study</a></strong></p>
		
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesseract OCR (154 pts)]]></title>
            <link>https://github.com/tesseract-ocr/tesseract</link>
            <guid>27876383</guid>
            <pubDate>Sun, 18 Jul 2021 20:27:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tesseract-ocr/tesseract">https://github.com/tesseract-ocr/tesseract</a>, See on <a href="https://news.ycombinator.com/item?id=27876383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<p><a href="https://travis-ci.org/tesseract-ocr/tesseract" rel="nofollow"><img src="https://camo.githubusercontent.com/2854e60bba2ebd2017d7d71bbd312fb485654606118d5df7bb9bad58afea8efb/68747470733a2f2f7472617669732d63692e6f72672f7465737365726163742d6f63722f7465737365726163742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tesseract-ocr/tesseract.svg?branch=master"></a>
<a href="https://ci.appveyor.com/project/zdenop/tesseract/" rel="nofollow"><img src="https://camo.githubusercontent.com/0029e047a1f03572a4cc1d1f390606028f57cf6faa8cfa2f999798920970c362/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6d69616830696b667366306a333831392f6272616e63682f6d61737465723f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseract-ocr/tesseract/workflows/sw/badge.svg"><img src="https://github.com/tesseract-ocr/tesseract/workflows/sw/badge.svg" alt="Build status"></a><br>
<a href="https://scan.coverity.com/projects/tesseract-ocr" rel="nofollow"><img src="https://camo.githubusercontent.com/3fdeaa0302f32e52e77d258f82d35571ac25ece6063d150c244e97ffc831bcc0/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f7465737365726163742d6f63722f62616467652e737667" alt="Coverity Scan Build Status" data-canonical-src="https://scan.coverity.com/projects/tesseract-ocr/badge.svg"></a>
<a href="https://lgtm.com/projects/g/tesseract-ocr/tesseract/context:cpp" rel="nofollow"><img src="https://camo.githubusercontent.com/dfd2df706b767c0aa08d89f7721ac58d252bba52844370bf51659aad68bcaa18/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6370702f672f7465737365726163742d6f63722f7465737365726163742e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Code Quality: Cpp" data-canonical-src="https://img.shields.io/lgtm/grade/cpp/g/tesseract-ocr/tesseract.svg?logo=lgtm&amp;logoWidth=18"></a>
<a href="https://lgtm.com/projects/g/tesseract-ocr/tesseract/alerts" rel="nofollow"><img src="https://camo.githubusercontent.com/8d16e87e6896eba9de704eadf867e4a4430c63e8f3b8bdc623e6dfcd1f97e605/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f7465737365726163742d6f63722f7465737365726163742e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Total Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/tesseract-ocr/tesseract.svg?logo=lgtm&amp;logoWidth=18"></a>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=2&amp;q=proj:tesseract-ocr" rel="nofollow"><img src="https://camo.githubusercontent.com/5897287e14b5ae305bbb8eb0b0b7e48b38e1dcd322abf88e34798ac9d05c7589/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f73732d2d66757a7a2d66757a7a696e672d627269676874677265656e" alt="OSS-Fuzz" data-canonical-src="https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen"></a>
<br>
<a href="https://raw.githubusercontent.com/tesseract-ocr/tesseract/master/LICENSE" rel="nofollow"><img src="https://camo.githubusercontent.com/9bf08b5718ffcc765664dead73e4212a8268d879d6e8626c3ab535592443ee95/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d2d322e302d626c75652e737667" alt="GitHub license" data-canonical-src="https://img.shields.io/badge/license-Apache--2.0-blue.svg"></a>
<a href="https://github.com/tesseract-ocr/tesseract/releases/"><img src="https://camo.githubusercontent.com/d744158ab8d7e46d9d59e29f0d7568c01f76490a6d818943e456c34071513d8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f61642d616c6c25323072656c65617365732d627269676874677265656e2e737667" alt="Downloads" data-canonical-src="https://img.shields.io/badge/download-all%20releases-brightgreen.svg"></a></p>
<h2>About</h2>
<p>This package contains an <strong>OCR engine</strong> - <code>libtesseract</code> and a <strong>command line program</strong> - <code>tesseract</code>.
Tesseract 4 adds a new neural net (LSTM) based OCR engine which is focused
on line recognition, but also still supports the legacy Tesseract OCR engine of
Tesseract 3 which works by recognizing character patterns. Compatibility with
Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).
It also needs <a href="https://tesseract-ocr.github.io/tessdoc/Data-Files.html" rel="nofollow">traineddata</a> files which support the legacy engine, for example
those from the tessdata repository.</p>
<p>The lead developer is Ray Smith. The maintainer is Zdenko Podobny.
For a list of contributors see <a href="https://github.com/tesseract-ocr/tesseract/blob/master/AUTHORS">AUTHORS</a>
and GitHub's log of <a href="https://github.com/tesseract-ocr/tesseract/graphs/contributors">contributors</a>.</p>
<p>Tesseract has <strong>unicode (UTF-8) support</strong>, and can <strong>recognize more than 100 languages</strong> "out of the box".</p>
<p>Tesseract supports <strong>various output formats</strong>: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV. The master branch also has experimental support for ALTO (XML) output.</p>
<p>You should note that in many cases, in order to get better OCR results,
you'll need to <strong><a href="https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html" rel="nofollow">improve the quality</a> of the image</strong> you are giving Tesseract.</p>
<p>This project <strong>does not include a GUI application</strong>.
If you need one, please see the <a href="https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html" rel="nofollow">3rdParty</a> documentation.</p>
<p>Tesseract <strong>can be trained to recognize other languages</strong>.
See <a href="https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html" rel="nofollow">Tesseract Training</a> for more information.</p>
<h2>Brief history</h2>
<p>Tesseract was originally developed at Hewlett-Packard Laboratories Bristol and
at Hewlett-Packard Co, Greeley Colorado between 1985 and 1994, with some
more changes made in 1996 to port to Windows, and some C++izing in 1998.
In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.</p>
<p>The latest (LSTM based) stable version is <strong><a href="https://github.com/tesseract-ocr/tesseract/releases/tag/4.1.1">4.1.1</a></strong>, released on December 26, 2019.
Latest source code is available from <a href="https://github.com/tesseract-ocr/tesseract/tree/master">master branch on GitHub</a>.
Open issues can be found in <a href="https://github.com/tesseract-ocr/tesseract/issues">issue tracker</a>,
and <a href="https://tesseract-ocr.github.io/tessdoc/Planning.html" rel="nofollow">planning documentation</a>.</p>
<p>The latest 3.0x version is <strong><a href="https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.02">3.05.02</a></strong>, released on June 19, 2018. Latest source code for 3.05 is available from <a href="https://github.com/tesseract-ocr/tesseract/tree/3.05">3.05 branch on GitHub</a>.
There is no development for this version, but it can be used for special cases (e.g. see <a href="https://tesseract-ocr.github.io/tessdoc/Planning.html#regression-of-features-from-30x" rel="nofollow">Regression of features from 3.0x</a>).</p>
<p>See <strong><a href="https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html" rel="nofollow">Release Notes</a></strong>
and <strong><a href="https://github.com/tesseract-ocr/tesseract/blob/master/ChangeLog">Change Log</a></strong> for more details of the releases.</p>
<h2>Installing Tesseract</h2>
<p>You can either <a href="https://tesseract-ocr.github.io/tessdoc/Home.html" rel="nofollow">Install Tesseract via pre-built binary package</a>
or <a href="https://tesseract-ocr.github.io/tessdoc/Compiling.html" rel="nofollow">build it from source</a>.</p>
<p>C++17 support is required for building.</p>
<h2>Running Tesseract</h2>
<p>Basic <strong><a href="https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html" rel="nofollow">command line usage</a></strong>:</p>
<div data-snippet-clipboard-copy-content="tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]
"><pre><code>tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]
</code></pre></div>
<p>For more information about the various command line options use <code>tesseract --help</code> or <code>man tesseract</code>.</p>
<p>Examples can be found in the <a href="https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image" rel="nofollow">documentation</a>.</p>
<h2>For developers</h2>
<p>Developers can use <code>libtesseract</code> <a href="https://github.com/tesseract-ocr/tesseract/blob/master/include/tesseract/capi.h">C</a> or
<a href="https://github.com/tesseract-ocr/tesseract/blob/master/include/tesseract/baseapi.h">C++</a> API to build their own application.
If you need bindings to <code>libtesseract</code> for other programming languages, please see the
<a href="https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers" rel="nofollow">wrapper</a> section in the AddOns documentation.</p>
<p>Documentation of Tesseract generated from source code by doxygen can be found on <a href="https://tesseract-ocr.github.io/" rel="nofollow">tesseract-ocr.github.io</a>.</p>
<h2>Support</h2>
<p>Before you submit an issue, please review <strong><a href="https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md">the guidelines for this repository</a></strong>.</p>
<p>For support, first read the <a href="https://tesseract-ocr.github.io/tessdoc/" rel="nofollow">documentation</a>,
particularly the <a href="https://tesseract-ocr.github.io/tessdoc/FAQ.html" rel="nofollow">FAQ</a> to see if your problem is addressed there.
If not, search the <a href="https://groups.google.com/g/tesseract-ocr" rel="nofollow">Tesseract user forum</a>, the <a href="https://groups.google.com/g/tesseract-dev" rel="nofollow">Tesseract developer forum</a> and <a href="https://github.com/tesseract-ocr/tesseract/issues">past issues</a>, and if you still can't find what you need, ask for support in the mailing-lists.</p>
<p>Mailing-lists:</p>
<ul>
<li><a href="https://groups.google.com/g/tesseract-ocr" rel="nofollow">tesseract-ocr</a> - For tesseract users.</li>
<li><a href="https://groups.google.com/g/tesseract-dev" rel="nofollow">tesseract-dev</a> - For tesseract developers.</li>
</ul>
<p>Please report an issue only for a <strong>bug</strong>, not for asking questions.</p>
<h2>License</h2>
<div data-snippet-clipboard-copy-content="The code in this repository is licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"><pre><code>The code in this repository is licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</code></pre></div>
<p><strong>NOTE</strong>: This software depends on other packages that may be licensed under different open source licenses.</p>
<p>Tesseract uses <a href="http://leptonica.com/" rel="nofollow">Leptonica library</a> which essentially
uses a <a href="http://leptonica.com/about-the-license.html" rel="nofollow">BSD 2-clause license</a>.</p>
<h2>Dependencies</h2>
<p>Tesseract uses <a href="https://github.com/DanBloomberg/leptonica">Leptonica library</a>
for opening input images (e.g. not documents like pdf).
It is suggested to use leptonica with built-in support for <a href="https://zlib.net/" rel="nofollow">zlib</a>,
<a href="https://sourceforge.net/projects/libpng" rel="nofollow">png</a> and
<a href="http://www.simplesystems.org/libtiff" rel="nofollow">tiff</a> (for multipage tiff).</p>
<h2>Latest Version of README</h2>
<p>For the latest online version of the README.md see:</p>
<p><a href="https://github.com/tesseract-ocr/tesseract/blob/master/README.md">https://github.com/tesseract-ocr/tesseract/blob/master/README.md</a></p>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study: Global plant growth surging alongside carbon dioxide (2017) (107 pts)]]></title>
            <link>https://www.noaa.gov/news/study-global-plant-growth-surging-alongside-carbon-dioxide</link>
            <guid>27876366</guid>
            <pubDate>Sun, 18 Jul 2021 20:25:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noaa.gov/news/study-global-plant-growth-surging-alongside-carbon-dioxide">https://www.noaa.gov/news/study-global-plant-growth-surging-alongside-carbon-dioxide</a>, See on <a href="https://news.ycombinator.com/item?id=27876366">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-observe-resizes="">
<p dir="ltr">A trace gas present in the atmosphere in miniscule amounts is helping scientists answer one of the biggest questions out there: <em>Has plant growth increased alongside rising levels of carbon dioxide in the atmosphere?</em></p>

<p dir="ltr">It turns out the answer is <em>Yes</em> – in a big way. A new study published in the April 6 edition of the journal Nature concludes that as emissions of carbon dioxide from burning fossil fuels have increased since the start of the 20th century, plants around the world are utilizing 30 percent more carbon dioxide (CO<sub>2</sub>), spurring plant growth.</p>

<p dir="ltr">In 2007, NOAA scientist Stephen Montzka wrote a pivotal paper that identified the trace gas, <em>carbonyl sulfide</em>, as a key to estimating how much CO<sub>2</sub> &nbsp;plants are taking in as they grow.</p>

<p dir="ltr">Recently, Montzka was part of a team of scientists led by Elliot Campbell of University of California, Merced, that reviewed the 54,000-year record for atmospheric carbonyl sulfide from measurements of air trapped in the snowpack at the South Pole. “When we did, we discovered a massive, changing signal from the<a href="https://www.esrl.noaa.gov/gmd/outreach/carbon_toolkit/basics.html"> biosphere</a>,” he says.<br>
&nbsp;</p>

<p dir="ltr"><span><strong>Why carbonyl sulfide?</strong></span></p>

<p dir="ltr">Plants take up CO<sub>2</sub> when they photosynthesize, but they release it when they respire, decay or are burned. That means that the removal rate of CO<sub>2</sub> by plants can’t be directly estimated on global scales from measurements of CO<sub>2</sub> alone.</p>

<p dir="ltr">But plants need other nutrients, including sulfur – and once they grab it, they don’t give it back. Carbonyl sulfide – or COS, a molecule comprised of a carbon atom, a sulfur atom and an oxygen atom – is found in tiny amounts (parts per trillion) in the atmosphere. Ongoing NOAA sampling and analysis of air trapped in Antarctic ice cores has enabled scientists to estimate changes in plant consumption of carbonyl sulfide during the past 100 years and then calculate how much CO<sub>2</sub> plants are absorbing.</p>

<p dir="ltr">The study provides the first truly global estimate of the amount of CO<sub>2</sub> that plants “fix” into their tissues like leaves in response to increasing concentrations of the gas over the past century.&nbsp;Montzka says that tracking COS will help scientists monitor how much carbon land plants are removing from the atmosphere as CO<sub>2</sub> levels increase.</p>

<p dir="ltr">“These results will help us better predict the biosphere’s response to continued fossil fuel emissions – and ultimately improve our predictions of climate change.”</p>

<p><a href="http://www.nature.com/nature/journal/v544/n7648/full/nature22030.html.">Read more about this study in the journal <em>Nature</em>.<span> offsite link</span></a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A plan to rescue the Web from the Internet (2017) (125 pts)]]></title>
            <link>https://staltz.com/a-plan-to-rescue-the-web-from-the-internet.html</link>
            <guid>27876201</guid>
            <pubDate>Sun, 18 Jul 2021 20:08:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://staltz.com/a-plan-to-rescue-the-web-from-the-internet.html">https://staltz.com/a-plan-to-rescue-the-web-from-the-internet.html</a>, See on <a href="https://news.ycombinator.com/item?id=27876201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>
      
      <h2>A plan to rescue the Web from the Internet</h2>
        <h3>18 Dec 2017</h3>
    </p>
    <p>My previous article, <a href="https://staltz.com/the-web-began-dying-in-2014-heres-how.html"><em>The Web began dying in 2014, here’s how</em></a>, raised much more awareness than I thought it would. Many people found it to be an insightful analysis of the Web under the control of tech giants, but the article ended without providing anything positive to hold on to.</p>

<p>I actually have hope for the Web. There are legimately viable ways of preserving freedom on the Web while taking the platform forward and keeping it competitive against proprietary alternatives from tech giants. But it can only happen if the Web takes a courageous step towards its next level. If it stays in its current form, the Web has little chance of being relevant while America’s <a href="https://www.nytimes.com/2017/12/14/technology/net-neutrality-repeal-vote.html">FCC kills Net Neutrality rules</a>, the <a href="https://www.eff.org/deeplinks/2017/10/drms-dead-canary-how-we-just-lost-web-what-we-learned-it-and-what-we-need-do-next">W3C favors DRM</a>, and tech giants build their Web-less vision of the future.</p>

<p>The community of peer-to-peer technologists has brought to the world several revolutionary technologies: USENET, Napster, BitTorrent, Kazaa, Skype, Bitcoin, Ethereum, and actually even the Web itself. Once again, we can turn to this community to seek digital solutions that defend freedom. Many months ago <a href="https://staltz.com/my-last-day-and-my-first-day.html">I quit my job</a> in order to join a group of peer-to-peer programmers and help build technology that can rescue our digital freedoms. I want to share with you our plan, which in short is:</p>

<p><strong>Build the mobile mesh Web that works with or without Internet access, to reach 4 billion people currently offline</strong></p>

<p>To explain this plan, we need to realize that the Web can be independent from the Internet. The core weaknesses of the Internet have to be recognized, and how exactly they were exploited by middlemen businesses. The problem we are solving is both social and technical, so the solution must be a harmony of these two. Finally, all the tools and opportunities we need to supersede them are already in our hands: smartphones, peer-to-peer protocols, and mesh networks.</p>

<h2 id="the-rise-of-closed-cyberspaces">The rise of closed cyberspaces</h2>

<p>The Web is an open cyberspace, a digital context where society can happen, where no single organization, company, or government has the final word on what is allowed or forbidden. It is also an access point to other cyberspaces. Every time you “sign in” with an account on a website, you are entering a closed cyberspace. These cyberspaces are hosted by servers owned by the company or organization behind that website.</p>

<p>Most closed cyberspaces don’t threaten the Web’s role as a public space. A school’s <em>intranet</em> is a closed cyberspace, and so is a private discussion forum or a company’s internal discussion platform. Most people will understand how it is necessary for those cyberspaces to be <strong>closed</strong> and <strong>controlled</strong>.</p>

<p>The real threat comes with giant closed cyberspaces that disguise themselves as public spaces. Facebook, for instance. Many of its users think of it as a neutral public space where society comes together, and in fact Facebook often efficiently carries out that role. It is, nevertheless, closed and controlled. It started as one of those justifiably closed cyberspaces: it was a private community of Harvard students. With its explosive growth, though, it had to quickly evolve to encompass all types of social structures.</p>

<p>While Facebook was growing on the Web, Apple launched the iPhone in 2007, and the world was revolutionized by smartphones after that. Zuckerberg saw the mobile <em>megatrend</em> before many others did, and as early as <a href="https://gigaom.com/2009/02/10/why-facebooks-future-is-mobile/">2009</a> there was a Facebook mobile app with explosive growth. Facebook began re-imagining itself as a platform independent from the Web.</p>

<p>Fast forward to December 2016, and 94% of all Facebook monthly active users access the blue closed cyberspace routinely through mobile apps (divide <a href="https://www.statista.com/statistics/277958/number-of-mobile-active-facebook-users-worldwide/">mobile MAU</a> by <a href="https://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/">MAU</a>), while 62% access it <em>only</em> from mobile (divide <a href="https://www.statista.com/statistics/281600/number-of-mobile-only-facebook-users/">mobile-only MAU</a> by <a href="https://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/">MAU</a>). As a result, <a href="https://www.cnbc.com/2017/02/01/facebooks-entire-business-relies-on-people-using-it-on-their-phones.html">84% of FB’s revenue</a> comes from mobile advertising. As an extrapolation of this data, their mobile-only users likely comprise today (December 2017) between 70% – 79% of all their users.</p>

<p><a href="https://staltz.com/img/facebook-mobile-stats.png"><img src="https://staltz.com/img/facebook-mobile-stats.png" alt="Facebook mobile stats"></a></p>

<p>(Sources: <a href="https://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/">[1]</a> <a href="https://www.statista.com/statistics/277958/number-of-mobile-active-facebook-users-worldwide/">[2]</a> <a href="https://www.statista.com/statistics/281600/number-of-mobile-only-facebook-users/">[3]</a>)</p>

<p>Those are large enough numbers to admit that the open Web is already rather irrelevant to Zuckerberg’s products. By now, Facebook, Messenger, Instagram, and WhatsApp are arguably <strong>non-Web closed cyberspaces</strong> of comparable scale to the Web (users of FB products are <a href="https://www.statista.com/statistics/617136/digital-population-worldwide/">roughly 2/3 of all Internet users</a>). Facebook even has <a href="https://amp.theguardian.com/uk-news/2015/jan/31/british-army-facebook-warriors-77th-brigade">its own concept of cyberwarfare</a>.</p>

<p>It competes with the Web in many use cases that people want from a public cyberspace: sharing notes and images, engaging with communities, doing business, marketing services and products, and organizing events. Similarly, this argument can also be made for YouTube. In fact, any closed cyberspace that grows too much could become a threat to the open Web.</p>

<p>Which brings me to the question: is it fundamentally inevitable that a closed cyberspace will use the open cyberspace to eventually outgrow it? I would answer: no. The Web only got to this current situation because of <strong>fundamental flaws in the Internet’s architecture which rigged the system</strong>. Closed cyberspaces thrive because they have artificially imposed incentives to thrive.</p>

<h2 id="technical-flaws-that-supported-middlemen-businesses">Technical flaws that supported middlemen businesses</h2>

<p>The Internet that supports the Web (as well as other applications such as email, Skype, WhatsApp, online mobile apps) is a technical marvel, but it shares similarities with some archaic systems.</p>

<p>The way data travels through the Internet is quite similar to how the postal system works. Each recipient needs a unique address. On the Internet, these are the so-called “IP addresses”, which are simply numbers given to each computer. A computer may be assigned the number 198.153.192.40, where the first part 198 refers to a specific region in the USA, and the other numbers help specify which particular computer in that region is the recipient.</p>

<p>Here’s the problem with IP addresses: <a href="https://en.wikipedia.org/wiki/IPv4_address_exhaustion">there aren’t enough of them</a>. When the Internet was being planned, it was initially a system of military and university networks. They did not account for the massive popular adoption of the Internet that made it mainstream in business, commerce, and for inter-personal communication. Imagine if there could only be a limited number of mailboxes in the postal system – that is virtually what occured to the Internet.</p>

<p><a href="https://staltz.com/img/ipv4_address_map.gif"><img src="https://staltz.com/img/ipv4_address_map.gif" alt="IPv4 address map"></a></p>

<p>There was a quick solution to this, though: a mechanism called Network Address Translation (NAT). Jargon aside, it’s a simple idea: one computer gets a real IP address and acts as an intermediate for other computers which do not have real IP addresses. Imagine that your neighborhood would share a single mailbox, then one person would be responsible for sorting and forwarding each received mail to the correct final destination. That is what NAT accomplishes for Internet addresses, and it is commonly deployed on local routers, such as the box you might have installed in your home or office. The advent of NAT routers also allowed for that intermediate computer to become a guardian and protect other computers from some dangers of the open Internet.</p>

<p>It also meant that some computers were first-class citizens on the Internet, while other computers were subordinates. In addition, the scarcity of IP addresses caused them to be considered valuable assets, and so it became a business opportunity. IP addresses are being sold so that some computers can become first-class citizens on the Internet.</p>

<p>It seems easy to solve this problem, though: just provide more IP addresses, since they are after all just artificial resources. That is what <em>IP version 6</em> is all about, and its purpose is to make sure there would always be enough addresses for everyone (the limit is more than a trillion trillions). However, IPv6 was declared ready for use in 1998 – two decades ago – but its adoption among organizations around the world is still just <a href="https://arstechnica.com/information-technology/2010/09/there-is-no-plan-b-why-the-ipv4-to-ipv6-transition-will-be-ugly/">catching up</a>, because it demands teaching every Internet-connected machine to understand and utilize the new types of addresses.</p>

<p>There isn’t enough economic incentives for IPv6, though, since the information industry has made its nest in massive systems that assume IPv4 plus NAT. Companies that sell IPv4 addresses see little benefit in adopting IPv6 and companies that depend on IPv4 + NAT systems prefer to avoid the risks associated with disturbing the infrastructures that power their always-online businesses. Even if all the computers started using IPv6, too many programs were built with NAT in mind, which could reveal many security vulnerabilities when exposed to a world without NAT. In other words, the Internet economy simply isn’t ready for a scenario where IPv6 is used everywhere and NAT is abandoned. We are stuck with what we have.</p>

<p>As a consequence, the Internet has allowed intermediate computers to rule. These are like parasites that have grown too large to remove without killing the host. The technical flaw that favored intermediate computers prefigured a world where middlemen business models thrive. Google and Facebook connect consumers with advertisement publishers, and charge fees for each ad. Amazon is a middleman business as well: it connects retailers with consumers, and takes a cut on transactions. Many popular ‘sharing economy’ startups and services are also middlemen: Airbnb, Uber, Kickstarter, Patreon, and many others.</p>

<p>It is hard to imagine how things could be different, yet the incentives for these businesses to exist were artificially erected. It is not fundamentally necessary to have any intermediate company profiting whenever a person reads news from their friends, rents an apartment from a stranger, or orders a ride from a driver. This is why it is important to analyze technical systems from an economical and societal perspective: because early design decisions foreshadow certain social orders.</p>

<p>We can – and urgently must – provide alternative ways of digitally supporting popular use cases for Web services. It is possible to escape middlemen businesses by decreasing reliance on the infrastructure that plugs their systems together: wires.</p>

<h2 id="the-internet-on-a-leash">The Internet, on a leash</h2>

<p>The physical foundation of the Internet is a global network of thick bundles of <a href="https://www.extremetech.com/computing/96827-the-secret-world-of-submarine-cables">privately-owned fiber optic undersea cables</a> spanning oceans to connect all the continents together. Undersea communication cables exist since the <a href="https://en.wikipedia.org/wiki/Submarine_communications_cable">1850s</a>.</p>

<p><a href="https://staltz.com/img/undersea-cable.jpg"><img src="https://staltz.com/img/undersea-cable.jpg" alt="Undersea cables"></a></p>

<p>(Source: Reuters/Landov)</p>

<p>These cables follow a hierarchical layout: continents are connected to other continents, countries  connected to countries, and within those countries, different companies (Internet Service Providers, ISPs) have to agree with their local government in order to plug into that network of cables. This well organized hierarchy is the only way the wired Internet can be feasible. Otherwise, a grassroots wired internet would be a true mess of cables. Countries and organizations also manage the distribution of IP addresses.</p>

<p>Although the Internet is praised as the technology that ushered us into a new era, the information age, it is just a fancy way of transfering data from computer A to computer B. It is highly efficient in transferring data globally at almost instantenous speeds, but it is nevertheless much like a USB cable that connects your computer to an external hard drive. In fact, transfer speeds are almost always better through USB cables than through the Internet. The real benefit of the Internet is instant globalization through the fact that it makes all computers in the world <em>seem like</em> they are in the same room.</p>

<p>The global real-time economy enabled by <em>the wirenet</em> is a historical achievement with permanent implications to humanity. That said, often we engage with apps that have no need for global connectivity. For instance, staying in contact with friends in the same city – a naive but likely the most popular use case for technology – requires no connections to countries on the other side of the planet. Yet we overutilize the global tangle of inter-connected cables to run proprietary and foreign (often American) apps which deliver messages that travel around the world just to reach a colleague nearby. This has opened our lives and our nations to digital colonialism from surveillance capitalism corporations (pick your favorite Silicon Valley company) married to three-letter intelligence agencies.</p>

<p>What could be the alternative? So much of our digital lives depend on technologies that are out of our reach, physically, legally, and economically. Gladly, technology itself has recently provided the first building blocks that can be put together to create a new cyberspace.</p>

<h2 id="untapped-opportunities">Untapped opportunities</h2>

<p>Technological innovation is quick to introduce amazing things such as smartphones, 4G connectivity, cryptocurrencies, and digital social networks. None of these existed when the Internet was being planned. Yet all of them rely on the very old idea (from the 19th century) of telecom companies, not as a fundamental requirement, but due to lack of alternatives.</p>

<p>As a thought experiment, how would the Next Internet look like if it were reinvented using all the accumulated knowledge from the last 3 decades of global cyberspaces? There are three promising things that can enable a reinvented Internet:</p>

<ul>
  <li><strong>The people-centered Web</strong></li>
  <li><strong>Mobile mesh networks</strong></li>
  <li><strong>4 billion people</strong></li>
</ul>

<p>The Web is classically a location-centered cyberspace. When you access the Web, you visit locations (URLs, like <code>wikipedia.org</code>) that contain content. You often don’t see the people who created that content, but they are implicitly assumed to be there. The problem with location-centered content – prefigured by the way HTTP was designed – is that it’s not easy to archive for posterity. An image hosted through some link may be there today, but maybe not tomorrow.</p>

<p>Novel peer-to-peer protocols such as <a href="https://ipfs.io/">IPFS</a> and <a href="http://datproject.org/">Dat</a> help replace HTTP and make the Web a content-centered cyberspace. This way the link to an image can be something like <code>QaPdNnDWRLF1b</code> – a so-called <em>hash</em> of the image, summarizing it – instead of <code>mywebsite.com/pic.jpeg</code> so that even if <code>mywebsite.com</code> servers are removed, you can still get the image by fetching it from any computer that has stored <code>QaPdNnDWRLF1b</code>. If you don’t like the unreadable code, you can just use a link shortener like <code>bit.ly</code> to create a shortcut to the unreadable code. This way, even if your <code>bit.ly</code> short link disappears, the content can still be recovered from the crowd of online computers.</p>

<p>Browsers can be made to work like that, and although it’s a small tweak to how the Web works, it has massive effects on social structures in cyberspace. The <a href="https://beakerbrowser.com/">Beaker Browser</a> is the best demonstration of that, which you can easily install and start using today. It allows your browser to directly share content with other people’s Beaker installations, without intermediate servers (like YouTube servers, Medium, blogs, etc).</p>

<p>These above mentioned technologies fix the Web by making it truly content-centered instead of location-centered. That said, the Web is good at putting content on stage, while keeping content authors in the backstage. While there are many use cases where it’s desirable to de-emphasize people, such as anonymous reports, crowd-sourced encyclopedias, and cat videos, in the recent years we have discovered a game-changing way of structuring cyberspaces: the Social Web, where content orbits the author like planets orbit a star.</p>

<p>It makes sense for a cyberspace, a digital context for people to engage with each other, to be people-centered. Websites in the social realm took a daring approach of making <em>You</em> a location: the URL <a href="https://twitter.com/andrestaltz"><code>twitter.com/andrestaltz</code></a> means that this content <em>is a person</em>. In fact, one of the earliest large social networks was named <em>Myspace</em>, emphasizing the location and its association with a person. We all have experienced how revolutionary this concept has been, and how it has pervasively reached to many corners of the Web: you can sign in with a Facebook account or insert blog comments using your Facebook profile.</p>

<p><a href="https://staltz.com/img/people-centered-web.png"><img src="https://staltz.com/img/people-centered-web.png" alt="Three types of Web arrangements"></a></p>

<p>Now that we have experience with some of the intricacies of the social Web, we can reinvent it to put people first without intermediate companies. The peer-to-peer protocol <a href="http://scuttlebutt.nz/">Secure Scuttlebutt</a> (SSB) does that, designed with <a href="https://coolguy.website/writing/the-future-will-be-technical/index.html">diversity-first principles</a> that prefigure (hopefully) social structures with freedom, <a href="https://www.youtube.com/watch?v=P5K18XssVBg">subjectivity</a>, and <a href="https://www.youtube.com/watch?v=FEU632_Em3g">political structures that can prevent capitalistic monopolies</a>. SSB was envisioned and created by <a href="https://www.theatlantic.com/technology/archive/2017/05/meet-the-counterantidisintermediationists/527553/">a nomad programmer</a> who had unreliable Internet connection and wanted to enable social networks for <a href="https://staltz.com/an-off-grid-social-network.html">off-grid lifestyles</a>. A growing community of pioneers and programmers are using SSB on a daily basis as their main social network. I really hope you click through all those links and explore SSB in more depth.</p>

<p>The mix of off-grid lifestyles with digital social networks is unusual, because we tend to associate technology with dependency on the <em>Grid</em> for energy and Internet connectivity. However, to create an alternative to the Grid, we need to look for technologies that provide <a href="https://staltz.com/layers-of-the-internet-economy.html">energy and connectivity</a> without the Grid. Solar panels provide the former and are a staple of the off-grid sustainability movement known as <a href="http://solarpunks.tumblr.com/">Solarpunks</a>. To provide the latter, we can use wireless technologies.</p>

<p>Cables gave birth to the information age, but wireless gave us wings to go untethered. And today, digital society gets together <a href="https://staltz.com/img/desktop-vs-mobile-2.jpg">through smartphones more than it does through desktop computers</a>. While smartphones enable us to easily share files directly to other devices – without intermediates – using Bluetooth or Apple’s AirDrop, we don’t transfer data through that as compulsively as we do through cables. Wireless technology exists today as a mere extension of the wired world, but it could be so much more than that. It could be, in fact, the opposite: wires as a mere extension of the wireless world.</p>

<p>You probably haven’t heard of <a href="https://en.wikipedia.org/wiki/Mobile_ad_hoc_network">mobile ad-hoc networks</a> (MANETs), also known as <em>meshes</em>. One of the reasons for their lack of popularity is that meshes would <a href="https://en.wikipedia.org/wiki/Smart_phone_ad_hoc_network#Threats_to_telcos">threaten the business of telecom operators</a>, so there is little incentive from the establishment to develop and deliver mobile ad-hoc networks to you. A MANET is like AirDrop, but automatically and seamlessly connects to devices around you and delivers data in multiple hops between those devices. Even if Bluetooth connections can only reach a few meters, after multiple jumps, you can connect to devices a few kilometers away. Information literally spreads through the air to a mesh of devices in a region. It is propelled even more by the fact that mobile devices are moving around, doing half of the work of transporting data.</p>

<p>On the other hand, the primary reason why MANETs are underappreciated is that they do not yet provide data transfer speeds comparable to those in the wirenet. A MANET upholds principles like freedom from fixed intermediate organizations, but it is simply too slow for transfer-intensive use cases like streaming video or instant messaging. Their adoption would feel like a step backwards to the early days of the Web when speeds were measured in a few Kilobits per second, not the usual Megabits per second you are used to in developed countries.</p>

<p>Mesh networks are nevertheless still promising, for two facts. First, the technology is evolving, with <a href="https://developer.apple.com/documentation/multipeerconnectivity">Apple MultipeerConnectivity</a> and <a href="https://blog.bluetooth.com/introducing-bluetooth-mesh-networking">Bluetooth Mesh</a> as a few cutting-edge examples. Novel protocols are being developed that envision <a href="https://github.com/cjdelisle/cjdns">IPv6 without ISPs</a>, ideal for meshes. Second, because many developing countries do not yet have Internet access. This accounts for 4 billion people, out of the total 7.6 billion, with currently zero bits per second of transfer speeds. Even if it seems like the Internet encompasses the whole world, it still barely reaches 45% of the planet. Some may have Internet connectivity, but it’s intermittent or not consistently speedy. For people with intermittent or unexistent connectivity, ISP-free mesh networks with moderate but consistent speeds become quite attractive.</p>

<p><a href="https://staltz.com/img/InternetPenetrationWorldMap.svg"><img src="https://staltz.com/img/InternetPenetrationWorldMap.svg" alt="Internet penetration world map"></a></p>

<p>Image: <strong>Internet users in 2015 as a percentage of a country’s population</strong> by <a href="https://en.wikipedia.org/wiki/List_of_countries_by_number_of_Internet_users#/media/File:InternetPenetrationWorldMap.svg">Jeff Ogden (W163)</a></p>

<p>Facebook and Google are desperate for getting an early grip of those 4 billion people, e.g. through <a href="http://internet.org/">Internet.org</a> and <a href="https://x.company/loon/">Project Loon</a>. However, because their middlemen businesses are tethered to the Internet, all of these projects require the old hierarchical structures of ISPs and cables. Their businesses and modus operandi are inherently infrastructure-heavy. The difficulties are several: balloons cannot reliably cover all the regions, local ISPs or local governments may be corrupt, and any other wired infrastructure project takes years or decades.</p>

<p>The exciting part is that we can actually beat the tech giants at this game by simply giving local and regional connectivity to people in developing countries. With mobile apps that are built mesh-first, the smartphones would make up self-organizing self-healing MANETs. Frankly, this is quite easy to do, if we are willing to gift mobile devices without expecting anything back, unlike tech giants. It won’t be an easy fight, though, <a href="https://www.youtube.com/watch?v=xCZOGZf_Pnc">Facebook is working hard to build a compromise</a> that still gives them the middleman upper hand. <a href="http://www.businessinsider.com/facebook-f8-ten-year-roadmap-2016-4">Zuckerberg’s 10-year roadmap</a> puts connectivity projects in the long-term spectrum (5–10 years). That’s basically our deadline, we need to get grassroots meshes in Africa before that.</p>

<p>The mobile apps for meshes would have to be best suited for the particular limitations of (current) MANET technologies. Video streaming and instant messaging are not the first options, but lightweight websites in content-addressed style (like in the Beaker Browser with Dat) and text-first social news feeds are applications that can be realistically delivered in the short term. Such apps don’t even require constant connection to other devices in the mesh. For text-based social news feeds, it suffices to occasionally sync the latest news with other devices whenever they are in range.</p>

<p>Even the mobile apps themselves can be deployed through MANETs, and I have already developed an “app store” mobile app that fits that use case, called <a href="https://github.com/staltz/dat-installer">Dat Installer</a>. My main project at the moment is to build a mesh-friendly <a href="https://github.com/staltz/mmmmm-mobile/">social network mobile app running on SSB</a>. It is important to highlight that while these apps are built for meshes, they know how to ‘surf’ the Internet and utilize it as a fallback.</p>

<p>When talking about decentralized peer-to-peer protocols in 2017, it is imperative to mention blockchains and cryptocurrencies. These are great innovations and directly tackle <em>intermediate organizations</em> (mostly banks) as a problem, much like IPFS, Dat, and SSB. On the other hand, most blockchain protocols were designed with high Internet speeds, powerful hardware, and global connectivity in mind. What most of these innovations share in common is the accomplishment of a distributed global database where no single actor is to be trusted above the others. There are legitimately useful use cases of this, such as <a href="https://jeremyrand.github.io/namecoin.org/">decentralized Web domain registration</a>. On the other hand, requiring global consensus, high Internet speeds, and powerful hardware makes it difficult to utilize blochchains for mesh networks in developing countries. Alternative not-quite-blockchain experiments like <a href="https://iota.org/">IOTA</a> might change this, though.</p>

<h2 id="the-plan">The plan</h2>

<p>While growing local mesh networks for-charity in developing countries is the proposed strategy, how is it connected to a plan for countering the tech oligarchy in developed countries? In Internet-less regions there is potential for scaling quickly, and through that we can spawn a new industry around peer-to-peer wireless mesh networks. If this industry grows, it can also support meshes in the developed world. Scaling fast is important to make meshes more than just niche projects by a few enthusiasts, but instead become a thriving ecosystem. The mega-projects listed below are a plan to rescue the Web from the Internet:</p>

<p>In the next year or two:</p>

<ul>
  <li>Developers improve peer-to-peer protocols that support the content-centered Web (IPFS, Dat) and the people-centered Web (SSB)</li>
  <li>Developers and hardware manufacturers write open protocols for mesh networking (comparable to <a href="https://developer.apple.com/documentation/multipeerconnectivity">MultipeerConnectivity</a>, <a href="https://github.com/cjdelisle/cjdns">CJDNS</a>, <a href="http://opengarden.com/">Open Garden</a>)</li>
  <li>Developers bring peer-to-peer protocols to smartphones and build mobile apps that use those</li>
  <li>Web enthusiasts and archivers help migrate content from the old Web to the new protocols</li>
  <li>Hardware startups compete in the market for regional mesh networks (e.g. <a href="http://gotenna.com/">goTenna</a>, <a href="https://www.beartooth.com/">Beartooth</a>, and others)</li>
</ul>

<p>In two years or more:</p>

<ul>
  <li>Smartphone manufacturers sell mesh-first mobile devices for the developing world</li>
  <li>Developers work with regional communities to localize mesh mobile apps (note the possibility of forking open source projects and customizing them to different cultures)</li>
  <li>Charitable organizations or companies offer mesh-first smartphones for free (or subsidized and cheap) to people in developing nations</li>
  <li>Mesh-based cyberspaces start to thrive in some countries</li>
  <li>Similar mesh cyberspaces in the developed world also gain relevance, specially in countries with unfair ISPs</li>
</ul>

<p>In six years or more:</p>

<ul>
  <li>Ecosystem of wireless mesh networks expands from regional “airnets” to national airnets</li>
  <li>National airnets are weaved together through a global mesh of satellites (much like <a href="https://motherboard.vice.com/en_us/article/599g4b/bitcoin-now-comes-from-satellites-in-space">Blockstream</a>)</li>
  <li>Make the global airnet competitive with the wirenet</li>
</ul>

<p>As a result of having competition between the two, we can hope to fix the overutilization of the wirenet and the underutilization of airnets, bringing balance to the wire-versus-air dichotomy, providing choice in how data should travel in each case.</p>

<p>Choice is freedom.</p>

    <p>
      If you liked this article, consider sharing
      <a href="https://twitter.com/intent/tweet?original_referer=https%3A%2F%2Fstaltz.com%2Fa-plan-to-rescue-the-web-from-the-internet.html&amp;text=A%20plan%20to%20rescue%20the%20Web%20from%20the%20Internet&amp;tw_p=tweetbutton&amp;url=https%3A%2F%2Fstaltz.com%2Fa-plan-to-rescue-the-web-from-the-internet.html&amp;via=andrestaltz" rel="nofollow" target="_blank" title="tweeting">(tweeting)
        <span>
      </span></a> it to your followers.
    </p>
    
    <p>
      Copyright (C) 2017 Andre 'Staltz' Medeiros, licensed under
      <a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons BY-NC 4.0</a>, translations to other languages allowed. You can make sure that the author wrote this
      post by copy-pasting
      <a href="https://raw.githubusercontent.com/staltz/staltz.com/master/signed_posts/2017-12-18-a-plan-to-rescue-the-web-from-the-internet.md.asc">this signature</a> into
      <a href="https://keybase.io/verify">this Keybase page</a>.
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iOS 14.6 device hacked with a zero-click iMessage exploit to install Pegasus (349 pts)]]></title>
            <link>https://twitter.com/billmarczak/status/1416801514685796352</link>
            <guid>27875976</guid>
            <pubDate>Sun, 18 Jul 2021 19:43:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/billmarczak/status/1416801514685796352">https://twitter.com/billmarczak/status/1416801514685796352</a>, See on <a href="https://news.ycombinator.com/item?id=27875976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span><br></p></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“We're Shutting Down Our 3G Network” (119 pts)]]></title>
            <link>https://benergize.com/2021/07/16/were-shutting-down-our-3g-network/</link>
            <guid>27875356</guid>
            <pubDate>Sun, 18 Jul 2021 18:44:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benergize.com/2021/07/16/were-shutting-down-our-3g-network/">https://benergize.com/2021/07/16/were-shutting-down-our-3g-network/</a>, See on <a href="https://news.ycombinator.com/item?id=27875356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>This is a tale of first world problems, culminating in me being pissed off about getting a free phone–so I’ll say up front: Yes, I know this is petty and silly, but also, I’m furious with how AT&amp;T has handled their transition off 3G and I’m here to complain about it.</p>

<h2>Oh Say Can You VoLTE?</h2>
<p>A few months ago, I received a text message from AT&amp;T that I didn’t understand. It read:</p>
<blockquote><p>“AT&amp;T Free msg: In Feb 2022, we’re shutting down our 3G network and your cell phone ending in *####* won’t work anymore. The good news is that we will send you a FREE cell phone that is similar to the one you have today that will work on the upgraded network. To get the new phone go to att.com/AcceptPhone”</p></blockquote>
<p>I was confused by this because my phone supports 4G LTE. I chalked this up to, I purchased my phone unlocked and AT&amp;T likely thought I was using an iPhone 3G, the last phone I bought from them directly. This has happened in the past, so I ignored the message.</p>
<p>But they kept sending it. So I did a little research and found out that, while my phone supports data through 4G LTE, AT&amp;T places calls through 3G. So when they take down their 3G network, away would go calling and texting for me.</p>
<p>The technology taking its place is called Voice Over LTE (VoLTE). True to its name, it places calls over LTE. I did a little more research and discovered that my phone <em>does</em> actually support VoLTE, but going to AT&amp;T’s whitelist of VoLTE phones revealed that my phone was, for reasons unknown, not supported. I saw speculation on AT&amp;T forums as to the reason for this, but no official answer from AT&amp;T. Attempts at getting AT&amp;T to whitelist it resulted in confusion and denial–I did have a lovely time at the mall, and enjoyed listening to their jaunty hold music at home.</p>
<h2>One Phone, Two Phone, Big Phone, New Phone</h2>
<p>I really didn’t want to give up my phone, because it still works great (and I’ve grown a sentimental attachment to it).</p>
<p>But slowly I started entertaining the idea of getting a new phone, because, like the rest of the country, I do like new shiny things, and I’m only so sentimental. The three things I care about in a phone are 1. A screen that’s not going to give me thumb strain 2. a battery that will last me as long as my current phone (it’s a few years old and I still get two days of charge out of it) and 3, though less important than 1 and 2, has a decent camera. The problem is, my current phone has a smaller screen than 95% of phones on the market today and it <em>still</em> hurts my hands to use it.</p>
<p>It seems virtually impossible to get all three of my criteria. The closest I could find (that was on AT&amp;T’s whitelist) was the Pixel 4a and the Galaxy S10e. The Pixel’s battery is on the small side, but for screen size and camera quality I was willing to compromise. The problem I have with both phones, especially the Galaxy, however is that they are several years old. Android users know that getting OS and Security updates is not something to take for granted, and buying a phone that’s more than two years old is a recipe for getting left behind (not that there are many new features I especially care about, but security updates are a big deal–and yes, I know it’s silly to have an issue with getting an older phone when my own phone is aging). I shelved the idea of getting these phones.</p>
<p>I decided to take a look at the glorious free phones AT&amp;T was so generously offering. Going through a maze of twisty passages all alike got me to the actual model they were offering. They offered me a selection of free phones to choose from, which was in fact 1 checkbox for one phone. Their offer was “based on my current phone,” but was a very low-end AT&amp;T branded Tracfone with awful specs, no doubt filled with AT&amp;T bloatware.</p>

	
	<div data-slide="0">
		
	<p><img src="https://benergize.com/wp-content/uploads/2021/07/specs.png" data-slide="0"></p><p data-slide="0">Highlights from the free phone's specs. Technically, Android can run on 32MB of RAM. That doesn't mean it's a good idea though.</p><p><img src="https://benergize.com/wp-content/uploads/2021/07/review.png" data-slide="1"></p><p data-slide="1">You said it, Dan.</p>
	</div>
	
	
	
	
<p>There was a button to choose other phones, which took me to a window that said I couldn’t choose any other phones. So, that was out. Thanks for the generous offer, AT&amp;T, but as my friend once said on leaving a restaurant after discovering there were no Chicken and Waffles on the menu, “we’re going to pursue other options, but we will reimburse you for the lemons.”</p>
<p>My thought at this point was, “their network is going down in 2022, it’s only June, phones will launch between now and then, and maybe there will be something that fits all my criteria.”</p>
<h2>Free Phones or Else</h2>
<p>A few days ago I received this message:</p>
<blockquote><p>AT&amp;T FREE MSG: In Feb 2022, we’re shutting down our 3G network to make improvements to our network. <strong>We’re shipping you a new FREE cell phone to replace your device ending in *####*. All you need to do is activate the new device. You’ll find setup information in the box. <span>If you don’t activate your new cell phone, we will automatically activate it in approximately 30 days. Once your new cell phone is activated, your current cell phone will only be able to call 911 and 611 until Feb 2022.</span></strong> If you need additional assistance, visit one of our stores or call us at 800.880.8581</p></blockquote>
<p>To which my response in my head was:</p>
<p>Are you ******* kidding me? Are you actually ******* kidding me?</p>
<p>I’m not sure if this is in good faith or bad faith on AT&amp;T’s part. I can absolutely see a world in which angry customers call them in February after their network goes down and demand to know why their phones, which they’ve been warned about getting shut down for months, are no longer working. This is a way for them to avoid that, and I’m sure a lot of people are happy to get the free phone. Having more AT&amp;T phones in their customer pool probably also makes their maintenance burden easier.</p>
<p>But I do not want their ****** free ******* phone. And now they’re ******* deactivating my phone and not even giving me a ******* choice? Are you ******* kidding me? And they’re wording it like it’s a ******* gift. Wow, the phone is FREE in all caps, which makes it run ten times faster than if the phone was just free in lower case. The all caps FREE <a href="https://www.youtube.com/watch?v=rwExrQSFq-4">boosts internet wallpaper</a> and improves ventilation–it’s a 60x improvement over my current phone because it’s in all caps.</p>
<h2>You Have 30 Days to Move Your Cube</h2>
<p>Functionally, AT&amp;T was saying that I have 30 days to vacate my phone. The February deadline they’ve been giving me for months wasn’t real.</p>
<p>I was very pissed off, so I picked up the phone and actually called their number. A few minutes of jaunty hold music later and I was on the line with Schmitty the support agent (I’m substituting a fake name, obviously). I want to assure you I was very polite–I know the behavior of the company or product is never the fault of the support rep, and, having been on the other side of similar calls, I know how horrible it is to field calls from belligerent customers. But the call went like this:</p>
<p>“Hi, I just got a message that you’re sending me a free phone in the mail. I don’t want the free phone, I’d like to stay on my current phone until February when 3G goes down.”</p>
<p>“Okay, I can send you a return label and you can just put it back in the mailbox, but you should know, February isn’t a hard deadline, we could turn your phone service off any day.”</p>
<p>Schmitty must have been fielding similar calls all day, and sounded very tired of having this conversation. At this point though, I was very tired of AT&amp;T.</p>
<p>“Okay, I’m going to go ahead and leave AT&amp;T. My phone supports VoLTE, I can get it whitelisted on a different network.”</p>
<p>“Okay. Do you want me to transfer you to cancellations?”</p>
<p>“Nope. Thanks.”</p>
<p>And so ended my brief but touching time with Schmitty the support rep.</p>
<h2>So Long Phone Plan!</h2>
<p><img loading="lazy" src="https://benergize.com/wp-content/uploads/2021/07/856001241-700x459.jpg" alt="Simpsons Meme, So Long Phone Plan!" width="640" height="420" srcset="https://benergize.com/wp-content/uploads/2021/07/856001241-700x459.jpg 700w, https://benergize.com/wp-content/uploads/2021/07/856001241-300x197.jpg 300w, https://benergize.com/wp-content/uploads/2021/07/856001241.jpg 707w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>I’ve been an AT&amp;T customer since they bought Cingular. Or Cingular might have bought them and then changed their name–I’m not really clear on that (I think one Bell bought another Bell and the bells rang so hard AT&amp;T came back from the grave and did a <a href="https://www.youtube.com/watch?v=A2tOlfLEHZI">bootleg Thriller</a>). I’ve never had any great love for them, but I’ve never had any reason to switch. Seventeen years on, it’s time to re-evaluate the cellular landscape and see who the right fit is. I know off the bat a few carriers who will take me and my current phone, but there are some more reviews to dig through before then. Recommendations welcome.</p>
<p>That’s my boring story of entitlement. I wanted to put this out there for anyone who didn’t know about AT&amp;T’s inelegant switch off 3G or anyone who is similarly pissed off and wants a comment section to say so. I’ve been a customer to a number of services that have nearly annoyed me enough to switch, but this is the first time I’ve ever been this motivated to make a change.</p>
<p><em>Opinions in this post are opinions, and the opinions are my own. I make no claims about AT&amp;Ts service, services, offerings, or support. AT&amp;T is a trademark of AT&amp;T Inc. This is a recounting of my experience and nothing else.</em></p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diffsitter: A tree-sitter based AST difftool to get meaningful semantic diffs (182 pts)]]></title>
            <link>https://github.com/afnanenayet/diffsitter</link>
            <guid>27875333</guid>
            <pubDate>Sun, 18 Jul 2021 18:41:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/afnanenayet/diffsitter">https://github.com/afnanenayet/diffsitter</a>, See on <a href="https://news.ycombinator.com/item?id=27875333">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<p><a href="https://github.com/afnanenayet/diffsitter/actions/workflows/CI.yml"><img src="https://github.com/afnanenayet/diffsitter/actions/workflows/CI.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/afnanenayet/diffsitter/actions/workflows/CD.yml"><img src="https://github.com/afnanenayet/diffsitter/actions/workflows/CD.yml/badge.svg" alt="CD"></a>
<a href="https://crates.io/crates/diffsitter" rel="nofollow"><img src="https://camo.githubusercontent.com/7c7c714de82b4ecfa007af7f3f18ae5abfd4b15e8c37244ed6099ad22f216132/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f64696666736974746572" alt="crates version" data-canonical-src="https://img.shields.io/crates/v/diffsitter"></a>
<a href="https://github.com/afnanenayet/diffsitter/releases/latest"><img src="https://camo.githubusercontent.com/9e51fef7ff8bdd89f739f160ef09f2c455fb8b82f07d369ed6b8d0b81f14874b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f7461672f61666e616e656e617965742f646966667369747465723f6c6162656c3d72656c65617365" alt="latest tag" data-canonical-src="https://img.shields.io/github/v/tag/afnanenayet/diffsitter?label=release"></a>
<a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/79d9bc32e4f171a6f2433371a5a7c4ac120c899e5673de627ab3c6bf0dbfb2b9/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f642f64696666736974746572"><img src="https://camo.githubusercontent.com/79d9bc32e4f171a6f2433371a5a7c4ac120c899e5673de627ab3c6bf0dbfb2b9/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f642f64696666736974746572" alt="downloads" data-canonical-src="https://img.shields.io/crates/d/diffsitter"></a>
<a href="https://github.com/afnanenayet/diffsitter/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/0a453c704f21f92910d1e5ab376eff5bce7856c6027ace5b27648fe5b0dc58e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f61666e616e656e617965742f64696666736974746572" alt="license" data-canonical-src="https://img.shields.io/github/license/afnanenayet/diffsitter"></a></p>
<p><a href="https://asciinema.org/a/joEIfP8XoxUhZKXEqUD8CEP7j" rel="nofollow"><img src="https://camo.githubusercontent.com/f2bd6af5f13d7d01ab117759b938e150cb97a00162925f685375cd9904c72326/68747470733a2f2f61736369696e656d612e6f72672f612f6a6f4549665038586f7855685a4b584571554438434550376a2e737667" alt="asciicast" data-canonical-src="https://asciinema.org/a/joEIfP8XoxUhZKXEqUD8CEP7j.svg"></a></p>
<h2>Disclaimer</h2>
<p><code>diffsitter</code> is very much a work in progress and nowhere close to production
ready (yet). Contributions are always welcome!</p>
<h2>Summary</h2>
<p><code>diffsitter</code> creates semantically meaningful diffs that ignore formatting
differences like spacing. It does so by computing a diff on the AST (abstract
syntax tree) of a file rather than computing the diff on the text contents of
the file.</p>
<p><code>diffstter</code> uses the parsers from the
<a href="https://tree-sitter.github.io/tree-sitter" rel="nofollow">tree-sitter</a> project to parse
source code. As such, the languages supported by this tool are restricted to the
languages supported by tree-sitter.</p>
<p><code>diffsitter</code> supports the following languages:</p>
<ul>
<li>Bash</li>
<li>C#</li>
<li>C++</li>
<li>CSS</li>
<li>Go</li>
<li>Java</li>
<li>OCaml</li>
<li>PHP</li>
<li>Python</li>
<li>Ruby</li>
<li>Rust</li>
</ul>
<h2>Examples</h2>
<p>Take the following files:</p>
<p><a href="https://github.com/afnanenayet/diffsitter/blob/main/test_data/test_1_a.rs"><code>a.rs</code></a></p>
<div data-snippet-clipboard-copy-content="fn main() {
    let x = 1;
}

fn add_one {
}
"><pre><span>fn</span> <span>main</span>() {
    <span>let</span> x <span>=</span> <span>1</span>;
}

<span>fn</span> <span>add_one</span> {
}</pre></div>
<p><a href="https://github.com/afnanenayet/diffsitter/blob/main/test_data/test_1_b.rs"><code>b.rs</code></a></p>
<div data-snippet-clipboard-copy-content="fn



main

()

{
}

fn addition() {
}

fn add_two() {
}
"><pre>fn



main

()

{
}

<span>fn</span> <span>addition</span>() {
}

<span>fn</span> <span>add_two</span>() {
}</pre></div>
<p>The standard output from <code>diff</code> will get you:</p>
<div data-snippet-clipboard-copy-content="1,2c1,12
< fn main() {
<     let x = 1;
---
> fn
>
>
>
> main
>
> ()
>
> {
> }
>
> fn addition() {
5c15
< fn add_one {
---
> fn add_two() {
"><pre lang="text"><code>1,2c1,12
&lt; fn main() {
&lt;     let x = 1;
---
&gt; fn
&gt;
&gt;
&gt;
&gt; main
&gt;
&gt; ()
&gt;
&gt; {
&gt; }
&gt;
&gt; fn addition() {
5c15
&lt; fn add_one {
---
&gt; fn add_two() {
</code></pre></div>
<p>You can see that it picks up the formatting differences for the <code>main</code>
function, even though they aren't semantically different.</p>
<p>Check out the output from <code>diffsitter</code>:</p>
<div data-snippet-clipboard-copy-content="test_data/test_1_a.rs -> test_data/test_1_b.rs
==============================================

1:
--
-     let x = 1;

4:
--
- fn add_one {

9:
--
+ }

11:
---
+ fn addition() {

14:
---
+ fn add_two() {
"><pre lang="text"><code>test_data/test_1_a.rs -&gt; test_data/test_1_b.rs
==============================================

1:
--
-     let x = 1;

4:
--
- fn add_one {

9:
--
+ }

11:
---
+ fn addition() {

14:
---
+ fn add_two() {
</code></pre></div>
<p><em>Note: the numbers correspond to line numbers from the original files.</em></p>
<p>Since it uses the AST to calculate the difference, it knows that the formatting
differences in <code>main</code> between the two files isn't a meaningful difference, so
it doesn't show up in the diff.</p>
<p><code>diffsitter</code> has some nice (terminal aware) formatting too:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/afnanenayet/diffsitter/blob/main/assets/rust_example.png"><img src="https://github.com/afnanenayet/diffsitter/raw/main/assets/rust_example.png" alt="screenshot of rust diff"></a></p>
<p>It also has extensive logging if you want to debug or see timing information:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/afnanenayet/diffsitter/blob/main/assets/rust_example_logs.png"><img src="https://github.com/afnanenayet/diffsitter/raw/main/assets/rust_example_logs.png" alt="screenshot of rust diff with logs"></a></p>
<h2>Installation</h2>
<h3>Published binaries</h3>
<p>This project uses Github actions to build and publish binaries for each tagged
release. You can download binaries from there if your platform is listed.</p>
<h3>Cargo</h3>
<p>You can install using <code>cargo</code> the standard way with <code>cargo install diffsitter</code>.</p>
<h3>Homebrew</h3>
<p>You can use my tap to install diffsitter:</p>
<div data-snippet-clipboard-copy-content="brew tap afnanenayet/tap
brew install diffsitter
# brew install afnanenayet/tap/diffsitter
"><pre>brew tap afnanenayet/tap
brew install diffsitter
<span><span>#</span> brew install afnanenayet/tap/diffsitter</span></pre></div>
<h3>Arch Linux (AUR)</h3>
<p>@samhh has packaged diffsitter for arch on the AUR. Use your favorite AUR
helper to install <a href="https://aur.archlinux.org/packages/diffsitter-bin/" rel="nofollow"><code>diffsitter-bin</code></a>.</p>
<h2>Usage</h2>
<p>For detailed help you can run <code>diffsitter --help</code> (<code>diffsitter -h</code> provides
brief help messages).</p>
<p>You can configure file associations and formatting options for <code>diffsitter</code>
using a config file. If a config is not supplied, the app will use the default
config, which you can see with <code>diffsitter --cmd dump_default_config</code>. It will
look for a config at <code>$XDG_HOME/.config</code> on macOS and Linux, and the standard
directory for Windows. You can also refer to the
<a href="https://github.com/afnanenayet/diffsitter/blob/main/assets/sample_config.json5">sample config</a>.</p>
<p><em>Note: the tests for this crate check to make sure the provided sample config
is a valid config.</em></p>
<h2>Development</h2>
<p>You need a Rust toolchain, which you can install from here: <a href="https://rustup.rs/" rel="nofollow">https://rustup.rs</a>.
You will also need a C and C++ compiler, any standard-compliant one should be
fine (GCC, Clang, or Visual Studio).</p>
<p>If you're on Mac and have <a href="https://brew.sh/" rel="nofollow">Homebrew</a> installed:</p>
<div data-snippet-clipboard-copy-content="brew install llvm

# or

brew install gcc
"><pre>brew install llvm

<span><span>#</span> or</span>

brew install gcc</pre></div>
<p>The built-in Apple clang that comes with XCode is also fine.</p>
<p>If you're on Ubuntu:</p>

<p>If you're on Arch Linux:</p>

<p>Once you have the requisite toolchains installed, you'll want to clone the
project and initialize submodules:</p>
<div data-snippet-clipboard-copy-content="git clone
git submodule --init --recursive
"><pre>git clone
git submodule --init --recursive</pre></div>
<p>This project targets the latest stable version of <code>rustc</code>, it may work on older
versions, but support is only guaranteed for the latest stable version.</p>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An app for M1 Macs that plays the sound of a fan as CPU usage goes up (729 pts)]]></title>
            <link>https://fanfan.rambo.codes/</link>
            <guid>27875158</guid>
            <pubDate>Sun, 18 Jul 2021 18:22:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fanfan.rambo.codes/">https://fanfan.rambo.codes/</a>, See on <a href="https://news.ycombinator.com/item?id=27875158">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="background-container">
<header id="hero">
<figure>FanFan app icon</figure>
<h2>If you're a fan of fans, this app is for you!</h2>
<p>With its state of the art Fan Simulation Engine (patent pending), FanFan can bring back that soothing sound of computer fans to your Apple Silicon Mac.</p>
<a id="buy-button-a" href="https://fanfan.rambo.codes/iLwfUwOzmv/FanFan_v1.0-1.dmg" rel="nofollow">Download FanFan</a>
<p>
Requires macOS 11 and Apple Silicon Mac.
</p>
</header>

<p>This is an April Fools joke.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ToyDB: Distributed SQL Database in Rust (259 pts)]]></title>
            <link>https://github.com/erikgrinaker/toydb</link>
            <guid>27874992</guid>
            <pubDate>Sun, 18 Jul 2021 18:03:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/erikgrinaker/toydb">https://github.com/erikgrinaker/toydb</a>, See on <a href="https://news.ycombinator.com/item?id=27874992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<p><a href="https://cloud.drone.io/erikgrinaker/toydb" rel="nofollow"><img src="https://camo.githubusercontent.com/40e01f4b3d1acade52d109435c5a0c0875f373ea2d245f57548235c78597cb4b/68747470733a2f2f636c6f75642e64726f6e652e696f2f6170692f6261646765732f6572696b6772696e616b65722f746f7964622f7374617475732e737667" alt="Build Status" data-canonical-src="https://cloud.drone.io/api/badges/erikgrinaker/toydb/status.svg"></a></p>
<p>Distributed SQL database in Rust, written as a learning project. Most components are built from
scratch, including:</p>
<ul>
<li>
<p>Raft-based distributed consensus engine for linearizable state machine replication.</p>
</li>
<li>
<p>ACID-compliant transaction engine with MVCC-based snapshot isolation.</p>
</li>
<li>
<p>Pluggable storage engine with B+tree and log-structured backends.</p>
</li>
<li>
<p>Iterator-based query engine with heuristic optimization and time-travel support.</p>
</li>
<li>
<p>SQL interface including projections, filters, joins, aggregates, and transactions.</p>
</li>
</ul>
<p>toyDB is not suitable for real-world use, but may be of interest to others learning about
database internals.</p>
<h2>Documentation</h2>
<ul>
<li>
<p><a href="https://github.com/erikgrinaker/toydb/blob/master/docs/architecture.md">Architecture guide</a>: a guide to toyDB's architecture and implementation.</p>
</li>
<li>
<p><a href="https://github.com/erikgrinaker/toydb/blob/master/docs/examples.md">SQL examples</a>: comprehensive examples of toyDB's SQL features.</p>
</li>
<li>
<p><a href="https://github.com/erikgrinaker/toydb/blob/master/docs/sql.md">SQL reference</a>: detailed reference documentation for toyDB's SQL dialect.</p>
</li>
<li>
<p><a href="https://github.com/erikgrinaker/toydb/blob/master/docs/references.md">References</a>: books and other research material used while building toyDB.</p>
</li>
</ul>
<h2>Usage</h2>
<p>With a <a href="https://www.rust-lang.org/tools/install" rel="nofollow">Rust compiler</a> installed, a local five-node
cluster can be started on <code>localhost</code> ports <code>9601</code> to <code>9605</code>:</p>
<div data-snippet-clipboard-copy-content="$ (cd clusters/local &amp;&amp; ./run.sh)
"><pre><code>$ (cd clusters/local &amp;&amp; ./run.sh)
</code></pre></div>
<p>A command-line client can be built and used with the node on <code>localhost</code> port <code>9605</code>:</p>
<div data-snippet-clipboard-copy-content="$ cargo run --release --bin toysql
Connected to toyDB node &quot;toydb-e&quot;. Enter !help for instructions.
toydb> CREATE TABLE movies (id INTEGER PRIMARY KEY, title VARCHAR NOT NULL);
toydb> INSERT INTO movies VALUES (1, 'Sicario'), (2, 'Stalker'), (3, 'Her');
toydb> SELECT * FROM movies;
1|Sicario
2|Stalker
3|Her
"><pre><code>$ cargo run --release --bin toysql
Connected to toyDB node "toydb-e". Enter !help for instructions.
toydb&gt; CREATE TABLE movies (id INTEGER PRIMARY KEY, title VARCHAR NOT NULL);
toydb&gt; INSERT INTO movies VALUES (1, 'Sicario'), (2, 'Stalker'), (3, 'Her');
toydb&gt; SELECT * FROM movies;
1|Sicario
2|Stalker
3|Her
</code></pre></div>
<p>toyDB supports most common SQL features, including joins, aggregates, and ACID transactions.</p>
<h2>Architecture</h2>
<p><a href="https://github.com/erikgrinaker/toydb/blob/master/docs/architecture.md"><img src="https://github.com/erikgrinaker/toydb/raw/master/docs/images/architecture.svg" alt="toyDB architecture"></a></p>
<p>toyDB's architecture is fairly typical for distributed SQL databases: a transactional
key/value store managed by a Raft cluster with a SQL query engine on top. See the
<a href="https://github.com/erikgrinaker/toydb/blob/master/docs/architecture.md">architecture guide</a> for more details.</p>
<h2>Tests</h2>
<p>toyDB has decent test coverage, with about a thousand tests of core functionality. These consist
of in-code unit-tests for many low-level components, golden master integration tests of the SQL
engine under <a href="https://github.com/erikgrinaker/toydb/tree/master/tests/sql"><code>tests/sql</code></a>, and a
basic set of end-to-end cluster tests under
<a href="https://github.com/erikgrinaker/toydb/tree/master/tests"><code>tests/</code></a>.
<a href="https://jepsen.io/" rel="nofollow">Jepsen tests</a>, or similar system-wide correctness and reliability tests, are
desirable but not yet implemented.</p>
<p>Execute <code>cargo test</code> to run all tests, or check out the latest
<a href="https://cloud.drone.io/erikgrinaker/toydb" rel="nofollow">CI run</a>.</p>
<h2>Performance</h2>
<p>Performance is not a primary goal of toyDB, but it has a bank simulation as a basic gauge of
throughput and correctness. This creates a set of customers and accounts, and spawns several
concurrent workers that make random transfers between them, retrying serialization failures and
verifying invariants:</p>
<div data-snippet-clipboard-copy-content="$ cargo run --release --bin bank
Created 100 customers (1000 accounts) in 0.123s
Verified that total balance is 100000 with no negative balances

Thread 0 transferred   18 from  92 (0911) to 100 (0994) in 0.007s (1 attempts)
Thread 1 transferred   84 from  61 (0601) to  85 (0843) in 0.007s (1 attempts)
Thread 3 transferred   15 from  40 (0393) to  62 (0614) in 0.007s (1 attempts)
[...]
Thread 6 transferred   48 from  78 (0777) to  52 (0513) in 0.004s (1 attempts)
Thread 3 transferred   57 from  93 (0921) to  19 (0188) in 0.065s (2 attempts)
Thread 4 transferred   70 from  35 (0347) to  49 (0484) in 0.068s (2 attempts)

Ran 1000 transactions in 0.937s (1067.691/s)
Verified that total balance is 100000 with no negative balances
"><pre>$ cargo run --release --bin bank
Created 100 customers (1000 accounts) <span>in</span> 0.123s
Verified that total balance is 100000 with no negative balances

Thread 0 transferred   18 from  92 (0911) to 100 (0994) <span>in</span> 0.007s (1 attempts)
Thread 1 transferred   84 from  61 (0601) to  85 (0843) <span>in</span> 0.007s (1 attempts)
Thread 3 transferred   15 from  40 (0393) to  62 (0614) <span>in</span> 0.007s (1 attempts)
[...]
Thread 6 transferred   48 from  78 (0777) to  52 (0513) <span>in</span> 0.004s (1 attempts)
Thread 3 transferred   57 from  93 (0921) to  19 (0188) <span>in</span> 0.065s (2 attempts)
Thread 4 transferred   70 from  35 (0347) to  49 (0484) <span>in</span> 0.068s (2 attempts)

Ran 1000 transactions <span>in</span> 0.937s (1067.691/s)
Verified that total balance is 100000 with no negative balances</pre></div>
<p>The informal target was 100 transactions per second, and these results exceed that by an order
of magnitude. For an unoptimized implementation, this is certainly "good enough". However, this
is with a single node and fsync disabled - the table below shows results for other configurations,
revealing clear potential for improvement:</p>
<table>
<thead>
<tr>
<th></th>
<th><code>sync: false</code></th>
<th><code>sync: true</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1 node</strong></td>
<td>1067 txn/s</td>
<td>38 txn/s</td>
</tr>
<tr>
<td><strong>5 nodes</strong></td>
<td>417 txn/s</td>
<td>19 txn/s</td>
</tr>
</tbody>
</table>
<p>Note that each transaction consists of six statements, including joins, not just a single update:</p>
<div data-snippet-clipboard-copy-content="BEGIN;

-- Find the sender account with the highest balance
SELECT a.id, a.balance
FROM account a JOIN customer c ON a.customer_id = c.id
WHERE c.id = {sender}
ORDER BY a.balance DESC
LIMIT 1;

-- Find the receiver account with the lowest balance
SELECT a.id, a.balance
FROM account a JOIN customer c ON a.customer_id = c.id
WHERE c.id = {receiver}
ORDER BY a.balance ASC
LIMIT 1;

-- Transfer a random amount within the sender's balance to the receiver
UPDATE account SET balance = balance - {amount} WHERE id = {source};
UPDATE account SET balance = balance + {amount} WHERE id = {destination};

COMMIT;
"><pre><span>BEGIN</span>;

<span><span>--</span> Find the sender account with the highest balance</span>
<span>SELECT</span> <span>a</span>.<span>id</span>, <span>a</span>.<span>balance</span>
<span>FROM</span> account a <span>JOIN</span> customer c <span>ON</span> <span>a</span>.<span>customer_id</span> <span>=</span> <span>c</span>.<span>id</span>
<span>WHERE</span> <span>c</span>.<span>id</span> <span>=</span> {sender}
<span>ORDER BY</span> <span>a</span>.<span>balance</span> <span>DESC</span>
<span>LIMIT</span> <span>1</span>;

<span><span>--</span> Find the receiver account with the lowest balance</span>
<span>SELECT</span> <span>a</span>.<span>id</span>, <span>a</span>.<span>balance</span>
<span>FROM</span> account a <span>JOIN</span> customer c <span>ON</span> <span>a</span>.<span>customer_id</span> <span>=</span> <span>c</span>.<span>id</span>
<span>WHERE</span> <span>c</span>.<span>id</span> <span>=</span> {receiver}
<span>ORDER BY</span> <span>a</span>.<span>balance</span> <span>ASC</span>
<span>LIMIT</span> <span>1</span>;

<span><span>--</span> Transfer a random amount within the sender's balance to the receiver</span>
<span>UPDATE</span> account <span>SET</span> balance <span>=</span> balance <span>-</span> {amount} <span>WHERE</span> id <span>=</span> {source};
<span>UPDATE</span> account <span>SET</span> balance <span>=</span> balance <span>+</span> {amount} <span>WHERE</span> id <span>=</span> {destination};

<span>COMMIT</span>;</pre></div>
<h2>Credits</h2>
<p>toyDB logo is courtesy of <a href="https://github.com/jonasmerlin">@jonasmerlin</a>.</p>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Police destroy Bitcoin miners with steamroller in Malaysia (193 pts)]]></title>
            <link>https://www.vice.com/en/article/7kv739/police-destroy-1069-bitcoin-miners-with-big-ass-steamroller-in-malaysia</link>
            <guid>27874794</guid>
            <pubDate>Sun, 18 Jul 2021 17:40:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/7kv739/police-destroy-1069-bitcoin-miners-with-big-ass-steamroller-in-malaysia">https://www.vice.com/en/article/7kv739/police-destroy-1069-bitcoin-miners-with-big-ass-steamroller-in-malaysia</a>, See on <a href="https://news.ycombinator.com/item?id=27874794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>As Bitcoin’s price surged this spring to a new all-time high, the spotlight shining on its controversial mining process only got brighter. Bitcoin, Ethereum, and many other cryptocurrencies use an energy-intensive “proof-of-work” process that makes computers on its decentralized network compete to solve complex mathematical equations to verify a batch of transactions; this makes the network less susceptible to certain attacks, and earns miners crypto rewards.</p></span><span></span><span data-component="TextBlock"><p>Given the competitive element in the quest for valuable cryptocurrency, powerful mining rigs—essentially, PCs purpose-built to maximize mining rewards—are the preferred tool of serious crypto miners. They are expensive, and persistent demand and manufacturing delays can mean <a href="https://shop.bitmain.com/" target="_blank"><span>months-long waits</span></a> for rigs to be delivered. This week, police in Malaysia crushed 1,069 of them with a steamroller.</p></span><span data-component="TextBlock"><p>Authorities in the city of Miri in Sarawak, Malaysia seized 1,069 rigs from miners alleged to have stolen electricity for their operations, per a report from local publication <a href="https://www.thestar.com.my/news/nation/2021/07/16/eight-arrested-over-power-theft-1069-bitcoin-mining-machines-worth-rm53mil-seized" target="_blank"><span>The Star</span></a>. The devices were seized in a joint operation between Miri police and Sarawak Energy Berhad between February and April, and have an estimated value of RM5.3 million ($1.25 million USD), according to the outlet.</p></span><span data-component="TextBlock"><p>Six individuals were arrested for electricity theft in the operation, and “have been fined up to RM8,000 and jailed for up to eight months," according to a statement from Miri police chief ACP Hakemal Hawari that was quoted by The Star. Local Sarawak news outlet <a href="https://dayakdaily.com/polis-miri-lupus-mesin-bitcoin-bernilai-rm5-3-juta/" target="_blank"><span>Dayak Daily</span></a> adds that the rigs were collected over the course of six separate raids. Sarawak Energy Berhad estimates that it lost RM8.4 million ($2 million USD) in energy that was stolen from its lines for the mining operation, the outlet reported. Dayak Daily also <a href="https://www.youtube.com/watch?v=c_tcg9kOfkg" target="_blank"><span>uploaded a video to YouTube</span></a> showing the miners being steamrolled.&nbsp;</p></span></p><p><span data-component="TextBlock"><p>Neither outlet stated why the police felt it was necessary to destroy the machines in such dramatic fashion, though it certainly sends a strong message. Electricity theft is a persistent issue in numerous regions where Bitcoin is mined, as some operators use illegal means to secure the cheap electricity necessary to make a big profit mining cryptocurrency.&nbsp;</p></span><span data-component="TextBlock"><p>"The electricity theft for mining Bitcoin activities has caused frequent power outages, and in 2021, three houses were razed due to illegal electricity supply connections," The Star quotes&nbsp; Hawari as saying.</p></span><span></span><span data-component="TextBlock"><p>According to the report, the mining rigs were demolished in the parking lot of the Miri district police headquarters this week, as seen in the video above. Bitcoin enthusiasts might watch the video and see dreams of prospective crypto wealth crushed to bits, while anti-mining advocates are likely to see Bitcoin’s ecological impact being slightly curtailed amidst all of that e-waste. </p></span></p><p><span data-component="TextBlock"><p>Bitcoin’s distributed ledger design ensures the security and stability of the blockchain network, but the mining model requires exorbitant amounts of energy. <a href="https://digiconomist.net/bitcoin-energy-consumption/" target="_blank"><span>Digiconomist</span></a> estimates that the Bitcoin network now uses as much energy annually as the entire county of Sweden, and the energy use of the network is sure to rise as more mining power is added to the network (and vice versa).&nbsp;</p></span><span data-component="TextBlock"><p>The leading cryptocurrency’s early-year surge was halted in part by Tesla announcing in May that it would <a href="https://www.vice.com/en/article/qj8bkx/elon-musk-says-bitcoin-has-great-cost-to-environment-and-tesla-will-no-longer-accept-it"><span>no longer accept Bitcoin payments</span></a>, citing concerns over the use of fossil fuels in mining. It was an about-face for the electric car maker, which announced in February that it had purchased&nbsp; $1.5 billion worth of Bitcoin to hold on its balance sheet, and soon after began accepting Bitcoin payments for a brief span.</p></span><span data-component="TextBlock"><p>Tesla CEO Elon Musk, the <a href="https://www.vice.com/en/article/g5gq3b/bitcoiners-are-so-so-mad-at-elon-musk"><span>terminally-online</span></a> <a href="https://www.vice.com/en/article/akgg4g/of-course-saturday-night-live-wanted-elon-musk-to-host"><span>Dogecoin memer</span></a>, has since become reviled by many crypto enthusiasts for his perceived meddling in the scene, including the <a href="https://www.vice.com/en/article/akgepg/bitcoiners-arent-thrilled-with-elon-musks-new-mining-council"><span>formation of a “Bitcoin Mining Council.”</span></a> Bitcoin’s price fell swiftly following Tesla’s announcement, and at a current price <a href="https://www.coingecko.com/en/coins/bitcoin" target="_blank"><span>just above $32,000 per coin</span></a>, it’s worth about half of its all-time high set in April.</p></span><span data-component="TextBlock"><div><p>China’s <a href="https://www.vice.com/en/article/pkb39z/chinas-major-bitcoin-crackdown-is-accelerating-global-shifts-in-cryptocurrency"><span>increasing crackdown on cryptocurrency</span></a> has also recently dampened enthusiasm around the industry. Crypto mining has been banned in multiple provinces, causing the Bitcoin network’s hash rate (or total computational power) to sink as miners shut down or move abroad. The People’s Bank of China also told top banks and payments services to root out cryptocurrency users and implement stricter know-your-customer processes.</p><p>Earlier this week, the Ukrainian Security Service (SBU) similarly busted a crypto mining operation for allegedly stealing electricity from a nearby regional energy provider. That bust had its own unique hook: <a href="https://www.vice.com/en/article/4av73b/feds-raid-cryptocurrency-mine-filled-with-thousands-of-playstation-4s-in-ukraine"><span>some 3,800 PlayStation 4 consoles</span></a> made up the majority of the seized devices, as the systems had apparently been modified to mine an unidentified cryptocurrency. Game consoles are significantly less powerful than dedicated PC mining rigs, but there’s still potential for profit when the energy cost is zero.</p></div></span></p></div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up to the VICE newsletter you agree to receive electronic communications from VICE that may sometimes include advertisements or sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Perils of M1 Ownership (104 pts)]]></title>
            <link>https://eclecticlight.co/2021/07/18/last-week-on-my-mac-the-perils-of-m1-ownership/</link>
            <guid>27874600</guid>
            <pubDate>Sun, 18 Jul 2021 17:13:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2021/07/18/last-week-on-my-mac-the-perils-of-m1-ownership/">https://eclecticlight.co/2021/07/18/last-week-on-my-mac-the-perils-of-m1-ownership/</a>, See on <a href="https://news.ycombinator.com/item?id=27874600">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-60213">
	
	<!-- .entry-header -->

	
		<div data-first_letter="I">
		<p>In the next few days those using M1 Macs will be updating to Big Sur 11.5, blissfully ignorant of how, as an admin user, their Mac could refuse to update. Because now, in addition to regular users, admin users and root, there’s another class of admin user: the Owner. Let me explain.</p>
<p>According to the small print in Apple’s <a href="https://support.apple.com/en-gb/guide/security/welcome/web" target="_blank">Platform Security Guide</a>, when you set up a new M1 Mac, or set one up after restoring it in DFU mode, the primary admin account created is special: it’s the Owner account of that Mac. During that inital setup, the Mac sends a request to Apple for that Mac’s signed Owner Identity Certificate (OIC). This is based on a private key generated in the Secure Enclave known as the Owner Identity Key (OIK).</p>
<p>Each M1 Mac has just a single OIK, and access to that is confined to that primary admin user of the internal SSD, who is thus its Owner. If your M1 is configured with a single macOS boot volume group on its internal SSD, never boots from an external disk, and has no other admin users – a vanilla system – then that’s all transparent.</p>
<p>If you install a second operating system, on internal or external storage, the Owner needs to agree to hand over Ownership to users of that second system. And that’s where problems can occur, with a combination of puzzlement and frustration. Last week, when trying to perform a macOS update on a second operating system on my M1 Mac mini, I only succeeded at the third attempt, after a total of five hours.</p>
<p>On an Intel Mac, there’s little to the installation and use of second operating systems: format the disk, run the installer, and by the end of the process you can switch readily between the two, logging in as an appropriate user on the system of your choice. For the M1’s Secure Boot, each bootable volume group needs a signed LocalPolicy which defines security policy for that system, and an Install User authorised by the Owner. When you run a macOS installer from the Owner account on internal storage, you’re normally invited to copy that Owner account to the second system, to become its primary admin user. If you agree to that, you’re prompted to enter the Owner’s password so their OIK can be accessed from the Secure Enclave.</p>
<p>When this works properly, it’s almost transparent to the Owner, and Ownership is handed over securely to the primary admin user of the second system. What happens, though, when a second admin user is created on that second system?</p>
<p>Because that second admin user has full admin rights, you’d expect them to be able to download and install macOS updates. What should happen before they’re installed is that macOS should ask for the primary admin user’s password, and installation should proceed. But it doesn’t always work that way. Depending on the version of iBoot installed, and which way the wind’s blowing, one of two failures can occur:</p>
<ul>
<li>macOS may be unable to identify the Owner or primary admin user for that second system, and display an error alert reporting that the system has no Owner, so refusing to even download the update.</li>
<li>macOS may proceed to download and install the update, apparently as normal, but at the final stage it gets cold feet and reverts to the previous version of macOS installed. In other words, the update proceeds right up to the last moments, then aborts.</li>
</ul>
<p>Having experienced both of these several times now, I’ve been unable to find any information provided by Apple (or anyone else) which explains what’s going on, what the errors mean, or how to address them. It’s only by wading through Apple’s Platform Security Guide, guesswork and experiment that I think I’ve realised what’s going on, and even then I stand by to be corrected by someone who really does know what they’re doing.</p>
<p>If you want to try duplicating these problems, here’s what I suggest:</p>
<ol>
<li>Take a standard M1 Mac with macOS 11.4 installed in vanilla form on its internal SSD.</li>
<li>Install Monterey Public Beta 3 on an external SSD, to update the Mac’s firmware to something more recent than that accompanying 11.4.</li>
<li>Connect (or create) an external SSD with macOS 11.3.1 installed on it, with just the primary admin user configured.</li>
<li>Boot from 11.3.1, create a second admin user, and restart, logging into 11.3.1 using the second admin account.</li>
<li>Try installing the waiting macOS update to 11.4 (or 11.5 when available).</li>
</ol>
<p>These may seem elaborate and esoteric, but in the next few months we’re all expecting Apple to release more Apple Silicon Macs aimed well above the lower end of the market, where users often live more adventurous lives and have Macs which are far from vanilla. Yet as far as I can see, none of these subtleties are documented for those more advanced users. That’s something I’ll be trying to put right in the coming week.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Right or left, you should be worried about big tech censorship (572 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2021/07/right-or-left-you-should-be-worried-about-big-tech-censorship</link>
            <guid>27874527</guid>
            <pubDate>Sun, 18 Jul 2021 17:04:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2021/07/right-or-left-you-should-be-worried-about-big-tech-censorship">https://www.eff.org/deeplinks/2021/07/right-or-left-you-should-be-worried-about-big-tech-censorship</a>, See on <a href="https://news.ycombinator.com/item?id=27874527">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><h2><b>Conservatives </b><b><i>are</i></b><b> being censored</b></h2>
<p><span>Claiming that “right-wing voices are being censored,” Republican-led legislatures in </span><a href="https://www.miamiherald.com/news/politics-government/state-politics/article252492548.html"><span>Florida</span></a><span> and </span><a href="https://www.techdirt.com/articles/20210708/09521047132/texas-legislature-sees-floridas-social-media-bill-go-down-unconstitutional-flames-decides-we-can-do-that-too.shtml"><span>Texas</span></a><span> have introduced legislation to “end Big Tech censorship.” They say that the dominant tech platforms block legitimate speech without ever articulating their moderation policies, that they are slow to admit their mistakes, and that there is no meaningful due process for people who think the platforms got it wrong.</span></p>
<p><span>They’re right.</span></p>
<h2><b>So is everyone else</b></h2>
<p><span>But it’s not just conservatives who have their political speech blocked by social media giants. It’s </span><a href="https://www.eff.org/deeplinks/2021/05/amid-systemic-censorship-palestinian-voices-facebook-owes-users-transparency"><span>Palestinians</span></a><span> and other </span><a href="https://www.eff.org/deeplinks/2021/02/facebooks-latest-proposed-policy-change-exemplifies-trouble-moderating-speech-0"><span>critics of Israel</span></a><span>, including many Israelis. And it’s </span><a href="https://www.eff.org/deeplinks/2019/06/during-pride-month-and-always-companies-must-consider-impact-their-policies-lgbtq"><span>queer people</span></a><span>, of course. We have </span><a href="https://www.eff.org/deeplinks/2019/05/tossed-out-highlighting-effects-content-rules-online"><span>a whole project</span></a><span> tracking people who’ve been censored, blocked, downranked, suspended and terminated for their legitimate speech, from </span><a href="https://www.eff.org/takedowns/facebook-treats-punk-rockers-crazy-conspiracy-theorists-kicks-them-offline"><span>punk musicians</span></a><span> to </span><a href="https://www.eff.org/takedowns/tough-nuts-twitter-suspends-meme-sharing-planters-accounts"><span>peanuts fans</span></a><span>, </span><a href="https://www.eff.org/tossedout/third-times-charm-historians-content-repeatedly-deleted-finally-restored"><span>historians</span></a><span> to </span><a href="https://www.eff.org/tossedout/documentation-war-crimes-disappeared-automated-tools"><span>war crimes investigators</span></a><span>, </span><a href="https://www.eff.org/tossedout/explicitly-art-or-sexually-explicit"><span>sex educators</span></a><span> to </span><a href="https://www.eff.org/tossedout/no-targeting-allowed-christian-veterans-ministry-denied-ad"><span>Christian ministries</span></a><span>.&nbsp;</span></p>
<h2><b>The goat-rodeo</b></h2>
<p><a href="https://www.eff.org/deeplinks/2019/04/content-moderation-broken-let-us-count-ways"><span>Content moderation is hard at any scale</span></a><span>, but even so, the </span><a href="https://www.eff.org/deeplinks/2018/01/private-censorship-not-best-way-fight-hate-or-defend-democracy-here-are-some"><span>catalog of big platforms’ unforced errors</span></a><span> makes for sorry reading. Experts who care about political diversity, harassment and inclusion came together in 2018 to draft the </span><a href="https://santaclaraprinciples.org/"><span>Santa Clara Principles on Transparency and Accountability in Content Moderation</span></a><span> but the biggest platforms are </span><a href="https://www.eff.org/deeplinks/2020/12/2020-year-review-what-comes-next-santa-clara-principles"><span>still just winging it</span></a><span> for the most part.</span></p>
<p><span>The situation is especially grim when it comes to </span><a href="https://www.eff.org/deeplinks/2019/10/facebook-shouldnt-give-politicians-more-power-ordinary-users"><span>political speech</span></a><span>, particularly when platforms are told they have a duty to remove “</span><a href="https://www.eff.org/deeplinks/2019/09/innocent-users-have-most-lose-rush-address-extremist-speech-online"><span>extremism</span></a><span>.” <br></span></p>
<p><span>The Florida and Texas social media laws are deeply misguided and nakedly unconstitutional, but we get why people are fed up with Big Tech’s ongoing goat-rodeo of content moderation gaffes.</span></p>
<h2><b>So what can we do about it?</b></h2>
<p><span>Let’s start with talking about why platform censorship matters. In theory, if you don’t like the moderation policies at Facebook, you can quit and go to a rival, or start your own. In practice, it’s not that simple. <br></span></p>
<p><span>First of all, the internet’s “marketplace of ideas” is severely lopsided at the platform level, consisting of a single gargantuan service (Facebook), a handful of massive services (YouTube, Twitter, Reddit, TikTok, etc) and </span><a href="https://www.eff.org/issues/public-interest-internet"><span>a constellation of plucky, struggling, endangered indieweb alternatives</span></a><span>.&nbsp;&nbsp; <br></span></p>
<h2><b>DIY?</b></h2>
<p><span>If none of the big platforms want you, you can try to strike out on your own. Setting up your own rival platform requires that you get cloud services, anti-DDoS, domain registration and DNS, payment processing and other essential infrastructure. Unfortunately, every one of these sectors has grown increasingly concentrated, and with just a handful of companies dominating every layer of the stack, </span><a href="https://www.eff.org/deeplinks/2021/01/beyond-platforms-private-censorship-parler-and-stack"><span>there are plenty of weak links in the chain </span></a><span>and if just one breaks, your service is at risk.</span></p>
<p><span>But even if you </span><i><span>can</span></i><span> set up your own service, you’ve still got a problem: everyone you want to talk about your disfavored ideas with is stuck in one of the Big Tech silos. Economists call this the “network effect,” when a service gets more valuable as more users join it. You join Facebook because your friends are there, and once you’re there, more of your friends join so they can talk to you.</span></p>
<p><span>Setting up your own service might get you a more nuanced and welcoming moderation environment, but it’s not going to do you much good if your people aren’t willing to give up access to all their friends, customers and communities by quitting Facebook and joining your nascent alternative, not least because there’s a limit to how many services you can be active on.</span></p>
<h2><b>Network effects</b></h2>
<p><span>If all you think about is network effects, then you might be tempted to think that we’ve arrived at the end of history, and that the internet was doomed to be a&nbsp; winner-take-all world of </span><a href="https://twitter.com/tveastman/status/1069674780826071040"><span>five giant websites filled with screenshots of text from the other four</span></a><span>.&nbsp;</span></p>
<h2><b>But not </b><b><i>just </i></b><b>network effects</b></h2>
<p><span>But network effects aren’t the only idea from economics we need to pay attention to when it comes to the internet and free speech. Just as important is the idea of “switching costs,” the things you have to give up when you switch away from one of the big services - if you resign from Facebook, you lose access to everyone who isn’t willing to follow you to a better place.</span></p>
<p><span>Switching costs aren’t an inevitable feature of large communications systems. You can switch email providers and still connect with your friends; you can change cellular carriers without even having to </span><i><span>tell</span></i><span> your friends because you get to keep your phone number.</span></p>
<p><span>The high switching costs of Big Tech are there by design. Social media may make signing up as easy as a greased slide, but leaving is another story. It's like a roach motel: users check in but they’re not supposed to check out.</span></p>
<h2><b>Interop vs. switching costs</b></h2>
<p><span>Enter </span><a href="https://www.eff.org/deeplinks/2019/10/adversarial-interoperability"><span>interoperability</span></a><span>, the practice of designing new technologies that connect to existing ones. Interoperability is why you can access any website with any browser, and read Microsoft Office files using free/open software like LibreOffice, cloud software like Google Office, or desktop software like Apple iWorks.</span></p>
<p><span>An interoperable social media giant - one that allowed new services to connect to it - would bust open that roach motel. If you could leave Facebook but continue to connect with the friends, communities and customers who stayed behind, the decision to leave would be </span><i><span>much </span></i><span>simpler. If you don’t like Facebook’s rules (and who does?) you could go somewhere else and still reach the people that matter to you, without having to convince them that it’s time to make a move.</span></p>
<h2><b>The ACCESS Act</b></h2>
<p><span>That’s where laws like the proposed ACCESS Act come in. While </span><a href="https://www.eff.org/deeplinks/2021/06/new-access-act-good-start-heres-how-make-sure-it-delivers"><span>not perfect</span></a><span>, this proposal to force the Big Tech platforms to open up their walled gardens to </span><a href="https://www.eff.org/wp/interoperability-and-privacy"><span>privacy-respecting, consent-seeking third parties</span></a><span> is a way forward for anyone who chafes against Big Tech’s moderation policies and their uneven, high-handed application.&nbsp;</span></p>
<p><span>Some tech platforms are already moving in that direction. Twitter says it wants to create an “app store for moderation,” with multiple services connecting to it, each offering different moderation options. We wish it well! </span><a href="https://www.eff.org/deeplinks/2021/01/twitter-and-interoperability-some-thoughts-peanut-gallery"><span>Twitter is well-positioned to do this</span></a><span> - it’s one tenth the size of Facebook and needs to find ways to grow.</span></p>
<p><span>But the biggest tech companies show no sign of voluntarily reducing their switching costs.&nbsp; The ACCESS Act is the most important interoperability proposal in the world, and it could be a game-changer for all internet users.</span></p>
<h2><b>Save Section 230, save the internet</b></h2>
<p><span>Unfortunately for all of us, many of the people who don’t like Big Tech’s moderation think the way to fix it is to eliminate </span><a href="https://www.eff.org/issues/cda230"><span>Section 230</span></a><span>, a law that promotes users' free speech. Section 230 is a rule that says you sue the person who caused the harm while organizations that host expressive speech are free to remove offensive, harassing or otherwise objectionable content. <br></span></p>
<p><span>That means that conservative Twitter alternatives can </span><a href="https://www.hitc.com/en-gb/2021/07/02/what-is-the-pig-poop-balls-meme-old-meme-resurfaces-amidst-new-social-gettr-app/"><span>delete floods of pornographic memes</span></a> <span>without being sued by their users. It means that online forums can allow </span><a href="https://www.techdirt.com/articles/20210512/16520946784/why-is-wired-so-focused-misrepresenting-section-230.shtml"><span>survivors of workplace harassment to name their abusers</span></a><span> without worrying about libel suits.</span></p>
<p><span>If hosting speech makes you liable for what your users say, then only the very biggest platforms can afford to operate, and then only by resorting to </span><a href="https://www.eff.org/deeplinks/2020/10/facebooks-most-recent-transparency-report-demonstrates-pitfalls-automated-content"><span>shoot-first/ask-questions-later automated takedown</span></a><span> systems.</span></p>
<h2><b>Kumbaya</b></h2>
<p><span>There’s not much that the political left and right agree on these days, but there’s one subject that reliably crosses the political divide: frustration with monopolists’ clumsy handling of online speech.&nbsp;</span></p>
<p><span>For the first time, there’s a law before Congress that could make Big Tech more accountable and give internet users more control over speech and moderation policies. The promise of the ACCESS Act is an internet where if you don’t like a big platform’s moderation policies, if you think they’re too tolerant of abusers or too quick to kick someone off for getting too passionate during a debate, </span><i><span>you can leave, </span></i><span>and still stay connected to the people who matter to you.</span></p>
<p><span>Killing CDA 230 won’t fix Big Tech (if that was the case, </span><a href="https://www.nbcnews.com/tech/tech-news/zuckerberg-calls-changes-techs-section-230-protections-rcna486"><span>Mark Zuckerberg wouldn’t be calling for CDA 230 reform</span></a><span>). The ACCESS Act won’t either, by itself -- but by making Big Tech open up to new services that are accountable to their users, the ACCESS Act takes several steps in the right direction.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Let Police Arm Autonomous or Remote-Controlled Robots and Drones (264 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2021/07/dont-let-police-arm-autonomous-or-remote-controlled-robots-and-drones</link>
            <guid>27874519</guid>
            <pubDate>Sun, 18 Jul 2021 17:03:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2021/07/dont-let-police-arm-autonomous-or-remote-controlled-robots-and-drones">https://www.eff.org/deeplinks/2021/07/dont-let-police-arm-autonomous-or-remote-controlled-robots-and-drones</a>, See on <a href="https://news.ycombinator.com/item?id=27874519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>It’s no longer science fiction or unreasonable paranoia. Now, it needs to be said: No, police must not be arming land-based robots or aerial drones. That<span>’</span>s true whether these mobile devices are remote controlled by a person or autonomously controlled by artificial&nbsp;intelligence, and whether the weapons are maximally lethal (like bullets) or less lethal (like tear gas). <br></span></p>
<p><span>Police currently deploy many different kinds of moving and task-performing technologies. These include flying drones, remote control bomb-defusing robots, and autonomous patrol robots. While these different devices serve different functions and operate differently, none of them--absolutely none of them--should be armed with any kind of weapon.&nbsp;</span></p>
<p><span>Mission creep is very real. Time and time again, technologies given to police to use only in the most extreme circumstances make their way onto streets during protests or to respond to petty crime. For example, cell site simulators (often called “Stingrays”) were developed for use in </span><a href="https://www.scientificamerican.com/article/what-is-the-big-secret-surrounding-stingray-surveillance/"><span>foreign battlefields,</span></a><span> brought home in the name of fighting “</span><a href="https://www.aclu.org/blog/privacy-technology/surveillance-technologies/police-citing-terrorism-buy-stingrays-used-only"><span>terrorism</span></a><span>,” then used by law enforcement to catch </span><a href="https://www.eff.org/deeplinks/2017/05/no-hunting-undocumented-immigrants-stingrays"><span>immigrants</span></a><span> and a man who stole </span><a href="https://www.eff.org/deeplinks/2017/05/no-hunting-undocumented-immigrants-stingrays"><span>$57 worth of food</span></a><span>. Likewise, police have targeted BLM protesters with </span><a href="https://www.theverge.com/2020/8/18/21373316/nypd-facial-recognition-black-lives-matter-activist-derrick-ingram"><span>face</span></a> <a href="https://www.nbcmiami.com/investigations/miami-police-used-facial-recognition-technology-in-protesters-arrest/2278848/"><span>surveillance</span></a><span> and Amazon Ring </span><a href="https://www.eff.org/deeplinks/2021/02/lapd-requested-ring-footage-black-lives-matter-protests"><span>doorbell cameras</span></a><span>. <br></span></p>
<p><span>Today, scientists are developing an AI-enhanced autonomous drone, </span><a href="https://www.washingtonpost.com/technology/2021/06/17/drone-human-screams/"><span>designed to find people during natural disasters by locating their screams</span></a><span>. How long until police use this technology to find protesters shouting chants? What if these autonomous drones were armed? We need a clear red line now: no armed police drones, period.</span></p>
<h4><b>The Threat is Real <br></b></h4>
<p><span>There are already law enforcement robots and drones of all shapes, sizes, and levels of autonomy patrolling the United States as we speak. From autonomous </span><a href="https://www.eff.org/deeplinks/2021/01/police-robots-are-not-selfie-opportunity-theyre-privacy-disaster-waiting-happen"><span>Knightscope robots</span></a>&nbsp;<span>prowling for “suspicious behavior” and collecting images of license plates and phone identifying information, to Boston Dynamic robotic </span><a href="https://www.nytimes.com/2021/04/28/nyregion/nypd-robot-dog-backlash.html"><span>dogs</span></a><span> accompanying police on calls in New York or </span><a href="https://www.civilbeat.org/2021/01/honolulu-police-spent-150000-in-cares-funds-on-a-robot-dog/"><span>checking the temperature</span></a><span> of unhoused people in Honolulu, to </span><a href="https://www.govtech.com/security/predator-drone-over-minneapolis-stokes-surveillance-fears.html"><span>predator surveillance drones</span></a><span> flying over BLM protests in Minneapolis. <br></span></p>
<p><span>We are moving quickly towards arming such robots and letting autonomous artificial intelligence determine whether or not to pull the trigger. <br></span></p>
<p><span>According to a </span><a href="https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/"><span>Wired</span></a><span> report earlier this year, the U.S. Defense Advanced Research Projects Agency (DARPA) in 2020 hosted a test of autonomous robots to see how quickly they could react in a combat simulation and how much human guidance they would need. News of this test comes only weeks after the federal government’s National Security Commission on Artificial Intelligence </span><a href="https://www.nscai.gov/2021-final-report/"><span>recommended</span></a><span> the United States not sign international agreements banning autonomous weapons. “It is neither feasible nor currently in the interests of the United States,” asserts the </span><a href="https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf"><span>report</span></a><span>, “to pursue a global prohibition of AI-enabled and autonomous weapon systems.” <br></span></p>
<p><span>In 2020, the Turkish military deployed </span><a href="https://www.fox5ny.com/news/fully-autonomous-drone-was-used-to-hunt-down-soldiers-un-says"><span>Kargu</span></a><span>, a fully autonomous armed drone, to hunt down and attack Libyan battlefield adversaries. Autonomous armed drones have </span><a href="https://www.washingtonpost.com/technology/2021/07/07/ai-weapons-us-military/"><span>also been deployed</span></a><span> (though not necessarily used to attack people) by the Turkish military in Syria, and by the Azerbaijani military in Armenia. While we have yet to see autonomous armed robots or drones deployed in a domestic law enforcement context, wartime tools used abroad often find their way home. <br></span></p>
<p><span>The U.S. government has become increasingly reliant on </span><a href="https://www.theguardian.com/news/2019/nov/18/killer-drones-how-many-uav-predator-reaper"><span>armed drones abroad</span></a><span>. Many police departments seem to purchase every </span><a href="https://www.digitaltrends.com/features/robot-law-enforcement-normalization/"><span>expensive new toy</span></a><span> that hits the market. The Dallas police have already killed someone by</span><a href="https://www.texastribune.org/2016/07/08/use-robot-kill-dallas-suspect-first-experts-say/"><span> strapping a bomb</span></a>&nbsp;<span>to a remote-controlled bomb-disarming robot.&nbsp;</span></p>
<p><span>So activists, politicians, and technologists need to step in now, before it is too late. We cannot allow a time lag between the development of this technology and the&nbsp;creation of policies to let police buy, deploy, or use armed robots. Rather, we must ban police from arming robots, whether in the air or on the ground, whether automated or remotely-controlled, whether lethal or less lethal, and in any other yet unimagined configuration.</span></p>
<h4><b>No Autonomous Armed Police Robots</b></h4>
<p><span>Whether they’re armed with a taser, a gun, or pepper spray, autonomous robots would make split-second decisions about taking a life, or inflicting serious injury, based on a set of computer programs. <br></span></p>
<p><span>But police technologies malfunction all the time. For example, false positives are frequently generated by </span><a href="https://www.nytimes.com/2020/12/29/technology/facial-recognition-misidentify-jail.html"><span>face recognition technology</span></a><span>, </span><a href="https://endpolicesurveillance.com/"><span>audio gunshot detection</span></a><span>, and </span><a href="https://www.nytimes.com/2020/08/05/us/aurora-police-black-family.html"><span>automatic license plate readers</span></a><span>. When this happens, the technology deploys armed police to a situation where they may not be needed, often leading to wrongful arrests and excessive force, especially against people of color erroneously identified as criminal suspects. If the malfunctioning police technology were armed and autonomous, that would create a far more dangerous situation for innocent civilians. <br></span></p>
<p><span>When, inevitably, a robot unjustifiably injures or kills someone--who would be held responsible? Holding police accountable for wrongfully killing civilians is already </span><a href="https://www.washingtonpost.com/crime-law/2020/05/29/charging-cops-with-crimes-is-still-difficult-prosecutors/"><span>hard enough</span></a><span>. In the case of a bad automated decision, who gets held responsible? The person who wrote the algorithm? The police department that deployed the robot? <br></span></p>
<p><span>Autonomous armed police robots might become one more way for police to skirt or redirect the blame for wrongdoing and avoid making any actual changes to how police function. Debate might bog down in whether to tweak the artificial intelligence guiding a killer robot’s decision making. Further, technology deployed by police is usually created and maintained by private corporations. A transparent investigation into a wrongful killing by an autonomous machine might be blocked by assertions of the company’s supposed need for trade secrecy in its proprietary technology, or by finger-pointing between police and the company. Meanwhile, nothing would be done to make people on the streets any safer. <br></span></p>
<p><span>MIT Professor and cofounder of the</span><a href="https://futureoflife.org/"> <span>Future of Life Institute</span></a> <a href="https://space.mit.edu/home/tegmark/"><span>Max Tegmark</span></a><span> told </span><a href="https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/"><span>Wired</span></a><span> that AI weapons should be “stigmatized and banned like biological weapons.” We agree.&nbsp; Although its mission is much more expansive than the concerns of this blog post,&nbsp; you can learn more about what activists have been doing around this issue by visiting the </span><a href="https://www.stopkillerrobots.org/act/"><span>Campaign to Stop Killer Robots</span></a><span>. <br></span></p>
<h4><b>No Remote-Controlled Armed Police Robots, Either</b></h4>
<p><span>Even where police have remote control over armed drones and robots, the grave dangers to human rights are far too great. Police routinely over-deploy powerful new technologies in already over-policed Black, Latinx, and immigrant communities.&nbsp; Police also use them too often as part of the United State’s immigration enforcement regime, and to monitor protests and other First Amendment-protected activities. We can expect more of the same with any armed robots.</span></p>
<p><span>Moreover, armed police robots would probably increase the frequency of excessive force against suspects and bystanders. A police officer on the scene generally will have better information about unfolding dangers and opportunities to de-escalate, compared to an officer miles away looking at a laptop screen. Moreover, a remote officer might have less empathy for the human target of mechanical violence.</span></p>
<p><span>Further, hackers will inevitably try to commandeer armed police robots. They already have succeeded at </span><a href="https://www.bloomberg.com/news/articles/2021-03-09/hackers-expose-tesla-jails-in-breach-of-150-000-security-cams"><span>taking control</span></a><span> of police surveillance cameras. The last thing we need are foreign governments or organized criminals seizing command of armed police robots and aiming them at innocent people. <br></span></p>
<p><span>Armed police robots are especially menacing at protests. The capabilities of police to conduct crowd control by force are already too great. Just look at how the New York City Police Department has had to pay out </span><a href="https://www.nytimes.com/2021/04/19/nyregion/nypd-sound-cannon-protests.html"><span>hundreds of thousands of dollars</span></a><span> to settle a civil lawsuit concerning police using a Long Range Acoustic Device (LRAD) punitively against protestors. Police must never deploy taser-equipped robots or pepper spray spewing drones against a crowd. Armed robots would discourage people from attending protests. We must de-militarize our police, not further militarize them.</span></p>
<p><span>We need a flat-out ban on armed police robots, even if their use might at first appear reasonable in uncommon circumstances. In Dallas in 2016, police </span><a href="https://www.texastribune.org/2016/07/08/use-robot-kill-dallas-suspect-first-experts-say/"><span>strapped a bomb to an explosive-diffusing robot</span></a><span> in order to kill a gunman hiding inside a parking garage who had already killed five police officers and shot seven others. Normalizing armed police robots poses too great a threat to the public to allow their use even in extenuating circumstances. Police have proven time and time again that technologies meant only for the most extreme circumstances inevitably become commonplace, even at protests. </span></p>
<h4><b>Conclusion <br></b></h4>
<p><span>Whether controlled by an artificial intelligence or a remote human operator, armed police robots and drones pose an unacceptable threat to civilians. It’s exponentially harder to remove a technology from the hands of police than prevent it from being purchased and deployed in the first place. That’s why now is the time to push for legislation to ban police deployment of these technologies. The ongoing revolution in the field of robotics requires us to act now to prevent a new era of police violence.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A reporter’s fight to expose Epstein’s crimes, and earn a living (129 pts)]]></title>
            <link>https://www.nytimes.com/2021/07/17/opinion/julie-brown-epstein-book.html</link>
            <guid>27874442</guid>
            <pubDate>Sun, 18 Jul 2021 16:53:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2021/07/17/opinion/julie-brown-epstein-book.html">https://www.nytimes.com/2021/07/17/opinion/julie-brown-epstein-book.html</a>, See on <a href="https://news.ycombinator.com/item?id=27874442">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="story"><header><p>Michelle Goldberg</p><p><time datetime="2021-07-17T11:00:07-04:00">July 17, 2021</time></p><div data-testid="photoviewer-wrapper"><figure aria-label="media" role="group"><div><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-mobileMasterAt3x.png?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-mobileMasterAt3x.png?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-mobileMasterAt3x.png?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"><img alt="" src="https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-articleLarge.png?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-articleLarge.png?quality=90&amp;auto=webp 600w,https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-jumbo.png?quality=90&amp;auto=webp 1024w,https://static01.nyt.com/images/2021/07/17/opinion/17goldberg_web/17goldberg_web-superJumbo.png?quality=90&amp;auto=webp 1600w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="600"></picture></div><figcaption><span><span>Credit...</span><span><span>Illustration by Emily Haasch; Photographs Via Getty</span></span></span></figcaption></figure></div></header><section name="articleBody"><div><p>At a news conference after Jeffrey Epstein’s 2019 sex trafficking indictment, a reporter asked Geoffrey Berman, then the U.S. attorney in Manhattan, if new information had prompted his office’s inquiry. The F.B.I., after all, had investigated Epstein’s sexual predation more than a decade earlier, and the crimes in the 2019 indictment took place between 2002 and 2005. Berman revealed little about what went on inside his office, but said that his team was helped by “some excellent investigative journalism.”</p><p>He was clearly referring to Julie K. Brown’s 2018 Miami Herald series “<a href="https://www.miamiherald.com/topics/jeffrey-epstein" title="" rel="noopener noreferrer" target="_blank">Perversion of Justice</a>.” Brown had delved into how prosecutors led by Alex Acosta, who would later become Donald Trump’s secretary of labor, went behind the backs of Epstein’s victims to give the pedophile financier a scandalously lenient deal.</p><p>She has now written a book with the same title, which both expands on the Epstein story and explains all that went into writing it. It’s a gripping journalistic procedural, sort of “Spotlight” meets “Erin Brockovich.” It also shows just how close Epstein came to getting away with his industrial-scale sexual exploitation.</p><p>Brown’s book, which comes out on Tuesday, is about a mind-blowing case of plutocratic corruption, full of noirish subplots that may never be fully understood. But it’s also about the slow strangulation of local and regional newspapers. Reading it, I kept thinking of all the malfeasance likely to go unexposed as many once-formidable newspapers outside of New York and Washington either shrink or disappear altogether.</p></div><div><p>Thanks to Brown, the basic outlines of the Epstein scandal — at least the part that preceded his baffling death — are well known. As she summarizes it in her book, “A supremely wealthy money manager with political connections wrestled an incredible immunity agreement out of the federal government — despite having molested, raped and sexually abused dozens of girls.” Rather than decades in federal prison, Epstein served only 13 months — with daily work release — in a county jail, where his cell door was left unlocked and a TV was installed for his entertainment.</p><p>Because of Brown’s reporting, Epstein seemed on the verge of real legal accountability when he died in his cell, apparently by suicide, in 2019. That reporting was done in the face of powerful headwinds. She was up against Epstein’s intimidating legal team and fears about her safety.</p><p>But Brown also had to contend with the punishing economics of the contracting newspaper industry, which for the last decade has been shedding experienced reporters and forcing those who remain to do much more with much less.</p><p>Brown, who has worked in journalism for more than three decades, got her start in Philadelphia at a time when newspapers were thriving. “We had so many news organizations and papers and it was so competitive,” she told me. There were people covering “every single city council, planning board, zoning board” meeting. In the past, she said, newspaper journalists were “used to uncovering all this corruption. We’re used to finding injustices pretty easily and writing these stories pretty easily. And now we just don’t have the staff to do that anymore.”</p><p>“Perversion of Justice” begins in 2017 with Brown trying to get hired at The Washington Post after more than 10 years at The Herald. “I hoped it would offer me the kind of stability that I never felt I had at The Herald, where layoffs, pay cuts and unpaid leaves were an annual ritual,” she wrote.</p></div><div><p>The Herald wasn’t unique: As the Pew Research Center recently reported, newsroom employment has <a href="https://www.pewresearch.org/fact-tank/2021/07/13/u-s-newsroom-employment-has-fallen-26-since-2008/" title="" rel="noopener noreferrer" target="_blank">plummeted 26 percent since 2008</a>. Journalists in the middle of their careers — those 35 to 54 — have been hit the hardest, as <a href="https://www.pewresearch.org/fact-tank/2020/04/07/decade-long-decline-in-newsroom-employment-hit-midcareer-workers-the-hardest/" title="" rel="noopener noreferrer" target="_blank">Pew found last year</a>.</p><p>At The Herald, said Brown, veteran reporters were pushed out because their salaries were too high. She was able to hang on, but she had to accept a 15 percent pay cut in 2009. “I consoled myself by remembering that I still had my waitressing chops from my early years in journalism in case I needed them,” she wrote.</p><p>While waiting to hear about the Post job, which she didn’t get, Brown started digging into Epstein. She’d spent four years covering prisons for The Herald, which led her to start reporting on sex trafficking. You couldn’t research sex trafficking in Florida without coming across the Epstein case. So when Trump nominated Acosta, Brown figured the Epstein deal he oversaw would be an issue in his confirmation hearings.</p><p>It wasn’t. “I was astonished that Epstein’s name barely came up, and that the questions Acosta was asked showed that the senators didn’t understand the gravity of what Acosta had done,” she wrote. She pitched her editor on the idea of tracking down some of Epstein’s victims and talking to them.</p><p>She would <a href="https://www.miamiherald.com/news/local/article221957120.html" title="" rel="noopener noreferrer" target="_blank">eventually identify around 80 women</a> who said they had been abused by Epstein when they were girls, and she got four of them to speak on the record. It was a journalistically grueling process. Many of the women’s names were redacted in legal documents, making it a challenge just to figure out who they were.</p><p>At first neither the women nor their lawyers responded to her phone calls. She tried knocking on doors, but got nowhere. Finally, she sent out nearly 60 letters. A week later one recipient, Michelle Licata — who’s referred to as Jane Doe 2 in the case files — called her.</p><p>Brown’s book is richer for including lots of reportorial impasses and rabbit holes; it shows what a painstaking and often maddening process investigative journalism is. People should understand, she said, “that journalism isn’t always about success. To be honest a lot of it is about failure.”</p></div><div><p>To keep going in the face of inevitable frustration — fruitless reporting trips, false leads, fraudulent would-be sources and a barrage of legal threats — Brown needed not just personal fortitude but institutional support. Even in its attenuated state, The Herald provided that, she said.</p><p>“I’m fortunate that they let me do the project, really,” she said. “They weren’t excited 100 percent, but I think they trusted that it was worth letting me pick away at it and see what I would come up with.”</p><p>Yet she still had to juggle the Epstein investigation with other assignments. She would sometimes <a href="https://www.nytimes.com/2019/07/09/business/media/miami-herald-epstein.html" title="">pay her own expenses</a> rather than justify them to higher-ups, even as she was relying on payday loans to make ends meet.</p><p>Brown is finally in a better place financially. She’s working with Adam McKay, the director of “The Big Short,” to turn “Perversion of Justice” into an HBO mini-series. After years of renting, she was recently able to buy a condo. “I’ve been able to pay down some of my horrible debt that I have accumulated,” she said. But she’s 59 and still doesn’t have a retirement account.</p><p>I asked Brown whether she plans to stay on the Epstein beat, since there are still so many loose ends. She said she was torn. There are still a lot of mysteries about Epstein, but plenty of other reporters are digging into them.</p><p>“I felt like at one point almost every journalist in the world hopped on this story,” she said. “At some point you sort of feel like, ‘What is your purpose?’ I feel like maybe my purpose right now isn’t this story anymore. Maybe I need to move onto another story like this that nobody was paying attention to.”</p><p>The more newspapers collapse, the more such stories there are likely to be.</p></div></section></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private Israeli spyware used to hack cellphones of journalists, activists (160 pts)]]></title>
            <link>https://www.washingtonpost.com/investigations/interactive/2021/nso-spyware-pegasus-cellphones/</link>
            <guid>27874100</guid>
            <pubDate>Sun, 18 Jul 2021 16:14:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/investigations/interactive/2021/nso-spyware-pegasus-cellphones/">https://www.washingtonpost.com/investigations/interactive/2021/nso-spyware-pegasus-cellphones/</a>, See on <a href="https://news.ycombinator.com/item?id=27874100">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Please enable cookies on your web browser in order to continue.</span> </p><div> <p> The new European data protection law requires us to inform you of the following before you use our website: </p> <p> <span> </span> <span> We use cookies and other technologies to customize your experience, perform analytics and deliver personalized advertising on our sites, apps and newsletters and across the Internet based on your interests. By clicking “I agree” below, you consent to the use by us and our third-party partners of cookies and data gathered from your use of our platforms. See our <a href="https://www.washingtonpost.com/privacy-policy/2011/11/18/gIQASIiaiN_story.html">Privacy Policy</a> and <a href="https://www.washingtonpost.com/third-party-partners">Third Party Partners </a> to learn more about the use of data and your rights. You also agree to our <a href="http://www.washingtonpost.com/terms-of-service/2011/11/18/gIQAldiYiN_story.html">Terms of Service</a>. </span> </p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leak uncovers global abuse of cyber-surveillance weapon (218 pts)]]></title>
            <link>https://www.theguardian.com/world/2021/jul/18/revealed-leak-uncovers-global-abuse-of-cyber-surveillance-weapon-nso-group-pegasus</link>
            <guid>27874027</guid>
            <pubDate>Sun, 18 Jul 2021 16:05:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2021/jul/18/revealed-leak-uncovers-global-abuse-of-cyber-surveillance-weapon-nso-group-pegasus">https://www.theguardian.com/world/2021/jul/18/revealed-leak-uncovers-global-abuse-of-cyber-surveillance-weapon-nso-group-pegasus</a>, See on <a href="https://news.ycombinator.com/item?id=27874027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="0" id="maincontent"><p>Human rights activists, journalists and lawyers across the world have been targeted by authoritarian governments using hacking software sold by the Israeli surveillance company NSO Group, according to an investigation into a massive data leak.</p><p>The investigation by the Guardian and 16 other media organisations suggests widespread and continuing abuse of NSO’s hacking spyware, Pegasus, which the company insists is only intended for use against criminals and terrorists.</p><p>Pegasus is a malware that infects iPhones and Android devices to enable operators of the tool to extract messages, photos and emails, record calls and secretly activate microphones.</p><p>The leak contains a list of more than 50,000 phone numbers that, it is believed, have been identified as those of people of interest by clients of NSO since 2016.</p><p>Forbidden Stories, a Paris-based nonprofit media organisation, and Amnesty International initially had access to the leaked list and shared access with media partners as part of the Pegasus project, a reporting consortium.</p><p>The presence of a phone number in the data does not reveal whether a device was infected with Pegasus or subject to an attempted hack. However, the consortium believes the data is indicative of the potential targets NSO’s government clients identified in advance of possible surveillance attempts.</p><figure id="8cc6f331-cd08-4d95-ac40-6f8be167f7d4"><div data-atom-id="8a29b04b-fdcd-4315-96ee-95603ef0436d" data-atom-type="guide"><details data-atom-id="8a29b04b-fdcd-4315-96ee-95603ef0436d" data-snippet-type="guide"><summary><span>Quick Guide</span><h4>What is in the Pegasus project data? </h4><span><span><span><svg viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.8 16.2l.425 9.8h1.525l.45-9.8 9.8-.45v-1.525l-9.8-.425-.45-9.8h-1.525l-.425 9.8-9.8.425v1.525l9.8.45z"></path></svg></span>Show</span></span></summary><div><p><strong>What is in the data leak?</strong></p><p>The data leak is a list of more than 50,000 phone numbers that, since 2016, are believed to have been selected as those of people of interest by government clients of NSO Group, which sells surveillance software. The data also contains the time and date that numbers were selected, or entered on to a system. Forbidden Stories, a Paris-based nonprofit journalism organisation, and Amnesty International initially had access to the list and shared access with 16 media organisations including the Guardian. More than 80 journalists have worked together over several months as part of the Pegasus project. Amnesty’s Security Lab, a technical partner on the project, did the forensic analyses.</p><p><strong>What does the leak indicate?</strong></p><p>The consortium believes the data indicates the potential targets NSO’s government clients identified in advance of possible surveillance. While the data is an indication of intent, the presence of a number in the data does not reveal whether there was an attempt to infect the phone with spyware&nbsp;such as Pegasus, the company’s signature surveillance tool, or whether any attempt succeeded. The presence in the data of a very small number of landlines and US numbers, which NSO says are “technically impossible” to access with its tools, reveals some targets were selected by NSO clients even though they could not be infected with Pegasus. However, forensic examinations of a small sample of mobile phones with numbers on the list found tight correlations between the time and date of a number in the data and the start of Pegasus activity – in some cases as little as a few seconds.</p><p><strong> What did forensic analysis reveal?</strong></p><p>Amnesty examined 67 smartphones where attacks were suspected. Of those, 23 were successfully infected and 14 showed signs of attempted penetration. For the remaining 30, the tests were inconclusive, in several cases because the handsets had been replaced. Fifteen of the phones were Android devices, none of which showed evidence of successful infection. However, unlike iPhones, phones that use Android do not log the kinds of information required for Amnesty’s detective work. Three Android phones showed&nbsp;signs&nbsp;of targeting, such as Pegasus-linked SMS messages.</p><p>Amnesty shared “backup copies” of four iPhones with Citizen Lab, a research group at the University of Toronto that specialises in studying Pegasus, which confirmed that they showed signs of Pegasus infection. Citizen Lab also conducted a peer review of Amnesty’s forensic methods, and found them to be sound.</p><p><strong>Which NSO clients were selecting numbers?</strong></p><p>While the data is organised into clusters, indicative of individual NSO clients, it does not say which NSO client was responsible for selecting any given number. NSO claims to sell its tools to 60 clients in 40 countries, but refuses to identify them. By closely examining the pattern of targeting by individual clients in the leaked data, media partners were able to identify 10 governments believed to be responsible for selecting the targets: Azerbaijan, Bahrain, Kazakhstan, Mexico, Morocco, Rwanda, Saudi Arabia, Hungary, India, and the United Arab Emirates. Citizen Lab has also found evidence of all 10 being clients of NSO.</p><p><strong>What does NSO Group say?</strong></p><p>You can read NSO Group’s&nbsp;<a href="https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments">full statement here</a>. The company has always said it does not have access to the data of its customers’ targets. Through its lawyers, NSO said the consortium had made “incorrect assumptions” about which clients use the company’s technology. It said the 50,000 number was “exaggerated” and the list could not be a list of numbers “targeted by governments using Pegasus”. The lawyers said NSO had reason to believe the list accessed by the consortium “is not a list of numbers targeted by governments using Pegasus, but instead, may be part of a larger list of numbers that might have been used by NSO Group customers for other purposes”. After further questions, the lawyers said the consortium was basing its findings “on misleading interpretation of leaked data from accessible and overt basic information, such as HLR Lookup services, which have no bearing on the list of the customers' targets of Pegasus or any other NSO products ... we still do not see any correlation of these lists to anything related to use of NSO Group technologies”.</p><p><strong>What is HLR lookup data?</strong></p><p>The term HLR, or home location register, refers to a database that is essential to operating mobile phone networks. Such registers keep records on the networks of phone users and their general locations, along with other identifying information that is used routinely in routing calls and texts. Telecoms and surveillance experts say HLR data can sometimes be used in the early phase of a surveillance attempt, when identifying whether it is possible to connect to a phone. The consortium understands NSO clients have the capability through an interface on the Pegasus system to conduct HLR lookup inquiries.&nbsp;It is unclear whether Pegasus operators are required to conduct HRL lookup inquiries via its interface to use its&nbsp;software; an NSO source stressed its clients&nbsp;may have different reasons – unrelated to Pegasus – for conducting HLR lookups via an NSO system.</p></div></details></div></figure><p>Forensics analysis of a small number of phones whose numbers appeared on the leaked list also showed more than half had traces of the Pegasus spyware.</p><p>The Guardian and its media partners will be revealing the identities of people whose number appeared on the list in the coming days. They include hundreds of business executives, religious figures, academics, NGO employees, union officials and government officials, including cabinet ministers, presidents and prime ministers.</p><p>The list also contains the numbers of close family members of one country’s ruler, suggesting the ruler may have instructed their intelligence agencies to explore the possibility of monitoring their own relatives.</p><p>The disclosures begin on Sunday, with the revelation that the numbers of <a href="https://www.theguardian.com/world/2021/jul/18/ft-editor-roula-khalaf-among-180-journalists-targeted-nso-spyware" data-link-name="in body link">more than 180 journalists</a> are listed in the data, including reporters, editors and executives at the Financial Times, CNN, the New York Times, France 24, the Economist, Associated Press and Reuters.</p><p>The phone number of a <a href="https://www.theguardian.com/news/2021/jul/18/revealed-murdered-journalist-number-selected-mexico-nso-client-cecilio-pineda-birto" data-link-name="in body link">freelance Mexican reporter, Cecilio Pineda Birto</a>, was found in the list, apparently of interest to a Mexican client in the weeks leading up to his murder, when his killers were able to locate him at a carwash. His phone has never been found so no forensic analysis has been possible to establish whether it was infected.</p><p>NSO said that even if Pineda’s phone had been targeted, it did not mean data collected from his phone contributed in any way to his death, stressing governments could have discovered his location by other means. He was among at least 25 Mexican journalists apparently selected as candidates for surveillance over a two-year period.</p><figure id="5ae81aa7-9cb2-4611-a121-541bb5104bb6"></figure><p>Without forensic examination of mobile devices, it is impossible to say whether phones were subjected to an attempted or successful hack using Pegasus.</p><p>NSO has always maintained it “does not operate the systems that it sells to vetted government customers, and does not have access to the data of its customers’ targets”.</p><p>In <a href="https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments" data-link-name="in body link">statements issued through its lawyers</a>, NSO denied “false claims” made about the activities of its clients, but said it would “continue to investigate all credible claims of misuse and take appropriate action”. It said the list could not be a list of numbers “targeted by governments using Pegasus”, and described the 50,000 figure as “exaggerated”.</p><p>The company sells only to military, law enforcement and intelligence agencies in 40 unnamed countries, and says it rigorously vets its customers’ human rights records before allowing them to use its spy tools.</p><figure id="f754efa5-a317-45aa-8774-3ca703b694e0"></figure><p>The Israeli minister of defence closely regulates NSO, granting individual export licences before its surveillance technology can be sold to a new country.</p><p>Last month, NSO released a transparency report in which it claimed to have an industry-leading approach to human rights and published excerpts from contracts with customers stipulating they must only use its products for criminal and national security investigations.</p><p>There is nothing to suggest NSO’s customers did not also use Pegasus in terrorism and crime investigations, and the consortium also found numbers in the data belonging to suspected criminals.</p><p>However, the broad array of numbers in the list belonging to people who seemingly have no connection to criminality suggests some NSO clients are breaching their contracts with the company, spying on pro-democracy activists and journalists investigating corruption, as well as political opponents and government critics.</p><p>That thesis is supported by forensic analysis on the phones of a small sample of journalists, human rights activists and lawyers whose numbers appeared on the leaked list. The research, conducted by Amnesty’s Security Lab, a technical partner on the Pegasus project, found traces of Pegasus activity on 37 out of the 67 phones examined.</p><figure id="0eab287d-eeb3-4d10-bf5b-8c4287709796"><div data-atom-id="6842a659-2c34-40e4-b107-d7163eee4f8b" data-atom-type="qanda"><details data-atom-id="6842a659-2c34-40e4-b107-d7163eee4f8b" data-snippet-type="qanda"><summary><span>Q&amp;A</span><h4>What is the Pegasus project?</h4><span><span><span><svg viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.8 16.2l.425 9.8h1.525l.45-9.8 9.8-.45v-1.525l-9.8-.425-.45-9.8h-1.525l-.425 9.8-9.8.425v1.525l9.8.45z"></path></svg></span>Show</span></span></summary><div><p>The Pegasus project is a collaborative journalistic investigation into the NSO Group and its clients. The company sells surveillance technology to governments worldwide. Its flagship product is Pegasus, spying software – or spyware – that targets iPhones and Android devices. Once a phone is infected, a Pegasus operator can secretly extract chats, photos, emails and location data, or activate microphones and cameras without a user knowing.</p><p>Forbidden Stories, a Paris-based nonprofit journalism organisation, and Amnesty International had access to a leak of more than 50,000 phone numbers selected as targets by clients of NSO since 2016. Access to the data was then shared with the Guardian and 16 other news organisations, including the Washington Post, Le Monde, Die Zeit and Süddeutsche Zeitung. More than 80 journalists have worked collaboratively over several months on the investigation, which was coordinated by Forbidden Stories.</p></div></details></div></figure><p>The analysis also uncovered some sequential correlations between the time and date a number was entered into the list and the onset of Pegasus activity on the device, which in some cases occurred just a few seconds later.</p><p>Amnesty shared its forensic work on four iPhones with Citizen Lab, a research group at the University of Toronto that specialises in studying Pegasus, which confirmed they showed signs of Pegasus infection. Citizen Lab also conducted a peer-review of Amnesty’s forensic methods, and found them to be sound.</p><p>The consortium’s analysis of the leaked data identified at least 10 governments believed to be NSO customers who were entering numbers into a system: Azerbaijan, Bahrain, Kazakhstan, Mexico, Morocco, Rwanda, Saudi Arabia, Hungary, India and the United Arab Emirates (UAE).</p><p>Analysis of the data suggests the NSO client country that selected the most numbers – more than 15,000 – was Mexico, where multiple different government agencies are known to have bought Pegasus. Both Morocco and the UAE selected more than 10,000 numbers, the analysis suggested.</p><p>The phone numbers that were selected, possibly ahead of a surveillance attack, spanned more than 45 countries across four continents. There were more than 1,000 numbers in European countries that, the analysis indicated, were selected by NSO clients.</p><p>The presence of a number in the data does not mean there was an attempt to infect the phone. NSO says there were other possible purposes for numbers being recorded on the list.</p><p>Rwanda, Morocco, India and Hungary <a href="https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments" data-link-name="in body link">denied having used Pegasus</a> to hack the phones of the individuals named in the list. The governments of Azerbaijan, Bahrain, Kazakhstan, Saudi Arabia, Mexico, the UAE and Dubai did not respond to invitations to comment.</p><p>The Pegasus project is likely to spur debates over government surveillance in several countries suspected of using the technology. The investigation suggests the Hungarian government of Viktor Orbán appears to have deployed NSO’s technology as part of his so-called<strong> </strong>war on the media, targeting investigative journalists in the country as well as the close circle of one of Hungary’s few independent media executives.</p><p>The leaked data and forensic analyses also suggest NSO’s spy tool was used by Saudi Arabia and its close ally, the UAE, to target the phones of close associates of the murdered Washington Post journalist Jamal Khashoggi in the months after his death. The Turkish prosecutor investigating his death was also a candidate for targeting, the data leak suggests.</p><p>Claudio Guarnieri, who runs Amnesty International’s Security Lab, said once a phone was infected with Pegasus, a client of NSO could in effect take control of a phone, enabling them to extract a person’s messages, calls, photos and emails, secretly activate cameras or microphones, and read the contents of encrypted messaging apps such as WhatsApp, Telegram and Signal.</p><figure id="13b4d668-7df9-4a49-8900-7dad1347c123"></figure><p>By accessing GPS and hardware sensors in the phone, he added, NSO’s clients could also secure a log of a person’s past movements and track their location in real time with pinpoint accuracy, for example by establishing the direction and speed a car was travelling in.</p><figure id="12511940-f15f-4020-bcd5-f92d2e65f702"></figure><p>The latest advances in NSO’s technology enable it to penetrate phones with “zero-click” attacks, meaning a user does not even need to click on a malicious link for their phone to be infected.</p><p>Guarnieri has identified evidence NSO has been exploiting vulnerabilities associated with iMessage, which comes installed on all iPhones, and has been able to penetrate even the most up-to-date iPhone running the latest version of iOS. His team’s forensic analysis discovered successful and attempted Pegasus infections of phones as recently as this month.</p><p>Apple said: “Security researchers agree iPhone is the safest, most secure consumer mobile device on the market.”</p><p>NSO declined to give specific details about its customers and the people they target.</p><p>However, a source familiar with the matter said the average number of annual targets per customer was 112. The source said the company had 45 customers for its Pegasus spyware.</p><ul> 
 <li><p><em>Additional reporting: Michael Safi in Beirut, Dan Sabbagh in London, </em><em>Nina Lakhani</em><em> in Mexico, Shaun Walker in Budapest, Angelique Chris</em><em>afis in Paris and Martin Hodgson in New York.</em></p></li> 
 <li><p><strong><a href="https://support.theguardian.com/contribute?acquisitionData=%7B%22source%22%3A%22GUARDIAN_WEB%22%2C%22componentType%22%3A%22ACQUISITIONS_EDITORIAL_LINK%22%2C%22componentId%22%3A%22pegasus_project_footnote%22%2C%22campaignCode%22%3A%22pegasus_project%22%7D&amp;INTCMP=pegasus_project" data-link-name="in body link">Show your support</a> for the Guardian’s fearless investigative journalism today so we can keep chasing the truth</strong></p></li> 
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canonical turned a profit, back above 500 employees (101 pts)]]></title>
            <link>https://www.phoronix.com/scan.php?page=news_item&amp;px=Canonical-2020-Filing</link>
            <guid>27872949</guid>
            <pubDate>Sun, 18 Jul 2021 13:58:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/scan.php?page=news_item&#x26;px=Canonical-2020-Filing">https://www.phoronix.com/scan.php?page=news_item&#x26;px=Canonical-2020-Filing</a>, See on <a href="https://news.ycombinator.com/item?id=27872949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="UBUNTU -- " src="https://www.phoronix.com/assets/categories/ubuntu.jpg" width="100" height="100"></p><p>
Thanks to Canonical's distributed workforce with most of their employees working from home even pre-pandemic and the booming Linux ecosystem, the Ubuntu maker performed very well over 2020 and even grew its headcount back above 500 employees and managed to swing from a loss in 2019 to a profit in 2020.
</p><p>
Canonical Group Limited recently filed their financial report for their year-end 31 December 2020. While the directors acknowledge the COVID-19 pandemic remains a concern, they did perform well during 2020.
</p><p>
Canonical Holdings Limited saw revenue grow from $119M in 2019 to $138M in 2020. While Canonical Holdings was at an operating loss of $2M in 2019, during 2020 that turned around and they ended with an operating profit of $20M. The average employee headcount also rose from 473 in 2019 to 505 in 2020. Granted, that's still down from their 700+ employees years ago when pursuing Ubuntu Touch and their other ambitions before laying off staff and focusing more on the enterprise, IoT, and cloud commercial operations.
</p><p><a href="https://www.phoronix.com/image-viewer.php?id=2021&amp;image=canonical_2020_performs_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=2021&amp;image=canonical_2020_performs_med"></a></p>
<p>Amid the pandemic Canonical not only made a profit but also expanded operations. On the Canonical Group limited side their operating profit went from $0.4M to $5.3M USD.
</p><p>
Canonical does have going concern though over the pandemic disrupting some of their customers and in turn may lead to lower new sales. Among their forecasts though indicate they could see an approximate up to 50% reduction in sales can be "comfortably sustained" before they would need to enact new cost-cutting measures. But fortunately they don't believe they will face such conditions and specifically mention the public cloud operators as in helping to provide them economic stability during this challenging pandemic.
</p><p>
Those curious about Canonical's financial performance during the past year can be found via <a href="https://find-and-update.company-information.service.gov.uk/company/06870835/filing-history">UK Companies House</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zig cc: A drop-in replacement for GCC/Clang (2020) (205 pts)]]></title>
            <link>https://andrewkelley.me/post/zig-cc-powerful-drop-in-replacement-gcc-clang.html</link>
            <guid>27872596</guid>
            <pubDate>Sun, 18 Jul 2021 13:04:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewkelley.me/post/zig-cc-powerful-drop-in-replacement-gcc-clang.html">https://andrewkelley.me/post/zig-cc-powerful-drop-in-replacement-gcc-clang.html</a>, See on <a href="https://news.ycombinator.com/item?id=27872596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        



<p>
If you have heard of <a href="https://ziglang.org/">Zig</a> before, you may know it as
a promising new programming language which is ambitiously trying to overthrow C as the
de-facto systems language. But did you know that it also can straight up compile C code?
</p>
<p>
This has been possible for a while, and you can see some
<a href="https://ziglang.org/#Zig-is-also-a-C-compiler">examples of this on the home page</a>.
What's new is that the <code>zig cc</code> sub-command is available, and it supports
the same options as <a href="https://clang.llvm.org/">Clang</a>, which, in turn, supports
the same options as <a href="https://gcc.gnu.org/">GCC</a>.
</p>
<p>
Now, I'm sure you're feeling pretty skeptical right about now, so let me hook you real
quick before I get into the juicy details.
</p>
<h2>Clang and GCC cannot do this:</h2>
<pre><strong>andy@ark ~/tmp&gt; cat hello.c</strong>
#include &lt;stdio.h&gt;

int main(int argc, char **argv) {
    fprintf(stderr, "Hello, World!\n");
    return 0;
}
<strong>andy@ark ~/tmp&gt; clang -o hello.exe hello.c -target x86_64-windows-gnu</strong>
clang-7: warning: argument unused during compilation: '--gcc-toolchain=/nix/store/ificps9si1nvz85f9xa7gjd9h6r5lzg6-gcc-9.2.0' [-Wunused-command-line-argument]
/nix/store/7bhi29ainf5rjrk7k7wyhndyskzyhsxh-binutils-2.31.1/bin/ld: unrecognised emulation mode: i386pep
Supported emulations: elf_x86_64 elf32_x86_64 elf_i386 elf_iamcu elf_l1om elf_k1om
clang-7: <span>error</span>: linker command failed with exit code 1 (use -v to see invocation)
<strong>andy@ark ~/tmp&gt; clang -o hello hello.c -target mipsel-linux-musl</strong>
In file included from hello.c:1:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/stdio.h:27:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/bits/libc-header-start.h:33:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/features.h:452:
/nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/gnu/stubs.h:7:11: <span>fatal error</span>: 
      'gnu/stubs-32.h' file not found
# include &lt;gnu/stubs-32.h&gt;
          ^~~~~~~~~~~~~~~~
1 error generated.
<strong>andy@ark ~/tmp&gt; clang -o hello hello.c -target aarch64-linux-gnu</strong>
In file included from hello.c:1:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/stdio.h:27:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/bits/libc-header-start.h:33:
In file included from /nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/features.h:452:
/nix/store/8pp3i3hcp7bv0f8jllzqq7gcp9dbzvp9-glibc-2.27-dev/include/gnu/stubs.h:7:11: <span>fatal error</span>: 
      'gnu/stubs-32.h' file not found
# include &lt;gnu/stubs-32.h&gt;
          ^~~~~~~~~~~~~~~~
1 error generated.
</pre>

<h2>`zig cc` can:</h2>
<pre><strong>andy@ark ~/tmp&gt; zig cc -o hello.exe hello.c -target x86_64-windows-gnu</strong>
<strong>andy@ark ~/tmp&gt; wine64 hello.exe</strong>
Hello, World!
<strong>andy@ark ~/tmp&gt; zig cc -o hello hello.c -target mipsel-linux-musl</strong>
<strong>andy@ark ~/tmp&gt; qemu-mipsel ./hello</strong>
Hello, World!
<strong>andy@ark ~/tmp&gt; zig cc -o hello hello.c -target aarch64-linux-gnu</strong>
<strong>andy@ark ~/tmp&gt; qemu-aarch64 -L ~/Downloads/glibc/multi-2.31/install/glibcs/aarch64-linux-gnu ./hello</strong>
Hello, World!
</pre>
<h2>Features of `zig cc`</h2>
<p>
<code>zig cc</code> is <em>not the main purpose of the Zig project</em>. It merely
exposes the already-existing capabilities of the Zig compiler via a small frontend layer
that parses C compiler options.
</p>
<h3>Install simply by unzipping a tarball</h3>
<p>
Zig is an open source project, and of course can be
<a href="https://github.com/ziglang/zig/#building-from-source">built and installed from source the usual way</a>. However, the Zig project also has tarballs available on
<a href="https://ziglang.org/download/">the download page</a>.
You can download a 45 MiB tarball, unpack it, and you're done.
You can even have multiple versions at the same time, no problem.
</p>
<p>
Here, rather than downloading the x86_64-linux version, which matches the computer I am
currently using, I'll download the Windows version and run it in
<a href="https://www.winehq.org/">Wine</a> to show how simple installation is:
</p>
<pre><strong>andy@ark ~/tmp&gt; wget --quiet https://ziglang.org/builds/zig-windows-x86_64-0.5.0+13d04f996.zip</strong>
<strong>andy@ark ~/tmp&gt; unzip -q zig-windows-x86_64-0.5.0+13d04f996.zip </strong>
<strong>andy@ark ~/tmp&gt; wine64 ./zig-windows-x86_64-0.5.0+13d04f996/zig.exe cc -o hello hello.c -target x86_64-linux</strong>
<strong>andy@ark ~/tmp&gt; ./hello</strong>
Hello, World!
</pre>
<p>
Take a moment to appreciate what just happened here - I downloaded a Windows build of Zig,
ran it in Wine, using it to cross compile for Linux, and then ran the binary natively.
Computers are fun!
</p>
<p>
Compare this to
<a href="https://github.com/llvm/llvm-project/releases/tag/llvmorg-9.0.1">downloading Clang</a>,
which has 380 MiB Linux-distribution-specific tarballs. Zig's Linux tarballs are fully statically
linked, and therefore work correctly on all Linux distributions. The size difference here
comes because the Clang tarball ships with more utilities than a C compiler, as well as
pre-compiled static libraries for both LLVM and Clang. Zig does not ship with any pre-compiled
libraries; instead it ships with source code, and builds what it needs on-the-fly.
</p>
<h3 id="caching-system">Caching System</h3>
<p>
The Zig compiler uses a sophisticated caching system to avoid needlessly rebuilding
artifacts. I carefully designed this caching system to
make optimal use of the file system while maintaining correct semantics - which is
<a href="https://apenwarr.ca/log/20181113">trickier than you might think</a>!
</p>
<p>
The caching system uses a combination of hashing inputs and checking the fstat values
of file paths, while being mindful of mtime granularity. This makes it avoid
needlessly hashing files, while at the same time detecting when a modified file has
the same contents. It always has correct behavior, whether the file system has nanosecond
mtime granularity, second granularity, always sets mtime to zero, or anything in between.
</p>
<p>
You can find a
<a href="https://ziglang.org/download/0.4.0/release-notes.html#Build-Artifact-Caching">detailed description of the caching system in the 0.4.0 release notes</a>.
</p>
<p>
<code>zig cc</code> makes this caching system available when compiling C code. For simple
enough projects, this obviates the need for a Makefile or other build system.
</p>
<pre><strong>andy@ark ~/tmp&gt; cat foo.c</strong>
#include &lt;stdio.h&gt;

#include "another_file.c"

int main(int argc, char **argv) {
#include "printf_many_times.c"
}
<strong>andy@ark ~/tmp&gt; cat another_file.c </strong>
void another(void) {}
<strong>andy@ark ~/tmp&gt; time zig cc -c foo.c</strong>
0.12
<strong>andy@ark ~/tmp&gt; time zig cc -c foo.c</strong>
0.01
<strong>andy@ark ~/tmp&gt; touch another_file.c </strong>
<strong>andy@ark ~/tmp&gt; time zig cc -c foo.c</strong>
0.01
<strong>andy@ark ~/tmp&gt; echo "/* add a comment */" &gt;&gt;another_file.c</strong>
<strong>andy@ark ~/tmp&gt; time zig cc -c foo.c</strong>
0.12
<strong>andy@ark ~/tmp&gt; time zig cc -c foo.c</strong>
0.01
</pre>
<p>
Here you can see the caching system is smart enough to find dependencies that are
included with the preprocessor, and smart enough to avoid a full rebuild when the
mtime of another_file.c was updated.
</p>
<p>
One last thing before I move on. I want to point out that this caching system is not
some fluffy bloated feature - rather it is an absolutely critical component to making
cross-compiling work in a usable manner. As we'll see below, other compilers ship with 
pre-compiled, target-specific binaries, while Zig ships with <em>source code only</em>
and cross-compiles on-the-fly, caching the result.
</p>

<h3>Cross Compiling</h3>
<p>I have carefully designed Zig since the very beginning to treat cross compilation
as a first class use case. Now that the <code>zig cc</code> frontend is available,
it brings these capabilities to C code.
</p>
<p>
I showed you above cross-compiling some simple "Hello, World!" programs. But now let's
try a real-world C project.
</p>
<p>
Let's try <a href="https://luajit.org/">LuaJIT</a>!
</p>
<pre>[~/Downloads]$ <strong>git clone https://github.com/LuaJIT/LuaJIT</strong>
[~/Downloads]$ <strong>cd LuaJIT</strong>
[~/Downloads/LuaJIT]$ <strong>ls</strong>
COPYRIGHT  doc  dynasm  etc  Makefile  README  src
</pre>
<p>
OK so it uses standard Makefiles. Here we go, first let's make sure it works natively
with <code>zig cc</code>.
</p>
<pre>[~/Downloads/LuaJIT]$ <strong>export CC="zig cc"</strong>
[~/Downloads/LuaJIT]$ <strong>make CC="$CC"</strong>
==== Building LuaJIT 2.1.0-beta3 ====
make -C src
make[1]: Entering directory '/home/andy/Downloads/LuaJIT/src'
HOSTCC    host/minilua.o
HOSTLINK  host/minilua
DYNASM    host/buildvm_arch.h
HOSTCC    host/buildvm.o
HOSTCC    host/buildvm_asm.o
HOSTCC    host/buildvm_peobj.o
HOSTCC    host/buildvm_lib.o
HOSTCC    host/buildvm_fold.o
HOSTLINK  host/buildvm
BUILDVM   lj_vm.S
ASM       lj_vm.o
CC        lj_gc.o
BUILDVM   lj_ffdef.h
CC        lj_err.o
CC        lj_char.o
BUILDVM   lj_bcdef.h
CC        lj_bc.o
CC        lj_obj.o
CC        lj_buf.o
CC        lj_str.o
CC        lj_tab.o
CC        lj_func.o
CC        lj_udata.o
CC        lj_meta.o
CC        lj_debug.o
CC        lj_state.o
CC        lj_dispatch.o
CC        lj_vmevent.o
CC        lj_vmmath.o
CC        lj_strscan.o
CC        lj_strfmt.o
CC        lj_strfmt_num.o
CC        lj_api.o
CC        lj_profile.o
CC        lj_lex.o
CC        lj_parse.o
CC        lj_bcread.o
CC        lj_bcwrite.o
CC        lj_load.o
CC        lj_ir.o
CC        lj_opt_mem.o
BUILDVM   lj_folddef.h
CC        lj_opt_fold.o
CC        lj_opt_narrow.o
CC        lj_opt_dce.o
CC        lj_opt_loop.o
CC        lj_opt_split.o
CC        lj_opt_sink.o
CC        lj_mcode.o
CC        lj_snap.o
CC        lj_record.o
CC        lj_crecord.o
BUILDVM   lj_recdef.h
CC        lj_ffrecord.o
CC        lj_asm.o
CC        lj_trace.o
CC        lj_gdbjit.o
CC        lj_ctype.o
CC        lj_cdata.o
CC        lj_cconv.o
CC        lj_ccall.o
CC        lj_ccallback.o
CC        lj_carith.o
CC        lj_clib.o
CC        lj_cparse.o
CC        lj_lib.o
CC        lj_alloc.o
CC        lib_aux.o
BUILDVM   lj_libdef.h
CC        lib_base.o
CC        lib_math.o
CC        lib_bit.o
CC        lib_string.o
CC        lib_table.o
CC        lib_io.o
CC        lib_os.o
CC        lib_package.o
CC        lib_debug.o
CC        lib_jit.o
CC        lib_ffi.o
CC        lib_init.o
AR        libluajit.a
CC        luajit.o
BUILDVM   jit/vmdef.lua
DYNLINK   libluajit.so
LINK      luajit
warning: unsupported linker arg: -E
OK        Successfully built LuaJIT
make[1]: Leaving directory '/home/andy/Downloads/LuaJIT/src'
==== Successfully built LuaJIT 2.1.0-beta3 ====

[~/Downloads/LuaJIT]$ <strong>ls</strong>
COPYRIGHT  doc  dynasm  etc  Makefile  README  src

[~/Downloads/LuaJIT]$ <strong>./src/</strong>
host/         jit/          libluajit.so  luajit        zig-cache/    

[~/Downloads/LuaJIT]$ <strong>./src/luajit </strong>
LuaJIT 2.1.0-beta3 -- Copyright (C) 2005-2020 Mike Pall. http://luajit.org/
JIT: ON SSE2 SSE3 SSE4.1 BMI2 fold cse dce fwd dse narrow loop abc sink fuse
&gt; <strong>print(3 + 4)</strong>
7
&gt; 
</pre>
<p>
OK so that worked. Now for the real test - can we make it cross compile?
</p>
<pre>[~/Downloads/LuaJIT]$ <strong>git clean -xfdq</strong>
[~/Downloads/LuaJIT]$ <strong>export CC="zig cc -target aarch64-linux-gnu"</strong>
[~/Downloads/LuaJIT]$ <strong>export HOST_CC="zig cc"</strong>
[~/Downloads/LuaJIT]$ <strong>make CC="$CC" HOST_CC="$HOST_CC" TARGET_STRIP="echo"</strong>
==== Building LuaJIT 2.1.0-beta3 ====
make -C src
make[1]: Entering directory '/home/andy/Downloads/LuaJIT/src'
HOSTCC    host/minilua.o
HOSTLINK  host/minilua
DYNASM    host/buildvm_arch.h
HOSTCC    host/buildvm.o
HOSTCC    host/buildvm_asm.o
HOSTCC    host/buildvm_peobj.o
HOSTCC    host/buildvm_lib.o
HOSTCC    host/buildvm_fold.o
HOSTLINK  host/buildvm
BUILDVM   lj_vm.S
ASM       lj_vm.o
CC        lj_gc.o
BUILDVM   lj_ffdef.h
CC        lj_err.o
CC        lj_char.o
BUILDVM   lj_bcdef.h
CC        lj_bc.o
CC        lj_obj.o
CC        lj_buf.o
CC        lj_str.o
CC        lj_tab.o
CC        lj_func.o
CC        lj_udata.o
CC        lj_meta.o
CC        lj_debug.o
CC        lj_state.o
CC        lj_dispatch.o
CC        lj_vmevent.o
CC        lj_vmmath.o
CC        lj_strscan.o
CC        lj_strfmt.o
CC        lj_strfmt_num.o
CC        lj_api.o
CC        lj_profile.o
CC        lj_lex.o
CC        lj_parse.o
CC        lj_bcread.o
CC        lj_bcwrite.o
CC        lj_load.o
CC        lj_ir.o
CC        lj_opt_mem.o
BUILDVM   lj_folddef.h
CC        lj_opt_fold.o
CC        lj_opt_narrow.o
CC        lj_opt_dce.o
CC        lj_opt_loop.o
CC        lj_opt_split.o
CC        lj_opt_sink.o
CC        lj_mcode.o
CC        lj_snap.o
CC        lj_record.o
CC        lj_crecord.o
BUILDVM   lj_recdef.h
CC        lj_ffrecord.o
CC        lj_asm.o
CC        lj_trace.o
CC        lj_gdbjit.o
CC        lj_ctype.o
CC        lj_cdata.o
CC        lj_cconv.o
CC        lj_ccall.o
CC        lj_ccallback.o
CC        lj_carith.o
CC        lj_clib.o
CC        lj_cparse.o
CC        lj_lib.o
CC        lj_alloc.o
CC        lib_aux.o
BUILDVM   lj_libdef.h
CC        lib_base.o
CC        lib_math.o
CC        lib_bit.o
CC        lib_string.o
CC        lib_table.o
CC        lib_io.o
CC        lib_os.o
CC        lib_package.o
CC        lib_debug.o
CC        lib_jit.o
CC        lib_ffi.o
CC        lib_init.o
AR        libluajit.a
CC        luajit.o
BUILDVM   jit/vmdef.lua
DYNLINK   libluajit.so
libluajit.so
LINK      luajit
warning: unsupported linker arg: -E
luajit
OK        Successfully built LuaJIT
make[1]: Leaving directory '/home/andy/Downloads/LuaJIT/src'
==== Successfully built LuaJIT 2.1.0-beta3 ====

[~/Downloads/LuaJIT]$ <strong>file ./src/luajit </strong>
./src/luajit: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 2.0.0, with debug_info, not stripped
</pre>
<p>
It worked! Will it run in <a href="https://www.qemu.org/">QEMU</a> though?
</p>
<pre>[~/Downloads/LuaJIT]$ <strong>qemu-aarch64 -L ~/Downloads/glibc/multi-2.31/install/glibcs/aarch64-linux-gnu ./src/luajit</strong>
LuaJIT 2.1.0-beta3 -- Copyright (C) 2005-2020 Mike Pall. http://luajit.org/
JIT: ON fold cse dce fwd dse narrow loop abc sink fuse
&gt; <strong>print(4 + 3)</strong>
7
&gt; 
</pre>
<p>
Amazing. QEMU never fails to impress me.
</p>
<p>
Before we move on, I want to show one more thing. You can see above, in order to run the
foreign-architecture binary, I had to pass
<code>-L ~/Downloads/glibc/multi-2.31/install/glibcs/aarch64-linux-gnu</code>. This is
due to the binary being dynamically linked. You can confirm this with the output from
<code>file</code> above where it says: <code>dynamically linked, interpreter /lib/ld-linux-aarch64.so.1</code>
</p>
<p>
Often, when cross-compiling, it is useful to make a <em>static</em> binary.
In the case of Linux, for example, this will make the resulting binary able to run on
any Linux distribution, rather than only ones with a hard-coded glibc dynamic linker path
of <code>/lib/ld-linux-aarch64.so.1</code>.
</p>
<p>
We can accomplish this by targeting musl rather than glibc:
</p>
<pre>[~/Downloads/LuaJIT]$ git clean -qxfd
[~/Downloads/LuaJIT]$ export CC="zig cc -target aarch64-linux-musl"
[~/Downloads/LuaJIT]$ make CC="$CC" CXX="$CXX" HOST_CC="$HOST_CC" TARGET_STRIP="echo"
==== Building LuaJIT 2.1.0-beta3 ====
(same output)
==== Successfully built LuaJIT 2.1.0-beta3 ====
[~/Downloads/LuaJIT]$ file src/luajit
src/luajit: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, not stripped
[~/Downloads/LuaJIT]$ qemu-aarch64 ./src/luajit
LuaJIT 2.1.0-beta3 -- Copyright (C) 2005-2020 Mike Pall. http://luajit.org/
JIT: ON fold cse dce fwd dse narrow loop abc sink fuse
&gt; print(11 + 22)
33
</pre>
<p>
Here you can see the <code>file</code> command reported <em>statically linked</em>,
and in the qemu command, the <code>-L</code> parameter was not needed.
</p>

<h2>Use Cases of `zig cc`</h2>
<p>
Alright, so I've given you a taste of what <code>zig cc</code> can do, but now I will
list explicitly what I consider to be the use cases:
</p>
<h3>Experimentation</h3>
<p>
Sometimes you just want a tool that you can use to try out different things. It can quickly
answer questions such as "What assembly does this code generate on MIPS vs ARM?". The widely
popular <a href="https://godbolt.org/">Compiler Explorer</a> serves this purpose.
</p>
<p>
<code>zig cc</code> provides a lightweight tool which can also answer questions such as,
"What happens if I swap out glibc for <a href="https://musl.libc.org/">musl</a>?" and
"How big is this executable when cross-compiled for Windows?".
<a href="https://twitter.com/andy_kelley/status/1242183564512366595">Here's me using Zig to
quickly find out what the maximum UDP packet size is on Linux</a>.
</p>
<p>
Since Zig is so easy to install - and it actually works everywhere without patches,
even Linux distributions such as <a href="https://nixos.org/">NixOS</a> -
it can often be a more convenient tool for running quick C test programs on your computer.
</p>
<p>
At the time of this writing, LLVM 10 was just released two hours ago.
It will take days or weeks for it to become available in various system package managers.
But you can already
<a href="https://ziglang.org/download/">download a master branch build of Zig</a>
and play with the new features of Clang/LLVM 10. For example, improved RISC-V support!
</p>
<pre>andy@ark ~/tmp&gt; <strong>zig cc -o hello hello.c -target riscv64-linux-musl</strong>
andy@ark ~/tmp&gt; <strong>qemu-riscv64 ./hello</strong>
Hello, World!
</pre>

<h3>Bundling a C compiler as part of a larger project</h3>
<p>
With Zig tarballs weighing in at under 45 MiB, zero system dependencies, no configuration,
and MIT license, it makes for an ideal candidate when you need to bundle a C compiler along
with another project.
</p>
<p>
For example, maybe you have
<a href="https://nim-lang.org/">a programming language that compiles to C</a>.
Zig is an obvious choice for what C compiler to ship with your language.
</p>
<p>
Or maybe you want to make a batteries-included
<a href="https://en.wikipedia.org/wiki/Integrated_development_environment">IDE</a>
that ships with a compiler.
</p>

<h3>Lightweight alternative to a cross compilation environment</h3>
<p>
If you're trying to build something with a large dependency tree, you'll probably want to
use a full cross compilation environment, such as <a href="https://mxe.cc/">mxe.cc</a>
or <a href="http://musl.cc/">musl.cc</a>.
</p>
<p>
But if you don't need such a sledgehammer, <code>zig cc</code> could be a useful alternative,
especially if your goal is to compile for N different targets. Consider that musl.cc lists different
tarballs for each architecture, each weighing in at roughly 85 MiB. Meanwhile Zig weighs in at 45 MiB
and it supports all those architectures, plus glibc and Windows.
</p>

<h3>An alternative to installing MSVC on Windows</h3>
<p>
You could spend days - literally! - waiting for Microsoft Visual Studio to install,
or you could install Zig and
<a href="https://code.visualstudio.com/">VS Code</a> in a matter of minutes.
</p>

<h2>Under the Hood</h2>
<p>If <code>zig cc</code> is built on top of Clang, why doesn't Clang just do this?
What exactly is Zig doing on top of Clang to make this work?</p>
<p>
The answer is, <em>a lot</em>, actually. I'll go over how it works here.
</p>
<h3>compiler-rt</h3>
<p>
compiler-rt is a library that provides "polyfill" implementations of language-supported features
when the target does not have machine code instructions for it. For example, compiler-rt has
the function <code>__muldi3</code> to perform signed 64-bit integer multiplication on architectures
that do not have a 64-bit wide integer multiplication instruction.
</p>
<p>
In the GNU world, compiler-rt is named <strong>libgcc</strong>.
</p>
<p>
Most C compilers ship with this library pre-built for the target.
For example, on an Ubuntu (Bionic) system, with the <code>build-essential</code> package installed,
you can find this at <code>/lib/x86_64-linux-gnu/libgcc_s.so.1</code>.
</p>
<p>
If you download <a href="https://github.com/llvm/llvm-project/releases/download/llvmorg-9.0.1/clang+llvm-9.0.1-x86_64-linux-gnu-ubuntu-16.04.tar.xz">clang+llvm-9.0.1-x86_64-linux-gnu-ubuntu-16.04.tar.xz</a> and take a look
around, clang actually does not even ship with compiler-rt. Instead, it relies on the system libgcc
noted above. This is one reason that this tarball is Ubuntu-specific and does not work on other
Linux distributions, 
<a href="https://www.leidinger.net/blog/2010/09/28/the-freebsd-linuxulator-explained-for-users/">FreeBSD's Linuxulator</a>,
or <a href="https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux">WSL</a>,
which have system files in different locations.
</p>
<p>
Zig's strategy with compiler-rt is that we have
<a href="https://github.com/ziglang/zig/blob/0.5.0/lib/std/special/compiler_rt.zig">our own implementation of this library</a>,
written in Zig. Most of it is ported from
<a href="https://github.com/llvm/llvm-project/tree/llvmorg-10.0.0-rc6/compiler-rt">LLVM's compiler-rt project</a>,
but we also have some of our own improvements on top of this.
</p>
<p>
Anyway, rather than depending on system compiler-rt being installed, or shipping a pre-compiled
library, Zig ships its compiler-rt <em>in source form</em>, and lazily builds compiler-rt 
for the compilation target, and then caches the result using
<a href="#caching-system">the caching system discussed above</a>.
</p>
<p>
Zig's compiler-rt is <a href="https://github.com/ziglang/zig/issues/1290">not yet complete</a>.
However, completing it is a prerequisite for releasing Zig version 1.0.0.
</p>

<h3>libc</h3>
<p>
When C code calls <code>printf</code>, <code>printf</code> has to be implemented <em>somewhere</em>,
and that somewhere is libc.
</p>
<p>
Some operating systems, such as <a href="https://www.freebsd.org/">FreeBSD</a> and macOS, have a
designated system libc, and it is the kernel syscall interface. On others, such as
Windows and Linux, libc is optional, and therefore there are multiple options of which
libc to use, if any.
</p>
<p>
As of the time of this writing, Zig can provide libcs for the following targets:
</p>
<pre>andy@ark ~&gt; zig targets | jq .libc
[
  "aarch64_be-linux-gnu",
  "aarch64_be-linux-musl",
  "aarch64_be-windows-gnu",
  "aarch64-linux-gnu",
  "aarch64-linux-musl",
  "aarch64-windows-gnu",
  "armeb-linux-gnueabi",
  "armeb-linux-gnueabihf",
  "armeb-linux-musleabi",
  "armeb-linux-musleabihf",
  "armeb-windows-gnu",
  "arm-linux-gnueabi",
  "arm-linux-gnueabihf",
  "arm-linux-musleabi",
  "arm-linux-musleabihf",
  "arm-windows-gnu",
  "i386-linux-gnu",
  "i386-linux-musl",
  "i386-windows-gnu",
  "mips64el-linux-gnuabi64",
  "mips64el-linux-gnuabin32",
  "mips64el-linux-musl",
  "mips64-linux-gnuabi64",
  "mips64-linux-gnuabin32",
  "mips64-linux-musl",
  "mipsel-linux-gnu",
  "mipsel-linux-musl",
  "mips-linux-gnu",
  "mips-linux-musl",
  "powerpc64le-linux-gnu",
  "powerpc64le-linux-musl",
  "powerpc64-linux-gnu",
  "powerpc64-linux-musl",
  "powerpc-linux-gnu",
  "powerpc-linux-musl",
  "riscv64-linux-gnu",
  "riscv64-linux-musl",
  "s390x-linux-gnu",
  "s390x-linux-musl",
  "sparc-linux-gnu",
  "sparcv9-linux-gnu",
  "wasm32-freestanding-musl",
  "x86_64-linux-gnu",
  "x86_64-linux-gnux32",
  "x86_64-linux-musl",
  "x86_64-windows-gnu"
]
</pre>
<p>
In order to provide libc on these targets, Zig ships with a subset of the source files
for these projects:
</p>
<ul>
  <li>musl v1.2.0</li>
  <li><a href="https://mingw-w64.org/">mingw-w64</a> v7.0.0</li>
  <li>glibc 2.31</li>
</ul>
<p>
For each libc, there is a
<a href="https://github.com/ziglang/zig/wiki/Updating-libc">process for upgrading to a new release</a>.
This process is a sort of pre-processing step. We still end up with source files, but we
de-duplicate non-multi-arch source files into multi-arch source files.
</p>

<h4>glibc</h4>
<p>
glibc is the most involved. The first step is building glibc for every target that it supports,
which takes upwards of 24 hours and 74 GiB of disk space.
</p>
<p>
From here, the
<a href="https://github.com/ziglang/zig/blob/dc44fe053c609f389e375f6857f96b6bb3794897/tools/process_headers.zig">process_headers tool</a>
inspects all the header files from all the targets, and identifies which files are the same across
all targets, and which header files are target-specific. They are then sorted into the
corresponding directories in Zig's source tree, in:
</p>
<ul>
  <li>lib/libc/include/generic-glibc/</li>
  <li>lib/libc/include/$ARCH-linux-$ABI/ (there are multiple of these directories)</li>
</ul>
<p>
Additionally, Linux header files are not included in glibc, and so the same process is applied to
Linux header files, with the directories:
</p>
<ul>
  <li>lib/libc/include/any-linux-any/</li>
  <li>lib/libc/include/$ARCH-linux-any/</li>
</ul>
<p>
That takes care of the header files, but now we have the problem of dynamic linking against
glibc, without touching any system files.
</p>
<p>
For this, we have the
<a href="https://github.com/ziglang/zig/blob/dc44fe053c609f389e375f6857f96b6bb3794897/tools/update_glibc.zig">update_glibc tool</a>.
Given the path to the glibc source directory, it finds all the <code>.abilist</code> text files
and uses them to produce 3 simple but crucial files:
</p>
<ul>
  <li><a href="https://github.com/ziglang/zig/blob/master/lib/libc/glibc/vers.txt">vers.txt</a>
    - the list of all glibc versions.
  </li>
  <li><a href="https://github.com/ziglang/zig/blob/master/lib/libc/glibc/fns.txt">fns.txt</a>
    - the list of all symbols that glibc provides, followed by the library it appears in
    (for example libm, libpthread, libc, librt).
  </li>
  <li><a href="https://github.com/ziglang/zig/blob/master/lib/libc/glibc/abi.txt">abi.txt</a>
    - for each target, for each function, tells which versions of glibc, if any, it appears in.
  </li>
</ul>
<p>
Together, these files amount to only 192 KB (27 KB gzipped), and they allow Zig to target any
version of glibc.
</p>
<p>
Yes, I did not make a typo there. Zig can target any of the 42 versions of glibc for any of the
architectures listed above. I'll show you:
</p>
<pre>andy@ark ~/tmp&gt; <strong>cat rand.zig </strong>
const std = @import("std");

pub fn main() anyerror!void {
    var buf: [10]u8 = undefined;
    _ = std.c.getrandom(&amp;buf, buf.len, 0);
    std.debug.warn("random bytes: {x}\n", .{buf});
}
andy@ark ~/tmp&gt; <strong>zig build-exe rand.zig -lc -target native-native-gnu.2.25</strong>
andy@ark ~/tmp&gt; <strong>./rand</strong>
random bytes: e2059382afb599ea6d29
andy@ark ~/tmp&gt; <strong>zig build-exe rand.zig -lc -target native-native-gnu.2.24</strong>
lld: error: undefined symbol: getrandom
&gt;&gt;&gt; referenced by rand.zig:5 (/home/andy/tmp/rand.zig:5)
&gt;&gt;&gt;               ./rand.o:(main.0)
</pre>
<p>
Sure enough, if you look at the
<a href="http://man7.org/linux/man-pages/man2/getrandom.2.html">man page for getrandom</a>,
it says:
</p>
<blockquote>
Support was added to glibc in version 2.25.
</blockquote>
<p>
When no explicit glibc version is requested, and the target OS is the native (host) OS,
Zig detects the native glibc version by inspecting the Zig executable's own dynamically
linked libraries, looking for glibc, and checking the version. It turns out you can look for
<code>libc.so.6</code> and then <code>readlink</code> on that, and it will look something
like <code>libc-2.27.so</code>. When this strategy does not work, Zig looks at
<code>/usr/bin/env</code>, looking for the same thing. Since this file path is hard-coded
into countless shebang lines, it's a pretty safe bet to find out the dynamic linker path and
glibc version (if any) of the native system!
</p>
<p>
<code>zig cc</code> currently does not provide a way to choose a specific glibc version
(because C compilers do not provide a way), and so Zig chooses the native version for
compiling natively, and the default (2.17) for cross-compiling.
However, I'm sure this problem can be solved, even when using <code>zig cc</code>. For example,
maybe it could support an environment variable, or simply introduce an extra command line
option that does not conflict with any Clang options.
</p>
<p>
When you request a certain version of glibc, Zig uses those text files noted above to
create dummy <code>.so</code> files to link against, which contain exactly the correct
set of symbols (with appropriate name mangling) based on the requested version.
The symbols will be resolved at runtime, by the dynamic linker on the target platform.
</p>
<p>
In this way, most of libc in the glibc case resides on the target file system. But not all of it!
There are still the "C runtime start files":
</p>
<ul>
  <li>Scrt1.o</li>
  <li>crti.o</li>
  <li>crtn.o</li>
</ul>
<p>
These are statically compiled into every binary that dynamically links glibc, and their
<a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a> is therefore
Very Very Stable.
</p>
<p>
And so, Zig bundles a small subset of glibc's source files needed to build these object
files from source for every target. The total size of this comes out to 1.4 MiB (252 KB gzipped).
I do think there is some room for improvement here, but I digress.
</p>
<p>
There are a couple of patches to this small subset of glibc source files, which simplify them
to avoid including too many .h files, since the end result that we need is some bare bones object
files, and not all of glibc.
</p>
<p>
And finally, we certainly do not ship the build system of glibc with Zig! I manually inspected,
audited, and analyzed glibc's build system, and then by hand wrote code in the Zig
compiler which hooks into Zig's <a href="#caching-system">caching system</a> and performs a minimal
build of only these start files, as needed.
</p>

<h4>musl</h4>
<p>
The process for preparing musl to ship with Zig is much simpler by comparison.
</p>
<p>
It still involves building musl for every target architecture that it supports,
but in this case only the <code>install-headers</code> target has to be run,
and it takes less than a minute, even to do it for all targets.
</p>
<p>
The same
<a href="https://github.com/ziglang/zig/blob/dc44fe053c609f389e375f6857f96b6bb3794897/tools/process_headers.zig">process_headers tool</a>
tool used for glibc headers is used on the musl headers:
</p>
<ul>
  <li>lib/libc/include/generic-musl/</li>
  <li>lib/libc/include/$ARCH-linux-$ABI/ (there are multiple of these directories)</li>
</ul>
<p>
Unlike glibc, musl supports building statically. Zig currently assumes a static libc
when musl is chosen, and does not support dynamically linking against musl, although
that could potentially be added in the future.
</p>
<p>
And so for musl, zig actually bundles most - but still not all - of musl's source files.
Everything in <code>arch</code>, <code>crt</code>, <code>compat</code>, <code>src</code>, and <code>include</code> gets copied in.
</p>
<p>
Again much like glibc, I carefully studied musl's build system, and then hand-coded logic
in the Zig compiler to build these source files. In musl's case it is simpler - just a bit
of logic having to do with the file extension, and whether to override files with an
architecture-specific file. The only file that needs to be patched (by hand) is
<code>version.h</code>, which is normally generated during the configure phase in musl's build
system.
</p>
<p>
I really appreciate Rich Felker's efforts to make musl simple to utilize in this way,
and he has been incredibly helpful in the <code>#musl</code> IRC channel when I ask
questions.
<a href="https://andrewkelley.me/post/why-donating-to-musl-libc-project.html">I proudly sponsor Rich Felker for $150/month</a>.
</p>

<h4>mingw-w64</h4>
<p>
mingw-w64 was an absolute joy to support in Zig. The beautiful thing about this project is that
they have already been transitioning into having one set of header files that applies to all
architectures (using <code>#ifdefs</code> only where needed). One set of header files
is sufficient to support all four architectures: arm, aarch64, x86, and x86_64. 
</p>
<p>
So for updating headers, all we have to do is build mingw-w64, then:
</p>
<pre>mv $INSTALLPREFIX/include $ZIGSRC/lib/libc/include/any-windows-any
</pre>
<p>
After doing this for all 3 libcs, the libc/include directory looks like this:
</p>
<pre>aarch64_be-linux-any   i386-linux-musl           powerpc-linux-any
aarch64_be-linux-gnu   mips64el-linux-any        powerpc-linux-gnu
aarch64-linux-any      mips64el-linux-gnuabi64   powerpc-linux-musl
aarch64-linux-gnu      mips64el-linux-gnuabin32  riscv32-linux-any
aarch64-linux-musl     mips64-linux-any          riscv64-linux-any
any-linux-any          mips64-linux-gnuabi64     riscv64-linux-gnu
any-windows-any        mips64-linux-gnuabin32    riscv64-linux-musl
armeb-linux-any        mips64-linux-musl         s390x-linux-any
armeb-linux-gnueabi    mipsel-linux-any          s390x-linux-gnu
armeb-linux-gnueabihf  mipsel-linux-gnu          s390x-linux-musl
arm-linux-any          mips-linux-any            sparc-linux-gnu
arm-linux-gnueabi      mips-linux-gnu            sparcv9-linux-gnu
arm-linux-gnueabihf    mips-linux-musl           x86_64-linux-any
arm-linux-musl         powerpc64le-linux-any     x86_64-linux-gnu
generic-glibc          powerpc64le-linux-gnu     x86_64-linux-gnux32
generic-musl           powerpc64-linux-any       x86_64-linux-musl
i386-linux-any         powerpc64-linux-gnu
i386-linux-gnu         powerpc64-linux-musl
</pre>
<p>
When Zig generates a C command line to send to clang, it puts the appropriate
include paths using <code>-I</code> depending on the target. For example, if the
target is <code>aarch64-linux-musl</code>, then the following command line parameters
are appended:
</p>
<ul>
  <li><code>-I$LIB/libc/include/aarch64-linux-musl</code></li>
  <li><code>-I$LIB/libc/include/aarch64-linux-any</code></li>
  <li><code>-I$LIB/libc/include/generic-musl</code></li>
</ul>
<p>
Anyway back to mingw-w64.
</p>
<p>
Again, Zig includes a subset of source files from mingw-w64 with a few patches applied
to make things compile successfully.
</p>
<p>
The Zig compiler code that builds mingw-w64 from source files emulates only the parts of
the build system that are needed for this subset. This includes preprocessing <code>.def.in</code>
files to get <code>.def</code> files, and then in-turn using LLD to generate <code>.lib</code> files
from the <code>.def</code> files, which allows Zig to provide <code>.lib</code> files for
any Windows DLL, such as kernel32.dll or even opengl32.dll.
</p>

<h3>Invoking Clang Without a System Dependency</h3>
<p>
Since Zig already links against Clang libraries for the
<a href="https://ziglang.org/#Integration-with-C-libraries-without-FFIbindings">translate-c feature</a>,
it was not much more cost to expose the <code>main()</code> entry point from Zig.
So that's exactly what we do:
</p>
<ul>
  <li><code>llvm-project/clang/tools/driver/driver.cpp</code> is copied to <code>$ZIGGIT/src/zig_clang_driver.cpp</code></li>
  <li><code>llvm-project/clang/tools/driver/cc1_main.cpp</code> is copied to <code>$ZIGGIT/src/zig_clang_cc1_main.cpp</code></li>
  <li><code>llvm-project/clang/tools/driver/cc1as_main.cpp</code> is copied to <code>$ZIGGIT/src/zig_clang_cc1as_main.cpp</code></li>
</ul>
<p>
The following patch is applied:
</p>
<pre>--- a/src/zig_clang_driver.cpp
+++ b/src/zig_clang_driver.cpp
@@ -206,8 +205,6 @@
                     void *MainAddr);
 extern int cc1as_main(ArrayRef&lt;const char *&gt; Argv, const char *Argv0,
                       void *MainAddr);
<span>-extern int cc1gen_reproducer_main(ArrayRef&lt;const char *&gt; Argv,</span>
<span>-                                  const char *Argv0, void *MainAddr);</span>
 
 static void insertTargetAndModeArgs(const ParsedClangName &amp;NameParts,
                                     SmallVectorImpl&lt;const char *&gt; &amp;ArgVector,
@@ -330,19 +327,18 @@
   if (Tool == "-cc1as")
     return cc1as_main(makeArrayRef(ArgV).slice(2), ArgV[0],
                       GetExecutablePathVP);
<span>-  if (Tool == "-cc1gen-reproducer")</span>
<span>-    return cc1gen_reproducer_main(makeArrayRef(ArgV).slice(2), ArgV[0],</span>
<span>-                                  GetExecutablePathVP);</span>
   // Reject unknown tools.
   llvm::errs() &lt;&lt; "error: unknown integrated tool '" &lt;&lt; Tool &lt;&lt; "'. "
                &lt;&lt; "Valid tools include '-cc1' and '-cc1as'.\n";
   return 1;
 }
 
<span>-int main(int argc_, const char **argv_) {</span>
<span>+extern "C" int ZigClang_main(int argc_, const char **argv_);</span>
<span>+int ZigClang_main(int argc_, const char **argv_) {</span>
   noteBottomOfStack();
   llvm::InitLLVM X(argc_, argv_);
<span>-  SmallVector&lt;const char *, 256&gt; argv(argv_, argv_ + argc_);</span>
<span>+  size_t argv_offset = (strcmp(argv_[1], "-cc1") == 0 || strcmp(argv_[1], "-cc1as") == 0) ? 0 : 1;</span>
<span>+  SmallVector&lt;const char *, 256&gt; argv(argv_ + argv_offset, argv_ + argc_);</span>
 
   if (llvm::sys::Process::FixupStandardFileDescriptors())
     return 1;
</pre>
<p>
This disables some cruft, and then renames <code>main</code> to <code>ZigClang_main</code> so that
it can be called like any other function. Next, in Zig's actual <code>main</code>, it looks
for <code>clang</code> as the first parameter, and calls it.
</p>
<p>
So, <code>zig clang</code> is low-level undocumented API that Zig exposes for directly invoking Clang.
But <code>zig cc</code> is much higher level than that. When Zig needs to compile C code,
it invokes itself as a child process, taking advantage of <code>zig clang</code>. <code>zig cc</code>
on the other hand, has a more difficult job: it must parse Clang's command line options and
map those to the Zig compiler's settings, so that ultimately <code>zig clang</code> can be invoked
as a child process.
</p>

<h3>Parsing Clang Command Line Options</h3>
<p>
When using <code>zig cc</code>, Zig acts as a proxy between the user and Clang. It does not need
to understand all the parameters, but it does need to understand some of them, such as
the target. This means that Zig must understand when a C command line parameter expects
to "consume" the next parameter on the command line.
</p>
<p>
For example, <code>-z -target</code> would mean to pass <code>-target</code> to the linker,
whereas <code>-E -target</code> would mean that the next parameter specifies the target.
</p>
<p>Clang has a
<a href="https://clang.llvm.org/docs/ClangCommandLineReference.html">long list of command line options</a> and so it would be foolish to try to hard-code all of them.
</p>
<p>
Fortunately, LLVM has a file "options.td" which describes all of its command line parameter options
in some obscure format. But fortunately again, LLVM comes with the <code>llvm-tblgen</code> tool
that can dump it as JSON format.
</p>
<p>
Zig has an
<a href="https://github.com/ziglang/zig/blob/dc44fe053c609f389e375f6857f96b6bb3794897/tools/update_clang_options.zig">update_clang_options tool</a>
which processes this JSON dump and produces a
<a href="https://github.com/ziglang/zig/blob/dc44fe053c609f389e375f6857f96b6bb3794897/src-self-hosted/clang_options_data.zig">big sorted list of Clang's command line options</a>.
</p>
<p>
Combined with a list of "known options" which correspond to Zig compiler options,
this is used to make an iterator API that <code>zig cc</code> uses to parse command line
parameters and instantiate a Zig compiler instance. Any Clang options that Zig is not
aware of are forwarded to Clang directly. Some parameters are handled specially.
</p>

<h3>Linking</h3>
<p>
This part is pretty straightforward. Zig depends on LLD for linking rather than
shelling out to the system linker, like GCC and Clang do.
</p>
<p>
When you use <code>-o</code> with <code>zig cc</code>, Clang is not actually acting as
a linker driver here. Zig is still the linker driver.
</p>

<h2>Everybody Wins</h2>
<p>
Now that I've spent this entire blog article comparing Zig and Clang as if they are
competitors, let me make it absolutely clear that both of these are harmonious,
mutually beneficial open-source projects. It's pretty obvious how Clang and the entire
LLVM project are massively beneficial to the Zig project, since Zig builds on top of them.
</p>
<p>
But it works the other way, too.
</p>
<p>
With Zig's focus on cross-compiling, its test suite has been expanding rapidly to cover
a large number of architectures and operating systems, leading to
<a href="https://github.com/ziglang/zig/issues?q=is%3Aissue+label%3Aupstream+is%3Aclosed">dozens of bugs reported upstream and patches sent</a>, including, for example:
</p>
<ul>
  <li><a href="https://bugs.llvm.org/show_bug.cgi?id=43268">Regression discovered in LLVM 9 release candidate</a></li>
  <li><a href="https://bugs.winehq.org/show_bug.cgi?id=47979">Bug fixed in Wine's NtDll</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/3338#issuecomment-536771508">Directly working with RISC-V target developers</a></li>
  <li><a href="https://bugs.llvm.org/show_bug.cgi?id=43768#c3">Bug fixes in LLVM's MIPS code generation</a></li>
</ul>
<p>Everybody wins.</p>

<h2>This is still experimental!</h2>
<p>
I have only recently landed <code>zig cc</code> support last week, and it is still experimental.
Please do not expect it to be production quality yet.
</p>
<p>
Zig's 0.6.0 release is right around the corner, scheduled for April 13th. I will be sure to provide
an update on the release notes on how stable and robust you can expect <code>zig cc</code> to be
in the 0.6.0 release.
</p>
<p>
There are some follow-up issues related to <code>zig cc</code> which are still open:
</p>
<ul>
  <li><a href="https://github.com/ziglang/zig/issues/4784">improve zig cc flag integration</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/4785">using zig as a drop in replacement for msvc</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/4786">support compiling and linking c++ code</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/4787">use case: directly symlink zig binary to /usr/bin/cc</a></li>
</ul><p>
As always, <a href="https://github.com/ziglang/zig/blob/master/CONTRIBUTING.md">Contributions are most welcome</a>.

</p><h2>💖 Sponsor Zig 💖</h2>
<p><a href="https://github.com/sponsors/andrewrk">Sponsor Andrew Kelley on GitHub</a></p>
<p>
If you're reading this and you already sponsor me, thank you so much! I wake up every day
absolutely thrilled that I get to do this for my full time job.
</p>
<p>
As Zig has been gaining popularity, demands for my time have been growing faster than
funds to hire another full-time programmer. Every recurring donation helps, and if the funds keep
growing then soon enough the Zig project will have two full-time programmers.
</p>
<p>
That's all folks. I hope you and your loved ones are well.
</p>



      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inserting One Billion Rows in SQLite Under a Minute (290 pts)]]></title>
            <link>https://avi.im/blag/2021/fast-sqlite-inserts/</link>
            <guid>27872575</guid>
            <pubDate>Sun, 18 Jul 2021 13:01:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avi.im/blag/2021/fast-sqlite-inserts/">https://avi.im/blag/2021/fast-sqlite-inserts/</a>, See on <a href="https://news.ycombinator.com/item?id=27872575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p><strong>Current Best</strong>: 100M rows inserts in 33 seconds. (you can check the <a href="https://github.com/avinassh/fast-sqlite3-inserts">source code on Github</a>)</p><hr><p>Recently, I ran into a situation where I needed a test database with lots of rows and needed it fast. So I did what any programmer would do: wrote a Python script to generate the DB. Unfortunately, it was slow. Really slow. So I did what any programmer would do: went down the rabbit hole of learning more about SQLite, Python, and eventually Rust… in my quest to get a 1B row database under a minute. This blog post is a summary of this fun and educational exercise.</p><h2 id="goal">Goal</h2><p>The goal of this experiment is to generate an SQLite database with one billion rows under a minute, on my machine, with the table having the following schema:</p><div><pre><code data-lang="sql"><span>create</span> <span>table</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>user</span>
(
    id INTEGER <span>not</span> <span>null</span> <span>primary</span> <span>key</span>,
    area CHAR(<span>6</span>),
    age INTEGER <span>not</span> <span>null</span>,
    active INTEGER <span>not</span> <span>null</span>
);
</code></pre></div><p>The generated data would be random with following constraints:
The <code>area</code> column would hold six digits area code (any six digits would do, no validation).
The <code>age</code> would be any of 5, 10, or 15.
The <code>active</code> column is either 0 or 1.</p><p>The machine I am using is MacBook Pro, 2019 (2.4 GHz Quad Core i5, 8GB, 256GB SSD, Big Sur 11.1)</p><p>Aspects I was willing to compromise on were:</p><ul><li>I don’t need the durability guarantee. That is, it is fine if the process crashes and all the data is lost. I could just run s the script again.</li><li>It may use my machine resources to the fullest: 100% CPU, 8GB Memory and gigabytes of SSD space.</li><li>No need of using true random methods, pseudo-random methods from stdlib are just fine.</li></ul><h2 id="python-prototype">Python Prototype</h2><p>Python is my go to language for any kind of scripting. The standard library provides a nice SQLite module, using which I wrote my first version. Here is the <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/f26951ea/naive.py">full code</a>. In this script, I tried to insert 10M rows, one by one, in a for loop. This version took close to 15 minutes, sparked my curiosity and made me explore further to reduce the time.</p><p>In SQLite, each insertion is atomic and is a transaction. Each transaction guarantees that it is written to disk thus could be slow. I tried different sizes of batch inserts, found out 100,000 to be a sweet spot. With this simple change, the running time was reduced to 10 minutes. Here is the <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/f26951ea/naive_batched.py">full code</a></p><h2 id="sqlite-optimisations">SQLite Optimisations</h2><p>The script I had written is very simple, so I assumed there isn’t much room for optimisation. Secondly, I wanted the code to be simple and near to the daily usage version. The next logical step was to look for database optimisations and I started diving into the amazing world of SQLite.</p><p>The internet is filled with many SQLite optimisation posts. Based on them, I made following changes:</p><div><pre><code data-lang="sql">PRAGMA journal_mode <span>=</span> <span>OFF</span>;
PRAGMA synchronous <span>=</span> <span>0</span>;
PRAGMA cache_size <span>=</span> <span>1000000</span>;
PRAGMA locking_mode <span>=</span> <span>EXCLUSIVE</span>;
PRAGMA temp_store <span>=</span> MEMORY;
</code></pre></div><p>What do these do?</p><ul><li>Turning off <code>journal_mode</code> will result in no rollback journal, thus we cannot go back if any of the transactions fail. This disables the atomic commit and rollback capabilities of SQLite. Do not use this in production.</li><li>By turning off <code>synchronous</code>, SQLite does not care about writing to disk reliably and hands off that responsibility to the OS. A write to SQLite, may not mean it is flushed to the disk. Do not use this in production.</li><li>The <code>cache_size</code> specifies how many memory pages SQLite is allowed to hold in the memory. Do not set this to a high value in production.</li><li>In <code>EXCLUSIVE</code> locking mode, the lock held by the SQLite connection is never released.</li><li>Setting <code>temp_store</code> to <code>MEMORY</code> will make it behave like an in-memory database.</li></ul><p>The SQLite docs have a <a href="https://www.sqlite.org/pragma.html">full page dedicated on these parameters</a>, they also list a bunch of other parameters. I haven’t tried all of them, the ones I selected provided a decent running time.</p><p>Here are some of the articles I read on the internet which helped me with these optimisation parameters: <a href="https://remusao.github.io/posts/few-tips-sqlite-perf.html">1</a>, <a href="https://stackoverflow.com/Questions/364017/faster-bulk-inserts-in-sqlite3">2</a>, <a href="https://stackoverflow.com/questions/1711631/improve-insert-per-second-performance-of-sqlite">3</a>, <a href="https://github.com/the-lean-crate/criner/issues/1">4</a>, <a href="https://stackoverflow.com/questions/25427769/how-does-executemany-work">5</a>.</p><h2 id="python-revisited">Python Revisited</h2><p>I rewrote the Python script again, this time including the fine-tuned SQLite parameters which gave a huge boost and the running time was reduced drastically.</p><ul><li>The <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/3b9850a/sqlite3_opt.py">naive for loop version</a> took about 10 minutes to insert 100M rows.</li><li>The <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/e126bd6/sqlite3_opt_batched.py">batched version</a> took about 8.5 minutes to insert 100M rows.</li></ul><h2 id="pypy">PyPy</h2><p>I have never used PyPy and <a href="https://www.pypy.org/">PyPy homepage</a> highlight that it is 4x faster than CPython, I felt this is a good opportunity to try it and test out their claims. I was also wondering if I had to make changes to make it run, however, my existing code ran smoothly.</p><p>All I had to do was run my existing code, without any change, using PyPy. It worked and the speed bump was phenomenal. The batched version took only 2.5 minutes to insert 100M rows. I got close to 3.5x speed :)</p><p>(I am not affiliated with PyPy but I would request you <a href="https://opencollective.com/pypy">consider donating to PyPy</a> for their efforts.)</p><h2 id="busy-loop">Busy Loop(?)</h2><p>I wanted to get some idea of how much time Python is spending just in loops. So I removed the SQL instructions and ran <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/d27601a/busy_loop.py">the code</a>:</p><ul><li>The batched version took 5.5 minutes in CPython</li><li>The batched version took 1.5 minutes in PyPy (again a 3.5x speed bump)</li></ul><p>I <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/47fd81f/src/bin/busy.rs">rewrote the same in Rust</a>, the loop took only 17 seconds. I decided to move from Python and experiment further in Rust.</p><p>(Note: This is NOT a speed comparison post between Python and Rust. Both have very different goals and places in your toolkit.)</p><h2 id="rust">Rust</h2><p>Just like Python, I wrote a <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/bdda921/src/bin/basic.rs">naive Rust version</a> where I inserted each row in a loop. However, I included all the SQLite optimisations. This version took about 3 minutes. Then I did further experiments:</p><ul><li>The previous version had used <code>rusqlite</code>, I <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/ebce33f/src/bin/basic_async.rs">switched to</a> <code>sqlx</code> which runs asynchronously. This version took about 14 mins. I was expecting this degraded performance. But it is worth noting that it performed worse than any of the Python iterations I had come up with so far.</li><li>I was executing raw SQL statements, <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/cbe53fd/src/bin/basic_prep.rs">switched to prepared statements</a> and inserted the rows in a loop, but reusing the prepared statement. This version took about only a minute.</li><li>Also tried creating a <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/9cc1ea1/src/bin/basic_batched_wp.rs">long string with an insert statement</a>, I don’t think this performed any better. The <a href="https://github.com/avinassh/fast-sqlite3-inserts">repository</a> has few other versions as well.</li></ul><h2 id="the-current-best-version">The (Current) Best Version</h2><ul><li>I used prepared statements and inserted them in a batch of 50 rows. To insert 100M rows, took 34.3 seconds. <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/009694f/src/bin/basic_batched.rs">source code</a></li><li>I created a threaded version, where I had one writer thread that received data from a channel and four other threads which pushed data to the channel. This is the current best version which took about 32.37 seconds. <a href="https://github.com/avinassh/fast-sqlite3-inserts/blob/bd8414f/src/bin/threaded_batched.rs">source code</a></li></ul><h2 id="io-time">IO Time</h2><p>Good folks at the SQLite forum gave me an interesting idea, measure the time it takes for in-memory DB. I ran the code again giving the DB location as <code>:memory:</code>, the rust version took two seconds less to complete (29 seconds). I guess it is fair to assume that it takes 2 seconds to flush 100M rows to disk. This also shows that there might not be any more SQLite optimisations possible to write to disk in a faster way, since 99% of time is being spent in generating and adding rows.</p><h2 id="leaderboard">Leaderboard</h2><p>(*at the time of writing. The repo has the upto date numbers)</p><table><thead><tr><th>Variant</th><th>Time</th></tr></thead><tbody><tr><td>Rust</td><td>33 seconds</td></tr><tr><td>PyPy</td><td>150 seconds</td></tr><tr><td>CPython</td><td>510 seconds</td></tr></tbody></table><h2 id="key-takeaways">Key Takeaways</h2><ul><li>Make use of SQLite <a href="https://www.sqlite.org/pragma.html">PRAGMA statements</a> when possible</li><li>Use prepared statements</li><li>Do a batched insertions</li><li>PyPy is actually 4x faster than CPython</li><li>Threads / async may not be faster always</li></ul><h2 id="further-ideas">Further Ideas</h2><p>Here are a few directions I plan to explore next to improve performance:</p><ol><li>I haven’t run the code through a profiler. It might give us hints about the slow parts and help us optimising the code further.</li><li>The second fastest version runs single threaded, on a single process. Since I have a four-core machine, I could launch 4 processes, get up to 800M rows under a minute. Then I would have to merge these in few seconds, so that the overall time taken is still less than a minute.</li><li>Write a go version with the garbage collector completely disabled.</li><li>It is entirely possible that rust compiler might have optimised the busy loop code and removed the allocations, calls to random functions since it had no side effects. Analysis of the generated binary might shed more light.</li><li>Here is a really crazy idea: learn about SQLite file format then generate the pages and write to disk directly.</li></ol><p>Looking forward to discussions and/or collaborations with curious souls in my quest to generate a billion record SQLite DB quickly. If this sounds interesting to you, reach out to me on <a href="https://twitter.com/iavins">Twitter</a> or <a href="https://github.com/avinassh/fast-sqlite3-inserts">submit a PR</a>.</p><p><small><i>Thanks to Bhargav, Rishi, Saad, Sumesh, Archana, and Aarush for reading a draft of this.</i></small></p><hr><p><small>1. Why? In <a href="https://github.com/avinassh/cowin-assist">a telegram bot</a>, I wrote, one of the SQL queries required a partial index. I have used partial indexes in Postgres/Mongo, but I was pleasantly surprised to know that SQLite also supported them. I decided to write a blog post (spoiler: which I never did), with numbers showing the effectiveness of partial indexes. I wrote a quick script and generated a DB, but the data was too small to show the power of partial indexes and queries were fast without them. The larger DB required more than 30 minutes to generate. So I spent 30+ hours to reduce the 30 mins of running time :p</small><br><small>2. If you liked this post, then you may like <a href="https://avi.im/blag/2021/mongo-dupes-in-unique-index/">my experiment with MongoDB</a> where I inserted duplicate records in a collection with a unique index - <a href="https://avi.im/blag/2021/mongo-dupes-in-unique-index/">link</a>.</small><br></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla is offering a $1500 upgrade for early cars to support “full self-driving” (118 pts)]]></title>
            <link>https://electrek.co/2021/07/18/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for/</link>
            <guid>27872468</guid>
            <pubDate>Sun, 18 Jul 2021 12:45:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2021/07/18/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for/">https://electrek.co/2021/07/18/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for/</a>, See on <a href="https://news.ycombinator.com/item?id=27872468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
						<p>This weekend, Tesla started offering their long-awaited <a href="https://electrek.co/2021/07/16/tesla-launches-full-self-driving-subscription-package-199-per-month/">Full Self-Driving subscription</a> package for $199/month.  Along with the package, Tesla is offering a $1,500 hardware upgrade for early owners who have old hardware that is not capable of full self-driving tasks.</p>
<p>The problem is, Tesla previously told those same owners that their cars <em>were</em> capable of full self-driving tasks and isn’t allowing those owners to take advantage of the new subscription scheme without paying again for a hardware upgrade that they already paid for.</p>

<p>All Teslas currently come with “Basic Autopilot,” a slate of driver-assist and safety features.  These include automatic lane keeping, traffic-aware cruise control, and other standard safety features like emergency brake assist.  These can help reduce the stress, particularly of highway driving, and enhance the safety of the vehicle.</p>
<p>The “Full Self-Driving” package takes this further and adds other driver-assist features that allow the car to make more decisions on its own.  These include:</p>
<ul>
<li>Navigate on Autopilot</li>
<li>Auto Lane Change</li>
<li>Autopark and Summon</li>
<li>Traffic Light and Stop Sign Control</li>
</ul>
<p>Eventually, this package will offer full autonomy, but the software is not there yet and still requires driver attention at all times.</p>
<p>Tesla’s Full Self-Driving package can be bought for $10,000 upfront or $199/month with the new subscription scheme.  It has cost less in the past, but as Tesla has rolled out more and more capabilities through software updates, the price has continually increased.</p>
<p>Since 2016, Tesla has said that all Tesla cars have Full-Self Driving <em>hardware</em> built in, but the software is what costs the extra money.  At press time, Tesla’s blog, where they announced this, is <a href="https://www.tesla.com/blog/all-tesla-cars-being-produced-now-have-full-self-driving-hardware">still up on their website</a>.  In case it goes down, we’ve screenshotted the contents of the blog for posterity:</p>
<figure>
<ul data-carousel-extra="{&quot;blog_id&quot;:3,&quot;permalink&quot;:&quot;https:\/\/electrek.co\/2021\/07\/18\/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for\/&quot;}">
<li>
<figure><img data-attachment-id="190221" data-permalink="https://electrek.co/2021/07/18/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for/screen-shot-2021-07-17-at-10-58-24-pm/" data-orig-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png" data-orig-size="1232,1592" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-07-17 at 10.58.24 PM" data-image-description="" data-medium-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?w=232" data-large-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?w=792" title="Tesla is charging owners $1,500 for hardware they already paid for" loading="lazy" width="1232" height="1592" src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?w=792" alt="" data-id="190221" data-full-url="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png" data-link="https://electrek.co/?attachment_id=190221" srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png 1232w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=116,150 116w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=232,300 232w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=768,992 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=792,1024 792w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=1189,1536 1189w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=271,350 271w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=774,1000 774w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=150,194 150w" sizes="(max-width: 1232px) 100vw, 1232px" data-lazy-srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png 1232w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=116,150 116w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=232,300 232w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=768,992 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=792,1024 792w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=1189,1536 1189w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=271,350 271w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=774,1000 774w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?resize=150,194 150w" data-lazy-src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.24-PM.png?w=792&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</li>
<li>
<figure><img data-attachment-id="190222" data-permalink="https://electrek.co/2021/07/18/tesla-is-charging-owners-1500-for-hardware-they-already-paid-for/screen-shot-2021-07-17-at-10-58-33-pm/" data-orig-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png" data-orig-size="1230,1652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-07-17 at 10.58.33 PM" data-image-description="" data-medium-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?w=223" data-large-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?w=762" title="Tesla is charging owners $1,500 for hardware they already paid for" loading="lazy" width="1230" height="1652" src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?w=762" alt="" data-id="190222" data-full-url="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png" data-link="https://electrek.co/?attachment_id=190222" srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png 1230w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=112,150 112w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=223,300 223w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=768,1031 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=762,1024 762w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=1144,1536 1144w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=261,350 261w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=745,1000 745w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=150,201 150w" sizes="(max-width: 1230px) 100vw, 1230px" data-lazy-srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png 1230w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=112,150 112w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=223,300 223w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=768,1031 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=762,1024 762w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=1144,1536 1144w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=261,350 261w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=745,1000 745w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?resize=150,201 150w" data-lazy-src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screen-Shot-2021-07-17-at-10.58.33-PM.png?w=762&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</li>
</ul>
</figure>
<p>Owners who bought Tesla vehicles between late 2016 and mid-2019 were sold a bill of goods that was capable of full self-driving with the hardware included in the vehicle.  They were told that no further hardware upgrades would be required.</p>
<p>Since that post, Tesla found that their previous computers, designated Hardware 2.0 and 2.5, weren’t quite up to the task of full self-driving.  So they <a href="https://electrek.co/2019/04/22/tesla-full-self-driving-computer-details/">designed their own chip</a>, alternately described as “Hardware 3.0” or “FSD Computer,” which was more capable.  Cars built since mid-2019 have this new hardware included.</p>
<p>As part of this change in hardware, Tesla said that all owners with the old hardware could upgrade to the new hardware for free, provided they had paid for Full Self-Driving.  Tesla has a blog describing the process for <a href="https://www.tesla.com/support/full-self-driving-computer">upgrading your computer to FSD Computer/Hardware 3.0</a>.</p>
<p>This was all fine and dandy – owners who would make use of the FSD Computer got a hardware upgrade along with their purchase of the software, and owners without Full Self-Driving weren’t missing out on anything since they didn’t have the software anyway.</p>
<p>But now, the much-awaited subscription scheme offers a lower barrier to entry.  Tesla owners with cars from late 2016-mid 2019 might want to try out the software and see what it can do, especially since it has improved since they purchased their car.  Maybe they don’t know if they’ll like it enough to want to spend $10,000, or maybe they don’t think they’ll have the car long enough for it to be worthwhile — any number of reasons.</p>
<p>But to get that subscription, Tesla is demanding that those owners pay $1,500 upfront for the hardware upgrade that was previously given to all Full Self-Driving purchasers for free.  Remember, this is an upgrade that all Tesla owners since late 2016 <em>already paid for</em> by purchasing a vehicle that <a href="https://www.tesla.com/blog/all-tesla-cars-being-produced-now-have-full-self-driving-hardware">Tesla said included Full Self-Driving hardware</a>.  Here’s the notice showing up in the Tesla app for older car owners who want to use the new subscription:</p>
<figure><img data-attachment-id="190224" data-permalink="https://electrek.co/screenshot-2021-07-17-at-11-19-17-pm-2/" data-orig-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?quality=82&amp;strip=all" data-orig-size="1125,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-2021-07-17-at-11.19.17-PM" data-image-description="" data-medium-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?quality=82&amp;strip=all&amp;w=225" data-large-file="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?quality=82&amp;strip=all&amp;w=768" title="Tesla is charging owners $1,500 for hardware they already paid for" loading="lazy" width="1125" height="1500" src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?quality=82&amp;strip=all" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg 1125w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=113,150 113w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=225,300 225w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=768,1024 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=263,350 263w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=750,1000 750w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=640,853 640w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=150,200 150w" sizes="(max-width: 1125px) 100vw, 1125px" data-lazy-srcset="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg 1125w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=113,150 113w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=225,300 225w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=768,1024 768w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=263,350 263w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=750,1000 750w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=640,853 640w, https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?resize=150,200 150w" data-lazy-src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Screenshot-2021-07-17-at-11.19.17-PM-edited.jpeg?quality=82&amp;strip=all&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>As this information has percolated through Tesla <a href="https://www.reddit.com/r/teslamotors/comments/om7b31/tesla_demanding_another_1500_dollars_for_a_fsd/">forums</a> and by word-of-mouth, many owners are showing their anger with Tesla over the changes.  We’ve received several <a href="https://electrek.co/contact-electrek/">tips</a> and messages and read lots of furious comments over this change, with some comments even calling for legal action.</p>
<h3 id="h-electrek-s-take">Electrek’s Take</h3>
<p>This isn’t the first time Tesla has broken a promise to early customers.</p>
<p>Tesla told early customers that prices would gradually rise for Full Self-Driving capability and to lock in their price now before it goes up.  Then, before any Full Self-Driving features actually rolled out, Tesla <a href="https://electrek.co/2019/03/04/teslas-autopilot-bait-and-switch/">pulled a bait-and-switch and lowered the price</a>, despite the software never having been delivered yet at that time.  Some might say that this is analogous to buying a product that later dropped in price, but the difference is that the early purchasers here<em> </em>gained no benefit from owning the software early since the software didn’t do anything yet at the time.</p>
<p>Tesla also recently broke a promise with Tesla Solar Roof customers, <a href="https://electrek.co/2021/04/11/tesla-hikes-solar-roof-price-on-contracts-signed-over-a-year-ago/">hiking prices on already-signed contracts</a> after stringing along those early customers for a year or more about Solar Roof availability.</p>
<p>This sort of thing seems to happen a lot with Tesla.  In fact, even before the aforementioned events, many early Model 3 owners purchased their vehicles with Full Self-Driving, even though the software didn’t do anything yet, because they thought doing so would obligate Tesla to upgrade their computers for free if they later found out the hardware was not capable enough.  So this sort of behavior is common enough from Tesla that many owners anticipated this happening years in advance.</p>
<p>But despite this, the company has loyal customers because they make a good product and because they truly are pushing the industry forward.  Tesla has been a major cause of the shift towards electric vehicles, which is necessary if we are to avoid the worst effects of the climate emergency we are all currently facing.  They’re innovating a lot, and the rest of the industry is finally starting to race to catch up.</p>
<p>The same fast-and-loose pace of innovation leads to a lot of basic errors like this.  Someone within the company should have remembered that this promise was made and should have noted that it would be unethical and unwise to charge your loyal, early customers $1,500 for a product they already purchased.  But that employee probably quit working at Tesla a while ago because the company overworks everyone, which leads to high turnover and little institutional memory, even for things that are <em>still up on the website</em>.</p>
<p>Tesla has gotten a certain amount of slack from owners and media. The company is a “startup” in a difficult industry and is trying to change that industry significantly and do a reasonable job of it.</p>
<p>However, Tesla was founded in <strong>2003</strong>, 18 years ago.  It’s an enormous company with over 70,000 employees, making ~$10 billion in revenue every quarter, and it’s even part of the S&amp;P 500.  It’s not a “startup” anymore.  It doesn’t get to use that excuse when it does stupid stuff like this.  It needs to grow up and stop lying to its customers.  And we’re getting tired of having to say this.</p>
<p>There is a simple solution here: remove the $1,500 charge for hardware that owners already paid for.  We hope this change happens swiftly.</p>
<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p><figure><a href="https://merch.electrek.co/listing/electric-cars-of-note?product=46"><img src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Electrek-T-shirt.jpg?" alt="Electrek T-Shirt" data-lazy-src="https://electrek.co/wp-content/uploads/sites/3/2021/07/Electrek-T-shirt.jpg?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div><hr>
<p><a href="https://www.youtube.com/channel/UCcOIZzJgLCyMPILY7-1Vsdg?sub_confirmation=1">Subscribe to Electrek on YouTube for exclusive videos</a> and subscribe to the <a href="https://www.electrek.co/guides/electrek-podcast">podcast</a>.<!-- youtube embed --></p><p><iframe title="Recent Videos" src="https://www.youtube.com/embed/LBbT114j-iM?playlist=_F8Wla9D5ic,0ZFyx5cFBQ0,qkZbu569_zA,qrcDtQGGWvw,IKYVtEJTOw0,rhw3jBsbSXY,QnglyXR5jsc,F5B71OCH7w0,dWmmT20N6vQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" width="1000" height="563"></iframe></p>
					</div><p>You’re reading Electrek— experts who break news about <a href="https://electrek.co/guides/tesla/">Tesla</a>, <a href="https://electrek.co/best-electric-vehicle-prices/">electric vehicles,</a> and <a href="https://electrek.co/guides/egeb/">green energy</a>, day after day. Be sure to check out our <a href="https://electrek.co/">homepage</a> for all the latest news, and follow Electrek on <a href="http://twitter.com/electrekco">Twitter</a>, <a href="https://www.facebook.com/electrekco/">Facebook</a>, and <a href="https://www.linkedin.com/company/electrek">LinkedIn</a> to stay in the loop. Don’t know where to start? Check out our <a href="https://youtube.com/c/electrekco">YouTube channel</a>&nbsp;for the latest reviews.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NYC Mesh Community Internet (106 pts)]]></title>
            <link>https://www.nytimes.com/2021/07/16/nyregion/nyc-mesh-community-internet.html</link>
            <guid>27872243</guid>
            <pubDate>Sun, 18 Jul 2021 12:04:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2021/07/16/nyregion/nyc-mesh-community-internet.html">https://www.nytimes.com/2021/07/16/nyregion/nyc-mesh-community-internet.html</a>, See on <a href="https://news.ycombinator.com/item?id=27872243">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="story"><div id="fullBleedHeaderContent"><header><div><figure aria-label="media" role="group"><div><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"><img alt="Daniel Heredia working this spring to bring inexpensive Wi-Fi to a building in Brownsville, Brooklyn." src="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-articleLarge.jpg?quality=90&amp;auto=webp 600w,https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-jumbo.jpg?quality=90&amp;auto=webp 1024w,https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh/16nyc-mesh-superJumbo.jpg?quality=90&amp;auto=webp 2048w" sizes="100vw" decoding="async" width="600" height="400"></picture></div><figcaption><span><span>Credit...</span><span><span>Jose A. Alvarado Jr. for The New York Times</span></span></span></figcaption></figure></div><div><p>NYC Mesh, a band of a few dozen tech volunteers, takes on Verizon and the big “incumbent providers,” with the promise of inexpensive community internet.</p></div></header><p><span>Daniel Heredia working this spring to bring inexpensive Wi-Fi to a building in Brownsville, Brooklyn.</span><span><span>Credit...</span><span><span>Jose A. Alvarado Jr. for The New York Times</span></span></span></p><div><ul><li><time datetime="2021-07-16T05:00:26-04:00">July 16, 2021</time></li></ul></div></div><section name="articleBody"><div><p>Daniel Heredia peered across rooftops, surveying the derelict satellite dishes and rusty television antennas of Brownsville, Brooklyn. Wearing a motorcycle jacket and boots, he crouched on Andre Cambridge’s roof, trying to see if he had a clear line of sight to the Riverdale Avenue Community School a half-mile off. A large tree was possibly in the way.</p><p>Mr. Cambridge, a 28-year-old student who lives with his parents and younger brother in an apartment on the first floor, watched the scene apprehensively. He had been without internet for nine weeks. “Man,” Mr. Heredia said, “you should have told us.” He could have moved up the installation.</p><p>Mr. Heredia is a 19-year-old volunteer with <a href="http://nycmesh.net/" title="" rel="noopener noreferrer" target="_blank">NYC Mesh</a>, a nonprofit community Wi-Fi initiative, and he was there to install a router that would bring inexpensive Wi-Fi to the building. Mr. Cambridge’s family said they had become fed up with the take-it-or-leave-it pricing for spotty service that internet providers seem to get away with in this part of Brooklyn.</p></div><div><p>Mr. Heredia crouched to affix the router to a plumbing vent, positioning it so the Wi-Fi signal could avoid the tree down the block. An app on his phone beeped to indicate the strength of the connection. Higher in pitch and more rapid was good. Mr. Cambridge whipped out his phone to search for NYC Mesh among the available networks. “It just came up!”</p></div><div data-testid="photoviewer-wrapper"><figure aria-label="media" role="group"><div><p><span>Image</span></p><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"><img alt="Mr. Heredia, left, a volunteer with NYC Mesh, a nonprofit community Wi-Fi initiative, installing a router on the building where Andre Cambridge, right, lives.&nbsp;" src="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-articleLarge.jpg?quality=90&amp;auto=webp 600w,https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-jumbo.jpg?quality=90&amp;auto=webp 1024w,https://static01.nyt.com/images/2021/07/16/nyregion/16nyc-mesh2/16nyc-mesh2-superJumbo.jpg?quality=90&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="400"></picture></div><figcaption><span><span>Credit...</span><span>Jose A. Alvarado Jr. for The New York Times</span></span></figcaption></figure></div><div><p>He skipped across the roof, beaming under Ray bans and dreadlocks. The installation took two hours and cost $240 to cover the equipment, plus a $50 tip for Mr. Heredia, the installer.</p><p>Mr. Cambridge ran a speed test. “We’re getting 80 megabits down and 50 megabits up!”</p><p>Mr. Heredia clasped palms and bumped shoulders with Mr. Cambridge. “Welcome to the Mesh, brother,” he said.</p><p>In New York, like most big cities, the wealthier a neighborhood is, the more options for internet service its residents probably have — and the more incentive for providers in those areas to compete on service and price. On some blocks on the Upper West Side, residents can choose among four carriers. In Brownsville, Mr. Cambridge could choose between Altice or Optimum — which is owned by Altice. Verizon’s fiber-optic service, Fios, is supposed to be available on every city block, which in theory would spur more competition, but that has yet to happen.</p><p>While a fiber connection remains the gold standard, “fixed wireless” options like the rooftop routers used by NYC Mesh can deliver a signal that is plenty strong for most residential uses and usually much faster and cheaper to deploy. NYC Mesh has a subsidized option for installations, and members pay a suggested monthly donation of $20 to $60.</p></div><div data-testid="photoviewer-wrapper"><figure aria-label="media" role="group"><div><p><span>Image</span></p></div><figcaption><span><span>Credit...</span><span>Jose A. Alvarado Jr. for The New York Times</span></span></figcaption></figure></div><div><p>NYC Mesh is one of many fixed-wireless outfits in New York City. They range from community-owned models — like the D.I.Y. “internet in a box” efforts led by the digital justice organization <a href="https://www.communitytechny.org/" title="" rel="noopener noreferrer" target="_blank">Community Tech NY</a>, and the internet cooperative <a href="https://peopleschoice.coop/" title="" rel="noopener noreferrer" target="_blank">People’s Choice</a>, started by former Spectrum strikers — to smaller for-profits like <a href="https://starry.com/" title="" rel="noopener noreferrer" target="_blank">Starry</a>, a Boston-based start-up rolling out flat-rate internet plans of $50 a month in large urban markets including New York City.</p><p>NYC Mesh covers more neighborhoods than the others and is the largest community network in the city by far. Yet it’s still small, serving only about 800 households, concentrated in Lower Manhattan and central Brooklyn. That’s a tiny slice of the 2.2 million New York City households with broadband at home, usually through one of the “incumbent providers,” as they are known: Verizon, Spectrum or Optimum.</p><p>But with NYC Mesh’s expansion into Brownsville, and a new contract with the city to place routers on a handful of housing developments, the one million New Yorkers who don’t have broadband — <a href="https://data.cityofnewyork.us/City-Government/Internet-Master-Plan-Broadband-Adoption-Demographi/6yzk-rwz2/data" title="" rel="noopener noreferrer" target="_blank">46 percent of households in poverty lack a home connection</a> — might soon have another, more affordable choice. “To grow, we need to be on more tall buildings,” said Brian Hall, the founder of NYC Mesh. The pandemic has actually helped his initiative get there, and it might encourage New Yorkers to think about the internet in a new way — as a utility that everyone should be able to access.</p><p>Community Wi-Fi networks have been operating in other countries since the early 2000s. It’s a relatively niche phenomenon. The biggest community network in the world is Guifi.net in Spain, and that has only 39,000 connections. Still, it was an inspiration to Mr. Hall when he was starting NYC Mesh back in 2014. Burned out from his job as a programmer, he wanted to do something community-based that could have an impact.</p></div><div data-testid="photoviewer-wrapper"><figure aria-label="media" role="group"><div><p><span>Image</span></p></div><figcaption><span><span>Credit...</span><span>Jose A. Alvarado Jr. for The New York Times</span></span></figcaption></figure></div><div><p>Mr. Hall secured funding from the <a href="https://www.internetsociety.org/" title="" rel="noopener noreferrer" target="_blank">Internet Society</a>, an international nonprofit that promotes open and secure internet around the world, to set up NYC Mesh’s first “supernode” on top of the former Verizon building in downtown Manhattan. This supernode, plus another in Industry City, on the Brooklyn waterfront, serve as the central spigots for NYC Mesh’s neighborhood hubs and nodes, as they refer to the members’ routers.</p></div><div><p>Early supporters were mostly tech-liberationist types. “Initially everyone united around hating Time Warner Cable,” Mr. Hall said. A manifesto on NYC Mesh’s website lists the reasons members were behind community Wi-Fi: to build a neutral network that doesn’t block content or sell personal data; to bridge the digital divide; and to “stand in opposition to the telecom oligopoly in New York of Verizon, Optimum and Spectrum.”</p><p>There are no paid employees. A team of 30 or so volunteers, about a third of them women, lead installations and maintain the network. A recent installation at a housing development in Bedford-Stuyvesant that Mr. Heredia helped lead included a 50-year-old coder/actor/carpenter, a 40-year-old Turkish woman who ran a tech company back home, a 26-year-old with a fellowship to study the digital divide from the Robin Hood Foundation (whose family used to live in that very complex), and a father with a week-old baby whose wife had given him permission to go.</p><p>Organizing occurs on the <a href="https://nycmesh.slack.com/join/shared_invite/zt-963llput-yxHk576OpjAWRUO7BNTRcg#/shared-invite/email" title="" rel="noopener noreferrer" target="_blank">online platform Slack</a>, with the work documented on public channels for the benefit of other groups interested in starting community Wi-Fi projects. The pandemic brought a rush of volunteers along with requests from people needing help to get communities connected, including one from an intrepid social worker from the Riverdale Avenue Community School in Brownsville. After setting up that hub, Mr. Heredia and another volunteer installed routers in the hallways of the family homeless shelter across the street.</p><p>Around that time, NYC Mesh members were already in negotiations with the New York City Housing Authority about putting a hub on a 24-story tower in Bed-Stuy. It would extend the nonprofit’s coverage area to less-gentrified parts of Brooklyn — hundreds of buildings within a two-mile radius of the hub could get internet. It wouldn’t cost the city anything. NYC Mesh simply needed permission. There was reason to be optimistic.</p></div><div data-testid="photoviewer-wrapper"><figure aria-label="media" role="group"><div><p><span>Image</span></p></div><figcaption><span><span>Credit...</span><span>Jose A. Alvarado Jr. for The New York Times</span></span></figcaption></figure></div><div><p>In January 2020, the office of Mayor Bill de Blasio released its <a href="https://www1.nyc.gov/assets/cto/downloads/internet-master-plan/NYC_IMP_1.7.20_FINAL-2.pdf" title="" rel="noopener noreferrer" target="_blank">Internet Master Plan</a>, an ambitious reimagining of the city’s broadband infrastructure. The plan offers free use of the rooftops of public buildings and streetlight poles to providers large and small to build out their network infrastructures. This strategy amounts to a thumb on the scale in favor of grass-roots outfits like NYC Mesh, whose technology depends on rooftop access versus the larger providers, who must bury their cable or string it from telephone poles.</p><p>Brian Dietz, a spokesman from the industry lobbying group <a href="https://www.ncta.com/" title="" rel="noopener noreferrer" target="_blank">NCTA — the Internet &amp; Television Association</a> — maintained that commercial broadband is the best for consumers. “It provides the fastest, most reliable service for the best value,” Mr. Dietz said. “We have made billions of dollars of investment in infrastructure and speeds have increased thousands of times over the last decade.”</p></div><div><p>Before the recent vision, the city’s last major broadband intervention was negotiated under Mayor Michael R. Bloomberg in 2006. New York entered a franchise <a href="https://www.nytimes.com/2006/08/14/technology/14verizon.html" title="">agreement with Verizon</a> that gave the company the privilege of burying fiber-optic cable under city streets in exchange for installing high-speed Fios in every neighborhood. But Verizon has <a href="https://www.nytimes.com/2017/03/13/nyregion/ny-sues-verizon-fios.html" title="">failed to do so</a> in many low-income neighborhoods. In a public hearing in April, the city’s chief technology officer, John Paul Farmer, testified that the relatively few providers in some neighborhoods meant that there was little market pressure to bring the prices down. “The current oligopolistic system is broken, and it has built digital inequity into the streets and neighborhoods of New York,” he said.</p><p>The city recently reached a <a href="https://arstechnica.com/tech-policy/2020/11/verizon-wiring-up-500k-homes-with-fios-to-settle-years-long-fight-with-nyc/" title="" rel="noopener noreferrer" target="_blank">settlement</a> with Verizon, requiring it to connect an additional 500,000 households, with at least 125,000 in underserved neighborhoods, by 2023.</p><p>Chris Serico, a spokesman for Verizon, said the company was on track to meet the terms of its settlement. “Verizon is committed to finding long-term solutions that make affordable broadband options available to low-income Americans,” Mr. Serico wrote in an email. </p><p>Clayton Banks, the chief executive of Silicon Harlem, a company focused on increasing connectivity in Harlem, said he hoped that the city’s strategy of betting on more competition would work, but that he was waiting to see how Fios and the current providers would be priced. “If you continue to build out infrastructure, which is certainly welcome and necessary, but you keep the same retail price,” he said, “you haven’t solved anything in terms of getting more people online.”</p><p>After months of back and forth, NYC Mesh got the greenlight to put a hub on the 24-story public housing tower in Bed-Stuy, along with two other developments in the Bronx and Queens. Four other small providers, including Silicon Harlem, were <a href="https://www1.nyc.gov/office-of-the-mayor/news/338-21/recovery-all-us-new-york-city-free-low-cost-broadband-access-13-nycha" title="" rel="noopener noreferrer" target="_blank">selected</a> to wire up 10 other NYCHA developments. As part of Phase One of the Internet Master Plan, to which the city will direct $157 million, NYC Mesh installed free public hot spots around the exterior grounds of the projects; the other companies must provide residents access to Wi-Fi in their apartments for no more than $20 a month.</p><p>NYC Mesh has applied to establish hubs on an additional 163 public buildings as part of Phase Two. If successful, this would allow NYC Mesh to cover much of the city in the next five to seven years. Since each router installation comes with a free public Wi-Fi hot spot, NYC Mesh could help make the internet truly universal throughout New York City.</p><p>Even as NYC Mesh has continually grown, it still runs into the same trouble as the big providers: The internet sometimes goes down. Mr. Heredia and other volunteers pride themselves on resolving service problems quickly, but as the organization expands, it will need more people like Mr. Heredia if it wants to keep members happy.</p></div><div><p>Mr. Heredia has been volunteering since last October, when he stumbled across NYC Mesh online when researching alternatives to commercial providers. After setting up a router using NYC Mesh’s instructions, he attended a socially distanced meet-up in a Brooklyn park. A half-dozen installs later, Mr. Heredia got his own cable-crimping set and became an install leader.</p><p>He also helps maintain the network, particularly the hub on top of a NYCHA building in Bed-Stuy that supplies his internet. A few months back, the power went out at Mr. Heredia’s hub. It turned out the building’s custodians were repairing the elevator and had shut off some breakers. Mr. Heredia (who is a full-time student with a part-time job) sped over on his motorcycle with a long extension cord and battery packs, and had it working again an hour and 15 minutes after the first complaint came in on the NYC Mesh Slack channel. “All the people I know in the Mesh who participate actively have a similar relationship,” he said about his own vested interest in maintaining the network.</p><p>But the people who use the free hot spots in public housing or the family shelter in Brownsville don’t know how to fix the equipment or where to request a repair or<span>  </span>report an outage on Slack. Indeed, all but one of the hallway routers in the shelter have been out for the last couple of months, and a number of new ones at the Bed-Stuy tower keep going offline. There’s an issue with the devices that Mr. Heredia and other volunteers have spent hours trying to figure out.</p><p>The future for Mesh relies on cooperation with members, but it’s a hard sell in certain neighborhoods. First, not all renters can put routers on the roofs of their buildings. Some people are suspicious of “free internet” and won’t use the hot spots. NYC Mesh volunteers acknowledge that they need community members from the underserved neighborhoods to take the same ownership over their hubs as Mr. Heredia does over his.</p><p>Brownsville’s newest member, Andre Cambridge, might be up for the task. A week after his installation, Mr. Cambridge told me that his speeds had been good and that he hadn’t experienced any problems. His mother even suggested that they should up their monthly donation from $20 to support the cause.</p><p>He said he was excited but also wary about Mesh’s future. He had seen other community solutions get up and running only to be squashed by regulation and corporate interests. He suggested that if the government really wanted to help, it should fund training for volunteer installs, subsidize hardware costs and pay for network education so community members would understand the hubs they would be stewarding.</p><p>In the meantime, Mr. Cambridge said he was prepared to do his part to take care of his new hub. “If you had a community well back in the day, you had to maintain it,” he said. “Eventually I’m going to be like, ‘What’s the network map on this, what’s my upkeep look like?’ I’m part of a system, so I have to be. I’m going to advocate for my neighbor. ‘Hey, would you like to join the system too?’”</p></div></section></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Copilot: First Impressions (111 pts)]]></title>
            <link>https://vladiliescu.net/github-copilot-first-impressions/</link>
            <guid>27872116</guid>
            <pubDate>Sun, 18 Jul 2021 11:27:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vladiliescu.net/github-copilot-first-impressions/">https://vladiliescu.net/github-copilot-first-impressions/</a>, See on <a href="https://news.ycombinator.com/item?id=27872116">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

<article><p>GitHub Copilot is a tool that helps you write better, faster, and most importantly, more code.</p>
<p>I’ve been lucky enough to use it for the past few weeks and so far has proven quite useful, having earned a place in my toolbox despite its rough edges. I also feel it signals a coming change in how we develop and reason about systems, a change which will allow us to go up a few layers of abstraction in the coming decades.</p>
<p>But those decades are too far off into the future, let’s see what happens before them.</p>
<p>For starters, I’m increasingly convinced that in the near future, three to five years tops, we’ll all be writing a whole lot <strong>more comments</strong>, use a whole lot <strong>more descriptive names</strong> for everything, and write a whole lot <strong>less code</strong>.</p>
<figure><img src="https://vladiliescu.net/github-copilot-first-impressions/img/more-code.png"><figcaption>
<h4>But not just yet</h4>
</figcaption>
</figure>
<p>We’ll also do <strong>code reviews</strong>. Lots and lots of code reviews. Like, all the time. The algorithm will have to be kept in check.</p>
<p>Let me tell you why I think that’ll happen.</p>
<hr>
<h4>Table of Contents</h4>

<hr>
<h2 id="the-good">The Good</h2>
<p>GitHub Copilot has been described as ‘magical’, ‘god send’, ‘seriously incredible work’, et cetera. I agree, it’s a pretty impressive tool, something I see myself using daily. Especially once they add support for PyCharm. Heck, I’ve been using it daily while Cmd+Tabbing between PyCharm and VSCode, writing code in PyCharm whenever I wanted to think for myself and in VSCode whenever I wanted the algorithm to do it for me.</p>
<p>In my experience, Copilot excels at writing <strong>repetitive, tedious, boilerplate-y code</strong>. With minimal context, it can whip up a function that slices and dices a dataset, trains and evaluates several ml models, and, if you ask it nicely, also makes a nice batch of french fries. Not just that, it can look at an example and a list of items, and apply that example to each and every item in the list, the kind of stuff you’d record a quick macro to fix.</p>
<figure><img src="https://vladiliescu.net/github-copilot-first-impressions/img/macros.gif"><figcaption>
<h4>No more recording quick macros I guess</h4>
</figcaption>
</figure>
<h2 id="the-bad">The Bad</h2>
<p>When it comes to more advanced stuff, Copilot’s usefulness is a bit more nuanced.</p>
<p>It’s ability to generate a large amount of code that may or may not do the right thing is not to be trifled with. At times it’s brilliant, at other times..less so. This is especially visible when writing <strong>important</strong> code, code you need to focus on and make sure you get right. Code reviews come into play here by the way, and they’ll become more important as tools like this gain traction.</p>
<p>GitHub Copilot can also suggest using obsolete versions of libraries, use syntactically incorrect or undefined code, and it will happily fill in hyperparameters for non-existent ml algorithms.</p>
<figure><img src="https://vladiliescu.net/github-copilot-first-impressions/img/cv_ridge.png"><figcaption>
<h4>It was an honest mistake</h4>
</figcaption>
</figure>
<p>I’ve found it helps to think of it as a preview version of Tesla’s Autopilot, where every 10 minutes or so it may or may not swerve into the opposite lane, so you need to pay attention <strong>at all times</strong>. Hands on the wheel, eyes on the road, close that tab running YouTube.</p>
<p>Long story short, while most of these issues will be fixed in time it looks like others <a href="#limitations">might take their place</a>. For the moment, you should limit its usage if you don’t know or don’t care what you’re doing. There be dragons.</p>
<h2 id="the-research">The Research</h2>
<p>I’ve found the <a href="https://vladiliescu.net/github-copilot-first-impressions/(https://arxiv.org/abs/2107.03374)">paper on Codex</a>, the GPT language model that powers GitHub Copilot to be quite insightful when trying to understand when to use and when not to use Copilot, its strengths and weaknesses.</p>
<p>Here are some of my favorite bits from that paper.</p>
<h3 id="potential">Potential</h3>
<blockquote>
<p>Codex has the potential to be useful in a range of ways. For example, it could help onboard users to new codebases, reduce context switching for experienced coders, enable non-programmers to write specifications and have Codex draft implementations, and aid in education and exploration.</p>
</blockquote>
<p>Having a Copilot model <strong>transfer learn</strong> your company’s codebase and then suggest patterns and modules used throughout the company, now that would be a dream come true. Just think how much this’ll help standardize your <strong>patterns and practices</strong>. It will most likely <strong>not</strong> happen in the next decade, as the computing power needed to run &amp; train a version of the model will remain prohibitive for a while, but I can definitely see this happening in the long run.</p>
<p>I’m also really excited about <strong>enabling non-programmers</strong> to write specs. Specifically, testers. Testers who cannot write the tiniest bit of code to test an API or an UI, but who can write a description of what they want to achieve. Most of the code they need should be simple enough that Copilot gets it right the first time, and it would massively increase their productivity.</p>
<p>That’s already possible to some extent, even the current preview version of Copilot.</p>
<figure><img src="https://vladiliescu.net/github-copilot-first-impressions/img/cypress.gif"><figcaption>
<h4>🤭</h4>
</figcaption>
</figure>
<h3 id="limitations">Limitations</h3>
<blockquote>
<p>Due to the limitations described above as well as alignment issues described below, Codex may suggest solutions that superficially appear correct but do not actually perform the task the user intended. This could particularly affect novice programmers, and could have significant safety implications depending on the context. We discuss a related issue in Appendix G, namely that code generation models can suggest insecure code. For these reasons, human oversight and vigilance is required for safe use of code generation systems like Codex.</p>
</blockquote>
<p>Code reviews, code reviews, code reviews. But even they might not help for long because:</p>
<blockquote>
<p>One challenge researchers should consider is that as capabilities improve, it may become increasingly difficult to guard against “automation bias.”</p>
</blockquote>
<p>So we’ll be hit by a double-whammy: the better GitHub Copilot and similar systems become, the less willing we’ll be to look for bugs in the generated code. And when we do look for bugs in the generated code, they’ll be really subtle and hard to identify.</p>
<p>I’m curious to see what safeguards we’ll build against these issues.</p>
<h3 id="incorrect-code">Incorrect Code</h3>
<blockquote>
<p>Applying this framework, we find that Codex can recommend syntactically incorrect or undefined code, and can invoke functions, variables, and attributes that are undefined or outside the scope of the codebase.</p>
</blockquote>
<p>Yup.</p>
<h3 id="less-is-more">Less is More</h3>
<blockquote>
<p>Moreover, Codex struggles to parse through increasingly long and higher-level or system-level specifications.(…) We find that as the number of chained building blocks in the docstring increases, model performance decreases exponentially.</p>
</blockquote>
<p>That’s an interesting one, I had been under the impression that the more details I’d write in a docstring the better Copilot would perform. The exact opposite appears to be true.</p>
<h2 id="parting-words">Parting Words</h2>
<p>I’m excited. Real excited. I think we’re fast approaching a paradigm shift in how we do development, taking us up one level of abstraction. I look forward to the day when a Copilot-powered compiler takes in my English description and compiles it to Python, or JavaScript, or C#, or all of them.</p>
<p>The future is now, might as well embrace it.</p>
<h2 id="ps">P.S.</h2>
<p>No, no part of this article has been generated by Copilot, all the good and the bad are mine to own. God knows I’ve tried to use it for the intro though.</p>
<figure><img src="https://vladiliescu.net/github-copilot-first-impressions/img/intro.gif"><figcaption>
<h4>Guess so</h4>
</figcaption>
</figure>
<hr>
<p>By the way, if you’ve enjoyed this article you might want to read the <a href="https://vladiliescu.net/archives/">others</a>, too. I usually write a new one each month, focused mostly on Azure ML but with other stuff thrown in for good measure.</p>
<p>Just make sure to subscribe below and you’ll get them fresh from the oven.</p>

<p>Or maybe you’d like to show the Twitter thread some ❤️?</p>
<blockquote><div lang="en" dir="ltr"><p>I've been using <a href="https://twitter.com/hashtag/GitHubCopilot?src=hash&amp;ref_src=twsrc%5Etfw">#GitHubCopilot</a> for a couple of weeks, and despite it's drawbacks I quite like it. </p><p>Actually, that's an understatement. I think it's the future of development. 🧶 👇<a href="https://t.co/SsqZ5MY0CV">https://t.co/SsqZ5MY0CV</a></p></div>— Vlad Iliescu (@vladiliescu) <a href="https://twitter.com/vladiliescu/status/1416761898226360321?ref_src=twsrc%5Etfw">July 18, 2021</a></blockquote>

</article>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cannabis first domesticated 12,000 years ago (111 pts)]]></title>
            <link>https://phys.org/news/2021-07-cannabis-domesticated-years.html</link>
            <guid>27871966</guid>
            <pubDate>Sun, 18 Jul 2021 10:46:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2021-07-cannabis-domesticated-years.html">https://phys.org/news/2021-07-cannabis-domesticated-years.html</a>, See on <a href="https://news.ycombinator.com/item?id=27871966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    <div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2021/cannabis-has-been-used.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2021/cannabis-has-been-used.jpg" data-sub-html="Cannabis has been used for millennia for textiles and for its medicinal and recreational properties.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2021/cannabis-has-been-used.jpg" alt="Cannabis has been used for millennia for textiles and for its medicinal and recreational properties" title="Cannabis has been used for millennia for textiles and for its medicinal and recreational properties." width="800" height="530">
             <figcaption>
                Cannabis has been used for millennia for textiles and for its medicinal and recreational properties.
            </figcaption>        </figure>
    </div><p>Cannabis was first domesticated around 12,000 years ago in China, researchers found, after analyzing the genomes of plants from across the world.

                                         
                                                  </p>
                                        
                                                                                    <p>The study, published in the journal <i>Science Advances</i> on Friday, said the genomic history of cannabis <a href="https://phys.org/tags/domestication/" rel="tag">domestication</a> had been under-studied compared to other crop species, largely due to <a href="https://phys.org/tags/legal+restrictions/" rel="tag">legal restrictions</a>.</p>
<p>The researchers compiled 110 whole genomes covering the full spectrum of wild-growing feral plants, landraces, historical cultivars, and modern hybrids of plants used for <a href="https://phys.org/tags/hemp/" rel="tag">hemp</a> and drug purposes.</p>
<p>The study said it identified "the time and origin of domestication, post-domestication divergence patterns and present-day genetic diversity".</p>
<p>"We show that cannabis sativa was first domesticated in early Neolithic times in East Asia and that all current hemp and drug cultivars diverged from an ancestral gene pool currently represented by feral plants and landraces in China," it said.</p>
<p>Cannabis has been used for millennia for textiles and for its medicinal and recreational properties.</p>
<p>The evolution of the cannabis genome suggests the plant was cultivated for multipurpose use over several millennia.</p>
<p>The current highly-specialized hemp and drug varieties are thought to come from selective cultures initiated about 4,000 years ago, optimized for the production of fibers or cannabinoids.</p>
<p>The selection led to unbranched, tall hemp plants with more fiber in the main stem, and well-branched, short marijuana <a href="https://phys.org/tags/plants/" rel="tag">plants</a> with more flowers, maximizing resin production.</p>
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2021/cannabis-first-domesti.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2021/cannabis-first-domesti.jpg" data-sub-html="Cannabis landraces in Qinghai province, central China. Credit: Guangpeng Ren">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2021/cannabis-first-domesti.jpg" alt="Cannabis first domesticated 12,000 years ago: study" title="Cannabis landraces in Qinghai province, central China. Credit: Guangpeng Ren">
             <figcaption>
                Cannabis landraces in Qinghai province, central China. Credit: Guangpeng Ren
            </figcaption>        </figure>
    </div>
<p><b>'New insights'</b></p>
<p>The study was led by Luca Fumagalli of the University of Lausanne and involved scientists from Britain, China, India, Pakistan, Qatar and Switzerland.</p>
<p>"Our genomic dating suggests that early domesticated ancestors of hemp and drug types diverged from Basal cannabis", around 12,000 years ago, "indicating that the species had already been domesticated by early Neolithic times", it said.</p>
<p>"Contrary to a widely-accepted view, which associates cannabis with a Central Asian center of crop domestication, our results are consistent with a single domestication origin of <a href="https://phys.org/tags/cannabis+sativa/" rel="tag">cannabis sativa</a> in East Asia, in line with early archaeological evidence."</p>
<p>It said that some of the <a href="https://phys.org/tags/wild+plants/" rel="tag">wild plants</a> currently found in China represent the closest descendants of the ancestral gene pool from which hemp and marijuana varieties have since derived.</p>
<p>"East Asia has been shown to be an important ancient hot spot of domestication for several crop species... our results thus add another line of evidence," the study said.</p>
<p>The researchers said their study offered an "unprecedented" base of genomic resources for ongoing molecular breeding and functional research, both in medicine and in agriculture.</p>
<p>The study, they said, also "provides new insights into the domestication and global spread of a plant with divergent structural and biochemical products at a time in which there is a resurgence of interest in its use, reflecting changing social attitudes and corresponding challenges to its legal status in many countries."
                                        
                                                                                </p><hr>										
                                        										
                                        <hr>
                                        																				
                                        											<div>
																								<p><strong>More information:</strong>
												G. Ren el al., "Large-scale whole-genome resequencing unravels the domestication history of Cannabis sativa," <i>Science Advances</i> (2021). <a href="https://advances.sciencemag.org/lookup/doi/10.1126/sciadv.abg2286" target="_blank">advances.sciencemag.org/lookup … .1126/sciadv.abg2286</a></p>
																							</div>
                                        											
										                                                                                    <p>
                                                © 2021 AFP
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Cannabis first domesticated 12,000 years ago: study (2021, July 17)
                                                 retrieved 18 July 2021
                                                 from https://phys.org/news/2021-07-cannabis-domesticated-years.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an app to create repeatable checklists to help with ADHD (215 pts)]]></title>
            <link>https://checkyourlist.app/</link>
            <guid>27871790</guid>
            <pubDate>Sun, 18 Jul 2021 09:57:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://checkyourlist.app/">https://checkyourlist.app/</a>, See on <a href="https://news.ycombinator.com/item?id=27871790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="-1" id="___gatsby"><main><header><a aria-current="page" href="https://checkyourlist.app/"><img src="data:image/svg+xml;base64,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" alt="App Icon" width="64" height="64"></a><a aria-current="page" href="https://checkyourlist.app/"><p>CheckYourList</p></a></header><div><div><h2>Make Repeatable checklists</h2><p>Don't forget your stuff with CheckYourList</p></div><div><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/ec5d678ce42a63bfa53dca35c31e4f52/6436f/checklist-app-screenshot-iphone.webp 150w,/static/ec5d678ce42a63bfa53dca35c31e4f52/80443/checklist-app-screenshot-iphone.webp 300w,/static/ec5d678ce42a63bfa53dca35c31e4f52/dfd81/checklist-app-screenshot-iphone.webp 600w" sizes="(min-width: 600px) 600px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 600px) 600px, 100vw" decoding="async" loading="lazy" data-src="/static/ec5d678ce42a63bfa53dca35c31e4f52/9ba0b/checklist-app-screenshot-iphone.png" data-srcset="/static/ec5d678ce42a63bfa53dca35c31e4f52/61e83/checklist-app-screenshot-iphone.png 150w,/static/ec5d678ce42a63bfa53dca35c31e4f52/00736/checklist-app-screenshot-iphone.png 300w,/static/ec5d678ce42a63bfa53dca35c31e4f52/9ba0b/checklist-app-screenshot-iphone.png 600w" alt="Screenshot of app in iPhone" src="https://checkyourlist.app/static/ec5d678ce42a63bfa53dca35c31e4f52/9ba0b/checklist-app-screenshot-iphone.png" srcset="https://checkyourlist.app/static/ec5d678ce42a63bfa53dca35c31e4f52/61e83/checklist-app-screenshot-iphone.png 150w,https://checkyourlist.app/static/ec5d678ce42a63bfa53dca35c31e4f52/00736/checklist-app-screenshot-iphone.png 300w,https://checkyourlist.app/static/ec5d678ce42a63bfa53dca35c31e4f52/9ba0b/checklist-app-screenshot-iphone.png 600w"></picture></div><div><p>Hi, I'm Spencer and I built this app to help with my ADHD. I found myself forgetting things more and more after the birth of my son. Dropping him at daycare and then going to the gym, required so many things. I felt overwhelmed and would take ages to leave the house. I wanted a solution, so I built this app. Now I run through CheckYourList and am confident I have everything I need.</p><p><a href="https://apps.apple.com/au/app/checkyourlist/id1571623264?itsct=apps_box_link&amp;itscg=30200"><img src="https://checkyourlist.app/static/App-Store-e43df60129791a3526f50daebd6196e3.svg" alt="Apple app store" height="48"></a></p><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/c2dc68c940f74a2ab21c2c5a11c48f6f/eac8d/checklist-app-screenshot-watch.webp 30w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/4f5ab/checklist-app-screenshot-watch.webp 60w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/87026/checklist-app-screenshot-watch.webp 120w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/8fd15/checklist-app-screenshot-watch.webp 240w" sizes="(min-width: 120px) 120px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 120px) 120px, 100vw" decoding="async" loading="lazy" data-src="/static/c2dc68c940f74a2ab21c2c5a11c48f6f/25321/checklist-app-screenshot-watch.png" data-srcset="/static/c2dc68c940f74a2ab21c2c5a11c48f6f/ab90c/checklist-app-screenshot-watch.png 30w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/09c0c/checklist-app-screenshot-watch.png 60w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/25321/checklist-app-screenshot-watch.png 120w,/static/c2dc68c940f74a2ab21c2c5a11c48f6f/0403b/checklist-app-screenshot-watch.png 240w" alt="Screenshot of app in Apple Watch" src="https://checkyourlist.app/static/c2dc68c940f74a2ab21c2c5a11c48f6f/25321/checklist-app-screenshot-watch.png" srcset="https://checkyourlist.app/static/c2dc68c940f74a2ab21c2c5a11c48f6f/ab90c/checklist-app-screenshot-watch.png 30w,https://checkyourlist.app/static/c2dc68c940f74a2ab21c2c5a11c48f6f/09c0c/checklist-app-screenshot-watch.png 60w,https://checkyourlist.app/static/c2dc68c940f74a2ab21c2c5a11c48f6f/25321/checklist-app-screenshot-watch.png 120w,https://checkyourlist.app/static/c2dc68c940f74a2ab21c2c5a11c48f6f/0403b/checklist-app-screenshot-watch.png 240w"></picture></div></div></div><div><div><h3>Feel less forgetful</h3><p>Always feeling like you've forgotten something? Feel organised and free up mental energy. Make repeating checklists so you don't forget your stuff.</p></div><div><h3>Don't be overwhelmed</h3><p>We live in an overwhelming world. It's easy to forget things when leaving the house. CheckYourList is a simple app, designed to make you organised.</p></div><div><h3>Remember your stuff</h3><p>Tired of turning up at the gym without your headphones? Forgot your lunch? Turned up at daycare but forgot your baby?</p></div><div><h3>Stop wasting time</h3><p>Create repeatable checklists when you need to remember things every day. Stop wasting time backtracking and worrying if you have everything. CheckYourList and be confident whenever you leave the house.</p></div></div></div></main></div></div>]]></description>
        </item>
    </channel>
</rss>