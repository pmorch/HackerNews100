<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 08 Apr 2024 10:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Just How Much Faster Are the Gnome 46 Terminals? (107 pts)]]></title>
            <link>https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/</link>
            <guid>39966918</guid>
            <pubDate>Mon, 08 Apr 2024 06:49:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/">https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/</a>, See on <a href="https://news.ycombinator.com/item?id=39966918">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="single">
    

    <p><span>
          Apr 6, 2024 12:00
        </span>
        <span>
          ·
        </span>
        <span>
          
            2408 words
          
        </span>
        <span>
          ·
        </span>
        <span>
          12 minute read
        </span>
    </p>

    <div>
      <p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/header.jpg">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/header.jpg" alt="">
</a>
</p>
<p><a href="https://gitlab.gnome.org/GNOME/vte">VTE</a> (Virtual TErminal library) is the library underpinning various GNOME terminal emulators.
It provides a GTK widget that shows a terminal view, which is used in apps like <a href="https://gitlab.gnome.org/GNOME/gnome-terminal">GNOME Terminal</a>, <a href="https://gitlab.gnome.org/GNOME/console">Console</a>, <a href="https://gitlab.gnome.org/raggesilver/blackbox">Black Box</a>, <a href="https://github.com/gnunn1/tilix">Tilix</a>, <a href="https://github.com/gnome-terminator/terminator">Terminator</a>, <a href="https://gitlab.gnome.org/chergert/ptyxis">Ptyxis</a>, and others.
It also powers embedded terminals in <a href="https://gitlab.gnome.org/GNOME/gnome-builder">Builder</a> and <a href="https://github.com/workbenchdev/Workbench">Workbench</a>.</p>
<p>Over the GNOME&nbsp;46 cycle, VTE has seen a <em>lot</em> of performance improvements.
Christian Hergert mentioned some of them in his blog posts <a href="https://blogs.gnome.org/chergert/2023/10/03/vte-performance-improvements/">about VTE</a> and <a href="https://blogs.gnome.org/chergert/2024/03/25/gnome-45-46-retrospective/">about his work in GNOME&nbsp;46</a>.
But how much did the performance actually improve?
What should you, the user, expect to <em>feel</em> after installing a fresh <a href="https://fedoraproject.org/">Fedora</a> 40 update and launching your favorite terminal?</p>
<p>Let’s measure and find out!
If you don’t have time for measuring, you can <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#input-latency-tests">skip</a> straight to the finding out.</p>
<h2 id="what-are-we-measuring">What Are We Measuring? <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#what-are-we-measuring">#</a></h2><p>There is no shortage of ways to define “performance”, especially when it comes to terminal emulators.
One of the more tangible metrics is <em>input latency</em>.
Roughly, it describes how quickly the program reacts to your actions: how much time passes from the moment you press a key on your keyboard to the change in color of the pixels on your monitor.
Apps with low input latency feel snappy, whereas apps with high input latency can feel sluggish.</p>
<p>When the input latency is small-ish, you can get used to it and think it feels <em>fine</em>.
However, comparing lower and higher input latency together (for example, by switching between two apps and typing in both) can make it quite noticeable.
If you’ve ever heard people say they can’t go back to a 60&nbsp;Hz monitor after trying out 144&nbsp;Hz, that’s a similar effect (and input latency is partially responsible).</p>
<p>So, how do you measure it?</p>
<h3 id="measuring-input-latency">Measuring Input Latency <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#measuring-input-latency">#</a></h3><p>There are tools like <a href="https://pavelfatin.com/typometer/">Typometer</a> that measure the input latency in software by detecting key press events and recording the screen to detect a change in pixel color.
This can work reasonably well but requires fiddling with your setup to make sure you’re not accidentally introducing any biases.
For example, a screen capture API may return the new pixel colors a few milliseconds before or after they are shown on the monitor, depending on the system setup, and you need to be aware of this when trying to measure something to a millisecond precision.</p>
<p>I’ve got something more interesting, a hardware input latency tester!
It consists of a light sensor attached to a <a href="https://www.pjrc.com/store/teensy32.html">Teensy</a> board, which in turn is plugged into the computer via USB.</p>
<figure>
    <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/latency-tester.jpg">
    
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/latency-tester.jpg" width="300" alt="Photo of the latency tester.">
    
    </a>
    <figcaption>
        
    </figcaption>
</figure>

<p>I should really get around to writing a full blog post about this latency tester, but for now, you should read <a href="https://thume.ca/2020/05/20/making-a-latency-tester/">this post by Tristan Hume</a> about building a similar device.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
I used that post as a reference for building mine, but I wrote <a href="https://gist.github.com/YaLTeR/8e8bd0cddb324a9e372b32e742ff992a">my own firmware</a> and analysis scripts (these I am <em>not</em> sharing until they are less of an utter mess).</p>
<p>The main benefit of such a device is that it allows you to measure a full end-to-end input latency, including processing time in the kernel, the compositor, the application, and then the response time of the monitor itself.
You are measuring what you really see and feel, excluding only the keyboard firmware (since the latency tester sends key press events directly over USB).
There’s also very little extra load on the system, especially compared to using something like a screen capture API.</p>
<p>Here’s a gist of how it works.
The light sensor is aimed at a specific, small area on the monitor, which will be affected by the key press (in our case, a specific character cell in the terminal).
The board sends a key press over USB (for example, Space) and starts monitoring the light sensor readings.
As soon as it detects a jump in the light amount, it releases the key.
Then, it presses a second key (for example, Backspace) and waits for the light to change back.
Now we’re back to square one; the firmware waits a randomized amount (to prevent “snapping” to the monitor refresh rate) and repeats the experiment.</p>
<p>During all of this process, the board dumps light sensor readings over a serial port as fast as it can manage (I’m getting about 35,500 readings per second with my current board and firmware).
On the computer, I save all of this data into a file for offline analysis with Python code.
This analysis code finds the timestamp where the light starts to change, and subtracts it from the timestamp of the key press, to get one input latency measurement.</p>
<p>I then aggregate the measurements and plot them with <a href="https://seaborn.pydata.org/">seaborn</a>.
Here’s an example of what the result looks like:</p>
<figure>
    <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/example-latency.png">
    
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/example-latency.png" width="200">
    
    </a>
    <figcaption>
        
    </figcaption>
</figure>

<h3 id="input-latency-plots">Input Latency Plots <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#input-latency-plots">#</a></h3><p>Let’s explore what you can find on this latency plot.</p>
<figure>
    <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/example-latency-breakdown.png">
    
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/example-latency-breakdown.png" width="500">
    
    </a>
    <figcaption>
        
    </figcaption>
</figure>

<p>The small black dots represent the individual measurements.
As in, every dot shows a real amount of time that had passed between one key press and the corresponding change in light on the sensor.
There are 120 of these dots since I repeat each test 120 times.</p>
<p>Looking at the dots can confirm that the data is sensible.
We expect the bulk of the measurements to be spread uniformly across an interval roughly the size of one monitor repaint cycle.
This is because monitors generally repaint at a constant rate, and pressing a key at a random point in time should land us in a random point of the repaint cycle.
We get the lowest latency if the application renders a new frame in response right in time for the monitor to show it.
And we get the highest latency when the application finishes rendering a new frame <em>just</em> missing the monitor deadline, having to wait one extra repaint cycle for the pixel colors to change.</p>
<p>In the example above, the dots are spread over 7–8&nbsp;ms, which is about equal to the ~6.94&nbsp;ms refresh cycle of my 144&nbsp;Hz monitor.</p>
<p>High outliers in the dots, or a larger spread, indicate lag or slowness of the application under test: some key presses are taking longer than others to process.</p>
<p>We do not expect to see any gaps between dot clusters.
They would usually indicate aliasing with the monitor repaint cycle, or some frame scheduling bug in the compositor.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>The box shows statistics over the individual measurements:</p>
<ul>
<li>median (a measurement perfectly “in the middle” with half of the measurements lower and half of the measurements higher),</li>
<li>lowest and highest measurement,</li>
<li>25th and 75th percentiles (with 25% and 75% of the measurements lower than the line, respectively).</li>
</ul>
<p>All in all, you can compare applications by their spread, then by the median latency, and also look if there are any outliers.</p>
<p>With all that said, we’re <em>almost</em> ready to look at some results.
I just need to tell you what exactly I was measuring the latency of.</p>
<h2 id="test-setup">Test Setup <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#test-setup">#</a></h2><p>I did all tests on this system:</p>
<ul>
<li><a href="https://www.lenovo.com/us/en/p/laptops/legion-laptops/legion-7-series/legion-7-gen-7-%2816-inch-amd%29/len101g0017">Lenovo Legion 7 Gen 7 AMD</a> with Ryzen 7 6800H CPU and Radeon RX 6700M dGPU (using the dGPU exclusively via the MUX switch).</li>
<li>Monitor: <a href="https://www.acer.com/il-en/monitors/gaming/nitro-xv0/pdp/UM.JX0EE.V01">Acer Nitro XV320QU</a>, 2560×1440, 144&nbsp;Hz, using 100% scale.</li>
<li>Host: Fedora&nbsp;40 Silverblue Beta, Mesa&nbsp;24.0.4.</li>
<li>Compositor: raw Mutter&nbsp;46.0.</li>
</ul>
<p>What is raw Mutter, you may ask?
Well, Mutter is the compositor that GNOME Shell builds on top of.
Turns out, you can start Mutter on its own, without GNOME Shell, by switching to a different VT and running a command like <code>mutter --display-server -- alacritty</code>.
This gives you a very bare-bones environment that is only really meant for testing.
It is, however, quite useful for benchmarking, as it represents something close to a zero-overhead GNOME Shell ideal case.</p>
<p>I’m testing several terminal applications.
In the order of appearance on the plots, they are:</p>
<ul>
<li><a href="https://github.com/alacritty/alacritty">Alacritty</a>: not VTE-based; serves as a baseline of sorts, because it is consistently one of the fastest terminals according to <a href="https://mastodon.online/@YaLTeR/110837121102628111">all of my prior tests</a>.</li>
<li><a href="https://gitlab.gnome.org/GNOME/console">Console</a>: GTK&nbsp;4, the default terminal in GNOME.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
<li><a href="https://gitlab.gnome.org/GNOME/vte/-/tree/0.76.0/src/app">VTE Test App</a>: GTK&nbsp;4, a test terminal that lives in the VTE repository.</li>
<li><a href="https://gitlab.gnome.org/GNOME/gnome-terminal">GNOME Terminal</a>: GTK&nbsp;3,<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> used to be the default in GNOME, and is still shipped out of the box in several distributions.</li>
</ul>
<p>Since the intention is to compare GNOME&nbsp;45 to GNOME&nbsp;46, I used <a href="https://containertoolbx.org/">toolb<span>\0</span>x</a> containers with Fedora&nbsp;39 and Fedora&nbsp;40 to install and run all terminals above, as packaged by Fedora with no extra tweaks.</p>
<p>I ran the terminals one by one and put their windows in the top left corner of the monitor.
The mouse cursor was outside the window for all tests.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p>
<h2 id="input-latency-tests">Input Latency Tests <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#input-latency-tests">#</a></h2><p>The first test is simple: I run <code>cat &gt; /dev/null</code> to get an input field with no readline or similar processing, and then I measure how long it takes for the terminal to move its block cursor one cell to the right after pressing Space.</p>
<p>This is meant to test the best possible scenario for the terminal, with the least overhead.</p>
<p>This is what the test process looks like:</p>
<figure>
    <video controls="" src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/test-kgx-cat.mp4"></video>
    <figcaption>
        
    </figcaption>
</figure>

<p>And here are the results:</p>
<p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-cat.png">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-cat.png" alt="">
</a>
</p>
<p>Alacritty, which is our baseline, did not change from F39 to F40, as expected.</p>
<p>But look at the massive improvement on all of the VTE terminals!
They went from <em>quite bad</em> to pretty much on par with Alacritty, even the GTK&nbsp;3 GNOME Terminal is very close.</p>
<p>The main change that caused this much improvement is likely <a href="https://gitlab.gnome.org/GNOME/vte/-/commit/c17d9c6b4571be0ab55c3818d9125233553bb7ee">this one by Christian</a> that moves away from a 40&nbsp;Hz VTE repaint timer to drawing every frame, synchronized with the monitor, as any self-respecting GTK widget should do.</p>
<p>Console has a few outliers which are <em>maybe</em> caused by its process tracking, but those are nothing new (they may be looked into for GNOME&nbsp;47).</p>
<p>For the next test, I constructed a more realistic case.
I took <a href="https://github.com/YaLTeR/dotfiles/tree/d3976398058f2f5b6eee57c7e656ee8e7f098ac5/common/.config/_nvim_latency">a snapshot of my neovim setup</a> and opened the README from <a href="https://gitlab.gnome.org/chergert/ptyxis">Ptyxis</a>.
I then strategically replaced a square of text with Unicode full-block characters to provide a bright “landing pad” for the light sensor.</p>
<figure>
    <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/test-kgx-nvim.png">
    
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/test-kgx-nvim.png" width="480">
    
    </a>
    <figcaption>
        
    </figcaption>
</figure>

<p>The test consists of repeatedly pressing Ctrl+D and Ctrl+U to scroll the text buffer down and up in neovim.
The light sensor alternates between an empty line (dark) and the full-block landing pad (bright).
The neovim setup has a bunch of bells and whistles, so the terminal gets to have fun drawing the various underlines, undercurls, gutter icons, and the statusline.</p>
<p>This is what the test process looks like:</p>
<figure>
    <video controls="" src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/test-kgx-nvim.mp4"></video>
    <figcaption>
        
    </figcaption>
</figure>

<p>Here are the results:</p>
<p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-nvim.png">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-nvim.png" alt="">
</a>
</p>
<p>The massive improvement is clear on this test too, and our GNOME&nbsp;46 terminals are still pretty much on par with Alacritty!</p>
<p>Finally, let’s take a closer look at all Fedora&nbsp;40 results on one plot:</p>
<p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-f40.png">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/all-f40.png" alt="">
</a>
</p>
<p>This plot shows how much of a latency toll the neovim test takes compared to a simple <code>cat</code>, but the latency increase is similar across all terminals.</p>
<h2 id="vtebench">vtebench <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#vtebench">#</a></h2><p>I also ran Alacritty’s <a href="https://github.com/alacritty/vtebench">vtebench</a> suite across the same set of applications and configurations.
This is a fully automated benchmark that measures something <em>completely different</em> from input latency: PTY read and parsing performance.
<del>It has also proven quite capable at finding <a href="https://gitlab.gnome.org/GNOME/vte/-/issues/2747">crashes</a> in VTE.</del></p>
<p>Here’s what vtebench’s README has to say:</p>
<blockquote>
<p>This benchmark is not sufficient to get a general understanding of the performance of a terminal emulator. It lacks support for critical factors like frame rate or latency. The only factor this benchmark stresses is the speed at which a terminal reads from the PTY. If you do not understand what this means, please do not jump to any conclusions from the results of this benchmark.</p>
</blockquote>
<p>The repaint duration can and does affect the results of this test, especially for terminals that read and parse PTY on the same thread as they run their repaint logic, like VTE.</p>
<p>This is what one of the vtebench benchmarks looks like:</p>
<p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench-kgx.jpg">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench-kgx.jpg" alt="">
</a>
</p>
<p>And here are the results:</p>
<figure>
    <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench.png">
    
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench.png">
    
    </a>
    <figcaption>
        <p>To avoid making this plot even busier, I drew the green arrows on only one of the benchmarks.
As you can see, other benchmarks show a similar trend.</p>

    </figcaption>
</figure>

<p>VTE from GNOME&nbsp;46 shows some welcome improvements here too, although a lot more varied, and not quite on par with Alacritty (which renders in a separate thread from reading and parsing).
These improvements likely come from the many other optimizations that happened in VTE during the GNOME&nbsp;46 cycle.</p>
<p>Note that I omitted two benchmarks from these results: <code>dense_cells</code> and <code>unicode</code>.
They are the main stress tests of vtebench that hit the terminal really hard.
Unfortunately, VTE still struggles with them and shows a huge spread, which pushes the rest of the results down and makes the plot less readable.</p>
<details>
    <summary>Open this to see the full results if you’re curious.</summary>
    <p><a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench-full.png">
    <img src="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/vtebench-full.png" alt="">
</a>
</p>

</details>

<h2 id="conclusion">Conclusion <a href="https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/#conclusion">#</a></h2><p>VTE had a round of massive performance improvements in GNOME&nbsp;46 which manifest as something you can really feel during normal terminal use.
The input latency is down to almost matching the fastest terminals, even in a non-trivial neovim setup with lots of complexity on screen.</p>
<p>The remaining difference, at least on these test cases, is close to negligible.
Some of it can be explained by VTE doing a bit more extra work for accessibility (enabled in GNOME Terminal and currently disabled in the GTK&nbsp;4 terminals), scrollbar calculations, and other features.</p>
<p>If you’ve been avoiding VTE-based terminals due to <em>sluggishness</em> and input lag, now is the time to give them another chance.
Just make sure you’re running VTE&nbsp;0.76, which includes all of this goodness.</p>
<p>Huge thanks to the VTE maintainers and contributors for making this a reality, and congratulations on an awesome release!</p>
<p>P.S. If you’re curious about Ptyxis or the behavior of GTK’s NGL vs. NVK vs. GL renderers, they all perform similarly to the F40 VTE Test App results shown above.
I did more extensive benchmarks of these a month ago, you can find them <a href="https://gitlab.gnome.org/-/snippets/6439">here</a>.</p>


    </div>

    
        
    
    
    

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify demonetizes all tracks under 1k streams (211 pts)]]></title>
            <link>https://djmag.com/news/spotify-officially-demonetises-all-tracks-under-1000-streams</link>
            <guid>39966743</guid>
            <pubDate>Mon, 08 Apr 2024 06:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://djmag.com/news/spotify-officially-demonetises-all-tracks-under-1000-streams">https://djmag.com/news/spotify-officially-demonetises-all-tracks-under-1000-streams</a>, See on <a href="https://news.ycombinator.com/item?id=39966743">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content" role="main">
<a id="main-content"></a>
<div id="block-djmag-content">
<article>

<div>
<div role="text">
<p>Spotify has officially demonetised all tracks with under 1,000 streams. The new policy came into effect for all artists in 1st April 2024.&nbsp;</p>
<p>The revised revenue scheme was <a href="https://djmag.com/news/spotify-confirms-new-royalty-policy-eliminating-payments-tracks-under-1000-streams">announced last year</a>, and means music will only be included in the royalty pool calculation if it passes a threshold of 1,000 plays in the preceding 12 months. According to a Spotify <a href="https://artists.spotify.com/en/blog/modernizing-our-royalty-system" target="_blank" rel="noreferrer external nofollow">blog post</a>, 99.5% of all streams on the platform are of tracks that have above that many plays, with the platform claiming that these tracks will now earn more as a result.&nbsp;</p>
</div>
<div role="text">
<p>Additionally, Spotify now requires a minimum number of unique listeners for royalties to apply. This attempt to stop "further manipulation by bad actors" targets people using automatic and artificial plays to ramp up stream counts. Meanwhile, "functional" genres, such as white noise, are being targeted, too. Whereas before these types of recordings could generate income from as little as 30 seconds of play, this has now been increased to two minutes.&nbsp;</p>
<p>However, the change has been met with anger and frustration from some corners of the music industry. This week, United Musicians and Allied Workers shared a post on X which suggested those numbers could be wildly overstated,&nbsp;arguing that 86% of all content on Spotify will now fail to meet the criteria for royalties based on play count.&nbsp;</p>
</div>

<div role="text">
<p>United Musicians and Allied Workers recently&nbsp;spearheaded the Make Streaming Pay initiative, demanding fairer revenue split for artists using platforms including Spotify and Apple Music. The campaign is behind a new <a href="https://djmag.com/news/living-wage-musicians-bill-aims-increase-streaming-royalties-artists">Living Wage For Musicians Bill</a>, which was introduced to US congress in March and aims to "ensure that artists and musicians can build sustainable careers in the digital age". You can find out more about this <a href="https://weareumaw.org/make-streaming-pay" target="_blank" rel="noreferrer external nofollow">here</a>.&nbsp;</p>
<p>While political and public pressure for better royalty payments grows, Spotify is looking to bring in more revenue to plug its own shortfall. Since going public on the stock market in 2018, the company has lost money every year. Just this week, it was reported that the streaming giant has confirmed intentions to <a href="https://www.bloomberg.com/news/articles/2024-04-03/spotify-is-changing-how-it-charges-customers-with-new-plans-and-prices?utm_medium=email&amp;utm_source=newsletter&amp;utm_term=240403&amp;utm_campaign=author_18846812&amp;embedded-checkout=true" target="_blank" rel="noreferrer external nofollow">revise and increase its pricing.</a></p>
<p>Between $1 and $2 will be added to monthly bills for customers in several territories,&nbsp;including the UK, Australia, and Pakistan, <em>Bloomburg&nbsp;</em>reports. This is said to cover the cost of audiobooks, added to the platform late-2023. More recently, <a href="https://djmag.com/tech/spotify-adds-video-learning-content-music-performance-and-production">video learning content</a> was introduced to further diversify the offering. A&nbsp;new basic tier package will be rolled out for those who do not want to access audiobooks, the first of several updated pricing options. This news led to a 4.6% jump in Spotify's share value, although it's unclear what the long-term impact will be.</p>
</div>


</div>
</article>
</div>


</section><div id="block-views-block-related-content-related-content" role="contentinfo">
<p>
<h3>Related Content</h3>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infant microbes and metabolites point to childhood neurodevelopmental disorders (104 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-04-autism-adhd-linked-disturbed-gut.html</link>
            <guid>39965446</guid>
            <pubDate>Mon, 08 Apr 2024 01:30:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-04-autism-adhd-linked-disturbed-gut.html">https://medicalxpress.com/news/2024-04-autism-adhd-linked-disturbed-gut.html</a>, See on <a href="https://news.ycombinator.com/item?id=39965446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/autism-and-adhd-are-li.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/autism-and-adhd-are-li.jpg" data-sub-html="Credit: <i>Cell</i> (2024). DOI: 10.1016/j.cell.2024.02.035">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/autism-and-adhd-are-li.jpg" alt="Autism and ADHD are linked to disturbed gut flora very early in life" title="Credit: Cell (2024). DOI: 10.1016/j.cell.2024.02.035" width="800" height="530">
             <figcaption>
                Credit: <i>Cell</i> (2024). DOI: 10.1016/j.cell.2024.02.035
            </figcaption>        </figure>
    </div><p>Disturbed gut flora during the first years of life is associated with diagnoses such as autism and ADHD later in life. This is according to a study led by researchers at the University of Florida and Linköping University and <a href="https://doi.org/10.1016/j.cell.2024.02.035" target="_blank">published</a> in the journal <i>Cell</i>.</p>


                                        
                                                                                  
                                        
                                                                                                                                    <p>The study is the first forward-looking, or prospective, study to examine gut flora composition and a large variety of other factors in infants, in relation to the development of the children's nervous system. The researchers have found many biological markers that seem to be associated with future neurological development disorders, such as autism spectrum disorder, ADHD, communication disorder and intellectual disability.</p>
<p>"The remarkable aspect of the work is that these biomarkers are found at birth in cord blood or in the child's stool at one year of age over a decade prior to the diagnosis," says Eric W Triplett, professor at the Department of Microbiology and Cell Science at the University of Florida, U.S., one of the researchers who led the study.</p>
<p>The study is part of the ABIS (All Babies in Southeast Sweden) study led by Johnny Ludvigsson at Linköping University. More than 16,000 children born in 1997–1999, representing the general population, have been followed from birth into their twenties. Of these, 1,197 children, corresponding to 7.3%, have been diagnosed with autism spectrum disorder, ADHD, communication disorder or intellectual disability.</p>
<p>A large number of lifestyle and environmental factors have been identified through surveys conducted on several occasions during the children's upbringing. For some of the children, the researchers have analyzed substances in <a href="https://medicalxpress.com/tags/umbilical+cord+blood/" rel="tag">umbilical cord blood</a> and bacteria in their stool at the age of 1.</p>

                                                                                                        <!-- Google middle Adsense block -->
    
                                                                                                                                            <p>"We can see in the study that there are clear differences in the intestinal flora already during the first year of life between those who develop autism or ADHD and those who don't. We've found associations with some factors that affect gut bacteria, such as antibiotic treatment during the child's first year, which is linked to an increased risk of these diseases," says Ludvigsson, senior professor at the Department of Biomedical and Clinical Sciences at Linköping University, who led the study together with Triplett.</p>
<p>Children who had repeated ear infections during their first year of life had an increased risk of being diagnosed with a developmental neurological disorder later in life. It is probably not the infection itself that is the culprit, but the researchers suspect a link to antibiotic treatment. They found that the presence of Citrobacter bacteria or the absence of Coprococcus bacteria increased the risk of future diagnosis.</p>
<p>One possible explanation may be that antibiotic treatment has disturbed the composition of the gut flora in a way that contributes to neurodevelopmental disorders. The risk of <a href="https://medicalxpress.com/tags/antibiotic+treatment/" rel="tag">antibiotic treatment</a> damaging the gut flora and increasing the risk of diseases linked to the immune system, such as type 1 diabetes and childhood rheumatism, has been shown in previous studies.</p>
<p>"Coprococcus and Akkermansia muciniphila have potential protective effects. These bacteria were correlated with important substances in the stool, such as vitamin B and precursors to neurotransmitters which play vital roles orchestrating signaling in the brain. Overall, we saw deficits in these bacteria in children who later received a developmental neurological diagnosis," says Angelica Ahrens, Assistant Scientist in Triplett's research group at the University of Florida and the first author of this study.</p>

                                                                                                                                            <p>The present study also confirms that the risk of developmental neurological diagnosis in the child increases if the parents smoke. Conversely, breastfeeding has a protective effect, according to the study.</p>
<p>In cord blood taken at the birth of children, the researchers analyzed the amounts of various substances from the body's metabolism, such as <a href="https://medicalxpress.com/tags/fatty+acids/" rel="tag">fatty acids</a> and amino acids. They also measured some harmful substances that come from outside, such as nicotine and environmental toxins. They compared substances in the umbilical cord blood of 27 children diagnosed with autism with the same number of children without a diagnosis.</p>
<p>It turned out that children who were later diagnosed had low levels of several important fats in the umbilical cord blood. One of these was linolenic acid, which is needed for the formation of omega 3 fatty acids that are anti-inflammatory and have several other effects in the brain.</p>
<p>The same group also had higher levels than the control group of a PFAS substance, a group of substances used as flame retardants and shown to negatively affect the immune system in several different ways. PFAS substances can enter the body via drinking water, food and the air we breathe.</p>
<p>It is not certain that the relationships that the research team found in the Swedish children can be generalized to other populations, but these issues need to be studied in other groups as well. Another question is whether gut flora imbalance is a triggering factor or whether it has occurred as a result of underlying factors, such as diet or antibiotics.</p>
<p>However, even when the researchers accounted for risk factors that might affect the gut flora, they found that the link between future diagnosis remained for many of the bacteria. This indicates that some of the differences in gut flora between children with and without future diagnosis are not explained by such risk factors.</p>
<p>The research is at an early stage and more studies are needed, but the discovery that many biomarkers for future developmental neurological disorders can be observed at an early age opens up the possibility of developing screening protocols and <a href="https://medicalxpress.com/tags/preventive+measures/" rel="tag">preventive measures</a> in the long term.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Angelica P. Ahrens et al, Infant microbes and metabolites point to childhood neurodevelopmental disorders, <i>Cell</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2024.02.035" target="_blank">DOI: 10.1016/j.cell.2024.02.035</a>
																								
																								</p><div>
													<p><strong>Journal information:</strong>
																											<a href="https://medicalxpress.com/journals/cell/"><cite>Cell</cite></a></p><a href="http://www.cell.com/" target="_blank" rel="nofollow">
															<svg>
																<use href="https://medx.b-cdn.net/tmpl/v6/img/svg/sprite.svg#icon_open" x="0" y="0"></use>
															</svg>
														</a> 
																									</div>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Autism and ADHD are linked to disturbed gut flora very early in life (2024, April 4)
                                                 retrieved 8 April 2024
                                                 from https://medicalxpress.com/news/2024-04-autism-adhd-linked-disturbed-gut.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Groq CEO: 'We No Longer Sell Hardware' (161 pts)]]></title>
            <link>https://www.eetimes.com/groq-ceo-we-no-longer-sell-hardware/</link>
            <guid>39964590</guid>
            <pubDate>Sun, 07 Apr 2024 22:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eetimes.com/groq-ceo-we-no-longer-sell-hardware/">https://www.eetimes.com/groq-ceo-we-no-longer-sell-hardware/</a>, See on <a href="https://news.ycombinator.com/item?id=39964590">Hacker News</a></p>
Couldn't get https://www.eetimes.com/groq-ceo-we-no-longer-sell-hardware/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Xkcd 1928: Seven Years (2017) (119 pts)]]></title>
            <link>https://xkcd.com/1928/</link>
            <guid>39963643</guid>
            <pubDate>Sun, 07 Apr 2024 20:33:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xkcd.com/1928/">https://xkcd.com/1928/</a>, See on <a href="https://news.ycombinator.com/item?id=39963643">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="topRight">
<p><span><a href="https://xkcd.com/"><img src="https://xkcd.com/s/0b7742.png" alt="xkcd.com logo" height="83" width="185"></a></span>
<span id="slogan">A webcomic of romance,<br> sarcasm, math, and language.</span>
</p>
<p>
Becky Beaton, sister of fellow cartoonist Kate Beaton, has also been diagnosed with cancer. You can support her treatment <a href="https://www.youcaring.com/beckybeaton-1008390">here</a>.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook banned website that links to critical article, claims phishing (105 pts)]]></title>
            <link>https://bsky.app/profile/mosseri.bsky.social/post/3kpimfpxjkh2r</link>
            <guid>39962644</guid>
            <pubDate>Sun, 07 Apr 2024 18:24:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/mosseri.bsky.social/post/3kpimfpxjkh2r">https://bsky.app/profile/mosseri.bsky.social/post/3kpimfpxjkh2r</a>, See on <a href="https://news.ycombinator.com/item?id=39962644">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Xemu: Original Xbox Emulator (160 pts)]]></title>
            <link>https://xemu.app/</link>
            <guid>39962184</guid>
            <pubDate>Sun, 07 Apr 2024 17:18:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xemu.app/">https://xemu.app/</a>, See on <a href="https://news.ycombinator.com/item?id=39962184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main"><div><p><img id="xbox-logo" src="https://xemu.app/xbox_logo.png" width="450"></p><div><h2><canvas id="logo-canvas"></canvas> <img alt="xemu logo" id="logo-fallback" src="https://xemu.app/logo-green-jumbotron.svg"></h2><h4>Original Xbox Emulator</h4><p>A free and open-source application that emulates the original Microsoft Xbox game console, enabling people to play their original Xbox games on Windows, macOS, and Linux systems.</p><div><p>Version 0.7.120 (Mar 23, 2024) <br></p></div></div></div><div><p><img src="https://xemu.app/linux_title_bar_dark_2x.png"></p></div><div><div><h4><i></i>Open Source</h4><p>The source code for xemu is available on <a href="https://github.com/xemu-project/xemu">GitHub</a>. You are invited to help improve the project! Learn more <a href="https://xemu.app/docs/dev/">here</a>.</p></div><div><h4><i></i>Cross Platform</h4><p>xemu runs natively on Windows, macOS, and Linux platforms. Binaries are available for all platforms, or you can build from source if desired. Learn more <a href="https://xemu.app/docs/download/">here</a>.</p></div><div><h4><i></i>Low Level Emulation</h4><p>xemu emulates the hardware of the original Xbox, providing superior compatibility with kernels, titles, and homebrew applications.</p></div><div><h4><i></i>Controller Support</h4><p>Built on <a href="https://www.libsdl.org/">SDL2</a>, xemu supports virtually all controllers. Connect up to 4 controllers at any time, just like a real Xbox. Learn more <a href="https://xemu.app/docs/input/">here</a>.</p></div><div><h4><i></i>Snapshots (Save States)</h4><p>No need to wait for game checkpoints. xemu supports saving the current machine state and loading it back up at any time. Learn more <a href="https://xemu.app/docs/snapshots/">here</a>.</p></div><div><h4><i></i>Render Scaling</h4><p>Breathe new life into your original Xbox games by easily increasing the resolution that games render at, on the fly. Scale up from 480p to 1080p at the click of a button.</p></div><div><h4><i></i>Networking</h4><p>Connect to other instances of xemu and real Xboxes, locally or over the Internet. Supports tunneling services and Xbox Live recreation projects. Learn more <a href="https://xemu.app/docs/networking/">here</a>.</p></div><div><h4><i></i>Community</h4><p>xemu has a thriving online community of original Xbox fans. Set up multiplayer matches, get help running xemu, and more by joining our community on <a href="https://discord.gg/ayyjsuM">Discord</a>!</p></div></div><div><h2 id="compatibility">Compatibility</h2><div><p><b>Note:</b> Title compatibility status is provided by volunteer reporters in the community, as the reporter experienced the title in the current version of xemu on their computer at time of reporting. As the project evolves, reports may need to be updated. You are invited to help improve the project by submitting an updated compatibility report. Join the Discord server to learn how to contribute!</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PumpkinOS, a Re-Implementation of PalmOS (316 pts)]]></title>
            <link>https://github.com/migueletto/PumpkinOS</link>
            <guid>39962023</guid>
            <pubDate>Sun, 07 Apr 2024 16:55:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/migueletto/PumpkinOS">https://github.com/migueletto/PumpkinOS</a>, See on <a href="https://news.ycombinator.com/item?id=39962023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">PumpkinOS</h2><a id="user-content-pumpkinos" aria-label="Permalink: PumpkinOS" href="#pumpkinos"></a></p>
<p dir="auto">PumpkinOS is a re-implementation of PalmOS that runs on modern architectures (x86, ARM, etc).
It is not your average PalmOS emulator (it does NOT require a PalmOS ROM), but it can run m68K PalmOS applications.
For a series of articles describing various aspects of PumpkinOS, look here: <a href="https://pmig96.wordpress.com/category/palmos/" rel="nofollow">https://pmig96.wordpress.com/category/palmos/</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/migueletto/PumpkinOS/blob/master/screenshots/pumpkin.png"><img src="https://github.com/migueletto/PumpkinOS/raw/master/screenshots/pumpkin.png" alt=""></a></p>
<p dir="auto">Launcher is the first application that runs when PumpkinOS starts. It shows a panel from which you can start other applications.
Preferences will eventually contain all preference options for configuring PumpkinOS.
Command is a command shell, still experimental.</p>
<p dir="auto">This release contains the four PIM applications found on PalmOS: AddressBook, MemoPad, ToDoList and DateBook. The source code for these applications
were distributed in one or more PalmOS SDks and were adapted for correct compilation on PumpkinOS.
Records created by AddressBook and MemoPad should be compatible with their PalmOS counterparts. Because of differences in
word size en endianness, however, records created by ToDoList and DateBook are not compatible.
These applications were tested just to the point where I could create and edit a few records. There are still some quirks, and some functions were not tested at all.
The goal here is just to offer a view of what to expect from PumpkinOS in the future.</p>
<p dir="auto">I am planing to setup a bug tracker to document enhancements and bugs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licensing</h2><a id="user-content-licensing" aria-label="Permalink: Licensing" href="#licensing"></a></p>
<p dir="auto">PumpkinOS is licensed under the GPL v3.
The license directory contains information on specific licenses of the various components used in PumpkinOS.
If you think something is missing and/or incorrect, please let me know.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">You have to build PumpkinOS from source. No IDE is required, you can build from the command line.
If you use 64-bits Windows, you can use MSYS2 (<a href="https://www.msys2.org/" rel="nofollow">https://www.msys2.org/</a>). Download the installer and follow the instructions there.
Open a MINGW64 terminal (the one with the blue 'M' icon) and install these additional packages:</p>
<div data-snippet-clipboard-copy-content="pacman -S gcc binutils make git"><pre><code>pacman -S gcc binutils make git
</code></pre></div>
<p dir="auto">Next clone the PumpkinOS repository:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/migueletto/PumpkinOS.git"><pre><code>git clone https://github.com/migueletto/PumpkinOS.git
</code></pre></div>
<p dir="auto">Finally go to the source directory of the PumpkinOS repository you have just cloned and run the make script:</p>
<div data-snippet-clipboard-copy-content="cd PumpkinOS/src
./mk.sh Msys 64"><pre><code>cd PumpkinOS/src
./mk.sh Msys 64
</code></pre></div>
<p dir="auto">If everything goes well, you will have a pumpkin.exe in the root directory, some DLLs in the bin directory, and some PRC files in the vfs/app_install directory.</p>
<p dir="auto">There is also experimental support for 32-bits Windows (Vista or later. It will not work on Windows XP).
Open a MINGW32 terminal (the one with the gray 'M' icon) and install this additional package:</p>
<div data-snippet-clipboard-copy-content="pacman -S mingw-w64-i686-gcc"><pre><code>pacman -S mingw-w64-i686-gcc
</code></pre></div>
<p dir="auto">From there, compile using (note that now argument is 32, for 32-bits):</p>
<div data-snippet-clipboard-copy-content="cd PumpkinOS/src
./mk.sh Msys 32"><pre><code>cd PumpkinOS/src
./mk.sh Msys 32
</code></pre></div>
<p dir="auto">If you are using a 64-bits Linux-based OS (like Debian, Ubuntu, etc), you also need gcc, binutils, make and git. If you are a developer,
there is a chance you already have those. If they are not installed, follow the instructions to download additional packages on your specific Linux distribution.
You must also install the SDL2 development package (the package that contains the libraries and the headers). On a Debian distribution, it is probably something like:</p>
<div data-snippet-clipboard-copy-content="sudo apt install gcc binutils make git libsdl2-dev"><pre><code>sudo apt install gcc binutils make git libsdl2-dev
</code></pre></div>
<p dir="auto">Again, you must clone the repository and compile it using:</p>
<div data-snippet-clipboard-copy-content="cd PumpkinOS/src
./mk.sh GNU/Linux 64"><pre><code>cd PumpkinOS/src
./mk.sh GNU/Linux 64
</code></pre></div>
<p dir="auto">On Windows 11 and recent releases of Windows 10, it is also possible to build PumpkinOS on WSL (Windows Subsystem for Linux, version 2).
Open a WSL terminal and follow the same instructions for a Linux build.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running</h2><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">On 64-bits Windows, run pumpkin.bat. On 32-bits Windows, run pumpkin32.bat. On Linux or WSL, run pumpkin.sh. PumpkinOS will open on a new window.
On WSL you may need to run a X-Window Manager, otherwise the PumpkinOS window will not have a border.</p>
<p dir="auto">When you run PumpkinOS, all PRCs inside vfs/app_install will be removed and expanded into folders inside vfs/app_storage.
Please keep in mind that everything is pretty much experimental at this stage, so expect a few issues here and there.
After either a successful or an unsuccessful run, you will find a pumpkin.log file on the root directory.
If something goes wrong, look for lines marked with an "E" on the third column of this file.
You can reach me for questions (and send me your log file if you wish).</p>
<p dir="auto">The Windows version implements Drag &amp; Drop functionality. You can drag a PalmOS PRC over the PumpkinOS window and hopefully
it will be installed and show up in the Launcher. The Linux version lacks this functionality. For now, you have to manually copy PRCs
to the vfs/app_install directory and restart PumpkinOS.</p>
<p dir="auto">If you really want to, you can debug PumpkinOS with gdb on Windows, Linux and WSL. On Windows, edit pumpkin.bat and change the last line to (you should also add the Windows equivalent of the /usr/bin directory of your MSYS2 installation the the PATH):</p>
<div data-snippet-clipboard-copy-content="gdb.exe --args .\pumpkin.exe -d 1 -f pumpkin.log -s libscriptlua.dll script\pumpkin_windows.lua"><pre><code>gdb.exe --args .\pumpkin.exe -d 1 -f pumpkin.log -s libscriptlua.dll script\pumpkin_windows.lua
</code></pre></div>
<p dir="auto">On Linux and WSL edit pumpkin.sh and change the last line to:</p>
<div data-snippet-clipboard-copy-content="gdb --args ./pumpkin -d 1 -f pumpkin.log -s libscriptlua.so ./script/pumpkin_linux.lua"><pre><code>gdb --args ./pumpkin -d 1 -f pumpkin.log -s libscriptlua.so ./script/pumpkin_linux.lua
</code></pre></div>
<p dir="auto">I am writing a full Wiki article on source level debuging PumpkinOS.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rpgp: Pure Rust implementation of OpenPGP (153 pts)]]></title>
            <link>https://github.com/rpgp/rpgp</link>
            <guid>39961994</guid>
            <pubDate>Sun, 07 Apr 2024 16:50:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rpgp/rpgp">https://github.com/rpgp/rpgp</a>, See on <a href="https://news.ycombinator.com/item?id=39961994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">rPGP</h2><a id="user-content-rpgp" aria-label="Permalink: rPGP" href="#rpgp"></a></p>
<p dir="auto"><a href="https://crates.io/crates/pgp" rel="nofollow"><img src="https://camo.githubusercontent.com/10e1dfae1eaa5abb346385ac94190b36ba0a4a7537ef6e8d320369e3233c8ce2/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f7067702e7376673f7374796c653d666c61742d737175617265" alt="crates.io" data-canonical-src="https://img.shields.io/crates/v/pgp.svg?style=flat-square"></a>
<a href="https://docs.rs/crate/pgp/" rel="nofollow"><img src="https://camo.githubusercontent.com/b5f09ebb64a35fd5c5c38e5e7a4727df4b0b833e987a210d5250fee2d62b7227/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6f6e6c696e652d626c75652e7376673f7374796c653d666c61742d737175617265" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-online-blue.svg?style=flat-square"></a>
<a href="https://github.com/rpgp/rpgp/actions?query=workflow%3ACI+branch%3Amaster"><img src="https://github.com/rpgp/rpgp/actions/workflows/ci.yml/badge.svg" alt="Build Status"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/46a8c8f591a66778ad0fb692f11b6efe5362f28b03c7f9c70e6cf1f221f61c90/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72757374632d312e37302b2d626c75652e737667"><img src="https://camo.githubusercontent.com/46a8c8f591a66778ad0fb692f11b6efe5362f28b03c7f9c70e6cf1f221f61c90/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72757374632d312e37302b2d626c75652e737667" alt="minimum rustc 1.70" data-canonical-src="https://img.shields.io/badge/rustc-1.70+-blue.svg"></a>
<a href="https://deps.rs/repo/github/rpgp/rpgp" rel="nofollow"><img src="https://camo.githubusercontent.com/9bd706a0e53959f32a739b515a2472a4a86590d086051da0c98804d51e15ed68/68747470733a2f2f646570732e72732f7265706f2f6769746875622f727067702f727067702f7374617475732e737667" alt="dependency status" data-canonical-src="https://deps.rs/repo/github/rpgp/rpgp/status.svg"></a>
<a href="https://github.com/rpgp/rpgp/blob/master/LICENSE.md"><img src="https://camo.githubusercontent.com/d3e815ecf6a689482215a733c6e5a9075c240b4498711cbce7c67ff59c971ff6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d4954253246417061636865322e302d677265656e2e7376673f7374796c653d666c61742d737175617265" alt="License" data-canonical-src="https://img.shields.io/badge/License-MIT%2FApache2.0-green.svg?style=flat-square"></a></p>
<blockquote>
<p dir="auto">OpenPGP implemented in pure Rust, permissively licensed</p>
</blockquote>
<p dir="auto">rPGP is the only pure Rust implementation of OpenPGP, following <a href="https://tools.ietf.org/html/rfc4880.html" rel="nofollow">RFC4880</a> and <a href="https://tools.ietf.org/html/rfc2440" rel="nofollow">RFC2440</a>. It offers a minimal low-level API and does not prescribe trust schemes or key management policies. It fully supports all functionality required by the <a href="https://autocrypt.org/level1.html" rel="nofollow">Autocrypt 1.1 e-mail encryption specification</a>.</p>
<p dir="auto">rPGP is regularly published as <a href="https://crates.io/crates/pgp/" rel="nofollow">the <code>pgp</code> Crate</a> and its <a href="https://crates.io/crates/rsa" rel="nofollow">RSA</a> implementation
lives under the collective <a href="https://github.com/RustCrypto/RSA">RustCrypto umbrella</a>.
For ECC crypto support we are using <a href="https://crates.io/crates/curve25519-dalek" rel="nofollow">Curve25519-dalek</a>.</p>
<blockquote>
<p dir="auto">Please note that the API is not well documented yet. You may check out
the tests which exercise the API. Please open issues here if if you are
attempting to use rPGP and need help.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status (Last updated: October 2019)</h2><a id="user-content-status-last-updated-october-2019" aria-label="Permalink: Status (Last updated: October 2019)" href="#status-last-updated-october-2019"></a></p>
<p dir="auto">rPGP and its RSA dependency got an independent security audit mid 2019,
see here for the <a href="https://delta.chat/assets/blog/2019-first-security-review.pdf" rel="nofollow">full report from IncludeSecurity</a>.
No critical flaws were found and we have fixed most high, medium and low risk ones.</p>
<p dir="auto">rPGP is used in production by <a href="https://delta.chat/" rel="nofollow">Delta Chat, the e-mail based messenger app suite</a>, successfully running on Windows, Linux, macOS, Android and iOS in 32bit (only Windows and Android) and 64 bit builds (for the other platforms).</p>
<p dir="auto">More details on platform and OpenPGP implementation status:</p>
<ul dir="auto">
<li><a href="https://github.com/rpgp/rpgp/blob/master/STATUS.md">OpenPGP Status document</a> which describes what of OpenPGP is supported</li>
<li><a href="https://github.com/rpgp/rpgp/blob/master/PLATFORMS.md">Platform status document</a> which describes current platform support.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Experimental WASM Support</h3><a id="user-content-experimental-wasm-support" aria-label="Permalink: Experimental WASM Support" href="#experimental-wasm-support"></a></p>
<p dir="auto">When enabeling the <code>wasm</code> feature, rpgp can be compiled to run using WASM in Node.js and the supported Browsers. Experimental bindings for this can be found in <a href="https://github.com/rpgp/rpgp-js">rpgp/rpgp-js</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developement</h2><a id="user-content-developement" aria-label="Permalink: Developement" href="#developement"></a></p>
<p dir="auto">To run the stress tests,</p>
<div dir="auto" data-snippet-clipboard-copy-content="> git submodule update --init --recursive
> cargo test --release -- --ignored"><pre><span>&gt;</span> git submodule update --init --recursive
<span>&gt;</span> cargo <span>test</span> --release -- --ignored</pre></div>
<p dir="auto">To enable debugging, add</p>
<div dir="auto" data-snippet-clipboard-copy-content="use pretty_env_logger;
let _ = pretty_env_logger::try_init();"><pre><span>use</span> pretty_env_logger<span>;</span>
<span>let</span> _ = pretty_env_logger<span>::</span><span>try_init</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">And then run tests with <code>RUST_LOG=pgp=info</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How is rPGP different from Sequoia?</h2><a id="user-content-how-is-rpgp-different-from-sequoia" aria-label="Permalink: How is rPGP different from Sequoia?" href="#how-is-rpgp-different-from-sequoia"></a></p>
<p dir="auto">Some key differences:</p>
<ul dir="auto">
<li>
<p dir="auto">rPGP has a more permissive license than Sequoia, which allows a broader usage</p>
</li>
<li>
<p dir="auto">rPGP is a library with a well-defined, relatively small feature-set
where Sequoia also tries to be a replacement for the GPG command line tool</p>
</li>
<li>
<p dir="auto">All crypto used in rPGP is implemented in pure Rust,
whereas Sequoia by default uses Nettle, which is implemented in C.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Minimum Supported Rust Version (MSRV)</h2><a id="user-content-minimum-supported-rust-version-msrv" aria-label="Permalink: Minimum Supported Rust Version (MSRV)" href="#minimum-supported-rust-version-msrv"></a></p>
<p dir="auto">All crates in this repository support Rust 1.70 or higher. In future minimally supported version of Rust can be changed, but it will be done with a minor version bump.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">LICENSE</h2><a id="user-content-license" aria-label="Permalink: LICENSE" href="#license"></a></p>
<p dir="auto">MIT or Apache 2.0</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribution</h2><a id="user-content-contribution" aria-label="Permalink: Contribution" href="#contribution"></a></p>
<p dir="auto">Unless you explicitly state otherwise, any contribution submitted
for inclusion in rPGP by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What John von Neumann did at Los Alamos (2020) (195 pts)]]></title>
            <link>https://3quarksdaily.com/3quarksdaily/2020/10/what-john-von-neumann-really-did-at-los-alamos.html</link>
            <guid>39961910</guid>
            <pubDate>Sun, 07 Apr 2024 16:42:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://3quarksdaily.com/3quarksdaily/2020/10/what-john-von-neumann-really-did-at-los-alamos.html">https://3quarksdaily.com/3quarksdaily/2020/10/what-john-von-neumann-really-did-at-los-alamos.html</a>, See on <a href="https://news.ycombinator.com/item?id=39961910">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-187398"><div><p><strong>by Ashutosh Jogalekar</strong></p><figure id="attachment_187408" aria-describedby="caption-attachment-187408"><img fetchpriority="high" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/1_NAhEjpkDIARExylyZ9CQ7w-360x241.png" alt="" width="360" height="241" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/1_NAhEjpkDIARExylyZ9CQ7w-360x241.png 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_NAhEjpkDIARExylyZ9CQ7w-768x514.png 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_NAhEjpkDIARExylyZ9CQ7w-300x201.png 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_NAhEjpkDIARExylyZ9CQ7w.png 999w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187408"><em>John von Neumann (Image: Life Magazine)</em></figcaption></figure><p><span>During a wartime visit to England in early 1943, John von Neumann wrote a letter to his fellow mathematician Oswald Veblen at the Institute for Advanced Study in Princeton, saying:</span></p><p><i><span>“I think I have learned a great deal of experimental physics here, particularly of the gas dynamical variety, and that I shall return a better and impurer man. I have also developed an obscene interest in computational techniques…”</span></i></p><p><span>This seemingly mundane communication was to foreshadow a decisive effect on the development of two overwhelmingly important aspects of 20th and 21st century technology – the development of computing and the development of nuclear weapons.</span></p><p><span>Johnny von Neumann was the multifaceted intellectual diamond of the 20th century. He contributed so many seminal ideas to so many fields so quickly that it would be impossible for any one person to summarize, let alone understand them. He may have been the last universalist in mathematics, having almost complete command of both pure and applied mathematics. But he didn’t stop there. After making fundamental contributions to operator algebra, set theory and the foundations of mathematics, he revolutionized at least two different and disparate fields – economics and computer science – and made contributions to a dozen others, each of which would have been important enough to enshrine his name in scientific history.</span></p><p><span>But at the end of his relatively short life which was cut down cruelly by cancer, von Neumann had acquired another identity – that of an American patriot who had done more than almost anyone else to make sure that his country was well-defended and ahead of the Soviet Union in the rapidly heating Cold War. Like most other contributions of this sort, this one had a distinctly Faustian gleam to it, bringing both glory and woe to humanity’s experiments in self-elevation and self-destruction. </span><span id="more-187398"></span></p><p><span>The origins of Johnny’s far-reaching accomplishments lay in the Manhattan Project. But this fact alone is curious: Von Neumann was never part of the regular cast of characters at Los Alamos which included Robert Oppenheimer, Hans Bethe, Edward Teller, Richard Feynman, Enrico Fermi and other world-renowned scientists; he features as a relatively minor player in most standard histories of the project. He visited as a consultant a few times a year. And yet in some sense, his contribution equalled or even exceeded in the long-term the contributions made by his fellow scientists. This discrepancy between his role in the Manhattan Project and the importance of his work speaks to both his awesome intellect and, more interestingly, to a core element in the history and philosophy of science in which ideas and technologies unexpectedly intersect and piggyback on each other. To understand this more fully, it’s important to understand von Neumann’s origins.</span></p><p><b>From Budapest to Los Alamos via Princeton</b></p><figure id="attachment_187409" aria-describedby="caption-attachment-187409"><img decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg-360x274.png" alt="" width="360" height="274" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg-360x274.png 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg-768x584.png 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg-1024x779.png 1024w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg-300x228.png 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_s7FpypggCfGVlPRp2l8Sfg.png 1039w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187409"><em>Johnny at age 11 with his cousin (Image: Michael Vonneumann and Cantor’s Paradise)</em></figcaption></figure><p><span>Von Neumann was the quintessential product of turn-of-the-century Jewish affluence and intellectual achievement in the Austro-Hungarian empire. Born in 1903 to a wealthy banker and his wife in Budapest, Johnny was one of history’s great child prodigies, speaking half a dozen languages and learning calculus by the time he was barely past the first decade of his life. He had an amazing photographic memory and an intense interest in history that stayed with him all his life and dazzled his friends and colleagues; as the story goes, by the time he was eight he had read and annotated all forty-three volumes of a comprehensive world history written by the German historian Wilhelm Oncken, and he used to stun his parents’ friends by reciting entire pages from the phone directory as a child. As he grew up he collected around himself some of the great Hungarian minds of the 20th century – Eugene Wigner, Leo Szilard, Edward Teller. Later all of them became émigrés to the United States, and their superior intelligence led others to joke that they were Martians who had learnt to perfectly mimic human beings. Toward the end of his life, Eugene Wigner who won a Nobel Prize for his work on nuclear structure was asked why a tiny country like Hungary produced so many scientific geniuses. Wigner said that Hungary had produced only one genius – Johnny von Neumann.</span></p><p><span>After getting two degrees in Zurich and Budapest, one in mathematics and one in chemical engineering – the latter to to please his father who, like many Jewish fathers, worried that his son might not be able to get a job in spite of his great intellect but due to his Jewish background – von Neumann became an assistant to David Hilbert, one of the 20th century’s greatest mathematicians. While his early forays were in set theory and operator algebra, in a short time he left a blazing trail of contributions whose depth and breadth would be unequalled in the annals of 20th century mathematics and science. By his 30th birthday, he had solved Hilbert’s <a href="https://en.wikipedia.org/wiki/Hilbert%27s_fifth_problem">fifth problem</a> for compact groups, proved the <a href="https://en.wikipedia.org/wiki/Ergodic_theory#Mean_ergodic_theorem">mean ergodic theorem</a>, provided a mathematical <a href="https://www.abebooks.com/servlet/BookDetailsPL?bi=4096840786&amp;searchurl=fe%3Don%26kn%3DMathematische%2BGrundlagen%2Bder%2BQuantenmechanik%26sortby%3D17&amp;cm_sp=snippet-_-srp1-_-title8">foundation</a> for quantum mechanics, proved the <a href="https://mathworld.wolfram.com/MinimaxTheorem.html#:~:text=The%20fundamental%20theorem%20of%20game,John%20von%20Neumann%20in%201928.&amp;text=It%20also%20turns%20out%20that,strategy%2C%20there%20are%20infinitely%20many.">minimax theorem</a>,&nbsp;started laying the foundation for game theory in economics and done important work in the foundations of mathematics.</span></p><p><span>He had already become acutely prescient about the deteriorating political situation in Europe. After Hitler became chancellor of Germany in 1933, Johnny started making trips to the United States where he had been invited to lecture at the Institute for Advanced Study. The institute had been set up as a kind of pure thinkers’ heaven by the renowned educator Abraham Flexner, and there were few fields more suited to pure thought than mathematics, philosophy and theoretical physics. Flexner went to great lengths to snag the greatest fish of them all – Albert Einstein. By 1933 Einstein had already been the target of virulent anti-Semitic attacks and was looking for a new home. After visiting a few universities in the United States and England, Flexner lured him to Princeton with the promise of a very generous salary and complete freedom to explore his interests without any administrative or teaching responsibilities. But even by 1933, when Einstein was fifty-four, the twenty-nine-year-old von Neumann was considered important enough to be made one of the first professors at the institute, along with Einstein, Hermann Weyl and Oswald Veblen, a mathematician who was as adept at hacking away at the brush in the Princeton woods as he was at problems in geometry and topology. Veblen was to become an important mentor to Johnny. When the institute’s plans to hire Weyl fell through, Johnny was hired as a permanent faculty member.</span></p><p><span>Ever since he moved to the United States, Johnny showed a great love for his adopted country. His home was the scene of weekly raucous parties, and he loved fast cars, expensive suits and hobnobbing with the rich and famous. His friend Eugene Wigner who had shipped from Hungary as a joint appointment with von Neumann recalled how Johnny was refreshed by the new world and by the youthful enthusiasm he saw there which rejected the reactionary and orthodox ideas of old world Europe, a motivation not uncommon among American émigrés. As Europe crumbled in the face of fascism in the next few years, Johnny was joined by European scientists like Bethe, Fermi and Weisskopf who became household names, started great schools of science and catapulted America into the front ranks of science and technology, a position that it continues to hold in no small part due to such immigrants.</span></p><figure id="attachment_187406" aria-describedby="caption-attachment-187406"><img decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/game-theory-360x156.jpg" alt="" width="360" height="156" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/game-theory-360x156.jpg 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/game-theory-768x332.jpg 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/game-theory-300x130.jpg 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/game-theory.jpg 898w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187406"><em>Oskar Morgenstern and von Neumann published “Theory of Games and Economic Behavior” in 1944, when Johnny was already deep into defense work (Image: ThatsMaths)</em></figcaption></figure><p><span>Because of his intense interest and background in history, Johnny could already see in 1935 that there would be some kind of war between Germany and other countries. By 1937 he had started expressing interest in the more applied parts of mathematics. His work on the minimax theorem and the foundations of quantum mechanics was already dazzling, especially for a pure mathematician, and in Princeton he had struck up a friendship with another Austrian emigre, the economist Oskar Morgenstern. During the next few years he would embark on the writing “<a href="https://www.abebooks.com/servlet/BookDetailsPL?bi=22795883348&amp;searchurl=fe%3Don%26sortby%3D17%26tn%3Dtheory%2Bgames%2Beconomic%2Bbehavior&amp;cm_sp=snippet-_-srp1-_-title7">The Theory of Games and Economic Behavior</a>” with Morgenstern which is now considered the foundation of game theory. </span></p><p><span>What accounted for Johnny’s forays into applied mathematics and away from pure mathematics? One reason was certainly his capacious mind that roamed over diverse domains out of sheer burning intellectual curiosity, but I also personally feel that it was partly a disillusionment with the foundations of mathematics, a disillusionment that was made acutely clear by the work of his friend and institute colleague Kurt Gödel who in 1932 had struck a blow at the foundations of mathematics through his famous <a href="https://plato.stanford.edu/entries/goedel-incompleteness/">incompleteness theorems</a>. Johnny had extended Gödel’s first theorem in short order, only to find that Gödel had already gotten there. Later he did what he could to ensure Gödel’s appointment at the institute; the two friends <a href="https://3quarksdaily.com/3quarksdaily/2019/05/life-and-death-in-new-jersey.html">now lie</a> only a few feet from each other. Gödel’s work might have convinced Johnny that making deep contributions to pure mathematics was perhaps not his forte. Fortunately for him, the escalating situation in Europe brought a new opportunity that would make full use of his intellectual powers.</span></p><p><b>Shaped charges and the Aberdeen Proving Ground</b></p><figure id="attachment_187401" aria-describedby="caption-attachment-187401"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe-270x360.jpg" alt="" width="270" height="360" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe-270x360.jpg 270w, https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe-768x1025.jpg 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe-767x1024.jpg 767w, https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe-225x300.jpg 225w, https://3quarksdaily.com/wp-content/uploads/2020/10/1024px-Charles_Edward_Munroe.jpg 1024w" sizes="(max-width: 270px) 100vw, 270px"><figcaption id="caption-attachment-187401"><em>Charles Munroe (Image: Wikipedia)</em></figcaption></figure><p><span>In 1888, an American chemist working for the navy named Charles Munroe discovered something quite wonderful and intriguing. Monroe found that when he detonated a block of explosive with the company’s name engraved on it with raised letters near a metal plate, the raised letters somehow got “transferred” into the metal plate. What was happening was that the explosive blast from the block took the shape of the letters – and stayed that way for some time. Later Munroe demonstrated this effect even more convincingly with a metal safe. As he <a href="https://en.wikisource.org/wiki/Popular_Science_Monthly/Volume_56/February_1900/The_Applications_of_Explosives_II">described it</a> in a 1900 ‘Popular Science’ article,</span></p><p><em><span>“Among the experiments made … was one upon a safe twenty-nine inches cube, with walls four inches and three quarters thick, made up of plates of iron and steel … When a hollow charge of dynamite nine pounds and a half in weight and untamped was detonated on it, a hole three inches in diameter was blown clear through the wall … The hollow cartridge was made by tying the sticks of dynamite around a tin can, the open mouth of the latter being placed downward.”</span></em></p><p><span>Thus was born the principle of the Munroe Effect and the shaped charge, a phenomenon which still has a little bit of a whiff of magic to it. The shaped charge essentially enables a precisely geometrically-shaped explosive to ephemerally create a small pocket of air that is packed with deadly force – hell in a puff of air. When this puff hits a target, even a metal safe cannot help but be cast in its shadow. Shaped charges soon started seeing use in many peaceful applications of explosives to create controlled, precisely shaped, powerful cavities in materials like rocks and metals. By the time the 1930s came along, scientists in many countries had gotten interested in them. A particularly important contribution was made by R. W. Wood, a Johns Hopkins physicist whose initial interest stemmed from morbid accidental deaths by shaped charges.</span></p><p><span><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM-360x309.png" alt="" width="360" height="309" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM-360x309.png 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM-768x659.png 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM-1024x879.png 1024w, https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM-300x257.png 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-25-at-8.39.04-PM.png 1156w" sizes="(max-width: 360px) 100vw, 360px">An<a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a220095.pdf"> illuminating history</a> of shaped charges tells the story of how the technology gradually percolated from America to Britain and back to America. But there was an ominous detour in Germany. An Austrian physicist named Rudolf Thomanek had become interested in the British and American work and was trying to develop an anti-tank gun. By 1932, he had become convinced that the Austrian authorities were “halfwits” who were uninterested – why not try to sell the concept to the much more enthusiastic German authorities? In fact, why not go straight to the top? By the end of 1935, Thomanek had pulled enough strings to find himself presenting the idea to an audience consisting of Hitler, Himmler, Goering and the General Staff of the Third Reich’s armed forces. Contrary to his later, well-deserved image as a strategist who routinely came up with unworkable and outlandish schemes, Hitler was extremely detail-oriented and well-versed when it came to weaponry. Thomanek had put a dented plate on Hitler’s desk.</span></p><figure id="attachment_187404" aria-describedby="caption-attachment-187404"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/HandTool-360x300.jpg" alt="" width="360" height="300" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/HandTool-360x300.jpg 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/HandTool-300x250.jpg 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/HandTool.jpg 600w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187404"><em>The German version of the American bazooka – the ‘Panzerfaust’ (Image: HistoryNet)</em></figcaption></figure><p><em><span>“I am in a hurry and will express my opinion immediately”, </span></em><span>Hitler</span><span>&nbsp;said. </span><em><span>“This proposal could be the solution I have always wanted to give the individual soldier a weapon to defeat tanks. Maybe the same principle could be used in bombs and torpedoes.”</span></em></p><p><span>The Führer had grasped the significance of the new idea immediately. So did scientists, engineers and politicians in Britain, the Soviet Union and the United States. In the United States the shaped charge saw incarnation as the fabled anti-tank weapon the Bazooka, a weapon whose detailed workings were kept secret until 1945 when the core principle was revealed by a reprint of Munroe’s 1900 Popular Science article. The point of this slight digression is to indicate that by 1937, shaped charges were a well-studied form of anti-tank weaponry. They were also ideally suited to von Neumann’s particular skill set, and it was at the Aberdeen Proving Ground that they found fertile landfall.</span></p><p><span>The Aberdeen Proving ground in Maryland had been set up during World War 1 for ballistics research. Ballistics research was a clear priority for any army utilizing artillery. The main area of research for ballistics specialists was firing tables that indicated the velocity and the angle at which to fire a projectile to hit both stationary and moving targets. In 1918, Oswald Veblen had been hired to oversee scientific work at the site, and among others had recruited von Neumann’s fellow mathematical prodigy Norbert Wiener to work with him. By the late 1930s, Aberdeen was in a good position to contribute to the war effort and Veblen invited von Neumann to join him. The newly naturalized Johnny was eager enough that he applied to take an exam as a lieutenant in the army reserve in 1939. Amusingly, even though he passed the exam, he was turned down because of an age cutoff. Senator William Smathers from New Jersey expressed his perplexed reaction to FDR’s Secretary of War, Harry Woodring: <em>“Mr. von Neumann is internationally known as a mathematician, and I cannot understand how a man with so much potential value to the American armed forces should be turned down for a technicality.”&nbsp;</em></span></p><p><span>The reason Smathers and Veblen considered Johnny so valuable to a potential war effort was simple. Although von Neumann had no training in war-related work, his singular skill as a universalist mathematician would be invaluable in analyzing the nonlinear phenomena involved in shaped charge detonation. Crudely speaking, nonlinear phenomena deal with cases in which a given stimulus produces a disproportionate response. Most complex phenomena in the real world of interest to scientists are nonlinear, and in that sense the name ‘nonlinear’ is a misnomer: As von Neumann’s best friend Stanislaw Ulam who had escaped Poland before the Nazis invaded it once said, <em>“</em></span><span><em>Using a term like nonlinear science is like referring to the bulk of zoology as the study of non-elephant animals.”</em> Nonlinear phenomena required mathematical manipulation at the highest level because of the complexity of the equations which usually involved partial differential equations in multiple dimensions. Both the versatility and speed of von Neumann’s mind made him an ideal candidate for analyzing these. As we will see later, Johnny’s interest in nonlinear equations was to have an unexpected and revolutionary impact on modern technology.</span></p><p><span>As the United States entered World War 2 after Pearl Harbor, most European émigré scientists wanted to do their part to help the war effort. Johnny’s point of departure into what became his most important contribution arose from Hans Bethe and Edward Teller’s work on shock waves. In 1941, Teller and Bethe had <a href="https://fas.org/sgp/othergov/doe/lanl/lib-www/la-pubs/00367149.pdf">analyzed</a> how the change in conditions around a shock wave, both in its front and back, can be analyzed in terms of characteristics like the medium’s temperature, pressure etc. To a simplifying approximation, Teller and Bethe found that the conditions at the front of the developing wave can be represented accurately by knowing the conditions at the back of the wave. Johnny was aware of this work, and in May 1941 wrote a letter to Bethe in which he asked the physicist if he and Teller could extend their work to air at 25,000 degrees centigrade. The scientists were finding out, interestingly, that the so-called equations of state for materials that relate pressure, temperature and density to each other were actually simplified at higher temperatures compared to lower ones because of a kind of equalizing behavior of different materials at those temperatures. Johnny’s main contribution had been to figure out that the behavior of the detonation of a shaped charge could be interpreted as the propagation of a shock wave followed by chemical reaction of the materials in the medium. We thus know that even before Pearl Harbor, Johnny was already making himself an expert in the behavior of shock waves at high temperatures.</span></p><p><b>From shaped charges to implosion</b></p><p><span>Curiously, von Neumann wasn’t involved in the early developments leading to the Manhattan Project, perhaps he already had much on his plate at that point. Not only was he consulting for multiple departments of the army and navy, but he was also making trips to England as a consultant. The early steps leading to the bomb project were all taken by physicists like Leo Szilard, Edward Teller, Robert Oppenheimer and Enrico Fermi. After the news of fission came to the United States in 1939, Szilard convinced his friend Einstein to write a famous <a href="http://wavefunction.fieldofscience.com/2014/08/celebrating-1939-leo-szilard-letter-to.html">letter</a> to FDR impressing on him the urgency of starting research into uranium fission. By the summer of 1942, Oppenheimer had been picked by Leslie Groves, the head of the project, to oversee a preliminary theoretical effort into a fission bomb. At Berkeley that summer, Oppenheimer, Bethe, Teller and others convinced themselves that theoretically, a simple fission bomb would be possible. By the end of 1942, Enrico Fermi and his team had done a proof-of-concept experiment and built the world’s first nuclear reactor at the University of Chicago. With Fermi’s experiments the Manhattan Project kicked into high gear, and by March 1943 an isolated site set among the majestic mesas of Los Alamos in New Mexico had been selected for the top-secret project.</span></p><p><span>As has been well documented, the basic principle of building a fission bomb was clear by 1943. You had to fire two subcritical pieces of uranium into one another, and once the critical mass had been exceeded there would be an explosion. It was also understood that this process needed to be exceptionally fast to prevent pre-detonation or a fizzle which would give suboptimal yield. The main challenge was always considered the separation of uranium isotopes and the production of plutonium, a novel material which would be even more fissile. By the time the scientists settled in at Los Alamos, Oppenheimer’s close collaborator and confidant Robert Serber had given a set of <a href="https://www.amazon.com/Los-Alamos-Primer-Lectures-Atomic/dp/0520075765">lectures</a> summarizing the state of knowledge.</span></p><p><span>It was then that a physicist named Seth Neddermeyer came up with an entirely novel approach to detonating a bomb – an approach called implosion. Instead of crashing two pieces of fissile material together, implosion called for bringing together those pieces inward, preferably in three dimensions to maximize efficiency. It says something about how novel and speculative this approach was that Neddermeyer’s idea met with fierce opposition from the likes of scientists like Bethe, Fermi and Feynman, men who weren’t known for a deficiency of new ideas. Deke Parsons, a naval physicist who was called in to help with ordnance, derisively called it the “beer can experiment”: the challenge was to symmetrically implode or squeeze a beer can from all sides without having the beer squirt out. But Oppenheimer was more prescient and he asked Neddermeyer to conduct preliminary experiments. Stymied by complex three dimensions, Neddermeyer started working with cylinders in two dimensions. By September 1943, the work was trudging along and Neddermeyer was not a particularly harmonious individual to work with, sticking to his ideas and seldom entertaining others. More importantly, what had been already suspected by Oppenheimer’s team in 1942 now became clear – that when it came to building a bomb, understanding the hydrodynamics or flow of shock waves was as important as understanding the nuclear physics and flow of radiation and particles like neutrons. Enter Johnny von Neumann.</span></p><p><span>Oppenheimer had written a letter to von Neumann in July 1943, and the contents of that letter make clear both the high regard in which he held Johnny and the difficulties he was facing:</span></p><p><i><span>“We are in what can only be described as a desperate need of your help. We have a good many theoretical people working here, but I think that if your usual shrewdness is a guide to you about the probable nature of our problems you will see why even this staff is in some respects critically inadequate…I would like you to come as a permanent, and let me assure you, honored member of our staff. A visit will give you a better idea of this somewhat Buck Rogers project than any amount of correspondence.”</span></i></p><p><span>At this point it’s worth noting von Neumann’s salient qualities that were considered to be helpful in such a project. I have noted these qualities in detail before in <a href="http://wavefunction.fieldofscience.com/2020/05/what-john-von-neumann-really-did-for.html">an essay</a> about his major contributions to computing. In a nutshell, while Johnny’s mind was as original as anyone else’s, his main strength was being able to jump ten steps ahead of everyone with his lightning fast mind, look at the big picture and connect disparate ideas together. This enabled him, in his friend Edward Teller’s words, <em>“to identify solutions where most people didn’t even notice the problems.”</em> All this not only made von Neumann a supremely reliable mind to seek advice from but lent his words enormous prestige. Johnny agreed to visit Los Alamos, not as a permanent member but as a consultant in September 1943. When not at Los Alamos, he would work out of the office of the National Academy of Sciences in Washington, D.C.&nbsp;</span></p><p><span>What Johnny essentially did in his critical visit was anoint implosion with his blessings. He confirmed that the best way to achieve implosion would be to spherically place shaped charges around a uranium or plutonium core; the Munroe Effect operating in three dimensions would then squeeze the core to the unearthly densities required to bring about the fission reaction. He also made the critical suggestion that implosion could be made much faster by increasing the ratio of the explosive in the shaped charges to the nuclear material. The faster assembly would not only prevent pre-detonation or a fizzle by making sure that the material has already reached critical mass before the nuclear fission reaction has been initiated, but the higher explosive to fissile material ratio would mean that you would need to use less of exceedingly precious enriched uranium or plutonium. In fact, as Johnny discovered because of his friend Teller who was very knowledgeable about the behavior of materials at high pressure, at the pressures that would exist in the core, materials would get squeezed so hard that they would become not just critical but supercritical, greatly accelerating the efficiency of the resulting explosion.</span></p><p><span>Because of his prestige and confidence in his calculations, von Neumann breathed fresh air into what was until then a creaky, uncertain program that Neddermeyer had been stubbornly sticking to. Fermi, Bethe and other senior scientists who had until then been skeptical of Neddermeyer’s scheme not only trusted von Neumann but regarded his dazzling mind with an awe that would be extraordinary for men who themselves were some of the leading scientific minds of the 20th century. Perhaps the ultimate tribute to von Neumann’s intelligence was paid by Bethe when he remarked after the war that <em>“Von Neumann’s mind seemed to indicate that he belonged to a new species, an evolution beyond man.”</em>, and Fermi once told his student Richard Garwin that von Neumann left him feeling he knew no mathematics at all. After von Neumann’s trip Charles Critchfield, a theoretical physicist on Oppenheimer’s team, said, <em>“Johnny woke everyone up. He was a very resourceful person, at least twenty years ahead of his time.”</em></span></p><p><span>Once von Neumann made his suggestions, it was quite clear that the implosion program had to be given top priority. There were two main challenges associated with implementing it. One was to work out the complicated nonlinear hydrodynamical equations associated with the shock wave. The other was to find explosive materials which would sustain an imploding wave and have it impinge on the center of the fission target uniformly. To aid with the latter task, Oppenheimer invited George Kistiakowsky from Harvard who was a world-class expert in explosives; in his spare time Kistiakowsky would use his explosives knowledge to raze trees and create ski slopes on the mesa for recreation for the scientists. He also set aside separate groups that would develop the diagnostics and assembly techniques for implosion, including the development of novel detonators that would assure an instantaneous detonation on multiple points of a sphere. None of these innovations or work was trivial, but von Neumann left everyone with the feeling that it was possible.</span></p><p><span>The biggest challenge in putting implosion into practice was to design an assembly of explosives that would ensure a symmetric shock wave – an asymmetry as little as 5% would lead to a “beer can experiment”. The problem with a standard explosion is that it sets off a diverging shock wave. To ensure that this wave impinged on the uranium or plutonium at the center, it had to somehow be turned from diverging to converging. How to achieve this? At this point another valuable character showed up, from England. James Tuck was part of the British contingent to Los Alamos, a small cadre of highly accomplished physicists who were to help with the bomb. The proof-of-concept for fission and critical mass had actually been worked out in England before the United States, so it was natural for British scientists to be involved. Tuck had experience working with explosive materials of differing densities. College physics says that when a light wave passes through materials of varying densities, it bends or refracts differently. Similarly a shock wave would “refract” or bend differently with different densities. And just like a material that refracts and transmits light is a lens, so an explosive that bends and transmits shock waves is an “explosive lens”. Tuck suggested an ingenious arrangement in which a diverging shock wave could be turned into a converging one by layering explosives burning at different rates together. By starting the detonation in fast-burning explosive and then maneuvering the resulting wave inside using shaped charges of slow-burning explosives, thirty-two different waves from thirty-two different points of detonation could be made to converge to a pinpoint at the center, squeezing the material to unearthly densities and triggering the fission reaction. It was again von Neumann who worked out the mathematics of explosive lenses and played a major role in their design.</span></p><figure id="attachment_187410" aria-describedby="caption-attachment-187410"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/2560px-Implosion_Nuclear_weapon.svg_-360x205.png" alt="" width="360" height="205" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/2560px-Implosion_Nuclear_weapon.svg_-360x205.png 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/2560px-Implosion_Nuclear_weapon.svg_-768x437.png 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/2560px-Implosion_Nuclear_weapon.svg_-1024x582.png 1024w, https://3quarksdaily.com/wp-content/uploads/2020/10/2560px-Implosion_Nuclear_weapon.svg_-300x171.png 300w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187410"><em>An explosive lens in an implosion weapon (Image: Wikipedia)</em></figcaption></figure><p><span>The real role played by von Neumann, Tuck, Kistiakowsky and others became apparent when a critical observation made it clear that implosion would be the only possible way to assemble the plutonium weapon. In the fall of 1944, Emilio Segrè, a protege of Fermi’s, <a href="http://wavefunction.fieldofscience.com/2017/02/born-otd-physicist-emilio-segre-who.html">discovered</a> that the plutonium-239 being used in the bomb contained an isotope, plutonium-240, that was an inevitable byproduct of the reactor-bred plutonium in the reactors at Hanford, Washington state. Pu-240 underwent spontaneous fission without any initiation, and it turned out that the gun method that was being used for the uranium bomb would be too slow to prevent pre-detonation or a fizzle. Implosion would be the only possible way to go for plutonium. Without implosion the plutonium bomb would likely have been abandoned at this stage. Implosion was still considered such a novel concept that the design was tested in New Mexico’s Alamogordo desert on July 16, 1945.</span></p><p><span>Von Neumann wasn’t done with his ideas though. A crucial albeit rather dark contribution that he made was to simplify the calculations used to estimate the pressures from a bomb. Von Neumann knew that for large explosions, the effects of the detonation are not dictated by the length of the pulse but only by the excess pressure that results; this made the relationship between bomb yield and effects a much simpler one. More importantly, using his knowledge of shock wave reflections, Johnny helped to estimate the optimal height at which a nuclear bomb should be exploded to cause maximum damage. On August 6, 1945, the Little Boy uranium bomb exploded at a height of about 1900 feet on top of Hiroshima. About 80,000 to 100,000 people were instantly killed, providing a real-life demonstration of von Neumann’s calculations.</span></p><figure id="attachment_187407" aria-describedby="caption-attachment-187407"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w-360x214.jpeg" alt="" width="360" height="214" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w-360x214.jpeg 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w-768x457.jpeg 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w-1024x610.jpeg 1024w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w-300x179.jpeg 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/1_EITY1jXNBfn2CN_VXIDH0w.jpeg 1149w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187407"><em>Von Neumann, Feynman and Ulam at Los Alamos: Their individual attire seems consonant with their personalities (Image: Atomic Heritage)</em></figcaption></figure><p><span>Johnny enjoyed being at Los Alamos. He reconnected with his old friend Edward Teller and invited a new friend, Stan Ulam, to help with the hydrodynamics calculations. Ulam was almost as versatile a mathematician as Johnny and the two were best friends – significant parts of Ulam’s wonderful memoir, “Adventures of a Mathematician”, are dedicated to describing conversations and travels with Johnny. They tried to recreate the famous cafe atmosphere in Eastern Europe that had fueled late night mathematical bull sessions in the early 20th century before it all came crashing down. In keeping with his predilection for wearing expensive, tailored three-piece suits, Johnny once wore one even when riding a mule in the Jemez mountains near the lab. He also went for walks with Richard Feynman, and in his own memoir “Surely You’re Joking Mr. Feynman”, Feynman points out that it was von Neumann who planted the idea in his mind that knowing how uncertain the consequences of our actions are, you should not have them weigh too heavily on your conscience. Knowing the rather grim endeavor that the physicists were involved with, this was psychologically soothing advice for Feynman.</span></p><p><b>“I am thinking about something much more important than bombs; I am thinking about computers.”</b></p><p><span>For all his critical ideas, the most important and far-reaching thing to come out of von Neumann’s work at Los Alamos had little to do with bombs. Once Johnny suggested using spherical implosion, it quickly became clear that the calculations involved would be too complex for individuals to perform. In England and before, Johnny had already been introduced to early computing machines, and he had been impressed with Alan Turing’s seminal paper on Turing machines and even tried to recruit Turing as his assistant when Turing visited Princeton to finish his PhD before the war. Now when it became clear that computing machines might be needed to handle the complex physics of implosion, Johnny was again in the right place at the right time. Stan Ulam who came to Los Alamos on Johnny’s invitation captured the problem well: <em>“The hydrodynamical problem was simply stated but very difficult to calculate, not just in its details but even in order of magnitude.”</em> He remembered a discussion in which von Neumann and others had suggested all kinds of ingenious shortcuts and theoretical simplifications, and he wondered whether<em> “more simpleminded brute force, that is, more realistic, numerical work”</em> might not be better.&nbsp;</span></p><p><span>To do this kind of work, the first IBM computing machines arrived in April, 1944 to help with the calculations. The implosion problem involved the integration of a hyperbolic partial differential equation in one space and one time coordinate. The integration was carried out using punched cards; Richard Feynman was in charge of this effort. Johnny himself spent two weeks programming the machines and getting a feel for the calculations. He found rewiring the tabulators especially cumbersome, and this frustration had an impact on his later crucial thinking about general-purpose computers. Johnny also knew that Howard Aiken at Harvard had had IBM build one of the first programmable computers, and he arranged for a numerical integration of a second-order partial differential equation to be run simultaneously on the Los Alamos computer and the Harvard computer as a contest; the Los Alamos computer finished first, but the Harvard computer calculated to more decimal places.</span></p><p><span>His experience at Los Alamos immediately suggested to the thinking-ten-steps-ahead Johnny that computers were going to become an invaluable asset in doing complex math and science. Quite fortuitously, around the same time he also came in contact with the pioneering engineers Presper Eckert and John Mauchly who were building one of the first pioneering general-purpose computers, the ENIAC, at the University of Pennsylvania. <a href="http://wavefunction.fieldofscience.com/2020/05/what-john-von-neumann-really-did-for.html">I have described</a> Johnny’s accidental introduction to computers and his subsequent work as one of the fathers of modern computing in a separate essay, but it is clear that it was his work at Los Alamos that crystallized in his mind the value of computers as an enabling tool for science and technology. It was characteristically far-sighted of him that even before the war ended he was writing to a colleague, <em>“I am thinking about something much more important than bombs; I am thinking about computers.”</em></span></p><p><b>Johnny’s&nbsp;legacy</b></p><p><span>Johnny von Neumann’s work at Los Alamos had a direct impact on the weapons of mass destruction that leveled Hiroshima and Nagasaki and that still decorate the world’s nuclear arsenals. Implosion is still the predominant technique used in fission bombs, and even in thermonuclear weapons it’s used as the primary fission device that ignites the fusion secondary. After the war Johnny kept on advising the United States government as a high-level consultant; at one point he advised every agency except the Coast Guard. He made valuable contributions not just to fission weapons but to the thermonuclear weapons that are today capable of killing hundreds of millions in a matter of minutes. Just before his death, he became one of the prime movers behind the <a href="https://en.wikipedia.org/wiki/Teapot_Committee">recommendation</a> to accelerate the United States’s nuclear ICBM program, a development that immediately made the entire world vulnerable to the threat of nuclear armageddon. He was convinced that the Soviet Union posed an existential danger to the security of the United States and advocated not just a preemptive but a preventive strike on that country; thankfully that part of his advice was not taken. </span></p><figure id="attachment_187412" aria-describedby="caption-attachment-187412"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/di_03376-360x294.jpg" alt="" width="360" height="294" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/di_03376-360x294.jpg 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/di_03376-300x245.jpg 300w, https://3quarksdaily.com/wp-content/uploads/2020/10/di_03376.jpg 500w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187412"><em>Von Neumann receiving the Medal of Freedom from President Eisenhower (Image: University of Texas)</em></figcaption></figure><p><span>He remained a steadfast patriot, often politically at odds with his more liberal colleagues but always friends with everyone, and was held in such esteem that during the last year of his life when cancer unexpectedly struck him, he received the Medal of Freedom from President Eisenhower and spent his last days in a special, guarded suite at Walter Reed Hospital that Eisenhower had specially requisitioned for him. On his deathbed lay a manuscript of a <a href="https://www.amazon.com/Computer-Brain-Silliman-Memorial-Lectures/dp/0300181116">set of lectures</a> comparing the computer with the brain. In it lay ideas whose seeds germinated at Los Alamos and whose branches now extend into artificial intelligence, robotics and neuroscience. Perhaps his most enduring idea in this regard, and one which is very much still waiting to play out, was the idea of self-reproducing automata which could be <a href="https://en.wikipedia.org/wiki/Self-replicating_spacecraft">sent out</a> into space and would populate the cosmos with a diversity of exploding life.</span></p><figure id="attachment_187411" aria-describedby="caption-attachment-187411"><img loading="lazy" decoding="async" src="https://3quarksdaily.com/wp-content/uploads/2020/10/1-1-360x288.jpg" alt="" width="360" height="288" srcset="https://3quarksdaily.com/wp-content/uploads/2020/10/1-1-360x288.jpg 360w, https://3quarksdaily.com/wp-content/uploads/2020/10/1-1-768x614.jpg 768w, https://3quarksdaily.com/wp-content/uploads/2020/10/1-1-1024x818.jpg 1024w, https://3quarksdaily.com/wp-content/uploads/2020/10/1-1-300x240.jpg 300w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-187411"><em>Von Neumann and Oppenheimer in front of the Institute for Advanced Study computer in Princeton (Image: IAS)</em></figcaption></figure><p><span>As the eminent historian of science George Dyson put it in his superb book “<a href="https://www.amazon.com/Turings-Cathedral-Origins-Digital-Universe-ebook/dp/B005IEGK5C/ref=sr_1_1?dchild=1&amp;keywords=turing%27s+cathedral&amp;qid=1603690526&amp;s=books&amp;sr=1-1">Turing’s Cathedral</a>”, <em>“Bombs made computers, and computers made bombs.”</em> If designing the implosion lens for nuclear weapons were to be Johnny’s biggest legacy from Los Alamos, it would be a morally dubious one. But his unexpected recognition of the value of computers takes his contributions to a completely new level. While initially he did encourage using computers to simulate the workings of first fission and then fusion weapons, he made seminal contributions to charting out the stored-program concept, random access memory and what is today called the von Neumann architecture. With a talented team of engineers he designed a pioneering computer at the Institute for Advanced Study. Using this computer, his team made forays into a remarkable number of important and fascinating topics: weather simulation, artificial life, fundamental mathematical research, geophysics. The branches that these explorations sent out continue to thrive.</span></p><p><span>Johnny von Neumann’s Los Alamos story shows us that often, the most important impact of a new technology is another new technology. Often this new technology is wholly unanticipated. When Johnny came to Los Alamos, he and his colleagues thought they would be designing bombs, but what they didn’t know was that they would need computers to design those bombs. And that the computers would be far more important than the bombs even in the short term. Ultimately a hundred or a thousand years from now, if humanity still survives and the world’s nuclear arsenals are a dim memory in a history textbook, we will still be using computers, and computers will still be using us.</span></p><p><em>Recommended further reading:</em></p><ol><li>John von Neumann and the Origins of Modern Computing – William Aspray</li><li>Critical Assembly: A Technical History of Los Alamos during the Oppenheimer Years, 1943-1945 – Lillian Hoddeson, Paul Henriksen, Roger Meade and Catherine Westfall</li><li>John von Neumann: Selected Letters – Edited by Miklós Rédei</li><li>The Making of the Atomic Bomb – Richard Rhodes</li><li>Adventures of a Mathematician – S. M. Ulam</li><li>John von Neumann – Norman Macrae</li><li>Prisoner’s Dilemma – William Poundstone</li><li><a href="http://wavefunction.fieldofscience.com/2020/05/what-john-von-neumann-really-did-for.html">What John von Neumann really did for modern computing</a> – Ashutosh Jogalekar</li><li><a href="https://3quarksdaily.com/3quarksdaily/2020/06/von-neumann-in-1955-and-2020-musings-of-a-cheerful-pessimist-on-technological-survival.html">Von Neumann in 1955 and 2020: Musings of a cheerful pessimist</a> – Ashutosh Jogalekar</li><li><a href="https://medium.com/cantors-paradise/the-unparalleled-genius-of-john-von-neumann-791bb9f42a2d">The Unparalleled Genius of John von Neumann</a> – Jørgen Veisdal</li><li><a href="https://youtu.be/Y2jiQXI6nrE">John von Neumann</a> – 1966 documentary by the Mathematical Association of America that includes great recollections by Johnny’s eminent colleagues (Eugene Wigner, Hans Bethe, Paul Halmos, Herman Goldstine, Edward Teller and others)</li></ol></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Adventures Making Vegemite (160 pts)]]></title>
            <link>https://daveon.design/adventures-making-vegemite.html</link>
            <guid>39960788</guid>
            <pubDate>Sun, 07 Apr 2024 13:55:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daveon.design/adventures-making-vegemite.html">https://daveon.design/adventures-making-vegemite.html</a>, See on <a href="https://news.ycombinator.com/item?id=39960788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
<article><section>
<p><span><span>To non-Australians, Vegemite</span> is one of the strangest food products you’re likely to ever encounter.</span> <span>It’s a dark brown, almost black, shiny paste with a pungent scent, and a very strong, almost indescribable taste that is strongly umami and very salty.</span> </p><figure>
<img src="https://daveon.design/images/vegemite.webp">
</figure>
<p><span>It is a little like soy sauce in solid form.</span> </p><p><span>We tend to eat it on toast for breakfast.</span> <span><span></span> <span><span>The trick is not to spread it thickly like peanut butter; instead, you take about a quarter of a teaspoon’s worth and scrape it thinly over the entire slice.</span> <span>It also goes very nicely in a toasted cheese sandwich.</span> </span> <span></span> </span><span> </span></p><p><span>It sounds unique, but perhaps the strangest thing about it is that it is <em>not:</em> the <span>British have Marmite, which tastes similar but is runnier, Australians have a <em>second</em> yeast extract spread called <span>Promite,<span><span></span> <span><span>In my personal opinion, even better than Vegemite.</span> </span> <span></span> </span><span>  the <span>Germans and Swiss have Cenovits and Vitam-R,<span><span></span> <span><span>I haven’t tried either of these.</span> </span> <span></span> </span><span>  and a <span>Latvian friend once gave me a jar of a tan-coloured, honey-consistency thick liquid he told me was like Vegemite and I (sadly) found inedible.</span> </span></span></span></span></span></span></p><p><span>This leads to spirited debates about which is best and, like a true Australian, I mock Marmite to the British friend with whom I made Vegemite for this article,<span><span></span> <span><span>Marmite is the <em>inferior</em> product: it is not a solid paste but is runny, and has a slightly less strong taste.</span> </span> <span></span> </span><span>  even as he keeps <span>Marmite in his cupboard and would never touch Vegemite.</span> <span>Both of us quietly admit they’re very similar and I have many times bought Marmite when Vegemite was not available.</span> <span><span></span> <span><span>When you live overseas, you make do with what you can get.</span> <span>In Australia, you’d never admit to eating Marmite.</span> <span>But among fraternity of overseas Aussie citizens, there’s an unspoken knowledge that we’ve all lowered ourselves to Marmite from time to time.</span> </span> <span></span> </span><span> </span></span></span></p><p><span>But even if thick black pungent salted umami spreads are common, <strong>how are they made?</strong></span> <span>And <strong>what is such a strange spread really made of?</strong></span> </p><p><span>The jar claims to be a ‘yeast extract’, and Aussie rumour had it that it was made from leftovers from making beer.</span> <span>Very Australian.</span> <span>Since it was invented in the 1920s, I personally had a mental image of a specific strain of yeast fermenting to produce some precursor substance, <a href="https://worldbuilding.stackexchange.com/questions/56560/can-you-make-arbitrary-food-out-of-yeast"><span>Asimov-style</span></a>.</span> </p><p><span>Then my Marmite-loving British friend sent me <a href="https://www.youtube.com/watch?v=ukd3lg3Z_Pg">this video</a>,<span><span></span> <span><span>From the <a href="https://www.youtube.com/@HowToCookThat"><em><span>How To Cook That</span></em></a> <span>Youtube channel by Ann Reardon.</span> </span> <span></span> </span>  and one afternoon we made it.</span><span> <span><span></span> <span><span>By ‘we made it’, it’s more that I’d casually mentioned I’d like to try, and then at the pub the previous evening he said he had all the ingredients and would I like to join him the next afternoon?</span> <span>In other words: his effort, his ingredients, his kitchen, and I took photos.</span> </span> <span></span> </span><span> </span></span></span></p><figure>
<img src="https://daveon.design/images/vegemite-results-toast.webp"><span></span>
</figure>
<section><h2 id="ingredients">Ingredients</h2>
<p><span>A homebrewing friend provided:</span></p><figure>
<img src="https://daveon.design/images/vegemite-yeast-slurry.webp">
</figure>
<ul>
<li><span>The yeast slurry from the bottom of a batch of beer (from a plain lager)</span></li><li><span>A fermented malt wort made from dry malt mixed with water</span></li></ul>
<p><span>The malt was very liquid and we boiled it down to a thick syrup.</span> <span>You could likely use supermarket malt.</span> </p><figure>
<img src="https://daveon.design/images/vegemite-slurry-liquid-boiling.webp"><figcaption>Boiling the skimmed yeast slurry liquid.</figcaption><span></span>
</figure>
<p><span>The yeast slurry in Ann Reardon’s video was separated into yeast and liquids via a home-made washing-machine centrifuge.</span> <span>But our slurry had been sitting in my friend’s fridge for a few days, and he simply poured off the top.</span> <span>This liquid, a pale clear tan, we boiled down into a thick, dark brown syrup too.</span> <span>Initially, the kitchen smelled like hot beer, but it soon changed to smell like something recognisable as a Vegemite-like scent.</span> <span><span></span> <span><span>It was not unpleasant—if you like Vegemite—but it was strong, and at some point despite the winter outside every window in the apartment was opened.</span> </span> <span></span> </span><span> </span></p><figure>
<img src="https://daveon.design/images/vegemite-boiling-down.webp"><figcaption role="complementary "><span>Left: the malt reducing to a syrup; right: the slurry liquid also being boiled down.</span> </figcaption><span><span></span>
</span></figure><p><span>A good half-liter or more of yeast-slurry-liquid turned into only a couple of tablespoons of dense brown syrup.</span> <span>This is definitely a recipe where large starting volumes are needed, and you won’t get a large quantity result.</span> </p><figure>
<img src="https://daveon.design/images/vegemite-boiled-malt-and-slurry-liquid-2.webp"><figcaption role="complementary "><span>The resulting two syrups: on the left, heavily reduced malt wort to a very dark, sweet, flavourful syrup; on the right, the main Vegemite flavour comes from the boiled-down reduction from the yeast slurry.</span> <br><span>A good cooking blog would show these two dishes very clean, with no drip remnants, but all this stuff is thick, sticky, and messy.</span> </figcaption><span><span></span>
</span></figure><p><span>The final major ingredient is nutritional yeast.</span> <span>We mixed several tablespoons with warm water to make a light yellow sludge.</span> <span><span></span> <span><span>The names for the ingredients—slurries, sludges—are as appetizing as many non-Australians claim Vegemite to be.</span> </span> <span></span> </span><span> </span></p><h3 id="taste-testing">Taste Testing</h3>
<p><span>A taste test gave:</span></p><ul>
<li><span>Boiled slurry liquid: Vegemite or Marmite overtones, but surprisingly bitter (perhaps the result of hops?)</span> </li><li><span>Boiled, thick malt: unexpectedly, a strong ‘this taste is not Vegemite but is in Vegemite’ response.</span> <span><span></span> <span><span>Vegemite does not taste like malt, and you would never eat Vegemite and think of malt, yet boiled-down malt wort syrup distinctly resembles very sweet Vegemite.</span> </span> <span></span> </span><span> </span></li></ul>
</section><section><h2 id="mixing">Mixing</h2><span></span>
<div>
<p><img src="https://daveon.design/images/vegemite-mixing-1.webp">
</p>
<p><img src="https://daveon.design/images/vegemite-mixing-2.webp">
<br>Drag ⇢ 
</p></div>
<p><span>The Youtube video has no proportions, and even with large quantities of starting liquids we had only teaspoons of boiled-down results.</span> <span>Taking the entire boiled-down yeast slurry runoff liquid, perhaps three teaspoons or a little more, we added about half a teaspoon of malt, a generous dash of salt<span><span></span> <span><span>Vegemite is very salty.</span> </span> <span></span> </span><span>  and about a teaspoon of nutritional yeast sludge.</span> <span>Some vigorous mixing, some adjustment (a tiny bit more malt, plus a bit more salt)<span><span></span> <span><span>Vegemite is <em>very</em> salty.</span> </span> <span></span> </span><span>  and we deemed it done.</span> </span></span></p><figure>
<img src="https://daveon.design/images/vegemite-result.webp"><figcaption role="complementary "><span>The appetizingly-coloured result!</span> </figcaption><span><span></span>
</span></figure><p><span>It was not the right colour.</span> <span>Nor did it taste exactly like Vegemite, though it was very close.</span> <span>But the taste was <em>exactly</em> like <span>Marmite!</span> </span></p></section><section><h2 id="taste-tests">Taste Tests</h2>
<p><span>British friend:</span></p><blockquote>
<span>Bang on.</span> <span>Yeah.</span> <span>Feels like you should make it with beer that’s not very hoppy.</span> </blockquote>
<p><span>Friend’s partner:</span></p><blockquote>
<span>Really really close.</span> <span>A little more bitter maybe.</span> </blockquote>
<p><span>My wife:</span></p><blockquote>
<span>It’s softer, and more bitter, than Marmite.</span> <span>Marmite is very sticky, and this lacks the stickiness of Marmite.</span> <span>But it still tastes like Marmite.</span> </blockquote>
<p><span>To me: There was a strong hit of salt and then it fades into distinct Marmite flavour.</span> <span>Then a slight unwanted bitter note.</span> <span>The aftertaste is just like Vegemite.</span> <span>The next day, cold from the fridge, it seemed more sharp in flavour than the previous day.</span> <span>Overall, very in the Vegemite/Marmite family.</span> </p></section></section><section><h2 id="variations">Variations</h2>
<p><span><span>In the same taste-test,</span> we also tried a variant made by our Czech friend who supplied the beer slurry.</span> <span>He was not interested in recreating Vegemite <em>per se,</em> but in creating an umami stock he could use for cooking.</span> <span>So he’d boiled it down with stock cubes and a lot more malt: the colour was right (very dark due to the malt) but it was sweet and very much not Vegemite.</span> </p><p><span>For ours, the main consensus is that there is a hint more bitterness in our Mite than in Vegemite.</span> <span>This may be due to the beer that provided the slurry: it came from a well-hopped lager.</span> <span>Perhaps we need to add more malt to offset the bitterness; it’s a strong flavour though and risks overpowering the key Vegemite notes that come from the boiled-down beer slurry.</span> <span>I’d like to try again using slurry from making a stout or one of the sweeter porters, which may have fewer hops, a darker colour from the roasted grains, and could give a less bitter starting point.</span> </p><p><span>The majority of Australian beer is lager, and if Vegemite uses the most widely available beer remnants, it likely comes from some kind of light, hopped beer.</span> <span>I am curious how they get such a dark colour.</span> </p><p><span>Finally, Wikipedia claims Vegemite is made with celery and onion extracts.</span> <span>I’d like to try again using a stout/sweet porter as basis, and add celery salt and onion powder.</span> </p></section><section><h2 id="making-vegemite">Making Vegemite</h2>
<p><span><span>What did I get for an afternoon’s</span> worth of watching beery liquids boil down in my friend’s kitchen?</span> <span>I came home with three quarters of a teaspoon of brown runny goop… and somewhat of a fascination for <a href="https://en.wikipedia.org/wiki/Justus_von_Liebig#Marmite">how people invented this stuff in the first place</a>.</span> </p><figure>
<img src="https://daveon.design/images/vegemite-results-toast.webp"><figcaption role="complementary "><span>Left to right: Marmite, our spread, our Czech friend’s umami stock spread, and some nutritional yeast paste to round out the last slice of toast.</span> </figcaption><span><span></span>
</span></figure></section></article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mixture-of-Depths: Dynamically allocating compute in transformers (242 pts)]]></title>
            <link>https://arxiv.org/abs/2404.02258</link>
            <guid>39960717</guid>
            <pubDate>Sun, 07 Apr 2024 13:42:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2404.02258">https://arxiv.org/abs/2404.02258</a>, See on <a href="https://news.ycombinator.com/item?id=39960717">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2404.02258">View PDF</a>
    <a href="https://arxiv.org/html/2404.02258v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Transformer-based language models spread FLOPs uniformly across input sequences. In this work we demonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute) to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth. Our method enforces a total compute budget by capping the number of tokens ($k$) that can participate in the self-attention and MLP computations at a given layer. The tokens to be processed are determined by the network using a top-$k$ routing mechanism. Since $k$ is defined a priori, this simple procedure uses a static computation graph with known tensor sizes, unlike other conditional computation techniques. Nevertheless, since the identities of the $k$ tokens are fluid, this method can expend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure is entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do models trained in this way learn to dynamically allocate compute, they do so efficiently. These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50\% faster to step during post-training sampling.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Adam Santoro [<a href="https://arxiv.org/show-email/7e3a6283/2404.02258">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 2 Apr 2024 19:28:11 UTC (1,763 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blog posts, sorted by sleep (189 pts)]]></title>
            <link>https://breckyunits.com/sleepWriting.html</link>
            <guid>39960645</guid>
            <pubDate>Sun, 07 Apr 2024 13:32:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://breckyunits.com/sleepWriting.html">https://breckyunits.com/sleepWriting.html</a>, See on <a href="https://news.ycombinator.com/item?id=39960645">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><span>April 5, 2024 — </span>Have you ever examined the correlation between your writing behavior and sleep?</p>
<p>I've written some things in my life that make me cringe. I might cringe because I see some past writing was naive, mistaken, locked-in, overconfident, unkind, insensitive, aggressive, or grandiose.</p>
<p>I now have a pretty big dataset to identify my secret trick to write more cringe: less sleep.</p>
<p>For this post I combined 2,500 nights of sleep data with 58 blog posts. A 7 year experiment to see how sleep affects my writing.</p>
<figure><a href="https://breckyunits.com/less-sleeping-less-thinking.png" target="_blank"><img src="https://breckyunits.com/less-sleeping-less-thinking.png" width="1240" height="942" loading="lazy"></a><figcaption><p><a href="https://www.datawrapper.de/_/YsKWU/">Interactive version.</a></p></figcaption></figure>
<div><h2>~7 Hours is the Cutoff</h2>
<p>Most posts above 7 hours of sleep do not need a sleep disclaimer. Most posts below 7 hours do. Not to say there is no value in the posts made with under 7 hours of sleep, it's just less rigorous writing (and thinking). On the plus side, writing with little sleep can be more concise at times. It might exaggerate the key ideas, but nevertheless identify them fearlessly and concisely.</p>
</div>

<figure><a href="https://breckyunits.com/sleeping-less-is-slightly-correlated-with-posting-more.png" target="_blank"><img src="https://breckyunits.com/sleeping-less-is-slightly-correlated-with-posting-more.png" width="1240" height="1006" loading="lazy"></a></figure>
<div><h2>More Posts. Similar Word Counts. Higher Scatteredness. Similar IQ. Higher Confidence.</h2>
<p>I actually post slightly more when I sleep less (Pearson correlation coefficient of -.14), but fewer words per post, which is indicative of a more "scattered" thinking state. I was surprised to see that I don't generally generate a whole lot more words in deprived sleep states. I <em>perceive</em> my writing to be smarter during those times, but looking back it's clearly not.</p>
</div>
<div><h2>Other Social Media</h2>
<p>Besides this blog, I have long written and posted content to HackerNews, Reddit, other discussion forums, and at times Twitter, Instagram, Facebook, YouTube, and LinkedIn. I haven't done the data grunt work, but if my memory serves me correctly I am confident my publishing behavior on those platforms mirrors the same patterns as my blogging behavior, with regards to sleep.</p>
</div>
<div><h2>Public vs Private Writing</h2>
<p>There have been stretches where I published little publicly but was generating a similar amount of tokens, just in private groups. My writing patterns in private groups also mirrors my patterns on this blog, with regards to sleep.</p>
</div>
<p>Tangent: when I've been lucky to be a part of brainiac private organizations (such as Microsoft, YCombinator, Our World in Data, academia, and so on), I got to read so much brilliant writing by people who rarely post publicly, and every time I think about that I am humbled. There is so much well written content on the public web, and to think it is <em>only a fraction</em> of the great content ever written, is humbling.</p>
<div><h2>Sleep Disclaimers</h2>
<p>I realize I already have an unofficial "sleep disclaimer" policy. I have de-indexed (but kept published) at least a couple of sleep-deprived posts, and added a disclaimer/correction to at least 2 others. Now with this dataset I am sure I will append a few more sleep disclaimers.</p>
</div>
<p>With sleep disclaimers, I can say, "hey, might be interesting ideas here, but don't train too heavily on this".</p>
<div><h2>Grateful for Git</h2>
<p>I am happy with my decision to use git for this blog so that I always keep an honest history, while still being free to down weight sleep deprived content and try and keep my more thought-out out ideas front and center.</p>
</div>
<div><h2>Benefits of Peer Review</h2>
<p>I don't have a column for it (yet), but it does seem my better posts often were the ones where I took the time to get friends and/or colleagues to review, IRL. Sleep deprived posts I would generally blast out without talking to anyone.</p>
</div>
<p>Peer review is a great filter, and a great forcing function to put more effort in.</p>
<p>On the other hand, because the importance of ideas varies by so many orders of magnitude (there are "black swan" ideas), you could make an argument that spending too much time in one area of ideas isn't the optimal strategy, and publishing things as you go, improving them later, is an approach with merit.</p>
<div><h2>Writing data reflects the current phenomena in your brain</h2>
<p>It seems when I sleep less, my brain is in more of a pleasure seeking state, has a bias to action ("don't think, just do"), and feels less pain than in a more rested state. Less sleep means less critical thinking. Less sleep seems to make me less willing to invest the time in rewiring my brain to correct mistaken thought habits. </p>
</div>
<div><h2>Grateful for FitBit</h2>
<p>I started wearing a Microsoft Band when it first came out in November 2014. Then a Band 2, then FitBit Charge, Ionic, Versa, and now Sense 2. I am grateful for all the people involved with creating these things. I think continued progress in the wearable sensor field is the best bet for improving human health.</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I open-sourced the in-memory PostgreSQL I built at work for E2E tests (283 pts)]]></title>
            <link>https://github.com/stackframe-projects/pgmock</link>
            <guid>39960537</guid>
            <pubDate>Sun, 07 Apr 2024 13:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/stackframe-projects/pgmock">https://github.com/stackframe-projects/pgmock</a>, See on <a href="https://news.ycombinator.com/item?id=39960537">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">pgmock</h2><a id="user-content-pgmock" aria-label="Permalink: pgmock" href="#pgmock"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://stackframe-projects.github.io/pgmock" rel="nofollow">Demo</a> —
  <a href="https://discord.gg/pD4nyYyKrb" rel="nofollow">Discord</a>
</h3><a id="user-content---demo---discord" aria-label="Permalink: Demo —
  Discord" href="#--demo---discord"></a></p>
<p dir="auto"><code>pgmock</code> is an in-memory PostgreSQL mock server for unit and E2E tests. It requires no external dependencies and runs entirely within WebAssembly on both Node.js and the browser.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">If you'd like to run <code>pgmock</code> in a browser, see the <a href="#browser-support">Browser support</a> section for detailed instructions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">You can run an in-memory server like so:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { PostgresMock } from &quot;pgmock&quot;;

const mock = await PostgresMock.create();
const connectionString = await mock.listen(5432);"><pre><span>import</span> <span>{</span> <span>PostgresMock</span> <span>}</span> <span>from</span> <span>"pgmock"</span><span>;</span>

<span>const</span> <span>mock</span> <span>=</span> <span>await</span> <span>PostgresMock</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>connectionString</span> <span>=</span> <span>await</span> <span>mock</span><span>.</span><span>listen</span><span>(</span><span>5432</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Recommended: If you use <code>node-postgres</code> (<code>pg</code> on npm), <code>pgmock</code> provides you with a configuration object that doesn't require you to serve on a port (and also works in the browser):</p>
<div dir="auto" data-snippet-clipboard-copy-content="import * as pg from &quot;pg&quot;;

const mock = await PostgresMock.create();
const client = new pg.Client(mock.getNodePostgresConfig());

await client.connect();
console.log(await client.query('SELECT $1::text as message', ['Hello world!']));"><pre><span>import</span> <span>*</span> <span>as</span> <span>pg</span> <span>from</span> <span>"pg"</span><span>;</span>

<span>const</span> <span>mock</span> <span>=</span> <span>await</span> <span>PostgresMock</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>pg</span><span>.</span><span>Client</span><span>(</span><span>mock</span><span>.</span><span>getNodePostgresConfig</span><span>(</span><span>)</span><span>)</span><span>;</span>

<span>await</span> <span>client</span><span>.</span><span>connect</span><span>(</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>client</span><span>.</span><span>query</span><span>(</span><span>'SELECT $1::text as message'</span><span>,</span> <span>[</span><span>'Hello world!'</span><span>]</span><span>)</span><span>)</span><span>;</span></pre></div>
<p dir="auto">It is considered good practice to destroy the mock server after you are done with it to free up resources:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Check the <a href="https://github.com/stackframe-projects/pgmock/blob/main/src/postgres-mock.ts">PostgresMock source file</a> for a list of all available methods and their documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Browser support</h2><a id="user-content-browser-support" aria-label="Permalink: Browser support" href="#browser-support"></a></p>
<p dir="auto"><code>pgmock</code> fully supports browser environments. While webapps can't listen to TCP ports, you can still use <code>PostgresMock.createSocket</code> and the <code>node-postgres</code> configuration. However, if your bundler statically analyzes imports, the default configuration may show a warning because of missing (optional) Node.js modules. Check <code>examples/web-demo/next.config.mjs</code> for an example on how to configure Webpack for bundling.</p>
<p dir="auto">If you're only looking to run a database in the browser, you might want to consider <a href="https://github.com/electric-sql/pglite">pglite</a> instead. It is more performant and lightweight, but only has a limited feature set. <code>pgmock</code> is designed for feature parity with production PostgreSQL environments, as you would want in a testing environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">There are two approaches to run Postgres in WebAssembly; by <a href="https://github.com/electric-sql/postgres-wasm">forking it to support WASM natively</a> or by <a href="https://supabase.com/blog/postgres-wasm" rel="nofollow">emulating the Postgres server in an x86 emulator</a>. The former is more performant and uses considerably less memory, but only supports single-user mode (no connections), and no extensions.</p>
<p dir="auto">To prevent discrepancies between testing and production, and because performance is not usually a concern in tests, <code>pgmock</code> currently uses the latter approach. In the mid-term future, once native Postgres WASM forks mature, we plan to make both options available, and eventually, switch to native WASM as default. We don't expect there to be many breaking changes besides the APIs inside <code>PostgresMock.subtle</code>.</p>
<p dir="auto"><code>pgmock</code> differs from previous Postgres-in-the-browser projects by providing full feature-compatibility entirely inside the JavaScript runtime, without depending on a network proxy for communication. We did this by simulating a network stack in JavaScript that behaves like a real network, that can simulate TCP connections even on platforms that do not allow raw socket access.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Wanna contribute?</h2><a id="user-content-wanna-contribute" aria-label="Permalink: Wanna contribute?" href="#wanna-contribute"></a></p>
<p dir="auto">Great! We have a <a href="https://discord.gg/pD4nyYyKrb" rel="nofollow">Discord server</a> where you can talk to us.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Can this run other Docker images or databases?</h2><a id="user-content-can-this-run-other-docker-images-or-databases" aria-label="Permalink: Can this run other Docker images or databases?" href="#can-this-run-other-docker-images-or-databases"></a></p>
<p dir="auto">In theory, yes. I just haven't tested them. Ping me on our <a href="https://discord.gg/pD4nyYyKrb" rel="nofollow">Discord server</a> if you're interested.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/copy/v86">v86</a>, the x86 emulator which makes this possible</li>
<li><a href="https://supabase.com/blog/postgres-wasm" rel="nofollow">Supabase &amp; Snaplet</a> for building their own approach of running Postgres inside WebAssembly, which this is based on</li>
<li><a href="https://stackframe.co/" rel="nofollow">Stackframe</a> for keeping me on a payroll while I was building <code>pgmock</code></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ClangQL: A tool to run SQL-like query on C/C++ Code (111 pts)]]></title>
            <link>https://github.com/AmrDeveloper/ClangQL</link>
            <guid>39960535</guid>
            <pubDate>Sun, 07 Apr 2024 13:13:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AmrDeveloper/ClangQL">https://github.com/AmrDeveloper/ClangQL</a>, See on <a href="https://news.ycombinator.com/item?id=39960535">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ClangQL - Clang AST Query Language</h2><a id="user-content-clangql---clang-ast-query-language" aria-label="Permalink: ClangQL - Clang AST Query Language" href="#clangql---clang-ast-query-language"></a></p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/AmrDeveloper/ClangQL/blob/master/media/clangql_logo.svg"><img src="https://github.com/AmrDeveloper/ClangQL/raw/master/media/clangql_logo.svg" width="20%" height="20%"></a>
</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1531c20d64a49760c4bfd70a9689861e5b3bd0b56f15c3f32d3da2b099d750df/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f636c616e67716c3f7374796c653d666c61742d737175617265"><img alt="Crates.io" src="https://camo.githubusercontent.com/1531c20d64a49760c4bfd70a9689861e5b3bd0b56f15c3f32d3da2b099d750df/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f636c616e67716c3f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/crates/v/clangql?style=flat-square"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6302052a609fdfc518cb92d7a05c93f1008386210057e1be2e5b3618f5410f26/68747470733a2f2f646570732e72732f7265706f2f6769746875622f616d72646576656c6f7065722f636c616e67716c2f7374617475732e737667"><img alt="Deps" src="https://camo.githubusercontent.com/6302052a609fdfc518cb92d7a05c93f1008386210057e1be2e5b3618f5410f26/68747470733a2f2f646570732e72732f7265706f2f6769746875622f616d72646576656c6f7065722f636c616e67716c2f7374617475732e737667" data-canonical-src="https://deps.rs/repo/github/amrdeveloper/clangql/status.svg"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/108ab52c954f90085e23ddb1da4751a08b3cc4591c9cda5319afadd162da3819/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f616d72646576656c6f7065722f636c616e67716c"><img alt="GitHub issues" src="https://camo.githubusercontent.com/108ab52c954f90085e23ddb1da4751a08b3cc4591c9cda5319afadd162da3819/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f616d72646576656c6f7065722f636c616e67716c" data-canonical-src="https://img.shields.io/github/issues/amrdeveloper/clangql"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a41fce30cc4544cc983c190f01021defdd17d1af49f62882537e28a582192022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616d72646576656c6f7065722f636c616e67716c"><img alt="GitHub" src="https://camo.githubusercontent.com/a41fce30cc4544cc983c190f01021defdd17d1af49f62882537e28a582192022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616d72646576656c6f7065722f636c616e67716c" data-canonical-src="https://img.shields.io/github/license/amrdeveloper/clangql"></a>
</p>
<p dir="auto">
ClangQL is a tool that allow you to run SQL-like query on C/C++ Code instead of database files using the GitQL SDK.
</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/AmrDeveloper/ClangQL/blob/master/media/clangql_demo.PNG"><img src="https://github.com/AmrDeveloper/ClangQL/raw/master/media/clangql_demo.PNG" alt="animated" width="100%"></a>
</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Samples</h3><a id="user-content-samples" aria-label="Permalink: Samples" href="#samples"></a></p>
<p dir="auto">Note that all Keywords in ClangQL are case-insensitive, similar to SQL.</p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT 1
SELECT 1 + 2
SELECT LEN(&quot;File Query Language&quot;)
SELECT &quot;One&quot; IN (&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;)
SELECT &quot;File Query Language&quot; LIKE &quot;%Query%&quot;

SELECT * FROM functions
SELECT COUNT(name) from functions WHERE return_type = &quot;int&quot;
SELECT DISTINCT name AS function_name FROM functions"><pre><span>SELECT</span> <span>1</span>
<span>SELECT</span> <span>1</span> <span>+</span> <span>2</span>
<span>SELECT</span> LEN(<span><span>"</span>File Query Language<span>"</span></span>)
<span>SELECT</span> <span><span>"</span>One<span>"</span></span> <span>IN</span> (<span><span>"</span>One<span>"</span></span>, <span><span>"</span>Two<span>"</span></span>, <span><span>"</span>Three<span>"</span></span>)
<span>SELECT</span> <span><span>"</span>File Query Language<span>"</span></span> <span>LIKE</span> <span><span>"</span>%Query%<span>"</span></span>

<span>SELECT</span> <span>*</span> <span>FROM</span> functions
<span>SELECT</span> <span>COUNT</span>(name) <span>from</span> functions <span>WHERE</span> return_type <span>=</span> <span><span>"</span>int<span>"</span></span>
<span>SELECT DISTINCT</span> name <span>AS</span> function_name <span>FROM</span> functions</pre></div>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Functions table structure</h3><a id="user-content-functions-table-structure" aria-label="Permalink: Functions table structure" href="#functions-table-structure"></a></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>Text</td>
<td>Function or Method name</td>
</tr>
<tr>
<td>signature</td>
<td>Text</td>
<td>Parameters and return type literal</td>
</tr>
<tr>
<td>args_count</td>
<td>Integer</td>
<td>Number of arguments</td>
</tr>
<tr>
<td>return_type</td>
<td>Text</td>
<td>Return type literal</td>
</tr>
<tr>
<td>is_method</td>
<td>Boolean</td>
<td>True if it's a method</td>
</tr>
</tbody>
</table>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Download or Install</h3><a id="user-content-download-or-install" aria-label="Permalink: Download or Install" href="#download-or-install"></a></p>
<p dir="auto">Note that Building from source or installing from Cargo.io requires LibClang 17 to be installed</p>
<ul dir="auto">
<li>Install from Cargo.io</li>
</ul>

<ul dir="auto">
<li>Build from source code</li>
</ul>
<div data-snippet-clipboard-copy-content="git clone https://github.com/AmrDeveloper/clangql.git
cd clangql
cargo build"><pre><code>git clone https://github.com/AmrDeveloper/clangql.git
cd clangql
cargo build
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run ClangQL</h3><a id="user-content-run-clangql" aria-label="Permalink: Run ClangQL" href="#run-clangql"></a></p>
<div data-snippet-clipboard-copy-content="ClangQL is a SQL like query language to run on local files
Usage: ClangQL [OPTIONS]

Options:
  -f,  --files <paths>        Path for local files to run query on
  -q,  --query <GQL Query>    ClangQL query to run on selected files
  -p,  --pagination           Enable print result with pagination
  -ps, --pagesize             Set pagination page size [default: 10]
  -o,  --output               Set output format [render, json, csv]
  -a,  --analysis             Print Query analysis
  -h,  --help                 Print ClangQL help
  -v,  --version              Print ClangQL Current Version"><pre><code>ClangQL is a SQL like query language to run on local files
Usage: ClangQL [OPTIONS]

Options:
  -f,  --files &lt;paths&gt;        Path for local files to run query on
  -q,  --query &lt;GQL Query&gt;    ClangQL query to run on selected files
  -p,  --pagination           Enable print result with pagination
  -ps, --pagesize             Set pagination page size [default: 10]
  -o,  --output               Set output format [render, json, csv]
  -a,  --analysis             Print Query analysis
  -h,  --help                 Print ClangQL help
  -v,  --version              Print ClangQL Current Version
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<div data-snippet-clipboard-copy-content="MIT License

Copyright (c) 2024 Amr Hesham

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE."><pre><code>MIT License

Copyright (c) 2024 Amr Hesham

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Public DNS's approach to fight against cache poisoning attacks (184 pts)]]></title>
            <link>https://security.googleblog.com/2024/03/google-public-dnss-approach-to-fight.html</link>
            <guid>39960125</guid>
            <pubDate>Sun, 07 Apr 2024 11:46:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2024/03/google-public-dnss-approach-to-fight.html">https://security.googleblog.com/2024/03/google-public-dnss-approach-to-fight.html</a>, See on <a href="https://news.ycombinator.com/item?id=39960125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Command Injection and Backdoor Account in D-Link NAS Devices (199 pts)]]></title>
            <link>https://github.com/netsecfish/dlink</link>
            <guid>39960107</guid>
            <pubDate>Sun, 07 Apr 2024 11:39:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/netsecfish/dlink">https://github.com/netsecfish/dlink</a>, See on <a href="https://news.ycombinator.com/item?id=39960107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Command Injection and Backdoor Account in D-Link NAS Devices</h2><a id="user-content-command-injection-and-backdoor-account-in-d-link-nas-devices" aria-label="Permalink: Command Injection and Backdoor Account in D-Link NAS Devices" href="#command-injection-and-backdoor-account-in-d-link-nas-devices"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Vulnerability Summary:</strong></h2><a id="user-content-vulnerability-summary" aria-label="Permalink: Vulnerability Summary:" href="#vulnerability-summary"></a></p>
<p dir="auto">The described vulnerability affects multiple D-Link NAS devices, including models DNS-340L, DNS-320L, DNS-327L, and DNS-325, among others. The vulnerability lies within the <strong><code>nas_sharing.cgi</code></strong> uri, which is vulnerable due to two main issues: a backdoor facilitated by hardcoded credentials, and a command injection vulnerability via the <strong><code>system</code></strong> parameter. This exploitation could lead to arbitrary command execution on the affected D-Link NAS devices, granting attackers potential access to sensitive information, system configuration alteration, or denial of service, by specifying a command,affecting over 92,000 devices on the Internet.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/netsecfish/dlink/blob/main/fofa-result.png"><img src="https://github.com/netsecfish/dlink/raw/main/fofa-result.png" alt="Untitled"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Corresponding CWE</h2><a id="user-content-corresponding-cwe" aria-label="Permalink: Corresponding CWE" href="#corresponding-cwe"></a></p>
<p dir="auto">CWE-77 (Command Injection) and CWE-798 (Use of Hard-coded Credentials).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Affected Devices:</h2><a id="user-content-affected-devices" aria-label="Permalink: Affected Devices:" href="#affected-devices"></a></p>
<ul dir="auto">
<li>DNS-320L Version 1.11, Version 1.03.0904.2013, Version 1.01.0702.2013</li>
<li>DNS-325 Version 1.01</li>
<li>DNS-327L Version 1.09, Version 1.00.0409.2013</li>
<li>DNS-340L Version 1.08</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Vulnerability Details:</h2><a id="user-content-vulnerability-details" aria-label="Permalink: Vulnerability Details:" href="#vulnerability-details"></a></p>
<p dir="auto">The vulnerability exists in the <code>nas_sharing.cgi</code> CGI script, which leads to:</p>
<ol dir="auto">
<li><strong>Backdoor through Username and Password Exposure</strong>: The request includes parameters for a username (<strong><code>user=messagebus</code></strong>) and an empty password field (<strong><code>passwd=</code></strong>). This indicates a backdoor allowing unauthorized access without proper authentication.</li>
<li><strong>Command Injection through the System Parameter</strong>: The <strong><code>system</code></strong> parameter within the request carries a base64 encoded value that, when decoded, appears to be a command.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exploitation:</h2><a id="user-content-exploitation" aria-label="Permalink: Exploitation:" href="#exploitation"></a></p>
<p dir="auto">Craft Malicious HTTP Request: Prepare an HTTP GET request targeting the <code>/cgi-bin/nas_sharing.cgi</code> endpoint.</p>
<div data-snippet-clipboard-copy-content="GET /cgi-bin/nas_sharing.cgi?user=messagebus&amp;passwd=&amp;cmd=15&amp;system=<BASE64_ENCODED_COMMAND_TO_BE_EXECUTED>"><pre><code>GET /cgi-bin/nas_sharing.cgi?user=messagebus&amp;passwd=&amp;cmd=15&amp;system=&lt;BASE64_ENCODED_COMMAND_TO_BE_EXECUTED&gt;
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Actual Result</strong></h2><a id="user-content-actual-result" aria-label="Permalink: Actual Result" href="#actual-result"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/netsecfish/dlink/blob/main/dns-320.jpg"><img src="https://github.com/netsecfish/dlink/raw/main/dns-320.jpg" alt="Untitled"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Impact:</h2><a id="user-content-impact" aria-label="Permalink: Impact:" href="#impact"></a></p>
<p dir="auto">Successful exploitation of this vulnerability could allow an attacker to execute arbitrary commands on the system, potentially leading to unauthorized access to sensitive information, modification of system configurations, or denial of service conditions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Fix Recommendation:</strong></h2><a id="user-content-fix-recommendation" aria-label="Permalink: Fix Recommendation:" href="#fix-recommendation"></a></p>
<ul dir="auto">
<li>Apply available patches and updates from the device manufacturer.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Court approves 3M multi-billion dollar settlement over PFAS in drinking water (191 pts)]]></title>
            <link>https://www.cbsnews.com/minnesota/news/3m-pfas-drinking-water-settlement/</link>
            <guid>39960069</guid>
            <pubDate>Sun, 07 Apr 2024 11:26:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbsnews.com/minnesota/news/3m-pfas-drinking-water-settlement/">https://www.cbsnews.com/minnesota/news/3m-pfas-drinking-water-settlement/</a>, See on <a href="https://news.ycombinator.com/item?id=39960069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                                                                
                                                        
<article id="article-0" data-index="0" data-path="/minnesota/news/3m-pfas-drinking-water-settlement/">

  <div id="article-header" data-sort-time="1712029688000" data-update-time="1712029688000">
    <header>

      
      <div>

        <!-- show SVG here -->
                            <p><a href="https://www.cbsnews.com/minnesota/" data-invalid-url-rewritten-http="">
            <img width="60" height="60" alt="minnesota" src="https://www.cbsnews.com/assets/show/minnesota/logo-square-32.svg" loading="lazy"></a></p><!-- end show SVG -->

              <p>
    By
                        
              , 
                              
              <span>The Associated Press</span>
              </p>
  
          

        <p>
          <time datetime="2024-04-01T22:48:08-0500">Updated on:  April 1, 2024 / 10:48 PM CDT</time>
          / CBS/AP
        </p>
        


</div>

          </header></div>

      




  
  
      
        
  <figure data-ads="{&quot;extraWordCount&quot;:50}"><div>
      
      
                      



  <svg xmlns="http://www.w3.org/2000/svg" style="position:absolute;width:0;height:0"><defs><symbol id="player-icon-pause" viewBox="0 0 32 32"><path d="M4 4h10v24h-10zM18 4h10v24h-10z"></path></symbol><symbol id="player-icon-play" viewBox="0 0 32 32"><path d="M6 4l20 12-20 12z"></path></symbol><symbol id="player-icon-close" viewBox="0 0 32 32"><line stroke-width="6" x1="3" y1="3" x2="29" y2="29"></line><line stroke-width="6" x1="29" y1="3" x2="3" y2="29"></line></symbol><symbol id="player-icon-fullscreen" viewBox="0 0 32 32"><path d="M32 0h-13l5 5-6 6 3 3 6-6 5 5z"></path><path d="M32 32v-13l-5 5-6-6-3 3 6 6-5 5z"></path><path d="M0 32h13l-5-5 6-6-3-3-6 6-5-5z"></path><path d="M0 0v13l5-5 6 6 3-3-6-6 5-5z"></path></symbol><symbol id="player-icon-drag" viewBox="0 0 40 55"><g fill="#f5f5f5"><circle cx="5" cy="5" r="5"></circle><circle cx="20" cy="5" r="5"></circle><circle cx="35" cy="5" r="5"></circle><circle cx="5" cy="20" r="5"></circle><circle cx="20" cy="20" r="5"></circle><circle cx="35" cy="20" r="5"></circle><circle cx="5" cy="35" r="5"></circle><circle cx="20" cy="35" r="5"></circle><circle cx="35" cy="35" r="5"></circle><circle cx="5" cy="50" r="5"></circle><circle cx="20" cy="50" r="5"></circle><circle cx="35" cy="50" r="5"></circle></g></symbol></defs></svg><div data-theme="default" data-component="viewability" data-viewability-options="true">
                  <svg><use xlink:href="#player-icon-drag"></use></svg><p><span>Report finds some water filters can reduce PFAS from tap water </span>
        
        

      </p></div>
          </div>
          <figcaption><a href="https://www.cbsnews.com/minnesota/video/report-finds-some-water-filters-can-reduce-pfas-from-tap-water/" data-invalid-url-rewritten-http="">
          
          <span>
            </span>

          <span>Report finds some water filters can reduce PFAS from tap water</span>

          <span>01:54</span>

                      </a>
                  
        
        
              </figcaption></figure><section><p><strong>MINNEAPOLIS —</strong> Minnesota-based chemical manufacturer 3M will begin payments this summer to many U.S. public drinking water systems as part of a multi-billion-dollar settlement over contamination with potentially dangerous chemicals, the company said.</p><p>Communities in the east metro are especially impacted by the contamination.</p><p>3M announced Monday that last year's lawsuit settlement received final approval from the U.S. District Court in Charleston, South Carolina.</p><p>The agreement called for payouts through 2036. Depending on what additional contamination is found, the amount paid out will range from $10.5 billion to $12.5 billion.</p><p><strong>RELATED:&nbsp;</strong><span><a href="https://www.cbsnews.com/minnesota/news/minnesota-pfas-forever-chemicals-drinking-water/" target="_blank" data-invalid-url-rewritten-http=""><strong>Despite historic 3M PFAS payout, Minnesota communities need millions more for cleanup</strong></a></span></p>

    

<p>"This is yet another important step forward for 3M as we continue to deliver on our priorities. The final approval of this settlement and continued progress toward exiting all PFAS manufacturing by the end of 2025 will further our efforts to reduce risk and uncertainty as we move forward," 3M's chairman and CEO, Mike Roman, said in a news release.</p><p>Six years ago, 3M settled with the state for $850 million for disposing the chemicals and contaminating drinking water and our environment —&nbsp;<span><a href="https://www.cbsnews.com/minnesota/news/3m-agrees-to-10-3-billion-in-pfas-settlement/" target="_blank" data-invalid-url-rewritten-http="">one of the largest settlements of its kind in the country</a></span>.</p><p>The deal compensates water providers for pollution with per- and polyfluorinated substances, known collectively as PFAS — a broad class of chemicals used in nonstick, water- and grease-resistant products such as clothing and cookware.</p><p>PFAS have been described as "forever chemicals" because they don't degrade naturally in the environment. They've been linked to a variety of health problems, including liver and immune-system damage and some cancers.</p>

    
    

<p>The compounds have been detected at varying levels in drinking water nationwide. The Environmental Protection Agency in March 2023 proposed strict limits on two common types, PFOA and PFOS, and said it wanted to regulate four others. Water providers would be responsible for monitoring their systems for the chemicals.</p><p><strong>RELATED:&nbsp;<span><a href="https://www.cbsnews.com/minnesota/news/pfas-in-minnesota-how-forever-chemicals-changed-the-state-of-water/" target="_blank" data-invalid-url-rewritten-http="">PFAS in Minnesota: How "forever chemicals" changed the state of water</a></span></strong></p><p><span><a href="https://www.cbsnews.com/minnesota/news/minnesota-house-approves-environment-package-that-includes-ban-on-forever-chemicals-pfas/" target="_blank" data-invalid-url-rewritten-http="">A new state law passed last year</a></span>&nbsp;will ban PFAS in some consumer products starting in 2025 with a full ban in 2032. But prevention is only one part of the solution. Some communities like Woodbury and St. Louis County also want lawmakers to approve funding for PFAS mitigation in their infrastructure package this year.</p><p>The <span><a href="https://www.cbsnews.com/minnesota/news/3m-agrees-to-10-3-billion-in-pfas-settlement/" target="_blank" data-invalid-url-rewritten-http="">3M settlement first announced in June</a></span> came in a lawsuit by Stuart, Florida, one of about 300 communities that had filed similar suits against companies that produced firefighting foam or the PFAS it contained. The payment will help cover the costs of filtering PFAS from systems.</p><p>Some of the settlement money will help additional water systems test for contamination from PFAS, said Scott Summy, one of the lead attorneys for those suing 3M and other manufacturers. They have until June 2026 to apply for compensation if contamination is found. </p><p>"That's great news for American citizens who drink from that water," Summy said. "It'll help rid our public drinking water systems of PFAS, and that's the most important thing about the settlement."</p><p>3M&nbsp;<span><a href="https://www.cbsnews.com/minnesota/news/3m-plans-to-end-manufacturing-and-use-of-pfas-by-end-of-2025/" target="_blank" data-invalid-url-rewritten-http="">pledged</a></span>&nbsp;in late 2022 that the company would stop manufacturing and using PFAS by the end of 2025.</p>
                  
        
      
                  
    <!-- data-recirc-source="queryly" -->

    <!-- tags --><ul>In:
          <li><a href="https://www.cbsnews.com/minnesota/tag/health/">Health</a></li>
          <li><a href="https://www.cbsnews.com/minnesota/tag/charleston/">Charleston</a></li>
          <li><a href="https://www.cbsnews.com/minnesota/tag/lawsuit/">Lawsuit</a></li>
      </ul><div>
      <p><a href="https://www.cbsnews.com/minnesota/search/author/wcco-staff/" data-invalid-url-rewritten-http="">WCCO Staff</a></p><div>
                  <p><a href="https://www.cbsnews.com/minnesota/search/author/wcco-staff/" data-invalid-url-rewritten-http="">
              <span><img src="https://www.cbsnews.com/minnesota/news/3m-pfas-drinking-water-settlement/512-appicon-minnesota.png" alt="512-appicon-minnesota.png " height="80" width="80" data-srcset="https://assets3.cbsnewsstatic.com/hub/i/r/2023/04/14/3f903c1c-7834-4b45-9e2a-d1e23d837478/thumbnail/80x80/e370a104780595f243857bf615c869d6/512-appicon-minnesota.png?v=95af720165ffeea582866d60dd9b1b18 1x" srcset="data:image/svg+xml,%3Csvg%20xmlns%3D'http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg'%20viewBox%3D'0%200%2080%2080'%2F%3E"></span>
            </a>
          </p>
                  <div>
            <p>The WCCO Staff is a group of experienced journalists who bring you the content on WCCO.com.</p>
                          <p>
                                                                                              <a href="https://twitter.com/wcco" rel="nofollow noopener">
                      
                      Twitter
                    </a>
                
                                                                        
                  <a href="https://facebook.com/CBSMinnesota" rel="nofollow noopener">
                    
                    Facebook
                  </a>
                
                
                                                                
                <a href="https://instagram.com/wcco" rel="nofollow noopener">
                  
                  Instagram
                </a>
                        </p>
                </div>
      </div>
    </div>
      </section>
  </article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did any processor implement an integer square root instruction? (216 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/29787/did-any-processor-implement-an-integer-square-root-instruction</link>
            <guid>39959946</guid>
            <pubDate>Sun, 07 Apr 2024 10:55:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/29787/did-any-processor-implement-an-integer-square-root-instruction">https://retrocomputing.stackexchange.com/questions/29787/did-any-processor-implement-an-integer-square-root-instruction</a>, See on <a href="https://news.ycombinator.com/item?id=39959946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p><strong>It's not that easy.</strong></p>
<p>The most efficient method to calculate square root is to calculate inverse/reciprocal of the square root using Newton-Raphson iterations, and then multiply it with the original.</p>
<p>This is best known as the <a href="https://thatonegamedev.com/math/fast-square-root-quake-iii/" rel="noreferrer">"Quake method"</a> (see also <a href="https://retrocomputing.stackexchange.com/q/4615/79">Where did Fast InvSqrt() come from?</a>). The more modern version used by contemporary CPU and GPUs are generalized into two instructions, one for estimating the initial guess (e.g. <a href="https://developer.arm.com/documentation/ddi0602/2022-03/SIMD-FP-Instructions/FRSQRTE--Floating-point-Reciprocal-Square-Root-Estimate-?lang=en" rel="noreferrer">frsqrte of ARMv8</a>), another to run the following iterations (e.g. <a href="https://developer.arm.com/documentation/ddi0602/2022-03/SIMD-FP-Instructions/FRSQRTS--Floating-point-Reciprocal-Square-Root-Step-?lang=en" rel="noreferrer">frsqrts of ARMv8</a>). Single-instruction version of sqrt is a micro-coded or pseudo-instruction version of these two instructions.</p>
<p><strong>The prerequisite for all of this is a multiplier.</strong></p>
<p>If you want to calculate FP (i)sqrt, then you need a (fast) FP multiplier, which all FPUs have.</p>
<p>If you want to calculate integer (i)sqrt, then you need a (fast) integer multiplier, which most CPUs <strong>don't</strong> have (historically). Otherwise it would be called a <strong>DSP</strong>.</p>
<p>To make it better, you need a (fast) multiplier that is twice the width of your input to have sufficient precision, which most CPUs definitely don't have until "relatively" recently (relative to RetroComputing).</p>
<p><strong>And precision matters, or not?</strong></p>
<p>If you look at the "Quake method" closely, you notice that one of the iterations was commented out.</p>
<p>There are a lot of use cases where the extreme precision isn't necessary and it'll be better to leave the choice of precision/speed trade off to programmers. <code>isqrt</code> was intentionally separated into <code>fsqrte</code> and <code>fsqrts</code> on ARMv8 exactly for this reason: so that the programmer can adjust the number of <code>fsqrts</code> for the desired speed and accuracy tradeoff.</p>
<p>So I don't quite agree to the statement that single instruction sqrt is very common. It's there because the IEEEE754 and the C stand math library requires it (for the flag bits and exceptions), but that doesn't mean it's frequently used.</p>
<p><strong>Further reading</strong></p>
<ul>
<li><a href="https://www.ti.com/tool/SPRC542" rel="noreferrer">SPRC542</a> TI's math library for C64x DSP (8-issue VLIW CPU with two 32x32=64 multipliers). In this library <code>_iq _IQisqrt</code> is implemented using Newton-Raphson iterations and <code>_iq _IQsqrt</code> is calculated by multiplying the original with the isqrt. The source code is available on request.</li>
<li><a href="https://www.ti.com/lit/ug/sprugg9/sprugg9.pdf" rel="noreferrer">SPRUGG9</a> TMS320C64x+ IQmath Library User's Guide.The user guide for SPRC542.</li>
<li>My implementation of square root using binary search, that doesn't depend on a multiplier. Only basic ALU instructions are used. It is vigorously undocumented. I have no idea what I wrote but it seems to work.</li>
</ul>
<p>.</p>
<pre><code>unsigned int usqrt(unsigned int x){
    unsigned int a=0;
    unsigned int masksq=0,mask=0;
    unsigned int mask_shift=15;
    for(masksq=1u&lt;&lt;(mask_shift&lt;&lt;1),mask=1u&lt;&lt;(mask_shift);
        mask!=0;
        masksq=masksq&gt;&gt;2,mask=mask&gt;&gt;1,mask_shift--){
        if(x&gt;=masksq){
            a=mask;
            break;
        }
    }
    x-=masksq;//masksq==a*a;
    mask=mask&gt;&gt;1;
    mask_shift--;
    while(mask&gt;0){
        unsigned int step=(mask&lt;&lt;mask_shift)+(a&lt;&lt;(mask_shift+1));
        if(x&gt;=step){
            a|=mask;
            x-=step;
        }
        mask=mask&gt;&gt;1;
        mask_shift--;
    }
    return a;
}
</code></pre>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SentenceTransformers: Python framework for sentence, text and image embeddings (181 pts)]]></title>
            <link>https://www.sbert.net/index.html</link>
            <guid>39959790</guid>
            <pubDate>Sun, 07 Apr 2024 10:23:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sbert.net/index.html">https://www.sbert.net/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39959790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="#">Sentence-Transformers</a>
        
      </nav>


      <div itemprop="articleBody" role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
            
  
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>You can install it using pip:</p>
<div><pre><span></span><span>pip</span> <span>install</span> <span>-</span><span>U</span> <span>sentence</span><span>-</span><span>transformers</span>
</pre></div>
<p>We recommend <strong>Python 3.8</strong> or higher, and at least <strong>PyTorch 1.11.0</strong>. See <a href="https://www.sbert.net/docs/installation.html">installation</a> for further installation options, especially if you want to use a GPU.</p>
</div>
<div id="usage">
<h2>Usage<a href="#usage" title="Permalink to this headline">¶</a></h2>
<p>The usage is as simple as:</p>
<div><pre><span></span><span>from</span> <span>sentence_transformers</span> <span>import</span> <span>SentenceTransformer</span>
<span>model</span> <span>=</span> <span>SentenceTransformer</span><span>(</span><span>"all-MiniLM-L6-v2"</span><span>)</span>

<span># Our sentences to encode</span>
<span>sentences</span> <span>=</span> <span>[</span>
    <span>"This framework generates embeddings for each input sentence"</span><span>,</span>
    <span>"Sentences are passed as a list of string."</span><span>,</span>
    <span>"The quick brown fox jumps over the lazy dog."</span>
<span>]</span>

<span># Sentences are encoded by calling model.encode()</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>)</span>

<span># Print the embeddings</span>
<span>for</span> <span>sentence</span><span>,</span> <span>embedding</span> <span>in</span> <span>zip</span><span>(</span><span>sentences</span><span>,</span> <span>embeddings</span><span>):</span>
    <span>print</span><span>(</span><span>"Sentence:"</span><span>,</span> <span>sentence</span><span>)</span>
    <span>print</span><span>(</span><span>"Embedding:"</span><span>,</span> <span>embedding</span><span>)</span>
    <span>print</span><span>(</span><span>""</span><span>)</span>
</pre></div>
</div>
<div id="performance">
<h2>Performance<a href="#performance" title="Permalink to this headline">¶</a></h2>
<p>Our models are evaluated extensively and achieve state-of-the-art performance on various tasks. Further, the code is tuned to provide the highest possible speed. Have a look at <a href="https://www.sbert.net/docs/pretrained_models.html">Pre-Trained Models</a> for an overview of available models and the respective performance on different tasks.</p>
</div>

<div id="citing-authors">
<h2>Citing &amp; Authors<a href="#citing-authors" title="Permalink to this headline">¶</a></h2>
<p>If you find this repository helpful, feel free to cite our publication <a href="https://arxiv.org/abs/1908.10084">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>reimers-2019-sentence-bert</span><span>,</span>
<span>  </span><span>title</span><span> </span><span>=</span><span> </span><span>"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"</span><span>,</span>
<span>  </span><span>author</span><span> </span><span>=</span><span> </span><span>"Reimers, Nils and Gurevych, Iryna"</span><span>,</span>
<span>  </span><span>booktitle</span><span> </span><span>=</span><span> </span><span>"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing"</span><span>,</span>
<span>  </span><span>month</span><span> </span><span>=</span><span> </span><span>"11"</span><span>,</span>
<span>  </span><span>year</span><span> </span><span>=</span><span> </span><span>"2019"</span><span>,</span>
<span>  </span><span>publisher</span><span> </span><span>=</span><span> </span><span>"Association for Computational Linguistics"</span><span>,</span>
<span>  </span><span>url</span><span> </span><span>=</span><span> </span><span>"https://arxiv.org/abs/1908.10084"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<p>If you use one of the multilingual models, feel free to cite our publication <a href="https://arxiv.org/abs/2004.09813">Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>reimers-2020-multilingual-sentence-bert</span><span>,</span>
<span>  </span><span>title</span><span> </span><span>=</span><span> </span><span>"Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation"</span><span>,</span>
<span>  </span><span>author</span><span> </span><span>=</span><span> </span><span>"Reimers, Nils and Gurevych, Iryna"</span><span>,</span>
<span>  </span><span>booktitle</span><span> </span><span>=</span><span> </span><span>"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"</span><span>,</span>
<span>  </span><span>month</span><span> </span><span>=</span><span> </span><span>"11"</span><span>,</span>
<span>  </span><span>year</span><span> </span><span>=</span><span> </span><span>"2020"</span><span>,</span>
<span>  </span><span>publisher</span><span> </span><span>=</span><span> </span><span>"Association for Computational Linguistics"</span><span>,</span>
<span>  </span><span>url</span><span> </span><span>=</span><span> </span><span>"https://arxiv.org/abs/2004.09813"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<p>If you use the code for <a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/data_augmentation">data augmentation</a>, feel free to cite our publication <a href="https://arxiv.org/abs/2010.08240">Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>thakur-2020-AugSBERT</span><span>,</span>
<span>  </span><span>title</span><span> </span><span>=</span><span> </span><span>"Augmented {SBERT}: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks"</span><span>,</span>
<span>  </span><span>author</span><span> </span><span>=</span><span> </span><span>"Thakur, Nandan and Reimers, Nils and Daxenberger, Johannes  and Gurevych, Iryna"</span><span>,</span>
<span>  </span><span>booktitle</span><span> </span><span>=</span><span> </span><span>"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"</span><span>,</span>
<span>  </span><span>month</span><span> </span><span>=</span><span> </span><span>jun</span><span>,</span>
<span>  </span><span>year</span><span> </span><span>=</span><span> </span><span>"2021"</span><span>,</span>
<span>  </span><span>address</span><span> </span><span>=</span><span> </span><span>"Online"</span><span>,</span>
<span>  </span><span>publisher</span><span> </span><span>=</span><span> </span><span>"Association for Computational Linguistics"</span><span>,</span>
<span>  </span><span>url</span><span> </span><span>=</span><span> </span><span>"https://www.aclweb.org/anthology/2021.naacl-main.28"</span><span>,</span>
<span>  </span><span>pages</span><span> </span><span>=</span><span> </span><span>"296--310"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<div>
<p><span>Overview</span></p>
<ul>
<li><a href="https://www.sbert.net/docs/installation.html">Installation</a><ul>
<li><a href="https://www.sbert.net/docs/installation.html#install-sentencetransformers">Install SentenceTransformers</a></li>
<li><a href="https://www.sbert.net/docs/installation.html#install-pytorch-with-cuda-support">Install PyTorch with CUDA support</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/quickstart.html">Quickstart</a><ul>
<li><a href="https://www.sbert.net/docs/quickstart.html#comparing-sentence-similarities">Comparing Sentence Similarities</a></li>
<li><a href="https://www.sbert.net/docs/quickstart.html#pre-trained-models">Pre-Trained Models</a></li>
<li><a href="https://www.sbert.net/docs/quickstart.html#training-your-own-embeddings">Training your own Embeddings</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/pretrained_models.html">Pretrained Models</a><ul>
<li><a href="https://www.sbert.net/docs/pretrained_models.html#model-overview">Model Overview</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_models.html#semantic-search">Semantic Search</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models">Multi-Lingual Models</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_models.html#image-text-models">Image &amp; Text-Models</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_models.html#other-models">Other Models</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html">Pretrained Cross-Encoders</a><ul>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html#ms-marco">MS MARCO</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html#squad-qnli">SQuAD (QNLI)</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html#stsbenchmark">STSbenchmark</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html#quora-duplicate-questions">Quora Duplicate Questions</a></li>
<li><a href="https://www.sbert.net/docs/pretrained_cross-encoders.html#nli">NLI</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/publications.html">Publications</a></li>
<li><a href="https://www.sbert.net/docs/hugging_face.html">Hugging Face 🤗</a><ul>
<li><a href="https://www.sbert.net/docs/hugging_face.html#the-hugging-face-hub">The Hugging Face Hub</a></li>
<li><a href="https://www.sbert.net/docs/hugging_face.html#using-hugging-face-models">Using Hugging Face models</a></li>
<li><a href="https://www.sbert.net/docs/hugging_face.html#sharing-your-models">Sharing your models</a></li>
<li><a href="https://www.sbert.net/docs/hugging_face.html#sharing-your-embeddings">Sharing your embeddings</a></li>
<li><a href="https://www.sbert.net/docs/hugging_face.html#additional-resources">Additional resources</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Usage</span></p>
<ul>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html">Computing Sentence Embeddings</a><ul>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html#prompt-templates">Prompt Templates</a></li>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html#input-sequence-length">Input Sequence Length</a></li>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html#storing-loading-embeddings">Storing &amp; Loading Embeddings</a></li>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html#multi-process-multi-gpu-encoding">Multi-Process / Multi-GPU Encoding</a></li>
<li><a href="https://www.sbert.net/examples/applications/computing-embeddings/README.html#sentence-embeddings-with-transformers">Sentence Embeddings with Transformers</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/usage/semantic_textual_similarity.html">Semantic Textual Similarity</a></li>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html">Embedding Quantization</a><ul>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html#binary-quantization">Binary Quantization</a></li>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html#scalar-int8-quantization">Scalar (int8) Quantization</a></li>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html#additional-extensions">Additional extensions</a></li>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html#demo">Demo</a></li>
<li><a href="https://www.sbert.net/examples/applications/embedding-quantization/README.html#try-it-yourself">Try it yourself</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html">Semantic Search</a><ul>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#background">Background</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#symmetric-vs-asymmetric-semantic-search">Symmetric vs. Asymmetric Semantic Search</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#python">Python</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#util-semantic-search">util.semantic_search</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#speed-optimization">Speed Optimization</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#elasticsearch">Elasticsearch</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#approximate-nearest-neighbor">Approximate Nearest Neighbor</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#retrieve-re-rank">Retrieve &amp; Re-Rank</a></li>
<li><a href="https://www.sbert.net/examples/applications/semantic-search/README.html#examples">Examples</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html">Retrieve &amp; Re-Rank</a><ul>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#retrieve-re-rank-pipeline">Retrieve &amp; Re-Rank Pipeline</a></li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#retrieval-bi-encoder">Retrieval: Bi-Encoder</a></li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#re-ranker-cross-encoder">Re-Ranker: Cross-Encoder</a></li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#example-scripts">Example Scripts</a></li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#pre-trained-bi-encoders-retrieval">Pre-trained Bi-Encoders (Retrieval)</a></li>
<li><a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html#pre-trained-cross-encoders-re-ranker">Pre-trained Cross-Encoders (Re-Ranker)</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/clustering/README.html">Clustering</a><ul>
<li><a href="https://www.sbert.net/examples/applications/clustering/README.html#k-means">k-Means</a></li>
<li><a href="https://www.sbert.net/examples/applications/clustering/README.html#agglomerative-clustering">Agglomerative Clustering</a></li>
<li><a href="https://www.sbert.net/examples/applications/clustering/README.html#fast-clustering">Fast Clustering</a></li>
<li><a href="https://www.sbert.net/examples/applications/clustering/README.html#topic-modeling">Topic Modeling</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/paraphrase-mining/README.html">Paraphrase Mining</a></li>
<li><a href="https://www.sbert.net/examples/applications/parallel-sentence-mining/README.html">Translated Sentence Mining</a><ul>
<li><a href="https://www.sbert.net/examples/applications/parallel-sentence-mining/README.html#marging-based-mining">Marging Based Mining</a></li>
<li><a href="https://www.sbert.net/examples/applications/parallel-sentence-mining/README.html#examples">Examples</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html">Cross-Encoders</a><ul>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html#bi-encoder-vs-cross-encoder">Bi-Encoder vs. Cross-Encoder</a></li>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html#when-to-use-cross-bi-encoders">When to use Cross- / Bi-Encoders?</a></li>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html#cross-encoders-usage">Cross-Encoders Usage</a></li>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html#combining-bi-and-cross-encoders">Combining Bi- and Cross-Encoders</a></li>
<li><a href="https://www.sbert.net/examples/applications/cross-encoder/README.html#training-cross-encoders">Training Cross-Encoders</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/applications/image-search/README.html">Image Search</a><ul>
<li><a href="https://www.sbert.net/examples/applications/image-search/README.html#installation">Installation</a></li>
<li><a href="https://www.sbert.net/examples/applications/image-search/README.html#usage">Usage</a></li>
<li><a href="https://www.sbert.net/examples/applications/image-search/README.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Training</span></p>
<ul>
<li><a href="https://www.sbert.net/docs/training/overview.html">Training Overview</a><ul>
<li><a href="https://www.sbert.net/docs/training/overview.html#network-architecture">Network Architecture</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#creating-networks-from-scratch">Creating Networks from Scratch</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#training-data">Training Data</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#loss-functions">Loss Functions</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#evaluators">Evaluators</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#loading-custom-sentencetransformer-models">Loading Custom SentenceTransformer Models</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#multitask-training">Multitask Training</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#adding-special-tokens">Adding Special Tokens</a></li>
<li><a href="https://www.sbert.net/docs/training/overview.html#best-transformer-model">Best Transformer Model</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/docs/training/loss_overview.html">Loss Overview</a><ul>
<li><a href="https://www.sbert.net/docs/training/loss_overview.html#loss-modifiers">Loss modifiers</a></li>
<li><a href="https://www.sbert.net/docs/training/loss_overview.html#distillation">Distillation</a></li>
<li><a href="https://www.sbert.net/docs/training/loss_overview.html#commonly-used-loss-functions">Commonly used Loss Functions</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html">Matryoshka Embeddings</a><ul>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html#use-cases">Use Cases</a></li>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html#results">Results</a></li>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html#inference">Inference</a></li>
<li><a href="https://www.sbert.net/examples/training/matryoshka/README.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html">Adaptive Layers</a><ul>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html#use-cases">Use Cases</a></li>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html#results">Results</a></li>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html#inference">Inference</a></li>
<li><a href="https://www.sbert.net/examples/training/adaptive_layer/README.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html">Multilingual-Models</a><ul>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#available-pre-trained-models">Available Pre-trained Models</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#usage">Usage</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#performance">Performance</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#extend-your-own-models">Extend your own models</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#data-format">Data Format</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#loading-training-datasets">Loading Training Datasets</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#sources-for-training-data">Sources for Training Data</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#evaluation">Evaluation</a></li>
<li><a href="https://www.sbert.net/examples/training/multilingual/README.html#citation">Citation</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/distillation/README.html">Model Distillation</a><ul>
<li><a href="https://www.sbert.net/examples/training/distillation/README.html#knowledge-distillation">Knowledge Distillation</a></li>
<li><a href="https://www.sbert.net/examples/training/distillation/README.html#speed-performance-trade-off">Speed - Performance Trade-Off</a></li>
<li><a href="https://www.sbert.net/examples/training/distillation/README.html#dimensionality-reduction">Dimensionality Reduction</a></li>
<li><a href="https://www.sbert.net/examples/training/distillation/README.html#quantization">Quantization</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/cross-encoder/README.html">Cross-Encoders</a><ul>
<li><a href="https://www.sbert.net/examples/training/cross-encoder/README.html#examples">Examples</a></li>
<li><a href="https://www.sbert.net/examples/training/cross-encoder/README.html#training-crossencoders">Training CrossEncoders</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html">Augmented SBERT</a><ul>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#motivation">Motivation</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#extend-to-your-own-datasets">Extend to your own datasets</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#methodology">Methodology</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#scenario-1-limited-or-small-annotated-datasets-few-labeled-sentence-pairs">Scenario 1: Limited or small annotated datasets (few labeled sentence-pairs)</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#scenario-2-no-annotated-datasets-only-unlabeled-sentence-pairs">Scenario 2: No annotated datasets (Only unlabeled sentence-pairs)</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/data_augmentation/README.html#citation">Citation</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/datasets/README.html">Training Datasets</a><ul>
<li><a href="https://www.sbert.net/examples/training/datasets/README.html#datasets-on-the-hugging-face-hub">Datasets on the Hugging Face Hub</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Training Examples</span></p>
<ul>
<li><a href="https://www.sbert.net/examples/training/sts/README.html">Semantic Textual Similarity</a><ul>
<li><a href="https://www.sbert.net/examples/training/sts/README.html#training-data">Training data</a></li>
<li><a href="https://www.sbert.net/examples/training/sts/README.html#loss-function">Loss Function</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/nli/README.html">Natural Language Inference</a><ul>
<li><a href="https://www.sbert.net/examples/training/nli/README.html#data">Data</a></li>
<li><a href="https://www.sbert.net/examples/training/nli/README.html#softmaxloss">SoftmaxLoss</a></li>
<li><a href="https://www.sbert.net/examples/training/nli/README.html#multiplenegativesrankingloss">MultipleNegativesRankingLoss</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/paraphrases/README.html">Paraphrase Data</a><ul>
<li><a href="https://www.sbert.net/examples/training/paraphrases/README.html#datasets">Datasets</a></li>
<li><a href="https://www.sbert.net/examples/training/paraphrases/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/paraphrases/README.html#pre-trained-models">Pre-Trained Models</a></li>
<li><a href="https://www.sbert.net/examples/training/paraphrases/README.html#work-in-progress">Work in Progress</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html">Quora Duplicate Questions</a><ul>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#pretrained-models">Pretrained Models</a></li>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#dataset">Dataset</a></li>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#usage">Usage</a></li>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#training">Training</a></li>
<li><a href="https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#multiplenegativesrankingloss">MultipleNegativesRankingLoss</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/training/ms_marco/README.html">MS MARCO</a><ul>
<li><a href="https://www.sbert.net/examples/training/ms_marco/README.html#bi-encoder">Bi-Encoder</a></li>
<li><a href="https://www.sbert.net/examples/training/ms_marco/README.html#cross-encoder">Cross-Encoder</a></li>
<li><a href="https://www.sbert.net/examples/training/ms_marco/README.html#cross-encoder-knowledge-distillation">Cross-Encoder Knowledge Distillation</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Unsupervised Learning</span></p>
<ul>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html">Unsupervised Learning</a><ul>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#tsdae">TSDAE</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#simcse">SimCSE</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#ct">CT</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#ct-in-batch-negative-sampling">CT (In-Batch Negative Sampling)</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#masked-language-model-mlm">Masked Language Model (MLM)</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#genq">GenQ</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#gpl">GPL</a></li>
<li><a href="https://www.sbert.net/examples/unsupervised_learning/README.html#performance-comparison">Performance Comparison</a></li>
</ul>
</li>
<li><a href="https://www.sbert.net/examples/domain_adaptation/README.html">Domain Adaptation</a><ul>
<li><a href="https://www.sbert.net/examples/domain_adaptation/README.html#domain-adaptation-vs-unsupervised-learning">Domain Adaptation vs. Unsupervised Learning</a></li>
<li><a href="https://www.sbert.net/examples/domain_adaptation/README.html#adaptive-pre-training">Adaptive Pre-Training</a></li>
<li><a href="https://www.sbert.net/examples/domain_adaptation/README.html#gpl-generative-pseudo-labeling">GPL: Generative Pseudo-Labeling</a></li>
</ul>
</li>
</ul>
</div>

</div>


           </div>

    </section>

  </div></div>]]></description>
        </item>
    </channel>
</rss>