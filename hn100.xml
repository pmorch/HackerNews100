<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 15 Jan 2024 01:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[When Random Isn't (126 pts)]]></title>
            <link>https://orlp.net/blog/when-random-isnt/</link>
            <guid>38994817</guid>
            <pubDate>Sun, 14 Jan 2024 21:56:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://orlp.net/blog/when-random-isnt/">https://orlp.net/blog/when-random-isnt/</a>, See on <a href="https://news.ycombinator.com/item?id=38994817">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<time datetime="2024-01-10">2024-01-10</time>
<p>This post is an anecdote from over a decade ago, of which I lost the actual
code. So please forgive me if I do not accurately remember all the details. Some
details are also simplified so that anyone that likes computer security can
enjoy this article, not just those who have played World of Warcraft (although
the <a href="https://en.wikipedia.org/wiki/Venn_diagram">Venn diagram</a> of those two
groups likely has a solid overlap).</p>
<p>When I was around 14 years old I discovered <a href="https://en.wikipedia.org/wiki/World_of_Warcraft">World of
Warcraft</a> developed by Blizzard
Games and was immediately hooked. Not long after I discovered add-ons which allow
you to modify how your game’s user interface looks and works. However, not all
add-ons I downloaded did exactly what I wanted to do. I wanted more. So I went to
find out how they were made.</p>
<p>In a weird twist of fate, I blame World of Warcraft for me seriously picking up
programming. It turned out that they were made in the
<a href="https://www.lua.org/">Lua</a> programming language. Add-ons were nothing more than
a couple <code>.lua</code> source files in a folder directly loaded into the game. The
barrier of entry was incredibly low: just edit a file, press save and reload the
interface. The fact that the game loaded <em>your</em> source code and you could see it
running was magical!</p>
<p>I enjoyed it immensely and in no time I was only writing add-ons and was barely playing
the game itself anymore. I published <a href="https://www.wowinterface.com/downloads/author-207710.html">quite a few
add-ons</a> in the next
two years, which mostly involved copying other people’s code with some
refactoring / recombining / tweaking to my wishes.</p>
<h2 id="add-on-security"><a href="#add-on-security" aria-label="Anchor link for: add-on-security">Add-on security</a></h2>
<p>A thought you might have is that it’s a really bad idea to let users have fully
programmable add-ons in your game, lest you get bots. However, the system
Blizzard made to prevent arbitrary programmable actions was quite clever.
Naturally, it did nothing to prevent actual botting, but at least
regular rule-abiding players were fundamentally restricted to the automation
Blizzard allowed.</p>
<p>Most UI elements that you could create were strictly decorative or
informational. These were completely unrestricted, as were most APIs that
strictly gather information. For example you can make a health bar display
using two frames, a background and a foreground, sizing the foreground
frame using an API call to get the health of your character.</p>
<p>Not all API calls were available to you however. Some were protected so they
could only be called from official Blizzard code. These typically involved
the API calls that would move your character, cast spells, use items, etc.
Generally speaking anything that actually makes you perform an in-game action
was protected.</p>

<p>However, some UI elements needed to actually interact with the game itself, e.g.
if I want to make a button that casts a certain spell. For this you could
construct a special kind of button that executes code in a secure environment
when clicked. You were only allowed to create/destroy/move such buttons when not
in combat, so you couldn’t simply conditionally place such buttons underneath
your cursor to automate actions during combat.</p>
<p>The catch was that this <a href="https://wowwiki-archive.fandom.com/wiki/RestrictedEnvironment">secure
environment</a>
<em>did</em> allow you to programmatically set which spell to cast, but doesn’t
let you gather the information you would need to do arbitrary automation. All
access to state from outside the secure environment was blocked. There were
some information gathering API calls available to match the more accessible
in-game macro system, but nothing as fancy as getting skill cooldowns or
unit health which would enable automatic optimal spellcasting. </p>
<p>So there were two environments: an insecure one where you can get all
information but can’t act on it, and a secure one where you can act but can’t
get the information needed for automation.</p>
<h2 id="a-backdoor-channel"><a href="#a-backdoor-channel" aria-label="Anchor link for: a-backdoor-channel">A backdoor channel</a></h2>
<p>Fast forward a couple years and I had mostly stopped playing. My interests had
mainly moved on to more “serious” programming, and I was only occasionally
playing, mostly messing around with add-on ideas. But this secure environment kept
on nagging in my brain; I wanted to break it.</p>
<p>Of course there was third-party
software that completely disables the security restrictions from Blizzard, but
what’s the fun in that? I wanted to do it “legitimately”, using the technically
allowed tools, as a challenge.</p>

<p>So I scanned the secure environment allowed function list to see if I could smuggle any
information from the outside into the secure environment. It all seemed pretty
hopeless until I saw one tiny, innocent little function: <code>random</code>.</p>
<p>An evil idea came in my head: random number generators (RNGs) used in computers are almost
always <a href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">pseudorandom number generators</a>
with (hidden) internal state. If I can manipulate this state, perhaps I can use
that to pass information into the secure environment.</p>
<h2 id="random-number-generator-woes"><a href="#random-number-generator-woes" aria-label="Anchor link for: random-number-generator-woes">Random number generator woes</a></h2>
<p>It turned out that <code>random</code> was just a small shim around C’s
<a href="https://en.cppreference.com/w/c/numeric/random/rand"><code>rand</code></a>. I was excited! 
This meant that there was a single global random state that was shared in the
process. It also helps that <code>rand</code> implementations tended to be on the weak side.
Since World
of Warcraft was compiled with MSVC, the actual implementation of <code>rand</code> was as follows:</p>
<pre data-lang="c"><code data-lang="c"><span>uint32_t state;
</span><span>
</span><span>int </span><span>rand() {
</span><span>    state = state * </span><span>214013 </span><span>+ </span><span>2531011</span><span>;
</span><span>    </span><span>return </span><span>(state &gt;&gt; </span><span>16</span><span>) &amp; </span><span>0x7fff</span><span>;
</span><span>}
</span></code></pre>
<p>This RNG is, for the lack of a better word, shite. It is
a naked <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a>,
and a weak one at that. Which in my case, was a good thing.</p>

<p>So let’s get to breaking this thing. Since the state is so laughably small
and you can see 15 bits of the state directly you can keep a full list of
all possible states consistent with a single output of the RNG and use
further calls to the RNG to eliminate possibilities until a
single one remains. But we can be significantly more clever.</p>
<p>First we note that the top bit of <code>state</code> never affects anything in this RNG.
<code>(state &gt;&gt; 16) &amp; 0x7fff</code> masks out 15 bits, after shifting away the bottom 16
bits, and thus effectively works mod $2^{31}$. Since on any update the new state
is a linear function of the previous state, we can propagate this modular form
all the way down to the initial state as $$f(x) \equiv f(x \bmod m) \mod m$$ for
any linear $f$.</p>
<p>Let $a = 214013$ and $b = 2531011$. We observe the 15-bit output $r_0, r_1$ of
two RNG calls. We’ll call the 16-bit portion of the RNG state that is hidden by
the shift $h_0, h_1$ respectively, for the states after the first and second
call. This means the state of the RNG after the first call is $2^{16} r_0 + h_0$
and similarly for $2^{16} r_1 + h_1$ after the second call. Then we have the following identity:</p>
<p>$$a\cdot (2^{16}r_0 + h_0) + b \equiv 2^{16}r_1 + h_1 \mod 2^{31},$$</p>
<p>$$ah_0 \equiv h_1 + 2^{16}(r_1 - ar_0) - b \mod 2^{31}.$$</p>
<p>Now let $c \geq 0$ be the known constant $(2^{16}(r_1 - ar_0) - b) \bmod 2^{31}$, then
for some integer $k$ we have</p>
<p>$$ah_0 = h_1 + c + 2^{31} k.$$</p>
<p>Note that the left hand side ranges from $0$ to $a (2^{16} - 1) \approx 2^{33.71}$.
Thus we must have $-1 \leq k \leq 2^{2.71} &lt; 7$. Reordering we get the following
expression for $h_0$:
$$h_0 = \frac{c + 2^{31} k}{a} + h_1/a.$$
Since $a &gt; 2^{16}$ while $0 \leq h_1 &lt; 2^{16}$ we note that the term $0 \leq h_1/a &lt; 1$.
Thus, assuming a solution exists, we must have
$$h_0 = \left\lceil\frac{c + 2^{31} k}{a}\right\rceil.$$</p>
<p>So for $-1 \leq k &lt; 7$ we compute the above guess for the hidden portion of
the RNG state after the first call. This gives us 8 guesses, after which we can
reject bad guesses using follow-up calls to the RNG until a single unique answer remains.</p>

<p>An example implementation of this process in Python:</p>
<pre data-lang="python"><code data-lang="python"><span>import </span><span>random
</span><span>
</span><span>A = </span><span>214013
</span><span>B = </span><span>2531011
</span><span>
</span><span>class </span><span>MsvcRng:
</span><span>    </span><span>def </span><span>__init__(self, state):
</span><span>        self.state = state
</span><span>        
</span><span>    </span><span>def </span><span>__call__(self):
</span><span>        self.state = (self.state * A + B) % </span><span>2</span><span>**</span><span>32
</span><span>        </span><span>return </span><span>(self.state &gt;&gt; </span><span>16</span><span>) &amp; </span><span>0x7fff
</span><span>
</span><span># Create a random RNG state we'll reverse engineer.
</span><span>hidden_rng = MsvcRng(random.randint(</span><span>0</span><span>, </span><span>2</span><span>**</span><span>32</span><span>))
</span><span>
</span><span># Compute guesses for hidden state from 2 observations.
</span><span>r0 = hidden_rng()
</span><span>r1 = hidden_rng()
</span><span>c = (</span><span>2</span><span>**</span><span>16 </span><span>* (r1 - A * r0) - B) % </span><span>2</span><span>**</span><span>31
</span><span>ceil_div = </span><span>lambda </span><span>a, b: (a + b - </span><span>1</span><span>) // b
</span><span>h_guesses = [ceil_div(c + </span><span>2</span><span>**</span><span>31 </span><span>* k, A) </span><span>for </span><span>k </span><span>in </span><span>range(-</span><span>1</span><span>, </span><span>7</span><span>)]
</span><span>
</span><span># Validate guesses until a single guess remains.
</span><span>guess_rngs = [MsvcRng(</span><span>2</span><span>**</span><span>16 </span><span>* r0 + h0) </span><span>for </span><span>h0 </span><span>in </span><span>h_guesses]
</span><span>guess_rngs = [g </span><span>for </span><span>g </span><span>in </span><span>guess_rngs </span><span>if </span><span>g() == r1]
</span><span>while </span><span>len(guess_rngs) &gt; </span><span>1</span><span>:
</span><span>    r = hidden_rng()
</span><span>    guess_rngs = [g </span><span>for </span><span>g </span><span>in </span><span>guess_rngs </span><span>if </span><span>g() == r]
</span><span>    
</span><span># The top bit can not be recovered as it never affects the output,
</span><span># but we should have recovered the effective hidden state.
</span><span>assert </span><span>guess_rngs[</span><span>0</span><span>].state % </span><span>2</span><span>**</span><span>31 </span><span>== hidden_rng.state % </span><span>2</span><span>**</span><span>31
</span></code></pre>
<p>While I did write the above process with a <code>while</code> loop, it appears to only ever
need a third output at most to narrow it down to a single guess.</p>
<h2 id="putting-it-together"><a href="#putting-it-together" aria-label="Anchor link for: putting-it-together">Putting it together</a></h2>
<p>Once we could reverse-engineer the internal state of the random number
generator we could make arbitrary automated decisions in the supposedly secure
environment. How it worked was as follows:</p>
<ol>
<li>
<p>An insecure hook was registered that would execute right before the secure
environment code would run.</p>
</li>
<li>
<p>In this hook we have full access to information, and make a decision as to
which action should be taken (e.g. casting a particular spell). This action
is looked up in a hardcoded list to get an index.</p>
</li>
<li>
<p>The current state of the RNG is reverse-engineered using the above process.</p>
</li>
<li>
<p>We predict the outcome of the next RNG call. If this (modulo the length
of our action list) does not give our desired outcome, we advance the RNG and
try again. This repeats until the next random number would correspond to our
desired action.</p>
</li>
<li>
<p>The hook returns, and the secure environment starts. It generates a “random”
number, indexes our hardcoded list of actions, and performs the “random” action.</p>
</li>
</ol>
<p>That’s all! By being able to simulate the RNG and looking one step ahead we could
use it as our information channel by choosing exactly the right moment to call
<code>random</code> in the secure environment. Now if you wanted to support a list of $n$
actions it would on average take $n$ steps of the RNG before the correct
number came up to pass along, but that wasn’t a problem in practice.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="Anchor link for: conclusion">Conclusion</a></h2>
<p>I don’t know when Blizzard fixed the issue where the RNG state is so weak and
shared, or whether they were aware of it being an issue at all. A few years
after I had written the code I tried it again out of curiosity, and it had
stopped working. Maybe they switched to a different algorithm,
or had a properly separated RNG state for the secure environment.</p>
<p>All-in-all it was a lot of effort for a niche exploit in a video game that I
didn’t even want to use. But there certainly was a magic to manipulating
something supposedly random into doing exactly what you want, like a magician
pulling four aces from a shuffled deck.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vanna.ai: Chat with your SQL database (273 pts)]]></title>
            <link>https://github.com/vanna-ai/vanna</link>
            <guid>38992601</guid>
            <pubDate>Sun, 14 Jan 2024 17:58:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/vanna-ai/vanna">https://github.com/vanna-ai/vanna</a>, See on <a href="https://news.ycombinator.com/item?id=38992601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:vanna-ai/vanna" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="sy62AniNONQrjyQVd791PLl3mu3WH4wPxwcABJpLiSnvmoEAVTiem7156VG_exr3OKfeTflOHmvhA-mrIQb5nw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="vanna-ai/vanna" data-current-org="vanna-ai" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=15%2B3PTD%2BSJCtIe5UHotNVErUjE3XWPrbHARXwU%2FSXt2qHGtwf71%2BF955wSfg5Gar5QDJifIT2kG55JfQcFcKVg%2Fx7POVW5QFudPjpnGbgZR7P1Ncy2tsMOmtWAB%2B5UXM8qrHZ4hou4v6zb1nGcdaPPqoaXNgLN9F9EsDy9hOdwEb4aLKyARQy5USWO7dbLlFJOPGHMo%2BNrJMQbiNKjuK521efDevj5PYcx77zvK9b%2FyCfRmK8dGXXWssBVYSusC9Ko%2F4tQ8mCqJEdEZBgkEEjrf2wcSktD1iMH2XUxe%2B7CcOwamClZBwmgLVz%2FItFTLF96aTo7AI%2BQKxL2sYycO%2BewHczoetJDcOTjiEg1%2FlQZiByFzqe%2Fc3hZI3Tj5fSKeDjleKP7kPZEo%2FWmxZLMV4Qi%2F%2BWY11gNq38V9oIPh%2Bh429etQhARFmlm8%2FpvqSTcNt0oExCEpszTI0yiRr7Q5ImhrrvAWvBQdRogk5xSvNTTWFNTIdEvfwZXvNSLm5FPwxSouVRhXCap1LPw%3D%3D--iOw7gg8jCFnNEDRZ--5xXUnQh7xRuEpWQNz%2B2V5g%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=vanna-ai%2Fvanna" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/vanna-ai/vanna&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="c214f09fb68fb4fbb987278020c7e49ca34bf8d7b10fb350d2c39c9d973f369b" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Bluefin: an immutable, developer-focused, Cloud-native Linux (109 pts)]]></title>
            <link>https://www.ypsidanger.com/announcing-project-bluefin/</link>
            <guid>38992292</guid>
            <pubDate>Sun, 14 Jan 2024 17:23:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ypsidanger.com/announcing-project-bluefin/">https://www.ypsidanger.com/announcing-project-bluefin/</a>, See on <a href="https://news.ycombinator.com/item?id=38992292">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
				<p>Today we "relaunched" <a href="https://github.com/ublue-os/bluefin?ref=ypsidanger.com">ublue-os/bluefin</a> as <a href="https://projectbluefin.io/?ref=ypsidanger.com">projectbluefin.io</a>. This is a beta until Spring 2024.  </p><p>Bluefin is a custom image of Fedora Silverblue by a bunch of cloud-native nerds. We want a reliable desktop experience that runs everything but we're too lazy to maintain anything. So we automated the entire delivery pipeline in GitHub. </p><figure><img src="https://www.ypsidanger.com/content/images/2023/09/BLUEFIN_21_9.png" alt="" loading="lazy" width="2000" height="844" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/BLUEFIN_21_9.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/BLUEFIN_21_9.png 1000w, https://www.ypsidanger.com/content/images/size/w1600/2023/09/BLUEFIN_21_9.png 1600w, https://www.ypsidanger.com/content/images/size/w2400/2023/09/BLUEFIN_21_9.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Say hello to Bluefin. She is a Deinonychus antirrhopus, "terrible claw". Artwork by Andy Frazer.</span></figcaption></figure><p>Originally Bluefin was "<a href="https://github.com/castrojo/ublue?ref=ypsidanger.com">Fedora Silverblue for Ubuntu Expatriates</a>". I was migrating to Fedora at the time and wanted Silverblue but with a more Ubuntu-like desktop: a dock and appindicators. </p><p>Over time it became apparent that it could stand on its own as an alternative for people who are tired of Linux desktops that aren't as reliable as cheap Chromebooks. We were tired of this shitty situation so decided to add a bit o' shine to Fedora Silverblue and maintain it as a clean, atomic layer on top of the default image. It's <a href="https://www.youtube.com/live/cHYyGVOae84?si=-TdsDiY0xtqgbeuu&amp;t=2370&amp;ref=ypsidanger.com" rel="noreferrer">not a distribution</a>, since you can always revert back to a stock image. </p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/Nz-yyDwTfRM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Bluefin Linux introduction"></iframe><figcaption><p><span>Justin Garrison gives us a quick tour!</span></p></figcaption></figure><p>So she became Bluefin, which coincidentally was the name of Canonical's office building on the Thames in London. Since it's basically an Ubuntu-style workflow on top of Fedora this seemed to make sense and scratch the easter egg itch. </p><p>So after about two years of prototyping and real world usage, we think she's ready for more people to try. We're calling this a Beta, with the hope of going GA in the spring. </p><p>Since she's built on <a href="https://universal-blue.org/?ref=ypsidanger.com">Universal Blue</a> we get all the <a href="https://universal-blue.org/?ref=ypsidanger.com#advantages-over-traditional-linux-desktops" rel="noreferrer">benefits</a> of the main images. While it can run on any PC, we also have specific images for Framework, Asus, and Microsoft Surface devices. Work is underway to generate images based on the work of the <a href="https://fedoraproject.org/wiki/SIGs/Asahi?ref=ypsidanger.com" rel="noreferrer">Fedora Asahi SIG</a>, so hopefully soon we'll have something for Mac users. </p><p>Updates are automatic and transparent, with built in drivers. It can do anything a Chromebook can, but can <a href="https://flathub.org/?ref=ypsidanger.com">use flathub packages</a> for applications, and crucially, a choice of browsers. And since a container runtime is included, it also means you can run just about any Linux workload. </p><figure><img src="https://www.ypsidanger.com/content/images/2023/09/bluefin-defaultish.png" alt="" loading="lazy" width="2000" height="1333" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/bluefin-defaultish.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/bluefin-defaultish.png 1000w, https://www.ypsidanger.com/content/images/size/w1600/2023/09/bluefin-defaultish.png 1600w, https://www.ypsidanger.com/content/images/2023/09/bluefin-defaultish.png 2256w" sizes="(min-width: 720px) 720px"><figcaption><span>Wallpapers by Jacob Schnurr, every season represents the ecology of our open source ecosystems</span></figcaption></figure><p>Major upgrades are handled at the CI level by our <a href="https://devboard.gitsense.com/ublue-os/bluefin?ref=ypsidanger.com">contributors</a>, and everything is set up to run automatically. We ingest Fedora, apply our changes, and then ship the OCI image to you every day. An image-based desktop with the least amount of end-user maintenance as we can automate. Since it's just a container you can <a href="https://universal-blue.discourse.group/docs?topic=43&amp;ref=ypsidanger.com" rel="noreferrer">fork to your heart's content</a> to make your own adjustments, or start from scratch. </p><p>We intend to use <a href="https://cockpit-project.org/?ref=ypsidanger.com">Cockpit</a> to act as fleet management. It is a powerful tool, however it's not set up out of the box, we hope to work on this over time as it's a complex issue, but it's also a problem to look forward to!</p><h2 id="taking-care-of-developers">Taking Care of Developers</h2><p>With the normal use case taken care of let's look at ourselves. Fedora Silverblue variants come with a container runtime, <a href="https://podman.io/?ref=ypsidanger.com">Podman</a>. This means that we can basically run anything we want. We include <a href="https://distrobox.privatedns.org/?ref=ypsidanger.com">distrobox</a> for an interactive experience so that users can use whatever distribution image they want as their day-to-day.  </p><p>But we needed a bit more oomph, so doing a <code>just devmode-on</code> in a terminal will switch you to <code>bluefin-dx</code>, our <a href="https://universal-blue.discourse.group/docs?topic=39&amp;ref=ypsidanger.com" rel="noreferrer">developer image</a>. In here you'll find Visual Studio Code with <a href="https://containers.dev/?ref=ypsidanger.com">devcontainers</a>, <a href="https://www.jetpack.io/devbox?ref=ypsidanger.com">devbox</a> with Fleek for nix, <a href="https://devpod.sh/?ref=ypsidanger.com">devpod</a>, and homebrew. And we toss in some shortcuts to install <a href="https://www.jetbrains.com/toolbox-app/?ref=ypsidanger.com">Jetbrains Toolbox</a>. </p><p>We also take care of the underlying stuff that you need, like LXD/LXC, KVM, and virt-manager. <a href="https://linuxcontainers.org/incus/introduction/?ref=ypsidanger.com">Incus</a> is available as a tech preview. And lastly we include Docker on the image so you can <code>just docker</code> yourself to a more familiar place if you prefer to use it. </p><figure><img src="https://www.ypsidanger.com/content/images/2023/10/image.png" alt="" loading="lazy" width="903" height="695" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/10/image.png 600w, https://www.ypsidanger.com/content/images/2023/10/image.png 903w" sizes="(min-width: 720px) 720px"><figcaption><span>VSCode comes ready with devcontainers out of the box</span></figcaption></figure><p>You can swap your userspace as you see fit. By default it's Bluefin/Ubuntu, but I've been enjoying Bluefin/Alpine for it's speed and small size. At some point I'll migrate to using <a href="https://github.com/wolfi-dev?ref=ypsidanger.com">Wolfi images</a> too. </p><p>Use whatever you want, or stick to the stock Fedora images. We purposely don't dictate a developer workflow, whatever works for you.  Homebrew is my preferred route and is what I recommend to people who are migrating to Bluefin DX. </p><p>We use the <a href="https://universal-blue.org/guide/just?ref=ypsidanger.com">just task runner</a> to ship a bunch of convenience features (and workarounds too). This has started to become a great method for our community to ship shortcuts to each other. For example one contributor submitted <code>just ml-box</code> - a one command shortcut to get pytorch up and running. When you look at what it can do vs. setting up Nvidia drivers and container support by hand it becomes clear that enabling contributors to "ship" directly to developers is a powerful pattern. </p><h2 id="sustainability-of-our-open-source-contributors">Sustainability of our Open Source Contributors</h2><p>And lastly, we wanted to make something lightweight from a contribution perspective. Universal Blue is Containerfiles with Python/Shell. It's a common toolset that tons of people know, and with our community's cloud-native knowledge we were able to fully automate much of the toil in maintaining your computer. I have not seen an "upgrade screen" on any of my computers for over two years, Bluefin quietly hums in CI/CD on GitHub. You don't even know she's there. (Probably because we are being hunted). </p><p>We take our <a href="https://universal-blue.org/mission/?ref=ypsidanger.com">governance and procedures</a> seriously, and welcome contributions. I try to take the same amount of care and dedication that I do when contributing to CNCF projects. </p><p>After spending over five years in cloud-native, I feel like we finally have an alternative operating system using the methods we're all familiar with. It just wasn't available on the desktop, until Fedora made it happen! Now it's up to us to consume it, and improve it! </p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/YFXufAVdrw4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="2023 10 25 21 54 49"></iframe><figcaption><p><span>Here's the companion video to this blog post.</span></p></figcaption></figure><h2 id="a-fresh-start-for-the-next-generation">A fresh start for the next generation</h2><p>I hope you'll join us. We've already got lots of tech in here including kind, flux, helm, and kubectl. We intend to accelerate the consumption of cloud-native tech by acting as your SREs. </p><p>I'll be traveling to conferences over the next 18 months talking about sustainability of our open source ecosystems and developers. Those talks will be delivered via <a href="https://community.frame.work/t/custom-fedora-oci-images-for-framework-laptops/34253?u=jorge_castro&amp;ref=ypsidanger.com">Bluefin on a Framework 13</a>. After using Linux since 1998 I believe this to be the state of the art of the Linux desktop. You won't find a more powerful system with the least amount of work - so if you see me ask for the demo. </p><p>We've been dogfooding Bluefin in some form or another for about two years, and Universal Blue's images have been pulled over 2 million times, it feels mature enough to move the Beta. I don't think <code>bluefin-dx</code> will ever be finished because we'll be revving at the same pace as the rest of cloud-native development, so that should be fun!</p><p>She might nip at you on occasion with a paper cut, but she evolves quickly. Clever girl.  </p><figure><img src="https://www.ypsidanger.com/content/images/2023/10/image-3.png" alt="" loading="lazy" width="949" height="716" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/10/image-3.png 600w, https://www.ypsidanger.com/content/images/2023/10/image-3.png 949w" sizes="(min-width: 720px) 720px"><figcaption><span>Find me at KubeCon North America for your very own bundle of joy!</span></figcaption></figure><h2 id="full-disclosure">Full Disclosure </h2><p>I started this project when I was on sabbatical. One of those "find yourself" ones where you're thinking about stuff like ... "Where does my career go from here?" The whole open source sustainability thing is bugging me, and I started working at the <a href="https://www.cncf.io/?ref=ypsidanger.com" rel="noreferrer">CNCF</a> to help fix this problem. </p><p>And my passion projected kinda ended up being a "hello world". What if we could use the Linux desktop to onboard people right into cloud native? There's way dumber ideas out there lol. Here's more color on how I'm thinking about sustainability in open source:</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/fdieyfrJRVk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Looking at the Past to Understand our Future — Jorge Castro"></iframe><figcaption><p><span>Here's me trying to explain all this in 15 minutes! It also explains why Bluefin is a dinosaur, she's trying to find her place in the ecosystem. </span></p></figcaption></figure><h2 id="finishing-the-beta">Finishing the Beta</h2><p>There's a few things that need to be sorted over the next six months. Mostly it involves the installation experience. It's hard to integrate code that doesn't exist so we're still waiting for Fedora's installer to become more robust at handling OCI installation. I'd like to personally thank the developers at Fedora and Red Hat for their support in working on these features, we're pretty confident that the installation process will get much better in the next six months. Luckily installation is the roughest part, once you're past that, it should be smooth sailing!</p><p>There are also lots of little paper cuts here and there. For example we don't automatically "detect and install Nvidia drivers" since that's not how these systems work, so you have to manually rebase to that image. That sort of thing.</p><p>Reliability is pretty great, the GitHub Package Registry keeps <a href="https://github.com/ublue-os/bluefin/pkgs/container/bluefin?ref=ypsidanger.com" rel="noreferrer">90 days of images</a> available so we can always boot off of any of those images if required, and due to the nature of the system it removes a bunch of the packaging complexity from the client entirely. </p><h2 id="appendix-their-stories">Appendix: Their Stories</h2><p><a href="https://www.etsy.com/listing/1425657775/cretaceous-chonkers-chonky-dinosaur?ref=ypsidanger.com">Jacob Schnurr</a> and <a href="https://www.etsy.com/uk/shop/dragonsofwales?ref=ypsidanger.com">Andy Frazer</a> brought Bluefin to life. If there's one lesson I've learned from this project is the technology is only one part of the equation. I purposely chose the dichotomy of paleo artists and operating systems at the leading edge of machine learning to be a statement on where we stand. A tool designed to make automation the most efficient it can possibly be, and yet unable to exist without the imagination of the human. </p><p>Here's some more shots of the gang in all the prehistoric glory ...</p><figure><img src="https://www.ypsidanger.com/content/images/2023/09/CustomChonk_Jorge_Deinonychus_Color3-1.png" alt="" loading="lazy" width="864" height="864" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/CustomChonk_Jorge_Deinonychus_Color3-1.png 600w, https://www.ypsidanger.com/content/images/2023/09/CustomChonk_Jorge_Deinonychus_Color3-1.png 864w" sizes="(min-width: 720px) 720px"><figcaption><span>Deinonychus antirrhopus, "Bluefin" - This was the species that changed our view of dinosaurs</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_DimetrodonA.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/Jorge_CustomChonks_DimetrodonA.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/Jorge_CustomChonks_DimetrodonA.png 1000w, https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_DimetrodonA.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>Dolly the Dimetrodon. They are actually a synapsid, not a dinosaur. You have more in common with Dolly than Dolly does to any of these dinosaurs. An incredible notion once you think about it!</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_Armagasaurusus_Post1.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/Jorge_CustomChonks_Armagasaurusus_Post1.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/Jorge_CustomChonks_Armagasaurusus_Post1.png 1000w, https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_Armagasaurusus_Post1.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>Karl, represents the Developer Experience. When I'm in my Linux terminal I want to feel powerful and strong. With his help I shred through my backlog – issues, eliminated. Builds – green. Tests – passing. Karl also represents the raw power of Kubernetes, which is why we ship so many cloud-native tools by default.</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_NestingRaptor_Post1.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/Jorge_CustomChonks_NestingRaptor_Post1.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/Jorge_CustomChonks_NestingRaptor_Post1.png 1000w, https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_NestingRaptor_Post1.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>Bluefin is a mother and takes care of her family, like we must take care of each other. Things that threaten her chicks end up meeting the other side of her personality ...</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_PivotRaptor_Post1.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/09/Jorge_CustomChonks_PivotRaptor_Post1.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/09/Jorge_CustomChonks_PivotRaptor_Post1.png 1000w, https://www.ypsidanger.com/content/images/2023/09/Jorge_CustomChonks_PivotRaptor_Post1.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>We call this one "murder chicken". Inspired by the raptor chase in S1E4 of Prehistoric Planet</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_PivotRaptor_BLMBlackGold_Post.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/10/Jorge_CustomChonks_PivotRaptor_BLMBlackGold_Post.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/10/Jorge_CustomChonks_PivotRaptor_BLMBlackGold_Post.png 1000w, https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_PivotRaptor_BLMBlackGold_Post.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>And just like real life, she comes in all sorts of varieties. This one is "Murder Crow"</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_PivotRaptor_Pride_Post.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/10/Jorge_CustomChonks_PivotRaptor_Pride_Post.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/10/Jorge_CustomChonks_PivotRaptor_Pride_Post.png 1000w, https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_PivotRaptor_Pride_Post.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>The team overwhelmingly fell in love with "Glitter Chicken". I'll be making a special Pride run of these at some point!</span></figcaption></figure><figure><img src="https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_Kentrosaurus_Post1.png" alt="" loading="lazy" width="1296" height="1296" srcset="https://www.ypsidanger.com/content/images/size/w600/2023/10/Jorge_CustomChonks_Kentrosaurus_Post1.png 600w, https://www.ypsidanger.com/content/images/size/w1000/2023/10/Jorge_CustomChonks_Kentrosaurus_Post1.png 1000w, https://www.ypsidanger.com/content/images/2023/10/Jorge_CustomChonks_Kentrosaurus_Post1.png 1296w" sizes="(min-width: 720px) 720px"><figcaption><span>.. and lastly this Kentrasaurus - you don't want to mess with them.</span></figcaption></figure>
			</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to delete your data from data brokers (173 pts)]]></title>
            <link>https://www.cybercollective.org/blog/how-to-delete-your-data-from-data-brokers</link>
            <guid>38990755</guid>
            <pubDate>Sun, 14 Jan 2024 14:34:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cybercollective.org/blog/how-to-delete-your-data-from-data-brokers">https://www.cybercollective.org/blog/how-to-delete-your-data-from-data-brokers</a>, See on <a href="https://news.ycombinator.com/item?id=38990755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You probably don't think much about data brokers, but these behind-the-scenes companies collect, trade, and profit from our personal information every day. Data brokers like Acxiom, Experian, and Equifax gather data about us from public records, online activities, store loyalty programs, and more. This data gets packaged into profiles and sold to other businesses for targeted advertising, credit checks, background screening, and who knows what else.</p><p>All this happens without our knowledge or consent. Most people have no idea the extent of their digital footprint or how to even access the data collected about them. While we willingly give away some personal information to use online services, plenty is taken without our permission.<br></p><p>This lack of transparency and control is cause for concern. We have a right to know what personal data exists about us and where it is going. The good news is that there are steps you can take to uncover and delete your data from broker sites:</p><h3>Request Your Data &amp; Send Removal Requests</h3><p>Many data brokers allow you to access your personal information in their systems. Some even offer opt-out tools to stop data collection. Search for "data broker opt-out" to find relevant sites and submit access/deletion requests.&nbsp;<br></p><p>Be sure to keep records of all your requests, including copies of any emails or letters sent. Maintaining this documentation can be useful if you need to follow up or dispute an unfulfilled request.<br></p><p>For brokers without online tools, you'll need to directly request data removal via email or letter. Clearly state your name, address, relevant account numbers, and that you want your data deleted. Keep records of all requests.</p><p>Here is a list of the most prevalent data brokers:</p><ul role="list"><li>Acxiom</li><li>Experian</li><li>Equifax</li><li>TransUnion&nbsp;</li><li>PeopleSmart</li><li>BeenVerified</li><li>WhitePages</li><li>InstantCheckmate</li><li>Pipl</li><li>Intelius</li></ul><h3>Leverage Consumer Protection Laws</h3><p>Depending on your location, laws like the <a href="https://oag.ca.gov/privacy/ccpa">CCPA</a> and <a href="https://gdpr-info.eu/">GDPR</a> give consumers the right to request that companies delete their data.&nbsp;<br></p><p>The California Consumer Privacy Act (CCPA) and the European Union's General Data Protection Regulation (GDPR) are two pivotal privacy laws that give consumers greater control over their personal data.<br></p><p>The CCPA went into effect in 2020 and grants new rights to California residents, like:<br></p><ul role="list"><li>The right to know what personal information companies collect about them and how it is used.</li><li>The right to opt-out of the sale of their data.</li><li>The right to request that their personal information be deleted.</li></ul><p>The GDPR took effect in 2018 and imposes strict guidelines around collecting and handling EU citizens' personal data, such as:<br></p><ul role="list"><li>Requiring affirmative consent before collecting an individual's data.</li><li>Obligating companies to honor requests for data erasure within one month.</li><li>Establishing protections for data breach notification and cross-border data transfers.</li></ul><p>Leveraging these landmark laws can strengthen your ability to take control of your data from brokers. Understand your rights and don't hesitate to cite CCPA or GDPR to compel compliance.<br></p><h3>Use a Deletion Service</h3><p>Sites like <a href="https://joindeleteme.com/">DeleteMe</a>, <a href="https://get.incogni.io/aff_c?offer_id=1017&amp;aff_id=6796">Incogni</a> and <a href="https://abine.com/">Abine</a> will submit opt-out requests on your behalf and monitor to ensure your data stays removed. This simplifies the process, for a fee.<br></p><p>Regaining control of your personal information takes persistence and vigilance, but is worth it. Data brokers will continue collecting our data until laws and consumer pressure demand change. But we can fight back by actively managing our digital footprints and being conscious about what we are consenting to online.</p><p>‍</p><p>*&nbsp;Links may contain affiliate links. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coding Self-Attention, Multi-Head Attention, Cross-Attention, Causal-Attention (116 pts)]]></title>
            <link>https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention</link>
            <guid>38990709</guid>
            <pubDate>Sun, 14 Jan 2024 14:29:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention">https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention</a>, See on <a href="https://news.ycombinator.com/item?id=38990709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama. Self-attention and related mechanisms are core components of LLMs, making them a useful topic to understand when working with these models.</p><p>However, rather than just discussing the self-attention mechanism, we will code it in Python and PyTorch from the ground up. In my opinion, coding algorithms, models, and techniques from scratch is an excellent way to learn!</p><p><span>As a side note, this article is a modernized and extended version of "</span><a href="https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html" rel="">Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch</a><span>," which I published on my old blog almost exactly a year ago. Since I really enjoy writing (and reading) 'from scratch' articles, I wanted to modernize this article for </span><em>Ahead of AI</em><span>.</span></p><p><span>Additionally, this article motivated me to write the book </span><em><a href="http://mng.bz/amjo" rel="">Build a Large Language Model (from Scratch)</a></em><span>, which is currently in progress. Below is a mental model that summarizes the book and illustrates how the self-attention mechanism fits into the bigger picture.</span></p><p>To keep the length of this article somewhat reasonable, I'll assume you already know about LLMs and you also know about attention mechanisms on a basic level. The goal and focus of this article is to understand how attention mechanisms work via a Python &amp; PyTorch code walkthrough.</p><p><span>Since its introduction via the original transformer paper (</span><a href="https://arxiv.org/abs/1706.03762" rel="">Attention Is All You Need</a><span>), self-attention has become a cornerstone of many state-of-the-art deep learning models, particularly in the field of Natural Language Processing (NLP). Since self-attention is now everywhere, it's important to understand how it works.</span></p><p><span>The concept of "attention" in deep learning </span><a href="https://arxiv.org/abs/1409.0473" rel="">has its roots in the effort to improve Recurrent Neural Networks (RNNs)</a><span> for handling longer sequences or sentences. For instance, consider translating a sentence from one language to another. Translating a sentence word-by-word is usually not an option because it ignores the complex grammatical structures and idiomatic expressions unique to each language, leading to inaccurate or nonsensical translations.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png" width="432" height="224.7864406779661" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:614,&quot;width&quot;:1180,&quot;resizeWidth&quot;:432,&quot;bytes&quot;:114671,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>An incorrect word-by-word translation (top) compared to a correct translation (bottom)</figcaption></figure></div><p><span>To overcome this issue, attention mechanisms were introduced to give access to all sequence elements at each time step. The key is to be selective and determine which words are most important in a specific context. </span><a href="https://arxiv.org/abs/1706.03762" rel="">In 2017, the transformer architecture</a><span> introduced a standalone self-attention mechanism, eliminating the need for RNNs altogether.</span></p><p>(For brevity, and to keep the article focused on the technical self-attention details, I am keeping this background motivation section brief so that we can focus on the code implementation.)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png" width="530" height="717.4656593406594" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:530,&quot;bytes&quot;:2180804,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49828e20-cd55-47bb-84a3-59effec1be79_3140x4251.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A visualization from the “Attention is All You Need” paper (</span><a href="https://arxiv.org/abs/1706.03762" rel="">https://arxiv.org/abs/1706.03762</a><span>) showing how much the word “making” depends or focuses on other words in the input via attention weights (the color intensity is proportional the attention weight value).</span></figcaption></figure></div><p>We can think of self-attention as a mechanism that enhances the information content of an input embedding by including information about the input's context. In other words, the self-attention mechanism enables the model to weigh the importance of different elements in an input sequence and dynamically adjust their influence on the output. This is especially important for language processing tasks, where the meaning of a word can change based on its context within a sentence or document.</p><p><span>Note that there are many variants of self-attention. A particular focus has been on making self-attention more efficient. However, most papers still implement the original scaled-dot product attention mechanism introduced in the </span><a href="https://arxiv.org/abs/1706.03762" rel="">Attention Is All You Need paper</a><span> since self-attention is rarely a computational bottleneck for most companies training large-scale transformers.</span></p><p><span>So, in this article, we focus on the original scaled-dot product attention mechanism (referred to as self-attention), which remains the most popular and most widely used attention mechanism in practice. However, if you are interested in other types of attention mechanisms, check out the </span><a href="https://arxiv.org/abs/2009.06732" rel="">2020 </a><em><a href="https://arxiv.org/abs/2009.06732" rel="">Efficient Transformers: A Survey</a></em><span>, the </span><a href="https://arxiv.org/abs/2302.01107" rel="">2023 </a><em><a href="https://arxiv.org/abs/2302.01107" rel="">A Survey on Efficient Training of Transformers</a></em><span> review, and the recent </span><a href="https://arxiv.org/abs/2205.14135" rel="">FlashAttention</a><span> and </span><a href="https://arxiv.org/abs/2307.08691" rel="">FlashAttention-v2</a><span> papers.</span></p><p><span>Before we begin, let's consider an input sentence </span><em>"Life is short, eat dessert first"</em><span> that we want to put through the self-attention mechanism. Similar to other types of modeling approaches for processing text (e.g., using recurrent neural networks or convolutional neural networks), we create a sentence embedding first.</span></p><p><span>For simplicity, here our dictionary </span><code>dc</code><span> is restricted to the words that occur in the input sentence. In a real-world application, we would consider all words in the training dataset (typical vocabulary sizes range between 30k to 50k entries).</span></p><p><strong>In:</strong></p><pre><code>sentence = 'Life is short, eat dessert first'
​
dc = {s:i for i,s 
      in enumerate(sorted(sentence.replace(',', '').split()))}

print(dc)</code></pre><p><strong>Out:</strong></p><pre><code>{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}</code></pre><p>Next, we use this dictionary to assign an integer index to each word:</p><p><strong>In:</strong></p><pre><code>import torch
​
sentence_int = torch.tensor(
    [dc[s] for s in sentence.replace(',', '').split()]
)
print(sentence_int)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([0, 4, 5, 2, 1, 3])</code></pre><p>Now, using the integer-vector representation of the input sentence, we can use an embedding layer to encode the inputs into a real-vector embedding. Here, we will use a tiny 3-dimensional embedding such that each input word is represented by a 3-dimensional vector. </p><p>Note that embedding sizes typically range from hundreds to thousands of dimensions. For instance, Llama 2 utilizes embedding sizes of 4,096. The reason we use 3-dimensional embeddings here is purely for illustration purposes. This allows us to examine the individual vectors without filling the entire page with numbers.</p><p>Since the sentence consists of 6 words, this will result in a 6×3-dimensional embedding:</p><p><strong>In:</strong></p><pre><code>vocab_size = 50_000
​
torch.manual_seed(123)
embed = torch.nn.Embedding(vocab_size, 3)
embedded_sentence = embed(sentence_int).detach()
​
print(embedded_sentence)
print(embedded_sentence.shape)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[ 0.3374, -0.1778, -0.3035],
 &nbsp; &nbsp; &nbsp;  [ 0.1794, &nbsp;1.8951, &nbsp;0.4954],
 &nbsp; &nbsp; &nbsp;  [ 0.2692, -0.0770, -1.0205],
 &nbsp; &nbsp; &nbsp;  [-0.2196, -0.3792, &nbsp;0.7671],
 &nbsp; &nbsp; &nbsp;  [-0.5880, &nbsp;0.3486, &nbsp;0.6603],
 &nbsp; &nbsp; &nbsp;  [-1.1925, &nbsp;0.6984, -1.4097]])
torch.Size([6, 3])</code></pre><p>Now, let's discuss the widely utilized self-attention mechanism known as the scaled dot-product attention, which is an integral part of the transformer architecture.</p><p><span>Self-attention utilizes three weight matrices, referred to as </span><em><strong><span>W</span><sub>q</sub></strong></em><span>, </span><em><strong><span>W</span><sub>k</sub></strong></em><span>, and </span><em><strong><span>W</span><sub>v</sub></strong></em><span>, which are adjusted as model parameters during training. These matrices serve to project the inputs into </span><em>query</em><span>, </span><em>key</em><span>, and </span><em>value</em><span> components of the sequence, respectively.</span></p><p><span>The respective query, key and value sequences are obtained via matrix multiplication between the weight matrices </span><em><strong>W</strong></em><span> and the embedded inputs </span><em><strong>x</strong></em><span>:</span></p><ul><li><p><span>Query sequence: </span><em><strong><span>q</span><sup>(i)</sup></strong><span> </span></em><span>= </span><strong>W</strong><em><strong><sub>q</sub></strong></em><span> </span><em><strong><span>x</span><sup>(i)</sup></strong></em><span> for </span><em>i</em><span> in sequence </span><em>1 … T</em></p></li><li><p><span>Key sequence: </span><em><strong><span>k</span><sup>(i)</sup></strong><span> </span></em><span>= </span><strong>W</strong><em><strong><sub>k</sub></strong></em><span> </span><em><strong><span>x</span><sup>(i)</sup></strong></em><span> for </span><em>i</em><span> in sequence </span><em>1 … T</em></p></li><li><p><span>Value sequence: </span><em><strong><span>v</span><sup>(i)</sup></strong><span> </span></em><span>= </span><strong>W</strong><em><strong><sub>v</sub></strong></em><span> </span><em><strong><span>x</span><sup>(i)</sup></strong></em><span> for </span><em>i</em><span> in sequence </span><em>1 … T</em></p></li></ul><p><span>The index </span><em>i</em><span> refers to the token index position in the input sequence, which has length </span><em>T</em><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png" width="174" height="373.672131147541" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:786,&quot;width&quot;:366,&quot;resizeWidth&quot;:174,&quot;bytes&quot;:58530,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Computing the query, key, and value vectors via the input x and weights W.</figcaption></figure></div><p><span>Here, both </span><em><strong><span>q</span><sup>(i)</sup></strong></em><span> and </span><em><strong><span>k</span><sup>(i)</sup></strong></em><span> are vectors of dimension </span><em><strong><span>d</span><sub>k</sub></strong></em><span>. The projection matrices </span><em><strong><span>W</span><sub>q</sub></strong></em><span> and </span><em><strong><span>W</span><sub>k</sub></strong></em><span> have a shape of </span><em><strong><span>d</span><sub>k</sub></strong></em><span> × </span><em><strong>d</strong></em><span>, while </span><em><strong><span>W</span><sub>v</sub></strong></em><span> has the shape </span><em><strong><span>d</span><sub>v</sub></strong></em><span> × </span><em><strong>d</strong></em><span>.</span></p><p><span>(It's important to note that </span><em><strong>d</strong></em><span> represents the size of each word vector, </span><em><strong>x</strong></em><span>.)</span></p><p><span>Since we are computing the dot-product between the query and key vectors, these two vectors have to contain the same number of elements (</span><em><strong><span>d</span><sub>q</sub><span> = d</span><sub>k</sub></strong></em><span>). In many LLMs, we use the same size for the value vectors such that </span><em><strong><span>d</span><sub>q</sub><span> = d</span><sub>k</sub><span> = d</span><sub>v</sub></strong></em><span>. However, the number of elements in the value vector </span><em><strong><span>v</span><sup>(i)</sup></strong></em><span>, which determines the size of the resulting context vector, can be arbitrary.</span></p><p><span>So, for the following code walkthrough, we will set </span><em><strong><span>d</span><sub>q</sub><span> = d</span><sub>k</sub><span> = 2</span></strong></em><span> and use </span><em><strong><span>d</span><sub>v</sub><span> = 4</span></strong></em><span>, initializing the projection matrices as follows:</span></p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
d = embedded_sentence.shape[1]
​
d_q, d_k, d_v = 2, 2, 4
​
W_query = torch.nn.Parameter(torch.rand(d_q, d))
W_key = torch.nn.Parameter(torch.rand(d_k, d))
W_value = torch.nn.Parameter(torch.rand(d_v, d))</code></pre><p><span>(Similar to the word embedding vectors earlier, the dimensions </span><em><strong><span>d</span><sub>q</sub><span>, d</span><sub>k</sub><span>, d</span><sub>v</sub></strong></em><span> are usually much larger, but we use small numbers here for illustration purposes.)</span></p><p>Now, let's suppose we are interested in computing the attention vector for the second input element -- the second input element acts as the query here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png" width="192" height="314.1224489795918" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:962,&quot;width&quot;:588,&quot;resizeWidth&quot;:192,&quot;bytes&quot;:124665,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>For the following sections below, we focus on the second input, </span><em><strong>x</strong></em><span>(2)</span></figcaption></figure></div><p>In code, this looks like as follows:</p><p><strong>In:</strong></p><pre><code>x_2 = embedded_sentence[1]
query_2 = W_query @ x_2
key_2 = W_key @ x_2
value_2 = W_value @ x_2
​
print(query_2.shape)
print(key_2.shape)
print(value_2.shape)</code></pre><p><strong>Out:</strong></p><pre><code>torch.Size([2])
torch.Size([2])
torch.Size([4])</code></pre><p>We can then generalize this to compute the remaining key, and value elements for all inputs as well, since we will need them in the next step when we compute the unnormalized attention weights later:</p><p><strong>In:</strong></p><pre><code>keys = embedded_sentence @ W_keys
values = embedded_sentence @ W_value
​
print("keys.shape:", keys.shape)
print("values.shape:", values.shape)</code></pre><p><strong>Out:</strong></p><pre><code>keys.shape: torch.Size([6, 2])
values.shape: torch.Size([6, 4])</code></pre><p><span>Now that we have all the required keys and values, we can proceed to the next step and compute the unnormalized attention weights </span><em><strong>ω</strong></em><span> (omega), which are illustrated in the figure below:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png" width="296" height="331.6363636363636" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/baf9e308-223b-429e-8527-a7b868003e8c_814x912.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:912,&quot;width&quot;:814,&quot;resizeWidth&quot;:296,&quot;bytes&quot;:156710,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Computing the unnormalized attention weights </span><em><strong>ω</strong></em><span> (omega)</span></figcaption></figure></div><p><span>As illustrated in the figure above, we compute </span><em><strong><span>ω</span><sub>i,j</sub></strong></em><span> as the dot product between the query and key sequences, </span><em><strong><span>ω</span><sub>i,j</sub><span> </span></strong><span>=</span></em><span> </span><em><strong><span>q</span><sup>(i)</sup></strong></em><span> </span><em><strong><span>k</span><sup>(j)</sup></strong></em><span>.</span></p><p>For example, we can compute the unnormalized attention weight for the query and 5th input element (corresponding to index position 4) as follows:</p><p><strong>In:</strong></p><pre><code>omega_24 = query_2.dot(keys[4])
print(omega_24)</code></pre><p><span>(Note that </span><em><strong>ω</strong></em><span> is the symbol for the Greek letter "omega", hence the code variable with the same name above.)</span></p><p><strong>Out:</strong></p><pre><code>tensor(1.2903)</code></pre><p><span>Since we will need those unnormalized attention weights </span><em><strong>ω</strong></em><span> to compute the actual attention weights later, let's compute the </span><em><strong>ω</strong></em><span> values for all input tokens as illustrated in the previous figure:</span></p><p><strong>In:</strong></p><pre><code>omega_2 = query_2 @ keys.T
print(omega_2)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([-0.6004, &nbsp;3.4707, -1.5023, &nbsp;0.4991, &nbsp;1.2903, -1.3374])</code></pre><p><span>The subsequent step in self-attention is to normalize the unnormalized attention weights, </span><em><strong>ω</strong></em><span>, to obtain the normalized attention weights, </span><em><strong>α</strong></em><span> (alpha), by applying the softmax function. Additionally, 1/√{</span><em><strong><span>d</span><sub>k</sub></strong></em><span>} is used to scale </span><em><strong>ω</strong></em><span> before normalizing it through the softmax function, as shown below:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png" width="618" height="351.0206043956044" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:827,&quot;width&quot;:1456,&quot;resizeWidth&quot;:618,&quot;bytes&quot;:214098,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F292da0d0-8138-4bef-8265-939827f55caa_1774x1008.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Computing the normalized attention weights </span><em><strong>α</strong></em></figcaption></figure></div><p><span>The scaling by </span><em><strong><span>d</span><sub>k</sub></strong></em><span> ensures that the Euclidean length of the weight vectors will be approximately in the same magnitude. This helps prevent the attention weights from becoming too small or too large, which could lead to numerical instability or affect the model's ability to converge during training.</span></p><p>In code, we can implement the computation of the attention weights as follows:</p><p><strong>In:</strong></p><pre><code>import torch.nn.functional as F
​
attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)
print(attention_weights_2)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229])</code></pre><p><span>Finally, the last step is to compute the context vector </span><em><strong><span>z</span><sup>(2)</sup></strong></em><span>, which is an attention-weighted version of our original query input </span><em><strong><span>x</span><sup>(2)</sup></strong></em><span>, including all the other input elements as its context via the attention weights:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png" width="664" height="363.010989010989" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:796,&quot;width&quot;:1456,&quot;resizeWidth&quot;:664,&quot;bytes&quot;:290098,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The attention weights are specific to a certain input element. Here, we chose input element </span><em><strong>x</strong><span>(2).</span></em></figcaption></figure></div><p>In code, this looks like as follows:</p><p><strong>In:</strong></p><pre><code>context_vector_2 = attention_weights_2 @ values
​
print(context_vector_2.shape)
print(context_vector_2)</code></pre><p><strong>Out:</strong></p><pre><code>torch.Size([4])
tensor([0.5313, 1.3607, 0.7891, 1.3110])</code></pre><p><span>Note that this output vector has more dimensions (</span><em><strong><span>d</span><sub>v</sub><span> = 4</span></strong></em><span>) than the original input vector (</span><em><strong>d</strong><span> </span><strong>= 3</strong></em><span>) since we specified </span><em><strong><span>d</span><sub>v</sub></strong><span> </span><strong>&gt; d</strong></em><span> earlier; however, the embedding size choice </span><em><strong><span>d</span><sub>v</sub></strong></em><span> is arbitrary.</span></p><p><span>Now, to wrap up the code implementation of the self-attention mechanism in the previous sections above, we can summarize the previous code in a compact </span><code>SelfAttention</code><span> class:</span></p><p><strong>In:</strong></p><pre><code>import torch.nn as nn
​
class SelfAttention(nn.Module):
​
 &nbsp; &nbsp;def __init__(self, d_in, d_out_kq, d_out_v):
 &nbsp; &nbsp; &nbsp; &nbsp;super().__init__()
 &nbsp; &nbsp; &nbsp; &nbsp;self.d_out_kq = d_out_kq
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_key &nbsp; = nn.Parameter(torch.rand(d_in, d_out_kq))
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))
​
 &nbsp; &nbsp;def forward(self, x):
 &nbsp; &nbsp; &nbsp; &nbsp;keys = x @ self.W_key
 &nbsp; &nbsp; &nbsp; &nbsp;queries = x @ self.W_query
 &nbsp; &nbsp; &nbsp; &nbsp;values = x @ self.W_value
 &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;attn_scores = queries @ keys.T &nbsp;# unnormalized attention weights &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;attn_weights = torch.softmax(
            attn_scores / self.d_out_kq**0.5, dim=-1
        )
 &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;context_vec = attn_weights @ values
 &nbsp; &nbsp; &nbsp; &nbsp;return context_vec</code></pre><p><span>Following PyTorch conventions, the </span><code>SelfAttention</code><span> class above initializes the self-attention parameters in the </span><code>__init__</code><span> method and computes attention weights and context vectors for all inputs via the </span><code>forward</code><span> method. We can use this class as follows:</span></p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
# reduce d_out_v from 4 to 1, because we have 4 heads
d_in, d_out_kq, d_out_v = 3, 2, 4
​
sa = SelfAttention(d_in, d_out_kq, d_out_v)
print(sa(embedded_sentence))</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[-0.1564, &nbsp;0.1028, -0.0763, -0.0764],
 &nbsp; &nbsp; &nbsp;  [ 0.5313, &nbsp;1.3607, &nbsp;0.7891, &nbsp;1.3110],
 &nbsp; &nbsp; &nbsp;  [-0.3542, -0.1234, -0.2627, -0.3706],
 &nbsp; &nbsp; &nbsp;  [ 0.0071, &nbsp;0.3345, &nbsp;0.0969, &nbsp;0.1998],
 &nbsp; &nbsp; &nbsp;  [ 0.1008, &nbsp;0.4780, &nbsp;0.2021, &nbsp;0.3674],
 &nbsp; &nbsp; &nbsp;  [-0.5296, -0.2799, -0.4107, -0.6006]], grad_fn=&lt;MmBackward0&gt;)</code></pre><p><span>If you look at the second row, you can see that it matches the values in </span><code>context_vector_2</code><span> from the previous section exactly: </span><code>tensor([0.5313, 1.3607, 0.7891, 1.3110])</code><span>.</span></p><p><span>In the very first figure, at the top of this article (also shown again for convenience below), we saw that transformers use a module called </span><em>multi-head attention</em><span>.</span></p><p>How does this "multi-head" attention module relate to the self-attention mechanism (scaled-dot product attention) we walked through above?</p><p>In scaled dot-product attention, the input sequence was transformed using three matrices representing the query, key, and value. These three matrices can be considered as a single attention head in the context of multi-head attention. The figure below summarizes this single attention head we covered and implemented previously:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png" width="500" height="303.91483516483515" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:885,&quot;width&quot;:1456,&quot;resizeWidth&quot;:500,&quot;bytes&quot;:178737,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Summarizing the self-attention mechanism implemented previously</figcaption></figure></div><p>As its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value matrices. This concept is similar to the use of multiple kernels in convolutional neural networks, producing feature maps with multiple output channels.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png" width="526" height="343.5618131868132" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:951,&quot;width&quot;:1456,&quot;resizeWidth&quot;:526,&quot;bytes&quot;:199096,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Multi-head attention: self-attention with multiple heads</figcaption></figure></div><p><span>To illustrate this in code, we can write a </span><code>MultiHeadAttentionWrapper</code><span> class for our previous </span><code>SelfAttention</code><span> class:</span></p><pre><code>class MultiHeadAttentionWrapper(nn.Module):
​
 &nbsp; &nbsp;def __init__(self, d_in, d_out_kq, d_out_v, num_heads):
 &nbsp; &nbsp; &nbsp; &nbsp;super().__init__()
 &nbsp; &nbsp; &nbsp; &nbsp;self.heads = nn.ModuleList(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  [SelfAttention(d_in, d_out_kq, d_out_v) 
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(num_heads)]
 &nbsp; &nbsp; &nbsp;  )
​
 &nbsp; &nbsp;def forward(self, x):
 &nbsp; &nbsp; &nbsp; &nbsp;return torch.cat([head(x) for head in self.heads], dim=-1)</code></pre><p><span>The </span><code>d_*</code><span> parameters are the same as before in the </span><code>SelfAttention</code><span> class -- the only new input parameter here is the number of attention heads:</span></p><ul><li><p><code>d_in</code><span>: Dimension of the input feature vector.</span></p></li><li><p><code>d_out_kq</code><span>: Dimension for both query and key outputs.</span></p></li><li><p><code>d_out_v</code><span>: Dimension for value outputs.</span></p></li><li><p><code>num_heads</code><span>: Number of attention heads.</span></p></li></ul><p><span>We initialize the </span><code>SelfAttention</code><span> class </span><code>num_heads</code><span> times using these input parameters. And we use a PyTorch </span><code>nn.ModuleList</code><span> to store these multiple </span><code>SelfAttention</code><span> instances.</span></p><p><span>Then, the </span><code>forward</code><span> pass involves applying each </span><code>SelfAttention</code><span> head (stored in </span><code>self.heads</code><span>) to the input </span><code>x</code><span> independently. The results from each head are then concatenated along the last dimension (</span><code>dim=-1</code><span>). Let's see it in action below!</span></p><p>First, let's suppose we have a single Self-Attention head with output dimension 1 to keep it simple for illustration purposes:</p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
d_in, d_out_kq, d_out_v = 3, 2, 1
​
sa = SelfAttention(d_in, d_out_kq, d_out_v)
print(sa(embedded_sentence))</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[-0.0185],
 &nbsp; &nbsp; &nbsp;  [ 0.4003],
 &nbsp; &nbsp; &nbsp;  [-0.1103],
 &nbsp; &nbsp; &nbsp;  [ 0.0668],
 &nbsp; &nbsp; &nbsp;  [ 0.1180],
 &nbsp; &nbsp; &nbsp;  [-0.1827]], grad_fn=&lt;MmBackward0&gt;)</code></pre><p>Now, let's extend this to 4 attention heads:</p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
block_size = embedded_sentence.shape[1]
mha = MultiHeadAttentionWrapper(
    d_in, d_out_kq, d_out_v, num_heads=4
)
​
context_vecs = mha(embedded_sentence)
​
print(context_vecs)
print("context_vecs.shape:", context_vecs.shape)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[-0.0185, &nbsp;0.0170, &nbsp;0.1999, -0.0860],
 &nbsp; &nbsp; &nbsp;  [ 0.4003, &nbsp;1.7137, &nbsp;1.3981, &nbsp;1.0497],
 &nbsp; &nbsp; &nbsp;  [-0.1103, -0.1609, &nbsp;0.0079, -0.2416],
 &nbsp; &nbsp; &nbsp;  [ 0.0668, &nbsp;0.3534, &nbsp;0.2322, &nbsp;0.1008],
 &nbsp; &nbsp; &nbsp;  [ 0.1180, &nbsp;0.6949, &nbsp;0.3157, &nbsp;0.2807],
 &nbsp; &nbsp; &nbsp;  [-0.1827, -0.2060, -0.2393, -0.3167]], grad_fn=&lt;CatBackward0&gt;)
context_vecs.shape: torch.Size([6, 4])</code></pre><p>Based on the output above, you can see that the single self-attention head created earlier now represents the first column in the output tensor above.</p><p><span>Notice that the multi-head attention result is a 6×4-dimensional tensor: We have 6 input tokens and 4 self-attention heads, where each self-attention head returns a 1-dimensional output. Previously, in the Self-Attention section, we also produced a 6×4-dimensional tensor. That's because we set the output dimension to 4 instead of 1. In practice, why do we even need multiple attention heads if we can regulate the output embedding size in the </span><code>SelfAttention</code><span> class itself?</span></p><p>The distinction between increasing the output dimension of a single self-attention head and using multiple attention heads lies in how the model processes and learns from the data. While both approaches increase the capacity of the model to represent different features or aspects of the data, they do so in fundamentally different ways.</p><p>For instance, each attention head in multi-head attention can potentially learn to focus on different parts of the input sequence, capturing various aspects or relationships within the data. This diversity in representation is key to the success of multi-head attention.</p><p>Multi-head attention can also be more efficient, especially in terms of parallel computation. Each head can be processed independently, making it well-suited for modern hardware accelerators like GPUs or TPUs that excel at parallel processing.</p><p>In short, the use of multiple attention heads is not just about increasing the model's capacity but about enhancing its ability to learn a diverse set of features and relationships within the data. For example, the 7B Llama 2 model uses 32 attention heads.</p><p><span>In the code walkthrough above, we set </span><em><strong>d_q = d_k = 2</strong></em><span> and </span><em><strong>d_v = 4</strong></em><span>. In other words, we used the same dimensions for query and key sequences. While the value matrix </span><em><strong>W_v</strong></em><span> is often chosen to have the same dimension as the query and key matrices (such as in PyTorch's </span><a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html" rel="">MultiHeadAttention</a><span> class), we can select an arbitrary number size for the value dimensions.</span></p><p>Since the dimensions are sometimes a bit tricky to keep track of, let's summarize everything we have covered so far in the figure below, which depicts the various tensor sizes for a single attention head.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png" width="636" height="477.8736263736264" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1094,&quot;width&quot;:1456,&quot;resizeWidth&quot;:636,&quot;bytes&quot;:138883,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Another view of the self-attention mechanism implemented previously, with a focus on the matrix dimensions</figcaption></figure></div><p><span>Now, the illustration above corresponds to the </span><em>self</em><span>-attention mechanism used in transformers. One particular flavor of this attention mechanism we have yet to discuss is </span><em>cross</em><span>-attention.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png" width="354" height="406.72340425531917" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:972,&quot;width&quot;:846,&quot;resizeWidth&quot;:354,&quot;bytes&quot;:252431,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>What is cross-attention, and how does it differ from self-attention?</p><p><span>In self-attention, we work with the same input sequence. In cross-attention, we mix or combine two </span><em>different</em><span> input sequences. In the case of the original transformer architecture above, that's the sequence returned by the encoder module on the left and the input sequence being processed by the decoder part on the right.</span></p><p><span>Note that in cross-attention, the two input sequences </span><code>x_1</code><span> and </span><code>x_2</code><span> can have different numbers of elements. However, their embedding dimensions must match.</span></p><p><span>The figure below illustrates the concept of cross-attention. If we set </span><code>x_1</code><em> = </em><code>x_2</code><span>, this is equivalent to self-attention.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png" width="624" height="454.7142857142857" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1061,&quot;width&quot;:1456,&quot;resizeWidth&quot;:624,&quot;bytes&quot;:166111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>(Note that the queries usually come from the decoder, and the keys and values typically come from the encoder.)</p><p><span>How does that work in code? We will adopt and modify the </span><code>SelfAttention</code><span> class that we previously implemented in the Self-Attention section and only make some minor modifications:</span></p><p><strong>In:</strong></p><pre><code>class CrossAttention(nn.Module):
​
 &nbsp; &nbsp;def __init__(self, d_in, d_out_kq, d_out_v):
 &nbsp; &nbsp; &nbsp; &nbsp;super().__init__()
 &nbsp; &nbsp; &nbsp; &nbsp;self.d_out_kq = d_out_kq
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_key &nbsp; = nn.Parameter(torch.rand(d_in, d_out_kq))
 &nbsp; &nbsp; &nbsp; &nbsp;self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))
​
 &nbsp; &nbsp;def forward(self, x_1, x_2): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # x_2 is new
 &nbsp; &nbsp; &nbsp; &nbsp;queries_1 = x_1 @ self.W_query
 &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;keys_2 = x_2 @ self.W_key &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# new
 &nbsp; &nbsp; &nbsp; &nbsp;values_2 = x_2 @ self.W_value &nbsp; &nbsp; &nbsp;# new
 &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;attn_scores = queries_1 @ keys_2.T # new 
 &nbsp; &nbsp; &nbsp; &nbsp;attn_weights = torch.softmax(attn_scores / self.d_out_kq**0.5, dim=-1)
 &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp;context_vec = attn_weights @ values_2
 &nbsp; &nbsp; &nbsp; &nbsp;return context_vec</code></pre><p><span>The differences between the </span><code>CrossAttention</code><span> class and the previous </span><code>SelfAttention</code><span> class are as follows:</span></p><ul><li><p><span>The </span><code>forward</code><span> method takes two distinct inputs, </span><code>x_1</code><span> and </span><code>x_2</code><span>. The queries are derived from </span><code>x_1</code><span>, while the keys and values are derived from </span><code>x_2</code><span>. This means that the attention mechanism is evaluating the interaction between two different inputs.</span></p></li><li><p><span>The attention scores are calculated by taking the dot product of the queries (from </span><code>x_1</code><span>) and keys (from </span><code>x_2</code><span>).</span></p></li><li><p><span>Similar to </span><code>SelfAttention</code><span>, each context vector is a weighted sum of the values. However, in </span><code>CrossAttention</code><span>, these values are derived from the second input (</span><code>x_2</code><span>), and the weights are based on the interaction between </span><code>x_1</code><span> and </span><code>x_2</code><span>.</span></p></li></ul><p>Let's see it in action:</p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
d_in, d_out_kq, d_out_v = 3, 2, 4
​
crossattn = CrossAttention(d_in, d_out_kq, d_out_v)
​
first_input = embedded_sentence
second_input = torch.rand(8, d_in)
​
print("First input shape:", first_input.shape)
print("Second input shape:", second_input.shape)</code></pre><p><strong>In:</strong></p><pre><code>First input shape: torch.Size([6, 3])
Second input shape: torch.Size([8, 3])</code></pre><p>Notice that the first and second inputs don't have to have the same number of tokens (here: rows) when computing cross-attention:</p><p><strong>In:</strong></p><pre><code>context_vectors = crossattn(first_input, second_input)
​
print(context_vectors)
print("Output shape:", context_vectors.shape)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[0.4231, 0.8665, 0.6503, 1.0042],
 &nbsp; &nbsp; &nbsp;  [0.4874, 0.9718, 0.7359, 1.1353],
 &nbsp; &nbsp; &nbsp;  [0.4054, 0.8359, 0.6258, 0.9667],
 &nbsp; &nbsp; &nbsp;  [0.4357, 0.8886, 0.6678, 1.0311],
 &nbsp; &nbsp; &nbsp;  [0.4429, 0.9006, 0.6775, 1.0460],
 &nbsp; &nbsp; &nbsp;  [0.3860, 0.8021, 0.5985, 0.9250]], grad_fn=&lt;MmBackward0&gt;)
Output shape: torch.Size([6, 4])</code></pre><p>We talked a lot about language transformers above. In the original transformer architecture, cross-attention is useful when we go from an input sentence to an output sentence in the context of language translation. The input sentence represents one input sequence, and the translation represent the second input sequence (the two sentences can different numbers of words).</p><p><span>Another popular model where cross-attention is used is Stable Diffusion. Stable Diffusion uses cross-attention between the generated image in the U-Net model and the text prompts used for conditioning as described in </span><a href="https://arxiv.org/abs/2112.10752" rel="">High-Resolution Image Synthesis with Latent Diffusion Models</a><span> -- the original paper that describes the Stable Diffusion model that was later adopted by Stability AI to implement the popular Stable Diffusion model.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png" width="620" height="303.8205980066445" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:590,&quot;width&quot;:1204,&quot;resizeWidth&quot;:620,&quot;bytes&quot;:239081,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In this section, we are adapting the previously discussed self-attention mechanism into a causal self-attention mechanism, specifically for GPT-like (decoder-style) LLMs that are used to generate text. This causal self-attention mechanism  is also often referred to as “masked self-attention”. In the original transformer architecture, it corresponds to the “masked multi-head attention” module — for simplicity, we will look at a single attention head in this section, but the same concept generalizes to multiple heads.</p><p>Causal self-attention ensures that the  outputs for a certain position in a sequence is based only on the known outputs at previous positions and not on future positions. In simpler terms, it ensures that the prediction for each next word should only depend on the preceding words. To achieve this in GPT-like LLMs, for each token processed, we mask out the future tokens, which come after the current token in the input text.</p><p>The application of a causal mask to the attention weights for hiding future input tokens in the inputs is illustrated in the figure below.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png" width="518" height="331.5769230769231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:932,&quot;width&quot;:1456,&quot;resizeWidth&quot;:518,&quot;bytes&quot;:611309,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>To illustrate and implement causal self-attention, let's work with the unweighted attention scores and attention weights from the previous section. First, we quickly recap the computation of the attention scores from the previous </span><em>Self-Attention</em><span> section:</span></p><p><strong>In:</strong></p><pre><code>torch.manual_seed(123)
​
d_in, d_out_kq, d_out_v = 3, 2, 4
​
W_query = nn.Parameter(torch.rand(d_in, d_out_kq))
W_key &nbsp; = nn.Parameter(torch.rand(d_in, d_out_kq))
W_value = nn.Parameter(torch.rand(d_in, d_out_v))
​
x = embedded_sentence
​
keys = x @ W_key
queries = x @ W_query
values = x @ W_value
​
# attn_scores are the "omegas", 
# the unnormalized attention weights
attn_scores = queries @ keys.T 
​
print(attn_scores)
print(attn_scores.shape)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[ 0.0613, -0.3491, &nbsp;0.1443, -0.0437, -0.1303, &nbsp;0.1076],
 &nbsp; &nbsp; &nbsp;  [-0.6004, &nbsp;3.4707, -1.5023, &nbsp;0.4991, &nbsp;1.2903, -1.3374],
 &nbsp; &nbsp; &nbsp;  [ 0.2432, -1.3934, &nbsp;0.5869, -0.1851, -0.5191, &nbsp;0.4730],
 &nbsp; &nbsp; &nbsp;  [-0.0794, &nbsp;0.4487, -0.1807, &nbsp;0.0518, &nbsp;0.1677, -0.1197],
 &nbsp; &nbsp; &nbsp;  [-0.1510, &nbsp;0.8626, -0.3597, &nbsp;0.1112, &nbsp;0.3216, -0.2787],
 &nbsp; &nbsp; &nbsp;  [ 0.4344, -2.5037, &nbsp;1.0740, -0.3509, -0.9315, &nbsp;0.9265]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;MmBackward0&gt;)
torch.Size([6, 6])</code></pre><p><span>Similar to the </span><em>Self-Attention</em><span> section before, the output above is a 6×6 tensor containing these pairwise unnormalized attention weights (also called attention scores) for the 6 input tokens.</span></p><p>Previously, we then computed the scaled dot-product attention via the softmax function as follows:</p><p><strong>In:</strong></p><pre><code>attn_weights = torch.softmax(attn_scores / d_out_kq**0.5, dim=1)
print(attn_weights)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[0.1772, 0.1326, 0.1879, 0.1645, 0.1547, 0.1831],
 &nbsp; &nbsp; &nbsp;  [0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],
 &nbsp; &nbsp; &nbsp;  [0.1965, 0.0618, 0.2506, 0.1452, 0.1146, 0.2312],
 &nbsp; &nbsp; &nbsp;  [0.1505, 0.2187, 0.1401, 0.1651, 0.1793, 0.1463],
 &nbsp; &nbsp; &nbsp;  [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.1231],
 &nbsp; &nbsp; &nbsp;  [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre><p><span>The 6×6 output above represents the attention weights, which we also computed in the </span><em>Self-Attention</em><span> section before.</span></p><p>Now, in GPT-like LLMs, we train the model to read and generate one token (or word) at a time, from left to right. If we have a training text sample like "Life is short eat desert first" we have the following setup, where the context vectors for the word to the right side of the arrow should only incorporate itself and the previous words:</p><ul><li><p>"Life" → "is"</p></li><li><p>"Life is" → "short"</p></li><li><p>"Life is short" → "eat"</p></li><li><p>"Life is short eat" → "desert"</p></li><li><p>"Life is short eat desert" → "first"</p></li></ul><p>The simplest way to achieve this setup above is to mask out all future tokens by applying a mask to the attention weight matrix above the diagonal, as illustrated in the figure below. This way, “future” words will not be included when creating the context vectors, which are created as a attention-weighted sum over the inputs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png" width="516" height="296.91147540983604" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e1317a05-3542-4158-94bf-085109a5793a_1220x702.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:702,&quot;width&quot;:1220,&quot;resizeWidth&quot;:516,&quot;bytes&quot;:379180,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Attention weights above the diagonal should be masked out</figcaption></figure></div><p><span>In code, we can achieve this via PyTorch's </span><a href="https://pytorch.org/docs/stable/generated/torch.tril.html#" rel="">tril</a><span> function, which we first use to create a mask of 1's and 0's:</span></p><p><strong>In:</strong></p><pre><code>block_size = attn_scores.shape[0]
mask_simple = torch.tril(torch.ones(block_size, block_size))
print(mask_simple)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[1., 0., 0., 0., 0., 0.],
 &nbsp; &nbsp; &nbsp;  [1., 1., 0., 0., 0., 0.],
 &nbsp; &nbsp; &nbsp;  [1., 1., 1., 0., 0., 0.],
 &nbsp; &nbsp; &nbsp;  [1., 1., 1., 1., 0., 0.],
 &nbsp; &nbsp; &nbsp;  [1., 1., 1., 1., 1., 0.],
 &nbsp; &nbsp; &nbsp;  [1., 1., 1., 1., 1., 1.]])</code></pre><p>Next, we multiply the attention weights with this mask to zero out all the attention weights above the diagonal:</p><p><strong>In:</strong></p><pre><code>masked_simple = attn_weights*mask_simple
print(masked_simple)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[0.1772, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.0386, 0.6870, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1965, 0.0618, 0.2506, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1505, 0.2187, 0.1401, 0.1651, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;MulBackward0&gt;)</code></pre><p>While the above is one way to mask out future words, notice that the attention weights in each row don't sum to one anymore. To mitigate that, we can normalize the rows such that they sum up to 1 again, which is a standard convention for attention weights:</p><p><strong>In:</strong></p><pre><code>row_sums = masked_simple.sum(dim=1, keepdim=True)
masked_simple_norm = masked_simple / row_sums
print(masked_simple_norm)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.0532, 0.9468, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.3862, 0.1214, 0.4924, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.2232, 0.3242, 0.2078, 0.2449, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1536, 0.3145, 0.1325, 0.1849, 0.2145, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;DivBackward0&gt;)</code></pre><p>As we can see, the attention weights in each row now sum up to 1.</p><p>Normalizing attention weights in neural networks, such as in transformer models, is advantageous over unnormalized weights for two main reasons. First, normalized attention weights that sum to 1 resemble a probability distribution. This makes it easier to interpret the model's attention to various parts of the input in terms of proportions. Second, by constraining the attention weights to sum to 1, this normalization helps control the scale of the weights and gradients to improve the training dynamics.</p><p><strong>More efficient masking without renormalization</strong></p><p>In the causal self-attention procedure we coded above, we first compute the attention scores, then compute the attention weights, mask out attention weights above the diagonal, and lastly renormalize the attention weights. This is summarized in the figure below:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png" width="1456" height="272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:272,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:74590,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fcce180-cda2-4094-bb7c-32ea12e60c9a_1468x274.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The previously implemented causal self-attention procedure</figcaption></figure></div><p>Alternatively, there is a more efficient way to achieve the same results. In this approach, we take the attention scores and replace the values above the diagonal with negative infinity before the values are input into the softmax function to compute the attention weights. This is summarized in the figure below:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png" width="538" height="137.8178368121442" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:270,&quot;width&quot;:1054,&quot;resizeWidth&quot;:538,&quot;bytes&quot;:57470,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa94e36c7-ec67-43d6-96c0-7f9781f402b5_1054x270.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>An alternative, more efficient approach to implementing causal self-attention</figcaption></figure></div><p>We can code up this procedure in PyTorch as follows, starting with masking the attention scores above the diagonal:</p><p><strong>In:</strong></p><pre><code>mask = torch.triu(torch.ones(block_size, block_size))
masked = attn_scores.masked_fill(mask.bool(), -torch.inf)
print(masked)</code></pre><p><span>The code above first creates a </span><code>mask</code><span> with 0s below the diagonal, and 1s above the diagonal. Here, </span><code>torch.triu</code><span> (*(</span><strong>u</strong><span>pper </span><strong>tri</strong><span>angle) retains the elements on and above the main diagonal of a matrix, zeroing out the elements below it, thus preserving the upper triangular portion. In contrast, </span><code>torch.tril</code><span> (</span><strong>l</strong><span>ower </span><strong>t</strong><span>riangle) keeps the elements on and below the main diagonal.</span></p><p><span>The </span><code>masked_fill</code><span> method then replaces all the elements on and above the diagonal via positive mask values (1s) with </span><code>-torch.inf</code><span>, with the results being shown below.</span></p><p><strong>Out:</strong></p><pre><code>tensor([[ 0.0613, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf],
 &nbsp; &nbsp; &nbsp;  [-0.6004,  3.4707, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf],
 &nbsp; &nbsp; &nbsp;  [ 0.2432, -1.3934,  0.5869, &nbsp;  -inf, &nbsp;  -inf, &nbsp;  -inf],
 &nbsp; &nbsp; &nbsp;  [-0.0794,  0.4487, -0.1807,  0.0518, &nbsp;  -inf, &nbsp;  -inf],
 &nbsp; &nbsp; &nbsp;  [-0.1510,  0.8626, -0.3597,  0.1112,  0.3216, &nbsp;  -inf],
 &nbsp; &nbsp; &nbsp;  [ 0.4344, -2.5037,  1.0740, -0.3509, -0.9315,  0.9265]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;MaskedFillBackward0&gt;)</code></pre><p>Then, all we have to do is to apply the softmax function as usual to obtain the normalized and masked attention weights:</p><p><strong>In:</strong></p><pre><code>attn_weights = torch.softmax(masked / d_out_kq**0.5, dim=1)
print(attn_weights)</code></pre><p><strong>Out:</strong></p><pre><code>tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.0532, 0.9468, 0.0000, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.3862, 0.1214, 0.4924, 0.0000, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.2232, 0.3242, 0.2078, 0.2449, 0.0000, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1536, 0.3145, 0.1325, 0.1849, 0.2145, 0.0000],
 &nbsp; &nbsp; &nbsp;  [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],
 &nbsp; &nbsp; &nbsp; grad_fn=&lt;SoftmaxBackward0&gt;)  </code></pre><p><span>Why does this work? The softmax function, applied in the last step, converts the input values into a probability distribution. When </span><code>-inf</code><span> is present in the inputs, softmax effectively treats them as zero probability. This is because </span><code>e^(-inf)</code><span> approaches 0, and thus these positions contribute nothing to the output probabilities.</span></p><p>IIn this article, we explored the inner workings of self-attention through a step-by-step coding approach. Using this as a foundation, we then looked into multi-head attention, a fundamental component of large language transformers.</p><p>We then also coded cross-attention, a variant of self-attention that is particularly effective when applied between two distinct sequences. And lastly, we coded causal self-attention, a concept crucial for generating coherent and contextually appropriate sequences in decoder-style LLMs such as GPT and Llama.</p><p>By coding these complex mechanisms from scratch, you hopefully gained a good understanding of the inner workings of the self-attention mechanism used in transformers and LLMs.</p><p><span>(Note that the code presented in this article is intended for illustrative purposes. If you plan to implement self-attention for training LLMs, I recommend considering optimized implementations like </span><a href="https://arxiv.org/abs/2307.08691" rel="">Flash Attention</a><span>, which reduce memory footprint and computational load.)</span></p><p><span>If you liked this article, my </span><a href="http://mng.bz/amjo" rel="">Build a Large Language Model from Scratch</a><span> book explains how LLMs work using a similar (but more detailed) from-scratch approach. This includes coding the data processing steps, LLM architecture, pretraining, finetuning, and alignment stages.</span></p><p><span>The book is currently part of Manning's early access program, where new chapters will be released regularly. (Purchasers of the currently discounted early access version through Manning will also receive the final book upon its release.) The corresponding code is </span><a href="https://github.com/rasbt/LLMs-from-scratch" rel="">available on GitHub</a><span>.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cars suck, man (182 pts)]]></title>
            <link>https://petargyurov.com/2024-01-14/cars-suck-man</link>
            <guid>38990080</guid>
            <pubDate>Sun, 14 Jan 2024 13:08:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://petargyurov.com/2024-01-14/cars-suck-man">https://petargyurov.com/2024-01-14/cars-suck-man</a>, See on <a href="https://news.ycombinator.com/item?id=38990080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><span>Published on</span>
    <span datetime="2024-01-14 00:00:00 +0000">January 14, 2024</span>
     
  </p>

  
  
  

  <p>What better way to start off the new year than with a little rant.</p>

<p>I am not car aficionado, in fact, I am probably less interested in cars than the average person. As the tech bros have slowly crept into the automotive industry, I can’t help but feel like I’m witnessing a <em>car crash</em> in slow motion.</p>

<h3 id="cars-are-the-smart-tvs-of-today">Cars are the Smart TVs of today</h3>

<p>Have you tried shopping for a TV in the past 5 years? Actually, scratch that – have you <em>used</em> a “smart” TV in the past 5 years? – it’s awful. Sure, displays are getting better, but manufacturers insist on cramming bloatware and spyware, embellished in the worst UI imaginable, running on a processor designed for a smartwatch.</p>

<p><img src="https://petargyurov.com/assets/images/cars-suck-man/smart-tv-pooramid.png" width="200"> <em>The Essential Smart TV Pooramid</em></p>

<p>Picture quality is at phenomenal levels, even on low-cost offerings, but those inky blanks come at the cost of compromised privacy and ad-infested UI.</p>

<p>So what do cars have to do with any of this? Every product that takes a concrete position in human dynamics, be it a TV, a fridge or a car, follows a relatively predictable evolution: it starts of limited but promising, gets meaningful upgrades, and eventually slides into into the valley of “enshittification”. Few are those who climb their way out of the shit-pit, fewer still are those who avoid it entirely.</p>

<p><img src="https://petargyurov.com/assets/images/cars-suck-man/valley-of-enshittification.png"> <em>100% science based chart</em></p>

<h3 id="whats-so-wrong-with-cars-then">What’s so wrong with cars then?</h3>

<p>We live in an era of peak automotive power, utility and luxury. Much like with TVs, we probably reached the first plateau of quality: image clarity, super thin displays, etc. Then we started getting things nobody asked for: frame rate interpolation (why God, why!?), insane image presets, automatic audio adjustments. I won’t talk about 3D TVs. Let’s just pretend that never happened and that drawer in your cabinet isn’t full of dusty 3D glasses that haven’t seen the light of day for the last decade.</p>

<p>Cars are entering the “frame-interpolation” era, the slippery slope into the loathed, anti-consumer, anti-logic Shit Pit.</p>

<p>Let’s just fire through this:</p>

<ul>
  <li>Hiding critical/often-used buttons behind touchscreens for the sake of minimalism (and cost?)</li>
  <li>On that note, poor physical layout in general (genuinely thinking that you can rate cars’ on a “hazard-light-button-placement index”)</li>
  <li>YOUR LED LIGHTS ARE TOO BRIGHT GODDAMIT</li>
  <li>Cars are getting too big; why are manufacturers pushing “crossovers” and SUVs on consumers and why are consumers buying them? I could write pages on this point alone.</li>
  <li>Combine the two previous points for peak blindness</li>
  <li>“Low profile” rims/tyres/wheels/whatever: cost a fortune and more prone to getting scratched</li>
  <li>Subscription style plans trying to creep their way in</li>
  <li>ALL the privacy violations you could think of</li>
  <li>Rubbish software and UI all round: it’s 2024 and I dread it every time I need to pair my phone to a car</li>
  <li>That weird glossy pastel paintwork that’s so popular all of a sudden (I’m allowed one subjective point on here, OK?)</li>
</ul>

<h3 id="the-car-of-the-future">The car of the future</h3>

<p>I don’t think we’ve reached the depths of the brown ocean… yet. Who’s to blame here? Consumers? Manufacturers?</p>

<p>I know I sound like a luddite here but the same way I just want a good display from my TV, I want less from my car, not more.</p>

<p>I miss my 2005 Toyota Corolla 😢</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free unexpected MIT courses to kick start the new year (112 pts)]]></title>
            <link>https://medium.com/open-learning/free-unexpected-mit-courses-to-kick-start-the-new-year-c226e444e61a</link>
            <guid>38988987</guid>
            <pubDate>Sun, 14 Jan 2024 09:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/open-learning/free-unexpected-mit-courses-to-kick-start-the-new-year-c226e444e61a">https://medium.com/open-learning/free-unexpected-mit-courses-to-kick-start-the-new-year-c226e444e61a</a>, See on <a href="https://news.ycombinator.com/item?id=38988987">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="43a1">From heavy metal to poker to the history of Samurai, make 2024 your year with these online course materials and educational resources.</h2><div><a rel="noopener follow" href="https://medium.com/@mitopenlearning?source=post_page-----c226e444e61a--------------------------------"><div aria-hidden="false"><p><img alt="MIT Open Learning" src="https://miro.medium.com/v2/resize:fill:88:88/1*WGiUuRRlXnFLwkvtM9c7KA.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://medium.com/open-learning?source=post_page-----c226e444e61a--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="MIT Open Learning" src="https://miro.medium.com/v2/resize:fill:48:48/1*RJQZG2O7JCd0njpHuP5r4Q.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div></div><figure><figcaption>Image: Jacek Kita via iStock</figcaption></figure><p id="3504">Are you looking to learn a new language, explore musical genres, or improve your poker game in 2024? We’ve compiled 13 free online courses from MIT OpenCourseWare to kick start the new year on a positive note — from Italian, The Beatles, and heavy metal to poker theory, the history of Samurai, and different ways to understand climate change.</p><h2 id="e177">Learn (or create) a new language</h2><h2 id="2925"><a href="https://ocw.mit.edu/courses/24-917-conlangs-how-to-construct-a-language-fall-2018/" rel="noopener ugc nofollow" target="_blank">How to Construct a Language</a></h2><p id="9bbe">Create your own language while considering the basic linguistic characteristics of various languages of the world. This course material explores languages that have been deliberately constructed, including Esperanto, Klingon, and Tolkien’s Elvish.</p><h2 id="3ceb"><a href="https://ocw.mit.edu/courses/es-s41-speak-italian-with-your-mouth-full-spring-2012/" rel="noopener ugc nofollow" target="_blank">Speak Italian with your Mouth Full</a></h2><p id="69a3">Learn basic conversational Italian, and discover Italian culture and the Mediterranean diet. Each topic in this course is based on bite-sized acquisition of Italian language and culture, as well as the preparation of a delicious dish.</p><h2 id="b464">Get creative with a music course</h2><h2 id="dde8"><a href="https://ocw.mit.edu/courses/res-21m-001-heavy-metal-101-january-iap-2023/" rel="noopener ugc nofollow" target="_blank">Heavy Metal 101</a></h2><p id="14fd">Learn everything you ever wanted to know about heavy metal music, including musicology, songwriting tropes, and how the genre tackles some of today’s biggest socio-political challenges — among other topics.</p><h2 id="f015"><a href="https://ocw.mit.edu/courses/21m-299-the-beatles-fall-2017/" rel="noopener ugc nofollow" target="_blank">The Beatles</a></h2><p id="109d">Delve into the music of The Beatles, from the band’s early years to their break-up. Learn how The Beatles’ musical style changed from skiffle and rock to studio-based experimentation. This course explores the cultural influences that helped to shape The Beatles and the band’s influence worldwide.</p><h2 id="2a6c"><a href="https://ocw.mit.edu/courses/21m-250-beethoven-to-mahler-spring-2014/pages/beethoven-concert/" rel="noopener ugc nofollow" target="_blank">Beethoven to Mahler</a></h2><p id="9ce2">Watch a recording of a concert of Beethoven violin sonatas on period instruments. This course also includes a discussion about Susanna Ogata and Ian Watson’s performance.</p><h2 id="efb0">Take a playful management course</h2><h2 id="dd3b"><a href="https://ocw.mit.edu/courses/15-s50-poker-theory-and-analytics-january-iap-2015/" rel="noopener ugc nofollow" target="_blank">Poker Theory and Analytics</a></h2><p id="9fc1">Improve your poker game by exploring theory and the applications of poker analytics to investment management and trading.</p><h2 id="8e4e"><a href="https://ocw.mit.edu/courses/15-s50-how-to-win-at-texas-holdem-poker-january-iap-2016/" rel="noopener ugc nofollow" target="_blank">How to Win at Texas Hold’em Poker</a></h2><p id="f209">Become a seasoned player at Texas Hold’em, one of the most popular variants of poker. This course covers general concepts, as well as the poker and math concepts needed to play the card game on a professional level.</p><h2 id="d1be">Travel to the past with a history course</h2><h2 id="123e"><a href="https://ocw.mit.edu/courses/21h-154-inventing-the-samurai-fall-2022/" rel="noopener ugc nofollow" target="_blank">Inventing the Samurai</a></h2><p id="64d8">Discover the historical origins of the Japanese warrior class and its reinvention. This course covers the rise of the imperial court, interactions with the broader world, and the establishment of a warrior-dominated state.</p><h2 id="65d0">Expand your mind with a science course</h2><h2 id="5e77"><a href="https://ocw.mit.edu/courses/9-401-tools-for-robust-science-fall-2022" rel="noopener ugc nofollow" target="_blank">Tools for Robust Science</a></h2><p id="b85e">Explore cutting-edge tools and techniques designed to revitalize and enhance scientific practices in the cognitive and neuro sciences. This course illustrates how to identify obstacles to conducting robust scientific research, as well as tools to overcome these obstacles.</p><h2 id="c66c"><a href="https://ocw.mit.edu/courses/res-2-008-thermodynamics-and-climate-change-summer-2020/" rel="noopener ugc nofollow" target="_blank">Thermodynamics and Climate Change</a></h2><p id="313a">Learn the three laws of thermodynamics through their connection with climate change. Explore concepts such as entropy and enthalpy, applications like energy conversion and energy storage, and investigate the causes and effects of global warming from a thermodynamics perspective.</p><h2 id="e95f"><a href="https://ocw.mit.edu/courses/3-091-introduction-to-solid-state-chemistry-fall-2018/pages/why-this-matters-videos/" rel="noopener ugc nofollow" target="_blank">Introduction to Solid-State Chemistry</a></h2><p id="2b1a">This course focuses on how chemistry is connected to important innovations — and sometimes unexpected consequences — in science and in life. You might start with the “Why This Matters” series of short excerpts from the course’s lecture videos to learn about real-world applications and creative directions for research.</p><h2 id="c0f0">Educational resources beyond the virtual classroom</h2><h2 id="eb61"><a href="https://ocw.mit.edu/courses/res-11-003-climate-justice-instructional-toolkit-fall-2023/" rel="noopener ugc nofollow" target="_blank">Climate Justice Instructional Toolkit</a></h2><p id="103a">These resources are made especially for educators who want to integrate climate justice content into courses across many disciplines, and they’re great for anyone exploring the many facets of climate justice.</p><h2 id="8a40"><a href="https://ocw.mit.edu/courses/res-2-006-girls-who-build-cameras-summer-2016/" rel="noopener ugc nofollow" target="_blank">Girls Who Build Cameras</a></h2><p id="7b25">This one-day, hands-on workshop for high school girls provides an introduction to camera physics and technology. Learn how to tear down old dSLR cameras, build a Raspberry Pi camera, design Instagram filters and Photoshop tools, and run your own version of this workshop.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Ultimate Docker Cheat Sheet (140 pts)]]></title>
            <link>https://devopscycle.com/blog/the-ultimate-docker-cheat-sheet/</link>
            <guid>38988960</guid>
            <pubDate>Sun, 14 Jan 2024 09:45:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devopscycle.com/blog/the-ultimate-docker-cheat-sheet/">https://devopscycle.com/blog/the-ultimate-docker-cheat-sheet/</a>, See on <a href="https://news.ycombinator.com/item?id=38988960">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
				
<div>
		<p>Get your Docker Cheat Sheet as&nbsp;<a href="http://devopscycle.com/wp-content/uploads/sites/4/2023/12/the-ultimate-docker-cheat-sheet-1.pdf" target="_blank" rel="noreferrer noopener" data-type="attachment" data-id="902">PDF</a>&nbsp;or as an&nbsp;<a href="http://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-4.png" target="_blank" rel="noreferrer noopener" data-type="attachment" data-id="900">image</a>. To follow this article, make sure your development machine has&nbsp;<a href="https://docs.docker.com/get-docker/" target="_blank" rel="noreferrer noopener">Docker installed</a>. In this blog post, we write our own Dockerfiles, learn how to create images, and finally run them as container. The complete source code is available on&nbsp;<a href="https://github.com/aichbauer/the-ultimate-docker-cheat-sheet" target="_blank" rel="noreferrer noopener">GitHub</a>.</p>

	</div>



<h2>Table of Contents</h2>
<div>
		<ul>
<li><a href="#download-the-ultimate-docker-cheat-sheet">Download the ultimate Docker Cheat Sheet</a></li>
<li><a href="#what-is-the-difference-between-a-dockerfile-an-image-and-a-container">What is the difference between a Dockerfile, an image and a container?</a></li>
<li><a href="#how-do-you-create-a-dockerfile">How do you create a Dockerfile?</a>
<ul>
<li><a href="#what-is-a-multistage-dockerfile">What is a multistage Dockerfile?</a></li>
</ul>
</li>
<li><a href="#how-do-you-create-a-docker-image">How do you create a Docker image?</a>
<ul>
<li><a href="#how-do-you-list-all-images">How do you list all images?</a></li>
<li><a href="#how-do-you-name-your-images">How do you name your images?</a></li>
</ul>
</li>
<li><a href="#how-do-you-create-a-container">How do you create a container?</a>
<ul>
<li><a href="#how-do-you-run-containers-in-the-background">How do you run containers in the background?</a></li>
<li><a href="#how-do-you-list-all-containers">How do you list all containers?</a></li>
<li><a href="#how-do-you-stop-and-remove-containers">How do you stop and remove containers?</a></li>
<li><a href="#what-if-i-killed-the-terminal-but-the-container-is-still-running">What if I killed the terminal, but the container is still running?</a></li>
<li><a href="#how-do-you-access-containers-from-the-host-system">How do you access containers from the host system?</a></li>
<li><a href="#how-do-you-publish-ports">How do you publish ports?</a></li>
<li><a href="#how-do-you-access-a-running-container">How do you access a running container?</a></li>
</ul>
</li>
<li><a href="#how-do-you-persist-data-with-docker-volumes">How do you persist data with Docker volumes?</a>
<ul>
<li><a href="#how-do-you-list-all-volumes">How do you list all volumes?</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
	</div>



<h2 id="download-the-ultimate-docker-cheat-sheet">Download The Ultimate Docker Cheat Sheet</h2>
<div>
	<p>Please&nbsp;<a href="http://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-1.pdf" target="_blank" rel="noreferrer noopener" data-type="attachment" data-id="902">download</a>&nbsp;your Docker Cheat Sheet to follow along with this article. You are also welcome to share it with your colleagues and friends.</p>
</div>



<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="none"> 
          <p><a href="http://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-4.png" target="_blank">
              <img data-delay="0" height="1087" width="768" data-animation="none" src="https://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-copy-768x1087.webp" alt="The Ultimate Docker Cheat Sheet" srcset="https://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-copy-768x1087.webp 768w, https://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-copy-212x300.webp 212w, https://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-copy-724x1024.webp 724w, https://devopscycle.com/wp-content/uploads/sites/4/2023/11/the-ultimate-docker-cheat-sheet-copy.webp 800w" sizes="(max-width: 768px) 100vw, 768px">
            </a>
          </p>
        </div><h2 id="what-is-the-difference-between-a-dockerfile-an-image-and-a-container">Do You Want More Resources Like This?</h2>
<div>
	<p>Be the first to join our new <a href="https://discord.gg/7xpRbG2gY9" target="_blank" rel="noopener">community</a> and stay up-to-date on the latest DevOps topics (free cookies for the first 42 arrivals!). Don’t miss out on any new resources by signing up for our <a href="#newsletter">newsletter</a>. Get access to our latest resources and insights directly in your inbox!</p>
</div>



<h2>What Is The Difference Between A Dockerfile, An Image And A Container?</h2>
<div>
	<p>All these things build on top of each other. You need a Dockerfile to create an image, and you need an Image to create a Container.</p>
</div>




<div>
		<ul>
<li><strong>Dockerfile:</strong>&nbsp;The first step in using Docker is writing a Dockerfile. It is an essential blueprint for constructing Docker images. It is a text file, is usually named “Dockerfile” without any extension, and contains a series of instructions. Each line in this file represents a new instruction, forming a stack of layers. Each layer is cache-able. When you build an image twice, it will use the cache. When you change a line in the file, it rebuilds all instructions after and including the change.</li>
<li><strong>Image:</strong>&nbsp;Building a Dockerfile outputs a Docker image. You can think of an image like an executable. Just like clicking an icon (executable) on your desktop to launch an application. You can start an image to launch a container. The Docker image encapsulates your application code and all its dependencies. This includes the runtime and system libraries. It is a self-contained unit that ensures consistency and portability across various environments. For example, your development machine and your production server.</li>
<li><strong>Container:</strong>&nbsp;This is a dynamic, running instance of a Docker image. An executed image spawns a container with the command in the Dockerfile. Important to note: one image can give life to many containers. If Linux is your operating system, the Docker container will run as a process on the host machine. If you have a Windows or macOS machine, docker will run in a virtual machine (VM). The container will use the same kernel, either the kernel of Linux or the VM on Windows or macOS. The container itself is not a virtual machine. The container cannot see other processes of the host and has its own file system. This is why it seems as it is a virtual machine. But in reality, it shares the kernel of the host machine (or the kernel of the VM).</li>
</ul>
	</div>




<div>
	<p>In conclusion: the Dockerfile is the base for an image, and an image is used to create a container. A container is running as a process on the host machine. Yet, it has its own file system and is separated from the other processes.</p>
</div>



<h2 id="how-do-you-create-a-dockerfile">How Do You Create A Dockerfile?</h2>
<div>
	<p>To generate a Dockerfile, you can create a plain text file. This article will use the command line for it:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-1" data-shcb-language-name="Dockerfile" data-shcb-language-slug="dockerfile"><code><span># create a new file in your current working directory called Dockerfile</span>
$ touch Dockerfile
<span># open the file in your favorite editor (we are using Visual Studio Code)</span>
<span># if you do not have the code command installed, you will need to open it manually</span>
$ code Dockerfile</code><small id="shcb-language-1"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>A Dockerfile holds all the instructions to build, start and run your application. Every command that you otherwise need to execute manually is written in a single file. It starts by using a base image. This is usually a small Linux distribution like alpine. If you have to execute a binary, you should use&nbsp;<code>FROM <a href="https://hub.docker.com/_/scratch/" target="_blank" rel="noreferrer noopener">scratch</a></code>. This article uses a&nbsp;<a href="https://fastify.dev/" target="_blank" rel="noreferrer noopener">Fastify</a>&nbsp;server, so it uses an&nbsp;<a href="https://www.alpinelinux.org/" target="_blank" rel="noreferrer noopener">alpine</a>&nbsp;image configured for&nbsp;<a href="https://nodejs.org/en" target="_blank" rel="noreferrer noopener">Node.js</a>. You can view the complete code on&nbsp;<a href="https://github.com/aichbauer/the-ultimate-docker-cheat-sheet" target="_blank" rel="noreferrer noopener">GitHub</a>.</p>
</div>




<div>
	<p>Now we will edit the Dockerfile in Visual Studio Code:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-2" data-shcb-language-name="Dockerfile" data-shcb-language-slug="dockerfile"><code><span><span># the next line sets the base image for this image</span>
</span><span><span># the base image is also based on a Dockerfile</span>
</span><span><span># see: https://hub.docker.com/layers/library/node/18-alpine/images/sha256-a0b787b0d53feacfa6d606fb555e0dbfebab30573277f1fe25148b05b66fa097</span>
</span><span><span># node provides official images for Node.js and</span>
</span><span><span># alpine: a lightweight Linux distribution to reduce image size</span>
</span><span><span>FROM</span> node:<span>18</span>-alpine
</span>
<span><span># sets the working directory inside the image</span>
</span><span><span># all commands after this instruction will be</span>
</span><span><span># executed inside this directory</span>
</span><span><span>WORKDIR</span><span> /app</span>
</span>
<span><span># copies the package.json and package-lock.json</span>
</span><span><span># from the client (e.g., your server or your development machine)</span>
</span><span><span># into the /app directory inside the image</span>
</span><span><span># before running npm ci to </span>
</span><span><span># get the advantage of layer caching</span>
</span><span><span>COPY</span><span> ./package* .</span>
</span>
<span><span># installs all node.js dependencies</span>
</span><span><span># npm ci is similar to npm install but intended to be</span>
</span><span><span># used in continuous integration (CI) environments</span>
</span><span><span># it will do a clean installion based on the package-lock.json</span>
</span><span><span>RUN</span><span> npm ci</span>
</span>
<span><span># copies the source code into the image</span>
</span><span><span>COPY</span><span> . .</span>
</span>
<span><span># this runs the build command specified in the package.json</span>
</span><span><span>RUN</span><span> npm run build:server</span>
</span>
<span><span># the EXPOSE instruction does not actually expose the port 300 of this image</span>
</span><span><span># this is documentation so that we know which port we need to expose</span>
</span><span><span># we do this when starting the container with the --publish flag</span>
</span><span><span>EXPOSE</span> <span>3000</span>
</span>
<span><span># executes the server.js file that is located in the build directory</span>
</span><span><span>CMD</span><span> [<span>"node"</span>, <span>"./build/index.js"</span>]</span>
</span>
</code><small id="shcb-language-2"><span>Code language:</span> <span>Dockerfile</span> <span>(</span><span>dockerfile</span><span>)</span></small></pre>
	</div>



<h3 id="what-is-a-multistage-dockerfile">What Is A Multistage Dockerfile?</h3>
<div>
	<p>You can compose a Dockerfile with many stages. You can think of one stage, as one image. Furthermore, you can then use materials like files from one stage in another stage. A new stage always starts with the line&nbsp;<code>FROM &lt;base-image&gt;</code>. You name a stage using the&nbsp;<code>as</code>&nbsp;keyword. This article uses a simple HTML and JavaScript file as our client application. As a web server, we will use&nbsp;<a href="https://www.nginx.com/" target="_blank" rel="noreferrer noopener">NGINX</a>. You can view the complete code on&nbsp;<a href="https://github.com/aichbauer/the-ultimate-docker-cheat-sheet" target="_blank" rel="noreferrer noopener" data-type="link" data-id="https://github.com/aichbauer/the-ultimate-docker-cheat-sheet">GitHub</a>.</p>
</div>




<div>
	<p>A typical approach is to have a&nbsp;<code>builder stage</code>, with a larger base image. This image holds all executables and libraries needed to build your source code.</p>
</div>




<div>
	<p>The second stage is the&nbsp;<code>serve stage</code>&nbsp;and has a small base image. The benefit is fewer dependencies and libraries. Just enough to execute and serve your application.</p>
</div>




<div>
	<p>With this approach, you make your final image both smaller and more secure. As the image size decreases and the image consists of fewer libraries. Fewer system libraries means it has a lower attack surface. Multistage Dockerfiles are not limited to this use case and can have more than two stages as well.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-3" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># lets create a new Dockerfile for our frontend application</span>
<span># as we can specify a file in the build command, we name this Dockerfile.client</span>
$ touch Dockerfile.client
<span># open the file in your favorite editor (we are using Visual Studio Code)</span>
<span># if you do not have the code command installed, you will need to open it</span>
$ code Dockerfile.client</code><small id="shcb-language-3"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>Here is an example of a multistage app:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-4" data-shcb-language-name="Dockerfile" data-shcb-language-slug="dockerfile"><code><span><span># the base image</span>
</span><span><span># name it builder</span>
</span><span><span># you can reference this stage</span>
</span><span><span># in other stages by this name</span>
</span><span><span>FROM</span> node:<span>18</span>-alpine as builder
</span>
<span><span># working directory inside the image</span>
</span><span><span>WORKDIR</span><span> /app</span>
</span>
<span><span># copies files from the client to the image</span>
</span><span><span>COPY</span><span> ./package* .</span>
</span>
<span><span># run a command inside the image</span>
</span><span><span>RUN</span><span> npm ci</span>
</span>
<span><span># copies files from the client to the image</span>
</span><span><span>COPY</span><span> . .</span>
</span>
<span><span># run a command inside the container</span>
</span><span><span># this will create a new folder in called dist in our app directory</span>
</span><span><span># inside the dist directory, you will find the</span>
</span><span><span># final HTML and JavaScript file</span>
</span><span><span>RUN</span><span> npm run build:client</span>
</span>
<span><span># serve stage</span>
</span><span><span># slim nginx base image named as serve</span>
</span><span><span># will start nginx as non root user</span>
</span><span><span>FROM</span> nginxinc/nginx-unprivileged:<span>1.24</span> as serve
</span>
<span><span># we can now copy things from the first stage to the second</span>
</span><span><span># we copy the build output to the directory where nginx serves files</span>
</span><span><span>COPY</span><span> --from=builder /app/dist /var/www</span>
</span>
<span><span># we overwrite the default config with our own</span>
</span><span><span># if you take a look at the GitHub repository, you</span>
</span><span><span># see the .nginx directory with the nginx.conf</span>
</span><span><span># here we only use the port 80</span>
</span><span><span># in production, you would also want to make sure</span>
</span><span><span># all requests, even in your internal network or Kubernetes cluster</span>
</span><span><span># is served via HTTPS when dealing with sensible data</span>
</span><span><span>COPY</span><span> --from=builder /app/.nginx/nginx.conf /etc/nginx/conf.d/default.conf</span>
</span>
<span><span># the EXPOSE instruction does not actually expose the port 80 of this image</span>
</span><span><span># this is documentation so that we know which port we need to expose</span>
</span><span><span># we do this when starting the container with the --publish flag</span>
</span><span><span>EXPOSE</span> <span>80</span>
</span>
<span><span># The command used when the image is started as a container</span>
</span><span><span># <span>Note:</span> for Docker containers (or for debugging),</span>
</span><span><span># the "daemon off;" directive which is used in this example</span>
</span><span><span># tells nginx to stay in the foreground.</span>
</span><span><span># for containers, this is useful.</span>
</span><span><span># best practice: one container = one process.</span>
</span><span><span># one server (container) has only one service.</span>
</span><span><span>CMD</span><span> [<span>"nginx"</span>, <span>"-g"</span>, <span>"daemon off;"</span>]</span>
</span>
</code><small id="shcb-language-4"><span>Code language:</span> <span>Dockerfile</span> <span>(</span><span>dockerfile</span><span>)</span></small></pre>
	</div>



<h2 id="how-do-you-create-a-docker-image">How Do You Create A Docker Image?</h2>
<div>
	<p>We use the Docker CLI to build images out of our Dockerfiles.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-5" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># list the directory to make sure you are in the directory with the Dockerfile</span>
$ ls
<span># if not, change the directory with "cd ./path/to/directory-with-Dockerfile"</span>
<span># build an Image out of the Dockerfile in the current working directory</span>
$ docker build .
<span># if you want to build another Dockerfile in this directory, use the --file flag</span>
<span># e.g., --file &lt;filename&gt;</span>
$ docker build --file Dockerfile.client .</code><small id="shcb-language-5"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>Creating an image from a Dockerfile only requires the&nbsp;<code>docker build</code>&nbsp;command. Without specifying a name and tag, you can reference the image only by its image ID.</p>
</div>



<h3 id="how-do-you-list-all-images">How Do You List All Images?</h3>
<div>
		<pre aria-describedby="shcb-language-6" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># list all local images on the client (your server or your development machine)</span>
$ docker image ls
<span># find your image ID</span></code><small id="shcb-language-6"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>If you want to give your image a name, you need to use the&nbsp;<code>--tag</code>&nbsp;(shorthand syntax:&nbsp;<code>-t</code>) flag while building the image. You will need this if you are working with a registry like&nbsp;<a href="https://hub.docker.com/" target="_blank" rel="noreferrer noopener">Docker Hub</a>.</p>
</div>



<h3 id="how-do-you-name-your-images">How Do You Name Your Images?</h3>
<div>
	<p>To name and tag your image, use the following pattern:&nbsp;<code>&lt;name&gt;:&lt;tag&gt;</code>. This is usually translated into&nbsp;<code>&lt;username&gt;/&lt;repository&gt;:&lt;version&gt;</code>. The username corresponds to the username of the registry.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-7" data-shcb-language-name="PHP" data-shcb-language-slug="php"><code><span># build and tag your image</span>
<span># a tag consists of a name and a tag, which is separated by a colon (:)</span>
$ docker build --tag examplename/examplerepository-server:<span>0.1</span><span>.0</span> .
<span># or</span>
$ docker build --file Dockerfile.client --tag examplename/examplerepository-client:<span>0.1</span><span>.0</span> .
<span># list all local images</span>
$ docker image ls
<span># you will see your image with a proper repository name and a tag</span></code><small id="shcb-language-7"><span>Code language:</span> <span>PHP</span> <span>(</span><span>php</span><span>)</span></small></pre>
	</div>



<h2 id="how-do-you-create-a-container">How Do You Create A Container?</h2>
<div>
	<p>A container is a running image. You can run images with the CLI command&nbsp;<code>docker run &lt;image-name&gt;</code>:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-8" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># start our image</span>
$ docker run examplename/examplerepository-server:0.1.0
<span># or</span>
$ docker run examplename/examplerepository-client:0.1.0</code><small id="shcb-language-8"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>Every Docker installation comes with a local registry. Docker stores your images here. First, the&nbsp;<code>docker run</code>&nbsp;command will look at the local registry and try to find the image. This will happen with our image, since we built it on the same machine we are executing the&nbsp;<code>docker run</code>&nbsp;command. If it does not find the image locally, it will take a look at the Docker Hub registry. You can also get images from other registries (e.g., your self-hosted registry). For that, you can use the URL of the self-hosted registry.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-9" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># try to find an image on another registry</span>
$ docker run https://registrydomain.com/examplename/examplerepository-server:0.1.0</code><small id="shcb-language-9"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>If you run an image, it starts in a foreground process. The container is running as a process in the terminal where you executed the&nbsp;<code>docker run</code>&nbsp;command. If you kill the terminal, it will stop the container immediately. To let your container run on your machine or server, you can run the container as a background process. In that way, you can close your terminal with no worries.</p>
</div>



<h3 id="how-do-you-run-containers-in-the-background">How Do You Run Containers In The Background?</h3>
<div>
	<p>The&nbsp;<code>--detached</code>&nbsp;(shorthand syntax:&nbsp;<code>-d</code>) flag will start containers in a background process:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-10" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># run container in the background</span>
$ docker run --detached examplename/examplerepository-server:0.1.0
<span># or</span>
$ docker run --detached examplename/examplerepository-client:0.1.0</code><small id="shcb-language-10"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>You will see that the command will exit, and you can use the terminal again.</p>
</div>



<h3 id="how-do-you-list-all-containers">How Do You List All Containers?</h3>
<div>
	<p>Docker will only show the running containers.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-11" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># list all running containers</span>
$ docker container ls
<span># short</span>
$ docker ps</code><small id="shcb-language-11"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>If you want to see all containers, even the stopped containers, you need to pass the flag&nbsp;<code>--all</code>&nbsp;(shorthand syntax:&nbsp;<code>-a</code>).</p>
</div>




<div>
		<pre aria-describedby="shcb-language-12" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># list all stopped and running containers</span>
$ docker container ls --all</code><small id="shcb-language-12"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h3 id="how-do-you-stop-and-remove-containers">How Do You Stop And Remove Containers?</h3>
<div>
	<p>Occasionally, you would like to stop containers. When you stop containers, they are still on the system, you can start them again. If you wish to clean the container from the system, you will need to remove it. You can only remove a stopped container.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-13" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># stop a container</span>
$ container stop &lt;container-id&gt;
<span># start a container</span>
$ container start &lt;container-id&gt;
<span># restart container</span>
$ container restart &lt;container-id&gt;
<span># remove a stopped container</span>
$ container rm &lt;container-id&gt;</code><small id="shcb-language-13"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>If you wish to remove a container as soon as you stop it, you can pass the&nbsp;<code>--rm</code>&nbsp;flag when starting a container. Only use this if your container is stateless. If your container has its own state, make sure to use volumes to preserve it. Otherwise, all your data inside the container is lost when your container stops.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-14" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># automatically remove a container after it stops</span>
$ docker run --rm examplename/examplerepository-server:0.1.0
<span># or</span>
$ docker run --rm examplename/examplerepository-client:0.1.0</code><small id="shcb-language-14"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h3 id="what-if-i-killed-the-terminal-but-the-container-is-still-running">What If I Killed The Terminal, But The Container Is Still Running?</h3>
<div>
	<p>Sometimes signals are not passed to the container properly. Imagine you have killed your terminal because you could not stop the container with CTRL+C. But If you try to restart the container, it tells you that the port is already allocated. This means your old container is still running. To kill a container, run the following command:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-15" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># kill a container</span>
$ docker <span>kill</span> &lt;conatiner-id&gt;</code><small id="shcb-language-15"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h3 id="how-do-you-access-containers-from-the-host-system">How Do You Access Containers From The Host System?</h3>
<div>
	<p>Usually, a Docker container exposes one or many ports. You can access the application which is running inside the container via those ports. To have access to these ports, you need to publish those port during the container creation. Another way to access containers from the host system is by executing commands inside them. This is often used for debugging or single use container application.</p>
</div>



<h3 id="how-do-you-publish-ports">How Do You Publish Ports?</h3>
<div>
	<p>To expose the ports to the host system, you need to add the&nbsp;<code>--publish</code>&nbsp;(shorthand syntax:&nbsp;<code>-p</code>) flag.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-16" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># publish ports, e.g., forward container port to a port on the host system</span>
$ docker run --publish 3000:3000 examplename/examplerepository-server:0.1.0
<span># or</span>
$ docker run --publish 80:80 examplename/examplerepository-server:0.1.0
<span># if you run both containers, the server and the client</span>
<span># and you visit the localhost:80 in your browser</span>
<span># you should see the message Hello World</span></code><small id="shcb-language-16"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>In the first example above, we bind the port 3000 from the container to the port 3000 on the host system. The host system is your development machine or your server. The format is the following&nbsp;<code>--publish &lt;hostport&gt;:&lt;containerport&gt;</code>.</p>
</div>



<h3 id="how-do-you-access-a-running-container">How Do You Access A Running Container?</h3>
<div>
	<p>Sometimes, you want access to a container. This can be beneficial for debugging.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-17" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># access the container</span>
$ docker <span>exec</span> --interactive --tty &lt;container-id&gt; &lt;shell-command&gt;</code><small id="shcb-language-17"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p><code>--interactive --tty</code>&nbsp;(shorthand syntax&nbsp;<code>-it</code>) instructs Docker to allocate a pseudo-TTY connection. In this way, the containers’ stdin (standard input) creates an interactive shell in the container.</p>
</div>




<div>
	<p>You can execute any command that would be possible within the container. If you have a Debian container running, you would be able to list the directory:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-18" data-shcb-language-name="PHP" data-shcb-language-slug="php"><code><span># list the directory inside the container</span>
$ docker exec --interactive --tty &lt;container-id&gt; ls</code><small id="shcb-language-18"><span>Code language:</span> <span>PHP</span> <span>(</span><span>php</span><span>)</span></small></pre>
	</div>




<div>
	<p>You can even create a secure shell like connection with the following command:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-19" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># SSH into the container (if the `sh` command exists in the container)</span>
$ docker <span>exec</span> --interactive --tty &lt;container-id&gt; sh
<span># this will keep the connection to the container open</span>
<span># and you can execute multiple commands within the container</span>
<span># to exit the container, run the following</span>
$ <span>exit</span></code><small id="shcb-language-19"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h2 id="how-do-you-persist-data-with-docker-volumes">How Do You Persist Data With Docker Volumes?</h2>
<div>
	<p>Data that is stored inside a container is not persisted by default. When you stop and remove a container, all data from this container is lost. In our application, if you click the button on the website (<a href="http://localhost/" target="_blank" rel="noopener">http://localhost:80</a>) we will write “New message” into a JSON file inside the container. Now if we stop and remove the container, all those messages are deleted as well.</p>
</div>




<div>
	<p>If you want to persist data between container starts, you need to use volumes. There are two different volume types: named volumes and mounted volumes. Named volumes are completely handled by Docker, a mounted volume is managed by you. For a mounted volume, you need to specify the location on the host system where this data will be stored. We use the&nbsp;<code>--volume</code>&nbsp;(shorthand&nbsp;<code>-v</code>) in our run command.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-20" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># using a named volume</span>
<span># everything within this path of the container will be stored</span>
<span># in a volume named &lt;volume-name&gt;</span>
$ docker run --volume &lt;volume-name&gt;:/path/<span>in</span>/container &lt;image-name&gt;

<span># using a mounted volume</span>
<span># everything inside the path of the container will be stored </span>
<span># in the path of the host</span>
$ docker run --volume /path/on/host:/path/<span>in</span>/container &lt;image-name&gt;</code><small id="shcb-language-20"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>




<div>
	<p>For our application, we need to use the following command for the server container:</p>
</div>




<div>
		<pre aria-describedby="shcb-language-21" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># create a volume called server-volume</span>
<span># we store the content of /app/build/data within our container</span>
<span># on our host machine (your dev machine or your server)</span>
docker run --volume server-volume:/app/build/data --publish 3000:3000 examplename/examplerepository-server:0.1.0</code><small id="shcb-language-21"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h3 id="how-do-you-list-all-volumes">How Do You List All Volumes?</h3>
<div>
	<p>You can get an overview of all volumes and their metadata by listing them.</p>
</div>




<div>
		<pre aria-describedby="shcb-language-22" data-shcb-language-name="Bash" data-shcb-language-slug="bash"><code><span># list all volumes</span>
$ docker volume ls

<span># here you will see the location where Docker will store the named volumes</span>
<span># on the host machine</span></code><small id="shcb-language-22"><span>Code language:</span> <span>Bash</span> <span>(</span><span>bash</span><span>)</span></small></pre>
	</div>



<h2 id="conclusion">Conclusion</h2>
<div>
	<p>In this article we learned the difference between a Dockerfile, an image and a container. You can now write your Dockerfiles to create images. Furthermore, you can start containers and access them from the host system. Additionally, you also learned how to persist data between container starts.</p>
</div>




<div>
	<p>If you need help with your containerization, <a href="https://calendly.com/devopsberatung/meet" target="_blank" rel="noreferrer noopener nofollow">feel free to contact us</a>, or join our new community for further questions and discussions (free cookies for the first 42 arrivals)!</p>
</div>



<p><a role="button" target="_blank" href="https://discord.gg/7xpRbG2gY9" data-color-override="#6bf4b2" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Join Our Community</span><i></i></a></p><div>
	<p>You liked this article? Share it with your colleagues and friends.</p>
</div>



<h2 id="newsletter">Sign up for our newsletter!</h2>
<div>
	<p>Do not miss out on our latest tips, guides, and updates – sign up for our newsletter now! We promise to only send you the most relevant and useful information. Be part of our journey in exploring the world of Docker and beyond.</p>
</div>








<h2>Author</h2>





			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic programming is not black magic (245 pts)]]></title>
            <link>https://qsantos.fr/2024/01/04/dynamic-programming-is-not-black-magic/</link>
            <guid>38988948</guid>
            <pubDate>Sun, 14 Jan 2024 09:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qsantos.fr/2024/01/04/dynamic-programming-is-not-black-magic/">https://qsantos.fr/2024/01/04/dynamic-programming-is-not-black-magic/</a>, See on <a href="https://news.ycombinator.com/item?id=38988948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content">

	
<article id="post-3499">

	
<!-- .entry-header -->

	<div>

			
<p>This year’s <a href="https://en.wikipedia.org/wiki/Advent_of_Code">Advent of Code</a> has been brutal (compare the <a href="https://adventofcode.com/2023/stats">stats of 2023</a> with <a href="https://adventofcode.com/2022/stats">that of 2022</a>, especially day 1 part 1 vs. day 1 part 2). It included a problem to solve with dynamic programming as soon as day 12, which discouraged some people I know. This specific problem was particularly gnarly for Advent of Code, with multiple special cases to take into account, making it basically intractable if you are not already familiar with dynamic programming.</p>



<p>However, dynamic programming itself is mostly natural when you understand what it does. And <a href="https://en.wikipedia.org/wiki/Dynamic_programming#Algorithms_that_use_dynamic_programming">many common algorithms are actually just the application of dynamic programming to specific problems</a>, including omnipresent path-finding algorithms such as Dijkstra’s algorithm.</p>



<p>This motivated me to write a gentler introduction and a detailed explanation of solving Day 12.</p>



<p>Let me start with a rant. You can <a href="#basic-caching">skip to the following section</a> if you want to get to the meat of the article.</p>



<h2>The Rant</h2>



<p>Software engineering is terrible at naming things.</p>



<ul>
<li>“<strong>Bootstrap</strong>” is an <a href="https://en.wikipedia.org/wiki/Bootstrapping">imaged expression to point to the absurdity and impossibility of a task</a>, but it has become synonymous with “start” without providing any additional information, <a href="https://en.wiktionary.org/wiki/bootstrap#Verb">such as “boot a computer”</a>. The illusion that it is actually meaningful had lead to an <a href="https://en.wikipedia.org/wiki/Bootstrapping_(disambiguation)">absurd level of polysemy</a>.</li>



<li>“<strong>Daemon</strong>”, for a process that is detached from your terminal</li>



<li>“<strong>Cascading Style Sheets</strong>”, just to mean that properties can be overridden</li>



<li>“<strong>Cookie</strong>”, for a piece of data stored on the Web browser, which is automatically sent to the server</li>



<li>“<strong>Artificial Intelligence</strong>” which is so vague it refers just as well to <a href="https://en.wikipedia.org/wiki/Expert_system">if-conditions</a>, or to <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">AGI</a></li>
</ul>



<p>Now, let’s take a look at “<strong>dynamic programming</strong>”. What can we learn from the name? “<strong>Programming</strong>” must refer to a style of programming, such as “functional <em>programming</em>”, or maybe “test-driven <em>development</em>”. Then, “<strong>dynamic</strong>” could mean:</p>



<ul>
<li>like in <strong>dynamic typing</strong>, maybe it could refer to the more general idea of handling objects of arbitrary types, with techniques such as <a href="https://en.wikipedia.org/wiki/Virtual_function">virtual classes</a>, <a href="https://doc.rust-lang.org/book/ch17-02-trait-objects.html">trait objects</a>, or a <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html">base Object type</a>.</li>



<li>maybe it could be the opposite of preferring <a href="https://en.wikipedia.org/wiki/Immutable_object">immutable state</a></li>



<li>if it’s not about data, maybe it could be about dynamic <em>code</em>, such as <a href="https://en.wikipedia.org/wiki/Self-modifying_code">self-modifying code</a>, or <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JIT</a></li>



<li>maybe it could be yet another framework such as <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a>, <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">SCRUM</a>, <a href="https://en.wikipedia.org/wiki/Extreme_programming">XP</a>, <a href="https://en.wikipedia.org/wiki/V-model_(software_development)">V-model</a>, <a href="https://en.wikipedia.org/wiki/Round-trip_engineering">RTE</a>, <a href="https://en.wikipedia.org/wiki/Rapid_application_development">RAD</a></li>



<li>maybe it could be referring to using practices from <a href="https://en.wikipedia.org/wiki/Competitive_programming">competitive programming</a>? Yes, it’s a stretch, but that might make sense</li>
</ul>



<p>Guess what. It means nothing of that, and it has nothing to do with being “dynamic”. It <em>is</em> an idea that you can use to design an algorithm, so there is a link to “programming”; I will grant it that.</p>



<p>So, what <em>is</em> it?</p>



<h2 id="basic-caching">Basic Caching</h2>



<p>Let’s say we want to solve a problem by splitting it in smaller similar problems. Basically, a recursive function. Often, we end-up having to solve the same smaller problems many times.</p>



<p>The typical example is Fibonacci, where you want to evaluate <code>f(n)</code>, which is defined as <code>f(n - 1) + f(n - 2)</code>. If we implement it naively, we will end up evaluating f(1) many times:</p>



<figure><img fetchpriority="high" decoding="async" width="925" height="404" src="https://qsantos.fr/wp-content/uploads/2024/01/image.png" alt=""><figcaption>Call tree for evaluating f(6), the 6-th Fibonacci number. To evaluate, f(6), we need to evaluate both f(5) and f(4). To evaluate f(5), we will need f(4) and f(3). Already, we see that we are going to need f(4) in two places. If we go further, we see that we will need f(1) 8 eight times, which happens to be f(6).</figcaption></figure>



<p>In fact, in this case, since only <code>f(1)</code> adds anything to the overall result, the number of times we will need <code>f(1)</code> is equal to <code>f(n)</code>. And <code>f(n)</code> grows very fast as <code>n</code> grows.</p>



<p>Of course, we can avoid doing this. We can just cache the results (or <a href="https://en.wikipedia.org/wiki/Memoization">memoize</a> <code>f</code>, in terrible academic vernacular).</p>



<p>In the example, once we have evaluated <code>f(4)</code> once, there is no need to evaluate it again, saving 3 evaluations of <code>f(1)</code>. By doing the same for <code>f(3)</code> and <code>f(2)</code>, we get down to 2 evaluations of <code>f(1)</code>. In total, <code>f(…)</code> is evaluated 7 times (<code>f(0)</code>, <code>f(1)</code>, <code>f(2)</code>, <code>f(3)</code>, <code>f(4)</code>, <code>f(5)</code>, <code>f(6)</code>), which is just f(n) + 1.</p>



<p>This is theoretically (<em>asymptotically</em>) optimal. But we can look at this in a different way.</p>



<h2>Optimized Caching</h2>



<p>With memoization, we keep the recursion: “to solve <code>f(6)</code>, I need <code>f(5)</code>, which will itself need <code>f(4)</code> […] and <code>f(3)</code> […], and <code>f(4)</code>, which will itself need <code>f(3)</code> […] and <code>f(2)</code> […].”. Basically, we figure out what we need just when we need them.</p>



<p>Instead, we can make the simple observation that we will need <em>f(0)</em> and <em>f(1)</em> for all other evaluations of <em>f(…)</em>. Once we have them, we can evaluate <em>f(2)</em>, which will need for all <em>other</em> evaluations of <em>f(…)</em>. </p>



<p>You can think of it as plucking the leaves (the nodes without descendants) from the call tree we saw before, and repeat until there are no more nodes. In other words, perform a <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>.</p>



<p>With the example, if we have some array F where we can store our partial results:</p>



<ul>
<li>F[0] = f(0) = 0</li>



<li>F[1] = f(1) = 1</li>



<li>F[2] = f(2) = f(1) + f(0) = F[1] + F[0] = 1 + 0 = 1</li>



<li>F[3] = f(3) = f(2) + f(1) = F[2] + F[1] = 1 + 1 = 2</li>



<li>F[4] = f(4) = f(3) + f(2) = F[3] + F[2] = 2 + 1 = 3</li>



<li>F[5] = f(5) = f(4) + f(3) = F[4] + F[3] = 3 + 2 = 5</li>



<li>F[6] = f(6) = f(5) + f(4) = F[5] + F[4] = 5 + 3 = 8</li>
</ul>



<p>With this approach, we do not have any recursive call anymore. And <em>that</em> is <strong>dynamic programming</strong>.</p>



<p>It also forces us to think clearly about what information we will be storing. In fact, in the case of Fibonacci we can notice that we only need the two last previous values. In other words:</p>



<ul>
<li>F[0] = f(0) = 0</li>



<li>F[1] = f(1) = 1</li>



<li>F[2] = f(2) = previous + previous_previous = 1 + 0 = 1</li>



<li>F[3] = f(3) = previous + previous_previous = 1 + 1 = 2</li>



<li>F[4] = f(4) = previous + previous_previous = 2 + 1 = 3</li>



<li>F[5] = f(5) = previous + previous_previous = 3 + 2 = 5</li>



<li>F[6] = f(6) = previous + previous_previous = 5 + 3 = 8</li>
</ul>



<p>So, we can discard other values and just keep two of them. Doing this in Python, we get:</p>



<pre><code lang="python">def fibo(n):
    if n == 0:
        return 0
    previous_previous = 0
    previous = 1
    for _ in range(n - 1):
        current = previous_previous + previous
        (previous, previous_previous) = (current, previous)
    return previous
</code></pre>



<p>I like that this gives us a natural and systematic progression from the mathematical definition of the Fibonacci function, to the iterative implementation (not the <a href="https://en.wikipedia.org/wiki/Fibonacci_sequence#Matrix_form">optimal one</a>, though).</p>



<p>Now, Fibonacci is more of a toy example. Let’s have a look at </p>



<h2>Edit Distance</h2>



<p>The edit distance between two strings is the smallest number of edits needed to transform one string into the other one.</p>



<p>There are actually several versions, depending on what you count as an “edit”. For instance, if you only allow replacing a character by another, you get <a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a>; evaluating the Hamming distance between two strings is algorithmically very simple.</p>



<p>Things become more interesting if you allow insertion and deletion of characters as well. This is the <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenstein distance</a>. Considering this title of the present article, this is of course something that can be solved efficiently using ✨&nbsp;dynamic programming&nbsp;✨.</p>



<p>To do that, we’ll need to find how we can derive a full solution from solutions to smaller-problems. Let’s say we have two strings: <code>A</code> and <code>B</code>. We’ll note <code>d(X, Y)</code> the edit distance between strings <code>X</code> and <code>Y</code>, and we’ll note <code>x</code> the length of string <code>X</code>. We need to formulate <code>d(A, B)</code> from any combination of d(X, Y) where <code>X</code> is a substring of <code>A</code> and <code>Y</code> a substring of <code>B</code><sup data-fn="4598dbdf-9a33-4bd6-976e-a06758eb4f07"><a href="#4598dbdf-9a33-4bd6-976e-a06758eb4f07" id="4598dbdf-9a33-4bd6-976e-a06758eb4f07-link">1</a></sup>.</p>



<p>We’re going to look at a single character. We’ll use the last one. The first one would work just as well but using a middle one would not be as convenient. So, let’s look at A[a – 1] and B[b – 1] (using zero-indexing). We have four cases:</p>



<ul>
<li><code>A[a - 1] == B[b - 1]</code>, then we can ignore that character and look at the rest, so <code>d(A, B) = d(A[0..a&nbsp;-&nbsp;1],&nbsp;B[0..b&nbsp;-&nbsp;1])</code></li>



<li><code>A[a - 1] != B[b - 1]</code>, then we could apply any of the three rules.  Since we want the smallest number of edits, we’ll need to select the smallest value given by applying each rule:
<ul>
<li><strong>substitute</strong> the last character of A by that of B, in which case <code>d(A,&nbsp;B) = d(A[0..a&nbsp;-&nbsp;1],&nbsp;B[0..b&nbsp;-&nbsp;1])&nbsp;+&nbsp;1</code></li>



<li><strong>delete</strong> the last character of <code>A</code>, in which case <code>d(A,&nbsp;B) = d(A[0..a&nbsp;-&nbsp;1],&nbsp;B)&nbsp;+&nbsp;1</code></li>



<li><strong>insert</strong> the last character of <code>B</code>, in which case <code>d(A,&nbsp;B) = d(A,&nbsp;B[0..b&nbsp;-&nbsp;1])&nbsp;+&nbsp;1</code></li>
</ul>
</li>



<li>A is actually empty (<code>a = 0</code>), then we need to <strong>insert</strong> all characters from B<sup data-fn="fb0dcaf1-f2c3-4035-aa3e-9d14652cb2fa"><a href="#fb0dcaf1-f2c3-4035-aa3e-9d14652cb2fa" id="fb0dcaf1-f2c3-4035-aa3e-9d14652cb2fa-link">2</a></sup>, so <code>d(A, B) = b</code></li>



<li>B is actually empty (b = 0), then we need to <strong>delete</strong> all characters from A, so <code>d(A, B) = a</code></li>
</ul>



<p>By translating this directly to Python, we get:</p>



<pre><code lang="python">def levenstein(A: str, B: str) -&gt; int:
    a = len(A)
    b = len(B)
    if a == 0:
        return b
    elif b == 0:
        return a
    elif A[a - 1] == B[b - 1]:
        return levenstein(A[:a - 1], B[:b - 1])
    else:
        return min([
            levenstein(A[:a - 1], B[:b - 1]) + 1,
            levenstein(A[:a - 1], B) + 1,
            levenstein(A, B[:b - 1]) + 1,
        ])


assert levenstein("", "puppy") == 5
assert levenstein("kitten", "sitting") == 3
assert levenstein("uninformed", "uniformed") == 1
# way too slow!
# assert levenstein("pneumonoultramicroscopicsilicovolcanoconiosis", "sisoinoconaclovociliscipocsorcimartluonomuenp") == 36</code></pre>



<p>As hinted by the last test, this version becomes very slow when comparing long strings with lots of differences. In Fibonnacci, we were doubling the number of instances for each level in the call tree; here, we are tripling it!</p>



<p>In Python, we can easily apply memoization:</p>



<pre><code lang="python">from functools import cache

@cache
def levenstein(A: str, B: str) -&gt; int:
    a = len(A)
    b = len(B)
    if a == 0:
        return b
    elif b == 0:
        return a
    elif A[a - 1] == B[b - 1]:
        return levenstein(A[:a - 1], B[:b - 1])
    else:
        return min([
            levenstein(A[:a - 1], B[:b - 1]) + 1,
            levenstein(A[:a - 1], B) + 1,
            levenstein(A, B[:b - 1]) + 1,
        ])


assert levenstein("", "puppy") == 5
assert levenstein("kitten", "sitting") == 3
assert levenstein("uninformed", "uniformed") == 1
# instantaneous!
assert levenstein("pneumonoultramicroscopicsilicovolcanoconiosis", "sisoinoconaclovociliscipocsorcimartluonomuenp") == 36</code></pre>



<p>Now, there is something that makes the code nicer, and more performant, but it is not technically necessary. The trick is that we do not actually need to create new strings in our recursive functions. We can just pass arounds the lengths of the substrings, and always refer to the original strings <code>A</code> and <code>B</code>. Then, our code becomes:</p>



<pre><code lang="python">from functools import cache

def levenstein(A: str, B: str) -&gt; int:
    @cache
    def aux(a: int, b: int) -&gt; int:
        if a == 0:
            return b
        elif b == 0:
            return a
        elif A[a - 1] == B[b - 1]:
            return aux(a - 1, b - 1)
        else:
            return min([
                aux(a - 1, b - 1) + 1,
                aux(a - 1, b) + 1,
                aux(a, b - 1) + 1,
            ])
    return aux(len(A), len(B))


assert levenstein("", "puppy") == 5
assert levenstein("kitten", "sitting") == 3
assert levenstein("uninformed", "uniformed") == 1
# instantaneous!
assert levenstein("pneumonoultramicroscopicsilicovolcanoconiosis", "sisoinoconaclovociliscipocsorcimartluonomuenp") == 36</code></pre>



<p>The next step is to build the cache ourselves:</p>



<pre><code lang="python">def levenstein(A: str, B: str) -&gt; int:
    # cache[a][b] = levenstein(A[:a], B[:b])
    # note the + 1 so that we can actually do cache[len(A)][len(B)]
    # the list comprehension ensures we create independent rows, not references to the same one
    cache = [[None] * (len(B) + 1) for _ in range(len(A) + 1)]
    def aux(a: int, b: int) -&gt; int:
        if cache[a][b] == None:
            if a == 0:
                cache[a][b] = b
            elif b == 0:
                cache[a][b] = a
            elif A[a - 1] == B[b - 1]:
                cache[a][b] = aux(a - 1, b - 1)
            else:
                cache[a][b] = min([
                    aux(a - 1, b - 1) + 1,
                    aux(a - 1, b) + 1,
                    aux(a, b - 1) + 1,
                ])
        return cache[a][b]
    return aux(len(A), len(B))


assert levenstein("", "puppy") == 5
assert levenstein("kitten", "sitting") == 3
assert levenstein("uninformed", "uniformed") == 1
# instantaneous!
assert levenstein("pneumonoultramicroscopicsilicovolcanoconiosis", "sisoinoconaclovociliscipocsorcimartluonomuenp") == 36</code></pre>



<p>The last thing we need to do is to replace the recursion with iterations. The important thing is to make sure we do that in the right order<sup data-fn="1d71982a-5567-4481-b278-15d8251bcee6"><a href="#1d71982a-5567-4481-b278-15d8251bcee6" id="1d71982a-5567-4481-b278-15d8251bcee6-link">3</a></sup>:</p>



<pre><code lang="python">def levenstein(A: str, B: str) -&gt; int:
    # cache[a][b] = levenstein(A[:a], B[:b])
    # note the + 1 so that we can actually do cache[len(A)][len(B)]
    # the list comprehension ensures we create independent rows, not references to the same one
    cache = [[None] * (len(B) + 1) for _ in range(len(A) + 1)]
    for a in range(0, len(A) + 1):
        for b in range(0, len(B) + 1):
            if a == 0:
                cache[a][b] = b
            elif b == 0:
                cache[a][b] = a
            elif A[a - 1] == B[b - 1]:
                # since we are at row a, we have already filled in row a - 1
                cache[a][b] = cache[a - 1][b - 1]
            else:
                cache[a][b] = min([
                    # since we are at row a, we have already filled in row a - 1
                    cache[a - 1][b - 1] + 1,
                    # since we are at row a, we have already filled in row a - 1
                    cache[a - 1][b] + 1,
                    # since we are at column b, we have already filled column b - 1
                    cache[a][b - 1] + 1,
                ])
    return cache[len(A)][len(B)]


assert levenstein("", "puppy") == 5
assert levenstein("kitten", "sitting") == 3
assert levenstein("uninformed", "uniformed") == 1
# instantaneous!
assert levenstein("pneumonoultramicroscopicsilicovolcanoconiosis", "sisoinoconaclovociliscipocsorcimartluonomuenp") == 36
</code></pre>



<p>Now, if you really want to grok dynamic programming, I invite you to try it yourself on the following problems, preferrably in this order:</p>



<ol>
<li><a href="https://en.wikipedia.org/wiki/Longest_common_subsequence">longest common subsequence</a> (not to be confused with <a href="https://en.wikipedia.org/wiki/Longest_common_substring">longest common <em>substring</em></a>, but you can do that one too with dynamic programming)</li>



<li><a href="https://en.wikipedia.org/wiki/Line_wrap_and_word_wrap">line warp</a></li>



<li><a href="https://en.wikipedia.org/wiki/Subset_sum_problem">subset sum</a></li>



<li><a href="https://en.wikipedia.org/wiki/Partition_problem">partition</a></li>



<li><a href="https://en.wikipedia.org/wiki/Knapsack_problem">knapsack</a></li>
</ol>



<p>Once you are comfortable with dynamic programming, Day 12 should become much less daunting!</p>



<h2>Advent of Code, Day 12</h2>



<p>In the <a href="https://adventofcode.com/2023/day/12">Advent of Code of December 12th, 2023</a>, you have to solve 1D <a href="https://en.wikipedia.org/wiki/Nonogram">nonograms</a>. Rather than rephrasing the problem, I will let you read the official description.</p>



<pre><code>.??..??...?##. 1,1,3</code></pre>



<p>This can be solved by brute-force. The proper technique for that is <a href="https://en.wikipedia.org/wiki/Backtracking">backtracking</a>, another terrible name. But the asymptotic complexity is exponential (for n question marks, we have to evaluate 2<sup>n</sup> potential solutions). Let’s see how it goes with this example:</p>



<ul>
<li><code>.??..??...?##. 1,1,3</code> the first question mark could be either a <code>.</code> or a <code>#</code>; in the second case, we “consume” the first group of size 1, and the second question mark has to be a <code>.</code>
<ol>
<li><code>..?..??...?##. 1,1,3</code> the next question mark could be either a . or a #; in the second case, we “consume” the first group of size 1, and the next character has to be a ., which is the case
<ol>
<li><code>.....??...?##. 1,1,3</code> the backtracking algorithm will continue to explore the 8 cases, but none of them is a valid solution</li>



<li><code>..#..??...?##. (1),1,3</code>
<ul>
<li>and so on…</li>
</ul>
</li>
</ol>
</li>



<li><code>.#...??...?##. (1),1,3</code>
<ul>
<li>and so on…</li>
</ul>
</li>
</ol>
</li>
</ul>



<p>There are 32 candidates, which would make 63 list items. I’ll spare you that. Instead, I want to draw your attention to the items 2.2 and 2:</p>



<ul>
<li>2.2. <code>..#..??...?##. <code>(1),</code>1,3</code></li>



<li>2. <code>.#...??...?##. <code>(1),</code>1,3</code></li>
</ul>



<p>They are extremely similar. In fact, if we discard the part that has already been accounted for, they are more like:</p>



<ul>
<li>2.2. <code>.??...?##. 1,3</code></li>



<li>2. <code>..??...?##. 1,3</code></li>
</ul>



<p>There is an extra <code>.</code> on the second one, but we can clearly see that it is actually the same problem, and has the same solutions.</p>



<p>In other words, just like with Fibonacci, the total number of cases is huge, but many of them will just be repeats of other ones. So we are going to apply memoization. And then, dynamic programming.</p>



<p>When we implement the “backtracking” algorithm we’ve overviewed above, we get something like this (<a href="https://github.com/Domyy95/Challenges/blob/02e9e5535b7ba027c11bb0e27fe3f2ce5dbd7d38/2023-12-Advent-of-code/12.py#L61-L79">not my code</a>):</p>



<pre><code lang="python">def count_arrangements(conditions, rules):
    if not rules:
        return 0 if "#" in conditions else 1
    if not conditions:
        return 1 if not rules else 0

    result = 0

    if conditions[0] in ".?":
        result += count_arrangements(conditions[1:], rules)
    if conditions[0] in "#?":
        if (
            rules[0] &lt;= len(conditions)
            and "." not in conditions[: rules[0]]
            and (rules[0] == len(conditions) or conditions[rules[0]] != "#")
        ):
            result += count_arrangements(conditions[rules[0] + 1 :], rules[1:])

    return result</code></pre>



<p>Note the program above handles <code>?</code> by treating it as both <code>.</code> and <code>#</code>. The first case is easy, but the second case need to check that it matches the next rules; and for that, it needs to check that there is a separator afterwards, or the end of the string.</p>



<p>Since it’s Python, to memoize, we just need to add <code>@cache</code>.</p>



<p>To make it dynamic programing, we use the same trick as in the example of the edit distance: we pass the offset in the string, and the offset in the rules as parameters in the recursion. This becomes:</p>



<pre><code lang="python">def count_arrangements(conditions, rules):
    @cache
    def aux(i, j):
        if not rules[j:]:
            return 0 if "#" in conditions[i:] else 1
        if not conditions[i:]:
            return 1 if not rules[j:] else 0

        result = 0

        if conditions[i] in ".?":
            result += aux(i + 1, j)
        if conditions[i] in "#?":
            if (
                rules[j] &lt;= len(conditions[i:])
                and "." not in conditions[i:i + rules[j]]
                and (rules[j] == len(conditions[i:]) or conditions[i + rules[j]] != "#")
            ):
                result += aux(i + rules[j] + 1, j + 1)

        return result
    return aux(0, 0)</code></pre>



<p>Then, we implement our own cache and fill it in the right order:</p>



<pre><code lang="python">def count_arrangements(conditions, rules):
    cache = [[0] * (len(rules) + 1) for _ in range(len(conditions) + 1)]
    # note that we are in the indices in reverse order here
    for i in reversed(range(0, len(conditions) + 1)):
        for j in reversed(range(0, len(rules) + 1)):
            if not rules[j:]:
                result = 0 if "#" in conditions[i:] else 1
            elif not conditions[i:]:
                result = 1 if not rules[j:] else 0
            else:
                result = 0
                if conditions[i] in ".?":
                    # since we are at row i, we already filled in row i + 1
                    result += cache[i + 1][j]
                if conditions[i] in "#?":
                    if (
                        rules[j] &lt;= len(conditions[i:])
                        and "." not in conditions[i:i + rules[j]]
                    ):
                        if rules[j] == len(conditions[i:]):
                            # since we are at row i, we already filled in row i + rules[j] &gt; i
                            result += cache[i + rules[j]][j + 1]
                        elif conditions[i + rules[j]] != "#":
                            # since we are at row i, we already filled in row i + rules[j] + 1 &gt; i
                            result += cache[i + rules[j] + 1][j + 1]
            cache[i][j] = result
    return cache[0][0]</code></pre>



<p>And, voilà! You can also have a look at a <a href="https://github.com/qsantos/advent-of-code/blob/master/2023/day12/src/main.rs#L6-L46">Rust implementation (my code, this time)</a>.</p>



<p><strong>Note:</strong> In this case, it looks like the dynamic programming version is slower than the memoized one. But that’s probably due to it being written in unoptimized Python.</p>



<p><strong>Note:</strong> Independently from using a faster language and micro-optimizations, the dynamic programming version allows us to see that we only need the previous column. Thus, we could replace the 2D array by two 1D arrays (one for the previous column, and one for the column being filled).</p>



<h2>Conclusion</h2>



<p>I’ll concede that dynamic programming is not trivial. But it is far from being unreachable for most programmers. Being able to understand how to split a problem in smaller problems will enable you to use memoization in various contexts, which is already a huge improvement above a naive implementation.</p>



<p>However, mastering dynamic programming will let us understand a whole class of algorithms, better understand trade-offs, and make other optimizations possible. So, if you have not already done them, I strongly encourage you to practice on these problems:</p>



<ol>
<li><a href="https://en.wikipedia.org/wiki/Longest_common_subsequence">longest common subsequence</a> (not to be confused with <a href="https://en.wikipedia.org/wiki/Longest_common_substring">longest common <em>substring</em></a>, but you can do that one too with dynamic programming)</li>



<li><a href="https://en.wikipedia.org/wiki/Line_wrap_and_word_wrap">line warp</a></li>



<li><a href="https://en.wikipedia.org/wiki/Subset_sum_problem">subset sum</a></li>



<li><a href="https://en.wikipedia.org/wiki/Partition_problem">partition</a></li>



<li><a href="https://en.wikipedia.org/wiki/Knapsack_problem">knapsack</a></li>
</ol>



<p>And don’t forget to benchmark and profile your code!</p>



<hr>


<ol><li id="4598dbdf-9a33-4bd6-976e-a06758eb4f07">Excluding, of course, <code>d(A, B)</code> itself <a href="#4598dbdf-9a33-4bd6-976e-a06758eb4f07-link" aria-label="Jump to footnote reference 1">↩︎</a></li><li id="fb0dcaf1-f2c3-4035-aa3e-9d14652cb2fa"><code>B</code> could be empty as well, in which case we need to insert 0 characters <a href="#fb0dcaf1-f2c3-4035-aa3e-9d14652cb2fa-link" aria-label="Jump to footnote reference 2">↩︎</a></li><li id="1d71982a-5567-4481-b278-15d8251bcee6">Note that we could permute the inner and outer loops as shown below. In this case, it works just as well:<br><code>for b in range(0, len(B) + 1):</code><br>    <code>for a in range(0, len(A) + 1):</code><br> <a href="#1d71982a-5567-4481-b278-15d8251bcee6-link" aria-label="Jump to footnote reference 3">↩︎</a></li></ol>
		</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICO fines HelloFresh £140k for spam texts and emails (214 pts)]]></title>
            <link>https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/01/ico-fines-hellofresh-140-000-for-spam-texts-and-emails/</link>
            <guid>38988944</guid>
            <pubDate>Sun, 14 Jan 2024 09:40:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/01/ico-fines-hellofresh-140-000-for-spam-texts-and-emails/">https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/01/ico-fines-hellofresh-140-000-for-spam-texts-and-emails/</a>, See on <a href="https://news.ycombinator.com/item?id=38988944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        
    <ul>
<li>Company sent 79 million spam emails and 1 million spam texts in seven months</li>
<li>Customers were not fully aware of what they were opting into, marking a “clear breach of trust”</li>
<li>“We will take clear and decisive action where we find the law has not been followed.” - ICO</li>
</ul>
<p>The Information Commissioner’s Office (ICO) has <a data-udi="umb://document/43b8cac81c294f9aa3ac7c9835b11752" href="https://ico.org.uk/action-weve-taken/enforcement/grocery-delivery-e-services-uk-ltd-ta-hellofresh/" title="Grocery Delivery E-Services UK Ltd t/a HelloFresh" data-anchor="#">fined food delivery company HelloFresh £140,000 for a campaign of 79 million spam emails and 1 million spam texts over a seven-month period</a>.</p>
<p>The marketing messages were sent based on an opt-in statement which did not make any reference to the sending of marketing via text. Whilst there was a reference to marketing via email, this was included in an age confirmation statement which was likely to unfairly incentivise customers to agree.</p>
<p>Customers were also not given sufficient information that their data would continue to be used for marketing purposes for up to 24 months after cancelling their subscriptions.</p>
<p>An investigation by the ICO began in March 2022 following complaints made directly to the regulator, as well as to the 7726 spam message reporting service. As part of this investigation, it was also discovered that the company continued to contact some individuals even after they had requested this to stop.</p>
<p>Following the investigation, we found that the company (Grocery Delivery E-Services UK Limited) contravened regulation 22 of the Privacy and Electronic Communications Regulations 2003 and it has now been served with a fine of £140,000.</p>
<p>Andy Curry, Head of Investigations at the Information Commissioner's Office, said:</p>
<blockquote><span><span></span></span>
<p>“This marked a clear breach of trust of the public by HelloFresh. Customers weren’t told exactly what they’d be opting into, nor was it clear how to opt out. From there, they were hit with a barrage of marketing texts they didn't want or expect, and in some cases, even when they told HelloFresh to stop, the deluge continued.</p>
<p>“In issuing this fine, we are showing that we will take clear and decisive action where we find the law has not been followed. We will always protect the right of customers to choose how their data is used.</p>
<p>“The investigation that led to this fine began following complaints filed by the public, both to the ICO and to the 7726 service. This shows just how important it is that if you are being contacted with nuisance calls, texts or emails, that you report it straight away.”</p>
</blockquote>
<h2>Further details of contraventions</h2>
<ul>
<li>Between 23 August 2021 and 23 February 2022 there were 80,893,013 direct marketing messages comprised of 79,779,279 emails and 1,113,734 SMS messages received by subscribers. The Commissioner found that HelloFresh transmitted those messages contrary to Regulation 22 of PECR.</li>
<li>The consent statement for these messages did not meet the requirement that it be “specific” and “informed”, as it did not mention SMS, was unclear and bundled with other aspects, and did not highlight that customers would receive messages for 24 months after they cancelled their HelloFresh subscription.</li>
<li>This therefore meant that 80,893,013 direct marketing messages were sent by HelloFresh that lacked proper consent.</li>
<li>8,729 complaints were logged with the 7726 service in relation to messages from HelloFresh. Additionally, the ICO received 14 complaints about unauthorised SMS messages from HelloFresh and three complaints about marketing emails.</li>
</ul>
<h2>ICO’s work to tackle nuisance communications</h2>
<p>The ICO enforces the Privacy and Electronic Communications Regulations 2003 (PECR), which cover the rules for organisations wishing to make direct marketing calls, texts or emails.</p>
<p>We have issued more than £2,440,000 million in fines against companies responsible for nuisance calls, texts and emails since April 2023. Some of these investigations began with a single complaint from a member of the public.</p>
<p>For more information about the ICO’s work to tackle nuisance calls, emails and texts visit <a data-udi="umb://document/fe5f20bb70f6448e86dfca76c69c261c" href="https://ico.org.uk/for-the-public/nuisance-calls/" title="Nuisance calls">ico.org.uk/nuisancecalls</a>.</p>
<h2>Advice for the public</h2>
<p>To help you, your friends and relatives stop unlawful marketing calls, texts or emails you can:</p>
<ul>
<li>Register landlines and mobile numbers with the <a rel="noopener" href="https://www.tpsonline.org.uk/" target="_blank" title="Telephone Preference Service">Telephone Preference Service<span></span></a> (TPS) and the <a rel="noopener" href="https://www.tpsonline.org.uk/register/corporate_tps" target="_blank" title="Corporate Telephone Preference Service">Corporate Telephone Preference Service<span></span></a> (CTPS) free of charge. The TPS and CTPS is a register used by legitimate marketing companies to identify people and businesses that have said they don’t want to receive marketing calls. Alternatively, you can tell the company directly that you do not wish to be contacted.</li>
<li>Mobile phone users can report the receipt of unsolicited marketing text messages to the Mobile UK's Spam Reporting Service by forwarding the message to 7726.</li>
<li>Refer concerns that you or someone you know has been the victim of fraud to <a rel="noopener" href="https://www.actionfraud.police.uk/" target="_blank" title="Action Fraud">Action Fraud<span></span></a> (in England, Northern Ireland and Wales) and <a rel="noopener" href="https://www.scotland.police.uk/advice-and-information/scams-and-frauds/" target="_blank" title="Police Scotland">Police Scotland<span></span></a> (in Scotland); wider concerns about a business’ practices can be referred to Trading Standards; any abandoned calls that you receive to <a rel="noopener" href="https://www.ofcom.org.uk/phones-telecoms-and-internet/advice-for-consumers/problems/tackling-nuisance-calls-and-messages/abandoned-and-silent-calls" target="_blank" title="Abandoned and silent calls">Ofcom<span></span></a>.</li>
<li><a data-udi="umb://document/74853109d122412992f3c77e24a232c0" href="https://ico.org.uk/make-a-complaint/nuisance-calls-and-messages/" title="Nuisance calls and messages">Complaints about nuisance calls, texts or emails</a> can be made to the ICO via our website.</li>
</ul>
<details>
    <summary aria-describedby="Details_18a79e96-bc20-449e-bc10-a64bbf4df6b5">
        <span>Notes for editors</span>
    </summary>
    <div>
        <ol>
<li>The Information Commissioner’s Office (ICO) is the UK’s independent regulator for data protection and information rights law, upholding information rights in the public interest, promoting openness by public bodies and data privacy for individuals.</li>
<li>The <a data-udi="umb://document/088cd96f62df4fb6bc35b33832b45cce" href="https://ico.org.uk/about-the-ico/what-we-do/legislation-we-cover/" title="Legislation we cover">ICO has specific responsibilities</a> set out in the Data Protection Act 2018 (DPA2018), the United Kingdom General Data Protection Regulation (UK GDPR), the Freedom of Information Act 2000 (FOIA), Environmental Information Regulations 2004 (EIR), Privacy and Electronic Communications Regulations 2003 (PECR) and a further five acts and regulations. </li>
<li>The ICO can take action to address and change the behaviour of organisations and individuals that collect, use and keep personal information. This includes criminal prosecution, non-criminal enforcement and audit. </li>
<li>To report a concern to the ICO telephone our helpline 0303 123 1113 or go to <a data-udi="umb://document/ab9e48b8fcd3472bb798c3c4cfcb43d3" href="https://ico.org.uk/make-a-complaint/" title="Make a complaint">ico.org.uk/concerns</a>.</li>
</ol>
    </div>
</details>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Modern Development of Cloud Applications (2023) (133 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/3593856.3595909</link>
            <guid>38988238</guid>
            <pubDate>Sun, 14 Jan 2024 07:17:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/3593856.3595909">https://dl.acm.org/doi/10.1145/3593856.3595909</a>, See on <a href="https://news.ycombinator.com/item?id=38988238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2 id="d1711058e1">ABSTRACT</h2></p><p>When writing a distributed application, conventional wisdom says to split your application into separate services that can be rolled out independently. This approach is well-intentioned, but a microservices-based architecture like this often backfires, introducing challenges that counteract the benefits the architecture tries to achieve. Fundamentally, this is because microservices conflate logical boundaries (how code is written) with physical boundaries (how code is deployed). In this paper, we propose a different programming methodology that decouples the two in order to solve these challenges. With our approach, developers write their applications as logical monoliths, offload the decisions of how to distribute and run applications to an automated runtime, and deploy applications atomically. Our prototype implementation reduces application latency by up to 15× and reduces cost by up to 9× compared to the status quo.</p></div><div data-widget-def="UX3TagWidget" data-widget-id="2a75f978-170a-4843-8722-e878a1b77fbc">
        



        
        









    
    
        <p data-widget-def="graphQueryWidget" data-widget-id="4ca2ed65-717e-4e67-bbb5-6578b8c6acac">
        



        
        <h2 id="sec-terms">Index Terms</h2>

        </p>
    


<ol><li><h6>Towards Modern Development of Cloud Applications</h6><ol><li><ol><li><ol><li><ol><li><ol></ol></li><li><ol></ol></li></ol></li></ol></li></ol></li></ol></li></ol>

        </div><div data-exp-type="" data-query-id="10.1145/3593856.3595909"><ul><li><div><a href="https://dl.acm.org/doi/10.1109/CISIS.2012.159" title="Towards a Semantic Engine for Cloud Applications Development"><h5 data-lines="2">Towards a Semantic Engine for Cloud Applications Development</h5></a><p>CISIS '12: Proceedings of the 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)  </p><div><p>In this paper we propose a Semantic Engine for Cloud applications development: a semantically enabled Search Engine that can be used by cloud applications developers as development support. The Semantic Engine will be a component of the EU project ...</p></div></div></li><li></li><li></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Citadel, a Calibre-compatible eBook management app (304 pts)]]></title>
            <link>https://github.com/every-day-things/citadel</link>
            <guid>38988019</guid>
            <pubDate>Sun, 14 Jan 2024 06:22:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/every-day-things/citadel">https://github.com/every-day-things/citadel</a>, See on <a href="https://news.ycombinator.com/item?id=38988019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:every-day-things/citadel" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="M1hb7dYhs1aJECuh8b5ghkUeJOdOtMha9C0J-5DQWAzcUY9TB2Xkhfqe5PUqFJK5byK0N27kuhsOOGNDvBH2YQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="every-day-things/citadel" data-current-org="every-day-things" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=1oaygfi9%2FQAWicQywwmvkud5ytZvKyER%2FIiJrTqAObaUgMkx6jbyZ9glRX09rruWwrFOCiQjSdNkbGgMgbW2yPCPARNU4UekXfEjMTQ2G%2ByCpvSX%2BgjuB8wXsce8PkX9XQS2q6Ihoo9IsAEwrLJwd6urgMNNef089aUyVhb9iv1mdNMR%2BV87X6LjiTHQPScJM%2FSgXRNT%2B687z2gsotnkjcaHwIF0b7B%2BXiFpBiY6x9A7NDo4aoqd4l20Tklk5PgilFbSlIfv0A%2BPY9V9gSwXqaXyw2xpkFo%2Fq1M9hHvbaOEUrLwi8Wz7UxBlpQIviHTbyL3ZvehiDT5twNWja0W5qc8IJKSVFKY%2BVA0%2FCZpr%2FBiikGMyTYAz1BXgbHuh9iO6%2B2M3mPdvpY7i3UbeW7vcmNdfCA23ZOx68K1bqvM1ip0wWpdkHaxftRWy8JJEf6cpQ%2F5JIgYvMEIkdURDQnN3L7tO%2FFC39A7AL6GuOqJFrB5xvOYm%2BmovUBpu7jDN7G82198icCqnAuFlhnEB0xdOflliRHx82Q%3D%3D--3N85ydkC1VhBm6Xm--M7LKIkTonizDxLJjniqKqg%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=every-day-things%2Fcitadel" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/every-day-things/citadel&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="622ffc1ec13699e465ff2bf231efc2b0e4b032d54b861950d4cac74106514c47" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Posthog is closing their Slack community in favor of forum (327 pts)]]></title>
            <link>https://posthog.com/blog/slack-closure</link>
            <guid>38987383</guid>
            <pubDate>Sun, 14 Jan 2024 04:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://posthog.com/blog/slack-closure">https://posthog.com/blog/slack-closure</a>, See on <a href="https://news.ycombinator.com/item?id=38987383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav><ul><li><a rel="noopener noreferrer" href="https://posthog.com/posts" target="">Posts</a></li><li><a href="https://posthog.com/blog">Blog</a></li></ul></nav><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/b3adc16e8f9c62187dd8d0acae678259/c7da1/posthog-company-culture-blog.webp 300w,/static/b3adc16e8f9c62187dd8d0acae678259/22c65/posthog-company-culture-blog.webp 600w,/static/b3adc16e8f9c62187dd8d0acae678259/81547/posthog-company-culture-blog.webp 1200w" sizes="(min-width: 1200px) 1200px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 1200px) 1200px, 100vw" decoding="async" loading="lazy" data-src="/static/b3adc16e8f9c62187dd8d0acae678259/b5380/posthog-company-culture-blog.png" data-srcset="/static/b3adc16e8f9c62187dd8d0acae678259/a0e1b/posthog-company-culture-blog.png 300w,/static/b3adc16e8f9c62187dd8d0acae678259/86184/posthog-company-culture-blog.png 600w,/static/b3adc16e8f9c62187dd8d0acae678259/b5380/posthog-company-culture-blog.png 1200w" alt="" src="https://posthog.com/static/b3adc16e8f9c62187dd8d0acae678259/b5380/posthog-company-culture-blog.png" srcset="https://posthog.com/static/b3adc16e8f9c62187dd8d0acae678259/a0e1b/posthog-company-culture-blog.png 300w,https://posthog.com/static/b3adc16e8f9c62187dd8d0acae678259/86184/posthog-company-culture-blog.png 600w,https://posthog.com/static/b3adc16e8f9c62187dd8d0acae678259/b5380/posthog-company-culture-blog.png 1200w"></picture></div><p>One of the great things about being open source is that we’ve grown a vibrant community around the project. Since launch we’ve accepted code from over 500 contributors and swapped ideas with thousands of users in our public Slack group. </p><p>Now, though, we’re closing that Slack group in favor of creating a better, more scalable, and helpful PostHog community <a href="https://posthog.com/questions">here on our site</a>. In this post, I’ll explain why we’re doing this, and what comes next. </p><blockquote><p><strong>TL;DR:</strong> We’re closing the Slack group on Jan 24 2024 and inviting members to join the 1,500 users who have already moved to the <a href="https://posthog.com/questions">new community forum</a>. As thanks you'll receive a unique community achievement when you create an account. This decision only impacts the public Slack group, not private Slack channels for users who pay for additional support.</p></blockquote><p>PostHog has grown incredibly fast over the last four years, and throughout that time the public Slack group has been the central hub of our community. It's been a place where we chat to users, listen to feature requests, answer questions, and solicit feedback. </p><p>However, with over 5,000 members in the community, it's become clear we've outgrown Slack as a platform. Messages quickly disappear from the chat history, it is disconnected from our main support flow, and useful solutions aren't searchable on our site or via Google. </p><p>We've explored a few things to fix this, including joining a paid plan ($7.25+ per user, per month) and <a href="https://posthog.com/blog/aruba-hackathon#maxai-our-friendly-posthog-support-ai">building our own AI bot</a>, but earlier this year we realized a new approach was needed.</p><p>So, we decided to build something better. </p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/blqgFrIaWY0?si=gSj1eNrGQ8l0ANlw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Rather than using an off-the-shelf forum platform, like vBulletin or phpBB, we decided to create our own forum using Strapi as a headless CMS. The forum has already been live for several months while we worked out the kinks, and has over 1,500 active members. </p><p>The new forum provides a dedicated area where you can post questions for both the PostHog team and the wider community. Anyone can respond, and answers can be selected as the preferred solution to help guide other users in the future. All of this content is connected to our main support flow, lives permanently on our website, and is visible to search engines, which is enough on its own to make the forums a better place for seeking community support.</p><p>We've also integrated the forum into other parts of the site. You can, for example, post questions when browsing the PostHog docs, and we'll automatically aggregate them into sortable categories. This is especially helpful if you're following a guide and something isn't clear enough for you - just pop a question on it and we'll take a look.</p><p>Profiles are also a big part of the forum; a place where you can add info, track discussions you're involved in, and display achievements earned through the community. In fact, we're giving everyone who joins the PostHog community from the public Slack a unique achievement to say thanks for the support!</p><p>You can even open your profile to function as an Ask Me Anything (AMA) - something <a rel="noopener noreferrer" href="https://posthog.com/community/profiles/71" target="">James</a>, <a rel="noopener noreferrer" href="https://posthog.com/community/profiles/2" target="">Cory</a>, and <a rel="noopener noreferrer" href="https://posthog.com/community/profiles/59" target="">myself</a> have already done.</p><blockquote><p><strong>Ready to join the community?</strong> <a href="https://posthog.com/questions">Create an account today</a> and, if you've previously signed up to the public Slack group, you'll get a unique achievement to display on your community profile!</p></blockquote><h2 id="what-happens-next"><span></span>What happens next?</h2><p>One option for the public Slack would have been to just leaving it running in parallel to the forums, but that would leave Slack users in limbo. Instead, we'll close the Slack in favor of the PostHog community forum. Currently you need to create an account to sign-up to the community, but soon we'll merge this with your normal PostHog account. </p><p>On January 12, we'll archive all channels in the public PostHog Slack, so that no new discussion or replies can be posted. This will give you chance to move on-going conversations to a new location, such as the PostHog community, without losing anything. </p><p>A week later, on January 22, we'll close the Slack group permanently and delete all existing content. </p><p><strong>Important:</strong> Private Slack channels for paying users will continue to function as normal via Slack Connect, and we’ll continue to handle the majority of customer support via the in-app help. Obviously, the <a rel="noopener noreferrer" href="https://github.com/PostHog/" target="">GitHub repos</a> will also continue to function as normal and you can add comments or submit there too.  </p><p>Thank you to everyone who participated in the Slack group over the last four years. Your support and feedback has helped us immensely, and we’ve deeply enjoyed speaking with you. We very much hope that all of you will <a href="https://posthog.com/questions">join us in the new community soon</a>!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: #!/usr/bin/env docker run (443 pts)]]></title>
            <link>https://gist.github.com/adtac/595b5823ef73b329167b815757bbce9f</link>
            <guid>38987109</guid>
            <pubDate>Sun, 14 Jan 2024 03:20:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/adtac/595b5823ef73b329167b815757bbce9f">https://gist.github.com/adtac/595b5823ef73b329167b815757bbce9f</a>, See on <a href="https://news.ycombinator.com/item?id=38987109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Dockerfile" data-tagsearch-path="Dockerfile">
        <tbody><tr>
          <td id="file-dockerfile-L1" data-line-number="1"></td>
          <td id="file-dockerfile-LC1"><span><span>#</span>!/usr/bin/env -S bash -c "docker run -p 8080:8080 -it --rm \$(docker build --progress plain -f \$0 . 2&gt;&amp;1 | tee /dev/stderr | grep -oP 'sha256:[0-9a-f]*')"</span></td>
        </tr>
        <tr>
          <td id="file-dockerfile-L2" data-line-number="2"></td>
          <td id="file-dockerfile-LC2">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L3" data-line-number="3"></td>
          <td id="file-dockerfile-LC3"><span><span>#</span> syntax = docker/dockerfile:1.4.0</span></td>
        </tr>
        <tr>
          <td id="file-dockerfile-L4" data-line-number="4"></td>
          <td id="file-dockerfile-LC4">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L5" data-line-number="5"></td>
          <td id="file-dockerfile-LC5"><span>FROM</span> node:20</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L6" data-line-number="6"></td>
          <td id="file-dockerfile-LC6">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L7" data-line-number="7"></td>
          <td id="file-dockerfile-LC7"><span>WORKDIR</span> /root</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L8" data-line-number="8"></td>
          <td id="file-dockerfile-LC8">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L9" data-line-number="9"></td>
          <td id="file-dockerfile-LC9"><span>RUN</span> npm install sqlite3</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L10" data-line-number="10"></td>
          <td id="file-dockerfile-LC10">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L11" data-line-number="11"></td>
          <td id="file-dockerfile-LC11"><span>RUN</span> &lt;&lt;EOF cat &gt;/root/schema.sql</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L12" data-line-number="12"></td>
          <td id="file-dockerfile-LC12">  CREATE TABLE IF NOT EXISTS clicks (</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L13" data-line-number="13"></td>
          <td id="file-dockerfile-LC13">    id   INTEGER PRIMARY KEY AUTOINCREMENT,</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L14" data-line-number="14"></td>
          <td id="file-dockerfile-LC14">    time INTEGER NOT NULL</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L15" data-line-number="15"></td>
          <td id="file-dockerfile-LC15">  );</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L16" data-line-number="16"></td>
          <td id="file-dockerfile-LC16">EOF</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L17" data-line-number="17"></td>
          <td id="file-dockerfile-LC17">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L18" data-line-number="18"></td>
          <td id="file-dockerfile-LC18"><span>RUN</span> &lt;&lt;EOF cat &gt;/root/server.js</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L19" data-line-number="19"></td>
          <td id="file-dockerfile-LC19">  const fs = require(<span>"fs"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L20" data-line-number="20"></td>
          <td id="file-dockerfile-LC20">  const http = require(<span>"http"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L21" data-line-number="21"></td>
          <td id="file-dockerfile-LC21">  const sqlite3 = require(<span>"sqlite3"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L22" data-line-number="22"></td>
          <td id="file-dockerfile-LC22">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L23" data-line-number="23"></td>
          <td id="file-dockerfile-LC23">  const db = new sqlite3.Database(<span>":memory:"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L24" data-line-number="24"></td>
          <td id="file-dockerfile-LC24">  db.run(fs.readFileSync(<span>"/root/schema.sql"</span>, <span>"utf8"</span>));</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L25" data-line-number="25"></td>
          <td id="file-dockerfile-LC25">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L26" data-line-number="26"></td>
          <td id="file-dockerfile-LC26">  const html = fs.readFileSync(<span>"/root/index.html"</span>, <span>"utf8"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L27" data-line-number="27"></td>
          <td id="file-dockerfile-LC27">  const server = http.createServer((req, res) =&gt; {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L28" data-line-number="28"></td>
          <td id="file-dockerfile-LC28">    db.run(<span>"INSERT INTO clicks(time) VALUES(unixepoch())"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L29" data-line-number="29"></td>
          <td id="file-dockerfile-LC29">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L30" data-line-number="30"></td>
          <td id="file-dockerfile-LC30">    const data = [];</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L31" data-line-number="31"></td>
          <td id="file-dockerfile-LC31">    db.each(</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L32" data-line-number="32"></td>
          <td id="file-dockerfile-LC32">      <span>"SELECT time as t, COUNT(*) as n FROM clicks WHERE t &gt; unixepoch()-4*60*60 GROUP BY t-t%60"</span>,</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L33" data-line-number="33"></td>
          <td id="file-dockerfile-LC33">      (_, { t, n }) =&gt; data.push([Math.floor(t/60), n]),</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L34" data-line-number="34"></td>
          <td id="file-dockerfile-LC34">      () =&gt; {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L35" data-line-number="35"></td>
          <td id="file-dockerfile-LC35">        res.writeHead(200, { <span>"content-type"</span>: <span>"text/html"</span> });</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L36" data-line-number="36"></td>
          <td id="file-dockerfile-LC36">        res.end(html.replace(<span>"__DATA__"</span>, JSON.stringify(data)));</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L37" data-line-number="37"></td>
          <td id="file-dockerfile-LC37">      },</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L38" data-line-number="38"></td>
          <td id="file-dockerfile-LC38">    );</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L39" data-line-number="39"></td>
          <td id="file-dockerfile-LC39">  });</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L40" data-line-number="40"></td>
          <td id="file-dockerfile-LC40">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L41" data-line-number="41"></td>
          <td id="file-dockerfile-LC41">  server.listen(8080, <span>""</span>, () =&gt; console.log(<span>"serving :8080..."</span>));</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L42" data-line-number="42"></td>
          <td id="file-dockerfile-LC42">EOF</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L43" data-line-number="43"></td>
          <td id="file-dockerfile-LC43">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L44" data-line-number="44"></td>
          <td id="file-dockerfile-LC44"><span>RUN</span> &lt;&lt;EOF cat &gt;/root/index.html</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L45" data-line-number="45"></td>
          <td id="file-dockerfile-LC45">&lt;!DOCTYPE html&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L46" data-line-number="46"></td>
          <td id="file-dockerfile-LC46">&lt;html&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L47" data-line-number="47"></td>
          <td id="file-dockerfile-LC47">  &lt;head&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L48" data-line-number="48"></td>
          <td id="file-dockerfile-LC48">    &lt;meta charset=<span>"utf-8"</span> /&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L49" data-line-number="49"></td>
          <td id="file-dockerfile-LC49">    &lt;meta name=<span>"viewport"</span> content=<span>"width=device-width, initial-scale=1.0"</span>&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L50" data-line-number="50"></td>
          <td id="file-dockerfile-LC50">    &lt;title&gt;#!/usr/bin/env docker run&lt;/title&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L51" data-line-number="51"></td>
          <td id="file-dockerfile-LC51">  &lt;/head&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L52" data-line-number="52"></td>
          <td id="file-dockerfile-LC52">  &lt;body style=<span>"font-family: monospace; font-size; 12px; "</span>&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L53" data-line-number="53"></td>
          <td id="file-dockerfile-LC53">    &lt;div style=<span>"position: absolute; top: 0; left: 0; width: 100vw; height: 100vh; background-size: 5vh 5vh; background-image: linear-gradient(to right, #f0f0f0 1px, transparent 1px), linear-gradient(to bottom, #f0f0f0 1px, transparent 1px); "</span>&gt;&lt;/div&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L54" data-line-number="54"></td>
          <td id="file-dockerfile-LC54">    &lt;span style=<span>"position: absolute; top: 1vh; left: 5vh;"</span>&gt;Page loads over time (last 4 hours)&lt;/span&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L55" data-line-number="55"></td>
          <td id="file-dockerfile-LC55">    &lt;span id=<span>"max"</span> style=<span>"position: absolute; top: 5vh; left: 1vh;"</span>&gt;&lt;/span&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L56" data-line-number="56"></td>
          <td id="file-dockerfile-LC56">    &lt;span id=<span>"min"</span> style=<span>"position: absolute; top: 95vh; left: 1vh;"</span>&gt;0&lt;/span&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L57" data-line-number="57"></td>
          <td id="file-dockerfile-LC57">    &lt;canvas id=<span>"canvas"</span> style=<span>"position: absolute; top: 5vh; left: 5vw; "</span>&gt;&lt;/canvas&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L58" data-line-number="58"></td>
          <td id="file-dockerfile-LC58">    &lt;script&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L59" data-line-number="59"></td>
          <td id="file-dockerfile-LC59">      (() =&gt; {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L60" data-line-number="60"></td>
          <td id="file-dockerfile-LC60">        const el = document.getElementById(<span>"canvas"</span>), ctx = el.getContext(<span>"2d"</span>);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L61" data-line-number="61"></td>
          <td id="file-dockerfile-LC61">        el.width = 0.9 * window.innerWidth * window.devicePixelRatio;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L62" data-line-number="62"></td>
          <td id="file-dockerfile-LC62">        el.height = 0.9 * window.innerHeight * window.devicePixelRatio;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L63" data-line-number="63"></td>
          <td id="file-dockerfile-LC63">        ctx.scale(window.devicePixelRatio, window.devicePixelRatio);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L64" data-line-number="64"></td>
          <td id="file-dockerfile-LC64">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L65" data-line-number="65"></td>
          <td id="file-dockerfile-LC65">        const data = __DATA__;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L66" data-line-number="66"></td>
          <td id="file-dockerfile-LC66">        const max = data.reduce((prev, [_, n]) =&gt; (n &gt; prev ? n : prev), 0);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L67" data-line-number="67"></td>
          <td id="file-dockerfile-LC67">        document.getElementById(<span>"max"</span>).innerText = max;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L68" data-line-number="68"></td>
          <td id="file-dockerfile-LC68">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L69" data-line-number="69"></td>
          <td id="file-dockerfile-LC69">        ctx.beginPath();</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L70" data-line-number="70"></td>
          <td id="file-dockerfile-LC70">        ctx.moveTo(0, el.height);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L71" data-line-number="71"></td>
          <td id="file-dockerfile-LC71">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L72" data-line-number="72"></td>
          <td id="file-dockerfile-LC72">        const draw = (t, n) =&gt; {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L73" data-line-number="73"></td>
          <td id="file-dockerfile-LC73">          const [x, y] = [el.width * (t-data[0][0])/240, el.height * (1 - n/max)];</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L74" data-line-number="74"></td>
          <td id="file-dockerfile-LC74">          ctx.lineTo(x, y);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L75" data-line-number="75"></td>
          <td id="file-dockerfile-LC75">          ctx.moveTo(x, y);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L76" data-line-number="76"></td>
          <td id="file-dockerfile-LC76">        }</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L77" data-line-number="77"></td>
          <td id="file-dockerfile-LC77">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L78" data-line-number="78"></td>
          <td id="file-dockerfile-LC78">        let last = -1;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L79" data-line-number="79"></td>
          <td id="file-dockerfile-LC79">        for (const [t, n] of data) {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L80" data-line-number="80"></td>
          <td id="file-dockerfile-LC80">          if (last != -1 &amp;&amp; t &gt; last + 1) {</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L81" data-line-number="81"></td>
          <td id="file-dockerfile-LC81">            draw(last + 0.1, 0);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L82" data-line-number="82"></td>
          <td id="file-dockerfile-LC82">            draw(t - 0.1, 0);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L83" data-line-number="83"></td>
          <td id="file-dockerfile-LC83">          }</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L84" data-line-number="84"></td>
          <td id="file-dockerfile-LC84">          draw(t, n);</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L85" data-line-number="85"></td>
          <td id="file-dockerfile-LC85">          last = t;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L86" data-line-number="86"></td>
          <td id="file-dockerfile-LC86">        }</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L87" data-line-number="87"></td>
          <td id="file-dockerfile-LC87">        ctx.stroke();</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L88" data-line-number="88"></td>
          <td id="file-dockerfile-LC88">      })();</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L89" data-line-number="89"></td>
          <td id="file-dockerfile-LC89">    &lt;/script&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L90" data-line-number="90"></td>
          <td id="file-dockerfile-LC90">  &lt;/body&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L91" data-line-number="91"></td>
          <td id="file-dockerfile-LC91">&lt;/html&gt;</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L92" data-line-number="92"></td>
          <td id="file-dockerfile-LC92">EOF</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L93" data-line-number="93"></td>
          <td id="file-dockerfile-LC93">
</td>
        </tr>
        <tr>
          <td id="file-dockerfile-L94" data-line-number="94"></td>
          <td id="file-dockerfile-LC94"><span>CMD</span> node /root/server.js</td>
        </tr>
  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[He spent his life building a $1M stereo (115 pts)]]></title>
            <link>https://www.washingtonpost.com/style/interactive/2024/ken-fritz-greatest-stereo-auction-cost</link>
            <guid>38987096</guid>
            <pubDate>Sun, 14 Jan 2024 03:17:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/style/interactive/2024/ken-fritz-greatest-stereo-auction-cost">https://www.washingtonpost.com/style/interactive/2024/ken-fritz-greatest-stereo-auction-cost</a>, See on <a href="https://news.ycombinator.com/item?id=38987096">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/style/interactive/2024/ken-fritz-greatest-stereo-auction-cost: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Inside Boeing’s manufacturing mess (154 pts)]]></title>
            <link>https://www.wsj.com/business/airlines/boeing-manufacturing-737-max-alaska-door-plug-spirit-18f7e233</link>
            <guid>38986899</guid>
            <pubDate>Sun, 14 Jan 2024 02:40:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/airlines/boeing-manufacturing-737-max-alaska-door-plug-spirit-18f7e233">https://www.wsj.com/business/airlines/boeing-manufacturing-737-max-alaska-door-plug-spirit-18f7e233</a>, See on <a href="https://news.ycombinator.com/item?id=38986899">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><div><p><time datetime="2024-01-13T05:01:00Z">Jan. 13, 2024 12:01 am ET</time></p></div><section><p data-type="paragraph">Long before the harrowing Alaska Airlines blowout on Jan. 5, there were concerns within <!-- -->Boeing<!-- --> about the way the aerospace giant was building its planes. Boeing, like so many other American manufacturers, was outsourcing more and more of the components that went into its complex machines.</p><p data-type="paragraph">A Boeing aerospace engineer presented a controversial <a data-type="link" href="https://www.documentcloud.org/documents/69746-hart-smith-on-outsourcing" rel="" target="_blank">white paper in 2001</a> at an internal technical symposium. The engineer, John Hart-Smith, warned colleagues of the risks of the subcontracting strategy, especially if Boeing outsourced too much work and didn’t provide sufficient on-site quality and technical support to its suppliers.&nbsp;</p></section><p>Copyright ©<!-- -->2024<!-- --> Dow Jones &amp; Company, Inc. All Rights Reserved. 87990cbe856818d5eddac44c7b1cdeb8</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nitter.net Has Disappeared (198 pts)]]></title>
            <link>https://github.com/zedeus/nitter/issues/1150</link>
            <guid>38986880</guid>
            <pubDate>Sun, 14 Jan 2024 02:36:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zedeus/nitter/issues/1150">https://github.com/zedeus/nitter/issues/1150</a>, See on <a href="https://news.ycombinator.com/item?id=38986880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="" data-quote-markdown=".js-comment-body" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-team-hovercards-enabled="">
      <div data-gid="I_kwDOC3_cDc58AmVK" data-url="/zedeus/nitter/issues/1150/partials/body?issue=1150" data-channel="eyJjIjoiaXNzdWU6MjA4MDUzMTc4NiIsInQiOjE3MDUyMTIwMDV9--2d7c159b4084244e70e67c811b01a12fe60f329a666d840d974bbb763794498b">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/thutt/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/thutt"><img src="https://avatars.githubusercontent.com/u/2482763?s=80&amp;v=4" width="40" height="40" alt="@thutt"></a>

</p>

  <div data-body-version="6e135367bfc379d1a8affdc2a75193dfb4a4c1af7ed73faa0b05bf5b97f66735" id="issue-2080531786">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">This isn't an issue with nitter software, but I'm getting the following:</p>
<p dir="auto">Hmm. We’re having trouble finding that site.<br>
We can’t connect to the server at nitter.net.</p>
<p dir="auto">When attempting to navigate to Twitter's user pages via nitter.net.</p>
<p dir="auto">Comparatively, has the DNS registration disappeared?  (The registration is valid until 2024.08.06, according to a whois lookup)</p>
<p dir="auto">nslookup twitter.com</p>
<p dir="auto">Non-authoritative answer:<br>
Name:   twitter.com<br>
Address: 104.244.42.65<br>
Name:   twitter.com<br>
Address: 104.244.42.1<br>
Name:   twitter.com<br>
Address: 104.244.42.129<br>
Name:   twitter.com<br>
Address: 104.244.42.193</p>
<p dir="auto">nslookup nitter.net</p>
<p dir="auto">Non-authoritative answer:<br>
*** Can't find nitter.net: No answer</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div>
    


      <div data-gid="IC_kwDOC3_cDc5ws4Oj" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws4Oj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zedeus/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zedeus"><img src="https://avatars.githubusercontent.com/u/9434921?s=80&amp;u=70b0757a69d84b0f31f0d50e2100cc5a505ca12c&amp;v=4" width="40" height="40" alt="@zedeus"></a>

</p>


  <div data-body-version="51ff37efaff36a99faed9e4aab1bb5ad64d42fef6fef35c2044c5a4a03b29b9b" id="issuecomment-1890812835">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">nitter.net is unavailable because Njalla (domain vendor) suspended my account. I'm waiting for them to respond.</p>
      </div>
</task-lists>


        
      </div>

</div>


      

      <div data-gid="IC_kwDOC3_cDc5ws4QX" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws4QX/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/awsms/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/awsms"><img src="https://avatars.githubusercontent.com/u/48278661?s=80&amp;v=4" width="40" height="40" alt="@awsms"></a>

</p>


  <div data-body-version="6e31d7103ba356bdb2fa75d9246334afda7a6b449d5bd35fdba9a4eb5e64f517" id="issuecomment-1890812951">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">nitter.net is unavailable because Njalla (domain vendor) suspended my account. I'm waiting for them to respond.</p>
</blockquote>
<p dir="auto">Thx for the quick answer, I was a bit worried as the website hasn't been available for the whole day</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws4c-" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws4c-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/gigirassy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/gigirassy"><img src="https://avatars.githubusercontent.com/u/145225213?s=80&amp;u=140c08ffac0468837efcf510b625a9649375a3e8&amp;v=4" width="40" height="40" alt="@gigirassy"></a>

</p>


  

</div>


      <div data-gid="IC_kwDOC3_cDc5ws4mG" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws4mG/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/stopmotio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stopmotio"><img src="https://avatars.githubusercontent.com/u/21047900?s=80&amp;u=7a138277df1b35d57b9a9e1fd067fc45c8b4f6b4&amp;v=4" width="40" height="40" alt="@stopmotio"></a>

</p>


  <div data-body-version="abd12ec70c4df9a12bb2424902d0de2323ddef3f0d9cb3275a56fb8fc00e3cbf" id="issuecomment-1890814342">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Any idea as to why they may have done that?</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws7Ru" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws7Ru/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc"><img src="https://avatars.githubusercontent.com/u/14036792?s=80&amp;v=4" width="40" height="40" alt="@lukefromdc"></a>

</p>


  <div data-body-version="27ca488d57fde1e5727279f5610fd5ae62e90c0575947546941e1c0b75ba139d" id="issuecomment-1890825326">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">We need to know if Twitter is whining to domain vendors about Nitter instances.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws7Yh" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws7Yh/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/retry-the-user/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/retry-the-user"><img src="https://avatars.githubusercontent.com/u/496035?s=80&amp;v=4" width="40" height="40" alt="@retry-the-user"></a>

</p>


  <div data-body-version="cbbfb085861f520f566963ace5e1246fce42def85e8530eb3c6cfe5b2344ab48" id="issuecomment-1890825761">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">in the meantime add 185.246.188.57 nitter.net to your hosts file and you can still use it</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws7dP" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws7dP/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc"><img src="https://avatars.githubusercontent.com/u/14036792?s=80&amp;v=4" width="40" height="40" alt="@lukefromdc"></a>

</p>


  <div data-body-version="5a007a2e1d92db3487638eccb31c404f05009e4d2d830483747541dc4f0624ce" id="issuecomment-1890826063">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">That gets a login request on an otherwise blank/white page</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws7pj" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws7pj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jrfondren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jrfondren"><img src="https://avatars.githubusercontent.com/u/41455523?s=80&amp;u=28f4f66d4ff5acfd77bfd344368694f93fa4881a&amp;v=4" width="40" height="40" alt="@jrfondren"></a>

</p>


  <div data-body-version="0684d8a225e2f721e803e06ddd30a48d47b2417ba54c43a799f4f2ffad47707d" id="issuecomment-1890826851">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">That IP works. You can't, however, go to https://$ip/ as that'll cause your browser to send the IP in the Host: header, which means the server won't dispatch the request to nitter.net. You need to do something like add it to your hosts file.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws7sg" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws7sg/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/retry-the-user/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/retry-the-user"><img src="https://avatars.githubusercontent.com/u/496035?s=80&amp;v=4" width="40" height="40" alt="@retry-the-user"></a>

</p>


  <div data-body-version="4784a4a0a1756eaabfdb0bbd16ccec69053cf5d9a8a17513bddb823268feb846" id="issuecomment-1890827040">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Do you people not read? "in the meantime <strong>add 185.246.188.57 nitter.net to your hosts file and you can still use it</strong>"</p>
<p dir="auto">add<br>
to your hosts file</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws716" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws716/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jrfondren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jrfondren"><img src="https://avatars.githubusercontent.com/u/41455523?s=80&amp;u=28f4f66d4ff5acfd77bfd344368694f93fa4881a&amp;v=4" width="40" height="40" alt="@jrfondren"></a>

</p>


  <div data-body-version="a500b1bc5a36793f909b5fb56fd5a84231f8989a55197336bb0fc970c7e43b19" id="issuecomment-1890827642">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Someone without a relatively thorough understanding of webhosting will go to https://$ip/, get an error, and then conclude that the IP is wrong. Since the IP is wrong, why go to the effort of modifying a hosts file to something wrong?</p>
<p dir="auto">Anything related to name resolution you'll just have to explain three times.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws8sS" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws8sS/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/stopmotio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stopmotio"><img src="https://avatars.githubusercontent.com/u/21047900?s=80&amp;u=7a138277df1b35d57b9a9e1fd067fc45c8b4f6b4&amp;v=4" width="40" height="40" alt="@stopmotio"></a>

</p>


  <div data-body-version="60b84200560eb4c03550f5c2c613d4608060bb462338d69b1530d937210b407b" id="issuecomment-1890831122">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">I was about to try the raw IP itself lol</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws89d" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws89d/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc"><img src="https://avatars.githubusercontent.com/u/14036792?s=80&amp;v=4" width="40" height="40" alt="@lukefromdc"></a>

</p>


  <div data-body-version="c06ec5d5dc33a993ecd4eaa380efa68697f1c8fdd0fab441ce4db93a8df158ee" id="issuecomment-1890832221">

        <task-lists disabled="" sortable="">
<div>
          <p>When using DNS over HTTPS in Firefox, /etc/hosts is ignored by the browser. I consider this
a nuisance side effect of forcing any ISP surveillance to use raw IP addresses and look them
up themselves (which automated snooping may not bother with) as it makes blocking things
like Facebook, Google, and their embedded content more difficult.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws9NJ" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws9NJ/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc"><img src="https://avatars.githubusercontent.com/u/14036792?s=80&amp;v=4" width="40" height="40" alt="@lukefromdc"></a>

</p>


  <div data-body-version="8937a17568288b99ab8317f0fd86e95b1b5faca55dbb8dd488c259faaa6cef27" id="issuecomment-1890833225">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">How do I stop Firefox from redirecting 185.246.188.57 to <a href="https://185.246.188.57/" rel="nofollow">https://185.246.188.57</a> with DNS over https engaged? Also I finally got Firefox to at least show just the IP address in the address bar but got error 401 "authorization required."</p>
<p dir="auto">Webhosting I know little about, BTW. EDIT: same with browsers, mostly I know how to block things like trackers and ad networks, and not to use Chrome for anything,.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws92w" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws92w/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jrfondren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jrfondren"><img src="https://avatars.githubusercontent.com/u/41455523?s=80&amp;u=28f4f66d4ff5acfd77bfd344368694f93fa4881a&amp;v=4" width="40" height="40" alt="@jrfondren"></a>

</p>


  <div data-body-version="a95f2164ad67f263475ff0a60a96bcccc9b52ed22f606c8fd1446d848ef9f197" id="issuecomment-1890835888">

        <task-lists disabled="" sortable="">
<div>
          <ol dir="auto">
<li>use another nitter instance that's still up</li>
<li>use another browser that the hosts file works for (Brave is one)</li>
<li>use your own DNS server and change your router or your computer to use it. A DNS server is a likely component of anti-adware solutions that work outside the browser, like a pihole.</li>
<li>use a public/alternate DNS service that supports edits (I don't know of any)</li>
<li>clone nitter, add in a new feature to have it proxy requests to an existing nitter server, plug the IP into that, and then make a pull request to add this as a normal feature. This way people can hit localhost without having to duplicate the elaborate auth system that's required now</li>
<li>run nitter locally with your own twitter creds</li>
</ol>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws-UX" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws-UX/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/stopmotio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stopmotio"><img src="https://avatars.githubusercontent.com/u/21047900?s=80&amp;u=7a138277df1b35d57b9a9e1fd067fc45c8b4f6b4&amp;v=4" width="40" height="40" alt="@stopmotio"></a>

</p>


  <div data-body-version="e52e5f93027751d208740097d17a007c9968b657b0805b5461b57b94e6e88cd2" id="issuecomment-1890837783">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Just disable DNS over HTTPS and give it another go</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5ws-Uk" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5ws-Uk/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jarrodmoldrich/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jarrodmoldrich"><img src="https://avatars.githubusercontent.com/u/920769?s=80&amp;v=4" width="40" height="40" alt="@jarrodmoldrich"></a>

</p>


  <div data-body-version="8e6e5f25ad990ad83b961b984f150aa04b595d541c9bf85d8cf42a3a329dca7e" id="issuecomment-1890837796">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc">@lukefromdc</a> In Firefox, I believe you can set <code>network.trr.exclude-etc-hosts</code> to <code>true</code> in <code>about:config</code>.  You may have to add the relevant domains to <code>network.trr.excluded-domains</code> also, but I didn't need to.</p>
      </div>
</task-lists>


        
      </div>

</div>


      

      <div data-gid="IC_kwDOC3_cDc5wtAma" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5wtAma/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/abhranil26/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/abhranil26"><img src="https://avatars.githubusercontent.com/u/30792751?s=80&amp;v=4" width="40" height="40" alt="@abhranil26"></a>

</p>


  <div data-body-version="ae30175ed95e1396e3b03f1ed07eabacb2eac2d5bb6f0bfb44d8c311cf2e6b7e" id="issuecomment-1890847130">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Yeah added to hosts file on macos, and seems to be working with Chrome</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5wtBuw" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5wtBuw/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zedeus/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zedeus"><img src="https://avatars.githubusercontent.com/u/9434921?s=80&amp;u=70b0757a69d84b0f31f0d50e2100cc5a505ca12c&amp;v=4" width="40" height="40" alt="@zedeus"></a>

</p>


  <div data-body-version="4290d80561307271663a5ace0736c7a57a23b3ca5f865ca7fdaec5f3fdfe6d45" id="issuecomment-1890851760">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/lukefromdc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lukefromdc">@lukefromdc</a> <a data-hovercard-type="user" data-hovercard-url="/users/stopmotio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stopmotio">@stopmotio</a> someone filed a complaint to Njalla about unconsensual nudity being hosted on nitter.net, with a link that actually came from another instance. It's the first time I've ever gotten any semblance of a takedown request via Njalla, so I didn't think much of it when I got an email with the subject "Njalla: New Message", and the body just being a link, while traveling. A couple days later and one more email, they just suspended the account. I only found out when nitter.net became unreachable.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOC3_cDc5wtClX" data-url="/zedeus/nitter/comments/IC_kwDOC3_cDc5wtClX/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zedeus/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zedeus"><img src="https://avatars.githubusercontent.com/u/9434921?s=80&amp;u=70b0757a69d84b0f31f0d50e2100cc5a505ca12c&amp;v=4" width="40" height="40" alt="@zedeus"></a>

</p>


  <div data-body-version="79582f7fb752f7aa5ea867abc81c2adeddf6356e0cf5ff57e083f7ed403d39f2" id="issuecomment-1890855255">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">These are the two emails I received prior to suspension:<br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9434921/296531658-50d14c5d-cf93-4d77-9a58-70007d68fde6.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTY1OC01MGQxNGM1ZC1jZjkzLTRkNzctOWE1OC03MDAwN2Q2OGZkZTYuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTljYjk3YjEzOTFhZDlkNTlmYjBmNmQ5MmFkYzQxOTdlMTU0NzYxNDMzNGM4OGQ5ZTRmNTI3OWZmZjZlODM5OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.IPzWHqjZnGGqmXcV25_RFKWjdSO4_rBs7z7RiLQGqgY"><img src="https://private-user-images.githubusercontent.com/9434921/296531658-50d14c5d-cf93-4d77-9a58-70007d68fde6.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTY1OC01MGQxNGM1ZC1jZjkzLTRkNzctOWE1OC03MDAwN2Q2OGZkZTYuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTljYjk3YjEzOTFhZDlkNTlmYjBmNmQ5MmFkYzQxOTdlMTU0NzYxNDMzNGM4OGQ5ZTRmNTI3OWZmZjZlODM5OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.IPzWHqjZnGGqmXcV25_RFKWjdSO4_rBs7z7RiLQGqgY" alt="Screenshot_2024-01-14-05-32-26-26_c3025e5ce50ffdc2876b487a5468618d"></a><br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9434921/296531659-160a5ab5-2a32-4b00-9c08-60fd12e0da2a.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTY1OS0xNjBhNWFiNS0yYTMyLTRiMDAtOWMwOC02MGZkMTJlMGRhMmEuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MjEzMGUxM2ZmN2M3MjY4NjNiMDc4YjU1ZTNjYzA0ZTBmZjRiNjQ3MWZmN2Y4NTIzNTE1MzUxNTUzZmI1OGIxNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.LTaWNqPeEZozPL5WECzCs3ckwgWrtghfhW8twOUmj7c"><img src="https://private-user-images.githubusercontent.com/9434921/296531659-160a5ab5-2a32-4b00-9c08-60fd12e0da2a.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTY1OS0xNjBhNWFiNS0yYTMyLTRiMDAtOWMwOC02MGZkMTJlMGRhMmEuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MjEzMGUxM2ZmN2M3MjY4NjNiMDc4YjU1ZTNjYzA0ZTBmZjRiNjQ3MWZmN2Y4NTIzNTE1MzUxNTUzZmI1OGIxNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.LTaWNqPeEZozPL5WECzCs3ckwgWrtghfhW8twOUmj7c" alt="Screenshot_2024-01-14-05-32-42-93_c3025e5ce50ffdc2876b487a5468618d"></a></p>
<p dir="auto">Hetzner at least included plenty of information about the urgency and the full report information, until they gave up and suspended my account.</p>
<p dir="auto">Njalla's handling of this is amateurish at best. Here's the actual support message:<br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9434921/296531744-a11a81eb-28e0-471e-baf2-03cba04d9f72.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTc0NC1hMTFhODFlYi0yOGUwLTQ3MWUtYmFmMi0wM2NiYTA0ZDlmNzIuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDE5OTlhNTVhOTNiYzgwNzYxNGRlNTYwOTA3OWE3NTAwZjM2MTFiNTlhZDA4MzAzZWM5MGYyNTdkNGJiYTA4ZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.DhaUqc-V1kC01toVyGRU3t-LhM-tcQNshoFhY8yJK5w"><img src="https://private-user-images.githubusercontent.com/9434921/296531744-a11a81eb-28e0-471e-baf2-03cba04d9f72.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDUyMTIzMDUsIm5iZiI6MTcwNTIxMjAwNSwicGF0aCI6Ii85NDM0OTIxLzI5NjUzMTc0NC1hMTFhODFlYi0yOGUwLTQ3MWUtYmFmMi0wM2NiYTA0ZDlmNzIuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDExNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDAxMTRUMDYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDE5OTlhNTVhOTNiYzgwNzYxNGRlNTYwOTA3OWE3NTAwZjM2MTFiNTlhZDA4MzAzZWM5MGYyNTdkNGJiYTA4ZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.DhaUqc-V1kC01toVyGRU3t-LhM-tcQNshoFhY8yJK5w" alt="IMG_20240114_053654_338"></a></p>
<p dir="auto">A funny thing to note here is that the image link, which first points at nitter.it, is a /enc/ link which only gets created by Nitter if the instance admin enables base64 link encoding for media proxying. This is not enabled for nitter.net, so I know for a fact someone copied an image from another instance (presumably nitter.it), changed the domain, and sent a complaint to Njalla.</p>
      </div>
</task-lists>


        
      </div>

</div>






  <!-- Rendered timeline since 2024-01-13 21:40:21 -->
  
</div>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenD, a D language fork that is open to your contributions (218 pts)]]></title>
            <link>https://dpldocs.info/this-week-in-d/Blog.Posted_2024_01_01.html</link>
            <guid>38986546</guid>
            <pubDate>Sun, 14 Jan 2024 01:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2024_01_01.html">https://dpldocs.info/this-week-in-d/Blog.Posted_2024_01_01.html</a>, See on <a href="https://news.ycombinator.com/item?id=38986546">Hacker News</a></p>
<div id="readability-page-1" class="page">
	
	<div id="page-body"><p><a href="https://dpldocs.info/this-week-in-d/Blog.html">Blog</a> 
		<span>Articles</span></p><ul><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2024_01_08.html">OpenD at one week old</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2024_01_01.html">A ship carrying silverware has sailed</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_12_25.html">arsd.pixmappresenter PR merged, stars and snow demo like the olden days, and update on me and D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_12_18.html">Browsers in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_12_11.html">Minigui's mechanism is ok now, what about policy?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_12_04.html">Ephemeral web chat in 50 lines of D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_11_27.html">November 27, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_11_20.html">arsd 11.3 coming soon, dpldocs search works again</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_11_13.html">November 13, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_11_06.html">D's selective imports have effects you may not want</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_10_30.html">Dos and Don'ts in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_10_23.html">Interpolated Expression Sequence PR opened</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_10_16.html">version considered harmful</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_10_09.html">di files are currently useless - the compiler does the same thing for the original source anyway</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_10_02.html">arsd 11.2 - COM dispatch revamp</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_09_25.html">arsd on Mac - solid progress</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_09_18.html">September 18, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_09_11.html">arsd 11.1 tagged, cgi.d performance, SerpentOS moves to Rust, trying out reggae</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_09_04.html">DConf 2023 roundups</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_08_28.html">dconf 2023 coming and arsd 11.1 progress - minigui tweaks, cgi hybrid new default mode on dub</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_08_21.html">August 21, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_08_14.html">August 14, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_08_07.html">arsd 11.0 finally tagged</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_07_31.html">arsd update - cgi listen to many</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_07_24.html">July 24, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_07_17.html">July 17, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_07_10.html">July 10, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_07_03.html">SAoC announced, my thoughts on potential projects</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_06_26.html">June 26, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_06_19.html">June 19, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_06_12.html">June 12, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_06_05.html">DConf deadline passes, write up on the -mv switch</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_05_29.html">What is all this talk about IVY?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_05_22.html">May 22, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_05_15.html">May 15, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_05_08.html">My rpg finally releasing a demo this month?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_05_01.html">May 1, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_04_24.html">April 24, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_04_17.html">April 17, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_04_10.html">Guis vs Games, why one library is unlikely to do both well</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_04_03.html">Linux is better than BSD. Directory watchers and decompressors in arsd.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_03_27.html">Busy working this week</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_03_20.html">arsd 11 progress report</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_03_13.html">A few more debugging tips - run debugger automatically on linux</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_03_06.html">March 6, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_02_27.html">February 27, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_02_20.html">Mike Parker hints D management changes coming, I write about static assert and platform porting</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_02_13.html">Guest tip from Webfreak about toString</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_02_06.html">Demo on custom sections</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_01_30.html">A couple user programs announced, Adam writes more cgi.d docs</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_01_23.html">On fullyQualifiedName</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_01_16.html">Some thoughts on UI</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_01_09.html">Moving toward arsd 11</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2023_01_02.html">January 2, 2023</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_12_26.html">More mixin tips to avoid stringof</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_12_19.html">new textlayout class, dconf online thoughts, step by step tech progression</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_12_12.html">Write barriers might not fix thread registration since you need to scan the stack</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_12_05.html">Brief thought: D from Java/.net could be another write barrier benefit</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_11_28.html">DIP DIP part 2: the user side</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_11_21.html">new dmd, new DIP, beta dub docs, game lib announced. And politics in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_11_14.html">dconf 2022 online schedule, some arsd.game work, template emission discussion with d index file proposal</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_11_07.html">How NO_SCAN makes shorter GC pauses</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_10_31.html">Write barriers could work</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_10_24.html">simpledisplay custom font stream of thought</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_10_17.html">Writing more arsd dox</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_10_10.html">D on Arduino</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_10_03.html">October 3, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_09_26.html">September 26, 2022 - tip of the week to bypass IFTI</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_09_19.html">September 19, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_09_12.html">My thoughts on bitfields and recap of binary literals</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_09_05.html">September 5, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_08_29.html">preliminary design discussion of arsd.core event loop</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_08_22.html">arsd 10.9 released</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_08_15.html">Idea: user-extensible effect attributes</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_08_08.html">DConf 2022 thoughts</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_07_25.html">musings on pure websites</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_07_18.html">static import object tricks</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_07_11.html">Thoughts on inferred attributes</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_07_04.html">I write on respect in discussions. D Vision document partial draft released.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_06_27.html">Exception idea: third Throwable branch. Probably won't work but written anyway.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_06_20.html">DIP DIP</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_06_13.html">June 13, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_06_06.html">June 6, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_05_30.html">DConf 22 announced. arsd 11 not likely needed soon, 10.9 expected in another month</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_05_23.html">May 23, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_05_16.html">ImportC's module namespace problem</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_05_09.html">Happy birthday, ImportC!</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_05_02.html">Developers developers developers developers</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_04_25.html">More dub 2.0 idea refinement</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_04_18.html">Thoughts on async io</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_04_11.html">April 11, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_04_04.html">arsd bug fixes, stack overflow answer about X child windows</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_03_28.html">dub 2.0 design discussion</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_03_21.html">Tip of the week on justification comments</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_03_14.html">March 14, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_03_07.html">March 7, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_02_28.html">February 28, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_02_21.html">February 21, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_02_14.html">dpldocs reindexing</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_02_07.html">More rant on names</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_01_31.html">Adam's thoughts on naming in code, tip from Steven about ufcs `i`</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_01_24.html">Tip of the week: use mixin to hack around order-of-eval problems</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_01_17.html">Tip: if code getting complicated, try rethinking the approach</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_01_10.html">January 10, 2022</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2022_01_03.html">arsd 10.5 coming this week, new midi code, a FF1 nsf player/editor application</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_12_27.html">December 27, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_12_13.html">arsd work in progress updates and new "do it in D" idioms section</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_12_06.html">December 6, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_11_29.html">gdc sync going upstream, arsd 10.4 released, otherwise i was busy.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_11_22.html">working toward arsd 10.4</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_11_15.html">DConf Online 2021 livestream</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_11_08.html">arsd.webview work, public imports in adrdox changed</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_11_01.html">importC released, preview of arsd web, database, gui updates, phobos2 coming, dual context tip of the week</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_10_25.html">October 25, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_10_18.html">My webasm updates, gdc in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_10_11.html">Assorted quick thoughts</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_10_04.html">October 4, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_09_27.html">arsd 10.3, dmd -target, druntime.dll</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_09_20.html">A potential GC puzzler discovered</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_09_06.html">Rant: using Firefox is meaningless</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_08_30.html">August 30, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_08_23.html">Improving today's error handling</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_08_16.html">Thoughts on error handling</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_08_09.html">August 9, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_08_02.html">August 2, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_07_26.html">arsd.qrcode introduced and on my wish list: __arguments.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_07_19.html">July 19, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_07_12.html">Drama on the github</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_07_05.html">arsd 10.2 with http cookies support</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_06_28.html">June 28, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_06_21.html">arsd 10.1, thought on virtual functions, community announces light weight Druntime 0.3 among others</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_06_14.html">arsd v10 tagged</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_06_07.html">New dmd and ldc releases, ldc with druntime.dll!</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_05_31.html">gdc 11 out with a lot of D updates</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_05_24.html">May 24, 2021 general update</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_05_17.html">Progress continues toward minigui 2.0</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_05_10.html">C compiler in dmd? new string type in Phobos? brief update on my minigui overhaul</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_05_03.html">Simpledisplay additions, minigui event changes</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_04_26.html">April 26, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_04_19.html">arsd 9.5 -- UPDATE: false alarm i forgot to tag it!</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_04_12.html">April 12, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_04_05.html">arsd 9.4 tagged, adrdox 2.5 released</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_03_29.html">Tip of the week: using C libs from D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_03_22.html">working on gdc on Windows</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_03_15.html">tip: use union to manually control struct member destructor</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_03_08.html">Rant: people in the past weren't stupid</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_03_01.html">Tip on DIY closures</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_02_22.html">arsd 9.2</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_02_15.html">Did you know about D anonymous classes?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_02_08.html">"Mental friction": my view on why D rox</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_02_01.html">String interpolation DIP prototype</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_01_25.html">terminal inline syntax highlighting, sdpy fonts improved</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_01_18.html">January 18, 2021</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_01_11.html">gdb debugging tips</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2021_01_04.html">A little work on sdpy/terminal interop and apng debugging</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_12_28.html">New plain tcp fiber socket class (with "how it works" docs), new arsd docs started, new dub subpackages in arsd. Also Turkish newsgroups added to forum.dlang.org</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_12_21.html">Little audio player in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_12_14.html">Thoughts on tutorial writing benefits, D marketing, and some simpledisplay.d improvements.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_12_07.html">arsd 9.0 rollup release, my thoughts on "google it" culture and related practices</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_11_30.html">dpldocs.info cross-package search finally released! and more terminal getline enhancements</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_11_23.html">I did a dconf livestream!</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_11_16.html">New selective mouse input in terminal stack, Xft used in simpledisplay to improve TrueType font support</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_11_09.html">simpleaudio now has playOgg, Mp3, Wav with resampling and can access multiple soundcards on Linux, adrdox gets ddoc on function params</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_11_02.html">Weekend experiment: declarative GUI in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_10_26.html">October 26, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_10_19.html">My DConf livestream sneak preview</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_10_12.html">Off topic jrpg video game review</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_10_05.html">My thoughts on breakage, and I'll be in DConf Online 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_09_28.html">cgi.d hybrid server basically working, terminal.d can redirect stdout to a window if requested</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_09_21.html">Some talk on cgi.d in benchmarks</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_09_14.html">September 14, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_09_07.html">New D update "dwidder" website launched, making-of post here</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_08_31.html">white noise app in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_08_24.html">More modern opengl in simpledisplay, document undocumented on dpldocs.info, tip on default template args</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_08_17.html">Xlib taskbar in D</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_08_10.html">D Tetris running on Webassembly</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_07_27.html">Zero-runtime classes</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_07_20.html">DConf online in the works for Nov 21-22, image copy/paste coming to sdpy soon</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_07_13.html">July 13, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_07_06.html">July 6, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_06_29.html">simpledisplay getting dynamic loads, terminal gui gracefully degrades, i muse on scope raii classes</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_06_22.html">Adam's dynamic link transition</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_06_15.html">June 15, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_06_08.html">June 8, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_06_01.html">June 1, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_05_25.html">foot pedal and midi fun, some dmd speed enhancements. Forum argues about @safe by default on extern.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_05_18.html">May 18, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_05_11.html">simpleaudio dev work, rasp pi gpio module, static foreach rant, gcc 10's D support upped</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_05_04.html">May 4, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_04_27.html">my http more compatible with ssl, script+jsvar can do subclasses of D objects</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_04_20.html">i want to make a jrpg, and have eye damage.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_04_06.html">What if I were dictator?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_03_30.html">March 30, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_03_23.html">terminal.d with built-in emulator option releaed</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_03_16.html">Online DConf in the works</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_03_09.html">Dconf 2020 cancelled, Adam plays with terminal gui integration</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_03_02.html">March 2, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_02_24.html">some adrdox/dpldocsinfo updates</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_02_17.html">terminal.d gets clipboard functions, ldc 1.20 out.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_02_10.html">DConf keynote speaker announced: Lua architect Roberto Ierusalimschy, Named args DIP discussed</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_02_03.html">February 3, 2020</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_01_27.html">Adam's terminal suite explained</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_01_20.html">Understanding mixin templates, terminal.d improvements</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_01_13.html">My attribute-by-default proposal. Also dmd 2.090 came out.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2020_01_06.html">DConf 2020 announced: June 17-20 in London. @safe by default debated. Adam did: Android, JNI, WebSocket in arsd libs</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_12_30.html">tar.xz, --DRT tip, dom bug fixes, more Android and JNI, link to old phobos docs</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_12_23.html">LDC 1.19 - Android, AVR. My rant on tests, update on JNI and COM.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_12_16.html">Walter's string interpolation proposal is OK but not great. My Android thing nearing beta release. dub downtime explained.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_12_09.html">Android project update, introduction to arsd.jni</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_12_02.html">New pattern about interface contracts</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_11_25.html">Adam shares Windows console secrets - DO NOT USE chcp!!</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_11_18.html">Adam's rant on benchmarks</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_11_11.html">Socket tutorial</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_11_04.html">November 4, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_10_28.html">October 28, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_10_21.html">arsd package updates, forum nonsense</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_10_07.html">Adam does iOS "goodbye world"</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_09_30.html">September 30, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_09_23.html">D turns 20, Adam rants on software freedom</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_09_16.html">Named arg DIPs and my thoughts on code organization</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_09_09.html">September 9, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_09_02.html">I wrote about mixin templates vs string mixins on Stack Overflow</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_08_26.html">August 26, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_08_19.html">Bug bounty in D again - my hot take, on reusing code, a fun picture, my tentative plan for the next month</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_08_12.html">Time invested is worth a lot</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_08_05.html">cgi.d's new scheduler, static this tricks</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_07_29.html">July 29, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_07_22.html">July 22, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_07_15.html">Solving vs managing problems</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_07_08.html">A big week in the arsd repo</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_06_24.html">June 24, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_06_10.html">CRTP thoughts, named arguments DIP review, DConf videos now on youtube</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_06_03.html">musings on hybrid CT/RT tests, some more progress on new web framework</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_05_27.html">a little more webassembly</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_05_20.html">May 20, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_05_13.html">Adam's string interpolation proposal</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_05_06.html">DMD 2.086 live, GCC 9 with D support formally released, DConf coming soon, links to posts on builder pattern and disallowing implicit conversions with templates, and 2d array op overloads</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_04_29.html">template constraint error improvements coming?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_04_22.html">dmd 2.086 beta, dstep 1.0 released, Adam works on memory usage</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_04_15.html">obj-c and webassembly report, tips on is expressions linked.</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_04_08.html">new ldc, new dmd, dpp on the blog</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_04_01.html">D's future discussed in forums</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_03_25.html">LDC beta, DConf blog link, Adam introduces gamehelpers.d</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_03_18.html">March 18, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_03_11.html">LDC 1.15.0-beta1, responsive design rant</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_03_04.html">dmd 2.085.0 released</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_02_25.html">Obj-C interop and D without druntime code to copy/paste</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_02_18.html">dmd beta, more info coming next time, demo of new web framework initial prototype</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_02_11.html">automatic web interface discussion, reflection tips and tricks</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_02_04.html">Adam busy with weather and a move, lots of community announcements</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_01_28.html">January 28, 2019</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_01_21.html">Working on official blog 2018 retro, C++ new wrapped, dmd reading zips?</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2019_01_14.html">dmd obj-c growing, Adam static foreaches an interface to RPC</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2018_12_31.html">IDE tools released, my cgi.d gets new features</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2018_12_24.html">DConf announced, tip, Adam rants: mouse trap</a></li><li><a href="https://dpldocs.info/this-week-in-d/Blog.Posted_2018_12_17.html">This Week in D is back!</a></li></ul></div>
	

</div>]]></description>
        </item>
    </channel>
</rss>