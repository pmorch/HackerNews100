<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Nov 2024 14:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Engineering Sleep (204 pts)]]></title>
            <link>https://minjunes.ai/posts/sleep/index.html</link>
            <guid>42279454</guid>
            <pubDate>Sat, 30 Nov 2024 04:33:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minjunes.ai/posts/sleep/index.html">https://minjunes.ai/posts/sleep/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42279454">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Engineering Sleep</span></p><p><span>Background</span><span>&nbsp;</span></p><p><span>Sleep claims a third of human life. Like water, it’s not a desire but a necessity. Sleep rules virtually every important system: brain, heart, mood, and immunity. Nature’s terms are harsh. Sleep eight hours or face mental and physical decay. Can we rewrite the terms in our favor? Can we sleep less, but still feel refreshed? I believe we can, and that now is the best time to start engineering sleep.</span></p><p><span>Rare mutations suggest a great variation in sleep efficiency between people</span><span>.</span><span>&nbsp;A small proportion of the population have Familial Natural Short Sleep (FNSS), a benign mutation that allows them to sleep 1-2 hours less than the recommended 7-9 hours, without experiencing the negative effects of sleep deprivation [</span><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">1</a></span><span>]</span><span>. </span></p><p><span>Contrary to symptoms of chronic sleep deprivation, people with FNSS are “healthy, energetic, optimistic, with high pain threshold, and do not seem to suffer adverse effects of chronic restricted sleep” [</span><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">2</a></span><span>]</span><span>. This goes against everything we know about sleep. The most plausible explanation is that people with FNSS are more efficient sleepers. Whichever functions of sleep make it so crucial, they are doing it faster and better.</span></p><p><span>The Sleep Mutation</span></p><p><span>How does FNSS work? Five genes have been implicated in the FNSS phenotype, but DEC2 is the most studied. In 2009, professor Ying-Hui Fu at UCSF discovered a DEC2 point mutation from two individuals in the same family who slept 6.25 hours on average [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. DEC2 codes for a repressive transcription factor (a protein that inhibits the expression of some gene). Normally, the gene that this transcription factor represses is responsible for expressing orexin, a neurotransmitter. In the mutation, proline is replaced by arginine at position 384 in exon 5 (DEC2P384R), disrupting its ability to repress orexin expression. Consequently, more orexin is expressed in individuals with this mutation. The UCSF group hypothesizes that this elevated level of orexin expression partially explains reduced sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">4</a></span><span>]. </span></p><p><span><img alt="image3" src="https://minjunes.ai/posts/sleep/images/image3.jpg" title=""></span></p><p><span>Fig 1. In normal humans, Dec2 weakens E12/Myod1’s binding affinity to the Ebox1 promoter site of prepro-orexin, which is responsible for endogenous orexin synthesis. In FNSS mutants, the DEC2P384R interaction with the E12/Myod1 complex is weaker, and there is greater orexin expression.</span></p><p><span>Two decades of sleep research supports the link between orexin and sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">5</a></span><span>]. In both narcolepsy and insomnia, orexin is the key neurotransmitter that modulates awakeness. A deficit of orexin producing neurons is responsible for excessive sleepiness in narcolepsy [</span><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">6</a></span><span>]. An overexpression of orexin is responsible for hypervigilance in insomnia [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">7</a></span><span>]. Throughout the day and night, we move between the wake-sleep axis defined by orexin levels, which are lowest in the middle of the day and highest during the transition from NREM to REM sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">8</a></span><span>].</span></p><p><span>Orexin is a commercially validated lever for controlling sleep. As of late 2024, there are eight orexin receptor agonists (promotes firing of neuron) in clinical trials for treating narcolepsy and hypersomnia, and two orexin receptor antagonists (inhibits firing of neuron) on the market for treating insomnia. To summarize orexin, too little of it makes you sleepy, and too much of it makes you unable to sleep.</span></p><p><span>But if elevated orexin levels explain reduced sleep in both FNSS carriers and insomniacs, why is one sleep deprived but not the other? We don’t know. Variation in dynamics of when, where, and how much orexin is released could explain the difference. Also, FNSS carriers might have developed compensatory mechanisms to cope with elevated orexin, leading to more efficient sleep. Experiments to reproduce FNSS will give us answers. </span></p><p><span>Reproducing FNSS</span></p><p><span>Given our current knowledge of FNSS, has anyone tried to reproduce it? A true reproduction would be safe and effective over the lifetime of the host, just like we see in the natural phenotype. The closest attempt was by the UCSF group that identified the DEC2P384R mutation. In their pioneering 2009 study, the group embryonically edited human DEC2P384R into transgenic mice and saw a 1-2 hour reduction in sleep. However, we don’t know if it was safe and effective over the lifetime of the mice. They recorded sleep architecture and sleep recovery during a 24-hour window in six to eight month old mice, tracking no other health markers [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. </span></p><p><span>The study intervened at the embryo level of the host and saw short-term success reproducing FNSS. But what we’re really interested in is adulthood intervention and lifelong efficacy. Giving normal people the ability to sleep more efficiently is the ultimate goal. Expressing the DEC2P384R mutation in normal adult animals and conducting a lifelong study would answer this question. Two possible pathways to reproducing FNSS are reviewed below. </span></p><p><span>Path I: Orexin Agonists</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image2.jpg" title=""></span></p><p><span>Fig 2. Pathway I success case</span></p><p><span>Approach</span></p><p><span>Orally dose orexin receptor agonists. The mechanism leverages direct receptor activation, similar to drugs currently in clinical trials for treating narcolepsy. These small molecules are designed for optimal blood-brain barrier penetration and selective binding to orexin receptors. </span></p><p><span>Unknowns</span></p><p><span>Primarily, we don’t know if elevated orexin levels explain the FNSS phenotype. Also, we don’t know the effects of chronic orexin receptor activation on sleep architecture and cognition. Pharma companies developing orexin agonists have data on short-term sleep effects, but none of them have published data on long term effects [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">9</a></span><span>]. Also unknown are tolerance and withdrawal effects over time: like other receptor agonists (think nicotine), we may see diminishing effects, and withdrawal effects on return to baseline. Finally, variations in individual response are unknown. </span></p><p><span>Path II: Gene Therapy</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image5.jpg" title=""></span></p><p><span>Fig 3. </span><span>Pathway II success case</span></p><p><span>Approach</span></p><p><span>Replicate the natural FNSS mutation through episomal expression. Episomal expression is when the gene is expressed from a piece of DNA that is outside the cell’s chromosomal DNA. Since chromosomal DNA is left alone, there is no risk of passing down the mutation to offspring. For this approach, we use Adeno-Associated Virus serotype 9 (AAV9) vectors to deliver the DEC2P384R gene to orexin-expressing neurons in adult mice. The vectors (the piece of extra chromosomal DNA) remain in the nucleus, continuously synthesizing the mutant DEC2 protein. This aims to partially mirror the mechanism seen in FNSS.</span></p><p><span>Unknowns</span></p><p><span>We are more certain that DEC2P384R explains FNSS, but we don’t know if expressing it in adulthood works. We also don’t know off-target effects on DEC2-regulated pathways beyond sleep. A specific unknown to episomal expression is the competition dynamics between DEC2P384R and native DEC2. The usual unknowns of variations between individual responses, particularly immune response, apply. </span></p><p><span>Overview of Pathways</span></p><p><span><img alt="image1" src="https://minjunes.ai/posts/sleep/images/image1.png" title=""></span></p><p><span>Too good to be true? &nbsp;</span></p><p><span>Around 90 families with FNSS have been identified to date [</span><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">10</a></span><span>]. If FNSS is truly benign, why is it so rare? Shouldn’t more efficient sleep confer a survival advantage? It could be that the mutation really is benign, but does not help reproductive success. But, the mutation could also have negative fitness effects that are not observed.</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image4.jpg" title=""></span></p><p><span>Fig 4. Fisher-Wright simulation showing allele frequency dynamics with 10% fitness penalty across population sizes (N=100, 1,000, 10,000). Initial carrier frequency 1%, tracked for 20 generations over 100 simulations. Solid lines show means; shaded regions show standard deviations.</span></p><p><span>Under the Fisher-Wright model, harmful mutations can appear neutral when tracking small populations across just a few generations. If the mutation has a tiny effective population size, limited generational depth, and low carrier frequency, it would be hard to distinguish between neutral drift and negative selection.</span></p><p><span>Fortunately, there is no risk of the mutation being passed down to offsprings in either the orexin agonist pathway or the gene therapy pathway. So we can rule out the nightmare scenario of offspring effects gone wrong. Instead, the risks are concentrated in medium to long term health of individuals who undergo therapy. As of now, we simply don’t have enough data to profile risk factors. More experiments are needed to know if “FNSS for all” is too good to be true. </span></p><p><span>Where is my better sleep? </span></p><p><span>People with FNSS are living proof that we don’t need 7-9 hours of sleep to be healthy. We already don’t get enough sleep. 34% of Americans are chronically sleep deprived [</span><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">11</a></span><span>]. What if they could keep sleeping less, but with no consequences? That’s possible with advanced sleep engineering. Here’s what else would be possible: falling asleep and waking at will, sleeping 4 hours but feeling like you slept 8 hours, always in perfect mental and physical condition. Considering the huge upside of engineering sleep, an unreasonably small number of experiments have studied FNSS. </span></p><p><span>Due to their relatively singular effect on sleep, FNSS mutations are a gold mine for studying sleep. But, there have been only two attempts to mimic FNSS outside of Fu et al: a study that found better memory consolidation in sleep deprived mice [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">12</a></span><span>], and another that found greater longevity in flies [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">13</a></span><span>]. None have been lifetime studies in mammals, which are most relevant to therapy development. </span></p><p><span>15 years after its pioneering work that identified DEC2P384R, Ying-Hui Fu’s lab is the only group that came close to reverse engineering FNSS. Perhaps this represents what J Storss Halls called a “civilizational failure of nerve”, where institutions become pathologically risk-averse, more focusing on preventing downside risks than enabling upside potential [</span><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">14</a></span><span>]. Scientific and technological progress rests on the willingness to experiment. If existing institution’s won’t give us better sleep, we should build ones that do.</span></p><p><span>Next Steps</span></p><p><span>Contact me if you are interested in: </span></p><ul><li><span>Expanding the known FNSS database, and sequencing everyone in it</span></li><li><span>Testing pathways I and II</span></li><li><span>Funding the above</span></li></ul><p><span>Special thanks to Andy Kong, Ishan Goel, Tazik Shahjahan, and Mae Richardson for valuable feedback. </span></p><p><span>References</span></p><ol start="1"><li><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">Short Sleeper Syndrome</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">A Genetic Mutation for Short Sleep Prevents Memory Deficits in a Mouse Model</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">He Y, Jones CR, Fujiki N, Xu Y, Guo B, Holder JL Jr, Rossner MJ, Nishino S, Fu YH. The transcriptional repressor DEC2 regulates sleep length in mammals. Science. 2009 Aug 14;325(5942):866-70. doi: 10.1126/science.1174443. PMID: 19679812; PMCID: PMC2884988.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">Hirano A, Hsu PK, Zhang L, Xing L, McMahon T, Yamazaki M, Ptáček LJ, Fu YH. DEC2 modulates orexin expression and regulates sleep. Proc Natl Acad Sci U S A. 2018 Mar 27;115(13):3434-3439. doi: 10.1073/pnas.1801693115. Epub 2018 Mar 12. PMID: 29531056; PMCID: PMC5879715.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">De Luca R, Nardone S, Grace KP, Venner A, Cristofolini M, Bandaru SS, Sohn LT, Kong D, Mochizuki T, Viberti B, Zhu L, Zito A, Scammell TE, Saper CB, Lowell BB, Fuller PM, Arrigoni E. Orexin neurons inhibit sleep to promote arousal. Nat Commun. 2022 Jul 18;13(1):4163. doi: 10.1038/s41467-022-31591-y. PMID: 35851580; PMCID: PMC9293990.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy</a></span><span>.</span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">Muehlan C, Roch C, Vaillant C, Dingemanse J. The orexin story and orexin receptor antagonists for the treatment of insomnia. J Sleep Res. 2023 Dec;32(6):e13902. doi: 10.1111/jsr.13902. Epub 2023 Apr 22. PMID: 37086045.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">Mogavero, M. P., Godos, J., Grosso, G., Caraci, F., &amp; Ferri, R. (2023). Rethinking the Role of Orexin in the Regulation of REM Sleep and Appetite. Nutrients, 15(17), 3679. https://doi.org/10.3390/nu15173679</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">Ishikawa T, Hara H, Kawano A, Kimura H. Danavorexton, a selective orexin 2 receptor agonist, provides a symptomatic improvement in a narcolepsy mouse model. Pharmacol Biochem Behav. 2022 Oct;220:173464. doi: 10.1016/j.pbb.2022.173464. Epub 2022 Sep 13. PMID: 36108771.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">Xing, L., Shi, G., Mostovoy, Y., Gentry, N. W., Fan, Z., McMahon, T. B., Kwok, P. Y., Jones, C. R., Ptáček, L. J., &amp; Fu, Y. H. (2019). Mutant neuropeptide S receptor reduces sleep duration with preserved memory consolidation. Science translational medicine, 11(514), eaax2014. https://doi.org/10.1126/scitranslmed.aax2014</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">Pandey P, Wall PK, Lopez SR, Dubuisson OS, Zunica ERM, Dantas WS, Kirwan JP, Axelrod CL, Johnson AE. A familial natural short sleep mutation promotes healthy aging and extends lifespan in Drosophila. bioRxiv [Preprint]. 2023 Apr 26:2023.04.25.538137. doi: 10.1101/2023.04.25.538137. PMID: 37163058; PMCID: PMC10168263.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">Hall, J. S. (2021). Where is my flying car? Stripe Press.</a></span></li></ol></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA's Europa Clipper: Miles Down, Instruments Deploying (108 pts)]]></title>
            <link>https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/</link>
            <guid>42278148</guid>
            <pubDate>Fri, 29 Nov 2024 23:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/">https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/</a>, See on <a href="https://news.ycombinator.com/item?id=42278148">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>Headed to Jupiter’s moon Europa, the spacecraft is operating without a hitch and will reach Mars in just three months for a gravity assist.</em></p>
<p>NASA’s Europa Clipper, which launched Oct. 14 on a journey to Jupiter’s moon Europa, is already <a href="https://eyes.nasa.gov/apps/solar-system/#/sc_europa_clipper/distance?to=earth" rel="noopener">13 million miles</a> (20 million kilometers) from Earth. Two science instruments have deployed hardware that will remain at attention, extending out from the spacecraft, for the next decade — through the cruise to Jupiter and the entire prime mission.</p>
<p>A SpaceX Falcon Heavy rocket launched it away from Earth’s gravity, and now the spacecraft is zooming along at 22 miles per second (35 kilometers per second) relative to the Sun.</p>
<p><a href="https://science.nasa.gov/mission/europa-clipper/" rel="noopener">Europa Clipper</a> is the largest spacecraft NASA has ever developed for a planetary mission. It will travel 1.8 billion miles (2.9 billion kilometers) to arrive at Jupiter in 2030 and in 2031 will begin a series of 49 flybys, using a <a href="https://europa.nasa.gov/spacecraft/instruments/" rel="noopener">suite of instruments</a> to gather data that will tell scientists if the icy moon and its internal ocean have the conditions needed to harbor life.</p>
<p>For now, the information mission teams are receiving from the spacecraft is strictly engineering data (the science will come later), telling them how the hardware is operating. Things are looking good. The team has a checklist of actions the spacecraft needs to take as it travels deeper into space. Here’s a peek:</p>

<p>Shortly after launch, the spacecraft deployed its massive <a href="https://www.jpl.nasa.gov/news/nasas-europa-clipper-gets-set-of-super-size-solar-arrays/" rel="noopener">solar arrays</a>, which extend the length of a basketball court. Next on the list was the <a href="https://europa.nasa.gov/spacecraft/instruments/ecm/" rel="noopener">magnetometer</a>’s boom, which uncoiled from a canister mounted on the spacecraft body, extending a full 28 feet (8.5 meters).</p>
<p>To confirm that all went well with the boom deployment, the team relied on data from the magnetometer’s three sensors. Once the spacecraft is at Jupiter, these sensors will measure the magnetic field around Europa, both confirming the presence of the ocean thought to be under the moon’s icy crust and telling scientists about its depth and salinity.</p>


<p>After the magnetometer, the spacecraft deployed several antennas for the radar instrument. Now extending crosswise from the solar arrays, the four high-frequency antennas form what look like two long poles, each measuring 57.7 feet (17.6 meters) long. Eight rectangular very-high-frequency antennas, each 9 feet (2.76 meters) long, were also deployed — two on the two solar arrays.</p>
<p>“It’s an exciting time on the spacecraft, getting these key deployments done,” said Europa Clipper project manager Jordan Evans of NASA’s Jet Propulsion Laboratory in Southern California. “Most of what the team is focusing on now is understanding the small, interesting things in the data that help them understand the behavior of the spacecraft on a deeper level. That’s really good to see.”</p>

<p>The remaining seven instruments will be powered on and off through December and January so that engineers can check their health. Several instruments, including the <a href="https://europa.nasa.gov/spacecraft/instruments/eis/" rel="noopener">visible imager</a> and the <a href="https://europa.nasa.gov/spacecraft/instruments/maspex/" rel="noopener">gas</a> and <a href="https://europa.nasa.gov/spacecraft/instruments/suda/" rel="noopener">dust</a> mass spectrometers, will keep their protective covers closed for the next three or so years to guard against potential damage from the Sun during Europa Clipper’s time in the inner solar system.</p>

<p>Once all the instruments and engineering subsystems have been checked out, mission teams will shift their focus to Mars. On March 1, 2025, Europa Clipper will reach Mars’ orbit and begin to loop around the Red Planet, using the planet’s gravity to gain speed. (This effect is similar to how a ball thrown at a moving train will bounce off the train in another direction at a higher speed.) Mission navigators already have completed one trajectory correction maneuver, as planned, to get the spacecraft on the precise course.</p>
<p>At Mars, scientists plan to turn on the spacecraft’s <a href="https://europa.nasa.gov/spacecraft/instruments/e-themis/" rel="noopener">thermal imager</a> to capture multicolored images of Mars as a test operation. They also plan to collect data with the radar instrument so engineers can be sure it’s operating as expected.</p>
<p>The spacecraft will perform another gravity assist in December 2026, swooping by Earth before making the remainder of the long journey to the Jupiter system. At that time, the magnetometer will measure Earth’s magnetic field, calibrating the instrument.</p>

<p>Europa Clipper’s three main science objectives are to determine the thickness of the moon’s icy shell and its interactions with the ocean below, to investigate its composition, and to characterize its geology. The mission’s detailed exploration of Europa will help scientists better understand the astrobiological potential for habitable worlds beyond our planet.</p>
<p>Managed by Caltech in Pasadena, California, JPL leads the development of the Europa Clipper mission in partnership with the Johns Hopkins Applied Physics Laboratory in Laurel, Maryland, for NASA’s Science Mission Directorate in Washington. APL designed the main spacecraft body in collaboration with JPL and NASA’s Goddard Space Flight Center in Greenbelt, Maryland, NASA’s Marshall Space Flight Center in Huntsville, Alabama, and Langley Research Center in Hampton, Virginia. The Planetary Missions Program Office at Marshall executes program management of the Europa Clipper mission. NASA’s Launch Services Program, based at Kennedy, managed the launch service for the Europa Clipper spacecraft.</p>
<p>Find more information about Europa Clipper here:</p>
<p><a href="https://science.nasa.gov/mission/europa-clipper" rel="noopener">https://science.nasa.gov/mission/europa-clipper</a></p>





<p>Gretchen McCartney<br>Jet Propulsion Laboratory, Pasadena, Calif.<br>818-287-4115<br><a href="mailto:gretchen.p.mccartney@jpl.nasa.gov%C2%A0">gretchen.p.mccartney@jpl.nasa.gov&nbsp;</a></p>
<p>Karen Fox / Molly Wasser<br>NASA Headquarters, Washington<br>202-358-1600<br><a href="mailto:karen.c.fox@nasa.gov">karen.c.fox@nasa.gov</a> / <a href="mailto:molly.l.wasser@nasa.gov">molly.l.wasser@nasa.gov</a> &nbsp;</p>
<p>2024-163</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Engagement Is Better on Bluesky (104 pts)]]></title>
            <link>https://bsky.social/about/blog/11-29-2024-engagement</link>
            <guid>42277963</guid>
            <pubDate>Fri, 29 Nov 2024 23:13:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.social/about/blog/11-29-2024-engagement">https://bsky.social/about/blog/11-29-2024-engagement</a>, See on <a href="https://news.ycombinator.com/item?id=42277963">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><header><section><a href="https://bsky.social/about/blog">Blog</a><svg width="8" height="12" viewBox="0 0 8 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 10L6 6L2 2" stroke="#667999" stroke-width="2" stroke-linecap="square"></path></svg><span>The Engagement Is Better on Bluesky</span></section><div><p>November 29, 2024</p><p><span>by <!-- -->The Bluesky Team</span></p></div></header><div><p>We could go on about how we welcome publishers, we don't demote links, we encourage independent developers to build apps and extensions on top of Bluesky's network.... but instead, we'll show you:</p>
<h3>The Boston Globe</h3>
<blockquote data-bluesky-uri="at://did:plc:e6zr6q76g4h7agw4tw6pnu3n/app.bsky.feed.post/3lbunm54agc2k" data-bluesky-cid="bafyreiddcne3ci43tnhmwmwdiihomvqkpliyxslsjshnnwxpryynal7udq"><p lang="en">Traffic from Bluesky to @bostonglobe.com is already 3x that of Threads, and we are seeing 4.5x the conversions to paying digital subscribers.</p>— Matt Karolian (<a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n?ref_src=embed">@mkarolian.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n/post/3lbunm54agc2k?ref_src=embed">November 26, 2024 at 10:19 AM</a></blockquote>
<h3>The Guardian</h3>
<blockquote data-bluesky-uri="at://did:plc:ayz3ljwsllsn7htnmu4q3zhq/app.bsky.feed.post/3lbvwh42ipk2y" data-bluesky-cid="bafyreihfz7ezs23z7scv4vyy7xi4vacsqan5llft5v4dc56umjhr7w7cfy"><p lang="en">By which I mean, I'm pretty sure traffic from 
@bsky.app to @theguardian.com is *significantly* higher than the very obvious 2x that of Threads
</p><div><p>This post brought to you by a reply to @mkarolian.bsky.social on Threads, where it has had just 105 engagements, as opposed to the 18k+ here</p><p><a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">[image or embed]</a></p></div>— Dave Earley (<a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq?ref_src=embed">@earleyedition.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">November 26, 2024 at 10:30 PM</a></blockquote>
<h3>The New York Times</h3>
<blockquote data-bluesky-uri="at://did:plc:ty42uz67qbam52si5yduwwaa/app.bsky.feed.post/3lbm65hi7bj2y" data-bluesky-cid="bafyreigjbemi4znbpyw52mdf77qxjlozfv6fzzds5mmn5rnkgprboclyaa"><div lang=""><p>hard to exaggerate how nuts the engagement is on Bluesky compared to 𝕏. a vastly smaller user base (at least officially), but just look at these stats for one of the biggest newspapers on Earth. Musk has absolutely trashed the platform. folks, you are not locked in on 𝕏. not even a little.</p><p><a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">[image or embed]</a></p></div>— Kevin Rothrock (<a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa?ref_src=embed">@kevinrothrock.me</a>) <a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">November 23, 2024 at 1:21 AM</a></blockquote>
<h3>Open-source Web Dev</h3>
<blockquote data-bluesky-uri="at://did:plc:2gkh62xvzokhlf6li4ol3b3d/app.bsky.feed.post/3lbwwdqztic2s" data-bluesky-cid="bafyreie2rhlpgr4rdrird346s7g77a2txztot2yelri5pcdzgdekzd4wuu"><div lang="en"><p>We have 6% of the followers here compared to the 100k in X. The vite 6.0 announcement in bluesky already got half the reposts and a third of the likes. And most of the comments and quotes from OSS maintainers happened here. I don't know about other communities, but OSS web dev is a bluesky game now.</p><p><a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">[image or embed]</a></p></div>— patak (<a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d?ref_src=embed">@patak.dev</a>) <a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">November 27, 2024 at 8:01 AM</a></blockquote>
<h3>Democracy Docket</h3>
<blockquote data-bluesky-uri="at://did:plc:pjiafkey2cokiupsxpswqlk7/app.bsky.feed.post/3lbwnypsssc2s" data-bluesky-cid="bafyreigqm6acubxf6hykcdxhjscpp5yynlbr5ni6eincnewe5dutubqmfm"><p lang="en">Traffic from Bluesky to @democracydocket.com is surging while X is falling and Threads remains largely irrelevant. This is powering rapid growth of both free subscribers and paid members.</p>— Marc Elias (<a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7?ref_src=embed">@marcelias.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7/post/3lbwnypsssc2s?ref_src=embed">November 27, 2024 at 5:31 AM</a></blockquote>
<p>Join us: <a href="https://bsky.app/download">bsky.app/download</a>. Publishers, you can find our <a href="https://bsky.social/about/blog/press-faq">press FAQ here</a>.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geometric line-art of Wacław Szpakowski (2017) (234 pts)]]></title>
            <link>https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</link>
            <guid>42277850</guid>
            <pubDate>Fri, 29 Nov 2024 22:54:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/">https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</a>, See on <a href="https://news.ycombinator.com/item?id=42277850">Hacker News</a></p>
Couldn't get https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Deterioration of Google (203 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</link>
            <guid>42277673</guid>
            <pubDate>Fri, 29 Nov 2024 22:26:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2024/the-deterioration-of-google/">https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42277673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
	



<p><time datetime="2024-11-07">7 November 2024</time> – <em>Baldur
		Bjarnason</em></p>
<ul>
		<li><a href="https://www.baldurbjarnason.com/tags/google/">google</a></li>
</ul>








<p>This post announcing the closure of Giant Freakin Robot set me on a bit of a journey into the state of Google.</p>
<p><a href="https://www.giantfreakinrobot.com/ent/independent-ends.html">“The End Of Independent Publishing And Giant Freakin Robot”</a></p>
<blockquote>
<p>GIANT FREAKIN ROBOT isn’t the first site to shut down. Hundreds of independent publishers have shuttered in the last two years, and thousands more are on the way. I’m in communication with dozens of other independents focused on different topics. None of them are doing well. They all expect to be out of business soon.</p>
<p>I went to Google directly, on their behalf, and told them about the problem. The message I walked away with, was that they do not care. Our industry is done.</p>
</blockquote>
<p>What I discovered was that web media companies can’t count on any of the traffic coming from Google or Facebook any more. Very few, even one that are frugally run, are capable of surviving on the traffic that remains.</p>
<p>The problem doesn’t seem limited to a few sites. What seems to have happened is that Google tried to “fix” their search engine results by using machine learning to rank sites.</p>
<p>From <a href="https://www.mariehaynes.com/what-we-can-learn-from-the-google-creators-summit-for-hcu-impacted-sites/"><em>What we can learn from the Google creators summit for HCU impacted sites</em></a>:</p>
<blockquote>
<p>We know that the helpful content system was a machine learning (AI) system.  Machine learning systems are trained by seeing good examples and bad examples. They then work to figure out the characteristics they can consider and how much weight to give them so as to predict whether an unseen example is a good one or a bad one.</p>
</blockquote>
<p>But this does not seem to be working properly. Anybody who has used Google for search over the past year knows that it lets a lot of LLM-generated spam through and blogs and small sites have basically disappeared from most results. Those sites have effectively been delisted by the machine learning model and nobody seems to know exactly why.</p>
<p>Some have been hit hard. From <a href="https://mike-hardaker.com/f/i-drank-the-kool-aid-at-the-2024-google-web-creator-summit/">“I Drank the Kool-Aid at the 2024 Google Web Creator Summit”</a>:</p>
<blockquote>
<p>I’m 44 years old, luckily I don’t have a mortgage, I barely getting by, I’m eating at the food bank now, I had grossed $250,000 last year and I just don’t know where to go from here my traffic is down 97%</p>
</blockquote>
<p>Even if your first reaction might be “good riddance” these are all people whose work Google <em>wants</em> to see in the search engine results. That’s why they were invited to the summit.</p>
<p>An exchange on Twitter, which I usually avoid but is where this crowd seems to still be congregating, describing a scene from the summit <a href="https://x.com/CharlestonCraft/status/1851643761375277103">captured the situation perfectly</a>:</p>
<blockquote>
<p>Lily Ray: I’m still stuck on “your content wasn’t the issue.” What?</p>
<p>Morgan: So, so many times they said this. Literally Danny hand picked us because we all create helpful and satisfying content. They just cannot get the algorithm to understand that. They are actively doing query debugging based on examples sent by our group.</p>
<p>Morgan: Literally Danny said he sat with an engineer team with examples of people in the room and said why aren’t they showing up and they did their “debugging process” and couldn’t figure it out.</p>
<p>Morgan: the robots are winning.</p>
</blockquote>
<p>The “algorithm” seems to have become a black box even Google engineers can’t figure out</p>
<p>The fact that over a year ago ML experts at Google (El-Mahdi El-Mhamdi at least, if I recall correctly) who have since left warned that LLMs should be avoided because they made products chaotic and hard to control seems relevant.</p>
<p>As is the fact that around the same time others also warned that one common consequence of mass layoffs is they tend to turn internal systems into black boxes because everybody with a deep understanding of them has left.</p>
<p>But, fundamentally, what lets this deterioration continue is that it does not affect business outcomes at Google in any way. They are a monopoly and monopolies are extremely effective at capturing whatever value happens in their vicinity, even if the utility of their products declines.</p>
<p>And, given the political situation in the US, the tech industry monopolies and oligopolies are only going to be strengthened and the actual productivity, performance, and effectiveness of their products will be less and less important to them.</p>
<p>Because they know that most of us will not have any real alternative.</p>

		<ul>
				<li>
					
				</li><li>
				
				</li>
		</ul>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brits are scrolling away from X and aren't that interested in AI (129 pts)]]></title>
            <link>https://www.theregister.com/2024/11/29/ofcom_online_nation/</link>
            <guid>42277089</guid>
            <pubDate>Fri, 29 Nov 2024 21:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/11/29/ofcom_online_nation/">https://www.theregister.com/2024/11/29/ofcom_online_nation/</a>, See on <a href="https://news.ycombinator.com/item?id=42277089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Usage of Elon Musk's X social media platform is declining in the UK, and adult Brits aren't particularly interested in generative AI tools.</p>
<p>That's according to Ofcom's <a target="_blank" rel="nofollow" href="https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/">Online Nation</a> report, an annual publication looking at what UK citizens do during their hours online and how much time they spend glued to gadgets.</p>
<p>According to the comms regulator, adults spent an average of four hours 20 minutes a day online in May 2024 across tablets, smartphones, and computers.</p>

    

<p>The report also shows that the total UK adult reach in a month of X (formerly Twitter) continues to decline. For May 2022, Ofcom measured X's adult reach at 26.8 million. In 2023, it was 24 million. By May 2024, it had fallen to 22.1 million, a year-on-year decline of 8 percent.</p>

        


        

<p>X suffered the most significant fall in total adult use of all social media sites, which also resulted in it sliding down the rankings to sixth, behind Reddit, which registered the largest year-on-year growth – 47 percent – taking May's figure to 22.9 million.</p>
<p><a target="_blank" rel="nofollow" href="https://www.theregister.com/2024/11/20/x_marks_the_spot_for/">Several changes</a> have been made at X in recent months, but the platform has continued on a downward trajectory in Britain and Northern Ireland.</p>

        

<p>Ofcom's figures align with other research on X. While still hugely popular, the service has been shedding users over the last two years. UK-based <a target="_blank" rel="nofollow" href="https://soax.com/research/twitter-active-users">SOAX reported</a> an 8.83 percent decrease in monthly active users since 2022 and 5.14 percent since 2023. This is despite global growth in social media users, according to <a target="_blank" rel="nofollow" href="https://www.statista.com/statistics/278414/number-of-worldwide-social-network-users/">Statista</a>.</p>
<p>The decline co-incides with a change of ownership after Musk bought the business for <a target="_blank" href="https://www.theregister.com/2022/10/27/musk_sink_twitter/">$44 billion in October 2022</a>, and it became a doyen of free speech - whether that includes more hateful or more honest content depends on the users' perspective.</p>
<h3>AI – huh – what is good for? Perhaps a bit of searching?</h3>
<p>Ofcom also found that Google's search engine dominance in the UK also slipped slightly over the year, with 83 percent of online adults visiting in May 2024 compared to 86 percent the year before. Microsoft's Bing fell further, down to 39 percent from 46 percent.</p>
<p>Microsoft and Google have invested heavily in AI, with generative AI content turning up in the search results from their respective services. However, ChatGPT remains the most popular GenAI tool. Microsoft's Copilot came second, with 15 percent of UK internet users aged 16 and over having used it. Despite being only recently introduced, Google's Gemini was ranked fourth, with 10 percent of users.</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/21/online_safety_act/">Now Online Safety Act is law, UK has 'priorities' – but still won't explain 'spy clause'</a></li>

<li><a href="https://www.theregister.com/2024/11/13/ofcom_mmwave_spectrum_auction/">Brit telcos to clash in high-speed mmWave spectrum showdown next year</a></li>

<li><a href="https://www.theregister.com/2024/11/12/cma_vodafone_three_remedies/">Watchdog reluctantly blesses Vodafone-Three merger – with strings attached</a></li>

<li><a href="https://www.theregister.com/2024/11/11/australia_social_media_ban/">Australia tells tots: No TikTok till you're 16... or X, Instagram and Facebook</a></li>
</ul>
<p>The figures also show sluggish AI adoption. More than half of adults in the survey had yet to use GenAI, with 38 percent declaring they were "not interested" and 35 percent saying they "did not need to."</p>
<p>Forty-eight percent of adults had used the technology, but only "for fun." Forty-three percent had used one for work, and the most popular activity was finding content. However, less than one in five (18 percent) trusted the output.</p>
<p>The numbers are slightly different for the under-16s. Fifty-four percent said they had used a GenAI tool, with more than half (53 percent) of those saying they had used it for schoolwork. Sixty-three percent reported using a GenAI tool "for fun."</p>

        

<p>The distribution across age groups shows that AI is making more significant inroads into younger demographics than older. However, it appears that investors may have to wait a little longer before AI bets start paying off. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Platform for senior devs to learn other programming languages? (101 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42276995</link>
            <guid>42276995</guid>
            <pubDate>Fri, 29 Nov 2024 20:49:28 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42276995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42279097"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279097" href="https://news.ycombinator.com/vote?id=42279097&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>These days my main problem when learning is coming to terms with the development environment.</p><p>Python, how do I install and work with venvs? What is poetry and why is it better?</p><p>Scala, what is sbt and how do I make it work in Intellij?</p><p>Things I have learned under way, but still more of a headache than the actual language, since most ideas there are recognizable. And problems in the dev env can make you get stuck for several hours.</p><p>Docker helps a bit as an abstraction, but not all the way to the development environment.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280135"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42280135" href="https://news.ycombinator.com/vote?id=42280135&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I couldn’t agree more. And once you have mastered or at least come to terms with the development environment, eventually you must learn how to deploy. That’s also a minefield.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42280534" href="https://news.ycombinator.com/vote?id=42280534&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The worst is js development.</p><p>You need thousands of tools and there always exists 3 alternatives.</p><p>Js/ts as a language is the smallest problem.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281500"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42281500" href="https://news.ycombinator.com/vote?id=42281500&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I think the worst is Java/Kotlin. Gradle is a nightmare and I just refuse to spend my time learning it. I just can’t.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280657"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280657" href="https://news.ycombinator.com/vote?id=42280657&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>It’s a newcomer confusion vs old-timer habit. You’ll feel the same in C, python, etc if you never seen these. And vice versa in any direction.</p><p>Edit: But I absolutely agree that $subj platform should focus on that, not even on the language. A language can be learned in one evening on a “fiddle” site, no platform required.</p><p>Personally, when I become interested in another language, all I want is a page of common snippets or a cheatsheet to get the feel of syntax, and then how to make and deploy a non-toy project with all the usual libs and tools attached.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281325"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42281325" href="https://news.ycombinator.com/vote?id=42281325&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I think the biggest problem is that js is way faster charging than almost every other language.</p><p>I was used to use vue, there was webpack now it's vite or nextjs, some tools are build on top of others like nextjs on webpack and vite on esbuild.</p><p>If you stop working 2 years in js your tools will completely change.</p><p>E.g. java has maven and more and more use graddle, but it's way slower change.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280685"><td></td></tr>
                <tr id="42280751"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42280751" href="https://news.ycombinator.com/vote?id=42280751&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>It’s a yet another facebook shaped opportunity though. The hardest part is not to collect and systematize information, but to become distinguishable from a mountain of shitty blogspam that google agrees to promote for financial reasons.</p><p>For meta, I’d say our issue here is not the lack of platforms or manuals, but that we simply don’t have a decent search engine, because we don’t have a decent internet economy model. Our models and tools are indecent and there’s no help.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280886"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42280886" href="https://news.ycombinator.com/vote?id=42280886&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>What you describe is exactly the challenge and opportunity to overcome.</p><p>Why should I have to rely on Google/stack overflow/chatgpt to set up my environment?</p></div></td></tr>
        </tbody></table></td></tr>
                                          <tr id="42277193"><td></td></tr>
                <tr id="42277199"><td></td></tr>
                  <tr id="42277522"><td></td></tr>
                <tr id="42278482"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278482" href="https://news.ycombinator.com/vote?id=42278482&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Would love the equivalent of this but before applying practical problem solving. For instance in go you learn to leverage goroutines and channels. In another language it would be threads. Common design patterns etc. Gotcha’s of the language. In Python you use exception handling very commonly, in golang you’re using a special return value of an error type. JavaScript you’re using a ton of anonymous function closures. Async vs await.</p><p>I keep wanting to build this mega doc site to teach more than just “what are scalar types in this language” and more of how to apply it in idiomatic ways.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280394"><td></td></tr>
            <tr id="42278963"><td></td></tr>
                <tr id="42280134"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42280134" href="https://news.ycombinator.com/vote?id=42280134&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Devdocs is just a collection of official documentations. GP wants a collection of documentation that explains comparative, idiomatic problem solving in each language. How are they even remotely similar?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280334"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42280334" href="https://news.ycombinator.com/vote?id=42280334&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>sure but the comment two steps up mentions wanting to build a site, devdocs exists and could host that information they want to compile and build.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42277724"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277724" href="https://news.ycombinator.com/vote?id=42277724&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>This is excellent. I checked Julia which is my main language and all essentials are there. Looked up to Zig, F#, Go all accessible expositions and makes it easy to get a good taste before looking into the manuals.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278939"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278939" href="https://news.ycombinator.com/vote?id=42278939&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Alternatively rewrite some non trivial work of your own from X to Y language. You'll learn more than making frivolous programs about made up stuff.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279727"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279727" href="https://news.ycombinator.com/vote?id=42279727&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Any time I start using a new language I always start with "Hello world" and working a few simple example programs to get my head around the syntax, idioms, and common data structures. But yes, don't spend a ton of time on this, as soon as you have a sense that you know what to do, start tackling actual work.</p><p>If the languages are at all commonplace, having an AI convert a program from language X to language Y might speed you along as well. No guarantees it will be perfect but it will probably get you in the ballpark.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280094"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280094" href="https://news.ycombinator.com/vote?id=42280094&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I try not to use AI when learning a new language. I don't want to rely on premade answers to my problem. I prefer using the language's documentation and some light SO searching so I can figure it out on my own. AI is the last resort for me when learning something new.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280407"><td></td></tr>
                              <tr id="42277920"><td></td></tr>
            <tr id="42278729"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278729" href="https://news.ycombinator.com/vote?id=42278729&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>On a related note, I found going through "The Raytracer Challenge" helped me to re-familiarise with C++ (after 20 years). Note that the book isn't language-specific.  Installing clangd (and getting it to work with my text editor) really helped too, to speed up the edit-fix loop.  Perhaps going through a book like that is a good way to challenge yourself to learn enough of a language and its tools.  The test-driven format of the book was good to make sure that my code is correct at every stage.</p><p><a href="https://pragprog.com/titles/jbtracer/the-ray-tracer-challenge/" rel="nofollow">https://pragprog.com/titles/jbtracer/the-ray-tracer-challeng...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278400"><td></td></tr>
                <tr id="42279827"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279827" href="https://news.ycombinator.com/vote?id=42279827&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I would second this.  I have pretty extensive experience in a few python-like languages, and had written a few hundred lines of python over the years, but had never had a full-time job writing it.  I had an upcoming job working on a python codebase.  I found ExecuteProgram to be a pretty great as a way to bone up on intermediate python syntax, idioms, and standard library so I could minimize the first few weeks of "How do I do [common thing I know in 5 other languages] in python?"</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277603"><td></td></tr>
                <tr id="42277804"><td></td></tr>
                  <tr id="42277701"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42277701" href="https://news.ycombinator.com/vote?id=42277701&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>What’s the difference between how a senior and non-senior learn that would warrant a unique platform for each?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42278128"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278128" href="https://news.ycombinator.com/vote?id=42278128&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I’m going to go against the flow and say nothing. I think the primary reason you see seniors looking for senior focused platforms is because almost all the learning content is terrible. Seniors will spot this sooner than juniors. I’ve worked as an external examiner for CS students for a decade and the stuff they put themselves through to avoid reading official docs is amazing. They’ll literally sit through 50 hours of video of what is essentially two a4 pages of “example how-to”.</p><p>Why a senior wouldn’t just head directly to the documentation for a programming language or the equivalent to “The C++ Programming Language” is a different question though. Learning a new language is extremely easy, it’s learning how the compiler, runtime and so on which is hard. You’ll very rarely find that outside of official docs or books written by extremely knowledgeable people.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279582"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42279582" href="https://news.ycombinator.com/vote?id=42279582&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I 100% agree with your take and suspect most actual "seniors" do as well.</p><p>Eventually most seniors should come to the realization that expecting there to be a "senior" oriented platform is unrealistic for a variety of reasons (mostly, because the exercise based nature of platform learning in the beginner sense just isn't the sort of thing you need to learn to become senior level in a language and isn't super useful to seniors coming from other languages...).</p><p>A real senior that is really trying to learn a new language or ecosystem to a reasonable amount of competence should start with the docs and with a small (but sizeable, enough to have to learn the languages tooling and whatnot) project.</p><p>I shouldn't even comment on this, but if you expect there to be video tutorials for the kind of thing you are trying to learn, then maybe you have experienced some form of title inflation. Eventually, people need to learn to read the (f'ing) manual, and I hate to say it like that because it's infamously toxic when inappropriately told to beginners as advice, but it's the truth for somebody that calls themselves a senior.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280322"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280322" href="https://news.ycombinator.com/vote?id=42280322&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>“50 hours of video” seems especially true for cloud certificates. Figured maybe I should finally pick up an AWS cloud cert or two and realised that video courses tend to be 40-50 hours per certificate. If you’ve already worked with AWS, or any cloud provider really, a lot of that content looks tedious.</p><p>In the end I bought a “course” that’s 6 practice exams with high quality questions and explanations of each answer. For AWS it’s been a nice approach, so far anyway, because the docs are truly vast and I probably wouldn’t have thought to read the docs for Snowmobile, which I don’t use day to day.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280437"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280437" href="https://news.ycombinator.com/vote?id=42280437&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I think the main issue with most documentation is that everything is treated equally, and often critical details get a passing mention, so it's helpful to have  focused course material that can give some indication of priority and a heads up for the tricky parts.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280588"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42280588" href="https://news.ycombinator.com/vote?id=42280588&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The challenge with this, and I agree with you, is that I don’t think you’ll find many people capable of creating such a course being in the course creation business. I suspect almost no one would be interested in doing it. The only financial motivation would be to go the consultancy route like Uncle Bob, and I’m not sure who would have any sort of motivation to do it as a hobby project. You’d be more likely to find those people contributing to the actual programming language in some way.</p><p>As I see it the programming teaching industry, or whatever you might call it, is similar to other self-help industries where people who are good at marketing sell you empty calories. Even if you created an in dept course on something, you would probably have an issue distributing it in the vast ocean of courses.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278174"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42278174" href="https://news.ycombinator.com/vote?id=42278174&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>All your reasoning is agreeable but I disagree with the foremost conclusion</p><p>&gt; I’m going to go against the flow and say nothing.</p><p>Whether we're talking about the actual language or the surrounding tooling and ecosystem, very few language and ecosystem experiences are actually different. As a result you're often mapping needs that you already satisfied and can explicitly state to another language. Someone who has already learned their n-th language looks at learning very differently.</p><p>This also makes a seasoned learner vastly more capable of extracting value from a friend or colleague who is willing to steer the learning experience.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278391"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42278391" href="https://news.ycombinator.com/vote?id=42278391&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>That's how I've learned Python, so far. Between that and, writing my own code, and looking at other's code, Ive picked up quite a bit (not an expert but I think I'm doing OK).</p><p>The easy part is the language, the difficult part is learning to do things the Pythonic way.</p><p>Of course, I have to allow for the Dunning-Kreuger effect.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279619"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42279619" href="https://news.ycombinator.com/vote?id=42279619&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>This doesn't sound like Dunning-Kreuger to me.</p><p>You sound well aware of the fact that being able to put out working python code doesn't necessarily mean you fully understand all of the best practices and idioms that the particular community uses, and that's okay. You are aware of your weakness.</p><p>If you were stuck in "tutorial hell" but thought you knew the language, then maybe that would be Dunning-Kreuger. Or if you were unaware of your not writing idiomatic code due to coming from a different language and being new.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42277765"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277765" href="https://news.ycombinator.com/vote?id=42277765&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Well a senior developer would be assumed to share a certain common understanding of concepts and terms that a more junior developer might not. When teaching anything one of the most important parts is ta gauge your pupils and determine whether they need more or less information to keep the topic interesting while not making it impossible to follow along. Since written or otherwise pre-recorded teaching materials aren't afforded the luxury of interacting with their pupils they must choose ahead of time what level they are aimed at. And since a senior in any field would be able to follow along with materials meant for the junior, albeit at a slower and less interesting pace, but not the other way around they tend to err on the side of over-explanation. A platform for teaching senior developers would therefore allow a more engaging and time saving experience for those able to consume it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278113"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278113" href="https://news.ycombinator.com/vote?id=42278113&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Senior doesn't need to learn about loops, ifs and so on</p><p>For example when learning C++ while being proficient at C# I found useful this blog: <a href="https://www.jacksondunstan.com/articles/5530" rel="nofollow">https://www.jacksondunstan.com/articles/5530</a></p><p>"C++ For C# Developers: Part 1 – Introduction"</p><p>Author compares features between C# and C++ and shows what is similar, the same, different, non-existent, etc.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281522"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42281522" href="https://news.ycombinator.com/vote?id=42281522&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>These things are taught in the first semester of a CS degree and part of the interview process for an entry-level position.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277723"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277723" href="https://news.ycombinator.com/vote?id=42277723&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Another programming language as reference. I can learn a new language really easily this way, but the first was really hard - it was so unlike anything i had ever done before.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279192"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42279192" href="https://news.ycombinator.com/vote?id=42279192&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>“Writing Fortran in Lisp” should not be disregarded. There’s a lot of value of having hands on exposure and success with common, even if not idiomatic, concepts.</p><p>Ye Olde “write once, throw it away” concept. Using prior language knowledge can make the first steps much smaller as you learn not just the new language, but environment and tools.</p><p>This can give you a quick, solid foundation with which to leverage learning newer ideas and idioms of the new system.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277932"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277932" href="https://news.ycombinator.com/vote?id=42277932&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The essence of being senior, I feel is "I have made the mistake you are about to make". This echoes in language learning. When I was learning Go I could easily pinpoint what language design decisions were made because of lessons learned from this language or that. (I do not want to suggest schismogenesis applies to programming languages but ... it kinda sorta does?) Teaching with this in mind needs a very different curriculum.</p><p>Also, basic exercises are boring because we did them ten thousand and one times already just with slightly different syntax.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278844"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278844" href="https://news.ycombinator.com/vote?id=42278844&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Learning a new syntax takes a day or two, a week or two at the most. Having a site or product that helps you with that doesn't seem important, at least to me. The hard part about learning a new language is learning <i>how</i> to use it, not its syntax. Learning how to use it requires working with it, and for a long time, somewhere in the 3 to 10 year range to really become an expert. You can't <i>learn</i> experience quickly using any product or YouTube video.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42279806"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279806" href="https://news.ycombinator.com/vote?id=42279806&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>My old boss gave me some good pointers: find Koans. Ruby Koans, Kotlin Koans, there's probably a Koan for your language. It'll help you wrap your head around the basics of the language, and sometimes they'll even help you set up the development environment, which some people have alluded to being difficult.</p><p>From there, it's just ... using it. Making lots and lots of mistakes.</p><p>I didn't start really learning Typescript until it was a very real obligation for me, and my style of programming and the reasons for it have definitely changed over the last year as a reflection.</p><p>Accept that this sort of change is going to happen and that it's natural and even a good thing. It's okay to be new at things again and to make mistakes :)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42279536"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279536" href="https://news.ycombinator.com/vote?id=42279536&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>As long as you know basic programming, the best way to learn a new language is to just jump into an existing project or start a new one from scratch. Classes and tutorials will get you nowhere.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280402"><td></td></tr>
            <tr id="42280384"><td></td></tr>
            <tr id="42278894"><td></td></tr>
            <tr id="42279530"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279530" href="https://news.ycombinator.com/vote?id=42279530&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>This is a bad question cause it comes off as judgmental and everything...</p><p>But what do you think you are getting out of a "platform" when it comes to learning a language?</p><p>I agree with keyle that you'll learn more working on a real project than doing a platform curriculum that is usually designed around beginners.</p><p>Just my personal hot take. I like exercise I suppose if that's the sort of thing you really think would be helpful.</p><p>The only reason I'm giving you this answer is cause you said explicitly "for senior devs". I don't really know any senior devs personally (that would admit to) using "platforms" or exercises to learn new languages. For me, I open up the docs and start writing a project, and I think that usually gets the job done learning a new language a bit faster.</p><p>Most platforms are way too beginner oriented, and you'll rarely get anything that requires more than a small amount of code...it's tough to learn a language very well until you have more than say 1000 lines and are seeing how the tooling and modules and whatnot really work on a realistic size of project...</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279904"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279904" href="https://news.ycombinator.com/vote?id=42279904&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The usefulness of beginner materials really depends on how big of a jump it is, no?</p><p>Going from writing firmware in C &amp; asm for 30 years to Haskell would likely require more than just documentation.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278017"><td></td></tr>
            <tr id="42279548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279548" href="https://news.ycombinator.com/vote?id=42279548&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Honestly, I find ChatGPT excellent for this. There are two basic things I usually ask it for:</p><p>1. First, I ask it to give me a conceptual overview, going through the main features of a language I know well and then asking for the equivalent in the new language. I also ask it for specifics/features in the new language that aren't present in the language I know well.</p><p>2. If I have specific questions, I'll write a code snippet in a language I know well and ask it to translate it to the other language. I might also ask it for "library equivalents", e.g. if there is some specific library that is the "standard" for doing something in one language, I'll ask what is the standard in the other language.</p><p>Related example: I <i>suck</i> at shell scripting because there is so much esoteric shit in it, so I used to just write short scripts in JavaScript and run them in Node because I'm so much more comfortable with JS and Node. Now, though, I'll just ask ChatGPT to write the script for me. The code isn't always 100% bug free, but I understand shell scripting well enough to usually fix any bugs. Also, if there is something I don't understand (e.g. ${VAR_NAME##*/} was a new one for me today), ChatGPT explains it well.</p><p>If you haven't tried it, I strongly recommend using ChatGPT (or Claude, etc.) for learning a new programming language.</p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking the 4Chan CAPTCHA (408 pts)]]></title>
            <link>https://www.nullpt.rs/breaking-the-4chan-captcha</link>
            <guid>42276865</guid>
            <pubDate>Fri, 29 Nov 2024 20:32:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nullpt.rs/breaking-the-4chan-captcha">https://www.nullpt.rs/breaking-the-4chan-captcha</a>, See on <a href="https://news.ycombinator.com/item?id=42276865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Breaking the 4Chan CAPTCHA</span></p><h2 id="introduction">Introduction</h2>
<p>This project was entered into as a learning experience, to enhance my knowledge of machine learning, as well as TensorFlow specifically. At the end, I wanted to have a trained machine learning model that runs in the browser to reliably (at least 80% accuracy, &gt;90% preferred) solve the 4Chan CAPTCHA. These goals were achieved - let's talk about how I got there!</p>
<p>If you'd like to follow along with the code references, I have made the code public on GitHub <a href="https://github.com/AppleDash/4chan-captcha-playground">here</a>.</p>
<h2 id="terminology">Terminology</h2>
<ul>
<li><strong>CAPTCHA</strong>: A challenge-response test to determine whether or not a computer or website user is a human. The acronym stands for Completely Automated Public Turing test to tell Computers and Humans Apart.</li>
<li><strong>4Chan</strong>: A public, anonymous imageboard website with discussion boards on various topics. These boards are used for posting images and text discussions. Filling out a CAPTCHA is required before every post or reply.</li>
<li><strong>Normal CAPTCHA</strong>: The simplest form of the 4Chan CAPTCHA, that consists of an image with 5 or 6 alphanumeric characters. The user must read and correctly enter all of the characters in a field in order to make a post on 4Chan.</li>
<li><strong>Slider CAPTCHA</strong>: A more complex form of the 4Chan CAPTCHA, that consists of a background image with random-looking character fragments, and a foreground image with transparent "holes" or "windows" in it. A slider in the browser CAPTCHA form must be moved to correctly align the two images in order to see the CAPTCHA text.</li>
</ul>
<h2 id="getting-the-data">Getting the Data</h2>
<p>I've heard many times that the hardest part of any machine learning problem is getting the data to train your model. This assertion was definitely pertinent here, for several reasons. There's two parts to this problem: Getting the CAPTCHAs, and getting solutions to those CAPTCHAs.</p>
<h3 id="scraping-captchas-from-4chan">Scraping CAPTCHAs from 4Chan</h3>
<p>After looking at the HTTP requests in the browser console when requesting a new CAPTCHA, I found that it makes a request to <code>https://sys.4chan.org/captcha?framed=1&amp;board={board}</code>, where <code>{board}</code> is the name of the board we're trying to post on. The response is an HTML document that contains a script tag with a <code>window.parent.postMessage()</code> call with some JSON. On a hunch, I tried to remove the <code>framed=1</code> parameter, and found that this causes it to just spit out the raw JSON. That should be easier to work with. The JSON looks like this:</p>
<pre><code><span>{</span>
    <span>"challenge"</span><span>:</span> <span>"[some long and random string here]"</span><span>,</span>
    <span>"ttl"</span><span>:</span> <span>120</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>5</span><span>,</span>
    <span>"img"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"img_width"</span><span>:</span> <span>300</span><span>,</span>
    <span>"img_height"</span><span>:</span> <span>80</span><span>,</span>
    <span>"bg"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"bg_width"</span><span>:</span> <span>349</span>
<span>}</span>
</code></pre>
<p>Some of these keys are pretty obvious. <code>ttl</code> and <code>cd</code> are the least obvious to me. I know from experience that the 4Chan CAPTCHA only displays for about 2 minutes before it expires and you have to request a new one, so that's what <code>ttl</code> must be. But what about <code>cd</code>? Let's make another request, shortly after the first one:</p>
<pre><code><span>{</span>
    <span>"error"</span><span>:</span> <span>"You have to wait a while before doing this again"</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>23</span>
<span>}</span>
</code></pre>
<p>If I keep making the same request, the <code>cd</code> parameter steadily decreases, at a rate of about 1 per second. Alright, so this is how long you have to wait before requesting a new CAPTCHA. <code>cd</code> likely stands for "cooldown".</p>
<p>If I wait the 23 seconds, and then make another request, I get a successful response, but this time, the <code>cd</code> is 32. We have to wait longer every time. After some experimentation with a script, it looks like the first few requests can be made every 5 seconds, then it increments to 8, and then continues to roughly double until it's capped at 280 seconds, and stays there.</p>
<p>Additionally, once you've hit the 280 second timers, the CAPTCHA gets somewhat harder. It looks like this:</p>
<figure><img alt="Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75"><figcaption>Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image</figcaption></figure>
<p>instead of this:</p>
<figure><img alt="Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75"><figcaption>Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image</figcaption></figure>
<p>So, there's some throttling in place. The data also gets of lower (but still usable) quality if you make too many requests.</p>
<p>Something I will briefly touch on is that the user has to pass a Cloudflare Turnstile challenge to even request a CAPTCHA in the first place. As a result, simply using many proxies with a naive script is not realistic, without first passing the Cloudflare Turnstile and saving the relevant cookies. When I was scraping CAPTCHAs with the script I wrote for this, I simply copied the Cloudflare cookies from my browser, and manually replaced them whenever they expired.</p>
<p>I scraped several hundred CAPTCHAs in this manner - not enough to train the model, but it's at least a start. This still leaves us with a problem, though. We have all these CAPTCHAs, but we don't have the solutions. I could fill them out manually, but instead, let's try something else.</p>
<h3 id="getting-the-solutions">Getting the Solutions</h3>
<p>Or, <em>Humans are bad at solving the 4Chan CAPTCHA</em>.</p>
<p>A recurring theme in this project has been "this is easy for a computer to do, but hard for a human to do." Many users find the "slider" style CAPTCHAs incredibly frustrating, but I've had a 100% success rate in aligning them with the heuristic script I made (<code>trainer/captcha_aligner.py</code>). The 4Chan CAPTCHAs in general are widely considered by users of the site to be frustrating to solve. But, surely, for people who solve CAPTCHAs <em>for a living</em>, it shouldn't be an insurmountable challenge, right?</p>
<p>I coded a quick script (seen in the project under <code>trainer/labeler.py</code>) to send the CAPTCHAs to <a href="https://anti-captcha.com/">a commercial CAPTCHA solving service</a>, where real humans would solve the CAPTCHAs for me for a nominal fee. Writing the script was simple, but actually employing it was an exercise in frustration. I sent a couple dozen CAPTCHAs to the service, and nearly all of them came back with one or more characters incorrectly solved.</p>
<p>The service has a feature called "100% Recognition", which allowed me to specify that all my requests be first sent to <code>n</code> workers, and if <code>x</code> of those workers don't return the same solution, then send them to up to <code>y</code> more workers. It would only return an error after sending the CAPTCHAs to <code>n + y</code> workers and not getting at least <code>x</code> solutions the same. I configured my account with the values <code>n = 2</code>, <code>x = 2</code>, and <code>y = 3</code> - that is, initially send the CAPTCHA to 2 workers, and if they don't both agree, then send them to up to 3 additional workers until two of them agree, or none of them agree.</p>
<p>This improved the situation somewhat. About 80% of the CAPTCHAs were now being successfully solved, and after reviewing the results, 90% of those were correct, but about 10% had errors in them, which indicated that multiple workers were making the same mistakes. This was still less than ideal.</p>
<p><strong>A quick aside: What if I just ask someone I know to be reliable to do it for me, or even do it myself?</strong> I explored both of these approaches. I wrote a quick user script that saved the CAPTCHA image and the solution text, and just sat there requesting and solving CAPTCHAs in my free time. I also asked a good friend of mine to do the same. This yielded several hundred images, which I did add to the training set, but in the end this approach was abandoned because we still ran into the throttling problem, and the problem of the CAPTCHAs getting harder (and eventually, near-impossible) if you request too many of them.</p>
<p>I begun to wonder if there was a different way to look at this altogether. What if we didn't need to scrape CAPTCHAs and have them solved by humans?</p>
<h3 id="generating-synthetic-data">Generating Synthetic Data</h3>
<p>What if we could generate our own 4Chan CAPTCHAs? 4Chan, and the CAPTCHA it uses, are not open source, so I couldn't literally run the same code locally. But I could definitely approximate it.</p>
<p>The 4Chan CAPTCHA can be dissected into two main parts. The background, which looks like this:</p>
<figure><img alt="4Chan CAPTCHA background with the characters removed, leaving only general noise over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA background with the characters removed, leaving only general noise over the image</figcaption></figure>
<p>and the characters, which look like this:</p>
<figure><img alt="4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion</figcaption></figure>
<p>We don't need to generate our own backgrounds from scratch. It's a relatively simple computer vision problem to take an image like the 4Chan CAPTCHA, and find all of the large <a href="https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html">contours</a> in the image, which represent the characters, and remove them. This leaves only the noisy background, as seen in the image above, which was generated using this algorithm.</p>
<p>Next, we need to isolate a decent number of characters, and label them with their values. If this was trivial to do with an algorithmic script, well, we wouldn't be here, because solving the CAPTCHA would also be trivial to do with an algorithmic script :) It's pretty easy to do this by hand, though, and that's what I settled on doing. It was annoying. I tagged the characters with <a href="https://github.com/microsoft/VoTT">VoTT</a> and then extracted them with a quick and dirty script, which also postprocessed them to make sure it was only the characters in the images. I ended up with 50-150 isolated images of each character. It was during this stage of the project that I realized the 4Chan CAPTCHA incoudes only the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y - likely done to avoid ambiguity.</p>
<p>Now we just have to put it all together. When extracting the digits, I observed a few patterns in how the characters are usually clustered or spread apart, and so I wrote my script to assemble images with backgrounds according to these formulas. And, of course, since the input character images are labelled, I can easily label the generated synthetic CAPTCHAs with their solutions.</p>
<h2 id="creating-the-model">Creating the Model</h2>
<p>Now we've got the data, it's time to train the model. I assembled a model architecture based on some research, after reading several different articles on CAPTCHA solving using neural networks.
I settled on an <abbr title="Long Short-Term Memory">LSTM</abbr> <abbr title="Convolutional Neural Network">CNN</abbr> architecture with 3 convolutional/max-pooling layers and 2 LSTM layers.
A fourth convolutional layer was also tested, but it did not improve performance.
CTC encoding of the CAPTCHA text was used, because the output was of variable length (either 5 or 6 characters).
I built the model using <a href="https://keras.io/">Keras</a> on top of <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<h3 id="processing-the-data">Processing the data</h3>
<p>The input to the model was a mix of pre-aligned slider CAPTCHAs, normal CAPTCHAs, and synthetic CAPTCHAs.
The training script took care of ensuring they were 300x80 pixels and converted to pure black-and-white.</p>
<h4 id="always-read-the-docs">Always read the docs</h4>
<p><em>The arguments might not be in the order you expect.</em></p>
<p>One of the important steps in my data processing pipeline was making sure that all the CAPTCHA images are exactly 300x80 pixels.
Some images from the dataset, namely the older aligned "slider" CAPTCHAs, don't match this resolution / aspect ratio.
I could just fix the training data, but it's better in the end to make the training script able to cope with any data I throw at it.</p>
<p>I used <code>tf.image.resize()</code> for this. <a href="https://www.tensorflow.org/api_docs/python/tf/image/resize">The docs</a> on this are pretty simple,
for my use case I just need to pass the input image tensor, and the size, which is probably just a tuple of <code>(width, height)</code>, right?
Well, I made that assumption, and the code ran fine, so I didn't really give it a second thought.</p>
<p>Until... My model's performance was absolutely abysmal! Even after training for 32+ epochs,
the model barely performed at all on images it had seen before, and it really couldn't make anything at all of brand new CAPTCHA images,
yielding seemingly random predictions. What the heck was going on?</p>
<p>I decided to actually visualize the images I was feeding into the model, and see what they looked like
- maybe my black/white thresholding was going wrong?
I took a random image from the input data after processing, and visualized it, and I got... this:</p>
<figure><img alt="4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable</figcaption></figure>
<p>Yeah, you probably saw that coming as soon as I said "probably just a tuple of <code>(width, height)</code>". Turns out it's not. It is, in fact, a tuple of <code>(height, width)</code>! Had I taken the time to read the whole documentation page, I would have found this near the bottom of the page, where it provides more detail on the expected argument. This is definitely a lesson learned - read the documentation thoroughly when working with libraries you're unfamiliar with, even if you think you know how it works, and especially if things aren't working how you'd expect.</p>
<p>After fixing this bug, the training performance looked a lot more promising.</p>
<h3 id="training-the-model">Training the model</h3>
<p>The final dataset consisted of approximately 500 hand-solved images, and approximately 50,000 synthetically-generated images.
The synthetic images were generated based on random samples from approximately 2,500 background images and 50-150 images of each character.
This dataset was randomly shuffled, and then segmented 90/10 into training and evaluation sets.
Training took approximately 45 seconds per epoch on my NVIDIA RTX A4000 Laptop GPU.</p>
<p>At the end of the first epoch, the loss did not look very promising - it's still all the way up at 19. During the evaluation callback phase, predictions were nowhere near correct, yielding only 1-2 predicted characters that didn't match any of the characters in the image. This is to be expected during the early stages of training.</p>
<p>Later epochs greatly improved performance. By the end of the fourth epoch, loss decreased to 0.55, and the predictions were already looking good, with 5/5 of the random test predictions at this stage yielding correct results. Loss steadily decreased throughout the rest of the training epochs.</p>
<p>After experimenting with different numbers of epochs, 8-16 epochs was found to be a good trade-off between time and final model performance.
Loss stabilized by the 8th epoch, and increasing the epoch count beyond 16 yielded greatly diminishing returns.</p>
<figure><img alt="Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75"><figcaption>Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out</figcaption></figure>
<p>I wrote a quick test script (<code>trainer/infer.py</code>) to infer CAPTCHA solutions in Python. Results were promising on images the model had not seen before, yielding correct solutions in the limited number of test cases I tried.</p>
<h2 id="using-the-model-in-tensorflowjs">Using the Model in TensorFlow.js</h2>
<p>Writing the <a href="https://www.tensorflow.org/js">TensorFlow.js</a> code for the user script was quite straightforward. I chose TypeScript for this task. I re-implemented the CAPTCHA alignment algorithm from the Python code, as well as the image preprocessing code. All of this code is located in the <code>user-scripts/</code> directory in the repository.</p>
<p>The Python TensorFlow/Keras model formats aren't compatible with the model format expected by TensorFlow.js. There's an <a href="https://www.tensorflow.org/js/guide/conversion">official conversion script</a>, with instructions on how to use it. This should be easy, right?</p>
<h3 id="the-converter-doesnt-work-on-python-312">The converter doesn't work on Python 3.12</h3>
<p>This was a pretty simple problem that took awhile to figure out. The official TensorFlow-to-TFJS model converter doesn't work on Python 3.12. This doesn't seem to really be documented, and the error messages thrown when you try to use it on Python 3.12 are non-obvious. I tried an older version of Python (3.10) on a hunch, using PyEnv, and it worked like a charm.</p>
<h3 id="tensorflowjs-doesnt-support-keras-3">TensorFlow.js doesn't support Keras 3</h3>
<p>New problem: The conversion script supports converting Keras 3 models to TensorFlow.js format. The only problem? TensorFlow.js doesn't support actually reading those converted models. I found this out from a <a href="https://discuss.ai.google.dev/t/corrupted-configuration-and-batch-input-shape-loading-pre-trained-layers-model-in-tensorflow-js/24454">forum post</a>, after I spent a bit of time puzzling out why TFJS wouldn't read the model that the official conversion script output.</p>
<p>Luckily, the solution was easy: Use Keras 2. We can do this by training the model with the environment variable <code>TF_USE_LEGACY_KERAS=1</code> set, after installing the legacy <code>tf_keras</code> package. This may require some code changes. In my case, I only had to trivially modify one line. We also have to export the model using the legacy <code>.h5</code> model format, and specify that as the input format when running the conversion script.</p>
<h2 id="real-world-performance">Real-World Performance</h2>
<p>We've seen the performance on the training dataset, which consists mainly of synthetic images. But it doesn't matter if it can solve synthetic CAPTCHAs - we care about solving the real ones.</p>
<p>Good news: It works great on the real 4Chan CAPTCHA. Solving is fast, taking about 1 second to load the model the first time, and then being imperceptibly quick on subsequent executions. In my experience over hundreds of real CAPTCHAs solved in the browser, the model exhibits a greater than 90% successful solve rate. It rarely gets characters wrong - when it is innacurate, it typically omits a single character entirely. I believe this could be improved with greater training on actual data, or possibly tweaking the CAPTCHA layouts in the synthetic dataset generator.</p>
<figure><img alt="Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script." loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75"><figcaption>Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script.</figcaption></figure>
<p>Small fun fact: This model has far better accuracy than the human-powered CAPTCHA solving service I described above.</p>
<h3 id="4-character-captchas">4-character CAPTCHAs</h3>
<p>While I was writing and editing this article after completing the project,
I noticed that 4Chan begun sometimes serving CAPTCHAs with only 4 characters, rather than the usual 5 and 6-character CAPTCHAs.
Despite this model only having been trained on 5 and 6-character CAPTCHAs,
performance on the 4-character CAPTCHAs is the same as for the 5 and 6-character CAPTCHAs.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I enjoyed this project a lot. It had a few challenges to overcome, and I learned a ton about machine learning and computer vision in the process. There are surely improvements that can be made, but for now, I'm pleased with the results, because I achieved what I set out to do from the start.</p>
<p>I hope you enjoyed reading this write-up as much as I enjoyed writing it, and I hope you learned something too!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What does this button do? – My new car has a mysterious and undocumented switch (436 pts)]]></title>
            <link>https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</link>
            <guid>42276620</guid>
            <pubDate>Fri, 29 Nov 2024 19:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr">https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</a>, See on <a href="https://news.ycombinator.com/item?id=42276620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2>My new car has a mysterious and undocumented switch</h2></p></div><div id="post-content-parent"><p>Last week I bought a car. After twelve years of service, my old trusty Peugeot 107 in blue has had its best. Expensive repairs were coming <em>at some point</em>, and I did not feel like waiting around for them to come. Plus the existing list of faults (like the high oil usage of about a litre per month, a brake that sometimes blocked without reason, or the smell of exhaust fumes that sometimes came into the car when the fan was on high) also started getting longer and longer.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732888980123/91643929-8f55-468a-8568-97d1a64862da.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Anyway, new car time! After a lot of research I ended up with an Opel Corsa from 2020. To be precise, it’s an Opel Corsa Edition with 101 HP, and most importantly, it’s mine.</p>
<p>Unlike the Peugeot, the Opel has gadgets - quite a few of them. Of course it being my car, I want to know what all buttons do, so I read the entire manual (which is very annoying to read, as they make one manual for every version of the car, so half of it does not apply to this car, but I digress). One of those buttons was the following below the lighting controls.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889068247/f39bda1d-77c1-4186-862b-c566cce517bb.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Those do not appear in the manual, or the website, or anywhere. What could they be? Just flipping the switch does nothing, apart from turning off the light on the switch. So let’s look where the button goes. I can see that part of it is wired to the back of the OBD2 port (a port that retrieves data from the onboard computer about the car, such as pedal position, temperature, lights, rev count, speed - basically if you can see it on your dashboard it can be read using the OBD2 port), so it is getting information from the car, but apart from that the wires go to places that I can’t see without taking the car further apart.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889143592/00372c30-63b8-4807-9ae3-4b15727304e5.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Something else that I noticed before is that I heard the typical inference noise coming from that area of the car when putting the ignition on. You know, <a target="_blank" href="https://youtu.be/FYjs7vsaSEw">this</a> sound. <em>Ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, TAAAAAAAAAAA</em>. That gave me the ominous feeling there might be something sending data in there. Sure, my car does that too so I can see in the app where I parked it (seriously, it does that), but at least I gave permission for that.</p>
<p>I asked the wisdom of the crowd. A lot of ideas came up: nitrous (would have been fun), LPG switch (it’s only petrol), flame kit (I wish), front parking sensors (those are standard on the car). No avail.</p>
<p>I called my dealership and asked. They guessed it might have been an immobiliser - bit strange on a car this young and type, and also strange for it to be a switch like this. I called the dealership that previously maintained the vehicle based on the phone number in the service history. They did not install it, and guessed it might be a black box. They did tell me who it previously belonged to (a large company), so I called their headquarters. They told me they don’t do their own cars any more, but that they outsourced it, and gave me a phone number. I called them, they told me they don’t do that, but he speculated it might be a GPS tracker.</p>
<p>Some more searching, and I figured I would just drive to my dealership. More speculating with the salespeople, who told me to make an appointment with the mechanics. I did, they had a quick look at it and I now have an answer:</p>
<p>The metal part is something to hold a magnet next to. It registers who's driving to a fleet tracker via a device also mounted in the car, which sends it to a fleet manager via the internet. That way it can be tracked which employee did what (and potentially who to send the fine to). That would also explain the mobile phone interference noises I've heard from that area of the car. So it’s a black box, a GPS tracker, and maybe also an immobiliser? I am not sure about the last one (and why it has a switch).</p>
<p>I'm getting it removed because now I'm basically driving around with a foreign GPS tracker. Some lease company somewhere is getting data on wherever I go. Kind of spooky if you think of it, especially as I assume I am one of the few actually looking into what this is. Most people would have probably driven around for years with a foreign GPS tracker.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889803408/1353bcc6-c25c-482b-9a75-67686582c479.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>And that’s how the search comes to an end. After a bit of perseverance I figured out what it is. I now know my car is being tracked still, and that they know I did try out what the car’s acceleration is like at full throttle.</p>
<p>There are more interesting angles to this, like “can I request my data from the fleet manager thing that has been tracking my whereabouts under the GDPR?”, and “can I get free data from the SIM card embedded in the device that I now technically own?” but I will leave those for another day.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US house prices in 1950 vs. 2024, accounting for inflation (132 pts)]]></title>
            <link>https://brilliantmaps.com/us-houses-prices-1950-2024/</link>
            <guid>42276155</guid>
            <pubDate>Fri, 29 Nov 2024 19:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brilliantmaps.com/us-houses-prices-1950-2024/">https://brilliantmaps.com/us-houses-prices-1950-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=42276155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
			<p><img decoding="async" src="https://brilliantmaps.com/wp-content/uploads/1950-vs-2024.png" alt="How Much US Houses Cost In 1950 vs How Much The Cost In 2024" width="1640" height="647" srcset="https://brilliantmaps.com/wp-content/uploads/1950-vs-2024.png 1640w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-300x118.png 300w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-1024x404.png 1024w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-768x303.png 768w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-1536x606.png 1536w" sizes="(max-width: 1640px) 100vw, 1640px"></p>
<p>The map above shows how much houses cost in 1950 in each US state in 2024 inflation adjusted US dollars, compared to what the average cost actually is in 2024.  </p>
<p>In every single US state the increase was at at least double the rate of inflation from a low in Ohio of just 107% above inflation to a high in <a href="https://brilliantmaps.com/us-maps/alaska-map/" data-internallinksmanager029f6b8e52c="99" title="Map of Alaska The Government Doesn’t Want You To See">Alaska</a> of 675% above inflation. </p>
<p>The following map shows the percentage increase above inflation:</p>

<p><img decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation.png" alt="House price increases above inflation 1950-2024" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-1536x1212.png 1536w" sizes="(max-width: 1640px) 100vw, 1640px"></p>
<p>And here are 3 maps showing Median Home Value in 1950 (in non-inflation adjusted terms), and bigger versions of the two maps at the top.</p>
<p>Finally, you can see all the data at the bottom:</p>
<h2>Median home value by state in 1950 in non-inflation adjusted dollars</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars.png" alt="median home value by state in 1950 in non-inflation adjusted dollars" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<h2>Median home value by state in 1950 in inflation adjusted dollars</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars.png" alt="Median home value by state in 1950 in inflation adjusted dollars" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<h2>Actual Median home value by state in 2024</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024.png" alt="Median home value by state in 2024" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<p>And here’s all the data on the changes:</p>

<table id="tablepress-223">
<thead>
<tr>
	<th>State</th><th>Median Home Value (1950)</th><th>Inflation Adjusted Median Home Value (1950)</th><th>Median Home Value (2024)</th><th>Absolute $ Increase Above Inflation</th><th>Percent Increase Above Inflation</th>
</tr>
</thead>
<tbody>
<tr>
	<td>Alabama</td><td>$4,473</td><td>$60,072</td><td>$227,508</td><td>$167,436</td><td>279%</td>
</tr>
<tr>
	<td>Alaska</td><td>$3,477</td><td>$46,696</td><td>$362,098</td><td>$315,402</td><td>675%</td>
</tr>
<tr>
	<td>Arizona</td><td>$5,935</td><td>$79,707</td><td>$428,711</td><td>$349,004</td><td>438%</td>
</tr>
<tr>
	<td>Arkansas</td><td>$4,087</td><td>$54,888</td><td>$208,078</td><td>$153,190</td><td>279%</td>
</tr>
<tr>
	<td>California</td><td>$9,564</td><td>$128,445</td><td>$771,057</td><td>$642,612</td><td>500%</td>
</tr>
<tr>
	<td>Colorado</td><td>$7,151</td><td>$96,038</td><td>$541,072</td><td>$445,034</td><td>463%</td>
</tr>
<tr>
	<td>Connecticut</td><td>$11,862</td><td>$159,307</td><td>$405,595</td><td>$246,289</td><td>155%</td>
</tr>
<tr>
	<td>Delaware</td><td>$9,079</td><td>$121,931</td><td>$388,654</td><td>$266,723</td><td>219%</td>
</tr>
<tr>
	<td>District of Columbia</td><td>$14,498</td><td>$194,708</td><td>$602,769</td><td>$408,060</td><td>210%</td>
</tr>
<tr>
	<td>Florida</td><td>$6,612</td><td>$88,799</td><td>$392,176</td><td>$303,376</td><td>342%</td>
</tr>
<tr>
	<td>Georgia</td><td>$5,235</td><td>$70,306</td><td>$326,617</td><td>$256,311</td><td>365%</td>
</tr>
<tr>
	<td>Hawaii</td><td>$12,283</td><td>$164,961</td><td>$845,946</td><td>$680,985</td><td>413%</td>
</tr>
<tr>
	<td>Idaho</td><td>$5,852</td><td>$78,592</td><td>$451,520</td><td>$372,928</td><td>475%</td>
</tr>
<tr>
	<td>Illinois</td><td>$8,646</td><td>$116,116</td><td>$266,706</td><td>$150,590</td><td>130%</td>
</tr>
<tr>
	<td>Indiana</td><td>$6,226</td><td>$83,615</td><td>$242,113</td><td>$158,498</td><td>190%</td>
</tr>
<tr>
	<td>Iowa</td><td>$6,320</td><td>$84,878</td><td>$220,277</td><td>$135,400</td><td>160%</td>
</tr>
<tr>
	<td>Kansas</td><td>$5,462</td><td>$73,355</td><td>$229,012</td><td>$155,658</td><td>212%</td>
</tr>
<tr>
	<td>Kentucky</td><td>$5,283</td><td>$70,951</td><td>$212,088</td><td>$141,137</td><td>199%</td>
</tr>
<tr>
	<td>Louisiana</td><td>$5,141</td><td>$69,044</td><td>$201,519</td><td>$132,476</td><td>192%</td>
</tr>
<tr>
	<td>Maine</td><td>$4,856</td><td>$65,216</td><td>$401,297</td><td>$336,081</td><td>515%</td>
</tr>
<tr>
	<td>Maryland</td><td>$8,033</td><td>$107,883</td><td>$418,438</td><td>$310,555</td><td>288%</td>
</tr>
<tr>
	<td>Massachusetts</td><td>$9,144</td><td>$122,804</td><td>$623,131</td><td>$500,327</td><td>407%</td>
</tr>
<tr>
	<td>Michigan</td><td>$7,496</td><td>$100,671</td><td>$245,716</td><td>$145,044</td><td>144%</td>
</tr>
<tr>
	<td>Minnesota</td><td>$7,806</td><td>$104,835</td><td>$334,119</td><td>$229,285</td><td>219%</td>
</tr>
<tr>
	<td>Mississippi</td><td>$4,159</td><td>$55,855</td><td>$181,313</td><td>$125,457</td><td>225%</td>
</tr>
<tr>
	<td>Missouri</td><td>$6,399</td><td>$85,939</td><td>$248,328</td><td>$162,389</td><td>189%</td>
</tr>
<tr>
	<td>Montana</td><td>$5,797</td><td>$77,854</td><td>$462,631</td><td>$384,777</td><td>494%</td>
</tr>
<tr>
	<td>Nebraska</td><td>$5,918</td><td>$79,479</td><td>$259,443</td><td>$179,964</td><td>226%</td>
</tr>
<tr>
	<td>Nevada</td><td>$8,859</td><td>$118,976</td><td>$442,185</td><td>$323,209</td><td>272%</td>
</tr>
<tr>
	<td>New Hampshire</td><td>$6,199</td><td>$83,253</td><td>$478,955</td><td>$395,703</td><td>475%</td>
</tr>
<tr>
	<td>New Jersey</td><td>$10,408</td><td>$139,779</td><td>$534,773</td><td>$394,994</td><td>283%</td>
</tr>
<tr>
	<td>New Mexico</td><td>$5,697</td><td>$76,511</td><td>$303,910</td><td>$227,399</td><td>297%</td>
</tr>
<tr>
	<td>New York</td><td>$10,152</td><td>$136,341</td><td>$482,742</td><td>$346,400</td><td>254%</td>
</tr>
<tr>
	<td>North Carolina</td><td>$4,901</td><td>$65,820</td><td>$328,715</td><td>$262,895</td><td>399%</td>
</tr>
<tr>
	<td>North Dakota</td><td>$5,396</td><td>$72,468</td><td>$263,410</td><td>$190,942</td><td>263%</td>
</tr>
<tr>
	<td>Ohio</td><td>$8,304</td><td>$111,523</td><td>$230,798</td><td>$119,275</td><td>107%</td>
</tr>
<tr>
	<td>Oklahoma</td><td>$5,228</td><td>$70,212</td><td>$205,968</td><td>$135,756</td><td>193%</td>
</tr>
<tr>
	<td>Oregon</td><td>$6,846</td><td>$91,942</td><td>$492,683</td><td>$400,742</td><td>436%</td>
</tr>
<tr>
	<td>Pennsylvania</td><td>$6,992</td><td>$93,903</td><td>$268,824</td><td>$174,921</td><td>186%</td>
</tr>
<tr>
	<td>Rhode Island</td><td>$9,767</td><td>$131,171</td><td>$467,485</td><td>$336,314</td><td>256%</td>
</tr>
<tr>
	<td>South Carolina</td><td>$5,112</td><td>$68,654</td><td>$295,769</td><td>$227,115</td><td>331%</td>
</tr>
<tr>
	<td>South Dakota</td><td>$5,410</td><td>$72,656</td><td>$306,944</td><td>$234,287</td><td>322%</td>
</tr>
<tr>
	<td>Tennessee</td><td>$5,268</td><td>$70,749</td><td>$319,208</td><td>$248,458</td><td>351%</td>
</tr>
<tr>
	<td>Texas</td><td>$5,805</td><td>$77,961</td><td>$300,267</td><td>$222,306</td><td>285%</td>
</tr>
<tr>
	<td>Utah</td><td>$7,409</td><td>$99,503</td><td>$517,020</td><td>$417,517</td><td>420%</td>
</tr>
<tr>
	<td>Vermont</td><td>$6,277</td><td>$84,300</td><td>$390,132</td><td>$305,832</td><td>363%</td>
</tr>
<tr>
	<td>Virginia</td><td>$6,581</td><td>$88,383</td><td>$392,682</td><td>$304,299</td><td>344%</td>
</tr>
<tr>
	<td>Washington</td><td>$7,169</td><td>$96,280</td><td>$588,856</td><td>$492,576</td><td>512%</td>
</tr>
<tr>
	<td>West Virginia</td><td>$5,473</td><td>$73,502</td><td>$168,172</td><td>$94,670</td><td>129%</td>
</tr>
<tr>
	<td>Wisconsin</td><td>$7,927</td><td>$106,460</td><td>$306,566</td><td>$200,106</td><td>188%</td>
</tr>
<tr>
	<td>Wyoming</td><td>$6,811</td><td>$91,472</td><td>$354,108</td><td>$262,636</td><td>287%</td>
</tr>
</tbody>
</table>
<!-- #tablepress-223 from cache -->
<p>Data for 1950 US house prices came from the <a href="https://www.census.gov/data/tables/time-series/dec/coh-values.html" target="_blank" rel="noopener">US Census</a>, inflation data for the <a href="https://data.bls.gov/cgi-bin/cpicalc.pl" target="_blank" rel="noopener">Bureau of Labour Statistics</a> and the 2024 house prices from <a href="https://www.zillow.com/research/data/" target="_blank" rel="noopener">Zillow</a>. Maps created using <a href="https://www.datawrapper.de/" target="_blank" rel="noopener">Datawrapper</a>.    </p>
<p>Why do you think home prices have outpaced inflation since the 1950s?</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Influence of Bell Labs (164 pts)]]></title>
            <link>https://www.construction-physics.com/p/the-influence-of-bell-labs</link>
            <guid>42275944</guid>
            <pubDate>Fri, 29 Nov 2024 18:36:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/the-influence-of-bell-labs">https://www.construction-physics.com/p/the-influence-of-bell-labs</a>, See on <a href="https://news.ycombinator.com/item?id=42275944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg" width="980" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:980,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Xerox PARC and the Origins of GUI | CRM.org&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Xerox PARC and the Origins of GUI | CRM.org" title="Xerox PARC and the Origins of GUI | CRM.org" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We’ve </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">talked previously</a><span> about Bell Labs’ long, storied history as an innovation engine and a generator of new technology. For decades, it spun off new major inventions and scientific discoveries as part of its mandate to help build AT&amp;T’s telephone network.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png" width="609" height="591" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a5e6d681-1029-41a0-a428-e6475b68b126_609x591.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:591,&quot;width&quot;:609,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Bell Labs was notable for combining the best aspects of academic and industrial research. As in a conventional academic lab, scientists had the freedom to pursue research avenues they found promising without being bound by concerns of immediate profitability or return on investment. It was understood that efforts might take years to pay off, and only a handful would. Researchers could also publish papers and engage with the broader intellectual community in their field, while using cutting-edge equipment that only an industrial lab could provide. And they could pursue their research without having to worry about teaching classes or applying for grants.</p><p>Discussion of Bell Labs tends to center around the impact and successes of the Labs itself. But a perhaps underappreciated impact of Bell Labs is the influence it had on other large corporations. Bell Labs was highly prestigious, and its invention of the transistor demonstrated that world-changing products could come by funding “basic” scientific research. Inspired by Bell Labs, in the second half of the 20th century, a variety of corporations started their own research operations based on the Bell Labs model.</p><p>Industrial research labs started to become popular in the US around the turn of the 20th century. Along with Bell Labs, companies like DuPont, General Electric, and Kodak all employed scientists in research labs, and by 1940 there were over 1,000 industrial research labs in the U.S. Most of these labs were small (on average they employed fewer than 100 people), and as late as 1940 there were fewer than 30,000 people employed in a “scientific” capacity in all US manufacturing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png" width="684" height="461" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:461,&quot;width&quot;:684,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1456w" sizes="100vw"></picture></div></a><figcaption>Research labs in the U.S. over time.</figcaption></figure></div><p>But following WWII, research spending by both the government and the private sector increased enormously. In 1946, private R&amp;D spending in the U.S. was about $500 million annually, roughly what it had been before the war. By 1951 it had increased four-fold to $2 billion annually, and between 1953 and 1977, in real terms, it quadrupled again.</p><p>Unpacking the reasons for this increase goes beyond the extent of this essay, and it certainly wasn’t just because of AT&amp;T and Bell Labs. But Bell Labs’ achievements, particularly the invention of the transistor in 1947, seem to have prompted the decisions of many companies to start their own R&amp;D labs, and influenced how those labs were structured.</p><p>There seem to have been several modes of influence. For one, the transistor itself ushered in a new world of semiconductor devices. Semiconductors were a product of deep, scientific understanding of the physical nature of matter. Anyone who wanted to compete in the new market by developing their own semiconductor-based products would need to acquire the relevant scientific expertise.</p><p>The transistor also demonstrated that “basic” research could result in enormously successful, world-changing products. The world had just seen the amazing power of scientific research in wartime achievements like radar and the atomic bomb, and the transistor showed that the fruits of such research weren’t limited to enormous government projects. The success of nylon, another successful product that was the result of basic research by DuPont, also reinforced this perception.</p><p><span>Finally, Bell Labs was incredibly prestigious, and companies wanted to burnish their reputations by having their own scientific research establishments. Not only was this prestige desirable in its own right, but it could allow companies to acquire the sort of talent that they otherwise might not be able to. The transistor cemented Bell Labs’ reputation as one of the best research labs in the world, which allowed it to acquire some of the world’s best scientific talent, which resulted in </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">further scientific achievements</a><span>.</span></p><blockquote><p><em>Its prestige, reputation for excellence, and envious working environment allowed Bell Labs to acquire some of the most talented researchers in the world. Bell Labs Nobel Prize winner Horst Stormer noted that “Over a very long stretch of time, it was the best place in the world and it attracted — and attracts — the best people.” In his short memoir about Bell Labs, Michael Noll likewise noted that “it seemed everybody wanted to get a job there.” Of Bell Labs’ 10 Nobel Prizes, 8 came from researchers hired in the ‘50s, ‘60s, and ‘70s following the invention of the transistor.</em></p></blockquote><p>Bell Labs thus created a new world that required some degree of scientific capability, showed what could result from creating such capabilities, and provided a playbook for how to do it. In the 1950s and beyond, many companies started their own research operations on the Bell Labs model: creating an academic-esque environment and giving researchers freedom to follow their interests, without necessarily needing to worry about marketable products or immediate profitability.</p><p><span>Several of these research labs, unsurprisingly, were founded by companies in the computers and electronics industry. IBM, for instance, had a research division prior to the 1950s, but it was mostly a small group of electrical engineers who were focused on figuring out how to build new products. Thomas Watson Jr., son of the founder of IBM and its former CEO, </span><a href="https://www.amazon.com/Father-Son-Co-Life-Beyond/dp/0553070118" rel="">describes it in his autobiography</a><span>:</span></p><blockquote><p><em>IBM’s main laboratory, on North Street in Endicott, was a very peculiar place. Between three hundred and four hundred people worked there, but the whole thing was built around seven senior engineers whom Dad called his “inventors”... When [Dad] had an idea for a product, he’d call in one or two of these old birds and describe what he wanted it to do. Then the inventors would go back and try to “put it in metal” as they used to say.</em></p></blockquote><p>At the time, IBM primarily produced mechanical punchcard-based calculators, but Watson Jr, recognizing that the future was in electronics, scaled up their research operations and hired thousands of scientists and engineers who understood semiconductors and solid-state physics. To organize a program of “pure research," IBM hired Emanuel Piore, the former head of the Office of Naval Research:</p><blockquote><p><em>Piore gave a jolt to some of our product development engineers as well. They were like sprinters encountering their first marathon runner, and were amazed to see IBM start funding experiments in exotic fields that seemed unlikely to bear fruit for decades, if ever — like superconductors and artificial intelligence. What the engineers thought of as basic research Piore often dismissed as mere long-term product development, and what he called research was so far removed from what the engineers were doing that they saw no reason for it at all. At Piore’s urging we doubled the percentage of our revenues devoted to research and development, and much of the additional spending was earmarked for pure science.</em></p></blockquote><p><span>IBM Research went on to spawn a variety of major scientific and technological discoveries. </span><a href="https://en.wikipedia.org/wiki/IBM_Research" rel="">From Wikipedia</a><span>:</span></p><blockquote><p><em>IBM Research's numerous contributions to physical and computer sciences include the Scanning Tunneling Microscope and high-temperature superconductivity, both of which were awarded the Nobel Prize. IBM Research was behind the inventions of the SABRE travel reservation system, the technology of laser eye surgery, magnetic storage, the relational database, UPC barcodes and Watson, the question-answering computing system that won a match against human champions on the Jeopardy! television quiz show.</em></p></blockquote><p><span>When setting up its research efforts, IBM consciously took notes from Bell Labs. An </span><a href="https://www.amazon.com/Making-World-Work-Better-Century/dp/0132755106" rel="">official company history</a><span> of IBM’s history of innovation notes that “IBM had a model: AT&amp;T’s Bell Laboratories”. </span><a href="https://www.amazon.com/Innovation-Passport-First-Kind-Research/dp/0133438759" rel="">Another book published</a><span> by IBM about its research commercialization strategies likewise notes that “Originally, the IBM Research division operated as a separate entity, patterned after Bell Labs.”</span></p><p><span>Another electronics manufacturer that patterned its research efforts after Bell Labs was Texas Instruments. </span><a href="https://en.wikipedia.org/wiki/Gordon_Kidd_Teal" rel="">Gordon Teal</a><span>, who invented single-crystal pulling at Bell Labs, was hired by Texas Instruments in 1953 to run its newly established research labs, the Central Research Laboratory. An </span><a href="https://www.amazon.com/Engineering-World-Stories-First-Instruments/dp/0870745026" rel="">official company history</a><span> states that “The strength of CRL was influenced by the basic research model that Teal had learned at his previous job with AT&amp;T's Bell Labs.” In an </span><a href="https://ethw.org/Oral-History:Gordon_K._Teal#Texas_Instruments" rel="">oral history</a><span>, Teal describes how researchers were allowed to pursue their own projects that they felt were promising:</span></p><blockquote><p><em>Goldstein: You were saying that by the late 'fifties and early 'sixties, you were spending less time in the lab. Where did the direction for the laboratory come from? Who was in charge of the projects that they were working on?</em></p><p><em>Teal: No one. As the people that I brought in got experience, they were capable of having good ideas themselves and not have to be directed in everything they did.</em></p><p><em>Goldstein: They would launch their own research projects?</em></p><p><em>Teal: Yes, and I depended on the group heads to give them instructions rather than me.</em></p></blockquote><p>While these efforts are described as “basic research," they don’t appear to be quite as sequestered from product development as in some other Bell Labs-inspired research labs. In the oral history, Teal notes that the labs’ efforts weren’t quite pure science, and research directions tended to be product-focused. They nevertheless appear to be highly influenced by Teals’ Bell Labs experience. Research at Texas Instruments would ultimately result in the first production silicon transistor, and the co-invention of the integrated circuit.</p><p><span>Perhaps the most famous research lab inspired by Bell Labs was Xerox’s Palo Alto Research Center (PARC). Concerned that their copier business would potentially be undermined by advancing computer technology, Xerox acquired computer manufacturer SDS in 1969 to help it stay at the forefront of modern technology. Following the purchase, chief scientist Jack Goldman convinced company leadership to build a new research operation. From </span><em>Dealers of Lightning</em><span>, a history of Xerox PARC:</span></p><blockquote><p><em>On the surface the rationale for the so-called “Xerox Advanced Scientific and Systems Laboratory” was to fortify the new subsidiary’s weak research capability. But from that foundation Goldman was intent on building a much larger edifice. Cannily recognizing that Xerox yearned to be ranked alongside such paragons of industrial muscle as IBM and AT&amp;T, he sketched out a corporate research center engaged in basic science independent of any existing product group, exactly like IBM’s fabled Yorktown Heights research center and AT&amp;T’s Bell Laboratories. About half the staff would be devoted to advanced physics and materials research, and the rest to the new sciences of systems and computing.</em></p></blockquote><p>PARC would be founded “by men whose experience had taught them that the only way to get the best research was to hire the best researchers they could find and leave them unburdened by directives, instructions, or deadlines.”&nbsp;</p><blockquote><p><em>For the most part, the computer engineers of PARC were exempt from corporate imperatives to improve Xerox’s existing products. They had a different charge: to lead the company into new and uncharted territory.</em></p></blockquote><div><p><span>PARC would become famous as the birthplace of much of the technology behind the PC revolution: out of PARC came the </span><a href="https://en.wikipedia.org/wiki/Xerox_Alto" rel="">first personal computer</a><span>, the graphical user interface, ethernet, and the laser printer.</span></p><p><span>But not every research lab inspired by Bell Labs was at a computer or electronics manufacturer. PARC was established by Jack Goldberg, who had formerly led the science arm of Ford’s Scientific Research Lab, which had been </span><a href="https://askus.thehenryford.org/researchguides/faq/372100" rel="">founded in 1951</a><span> and </span><a href="https://books.google.com/books?id=nBdXAAAAMAAJ&amp;pg=PA92&amp;dq=%22Ford%22+%22Jack+Goldman%22&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwiPjoiShM2JAxWtgIQIHUrCE_0Q6AF6BAgLEAI#v=onepage&amp;q=%22Ford%22%20%22Jack%20Goldman%22&amp;f=false" rel="">was intended</a><span> “to be a major scientific institution producing innovation," pursuing basic research independent of any product development. Ford’s research efforts also </span><a href="https://spectrum.ieee.org/how-the-ford-motor-co-invented-the-squid" rel="">seem to have been inspired</a><span> by Bell Labs:</span></p></div><blockquote><p><em>…The lab operated according to a philosophy that was established by AT&amp;T’s Bell Labs and IBM’s Thomas J. Watson Research Center and that has now been essentially abandoned. These great institutions pursued research topics not because they were likely to contribute to the parent company’s bottom line anytime soon but because the corporation believed that research for research’s sake was something a real company did.</em></p><p><em>“We had the freedom to do what we were interested in,” says Arnold Silver, who worked in the Ford lab in its heyday. “We could follow our noses — and particularly, we could follow the data.”</em></p></blockquote><p><span>Among the achievements of Ford’s research labs are the </span><a href="https://en.wikipedia.org/wiki/SQUID" rel="">SQUID</a><span> (an extremely sensitive magnetic field sensor) and the </span><a href="https://en.wikipedia.org/wiki/Sodium%E2%80%93sulfur_battery" rel="">sodium-sulfur</a><span> battery.</span></p><p><span>Another Bell Labs-inspired research lab outside the electronics industry was Exxon’s. In the early 1970s Exxon was worried that petroleum would begin to be exhausted in the coming decades, and was willing to fund long-term research in the hunt for alternative energy technologies. These efforts were wide-ranging, including “fuel cells, solar cells, computer chips, superconductors, and batteries, as well some non-energy projects, such as fax machines and word processors.” Exxon researchers had a great deal of freedom, access to the best equipment, and weren’t burdened with questions of profitability or return on investment. From </span><em><a href="https://www.amazon.com/Long-Hard-Road-Lithium-Ion-Electric-ebook/dp/B09GB3HGHY?crid=328KTS4O3GJ7D&amp;dib=eyJ2IjoiMSJ9.9Hutwsk8qUiVp9bQaV50jsN9H42ejgLzWSDjU7RdBqo.CWvvF0gifrr5G-axjtk2dop_kZJtK61q3KzRyvFB4N4&amp;dib_tag=se&amp;keywords=long+hard+road+the+lithium-ion+battery+and+the+electric+car&amp;qid=1731014737&amp;sprefix=the+long+hard+road+%2Caps%2C243&amp;sr=8-1" rel="">The Long Hard Road</a></em><span>, a history of the lithium ion battery and the electric car:</span></p><blockquote><p><em>…Life at Exxon Research and Engineering was turning out to be a lot like life at Stanford. Exxon Research featured a highly academic atmosphere — groups of PhDs in small labs, surrounded by more small labs with more PhDs, mostly doing chemical and solids research. Moreover, Exxon’s lab was legally considered a not-for-profit entity, so there was no pressure to produce any sort of short-term economic benefit.</em></p></blockquote><p>Exxon felt that it was in direct competition with Bell Labs, and acted accordingly:</p><blockquote><p><em>Exxon corporate management felt they were in a head-to-head competition with Bell Labs, which was about twenty miles down the road in Murray Hill, New Jersey. Edward E. David, who was later named president of Exxon Research and Engineering, actually saw it as a point of pride. David had a doctorate from MIT in electrical engineering. He had previously served as a scientific advisor to President Richard Nixon and had spent twenty years at Bell Labs. And he wanted Exxon Research to be better than Bell Labs. Better, in fact, than any corporate lab in the world. Moreover, he kept score, not by counting dollars but by counting scientific papers and patents.</em></p></blockquote><p><span>Exxon research would later become infamous for </span><a href="https://news.harvard.edu/gazette/story/2023/01/harvard-led-analysis-finds-exxonmobil-internal-research-accurately-predicted-climate-change/" rel="">predicting</a><span> the climate impacts of greenhouse emissions, then suppressing the findings, but it also created the </span><a href="https://spectrum.ieee.org/lithium-ion-battery-2662487214" rel="">first rechargeable lithium ion battery</a><span>.</span></p><p><span>Bell Labs ultimately wasn’t able to maintain its long-horizon research environment following the dissolution of the AT&amp;T monopoly, and it seems like the same is true for the Bell Labs-inspired research organizations. IBM still funds a great deal of research, but is much more tightly integrated with product development, and its </span><a href="https://web.archive.org/web/20110629122453/http://www.research.ibm.com/resources/awards.shtml" rel="">major science and technology awards</a><span> mostly seem to be for work done decades ago. Likewise, Exxon </span><a href="https://corporate.exxonmobil.com/who-we-are/technology-and-collaborations/university-and-national-labs-partnerships/exxonmobil-invests-1-billion-per-year-in-energy-research-emerging-technologies" rel="">spends</a><span> more than a billion dollars annually on research, but via a more carefully managed “stage-gating” process, where “Researchers partner with the business lines to determine the business benefit of a technology, establish research and development goals and timelines, steward independent project reviews and authorize project funding.” In </span><em>Dealers of Lightning</em><span>, Michael Hiltzik argues that by the 1990s PARC was no longer engaged in such unrestricted research decoupled from product development.</span></p><p><span>This probably shouldn’t be surprising. I argued in my </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">earlier piece on Bell Labs</a><span> that only a fairly unique set of historical circumstances allowed Bell Labs to exist:</span></p><blockquote><p><em>Bell Labs was made possible by a large-scale, vertically integrated telephone monopoly that allowed for an unusually long and wide research and development horizon for an industrial lab. Outside of those conditions (not likely to be repeated), funding a Bell Labs-style operation does not appear to be something most companies are willing to do. Even a company like Google, which spends billions on R&amp;D and has displayed a willingness to fund speculative, longer-term moonshot projects like self-driving cars or life extension, doesn’t completely bite the Bell Labs bullet. Google’s Moonshot projects absorb billions in funding each year, but they tend to be organized as independent companies that raise money outside Google and get spun off when they seem promising enough.&nbsp;</em></p><p><em>Bell Labs also took advantage of historical circumstances: discoveries in quantum mechanics yielded promising new phenomena, and WWII energized the organization while simultaneously creating scientific and technological progress that could later be capitalized on. These contingencies were the result of pure chance, not anything that could be controlled.</em></p></blockquote><p><span>Part of corporations increasing unwillingness to fund unrestricted, speculative research likely comes down to the fact that labs with unrestricted research operations don’t appear to have been particularly successful. In </span><em><a href="https://books.google.com/books/about/Science_in_the_Twentieth_Century.html?id=sb6MlItuOqsC" rel="">Science in the Twentieth Centur</a><span>y</span></em><span>, W. Bernard Carlson argues that corporations turned away from unrestricted research because it didn’t achieve anything as transformative as the transistor or nylon:</span></p><blockquote><p><em>In investing in R&amp;D, American companies employed thousands of Ph.D scientists and built elaborate research “campuses.” At these new facilities, scientists were granted a large degree of autonomy, in the belief that such freedom had been the crucial ingredient in the development of nylon and the transistor. And yet despite ample funds, new facilities, and unprecedented freedom, scientists at the major corporate labs came up with few major breakthroughs from the 1950s to the 1980s.&nbsp;</em></p></blockquote><p><span>Looking at the history of the Bell Labs-inspired organizations seems to at least somewhat confirm this thesis. I haven’t studied their output exhaustively, but their most successful achievements — things like the Texas Instruments’ integrated circuit, IBM’s DRAM, and Xerox’s laser printer — mostly seem fairly closely tied to immediate product needs, and aren’t obviously the sort of thing you’d need to fund “basic” research to get. Indeed, research on the laser printer started years before Xerox formed PARC, and the other co-inventor of the integrated circuit was Fairchild Semiconductor, which as far as I can tell didn’t operate anything like a basic research lab. Their longer-timeline, “breakthrough” achievements seem to perhaps yield interesting scientific discoveries (the scanning tunneling microscope, Mandelbrot’s </span><a href="https://www.amazon.com/Fractal-Geometry-Nature-Benoit-Mandelbrot/dp/0716711869" rel="">work on fractals</a><span>, the SQUID), but not industry-transforming products. The only real “transformative” discovery to me seems like Exxon’s lithium-ion battery, and it was only subsequent developments outside of Exxon that made this successful.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-151672861" href="https://www.construction-physics.com/p/the-influence-of-bell-labs#footnote-1-151672861" target="_self" rel="">1</a></span></p><p><span>There’s a well-known phenomenon that technological progress is often driven by </span><a href="https://www.amazon.com/Boom-Bubbles-Stagnation-Byrne-Hobart/dp/1953953476" rel="">bubbles</a><span>, as irrational enthusiasm drives huge amounts of investment in a novel technology far beyond what can be economically justified. Carlota Perez describes the dynamic in </span><em>Technological Revolutions and Financial Capital</em><span>:</span></p><blockquote><p><em>Two or three decades of turbulent adaptation and assimilation elapse from the moment when the set of new technologies, products, industries and infrastructure make their first impact to the beginning of a “golden age’” or “era of good feeling” based on them… Historically, those decades have brought the greatest excitement in financial markets, where brilliant successes and innovations share the stage with great manias and outrageous swindles. They have also ended with the most virulent crashes, recessions, and depressions…</em></p></blockquote><p>It’s possible something similar happened with Bell Labs following the invention of the transistor. Not necessarily a bubble in electronics investment (though that could well be the case), but in the meta-idea of economically unjustifiable investments in pursuing basic research decoupled from immediate product needs. People often bemoan that American companies aren’t willing to fund research the way that they once did, but perhaps that age of industrial research was simply a bubble that was invariably going to pop.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Sabotage for the 21st Century – Specific Suggestions (110 pts)]]></title>
            <link>https://specificsuggestions.com</link>
            <guid>42275919</guid>
            <pubDate>Fri, 29 Nov 2024 18:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://specificsuggestions.com">https://specificsuggestions.com</a>, See on <a href="https://news.ycombinator.com/item?id=42275919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="generatorBlock">
            
            <p>
                <h2>SPECIFIC SUGGESTIONS</h2>
                <h2>SIMPLE SABOTAGE FOR THE 21<span>ST</span> CENTURY</h2>
            </p>
            <p>The most potent tools for fighting injustice are the ones already in your hands.</p>
            
            <div id="publicDomain">
                <p>
                    Secret</p>

                <p>This work is dedicated to the <span>Public Domain</span></p>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                    <g data-name="Public Domain Stamp">
                        <path d="M110.65,192.52l12.51-25.89a30.43,30.43,0,0,1,22.23-46L157.9,94.72a56.31,56.31,0,0,0-8.77-.69h-.72c-.25,0-.49,0-.73,0h-.35a56.78,56.78,0,0,0-36.68,98.49Z"></path>
                        <path d="M176.54,164a30.41,30.41,0,0,1-23.86,17l-12.49,25.86A56.73,56.73,0,0,0,204.39,164Z"></path>
                        <path d="M187.49,108.94,175,134.83a30.42,30.42,0,0,1,1.55,2.79h27.85A56.72,56.72,0,0,0,187.49,108.94Z"></path>
                        <path d="M149.13,51.45c-.42,0-.87,0-1.29,0a100,100,0,1,0,1.29,0ZM71.07,150.8a78.08,78.08,0,0,1,76.54-78.06h1.52a78.06,78.06,0,0,1,21.37,3L103.64,214.24A78,78,0,0,1,71.07,150.8Zm78.06,78.07a78,78,0,0,1-21.36-3L194.63,87.36a78.07,78.07,0,0,1-45.5,141.51Z"></path>
                        <path d="M21.38,121.87l7.53,1.8a4.85,4.85,0,0,0,3.2,0c.68-.35,1.21-1.31,1.58-2.86l.17-.72,2.59.61-4.09,17.14-2.59-.62.13-.56c.38-1.57.33-2.66-.14-3.27A4.93,4.93,0,0,0,26.93,132l-18.7-4.47a4.82,4.82,0,0,0-3.19,0c-.68.36-1.21,1.3-1.58,2.84l-.18.77-2.59-.62,2.78-12.89c.77-3.2,1.45-5.66,2-7.36a13.16,13.16,0,0,1,2.57-4.48A8.32,8.32,0,0,1,12,103.19a8.57,8.57,0,0,1,4.47-.1,8,8,0,0,1,4.85,3.19,9.36,9.36,0,0,1,1.76,5.5,33.42,33.42,0,0,1-1.1,7.76Zm-2.8-.67.37-1.54c.59-2.47.45-4.24-.44-5.33a7.18,7.18,0,0,0-4-2.27,7.84,7.84,0,0,0-4.14,0,4.34,4.34,0,0,0-2.51,1.84,16.16,16.16,0,0,0-1.53,4.4Z"></path>
                        <path d="M26.21,69.22l-2-1.74,11.18-13,2,1.73-.36.42c-1.05,1.23-1.51,2.21-1.38,3a5.09,5.09,0,0,0,1.88,2.56l9.74,8.36a20.89,20.89,0,0,0,4.55,3.15,6.4,6.4,0,0,0,4.24.32,7.65,7.65,0,0,0,4.11-2.6,8.46,8.46,0,0,0,2.14-4.82,6.8,6.8,0,0,0-1-4.46,22.65,22.65,0,0,0-4.19-4.41l-8.29-7.12c-2.53-2.17-4.83-2-6.93.4l-2-1.73,7.83-9.13,2,1.73a4.88,4.88,0,0,0-1,2A3.24,3.24,0,0,0,49,46.09a8.1,8.1,0,0,0,1.93,2.22l8.24,7.07a30,30,0,0,1,4.05,4.07,9.83,9.83,0,0,1,1.88,4.37,11.66,11.66,0,0,1-.5,5.64,16.69,16.69,0,0,1-3.32,5.77,17.33,17.33,0,0,1-5.33,4.32A11.78,11.78,0,0,1,50.59,81a10.28,10.28,0,0,1-4.51-1,20.84,20.84,0,0,1-4.36-3L32,68.59a4.7,4.7,0,0,0-2.9-1.45C28.32,67.18,27.36,67.87,26.21,69.22Z"></path>
                        <path d="M104.47,24.49a14.18,14.18,0,0,1,7.81.18,7.4,7.4,0,0,1,4.34,4.43,7.36,7.36,0,0,1-.55,6.93c-1.34,2.17-4.22,4.12-8.63,5.88L91.6,48.19l-1-2.47c1.59-.63,2.55-1.3,2.87-2s.19-1.79-.39-3.26l-7-17.72a4.63,4.63,0,0,0-1.9-2.62c-.69-.33-1.87-.17-3.52.49l-1-2.47,11.48-5,1.65-.65q7.84-3.12,11.47-2.3a6.6,6.6,0,0,1,5,4.18,6.1,6.1,0,0,1-.18,5A14.17,14.17,0,0,1,104.47,24.49Zm-7.91,1.64,1.54-.61a5.51,5.51,0,0,0,3.2-2.6c.49-1.08.37-2.57-.38-4.45a6.77,6.77,0,0,0-2.09-3,3.67,3.67,0,0,0-2.62-.79,14.88,14.88,0,0,0-3.78,1.09Zm1.08,2.72,3.4,8.58a5.79,5.79,0,0,0,1,1.79,2.38,2.38,0,0,0,1.43.68,4.45,4.45,0,0,0,2.28-.4,3.91,3.91,0,0,0,2.58-2.75,8.35,8.35,0,0,0-.72-4.9,8.92,8.92,0,0,0-2.17-3.46,3.86,3.86,0,0,0-2.61-1.06,11,11,0,0,0-3.75.94Z"></path>
                        <path d="M174.44,25l-1,10.77-29.54-2.32.21-2.65.48,0c1.62.12,2.7-.09,3.23-.65a4.91,4.91,0,0,0,1-3L150.31,8a4.77,4.77,0,0,0-.53-3.16c-.46-.62-1.48-1-3.06-1.12l-.47,0,.2-2.65,17.38,1.37-.21,2.65L163,5c-1.62-.13-2.7.09-3.23.65a4.86,4.86,0,0,0-1,3l-1.45,18.5a10.19,10.19,0,0,0,0,2.77,2.27,2.27,0,0,0,1.16,1.25A9,9,0,0,0,162,32c2.83.22,5-.32,6.52-1.64a11.39,11.39,0,0,0,3.32-5.52Z"></path>
                        <path d="M209.25,17l1.24-2.35,15.23,8L224.48,25l-.44-.23q-2.14-1.12-3.21-.66a4.91,4.91,0,0,0-2.08,2.39l-8.91,17a4.8,4.8,0,0,0-.77,3.1c.17.75,1,1.49,2.36,2.23l.45.23-1.23,2.36-15.24-8,1.24-2.36c1.53.8,2.67,1.1,3.41.9s1.49-1,2.24-2.43l8.91-17a4.57,4.57,0,0,0,.75-3.16C211.74,18.6,210.84,17.81,209.25,17Z"></path>
                        <path d="M260.08,83.11l-9.6,7.54-1.64-2.1a8,8,0,0,0,1.6-3,14.37,14.37,0,0,1-9.8-5.89q-4.66-5.94-3.58-12.55a16.76,16.76,0,0,1,6.42-10.81,17.71,17.71,0,0,1,12.12-3.81q6.86.3,11.75,6.53a14.11,14.11,0,0,1,3.13,10.32,21,21,0,0,0,2.9-1L275,70.41l-9.24,7.68L264.14,76a14.48,14.48,0,0,0,3.44-7.6,9,9,0,0,0-1.94-6.53,7.07,7.07,0,0,0-6.53-3q-3.92.36-9.44,4.7A31.43,31.43,0,0,0,244,69.08a7.49,7.49,0,0,0-1.62,5.13,8.44,8.44,0,0,0,1.83,4.85A9.27,9.27,0,0,0,250,82.52a14.25,14.25,0,0,0,8.39-1.5Z"></path>
                        <path d="M267.08,148.1l2.64.34c-.22,1.7-.11,2.86.35,3.49s1.47,1,3,1.24l19.09,2.52a4.69,4.69,0,0,0,3.21-.37c.63-.45,1.06-1.56,1.29-3.32l2.61.35-.37,3.89c-.35,3.92-.68,7-1,9.21a52.92,52.92,0,0,1-1.83,9,17,17,0,0,1-3.69,6.21,14.6,14.6,0,0,1-6.26,4,17.39,17.39,0,0,1-7.84.67,16.16,16.16,0,0,1-7.37-2.77,14.54,14.54,0,0,1-4.72-5.47,15.3,15.3,0,0,1-1.66-6.53,86.91,86.91,0,0,1,.95-10.85Zm28,16.56-22.19-2.93a13.21,13.21,0,0,0-2.91-.18,2.19,2.19,0,0,0-1.4.91,5.42,5.42,0,0,0-.87,2.6,7.61,7.61,0,0,0,2.39,7.13c2,1.76,5.17,2.94,9.53,3.51a18.21,18.21,0,0,0,8.61-.53,8.91,8.91,0,0,0,4.81-3.69A18.27,18.27,0,0,0,295.12,164.66Z"></path>
                        <path d="M265.89,216.92a16.8,16.8,0,0,1,5.32,7.13,15.18,15.18,0,0,1,.88,9,20.5,20.5,0,0,1-3.84,8.33q-5.21,6.82-12.1,7.7a16.63,16.63,0,0,1-12.61-3.49,16.13,16.13,0,0,1-6.39-11q-1-6.84,4.12-13.5a20.73,20.73,0,0,1,8.07-6.58,14.11,14.11,0,0,1,9-1A19.53,19.53,0,0,1,265.89,216.92ZM260,225q-6-4.54-9.83-5a6.54,6.54,0,0,0-6.27,2.75,7.13,7.13,0,0,0-1.39,6.81q1.13,3.53,7.17,8.13,5.53,4.22,9.45,4.72a7.45,7.45,0,0,0,7.71-9.69Q265.54,229.26,260,225Z"></path>
                        <path d="M194.34,258.35l20.31,19.38-6-15.71a13.46,13.46,0,0,0-1.47-3,3.28,3.28,0,0,0-2-1.17,5,5,0,0,0-2.86.29l-.94-2.49,10.93-4.16.95,2.48a4.46,4.46,0,0,0-2.2,1.7,3.15,3.15,0,0,0-.63,2.22,15.29,15.29,0,0,0,1,3.21l6.09,16c.58,1.52,1.23,2.44,2,2.75s1.89.16,3.51-.45l.94,2.48-12.16,4.64-17-16.39-1.85,23.56-12.21,4.65-1-2.48.61-.23c1.52-.58,2.41-1.24,2.65-2a5,5,0,0,0-.42-3.13l-6.84-18a4.79,4.79,0,0,0-1.81-2.63c-.68-.37-1.77-.27-3.26.3l-.69.27-.95-2.49,16.53-6.3.95,2.49-.61.23c-1.5.57-2.38,1.23-2.62,2a4.89,4.89,0,0,0,.41,3.14l6.8,17.85L192.59,259Z"></path>
                        <path d="M137.91,275.9l.86-1.49a7.92,7.92,0,0,0,1-2.27,1.74,1.74,0,0,0-.54-1.75,5.38,5.38,0,0,0-2.48-.85l.4-2.63,10.61,1.62-.4,2.63c-2-.31-4,1.16-5.88,4.39L127.82,299l-2.77-.43-6.27-26.42c-.62-2.62-1.3-4.23-2-4.85a4.47,4.47,0,0,0-2.2-1.11l.4-2.63,16,2.44-.4,2.63a5.2,5.2,0,0,0-2.75,0,1.31,1.31,0,0,0-.68,1,3.84,3.84,0,0,0,.2,1.56l.2.78.56,2.49Zm-1.43,2.57-7.8-1.19,2.54,10.21Z"></path>
                        <path d="M79.39,279.86,78,282.12l-14.61-9.07,1.41-2.26.42.27c1.38.85,2.43,1.15,3.16.89a4.93,4.93,0,0,0,2.24-2.23l10.14-16.33a4.89,4.89,0,0,0,1-3c-.12-.76-.86-1.56-2.2-2.39l-.43-.27,1.4-2.26,14.61,9.07-1.4,2.26c-1.47-.91-2.58-1.29-3.34-1.15s-1.57.91-2.41,2.26L77.84,274.21a4.66,4.66,0,0,0-1,3.1C77,278.06,77.87,278.91,79.39,279.86Z"></path>
                        <path d="M38.31,236.68l12.44-8.26c2-1.33,3-2.54,3.13-3.65a5.24,5.24,0,0,0-1-3.35l2.22-1.48,6.75,10.17-2.22,1.47a4.8,4.8,0,0,0-2.13-1.84,3.35,3.35,0,0,0-2.26-.25A11.71,11.71,0,0,0,52.47,231l-13.82,9.18q-4.14,2.75-1.56,6.62l-2.22,1.47-6.07-9.14,6.72-25.85-9.93,6.59c-2.95,2-3.61,4.19-1.95,6.68L21.42,228,15,218.26l2.22-1.47A4.16,4.16,0,0,0,19,218.32a3.37,3.37,0,0,0,2.23.26A9,9,0,0,0,24,217.22l20.79-13.8,1.7,2.55Z"></path>
                    </g>
                </svg>
            </div>
        </div><div id="manual">
            <article>
                <section id="introduction">
                    <h2>1. <i>Introduction</i></h2>
                    <p>The <span>enemy</span> has a new form. Today's wars are fought from computer
                        consoles; climate disinformation campaigns are planned in web conferences; decisions to deny
                        healthcare are codified in software.</p>
                    <p>Free and just futures demand new strategies.</p>
                    <p>Unassuming civilians have an outsized ability to make a difference by directly impacting the
                        ordinary services we build and maintain everyday. Many small actions can create a constant and
                        tangible drag on the systems of violence and exploitation. When tyranny suffers, we create an
                        opportunity for more sustainable and prosperous systems to replace it.</p>
                    <p>These ideas are specific suggestions for taking action in this new theater.</p>
                    <p>This is not a guide for overt displays of heroism. Surveillance is abundant in the 21st century
                        work environment. Presented here are practical, everyday actions for reducing systemic harm
                        while minimizing vulnerability.</p>
                    <p>These are Specific Suggestions for <a href="https://www.gutenberg.org/ebooks/26184" target="_blank">Simple Sabotage</a> in the 21st century.</p>
                </section>

                <section id="simple-sabotage">
                    <h2>2. <i>Simple Sabotage</i></h2>
                    <ol>
                        <li>Simple sabotage is more than malicious mischief, and it should always consist of acts whose
                            results will be detrimental to the tools and systems of oppression.</li>
                        <li>Occurring on a wide scale, simple sabotage will be a constant and tangible drag on the
                            operations of hostile systems, making it possible for just, resilient, and thriving ones to
                            take their place.</li>
                        <li>Simple sabotage does not require specially prepared tools or equipment; it is executed by an
                            ordinary person, and it is carried out in such a way as to involve a minimum danger of
                            injury, detection, and retaliation.</li>
                        <li>The saboteur should be creative in using their every-day instruments. Opportunities will
                            present themselves if one looks at their surroundings in a different light. For example,
                            disabling the productivity of an entire workplace may at first seem impossible, but if the
                            saboteur were to unplug a single wifi access point within a space, work might grind to a
                            halt.</li>
                        <li>Where destruction is involved, the weapons of the saboteur are materials and tools they
                            might normally be expected to possess in their particular occupation. Their arsenal is the
                            conference room, the email client, their own usual software applications and supplies. The
                            targets of sabotage are objects to which they have normal and inconspicuous access in
                            everyday life.</li>
                        <li>There is also a type of simple sabotage that requires no destructive tools whatsoever and
                            produces physical damage, if any, by highly indirect means. It is based on universal
                            opportunities to make faulty decisions and generally slow the efficiency of a hostile
                            process. Making a faulty decision may be simply a matter of committing software changes to
                            one repository instead of another or copying the wrong person onto an email.
                            <p>
                                This type of activity, sometimes referred to as the "human element," is frequently
                                responsible for accidents, delays, and general obstruction even under normal conditions.
                                The potential saboteur should discover what types of faulty decisions and operations are
                                normally found in their work and should then devise their sabotage so as to enlarge that
                                "margin for error" while avoiding detection.
                            </p>
                        </li>
                        <li>The saboteur should never attack targets beyond their capacity or the capacity of their
                            tools. An inexperienced person should not, for example, attempt to deploy malware or falsify
                            legal documents, but should make use of familiar tools to carry out their work.</li>
                        <li>The saboteur finds power in the routine, the inconspicuous, and the mundane.</li>
                        <li>The saboteur should try to damage only objects, materials, and systems known to be used to
                            carry out oppression or to be destined for use in harmful systems. (It will be safe to
                            assume that almost any surveillance technology is destined for oppressive use.) Without
                            special knowledge, however, it would be undesirable to attempt destruction of accessibility
                            technologies or interfere with the distribution of health services.</li>
                        <li>The saboteur should never aim to hinder aid.</li>
                        <li>Potential saboteurs should vigilantly consider the extent of surveillance in contemporary
                            work environments. <strong>Assume all actions are monitored</strong> when using an
                            employer-provided digital device, such as a computer or smartphone, or on personal devices
                            after any employer-provided software is installed onto them. Devices provided for public use
                            like those in libraries should also be used with caution.</li>
                        <li>Although the saboteur may rarely have direct access to explicitly malicious processes—such
                            as eviction and displacement, ecological destruction, or the manufacture of anti-personnel
                            weapons—they should prioritize these above all others.</li>
                        <li>It will not be possible to evaluate the desirability of simple sabotage in an organization
                            without having in mind what specific individual acts and results are embraced by the
                            definition of simple sabotage.</li>
                        <li>Access to these materials should not depend upon any one individual and should be published
                            widely to increase resilience.</li>
                    </ol>
                </section>
                <section id="specific-suggestions">
                    <h2>3. <i>Specific Suggestions</i></h2>
                    <ol>
                        <li>Unplugging routers, committing buggy code, changing file extensions, acting absentminded,
                            feigning ignorance, and hiding key technologies and supplies will waste the materials,
                            manpower, and time of the enemy. Sabotage may be as mundane as leaving the caps off of
                            shared dry erase markers or as complex as supporting unprofitable business objectives.</li>
                        <li>The generator provided on this webpage suggests specific acts, classified according to
                            context.</li>
                        <li>This entire library of specific suggestions and accompanying source code is deliberately
                            placed into the public domain allowing anyone to download and repurpose for their particular
                            needs.</li>
                        <li>As new techniques are developed, or new fields explored, the public is encouraged to make
                            amendments and independently republish this reference with their own updates.</li>
                        <li>The suggestions presented here focus on novel actions within contemporary office and
                            administrative work settings. More traditional environments are better covered by the <a href="https://www.gutenberg.org/ebooks/26184" target="_blank">Simple Sabotage Field
                                Manual</a> published by the United States Office of Strategic Services.</li>
                        <li>Interactive table of specific suggestions is provided below.</li>
                        
                        
                        <p>
                            <a target="_blank" href="https://specificsuggestions.com/viewtables.html">Table Exploration Tools</a>
                        </p>
                    </ol>

                </section>
                <section id="motivation">
                    <h2>4. <i>Motivating The Saboteur</i></h2>
                    <div id="motivationQuotes" onclick="showQuote();">
                        <blockquote>
                            There's a time when the operation of the machine becomes so odious, makes you so sick at heart that you can't take part! You can't even passively take part! … That doesn't mean that you have to break anything. One thousand people sitting down some place, not letting anybody by, not [letting] anything happen, can stop any machine.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Mario_Savio');">Mario Savio</cite>
                        </blockquote>
                        <blockquote>
                            We must always take sides. Neutrality helps the oppressor, never the victim. Silence encourages the tormentor, never the tormented.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Elie_Wiesel');">Elie Wiesel</cite>
                        </blockquote>
                        <blockquote>
                            Nonviolence is a powerful and just weapon. It is a weapon unique in history, which cuts without wounding and ennobles the man who wields it. It is a sword that heals.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Martin_Luther_King_Jr.');">Martin Luther King Jr.</cite>
                        </blockquote>
                        <blockquote>
                            When we identify where our privilege intersects with somebody else's oppression, we'll find our opportunities to make real change.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Ijeoma_Oluo');">Ijeoma Oluo</cite>
                        </blockquote>
                        <blockquote>
                            When you get these jobs you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Toni_Morrison');">Toni Morrison</cite>
                        </blockquote>
                        <blockquote>Don't sit around and wait for the perfect opportunity to come along — find something and make it an opportunity.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Cecile_Richards');">Cecile Richards</cite>
                        </blockquote>
                        <blockquote>
                            Our problems stem from our acceptance of this filthy, rotten system.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Dorothy_Day');">Dorothy Day</cite>
                        </blockquote>
                        <blockquote>Colorful demonstrations and weekend marches are vital but alone are not powerful enough to stop wars. Wars will be stopped only when soldiers refuse to fight, when workers refuse to load weapons onto ships and aircraft, when people boycott the economic outposts of Empire that are strung across the globe.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Arundhati_Roy');">Arundhati Roy</cite>
                        </blockquote>
                        <blockquote>
                            Tyranny, like hell, is not easily conquered; yet we have this consolation with us, that the harder the conflict, the more glorious the triumph.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Thomas_Paine');">Thomas Paine</cite>
                        </blockquote>
                        <blockquote>自由、公正、平等是我們的目標。
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Sun_Yat-sen');">孙逸仙</cite>
                        </blockquote>
                        <blockquote>As we contemplate the vast amount of work to be done for justice and peace in this world, we trust that we will find the grace to accomplish , to believe in, and to hope for the greatest things. 
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Peter_Faber');">Peter Faber</cite>
                        </blockquote>
                        <blockquote>It is the greatest of all mistakes to do nothing because you can only do a little.  
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Sydney_Smith');">Sydney Smith</cite>
                        </blockquote>
                        </div>
                </section>
                
                <section id="publication">
                    <hr>
                    <p>Published into the Public Domain.</p>
                    <div id="dates">
                        <p>First Published: <span>NOV 28 2024</span></p>
                        <p>Updated: <span>NOV 29 2024</span></p> </div>
                </section>
            </article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese pebble-bed nuclear reactor passes "meltdown" test (137 pts)]]></title>
            <link>https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/</link>
            <guid>42275834</guid>
            <pubDate>Fri, 29 Nov 2024 18:21:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/">https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/</a>, See on <a href="https://news.ycombinator.com/item?id=42275834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="expand_6241"><p>The <a href="https://www.tsinghua.edu.cn/en/info/1399/10915.htm">Shidaowan plant</a>, a demonstration high-temperature, gas-cooled reactor with a pebble-bed module (HTR-PM), went into commercial operation last December. </p><p>Shidaowan’s twin 100-MW units house tiny uranium capsules encased in graphite shells about the size of billiard balls (dubbed “pebbles”), which make the energy density of the fuel much lower than in a traditional nuclear reactor with fuel rods. In the pebble design, the nuclear fission reaction occurs more slowly than in conventional reactors, but the fuel can withstand higher temperatures for longer and the heat resulting from the fission reaction is dispersed, enabling a passive cooling process.</p><p>The reactor doesn’t rely on large volumes of water in the cooling process—instead, a small amount of helium gas, which can withstand much higher temperatures than water, is piped through the system to naturally cool it down. If the reactor starts to get too hot, its components automatically slow down the nuclear reaction and the system cools. This setup makes such a reactor “meltdown proof,” in concept.</p><p><strong>The study:</strong> Researchers at Tsinghua University in China performed two safety tests on the Shidaowan plant’s reactor modules by shutting off active power supply to see if the decay heat could be removed passively. The responses of temperatures and nuclear power in each unit confirmed that they can be cooled down naturally, without active intervention.</p><p>“The results of the tests manifest the existence of commercial-scale inherent safety for the first time,” according to findings published in the journal <em><a href="https://www.cell.com/joule/abstract/S2542-4351(24)00290-3?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2542435124002903%3Fshowall%3Dtrue">Joule</a></em>.</p><p>The Shidaowan project is a collaboration involving Tsinghua University as a technical leader, responsible for research and development and main components and systems design; China Huaneng Group as owner and operator of the plant; and China National Nuclear Corporation as overseer of engineering and procurement and fuel manufacturing.</p><p><strong>Other pebble beds:</strong> The pebble bed technology and design has previously been used in prototype reactors in China and Germany, but not a larger-scale plant like Shidaowan.</p><p>In the U.S., X-energy is working to deploy its pebble-fueled <a href="https://x-energy.com/reactors/xe-100">Xe-100</a> design—an 80-MWe high-temperature, gas-cooled reactor that can be scaled into a four-pack to make a 320-MWe power plant. X-energy’s license request is <a href="https://www.nrc.gov/reactors/new-reactors/advanced/who-were-working-with/licensing-activities/pre-application-activities/xe-100.html">under review</a> by the Nuclear Regulatory Commission.</p><p>X-energy was <a href="https://x-energy.com/media/news-releases/x-energy-awarded-80-million-department-of-energy-advanced-reactor-demonstration-program-ardp">one of two chosen</a> for the Department of Energy’s Advanced Reactor Demonstration Program in 2020. With $160 million in initial funding, ARDP set out to help bring two advanced reactors to commercial operation within seven years. (TerraPower’s Natrium reactor is the other.)</p><p>X-energy has a joint development agreement with Dow to develop its first Xe-100 plant at the chemical company’s plant in Seadrift, Texas. X-energy is also working with Energy Northwest under a joint development agreement to bring up to 12 of the Xe-100 small modular reactors to Washington state. That project is expected to be developed at a site adjacent to Energy Northwest’s Columbia nuclear power plant.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Buy Nothing Day (167 pts)]]></title>
            <link>https://buynothingday.co.uk/</link>
            <guid>42275745</guid>
            <pubDate>Fri, 29 Nov 2024 18:10:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buynothingday.co.uk/">https://buynothingday.co.uk/</a>, See on <a href="https://news.ycombinator.com/item?id=42275745">Hacker News</a></p>
Couldn't get https://buynothingday.co.uk/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why pipes sometimes get "stuck": buffering (370 pts)]]></title>
            <link>https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/</link>
            <guid>42275033</guid>
            <pubDate>Fri, 29 Nov 2024 16:43:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/">https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/</a>, See on <a href="https://news.ycombinator.com/item?id=42275033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     <p>Here’s a niche terminal problem that has bothered me for years but that I never
really understood until a few weeks ago. Let’s say you’re running this command
to watch for some specific output in a log file:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>If log lines are being added to the file relatively slowly, the result I’d see
is… nothing! It doesn’t matter if there were matches in the log file or not,
there just wouldn’t be any output.</p>
<p>I internalized this as “uh, I guess pipes just get stuck sometimes and don’t
show me the output, that’s weird”, and I’d handle it by just
running <code>grep thing1 /some/log/file | grep thing2</code> instead, which would work.</p>
<p>So as I’ve been doing a terminal deep dive over the last few months I was
really excited to finally learn exactly why this happens.</p>
<h3 id="why-this-happens-buffering">why this happens: buffering</h3>
<p>The reason why “pipes get stuck” sometimes is that it’s VERY common for
programs to buffer their output before writing it to a pipe or file. So the
pipe is working fine, the problem is that the program never even wrote the data
to the pipe!</p>
<p>This is for performance reasons: writing all output immediately as soon as you
can uses more system calls, so it’s more efficient to save up data until you
have 8KB or so of data to write (or until the program exits) and THEN write it
to the pipe.</p>
<p>In this example:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>the problem is that <code>grep thing1</code> is saving up all of its matches until it has
8KB of data to write, which might literally never happen.</p>
<h3 id="programs-don-t-buffer-when-writing-to-a-terminal">programs don’t buffer when writing to a terminal</h3>
<p>Part of why I found this so disorienting is that <code>tail -f file | grep thing</code>
will work totally fine, but then when you add the second <code>grep</code>, it stops
working!! The reason for this is that the way <code>grep</code> handles buffering depends
on whether it’s writing to a terminal or not.</p>
<p>Here’s how <code>grep</code> (and many other programs) decides to buffer its output:</p>
<ul>
<li>Check if stdout is a terminal or not using the <code>isatty</code> function
<ul>
<li>If it’s a terminal, use line buffering (print every line immediately as soon as you have it)</li>
<li>Otherwise, use “block buffering” – only print data if you have at least 8KB or so of data to print</li>
</ul>
</li>
</ul>
<p>So if <code>grep</code> is writing directly to your terminal then you’ll see the line as
soon as it’s printed, but if it’s writing to a pipe, you won’t.</p>
<p>Of course the buffer size isn’t always 8KB for every program, it depends on the implementation. For <code>grep</code> the buffering is handled by libc, and libc’s buffer size is
defined in the <code>BUFSIZ</code> variable. <a href="https://github.com/bminor/glibc/blob/c69e8cccaff8f2d89cee43202623b33e6ef5d24a/libio/stdio.h#L100">Here’s where that’s defined in glibc</a>.</p>
<p>(as an aside: “programs do not use 8KB output buffers when writing to a
terminal” isn’t, like, a law of terminal physics, a program COULD use an 8KB
buffer when writing output to a terminal if it wanted, it would just be
extremely weird if it did that, I can’t think of any program that behaves that
way)</p>
<h3 id="commands-that-buffer-commands-that-don-t">commands that buffer &amp; commands that don’t</h3>
<p>One annoying thing about this buffering behaviour is that you kind of need to
remember which commands buffer their output when writing to a pipe.</p>
<p>Some commands that <strong>don’t</strong> buffer their output:</p>
<ul>
<li>tail</li>
<li>cat</li>
<li>tee</li>
</ul>
<p>I think almost everything else will buffer output, especially if it’s a command
where you’re likely to be using it for batch processing. Here’s a list of some
common commands that buffer their output when writing to a pipe, along with the
flag that disables block buffering.</p>
<ul>
<li>grep (<code>--line-buffered</code>)</li>
<li>sed (<code>-u</code>)</li>
<li>awk (there’s a <code>fflush()</code> function)</li>
<li>tcpdump (<code>-l</code>)</li>
<li>jq (<code>-u</code>)</li>
<li>tr (<code>-u</code>)</li>
<li>cut (can’t disable buffering)</li>
</ul>
<p>Those are all the ones I can think of, lots of unix commands (like <code>sort</code>) may
or may not buffer their output but it doesn’t matter because <code>sort</code> can’t do
anything until it finishes receiving input anyway.</p>
<p>Also I did my best to test both the Mac OS and GNU versions of these but there
are a lot of variations and I might have made some mistakes.</p>
<h3 id="programming-languages-where-the-default-print-statement-buffers">programming languages where the default “print” statement buffers</h3>
<p>Also, here are a few programming language where the default print statement
will buffer output when writing to a pipe, and some ways to disable buffering
if you want:</p>
<ul>
<li>C (disable with <code>setvbuf</code>)</li>
<li>Python (disable with <code>python -u</code>, or <code>PYTHON_UNBUFFERED=1</code>, or <code>sys.stdout.reconfigure(line_buffering=False)</code>, or <code>print(x, flush=True)</code>)</li>
<li>Ruby (disable with <code>STDOUT.sync = true</code>)</li>
<li>Perl (disable with <code>$| = 1</code>)</li>
</ul>
<p>I assume that these languages are designed this way so that the default print
function will be fast when you’re doing batch processing.</p>
<p>Also whether output is buffered or not might depend on what print function you
use, for example in Rust <code>print!</code> buffers when writing to a pipe but <code>println!</code>
will flush its output.</p>
<h3 id="when-you-press-ctrl-c-on-a-pipe-the-contents-of-the-buffer-are-lost">when you press <code>Ctrl-C</code> on a pipe, the contents of the buffer are lost</h3>
<p>Let’s say you’re running this command as a hacky way to watch for DNS requests
to <code>example.com</code>, and you forgot to pass <code>-l</code> to tcpdump:</p>
<pre><code>sudo tcpdump -ni any port 53 | grep example.com
</code></pre>
<p>When you press <code>Ctrl-C</code>, what happens? In a magical perfect world, what I would
<em>want</em> to happen is for <code>tcpdump</code> to flush its buffer, <code>grep</code> would search for
<code>example.com</code>, and I would see all the output I missed.</p>
<p>But in the real world, what happens is that all the programs get killed and the
output in <code>tcpdump</code>’s buffer is lost.</p>
<p>I think this problem is probably unavoidable – I spent a little time with
<code>strace</code> to see how this works and <code>grep</code> receives the <code>SIGINT</code> before
<code>tcpdump</code> anyway so even if <code>tcpdump</code> tried to flush its buffer <code>grep</code> would
already be dead.</p>
<h3 id="redirecting-to-a-file-also-buffers">redirecting to a file also buffers</h3>
<p>It’s not just pipes, this will also buffer:</p>
<pre><code>sudo tcpdump -ni any port 53 &gt; output.txt
</code></pre>
<p>Redirecting to a file doesn’t have the same “<code>Ctrl-C</code> will totally destroy the
contents of the buffer” problem though – in my experience it usually behaves
more like you’d want, where the contents of the buffer get written to the file
before the program exits. I’m not 100% sure whether this is something you can
always rely on or not.</p>
<h3 id="a-bunch-of-potential-ways-to-avoid-buffering">a bunch of potential ways to avoid buffering</h3>
<p>Okay, let’s talk solutions. Let’s say you’ve run this command or s</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>I asked people on Mastodon how they would solve this in practice and there were
5 basic approaches. Here they are:</p>
<h4 id="solution-1-run-a-program-that-finishes-quickly">solution 1: run a program that finishes quickly</h4>
<p>Historically my solution to this has been to just avoid the “command writing to
pipe slowly” situation completely and instead run a program that will finish quickly
like this:</p>
<pre><code>cat /some/log/file | grep thing1 | grep thing2 | tail
</code></pre>
<p>This doesn’t do the same thing as the original command but it does mean that
you get to avoid thinking about these weird buffering issues.</p>
<p>(you could also do <code>grep thing1 /some/log/file</code> but I often prefer to use an
“unnecessary” <code>cat</code>)</p>
<h4 id="solution-2-remember-the-line-buffer-flag-to-grep">solution 2: remember the “line buffer” flag to grep</h4>
<p>You could remember that grep has a flag to avoid buffering and pass it like this:</p>
<pre><code>tail -f /some/log/file | grep --line-buffered thing1 | grep thing2
</code></pre>
<h4 id="solution-3-use-awk">solution 3: use awk</h4>
<p>Some people said that if they’re specifically dealing with a multiple greps
situation, they’ll rewrite it to use a single <code>awk</code> instead, like this:</p>
<pre><code>tail -f /some/log/file |  awk '/thing1/ &amp;&amp; /thing2/'
</code></pre>
<p>Or you would write a more complicated <code>grep</code>, like this:</p>
<pre><code>tail -f /some/log/file |  grep -E 'thing1.*thing2'
</code></pre>
<p>(<code>awk</code> also buffers, so for this to work you’ll want <code>awk</code> to be the last command in the pipeline)</p>
<h4 id="solution-4-use-stdbuf">solution 4: use <code>stdbuf</code></h4>
<p><code>stdbuf</code> uses LD_PRELOAD to turn off libc’s buffering, and you can use it to turn off output buffering like this:</p>
<pre><code>tail -f /some/log/file | stdbuf -o0 grep thing1 | grep thing2
</code></pre>
<p>Like any <code>LD_PRELOAD</code> solution it’s a bit unreliable – it doesn’t work on
static binaries, I think won’t work if the program isn’t using libc’s
buffering, and doesn’t always work on Mac OS. Harry Marr has a really nice <a href="https://hmarr.com/blog/how-stdbuf-works/">How stdbuf works</a> post.</p>
<h4 id="solution-5-use-unbuffer">solution 5: use <code>unbuffer</code></h4>
<p><code>unbuffer program</code> will force the program’s output to be a TTY, which means
that it’ll behave the way it normally would on a TTY (less buffering, colour
output, etc). You could use it in this example like this:</p>
<pre><code>tail -f /some/log/file | unbuffer grep thing1 | grep thing2
</code></pre>
<p>Unlike <code>stdbuf</code> it will always work, though it might have unwanted side
effects, for example <code>grep thing1</code>’s will also colour matches.</p>
<p>If you want to install unbuffer, it’s in the <code>expect</code> package.</p>
<h3 id="that-s-all-the-solutions-i-know-about">that’s all the solutions I know about!</h3>
<p>It’s a bit hard for me to say which one is “best”, I think personally I’m
mostly likely to use <code>unbuffer</code> because I know it’s always going to work.</p>
<p>If I learn about more solutions I’ll try to add them to this post.</p>
<h3 id="i-m-not-really-sure-how-often-this-comes-up">I’m not really sure how often this comes up</h3>
<p>I think it’s not very common for me to have a program that slowly trickles data
into a pipe like this, normally if I’m using a pipe a bunch of data gets
written very quickly, processed by everything in the pipeline, and then
everything exits. The only examples I can come up with right now are:</p>
<ul>
<li>tcpdump</li>
<li><code>tail -f</code></li>
<li>watching log files in a different way like with <code>kubectl logs</code></li>
<li>the output of a slow computation</li>
</ul>
<h3 id="what-if-there-were-an-environment-variable-to-disable-buffering">what if there were an environment variable to disable buffering?</h3>
<p>I think it would be cool if there were a standard environment variable to turn
off buffering, like <code>PYTHON_UNBUFFERED</code> in Python. I got this idea from a
<a href="https://blog.plover.com/Unix/stdio-buffering.html">couple</a> of <a href="https://blog.plover.com/Unix/stdio-buffering-2.html">blog posts</a> by Mark Dominus
in 2018. Maybe <code>NO_BUFFER</code> like <a href="https://no-color.org/">NO_COLOR</a>?</p>
<p>The design seems tricky to get right; Mark points out that NETBSD has <a href="https://man.netbsd.org/setbuf.3">environment variables called <code>STDBUF</code>, <code>STDBUF1</code>, etc</a> which gives you a
ton of control over buffering but I imagine most developers don’t want to
implement many different environment variables to handle a relatively minor
edge case.</p>
<p>I’m also curious about whether there are any programs that just
automatically flush their output buffers after some period of time (like 1
second). It feels like it would be a nice solution but I can’t think of any
program that does that, maybe it’s not easy to implement?</p>
<h3 id="stuff-i-left-out">stuff I left out</h3>
<p>Some things I didn’t talk about in this post since these posts have been
getting pretty long recently and seriously does anyone REALLY want to read 3000
words about buffering?</p>
<ul>
<li>the difference between line buffering and having totally unbuffered output</li>
<li>how buffering to stderr is different from buffering to stdout</li>
<li>this post is only about buffering that happens <strong>inside the program</strong>, your
operating system’s TTY driver also does a little bit of buffering sometimes</li>
<li>other reasons you might need to flush your output other than “you’re writing
to a pipe”</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prometheus 3.0 (196 pts)]]></title>
            <link>https://prometheus.io/blog/2024/11/14/prometheus-3-0/</link>
            <guid>42274660</guid>
            <pubDate>Fri, 29 Nov 2024 15:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prometheus.io/blog/2024/11/14/prometheus-3-0/">https://prometheus.io/blog/2024/11/14/prometheus-3-0/</a>, See on <a href="https://news.ycombinator.com/item?id=42274660">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      

<p>Following the recent release of <a href="https://prometheus.io/blog/2024/09/11/prometheus-3-beta/">Prometheus 3.0 beta</a> at PromCon in Berlin, the Prometheus Team
is excited to announce the immediate availability of Prometheus Version 3.0!</p>

<p>This latest version marks a significant milestone as it is the first major release in 7 years. Prometheus has come a long way in that time, 
evolving from a project for early adopters to becoming a standard part of the cloud native monitoring stack. Prometheus 3.0 aims to 
continue that journey by adding some exciting new features while largely maintaining stability and compatibility with previous versions.</p>

<p>The full 3.0 release adds some new features on top of the beta and also introduces a few additional breaking changes that we will describe in this article.</p>


<div><ul>
<li><a href="#new-ui">New UI
</a></li>
<li><a href="#remote-write-2-0">Remote Write 2.0
</a></li>
<li><a href="#utf-8-support">UTF-8 Support
</a></li>
<li><a href="#otlp-support">OTLP Support
</a></li>
<ul>
<li><a href="#otlp-ingestion">OTLP Ingestion
</a></li>
<li><a href="#utf-8-normalization">UTF-8 Normalization
</a></li>
</ul>
<li><a href="#native-histograms">Native Histograms
</a></li>
<li><a href="#breaking-changes">Breaking Changes
</a></li>
</ul></div>

<p>Here is a summary of the exciting changes that have been released as part of the beta version, as well as what has been added since:</p>

<h2 id="new-ui">New UI<a href="#new-ui" name="new-ui"></a>
</h2>

<p>One of the highlights in Prometheus 3.0 is its brand-new UI that is enabled by default:</p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/blog_post_screenshot_tree_view-s.png" alt="New UI query page"></p>

<p>The UI has been completely rewritten with less clutter, a more modern look and feel, new features like a <a href="https://promlens.com/"><strong>PromLens</strong></a>-style tree view,
and will make future maintenance easier by using a more modern technical stack.</p>

<p>Learn more about the new UI in general in <a href="https://promlabs.com/blog/2024/09/11/a-look-at-the-new-prometheus-3-0-ui/">Julius' detailed article on the PromLabs blog</a>.
Users can temporarily enable the old UI by using the <code>old-ui</code> feature flag.</p>

<p>Since the new UI is not battle-tested yet, it is also very possible that there are still bugs. If you find any, please 
<a href="https://github.com/prometheus/prometheus/issues/new?assignees=&amp;labels=&amp;projects=&amp;template=bug_report.yml">report them on GitHub</a>.</p>

<p>Since the beta, the user interface has been updated to support UTF-8 metric and label names.</p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/utf8_ui.png" alt="New UTF-8 UI"></p>

<h2 id="remote-write-2-0">Remote Write 2.0<a href="#remote-write-2-0" name="remote-write-2-0"></a>
</h2>

<p>Remote-Write 2.0 iterates on the previous protocol version by adding native support for a host of new elements including metadata, exemplars,
created timestamp and native histograms. It also uses string interning to reduce payload size and CPU usage when compressing and decompressing. 
There is better handling for partial writes to provide more details to clients when this occurs. More details can be found
<a href="https://prometheus.io/docs/specs/remote_write_spec_2_0/">here</a>.</p>

<h2 id="utf-8-support">UTF-8 Support<a href="#utf-8-support" name="utf-8-support"></a>
</h2>

<p>Prometheus now allows all valid UTF-8 characters to be used in metric and label names by default, as well as label values,
as has been true in version 2.x.</p>

<p>Users will need to make sure their metrics producers are configured to pass UTF-8 names, and if either side does not support UTF-8,
metric names will be escaped using the traditional underscore-replacement method. PromQL queries can be written with the new quoting syntax
in order to retrieve UTF-8 metrics, or users can specify the <code>__name__</code>  label name manually.</p>

<p>Currently only the Go client library has been updated to support UTF-8, but support for other languages will be added soon.</p>

<h2 id="otlp-support">OTLP Support<a href="#otlp-support" name="otlp-support"></a>
</h2>

<p>In alignment with <a href="https://prometheus.io/blog/2024/03/14/commitment-to-opentelemetry/">our commitment to OpenTelemetry</a>, Prometheus 3.0 features 
several new features to improve interoperability with OpenTelemetry. </p>

<h3 id="otlp-ingestion">OTLP Ingestion<a href="#otlp-ingestion" name="otlp-ingestion"></a>
</h3>

<p>Prometheus can be configured as a native receiver for the OTLP Metrics protocol, receiving OTLP metrics on the <code>/api/v1/otlp/v1/metrics</code> endpoint.</p>

<p>See our <a href="https://prometheus.io/docs/guides/opentelemetry">guide</a> on best practices for consuming OTLP metric traffic into Prometheus.</p>

<h3 id="utf-8-normalization">UTF-8 Normalization<a href="#utf-8-normalization" name="utf-8-normalization"></a>
</h3>

<p>With Prometheus 3.0, thanks to <a href="#utf-8-support">UTF-8 support</a>, users can store and query OpenTelemetry metrics without annoying changes to metric and label names like <a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/translator/prometheus">changing dots to underscores</a>.</p>

<p>Notably this allows <strong>less confusion</strong> for users and tooling in terms of the discrepancy between what’s defined in OpenTelemetry semantic convention or SDK and what’s actually queryable.</p>

<p>To achieve this for OTLP ingestion, Prometheus 3.0 has experimental support for different translation strategies. See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#:%7E:text=Settings%20related%20to%20the%20OTLP%20receiver%20feature">otlp section in the Prometheus configuration</a> for details.</p>

<blockquote>

</blockquote>

<h2 id="native-histograms">Native Histograms<a href="#native-histograms" name="native-histograms"></a>
</h2>

<p>Native histograms are a Prometheus metric type that offer a higher efficiency and lower cost alternative to Classic Histograms. Rather than having to choose (and potentially have to update) bucket boundaries based on the data set, native histograms have pre-set bucket boundaries based on exponential growth.</p>

<p>Native Histograms are still experimental and not yet enabled by default, and can be turned on by passing <code>--enable-feature=native-histograms</code>. Some aspects of Native Histograms, like the text format and accessor functions / operators are still under active design.</p>

<h2 id="breaking-changes">Breaking Changes<a href="#breaking-changes" name="breaking-changes"></a>
</h2>

<p>The Prometheus community strives to <a href="https://prometheus.io/docs/prometheus/latest/stability/">not break existing features within a major release</a>. With a new major release we took the opportunity to clean up a few, but small, long-standing issues. In other words, Prometheus 3.0 contains a few breaking changes. This includes changes to feature flags, configuration files, PromQL, and scrape protocols.</p>

<p>Please read the <a href="https://prometheus.io/docs/prometheus/3.0/migration/">migration guide</a> to find out if your setup is affected and what actions to take.</p>



<p>It’s impressive to see what we have accomplished in the community since Prometheus 2.0. We all love numbers, so let’s celebrate the efficiency improvements we made for both CPU and memory use for the TSDB mode. Below you can see performance numbers between 3 Prometheus versions on the node with 8 CPU and 49 GB allocatable memory.</p>

<ul>
<li>2.0.0 (7 years ago)</li>
<li>2.18.0 (4 years ago)</li>
<li>3.0.0 (now)</li>
</ul>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/memory_bytes_ui.png" alt="Memory bytes"></p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/cpu_seconds_ui.png" alt="CPU seconds"></p>

<p>It’s furthermore impressive that those numbers were taken using our <a href="https://github.com/prometheus/prometheus/pull/15366">prombench macrobenchmark</a> 
that uses the same PromQL queries, configuration and environment–highlighting backward compatibility and stability for the core features, even with 3.0.</p>



<p>There are still tons of exciting features and improvements we can make in Prometheus and the ecosystem. Here is a non-exhaustive list to get you excited and… 
hopefully motivate you to contribute and join us!</p>

<ul>
<li>New, more inclusive <strong>governance</strong>
</li>
<li>More <strong>OpenTelemetry</strong> compatibility and features</li>
<li>OpenMetrics 2.0, now under Prometheus governance!</li>
<li>Native Histograms stability (and with custom buckets!)</li>
<li>More optimizations!</li>
<li>UTF-8 support coverage in more SDKs and tools</li>
</ul>



<p>You can try out Prometheus 3.0 by downloading it from our <a href="https://prometheus.io/download/#prometheus">official binaries</a> and <a href="https://quay.io/repository/prometheus/prometheus?tab=tags">container images</a>.</p>

<p>If you are upgrading from Prometheus 2.x, check out the migration guide for more information on any adjustments you will have to make.
Please note that we strongly recommend upgrading to v2.55 before upgrading to v3.0. Rollback is possible from v3.0 to v2.55, but not to earlier versions.</p>

<p>As always, we welcome feedback and contributions from the community!</p>


    <article>

    
    
    
  </article></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama.cpp guide – Running LLMs locally on any hardware, from scratch (340 pts)]]></title>
            <link>https://steelph0enix.github.io/posts/llama-cpp-guide/</link>
            <guid>42274489</guid>
            <pubDate>Fri, 29 Nov 2024 15:28:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steelph0enix.github.io/posts/llama-cpp-guide/">https://steelph0enix.github.io/posts/llama-cpp-guide/</a>, See on <a href="https://news.ycombinator.com/item?id=42274489">Hacker News</a></p>
Couldn't get https://steelph0enix.github.io/posts/llama-cpp-guide/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Nodezator is a generalist Python node editor (112 pts)]]></title>
            <link>https://github.com/IndiePython/nodezator</link>
            <guid>42274399</guid>
            <pubDate>Fri, 29 Nov 2024 15:14:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/IndiePython/nodezator">https://github.com/IndiePython/nodezator</a>, See on <a href="https://news.ycombinator.com/item?id=42274399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Nodezator</h2><a id="user-content-nodezator" aria-label="Permalink: Nodezator" href="#nodezator"></a></p>
<p dir="auto">Nodezator is a generalist Python node editor. It is a desktop application that works by connecting Python functions (and callables in general) visually in order to produce flexible parametric behavior/data/applications/snippets.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ed501f6cf2891791b66448048c8ae76110914ee3ff18cbf75ee4848c2d58da5d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f73637265656e73686f742e706e67"><img src="https://camo.githubusercontent.com/ed501f6cf2891791b66448048c8ae76110914ee3ff18cbf75ee4848c2d58da5d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f73637265656e73686f742e706e67" alt="nodezator screenshot" data-canonical-src="https://nodezator.com/images/screenshot.png"></a></p>
<p dir="auto">Original pomegranate tree image by <a href="https://pixabay.com/pt/users/aselvadaana-16928598/" rel="nofollow">AselvadaAna</a> can be found <a href="https://pixabay.com/pt/photos/rom%C3%A3-fruta-%C3%A1rvore-folhas-suculento-5609442/" rel="nofollow">here</a>.</p>
<p dir="auto"><strong>What Nodezator IS</strong>: a ready-to-use and versatile Python node-based interface on top of which you can define your own nodes and distribute them so others can download/install and use.</p>
<p dir="auto">Also, in addition to being able to distribute their nodes using their own means, users can also distribute them as Python libraries via <a href="https://pypi.org/" rel="nofollow">PyPI</a>.</p>
<p dir="auto">The usage of PyPI to distribute your nodes is very advantageous actually, cause it relies solely on the infrastructure already made available for free to all Python users by the <a href="https://www.python.org/psf-landing/" rel="nofollow">Python Software Foundation</a>, not on me (the developer) or some third-party unknown service/organization. This makes Nodezator a safe bet when it comes to defining and distributing your nodes.</p>
<p dir="auto"><strong>What Nodezator is NOT</strong>: Nodezator is NOT a framework, which means you can't use it to create your own node-based interface.</p>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">AI developers: Nodezator's UI struggles with the super long processing times required by artificial intelligence workflows. Even so users actually do some AI experimentation from time to time.</p>
</div>
<p dir="auto">Nodezator enables node-based programming with Python and allows its integration with regular text-based programming in Python, by letting users export their node layouts as plain Python code. This means your workflow is never overly dependent on the app itself. We guarantee your freedom!</p>
<p dir="auto">Creating nodes is very straightforward: all you need to define a node is a function, since Nodezator automatically converts functions into nodes. For instance, the function below...</p>
<div dir="auto" data-snippet-clipboard-copy-content="def get_circle_area(radius:float=0.0):
    return math.pi * (radius ** 2)

main_callable = get_circle_area"><pre><span>def</span> <span>get_circle_area</span>(<span>radius</span>:<span>float</span><span>=</span><span>0.0</span>):
    <span>return</span> <span>math</span>.<span>pi</span> <span>*</span> (<span>radius</span> <span>**</span> <span>2</span>)

<span>main_callable</span> <span>=</span> <span>get_circle_area</span></pre></div>
<p dir="auto">...is automatically turned into the following node:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4c6a3c1be4ee7d73c3ebed3f29094bea104ef07ec6b3761d40751797a8a41245/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6765745f636972636c655f617265615f6e6f64652e706e67"><img src="https://camo.githubusercontent.com/4c6a3c1be4ee7d73c3ebed3f29094bea104ef07ec6b3761d40751797a8a41245/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6765745f636972636c655f617265615f6e6f64652e706e67" alt="node image" data-canonical-src="https://nodezator.com/images/get_circle_area_node.png"></a></p>
<p dir="auto">You can store these functions/node definitions anywhere you want in your disk and once you launch Nodezator just provide the path so Nodezator can load them. The only requirement is that you organize these nodes definitions in separate files and store then in a folder (more about that further ahead in another section).</p>
<p dir="auto">You can actually turn <strong>any</strong> callable into a node very easily: classes, methods, etc. All callables available in the Python ecosystem can be turned into a node (even the ones defined in C, for instance).</p>
<p dir="auto">This means you can turn callables from existing Python libraries into nodes very easily! That is, any callable from all hundreds of thousands of projects in the Python Package Index (<a href="https://pypi.org/" rel="nofollow">PyPI</a>) can be virtually be turned into a node already!</p>
<p dir="auto">For instance, this is all you need to turn <a href="https://numpy.org/doc/stable/reference/generated/numpy.save.html" rel="nofollow">numpy.save()</a> into a node:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from numpy import save

main_callable = save

third_party_import_text = 'from numpy import save'"><pre><span>from</span> <span>numpy</span> <span>import</span> <span>save</span>

<span>main_callable</span> <span>=</span> <span>save</span>

<span>third_party_import_text</span> <span>=</span> <span>'from numpy import save'</span></pre></div>
<p dir="auto">With just those 03 lines of code you generate this node:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c97b34c4e01bb04ba0e5d3372173e7294b778427555830a1b3716e7d7768077d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e756d70795f736176652e706e67"><img src="https://camo.githubusercontent.com/c97b34c4e01bb04ba0e5d3372173e7294b778427555830a1b3716e7d7768077d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e756d70795f736176652e706e67" alt="numpy save node" data-canonical-src="https://nodezator.com/images/numpy_save.png"></a></p>
<p dir="auto">There's also a <a href="https://www.youtube.com/watch?v=GlQJvuU7Z_8" rel="nofollow">youtube video</a> presenting Nodezator:</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=GlQJvuU7Z_8" rel="nofollow"><img src="https://camo.githubusercontent.com/00529d3e77d23d8cdb0e97a39d2f04d2606b10f2f9137ac0bc9c8b520284a048/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f476c514a767555375a5f382f687164656661756c742e6a7067" alt="thumb of youtube video" data-canonical-src="https://img.youtube.com/vi/GlQJvuU7Z_8/hqdefault.jpg"></a></p>
<p dir="auto">Nodezator is made with pure Python on top of the <a href="https://pyga.me/" rel="nofollow">pygame-ce</a> library (and a bit of the excellent <a href="https://numpy.org/" rel="nofollow">numpy</a> library as well), by <a href="https://kennedyrichard.com/" rel="nofollow">Kennedy Richard Silva Guerra</a> (born in 1990), as part of the <a href="https://indiepython.com/" rel="nofollow">Indie Python</a> project.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Despite being maintained mostly by a single person, Nodezator is a serious and active project that gets a couple of large releases every year.</p>
</div>
<p dir="auto">We recommend Nodezator for <strong>intermediate Python users</strong>. Or, in case you are not a programmer, have an intermediate Python user next to you so that person can help you set up a no-code/low-code workflow for you.</p>
<p dir="auto">Nodezator can already be used in production and supports a vast variety of workflows. It still has a long way to go, though. So, please, be patient and also consider supporting it: <a href="https://indiepython.com/donate" rel="nofollow">https://indiepython.com/donate</a></p>
<p dir="auto">After you finish reading this README file, you may also want to visit Nodezator's homepage: <a href="https://nodezator.com/" rel="nofollow">https://nodezator.com</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">On top of making it very easy to define nodes, Nodezator comes packed full of useful features for both Python programmers and other professionals that (likely with the help of a fellow programmer) can setup a no-code/low-code workflow.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Work effortlessly with other libraries</h3><a id="user-content-work-effortlessly-with-other-libraries" aria-label="Permalink: Work effortlessly with other libraries" href="#work-effortlessly-with-other-libraries"></a></p>
<p dir="auto">As we said before, Nodezator allows you to convert callables from third-party libraries with minimal effort. Here are just a few screenshots showing the usage of Nodezator with different libraries.</p>
<p dir="auto">Here's is a simple graph showing Nodezator usage with the <a href="https://python-pillow.org/" rel="nofollow">Pillow</a> library.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9d5bf7e4a31496113356d5f0c75392bdd89516affb8c400c40eb1414e57fb4ae/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f70696c6c6f775f64656d6f2e706e67"><img src="https://camo.githubusercontent.com/9d5bf7e4a31496113356d5f0c75392bdd89516affb8c400c40eb1414e57fb4ae/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f70696c6c6f775f64656d6f2e706e67" alt="Pillow demonstration" data-canonical-src="https://nodezator.com/images/nodezator_pillow_demo.png"></a></p>
<p dir="auto">Original strawberry basket image by <a href="https://pixabay.com/pt/users/nickype-10327513/" rel="nofollow">NickyPe</a> can be found <a href="https://pixabay.com/pt/photos/morangos-fruta-refei%c3%a7%c3%a3o-vermelho-4255928/" rel="nofollow">here</a>.</p>
<p dir="auto">And here's another one showing the usage of <a href="https://matplotlib.org/" rel="nofollow">matplotlib</a> to generate charts.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f7a6aba4f9980f25019743f6a55a5ea2c4ff38497164afef16c20792e4f64c37/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f6d6174706c6f746c69625f64656d6f2e706e67"><img src="https://camo.githubusercontent.com/f7a6aba4f9980f25019743f6a55a5ea2c4ff38497164afef16c20792e4f64c37/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f6d6174706c6f746c69625f64656d6f2e706e67" alt="Matplotlib demonstration" data-canonical-src="https://nodezator.com/images/nodezator_matplotlib_demo.png"></a></p>
<p dir="auto">And a more complex graph showing usage of the <a href="https://github.com/CadQuery/cadquery">CadQuery</a> library to generate a 3D model along with a 2D preview shown in the graph itself:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/be6c242214377170040da61179bfdcfc8f15438d987e74f0c3478044d6454164/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f63616471756572795f64656d6f2e706e67"><img src="https://camo.githubusercontent.com/be6c242214377170040da61179bfdcfc8f15438d987e74f0c3478044d6454164/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64657a61746f725f63616471756572795f64656d6f2e706e67" alt="CadQuery demonstration" data-canonical-src="https://nodezator.com/images/nodezator_cadquery_demo.png"></a></p>
<p dir="auto">The CadQuery graph above in particular uses only nodes available by default in Nodezator (you can tell cause nodes available by default either do not have a header or have a black one, whereas custom nodes have colored headers). That is, we didn't even need to create custom nodes to achieve those results.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nodezator is Python</h3><a id="user-content-nodezator-is-python" aria-label="Permalink: Nodezator is Python" href="#nodezator-is-python"></a></p>
<p dir="auto">On top of being able to define nodes directly from Python functions/callables, any graph in Nodezator can be directly exported back as Python code. This means you are never overly dependent on the app.</p>
<p dir="auto">If you ever create nodes and graphs in another app, it will be much harder to port all the codebase you built over the time to plain Python or another Python API. In Nodezator, this problem is much reduced cause it requires much less changes in your code in order for it to be loaded in the app and you can convert graphs you create on it back to Python scripts.</p>
<p dir="auto">Check the example at the top of this <code>README</code> document again, for instance. The only change required was to add a simple line: <code>main_callable = ...</code>.</p>
<p dir="auto">If you were to use other apps you'd probably have to export a class and subclass it in order to define a node, increasing the complexity of you code and its reliance on external interfaces and tech. Most other apps don't even offer the ability to export your graphs back as Python code.</p>
<p dir="auto">As an example of Nodezator's Python exporting capabilities, here's a simple graph followed by the Python code exported from it:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b3897f092c6b06168b07b55dbcdca0c3767ecb05c71ece0c760a6f182892621b/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f67726170685f746f5f62655f6578706f727465645f61735f707974686f6e2e706e67"><img src="https://camo.githubusercontent.com/b3897f092c6b06168b07b55dbcdca0c3767ecb05c71ece0c760a6f182892621b/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f67726170685f746f5f62655f6578706f727465645f61735f707974686f6e2e706e67" alt="Graph to be exported as Python" data-canonical-src="https://nodezator.com/images/graph_to_be_exported_as_python.png"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="### main function

def temp_2024_08_30_11_11_12():
    &quot;&quot;&quot;Execute script version of Python visual graph.&quot;&quot;&quot;

    _1_number_b = 10
    _0_number_a = 10
    _2_output = _0_number_a + _1_number_b
    _3_output = print(*(_2_output, ), sep=' ', end='\n', flush=False, )


if __name__ == '__main__':
    temp_2024_08_30_11_11_12()"><pre><span>### main function</span>

<span>def</span> <span>temp_2024_08_30_11_11_12</span>():
    <span>"""Execute script version of Python visual graph."""</span>

    <span>_1_number_b</span> <span>=</span> <span>10</span>
    <span>_0_number_a</span> <span>=</span> <span>10</span>
    <span>_2_output</span> <span>=</span> <span>_0_number_a</span> <span>+</span> <span>_1_number_b</span>
    <span>_3_output</span> <span>=</span> <span>print</span>(<span>*</span>(<span>_2_output</span>, ), <span>sep</span><span>=</span><span>' '</span>, <span>end</span><span>=</span><span>'<span>\n</span>'</span>, <span>flush</span><span>=</span><span>False</span>, )


<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span>:
    <span>temp_2024_08_30_11_11_12</span>()</pre></div>
<p dir="auto">Nodezator can export graphs of any size and complexity as Python code, including graphs containing user-defined nodes.</p>
<p dir="auto">Simply put, Nodezator is just a visual, node-based representation of Python.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Socket proximity detection</h3><a id="user-content-socket-proximity-detection" aria-label="Permalink: Socket proximity detection" href="#socket-proximity-detection"></a></p>
<p dir="auto">Having to click exactly over a socket to drag a new connection out of it and on top of that having to drop such new connection exactly on top of another socket are both repetitive tasks that are difficult to do right in one quick motion. Often, people loose precious time trying to ensure the mouse is exactly over the desired socket, specially considering how often those tasks are performed in any graph edition session.</p>
<p dir="auto">Because of that, Nodezator features socket proximity detection to assist the user when establishing or replacing existing connection. The user doesn't need to click exactly over a socket to drag a new connection out of it anymore. Dropping the new connection exactly over the other socket isn't necessary either. As long as the mouse is close enough, these actions can be carried over effortlessly. Here you can see it in action:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/da3734a61dd0eac6f0fcb3941513d2cf4c87bbee68f81f2189900bfc48b6aa05/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f68616e64735f616e645f657965732e676966"><img src="https://camo.githubusercontent.com/da3734a61dd0eac6f0fcb3941513d2cf4c87bbee68f81f2189900bfc48b6aa05/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f68616e64735f616e645f657965732e676966" alt="Socket detection demonstration" data-animated-image="" data-canonical-src="https://nodezator.com/images/socket_detection_hands_and_eyes.gif"></a></p>
<p dir="auto">The user can even customize how close the mouse needs to be for the socket to be detected and for the connection to be recognized!</p>
<p dir="auto">On top of that, there's no need to worry about being precise with your mouse motion either, cause the connection is only confirmed if the user releases the mouse. This way you can freely move the mouse near a desired socket with no fear of it being accidentally connected to another socket next to it:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1241a483c123b23fdf381eebb309260bb9ffd2b50f85e113f1cc0e340447f607/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f6e6561725f6d616e795f736f636b6574732e676966"><img src="https://camo.githubusercontent.com/1241a483c123b23fdf381eebb309260bb9ffd2b50f85e113f1cc0e340447f607/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f6e6561725f6d616e795f736f636b6574732e676966" alt="Socket detection near many sockets" data-animated-image="" data-canonical-src="https://nodezator.com/images/socket_detection_near_many_sockets.gif"></a></p>
<p dir="auto">Users can even choose the detection graphics used. From the most serious and distraction-free to the most fun and silly ones:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2b9cf6ebe872dfb4ce1c47b576d55bcb9063ee31a63dc1c84701cf55adf6f0d2/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f617373697374696e675f6c696e652e676966"><img src="https://camo.githubusercontent.com/2b9cf6ebe872dfb4ce1c47b576d55bcb9063ee31a63dc1c84701cf55adf6f0d2/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f617373697374696e675f6c696e652e676966" alt="Socket detection using assisting line" data-animated-image="" data-canonical-src="https://nodezator.com/images/socket_detection_assisting_line.gif"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0ef5035aa0e19a6c12c65add613321a6dbabae6b5847a9aaf1812c0e86625c0a/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f6261736562616c6c5f656c656d656e74735f616e645f657965732e676966"><img src="https://camo.githubusercontent.com/0ef5035aa0e19a6c12c65add613321a6dbabae6b5847a9aaf1812c0e86625c0a/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f636b65745f646574656374696f6e5f6261736562616c6c5f656c656d656e74735f616e645f657965732e676966" alt="Socket detection using baseball elements and eyes" data-animated-image="" data-canonical-src="https://nodezator.com/images/socket_detection_baseball_elements_and_eyes.gif"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Additional Python-related tools</h3><a id="user-content-additional-python-related-tools" aria-label="Permalink: Additional Python-related tools" href="#additional-python-related-tools"></a></p>
<p dir="auto">Being a node-based representation of Python, Nodezator includes a few extra features that help you access Python features in a node-based interface.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Variable-kind parameters (<code>*args</code> and <code>**kwargs</code>)</h4><a id="user-content-variable-kind-parameters-args-and-kwargs" aria-label="Permalink: Variable-kind parameters (*args and **kwargs)" href="#variable-kind-parameters-args-and-kwargs"></a></p>
<p dir="auto">Nodezator offers the ability to define nodes with variable-kind parameters, that is, <code>*args</code> and <code>**kwargs</code>, parameters that can receive as arguments as needed. All you need is for the callabe you create/provide to have such parameters (of course, you can name these parameters whatever you want, as long as they have the <code>*</code> or <code>**</code> to indicate their kind).</p>
<p dir="auto">This results in nodes with placeholder sockets that accept as many connections as needed. They do so by creating an additional socket on the node for each connection received. Like so:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/84cbdd0e129dcee9de9c14f3ddf92896cbba9f6e2bd73665bdb74afc2674cfea/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f636f6e6e656374696e675f746f5f7661726961626c655f6b696e645f706172616d657465722e676966"><img src="https://camo.githubusercontent.com/84cbdd0e129dcee9de9c14f3ddf92896cbba9f6e2bd73665bdb74afc2674cfea/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f636f6e6e656374696e675f746f5f7661726961626c655f6b696e645f706172616d657465722e676966" alt="Connecting sockets to a variable-kind parameters" data-animated-image="" data-canonical-src="https://nodezator.com/images/connecting_to_variable_kind_parameter.gif"></a></p>
<p dir="auto">If the received argument is an iterable, you can even unpack it by right-clicking the socket receiving the argument and selecting the corresponding option in the menu that pops up:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/359447049dc411fc1b1137b47b7585c06cf9687c40c4bc018d78c6f5476a1f80/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f756e7061636b696e675f72656365697665645f6172672e676966"><img src="https://camo.githubusercontent.com/359447049dc411fc1b1137b47b7585c06cf9687c40c4bc018d78c6f5476a1f80/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f756e7061636b696e675f72656365697665645f6172672e676966" alt="Unpacking argument received in a variable-kind parameter" data-animated-image="" data-canonical-src="https://nodezator.com/images/unpacking_received_arg.gif"></a></p>
<p dir="auto">Dictionaries/mappings can be dict-unpacked in the same way:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9ef876625be10a3add08fda25bec4e3c6b575a86bc6d133e7792c47e02db907d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f646963745f756e7061636b696e675f72656365697665645f6172672e676966"><img src="https://camo.githubusercontent.com/9ef876625be10a3add08fda25bec4e3c6b575a86bc6d133e7792c47e02db907d/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f646963745f756e7061636b696e675f72656365697665645f6172672e676966" alt="Dict-unpacking argument received in a variable-kind parameter" data-animated-image="" data-canonical-src="https://nodezator.com/images/dict_unpacking_received_arg.gif"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Specialized widgets</h4><a id="user-content-specialized-widgets" aria-label="Permalink: Specialized widgets" href="#specialized-widgets"></a></p>
<p dir="auto">Although Nodezator still has much to implement when it comes to widget support, it already offers widgets with many useful features for Pythonistas.</p>
<p dir="auto">Take the entry used for holding and editing integers and floats, for instance: in addition to allowing the user to click and drag the mouse in both directions to increment or decrement the value and writing simple arithmetic expressions (features that are present in other node editors, like Blender's), also allow users to write expressions using some Python built-in functions and some functions from standard library modules.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/043c5c99c925baa5c241e27da7a322e4f5d1cb7fb2f037a9eafc6af4ee3c5f97/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f66656174757265735f6f665f696e745f666c6f61745f656e7472792e676966"><img src="https://camo.githubusercontent.com/043c5c99c925baa5c241e27da7a322e4f5d1cb7fb2f037a9eafc6af4ee3c5f97/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f66656174757265735f6f665f696e745f666c6f61745f656e7472792e676966" alt="Features of entry used to hold integers/floats" data-animated-image="" data-canonical-src="https://nodezator.com/images/features_of_int_float_entry.gif"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Functional style programming</h4><a id="user-content-functional-style-programming" aria-label="Permalink: Functional style programming" href="#functional-style-programming"></a></p>
<p dir="auto">In addition to representing a call to a specific function/callable, a node can also represent a reference to the function/callable itself. This unlocks powerful capabilities like the usage of higher-order functions and other functional programming tools/concepts.</p>
<p dir="auto">All you need to do for a node to reference its callable (instead of a call to it), is to right-click the node and change its mode to <code>callable</code> in the menu that pops up, like this:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6d081a499b23276b5006f958fd2d9a15272b9b321678eafcd8fed9e310fe882b/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6d616b696e675f6e6f64655f7265666572656e63655f7468655f63616c6c61626c652e676966"><img src="https://camo.githubusercontent.com/6d081a499b23276b5006f958fd2d9a15272b9b321678eafcd8fed9e310fe882b/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6d616b696e675f6e6f64655f7265666572656e63655f7468655f63616c6c61626c652e676966" alt="Making a node reference its callable" data-animated-image="" data-canonical-src="https://nodezator.com/images/making_node_reference_the_callable.gif"></a></p>
<p dir="auto">As explained on <a href="https://docs.python.org/3/howto/functional.html" rel="nofollow">Python's Functional Programming HOWTO</a> and programming with Python in a functional style offers many advantages, both theoretical and practical:</p>
<ul dir="auto">
<li>Formal provability</li>
<li>Modularity</li>
<li>Composability</li>
<li>Ease of debugging and testing</li>
</ul>
<p dir="auto">For instance, the <code>pow</code> node, which represents Python's built-in function <a href="https://docs.python.org/3/library/functions.html#pow" rel="nofollow">pow</a>, can be used to calculate the power of several numbers at once instead of just a single number, when used in callable mode, in conjunction with the <code>map</code> node, which represents the higher-order built-in function <a href="https://docs.python.org/3/library/functions.html#map" rel="nofollow">map</a>. Like in the graph below where we produce and display a list of numbers to the power of 2 from a given range of integers:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/aa17e26d1ef7ab334caa04fab02606e476b0e674a70922d716196fb817b9814c/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f706f775f63616c6c61626c655f6d6f64655f64656d6f2e706e67"><img src="https://camo.githubusercontent.com/aa17e26d1ef7ab334caa04fab02606e476b0e674a70922d716196fb817b9814c/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f706f775f63616c6c61626c655f6d6f64655f64656d6f2e706e67" alt="Using the pow node in callable mode" data-canonical-src="https://nodezator.com/images/pow_callable_mode_demo.png"></a></p>
<p dir="auto">Again, Nodezator is just a node-based visual representation of Python, so it is only natural that we also offer such capability.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How nodes are created, loaded and distributed</h2><a id="user-content-how-nodes-are-created-loaded-and-distributed" aria-label="Permalink: How nodes are created, loaded and distributed" href="#how-nodes-are-created-loaded-and-distributed"></a></p>
<p dir="auto">Nodezator already comes with a lot of useful general nodes representing common Python operations, built-ins and callables from the standard library. You can easily spot them cause they either have a black header or no header at all, like demonstrated in the image below:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/088165e753670ef245185e231193cdf59a9512b482cc22ea5176b27e7b12b156/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f6d655f64656661756c745f6e6f6465732e706e67"><img src="https://camo.githubusercontent.com/088165e753670ef245185e231193cdf59a9512b482cc22ea5176b27e7b12b156/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f736f6d655f64656661756c745f6e6f6465732e706e67" alt="some default nodes" data-canonical-src="https://nodezator.com/images/some_default_nodes.png"></a></p>
<p dir="auto">Original cherries image by <a href="https://pixabay.com/pt/users/congerdesign-509903/" rel="nofollow">congerdesign</a> can be found <a href="https://pixabay.com/pt/photos/cerejas-fruta-doce-de-cereja-1503977/" rel="nofollow">here</a>.</p>
<p dir="auto">However, users are encouraged to define their own nodes for their specific purposes, or use existing nodes from other users. Nodes defined by users have colored headers (green, blue, etc.), like the one below:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/76dfb9a14c2499d917606bde913e020fcd60cf5a36432547e66ee83d011f714c/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64652e706e67"><img src="https://camo.githubusercontent.com/76dfb9a14c2499d917606bde913e020fcd60cf5a36432547e66ee83d011f714c/68747470733a2f2f6e6f64657a61746f722e636f6d2f696d616765732f6e6f64652e706e67" alt="A user-defined node" data-canonical-src="https://nodezator.com/images/node.png"></a></p>
<p dir="auto">Nodes are created from Python scripts organized within folders that we call <strong>node packs</strong>. You can create a node pack folder <strong>anywhere you want in your disk</strong>. Under the hood, Nodezator treats it as a package in some contexts, so you can name that folder whatever you like, as long as it is a Python identifier. That is, it must start with a letter or underscore and contain only letters, digits and underscores.</p>
<p dir="auto">In other words, you <strong>create nodes by writing Python functions/callables using your preferred text editor or IDE</strong> and only then you <strong>launch Nodezator in order to load them as nodes</strong>, so you can create, edit and execute graphs.</p>
<p dir="auto">Since node packs are just folders containing your Python functions/callables, you can:</p>
<ul dir="auto">
<li>keep them local to your own machine;</li>
<li>share them with other people by your own means (in a pen drive or over the internet, etc.);</li>
<li>upload them to <a href="https://pypi.org/" rel="nofollow">PyPI</a> (the Python Package Index) as Python packages so anyone can install them with the <code>pip</code> command;</li>
</ul>
<p dir="auto">This chapter of the manual teaches you how to define your own node packs: <a href="https://manual.nodezator.com/ch-defining-your-first-node.html" rel="nofollow">defining your first node</a>.</p>
<p dir="auto">Node scripts are meant to be completely independent from one another, that is, they shouldn't import resources from one another. However, when necesary, you can make common resources available to them so they can import such resources.</p>
<p dir="auto">In case you need to do that, all you have to do to <strong>share common resources among your nodes</strong> is to create an additional library/package and place it in your <code>site-packages</code> directory. Then, in each node script that needs such resources, you can simply import from that library/package.</p>
<p dir="auto">The process is also explained in the first chapter of the manual we linked earlier. The chapters following it are also useful to learn additional ways to define nodes and access more features.</p>
<p dir="auto">To learn how to load node packs, you can check this chapter: <a href="https://manual.nodezator.com/ch-loading-nodes.html" rel="nofollow">loading nodes</a>.</p>
<p dir="auto">Finally, to learn all the different ways by which you can distribute node packs, you can check this chapter: <a href="https://manual.nodezator.com/ch-distributing-nodes.html" rel="nofollow">distributing your nodes</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Finding and letting people find nodes for download</h2><a id="user-content-finding-and-letting-people-find-nodes-for-download" aria-label="Permalink: Finding and letting people find nodes for download" href="#finding-and-letting-people-find-nodes-for-download"></a></p>
<p dir="auto">Once you distributed your nodes, you may want a place wherein to let people know they exist! Or maybe you yourself is looking for nodes to download.</p>
<p dir="auto">You can do all this on the <a href="https://gallery.nodezator.com/" rel="nofollow">nodes gallery</a> website. There you can search node packs by name, author and tags.</p>
<p dir="auto">To have a link to your node pack added to the nodes gallery/database, upload it somewhere people can download/install it from, as described in the manual's chapter about <a href="https://manual.nodezator.com/ch-distributing-nodes.html" rel="nofollow">distributing your nodes</a>, then submit the relevant info about your node pack in this <a href="https://docs.google.com/forms/d/e/1FAIpQLSd1XceOnzEeaBZcpkkXEFiAVO_5YUbd43sieQUekh1PZ8dm5A/viewform?usp=sf_link" rel="nofollow">node pack submission form</a>. Alternatively, you can also submit a pull request to the <a href="https://github.com/IndiePython/gallery.nodezator.com">nodes gallery repository</a> on github following the instructions on the README.md file.</p>
<p dir="auto">You can also <a href="mailto:kennedy@kennedyrichard.com">email</a> me if you need any help.</p>
<p dir="auto">Remember that before loading nodes you download from the web you might need to install extra modules if the nodes use them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation/usage</h2><a id="user-content-installationusage" aria-label="Permalink: Installation/usage" href="#installationusage"></a></p>
<p dir="auto">To launch and use Nodezator you can either install it with <code>pip</code> or you can just download the source and launch Nodezator as a standalone/portable application (that is, without installing it).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installing Nodezator with pip</h3><a id="user-content-installing-nodezator-with-pip" aria-label="Permalink: Installing Nodezator with pip" href="#installing-nodezator-with-pip"></a></p>
<p dir="auto">If you want to install it, just execute the command below. It will install nodezator and also, if not available yet, <a href="https://pyga.me/" rel="nofollow">pygame-ce</a> and <a href="https://numpy.org/" rel="nofollow">numpy</a>.</p>
<div data-snippet-clipboard-copy-content="pip install --upgrade nodezator"><pre><code>pip install --upgrade nodezator
</code></pre></div>
<p dir="auto">If everything goes well, after installing you should be able to launch the app by typing <code>nodezator</code> or <code>python -m nodezator</code> in your command line (or <code>python3 -m nodezator</code> depending on you system).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Nodezator as a standalone/portable app (without installing it)</h3><a id="user-content-using-nodezator-as-a-standaloneportable-app-without-installing-it" aria-label="Permalink: Using Nodezator as a standalone/portable app (without installing it)" href="#using-nodezator-as-a-standaloneportable-app-without-installing-it"></a></p>
<p dir="auto">If you want to use Nodezator without installing it, you'll need 02 things:</p>
<ul dir="auto">
<li>to have Python installed in your system along with the <a href="https://pyga.me/" rel="nofollow">pygame-ce</a> and <a href="https://numpy.org/" rel="nofollow">numpy</a> libraries;</li>
<li>to download Nodezator's source (the <code>nodezator</code> folder in the top level of this repository).</li>
</ul>
<p dir="auto">Then, to launch the app, you just need to go to the location where you put the <code>nodezator</code> folder containing the source (not inside it), open the command line and run <code>python -m nodezator</code> or <code>python3 -m nodezator</code>, depending on your system.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">User Manual</h2><a id="user-content-user-manual" aria-label="Permalink: User Manual" href="#user-manual"></a></p>
<p dir="auto">Check the user <a href="https://manual.nodezator.com/" rel="nofollow">manual</a> to know how to use Nodezator.</p>
<p dir="auto">The manual is also available inside the app in the menu <strong>Help &gt; Open manual</strong>.</p>
<p dir="auto">The in-app version is always the most accurate, since it is updated first, whereas the web version is exported from it. Nonetheless, effort is made to always keep both of them up to date and in sync.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Everyone is welcome to suggest and contribute changes.</p>
<p dir="auto">If the proposed change is small enough, you can submit your pull request for analysis right away and it will be answered ASAP.</p>
<p dir="auto">More complex pull requests will also be welcome in the future, but due to the complexity of the app, I will first need to implement some automated GUI tests to ensure everyone's future contributions do not break each other.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Issues</h2><a id="user-content-issues" aria-label="Permalink: Issues" href="#issues"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Urgent/critical issues</h3><a id="user-content-urgentcritical-issues" aria-label="Permalink: Urgent/critical issues" href="#urgentcritical-issues"></a></p>
<p dir="auto">If you find a bug that...</p>
<ul dir="auto">
<li>causes Nodezator to crash;</li>
<li>representing something malfunctioning or not working at all;</li>
</ul>
<p dir="auto">...then, please, use <a href="https://github.com/IndiePython/nodezator/issues">github issues</a> to submit an issue as soon as possible.</p>
<p dir="auto">Please, include as much information as you can:</p>
<ul dir="auto">
<li>your operating system;</li>
<li>your Python version;</li>
<li>what was your goal;</li>
<li>the steps that resulted in the problem;</li>
<li>screenshots/videos, if applicable.</li>
</ul>
<p dir="auto">If possible, also read the Nodezator's <a href="https://manual.nodezator.com/" rel="nofollow">manual</a> to ensure you are doing everything as they are supposed to be done. I often find myself wondering if I there is any problem only to later find out that I was doing something wrong myself.</p>
<p dir="auto">Nevertheless, never hesitate to ask for help, even if you don't have much info about the problem or don't have any technical expertise.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Minor issues</h3><a id="user-content-minor-issues" aria-label="Permalink: Minor issues" href="#minor-issues"></a></p>
<p dir="auto">If however, the problem is not as serious/urgent, that is, it doesn't cause Nodezator to crash or malfunction, then, please, open a discussion on <a href="https://github.com/IndiePython/nodezator/discussions">github discussions</a> instead. There's a dedicated category for this kind of problem called "Minor issue".</p>
<p dir="auto">It doesn't mean your issue is any less important. It is just that in Nodezator and other Indie Python repos we use <a href="https://github.com/IndiePython/nodezator/issues">github issues</a> for things that crash the app or otherwise prevent the user from doing something that is supposed to be available (stuff that cause crashes or malfunctioning). When such a critical issue appears, any other work is paused and all attention is given to that issue so that it can be fixed ASAP.</p>
<p dir="auto">This measure is taken for the benefit of the users: by doing things this way, whenever you have an urgent/critical issue, it won't compete for space with other less urgent matters. We'll be able to promptly schedule time to solve the issue.</p>
<p dir="auto">Minor issues, suggestions of improvements, feature requests, feedback about bad experiences, etc. are all important, but they don't have the same urgency as something that crashes the app or causes it to malfunction. This is why we use <a href="https://github.com/IndiePython/nodezator/discussions">github discussions</a> for the less urgent stuff. They'll be tended to all the same, just not with the same urgency.</p>
<p dir="auto">Of course, <a href="https://github.com/IndiePython/nodezator/discussions">github discussions</a> is used for many other important stuff as well, as we'll see in the next section.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Discussions/forum</h2><a id="user-content-discussionsforum" aria-label="Permalink: Discussions/forum" href="#discussionsforum"></a></p>
<p dir="auto">Consider <a href="https://github.com/IndiePython/nodezator/discussions">github discussions</a> as the official online forum for Nodezator.</p>
<p dir="auto">It is used for many things like announcements to the community, to list planned/requested features, to communicate and discuss current work, etc.</p>
<p dir="auto">If you have...</p>
<ul dir="auto">
<li>feedback;</li>
<li>suggestions;</li>
<li>ideas;</li>
<li>concerns;</li>
<li>questions;</li>
<li>constructive criticism;</li>
<li>minor issues that don't cause the app to crash or malfunction;</li>
</ul>
<p dir="auto">...you are encouraged to post there.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">Contact me any time via <a href="https://x.com/KennedyRichard" rel="nofollow">Twitter/X</a> or <a href="mailto:kennedy@kennedyrichard.com">email</a>.</p>
<p dir="auto">You are also welcome on the Indie Python's <a href="https://indiepython.com/discord" rel="nofollow">discord server</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Patreon and donations</h2><a id="user-content-patreon-and-donations" aria-label="Permalink: Patreon and donations" href="#patreon-and-donations"></a></p>
<p dir="auto">Please, support Nodezator and other useful apps of the Indie Python project by becoming our patron on <a href="https://patreon.com/KennedyRichard" rel="nofollow">patreon</a>. You can also make recurrent donations using <a href="https://github.com/sponsors/KennedyRichard">github sponsors</a>, <a href="https://liberapay.com/KennedyRichard" rel="nofollow">liberapay</a> or <a href="https://ko-fi.com/kennedyrichard" rel="nofollow">Ko-fi</a>.</p>
<p dir="auto">Both <a href="https://github.com/sponsors/KennedyRichard">github sponsors</a> and <a href="https://ko-fi.com/kennedyrichard" rel="nofollow">Ko-fi</a> also accept one-time donations.</p>
<p dir="auto">Any amount is welcome and helps. Check the project's <a href="https://indiepython.com/donate" rel="nofollow">donation page</a> for all donation methods available.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Nodezator's source is dedicated to the public domain with <a href="https://unlicense.org/" rel="nofollow">The Unlicense</a>.</p>
<p dir="auto">The <code>nodezator_icons</code> font used in the app for its icons was created by me and is dedicated to the public domain with a <a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 license</a>. All other fonts are not mine and are licensed under the <a href="https://en.wikipedia.org/wiki/SIL_Open_Font_License" rel="nofollow">Open Font License</a>.</p>
<p dir="auto">The logos/images listed below, featured in Nodezator's splash screen (and sometimes in other spots in the app), are all mine:</p>
<ul dir="auto">
<li>the Kennedy Richard "KR" logo;</li>
<li>the Indie Python project logo;</li>
<li>the Nodezator logo;</li>
<li>the robot, called Zenith Green, Nodezator's mascot.</li>
</ul>
<p dir="auto">Please, don't use them for questionable ends. Use them only as references to the stuff they represent.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code quality</h2><a id="user-content-code-quality" aria-label="Permalink: Code quality" href="#code-quality"></a></p>
<p dir="auto">Nodezator is the result of more than 04 years of development. Some of the code was reviewed and refactored many times and is not only carefully designed but also commented in detail, as if you were on a field/school trip inside the code. A few unit tests are available as well. Also, whenever possible, I kept the line count of the modules close to 500 lines.</p>
<p dir="auto">Other parts of the code, however, specially the most recent ones, are not so refined. Bear this in mind as you browse the code for the first time. Expect such parts of the code to be refactored and properly commented in the future.</p>
<p dir="auto">Also, other parts of the code, despite being carefully designed, might be redesigned in the future, since now that the app is published, it should evolve as we find problems and contribute to improve the app. In other words, some of the design may change in the future, so bear in mind that the software is still evolving.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>