<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 17 Dec 2024 11:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Running NetBSD on IBM ThinkPad 380Z (149 pts)]]></title>
            <link>https://luke8086.dev/netbsd-on-thinkpad-380z.html</link>
            <guid>42438431</guid>
            <pubDate>Tue, 17 Dec 2024 04:51:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://luke8086.dev/netbsd-on-thinkpad-380z.html">https://luke8086.dev/netbsd-on-thinkpad-380z.html</a>, See on <a href="https://news.ycombinator.com/item?id=42438431">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>
  Launched in 1998, the 380Z was one very fine ThinkPad.

  It was the last ThinkPad to come in the classic bulky and rectangular form factor.

  It was also one of the first to feature a huge 13.3" TFT display, powerful 233MHz Pentium II, and whopping 160 megs of RAM.
</p>

<p>
  I recently stumbled upon one in perfect condition on eBay, and immediately thought it'd be a cool vintage gadget to put on the desk.

  I only wondered if I could still use it for some slow-paced, distraction-free coding, using reasonably modern software.
</p>

<p>
  I evaluated a bunch of contemporary operating systems, including different variants of BSD and Linux.

  Usually, the experience was underwhelming in terms of performance, hardware support and stability.

  Well... except for NetBSD, which gave me such perfectly smooth ride, that I thought it was worth sharing.
</p>

<img src="https://luke8086.dev/images/netbsd-photo-380z.jpg" alt="ThinkPad 380Z booting NetBSD">

<h2>Upgrading hard drive</h2>

<p>
  First things first, to improve performance, I've replaced the original HDD with a 16GB mSATA.

  The 380Z comes with a standard 44-pin PATA interface, so I plugged it in through a generic mSATA-to-PATA adapter.

  It works <i>almost</i> seamlessly.
</p>

<p>
  One minor issue is that the BIOS-reported size is limited to 8GB.

  It doesn't matter to operating systems, but confuses some bootloaders.

  In general it's safer to use a smaller root partition and a separate one for <code>/home</code>. 

  However, NetBSD worked just fine off a single full-disk partition.
</p>

<h2>Connecting to network</h2>

<p>
  The 380Z doesn't have a built-in network card.

  Fortunately it has both CardBus and USB slots, so there are plenty of options.
</p>

<p>
  One that worked for me was Edimax EW-7108PCg — a WiFi CardBus card based on a RT2561S chipset.

  Another one was a generic no-name USB-to-LAN adapter based on RTL8153.
</p>

<h2>Booting the installer</h2>

<p>
  Despite having a USB port, the 380Z doesn't support USB boot.

  My CD drive was also erratic and practically unusable - a common issue in vintage laptops.

  Fortunately, the 380Z supports yet another, rather unusual boot option — using a CardBus disk.
</p>

<p>
  So I grabbed the <code>NetBSD-10.0-i386-install.img</code> image and wrote to a Compact Flash card.

  Then, plugged it in using a generic CF-to-CardBus adapter, and off it went.

  For NetBSD, booting from CardBus is business as usual, no questions asked.
</p>

<p>
  To be fair, with other systems it's also doable, but usually requires some tinkering to mount the root filesystem.
</p>


<h2>Installation</h2>

<p>
  NetBSD comes with a lightweight, friendly, text-mode installer.

  Step by step, it guides you through setting the keyboard layout, partitioning, selecting distribution sets, setting up the network, timezone, root shell and password, enabling the package manager, choosing optional daemons, and adding a user account.
</p>

<p>
  Unless you go for automatic full-disk mode, the trickiest part may be partitioning, since NetBSD uses its own custom scheme on top of MBR partitions.

  Fortunately, the whole process is <a href="https://www.netbsd.org/docs/guide/en/" target="_blank">well documented</a>.
</p>

<p>
  In my case, when prompted for distribution sets, I selected "custom installation", and selected all sets except for source and debug ones.

  The resulting installation took about 1.6GB of disk space, and included the entire X11 environment.
</p>

<img src="https://luke8086.dev/images/netbsd-shot-install.png" alt="NetBSD installer">

  
<h2>Enabling framebuffer</h2>

<p>
  NetBSD supports VESA console framebuffer, though it's not enabled by default, and not particularly advertised in the docs.

  Turning it on is as simple as adding <code>vesa on; vesa 1024x768;</code> commands to a menu item in <code>/boot.cfg</code>.
</p>

<p>
  By the way, it's too bad that NetBSD's console doesn't support unicode, so it's not very usable without X.

  I think this could be a killer feature for hardware with even less RAM.
</p>

<h2>Saving RAM</h2>

<p>
  Even NetBSD comes with some bloatware ;-)

  To save as much RAM as possible, you can turn it off by adding to <code>/etc/rc.conf</code>:
</p>

<pre><code>inetd=NO
postfix=NO
cron=NO
virecover=NO
makemandb=NO
powerd=NO
syslogd=NO
</code></pre>

<p>
  You can also reduce the amount of consoles by commenting them out in <code>/etc/ttys</code>.
</p>

<p>
  After reboot, you'll have a pretty clean slate:
</p>


<pre><code>t380z# ps auxc
USER PID %CPU %MEM   VSZ   RSS TTY   STAT STARTED    TIME COMMAND
root   0  0.0 18.6     0 30300 ?     DKl   3:45PM 0:00.08 system
root   1  0.0  0.9  5836  1504 ?     Ss    3:45PM 0:00.08 init
root 345  0.0  2.0 12724  3292 ?     Ss    3:45PM 0:00.09 wpa_supplicant
root 707  0.0  1.0  6104  1544 ttyE0 O+    3:45PM 0:00.03 ps
root 711  0.0  3.1 12848  4988 ttyE0 Ss    3:45PM 0:00.54 login
root 712  0.0  1.4  6576  2216 ttyE0 S     3:45PM 0:00.24 sh
root 709  0.0  1.0  5744  1556 ttyE1 Ss+   3:45PM 0:00.03 getty

t380z# cat /proc/meminfo
        total:    used:    free:  shared: buffers: cached:
Mem:  139943936 32768000 107175936        0  8208384 18546688
Swap: 167759872        0 167759872
MemTotal:    136664 kB
MemFree:     104664 kB
MemShared:        0 kB
Buffers:     104664 kB
Cached:       18112 kB
SwapTotal:   163828 kB
SwapFree:    163828 kB
</code></pre>

<h2>WireGuard</h2>

<p>
  In case you'd like to use WireGuard, NetBSD's got you covered.

  It supports it out of the box, with no extra dependencies.
  
  The entire documentation is a single man page and it's very straighforward.

  However, it only shows commands to manually execute, there's no dedicated config file.

  To make your setup persistent, you can simply add it to <code>/etc/rc.local</code>:
</p>

<pre><code>echo -n 'Setting up wireguard: '

ifconfig wg0 create
ifconfig wg0 inet [ip/prefix]
wgconfig wg0 set private-key /etc/wg/key
wgconfig wg0 add peer [peer-name] \
        [public-key]
        --allowed-ips=[ip/prefix] \
        --endpoint=[endpoint]
ifconfig wg0 up

echo 'done.'
</code></pre>

<h2>Setting locale</h2>

<p>
  The default locale in NetBSD is C.

  The installer doesn't prompt you to change it, and there isn't any dedicated config file.

  Instead, you need to set it manually, for example in <code>/etc/profile</code> or <code>~/.profile</code>:
</p>

<pre><code>export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8
export LC_COLLATE=en_US.UTF-8
</code></pre>

<h2>The X server</h2>

<p>
  The GPU on 380Z is a NeoMagic MagicMedia 256AV and it has a dedicated driver in Xorg, called <code>neomagic</code>.

  However, only in NetBSD it worked out of the box without any tinkering, just by running <code>startx</code>.

  On other systems I tried, it required some adjustments or even resorting to plain VESA/FB drivers.
</p>


<h2>Window manager</h2>

<p>
  The default desktop environment of NetBSD, as included in the basesystem, consists of CTWM, XClock and XTerm.

  It looks <a href="https://luke8086.dev/images/netbsd-shot-ctwm.jpg" target="_blank">like this</a>.

  It's as minimal as it gets, it's not too ugly, and it's somewhat usable.
</p>

<p>
  I tried it for a bit, but couldn't get to like CTWM.

  Instead I've replaced it with <a href="https://fastestcode.org/emwm.html" target="_blank">EMWM</a> (Enhanced Motif Window Manager), which is similarly lightweight.
</p>

<img src="https://luke8086.dev/images/netbsd-shot-emwm.png" alt="NetBSD running EMWM">

<h2>Terminal emulator</h2>

<p>
  I haven't found a terminal with a smaller memory footprint than XTerm.

  Even urxvt or st were larger.

  However, for me XTerm is actually good enough, so I didn't spent much time looking for alternatives.

  I only adjusted some colors, changed the font to Terminus, and added shortcuts for copy-pasting:
</p>

<pre><code>XTerm*VT100.background: black
XTerm*VT100.foreground: grey90
XTerm*VT100.faceName: Terminus
XTerm*VT100.faceSize: 12
XTerm*VT100.allowBoldFonts: false
XTerm*VT100.translations: #override \
      Ctrl Shift <key>V:    insert-selection(CLIPBOARD) \n\
      Ctrl Shift <key>C:    copy-selection(CLIPBOARD)
</key></key></code></pre>

<h2>The shell</h2>

<p>
  In the basesystem, NetBSD comes with sh, csh and ksh.

  I've never bothered learning csh, but sh is fine for basic administrative tasks, and ksh is somewhere in between sh and bash in terms of functionality.

  I tried using ksh for a while but I kept missing features.

  Eventually I gave up on it and installed bash from packages.
</p>

<h2>Browsing web</h2>

<p>
  The most reasonable web browser for the 380Z is <a href="https://dillo-browser.github.io/" target="_blank">Dillo</a>.

  It lacks support for JavaScript and modern CSS layouts, so many pages render all over the place, but it's still useful for reading docs and static pages.

  To my surprise, Google seems to work, and doesn't block it with captcha.
</p>

<p>
  One could argue Dillo is <i>exactly</i> what a web browser is supposed to be — a productivity tool for browsing nicely-formatted hypertext documents.

  I only wish I had some time to contribute to its development.

  Well, maybe when I retire...
</p>

<img src="https://luke8086.dev/images/netbsd-shot-web.png" alt="NetBSD running Dillo browser">

<h2>Playing music</h2>

<p>
  NetBSD was the only system I tried that properly supported the built-in Crystal CS4237B soundcard.

  In fact, it detected it twice, with two different drivers, <code>wss</code>&nbsp;and&nbsp;<code>sb</code>.

  Unfortunately this caused a conflict and they both emited garbage noise.

  I was able to fix it by adding <code>usermod disable wss</code> to the bootloader line.
</p>

<p>
  The most viable player is mpg123.

  It manages to play an online low-fi radio stream with only slight stuttering when other CPU-heavy tasks are running.

  Itself it seems to take around 10-20% of the CPU time.

  The audio quality of the soundcard is also just adequate for low-fi music, so for sure it won't be too distracting.
</p>

<h2>Once set up, what's it good for?</h2>

<p>
  The 380Z has a very comfortable, high-profile, classic ThinkPad keyboard, as well as a crispy 4:3 display.

  It's not as snappy as your latest MacBook, but it's fine for many terminal-based tasks, for example:
</p>

<ul>
  <li>any kind of work over SSH, even through WireGuard</li>
  <li>tinkering with UNIX and learning its internals</li>
  <li>low-level coding in C, assembly, etc.</li>
  <li>developing TUI and even lightweight GUI apps</li>
  <li>taking notes, writing blog posts</li>
  <li>developing a modern web browser (building dillo only takes ~20min) ;-)</li>
  <li>learning how to solve problems in a resource constrained environment</li>
  <li><span><a href="https://luke8086.dev/retronews.html" target="_blank">wasting time</a> on social media</span> practicing patience and mindfulness</li>
</ul>

<h2>Final thoughts on NetBSD</h2>

<p>
  NetBSD is a lightweight, compact, finely engineered system.

  It doesn't get as much attention as its BSD cousins, not to mention Linux, but I just cannot overstate how <i>pleasant</i> it is to use.
</p>

<p>
  It doesn't overwhelm you with thousands of packages and dozens of boot services right in a fresh install.

  On the contrary, it does only what you tell it to do.

  It puts you in charge and makes you feel like you can understand it top to bottom.
</p>

<p>
  It happily boots on a 25-year old machine, like you moved back in time, but still provides you with a full repository of the latest software.
</p>

<p>
  It may not be mainstream enough for a daily driver, but I think it's the ultimate UNIX to put on a spare, underpowered machine.
</p>

<p><em>~luke, 2024-12-16</em></p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waymo will bring autonomous vehicles to Tokyo (165 pts)]]></title>
            <link>https://waymo.com/blog/2024/12/partnering-with-nihon-kotsu-and-go-on-our-first-international-road-trip</link>
            <guid>42438009</guid>
            <pubDate>Tue, 17 Dec 2024 03:17:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waymo.com/blog/2024/12/partnering-with-nihon-kotsu-and-go-on-our-first-international-road-trip">https://waymo.com/blog/2024/12/partnering-with-nihon-kotsu-and-go-on-our-first-international-road-trip</a>, See on <a href="https://news.ycombinator.com/item?id=42438009">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-labelledby="P0-7-title"><a href="https://waymo.com/blog/"><img alt="" role="presentation" src="https://waymo.com/static/images/blog/icon-left-arrow.svg"><img alt="" role="presentation" src="https://waymo.com/static/images/blog/icon-left-arrow-rollover.svg"><span>Back to all posts</span></a><section><div><picture><source srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1440&amp;fm=webp" media="(min-width: 600px)" type="image/webp" width="1920" height="1080"><source srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1440" media="(min-width: 600px)" type="image/jpeg" width="1920" height="1080"><source srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1024&amp;fm=webp" media="(min-width: 600px) and (max-width: 1023px)" type="image/webp" width="1920" height="1080"><source srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1024" media="(min-width: 600px) and (max-width: 1023px)" type="image/jpeg" width="1920" height="1080"><source srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1024&amp;fm=webp" media="(max-width: 599px)" type="image/webp" width="1920" height="1080"><img alt="A white Waymo vehicle in front of a a radiating red spiral, with Nihon Kotsu, Waymo, and GO logos in the footer" loading="lazy" srcset="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg 2x, https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=1024" src="https://images.ctfassets.net/e6t5diu0txbw/lHhourBhrG3ffzwe7rNqU/b952ca5a0e2c73bf60f058081b7b96b8/Waymo_GO_NihonKotsu_Hero.jpg?w=420" width="1920" height="1080"></picture></div><div><p>こんにちは(Konnichiwa) and hello, Japan! We're thrilled to announce that Waymo, in partnership with Nihon Kotsu and GO, will bring our autonomous vehicles to Tokyo for our first international <a href="https://waymo.com/blog/2023/11/road-trip-how-our-cross-country-testing-helps-advance-the-waymo-driver/"><u>road trip</u></a>. There, our Driver will learn and adapt to left-hand traffic and new driving nuances associated with operating in one of the world's most densely populated urban environments.</p><p>Our upcoming road trip to Tokyo gives us the chance to work alongside local partners, government officials, and community groups to understand the new landscape. We’ll learn how Waymo can serve Tokyo’s residents and become a beneficial part of the city’s transportation ecosystem. And every step of the way, we’ll take a rigorous approach to validating our technology's safety and performance.</p><p>This expansion into Japan aligns with the country's vision for the future of transportation. Over the years, the Japanese National and Tokyo Metropolitan governments have been proactively working to address the evolving transportation needs of society and foster the adoption of innovative technologies that can enhance safety and mobility. We are engaging with Japanese policymakers, regulators, and local safety officials to ensure a responsible and seamless implementation of Waymo's technology to Tokyo's streets.</p><p>The first Waymo, all-electric Jaguar I-PACEs will arrive in Tokyo in early 2025. Our partner, Nihon Kotsu, Tokyo’s largest taxi company, will oversee the management and servicing of the Waymo vehicles. The companies are working closely together to train Nihon Kotsu’s team on operating vehicles equipped with Waymo's autonomous driving system. Initially, Nihon Kotsu drivers will operate the vehicles manually to map key areas of the Japanese capital, including Minato, Shinjuku, Shibuya, Chiyoda, Chūō, Shinagawa, and Kōtō.&nbsp;</p><p>Through this initial phase in Tokyo, we’ll gain valuable experience that accelerates the development of the Waymo Driver, allowing us to evaluate how our AI-powered driver generalizes to new environments through simulation. This expansion follows Waymo's best-in-class <a href="https://waymo.com/blog/2020/10/sharing-our-safety-framework/"><u>safety framework</u></a>—the same approach that guided us from the world's first fully autonomous ride on public roads to tens of millions of miles on US roads, and soon, our first kilometers in Tokyo.&nbsp;&nbsp;</p><p>We look forward to sharing more as we introduce Waymo to Tokyo residents, providing updates on our progress along the way.</p></div></section></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advent of Code on the Nintendo DS (109 pts)]]></title>
            <link>https://sailor.li/aocnds.html</link>
            <guid>42436440</guid>
            <pubDate>Mon, 16 Dec 2024 22:57:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sailor.li/aocnds.html">https://sailor.li/aocnds.html</a>, See on <a href="https://news.ycombinator.com/item?id=42436440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-text">
            
<p><img src="https://sailor.li/static/aocnds/img/hero.png"></p><p>
    It is December. That means annoying Christmas things are everywhere, including but not limited
    to the annual programming semi-competition known as Advent of Code.
</p>

<p>
    The problem with Advent of Code is that it is a waste of time. Most of the puzzles are in the
    realm of either string processing (somewhat applicable to programming), logic puzzles (not
    really applicable to most programming), or stupid gotchas in the input format (annoyingly, very
    applicable to most programming). So to combat this a lot of people use Advent of Code as an
    excuse to learn a new programming language that they wouldn't otherwise have a reason to use.
</p>

<p>
    In this spirit, I've decided to do Advent of Code 2024 in Rust, a language don't I use that
    often.
</p>

<blockquote>
    I do actually know Rust, but I never learned how to use it. I just started writing it because I
    was born with an innate knowledge of the language, similar to how I know Java or Kotlin despite
    never having learned them.
</blockquote>

<p>
    However, writing standard userland Rust on a system with a runtime is too easy; it's like
    writing a more annoying version of Java. So instead I will write it for an embedded system which
    has no runtime, a limited amount of memory, and most importantly little to no existing ecosystem
    for me to fall back on.
</p>

<blockquote>
    All the code for this project is available
    <a href="https://github.com/Fuyukai/aocnds">in the repository.</a>
</blockquote>

<blockquote>
    <h4>Warning!</h4>

    <p>
        This post is long, verbose, and explains a lot about things that aren't relevant because
        this was written in tandem with developing the project and is meant to show everything I
        learned on the way. There's a lot of things here that might seem obvious to people who know
        things about executables or embedded systems.
    </p>

    <p>
        If I wanted to do this fast, I could've just copied everything BlocksDS does, but I
        deliberately avoided anything related to other Nintendo DS homebrew projects or SDKs as they
        are focused on teaching you how to put all of the blocks together, but not how to actually
        build the blocks yourself.
    </p>
</blockquote>

<h2>A quick overview of the Nintendo DS (Nitro)</h2>

<p>
    As the title of this post states, I'm going to be writing it on the Nintendo DS (the original
    edition). Whilst there is a fair bit of interest in the "embedded gaming" scene of its
    predecessor systems (the Game Boy and Game Boy Advance), as well as its successor system the
    3DS, the homebrew and emulation scene for the DS itself is relatively limited due to the more
    esoteric design of the system.
</p>

<p>
    The DS's codename was "Nitro", hence the model number NTR-001. Its successor system, the DSi,
    has the codename of "Twilight" with the model number TWL-001. I'll refer to the system
    exclusively using its codename, as Nitro sounds cooler and is easier to refer to than "Nintendo
    DS" is.
</p>

<blockquote>
    If you're interested in a more comprehensive overview of the system, I recommend this
    <a href="https://www.copetti.org/writings/consoles/nintendo-ds/">excellent article</a>
    by Rodrigo Copetti.
</blockquote>

<p>
    The Nitro uses two processors; an ARM946E-S running at 67MHz (in practice, less) which uses the
    ARM v5 instruction set, and an ARM7TDMI running at 33MHz which uses the ARM v4 instruction set.
</p>

<blockquote>
    <p>
        In fact, the ARM7 CPU is identical the one inside of the Game Boy Advance, meaning that when
        you play a GBA game on the Nitro it executes a small amount of code to lock out the main CPU
        and sets up the secondary processor into the same setup as the original console.
    </p>

    <p>
        The Twilight includes the same ARM7 CPU, just without the GBA slot. The 3DS/CTR also
        includes this CPU alongside its other two CPUs, which is used to run DS(i) games (and, when
        hacked, GBA games). Every Nintendo handheld up to the 3DS contains a GameBoy inside it!
    </p>
</blockquote>

<p>
    Unlike what you might expect, the two processors have different roles; the ARM9 processor is
    where the majority - if not all - of the game's code exists, and the ARM7 processor acts
    strictly as a coprocessor that controls interaction with the system's I/O. The two processors
    talk to each-other using a FIFO interface mapped in both processors' memory space. It's hard to
    get an actual source on this, but various comments spread across the internet talk about how
    most code on the ARM7 was heavily restricted by Nintendo, thus most of the power of the
    secondary processor goes entirely unused.
</p>

<p>
    This works out great for me, as it means I can focus only on writing code to run on the ARM9,
    and let the ARM7 spin idly.
</p>

<h2>Preparations</h2>

<p>
    I know a little bit about how the DS works from reverse-engineering a game over the last two
    years or so; but beyond that everything here is gleamed from a few sources:
</p>

<ul>
    <li>
        <a href="https://problemkaputt.de/gbatek.htm">GBATEK</a> which is a very large and very
        detailed technical reference on everything there is to know about the GameBoy Advance as
        well as the Nitro/Twilight.
    </li>
    <li>
        The aforementioned decompiled game,
        <a href="https://en.wikipedia.org/wiki/Infinite_Space">Infinite Space (2009)</a>. It's a
        pretty decent JRPG albeit unbelievably difficult, and is worth playing with cheats on a few
        times.
    </li>
    <li>
        The official ARM v5 ARM Architecture Reference Manual, (ARM v5 ARM) available from the A RM
        website.
    </li>
</ul>

<p>
    In addition, I set up an ARM cross-compiler using
    <a href="https://wiki.gentoo.org/wiki/Crossdev">Crossdev</a>, compiling only binutils and GDB.
</p>

<h2>Getting a working ROM</h2>

<p>There's three major tasks to do to finish this project:</p>

<ol>
    <li>Get something that even boots. This is 90% of the effort.</li>
    <li>Solve Advent of Code. This is also 90% of the effort.</li>
    <li>Actually display something to the screen. This is <i>also</i> 90% of the effort.</li>
</ol>

<h3>The sample program</h3>

<p>
    First, I need a sample program to actually <i>run</i> on the Nitro. Let's just write something
    that loops forever, helpfully annotated:
</p>

<pre data-snippet="00/00sample.rs"><code>#![no_std]   // Obviously, we don't have a runtime.
#![no_main]  // We use an extern "C" main instead of a Rust main.
#![allow(clippy::empty_loop)]  // Otherwise clippy gets mad at our infinite loop.

// This is an empty panic handler as we don't have any infrastructure to actually... well, handle
// panics in any form.
//
// On platforms with a runtime, ``std`` provides lots of helpful code to unwind all of the code
// and print a stacktrace, but we don't have that, so instead when ``panic!()`` (or, rather,
// ``core::panicking::panic``) is called, it calls this function instead.
//
// See https://fractalfir.github.io/generated_html/rustc_codegen_clr_v0_2_1.html for the
// nitty-gritty details.
#[panic_handler]
fn _handle_panic(_: &amp;core::panic::PanicInfo) -&gt; ! {
    loop {}
}

// Unsafe attributes are a new feature in Rust 2024, and means "you now need to prefix this
// attribute with unsafe".
//
// Without ``no_mangle``, this function would get optimised out (as nothing calls it), and even
// if it didn't, it would be given an unintelligible name so that it wouldn't conflict with
// functions from other packages called ``_start`` (as unwise as it would be to use that name).
//
// This also needs to be named ``_start``, or else the linker just won't output anything. More on
// that later!
#[unsafe(no_mangle)]
extern "C" fn _start() -&gt; ! {
    loop {}
}</code></pre>

<p>
    Next, Cargo/Rust needs to be configured to build for Nitro. The compiler triplet for ARM9 CPUs
    like the Nitro's is <code>armv5te-none-eabi</code>; i.e., ARM version 5, no OS (baremetal),
    using the embedded ABI. I could do <code>cargo build --target=armv5te-none-eabi</code> every
    time, but Cargo has the ability to do this automatically with the confusingly named
    <code>.cargo/config.toml</code> file:
</p>

<pre data-snippet="00/00config.toml"><code>[build]
target = "armv5te-none-eabi"</code></pre>

<p>Running <code>cargo build</code> now will grant me an error:</p>

<pre data-snippet="00/00cargo-build-err.txt"><code>$ cargo build
   Compiling aocnds v25.0.0 (/home/lura/dev/misc/aocnds)
error[E0463]: can't find crate for `core`
  |
  = note: the `armv5te-none-eabi` target may not be installed
  = help: consider downloading the target with `rustup target add armv5te-none-eabi`
  = help: consider building the standard library from source with `cargo build -Zbuild-std`</code></pre>

<p>
    The help text in this case is useless, as <code>armv5te-none-eabi</code> is a
    <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">Tier 3</a>
    target and doesn't come with any pre-built standard library packages. Instead, I need to use the
    <a href="https://doc.rust-lang.org/cargo/reference/unstable.html#build-std"><code>build-std</code></a>
    feature of Cargo to compile the <code>core</code> (and, later, <code>alloc</code>) packages for
    my target.
</p>

<blockquote>
    This feature is (still) unstable and requires a nightly compiler + cargo version to use.
</blockquote>

<p>
    Now with this, I can build my program with a regular
    <code>cargo build --release</code>, which spits out a nice, 4440 byte
    <code>aocnds</code> executable (after stripping).
</p>

<h3>Wait, is that it?</h3>

<p>
    Okay, I don't have a ROM. But I do have a nice blob of ARM9 code that I can turn into a ROM,
    right?
</p>

<pre data-snippet="01/01-objcopy-broken.txt"><code># Just do a straight up memory copy with objcopy...
$ arm-none-eabi-objcopy -O binary aocnds arm9.bin
# Then disassemble it with objdump:
$ arm-none-eabi-objdump -D -b binary -marmv5te arm9.bin

arm9.bin:     file format binary


Disassembly of section .data:

00000000 &lt;.data&gt;:
       0:	00010010 	andeq	r0, r1, r0, lsl r0
       4:	00000001 	andeq	r0, r0, r1
       8:	00010010 	andeq	r0, r1, r0, lsl r0
       c:	00000001 	andeq	r0, r0, r1
	...
   10010:	eaffffff 	b	0x10014
   10014:	eafffffe 	b	0x10014</code></pre>

<blockquote>
    <p>
        If you don't know how to read a disassembly, there's three columns: the <i>address</i> of
        the instruction, the <i>raw bytes</i> of the instruction, and the <i>assembly</i>
        for the instruction.
    </p>
    <p>
        Objdump and other disassemblers don't discriminate between actual ARM machine code and
        random data included by the compiler and linker. Thanks to a quirk of the way the ARM
        instruction encoding was designed, most junk instructions end up being decoded as valid
        instructions, albeit nonsensical and usually nonfunctional.
    </p>
</blockquote>

<p>
    There's some junk at the beginning of the file, and then finally the actual code begins at
    offset 0x10010. By using <code>readelf</code> and <code>objdump</code> on the file, we can see
    that the 16 bytes of junk at the start is the same as the <code>.ARM.exidx</code> section:
</p>

<pre data-snippet="01/01-exidx.txt"><code>Disassembly of section .ARM.exidx:

000100d4 &lt;.ARM.exidx&gt;:
   100d4:       00010010        andeq   r0, r1, r0, lsl r0
   100d8:       00000001        andeq   r0, r0, r1
   100dc:       00010010        andeq   r0, r1, r0, lsl r0
   100e0:       00000001        andeq   r0, r0, r1</code></pre>

<p>
    The <code>0x10010</code> bytes of padding before the program text and after the ARM section is
    because the second header is loaded at a virtual address 0x10010 bytes later.
</p>

<pre data-snippet="01/01-progheaders.txt"><code>Program Headers:
  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
  PHDR           0x000034 0x00010034 0x00010034 0x000a0 0x000a0 R   0x4
  LOAD           0x000000 0x00010000 0x00010000 0x000e4 0x000e4 R   0x10000
  LOAD           0x0000e4 0x000200e4 0x000200e4 0x00008 0x00008 R E 0x10000
  GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RW  0
  ARM_EXIDX      0x0000d4 0x000100d4 0x000100d4 0x00010 0x00010 R   0x4</code></pre>

<p>
    The code at <code>0x10010</code> is a <strong>B</strong>ranch instruction to
    <code>0x10014</code>, which is then a branch instruction to itself. Because the
    <code>b</code> instruction with a constant is always a relative jump,
    <code>eafffffe</code> means "jump zero bytes forwards"; or, <code>PC := PC</code> which matches
    the Rust code. Great!
</p>

<p>
    The outputted ARM9 blob can be packed into a ROM using
    <a href="https://github.com/devkitPro/ndstool"><code>ndstool</code></a> for now. Borrowing an
    ARM7 from a game, I can pack my blob like so:
</p>

<pre data-snippet="01/01-ndstool.txt"><code>$ ndstool -c rom.nds -9 arm9.bin -7 ~/aur/emulation/roms/nds/arm7-is.bin
$ ndstool -i rom.nds
...
0x20    ARM9 ROM offset                 0x200
0x24    ARM9 entry address              0x2000000
0x28    ARM9 RAM address                0x2000000
0x2C    ARM9 code size                  0x10018
...</code></pre>

<p><img src="https://sailor.li/static/aocnds/img/nogba_firstrun.png"></p><p>
    For the moment I'll use NO$GBA debug to load the rom; I'll use a better emulator with a GDB stub
    for debugging later. After hitting run, the emulated ARM9 skips past the junk at the start of
    the file (thankfully, that junk all decodes to <code>andeq</code> instructions, which don't do
    anything) until it reaches the infinite loop. Success! I have built my first rust binary for
    Nitro, and I didn't really have to do anything!
</p>

<h3>No, that's not it</h3>

<p>Unfortunately, I got lucky here. This program actually has some immediate problems:</p>
<ul>
    <li>
        <code>.bss</code> has not been zeroed, which is UB. At least I don't have any global
        variables.
    </li>
    <li>The stack pointer is set to a junk value, not real memory.</li>
</ul>
<p>Oh, but there's another really important one:</p>
<ul>
    <li>The code is not running where it expects to!</li>
</ul>

<p>Nitro has, essentially, three main memory areas:</p>
<ul>
    <li>
        <p>
            The Instruction Tightly Coupled Memory (ITCM), which is mapped at 0x0 and mirrored at
            <code>0x01000000</code> (but most commercial Nitro software uses the mirror at
            <code>0x01ff8000</code>). This is 32KiB.
        </p>
    </li>
    <li>
        <p>
            The Data Tightly Coupled Memory (DOCM), which is movable throughout the entire memory
            space but in practice is usually mapped at <code>0x027e0000</code>. This is only 16KiB.
            Most commercial Nitro software uses this for the stack.
        </p>
    </li>
    <li>
        <p>
            Main memory, which is mapped at <code>0x02000000</code>. This is 4MiB on retail units
            and 8MiB on debug units.
        </p>
    </li>
</ul>

<blockquote>
    There's also the "shared RAM", which is 32KiB in total and can be allocated to either the ARM7
    or the ARM9, either half and half or all to one. The ARM7 is crying out for memory as it only
    has 64KiB for itself, so this can all be allocated to the ARM7 and ignored. I believe all
    official Nitro games do this.
</blockquote>

<p>
    At boot, the software running on the cartridge is copied to the very bottom of main memory, and
    the BIOS jumps to the entrypoint specified by the cart header. With my binary, the entrypoint
    was set to be the very first address of main memory (the gigantic stack of empty
    <code>andeq</code>s) with the <code>_start</code> function trailing it. The more pressing manner
    is that the code in <code>_start</code> was built and linked with the assumption that it would
    be loaded at <code>0x200e4</code>, which it very much is not.
</p>

<blockquote>
    <p>A quick terminology lesson here, as some of those terms might not be familiar.</p>
    <br>
    <details>
        <summary>ELF terminology</summary>
        <p>
            <code>.data</code> and <code>.bss</code> are both <em>sections</em> in the final
            executable. Sections are what they sound like; literally a part of an executable file
            that is loaded by a program loader into memory when a program starts. Of course, my
            program doesn't <em>have</em> a program loader yet; it's just a raw blob of ARM9
            instructions interlaced with the other sections.
        </p>
        <p>
            The <code>.data</code> (and, <code>.rodata</code>) section contains
            <em>global variables</em> that have been explicitly initialised; in Rust, examples of
            this would be static globals, like so:
        </p>

        <pre data-snippet="02/02-rodata-mizuki.rs"><code>#[unsafe(no_mangle)]
pub static BLOB: &amp;str = "暁山瑞希";</code></pre>

        <p>
            This data is stored directly in the <code>.rodata</code> section of the file, and an
            entry in the Program Headers of the elf file is emitted to tell the dynamic loader to
            load these globals at the right spot in virtual memory.
        </p>
        <p>
            The <code>.bss</code> section is used for <em>uninitialised</em> global variables and is
            by convention set to all zeroes. To avoid bloating a file with emptiness the binary
            contains only the length of the section which will be allocated by the program loader as
            an empty block on startup. Again, this is something my program doesn't have and will
            need to set up manually.
        </p>
        <p>
            Also, for good measure, <code>.text</code> is the raw machine code for the program, also
            referred to as "program text" sometimes.
        </p>
    </details>
</blockquote>

<blockquote>
    <p>
        If all of the <code>b</code> instructions are relative, what's the problem with the code
        thinking it's loaded somewhere else?
    </p>

    <br>

    <details>
        <summary>Deeper explanation</summary>

        <p>Let's take this bit of code as an example:</p>

        <pre data-snippet="02/02-thumb-interwork.rs"><code>#[instruction_set(arm::t32)]
fn other() -&gt; u8 {
    1
}
#[unsafe(no_mangle)]
#[instruction_set(arm::a32)]
extern "C" fn _start() -&gt; ! {
    let _ = other();
    loop {}
}</code></pre>

        <p>
            Notice that the function <code>other</code> is using the Thumb instruction set and the
            function <code>_start</code> is using the Arm32 instruction set. This is linked to load
            at the start of memory like before, so let's look at the disassembly for it:
        </p>

        <pre data-snippet="02/02-thumb-interwork-disasm.txt"><code>Disassembly of section .text:

# Mangled name of "other"
00008000 &lt;_ZN6aocnds5other17h6d2efad51ed937f1E&gt;:
    8000:       2001            movs    r0, #1
    8002:       4770            bx      lr

00008004 &lt;_start&gt;:
    8004:       eb000001        bl      8010 &lt;___ZN6aocnds5other17h6d2efad51ed937f1E_from_arm&gt;
    8008:       eaffffff        b       800c &lt;_start+0x8&gt;
    800c:       eafffffe        b       800c &lt;_start+0x8&gt;

# Trampoline for ARM code to Thumb code
00008010 &lt;___ZN6aocnds5other17h6d2efad51ed937f1E_from_arm&gt;:
    8010:       e59fc000        ldr     ip, [pc]        @ 8018 &lt;___ZN6aocnds5other17h6d2efad51ed937f1E_from_arm+0x8&gt;
    8014:       e12fff1c        bx      ip
    8018:       00008001        andeq   r8, r0, r1
    801c:       00000000        andeq   r0, r0, r0</code></pre>

        <p>
            The linker has inserted a function trampoline to switch from ARM to Thumb mode. The
            Branch with Exchange instruction only takes an absolute register argument, unlike the
            normal branch with link instruction, so the assembled code uses the IP (R12) register.
            The IP register is loaded with a constant stored just after the function body -
            0x00008001, the absolute address of the actual <code>other</code> function in memory.
        </p>
        <p>
            Since the program is loaded at 0x02000000 this will jump straight into unmapped memory
            and cause the processor to fault.
        </p>
    </details>
</blockquote>

<h3>The first linker script</h3>

<p>I need to somehow tell the compiler and my code to do the following:</p>
<ul>
    <li>Compile with the assumption the code will be loaded and running at 0x02000000.</li>
    <li>
        Arrange the <code>.data</code>/<code>.rodata</code> section with the assumption it'll be
        loaded after 0x02000000 too.
    </li>
    <li>
        Set up a stack pointer that points into the Data Tightly Coupled Memory section so that I
        can actually use local variables.
    </li>
</ul>

<p>
    The first two can be done using a <em>linker script</em>. The misleadingly named linker script
    is a configuration file for the linker which tells it where to put the sections found in the
    intermediate files produced by the compiler into the final binary file.
</p>

<p>
    The average programmer will likely never interact with a non-default linker script in their
    life. Of the ones that do, only a tiny percentage will ever write their own linker script.
    Thankfully the programmers that <em>do</em> know how to write linker scripts have
    <a href="https://mcyoung.xyz/2021/06/01/linker-script">documented it</a>.
</p>

<pre data-snippet="03/03-ld-pt1.ld"><code>/* Standard cruft at the beginning of the file. I don't know what omitting this does,
  so let's not do that. */
OUTPUT_FORMAT("elf32-littlearm")
OUTPUT_ARCH(arm)
ENTRY(_start)

/*
 * The memory layout of the DS is pretty simple; for now, we'll just define the main memory.
 * It's a nice block of 4MB that's Readable, Writable, and eXecutable.
 */
MEMORY {
    main_ram (rwx) : ORIGIN = 0x02000000, LENGTH = 4M
}</code></pre>

<p>
    To actually use this file, I need to add another option to my <code>.cargo/config.toml</code> to
    tell the linker what script to use:
</p>

<pre data-snippet="03/03-config.toml"><code>[target.armv5te-none-eabi]
rustflags = [
    # The default ``rust-lld`` linker kinda works, but it doesn't support some linker script options
    # in weird and obscure ways. I'll just use my cross-compiler linker instead.
    "-Clinker=arm-none-eabi-ld",
    "-Clink-arg=-Tlinker.ld"
]</code></pre>

<p>I was curious to see if this would Just Work, so I built the ELF file and objdump'd it:</p>

<pre data-snippet="03/03-objdump-1.txt"><code>Disassembly of section .text:

02010010 &lt;_start&gt;:
 2010010:       eaffffff        b       2010014 &lt;_start+0x4&gt;
 2010014:       eafffffe        b       2010014 &lt;_start+0x4&gt;</code></pre>

<p>
    Aha! The 0x10000 bytes of junk is still there at the start, but now the code is correctly being
    loaded into Nitro's main memory. Not only that but the entrypoint is correct too:
</p>

<pre data-snippet="03/readelf.txt"><code>$ arm-none-eabi-readelf -h aocnds
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           ARM
  Version:                           0x1
  Entry point address:               0x2010010</code></pre>

<p>
    If I compile a slightly modified program that calls a function with a
    <code>&amp;'static str</code> variable, I can also verify that it's using the right addresses
    for <code>.rodata</code>:
</p>

<pre data-snippet="03/rodata-mizuki.rs"><code>#[unsafe(no_mangle)]
pub static BLOB: &amp;str = "暁山瑞希";

// has to 1) exist 2) take the arg or the linker GCs us :(
fn other(_: &amp;str) {
    // bx lr
}

#[unsafe(no_mangle)]
extern "C" fn _start() -&gt; ! {
    other(BLOB);
    loop {}
}</code></pre> <pre data-snippet="03/rodata-mizuki-nm.txt"><code>Disassembly of section .rodata:

02000010 &lt;BLOB-0xc&gt;:
 2000010:       e5819ae6        str     r9, [r1, #2790] @ 0xae6
 2000014:       91e7b1b1        strhls  fp, [r7, #17]!
 2000018:       8cb8e59e        ldchi   5, cr14, [r8], #632     @ 0x278

0200001c &lt;BLOB&gt;:
 200001c:       02000010        andeq   r0, r0, #16
 2000020:       0000000c        andeq   r0, r0, ip

Disassembly of section .text:

02010024 &lt;_ZN6aocnds5other17hd0540aae0727baf3E&gt;:
 2010024:       e24dd008        sub     sp, sp, #8
 2010028:       e58d0000        str     r0, [sp]
 201002c:       e58d1004        str     r1, [sp, #4]
 2010030:       e28dd008        add     sp, sp, #8
 2010034:       e12fff1e        bx      lr

02010038 &lt;_start&gt;:
 2010038:       e59f1010        ldr     r1, [pc, #16]   @ 2010050 &lt;_start+0x18&gt;
 201003c:       e5910000        ldr     r0, [r1]
 2010040:       e5911004        ldr     r1, [r1, #4]
 2010044:       ebfffff6        bl      2010024 &lt;_ZN6aocnds5other17hd0540aae0727baf3E&gt;
 2010048:       eaffffff        b       201004c &lt;_start+0x14&gt;
 201004c:       eafffffe        b       201004c &lt;_start+0x14&gt;
 2010050:       0200001c        andeq   r0, r0, #28  &lt;-- BLOB &lt;-- BLOB-0xc</code></pre>

<p>
    The linker is placing the data in the right memory section and the reference after the body of
    <code>_start</code> is pointing to main memory. Success!
</p>

<h3>The C Runtime</h3>

<p>
    I'm still in no man's land here; without a stack pointer, I can't use local variables or call
    other functions as the compiler automatically emits instructions to manipulate the stack pointer
    on function entry and exit.
</p>

<blockquote>
    <p>
        The stack is an area of memory where local variables are stored. It's called a stack because
        it grows in a first-in last-out manner. When a function needs to use a local variable, it
        allocates some space in the stack at the address of <i>stack pointer</i> - one of the
        processor registers specifically designated for this purpose - then moves it downwards by
        the amount of space that variable takes. That way, every local variable in a function has
        its own memory address automatically assigned.
    </p>

    <p>
        The stack is also used to preserve the state of the processor registers from a previous
        function when calling a function. The number of registers preserved varies depending on
        something known as a <i>calling convention</i>; for 32-bit ARM in the embedded ABI, this is
        registers four through eleven, as well as the Link register which is used to return from a
        function to the previous one.
    </p>

    <p>
        When a function exits, it no longer needs the space for the local variables, so the stack
        pointer is reset back to where it was before the function was called, allowing the previous
        function to reuse that memory for other local variables or other function calls. The
        compiler does this automatically for me in assembly known as the function prologues and
        epilogues. Without a valid stack pointer, <i>none</i> of the operations described here are
        valid, and will cause the processor to fault.
    </p>
</blockquote>

<blockquote>
    <p>
        These instructions on entry/exit are known as the function prologue and epilogue, and are
        related to avoiding clobbering registers used by previous functions. You can find more
        information about the 32-bit ARM calling convention
        <a href="https://en.wikipedia.org/wiki/Calling_convention#ARM_(A32">here</a>).
    </p>
</blockquote>

<p>
    Before every single program is a small stub of hand-written assembly known as the
    <code>crt</code>, which stands for "C Runtime". This is also a misleading name, as it is neither
    a runtime nor exclusive to the C programming language. On Nitro, this has a few things it needs
    to do before jumping into the managed (i.e. my Rust) code:
</p>

<ul>
    <li>Set up the stack pointer</li>
    <li>Set up Coprocessor 15 for memory protection</li>
    <li>Zero out a memory area for the BSS segment</li>
    <li>Finally, jump into the high-level main function.</li>
</ul>

<blockquote>
    <p>
        If you don't know assembly or anything about it; that's okay. I didn't either until I
        started this. Sure, I could read <em>some</em> ARM assembly, but writing it is a whole
        different beast. Luckily it's a very nice instruction set that is easy to understand.
    </p>
</blockquote>

<p>
    Before I dive straight into writing all of this, let's get the infrastructure for the assembly
    working first. It's all going to go into a file named <code>start.s</code> in src, and can be
    included in the build process with the <code>global_asm!</code> macro, like so:
</p>

<pre><code>global_asm!(include_str!("start.s"));</code></pre>

<p>
    I'll just write a basic asm file that jumps straight to the Rust main function to make sure it
    builds properly:
</p>

<pre data-snippet="04/start-1.s"><code>// Put it in the ``.text`` section, i.e. where all the functions are.
.section ".text._start"
// Export it globally so the linker can see it. 
.global _start

_start:
    // Branch relative to the label (function) called main.
    b main</code></pre>

<p>
    I'll also go back and rename the Rust function from <code>_start</code> to <code>main</code> so
    that it gets picked up. Dumping the executable shows that it is indeed included in my build:
</p>

<pre data-snippet="04/start-1-nm.txt"><code>Disassembly of section .text:

02010010 &lt;_start&gt;:
 2010010:       eaffffff        b       2010014 &lt;main&gt;

02010014 &lt;main&gt;:
 2010014:       eaffffff        b       2010018 &lt;main+0x4&gt;
 2010018:       eafffffe        b       2010018 &lt;main+0x4&gt;</code></pre>

<h3>A real linker script</h3>

<p>
    Up until now, I've been coasting along on what is essentially a bunch of heuristics from the
    linker to put all of the sections in the right place. This <em>mostly</em> works, but let's see
    what happens if I add a region for the ITCM to the memory map in the linker script. The ITCM is
    officially mapped starting at <code>0x0</code>, but most official software pretends it's mapped
    at <code>0x01000000</code>. Because it's mirrored every <code>0x8000</code> bytes, most official
    software seems to pretend it actually starts at <code>0x01ff8000</code>, which is
    <code>0x8000</code> bytes before main memory.
</p>

<pre data-snippet="05/memory.diff"><code>MEMORY {
+   itcm (rwx)      : ORIGIN = 0x01ff8000, LENGTH = 32K
    main_ram (rwx)  : ORIGIN = 0x02000000, LENGTH = 4M
+   dtcm (rw)       : ORIGIN = 0x027e0000, LENGTH = 16K
}</code></pre>



<blockquote>
    I could just not add it to the linker, but eventually I want to move some of my code into the
    ITCM as it's significantly faster to fetch instructions from the ITCM than from main memory.
</blockquote>

<p>
    Attempting to compile with this linker script will result in an immediate error because the ARM
    unwind table doesn't fit into 32KiB:
</p>

<pre data-snippet="05/lld-error.txt"><code>  = note: rust-lld: error: section '.ARM.exidx' will not fit in region 'itcm': overflowed by 32784 bytes
          rust-lld: error: section '.text' will not fit in region 'itcm': overflowed by 98372 bytes</code></pre>

<p>
    This is because the heuristics the linker uses is to put all sections in the first memory
    segment it finds; in this case, it's the ITCM segment. I don't want unwind tables or the first
    half of my program text in the ITCM anyway!
</p>

<p>
    To solve this, I need to actually start defining some sections in the linker script. First, I'm
    going to make it so that Cargo will correctly rebuild the project if the script changes, rather
    than going "yup, looks good to me!", by creating a `build.rs` file in the root of the project:
</p>

<pre data-snippet="05/build.rs"><code>pub fn main() {
    println!("cargo::rerun-if-changed=linker.ld");
}</code></pre>

<p>Next, let's define some code sections in a... <code>SECTIONS</code> block:</p>

<pre data-snippet="05/sections.ld"><code>SECTIONS {
    /* The CRT always needs to be in main memory. Let's put it at the start for good measure. */
    .crt : ALIGN(4) { *(.crt); *(.crt.*) } &gt; main_ram =0x39

    /* The text section should be in main memory. Things that will go into the ITCM can be put
       there explicitly. */
    .text : ALIGN(4) { *(.text); *(.text.*) } &gt; main_ram =0x39
    /* The data section should also be in RAM. DTCM variables can be placed there explicitly. */
    .data : ALIGN(4) { *(.data); *(.data.*) } &gt; main_ram =0x39
    .rodata : ALIGN(4) { *(.rodata); *(.rodata.*); } &gt; main_ram =0x39
    /* The BSS section doesn't really... exist, but we need to allocate some space for it anyway. */
    .bss : ALIGN(4) { KEEP(*(.bss)); KEEP(*(.bss.*)); } &gt; main_ram

    /* Make sure the start of the heap is properly aligned. */
    . = ALIGN(4);
    __text_end = .;

    /* Let's get rid of anything we haven't explicitly specified. This includes some debugging
       info for now. */
    /DISCARD/ : { * }
}</code></pre>

<p>
    As the comments show, this forces the <code>crt</code> assembly to be in main memory and at the
    very start of the code, then the <code>.text</code> section after, and finally the
    <code>.(ro)data</code> sections. All of these sections have their unused bytes filled with a
    fixed <code>0x39</code> (e.g. the trailing, unaligned bytes for global data or THUMB
    instructions). The <code>.bss</code> section doesn't exist in the binary, but I need to mark it
    in the linker script so that the code knows where to zero it out at runtime.
</p>

<p>Finally, I can define some "variables" which will be exported to the final code:</p>

<pre data-snippet="05/variables.ld"><code>__bss_start = ADDR(.bss);
__bss_end = ADDR(.bss) + SIZEOF(.bss);</code></pre>

<p>With the BSS labels defined, I can write some assembly to zero the section out:</p>

<pre data-snippet="05/start-1.s"><code>// R0: value
// R1: ptr to start
// R2: size
_ASM_primitive_memset:
    // R12 (end) = start + size
    add r12, r1, r2
.L0:
    // Compare current pointer to end
    cmp r1, r12
    // Store multiple registers, increment address, only run if R1 &lt; R12
    // *R1 = R0, R1 += 4
    // Also, the double braces are because this is being compiled with ``global_asm!()``, and single
    // braces means it would think it's a parameter and flip out at me for not providing an ``R0``
    // parameter.
    // Doesn't clear the condition bits so...
    stmialt r1!, {{R0}}
    // ... jump back if the condition still matches
    blt .L0
    // Return
    bx lr

_start:
    // Clear BSS
    ldr r2, =__bss_size
    ldr r1, =__bss_start
    mov r0, #0
    bl _ASM_primitive_memset

    // For future-proofing, we do a branch-with-exchange in case ``main`` ends up as a thumb
    // function.
    ldr r0, =main
    bx r0</code></pre>

<h3>The rest of the CRT</h3>

<p>
    With a working linker script and my memory sections actively defined in the linker script, I can
    start filling in the rest of the CRT. First, I disable interrupts and wait for vertical sync:
</p>

<pre data-snippet="06/start-2.s"><code>_start:
    // The IME is at address 0x4000208, and is a 32-bit register.
    // The only bit in it that matters is bit zero, which acts as the enable bit.
    // 1 = interrupts controlled by IE
    // 0 = interrupts forcibly disabled.
    //
    // The ``mov`` instruction with an immediate can only operate on any 8-bit value that is shifted
    // by an even power of two, which 0x04000208 is not. 0x04000000 (the base address for I/O
    // registers) is, so that's loaded into register zero. Then, exploiting the fact that the
    // LSB of 0x04000000 is 0, we store that into IME and the upper bits are ignored.

    mov r0, #0x04000000
    str r0, [r0, #0x208]

    // Wait for vertical sync.
    // Note: The syntax ``.L&lt;name&gt;`` signifies a local label, which isn't exported as a symbol
    // in the final compiled object.
.Lvsync:
    // Load half-word at REG_DISP_VCOUNT. R0 was already the base of the I/O registers, so we
    // can just add 0x6 to it to load it into R1.
    ldrh r1, [r0, #0x6]
    // Compare to 0x0 and set the comparison flag.
    cmp r1, #0
    // Branch if not equal back to the VSYNC label.
    bne .Lvsync</code></pre>

<p>
    Next, I set up my stack pointers. I want it to be in the DTCM, as that is significantly faster
    than main memory. As eventually I'll want to copy things into the DTCM from main memory, I'll
    define some variables in the linker script:
</p>

<pre data-snippet="06/variables.ld"><code>__dtcm_region_start = ORIGIN(dtcm);
__dtcm_region_end = ORIGIN(dtcm) + LENGTH(dtcm) - 4;</code></pre>

<p>
    Now, I'll finally give myself a frame pointer - or, in fact, <i>three</i> frame pointers; one
    for each mode (Supervisor, IRQ, and System).
</p>

<blockquote>
    <p>
        The vast majority of CPUs ever made have a concept of special modes; these are sometimes
        called privilege modes, or rings, and are normally used to protect the kernel from user
        software and userland software from <em>other</em> userland software. Each mode has its own
        set of registers and state that is isolated from the other modes.
    </p>
    <p>
        Being that this is a game console - and an old, low-powered one at that - there's no need
        for this protection, so the modes are used primarily to separate the stacks and registers
        when doing things like processing exceptions or interrupts.
    </p>
</blockquote>

<blockquote>
    <h4>Trivia!</h4>

    <p>
        On x86 (but not AMD64), there are four rings, numbered zero through three. User code
        typically runs in Ring 3 and kernel code typically runs in Ring 0, with Ring 1 and 2 unused.
        Back in the day, OS/2 used Ring 2 for device drivers, which makes emulating/virtualising it
        a bit harder as one would have to support the middle rings.
    </p>
</blockquote>

<blockquote>
    <h4>More trivia!</h4>

    <p>
        ARM actually supports <em>seven</em> modes; in addition to those four, there's also User
        mode, FIQ mode, Abort mode, and... Undefined mode. I have no reason for User mode as there's
        no end-user programs (or even an MMU), and the other four modes are treated identically by
        the BIOS.
    </p>
</blockquote>

<p>
    To set the frame pointers, I need to switch into every mode and assign a value to the register.
    The mode is set by the lower four bits of the CPSR (Current Program Status Register), and all
    the other bits can safely be set to zero without issue. The offsets from the DTCM are calculated
    in the linker script rather than the assembly file as they are known at compile time:
</p>

<pre data-snippet="06/stacks.ld"><code>__stack_start_irq = __dtcm_region_end - 0x100;
__stack_start_svc = __stack_start_irq - 0x100;
__stack_start_sys = __stack_start_sys - 0x100;</code></pre>

<p>Then, it's just a few repeated instructions to change modes:</p>

<pre data-snippet="06/stacks.s"><code>// Stack setup for every mode
// 0b10010 == 0x12, IRQ mode
mov r0, #0x12
msr cpsr, r0
ldr sp, =__stack_start_irq

// 0b10011 == 0x13, Supervisor mode
mov r0, #0x13
msr cpsr, r0
ldr sp, =__stack_start_svc

// 0b11111 == 0x1f, System mode
mov r0, #0x1f
msr cpsr, r0
ldr sp, =__stack_start_sys</code></pre>

<p>
    With the stack pointers now valid and the <code>.bss</code> zeroed, I now have a
    <em>valid</em> Rust program that can be built and linked.
</p>

<h3>Coprocessor 15</h3>

<p>
    Coprocessor 15 (also known as the System Control coprocessor) is a special processor built-in to
    the ARM9 (and ARM7) chips that controls things mostly relating to memory layouts and memory
    protection. CP15 has sixteen registers, with the most interesting ones being:
</p>
<ul>
    <li>
        <p>
            Registers 2, 5, 6, 8, 10, and 13 control the memory protection subsystem, which is an
            alternative to the memory management unit subsystem (which the ARM9 doesn't have). This
            subsystem mostly pertains to caching and raising CPU exceptions on out-of-bounds reads.
        </p>
    </li>
    <li>
        <p>
            Registers 7 and 9 control the cache and write buffers, as well as the tightly coupled
            memory locations.
        </p>
    </li>
</ul>
<p>
    This is fiddly and annoying (my decompiled game has 45 (!) instructions to set it up)... so I'm
    simply going to blindly steal what said game does. I've helpfully commented everything too, so
    that future generations can understand it easier.
</p>

<br>

<details>
    <summary><code>setup_coprocessor</code> function (it's really long!)</summary>

    <pre data-snippet="07-cp15.s"><code>setup_coprocessor:
    // The creatively named MCR and MRC stand for "Move Coprocessor to Register" and
    // "Move Register to Coprocessor", respectively. The names are misleading; it really means
    // "do coprocessor command".

    // C1/C0/0 = System control, copy the definition into R0
    mrc p15, 0x0, r0, cr1, cr0, 0x0

    // load constant control value
    // this (temporarrily) disables the protection unit, the DTCM and ITCM, and disables 
    // caching for them
    ldr r1, =0x000F90053
    // BIC = Rd AND (NOT Rn)
    // clear any set bits in R0 that are set in R1, leave the rest alone
    bic r0, r0, r1
    // write it back
    mcr p15, 0x0, r0, cr1, cr0, 0x0

    // Disable caches for both TCMs (?)
    // C7,C5,0   0    Yes  Invalidate Entire Instruction Cache
    // C7,C6,0   0    Yes  Invalidate Entire Data Cache
    mov r0, #0
    mcr p15, 0, r0, c7, c5, 0
    mcr p15, 0, r0, c7, c6, 0
    // C7,C10,4  0    -    Drain Write Buffer
    mcr p15, 0, r0, c7, c10, 4

    // == Memory Protection == //
    // The protection regions are almost identical to the ones on GBATEK, which are in themselves
    // identical to the ones setup by the CRT of the game I've decompiled.
    // 
    // Control register C6 defines the region, C0-C7 all define a specific subregion.
    // Bit   0: 1 = enable protection, 0 = disable protection
    // Bit 1-5: 2 SHL value = region size
    // Bit 6-11: reserved
    // Bit 12-31: Region address * 4096
    //
    // The official ARM docs marks sizees less than 0b01011 as unpredictable, so the base unit is
    // in 4KB blocks?
    //
    // "The address of the first byte is required to be a multiple of the region size."

    // Protection region 0: 0x04000000, 64MiB (i.e. up to 0x8000000)
    // This is the I/O registers all the way up to the end of the OAM!
    ldr r0, =(0x04000000 | 0x33)
    mcr p15, 0, r0, c6, c0, 0

    // Protection region 1: 0x02000000, 4MiB
    // The compiled game I'm looking at has it incorrectly set to 8MiB. I guess the SDK always
    // sets it that high? This is main memory.
    ldr r0, =(0x02000000 | 0x2b)
    mcr p15, 0, r0, c6, c1, 0
    
    // Protection region 2: 0x027e0000, 128KiB (what?)
    // GBATEK: Region 2 and 7 are not understood?
    // Not going to set this. All zeroes to disable memory protection.
    mov r0, 0
    mcr p15, 0, r0, c6, c2, 0

    // Protection region 3: 0x08000000, 128MiB 
    // GBATEK: GBA Slot should be max 32MB+64KB, rounded up to 64MB, no idea why it is 128MB?
    ldr r0, =(0x08000000 | 0x35)
    mcr p15, 0, r0, c6, c3, 0

    // Protection region 4: 0x027e0000, 16KiB
    // This is the DTCM.
    ldr r0, =__dtcm_region_start
    orr r0, r0, #0x1b
    mcr p15, 0, r0, c6, c4, 0

    // Protection region 5: 0x01000000, 32KiB
    // ITCM. Thanks to mirroring, this repeats itself every 32KiB.
    ldr r0, =__itcm_region_start
    orr r0, r0, #0x1d
    mcr p15, 0, r0, c6, c5, 0

    // Protection region 6: 0xFFFF0000, 32KiB.
    // This is where the BIOS is mapped.
    ldr r0, =(0xFFFF0000 | 0x1d)
    mcr p15, 0, r0, c6, c6, 0

    // Protection region 7: 0x027FF000, 4KiB.
    // GBATEK says "shared work". I do wonder where it got that name from.
    //
    // The actual shared WRAM area is at the 0x03... addresses.
    // So... let's set it there.
    // Protection region 7: 0x037F8000, 32KiB. 
    ldr r0, =__shram_region_start
    orr r0, r0, #0x1d
    mcr p15, 0, r0, c6, c7, 0 

    // Protection region 2: 0x027FF00, 4KiB.
    // This is BIOS ram, see NDS BIOS RAM usage in GBATEK. Only realised this when looking through
    // addresses. 
    ldr r0, =(0x027FF00 | 0x17)
    mcr p15, 0, r0, c6, c2, 0

    // == Tightly Coupled Memory == //
    // C9, C1 controls the TCM Region. 
    //
    // The ARM manual states "Prior to ARMv6 it is IMPLEMENTATION DEFINED how TCMs are supported, 
    // "though generally this is through a System Control Coprocessor interface.""
    //
    // ITCM is fixed, so just set the size to 32MiB so it covers the entire first part of memory 
    // space. It'll get mirrored apparently.
    // Table B7-2: 32MiB is 0b10000 (&lt;&lt; 1), 16KiB is 0b00101 (&lt;&lt; 1).
    mov r0, 0x20
    mcr p15, 0, r0, c9, c1, 1

    // DTCM is movable, so load it at the right address and set its size to 16KiB.
    ldr r0, =__dtcm_region_start
    orr r0, r0, 0xa
    mcr p15, 0, r0, c9, c1, 0

    // == Protection Unit, Pt 2 == //
    // Register C2,C0 controls data caching and it's a bitfield for every region that needs caches.
    // 0x1 = instructions, 0x0 = data
    //
    // The only regions that needs caching is main memory, which is region 1, and the BIOS, which
    // is region 6. (The bitfield starts from the LSB.)
    mov r0, #0b01000010
    mcr p15, 0, r0, c2, c0, 0
    mcr p15, 0, r0, c2, c0, 1

    // C3,C0,0 is... write-bufferability? This is too far into the details of CPUs for me.
    // Just do what the official CRT does, which is region 1 (main memory).
    mov r0, #0b00000010
    mcr p15, 0, r0, c3, c0, 0

    // C5,C0 controls the permissions for the various memory protection regions. Immediate
    // value 2 and 3 control *extended* permissions, which give 4 bits per region with up to
    // six values. 2 = Data/Unified, 3 = Instruction. Immediate value 0 and 1 control basic 
    // permissions, with two bits per region.
    // 
    // We're just going to fill this with 0b11 for all eight regions as constructing the individual
    // permission bits is fiddly and not really needed.
    ldr r0, =0xffff
    mcr p15, 0, r0, c5, c0, 0
    mcr p15, 0, r0, c5, c0, 1

    // Re-enable ITCM, DTCM, caches, and protection unit.
    mrc p15, 0, r0, c1, c0, 0
    ldr r1, =0x0005707D
    orr r0, r0, r1
    mcr p15, 0, r0, c1, c0, 0

    bx lr</code></pre>
</details>

<h2>Emulator setup</h2>

<p>
    With a basic working binary and project skeleton ready, I can now run my rom. Whilst there's
    nothing stopping this from working on real hardware, it's a bit more difficult to attach a
    debugger to my O3DS so I'm going to use an emulator for nearly everything and only test the
    final products on my 3DS.
</p>

<blockquote>
    <h4>Editor's note!</h4>

    <p>
        This is a lie. I don't know where my 3DS charger is so I can't test it on real hardware yet.
    </p>
</blockquote>

<p>
    For debugging purposes, I need an emulator with a debugger. There's a handful of options
    available:
</p>
<ul>
    <li>
        <p>
            NO$GBA was the first Nitro emulator, and technically has a debugger. In practice it
            either doesn't work or I just can't figure out how to make it work beyond showing a
            memory dump.
        </p>
        <p>It's also proprietary and requires running via Wine.</p>
    </li>
    <li>
        <p>
            DeSmuME (when built with <code>USE="gdb"</code>) has a GDB stub, but it was a bit buggy
            the last time I used it. It also allegedly has a "View IO Registers" function, but it's
            permanently greyed out.
        </p>
    </li>
    <li>
        <p>
            melonDS, as of sometime in the last two years, has a GDB stub (which didn't work until
            sometime in the last few months) but no other debugging info.
        </p>
    </li>
    <li>
        <p>
            <a href="https://github.com/kelpsyberry/dust">dust</a> has full debugging features and a
            GDB stub, which seems perfect! But... it locks up when attaching GDB, and the registers
            are full of junk, so it's not really suitable for step-by-step debugging.
        </p>
    </li>
</ul>
<p>
    I'll use a mixture of melonDS and DeSmuME for this as the GDB stub in both does work but melonDS
    has some odd behaviours on halting that make it a bit more inconvenient. For ease of debugging,
    I'll un-discard the missing debug sections in the linker script:
</p>

<pre data-snippet="08/undebug.diff"><code>    __text_end = .;

-   /* Let's get rid of anything we haven't explicitly specified. This includes some debugging
-      info for now. */
-   /*/DISCARD/ : { * }*/</code></pre>

<p><img src="https://sailor.li/static/aocnds/img/gdb1.png"></p><p>
    I enable the GDB stub in melonDS (Config -&gt; Emu Settings -&gt; Devtools, enable GDB stub,
    check Break on startup), load my rom with <code>melonDS rom.nds</code>, then start my
    cross-compiled GDB with <code>env RUST_GDB=arm-none-eabi-gdb rust-gdb</code>. I can load the
    original ELF executable with <code>file ./target/armv5te-none-eabi/debug/aocnds</code>, then
    connect to the GDB stub with <code>target remote 127.0.0.1:3333</code>. From there, it's just
    like using GDB normally.
</p>

<blockquote>
    <p>
        I'm using the <a href="https://github.com/cyrus-and/gdb-dashboard">GDB dashboard</a> for a
        prettier GDB output.
    </p>
</blockquote>

<h2>Getting it to work, pt 1</h2>

<p>
    In a strict sense, a working bootstrap script and a payload is nearly all that's needed. I could
    solve the problem now and "output" it to a known fixed memory address, which can be read in the
    debugger, code golf style. Let's do that now, and get the boring work out of the way.
</p>

<p>Rust's standard library is actually several separate libraries glued together:</p>
<ul>
    <li>
        <p>
            The <code>core</code> library contains... well, the core code for the language. Pointer
            types, the <code>&amp;str</code> type, panic logic, the core formatting logic, and other
            core language traits are all defined in this library.
        </p>
    </li>
    <li>
        <p>
            The <code>alloc</code> library contains things that allocate memory onto the heap. These
            are types such as Box (heap pointers), Vec (heap arrays), and the reference counting
            utilities.
        </p>
    </li>
    <li>
        <p>
            The <code>std</code> library re-exports all of the former two libraries under the
            <code>std</code> namespace (see: <code>std::boxed::Boxed</code> is actually an
            <code>alloc::boxed::Box</code> in disguise) and contains things that allow interacting
            with the running system, such as filesystem or network I/O.
        </p>
    </li>
</ul>

<p>
    In a normal, hosted environment Rust uses the operating system's memory management functions
    (<code>malloc()</code> to allocate a block, <code>free()</code> to deallocate a block) to handle
    the heap, wrapped in internal tracking code. In this <code>no_std</code> environment, there are
    no operating system memory management functions, and I need to provide my own. Instead of
    writing the tracking code, I'll use a pre-built one known as <code>talc</code>. I'll also add
    the <code>spin</code> library as well:
</p>

<pre data-snippet="10/add-talc.toml"><code>[dependencies]
spin = { version = "=0.9.8" }
talc = { version = "=4.4.2" }</code></pre>

<p>Next, I can update my <code>main.rs</code> to create a new <em>global allocator</em>:</p>

<pre data-snippet="10/global_alloc.rs"><code>use talc::{ErrOnOom, Talc, Talck};

// Normally cargo links in all external libraries manually if using Rust 2018 or later, with one
// exception: ``alloc`` on no_std targets. It needs to be explicitly provided using ``extern crate``.
extern crate alloc;

#[global_allocator]
static ALLOCATOR: Talck&lt;spin::Mutex&lt;()&gt;, ErrOnOom&gt; = Talc::new(ErrOnOom).lock();</code></pre>

<blockquote>
    <p>
        The global allocator is a Rust-ism that means "the implementation of malloc()". Changing it
        is like hooking malloc and free in C/++ code.
    </p>
    <p>
        The alternative is local allocators via the allocator API, a bootleg mechanism to allow
        certain stdlib structures to use an explicitly provided allocator. Like most Rust features,
        it's currently unstable and that's not likely to change for the foreseeable future.
    </p>
</blockquote>

<p>Finally, I'll update the <code>config.toml</code> to build <code>alloc</code> as well:</p>

<pre data-snippet="10/add-build-std.toml"><code>[unstable]
build-std = ["core", "alloc"]</code></pre>

<p>
    This doesn't work yet because I haven't told the allocator where to start allocating things.
    Nevertheless, I like to compile things like this early because modern IDEs are terrible at
    actually showing errors:
</p>

<pre><code>error: could not compile `spin` (lib) due to 14 previous errors</code></pre>

<p><abbr title="Short for 'ah fuck.'">Ah</abbr>.</p>

<h3>A Multithreaded World</h3>

<p>In the programming world, there are two approaches to making multithreaded code safe:</p>
<ol>
    <li>Fuck you. This model is used by C/++, amongst others.</li>
    <li>
        Make it annoying (if correct) to use multithreaded code. This is the approach Rust uses, and
        by technicality pre-Python 3.13.
    </li>
</ol>
<p>
    In order to do anything with multiple threads in Rust, you need a set of operations known as
    <em>atomic</em> operations. There is a <em>lot</em> to be written about a safe model of
    multithreading, up to and including academic papers, but the gist of it is that atomic
    operations are used to perform safe, multi-threaded synchronisation and communication. For
    example, a compare-and-swap operation will <em>compare</em> the current value with a provided
    value, and if it matches, swap it with a different one. This means that to all threads, that
    value is <em>only</em> set if it matches, whereas a regular comparison and assignment might
    allow another thread to change the value between the two operations.
</p>

<p>
    On most architectures, such as x86_64 and AArch64, Rust provides a set of functions in the
    <code>core</code> library that directly map to hardware instructions or features that perform
    these operations. The ARM v5 architecture does not have these operations - it doesn't even have
    threads. When I try and compile the <code>spin</code> library, which relies heavily on atomics,
    it fails due to missing all of those atomic operations for this platform.
</p>

<p>
    Luckily, there is a library that fills in the missing atomic operations:
    <a href="https://docs.rs/portable-atomic"><code>portable-atomic</code></a>. Even luckier is that <code>spin</code> supports the usage of <code>portable-atomic</code>!
    Even luckier still is that <code>portable-atomic</code> has support for working safely using the
    <code>critical-section</code> library.
</p>

<blockquote>
    <h4>Warning!</h4>

    <p>
        Upon reading the above, some incredibly-credibly smart person has gone: but wait! There's no
        threads on ARMv5! You don't need to pull in a lock library because there will only ever be
        one thing asking for the lock!
    </p>

    <p>To which, I will respond:</p>

    <ol>
        <li>I don't care.</li>
        <li>Even without threads, I still need to implement atomics due to interrupts.</li>
        <li>The compiler complains really hard if I access static mutable variables.</li>
    </ol>
</blockquote>

<blockquote>
    <h4>Trivia!</h4>

    <p>
        A "critical section" is a global per-process lock.
        <code>portable-atomic</code> will enter the critical section before every "atomic" call and
        exit it afterwards, achieving atomic behaviour even in the presence of interrupts.
    </p>
</blockquote>

<h3>Rust-level Runtimes</h3>

<p>First, I'll add the new dependencies and features to <code>Cargo.toml</code>:</p>

<pre data-snippet="11/add-atomics.diff"><code>[dependencies]
+spin = { version = "=0.9.8", features = ["portable-atomic"] }
talc = { version = "=4.4.2" }
+portable-atomic = { version = "=1.10.0", default-features = false, features = ["critical-section"] }
+critical-section = { version = "=1.2.0", features = ["restore-state-u32"] }</code></pre>

<p>
    As this requires some extra code, I'm going to separate this out into its own file and include
    some of my previous runtime helpers such as the panic handler and the allocator instance:
</p>

<pre data-snippet="11/runtime-1.rs"><code>// File: runtime.rs
use talc::{ErrOnOom, Talc, Talck};

#[panic_handler]
fn _handle_panic(_: &amp;core::panic::PanicInfo) -&gt; ! {
    // TODO: Do something better than this
    loop {}
}

#[global_allocator]
static ALLOCATOR: Talck&lt;spin::Mutex&lt;()&gt;, ErrOnOom&gt; = Talc::new(ErrOnOom).lock();

// File: main.rs
mod runtime;</code></pre>

<p>Next, I need to provide an "implementation" of my critical section for the library:</p>

<pre data-snippet="11/crit-1.rs"><code>struct NitroCriticalSection;

unsafe impl critical_section::Impl for NitroCriticalSection {
    unsafe fn acquire() -&gt; critical_section::RawRestoreState {
        todo!()
    }

    unsafe fn release(restore_state: critical_section::RawRestoreState) {
        todo!()
    }
}

critical_section::set_impl!(NitroCriticalSection);</code></pre>

<p>This so-called implementation doesn't do anything yet, but it does let me build...</p>

<pre><code>= note: arm-none-eabi-ld: warning: /home/lura/dev/misc/aocnds/target/armv5te-none-eabi/debug/deps/aocnds-e996ce57e42739ae has a LOAD segment with RWX permissions
        arm-none-eabi-ld: /home/lura/dev/misc/aocnds/target/armv5te-none-eabi/debug/deps/aocnds-e996ce57e42739ae.9kjzfmijbuatij09ciw83phbt.rcgu.o:(.ARM.exidx.text.__rust_alloc_error_handler+0x0): undefined reference to `__aeabi_unwind_cpp_pr0'</code></pre>

<p>
    I'm not really sure why the allocation error handler is emitting calls to the C++ exception
    unwinding function instead of going through panic machinery, but I'll provide some stub
    implementations anyway:
</p>

<pre data-snippet="11/aeabi.rs"><code>#[unsafe(no_mangle)]
pub fn __aeabi_unwind_cpp_pr0() -&gt; ! {
    loop {}
}

#[unsafe(no_mangle)]
pub fn __aeabi_unwind_cpp_pr1() -&gt; ! {
    loop {}
}

#[unsafe(no_mangle)]
pub fn __aeabi_unwind_cpp_pr2() -&gt; ! {
    loop {}
}</code></pre>

<blockquote>
    <p>
        Even the Linux kernel
        <a href="https://elixir.bootlin.com/linux/v6.11.5/source/arch/arm/kernel/unwind.c#L40">has these stubbed out</a>. Thanks, binutils?
    </p>
</blockquote>

<p>
    Whilst this does build, this will immediately panic when attempting to allocate memory as the
    critical sections are stubs that don't do anything. I need to actually write a critical section
    handler.
</p>

<h3>Memory-mapped I/O</h3>

<p>
    The critical section needs to disable the Interrupt Master Enable register before entering, and
    then disable it again afterwards.
</p>

<blockquote>
    Not to be confused with the "Disable interrupts" flag on the Current Processor State register in
    the ARM architecture, obviously. I don't know why there's two, but one added explicitly by
    Nintendo seems more legit.
</blockquote>

<p>
    The IME is an example of <em>memory-mapped I/O</em>; hardware that is controlled by writing to
    specific memory addresses in the address space of the program. A lot of systems use
    memory-mapped I/O for hardware control; whilst modern x86 computers started out using
    <em>port-mapped I/O</em> (which uses special instructions and a separate memory space) AMD64 has
    moved to using memory-mapped I/O for modern peripherals. These special addresses are treated
    just like any other memory when reading or writing from them - although not all addresses are
    actually readable or writeable, and some will only allow reading or writing specific bits of the
    value.
</p>

<p>
    When I wrote the CRT for the program, the first thing I did was set the IME to zero. In
    assembly, this is easy enough; a
    <code>str &lt;Input reg&gt; [&lt;Address reg&gt;]</code> instruction just sets
    <code>Address := Input</code>. Reading or writing from arbitrary memory addresses in bare Rust
    may cause everything ever to violently explode, so I'm going to use a wrapper library called
    <code>voladdress</code>, which is not-so-coincidentally used by the GBA wrapper library.
</p>

<blockquote>
    <p>
        For more information why this may cause everything ever to violently explode, see
        <a href="https://lokathor.github.io/volatile/">this excellent post</a>. The most notable
        thing is that LLVM can just elide subsequent writes to an address, which is fine for normal
        memory but extremely wrong for memory-mapped I/O where writing has side effects.
    </p>
</blockquote>

<pre data-snippet="11/crit-fr.rs"><code>use voladdress::{Safe, VolAddress};

// Whilst only the lower bit is used, this isn't a boolean because representing non-0 or 1 as
// a boolean is UB.
static REG_IME: VolAddress&lt;u32, Safe, Safe&gt; =
    unsafe { VolAddress::new(0x4000208) };

unsafe impl critical_section::Impl for NitroCriticalSection {
    unsafe fn acquire() -&gt; critical_section::RawRestoreState {
        // Read it off first so that it can be restored properly. If the previous value was zero,
        // we need the restore to remain zero!
        let prev = REG_IME.read();
        REG_IME.write(0);
        return prev;
    }

    unsafe fn release(restore_state: critical_section::RawRestoreState) {
        REG_IME.write(restore_state);
    }
}</code></pre>

<p>
    Whilst the memory allocator will still <em>crash</em> (because I haven't given it anywhere to
    take memory from), at least it won't crash due to the lack of atomics.
</p>

<h3>The heap, for real</h3>

<p>
    In my linker script above, I defined a symbol called <code>__text_end</code>, which marks where
    the program code ends. This will be the start of my heap. I can define the end of the heap with
    <code>__memory_end = ORIGIN(main_ram) + LENGTH(main_ram) - LENGTH(dtcm) - 4;</code>. Combined,
    this will let me tell the allocator "okay, this is where you can use memory".
</p>

<blockquote>
    <p>
        Linker script variables (when exposed to higher level code) aren't really variables in the
        traditional sense: they're addresses. Global variables require space to be allocated in the
        <code>data</code> sections, whereas linker variables don't get that. To get the value of a
        linker variable, I have to get the address of it. It's a bit confusing.
    </p>
</blockquote>

<blockquote>
    <h4>Warning!</h4>

    <p>
        The <code>- LENGTH(dtcm)</code> is very important! The <code>talc</code> allocator stores
        metadata at the very <em>end</em> of memory, growing downwards. The stack exists at the very
        end of memory (in the DTCM), growing downwards. When the stack overwrites the metadata
        stored by the allocator, the next allocation call will check the previous metadata, see that
        it's all messed up, and panic.
    </p>
</blockquote>

<pre data-snippet="12/setup-allocator.rs"><code>// File: runtime.rs
use talc::Span;

unsafe extern "C" {
    static mut __text_end: u8;
    static mut __memory_end: u8;
}

/**
 * Sets up the heap allocator with the memory span defined by the linker.
 */
#[allow(static_mut_refs)]
pub fn setup_heap_allocator() {
    // Evil linker incantations!
    unsafe {
        let text_end = &amp;mut __text_end as *mut u8;
        let memory_end = &amp;mut __memory_end as *mut u8;
        let span = Span::new(text_end, memory_end);
        ALLOCATOR.lock().claim(span).unwrap();
    }
}

// File: main.rs
extern "C" fn main() -&gt; ! {
    setup_heap_allocator();

    // ...
}</code></pre>

<p>
    With this, I have a working heap that can allocate objects. The program binary size is ~81KiB
    (all that heap tracking machinery doesn't come cheap) or ~25KiB with <code>-Os</code>, which
    leaves ~3.6MiB of heap space. That's almost enough to run Windows 95.
</p>

<h3>Solving the problem</h3>

<p>
    The actual implementation of Day 1 Part 1 is trivial. This is not a very fast (or good)
    implementation, but it works. With no output, I'll just write to the fixed address 0x02200000,
    which is likely to be very past the end of the heap. I'll also add a hardware breakpoint, which
    will freeze GDB when it's done (if running in melonDS).
</p>

<pre data-snippet="13/day1pt1.rs"><code>// Outside main:
static PUZZLE_INPUT: &amp;str = include_str!("day1.txt");

// Format of the file is XXXXX   XXXXX
let mut first: Vec&lt;u32&gt; = Vec::new();
let mut second: Vec&lt;u32&gt; = Vec::new();

for line in PUZZLE_INPUT.split_terminator('\n') {
    let first_num: u32 = line[0..5].parse().unwrap();
    let second_num: u32 = line[8..13].parse().unwrap();
    first.push(first_num);
    second.push(second_num);
}

first.sort();
second.sort();

let mut sum: u32 = 0;
for (first, second) in first.iter().zip(second) {
    let diff = ((*first as i32) - (second as i32)).abs();
    sum += diff as u32;
}

let output: VolAddress&lt;u32, Safe, Safe&gt; = unsafe { VolAddress::new(0x02200000) };
output.write(sum);

unsafe {
    asm!("bkpt");
}</code></pre>

<p>Running this in GDB and checking memory at the breakpoint gives me my final answer:</p>

<pre><code>&gt;&gt;&gt; x/d 0x02200000
0x2200000:      2344935</code></pre>

<p>Plugging it into the Advent of Code website verifies the solution is correct.</p>

<h3>Doing it in a less lame way</h3>

<p>
    Only having output under the debugger is lame. Nitro has <em>two</em> screens that I'm not
    using!
</p>
<p>
    Nitro's graphics system is two GBAs, one per screen, and a 3D engine outputting to one screen. I
    don't need the 3D engine and I don't need the second screen, so I only need to program one of
    the GBAs (engine A).
</p>

<blockquote>
    <p>
        "2D Engine" is a Nintendo-ism for "graphics chip". It's a programmable way of doing 2D
        graphics per screen. Imagine it like a hardware game engine, same for the 3D engine.
    </p>
</blockquote>

<blockquote>
    <h4>Trivia!</h4>

    <p>
        Most Nitro games are fine with having 3D on one screen only; see Mario Kart DS as an
        example, where the top screen is the 3D game and the bottom screen is a 2D map. But some
        games managed to achieve 3D by a combination of two techniques:
    </p>
    <ol>
        <li>
            <p>
                Swapping which engine outputs to which screen every other frame. Frame 1 has engine
                A outputting to the main screen, and frame 2 has engine B outputting to the main
                screen.
            </p>
        </li>
        <li>
            <p>
                Using the <em>display capture</em> feature to capture the previous 3D frame and
                having engine B display it. This way Nitro games got 3D graphics on both screens, at
                the penalty of only being able to run at 30FPS.
            </p>
        </li>
    </ol>
</blockquote>

<h3>Interrupts &amp; Vertical Sync</h3>

<p>
    There's always some bureaucracy to do first. Whilst displays and screens can be thought of as
    just a 2D array of pixels, there's some intricacy in how these pixels are drawn. Historically,
    for Cathode Ray screens, the electron gun would physically move left to right until it hit the
    edge of the screen and it would have to reposition itself back to the left and go down one line.
    This is known as a <em>scanline</em>. When it reached the bottom of the screen it would then
    have to move the electron gun back to the top left and continue.
</p>
<p>
    The periods between moving the gun to the left and moving the gun to the top were known as the
    <em>horizontal blank</em> and <em>vertical blank</em> respectively. The horizontal blank isn't
    very useful but the vertical blank is <em>very</em> useful: it's the point where the game should
    update all of its graphics. This is because the display is a <em>live</em> view of the current
    graphical settings, and updating things whilst the screen is currently drawing results in
    graphical artefacts known as tearing. The behaviour of waiting for the vertical blank to draw is
    known as vertical sync. There are two ways to wait until vertical blank:
</p>
<ol>
    <li>
        <p>
            Wait until the VCOUNT register is past 160. Nitro's screen resolution is 256x160, so
            when the VCOUNT is above this the Nitro is in the vertical blank period.
        </p>
        <p>
            This has the problem that this spends all of its time spinning the CPU whilst waiting
            for the next frame.
        </p>
    </li>
    <li>
        <p>
            Ask the CPU to suspend until the next <em>vertical blank interrupt</em>. An interrupt is
            exactly what it sounds like; a mechanism for hardware to interrupt the currently running
            code and force it to deal with something else. (In this case, the hardware is the LCD
            controller.)
        </p>
    </li>
</ol>
<p>
    The latter is absolutely the correct approach, but that means dealing with a bunch of interrupt
    control code.
</p>

<h3>The IRQ handler</h3>

<p>
    The Nitro BIOS is a small (3KB) binary built-in to the hardware of the console. It's responsible
    for actually dealing with interrupts, as it is mapped to where the hardcoded ARM9 interrupt
    handlers are. When an interrupt happens, the ARM core switches mode into IRQ mode, and then
    jumps to the IRQ vector in the BIOS code.
</p>

<blockquote>
    <p>
        For embedded systems, vectors are a set of instructions at the very start of a memory region
        that are used for running the code upon boot or reset, for interrupts, or for exceptions.
        These are all jump opcodes to an actual function that does the work; for example, the reset
        vector for Nitro is located at <code>0xffff0000</code>, and is a single instruction that
        does a jump to <code>0xffff0110</code> which is the actual bring-up code for the system.
    </p>
    <p>
        The ARM9 has eight of these: Reset, Undefined, Supervisor Call, Prefetch Abort, Data Abort,
        Unused, Interrupt, and Fast Interrupt. On Nitro, only Reset, Supervisor Call, and Interrupt
        have assigned functions; the rest all share the vector for Fast Interrupt which is used for
        hardware debugging.
    </p>
    <p>If you see the word IRQ, that's the same as "interrupt".</p>
</blockquote>

<p>Here's the function in the BIOS responsible for handling interrupts, annotated by me:</p>

<pre data-snippet="14/irq_func.s"><code>// Save registers used by user code
// The other registers are saved by the IRQ function in its prologue and epilogue.
stmdb      sp!,{r0,r1,r2,r3,r12,lr}
// Load DTCM address (shifting off lower bits)
mrc        p15,0x0,r0,cr9,cr1,0x0
mov        r0,r0, lsr #0xc
mov        r0,r0, lsl #0xc
// Add fixed offset to the DTCM for the IRQ handler address
add        r0,r0,#0x4000
// Load BIOS return address
adr        lr,0xffff0290
// Jump to IRQ handler
ldr        pc,[r0,#-0x4]
// Restore registers used by user code
ldmia      sp!,{r0,r1,r2,r3,r12,lr}=&gt;local_18
// Jump back to previous code
subs       pc,lr,#0x4</code></pre>

<blockquote>
    <p>
        <code>subs pc, lr, #0x4</code> is a magic instruction that tells the ARM9 to switch from IRQ
        mode back to the previous mode. It returns to the code that was previously interrupted.
    </p>
</blockquote>

<p>
    Summarising this, the <em>address</em> of my interrupt handler needs to be at the address of
    DTCM + 0x3ffc. I'll put the code to load this into the <code>start.s</code> file, to avoid even
    more Rust-level linker script incantations:
</p>

<pre data-snippet="14/set_irq.diff"><code>+   // Less of a minefield to just set the IRQ handler in ``_start``
+   ldr r0, =irq_handler
+   ldr r1, =__dtcm_region_end
+   str r0, [r1]

    // After all of our setup is done, we can finally switch to main.</code></pre>

<p>
    The BIOS takes care of the busywork, so my interrupt handler can be a regular Rust function with
    the regular C calling convention:
</p>

<pre data-snippet="14/irq.rs"><code>// File: interrupts.rs
#[unsafe(no_mangle)]
pub extern "C" fn handle_irq() {
    todo!()
}</code></pre>

<p>
    Right now, interrupts are entirely disabled because the Interrupt Master Enable register is
    unset; even if it wasn't, there's another two registers I need to set to actually enable
    interrupts: the Interrupt Enable register (that's right, there's two) and the Display Status
    register. The Interrupt Enable register is a bitfield of the enabled interrupt types, with bit 0
    being vertical blank interrupts. I'll write a middleware function to handle setting IME and IE:
</p>

<pre data-snippet="14/wfi.rs"><code>// File: interrupts.rs
pub static REG_IME: VolAddress&lt;u32, Safe, Safe&gt; =
    unsafe { VolAddress::new(0x4000208) };

static REG_IE: VolAddress&lt;u32, Safe, Safe&gt; =
    unsafe { VolAddress::new(0x4000210) };

/**
 * Waits for the next interrupt, based on the provided mask.
 */
pub fn wait_for_interrupt(mask: u32) {
    let old_mask = REG_IE.read();

    REG_IE.write(mask);
    // enable global interrupts
    REG_IME.write(1);

    todo!("Actually halt the processor!")

    REG_IME.write(0);
    REG_IE.write(old_mask);
}</code></pre>

<p>
    I'll write a second wrapper function that sets DISPSTAT and then calls the
    <code>wait_for_interrupt</code> function as above:
</p>

<pre data-snippet="14/wfb.rs"><code>/**
 * Waits for the next vertical blank interrupt.
 */
pub fn wait_for_vblank() {
    let old_disp_stat = REG_DISPSTAT.read();
    // Bit 3 of DISPSTAT enables vertical blank interrupts
    let new_disp_stat = old_disp_stat | 0b100;

    REG_DISPSTAT.write(new_disp_stat);
    wait_for_interrupt(0b1);
    REG_DISPSTAT.write(old_disp_stat);
}</code></pre>

<p>
    Finally, I need to fill in the code that <em>actually</em> halts the system. The easiest way is
    to delegate it to the BIOS with an SWI (Software Interrupt) instruction; this will jump into the
    BIOS and call Software Interrupt #0x06 which is the interrupt for Halt.
</p>

<pre data-snippet="14/swi_halt.s"><code>.section .text

// See the definitions in ``supervisor.rs`` for more information.
// 
// GBATEK says:
// Caution: When invoking SWIs from inside of ARM state specify SWI NN*10000h, instead of
// SWI NN as in THUMB state.

.global SWI_Halt
SWI_Halt:
    swi #0x60000
    bx lr</code></pre>

<p>
    I'll replace the <code>todo!()</code> in the interrupt waiter with
    <code>unsafe { SWI_Halt() }</code>. The last thing to do is to <em>acknowledge</em> the
    interrupt by setting the same bit in the Interrupt Flags register (at <code>0x4000202</code>) as
    well as the bits at the fixed address DTCM + 3FFCh, which is done by another assembly function.
</p>

<pre data-snippet="14/irq-2.rs"><code>#[unsafe(no_mangle)]
pub extern "C" fn irq_handler() {
    let mask = REG_IF.read();
    if mask &amp; 0b1 == 0 {
        // don't care
        return
    }

    // clear V-blank bit
    REG_IF.write(0b1);
    unsafe {
        _set_irq_flags(0b1);
    }
}</code></pre>

<blockquote>
    <h4>Editor's note!</h4>

    <p>
        As it turns out, none of that was needed because the next section doesn't care about
        interrupts. Oh well. It's still good to have for the future, and to lower power usage by
        explicitly halting instead of spinning.
    </p>
</blockquote>

<h3>Drawing to the screen</h3>

<p>
    Nitro has a very configurable graphics system based around <em>backgrounds</em> and
    <em>sprites</em> (known as <em>objects</em> internally) each with various configurable modes. It
    also has an impressive ~650KiB of video memory (you could run Wing Commander: Privateer on
    that!) configurable into various blocks.
</p>
<p>
    The logical way to output the solution for the AoC problem is to create sprites for every digit,
    upload them to video memory, and arrange the sprites on screen. I'm not going to do that and
    instead I will use Display Mode 2, one of the four display modes for Engine A:
</p>
<ul>
    <li>Mode 0: Screen off</li>
    <li>Mode 1: Normal graphics mode, with backgrounds and objects</li>
    <li>Mode 2: Framebuffer mode, using video RAM</li>
    <li>Mode 3: Framebuffer mode, using DMA from main memory</li>
</ul>

<p>Mode 2 lets me treat the entire of VRAM Bank A as a framebuffer of 16-bit BGR555 pixels.</p>

<blockquote>
    <p>
        A framebuffer is a block of memory treated as a raw bitmap which is drawn upon to make a
        final frame. The framebuffer is copied to the output device (in my case, the LCD) and
        presented to the user. This is how graphics was done in the olden days, with code writing
        directly to the framebuffer.
    </p>

    <p>
        On modern graphics cards, the framebuffer is handled internally by the GPU and commands are
        instead sent to efficiently draw to it, rather than having the user code drawing directly to
        the framebuffer.
    </p>
</blockquote>

<blockquote>
    <p>
        The 650KiB of video memory is separated into multiple configurable banks which changes
        address in the VRAM area of memory depending on its configuration. Each VRAM bank has a
        register for controlling it's mode (three bits) and offset (two bits), as well as if it is
        enabled or not.
    </p>

    <p>
        Framebuffer mode and capture mode can use one of the first four banks, so for simplicity I
        will just use the first bank, which is 128KiB and is mapped at <code>0x6800000</code>
        in mode zero. This is more than enough to fit the entire framebuffer into the screen.
    </p>
</blockquote>

<p>
    I'm going to be using the
    <a href="https://docs.rs/embedded-graphics/latest/embedded_graphics/">embedded_graphics</a>
    library for drawing things on the screen, as it saves a lot of effort writing the individual
    primitives. First, I need a framebuffer implementation:
</p>

<pre data-snippet="15/fb.rs"><code>pub struct LcdFramebuffer {
    vram: VolBlock&lt;u16, Safe, Safe, 131072&gt;,
}

impl LcdFramebuffer {
    pub fn new() -&gt; LcdFramebuffer {
        let vram = unsafe { voladdress::VolBlock::new(0x6800000) };
        return LcdFramebuffer { vram };
    }
}

impl OriginDimensions for LcdFramebuffer {
    fn size(&amp;self) -&gt; embedded_graphics::prelude::Size {
        return Size::new(256, 192);
    }
}

impl DrawTarget for LcdFramebuffer {
    type Color = Bgr555;
    type Error = core::convert::Infallible;

    fn draw_iter&lt;I: IntoIterator&lt;Item = embedded_graphics::Pixel&lt;Self::Color&gt;&gt;&gt;(
        &amp;mut self,
        pixels: I,
    ) -&gt; Result&lt;(), Self::Error&gt; {
        let bound = self.size();

        for Pixel(coord, colour) in pixels {
            if coord.x &lt; 0 || coord.x &gt; bound.width as i32 {
                continue;
            }

            if coord.y &lt; 0 || coord.y &gt; bound.height as i32 {
                continue;
            }

            let pos = coord.x + (coord.y * 256);
            let offset = self.vram.index(pos as usize);
            offset.write(colour.into_storage());
        }

        return Ok(());
    }
}</code></pre>

<p>Next, I can enable VRAM Bank A by sitting bit 7 (enable) of the VRAMCTL_A in my main:</p>

<pre><code>VRAMCTL_A.write(0b10000000);</code></pre>

<p>
    Display mode is controlled by bits 16-17 of the DISPCNT_A register (Display Control for Engine
    A). I'll set that to Mode 2 like so:
</p>

<pre data-snippet="15/dispcnt.rs"><code>let mut dispcnt = DISPCNT_A.read();
let bits = 2u32 &lt;&lt; 16;
dispcnt |= bits;
DISPCNT_A.write(dispcnt);</code></pre>

<blockquote>
    <h4>Warning!</h4>

    <p>
        GBATEK notes that bit 7 of DISPCNT enabled forced blanking, turning the screen white and
        enabling faster access to VRAM. In all the emulators I tested, this does <i>not</i>
        work in framebuffer mode.
    </p>
</blockquote>

<p>Finally, I can draw the trademark OpenGL triangle with a Triangle primitive:</p>

<pre data-snippet="15/triangle.rs"><code>let mut lcd = LcdFramebuffer::new();
let tri = Triangle::new(Point::new(10, 10), Point::new(100, 10), Point::new(10, 100))
    .into_styled(PrimitiveStyle::with_fill(Bgr555::new(31, 0, 0)));
tri.draw(&amp;mut lcd).unwrap();</code></pre>

<p><img src="https://sailor.li/static/aocnds/img/opengl_triangle.png"></p><p>
    Unfortunately, upon seeing this I immediately became overwhelmed with evil power and used the
    <a href="https://docs.rs/tinybmp/0.6.0/tinybmp/">tinybmp</a> library to pull in an image and
    some text:
</p>

<p><img src="https://sailor.li/static/aocnds/img/yum_yum_squid.png"></p><blockquote>
    <p>
        The overhead of the inefficient debug code makes this comically slow. It takes about 20
        seconds for everything to be fully drawn at 60fps, because moving from main memory to video
        memory byte-by-byte is very sluggish.
    </p>

    <p>
        The right way to do this - without even optimising the inner loop - would be to draw to an
        in-memory framebuffer, then use a <abbr title="Direct Memory Access">DMA</abbr>
        transfer to copy into VRAM significantly faster; and, only after doing that, turn on the
        screen. At least it's fast enough in release mode.
    </p>
</blockquote>

<p>The final step is to actually hook up the Advent of Code solution to the font:</p>

<pre data-snippet="15/aoc.rs"><code>Text::new(
    format!("The solution is: {}", solve_aoc2021_pt1()).as_str(),
    Point::new(0, 175),
    font,
)
.draw(&amp;mut lcd)
.unwrap();</code></pre>

<h3>Conclusion</h3>

<p>
    This is a bit of a bootleg solution. The puzzle input is hardcoded into the program text which
    cuts in to precious memory; if I wanted to do more of the puzzles, I'd have to either hardcode
    them as well into memory (which takes up even more memory) or read them from the cart (which is
    an involved process). I'd also need to add the ability to select the solution, which would
    require input, which requires writing code onto the ARM7 because the ARM9 doesn't get to know
    input.
</p>

<p>
    But those are all topics for another day, because this post is already very long and
    implementing more complex features such as cart transfers or extended graphics is an entire
    entry's worth of detail in itself. So, I'll leave it at this.
</p>

<p>
    The final thing to say is that this project was disappointingly easy. It took me about two weeks
    to implement, working on and off, and most of it Just Worked; I only had to debug maybe two or
    three things. Hopefully extending this into a proper SDK will be harder.
</p>



        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Always go to the funeral (2005) (184 pts)]]></title>
            <link>https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral</link>
            <guid>42435972</guid>
            <pubDate>Mon, 16 Dec 2024 22:04:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral">https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral</a>, See on <a href="https://news.ycombinator.com/item?id=42435972">Hacker News</a></p>
Couldn't get https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Go Protobuf: The New Opaque API (255 pts)]]></title>
            <link>https://go.dev/blog/protobuf-opaque</link>
            <guid>42434947</guid>
            <pubDate>Mon, 16 Dec 2024 20:18:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/blog/protobuf-opaque">https://go.dev/blog/protobuf-opaque</a>, See on <a href="https://news.ycombinator.com/item?id=42434947">Hacker News</a></p>
Couldn't get https://go.dev/blog/protobuf-opaque: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Our muscles will atrophy as we climb the Kardashev Scale (140 pts)]]></title>
            <link>https://solmaz.io/our-muscles-will-atrophy</link>
            <guid>42433205</guid>
            <pubDate>Mon, 16 Dec 2024 17:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://solmaz.io/our-muscles-will-atrophy">https://solmaz.io/our-muscles-will-atrophy</a>, See on <a href="https://news.ycombinator.com/item?id=42433205">Hacker News</a></p>
Couldn't get https://solmaz.io/our-muscles-will-atrophy: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Lfgss shutting down 16th March 2025 (day before Online Safety Act is enforced) (581 pts)]]></title>
            <link>https://www.lfgss.com/conversations/401475/</link>
            <guid>42433044</guid>
            <pubDate>Mon, 16 Dec 2024 17:18:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lfgss.com/conversations/401475/">https://www.lfgss.com/conversations/401475/</a>, See on <a href="https://news.ycombinator.com/item?id=42433044">Hacker News</a></p>
Couldn't get https://www.lfgss.com/conversations/401475/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Veo 2: Our video generation model (444 pts)]]></title>
            <link>https://deepmind.google/technologies/veo/veo-2/</link>
            <guid>42432914</guid>
            <pubDate>Mon, 16 Dec 2024 17:04:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/technologies/veo/veo-2/">https://deepmind.google/technologies/veo/veo-2/</a>, See on <a href="https://news.ycombinator.com/item?id=42432914">Hacker News</a></p>
Couldn't get https://deepmind.google/technologies/veo/veo-2/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What did Ada Lovelace's program actually do? (2018) (275 pts)]]></title>
            <link>https://twobithistory.org/2018/08/18/ada-lovelace-note-g.html</link>
            <guid>42432867</guid>
            <pubDate>Mon, 16 Dec 2024 16:58:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twobithistory.org/2018/08/18/ada-lovelace-note-g.html">https://twobithistory.org/2018/08/18/ada-lovelace-note-g.html</a>, See on <a href="https://news.ycombinator.com/item?id=42432867">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>The story of Microsoft’s founding is one of the most famous episodes in
computing history. In 1975, Paul Allen flew out to Albuquerque to demonstrate
the BASIC interpreter that he and Bill Gates had written for the Altair
microcomputer. Because neither of them had a working Altair, Allen and Gates
tested their interpreter using an emulator that they wrote and ran on Harvard’s
computer system. The emulator was based on nothing more than the published
specifications for the Intel 8080 processor. When Allen finally ran their
interpreter on a real Altair—in front of the person he and Gates hoped would
buy their software—he had no idea if it would work. But it did. The next month,
Allen and Gates officially founded their new company.</p>

<p>Over a century before Allen and Gates wrote their BASIC interpreter, Ada
Lovelace wrote and published a computer program. She, too, wrote a program for
a computer that had only been described to her. But her program, unlike the
Microsoft BASIC interpreter, was never run, because the computer she was
targeting was never built.</p>

<!--more-->

<p>Lovelace’s program is often called the world’s first computer program. Not
everyone agrees that it should be called that. Lovelace’s legacy, it turns out,
is one of computing history’s most hotly debated subjects. Walter Isaacson has
written that the dispute about the extent and merit of her contributions
constitutes a “minor academic specialty.”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> Inevitably, the fact that
Lovelace was a woman has made this dispute a charged one. Historians have cited
all kinds of primary evidence to argue that the credit given to Lovelace is
either appropriate or undeserved. But they seem to spend less time explaining
the technical details of her published writing, which is unfortunate, because
the technical details are the most fascinating part of the story. Who wouldn’t
want to know exactly how a program written in 1843 was supposed to work?</p>

<p>In fairness, Lovelace’s program is not easy to explain to the layperson without
some hand-waving. It’s the intricacies of her program, though, that make it so
remarkable. Whether or not she ought to be known as “the first programmer,” her
program was specified with a degree of rigor that far surpassed anything that
came before. She thought carefully about how operations could be organized into
groups that could be repeated, thereby inventing the loop. She realized how
important it was to track the state of variables as they changed, introducing a
notation to illustrate those changes. As a programmer myself, I’m startled to
see how much of what Lovelace was doing resembles the experience of writing
software today.</p>

<p>So let’s take a closer look at Lovelace’s program. She designed it to calculate
the Bernoulli numbers. To understand what those are, we have to go back a
couple millennia to the genesis of one of mathematics’ oldest problems.</p>

<h2 id="sums-of-powers">Sums of Powers</h2>
<p>The Pythagoreans lived on the shores of the Mediterranean and worshiped
numbers. One of their pastimes was making triangles out of pebbles.</p>

<p><img src="https://twobithistory.org/images/triangular_numbers1.png" alt=""></p>

<p>One pebble followed by a row of two pebbles makes a triangle
containing three pebbles. Add another row of three pebbles and you get a
triangle containing six pebbles. You can continue like this, each time adding a
row with one more pebble in it than the previous row. A triangle with six rows
contains 21 pebbles. But how many pebbles does a triangle with 423 rows
contain?</p>

<p>What the Pythagoreans were looking for was a way to calculate the following
without doing all the addition:</p>

\[1 + 2 + 3 + \cdots + n\]

<p>They eventually realized that, if you place two triangles of the same size up
against each other so that they form a rectangle, you can find the area of the
rectangle and divide by two to get the number of pebbles in each of the
triangles:</p>

<p><img src="https://twobithistory.org/images/triangular_numbers2.png" alt=""></p>

\[1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}\]

<p>Archimedes later explored a similar problem. He was interested in the following
series:</p>

\[1^2 + 2^2 + 3^2 + \cdots + n^2\]

<p>You might visualize this series by imagining a stack of progressively larger
squares (made out of tiny cubes), one on top of the other, forming a pyramid.
Archimedes wanted to know if there was an easy way to tell how many cubes would
be needed to construct a pyramid with, say, 423 levels. He recorded a solution
that also permits a geometrical interpretation.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup></p>

<p>Three pyramids can be fit together to form a rectangular prism with a tiny,
one-cube-high extrusion at one end. That little extrusion happens to be a
triangle that obeys the same rules that the Pythagoreans used to make their
pebble triangles. (<a href="https://www.youtube.com/watch?v=aXbT37IlyZQ">This video</a>
might be a more helpful explanation of what I mean.) So the volume of the whole
shape is given by the following equation:</p>

\[3(1^2 + 2^2 + 3^2 + \cdots + n^2) = (n+1)n^2 + (1 + 2 + 3 + \cdots + n)\]

<p>By substituting the Pythagorean equation for the sum of the first <em>n</em>
integers and doing some algebra, you get this:</p>

\[1^2 + 2^2 + 3^2 + \cdots + n^2 = \frac{n(n+1)(2n+1)}{6}\]

<p>In 499, the Indian mathematician and astronomer, Aryabhata, published a work
known as the <em>Aryabhatiya</em>, which included a formula for calculating the sum of
cubes:</p>

\[1^3 + 2^3 + 3^3 + \cdots + n^3 = (1 + 2 + 3 + \cdots + n)^2\]

<p>A formula for the sum of the first <em>n</em> positive integers raised to the fourth
power wasn’t published for another 500 years.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup></p>

<p>You might be wondering at this point if there is a general method for finding
the sum of the first <em>n</em> integers raised to the <em>kth</em> power.
Mathematicians were wondering too. Johann Faulhaber, a German mathematician and
slightly kooky numerologist, was able to calculate formulas for sums of
integers up to the 17th power, which he published in 1631. But this may have
taken him years and he did not state a general solution.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup> Blaise Pascal
finally outlined a general method in 1665, though it depended on first knowing
how to calculate the sum of integers raised to every lesser power.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> To
calculate the sum of the first <em>n</em> positive integers raised to the sixth power,
for example, you would first have to know how to calculate the sum of the first
<em>n</em> positive integers raised to the fifth power.</p>

<p>A more practical general solution was stated in the posthumously published work
of Swiss mathematician Jakob Bernoulli, who died in 1705. Bernoulli began by
deriving the formulas for calculating the sums of the first <em>n</em> positive
integers to the first, second, and third powers.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup> These he gave in
polynomial form, so they looked like the below:</p>

\[1 + 2 + 3 + \cdots + n = \frac{1}{2}n^2 + \frac{1}{2}n \\

1^2 + 2^2 + 3^2 + \cdots + n^2 = \frac{1}{3}n^3 + \frac{1}{2}n^2 + \frac{1}{6}n
\\

1^3 + 2^3 + 3^3 + \cdots + n^3 = \frac{1}{4}n^4 + \frac{1}{2}n^3 +
\frac{1}{4}n^2\]

<p>Using Pascal’s Triangle, Bernoulli realized that these polynomials followed a
predictable pattern. Essentially, Bernoulli broke the coefficients of each
term down into two factors, one of which he could determine using Pascal’s
Triangle and the other which he could derive from the interesting property that
all the coefficients in the polynomial seemed to always add to one. Figuring
out the exponent that should be attached to each term was no problem,
because that also followed a predictable pattern. The factor of each
coefficient that had to be calculated using the sums-to-one rule formed a
sequence that became known as the Bernoulli numbers.</p>

<p>Bernoulli’s discovery did not mean that it was now trivial to calculate the sum
of the first positive <em>n</em> integers to any given power. In order to calculate
the sum of the first positive <em>n</em> integers raised to the <em>kth</em> power,
you would need to know every Bernoulli number up to the <em>kth</em> Bernoulli
number. Each Bernoulli number could only be calculated if the previous
Bernoulli numbers were known. But calculating a long series of Bernoulli
numbers was significantly easier than deriving each sum of powers formula in
turn, so Bernoulli’s discovery was a big advance for mathematics.</p>

<h2 id="babbage">Babbage</h2>
<p>Charles Babbage was born in 1791, nearly a century after Bernoulli died. I’ve
always had some vague idea that Babbage designed but did not build a mechanical
computer. But I’ve never entirely understood how that computer was supposed to
work. The basic ideas, as it happens, are not that difficult to grasp, which is
good news. Lovelace’s program was designed to run on one of Babbage’s machines,
so we need to take another quick detour here to talk about how those machines
worked.</p>

<p>Babbage designed two separate mechanical computing machines. His first machine
was called the Difference Engine. Before the invention of the pocket
calculator, people relied on logarithmic tables to calculate the product of
large numbers. (There is a good <a href="https://youtu.be/VRzH4xB0GdM">Numberphile
video</a> on how this was done.) Large logarithmic
tables are not difficult to create, at least conceptually, but the sheer number
of calculations that need to be done in order to create them meant that in
Babbage’s time they often contained errors. Babbage, frustrated by this, sought
to create a machine that could tabulate logarithms mechanically and therefore
without error.<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup></p>

<p>The Difference Engine was not a computer, because all it did was add and
subtract. It took advantage of a method devised by the French mathematician
Gaspard de Prony that broke the process of tabulating logarithms down into
small steps.<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup> These small steps involved only addition and subtraction,
meaning that a small army of people without any special mathematical aptitude
or training could be employed to produce a table. De Prony’s method, known as
the method of divided differences, could be used to tabulate any polynomial.
Polynomials, in turn, could be used to approximate logarithmic and
trigonometric functions.</p>

<p>To get a sense of how this process worked, consider the following simple
polynomial function:</p>

\[y = x^2 + 1\]

<p>The method of divided differences involves finding the difference between each
successive value of <em>y</em> for different values of <em>x</em>. The differences
between these differences are then found, and possibly the differences between
those next differences themselves, until a constant difference appears. These
differences can then be used to get the next value of the polynomial simply by
adding.</p>

<p>Because the above polynomial is only a second-degree polynomial, we are able to
find the constant difference after only two columns of differences:</p>

<div>
  <table>
    <thead>
      <tr>
        <th>x</th>
        <th>y</th>
        <th>Diff 1</th>
        <th>Diff 2</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>1</td>
        <td>2</td>
        <td>&nbsp;</td>
        <td>&nbsp;</td>
      </tr>
      <tr>
        <td>2</td>
        <td>5</td>
        <td>3</td>
        <td>&nbsp;</td>
      </tr>
      <tr>
        <td>3</td>
        <td>10</td>
        <td>5</td>
        <td>2</td>
      </tr>
      <tr>
        <td>4</td>
        <td>17</td>
        <td>7</td>
        <td>2</td>
      </tr>
      <tr>
        <td>5</td>
        <td>?</td>
        <td>?</td>
        <td>2</td>
      </tr>
      <tr>
        <td>…</td>
        <td>…</td>
        <td>…</td>
        <td>…</td>
      </tr>
    </tbody>
  </table>

</div>

<p>Now, since we know that the constant difference is 2, we can find the value of
<em>y</em> when <em>x</em> is 5 through addition only. If we add 2 to 7, the last entry in
the “Diff 1” column, we get 9. If we add 9 to 17, the last entry in the <em>y</em>
column, we get 26, our answer.</p>

<p>Babbage’s Difference Engine had, for each difference column in a table like the
one above, a physical column of gears. Each gear was a decimal digit and one
whole column was a decimal number. The Difference Engine had eight columns of
gears, so it could tabulate a polynomial up to the seventh degree. The columns
were initially set with values matching an early row in the difference table,
worked out ahead of time. A human operator would then turn a crank shaft,
causing the constant difference to propagate through the machine as the value
stored on each column was added to the next.</p>

<p>Babbage was able to build a small section of the Difference Engine and use it
to demonstrate his ideas at parties.<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">9</a></sup> But even after spending an amount of
public money equal to the cost of two large warships, he never built the entire
machine.<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" rel="footnote">10</a></sup> Babbage could not find anyone in the early 1800s that could make
the number of gears he needed with sufficient accuracy. A working Difference
Engine would not be built until the 1990s, after the advent of precision
machining. There is <a href="https://www.youtube.com/watch?v=BlbQsKpq3Ak">a great video on
YouTube</a> demonstrating a working
Difference Engine on loan to the Computer History Museum in Mountain View,
which is worth watching even just to listen to the marvelous sounds the machine
makes while it runs.</p>

<p>Babbage eventually lost interest in the Difference Engine when he realized that
a much more powerful and flexible machine could be built. His Analytical Engine
was the machine that we know today as Babbage’s mechanical computer. The
Analytical Engine was based on the same columns of gears used in the Difference
Engine, but whereas the Difference Engine only had eight columns, the
Analytical Engine was supposed to have many hundreds more. The Analytical
Engine could be programmed using punched cards like a Jacquard Loom and could
multiply and divide as well as add and subtract. In order to perform one of
these operations, a section of the machine called the “mill” would rearrange
itself into the appropriate configuration, read the operands off of other
columns used for data storage, and then write the result back to another
column.</p>

<p>Babbage called his new machine the Analytical Engine because it was powerful
enough to do something resembling mathematical analysis. The Difference Engine
could tabulate a polynomial, but the Analytical Engine would be able to
calculate, for example, the coefficients of the polynomial expansion of another
expression. It was an amazing machine, but the British government wisely
declined to fund its construction. So Babbage went abroad to Italy to try to
drum up support for his idea.</p>

<h2 id="notes-by-the-translator">Notes by The Translator</h2>
<p>In Turin, Babbage met Italian engineer and future prime minister Luigi
Menabrea. He persuaded Menabrea to write an outline of what the Analytical
Engine could accomplish. In 1842, Menabrea published a paper on the topic in
French. The following year, Lovelace published a translation of Menabrea’s
paper into English.</p>

<p>Lovelace, then known as Ada Byron, first met Babbage at a party in 1833, when
she was 17 and he was 41.<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup> Lovelace was fascinated with Babbage’s
Difference Engine. She could also understand how it worked, because she had
been extensively tutored in mathematics throughout her childhood. Her mother,
Annabella Milbanke, had decided that a solid grounding in mathematics would
ward off the wild, romantic sensibility that possessed Lovelace’s father, Lord
Byron, the famous poet. After meeting in 1833, Lovelace and Babbage remained a
part of the same social circle and wrote to each other frequently.</p>

<p>Ada Byron married William King in 1835. King later became the Earl of Lovelace,
making Ada the Countess of Lovelace. Even after having three children, she
continued her education in mathematics, employing Augustus de Morgan, who
discovered De Morgan’s laws, as her tutor.<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" rel="footnote">12</a></sup> Lovelace saw the potential of
Babbage’s Analytical Machine immediately and was eager to work with him to
promote the idea. A friend suggested that she translate Menabrea’s paper for an
English audience.<sup id="fnref:13" role="doc-noteref"><a href="#fn:13" rel="footnote">13</a></sup></p>

<p>Menabrea’s paper gave a brief overview of how the Difference Engine worked,
then showed how the Analytical Engine would be a far superior machine. The
Analytical Engine would be so powerful that it could “form the product of two
numbers, each containing twenty figures, in <em>three minutes</em>”<sup id="fnref:14" role="doc-noteref"><a href="#fn:14" rel="footnote">14</a></sup> (emphasis in
the original). Menabrea gave further examples of the machine’s capabilities,
demonstrating how it could solve a simple system of linear equations and
expand the product of two binomial expressions. In both cases, Menabrea
provided what Lovelace called “diagrams of development,” which listed the
sequence of operations that would need to be performed to calculate the correct
answer.<sup id="fnref:15" role="doc-noteref"><a href="#fn:15" rel="footnote">15</a></sup> These were programs in the same sense that Lovelace’s own program
was a program and they were originally published the year before. But as we
will see, Menabrea’s programs were only simple examples of what was possible.
All of them were trivial in the sense that they did not require any kind of
branching or looping.</p>

<p>Lovelace appended a series of notes to her translation of Menabrea’s paper that
together ran much longer than the original work. It was here that she made her
major contributions to computing. In Note A, which Lovelace attached to
Menabrea’s initial description of the Analytical Engine, Lovelace explained at
some length and often in lyrical language the promise of a machine that could
perform arbitrary mathematical operations. She foresaw that a machine like the
Analytical Engine wasn’t just limited to numbers and could in fact act on
any objects “whose mutual fundamental relations could be expressed by those of
the abstract science of operations, and which should be also susceptible of
adaptations to the action of the operating notation and mechanism of the
engine.”<sup id="fnref:16" role="doc-noteref"><a href="#fn:16" rel="footnote">16</a></sup> She added that the machine might one day, for example, compose
music. This insight was all the more remarkable given that Menabrea saw the
Analytical Engine primarily as a tool for automating “long and arid
computation,” which would free up the intellectual capacities of brilliant
scientists for more advanced thinking.<sup id="fnref:17" role="doc-noteref"><a href="#fn:17" rel="footnote">17</a></sup> The miraculous foresight that
Lovelace demonstrated in Note A is one major reason that she is celebrated
today.</p>

<p>The other famous note is Note G. Lovelace begins Note G by arguing that,
despite its impressive powers, the Analytical Machine cannot really be said to
“think.” This part of Note G is what Alan Turing would later refer to as “Lady
Lovelace’s Objection.” Nevertheless, Lovelace continues, the machine can do
extraordinary things. To illustrate its ability to handle even more complex
problems, Lovelace provides her program calculating the Bernoulli numbers.</p>

<p>The full program, in the expanded “diagram of development” format that Lovelace
explains in Note D, can be seen
<a href="https://upload.wikimedia.org/wikipedia/commons/c/cf/Diagram_for_the_computation_of_Bernoulli_numbers.jpg">here</a>.
The program is essentially a list of operations, specified using the usual
mathematical symbols. It doesn’t appear that Babbage or Lovelace got as far as
developing anything like a set of op codes for the Analytical Engine.</p>

<p>Though Lovelace was describing a method for computing the entire sequence of
Bernoulli numbers up to some limit, the program she provided only illustrated
one step of that process. Her program calculated a number that she called B7,
which modern mathematicians know as the eighth Bernoulli number. Her program
thus sought to solve the following equation:</p>

\[B_7 = -1(A_0 + B_1A_1 + B_3A_3 + B_5A_5)\]

<p>In the above, each term represents a coefficient in the polynomial formula for
the sum of integers to a particular power. Here that power is eight, since the
eighth Bernoulli number first appears in the formula for the sum of positive
integers to the eighth power. The B and A numbers represent the two kinds of
factors that Bernoulli discovered. B1 through B7 are all different Bernoulli
numbers, indexed according to Lovelace’s indexing. A0 through A5 represent the
factors of the coefficients that Bernoulli could calculate using Pascal’s
Triangle. The values of A0, A1, A3, and A5 appear below. Here <em>n</em> represents
the index of the Bernoulli number in the sequence of odd-numbered Bernoulli
numbers starting with the first. Lovelace’s program used <em>n</em> = 4.</p>

\[A_0 = -\frac{1}{2} \cdot \frac{2n - 1}{2n + 1} \\
A_1 = \frac{2n}{2} \\
A_3 = \frac{2n(2n-1)(2n-2)}{2 \cdot 3 \cdot 4} \\
A_5 = \frac{2n(2n-1)(2n-2)(2n-3)(2n-4)}{2 \cdot 3 \cdot 4 \cdot 5 \cdot 6}\]

<p>I’ve created a
<a href="https://gist.github.com/sinclairtarget/ad18ac65d277e453da5f479d6ccfc20e">translation</a>
of Lovelace’s program into C, which may be easier to follow. Lovelace’s program
first calculates A0 and the product B1A1. It then enters a loop that repeats
twice to calculate B3A3 and B5A5, since those are formed according to an
identical pattern. After each product is calculated, it is added with all the
previous products, so that by the end of the program the full sum has been
obtained.</p>

<p>Obviously the C translation is not an exact recreation of Lovelace’s program.
It declares variables on the stack, for example, whereas Lovelace’s variables
were more like registers. But it makes obvious the parts of Lovelace’s program
that were so prescient. The C program contains two <code>while</code> loops, one nested
inside the other. Lovelace’s program did not have <code>while</code> loops exactly, but
she made groups of operations and in the text of her note specified when they
should repeat. The variable <code>v10</code>, in the original program and in the C
translation, functions as a counter variable that decrements with each loop, a
construct any programmer would be familiar with. In fact, aside from the
profusion of variables with unhelpful names, the C translation of Lovelace’s
program doesn’t look that alien at all.</p>

<p>The other thing worth mentioning quickly is that translating Lovelace’s program
into C was not that difficult, thanks to the detail present in her diagram.
Unlike Menabrea’s tables, her table includes a column labeled “Indication of
change in the value on any Variable,” which makes it much easier to follow the
mutation of state throughout the program. She adds a superscript index here to
each variable to indicate the successive values they hold. A superscript of
two, for example, means that the value being used here is the second value that
has been assigned to the variable since the beginning of the program.</p>

<h2 id="the-first-programmer">The First Programmer?</h2>
<p>After I had translated Lovelace’s program into C, I was able to run it on my
own computer. To my frustration, I kept getting the wrong result. After some
debugging, I finally realized that the problem wasn’t the code that I had
written. The bug was in the original!</p>

<p>In her “diagram of development,” Lovelace gives the fourth operation as
<code>v5 / v4</code>. But the correct ordering here is <code>v4 / v5</code>. This may well have been
a typesetting error and not an error in the program that Lovelace devised. All
the same, this must be the oldest bug in computing. I marveled that, for ten
minutes or so, unknowingly, I had wrestled with this first ever bug.</p>

<p>Jim Randall, another blogger that has <a href="https://enigmaticcode.wordpress.com/tag/bernoulli-numbers/">translated Lovelace’s program into
Python</a>, has noted
this division bug and two other issues. What does it say about Ada Lovelace
that her published program contains minor bugs? Perhaps it shows that she
was attempting to write not just a demonstration but a real program. After all,
can you really be writing anything more than toy programs if you aren’t also
writing lots of bugs?</p>

<p>One Wikipedia article calls Lovelace the first to publish a “complex
program.”<sup id="fnref:18" role="doc-noteref"><a href="#fn:18" rel="footnote">18</a></sup> Maybe that’s the right way to think about Lovelace’
accomplishment. Menabrea published “diagrams of development” in his paper a
year before Lovelace published her translation. Babbage also wrote more than
twenty programs that he never published.<sup id="fnref:19" role="doc-noteref"><a href="#fn:19" rel="footnote">19</a></sup> So it’s not quite accurate to say
that Lovelace wrote or published the first program, though there’s always room
to quibble about what exactly constitutes a “program.” Even so, Lovelace’s
program was miles ahead of anything else that had been published before. The
longest program that Menabrea presented was 11 operations long and contained no
loops or branches; Lovelace’s program contains 25 operations and a nested loop
(and thus branching). Menabrea wrote the following toward the end of his paper:</p>

<blockquote>
  <p>When once the engine shall have been constructed, the difficulty will be
reduced to the making of the cards; but as these are merely the translation
of algebraic formulae, it will, by means of some simple notation, be easy to
consign the execution of them to a workman.<sup id="fnref:20" role="doc-noteref"><a href="#fn:20" rel="footnote">20</a></sup></p>
</blockquote>

<p>Neither Babbage nor Menabrea were especially interested in applying the
Analytical Engine to problems beyond the immediate mathematical challenges that
first drove Babbage to construct calculating machines. Lovelace saw that the
Analytical Engine was capable of much more than Babbage or Menabrea could
imagine. Lovelace also grasped that “the making of the cards” would not be a
mere afterthought and that it could be done well or done poorly. This is hard
to appreciate without understanding her program from Note G and seeing for
oneself the care she put into designing it. But having done that, you might
agree that Lovelace, even if she was not the very first programmer, was the
first programmer to deserve the title.</p>

<p><em>
If you enjoyed this post, more like it come out every four weeks! Follow
<a href="https://twitter.com/TwoBitHistory">
  @TwoBitHistory
</a> on Twitter or subscribe to the
<a href="https://twobithistory.org/feed.xml">
  RSS feed
</a>
to make sure you know when a new post is out.
</em></p>

<p><em>Previously on TwoBitHistory…</em></p>

<blockquote data-lang="en"><p lang="en" dir="ltr">This week's post: Parsing Vim's prestigious pedigree!<a href="https://t.co/1YUszI5dIC">https://t.co/1YUszI5dIC</a></p>— TwoBitHistory (@TwoBitHistory) <a href="https://twitter.com/TwoBitHistory/status/1026240555062386689?ref_src=twsrc%5Etfw">August 5, 2018</a></blockquote>




</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Search of a Faster SQLite (270 pts)]]></title>
            <link>https://avi.im/blag/2024/faster-sqlite/</link>
            <guid>42432730</guid>
            <pubDate>Mon, 16 Dec 2024 16:46:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avi.im/blag/2024/faster-sqlite/">https://avi.im/blag/2024/faster-sqlite/</a>, See on <a href="https://news.ycombinator.com/item?id=42432730">Hacker News</a></p>
Couldn't get https://avi.im/blag/2024/faster-sqlite/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Xiaomi has provided official support for Home Assistant (511 pts)]]></title>
            <link>https://github.com/XiaoMi/ha_xiaomi_home</link>
            <guid>42432151</guid>
            <pubDate>Mon, 16 Dec 2024 15:52:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/XiaoMi/ha_xiaomi_home">https://github.com/XiaoMi/ha_xiaomi_home</a>, See on <a href="https://news.ycombinator.com/item?id=42432151">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Xiaomi Home Integration for Home Assistant</h2><a id="user-content-xiaomi-home-integration-for-home-assistant" aria-label="Permalink: Xiaomi Home Integration for Home Assistant" href="#xiaomi-home-integration-for-home-assistant"></a></p>
<p dir="auto"><a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/README.md">English</a> | <a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/README_zh.md">简体中文</a></p>
<p dir="auto">Xiaomi Home Integration is an integrated component of Home Assistant supported by Xiaomi official. It allows you to use Xiaomi IoT smart devices in Home Assistant.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<blockquote>
<p dir="auto">Home Assistant version requirement:</p>
<ul dir="auto">
<li>Core <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="f12297ba6e5c0ae3b6b0018d7cce056e">$\geq$</math-renderer> 2024.11.0</li>
<li>Operating System <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="f12297ba6e5c0ae3b6b0018d7cce056e">$\geq$</math-renderer> 13.0</li>
</ul>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 1: Git clone from GitHub</h3><a id="user-content-method-1-git-clone-from-github" aria-label="Permalink: Method 1: Git clone from GitHub" href="#method-1-git-clone-from-github"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd config
git clone https://github.com/XiaoMi/ha_xiaomi_home.git
cd ha_xiaomi_home
./install.sh /config"><pre><span>cd</span> config
git clone https://github.com/XiaoMi/ha_xiaomi_home.git
<span>cd</span> ha_xiaomi_home
./install.sh /config</pre></div>
<p dir="auto">We recommend this installation method, for it is convenient to switch to a tag when updating <code>xiaomi_home</code> to a certain version.</p>
<p dir="auto">For example, update to version v1.0.0</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd config/ha_xiaomi_home
git checkout v1.0.0
./install.sh /config"><pre><span>cd</span> config/ha_xiaomi_home
git checkout v1.0.0
./install.sh /config</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 2: <a href="https://hacs.xyz/" rel="nofollow">HACS</a></h3><a id="user-content-method-2-hacs" aria-label="Permalink: Method 2: HACS" href="#method-2-hacs"></a></p>
<p dir="auto">HACS &gt; Overflow Menu &gt; Custom repositories &gt; Repository: <a href="https://github.com/XiaoMi/ha_xiaomi_home.git">https://github.com/XiaoMi/ha_xiaomi_home.git</a> &amp; Category: Integration &gt; ADD</p>
<blockquote>
<p dir="auto">Xiaomi Home has not been added to the HACS store as a default yet. It's coming soon.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 3: Manually installation via <a href="https://github.com/home-assistant/addons/tree/master/samba">Samba</a> / <a href="https://github.com/hassio-addons/addon-ftp">FTPS</a></h3><a id="user-content-method-3-manually-installation-via-samba--ftps" aria-label="Permalink: Method 3: Manually installation via Samba / FTPS" href="#method-3-manually-installation-via-samba--ftps"></a></p>
<p dir="auto">Download and copy <code>custom_components/xiaomi_home</code> folder to <code>config/custom_components</code> folder in your Home Assistant.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Login</h3><a id="user-content-login" aria-label="Permalink: Login" href="#login"></a></p>
<p dir="auto"><a href="https://my.home-assistant.io/redirect/brand/?brand=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; ADD INTEGRATION</a> &gt; Search <code>Xiaomi Home</code> &gt; NEXT &gt; Click here to login &gt; Sign in with Xiaomi account</p>
<p dir="auto"><a href="https://my.home-assistant.io/redirect/config_flow_start/?domain=xiaomi_home" rel="nofollow"><img src="https://camo.githubusercontent.com/adbb09f7a40eb3933f3220dfe49dd8dff1e0f86acf59e9803662bb6f8f988910/68747470733a2f2f6d792e686f6d652d617373697374616e742e696f2f6261646765732f636f6e6669675f666c6f775f73746172742e737667" alt="Open your Home Assistant instance and start setting up a new integration." data-canonical-src="https://my.home-assistant.io/badges/config_flow_start.svg"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Add MIoT Devices</h3><a id="user-content-add-miot-devices" aria-label="Permalink: Add MIoT Devices" href="#add-miot-devices"></a></p>
<p dir="auto">After logging in successfully, a dialog box named "Select Home and Devices" pops up. You can select the home containing the device that you want to import in Home Assistant.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multiple User Login</h3><a id="user-content-multiple-user-login" aria-label="Permalink: Multiple User Login" href="#multiple-user-login"></a></p>
<p dir="auto">After a Xiaomi account login and its user configuration are completed, you can continue to add other Xiaomi accounts in the configured Xiaomi Home Integration page.</p>
<p dir="auto">Method: <a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; Configured &gt; Xiaomi Home</a> &gt; ADD HUB &gt; NEXT &gt; Click here to login &gt; Sign in with Xiaomi account</p>
<p dir="auto"><a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow"><img src="https://camo.githubusercontent.com/15a86d08f7563387040afaf0ccbc46e4bee0f1002dfba800b01196693feff43f/68747470733a2f2f6d792e686f6d652d617373697374616e742e696f2f6261646765732f696e746567726174696f6e2e737667" alt="Open your Home Assistant instance and show an integration." data-canonical-src="https://my.home-assistant.io/badges/integration.svg"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Update Configurations</h3><a id="user-content-update-configurations" aria-label="Permalink: Update Configurations" href="#update-configurations"></a></p>
<p dir="auto">You can change the configurations in the "Configuration Options" dialog box, in which you can update your user nickname and the list of the devices importing from Xiaomi Home APP, etc.</p>
<p dir="auto">Method: <a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; Configured &gt; Xiaomi Home</a> &gt; CONFIGURE &gt; Select the option to update</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debug Mode for Action</h3><a id="user-content-debug-mode-for-action" aria-label="Permalink: Debug Mode for Action" href="#debug-mode-for-action"></a></p>
<p dir="auto">You can manually send Action command message with parameters to the device when the debug mode for action is activated. The user interface for sending the Action command with parameters is shown as a Text entity.</p>
<p dir="auto">Method: <a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; Configured &gt; Xiaomi Home</a> &gt; CONFIGURE &gt; Debug mode for action</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Xiaomi Home Integration and the affiliated cloud interface is provided by Xiaomi officially. You need to use your Xiaomi account to login to get your device list. Xiaomi Home Integration implements OAuth 2.0 login process, which does not keep your account password in the Home Assistant application. However, due to the limitation of the Home Assistant platform, the user information (including device information, certificates, tokens, etc.) of your Xiaomi account will be saved in the Home Assistant configuration file in clear text after successful login. You need to ensure that your Home Assistant configuration file is properly stored. The exposure of your configuration file may result in others logging in with your identity.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Does Xiaomi Home Integration support all Xiaomi Home devices?</p>
<p dir="auto">Xiaomi Home Integration currently supports most categories of Home device. Only a few categories are not supported. They are Bluetooth device, infrared device and virtual device.</p>
</li>
<li>
<p dir="auto">Does Xiaomi Home Integration support multiple Xiaomi accounts?</p>
<p dir="auto">Yes, it supports multiple Xiaomi accounts. Furthermore, Xiaomi Home Integration allows that devices belonging to different accounts can be added to a same area.</p>
</li>
<li>
<p dir="auto">Does Xiaomi Home Integration support local control?</p>
<p dir="auto">Local control is implemented by <a href="https://www.mi.com/shop/buy/detail?product_id=15755&amp;cfrom=search" rel="nofollow">Xiaomi Central Hub Gateway</a> (firmware version 3.4.0_0000 above) or Xiaomi home devices with built-in central hub gateway (software version 0.8.0 above) inside. If you do not have a Xiaomi central hub gateway or other devices having central hub gateway function, all control commands are sent through Xiaomi Cloud. The firmware for Xiaomi central hub gateway including the built-in central hub gateway supporting Home Assistant local control feature has not been released yet. Please refer to MIoT team's notification for upgrade plans.</p>
<p dir="auto">Xiaomi central hub gateway is only available in mainland China. In other regions, it is not available.</p>
<p dir="auto">Xiaomi Home Integration can also implement partial local control by enabling Xiaomi LAN control function. Xiaomi LAN control function can only control IP devices (devices connected to the router via WiFi or ethernet cable) in the same local area network as Home Assistant. It cannot control BLE Mesh, ZigBee, etc. devices. This function may cause some abnormalities. We recommend not to use this function. Xiaomi LAN control function is enabled by <a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; Configured &gt; Xiaomi Home</a> &gt; CONFIGURE &gt; Update LAN control configuration</p>
<p dir="auto">Xiaomi LAN control function is not restricted by region. It is available in all regions. However, if there is a central gateway in the local area network where Home Assistant is located, even Xiaomi LAN control function is enabled in the integration, it will not take effect.</p>
</li>
<li>
<p dir="auto">In which regions is Xiaomi Home Integration available?</p>
<p dir="auto">Xiaomi Home Integration can be used in the mainland of China, Europe, India, Russia, Singapore, and USA. As user data in Xiaomi Cloud of different regions is isolated, you need to choose your region when importing MIoT devices in the configuration process. Xiaomi Home Integration allows you to import devices of different regions to a same area.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Principle of Messaging</h2><a id="user-content-principle-of-messaging" aria-label="Permalink: Principle of Messaging" href="#principle-of-messaging"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Control through the Cloud</h3><a id="user-content-control-through-the-cloud" aria-label="Permalink: Control through the Cloud" href="#control-through-the-cloud"></a></p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/images/cloud_control.jpg"><img src="https://github.com/XiaoMi/ha_xiaomi_home/raw/main/doc/images/cloud_control.jpg" width="300"></a></p><p dir="auto">Image 1: Cloud control architecture</p>
 </div>
<p dir="auto">Xiaomi Home Integration subscribes to the interested device messages on the MQTT Broker in MIoT Cloud. When a device property changes or a device event occurs, the device sends an upstream message to MIoT Cloud, and the MQTT Broker pushes the subscribed device message to Xiaomi Home Integration. Because Xiaomi Home Integration does not need to poll to obtain the current device property value in the cloud, it can immediately receive the notification message when the properties change or the events occur. Thanks to the message subscription mechanism, Xiaomi Home Integration only queries the properties of all devices from the cloud once when the integration configuration is completed, which puts little access pressure on the cloud.</p>
<p dir="auto">Xiaomi Home Integration sends command messages to the devices via the HTTP interface of MIoT Cloud to control devices. The device reacts and responds after receiving the downstream message sent forward by MIoT Cloud.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Control locally</h3><a id="user-content-control-locally" aria-label="Permalink: Control locally" href="#control-locally"></a></p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/images/local_control.jpg"><img src="https://github.com/XiaoMi/ha_xiaomi_home/raw/main/doc/images/local_control.jpg" width="300"></a></p><p dir="auto">Image 2: Local control architecture</p>
</div>
<p dir="auto">Xiaomi central hub gateway contains a standard MQTT Broker, which implements a complete subscribe-publish mechanism. Xiaomi Home Integration subscribes to the interested device messages through Xiaomi central hub gateway. When a device property changes or a device event occurs, the device sends an upstream message to Xiaomi central hub gateway, and the MQTT Broker pushes the subscribed device message to Xiaomi Home Integration.</p>
<p dir="auto">When Xiaomi Home Integration needs to control a device, it publishes a device command message to the MQTT Broker, which is then forwarded to the device by Xiaomi central hub gateway. The device reacts and responds after receiving the downstream message from the gateway.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mapping Relationship between MIoT-Spec-V2 and Home Assistant Entity</h2><a id="user-content-mapping-relationship-between-miot-spec-v2-and-home-assistant-entity" aria-label="Permalink: Mapping Relationship between MIoT-Spec-V2 and Home Assistant Entity" href="#mapping-relationship-between-miot-spec-v2-and-home-assistant-entity"></a></p>
<p dir="auto"><a href="https://iot.mi.com/v2/new/doc/introduction/knowledge/spec" rel="nofollow">MIoT-Spec-V2</a> is the abbreviation for MIoT Specification Version 2, which is an IoT protocol formulated by Xiaomi IoT platform to give a standard functional description of IoT devices. It includes function definition (referred to as data model by other IoT platforms), interaction model, message format, and encoding.</p>
<p dir="auto">In MIoT-Spec-V2 protocol, a product is defined as a device. A device contains several services. A service may have some properties, events and actions. Xiaomi Home Integration creates Home Assistant entities according to MIoT-Spec-V2. The conversion relationship is as follows.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">General Conversion</h3><a id="user-content-general-conversion" aria-label="Permalink: General Conversion" href="#general-conversion"></a></p>
<ul dir="auto">
<li>Property</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>format</th>
<th>access</th>
<th>value-list</th>
<th>value-range</th>
<th>Entity in Home Assistant</th>
</tr>
</thead>
<tbody>
<tr>
<td>writable</td>
<td>string</td>
<td>-</td>
<td>-</td>
<td>Text</td>
</tr>
<tr>
<td>writable</td>
<td>bool</td>
<td>-</td>
<td>-</td>
<td>Switch</td>
</tr>
<tr>
<td>writable</td>
<td>not string &amp; not bool</td>
<td>existent</td>
<td>-</td>
<td>Select</td>
</tr>
<tr>
<td>writable</td>
<td>not string &amp; not bool</td>
<td>non-existent</td>
<td>existent</td>
<td>Number</td>
</tr>
<tr>
<td>not writable</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>Sensor</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li>Event</li>
</ul>
<p dir="auto">MIoT-Spec-V2 event is transformed to Event entity in Home Assistant. The event's parameters are also passed to entity's <code>_trigger_event</code>.</p>
<ul dir="auto">
<li>Action</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>in</th>
<th>Entity in Home Assistant</th>
</tr>
</thead>
<tbody>
<tr>
<td>empty</td>
<td>Button</td>
</tr>
<tr>
<td>not empty</td>
<td>Notify</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">If the debug mode for action is activated, the Text entity will be created when the "in" field in the action spec is not empty.</p>
<p dir="auto">The "Attribute" item in the entity details page displays the format of the input parameter which is an ordered list, enclosed in square brackets []. The string elements in the list are enclosed in double quotation marks "".</p>
<p dir="auto">For example, the "Attributes" item in the details page of the Notify entity converted by the "Intelligent Speaker Execute Text Directive" action of xiaomi.wifispeaker.s12 siid=5, aiid=5 instance shows the action params as <code>[Text Content(str), Silent Execution(bool)]</code>. A properly formatted input is <code>["Hello", true]</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Specific Conversion</h3><a id="user-content-specific-conversion" aria-label="Permalink: Specific Conversion" href="#specific-conversion"></a></p>
<p dir="auto">MIoT-Spec-V2 uses URN for defining types. The format is <code>urn:&lt;namespace&gt;:&lt;type&gt;:&lt;name&gt;:&lt;value&gt;[:&lt;vendor-product&gt;:&lt;version&gt;]</code>, in which <code>name</code> is a human-readable word or phrase describing the instance of device, service, property, event and action. Xiaomi Home Integration first determines whether to convert the MIoT-Spec-V2 instance into a specific Home Assistant entity based on the instance's name. For the instance that does not meet the specific conversion rules, general conversion rules are used for conversion.</p>
<p dir="auto"><code>namespace</code> is the namespace of MIoT-Spec-V2 instance. When its value is miot-spec-v2, it means that the specification is defined by Xiaomi. When its value is bluetooth-spec, it means that the specification is defined by Bluetooth Special Interest Group (SIG). When its value is not miot-spec-v2 or bluetooth-spec, it means that the specification is defined by other vendors. If MIoT-Spec-V2 <code>namespace</code> is not miot-spec-v2, a star mark <code>*</code> is added in front of the entity's name .</p>
<ul dir="auto">
<li>Device</li>
</ul>
<p dir="auto">The conversion follows <code>SPEC_DEVICE_TRANS_MAP</code>.</p>
<div data-snippet-clipboard-copy-content="{
    '<device instance name>':{
        'required':{
            '<service instance name>':{
                'required':{
                    'properties': {
                        '<property instance name>': set<property access: str>
                    },
                    'events': set<event instance name: str>,
                    'actions': set<action instance name: str>
                },
                'optional':{
                    'properties': set<property instance name: str>,
                    'events': set<event instance name: str>,
                    'actions': set<action instance name: str>
                }
            }
        },
        'optional':{
            '<service instance name>':{
                'required':{
                    'properties': {
                        '<property instance name>': set<property access: str>
                    },
                    'events': set<event instance name: str>,
                    'actions': set<action instance name: str>
                },
                'optional':{
                    'properties': set<property instance name: str>,
                    'events': set<event instance name: str>,
                    'actions': set<action instance name: str>
                }
            }
        },
        'entity': str
    }
}"><pre><code>{
    '&lt;device instance name&gt;':{
        'required':{
            '&lt;service instance name&gt;':{
                'required':{
                    'properties': {
                        '&lt;property instance name&gt;': set&lt;property access: str&gt;
                    },
                    'events': set&lt;event instance name: str&gt;,
                    'actions': set&lt;action instance name: str&gt;
                },
                'optional':{
                    'properties': set&lt;property instance name: str&gt;,
                    'events': set&lt;event instance name: str&gt;,
                    'actions': set&lt;action instance name: str&gt;
                }
            }
        },
        'optional':{
            '&lt;service instance name&gt;':{
                'required':{
                    'properties': {
                        '&lt;property instance name&gt;': set&lt;property access: str&gt;
                    },
                    'events': set&lt;event instance name: str&gt;,
                    'actions': set&lt;action instance name: str&gt;
                },
                'optional':{
                    'properties': set&lt;property instance name: str&gt;,
                    'events': set&lt;event instance name: str&gt;,
                    'actions': set&lt;action instance name: str&gt;
                }
            }
        },
        'entity': str
    }
}
</code></pre></div>
<p dir="auto">The "required" field under "device instance name" indicates the required services of the device. The "optional" field under "device instance name" indicates the optional services of the device. The "entity" field indicates the Home Assistant entity to be created. The "required" and the "optional" field under "service instance name" are required and optional properties, events and actions of the service respectively. The value of "property instance name" under "required" "properties" field is the access mode of the property. The condition for a successful match is that the value of "property instance name" is a subset of the access mode of the corresponding MIoT-Spec-V2 property instance.</p>
<p dir="auto">Home Assistant entity will not be created if MIoT-Spec-V2 device instance does not contain all required services, properties, events or actions.</p>
<ul dir="auto">
<li>Service</li>
</ul>
<p dir="auto">The conversion follows <code>SPEC_SERVICE_TRANS_MAP</code>.</p>
<div data-snippet-clipboard-copy-content="{
    '<service instance name>':{
        'required':{
            'properties': {
                '<property instance name>': set<property access: str>
            },
            'events': set<event instance name: str>,
            'actions': set<action instance name: str>
        },
        'optional':{
            'properties': set<property instance name: str>,
            'events': set<event instance name: str>,
            'actions': set<action instance name: str>
        },
        'entity': str
    }
}"><pre><code>{
    '&lt;service instance name&gt;':{
        'required':{
            'properties': {
                '&lt;property instance name&gt;': set&lt;property access: str&gt;
            },
            'events': set&lt;event instance name: str&gt;,
            'actions': set&lt;action instance name: str&gt;
        },
        'optional':{
            'properties': set&lt;property instance name: str&gt;,
            'events': set&lt;event instance name: str&gt;,
            'actions': set&lt;action instance name: str&gt;
        },
        'entity': str
    }
}
</code></pre></div>
<p dir="auto">The "required" field under "service instance name" indicates the required properties, events and actions of the service. The "optional" field indicates the optional properties, events and actions of the service. The "entity" field indicates the Home Assistant entity to be created. The value of "property instance name" under "required" "properties" field is the access mode of the property. The condition for a successful match is that the value of "property instance name" is a subset of the access mode of the corresponding MIoT-Spec-V2 property instance.</p>
<p dir="auto">Home Assistant entity will not be created if MIoT-Spec-V2 service instance does not contain all required properties, events or actions.</p>
<ul dir="auto">
<li>Property</li>
</ul>
<p dir="auto">The conversion follows <code>SPEC_PROP_TRANS_MAP</code>.</p>
<div data-snippet-clipboard-copy-content="{
    'entities':{
        '<entity name>':{
            'format': set<str>,
            'access': set<str>
        }
    },
    'properties': {
        '<property instance name>':{
            'device_class': str,
            'entity': str
        }
    }
}"><pre><code>{
    'entities':{
        '&lt;entity name&gt;':{
            'format': set&lt;str&gt;,
            'access': set&lt;str&gt;
        }
    },
    'properties': {
        '&lt;property instance name&gt;':{
            'device_class': str,
            'entity': str
        }
    }
}
</code></pre></div>
<p dir="auto">The "format" field under "entity name" represents the data format of the property, and matching with one value indicates a successful match. The "access" field under "entity name" represents the access mode of the property, and matching with all values is considered a successful match.</p>
<p dir="auto">The "entity" field under "property instance name", of which value is one of entity name under "entities" field, indicates the Home Assistant entity to be created. The "device_class" field under "property instance name" indicates the Home Assistant entity's <code>_attr_device_class</code>.</p>
<ul dir="auto">
<li>Event</li>
</ul>
<p dir="auto">The conversion follows <code>SPEC_EVENT_TRANS_MAP</code>.</p>
<div data-snippet-clipboard-copy-content="{
    '<event instance name>': str
}"><pre><code>{
    '&lt;event instance name&gt;': str
}
</code></pre></div>
<p dir="auto">The value of the event instance name indicates <code>_attr_device_class</code> of the Home Assistant entity to be created.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MIoT-Spec-V2 Filter</h3><a id="user-content-miot-spec-v2-filter" aria-label="Permalink: MIoT-Spec-V2 Filter" href="#miot-spec-v2-filter"></a></p>
<p dir="auto"><code>spec_filter.json</code> is used to filter out the MIoT-Spec-V2 instance that will not be converted to Home Assistant entity.</p>
<p dir="auto">The format of <code>spec_filter.json</code> is as follows.</p>
<div data-snippet-clipboard-copy-content="{
    &quot;<MIoT-Spec-V2 device instance>&quot;:{
        &quot;services&quot;: list<service_iid: str>,
        &quot;properties&quot;: list<service_iid.property_iid: str>,
        &quot;events&quot;: list<service_iid.event_iid: str>,
        &quot;actions&quot;: list<service_iid.action_iid: str>,
    }
}"><pre><code>{
    "&lt;MIoT-Spec-V2 device instance&gt;":{
        "services": list&lt;service_iid: str&gt;,
        "properties": list&lt;service_iid.property_iid: str&gt;,
        "events": list&lt;service_iid.event_iid: str&gt;,
        "actions": list&lt;service_iid.action_iid: str&gt;,
    }
}
</code></pre></div>
<p dir="auto">The key of <code>spec_filter.json</code> dictionary is the urn excluding the "version" field of the MIoT-Spec-V2 device instance. The firmware of different versions of the same product may be associated with the MIoT-Spec-V2 device instances of different versions. It is required that the MIoT-Spec-V2 instance of a higher version must contain all MIoT-Spec-V2 instances of the lower versions when a vendor defines the MIoT-Spec-V2 of its product on MIoT platform. Thus, the key of <code>spec_filter.json</code> does not need to specify the version number of MIoT-Spec-V2 device instance.</p>
<p dir="auto">The value of "services", "properties", "events" or "actions" fields under "device instance" is the instance id (iid) of the service, property, event or action that will be ignored in the conversion process. Wildcard matching is supported.</p>
<p dir="auto">Example:</p>
<div data-snippet-clipboard-copy-content="{
    &quot;urn:miot-spec-v2:device:television:0000A010:xiaomi-rmi1&quot;:{
        &quot;services&quot;: [&quot;*&quot;]   # Filter out all services. It is equivalent to completely ignoring the device with such MIoT-Spec-V2 device instance.
    },
    &quot;urn:miot-spec-v2:device:gateway:0000A019:xiaomi-hub1&quot;: {
        &quot;services&quot;: [&quot;3&quot;],  # Filter out the service whose iid=3.
        &quot;properties&quot;: [&quot;4.*&quot;]   # Filter out all properties in the service whose iid=4.
        &quot;events&quot;: [&quot;4.1&quot;],  # Filter out the iid=1 event in the iid=4 service.
        &quot;actions&quot;: [&quot;4.1&quot;]  # Filter out the iid=1 action in the iid=4 service.
    }
}"><pre><code>{
    "urn:miot-spec-v2:device:television:0000A010:xiaomi-rmi1":{
        "services": ["*"]   # Filter out all services. It is equivalent to completely ignoring the device with such MIoT-Spec-V2 device instance.
    },
    "urn:miot-spec-v2:device:gateway:0000A019:xiaomi-hub1": {
        "services": ["3"],  # Filter out the service whose iid=3.
        "properties": ["4.*"]   # Filter out all properties in the service whose iid=4.
        "events": ["4.1"],  # Filter out the iid=1 event in the iid=4 service.
        "actions": ["4.1"]  # Filter out the iid=1 action in the iid=4 service.
    }
}
</code></pre></div>
<p dir="auto">Device information service (urn:miot-spec-v2:service:device-information:00007801) of all devices will never be converted to Home Assistant entity.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Multiple Language Support</h2><a id="user-content-multiple-language-support" aria-label="Permalink: Multiple Language Support" href="#multiple-language-support"></a></p>
<p dir="auto">There are 8 languages available for selection in the config flow language option of Xiaomi Home, including Simplified Chinese, Traditional Chinese, English, Spanish, Russian, French, German, and Japanese. The config flow page in Simplified Chinese and English has been manually reviewed by the developer. Other languages are translated by machine translation. If you want to modify the words and sentences in the config flow page, you need to modify the json file of the certain language in <code>custom_components/xiaomi_home/translations/</code> directory.</p>
<p dir="auto">When displaying Home Assistant entity name, Xiaomi Home downloads the multiple language file configured by the device vendor from MIoT Cloud, which contains translations for MIoT-Spec-V2 instances of the device. <code>multi_lang.json</code> is a locally maintained multiple language dictionary, which has a higher priority than the multiple language file obtained from the cloud and can be used to supplement or modify the multiple language translation of devices.</p>
<p dir="auto">The format of <code>multi_lang.json</code> is as follows.</p>
<div data-snippet-clipboard-copy-content="{
    &quot;<MIoT-Spec-V2 device instance>&quot;: {
        &quot;<language code>&quot;: {
            &quot;<instance code>&quot;: <translation: str>
        }
    }
}"><pre><code>{
    "&lt;MIoT-Spec-V2 device instance&gt;": {
        "&lt;language code&gt;": {
            "&lt;instance code&gt;": &lt;translation: str&gt;
        }
    }
}
</code></pre></div>
<p dir="auto">The key of <code>multi_lang.json</code> dictionary is the urn excluding the "version" field of the MIoT-Spec-V2 device instance.</p>
<p dir="auto">The language code is zh-Hans, zh-Hant, en, es, ru, fr, de, or ja, corresponding to the 8 selectable languages mentioned above.</p>
<p dir="auto">The instance code is the code of the MIoT-Spec-V2 instance, which is in the format of:</p>
<div data-snippet-clipboard-copy-content="service:<siid>                  # service
service:<siid>:property:<piid>  # property
service:<siid>:property:<piid>:valuelist:<value> # the value in value-list of a property
service:<siid>:event:<eiid>     # event
service:<siid>:action:<aiid>    # action"><pre><code>service:&lt;siid&gt;                  # service
service:&lt;siid&gt;:property:&lt;piid&gt;  # property
service:&lt;siid&gt;:property:&lt;piid&gt;:valuelist:&lt;value&gt; # the value in value-list of a property
service:&lt;siid&gt;:event:&lt;eiid&gt;     # event
service:&lt;siid&gt;:action:&lt;aiid&gt;    # action
</code></pre></div>
<p dir="auto">siid, piid, eiid, aiid and value are all decimal three-digit integers.</p>
<p dir="auto">Example:</p>
<div data-snippet-clipboard-copy-content="{
    &quot;urn:miot-spec-v2:device:health-pot:0000A051:chunmi-a1&quot;: {
        &quot;zh-Hant&quot;: {
            &quot;service:002&quot;: &quot;養生壺&quot;,
            &quot;service:002:property:001&quot;: &quot;工作狀態&quot;,
            &quot;service:002:property:001:valuelist:000&quot;: &quot;待機中&quot;,
            &quot;service:002:action:002&quot;: &quot;停止烹飪&quot;,
            &quot;service:005:event:001&quot;: &quot;烹飪完成&quot;
        }
    }
}"><pre><code>{
    "urn:miot-spec-v2:device:health-pot:0000A051:chunmi-a1": {
        "zh-Hant": {
            "service:002": "養生壺",
            "service:002:property:001": "工作狀態",
            "service:002:property:001:valuelist:000": "待機中",
            "service:002:action:002": "停止烹飪",
            "service:005:event:001": "烹飪完成"
        }
    }
}
</code></pre></div>
<blockquote>
<p dir="auto">If you edit <code>specv2entity.py</code>, <code>spec_filter.json</code> or <code>multi_lang.json</code> in the <code>custom_components/xiaomi_home/miot/specs</code> directory in your Home Assistant, you need to update the entity conversion rule in the integration's CONFIGURE page to take effect. Method: <a href="https://my.home-assistant.io/redirect/integration/?domain=xiaomi_home" rel="nofollow">Settings &gt; Devices &amp; services &gt; Configured &gt; Xiaomi Home</a> &gt; CONFIGURE &gt; Update Entity Conversion Rule</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documents</h2><a id="user-content-documents" aria-label="Permalink: Documents" href="#documents"></a></p>
<ul dir="auto">
<li><a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/LICENSE.md">License</a></li>
<li>Contribution Guidelines: <a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/CONTRIBUTING.md">English</a> | <a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/CONTRIBUTING_zh.md">简体中文</a></li>
<li><a href="https://github.com/XiaoMi/ha_xiaomi_home/blob/main/doc/CHANGELOG.md">ChangeLog</a></li>
<li>Development Documents: <a href="https://developers.home-assistant.io/docs/creating_component_index" rel="nofollow">https://developers.home-assistant.io/docs/creating_component_index</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Directory Structure</h2><a id="user-content-directory-structure" aria-label="Permalink: Directory Structure" href="#directory-structure"></a></p>
<ul dir="auto">
<li>miot: core code.</li>
<li>miot/miot_client: Adding a login user in the integration needs adding a miot_client instance.</li>
<li>miot/miot_cloud: Contains functions related to the cloud service, including OAuth login process, HTTP interface functions (to get the user information, to send the device control command, etc.)</li>
<li>miot/miot_device: Device entity, including device information, processing logic of property, event and action.</li>
<li>miot/miot_mips: Message bus for subscribing and publishing method.</li>
<li>miot/miot_spec: Parse MIoT-Spec-V2.</li>
<li>miot/miot_lan: Device LAN control, including device discovery, device control, etc.</li>
<li>miot/miot_mdns: Central hub gateway service LAN discovery.</li>
<li>miot/miot_network: Obtain network status and network information.</li>
<li>miot/miot_storage: File storage for the integration.</li>
<li>miot/test: Test scripts.</li>
<li>config_flow: Config flow.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Guile for Emacs (151 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1001645/b1e4453a8c6c16d7/</link>
            <guid>42432004</guid>
            <pubDate>Mon, 16 Dec 2024 15:37:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1001645/b1e4453a8c6c16d7/">https://lwn.net/SubscriberLink/1001645/b1e4453a8c6c16d7/</a>, See on <a href="https://news.ycombinator.com/item?id=42432004">Hacker News</a></p>
Couldn't get https://lwn.net/SubscriberLink/1001645/b1e4453a8c6c16d7/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Modelica (256 pts)]]></title>
            <link>https://modelica.org/</link>
            <guid>42431186</guid>
            <pubDate>Mon, 16 Dec 2024 14:22:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modelica.org/">https://modelica.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42431186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      
      <p><a href="https://modelica.org/news/2024-11-18-fall-ma-newsletter/">
        <span>
          Fall Modelica Association Newsletter published
          <i></i>
        </span>
      </a></p>
  
      
  
      <p>
        Modelica is an object oriented language to model cyber-physical systems. 
        It supports acausal connection of reusable components governed by mathematical equations to facilitate modeling from first principles.
      </p>

      <div>
          <p><a href="https://modelica.org/language/"><i></i>Modelica Language</a>
          <a href="https://modelica.org/libraries/"><i></i>Modelica Libraries</a>
          <a href="https://modelica.org/tools/"><i></i>Modelica Tools</a>
          <a href="https://modelica.org/association/"><i></i>Modelica Association</a>
      </p></div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: SWEs how do you future-proof your career in light of LLMs? (401 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42431103</link>
            <guid>42431103</guid>
            <pubDate>Mon, 16 Dec 2024 14:11:19 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42431103">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42431103: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Most iPhone owners see little to no value in Apple Intelligence so far (317 pts)]]></title>
            <link>https://9to5mac.com/2024/12/16/most-iphone-owners-see-little-to-no-value-in-apple-intelligence-so-far/</link>
            <guid>42431090</guid>
            <pubDate>Mon, 16 Dec 2024 14:10:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2024/12/16/most-iphone-owners-see-little-to-no-value-in-apple-intelligence-so-far/">https://9to5mac.com/2024/12/16/most-iphone-owners-see-little-to-no-value-in-apple-intelligence-so-far/</a>, See on <a href="https://news.ycombinator.com/item?id=42431090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1500" height="750" src="https://9to5mac.com/wp-content/uploads/sites/6/2024/12/Most-iPhone-owners-see-little-to-no-value-in-Apple-Intelligence-so-far.webp?w=1500" alt="Most iPhone owners see little to no value in Apple Intelligence so far | AI icons seen on Mac, iPad, and iPhone" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/12/Most-iPhone-owners-see-little-to-no-value-in-Apple-Intelligence-so-far.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/12/Most-iPhone-owners-see-little-to-no-value-in-Apple-Intelligence-so-far.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/12/Most-iPhone-owners-see-little-to-no-value-in-Apple-Intelligence-so-far.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/12/Most-iPhone-owners-see-little-to-no-value-in-Apple-Intelligence-so-far.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>A new survey suggests that <a href="https://9to5mac.com/guides/apple-intelligence/" target="_blank" rel="noreferrer noopener">Apple Intelligence</a> matters to <a href="https://9to5mac.com/guides/iphone-16/" target="_blank" rel="noreferrer noopener">iPhone</a> buyers, but the majority say that the initial features add little to no value. It remains to be seen whether Genmoji and ChatGPT integration will change that view.</p>



<p>Things are even worse for Samsung smartphones, with an even greater majority of owners saying they can’t see much point in the AI features offered … </p>



<h2 id="h-iphone-owners-do-care-about-ai">iPhone owners do care about AI</h2>



<p><a href="https://www.sellcell.com/blog/iphone-vs-samsung-ai-survey/" target="_blank" rel="noreferrer noopener">A new survey</a> by tech trade-in site SellCell found that AI is an important factor when choosing a new smartphone.</p>



<blockquote>
<p>iPhone users showed relatively higher interest in mobile AI than Samsung users as almost half (47.6%) of iPhone users reported AI features as a ‘very’ or ‘somewhat’ important deciding factor when buying a new phone vs. 23.7% of Samsung users who said the same.</p>
</blockquote>



<h2 id="h-but-what-they-ve-seen-so-far-doesn-t-impress">But what they’ve seen so far doesn’t impress</h2>



<p>But while iPhone users want AI features, the Apple Intelligence ones seen to date don’t seem to impress them.</p>



<blockquote>
<p>Smartphone users in general are unsatisfied with the existing AI features as the survey recorded 73% of Apple Intelligence users and 87% of Galaxy AI users stating the new features to be either ‘not very valuable’ or they ‘add little to no value’ to their smartphone experience.</p>
</blockquote>



<p>The site also ranked the popularity of different Apple Intelligence features available prior to the launch of iOS 18.2:</p>



<ul>
<li>Writing Tools (72%)</li>



<li>Notification summaries (54%)</li>



<li>Priority Messages (44.5%)</li>



<li>Clean Up in Photos (29.1%)</li>



<li>Smart Reply in Mail and Messages (20.9%)</li>
</ul>



<h2 id="h-perhaps-genmoji-and-chatgpt-will-change-that">Perhaps Genmoji and ChatGPT will change that</h2>



<p>The survey was carried out before the launch of iOS 18.2, which <a href="https://9to5mac.com/2024/12/11/genmoji-are-here-in-ios-182/" target="_blank" rel="noreferrer noopener">added Genmoji</a> and <a href="https://9to5mac.com/chatgpt-in-ios-18-2-heres-what-apple-intelligence-has-coming-next/" target="_blank" rel="noreferrer noopener">ChatGPT integration</a>.</p>



<blockquote>
<p>Genmoji is a play on two phrases: ‘emoji’ and ‘AI-generated.’ Simply put, in iOS 18.2 you can use Apple Intelligence to create new emoji in an instant.</p>



<p>Open the emoji keyboard on your iPhone running iOS 18.2, and you’ll see a new glowing smiley icon in the top-right corner.&nbsp;Tap that icon, then describe the emoji you’d like created—and that’s it! […]</p>



<p>Apple demoed its ChatGPT integration as something secondary to Siri’s knowledge, with certain questions answered by Siri and others by ChatGPT. But in iOS 18.2 you can start your Siri request with “Ask ChatGPT” and the assistant will automatically send the query straight to ChatGPT.</p>
</blockquote>



<p><em>Image: Apple and Michael Bower/9to5Mac</em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4eWBGsp"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2024/12/XGIMI-750-150.jpg?quality=82&amp;strip=all" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coder wrote a bug so bad security guards wanted a word when he arrived at work (126 pts)]]></title>
            <link>https://www.theregister.com/2024/12/16/who_me/</link>
            <guid>42431046</guid>
            <pubDate>Mon, 16 Dec 2024 14:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/12/16/who_me/">https://www.theregister.com/2024/12/16/who_me/</a>, See on <a href="https://news.ycombinator.com/item?id=42431046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Who, Me?</span> Welcome once again to Who, Me? The Register's Monday morning feature in which we share tales of technological messes your fellow readers made, and escaped, to give you hope in case you err during the coming week.</p>
<p>This week's hero we'll Regomize as "Trey" because back in the first decade of this millennium he was working for one of the many startup telcos trying to cash in on 3G. (Sadly, he tells Who, Me? it was not one of the ones that succeeded.)</p>
<p>Trey worked on the platforms and services team, which created and maintained apps for internal users and customers. Among his responsibilities was working with external service providers, such as a payment provider, an identity services outfit, and bulk SMS handler.</p>

    

<p>One day, Trey noticed the payments gateway misbehaving, so he wrote a piece of software that sent it a test transaction, checked it had worked, then repeated the process five minutes later.</p>

        


        

<p>Another experiment saw him write a demo app that automated payments, using SMS as prompts.</p>
<p>The app had its own syntax for commands. In theory, the message “Credit 5” would send that sum to an account, and so on.</p>

        

<p>Trey showed the automated payments applications to the head of his department, who was well pleased – so pleased he asked for it to be deployed immediately.</p>
<p>Oh yeah, immediate deployment. That never goes wrong, right?</p>
<ul>

<li><a href="https://www.theregister.com/2024/12/09/who_me/">Panic at the Cisco tech, thanks to ancient IOS syntax helper that outsmarted itself</a></li>

<li><a href="https://www.theregister.com/2024/12/02/who_me/">NetAdmin learns that wooden chocks, unlike swipe cards, open doors when networks can't</a></li>

<li><a href="https://www.theregister.com/2024/11/25/who_me/">Network engineer chose humiliation over a night on the datacenter floor</a></li>

<li><a href="https://www.theregister.com/2024/11/18/who_me/">Undergrad thought he had mastered Unix in weeks. Then he discovered rm -rf</a></li>
</ul>
<p>Wrong. It turns out Trey's little demo had exactly three bugs in it that had not been spotted in his limited testing.</p>
<p>The first bug was in the value of the test transactions. The value had to be a whole number, followed by a modifier.</p>
<p>His intention was that the whole number would be 1 and the modifier -2, a combo that would generate a test transaction of $0.01. But the exponent had accidentally been set to 2 – so each transaction was worth $100. Not an insignificant difference.</p>

        

<p>The second bug was the lack of a liveness check. If one of the gateways failed, the program wouldn't sleep for five minutes but would simply attempt the transaction again immediately.</p>
<p>The third bug – which Trey did in fact know about but had made a mental note to fix later – was that the choice of credit or debit on the test transactions was supposed to be random, but for some reason always came up credit. He figured it wouldn't be that big of an issue, given the transactions were only supposed to be $0.01 every five minutes, right?</p>
<p>You can easily see where this is headed. As he ran the program overnight, one of the gateways failed. Trey's little proof of concept demo program then began crediting his test account with $100 pretty much constantly for the next few hours.</p>
<p>When he arrived at work the next morning, there were some very serious faces – including a security team – waiting to greet him and find out what sort of fraud he thought he was trying to pull. The account had amassed a considerable fortune by that stage.</p>
<p>Thankfully the head of department, who had authorized the deployment, came to Trey's rescue and explained the situation. Tragically, though, the balance of the test account was reset to zero.</p>
<p>Ever had a programming error make a fortune appear – or disappear – like magic? <a target="_blank" href="mailto:whome@theregister.com">Tell us all about it in an email to Who, Me?</a> and we may share your adventure on some future Monday morning. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is it so hard to buy things that work well? (586 pts)]]></title>
            <link>https://danluu.com/nothing-works/</link>
            <guid>42430450</guid>
            <pubDate>Mon, 16 Dec 2024 12:38:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danluu.com/nothing-works/">https://danluu.com/nothing-works/</a>, See on <a href="https://news.ycombinator.com/item?id=42430450">Hacker News</a></p>
Couldn't get https://danluu.com/nothing-works/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA["Nvidia is so far ahead that all the 4090s are nerfed to half speed" (187 pts)]]></title>
            <link>https://twitter.com/realGeorgeHotz/status/1868356459542770087</link>
            <guid>42430184</guid>
            <pubDate>Mon, 16 Dec 2024 11:45:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/realGeorgeHotz/status/1868356459542770087">https://twitter.com/realGeorgeHotz/status/1868356459542770087</a>, See on <a href="https://news.ycombinator.com/item?id=42430184">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>