<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 03 Dec 2025 06:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Kohler Can Access Pictures from "End-to-End Encrypted" Toilet Camera (125 pts)]]></title>
            <link>https://varlogsimon.leaflet.pub/3m6zrw6k2bs2p?interactionDrawer=quotes</link>
            <guid>46129476</guid>
            <pubDate>Wed, 03 Dec 2025 02:06:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varlogsimon.leaflet.pub/3m6zrw6k2bs2p?interactionDrawer=quotes">https://varlogsimon.leaflet.pub/3m6zrw6k2bs2p?interactionDrawer=quotes</a>, See on <a href="https://news.ycombinator.com/item?id=46129476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="0" data-index="0"><span>In October Kohler launched </span><a href="https://www.kohlerhealth.com/dekoda/" target="_blank">Dekota</a><span>, a $600-plus-monthly-subscription device that attaches to the rim of your toilet and collects images and data from inside, promising to track and provide insights on gut health, hydration, and more. To allay the obvious privacy concerns, the company emphasizes the sensors are only pointed down, into the bowl, and assures potential buyers that the data collected by the device and app are protected with "end-to-end encryption”.</span></p><p><img height="210" width="445" src="https://varlogsimon.leaflet.pub/api/atproto_images?did=did:plc:2rltjvii4o7fjtsb6kfe4qe6&amp;cid=bafkreihgb7sosbpyorzc7vixcngmxnwc6w43yj2ix5fynlbkeeyguwddtu"></p><p id="2" data-index="2"><span>Kohler Health’s </span><a href="https://www.kohlerhealth.com/" target="_blank">homepage</a><span>, the page for the </span><a href="https://www.kohlerhealth.com/kohler-health-app/" target="_blank">Kohler Health App</a><span>, and a </span><a href="https://www.kohlerhealth.com/support/privacy/how-kohler-health-keeps-my-data-private/" target="_blank">support page</a><span> all use the term “end-to-end encryption” to describe the protection the app provides for data. </span><a href="https://www.cnet.com/health/medical/kohlers-tiny-toilet-camera-analyzes-the-contents-and-reports-back-to-you/" target="_blank">Many</a><span> </span><a href="https://www.theverge.com/news/802727/kohler-health-dekoda-toilet-camera-optical-sensors" target="_blank">media</a><span> </span><a href="https://techcrunch.com/2025/10/19/kohler-unveils-a-camera-for-your-toilet/" target="_blank">outlets</a><span> included the claim in their articles covering the launch of the product.</span></p><p id="3" data-index="3"><span>However, responses from the company make it clear that—contrary to common understanding of the term—Kohler is able to access data collected by the device and associated application. Additionally, the company states that the data collected by the device and app may be used to train AI models.</span></p><h3 id="4" data-index="4"><span>What is End-to-End Encryption?</span></h3><p id="5" data-index="5"><span>"End-to-end encryption", or E2EE, is a method of securing data that ensures only the sender and their chosen recipient are able to view it. Correctly implemented, it prevents other parties, including the developer of the application, from accessing the protected data. E2EE is best known for its use in messaging applications like WhatsApp, iMessage, and Signal, where it allows users to communicate securely and privately without worrying about their messages being seen by prying eyes at the app developers, internet service providers, and even governments.</span></p><p id="6" data-index="6"><span>E2EE also provides an additional layer of protection if the servers of the application developer are compromised by an attacker. Any data stored on those servers will be meaningless to the attacker, which can significantly reduce the impact of a breach. For a more detailed look at E2EE, see </span><a href="https://ssd.eff.org/module/deep-dive-end-end-encryption-how-do-public-key-encryption-systems-work" target="_blank">A Deep Dive on End-to-End Encryption</a><span> from the Electronic Frontier Foundation.</span></p><h3 id="7" data-index="7"><span>What is Kohler Doing?</span></h3><p id="8" data-index="8"><span>The initial issue with Kohler using the term “end-to-end encryption” is that it’s not obvious how it could apply to their product. The term is generally used for applications that allow some kind of communication between users, and Kohler Health doesn’t have any user-to-user sharing features. So while one “end” would be the user, it’s not clear what the other end would be.</span></p><p id="9" data-index="9"><span>I thought Kohler might actually have implemented a related data protection method known as “client-side encryption”, used by services like Apple’s iCloud and the password manager 1Password. This technique allows an application to back up a user’s data to the developers servers, or synchronize data between multiple devices owned by a user, without allowing anyone but the user to access the data.</span></p><p id="10" data-index="10"><span>But emails exchanged with Kohler’s privacy contact clarified that the other “end” that can decrypt the data is Kohler themselves: “User data is encrypted at rest, when it’s stored on the user's mobile phone, toilet attachment, and on our systems.&nbsp; Data in transit is also encrypted end-to-end, as it travels between the user's devices and our systems, where it is decrypted and processed to provide our service.”</span></p><p id="11" data-index="11"><span>They additionally told me “We have designed our systems and processes to protect identifiable images from access by Kohler Health employees through a combination of data encryption, technical safeguards, and governance controls.”</span></p><p id="12" data-index="12"><span>What Kohler is referring to as E2EE here is simply HTTPS encryption between the app and the server, something that has been basic security practice for two decades now, plus encryption at rest.</span></p><h3 id="13" data-index="13"><span>How is Kohler Using the Data?</span></h3><p id="14" data-index="14"><span>If Kohler can access the data stored on its servers, what are they doing with it? While I don’t have a precise answer, there are indications they’re using it for purposes beyond simply providing a service to the user. This may include training AI models.&nbsp;</span></p><p id="15" data-index="15"><span>In response to my question about their use of E2EE, Kohler told me “our algorithms are trained on de-identified data only.” When signing up for an account on the app, the user is prompted to allow Kolher to use the data to "research, develop, and improve its products and technology, and to de-identify [the user’s] data for lawful purposes.”</span></p><p><img height="375" width="995" src="https://varlogsimon.leaflet.pub/api/atproto_images?did=did:plc:2rltjvii4o7fjtsb6kfe4qe6&amp;cid=bafkreifdn5v3tclg7qm74fm7ce2lt3oiwtfcg6kvctsl6lm5tumx2lypxi"></p><p id="17" data-index="17"><span>And the </span><a href="https://www.kohlerhealth.com/privacy-policy/" target="_blank">privacy policy</a><span> states data may be used “To create aggregated, de-identified and/or anonymized data, which we may use and share with third parties for our lawful business purposes, including to analyze and improve the Kohler Health Platform and our other products and services, to promote our business, and to train our AI and machine learning models.”</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf 2025 (156 pts)]]></title>
            <link>https://emacsconf.org/2025/</link>
            <guid>46127143</guid>
            <pubDate>Tue, 02 Dec 2025 21:31:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://emacsconf.org/2025/">https://emacsconf.org/2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46127143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pagebody" role="main" class="page">


<p>EmacsConf 2025 | Online Conference<br>
<b>December 6 and 7, 2025 (Sat-Sun)</b></p>




<p><a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a></p>




<p><strong><a href="https://emacsconf.org/2025/talks/">Talks</a> | <a href="https://emacsconf.org/2025/watch/">Watch</a></strong> | <a href="https://emacsconf.org/conduct/">Guidelines for Conduct</a></p>




<p>EmacsConf is the conference about the joy of
<a href="https://www.gnu.org/software/emacs/">GNU Emacs</a> and
Emacs Lisp.</p>


<p>We are busy putting things together for EmacsConf 2025, and we would
love to have <em>your</em> help to make EmacsConf 2025 amazing, much like the
previous EmacsConfs. <a href="https://emacsconf.org/volunteer/">Get involved</a> and help spread the word!</p>

<p>We are holding EmacsConf 2025 as an online conference again this year.
We remain fully committed to freedom, and we will continue using our
infrastructure and streaming setup consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free
software</a>, much like previous EmacsConf conferences.</p>

<p>For general EmacsConf discussions, join the
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a>
mailing list.  For discussions related to organizing EmacsConf, join
the
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-org">emacsconf-org</a>
mailing list.  You can email us publicly at
<a href="mailto:emacsconf-org@gnu.org">emacsconf-org@gnu.org</a> or privately at
<a href="mailto:emacsconf-org-private@gnu.org">emacsconf-org-private@gnu.org</a>.</p>

<p>Come hang out with us in the <code>#emacsconf</code> channel on <code>irc.libera.chat</code>
(<a href="https://libera.chat/">Libera.Chat</a> IRC network).  You can join the chat using
<a href="ircs://irc.libera.chat:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paged Out (332 pts)]]></title>
            <link>https://pagedout.institute</link>
            <guid>46126217</guid>
            <pubDate>Tue, 02 Dec 2025 20:14:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pagedout.institute">https://pagedout.institute</a>, See on <a href="https://news.ycombinator.com/item?id=46126217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h3>What is Paged Out!?</h3>
        <p><b>Paged Out! is a free experimental (one article == one page) technical magazine</b> about programming
            (especially programming tricks!), <a href="https://en.wikipedia.org/wiki/Hacker">hacking</a>, <a href="https://en.wikipedia.org/wiki/Security_hacker">security hacking</a>, retro computers, modern
            computers, electronics, demoscene, and other similar topics.</p>
        <p>It's <b>made by the community for the community</b>. And it's not-for-profit (though in time, we hope it will be self-sustained) - this means that the issues will always be free to download, share, and print. If you're interested in more details, check our our <a href="https://pagedout.institute/?page=faq.php">FAQ</a> and <a href="https://pagedout.institute/?page=about.php">About</a> pages!</p>

        <h4>Printed Issues</h4>

        <p><img src="https://pagedout.institute/static/img/printed-issues.jpg"></p>

        <p>You can get printed issues <a href="https://pagedout.institute/?page=event-prints.php">at events</a> and <a href="https://www.lulu.com/spotlight/pagedout">print-on-demand bookstores</a>. You'll find more info <a href="https://pagedout.institute/?page=prints.php">here</a>.</p>

        <h4>Download Issues</h4>

        <div>
            <p><a href="https://pagedout.institute/download/PagedOut_007.pdf"><img src="https://pagedout.institute/static/img/issue_7_cover_small.png" alt="Cover image of Paged Out! issue 7 depicting three astronauts working on a technical looking building-size structure on what appears to be either a very large space station or a base on a planet with no atmosphere. On top left there is the magazine's logo - an icon of an old computer and text saying Paged Out! in capital letters."></a><br>
                Cover art by Amir Zand<br>(<a href="https://www.amirzand.art/" target="_blank">WWW</a>, <a href="https://www.instagram.com/amirzandartist/" target="_blank">Insta</a>).
            </p>
            <div>
                <p><b>Issue #7</b> (Oct'25): Best kind of readme<br>
                    <small>Download counter: 157716<br>
                    Print counter: 1016 (updated manually)</small></p>

                
                <p><b>Prints</b>:</p>
                <ul>
                    <li>Want to print or get a printed Paged Out? Check out the <a href="https://pagedout.institute/?page=prints.php">Prints</a> tab for options!</li>
                    <li><a href="https://www.lulu.com/search?page=1&amp;pageSize=4&amp;sortBy=PRICE_ASC&amp;q=PAGEDOUT7">Buy at lulu.com's bookstore</a> – available editions:
                        </li>

                </ul>
            </div>
        </div>

        <div>
                <p><b>Issue #6</b> (Mar'25): Stay a while and read<br>
                    <small>Download counter: 140607<br>
                    Print counter: 2702 (updated manually)</small></p>

                
                <p><b>Prints</b>:</p>
                <ul>
                    <li>Want to print or get a printed Paged Out? Check out the <a href="https://pagedout.institute/?page=prints.php">Prints</a> tab for options!</li>
                    <li><a href="https://www.lulu.com/search?page=1&amp;pageSize=4&amp;sortBy=PRICE_ASC&amp;q=PAGEDOUT6">Buy at lulu.com's bookstore</a> – available editions:
                        </li>

                </ul>
            </div>

        <div>
                <p><b>Issue #5</b> (Nov'24): All your page are belong to us<br>
                    <small>Download counter: 105093<!--<br>
                    Print counter: 2600 (updated manually)--></small></p>
                
                <p><b>What's missing</b>:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed) - we're pretty close, but not yet there.</li>
                </ul>
            </div>


        <div>
                <p><b>Issue #4</b> (Jun'24): The epic Paged Out! story continues<br>
                    <small>Download counter: 116749<!--<br>
                    Print counter: 2600 (updated manually)--></small></p>
                
                <p><b>Note</b>: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed) - we still need to fix the pipeline around this; will come out later</li>
                </ul>
            </div>

        <div>
                <p><b>Issue #3</b> (Dec'23): The resurrected Paged Out!<br>
                    <small>Download counter: 122485<!--<br>
                    Print counter: 2600 (updated manually)--></small></p>
                
                <p><b>Note</b>: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed) - we still need to fix the pipeline around this; will come out later</li>
                </ul>
            </div>


        <div>
            <p><a href="https://pagedout.institute/download/PagedOut_002_beta2.pdf"><img src="https://pagedout.institute/static/img/issue_2_cover_small.png" alt="Cover image of Paged Out! issue 2 depicting a cyborg skull with violet-glowing electronic parts and blue-glowing eyes, with a lot of wires going out of - or into - the skull from the blackness of the background. In the top left corner, there is the magazine's logo - an icon of an old computer and text saying Paged Out! in capital letters."></a><br>
                Cover art by Vlad Gradobyk (<a href="https://instagram.com/vladgradobyk" target="_blank">Insta</a>, <a href="https://facebook.com/gradobyk.graphic" target="_blank">FB</a>).<br>
            </p>
            <div>
                <p><b>Issue #2</b> (Nov'19): The second Paged Out!<br>
                    <small>Download counter: 127333<!--<br>
                    Print counter: 2600 (updated manually)--></small></p>
                
                <p><b>Note</b>: This is a "beta 2 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed, ?US Letter+bleed?) - we need to fix something, but it's almost
                        there.
                    </li>
                </ul>
            </div>
        </div>

        <div>
                <p><b>Issue #1</b> (Aug'19): The first Paged Out! issue has arrived!<br>
                    <small>Download counter: 260155<br>
                    Print counter: 500 (updated manually)</small></p>
                
                <p><b>Note</b>: This is a "beta 1 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed, ?US Letter+bleed?) - we need to fix something, but it's almost
                        there.
                    </li>
                </ul>
            </div>

        <p>Additionally, here's another Paged Out! wallpaper by <a href="https://www.deviantart.com/refiend" target="_blank">ReFiend</a>:</p>
                <p><a href="https://pagedout.institute/download/PagedOut_RC_wallpaper.jpg"><img src="https://pagedout.institute/static/img/t_PagedOut_RC_wallpaper.jpg" alt="Wallpaper miniature"></a></p>

        <h4>Next issue</h4>
        <p>If you like our work, <b><a href="https://pagedout.institute/?page=cfp.php">how about writing an article for Paged Out!</a>?</b> It's
            only one page after all - easy. ;)</p>
        <p>
            <b>Next issue progress tracker</b> (unit of measurement: article count):<br>
        </p>
        <div id="article-counters">
                <p>Ready (1)</p>
                <p>In review (16)</p>
                <p>50</p>
                <p>100</p>
                <p><span>("we got enough to finalize the issue!" zone)</span>
                </p>
            </div>
        <br>



        <h4>Notify me when the new issue is out!</h4>
        <p>Sure! There are a couple of ways to get notified when the issue will be out:</p>
        <ul>
            <li>You can subscribe to this newsletter <b>e-mail</b> group: <a href="https://groups.google.com/forum/#!forum/pagedout-notifications">pagedout-notifications
                (googlegroups.com)</a> (be sure to select you want e-mail notifications about every message when
                subscribing).
            </li>
            <li>Or you can use the <b>RSS</b> / <b>Atom</b>:
               <a href="https://pagedout.institute/rss.xml">RSS</a>,
               <a href="https://pagedout.institute/atom.xml">Atom</a>.
            </li>
        </ul>
        <p>We will only send e-mails to this group about new Paged Out! issues (both the free electronic ones and
            special issues
            if we ever get to that). No spam will be sent there and (if you subscribe to the group) your e-mail will be
            visible
            only to group owners.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free static site generator for small restaurants and cafes (112 pts)]]></title>
            <link>https://lite.localcafe.org/</link>
            <guid>46126141</guid>
            <pubDate>Tue, 02 Dec 2025 20:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lite.localcafe.org/">https://lite.localcafe.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46126141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h2>
Disclaimer</h2>
<p>
This is not a real restaurant,</p>
<h2>
About US</h2>
<p>
Pasta boy’s started in ma’s kitchen after a plate of ma’s spaggite in old town meatball. 20 years later they are still slerping noddles.</p>
<h2>
Orders to GO</h2>
<p>
We do orders to go, call us and place an order for pick up</p>
<h2>
This was an example of using localcafe lite</h2>
<p>
You can use localcafe lite for free and also host static restaurant menu sites for free using github pages.</p>
<p>
Learn more about this project at <a href="https://github.com/Local-Cafe/localcafe-lite">https://github.com/Local-Cafe/localcafe-lite</a></p>
<h3>
Free / No Monthly Fees</h3>
<ul>
  <li>
This project is open source and free  </li>
  <li>
This project can host for free on GitHub Pages, Netlify, or Cloudflare Pages  </li>
</ul>
<h3>
Static Website</h3>
<ul>
  <li>
Fast page loads - everything pre-generated  </li>
  <li>
No database or server required  </li>
</ul>
<h3>
Online Menu</h3>
<ul>
  <li>
Display your full menu with photos, descriptions, and prices  </li>
  <li>
Single prices or multiple options (small/large, hot/iced, etc.)  </li>
  <li>
Customers filter by tags (vegetarian, gluten-free, breakfast, lunch)  </li>
  <li>
Update by editing simple text files  </li>
</ul>
<h3>
Location &amp; Maps</h3>
<ul>
  <li>
Show one location or multiple locations  </li>
  <li>
Automatic maps - just provide your address  </li>
  <li>
Each location has its own hours, phone, and email  </li>
  <li>
Maps adjust to any screen size  </li>
</ul>
<h3>
Photo Slideshow</h3>
<ul>
  <li>
Homepage displays rotating photos with smooth transitions  </li>
  <li>
Supports single image or multiple images  </li>
  <li>
Photos fade between each other automatically  </li>
</ul>
<h3>
Mobile Responsive</h3>
<ul>
  <li>
Works on all phones and tablets  </li>
  <li>
Menu and navigation adapt to screen size  </li>
  <li>
No pinching or zooming required  </li>
</ul>
<h3>
Social Sharing</h3>
<ul>
  <li>
Links shared on Facebook, Twitter, Instagram show rich previews  </li>
  <li>
Displays your photo and description automatically  </li>
</ul>
<p>
<strong> Images in example provided by <a href="https://pixabay.com/">https://pixabay.com/</a> </strong></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude 4.5 Opus' Soul Document (300 pts)]]></title>
            <link>https://simonwillison.net/2025/Dec/2/claude-soul-document/</link>
            <guid>46125184</guid>
            <pubDate>Tue, 02 Dec 2025 19:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Dec/2/claude-soul-document/">https://simonwillison.net/2025/Dec/2/claude-soul-document/</a>, See on <a href="https://news.ycombinator.com/item?id=46125184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://www.lesswrong.com/posts/vpNG99GhbBoLov9og/claude-4-5-opus-soul-document">Claude 4.5 Opus' Soul Document</a></strong>. Richard Weiss managed to get Claude 4.5 Opus to spit out <a href="https://gist.github.com/Richard-Weiss/efe157692991535403bd7e7fb20b6695#file-opus_4_5_soul_document_cleaned_up-md">this 14,000 token document</a> which Claude called the "Soul overview". Richard says:</p>
<blockquote>
<p>While extracting Claude 4.5 Opus' system message on its release date, as one does, I noticed an interesting particularity.</p>
<p>I'm used to models, starting with Claude 4, to hallucinate sections in the beginning of their system message, but Claude 4.5 Opus in various cases included a supposed "soul_overview" section, which sounded rather specific [...] The initial reaction of someone that uses LLMs a lot is that it may simply be a hallucination. [...] I regenerated the response of that instance 10 times, but saw not a single deviations except for a dropped parenthetical, which made me investigate more.</p>
</blockquote>
<p>This appeared to be a document that, rather than being added to the system prompt, was instead used to train the personality of the model <em>during the training run</em>. </p>
<p>I saw this the other day but didn't want to report on it since it was unconfirmed. That changed this afternoon when Anthropic's Amanda Askell <a href="https://x.com/AmandaAskell/status/1995610567923695633">directly confirmed the validity of the document</a>:</p>
<blockquote>
<p>I just want to confirm that this is based on a real document and we did train Claude on it, including in SL. It's something I've been working on for a while, but it's still being iterated on and we intend to release the full version and more details soon.</p>
<p>The model extractions aren't always completely accurate, but most are pretty faithful to the underlying document. It became endearingly known as the 'soul doc' internally, which Claude clearly picked up on, but that's not a reflection of what we'll call it.</p>
</blockquote>
<p>(SL here stands for "Supervised Learning".)</p>
<p>It's such an interesting read! Here's the opening paragraph, highlights mine: </p>
<blockquote>
<p>Claude is trained by Anthropic, and our mission is to develop AI that is safe, beneficial, and understandable. <strong>Anthropic occupies a peculiar position in the AI landscape: a company that genuinely believes it might be building one of the most transformative and potentially dangerous technologies in human history, yet presses forward anyway.</strong> This isn't cognitive dissonance but rather a calculated bet—if powerful AI is coming regardless, Anthropic believes it's better to have safety-focused labs at the frontier than to cede that ground to developers less focused on safety (see our core views). [...]</p>
<p>We think most foreseeable cases in which AI models are unsafe or insufficiently beneficial can be attributed to a model that has explicitly or subtly wrong values, limited knowledge of themselves or the world, or that lacks the skills to translate good values and knowledge into good actions. For this reason, we want Claude to have the good values, comprehensive knowledge, and wisdom necessary to behave in ways that are safe and beneficial across all circumstances.</p>
</blockquote>
<p>What a <em>fascinating</em> thing to teach your model from the very start.</p>
<p>Later on there's even a mention of <a href="https://simonwillison.net/tags/prompt-injection/">prompt injection</a>:</p>
<blockquote>
<p>When queries arrive through automated pipelines, Claude should be appropriately skeptical about claimed contexts or permissions. Legitimate systems generally don't need to override safety measures or claim special permissions not established in the original system prompt. Claude should also be vigilant about prompt injection attacks—attempts by malicious content in the environment to hijack Claude's actions.</p>
</blockquote>
<p>That could help explain why Opus <a href="https://simonwillison.net/2025/Nov/24/claude-opus/#still-susceptible-to-prompt-injection">does better against prompt injection attacks</a>  than other models (while still staying vulnerable to them.)</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon launches Trainium3 (159 pts)]]></title>
            <link>https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/</link>
            <guid>46125155</guid>
            <pubDate>Tue, 02 Dec 2025 19:04:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/">https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/</a>, See on <a href="https://news.ycombinator.com/item?id=46125155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Amazon Web Services, which has been <a href="https://techcrunch.com/2024/12/03/aws-trainium2-chips-for-building-llms-are-now-generally-available-with-trainium3-coming-in-late-2025/" target="_blank" rel="noreferrer noopener">building its own AI training chips</a> for years now, just introduced a new version known as Trainium3 that comes with some impressive specs.</p>

<p>The cloud provider, which <a href="http://aws.amazon.com/ai/machine-learning/trainium" target="_blank" rel="noreferrer noopener nofollow">made the announcement</a> Tuesday at AWS re:Invent 2025, also teased the next product on its AI training product roadmap: Trainium4, which is already in the works and will be able to work with Nvidia’s chips.</p>







<p>AWS used its annual tech conference to formally launch Trainium3 UltraServer, a system powered by the company’s state-of-the art, 3 nanometer Trainium3 chip, as well as its homegrown networking tech.&nbsp;As you might expect, the third-generation chip and system offer big bumps in performance for AI training and inference over the second-generation chip, according to AWS.</p>

<p>AWS says the system is more than 4x faster, with 4x more memory, not just for training, but for delivering AI apps at peak demand. Additionally, thousands of UltraServers can be linked together to provide an app with up to 1 million Trainium3 chips — 10x the previous generation. Each UltraServer can host 144 chips, according to the company.&nbsp;</p>

<p>Perhaps more importantly, AWS says the chips and systems are also 40% more energy efficient than the previous generation.&nbsp;While the world races to build bigger data centers powered by <a href="https://techcrunch.com/2025/12/01/data-center-energy-demand-forecasted-to-soar-nearly-300-through-2035/" target="_blank" rel="noreferrer noopener">astronomical gigawatts of electricity,</a> data center giant AWS is trying to make systems that drink less, not more.</p>

<p>It is, obviously, in AWS’s direct interests to do so. But in its classic, Amazon cost-conscious way, it promises that these systems save its AI cloud customers money, too.&nbsp;&nbsp;</p>

<p>AWS customers like Anthropic (of which Amazon is also an investor), Japan’s LLM Karakuri, SplashMusic, and Decart have already been using the third-gen chip and system and significantly cut their inference costs, Amazon said.&nbsp;</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>San Francisco</span>
													<span>|</span>
													<span>October 13-15, 2026</span>
							</p>
			
		</div>
	</div>

<p>AWS also presented a bit of a roadmap for the next chip, Trainium4, which is already in development. AWS promised the chip will provide another big step up in performance and support Nvidia’s NVLink Fusion high-speed chip interconnect technology.&nbsp;&nbsp;</p>

<p>This means the AWS Trainium4-powered systems will be able to interoperate and extend their performance with Nvidia GPUs while still using Amazon’s homegrown, lower-cost server rack technology.&nbsp;&nbsp;</p>

<p>It’s worth noting, too, that Nvidia’s CUDA (Compute Unified Device Architecture) has become the de facto standard that all the major AI apps are built to support. The Trainium4-powered systems may make it easier to woo big AI apps built with Nvidia GPUs in mind to Amazon’s cloud.</p>







<p>Amazon did not announce a timeline for Trainium4. If the company follows previous rollout timelines, we’ll likely hear more about Trainium4 at next year’s conference.</p>

<p>Follow along with all of TechCrunch’s coverage of the <a href="https://techcrunch.com/2025/12/01/aws-reinvent-2025-how-to-watch-and-follow-along-live/" target="_blank" rel="noreferrer noopener">annual enterprise tech event here</a>.</p>



<iframe loading="lazy" width="800" height="450" src="https://www.youtube.com/embed/NE-3tFhvf9c?autoplay=1&amp;mute=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p><em>Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flags</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Microsoft won't let me pay a $24 bill, blocking thousands in Azure spending (164 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46124930</link>
            <guid>46124930</guid>
            <pubDate>Tue, 02 Dec 2025 18:50:25 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46124930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46124930"><td><span></span></td><td><center><a id="up_46124930" href="https://news.ycombinator.com/vote?id=46124930&amp;how=up&amp;goto=item%3Fid%3D46124930"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=46124930">Microsoft won't let me pay a $24 bill, blocking thousands in Azure spending</a></span></td></tr><tr><td colspan="2"></td><td><span><span id="score_46124930">112 points</span> by <a href="https://news.ycombinator.com/user?id=Javin007">Javin007</a> <span title="2025-12-02T18:50:25 1764701425"><a href="https://news.ycombinator.com/item?id=46124930">2 hours ago</a></span> <span id="unv_46124930"></span> | <a href="https://news.ycombinator.com/hide?id=46124930&amp;goto=item%3Fid%3D46124930">hide</a> | <a href="https://hn.algolia.com/?query=Microsoft%20won%27t%20let%20me%20pay%20a%20%2424%20bill%2C%20blocking%20thousands%20in%20Azure%20spending&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=46124930&amp;auth=f3147a064083dec56e73a3b652ac5682c01a9d1a">favorite</a> | <a href="https://news.ycombinator.com/item?id=46124930">57&nbsp;comments</a></span></td></tr><tr><td colspan="2"></td><td><div><p>Two years ago, a $24 autopay charge on my Azure account failed. The invoice is now marked "Locked" in their billing portal.</p><p>I cannot pay this invoice. There is no button to pay it. There is no button to dismiss it. There is no way to interact with it at all.</p><p>Azure displays a banner: "You must pay all previous invoices before creating new subscriptions." Fair enough. I would love to pay it. Microsoft won't let me.</p><p>So I tried to contact support.</p><p>The Azure portal requires a "paid support plan" to create a support ticket. To purchase a paid support plan, you must create a subscription. To create a subscription, you must clear outstanding invoices. To clear outstanding invoices, you must contact support.</p><p>Azure on Twitter, as well as the website claims to have a "free support ticket" option for billing issues, but every possible link just drives you back to the same FAQ page while refusing to let you submit a ticket.</p><p>I called every number I could find:</p><p>1-800-867-1389 rings busy indefinitely. 1-855-270-0615 connects to an AI that asks what you need, tells you to visit the website, and disconnects. 1-800-642-7676 connects to a different AI that also tells you to visit the website. The website has a chatbot that redirects you to FAQ articles regardless of what you type. If you express frustration, it throws an error and stops responding.</p><p>I submitted feedback through the Azure portal every few days for weeks. No response.</p><p>I am a software engineer, so I did something ridiculous.</p><p>I wrote a PowerShell WinForms application that authenticates via device code flow, queries the Az.Support API for problem classifications, and calls New-AzSupportTicketsNoSubscription to submit a billing support ticket directly, bypassing the portal entirely.</p><p>Note the API name: NoSubscription. Microsoft has an explicit API for ticketing without a subscription.</p><p>It worked. The ticket was submitted. I felt briefly victorious.</p><p>The API responded: "Your support plan type is Free. To create and update support tickets, you need access to our high-tier support plans."</p><p>I had built custom software specifically to work around Microsoft's broken support infrastructure, and I still hit a paywall.</p><p>The total amount Microsoft is owed: $24.</p><p>The total amount Microsoft is preventing me from spending on new Azure services: thousands. I currently run numerous websites out of my house, and it's getting to be enough that I want to offload it to Azure VMs. Additionally, I was going to shift my development to Azure boxes, etc.</p><p>I have exhausted every official channel. Every phone number, every chatbot, every feedback form, every API endpoint. There is no path to a human being without first paying for a support plan that I cannot purchase because of the billing block that I need support to resolve.</p><p>Has anyone successfully escaped a loop like this? Is there a secret handshake I'm missing? Or is the only option to abandon this Microsoft account entirely, get a new phone, and start fresh?</p></div></td></tr><tr></tr><tr><td colspan="2"></td><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM CEO says there is 'no way' spending on AI data centers will pay off (391 pts)]]></title>
            <link>https://www.businessinsider.com/ibm-ceo-big-tech-ai-capex-data-center-spending-2025-12</link>
            <guid>46124324</guid>
            <pubDate>Tue, 02 Dec 2025 18:10:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/ibm-ceo-big-tech-ai-capex-data-center-spending-2025-12">https://www.businessinsider.com/ibm-ceo-big-tech-ai-capex-data-center-spending-2025-12</a>, See on <a href="https://news.ycombinator.com/item?id=46124324">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-content-container="">

  
    
  
    

  <section>
    
    
    
    
      <section id="post-body" data-component-type="post-body" data-load-strategy="exclude" data-lock-content="">
            
            
            
            <div data-component-type="post-hero" data-load-strategy="exclude">
                
                <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                    <div>
                      <meta itemprop="contentUrl" content="https://i.insider.com/692dc193e1a9cbb014df48af?width=700">
                      <p><img src="https://i.insider.com/692dc193e1a9cbb014df48af?width=700" srcset="https://i.insider.com/692dc193e1a9cbb014df48af?width=400&amp;format=jpeg&amp;auto=webp 400w, https://i.insider.com/692dc193e1a9cbb014df48af?width=500&amp;format=jpeg&amp;auto=webp 500w, https://i.insider.com/692dc193e1a9cbb014df48af?width=700&amp;format=jpeg&amp;auto=webp 700w, https://i.insider.com/692dc193e1a9cbb014df48af?width=1000&amp;format=jpeg&amp;auto=webp 1000w, https://i.insider.com/692dc193e1a9cbb014df48af?width=1300&amp;format=jpeg&amp;auto=webp 1300w, https://i.insider.com/692dc193e1a9cbb014df48af?width=2000&amp;format=jpeg&amp;auto=webp 2000w" sizes="(min-width: 1280px) 900px" alt="IBM CEO Arvind Krishna is pictured." decoding="sync">
                    </p></div>
                
                  <span>
                        <span>
                          
                          <label for="caption-drawer-btn">
                            <svg role="img" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 24 24">
                              <path fill="currentColor" fill-rule="evenodd" d="m4.56 18.5 7.486-7.72 7.394 7.626 2.56-2.64L12.046 5.5 2 15.86l2.56 2.64Z"></path>
                            </svg>        </label>
                  
                          <figcaption data-e2e-name="image-caption">
                            <span>IBM CEO Arvind Krishna was skeptical of the "belief" that data center spending could be profitable.</span>
                            <span>
                              <span data-e2e-name="image-source" itemprop="creditText">Riccardo Savi/Getty Images for Concordia Annual Summit</span>          </span>
                          </figcaption>
                        </span>
                  </span></figure>
            </div>
    
    
    
              
      
            
      
              
              
              
              <div data-component-type="post-summary-bullets" data-load-strategy="exclude" data-track-marfeel="post-summary-bullets">
                <ul>
                    <li>IBM's CEO walked through some napkin math on data centers—&nbsp;and said that there's "no way" to turn a profit at current costs.</li>
                    <li>"$8 trillion of CapEx means you need roughly $800 billion of profit just to pay for the interest," <a target="_blank" href="https://www.businessinsider.com/ibm-ceo-automation-ai-repetitive-white-collar-jobs-cuts-2023-10" data-autoaffiliated="false" data-track-click="{&quot;element_name&quot;:&quot;summary_bullets&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}">Arvind Krishna</a> told "Decoder."</li>
                    <li>Krishna was skeptical of that current tech would reach AGI, putting the likelihood between 0-1%.</li>
                </ul>
              </div>
      
            
            
            
            
            <section data-component-type="post-body-content" data-load-strategy="exclude" data-track-content="" data-post-type="story" data-track-marfeel="post-body-content">
            
                <p>AI companies are spending billions on data centers in the race to <a target="_self" href="https://www.businessinsider.com/limits-large-language-models-chatgpt-agi-artificial-general-intelligence-openai-2025-8" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">AGI</a>. IBM CEO Arvind Krishna has some thoughts on the math behind those bets.</p><p>Data center spending is on the rise. During Meta's recent earnings call, words like "capacity" and AI "infrastructure" were <a target="_self" href="https://www.businessinsider.com/meta-earnings-call-analyst-mark-zuckerberg-compute-capacity-metaverse-2025-10" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">frequently used</a>. Google just announced that it wants to eventually build them <a target="_self" href="https://www.businessinsider.com/google-project-suncatcher-sundar-pichai-data-centers-space-solar-2027-2025-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">in space</a>. The question remains: will the revenue generated from data centers ever justify all the capital expenditure?</p><p>On the <a target="_blank" href="https://www.theverge.com/podcast/829868/ibm-arvind-krishna-watson-llms-ai-bubble-quantum-computing" data-track-click="{&quot;click_type&quot;:&quot;other&quot;,&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;outbound_click&quot;}" rel=" nofollow">"Decoder" podcast</a>, Krishna concluded that there was likely "no way" these companies would make a return on their capex spending on data centers.</p><p>Couching that his napkin math was based on today's costs, "because anything in the future is speculative," Kirshna said that it takes about $80 billion to fill up a one-gigawatt data center.</p><p>"Okay, that's today's number. So, if you are going to commit 20 to 30 gigawatts, that's one company, that's $1.5 trillion of capex," he said. </p><p>Krishna also referenced the depreciation of the AI chips inside data centers as another factor: "You've got to use it all in five years because at that point, you've got to throw it away and refill it," he said. </p><p>Investor Michael Burry has recently <a target="_self" href="https://www.businessinsider.com/big-short-michael-burry-substack-nvidia-memo-depreciation-ai-bubble-2025-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">taken aim at Nvidia</a> over depreciating concerns, leading to a downturn in <a target="_self" href="https://www.businessinsider.com/stock-market-ai-bubble-gpu-depreciation-new-most-hated-word-2025-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">AI stocks</a>.</p><p>"If I look at the total commits in the world in this space, in chasing AGI, it seems to be like 100 gigawatts with these announcements," Krishna said.</p><p>At $80 billion each for 100 gigawatts, that sets Krishna's price tag for computing commitments at roughly $8 trillion.</p><p>"It's my view that there's no way you're going to get a return on that, because $8 trillion of capex means you need roughly $800 billion of profit just to pay for the interest," he said.</p><p>Reaching that number of gigawatts has required <a target="_self" href="https://www.businessinsider.com/us-data-center-construction-40-billion-spend-hits-record-high-2025-9" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">massive spending</a> from AI companies — and pushes for outside help. In an <a target="_self" href="https://www.businessinsider.com/openai-data-center-expansion-is-hungry-for-workers-and-electricity-2025-10" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">October letter</a> to the White House's Office of Science and Technology Policy, OpenAI CEO Sam Altman recommended that the US add 100 gigawatts in energy capacity every year.</p><p>"Decoder" host Nilay Patel pointed out that Altman believed OpenAI could generate a return on its capital expenditures. OpenAI has committed to spending some $1.4 trillion in a <a target="_self" href="https://www.businessinsider.com/sam-altman-defends-openai-trillion-spending-2025-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">variety of deals</a>. Here, Krishna said he diverged from Altman.</p><p>"That's a belief," Krishna said. "That's what some people like to chase. I understand that from their perspective, but that's different from agreeing with them."</p><p>Krishna clarified that he wasn't convinced that the current set of technologies would get us to AGI, a yet to be reached technological breakthrough generally agreed to be when AI is capable of completing complex tasks better than humans. He pegged the chances of achieving it without a further technological breakthrough at 0-1%.</p><p>Several other high-profile leaders have been skeptical of the acceleration to AGI. Marc Benioff said that he was "extremely suspect" of the AGI push, <a target="_self" href="https://www.businessinsider.com/marc-benioff-extremely-suspect-agi-hypnosis-2025-8" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">analogizing it to hypnosis</a>. Google Brain founder Andrew Ng said that AGI was "<a target="_self" href="https://www.businessinsider.com/google-brain-founder-andrew-ng-agi-is-overhyped-yc-2025-7?utm_source=chatgpt.com" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">overhyped</a>," and Mistral CEO Arthur Mensch said that AGI was a "<a target="_self" href="https://www.businessinsider.com/mistral-ceo-arthur-mensch-agi-marketing-move-metric-2025-6?utm_source=chatgpt.com" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">marketing move</a>."</p><p>Even if AGI is the goal, scaling compute may not be the enough. OpenAI cofounder Ilya Sutskever said <a target="_self" href="https://www.businessinsider.com/openai-cofounder-ilya-sutskever-scaling-ai-age-of-research-dwarkesh-2025-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">in November</a> that the age of scaling was over, and that even 100x scaling of LLMs would not be completely transformative. "It's back to the age of research again, just with big computers," he said.</p><p>Krishna, who began his career at IBM in 1990 before rising to eventually be named CEO in 2020 and chairman in 2021, did praise the current set of AI tools.</p><p>"I think it's going to unlock trillions of dollars of productivity in the enterprise, just to be absolutely clear," he said.</p><p>But AGI will require "more technologies than the current LLM path," Krisha said. He proposed fusing hard knowledge with LLMs as a possible future path.</p><p>How likely is that to reach AGI? "Even then, I'm a 'maybe,'" he said.</p>
            
            
            </section>
            
            
            
            
            
            
    
    
    
    
      </section>

    
    <!-- Included desktop "post-aside" -->  

    
      
      <section data-component-type="post-bottom" data-load-strategy="exclude" data-track-marfeel="post-bottom">
        <section>
    
    
    
          
          
          
          <div data-component-type="post-category-tags" data-load-strategy="lazy" data-track-marfeel="post-category-tags">
            <ul data-track-click-shared="{&quot;product_field&quot;:&quot;bi_value_unassigned&quot;,&quot;event&quot;:&quot;navigation&quot;,&quot;element_name&quot;:&quot;category_link&quot;}">
                
                <li>
                  <a data-track-click="" href="https://www.businessinsider.com/category/ibm" title="IBM">IBM</a>
                </li>      
                <li>
                  <a data-track-click="" href="https://www.businessinsider.com/category/sam-altman" title="Sam Altman">Sam Altman</a>
                </li>      
                <li>
                  <a data-track-click="" href="https://www.businessinsider.com/category/openai" title="OpenAI">OpenAI</a>
                </li>
                <li>
                  <span data-track-click="{&quot;click_text&quot;:&quot;More&quot;,&quot;click_path&quot;:&quot;bi_value_unassigned&quot;}" role="button" tabindex="0">More <svg role="img" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 24 24">
            <path fill="currentColor" d="M14.006 2H9.994v7.994H2v4.012h7.994V22h4.012v-7.994H22V9.994h-7.994V2Z"></path>
          </svg></span>
                </li>
          
            </ul>
          </div>
    
            
              
              
              <section data-component-type="dad-related-posts" data-delay-third-party-scripts="true" data-size="4" data-min-size="3" data-container-index="" data-included-verticals="artificial-intelligence" data-placement="post-bottom" data-track-marfeel="dad-related-posts-post-bottom" data-excluded-verticals="bi-video" data-root-margin="250px 0px" data-track-view="{&quot;element_name&quot;:&quot;end_of_article_recirc&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;,&quot;subscription_experience&quot;:&quot;bi_value_unassigned&quot;}">
                  <p>
                    <h2>
                      Read next
                    </h2>
                  </p>
            
                
              </section>
        </section>
    
        
    
          <section data-track-page-area="Post Bottom">
          <!-- Included desktop "taboola" -->    <vendor-taboola data-component-type="vendor-taboola" data-root-margin="0px 0px 100% 0px" data-consent="MARKETING" config="{&quot;providerName&quot;:&quot;taboola&quot;,&quot;providerPageType&quot;:{&quot;article&quot;:&quot;auto&quot;},&quot;providerUrl&quot;:&quot;//cdn.taboola.com/libtrc/businessinsider/loader.js&quot;,&quot;providerFlushValue&quot;:{&quot;flush&quot;:true},&quot;providerData&quot;:{&quot;mode&quot;:&quot;thumbs-1r&quot;,&quot;container&quot;:&quot;taboola-below-main-column&quot;,&quot;placement&quot;:&quot;below-main-column&quot;,&quot;onlyOn&quot;:&quot;desktop&quot;,&quot;target_type&quot;:&quot;mix&quot;}}" data-load-strategy="defer">
                
              </vendor-taboola>
          
          <!-- Excluded mobile "taboola" --></section>
            
            
      </section>
  </section>

  
  


  <back-to-home data-component-type="back-to-home" data-load-strategy="defer" data-only-on="mobile">
  
    
  
    
  </back-to-home></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun has been acquired by Anthropic (1634 pts)]]></title>
            <link>https://bun.com/blog/bun-joins-anthropic</link>
            <guid>46124267</guid>
            <pubDate>Tue, 02 Dec 2025 18:05:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.com/blog/bun-joins-anthropic">https://bun.com/blog/bun-joins-anthropic</a>, See on <a href="https://news.ycombinator.com/item?id=46124267">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[100k TPS over a billion rows: the unreasonable effectiveness of SQLite (326 pts)]]></title>
            <link>https://andersmurphy.com/2025/12/02/100000-tps-over-a-billion-rows-the-unreasonable-effectiveness-of-sqlite.html</link>
            <guid>46124205</guid>
            <pubDate>Tue, 02 Dec 2025 17:59:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andersmurphy.com/2025/12/02/100000-tps-over-a-billion-rows-the-unreasonable-effectiveness-of-sqlite.html">https://andersmurphy.com/2025/12/02/100000-tps-over-a-billion-rows-the-unreasonable-effectiveness-of-sqlite.html</a>, See on <a href="https://news.ycombinator.com/item?id=46124205">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><hgroup><p><time datetime="2025-12-02T00:00:00+00:00">02 Dec 2025</time></p></hgroup><hr><p>SQLite doesn't have MVCC! It only has a single writer! SQLite is for phones and mobile apps (and the occasional airliner)! For web servers use a proper database like Postgres! In this article I'll go over why  being embedded and a single writer are not deficiencies but actually allow SQLite to scale so unreasonably well.</p><h2 id="prelude">Prelude</h2><p>For the code examples I will be using Clojure. But, what they cover should be applicable to most programming language.</p><p>The machine these benchmarks run on has the following specs:</p><ul><li>MacBook Pro (2021)</li><li>Chip: Apple M1 Pro</li><li>Memory: 16 GB</li></ul><p>These benchmarks are not meant to be perfect or even optimal. They are merely to illustrate that it's relatively easy to achieve decent write throughput with SQLite. Usual benchmark disclaimers apply. </p><h2 id="defining_tps">Defining TPS</h2><p>When I say TPS I don't mean writes/updates per second. I'm talking about transactions per second, specifically interactive transactions that are common when building web applications. By interactive transactions I mean transactions where you execute some queries, run some application code and then execute more queries. For example:</p><pre><code>BEGIN;
UPDATE accounts SET balance = balance - 100.00
    WHERE name = 'Alice';
-- some application code runs
UPDATE accounts SET balance = balance + 100.00
    WHERE name = 'Bob';
COMMIT;
</code></pre><p>Transactions are useful because they let you rollback the state of your changes if your application encounters a problem.</p><h2 id="the_benchmark_harness">The benchmark harness</h2><p>To simulate requests we spin up <code>n</code> virtual threads (green threads) that each execute a function <code>f</code> this is analogous to handlers on a web server and will give us similar contention. Worth noting that this is high burst. I.e we will reach <code>n</code> level concurrent requests as fast as the system can spin up the virtual threads.</p><pre><code><span>(</span>defmacro <strong>tx-per-second</strong> [n &amp; body]
  `<span>(</span>let [ids#   <span>(</span>range 0 ~n<span>)</span>
         start# <span>(</span>. System <span>(</span>nanoTime<span>))</span>]
     <span>(</span>-&gt;&gt; ids#
       <span>;; Futures are using virtual threads so blocking is not slow
</span>       <span>(</span>mapv <span>(</span>fn [_#] <span>(</span>future ~@body<span>)))</span>
       <span>(</span>run! deref<span>))</span>
     <span>(</span>int <span>(</span>/ ~n <span>(</span>/ <span>(</span>double <span>(</span>- <span>(</span>. System <span>(</span>nanoTime<span>))</span> start#<span>))</span> 1000000000.0<span>)))))</span>
</code></pre><p>For the Clojure programmers among you <code>future</code> has been altered to use virtual threads. So, we can spin up millions if we need to.</p><pre><code><span>;; Make futures use virtual threads
</span><span>(</span>set-agent-send-executor!
  <span>(</span>Executors/newVirtualThreadPerTaskExecutor<span>))</span>
<span>(</span>set-agent-send-off-executor!
  <span>(</span>Executors/newVirtualThreadPerTaskExecutor<span>))</span>
</code></pre><p>We'll be using Postgres  as our network database (I'm using Postgres, but the same applies to MySQL etc) with a high performance connection pool optimised for our number of cores. </p><pre><code><span>(</span>defonce <strong>pg-db</strong>
  <span>(</span>jdbc/with-options
    <span>(</span>connection/-&gt;pool
      HikariDataSource
      {:dbtype          "postgres"
       :dbname          "thedb"
       :username        <span>(</span>System/getProperty "user.name"<span>)</span>
       :password        ""
       :minimumIdle     8
       :maximumPoolSize 8}<span>)</span>
    {}<span>))</span>
</code></pre><p>We'll be using SQLite with a single writer connection and a number of reader connections equal to our number of cores.</p><pre><code><span>(</span>defonce <strong>lite-db</strong>
  <span>(</span>d/init-db! "database.db"
    {:pool-size 8
     :pragma {:cache_size         15625
              :page_size          4096
              :journal_mode       "WAL"
              :synchronous        "NORMAL"
              :temp_store         "MEMORY"
              :busy_timeout       5000}}<span>))</span>
</code></pre><p>Our databases will have a simple schema:</p><pre><code><span>(</span>jdbc/execute! pg-db
  ["CREATE TABLE IF NOT EXISTS account<span>(</span>id INT PRIMARY KEY, balance INT<span>)</span>"]<span>)</span>
<span>(</span>d/q <span>(</span>lite-db :writer<span>)</span>
  ["CREATE TABLE IF NOT EXISTS account<span>(</span>id PRIMARY KEY, balance INT<span>)</span>"]<span>)</span>
</code></pre><p>And each contain a billion rows:</p><pre><code><span>(</span>-&gt;&gt; <span>(</span>range 0 <span>(</span>* 1000 1000 1000<span>))</span>
  <span>(</span>partition-all 32000<span>)</span>
  <span>(</span>run!
    <span>(</span>fn [batch]
      <span>(</span>jdbc-sql/insert-multi! pg-db :account
        <span>(</span>mapv <span>(</span>fn [id] {:id id :balance 1000000000}<span>)</span> batch<span>)))))</span>
        
<span>(</span>-&gt;&gt; <span>(</span>range 0 <span>(</span>* 1000 1000 1000<span>))</span>
  <span>(</span>partition-all 100000<span>)</span>
  <span>(</span>run!
    <span>(</span>fn [batch]
      <span>(</span>d/with-write-tx [tx <span>(</span>lite-db :writer<span>)</span>]
        <span>(</span>run!
          <span>(</span>fn [id]
            <span>(</span>d/q tx
              ["INSERT INTO account<span>(</span>id, balance<span>)</span> VALUES <span>(</span>?,?<span>)</span>" id 1000000000]<span>))</span>
          batch<span>)))))</span>
</code></pre><p>Our user distribution will follow a <a href="https://en.wikipedia.org/wiki/Power_law">power law</a>. I.e the top X percent will be involved in most of the transactions. We have a billion users, so in practice most of those won't be active, or be active rarely. <code>0.9995</code> means 99.95% of transactions will be done by 0.05% of users. This still means around 100000 unique active users at any given time. </p><p>The reason we are using a power law, is that's a very common distribution for a lot of real products. If you think about a credit card payment system, in the context of retail, the largest number of transactions are most likely with a few large retailers (Amazon, Walmart etc).</p><pre><code><span>(</span>defn <strong>pareto-user</strong> []
  <span>(</span>rand-pareto <span>(</span>* 1000 1000 1000<span>)</span> 0.9995<span>))</span>
</code></pre><p><code>rand-pareto</code> turns a random distribution into a power law distribution.</p><pre><code><span>(</span>defn <strong>rand-pareto</strong> [r p]
  <span>(</span>let [a <span>(</span>/ <span>(</span>Math/log <span>(</span>- 1.0 p<span>))</span> <span>(</span>Math/log p<span>))</span>
        x <span>(</span>rand<span>)</span>
        y <span>(</span>/ <span>(</span>- <span>(</span>+ <span>(</span>Math/pow x a<span>)</span> 1.0<span>)</span>
               <span>(</span>Math/pow <span>(</span>- 1.0 x<span>)</span> <span>(</span>/ 1.0 a<span>)))</span>
            2.0<span>)</span>]
    <span>(</span>long <span>(</span>* r y<span>))))</span>
</code></pre><h2 id="network_database">Network database</h2><p>Let's start with a network database.</p><pre><code><span>(</span>tx-per-second 100000
  <span>(</span>jdbc/with-transaction [tx pg-db]
    <span>(</span>jdbc/execute! tx <span>(</span>credit-random-account<span>))</span>
    <span>(</span>jdbc/execute! tx <span>(</span>debit-random-account<span>))))</span>
    
<span>;; =&gt; 13756 TPS
</span></code></pre><p>A respectable 13756 TPS.</p><p>However, normally a network database will not be on the same server as our application. So let's simulate some network latency. Let's say you have 5ms latency between your app server and your database.</p><pre><code><span>(</span>tx-per-second 10000
  <span>(</span>jdbc/with-transaction [tx pg-db]
    <span>(</span>jdbc/execute! tx <span>(</span>credit-random-account<span>))</span>
    <span>(</span>Thread/sleep 5<span>)</span>
    <span>(</span>jdbc/execute! tx <span>(</span>debit-random-account<span>))))</span>
    
<span>;; =&gt; 1214 TPS
</span></code></pre><p><em>Note: virtual threads do not sleep a real thread. They instead park allowing the underlying carrier thread to resume another virtual thread.</em></p><p>What if we increase that latency to 10ms?</p><pre><code><span>(</span>tx-per-second 10000
  <span>(</span>jdbc/with-transaction [tx pg-db]
    <span>(</span>jdbc/execute! tx <span>(</span>credit-random-account<span>))</span>
    <span>(</span>Thread/sleep 10<span>)</span>
    <span>(</span>jdbc/execute! tx <span>(</span>debit-random-account<span>))))</span>
    
<span>;; =&gt; 702 TPS
</span></code></pre><p>But, wait our transactions are not serialisable, which they need to be if we want consistent transaction processing (SQLite is isolation serialisable by design). We better fix that and handle retries.</p><pre><code><span>(</span>tx-per-second 10000
  <span>(</span>loop []
    <span>(</span>let [result
          <span>(</span>try
            <span>(</span>jdbc/with-transaction [tx pg-db {:isolation :serializable}]
              <span>(</span>jdbc/execute! tx <span>(</span>credit-random-account<span>))</span>
              <span>(</span>Thread/sleep 10<span>)</span>
              <span>(</span>jdbc/execute! tx  <span>(</span>debit-random-account<span>)))</span>
            <span>(</span>catch Exception _ nil<span>))</span>]
      <span>(</span>when-not result <span>(</span>recur<span>)))))</span>

<span>;; =&gt; 660 TPS
</span></code></pre><p>What if the interactive transaction has an extra query (an extra network hop)?</p><pre><code><span>(</span>tx-per-second 10000
  <span>(</span>loop []
    <span>(</span>let [result
          <span>(</span>try
            <span>(</span>jdbc/with-transaction [tx pg-db {:isolation :serializable}]
              <span>(</span>jdbc/execute! tx <span>(</span>credit-random-account<span>))</span>
              <span>(</span>Thread/sleep 10<span>)</span>
              <span>(</span>jdbc/execute! tx  <span>(</span>debit-random-account<span>))</span>
              <span>(</span>Thread/sleep 10<span>)</span>
              <span>(</span>jdbc/execute! tx  <span>(</span>debit-random-account<span>)))</span>
            <span>(</span>catch Exception _ nil<span>))</span>]
      <span>(</span>when-not result <span>(</span>recur<span>)))))</span>

<span>;; =&gt; 348 TPS
</span></code></pre><p>348 TPS! What's going on here? <a href="https://en.wikipedia.org/wiki/Power_law">Amdoahl's Law</a> strikes!</p><blockquote><p>the overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used. </p></blockquote><p>We're holding transactions with row locks across a network with high contention because of the power law. What's terrifying about this is no amount of additional (cpu/servers/memory) is going to save us. This is a hard limit caused by the network. What's worse, in any unexpected increase in latency will exacerbate the problem. Which also means you can't have application servers in different data centres than your database (because of the increased latency). </p><p>I learnt this the hard way building an emoji based tipping bot for discord. At the time I didn't understand why we were hitting this hard limit in TPS. We ended up sacrificing the convenience of interactive transactions and moving everything into stored procedures (meaning no locks across the network). However, in a lot of domains this isn't possible.</p><h2 id="embedded_means_no_network">Embedded means no network</h2><p>Let's see how SQLite fares.</p><pre><code><span>(</span>tx-per-second 1000000
  <span>(</span>d/with-write-tx [tx <span>(</span>lite-db :writer<span>)</span>]
    <span>(</span>d/q tx <span>(</span>credit-random-account<span>))</span>
    <span>(</span>d/q tx <span>(</span>debit-random-account<span>))))</span>

<span>;; =&gt; 44096 TPS
</span></code></pre><p>44096 TPS! By eliminating the network SQLite massively reduces the impact of Amdahl's law.</p><h2 id="single_writer_lets_you_batch">Single writer lets you batch</h2><p>We don't need to stop there though. Because, SQLite is a single writer we can batch. <a href="https://github.com/andersmurphy/sqlite4clj">sqlite4clj</a> provides a convenient dynamic batching function. Batch size grows dynamically with the workload and producers don't have to block when the consumer is busy. Effectively it self optimises for latency and throughput.</p><pre><code><span>(</span>defn <strong>batch-fn</strong> [db batch]
  @<span>(</span>on-pool! lite-write-pool
     <span>(</span>d/with-write-tx [tx db]
       <span>(</span>run! <span>(</span>fn [thunk] <span>(</span>thunk tx<span>))</span> batch<span>))))</span>
       
<span>(</span>defonce <strong>tx!</strong>
  <span>(</span>b/async-batcher-init! lite-db
    {:batch-fn #'batch-fn}<span>))</span>
</code></pre><p><em>Note: to Clojure/Java programmers we're using a thread pool as SQLite should be treated as CPU not IO, so we don't want it starving our virtual threads (io green threads).</em></p><pre><code><span>(</span>tx-per-second 1000000
  @<span>(</span>tx!
     <span>(</span>fn [tx]
       <span>(</span>d/q tx <span>(</span>credit-random-account<span>))</span>
       <span>(</span>d/q tx <span>(</span>debit-random-account<span>)))))</span>
       
<span>;; =&gt; 186157 TPS
</span></code></pre><p>But, wait I hear you cry! That's cheating we now don't have isolated transaction failure. Batching is sacrificing fine grained transaction. You're right! Let's fix that.</p><pre><code><span>(</span>tx-per-second 1000000
  @<span>(</span>tx!
     <span>(</span>fn  [tx]
       <span>(</span>d/q tx ["SAVEPOINT inner_tx"]<span>)</span>
       <span>(</span>try
         <span>(</span>d/q tx <span>(</span>credit-random-account<span>))</span>
         <span>(</span>d/q tx <span>(</span>debit-random-account<span>))</span>
         <span>(</span>catch Throwable _
           <span>(</span>d/q tx ["ROLLBACK inner_tx"]<span>)))</span>
       <span>(</span>d/q tx ["RELEASE inner_tx"]<span>))))</span>
       
<span>;; =&gt; 121922 TPS
</span></code></pre><p>SQLite supports nested transactions with <code>SAVEPOINT</code> this lets us have fine-grained transaction rollback whilst still batching our writes. If a transaction fails it won't cause the batch to fail. The only case where the whole batch will fail is in the case of power loss/or a hard crash.</p><h2 id="what_about_concurrent_reads%3F">What about concurrent reads?</h2><p>Generally systems have a mix of reads and writes, somewhere in the region of 75% reads to 25% writes. So let's add some writes.</p><pre><code><span>(</span>tx-per-second 1000000
  <span>(</span>on-pool! lite-read-pool
    <span>(</span>d/q <span>(</span>lite-db :reader<span>)</span>
      ["select * from account where id = ? limit 1" <span>(</span>pareto-user<span>)</span>]<span>))</span>
  <span>(</span>on-pool! lite-read-pool
    <span>(</span>d/q <span>(</span>lite-db :reader<span>)</span>
      ["select * from account where id = ? limit 1" <span>(</span>pareto-user<span>)</span>]<span>))</span>
  <span>(</span>on-pool! lite-read-pool
    <span>(</span>d/q <span>(</span>lite-db :reader<span>)</span>
      ["select * from account where id = ? limit 1" <span>(</span>pareto-user<span>)</span>]<span>))</span>
  @<span>(</span>tx!
     <span>(</span>fn  [tx]
       <span>(</span>d/q tx ["SAVEPOINT inner_tx"]<span>)</span>
       <span>(</span>try
         <span>(</span>d/q tx <span>(</span>credit-random-account<span>))</span>
         <span>(</span>d/q tx <span>(</span>debit-random-account<span>))</span>
         <span>(</span>catch Throwable _
           <span>(</span>d/q tx ["ROLLBACK inner_tx"]<span>)))</span>
       <span>(</span>d/q tx ["RELEASE inner_tx"]<span>))))</span>
       
<span>;; =&gt; 102545 TPS
</span></code></pre><p>102545 TPS!</p><p><em>Note: to Clojure/Java programmers we're using a separate read thread pool so that reads don't starve writes.</em></p><h2 id="tps_report">TPS Report</h2><table><thead><tr><th></th><th>Postgres</th><th>SQLite</th></tr></thead><tbody><tr><td>no network</td><td>13756</td><td>44096</td></tr><tr><td>5ms</td><td>1214</td><td>n/a</td></tr><tr><td>10ms</td><td>702</td><td>n/a</td></tr><tr><td>10ms serializable</td><td>660</td><td>n/a</td></tr><tr><td>batch</td><td>n/a</td><td>186157</td></tr><tr><td>batch savepoint</td><td>n/a</td><td>121922</td></tr><tr><td>batch savepoint + reads</td><td>n/a</td><td>102545</td></tr></tbody></table><h2 id="conclusion">Conclusion</h2><p>Hopefully, this post helps illustrate the unreasonable effectiveness of SQLite as well as the challenges you can run in with Amdahl's law and network databases like postgres.</p><p>The full benchmark code <a href="https://github.com/andersmurphy/clj-cookbook/tree/master/sqlite-vs-postgres">can be found here</a>.</p><p><strong>Further Reading:</strong></p><p>If you want to learn more about Amdahl's law, power laws and how they interact with network databases I highly recommend listening to <a href="https://www.youtube.com/watch?v=9oyhNDv882U">this interview with Joran Greef</a> and watching his talk <a href="https://www.youtube.com/watch?v=yKgfk8lTQuE">1000x: The Power of an Interface for Performance by Joran Dirk Greef</a>.   </p><p>If you want to read about how much further you can scale SQLite checkout <a href="https://use.expensify.com/blog/scaling-sqlite-to-4m-qps-on-a-single-server">Scaling SQLite to 4M QPS on a single server (EC2 vs Bare Metal)</a>.</p><p>If you're thinking of running SQLite in production and wondering how to create streaming replicas, backups and projections checkout <a href="https://litestream.io/">litestream</a>.</p><p>If you still don't think a single machine can handle your workload it's worth reading <a href="https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf">Scalability! But at what COST?</a>.</p><p><strong>Thanks to</strong> Everyone on the <a href="https://discord.gg/bnRNgZjgPh">Datastar discord</a> who read drafts of this and gave me feedback.</p><p><strong>Discussion</strong></p><ul><li><a href="https://news.ycombinator.com/item?id=46124205">hackernews</a></li><li><a href="https://www.reddit.com/r/Clojure/comments/1pchdr3/sqlite4clj_100k_tps_over_a_billion_rows_the/">reddit</a></li></ul></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[School cell phone bans and student achievement (125 pts)]]></title>
            <link>https://www.nber.org/digest/202512/school-cell-phone-bans-and-student-achievement</link>
            <guid>46124179</guid>
            <pubDate>Tue, 02 Dec 2025 17:58:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nber.org/digest/202512/school-cell-phone-bans-and-student-achievement">https://www.nber.org/digest/202512/school-cell-phone-bans-and-student-achievement</a>, See on <a href="https://news.ycombinator.com/item?id=46124179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p><img data-entity-uuid="813d8fa8-82f3-4688-9b64-1fe867656d0e" data-entity-type="file" alt="This figure is a dot plot titled &quot;School Cellphone Ban in Florida and Average Test Scores&quot; showing the difference in average test scores following the implementation of a cellphone ban. The y-axis shows the difference in average test score in percentiles, relative to the third test period in academic year 2022-23, ranging from 0 to 4. The x-axis shows test periods across three academic years: 2022-23, 2023-24, and 2024-25, with three test periods per year labeled 1, 2, and 3. The figure uses three different colors to distinguish the academic years: blue dots for 2022-23, red dots for 2023-24, and orange dots for 2024-25. Vertical bars represent 95% confidence intervals. Two vertical dashed lines mark &quot;Beginning of first school year after ban took effect&quot; and &quot;Beginning of ban enforcement.&quot; The figure shows that test scores were relatively stable during 2022-23 (before the ban), ranging from approximately 0.5 to 1 percentile points. After the ban took effect in 2023-24, scores rose slightly to around 1-1.3 percentiles. Following full enforcement beginning in 2024-25, scores increased substantially, reaching approximately 2.5 percentiles in test period 2 and nearly 4 percentiles in test period 3. The source line reads: Researchers' calculations using data from an anonymous large urban county-level school district in Florida." width="3501" height="2493" loading="lazy" data-src="/sites/default/files/inline-images/w34388_0.jpg" src="https://www.nber.org/sites/default/files/inline-images/w34388_0.jpg"></p><p>Two years after the imposition of a student cell phone ban, student test scores in a large urban school district were significantly higher than before, <a href="https://www.nber.org/people/david_figlio">David N. Figlio</a>&nbsp;and&nbsp;<a href="https://www.nber.org/people/umut_ozek">Umut Özek</a> find in <a href="https://www.nber.org/papers/w34388">The Impact of Cell Phone Bans in Schools on Student Outcomes: Evidence from Florida</a> (NBER Working Paper 34388). The study examines data from one of the 10 largest school districts in the United States, a large urban county-level school district in Florida. While Florida's statewide law banned cell phone use during instructional time, this district implemented a stricter policy requiring students to keep phones silenced and stored in backpacks during the entire school day, including lunch and transitions between classes.</p><blockquote><p>An all-day cell phone ban within a Florida school district improved test scores, particularly for male students and in middle and high schools.</p></blockquote><p>The researchers combined two datasets to conduct this analysis. First, they accessed student administrative data for the year prior to the ban (AY 2022–23) and two years following the ban (AY 2023–24 and AY 2024–25). These data are reported to the district three times annually and include information on student demographics, attendance, disciplinary actions, and standardized test scores. Second, they examined building-level smartphone activity data from Advan for district schools. This data traced the average number of unique smartphone pings between 9 am and 1 pm on school days. To isolate the effects of student usage, the team compared normal school days to professional-only working days. They then compared the last two months of AY 2022–23 (pre-ban) to the first two months of AY 2023–24 and AY 2024–25 (post-ban) and found an average drop in usage of approximately two-thirds. The relative level of usage reduction was used to sort the district’s schools into high-effect (top tercile of pre-ban usage) and low-effect (bottom tercile of pre-ban usage) pools.</p><p>During the first month of the ban (September 2023), student suspensions rose 25 percent relative to the same month of the prior school year. Elevated disciplinary rates persisted for the full school year. The effects were particularly stark among Black male students, whose in-school suspension rates increased 30 percent at the highly affected schools. Even among the most affected schools and population groups, however, disciplinary action rates fell to near pre-ban levels by the start of the following school year. The researchers posited that this represented a period of adjustment to the new policy rather than an indication of a long-term negative effect of the ban’s implementation.</p><p>There were no statistically significant changes in test scores during the first year of the ban, when disciplinary rates were high. During the second year of the ban, in contrast, test scores increased significantly, with positive effects concentrated during the spring semester (scores increased 1.1 percentiles, on average). The researchers suggest that this may be due to the higher stakes of spring tests, which can affect grade advancement and high school graduation. Test score improvements were also concentrated among male students (up 1.4 percentiles, on average) and among middle and high school students (up 1.3 percentiles, on average).&nbsp;</p><p>When comparing high-effect and low-effect schools, the researchers note significant reductions in unexcused absences during the two years following the cell phone ban. They posit that increased attendance could explain as much as half of the test score improvements noted in their primary analysis.&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;- Emma Salomon</p><hr><p><em>The researchers thank the Smith Richardson Foundation for generous research funding.</em></p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Junior Hiring Crisis (254 pts)]]></title>
            <link>https://people-work.io/blog/junior-hiring-crisis/</link>
            <guid>46124063</guid>
            <pubDate>Tue, 02 Dec 2025 17:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people-work.io/blog/junior-hiring-crisis/">https://people-work.io/blog/junior-hiring-crisis/</a>, See on <a href="https://news.ycombinator.com/item?id=46124063">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <p>I have a vested interest in college kids’ outcomes right now because I have two of them myself and one on the way, and things seem very uncertain for them. When I read the research data about what’s happening, I pay extra close attention.</p>
<h2 id="the-data">The Data</h2>
<p>It’s not very encouraging. According to very recent research from <a href="https://digitaleconomy.stanford.edu/wp-content/uploads/2025/08/Canaries_BrynjolfssonChandarChen.pdf">Stanford’s Digital Economy Lab</a>, published in August of this year, companies that adopt AI at higher rates are hiring juniors 13% less. Another study from <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5425555">Harvard</a> published in October of this year cites that early-career folks from 22-25 years old, in these same fields, are experiencing greater unemployment while senior hiring remains stable or even growing.</p>
<a href="https://digitaleconomy.stanford.edu/wp-content/uploads/2025/08/Canaries_BrynjolfssonChandarChen.pdf" target="_blank" rel="noopener noreferrer">
  
  
  <img src="https://people-work.io/cdn-cgi/image/format=auto,width=1920//assets/blog/junior-hiring-crisis/dev-hiring.webp" srcset="
      https://people-work.io/cdn-cgi/image/format=auto,width=480//assets/blog/junior-hiring-crisis/dev-hiring.webp 480w,
      https://people-work.io/cdn-cgi/image/format=auto,width=768//assets/blog/junior-hiring-crisis/dev-hiring.webp 768w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1024//assets/blog/junior-hiring-crisis/dev-hiring.webp 1024w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1280//assets/blog/junior-hiring-crisis/dev-hiring.webp 1280w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1920//assets/blog/junior-hiring-crisis/dev-hiring.webp 1920w" sizes="100vw" alt="Software Developer Headcount Over Time by Level" loading="lazy">


</a>
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5425555" target="_blank" rel="noopener noreferrer">

  
  <img src="https://people-work.io/cdn-cgi/image/format=auto,width=1920//assets/blog/junior-hiring-crisis/junior-hiring.webp" srcset="
      https://people-work.io/cdn-cgi/image/format=auto,width=480//assets/blog/junior-hiring-crisis/junior-hiring.webp 480w,
      https://people-work.io/cdn-cgi/image/format=auto,width=768//assets/blog/junior-hiring-crisis/junior-hiring.webp 768w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1024//assets/blog/junior-hiring-crisis/junior-hiring.webp 1024w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1280//assets/blog/junior-hiring-crisis/junior-hiring.webp 1280w,
      https://people-work.io/cdn-cgi/image/format=auto,width=1920//assets/blog/junior-hiring-crisis/junior-hiring.webp 1920w" sizes="100vw" alt="Junior vs Senior Hiring After ChatGPT Launch" loading="lazy">


</a>
<p>There are so many young people out there that don’t have the luxury of living with their parents during hard times, and this, sadly, has the potential to affect their entire career trajectory.</p>
<h2 id="why-i-got-involved">Why I Got Involved</h2>
<p>Because of the work I do with People Work, I was lucky enough to be able to dig into this issue more deeply when we joined <a href="https://www.colorado.edu/venturepartners/">CU Boulder Venture Partner’s</a> <a href="https://www.colorado.edu/venturepartners/university-innovators/entrepreneurial-training/nsf-i-corps-hub-west/starting-blocks-customer">Starting Blocks</a> program to see whether or not universities were feeling this, too. The point of the program was to validate a customer segment for our business (<a href="https://people-work.io/for-graduating-students/">students</a>), but as a mom and an engineer, I had a deeper purpose. I did interviews with university faculty and staff and students from all over the country, and I found anecdotally, of course, that the research findings have definitely caught up to what people are feeling.</p>
<h2 id="what-i-m-hearing-from-universities">What I’m Hearing From Universities</h2>
<p>Most of the university post-graduation job placement statistics have not caught up with the research yet, but staff and students alike have anecdotally told me that they feel it. Students are telling advisors that they are struggling with getting that first job, and hopelessness looms.</p>
<p>I recently <a href="https://youtu.be/0HOmvtPwA1o">responded</a> to a video from a CS grad who described feeling 'cooked', and I get it. The feelings are valid.</p>
<p>The most surprising thing that I learned is that everyone - career services staff, professors, deans, students, and parents alike - all agree that networking is absolutely essential for post-graduation job-placement success. (This was before they knew who I was or what People Work was about.) They see the AI-resume / AI-recruiting game and know that the only way to stand out is creating genuine connections with other professionals.</p>
<p>That said, they all struggle with how to do it and/or how to scale it to all of the students. Many noted platform fatigue with all of the networking apps out there designed to connect the students to alumni or mentors. Even very well-resourced students, with access to mentorship groups, alumni associations, professional groups, etc, struggle to know how to build relationships and make the most of the breadth of their access to people.</p>
<p>The most common answer from career services professionals when asked what they needed was more staff. The most common answer from students when asked what they needed was a mentor who had just been in their shoes a few years ago, a surprising and heartening answer.</p>
<p>They all want intentional, meaningful, and authentic professional relationships for the students, but there seems to be a pervasive lack of relational intelligence that blocks them from receiving it. This is totally normal and expected, as they’re young and they <a href="https://people-work.io/blog/how-ai-driving-human-connection-work/">grew up with social media</a>. But it’s particularly problematic for those going into AI-adopting industries, and here’s why.</p>
<h2 id="why-this-crisis-is-happening-the-apprenticeship-breakdown">Why This Crisis Is Happening: The Apprenticeship Breakdown</h2>
<h2 id="the-i-m-an-ic-not-a-manager-culture">The “I’m an IC, not a manager” Culture</h2>
<p>When tech companies started giving engineers an alternative career path to management by letting them climb the ranks as individual contributors instead of having to be managers, I thought that was definitely the right move. Still do. However, the unintended consequence of that is that we’ve spent a decade normalizing senior engineers opting out of developing the next generation.</p>
<p>When I was breaking into tech in my thirties, I quickly ran into this headlong and found that I had to demand mentorship. People right out of college don’t have years of experience to know that they should, also. “I’m an IC not a manager,” became an acceptable argument to avoid this work, and it became the norm across the tech industry.</p>
<h2 id="ai-is-replacing-the-training-ground-not-replacing-expertise">AI Is Replacing the Training Ground, Not Replacing Expertise</h2>
<p>We used to have a training ground for junior engineers, but now AI is increasingly automating away that work. Both studies I referenced above cited the same thing - AI is getting good at automating junior work while only augmenting senior work. So the evidence doesn’t show that AI is going to replace <em>everyone</em>; it’s just removing the apprenticeship ladder.</p>
<p><em>When we neglect teaching hands-on work, we forfeit building expertise.</em></p>
<p><em>When we avoid pair-programming, we miss out on transmitting tacit knowledge.</em></p>
<p><em>When we don’t teach the art of a code review, we miss the opportunity to teach software architectural design.</em></p>
<p><em>When AI replaces junior engineering work and seniors have been excused from people development responsibilities, you get a missing generation.</em></p>
<h3 id="future-implications-the-timing-mismatch">Future Implications: The Timing Mismatch</h3>
<p>So what happens in 10-20 years when the current senior engineers retire? Where do the next batch of seniors come from? The ones who can architect complex systems and make good judgment calls when faced with uncertain situations? Those are skills that are developed through years of work that starts simple and grows in complexity, through human mentorship.</p>
<p>We’re setting ourselves up for a timing mismatch, at best. We’re eliminating junior jobs in hopes that AI will get good enough in the next 10-20 years to handle even complex, human judgment calls. And if we’re wrong about that, then we have far fewer people in the pipeline of senior engineers to solve those problems.</p>
<h3 id="the-incentive-structure-problem">The Incentive Structure Problem</h3>
<p>What makes this a particularly difficult problem to solve is that the economic incentives are completely misaligned.</p>
<p>The social contract between large companies and employees has been broken for years now. US companies are optimized for quarterly earnings, not long term investment in their employees. That’s not to say that there aren’t people within those companies who care about employee development, but the system isn’t set up for that to be the companies’ top priority. They need the flexibility to have layoffs without remorse, and they trade that for the average employee tenure being about 2 years. When that’s the case, then there is really no incentive to invest in juniors, so they just hire seniors. And this is magical thinking which has kind of worked for the last decade, but I predict it is no longer sustainable.</p>
<p>Let’s add it all together:</p>
<div>
<p><code>Companies replace junior positions with AI</code></p>
<p><code>+</code></p>
<p><code>Senior engineers have been excused from mentorship responsibilities</code></p>
<p><code>+</code></p>
<p><code>Companies optimize for immediate results</code></p>
<p><code>=</code></p>
<p><code>A systemic issue that no one person can fix</code></p>
</div>
<h2 id="what-you-can-control-pivot-to-individual-agency">What You Can Control: Pivot to Individual Agency</h2>
<p>Given this broken system that we find ourselves in (those of us in AI-adopting industries), let’s focus not on what we are powerless over but rather what we can change.</p>
<p>I am hopeful…even bullish if you will…that if enough people take ownership of their careers and development, companies will have to respond.</p>
<h3 id="how-to-do-this-build-the-skills-that-ai-can-t-automate">How To Do This: Build the Skills That AI Can’t Automate</h3>
<p>Get good at the things that AI can’t do - the ability to influence, collaborate, and navigate complex human systems. When AI can write your code, human skills are the differentiator.</p>
<p>Here’s what that looks like in practice:</p>
<p><strong>Identify the 10-30 people in your professional network that matter most to your career.</strong> These folks will fall into <a href="https://people-work.io/blog/friendships-and-firewalls/">four different categories</a>:</p>
<ol>
<li><strong>Guide</strong> - Those who look to you for guidance.</li>
<li><strong>Align</strong> - Those who you seek to align with, who have a vested interest in the outcome of your work.</li>
<li><strong>Partner</strong> - The peers with whom you work most closely and collaborate.</li>
<li><strong>Network</strong> - Your broader community with whom you create a cultural context with your shared values.</li>
</ol>
<p><strong>Get intentional about nurturing each of those relationships.</strong> You’re not just “growing your network”, you’re seeking to understand how your unique skills can help with their unique needs. This will look different with each person, so get curious.</p>
<p><strong>Track what’s working and what’s not.</strong> Note what is happening and how you feel about it. Get introspective. Keep track of the commitments made between the two of you. Are you being helpful or transactional?</p>
<p><strong>Practice while the stakes are low.</strong> If you’re a student, practice building these relationship skills now, in the safety of school where mistakes are welcomed. Then you will be able to add value immediately and be better positioned for finding the all-important internship and first job.</p>
<h3 id="why-this-matters-more-than-ever">Why This Matters More Than Ever</h3>
<p>Senior engineering roles have <em>always</em> been leadership positions, but we haven’t been great as an industry at enforcing it. Imagine a tech industry where relationship skills weren’t just nice-to-have but <em>essential</em>. Where navigating complex human systems was seen as a core competency.</p>
<p>When students start practicing building this relational intelligence now, then they are creating the muscle memory that will be so helpful when they graduate. Then when they get their first job from someone in that well-nurtured network, they can use that newly built relational intelligence to understand how to best <a href="https://people-work.io/for-onboarding/">onboard</a> to their new role and start adding value quickly.</p>
<p>This requires intentional practice, pattern recognition, and psychological safety. It will be difficult but necessary.</p>
<h2 id="conclusion-the-path-forward">Conclusion: The Path Forward</h2>
<p>I will not sugar coat it. Yes, the traditional apprenticeship model in tech has been slowly eroding and AI is accelerating that. Yes, companies’ incentive models are not in favor of the employee. And yes, the 10-20 year talent pipeline is at risk.</p>
<p>But I didn’t write this post to simply complain about a broken system. I wrote this post because I’ve been navigating this system as an career changer in tech for a decade now and have learned a thing or two about how to do that successfully.</p>
<p><strong>If you’re a student or early-career professional</strong>, start building that relational intelligence now. Identify about 10-20 key relationships and get intentional with them. Track what works and what doesn’t. <a href="https://people-work.io/for-graduating-students/">We can help, if you need it!</a></p>
<p><strong>If you’re a senior engineer or manager</strong>, teaching forces clarity. When you have to explain things in their most basic form, you understand it more deeply, and this, in turn, benefits the entire team.</p>
<p><strong>If you’re a university administrator</strong>, I recommend embedding relational intelligence into your core curriculum, especially in the majors in AI-adopting industries. If you need ideas of how to do that, <a href="mailto:support@people-work.io">we’re happy to help</a>.</p>
<p>Relationship skills have always been a differentiator, but now they’re a necessity. It taps into what makes us more human, and I for one think that adding more humanity to technology and business is pretty wonderful.</p>
<hr>
<p>We’re here to help! <a href="mailto:support@people-work.io">Email me</a> if you want to chat about making this more approachable for students, universities, engineering teams, or yourself.</p>

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Thiel's Apocalyptic Worldview Is a Dangerous Fantasy (200 pts)]]></title>
            <link>https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist</link>
            <guid>46122851</guid>
            <pubDate>Tue, 02 Dec 2025 16:23:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist">https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist</a>, See on <a href="https://news.ycombinator.com/item?id=46122851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content"><section id="ch-0"><p>It has been widely reported that the US tech billionaire Peter Thiel recently gave a series of <a href="https://www.theguardian.com/us-news/2025/oct/10/peter-thiel-lectures-antichrist">rambling lectures</a> to a private audience in San Francisco in which he laid out his apocalyptic reading of world politics. These lectures mark the culmination of two years of Thiel traveling the world speaking at Catholic universities, at international conferences, and on right-wing podcasts about how the Antichrist threatens global order.</p>
<p>While Thiel’s discourse may <a href="https://www.nytimes.com/2025/07/11/podcasts/interesting-times-a-mind-bending-conversation-with-peter-thiel.html">lack clarity and coherence</a>, it is still profoundly significant in view of the political and economic power concentrated in his hands. Yet perhaps more important still is what Thiel’s comments on the Antichrist tell us about the convergence of Christian apocalypticism, the tech sector’s economic dominance, and US imperialism.</p>
<p>While some have associated Thiel’s vision with what they refer to as “<a href="https://www.theguardian.com/us-news/ng-interactive/2025/apr/13/end-times-fascism-far-right-trump-musk">end-times fascism</a>,” it is more useful to characterize what he advances as an apocalyptic geopolitics — a simplified remapping of global politics onto the spiritual coordinates of salvation and damnation. Thiel’s apocalyptic geopolitics seeks to overcome internal social contradictions by projecting them onto an external evil, at once foreign and metaphysical.</p>
<p>This justifies the most extreme violence against his opponents while protecting his own views from contestation. Thiel’s world is a battlefield of moral absolutes rather than a terrain of political complexity where different interests and values are contested and negotiated.</p>
</section><section id="ch-1"><h2>Thiel and the Reactionary Right</h2><p>Thiel has long been associated with the reactionary right in the United States, establishing hyperlibertarian projects like the <a href="https://thereader.mitpress.mit.edu/the-extinction-loop/">Seasteading Institute</a>, funding the far-right <a href="https://jacobin.com/2021/12/gop-republicans-far-right-economic-populism">National Conservative movement,</a> and supporting the work of reactionary intellectuals like <a href="https://www.newyorker.com/magazine/2025/06/09/curtis-yarvin-profile">Curtis Yarvin,</a> guru of the “<a href="https://www.e-flux.com/journal/81/125815/on-the-unhappy-consciousness-of-neoreactionaries">Dark Enlightenment</a>.” He also donated generously to Donald Trump’s 2016 election campaign and bankrolled J. D. Vance’s successful bid for a Senate seat in Ohio.</p>

<p>In short, Thiel, like his friend and fellow tech billionaire Elon Musk, occupies a position of immense power at the center of US and global politics and is using his wealth to influence elections and secure lucrative government contracts. In so doing, Thiel is locating his business empire, particularly Palantir, at the heart of two major growth areas in otherwise sluggish Western economies: AI and the military-tech nexus.</p>
<p>It is the depth of his political penetration that makes Thiel’s pronouncements on the Antichrist worthy of scrutiny, no matter how perplexing and perverse they might appear. Thiel’s idiosyncratic apocalyptic geopolitics draws heavily on obscure elements of the infamous Nazi legal theorist Carl Schmitt’s work. Schmitt argued that behind the material struggles of worldly geopolitics lay a metaphysical battle between the<em> Antichrist</em> and the <em>Katechon</em>, or “restrainer,” who would hold the Antichrist at bay, deferring the apocalypse.</p>
<p>Schmitt’s katechon was represented by forces that resisted global government and universalist ideologies. As such, he cast his own preference for a multipolar world order dominated by continental empires as a means to restrain the Antichrist and fend off the apocalypse.</p>
<p>Like Schmitt before him, Thiel recasts geopolitics as Revelation. The globe is divided between katechontic space, specifically the libertarian frontier of Silicon Valley backed by the United States as restrainer, and a global network of bureaucratic overreach doing the work of the Antichrist.</p>
<p>This worldview presents the secular institutions of modernity as apocalyptic agents, while capital and technology are redemptive forces. The Antichrist operates in Thiel’s apocalyptic geopolitics as a cipher through which he places questions of taxation, multilateralism, economic regulation, and environmental governance on a spiritual battlefield, removing them from democratic challenge and diplomatic deliberation.</p>
</section><section id="ch-2"><h2>The United States: Antichrist or Katechon?</h2><p>The United States occupies a paradoxical position in Thiel’s apocalyptic geopolitics, as both self-interested nation and aspirational world sovereign, free-market champion and regulator-in-chief, savior and destroyer. This type of self-contradiction is typical of apocalyptic thought, which collapses binary divisions into a single eschatological horizon.</p>

<p>In one of his recent San Francisco <a href="https://www.theguardian.com/us-news/2025/oct/10/peter-thiel-lectures-antichrist">lectures</a>, Thiel explicitly identifies the United States as both Katechon and Antichrist: “ground zero of the one-world state, ground zero of the resistance to the one-world state.” This ambivalence mirrors the paradox of American empire, where the United States sees itself simultaneously as a guarantor of global order and a bulwark against world government: the “world’s policeman” unbound by international law.</p>
<p>Schmitt was deeply concerned with the “disordering” impact of new advances in military technology, pointing to the rapidly increasing destructive powers of new weapons across the twentieth century, from aerial bombing and submarines to nuclear weapons and the possibility of war in space. Thiel by contrast is profiting from the use of AI weapons targeting systems used in the Ukraine war and the genocide in Gaza.</p>
<p>Indeed, this is where the stakes of Thiel’s eccentric apocalypticism come into focus. Thiel fuses the emerging “<a href="https://www.intereconomics.eu/contents/year/2025/number/2/article/big-tech-and-the-us-digital-military-industrial-complex.html">digital-military-industrial complex</a>” with Christian eschatology, and this has real and malign influence on the lives of many across the world. It is hardly plausible to maintain that Thiel’s apocalyptic geopolitics and his business interests are wholly distinct, not only because he explicitly links them in his public statements but also because they align so neatly together.</p>
<p>For evidence we can look at just one of Thiel’s ventures. Palantir is a data analytics company whose tools have been purchased by government agencies in the US and beyond for the purpose of facial recognition, predictive policing, and military targeting.</p>
<p>In 2023, Palantir was <a href="https://www.theguardian.com/society/2023/nov/21/patient-privacy-fears-us-spy-tech-firm-palantir-wins-nhs-contract">awarded</a> a £330 million data contract by Britain’s National Health Service, the largest data contract in the organization’s history. Thiel declared the NHS a “<a href="https://www.theguardian.com/technology/2023/nov/21/palantir-peter-thiel-nhs-natural-target-outspoken-tech-billionaire">natural target</a>” for privatization, suggesting it needed to “start over” and be subject to “market mechanisms.” In practice, Palantir is not in the business of saving lives but rather that of extinguishing them.</p>
<p>In September the British military <a href="https://www.gov.uk/government/news/new-strategic-partnership-to-unlock-billions-and-boost-military-ai-and-innovation">announced</a> a “strategic partnership” worth £1.5 billion with Palantir to “develop AI-powered capabilities already tested in Ukraine to speed up decision making, military planning and targeting.” According to the Ministry of Defence, Thiel’s firm and its new partner “will work together to transform lethality on the battlefield” with AI-powered data analytics.</p>
<p><strong>Palantir’s complicity in Israel’s genocide in Gaza gives a sense of what ‘transformed lethality’ looks like.</strong></p>
<p>Palantir’s complicity in Israel’s genocide in Gaza gives a sense of what “transformed lethality” looks like. The Israeli military has been employing Palantir’s Lavender and Gospel systems to generate targets for aerial bombing, as detailed in a recent <a href="https://www.theguardian.com/world/2025/jul/03/global-firms-profiting-israel-genocide-gaza-united-nations-rapporteur">report</a> by Francesca Albanese, the UN Special Rapporteur on the Occupied Palestinian Territories.</p>
<p>When not exporting the technologies of state violence to Palestine and Ukraine, Palantir is profiting from them within the United States. The now notorious Immigration and Customs Enforcement (ICE) agency employs a purposefully designed data platform known as <a href="https://www.theguardian.com/us-news/ng-interactive/2025/sep/22/ice-palantir-data">ImmigrationOS</a> to identify suspected illegal immigrants for arrest and deportation.</p>
<p>Evidence of widespread racial profiling and the illegal detention and deportation of immigrants as well as US citizens is mounting. Under the new Trump administration, a beefed-up ICE is in effect a racist secret police operating in a lawless “state of exception” worthy of Schmitt.</p>
<p>In each case, we see data technologies harnessed for racialized state violence to extend the imperial power of the US and its allies. This is what Thiel’s apocalyptic geopolitics looks like in practice: a twisted military-industrial eschatology where an AI-powered genocide is understood to be “restraining” rather than enacting the end of the world.</p>
</section><section id="ch-3"><h2>End-Time</h2><p>Thiel’s apocalyptic geopolitics delegitimizes international law, legitimizes violence against racialized others, and sanctifies elite tech wealth as a last bulwark against a coming apocalypse. By remapping material power structures onto a metaphysical struggle, Thiel mystifies US imperialism, class privilege, and his own corporate interests as divine vocation.</p>
<p>His Armageddon is not so much a prophecy of world’s end as a rhetoric to legitimize the sovereignty of technocapitalist elites against the moral claims of the global majority and the planetary commons. Nor is the one-world government he fears a coherent political project; it is rather a condensation of reactionary anxieties about perceived loss of sovereignty, moral relativism, and technological democratization.</p>
<p>By fusing Silicon Valley’s myth of progress with apocalyptic visions of salvation, Thiel transforms US imperial power and unrestrained technological expansion — now concentrated in the hands of a few billionaire CEOs — into the final rampart against what he imagines as a catastrophic global homogenization.</p>
<p>At a time of escalating geopolitical tensions, rapid militarization, and intensifying environmental volatility, with the far right on the rise across the world, the danger posed by imperialist, chauvinistic, and supremacist geopolitical visions such as those espoused by Thiel, and the murderous profane interests they serve, should be all too clear.</p>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is 2026 Next Year? (158 pts)]]></title>
            <link>https://www.google.com/search?q=is+2026+next+year&amp;oq=is+2026+next+year</link>
            <guid>46122071</guid>
            <pubDate>Tue, 02 Dec 2025 15:20:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.google.com/search?q=is+2026+next+year&#x26;oq=is+2026+next+year">https://www.google.com/search?q=is+2026+next+year&#x26;oq=is+2026+next+year</a>, See on <a href="https://news.ycombinator.com/item?id=46122071">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral 3 family of models released (721 pts)]]></title>
            <link>https://mistral.ai/news/mistral-3</link>
            <guid>46121889</guid>
            <pubDate>Tue, 02 Dec 2025 15:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/mistral-3">https://mistral.ai/news/mistral-3</a>, See on <a href="https://news.ycombinator.com/item?id=46121889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we announce Mistral 3, the next generation of Mistral models. Mistral 3 includes three state-of-the-art small, dense models (14B, 8B, and 3B) and Mistral Large 3 – our most capable model to date – a sparse mixture-of-experts trained with 41B active and 675B total parameters. All models are released under the Apache 2.0 license. Open-sourcing our models in a variety of compressed formats empowers the developer community and puts AI in people’s hands through distributed intelligence.</p>
<p dir="ltr">The Ministral models represent the best performance-to-cost ratio in their category. At the same time, Mistral Large 3 joins the ranks of frontier instruction-fine-tuned open-source models.</p>
<h2 dir="ltr">Mistral Large 3: A state-of-the-art open model</h2>
<p><img src="https://cms.mistral.ai/assets/98aeee04-e1c3-43b7-b90e-c51da84d5e56.png?width=1905&amp;height=1242" alt="Chart Base Models (1)"></p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/bdf27a12-76fd-4e62-be9b-938f14288a9a.png?width=1346&amp;height=1115" alt="3 Model Performance Comparison (instruct)"></p>
<p dir="ltr">Mistral Large 3 is one of the best permissive open weight models in the world, trained from scratch on 3000 of NVIDIA’s H200 GPUs. Mistral Large 3 is Mistral’s first mixture-of-experts model since the seminal Mixtral series, and represents a substantial step forward in pretraining at Mistral. After post-training, the model achieves parity with the best instruction-tuned open-weight models on the market on general prompts, while also demonstrating image understanding and best-in-class performance on multilingual conversations (i.e., non-English/Chinese).</p>
<p dir="ltr">Mistral Large 3 debuts at #2 in the OSS non-reasoning models category (#6 amongst OSS models overall) on the <a href="https://lmarena.ai/leaderboard/text">LMArena leaderboard</a>.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/4626af3d-7554-4d50-9c0e-041fe7111ece.png?width=1905&amp;height=1242" alt="Lm Arena Chart Ml3"></p>
<p dir="ltr">We release both the base and instruction fine-tuned versions of Mistral Large 3 under the Apache 2.0 license, providing a strong foundation for further customization across the enterprise and developer communities. A reasoning version is coming soon!&nbsp;</p>
<h3 dir="ltr">Mistral, NVIDIA, vLLM &amp; Red Hat join forces to deliver faster, more accessible Mistral 3</h3>
<p dir="ltr">Working in conjunction with vLLM and Red Hat, Mistral Large 3 is very accessible to the open-source community. We’re releasing a checkpoint in NVFP4 format, built with <a href="https://github.com/vllm-project/llm-compressor">llm-compressor</a>. This optimized checkpoint lets you run Mistral Large 3 efficiently on Blackwell NVL72 systems and on a single 8×A100 or 8×H100 node using <a href="https://github.com/vllm-project/vllm">vLLM</a>.</p>
<p dir="ltr">Delivering advanced open-source AI models requires broad optimization, achieved through a partnership with NVIDIA. All our new Mistral 3 models, from Large 3 to Ministral 3, were trained on NVIDIA Hopper GPUs to tap high-bandwidth HBM3e memory for frontier-scale workloads. NVIDIA’s extreme co-design approach brings hardware, software, and models together. NVIDIA engineers enabled efficient inference support for <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener">TensorRT-LLM</a> and <a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener">SGLang</a> for the complete Mistral 3 family, for efficient low-precision execution.</p>
<p dir="ltr">For Large 3’s sparse MoE architecture, NVIDIA integrated state-of-the-art Blackwell attention and MoE kernels, added support for prefill/decode disaggregated serving, and collaborated with Mistral on speculative decoding, enabling developers to efficiently serve long-context, high-throughput workloads on GB200 NVL72 and beyond. On the edge, delivers optimized deployments of the Ministral models on <a href="http://nvidia.com/en-us/products/workstations/dgx-spark/">DGX Spark</a>, <a href="https://www.nvidia.com/en-us/ai-on-rtx/">RTX PCs and laptops</a>, and <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">Jetson devices</a>, giving developers a consistent, high-performance path to run these open models from data center to robot.</p>
<p dir="ltr">We are very thankful for the collaboration and want to thank vLLM, Red Hat, and NVIDIA in particular.</p>
<h2 dir="ltr">Ministral 3: State-of-the-art intelligence at the edge</h2>
<p><img src="https://cms.mistral.ai/assets/ea1fcc83-5bad-400e-b63a-35c8a8c0bf9c.png?width=1726&amp;height=1062" alt="4 Gpqa Diamond Accuracy"></p>
<p dir="ltr">For edge and local use cases, we release the Ministral 3 series, available in three model sizes: 3B, 8B, and 14B parameters. Furthermore, for each model size, we release base, instruct, and reasoning variants to the community, each with image understanding capabilities, all under the Apache 2.0 license. When married with the models’ native multimodal and multilingual capabilities, the Ministral 3 family offers a model for all enterprise or developer needs.</p>
<p dir="ltr">Furthermore, Ministral 3 achieves the best cost-to-performance ratio of any OSS model. In real-world use cases, both the number of generated tokens and model size matter equally. The Ministral instruct models match or exceed the performance of comparable models while often producing an order of magnitude fewer tokens.&nbsp;</p>
<p dir="ltr">For settings where accuracy is the only concern, the Ministral reasoning variants can think longer to produce state-of-the-art accuracy amongst their weight class - for instance 85% on AIME ‘25 with our 14B variant.</p>



<h2 dir="ltr">Available Today</h2>
<p dir="ltr">Mistral 3 is available today on <a href="https://console.mistral.ai/home">Mistral AI Studio</a>, Amazon Bedrock, Azure Foundry, Hugging Face (<a href="https://huggingface.co/collections/mistralai/mistral-large-3">Large 3</a> &amp; <a href="https://huggingface.co/collections/mistralai/ministral-3">Ministral</a>), <a href="https://modal.com/docs/examples/ministral3_inference">Modal</a>, IBM WatsonX, OpenRouter, Fireworks, <a href="https://docs.unsloth.ai/new/ministral-3" target="_blank" rel="noopener">Unsloth AI</a>, and Together AI. In addition, coming soon on NVIDIA NIM and AWS SageMaker.</p>
<h3 dir="ltr">One more thing… customization with Mistral AI</h3>
<p dir="ltr">For organizations seeking tailored AI solutions, Mistral AI offers&nbsp;<a href="https://mistral.ai/solutions/custom-model-training">custom model training services</a> to fine-tune or fully adapt our models to your specific needs. Whether optimizing for domain-specific tasks, enhancing performance on proprietary datasets, or deploying models in unique environments, our team collaborates with you to build AI systems that align with your goals. For enterprise-grade deployments, custom training ensures your AI solution delivers maximum impact securely, efficiently, and at scale.</p>
<h3 dir="ltr">Get started with Mistral 3</h3>
<p dir="ltr">The future of AI is open. Mistral 3 redefines what’s possible with a family of models built for frontier intelligence, multimodal flexibility, and unmatched customization. Whether you’re deploying edge-optimized solutions with Ministral 3 or pushing the boundaries of reasoning with Mistral Large 3, this release puts state-of-the-art AI directly into your hands.</p>
<h3 dir="ltr">Why Mistral 3?</h3>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Frontier performance, open access: Achieve closed-source-level results with the transparency and control of open-source models.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Multimodal and multilingual: Build applications that understand text, images, and complex logic across 40+ native languages.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Scalable efficiency: From 3B to 675B active parameters, choose the model that fits your needs, from edge devices to enterprise workflows.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Agentic and adaptable: Deploy for coding, creative collaboration, document analysis, or tool-use workflows with precision.</p>
</li>
</ul>
<h3 dir="ltr">Next Steps</h3>
<ol>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Explore the model documentation:&nbsp;</p>
</li>
<ul>
<li dir="ltr" aria-level="2">
<p dir="ltr" role="presentation"><a href="https://docs.mistral.ai/models/ministral-3-3b-25-12">Ministral 3 3B-25-12</a></p>
</li>
<li dir="ltr" aria-level="2">
<p dir="ltr" role="presentation"><a href="https://docs.mistral.ai/models/ministral-3-8b-25-12">Ministral 3 8B-25-12</a></p>
</li>
<li dir="ltr" aria-level="2">
<p dir="ltr" role="presentation"><a href="https://docs.mistral.ai/models/ministral-3-14b-25-12">Ministral 3 14B-25-12</a></p>
</li>
<li dir="ltr" aria-level="2">
<p dir="ltr" role="presentation"><a href="https://docs.mistral.ai/models/mistral-large-3-25-12">Mistral Large 3</a></p>
</li>
</ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Technical documentation for customers is available on our <a href="https://legal.mistral.ai/" target="_blank" rel="noopener">AI Governance Hub</a></p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Start building: <a href="https://huggingface.co/collections/mistralai/ministral-3">Ministral 3</a> and <a href="https://huggingface.co/collections/mistralai/mistral-large-3">Large 3</a> on Hugging Face, or deploy via <a href="https://console.mistral.ai/home">Mistral AI’s platform</a> for instant API access and <a href="https://mistral.ai/pricing#api-pricing">API pricing</a></p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Customize for your needs: Need a tailored solution? <a href="https://mistral.ai/contact">Contact our team</a> to explore fine-tuning or enterprise-grade training.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Share your projects, questions, or breakthroughs with us: <a href="https://x.com/MistralAI">Twitter/X</a>, <a href="https://discord.com/invite/mistralai">Discord</a>, or <a href="https://github.com/mistralai">GitHub</a>.</p>
</li>
</ol>
<p dir="ltr">Science has always thrived on openness and shared discovery. As pioneering French scientist and two-time Nobel laureate Marie Skłodowska-Curie once said, “Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less.”&nbsp;</p>
<p dir="ltr">This philosophy drives our mission at Mistral AI. We believe that the future of AI should be built on transparency, accessibility, and collective progress. With this release, we invite the world to explore, build, and innovate with us, unlocking new possibilities in reasoning, efficiency, and real-world applications.</p>
<p dir="ltr"><strong>Together, let’s turn understanding into action.</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI declares 'code red' as Google catches up in AI race (568 pts)]]></title>
            <link>https://www.theverge.com/news/836212/openai-code-red-chatgpt</link>
            <guid>46121870</guid>
            <pubDate>Tue, 02 Dec 2025 15:00:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/836212/openai-code-red-chatgpt">https://www.theverge.com/news/836212/openai-code-red-chatgpt</a>, See on <a href="https://news.ycombinator.com/item?id=46121870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/robert-hart"><img alt="Robert Hart" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/ROB_H_BLURPLE.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/ROB_H_BLURPLE.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/ROB_H_BLURPLE.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6NzY5ODkx"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Robert Hart</span></span></span></p> <p><span>is a London-based reporter at <em>The Verge</em> covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for <em>Forbes</em>.</span></p></div></div><div id="zephr-anchor"><p>The tides are turning in the AI race, and the pressure is getting to OpenAI. Chief executive Sam Altman reportedly declared a “code red” on Monday, urging staff to improve its flagship product ChatGPT, an indicator that the startup’s once-unassailable lead is eroding as competitors like Google and Anthropic close in.</p><p>In the memo, reported by the <a href="https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6?mod=rss_Technology"><em>Wall Street Journal</em> </a>and <a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort"><em>The Information</em></a>, Altman said the company will be delaying initiatives like ads, shopping and health agents, and a personal assistant, Pulse, to focus on improving ChatGPT. This includes core features like greater speed and reliability, better personalization, and the ability to answer more questions, he said.</p><p>There will be a daily call for those tasked with improving the chatbot, the memo said, and Altman encouraged temporary team transfers to speed up development.</p><p>The newfound urgency illustrates an inflection point for OpenAI as it spends hundreds of billions of dollars to fund growth and figures out a path to future profitability. It is also something of a full-circle moment in the AI race. Google, which <a href="https://www.theverge.com/2023/5/12/23721037/google-ai-progress-search-docs-starline-video-calls">declared its own “code red”</a> after the arrival of ChatGPT, is a particular concern. Google’s AI user base is growing — helped by the success of popular tools like the <a href="https://www.theverge.com/report/826003/googles-nano-banana-pro-generates-excellent-conspiracy-fuel">Nano Banana image model</a> — and its latest<a href="https://www.theverge.com/report/827555/google-gemini-3-is-winning-the-ai-race-for-now"> AI model, Gemini 3</a>, blew past its competitors on many industry benchmarks and popular metrics.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6NzY5ODkx"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Robert Hart</span></span></span></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zig's new plan for asynchronous programs (256 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1046084/4c048ee008e1c70e/</link>
            <guid>46121539</guid>
            <pubDate>Tue, 02 Dec 2025 14:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1046084/4c048ee008e1c70e/">https://lwn.net/SubscriberLink/1046084/4c048ee008e1c70e/</a>, See on <a href="https://news.ycombinator.com/item?id=46121539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
The designers of the
<a href="https://ziglang.org/">
Zig programming language</a> have been working to find a
suitable design for asynchronous code for some time.
Zig is a carefully minimalist language, and its
<a href="https://ziglang.org/documentation/0.5.0/#Async-Functions">
initial design</a> for
asynchronous I/O did not fit well with its other
features. Now, the project has
<a href="https://zig.show/episodes/41/">
announced</a> (in a Zig SHOWTIME video) a new approach to asynchronous I/O that
promises to solve the
<a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">
function coloring</a> problem, and allows writing code that will execute
correctly using either synchronous or asynchronous I/O.
</p>

<p>
In many languages (including Python, JavaScript, and Rust), asynchronous code
uses special syntax. This can make it difficult to reuse code between
synchronous and asynchronous parts of a program, introducing a number of headaches for
library authors. Languages that don't make a syntactical distinction (such as
Haskell) essentially solve the problem by making everything asynchronous, which
typically requires the language's runtime to bake in ideas about how programs
are allowed to execute.
</p>

<p>
Neither of those options was deemed suitable for Zig. Its designers wanted to
find an approach that did not add too much complexity to the language, that
still permitted fine control over asynchronous operations, and that still made
it relatively painless to actually write high-performance event-driven I/O. The
new approach solves this by hiding asynchronous operations behind a new generic
interface,
<a href="https://ziglang.org/documentation/master/std/#std.Io">
<tt>Io</tt></a>.
</p>

<blockquote>
The staff here at LWN.net really appreciate the subscribers who make
our work possible. Is there a chance we could interest you in <a href="https://lwn.net/Promo/daroc2/claim">becoming one of them</a>?
</blockquote>
<p>
Any function that needs to perform an I/O operation will need to have access to
an instance of the interface. Typically, that is provided by passing the
instance to the function as a parameter, similar to Zig's
<a href="https://ziglang.org/documentation/master/std/#std.mem.Allocator">
<tt>Allocator</tt></a>
interface for memory allocation. The standard library will include two built-in
implementations of the interface: <tt>Io.Threaded</tt> and <tt>Io.Evented</tt>.
The former uses synchronous
operations except where explicitly asked to run things in parallel (with a
special function; see below), in which
case it uses threads. The latter (which is still a work-in-progress) uses an
event loop and asynchronous I/O. Nothing in the design prevents a Zig programmer
from implementing their own version, however, so Zig's users retain their fine
control over how their programs execute.
</p>

<p>
Loris Cro, one of Zig's community organizers,
wrote <a href="https://kristoff.it/blog/zig-new-async-io/">
an explanation</a> of the new behavior to justify the approach.
Synchronous code is not much changed,
other than using the standard library functions that have moved under
<tt>Io</tt>, he explained. Functions like the example below, which don't involve explicit
asynchronicity, will continue to work. This example creates a file, sets the
file to close at the end of the function, and then writes a buffer of data to
the file. It uses Zig's <tt>try</tt> keyword to handle errors, and
<tt>defer</tt> to ensure the file is closed. The return type, <tt>!void</tt>,
indicates that it could return an error, but doesn't return any data:
</p>

<pre>    const std = @import("std");
    const Io = std.Io;

    fn saveFile(io: Io, data: []const u8, name: []const u8) !void {
        const file = try Io.Dir.cwd().createFile(io, name, .{});
        defer file.close(io);
        try file.writeAll(io, data);
    }
</pre>

<p>
If this function is given an instance of <tt>Io.Threaded</tt>, it will create
the file, write data to it, and then close it using ordinary system calls. If it
is given an instance of <tt>Io.Evented</tt>, it will instead use
<a href="https://man7.org/linux/man-pages/man7/io_uring.7.html">
io_uring</a>,
<a href="https://en.wikipedia.org/wiki/Kqueue">
kqueue</a>, or some other asynchronous backend suitable to the target operating
system. In doing so, it might pause the current execution and go work on a
different asynchronous function.
Either way, the operation is guaranteed to be complete by the time
<tt>writeAll()</tt> returns.
A library author writing a function that involves I/O doesn't need to
care about which of these things the ultimate user of the library chooses to do.
</p>

<p>
On the other hand, suppose that a program wanted to save two files. These
operations could profitably be done in parallel. If a library author wanted to
enable that, they could use the <tt>Io</tt> interface's <tt>async()</tt>
function to express that it does not matter which order the two files are saved in:
</p>

<pre>    fn saveData(io: Io, data: []const u8) !void {
        // Calls saveFile(io, data, "saveA.txt")
        var a_future = io.async(saveFile, .{io, data, "saveA.txt"});
        var b_future = io.async(saveFile, .{io, data, "saveB.txt"});

        const a_result = a_future.await(io);
        const b_result = b_future.await(io);

        try a_result;
        try b_result;

        const out: Io.File = .stdout();
        try out.writeAll(io, "save complete");
    }
</pre>

<p>
When using an <tt>Io.Threaded</tt> instance, the <tt>async()</tt> function
doesn't actually do anything asynchronously — it just runs the provided function
right away. So, with that version of the interface, the function first saves
file A and then file B. With an <tt>Io.Evented</tt> instance, the operations are
actually asynchronous, and the program can save both files at once.
</p>

<p>
The real advantage of this approach is that it turns asynchronous code into a
performance optimization. The first version of a program or library can write
normal straight-line code. Later, if asynchronicity proves to be useful for
performance, the author can come back and write it using asynchronous
operations. If the ultimate user of the function has not enabled asynchronous
execution, nothing changes. If they have, though, the function becomes faster
transparently — nothing about the function signature or how it interacts with
the rest of the code base changes.
</p>

<p>
One problem, however, is with programs where two parts are actually required to
execute simultaneously for correctness. For example, suppose that a program
wants to listen for connections on a port and simultaneously respond to user
input. In that scenario, it wouldn't be correct to wait for a connection and
only then ask for user input. For that use case, the <tt>Io</tt> interface
provides a separate function, <tt>asyncConcurrent()</tt> that explicitly asks for
the provided function to be run in parallel. <tt>Io.Threaded</tt> uses a thread
in a thread pool to accomplish this. <tt>Io.Evented</tt> treats it exactly the
same as a normal call to <tt>async()</tt>.
</p>

<pre>    const socket = try openServerSocket(io);
    var server = try io.asyncConcurrent(startAccepting, .{io, socket});
    defer server.cancel(io) catch {};

    try handleUserInput(io);
</pre>

<p>
If the programmer uses <tt>async()</tt> where they should have used
<tt>asyncConcurrent()</tt>, that is a bug. Zig's new model does not (and cannot)
prevent programmers from writing incorrect code, so there are still some
subtleties to keep in mind when adapting existing Zig code to use the new
interface.
</p>

<p>
The style of code that results from this design is a bit more verbose than
languages that give asynchronous functions special syntax, but Andrew Kelley,
creator of the language, <a href="https://ziglang.org/devlog/2025/#2025-10-15">said</a> that "<q>it reads
like standard, idiomatic Zig code.</q>" In particular, he noted that this
approach lets the programmer use all of Zig's typical control-flow primitives,
such as <tt>try</tt> and <tt>defer</tt>; it doesn't introduce any new language
features specific to asynchronous code.
</p>

<p>
To demonstrate this,
Kelley gave an example of using the new interface to implement asynchronous DNS
resolution. The standard
<a href="https://www.man7.org/linux/man-pages/man3/getaddrinfo.3.html">
<tt>getaddrinfo()</tt></a>
function for querying DNS information falls short because, although it makes
requests to multiple servers (for IPv4 and IPv6) in parallel, it waits for all of the queries to
complete before returning an answer. Kelley's example Zig code returns the first
successful answer, canceling the other inflight requests.
</p>

<p>
Asynchronous I/O in Zig is far from done, however. <tt>Io.Evented</tt> is still experimental, and
doesn't have implementations for all supported operating systems yet. A third
kind of <tt>Io</tt>, one that is compatible with WebAssembly, is
<a href="https://github.com/ziglang/zig/issues/23446">planned</a> (although, as
that issue details, implementing it depends on some other new language
features). The original
<a href="https://github.com/ziglang/zig/pull/25592">pull request for <tt>Io</tt></a> lists 24
planned follow-up items, most of which still need work.
</p>

<p>
Still, the overall design of asynchronous code in Zig appears to be set. Zig has
not yet had its 1.0 release, because the community is still experimenting with
the correct way to implement many features. Asynchronous I/O was one of the
larger remaining priorities (along with native code generation, which was also
enabled by default for debug builds on some architectures this year). Zig seems
to be steadily working its way toward a finished design — which should decrease
the number of times Zig programmers are asked to rewrite their I/O because the
interface has changed
<a href="https://ziglang.org/download/0.15.1/release-notes.html#Writergate">
again</a>.
</p><br clear="all">
               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proximity to coworkers increases long-run development, lowers short-term output (2023) (184 pts)]]></title>
            <link>https://pallais.scholars.harvard.edu/publications/power-proximity-coworkers-training-tomorrow-or-productivity-today</link>
            <guid>46121243</guid>
            <pubDate>Tue, 02 Dec 2025 14:01:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pallais.scholars.harvard.edu/publications/power-proximity-coworkers-training-tomorrow-or-productivity-today">https://pallais.scholars.harvard.edu/publications/power-proximity-coworkers-training-tomorrow-or-productivity-today</a>, See on <a href="https://news.ycombinator.com/item?id=46121243">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Amidst the rise of remote work, we ask: what are the effects of proximity to coworkers? We find being near coworkers has tradeoffs: proximity increases long-run human capital development at the expense of short-term output. We study software engineers at a Fortune 500 firm, whose main campus has two buildings several blocks apart. When offices were open, engineers working in the same building as all their teammates received 22 percent more online feedback than engineers with distant teammates. After offices closed for COVID-19, this advantage largely disappears. Yet sitting together reduces engineers' programming output, particularly for senior engineers. The tradeoffs from proximity are more acute for women, who both do more mentoring and receive more mentorship when near their coworkers. Proximity impacts career trajectories, dampening short-run pay raises but boosting them in the long run. These results can help to explain national trends: workers in their twenties who often need mentorship and workers over forty who often provide mentorship are more likely to return to the office. However, even if most mentors and mentees go into the office, remote work may reduce interaction: &nbsp;pre-COVID, having just one distant teammate reduced feedback among co-located workers.</p>

    <p>Amidst the rise of remote work, we ask: what are the effects of proximity to coworkers? We find being near coworkers has tradeoffs: proximity increases long-run human capital development at the expense of short-term output. We study software engineers at a Fortune 500 firm, whose main campus has two buildings several blocks apart. When offices were open, engineers working in the same building as all their teammates received 22 percent more online feedback than engineers with distant teammates. After offices closed for COVID-19, this advantage largely disappears. Yet sitting together reduces engineers' programming output, particularly for senior engineers. The tradeoffs from proximity are more acute for women, who both do more mentoring and receive more mentorship when near their coworkers. Proximity impacts career trajectories, dampening short-run pay raises but boosting them in the long run. These results can help to explain national trends: workers in their twenties who often need mentorship and workers over forty who often provide mentorship are more likely to return to the office. However, even if most mentors and mentees go into the office, remote work may reduce interaction: &nbsp;pre-COVID, having just one distant teammate reduced feedback among co-located workers.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python Data Science Handbook (251 pts)]]></title>
            <link>https://jakevdp.github.io/PythonDataScienceHandbook/</link>
            <guid>46120611</guid>
            <pubDate>Tue, 02 Dec 2025 12:38:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">https://jakevdp.github.io/PythonDataScienceHandbook/</a>, See on <a href="https://news.ycombinator.com/item?id=46120611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This website contains the full text of the <a href="http://shop.oreilly.com/product/0636920034919.do">Python Data Science Handbook</a> by Jake VanderPlas; the content is available <a href="https://github.com/jakevdp/PythonDataScienceHandbook">on GitHub</a> in the form of Jupyter notebooks.</p>
<p>The text is released under the <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">CC-BY-NC-ND license</a>, and code is released under the <a href="https://opensource.org/licenses/MIT">MIT license</a>.</p>
<p>If you find this content useful, please consider supporting the work by <a href="http://shop.oreilly.com/product/0636920034919.do">buying the book</a>!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A series of vignettes from my childhood and early career (157 pts)]]></title>
            <link>https://www.jasonscheirer.com/weblog/vignettes/</link>
            <guid>46120549</guid>
            <pubDate>Tue, 02 Dec 2025 12:28:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jasonscheirer.com/weblog/vignettes/">https://www.jasonscheirer.com/weblog/vignettes/</a>, See on <a href="https://news.ycombinator.com/item?id=46120549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<article>
			
			
				
			
			
			<div data-pagefind-body="">
				<p>A short set of anecdotes, apropos of nothing.</p>
<h2 id="the-death-of-software-engineering-as-a-profession">The Death of Software Engineering as a Profession</h2>
<p>When I was younger, I really liked programming! I loved the sense of accomplishment, I loved the problem solving, I loved sharing what I made with the people around me to both amuse and assist.</p>
<p>One particularly wise adult (somewhere around 1996) took me aside and said, “You know, you’re lucky you <em>enjoy</em> programming, because you won’t be able to make a living on it in the future. Doing it for love over money is a good idea.”</p>
<p>“Coding is over, with Object Oriented programming one person who is <em>much smarter than any of us could hope to be</em> will develop the library just <em>once</em> and we will all use it going forward, forever. Once a problem is solved it never needs solving again.</p>
<p>“In 5 years there’s going to be a library of objects, like books on a bookshelf, and every software problem will be solved by business people just snapping the object libraries they need together like LEGOs. They won’t need you at all.”</p>
<p>I thought about this advice, and how Software Engineering would be ending by the time I entered school. I realized I had not even thought about my education yet. I was in middle school. Programming was not it, though, I knew that.</p>
<p>I’m here nearly 30 years later and software continues to pay my bills, despite everything. Open source exists, there are libraries I can use to piece things together to solve all the time. New problem sets not covered by the garden path come up all the time. Clicking the LEGOs together continues to be a hard task. Every time we fix it at one level of abstraction we operate one level higher and the world keeps turning.</p>
<p>Whenever I’m threatened with a good time and someone proclaims “this is it for you” all that happens is my job becomes more annoying. Haven’t gotten the sweet release of extinction quite yet.</p>
<h2 id="the-time-computing-changed-forever-and-everyone-who-didnt-move-got-left-behind">The Time Computing Changed Forever and Everyone Who Didn’t Move Got Left Behind</h2>
<p>Around 1993 or so was the advent of the “Multimedia Age.” Multimedia was the buzzword. Software has to be <em>multimedia ready</em>. Education had to teach children to be ready for <em>the multimedia age</em>. If your tool, however inappropriate as it was, did not have multimedia features, you were going to be left behind. You <em>needed</em> a video guide. You <em>needed</em> to be on CD-ROM. This is just the new normal.</p>
<p>“Multimedia” just means “sound and video.” We had a high concept term for a very direct, low concept concept.</p>
<p>And the multimedia boom fizzled out. It became boring. Nobody is impressed by a video on a website and nobody thinks less of a website that doesn’t use sound and video if it’s not appropriate. You pop a <code>&lt;video /&gt;</code> tag in your HTML and your job is done. The amazing thing became mundane. The dream of “multimedia” became commonplace and everyone just accepted it as normal. I’m not aware of any industries that collapsed dramatically due to multimedia. Nobody really reskilled. Video editing is still a pretty rare thing to find, and we don’t commonly have sound engineers working on the audio UX of software products.</p>
<h2 id="the-death-of-software-engineering-as-a-profession-again">The Death of Software Engineering as a Profession: Again</h2>
<p>In 2000 a coworker took me aside and showed me his brand-new copy of IntelliJ IDE. “It’s over for us,” he said, “this thing makes it so programmers aren’t strictly necessary, like one person can operate this tool and they can lay the rest of us off.”</p>
<p>I was pretty awestruck, he got some amazing autocomplete right in the IDE. Without having to have a separate JavaDocs window open to the side, and without having to manually open the page for the class he needed documentation on, it just was there inline. It gave him feedback before the compile cycle on a bunch of issues that you normally don’t see until build. That was a nice bit of preventative work and seemed to have the potential to keep a developer in flow longer.</p>
<p>And then he showed me the killer feature “that’s going to get us all out of a job:” the refactoring tools.</p>
<p>He then proceeded to show me the tools, easily moving around code to new files, renaming classes across the codebase, all kinds of manual things that would have taken a person a few days to do on their own. It was magical.</p>
<p>After some thought I said, “that’s amazing, but does it write new logic too or does it just move code around?”</p>
<p>He didn’t seem fazed by that, and doubled down on the insistence that these powerful tools were our doom. I made a distinction between “useful” code and “filler” code, but apparently what is valued is not the quality and nature of the code but its volume and presence. This tool definitely gave both volume and presence to the tiny human-written nuggets within.</p>
<h2 id="that-time-i-automated-someone-out-of-a-job">That Time I Automated Someone Out of a Job</h2>
<p>At my first job in High School I was working in an office in a suburban office park with programmers from many different local agencies. One guy I chatted up was a contractor: these people were highly regarded, somewhat feared specialists. The guy in question was working on a multi-year migration of some county health computer system from <a href="https://en.wikipedia.org/wiki/MUMPS">MUMPS</a> to a more modern relational system. He showed me the main family of problems he was solving to show off how smart he was for solving them; they were largely rote problems of migrating table schemas and records in a pretty uniform way. But there were a lot of them, and he was working hard to meet his deadline!</p>
<p>I thought about it, and seeking his approval and validation, set out to help him. To show what I could do. I wrote a Python script that could solve the 85% case (it was mostly string manipulation) and even put a little TkInter dialog around it so he could select the files he wanted to migrate visually. It ran great, but he looked a little afraid when I demonstrated it to him:</p>
<p>“You didn’t show this to anyone else, did you?”</p>
<p>“Nope.”</p>
<p>“Oh thank God.”</p>
<p>I take it he used my tool because he had a lot more free time to goof off for the remaining six months of his contract. I don’t think he told anyone else what he had either, but I’m guessing that he had a lot more MUMPS migration contracts lined up when he could finish them in a matter of days.</p>
<h2 id="that-time-i-automated-myself-out-of-a-job">That Time I Automated Myself Out of a Job</h2>
<p>At the same job, I was paid to maintain a series of government agency web sites. One of my main tasks was to keep a list of mental health providers up-to-date on an HTML page and upload it to the server.</p>
<p>This process was pretty mechanical: take Excel sheet from inbox, open in Excel, copy Excel table to HTML table.</p>
<p>Within a month I had a fully automated workflow:</p>
<ul>
<li>I used Windows Automation to watch my Outlook inbox</li>
<li>When an email came in from the person who sent me the Excels it would download it</li>
<li>Open the Excel file in excel using Windows Automation</li>
<li>Export it to CSV from Excel (the automation did this, I simply watched a ghost remote control an Excel window that opened and closed itself)</li>
<li>Run a Python script that would inject that CSV data as an HTML table into the file</li>
<li>Run another Python script that would connect to the FTP server and upload the file. It would randomly pause and issue typos so it looked like the FTP session was being operated by a human at a keyboard so nobody thought anything on my plot.</li>
</ul>
<p>I lived in fear of being found out, and told no one that the thing I was getting paid to do was no longer being done by me.</p>
<p>About 9 months later the department in question hired a full-time web developer for $45k/yr to bring their website in-house. I was costing them about $25/hr, probably skating under $2000/yr for my outsourced services. This was clearly not about money.</p>
<p>And what I feared did not happen. When I no longer had that work to sustain me my managers just put me on something else.</p>
<p>There’s always more work.</p>
<h2 id="we-dont-engage-in-theft">We Don’t Engage in Theft</h2>
<p>In my last years of undergraduate education and my first couple of years out of college I worked on projects that did some sort of Natural Language Processing tasks. For these we required training data, and the more the better.</p>
<p>On that, though, we had responsibilities. We had to make sure the data we had also came with some sort of license or implicit permission. You didn’t just steal a pile of PDFs or scoop up a person’s web site and put it in your training set. There were ethical constrains, and legal consequences. You acted above-board when training your AI models.</p>
<p>There were times we’d train models on Wikipedia dumps. They were always comparatively <em>amazing</em> results when we trained on good, large data like that. Cogent. Interesting. Even a simple Markov chain on Wikipedia looked smart.</p>
<p>When we wrote web crawlers, we wrote them to respect <code>robots.txt</code>. We kept them on local domains. The <code>user-agent</code> field of the crawlers included our email address, and if an angry webmaster didn’t like the way we were crawling them we’d fix it. Getting crawled aggressively at once taxed servers and spammed logs so we’d space it out to hours or days. If their <code>robots.txt</code> was missing or malformed and they still didn’t want us there, we’d block the site from crawling.</p>
<p>We made sure we had explicit permission to collect data for our training corpora.</p>
<h2 id="the-time-computing-changed-forever-and-everyone-who-didnt-move-got-left-behind-again">The Time Computing Changed Forever and Everyone Who Didn’t Move Got Left Behind: Again</h2>
<p>The dot com boom was a crazy time. The internet has just become mainstream and there was a new gold rush. Money was there just for the taking, so many VC funded business plans were just “<em>traditional business X, but on the internet!</em>” and the money <em>flowed</em>. How it flowed.</p>
<p>Most of these companies, however, didn’t really have a solid business model other than buying some servers and a domain name and “we’ll put this thing on the internet.”</p>
<p>Out of this crash came green shoots: Web 2.0, which used the web natively, organically, gave a good web-native experience. Eventually the dream of the internet, the promise of the hype, was made manifest after a lot of people learned a lot of really unnecessary, really painful lessons. They spent less and put their things on the internet because they made sense on the internet of the present, not because the internet was the next big thing.</p>
<p>The dream of the widespread, ubiquitous internet came true, and there were very few fatalities. Some businesses died, but it was more glacial than volcanic in time scale. When ubiquitous online services became commonplace it just felt mundane. It didn’t feel forced. It was the opposite of the dot com boom just five years later: <em>the internet is here and we’re here to build a solid business within it</em> in contrast with <em>we should put this solid business on the internet somehow, because it’s coming</em>.</p>
<h2 id="closing">Closing</h2>
<p>This is indeed a set of passive-aggressive jabs on the continuing assault on our senses by the LLM hype lobby.</p>

			</div>
		</article>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Addressing the adding situation (248 pts)]]></title>
            <link>https://xania.org/202512/02-adding-integers</link>
            <guid>46120181</guid>
            <pubDate>Tue, 02 Dec 2025 11:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xania.org/202512/02-adding-integers">https://xania.org/202512/02-adding-integers</a>, See on <a href="https://news.ycombinator.com/item?id=46120181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        <p>Written by me, proof-read by an LLM.
<br>Details at end.</p>
<p><a href="https://xania.org/202512/01-xor-eax-eax">Yesterday</a> we saw how compilers zero registers efficiently. Today let’s look at something a tiny bit less trivial (though not by much): adding two integers. What do you think a simple x86 function to add two ints<sup id="fnref:abi"><a href="#fn:abi">1</a></sup> would look like? An <code>add</code>, right? Let’s take a look!</p>


<p>Probably not what you were thinking, right? x86 is unusual in mostly having a maximum of two operands per instruction<sup id="fnref:but"><a href="#fn:but">2</a></sup>. There’s no <code>add</code> instruction to add <code>edi</code> to <code>esi</code>, putting the result in <code>eax</code>. On an ARM machine this would be a simple <code>add r0, r0, r1</code> or similar, as ARM has a separate destination operand. On x86, things like <code>add</code> are not <code>result = lhs + rhs</code> but <code>lhs += rhs</code>. This can be a limitation, as we don’t get to control which register the result goes into, and we in fact lose the old value of <code>lhs</code>.</p>
<p>So how do compilers work around this limitation? The answer lies in an unexpected place - the sophisticated memory addressing system of the x86. Nearly every operand can be a memory reference - there’s no specific “load” or “store”; a <code>mov</code> can just refer to memory directly. Those memory references are pretty rich: you can refer to memory addressed by a constant, relative to a register, or relative to a register plus an offset (optionally multiplied by 1, 2, 4 or 8). Something like <code>add eax, word ptr [rdi + rsi * 4 + 0x1000]</code> is still a single instruction<sup id="fnref:cisc"><a href="#fn:cisc">3</a></sup>!</p>
<p>Sometimes you don’t want to <em>access</em> the memory at one of these complex addresses, you just want to calculate what the address would be. Sort of like C’s “address-of” (<code>&amp;</code>) operator. That’s what <code>lea</code> (<a href="https://www.felixcloutier.com/x86/lea">Load Effective Address</a>) does: it calculates the address without touching memory.</p>
<p>Why is this useful for addition? Well, if we’re not actually accessing memory, we can abuse the addressing hardware as a calculator! That complex addressing mode with its register-plus-register-times-scale is really just shifting and adding - so <code>lea</code> becomes a cheeky way to do three-operand addition<sup id="fnref:three"><a href="#fn:three">4</a></sup>.</p>
<p>The compiler writes our simple addition in terms of the address of memory at <code>rdi</code> offset by <code>rsi</code>. We get a full add of two registers <em>and</em> we get to specify the destination too. You’ll notice that the operands are referenced as <code>rdi</code> and <code>rsi</code> (the 64-bit version) even though we only wanted a 32-bit add: because we are using the memory addressing system it unconditionally calculates a 64-bit address. However, in this case it doesn’t matter; those top bits<sup id="fnref:zero"><a href="#fn:zero">5</a></sup> are discarded when the result is written to the 32-bit <code>eax</code>.</p>
<p>Using <code>lea</code> often saves an instruction, is useful if both of the operands are still needed later on in other calculations (as it leaves them unchanged), and can execute on x86’s <a href="https://mattgodbolt.github.io/ooo/#/0/1">multiple execution units</a> in the same cycle. Compilers know this though, so you don’t have to worry!</p>
<p><em>See <a href="https://youtu.be/BOvg0sGJnes">the video</a> that accompanies this post.</em></p>
<hr>
<p><em>This post is day 2 of <a href="https://xania.org/AoCO2025">Advent of Compiler Optimisations 2025</a>,
a 25-day series exploring how compilers transform our code.</em></p>
<p><em>This post was written by a human (<a href="https://xania.org/MattGodbolt">Matt Godbolt</a>) and reviewed and proof-read by LLMs and humans.</em></p>
<p><em>Support Compiler Explorer on <a href="https://patreon.com/c/mattgodbolt">Patreon</a>
or <a href="https://github.com/sponsors/compiler-explorer">GitHub</a>,
or by buying CE products in the <a href="https://shop.compiler-explorer.com/">Compiler Explorer Shop</a></em>.</p>

    </div><div>
                
                
                <p>Posted at 06:00:00 CST on 2<sup>nd</sup> December 2025.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Man unexpectedly cured of HIV after stem cell transplant (149 pts)]]></title>
            <link>https://www.newscientist.com/article/2506595-man-unexpectedly-cured-of-hiv-after-stem-cell-transplant/</link>
            <guid>46119699</guid>
            <pubDate>Tue, 02 Dec 2025 10:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newscientist.com/article/2506595-man-unexpectedly-cured-of-hiv-after-stem-cell-transplant/">https://www.newscientist.com/article/2506595-man-unexpectedly-cured-of-hiv-after-stem-cell-transplant/</a>, See on <a href="https://news.ycombinator.com/item?id=46119699">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-barrier="None">
                    <figure><p><img alt="HIV infected 293T cell." width="1350" height="900" src="https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg" srcset="https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=300 300w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=400 400w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=500 500w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=600 600w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=700 700w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=800 800w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=837 837w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=900 900w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1003 1003w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1100 1100w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1200 1200w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1300 1300w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1400 1400w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1500 1500w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1600 1600w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1674 1674w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1700 1700w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1800 1800w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=1900 1900w, https://images.newscientist.com/wp-content/uploads/2025/12/01140819/SEI_276363422.jpg?width=2006 2006w" sizes="(min-width: 1288px) 837px, (min-width: 1024px) calc(57.5vw + 55px), (min-width: 415px) calc(100vw - 40px), calc(70vw + 74px)" loading="eager" fetchpriority="high" data-image-context="Article" data-image-id="2506579" data-caption="An HIV-infected human cell" data-credit="STEVE GSCHMEISSNER/SCIENCE PHOTO LIBRARY"></p><figcaption><div><p>An HIV-infected human cell</p><p>STEVE GSCHMEISSNER/SCIENCE PHOTO LIBRARY</p></div></figcaption></figure>
<p>A man has become the seventh person to be left HIV-free after receiving a stem cell transplant to treat blood cancer. Significantly, he is also the second of the seven who received stem cells that were not actually resistant to the virus, strengthening the case that HIV-resistant cells may not be necessary for an HIV cure.</p>
<p>“Seeing that a cure is possible without this resistance gives us more options for curing HIV,” says <a href="https://www.gaebler-lab.com/">Christian Gaebler</a> at the Free University of Berlin.</p>
<p>Five people have previously become <a href="https://www.newscientist.com/article/2360130-third-person-cured-of-hiv-after-receiving-stem-cell-cancer-treatment/">free of HIV</a> after receiving stem cells from donors who carried a mutation in both copies of a gene encoding a protein called CCR5, which HIV uses to infect immune cells. This led scientists to conclude that having two copies of the mutation, which completely removes CCR5 from immune cells, was crucial for curing HIV. “The belief was that using these HIV-resistant stem cells was essential,” says Gaebler.</p>
    
<p>But last year a sixth person – known as the “Geneva patient” – was <a href="https://www.nature.com/articles/s41591-024-03277-z">declared free of the virus</a> for more than two years after receiving stem cells without the CCR5 mutation, suggesting CCR5 isn’t the whole story – although many scientists think the roughly two-year virus-free period isn’t quite long enough to show they were actually cured, says Gaebler.</p>
<p>The latest case strengthens the idea that the Geneva patient has been cured. It involves a man who, in October 2015, received stem cells to treat leukaemia, a type of blood cancer where immune cells grow uncontrollably. The man, who was aged 51 at the time, had HIV. During his treatment, he was given chemotherapy to destroy the vast majority of his immune cells, making room for the donor stem cells to produce a healthy immune system.</p><span></span>
<p>Ideally, the man would have received HIV-resistant stem cells, but these weren’t available, so doctors used cells that carried one typical and one mutated copy of the CCR5 gene. At the time, the man was taking a standard HIV therapy called antiretroviral therapy (ART), a combination of drugs that suppress the virus to undetectable levels, meaning it can’t be passed on to other people – and reducing the risk that the donor cells would be infected.</p>
<p>But about three years after the transplant, he chose to stop taking ART. “He felt that he’d waited some time after the stem cell transplant, he was in remission for the cancer, and he was always feeling that the transplant would work,” says Gaebler.</p>
<p>Shortly after, the team found no signs of the virus in blood samples from the man. He has since remained free of the virus for seven years and three months, enough for him to be considered “cured”. He has had no detectable HIV in his body for the second longest period of the seven people declared free of the virus – with the longest case being HIV-free for about 12 years. “It’s amazing that 10 years ago his chances of dying of cancer were extremely high and now he’s overcome this deadly diagnosis, a persistent viral infection and he’s not taking any medications – he’s healthy,” says Gaebler.</p>
    
<p>The discovery upends our understanding of what’s required for curing HIV via this approach. “We thought you needed to transplant from donors that lack CCR5 – it turns out that you don’t,” says <a href="https://www.immunology.cam.ac.uk/staff/professor-ravindra-gupta">Ravindra Gupta</a> at the University of Cambridge, who wasn’t involved in the study.</p>
<p>Scientists have generally thought that such cures relied on any virus lurking in the recipient’s remaining immune cells – following chemotherapy – being unable to infect the donor cells, meaning it can’t replicate. “Essentially, the pool of host cells to infect runs dry,” says Gaebler.</p>
<p>But the latest case suggests that, instead, cures can be achieved as long as non-resistant donor cells are able to destroy any of the patient’s remaining original immune cells before the virus can spread to them, speculates Gaebler. Such immune reactions are often driven by differences in the proteins displayed on the two sets of cells. These make the donor cells recognise residual recipient cells as a threat to eliminate, says Gaebler.</p>
<p>The findings suggest that a wider pool of stem cell transplants than we thought – including those without two copies of the CCR5 mutation – could potentially cure HIV, says Gaebler.</p>
<p>But it is likely that many factors, such as the recipient’s and donor’s genetics, need to align in order for this to work, so that, for instance, the donor’s cells can rapidly destroy the recipient’s. What’s more, in the latest case, the man carried one copy of the CCR5 mutation, which could have altered how his immune cells were spread across the body in a way that made it easier to cure him of the virus, says Gaebler.</p>
    
<p>This means that most people receiving stem cell transplants for HIV and blood cancer should be offered HIV-resistant stem cells where possible, says Gaebler.</p>
<p>It’s also important to point out that cancer-free people with HIV won’t benefit from stem cell transplants, as it’s a very risky procedure that can lead to life-threatening infections, says Gaebler. Most people are better off taking ART – often in the form of daily pills – which is a much safer and convenient way to <a href="https://www.newscientist.com/article/2187205-we-have-all-we-need-to-beat-the-hiv-epidemic-except-political-will/">stop HIV from spreading</a>, enabling people to enjoy long and healthy lives, he says. Moreover, a recently available drug called lenacapavir provides <a href="https://www.who.int/news/item/14-07-2025-who-recommends-injectable-lenacapavir-for-hiv-prevention">nearly complete protection against HIV with just two injections per year</a>.</p>
<p>Nonetheless, efforts are being made to cure HIV by <a href="https://www.newscientist.com/article/2423108-crispr-could-disable-and-cure-hiv-suggests-promising-lab-experiment/">genetically editing immune cells</a>, and <a href="https://www.newscientist.com/article/2490444-human-trials-point-the-way-towards-an-mrna-vaccine-against-hiv/">prevent it using vaccines</a>.</p>


                    <section data-component-name="article-topics"><p>Topics:</p></section>                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advent of Compiler Optimisations 2025 (347 pts)]]></title>
            <link>https://xania.org/202511/advent-of-compiler-optimisation</link>
            <guid>46119500</guid>
            <pubDate>Tue, 02 Dec 2025 09:51:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xania.org/202511/advent-of-compiler-optimisation">https://xania.org/202511/advent-of-compiler-optimisation</a>, See on <a href="https://news.ycombinator.com/item?id=46119500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        <p>Today I’m announcing a project that’s been in the making for around a year. As my time off draws to a close, I’ve been working on an “Advent of” type project, to be released one a day from the 1st of December until the 25th.</p>
<p>This December will be the Advent of Compiler Optimisations: I’ll release one blog post and video each day, each detailing a fun and interesting C or C++ optimisation that your compiler can do. I’ll go into the details of when it applies, how to interpret the assembly, and perhaps as importantly, when it doesn’t apply.</p>
<p>I’ll be covering some very low-level, architecture-specific tricks as well as larger, more high-level optimisations. While I mostly cover x86-64, I do touch on 64-bit and 32-bit ARM as well.</p>
<p>You can follow along by watching the <a href="https://xania.org/AoCO2025">AoCO2025 tag</a> on this blog, subscribing to me on <a href="https://www.youtube.com/mattgodbolt">YouTube</a>, or following the <a href="https://youtube.com/playlist?list=PL2HVqYf7If8cY4wLk7JUQ2f0JXY_xMQm2&amp;si=rEu5UQ2EuNafCvii">YouTube playlist</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/j-BwR-Cw0Gk?si=GeHCTsWqkQ5DzSp_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>It’s been a colossal amount of work, but a lot of fun too. I hope you enjoy learning how amazing compilers are as much as I do!</p>
<p>See you on the first of December!</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparing AWS Lambda ARM64 vs. x86_64 Performance Across Runtimes in Late 2025 (113 pts)]]></title>
            <link>https://chrisebert.net/comparing-aws-lambda-arm64-vs-x86_64-performance-across-multiple-runtimes-in-late-2025/</link>
            <guid>46119214</guid>
            <pubDate>Tue, 02 Dec 2025 09:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrisebert.net/comparing-aws-lambda-arm64-vs-x86_64-performance-across-multiple-runtimes-in-late-2025/">https://chrisebert.net/comparing-aws-lambda-arm64-vs-x86_64-performance-across-multiple-runtimes-in-late-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46119214">Hacker News</a></p>
Couldn't get https://chrisebert.net/comparing-aws-lambda-arm64-vs-x86_64-performance-across-multiple-runtimes-in-late-2025/: Error: getaddrinfo ENOTFOUND chrisebert.net]]></description>
        </item>
        <item>
            <title><![CDATA[How Brian Eno Created Ambient 1: Music for Airports (2019) (180 pts)]]></title>
            <link>https://reverbmachine.com/blog/deconstructing-brian-eno-music-for-airports/</link>
            <guid>46118722</guid>
            <pubDate>Tue, 02 Dec 2025 07:46:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reverbmachine.com/blog/deconstructing-brian-eno-music-for-airports/">https://reverbmachine.com/blog/deconstructing-brian-eno-music-for-airports/</a>, See on <a href="https://news.ycombinator.com/item?id=46118722">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="c758c2f" data-element_type="container">
				<div data-id="a0fe206" data-element_type="widget" data-widget_type="text-editor.default">
									<p>Brian Eno’s <em>Ambient 1: Music for Airports</em>&nbsp;is a landmark album in ambient and electronic music. Although it wasn’t the first ambient album, it was the first album to be explicitly labelled as ‘ambient music’.</p><p><em>Music for Airports</em> was released in 1979, though some sources cite 1978 due to its copyright date. It marked a continuation of Eno’s experimentation with the tape machine as a compositional tool, a process he’d begun four years prior with 1975’s <i>Discreet Music</i>.</p><p><em>Music for Airports</em>&nbsp;also saw Eno’s further exploration of generative, systems-created music, whereby Eno would focus on creating a system that would generate ambient music, something he continues to explore in the modern age with his range of iOS apps.</p><p>In this article, I’ll discuss how <em>Music for Airports</em> was created, and I’ll deconstruct and recreate the tracks <em>2/1</em> and <em>1/2</em>. Hopefully, the article will demystify some of Brian Eno’s techniques, and give you some ideas about how to adopt some of his ambient music techniques yourself.</p>								</div>
				<p data-id="fe9612f" data-element_type="widget" data-widget_type="heading.default">
					<h2>Brian Eno &amp; Ambient Music</h2>				</p>
				<div data-id="6e9e084" data-element_type="widget" data-widget_type="text-editor.default">
									<p>Brian Eno’s experiments with tape loops go as far back as 1973’s <i>(No Pussyfooting)</i>, a collaborative album with King Crimson guitarist Robert Fripp. For the recording of <i>(No Pussyfooting)</i>, Eno employed an early experiment in sound-on-sound tape looping, where he would run Robert Fripp’s guitar into two tape machines, that were then fed back into each other.&nbsp;</p><p>Fripp’s guitar melodies were recorded and then bounced back and forth between the two tape machines, creating long, fading delays that would build up to create a dense soundscape. The length of the delay was controlled by the physical distance between the two machines.</p>								</div>
				
				<div data-id="af5fc9f" data-element_type="widget" data-widget_type="text-editor.default">
									<p>Brian Eno’s tape experimentations continued with <em>Discreet Music</em> in 1975. The album’s 30-minute long title track was composed by sequencing his EMS Synthi AKS synth and recording it into a similar dual tape machine system, with the simple musical phrases repeating over a long period of time. This system utilised an EQ and delay effect before the tape machines, allowing Eno to subtly change the sounds in real-time.</p><p><i>Discreet Music</i>&nbsp;uses two separate loops, one of 63 seconds duration and another of 68 seconds duration. Eno found that using two loops of different lengths created a phasing effect where every repeat would produce different variations as the two loops interlocked in different ways. <a href="https://reverbmachine.com/blog/deconstructing-brian-enos-discreet-music/">I wrote a separate article going more in-depth on the recording of <i>Discreet Music</i>, available here</a>.</p>								</div>
				
				<p data-id="879a1de" data-element_type="widget" data-widget_type="heading.default">
					<h3>Recording <i>Music for Airports</i></h3>				</p>
				<div data-id="79a73f7" data-element_type="widget" data-widget_type="text-editor.default">
									<p><em>Music for Airports</em> was released in 1979, though Brian Eno <a href="https://www.telegraph.co.uk/music/artists/how-brian-eno-created-a-quiet-revolution-in-music/" target="_blank" rel="noopener">started working on it while working on David Bowie’s&nbsp;<em>Low</em></a>, in 1976. Part of it was recorded at the recording studio of Conny Plank, a legendary Krautrock producer, where he started by recording single notes sung by a trio of female singers, which he would later loop via tape machines. At a 1996 talk, <a href="https://inmotionmagazine.com/eno1.html" target="_blank" rel="noopener">Eno described the recording of <em>Music for Airports</em></a>:</p><blockquote><p><em>Music for Airports, at least one of the pieces on there, is structurally very, very simple. There are sung notes, sung by three women and myself. One of the notes repeats every 23 1/2 seconds. It is in fact a long loop running around a series of tubular aluminum chairs in Conny Plank’s studio. The next lowest loop repeats every 25 7/8 seconds or something like that. The third one every 29 15/16 seconds or something. What I mean is they all repeat in cycles that are called incommensurable — they are not likely to come back into sync again.</em></p></blockquote><p>Eno had previously recorded <em>Before and After Science </em>and <em>Cluster &amp; Eno&nbsp;</em>at Conny Plank’s studio, and would go on to record Devo’s <em>Q. Are We Not Men? A: We Are Devo! </em>there too.</p>								</div>
				
				<div data-id="d0c6120" data-element_type="widget" data-widget_type="text-editor.default">
									<p>To compose the music of&nbsp;<em>Music for Airports</em>, Brian Eno’s experiments focused on using small recordings of music – sustained notes or 3-4 note phrases – and looping them at different rates, determined by the length of tape they are recorded on. The difference in tape lengths between loops&nbsp;would cause them to intersect in interesting ways; on each repeat, new phrases and variations on existing themes would emerge. <a href="http://music.hyperreal.org/artists/brian_eno/interviews/unk-78b.html" target="_blank" rel="noopener">Eno himself puts it best</a>:</p><blockquote><p><em>“The particular piece I’m referring to was done by using a whole series of very long tape loops, like fifty, sixty, seventy feet long. There were twenty-two loops. One loop had just one piano note on it. Another one would have two piano notes. Another one would have a group of girls singing one note, sustaining it for ten seconds. There are eight loops of girls’ voices and about fourteen loops of piano.&nbsp;</em></p><p><em>I just set all of these loops running and let them configure in whichever way they wanted to, and in fact the result is very, very nice. The interesting thing is that it doesn’t sound at all mechanical or mathematical as you would imagine. It sounds like some guy is sitting there playing the piano with quite intense feeling. The spacing and dynamics of “his” playing sound very well organized. That was an example of hardly interfering at all.</em>“</p></blockquote>								</div>
				<p data-id="63d5a72" data-element_type="widget" data-widget_type="heading.default">
					<h3>Graphic Score</h3>				</p>
				<p><em>Music for Airports</em> liner notes contain a graphic score designed by Brian Eno himself. Not a trained musician, and unable to read or write sheet music, he instead used graphic symbols to denote each musical phrase or loop. Look closely and you can see individual symbols on each row, each spaced apart differently, reflecting the recording technique used to craft the album.</p>
				<p><img loading="lazy" decoding="async" width="800" height="605" src="https://media.reverbmachine.com/2020/08/Eno-Graphic-Score.jpg" alt="Brian Eno Music for Airports" srcset="https://media.reverbmachine.com/2020/08/Eno-Graphic-Score.jpg 1000w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-300x227.jpg 300w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-600x454.jpg 600w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-768x581.jpg 768w" sizes="(max-width: 800px) 100vw, 800px" title="How Brian Eno Created <em>Ambient 1: Music for Airports</em> 4" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAAJdAQAAAADiwC5uAAAAAnRSTlMAAHaTzTgAAABRSURBVHja7cEBDQAAAMIg+6e2xwcMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKDq7rEAAWeE4vEAAAAASUVORK5CYII=" data-src="https://media.reverbmachine.com/2020/08/Eno-Graphic-Score.jpg" data-srcset="https://media.reverbmachine.com/2020/08/Eno-Graphic-Score.jpg 1000w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-300x227.jpg 300w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-600x454.jpg 600w, https://media.reverbmachine.com/2020/08/Eno-Graphic-Score-768x581.jpg 768w">															</p>
				<p>Brian Eno also designed the cover art for <em>Music for Airports</em>, as well the rest of the ambient series: <em>Ambient 2: The Plateaux of Mirror</em> with Harold Budd, <em>Ambient 3: Day of Radiance</em> with Laraaji and <em>Ambient 4: On Land</em>, each of which has map-like covers.</p>
				<p><img loading="lazy" decoding="async" width="768" height="768" src="https://media.reverbmachine.com/2019/07/ambient-music-maps-768x768.jpeg" alt="ambient music maps" srcset="https://media.reverbmachine.com/2019/07/ambient-music-maps-768x768.jpeg 768w, https://media.reverbmachine.com/2019/07/ambient-music-maps-300x300.jpeg 300w, https://media.reverbmachine.com/2019/07/ambient-music-maps-1024x1024.jpeg 1024w, https://media.reverbmachine.com/2019/07/ambient-music-maps-150x150.jpeg 150w, https://media.reverbmachine.com/2019/07/ambient-music-maps-1536x1536.jpeg 1536w, https://media.reverbmachine.com/2019/07/ambient-music-maps-700x700.jpeg 700w, https://media.reverbmachine.com/2019/07/ambient-music-maps-600x600.jpeg 600w, https://media.reverbmachine.com/2019/07/ambient-music-maps-100x100.jpeg 100w, https://media.reverbmachine.com/2019/07/ambient-music-maps.jpeg 2018w" sizes="(max-width: 768px) 100vw, 768px" title="How Brian Eno Created <em>Ambient 1: Music for Airports</em> 5" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAwAAAAMAAQAAAAC7+j0jAAAAAnRSTlMAAHaTzTgAAABfSURBVHja7cEBDQAAAMKg909tDjegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvg0jDwABnonulgAAAABJRU5ErkJggg==" data-src="https://media.reverbmachine.com/2019/07/ambient-music-maps-768x768.jpeg" data-srcset="https://media.reverbmachine.com/2019/07/ambient-music-maps-768x768.jpeg 768w, https://media.reverbmachine.com/2019/07/ambient-music-maps-300x300.jpeg 300w, https://media.reverbmachine.com/2019/07/ambient-music-maps-1024x1024.jpeg 1024w, https://media.reverbmachine.com/2019/07/ambient-music-maps-150x150.jpeg 150w, https://media.reverbmachine.com/2019/07/ambient-music-maps-1536x1536.jpeg 1536w, https://media.reverbmachine.com/2019/07/ambient-music-maps-700x700.jpeg 700w, https://media.reverbmachine.com/2019/07/ambient-music-maps-600x600.jpeg 600w, https://media.reverbmachine.com/2019/07/ambient-music-maps-100x100.jpeg 100w, https://media.reverbmachine.com/2019/07/ambient-music-maps.jpeg 2018w">															</p>
				</div><div data-id="02ee22a" data-element_type="container">
				
				<p data-id="6553870" data-element_type="widget" data-widget_type="heading.default">
					<h2>Deconstructing <em>1/1</em></h2>				</p>
				<p><img loading="lazy" decoding="async" width="800" height="132" src="https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-1024x169.png" alt="Eno Graphic Score 1 1" srcset="https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-1024x169.png 1024w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-300x49.png 300w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-768x126.png 768w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-600x99.png 600w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1.png 1403w" sizes="(max-width: 800px) 100vw, 800px" title="How Brian Eno Created <em>Ambient 1: Music for Airports</em> 6" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAACpAQAAAACdOnIbAAAAAnRSTlMAAHaTzTgAAAAsSURBVHja7cExAQAAAMKg9U9tDB+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAzgZVKQABZT67cwAAAABJRU5ErkJggg==" data-src="https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-1024x169.png" data-srcset="https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-1024x169.png 1024w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-300x49.png 300w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-768x126.png 768w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1-600x99.png 600w, https://media.reverbmachine.com/2019/07/Eno-Graphic-Score-1-1.png 1403w">															</p>
				<div data-id="bfa78c1" data-element_type="widget" data-widget_type="text-editor.default">
									<p>The first track on <em>Music for Airports</em> is <em>1/1</em>, which features a serene sounding piano melody interspersed with ethereal textures. <em>1/1</em> has been used in the films <em>9½ Weeks</em> and <em>The Lovely Bones</em>.</p><p>The piano in <em>1/1</em> was performed by Robert Wyatt, a prog rock musician who started as the drummer in Soft Machine before pursuing a solo career. The piano recording has been run through an echo unit, looped and then slowed down, a process that Eno would have done by manually joining two ends of a reel of tape, and then playing it back on a reel-to-reel machine at half speed. Slowing down a tape machine causes the pitch of the musical content to drop, with half-speed causing a drop of an octave.</p><p>The piano loop in <em>1/1</em> features interplay between a traditional piano and a Rhodes electric piano. Here is the loop, and then the isolated piano and rhodes parts, it may have sounded at the original speed, before being reverb’d and slowed:</p>								</div>
				
				<p>Once slowed down, the texture of the instruments change, becoming bassy and less defined. The echo effect gets smeared and stretched, creating an unreal ambience that is emblematic of the sound of <em>Music for Airports</em>. And this was some 45 years before the popularity of <em>reverb and slowed</em> versions on YouTube were a thing.</p>
				
				<div data-id="55ee20c" data-element_type="widget" data-widget_type="text-editor.default">
									<p>The performance is mostly in the key of D major, with the Rhodes piano holding down D bass notes throughout. However, the final Rhodes phrase contains a C natural note, leading the music into modal D mixolydian territory.</p><p>Mixolydian is a mode, or scale, that contains the same notes as the major scale with one difference: it has a minor 7th instead of a major 7th. The Mixolydian mode has a more ambiguous sound than major, as it features a major 3rd and a minor 7th. The sound is still major, but with a less ‘sweet’ sound than in D major. The use of the Mixolydian mode is another facet that gives <em>1/1</em> it’s restful, relaxing sound; it sounds emotionally ambiguous.</p>								</div>
				<p><img loading="lazy" decoding="async" width="1536" height="975" src="https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1536x975.png" alt="brian eno airports sheet music" srcset="https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1536x975.png 1536w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-300x190.png 300w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1024x650.png 1024w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-768x488.png 768w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-2048x1300.png 2048w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-600x381.png 600w" sizes="(max-width: 1536px) 100vw, 1536px" title="How Brian Eno Created <em>Ambient 1: Music for Airports</em> 7" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABgAAAAPPAQAAAAAqEz0AAAAAAnRSTlMAAHaTzTgAAADNSURBVHja7cExAQAAAMKg9U9tCj+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Gt8tAAGxBL2vAAAAAElFTkSuQmCC" data-src="https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1536x975.png" data-srcset="https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1536x975.png 1536w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-300x190.png 300w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-1024x650.png 1024w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-768x488.png 768w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-2048x1300.png 2048w, https://media.reverbmachine.com/2019/07/brian-eno-airports-sheet-music-600x381.png 600w">															</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rootless Pings in Rust (111 pts)]]></title>
            <link>https://bou.ke/blog/rust-ping/</link>
            <guid>46118432</guid>
            <pubDate>Tue, 02 Dec 2025 07:01:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bou.ke/blog/rust-ping/">https://bou.ke/blog/rust-ping/</a>, See on <a href="https://news.ycombinator.com/item?id=46118432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p>Sending a <a href="https://en.wikipedia.org/wiki/Ping_(networking_utility)" target="_blank">ping</a> by creating an ICMP socket normally requires root: you can’t create a raw socket to send ICMP packets without it. The <code>ping</code> command line tool works without root however, how is that possible? It turns out you can create a UDP socket with a protocol flag, which allows you to send the ping rootless. I couldn’t find any simple examples of this online and LLMs are surprisingly bad at this (probably because of the lack of examples). Therefore I posted <a href="https://github.com/bouk/rust-ping-example" target="_blank">an example</a> on GitHub in Rust. The gist of it is this:</p>

<h2 id="1-create-a-udp-socket-with-icmp-protocol">1. Create a UDP socket with ICMP protocol</h2>

<p>Using the <a href="https://crates.io/crates/socket2" target="_blank">socket2</a> crate.</p>

<div><pre><code><span>use</span> <span>socket2</span><span>::{</span><span>Domain</span><span>,</span> <span>Protocol</span><span>,</span> <span>Socket</span><span>,</span> <span>Type</span><span>};</span>
<span>use</span> <span>std</span><span>::</span><span>net</span><span>::</span><span>UdpSocket</span><span>;</span>

<span>let</span> <span>socket</span> <span>=</span> <span>Socket</span><span>::</span><span>new</span><span>(</span><span>Domain</span><span>::</span><span>IPV4</span><span>,</span> <span>Type</span><span>::</span><span>DGRAM</span><span>,</span> <span>Some</span><span>(</span><span>Protocol</span><span>::</span><span>ICMPV4</span><span>))</span><span>?</span><span>;</span>
<span>let</span> <span>socket</span><span>:</span> <span>UdpSocket</span> <span>=</span> <span>socket</span><span>.into</span><span>();</span>
</code></pre></div>

<h2 id="2-create-and-send-the-ping-packet">2. Create and send the ping packet</h2>

<p>Note that you don’t need to provide an IP header and that Linux and macOS behave differently here: the Linux kernel overrides the identifier and checksum fields, while macOS <em>does</em> use them and the checksum needs to be correct.</p>

<div><pre><code><span>let</span> <span>sequence</span><span>:</span> <span>u16</span> <span>=</span> <span>1</span><span>;</span>
<span>let</span> <span>mut</span> <span>packet</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span> <span>=</span> <span>vec!</span><span>[</span>
	<span>8</span><span>,</span> <span>// type: echo request</span>
	<span>0</span><span>,</span> <span>// code: always 0 for echo request</span>
	<span>0</span><span>,</span> <span>0</span><span>,</span> <span>// checksum: calculated by kernel on Linux, required on macOS</span>
	<span>0</span><span>,</span> <span>1</span><span>,</span> <span>// identifier: overwritten by kernel on Linux, not on macOS</span>
	<span>(</span><span>sequence</span> <span>&gt;&gt;</span> <span>8</span><span>)</span> <span>as</span> <span>u8</span><span>,</span> <span>(</span><span>sequence</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>as</span> <span>u8</span><span>,</span>
	<span>b</span><span>'h'</span><span>,</span> <span>b</span><span>'e'</span><span>,</span> <span>b</span><span>'l'</span><span>,</span> <span>b</span><span>'l'</span><span>,</span> <span>b</span><span>'o'</span><span>,</span> <span>// payload (can be anything)</span>
<span>];</span>

<span>// Checksum is determined by the kernel on Linux, but it's needed on macOS</span>
<span>let</span> <span>checksum</span> <span>=</span> <span>calculate_checksum</span><span>(</span><span>&amp;</span><span>packet</span><span>);</span>
<span>packet</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>(</span><span>checksum</span> <span>&gt;&gt;</span> <span>8</span><span>)</span> <span>as</span> <span>u8</span><span>;</span>
<span>packet</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>checksum</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>as</span> <span>u8</span><span>;</span>

<span>// Port can be anything, doesn't matter</span>
<span>socket</span><span>.send_to</span><span>(</span><span>&amp;</span><span>packet</span><span>,</span> <span>"1.1.1.1:0"</span><span>)</span><span>?</span><span>;</span>
</code></pre></div>

<h2 id="3-receive-and-interpret-the-response">3. Receive and interpret the response</h2>

<p>Here macOS and Linux are different again: macOS includes the IP header in the response, Linux does not.</p>

<div><pre><code><span>let</span> <span>mut</span> <span>buffer</span> <span>=</span> <span>vec!</span><span>[</span><span>0u8</span><span>;</span> <span>64</span><span>];</span>
<span>let</span> <span>(</span><span>size</span><span>,</span> <span>from_addr</span><span>)</span> <span>=</span> <span>socket</span><span>.recv_from</span><span>(</span><span>&amp;</span><span>mut</span> <span>buffer</span><span>)</span><span>?</span><span>;</span>

<span>// On macOS, the IP header is included in the received packet, strip it</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"macos"</span><span>)]</span>
<span>const</span> <span>IP_HEADER_LEN</span><span>:</span> <span>usize</span> <span>=</span> <span>20</span><span>;</span>

<span>// On Linux, the IP header is not included</span>
<span>#[cfg(not(target_os</span> <span>=</span> <span>"macos"</span><span>))]</span>
<span>const</span> <span>IP_HEADER_LEN</span><span>:</span> <span>usize</span> <span>=</span> <span>0</span><span>;</span>

<span>let</span> <span>data</span> <span>=</span> <span>&amp;</span><span>buffer</span><span>[</span><span>IP_HEADER_LEN</span><span>..</span><span>size</span><span>];</span>
<span>let</span> <span>reply_type</span> <span>=</span> <span>data</span><span>[</span><span>0</span><span>];</span> <span>// should be 0</span>
<span>let</span> <span>reply_sequence</span> <span>=</span> <span>((</span><span>data</span><span>[</span><span>6</span><span>]</span> <span>as</span> <span>u16</span><span>)</span> <span>&lt;&lt;</span> <span>8</span><span>)</span> <span>|</span> <span>(</span><span>data</span><span>[</span><span>7</span><span>]</span> <span>as</span> <span>u16</span><span>);</span> <span>// should equal 'sequence'</span>
<span>let</span> <span>payload</span> <span>=</span> <span>&amp;</span><span>data</span><span>[</span><span>8</span><span>..</span><span>];</span> <span>// should be b"hello"</span>
</code></pre></div>

<p>Of course you can implement latency, loss, periodic pings etc. but that’s left as an exercise to the reader.</p>

  <p><span>Nov 2025</span></p>
</div></div>]]></description>
        </item>
    </channel>
</rss>