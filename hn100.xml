<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 14 Feb 2024 19:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Only real people can patent inventions – not AI – US Government says (131 pts)]]></title>
            <link>https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html</link>
            <guid>39370681</guid>
            <pubDate>Wed, 14 Feb 2024 15:14:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html">https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39370681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskox92m0027knpc3sdueh25@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Artificial intelligence promises to supercharge scientific research and entrepreneurial innovation, helping researchers and inventors make new discoveries and creations.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoyej6000n3b5wrwmlm496@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But how will patent protections apply to inventions made with the help of AI tools, particularly generative AI?
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800023b5wx4p50iy7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            For the first time, the US government has provided an answer, one that will shape how everyone from large businesses to home tinkerers alike can apply for intellectual property protections.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800033b5waf0szdj8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The decision could influence the future of billions of dollars in investments and subtly guide how artificial intelligence is marketed and used.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800043b5wmn1q8cqy@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            On Tuesday, the US Patent and Trademark Office (USPTO) said that to obtain a patent, a real person must have made a “significant contribution” to the invention and that only a human being can be named as an inventor on a patent.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800053b5wgvqshzfh@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The official guidance <a href="https://www.federalregister.gov/documents/2024/02/13/2024-02623/inventorship-guidance-for-ai-assisted-inventions" target="_blank">published this week</a> provides a boost to innovators by reassuring them that their inventions involving AI can be patented, while continuing to enshrine human creativity and ingenuity by establishing basic expectations about how AI could make or break a patent application.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800063b5wm5cclk70@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The guidelines reflect the Biden administration’s swift moves to get ahead of artificial intelligence issues. In a sweeping <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" target="_blank">executive order</a> last fall, the White House had directed the USPTO to issue its inventorship guidelines by the end of February.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800073b5wmfnc8avm@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Precisely what constitutes a “significant contribution” is a little bit fuzzy and case-specific, and much of how the guidelines work will necessarily be figured out in real-time as they are applied and, perhaps in some situations, debated in court.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800083b5wkfpk9739@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The challenge will be in implementing the guidance,” said Jamie Nafziger, an attorney at the law firm Dorsey &amp; Whitney. “How sophisticated of a prompt will be required for a given invention? In connection with training an AI system, what level of planning will be required?&nbsp;Patent examiners will surely have some interesting challenges ahead.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800093b5wol3fcbps@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Still, the overall picture the USPTO has painted is one where real people continue to sit at the center of the US patent system, in what experts describe as a logical extension of the status quo.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz8000a3b5wwzruw5al@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The USPTO has <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-mechanical.pdf" target="_blank">provided</a> some hypothetical <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-chemical.pdf" target="_blank">examples</a> of ways that its guidelines could work. For instance, an inventor who simply asks an AI chatbot to design a critical part for a remote-control car would not be eligible for a patent on the car, because he or she didn’t make enough of a contribution to the car’s invention. It was the AI that did the hard part, not the human.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz8000b3b5wc1l0l7tp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “A natural person who only presents a problem to an AI system may not be a proper inventor” of something, the USPTO <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-mechanical.pdf" target="_blank">said</a>. “However, a significant contribution could be shown by the way the person constructs the prompt in view of a specific problem to elicit a particular solution from the AI system.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000c3b5wq6habudr@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            If an inventor could show the work he or she did to get the AI chatbot to produce a specific design that enabled the remote-control car to function, then that could open the door to a patent, according to the USPTO.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000d3b5w5t4mrvnb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The USPTO guidance builds on existing case law. A federal appeals court already held last year, in a case known as <a href="https://cafc.uscourts.gov/opinions-orders/21-2347.OPINION.8-5-2022_1988142.pdf" target="_blank"><em>Thaler v. Vidal</em></a>,  that only actual people can be listed as inventors on US patents, effectively ruling out the possibility for AI to be named as an inventor or co-inventor.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000e3b5wbrvmlw67@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In that case, the USPTO had rejected the patent applications of an inventor who had given his AI system sole credit for the inventions.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clslxupqq00003b6hkbrvot1l@published" data-name="GettyImages-483223701.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6665" data-original-height="1333" data-original-width="2000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?c=original" data-editable="settings">
       <picture><source height="1333" width="2000" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1110,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1015,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1160,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1110,c_fill" alt="A man walks through the public search facility at the U.S. Patent and Trademark Office (USPTO) headquarters in Alexandria, Virginia, U.S., on Friday, April 4, 2014." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1333" width="2000" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000f3b5w8578l5bg@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The&nbsp;inventorship guidelines will help everyone understand the boundaries of patent protections as AI is increasingly used in the inventive process. That may resolve some of the uncertainties that could otherwise slow the development and use of AI, said Randy McCarthy, an attorney at the law firm Hall Estill.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000g3b5wubu01697@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            It’s also consistent with how the US Copyright Office is approaching copyright protections in relation to AI, McCarthy added.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000h3b5wbhu8qavp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Some sort of human agency is required, or no protection is available,” he said. “A practical result is that, when creating a new design, artwork, invention, novel, or even computer code, a human can use an AI-based system to assist in the creation of this content, but must make sure that they are sufficiently involved in the process.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000i3b5wdzn1fceo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            At the same time, the USPTO guidelines don’t require inventors to disclose the use of AI, and some worry it could encourage so-called patent trolls to apply for broad patents that don’t lead to any actual creations but serve as the&nbsp;foundation for bogus patent lawsuits.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000j3b5wjp1711md@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The economy already is harmed by a surplus of low-quality patents which leads to unproductive litigation, rent-seeking and transfers of wealth from productive businesses to those who are experts at navigating the legal system,” said John Bergmayer, legal director at the consumer advocacy group Public Knowledge.&nbsp;“My worry would be that AI-assisted “inventions” [where the involvement of AI might be concealed] or just AI-assisted patent applications supercharges this.”
    </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Your AI Girlfriend Is a Data-Harvesting Horror Show (123 pts)]]></title>
            <link>https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284</link>
            <guid>39370235</guid>
            <pubDate>Wed, 14 Feb 2024 14:38:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284">https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284</a>, See on <a href="https://news.ycombinator.com/item?id=39370235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Lonely on Valentine’s Day? AI can help. At least, that’s what a number of companies hawking “romantic” chatbots will tell you. But as your robot love story unfolds, there’s a tradeoff you may not realize you’re making. According to a new study from Mozilla’s *Privacy Not Included project, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240">AI girlfriends and boyfriends</a></span> harvest shockingly personal information, and almost all of them sell or share the data they collect. </p><div data-video-id="196019" data-monetizable="true" data-position="sidebar" data-video-title="Like It or Not, Your Doctor Will Use AI | AI Unlocked" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="209" data-playlist="196019,196111,195635" data-current="196019"><div><p>Like It or Not, Your Doctor Will Use AI | AI Unlocked</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/196019/196019_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/21541.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>“To be perfectly blunt, AI girlfriends and boyfriends are not your friends,” said Misha Rykov, a Mozilla Researcher, in a press statement. “Although they are marketed as something that will enhance your mental health and well-being, they specialize in delivering dependency, loneliness, and toxicity, all while prying as much data as possible from you.”</p><p>Mozilla dug into <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/&quot;,{&quot;metric25&quot;:1}]]" href="https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/" target="_blank" rel="noopener noreferrer">11 different AI romance chatbots</a></span>, including popular apps such as Replika, Chai, Romantic AI, EVA AI Chat Bot &amp; Soulmate, and CrushOn.AI. Every single one earned the Privacy Not Included label, putting these chatbots among the worst categories of products Mozilla has ever reviewed. The apps mentioned in this story didn’t immediately respond to requests for comment.</p><p>You’ve heard stories about data problems before, but according to Mozilla, AI girlfriends violate your privacy in “disturbing new ways.” For example, CrushOn.AI collects details including information about sexual health, use of medication, and gender-affirming care. 90% of the apps may sell or share user data for targeted ads and other purposes, and more than half won’t let you delete the data they collect. Security was also a problem. Only one app, Genesia AI Friend &amp; Partner, met Mozilla’s minimum security standards. </p><p>One of the more striking findings came when Mozilla counted the trackers in these apps, little bits of code that collect data and share them with other companies for advertising and other purposes. Mozilla found the AI girlfriend apps used an average of 2,663 trackers per minute, though that number was driven up by Romantic AI, which called a whopping 24,354 trackers in just one minute of using the app.</p><p>The privacy mess is even more troubling because the apps actively encourage you to share details that are far more personal than the kind of thing you might enter into a typical app. EVA AI Chat Bot &amp; Soulmate pushes users to “share all your secrets and desires,” and specifically asks for photos and voice recordings. It’s worth noting that EVA was the only chatbot that didn’t get dinged for how it uses that data, though the app did have security issues. </p><p>Data issues aside, the apps also made some questionable claims about what they’re good for. EVA AI Chat Bot &amp; Soulmate bills itself as “a provider of software and content developed to improve your mood and well-being.” Romantic AI says it’s “here to maintain your MENTAL HEALTH.” When you read the company’s terms and services though, they go out of their way to distance themselves from their own claims. Romantic AI’s policies, for example, say it is “neither a provider of healthcare or medical Service nor providing medical care, mental health Service, or other professional Service.”</p><p>That’s probably important legal ground to cover, given these app’s history. Replika reportedly encouraged a man’s attempt to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625">assassinate the Queen of England</a></span>. A Chai chatbot allegedly <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says&quot;,{&quot;metric25&quot;:1}]]" href="https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says" target="_blank" rel="noopener noreferrer">encouraged a user to commit suicide</a></span>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tai chi reduces blood pressure better than aerobic exercise (108 pts)]]></title>
            <link>https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness</link>
            <guid>39370173</guid>
            <pubDate>Wed, 14 Feb 2024 14:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness">https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness</a>, See on <a href="https://news.ycombinator.com/item?id=39370173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primaryaudio">
      <article id="res1231438499" aria-label="audio-module"><div>
      <h4>Tai chi reduces blood pressure better than aerobic exercise, study finds</h4>
   

   
    
</div>
</article>
</div><div id="storytext">
      <div id="res1231265260">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Tai chi has many health benefits. It improves flexibility, reduces stress and can help lower blood pressure.
                <b aria-label="Image credit">
                    
                    Ruth Jenkinson/Getty Images/Science Photo Library
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Ruth Jenkinson/Getty Images/Science Photo Library
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Tai chi has many health benefits. It improves flexibility, reduces stress and can help lower blood pressure.</p>
        <p><span aria-label="Image credit">
            
            Ruth Jenkinson/Getty Images/Science Photo Library
            
        </span>
    </p></div>
   </div>
   <p>Tai chi, a traditional, slow-moving form of Chinese martial art, is known to increase flexibility and improve balance. Now, new research suggests it's better than more vigorous aerobic exercises for lowering blood pressure in people with prehypertension.</p>   <p>Prehypertension is blood pressure that's higher than normal but doesn't quite reach the level of high blood pressure, or hypertension. It's considered a warning sign that heart disease may be ahead, and it raises the risk of having a heart attack.</p>   <p>The new findings,<a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2814872"> published in the journal <em>JAMA Network Open</em></a>, add to a large body of research pointing to health benefits from tai chi, a wellness practice that combines slow, gentle movements and postures with mindfulness. It's often called meditation in motion.</p>   
   
   
<!-- END ID="RES1231265664" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>In the study, researchers in China randomly assigned 342 adults with prehypertension to one of two interventions. The average age of participants was 49. Roughly half the people participated in supervised aerobic exercise, including jogging, climbing stairs, brisk walking and cycling. The other half was trained to practice tai chi. Both groups got hourlong sessions four times a week.</p>   <p>After 12 months, those in the tai chi group saw bigger drops in their blood pressure than those in the aerobic exercise group. What's more, nearly 22% of the people who practiced tai chi saw their blood pressure fall to within normal range, compared with nearly 16% of people in the aerobic exercise group. And fewer patients in the tai chi group went on to develop hypertension than in the aerobic exercise group.</p>   <p>Previous research has found that<a href="https://pubmed.ncbi.nlm.nih.gov/30195124/"> tai chi is more effective than brisk walking</a> at lowering blood pressure, fasting blood sugar levels and perceived stress in people who have hypertension.</p>   <p>So what is it about tai chi that helps lower blood pressure? The practice tends to elicit more of a response from the parasympathetic nervous system, says<a href="https://www.nursing.arizona.edu/rpiliae"> Ruth Taylor-Piliae</a>, a professor at the University of Arizona's College of Nursing, who was not involved in the study. The <a href="https://my.clevelandclinic.org/health/body/23266-parasympathetic-nervous-system-psns">parasympathetic nervous system</a> is the network of nerves that relaxes your body after periods of stress or danger.</p>   
   <p>"It [tai chi] kind of helps to just relax everything, and I think it's that response that's working towards lowering blood pressure," says Taylor-Piliae, whose research focuses on how mind-body interventions such as tai chi can benefit older adults with cardiovascular disease. "I think it's the meditative quality of it."</p>   <p>She notes a large body of evidence has now shown the benefits of tai chi on blood pressure. The practice is appealing as a form of exercise because it is low impact and requires little space or equipment.</p>   <p>"I think the beauty of tai chi is that you don't have to have a special gym membership, you don't have to have special clothing," Taylor-Piliae says. "Once you learn tai chi, you can do it anytime, anyplace, anywhere. And it does kind of provide that calming, relaxing" effect.</p>   <p>Studies have also shown that practicing tai chi can help reduce the risk of<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10509476/"> falls, improve balance</a> and walking speed in older adults, and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9957102/#:~:text=Several%20trials%20have%20reported%20the,24%2C25%2C26%5D.">reduce depression and anxiety</a>. </p>   <p>Evidence suggests it can also help protect against cognitive decline and even <a href="https://www.npr.org/sections/health-shots/2023/11/06/1210507968/thai-chi-word-games-cognition-mentally-sharp-meditation-motion">boost memory</a>. But you have to practice it consistently to reap the most benefit.</p>   <p>"You have to have enough 'dose' of  tai chi," Taylor-Piliae says. "You can't just do it one hour, one time<em>."</em></p>   <p><em>This story was edited by Jane Greenhalgh.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We sped up time series by 20-30x (109 pts)]]></title>
            <link>https://www.rerun.io/blog/primary-query-caching</link>
            <guid>39369853</guid>
            <pubDate>Wed, 14 Feb 2024 14:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rerun.io/blog/primary-query-caching">https://www.rerun.io/blog/primary-query-caching</a>, See on <a href="https://news.ycombinator.com/item?id=39369853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><p>This is a follow up post to the post <a href="https://www.rerun.io/blog/fast-plots">Real-time kHz time series in a multimodal visualizer</a> that dives into how we managed to achieve such huge performance gains for time series (among other things), and why it was so hard in the first place.</p>
<p><img src="https://www.rerun.io/blog/1M_series_before_v_after.png" alt="Before and after graph of time taken to draw a 1M point time series in Rerun"></p>
<p><em>Comparison of time taken to draw a time series plot in Rerun with 1M points between version 0.12 and 0.13. The numbers come from profiling on a 2021 M1 MacBook Pro.</em></p>
<h2 id="flexible-multimodal-data-is-hard-to-combine-with-fast-plots">Flexible multimodal data is hard to combine with fast plots<!-- --> <a href="#flexible-multimodal-data-is-hard-to-combine-with-fast-plots"></a></h2>
<p>Ever since the first release of Rerun, plotting larger time series has been painfully slow.
<a href="https://github.com/rerun-io/rerun/releases/tag/0.13.0">0.13</a> is the first release where we think they're actually usable.
It’s worth taking a step back to explain why making plots fast in Rerun was hard, before getting into what we did about it.
To do that, we need some more background on how Rerun, the in-memory database, works.</p>
<h3 id="rerun-as-a-multimodal-time-series-database">Rerun as a multimodal time series database<!-- --> <a href="#rerun-as-a-multimodal-time-series-database"></a></h3>
<p>One way of looking at Rerun is as an in-memory multimodal time series database with visualization on top.</p>
<ul>
<li>You can throw many kinds of data at it, from simple metrics to big multi dimensional tensors, point clouds, and text documents.</li>
<li>Data is indexed along multiple user defined timelines, and can come in out of order.</li>
<li>The Rerun data model is a temporal Entity Component System (ECS) that allows updating single components at a time.</li>
</ul>
<p>Let's look at a small example of updating a colored point cloud in parts and out of order:</p>
<p><img src="https://www.rerun.io/blog/data-model-example.png" alt="Overview of Rerun's ECS updated out of order"></p>
<p>For any given time point, the datastore needs to be able to collect the latest components of any entity, and join them against the primary component (3D positions in this case). Queries run every time Rerun renders a frame, which should be 60 times per second.</p>
<p>Getting all this to be both correct and fast took considerable effort during the first year of Rerun. The combination of all these features is what makes Rerun so versatile and easy to use.</p>
<p><iframe src="https://player.vimeo.com/video/910960113?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<h3 id="overhead-from-flexibility-make-simple-time-series-the-worst-case">Overhead from flexibility make simple time series the worst case<!-- --> <a href="#overhead-from-flexibility-make-simple-time-series-the-worst-case"></a></h3>
<p>Flexibility comes at the cost of added overhead. That matters less for larger data, but dominates performance for small data like scalars. In Rerun, time series are created by querying the datastore for all scalars on an entity for a range of time.
Before 0.13, the worst case was therefore simple time series plots, since you'd have to pay all that overhead many times for very little data.</p>
<h2 id="speeding-up-time-series-by-a-factor-of-2030">Speeding up time series by a factor of 20-30<!-- --> <a href="#speeding-up-time-series-by-a-factor-of-2030"></a></h2>
<p>On Rerun 0.12, rendering a single frame of a 1M point time series plot takes ~600ms on a 2021 M1 MacBook Pro. On 0.13 it takes ~20ms, a 30x speedup. For smaller series the speedup tends to come closer to 20x, which is still huge. How did we get there?</p>
<h3 id="sources-of-overhead-in-time-series-plots">Sources of overhead in time series plots<!-- --> <a href="#sources-of-overhead-in-time-series-plots"></a></h3>
<p>Let’s sum up the main sources of overhead in producing data for and rendering a time series plot:</p>
<ol>
<li><strong>Bookkeeping</strong>: Keeping track of which components exist at each timestamp is relatively costly for small data.</li>
<li><strong>Data locality</strong>: For small data, the flexible data model (both in time and data type) bottoms out in a lack of data locality, which is bad for CPU cache efficiency.</li>
<li><strong>Redundant work</strong>: When plotting a moving time window, data is usually only changing at the edges of the window. Repeatedly running the full range query creates lots of redundant work.</li>
<li><strong>Rendering</strong>: For large time series, there may be more points than pixels to draw them on along the time dimension (x-axis). This leads to redundant tessellation and overdraw in the rendering pipeline.</li>
</ol>
<h3 id="why-we-didnt-just-special-case-metrics">Why we didn't just special case metrics<!-- --> <a href="#why-we-didnt-just-special-case-metrics"></a></h3>
<p>The easiest solution for speeding up time series plots would be to special case the path for metrics. A specialized code path for simple metrics would make huge gains relatively easy.</p>
<p>Unfortunately this isn’t good enough because our users need good performance for more kinds of range queries. Here is an example using time ranges to show an aggregate point cloud in a structure from motion setting:</p>
<p><iframe src="https://player.vimeo.com/video/910977084?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<p>In addition, our motivating example for kHz plots was <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit">IMU</a> samples, which usually come as messages containing multiple values to plot. That makes special casing the single metrics less useful. For example:</p>
<pre><p><code><span>typedef</span> <span>struct</span> <span>{</span>
    <span>float</span> acc<span>[</span><span>3</span><span>]</span><span>;</span>

    <span>float</span> gyro<span>[</span><span>3</span><span>]</span><span>;</span>  <span>// &lt;- Want to plot these as time series</span>
    
    <span>unsigned</span> <span>long</span> timestamp<span>;</span>
<span>}</span> IMUSample<span>;</span>
</code></p></pre>
<p>Rerun doesn’t yet support visualizing time series from single fields of larger structs directly, but we will soon and our approach needs to support this as a first class use-case.</p>
<h3 id="caching-is-difficult-but-necessary">Caching is difficult but necessary<!-- --> <a href="#caching-is-difficult-but-necessary"></a></h3>
<blockquote>
<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
<p>Phil Karlton</p>
</blockquote>
<p>The non-rendering sources of overhead just scream caching, but as usual the devil is in the details, in particular the details of cache invalidation. In our case, out of order insertions combined with composing multiple components over time make invalidation particularly gnarly.</p>
<h3 id="datastore-changelogs-make-invalidation-manageable">Datastore changelogs make invalidation manageable<!-- --> <a href="#datastore-changelogs-make-invalidation-manageable"></a></h3>
<p>Except for garbage collection (dropping old data to free up memory), the Rerun datastore is immutable. Data is always dropped through snapshotting so that query semantics are left unchanged. Every single change results in adding or removing rows to the store.</p>
<p>The first step we took after deciding it was time for caching was a refactor that turned every system that maintains a derived dataset in Rerun (timeline widget, view heuristics engine, etc) into a store subscriber, which listens to changelogs of added or removed rows in the datastore.</p>
<p>Cache invalidation is yet another store subscriber, and having this protocol in place is what made it manageable to deal with all the complexity.</p>
<h3 id="caches-are-built-lazily-at-query-time">Caches are built lazily at query time<!-- --> <a href="#caches-are-built-lazily-at-query-time"></a></h3>
<p>Cache invalidation only sets a dirty flag. Actually building the cache happens lazily at query time. Since Rerun uses an end to end immediate mode architecture, we query the datastore on every frame, ideally 60 times per second.</p>
<p>This acts as a natural micro-batching mechanism where we first accumulate changes while we render the current frame and then handle all these changes at the start of the next frame. Batching updates like this is great for performance.</p>
<p>Visible views query the datastore right before rendering. Building caches lazily therefore means we never spend time updating a cache that isn’t used.</p>
<h3 id="multitenancy-requires-fine-grained-locking">Multi-tenancy requires fine grained locking<!-- --> <a href="#multitenancy-requires-fine-grained-locking"></a></h3>
<p>When not on the web, each space view (draggable visualization panel) runs and queries the datastore in parallel. Many of these queries might overlap so we need to make sure to share data and cache resources appropriately.</p>
<p>Supporting this multi-tenancy requires fine grained locking on the combination of store (there are multiple), entity, set of components, and the component “point of view” (the component we join against).</p>
<h3 id="aggregating-subpixel-points-speeds-up-rendering">Aggregating sub-pixel points speeds up rendering<!-- --> <a href="#aggregating-subpixel-points-speeds-up-rendering"></a></h3>
<p>There are only so many pixels available to draw on along the x-axis. For large time series, that means you need to aggregate points that would show up on the same x-axis tick to avoid overdraw and redundant tessellation in the render pipeline.</p>
<p><iframe src="https://player.vimeo.com/video/910983296?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<p>We compute these aggregations on every frame and let users choose between a set of basic options.</p>
<h3 id="a-caveat-on-performance-for-out-of-order-logs">A caveat on performance for out of order logs<!-- --> <a href="#a-caveat-on-performance-for-out-of-order-logs"></a></h3>
<p>The speedups added in 0.13 slow down ingestion speed for out of order logs.
In practice this only matters for scalars logged out of order at high frequency,
but it does mean that live time series plots are slow in this case.
An update that fixes this is planned for 0.13.1.
Follow the progress <a href="https://github.com/rerun-io/rerun/issues/4810">here</a>.</p>
<h2 id="huge-wins-already-but-there-is-more-to-be-had">Huge wins already but there is more to be had<!-- --> <a href="#huge-wins-already-but-there-is-more-to-be-had"></a></h2>
<p>Adding a caching layer to the Rerun datastore has taken lots of effort over the last months, but the performance gains are clearly worth the added complexity.</p>
<p>There are still lots of gains to be had by adding secondary caches on top, for scalars and other data. For example, slowly changing 3D geometry could be cached on the GPU to avoid redundant CPU -&gt; GPU transfers, which are currently the performance bottleneck for point clouds.</p>
<p>Join us on <a href="https://github.com/rerun-io/rerun">Github</a> or <a href="https://discord.gg/PXtCgFBSmH">Discord</a>
and let us know what if these performance improvement made a difference for you,
and what areas you'd love to see us speed up next.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Court of Human Rights bans weakening of secure end-to-endencryption (1062 pts)]]></title>
            <link>https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/</link>
            <guid>39369653</guid>
            <pubDate>Wed, 14 Feb 2024 13:44:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/">https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/</a>, See on <a href="https://news.ycombinator.com/item?id=39369653">Hacker News</a></p>
Couldn't get https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What made Earth a giant snowball 700M years ago? Scientists have an answer (125 pts)]]></title>
            <link>https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html</link>
            <guid>39369040</guid>
            <pubDate>Wed, 14 Feb 2024 12:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html">https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html</a>, See on <a href="https://news.ycombinator.com/item?id=39369040">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div><figure>

	
		

			<img src="https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2024/february/dr-adriana-dutkiewicz-geosciences-in-the-flinders-ranges,-south-australia.jpg/_jcr_content/renditions/cq5dam.web.1280.1280.jpeg" alt="Research lead author Dr Adriana Dutkiewicz pointing to a thick bed of glacial deposits.  ">

			
			
		
	

	<figcaption>
		<p> Deposits from the Sturtian Glaciation 717­–664 million years ago in the northern Flinders Ranges, Australia. Research lead author Dr Adriana Dutkiewicz pointing to a thick bed of glacial deposits. &nbsp;<em>Photo: Professor Dietmar Müller/University of Sydney</em></p>

	</figcaption>
</figure>
</div>
		
			<p>Australian geologists have used plate tectonic modelling to determine what most likely caused an extreme ice-age climate in Earth’s history, more than 700 million years ago.</p>
<p>The study, published in<em> </em><a href="https://pubs.geoscienceworld.org/geology"><em>Geology</em></a>, helps our understanding of the functioning of the Earth's built-in thermostat that prevents the Earth from getting stuck in overheating mode. It also shows how sensitive global climate is to atmospheric carbon concentration.</p>
<p>“Imagine the Earth almost completely frozen over,” said the study’s lead author, ARC Future Fellow <a href="https://sydney.edu.au/science/people/adriana.dutkiewicz.php">Dr Adriana Dutkiewicz</a>. “That’s just what happened about 700 million years ago; the planet was blanketed in ice from poles to equator and temperatures plunged. However, just what caused this has been an open question.</p>
<p>“We now think we have cracked the mystery: historically low volcanic carbon dioxide emissions, aided by weathering of a large pile of volcanic rocks in what is now Canada; a process that absorbs atmospheric carbon dioxide.”</p>
<p>The project was inspired by the glacial debris left by the ancient glaciation from this period that can be spectacularly observed in the Flinders Ranges in South Australia.</p>
<p>A recent geological field trip to the Ranges, led by co-author <a href="https://www.adelaide.edu.au/directory/alan.collins">Professor Alan Collins</a> from the University of Adelaide, prompted the team to use the University of Sydney <a href="https://www.earthbyte.org/">EarthByte</a> computer models to investigate the cause and the exceptionally long duration of this ice age.</p>
<p>The extended ice age, also called the Sturtian glaciation after the 19th century European colonial explorer of central Australia, Charles Sturt, stretched from 717 to 660 million years ago, a period well before the dinosaurs and complex plant life on land existed.</p>

		
		
	</div><div>
		
		
			<p>Dr Dutkiewicz said: “Various causes have been proposed for the trigger and the end of this extreme ice age, but the most mysterious aspect is why it lasted for 57 million years – a time span hard for us humans to imagine.”</p>
<p>The team went back to a plate tectonic model that shows the evolution of continents and ocean basins at a time after the breakup of the ancient supercontinent Rodina. They connected it to a computer model that calculates CO2&nbsp;degassing of underwater volcanoes along mid-ocean ridges – the sites where plates diverge and new ocean crust is born.</p>
<p>They soon realised that the start of the Sturtian ice age precisely correlates with an all-time low in volcanic CO2&nbsp;emissions. In addition, the CO2&nbsp;outflux remained relatively low for the entire duration of the ice age.</p>
<p>Dr Dutkiewicz said: “At this time, there were no multicellular animals or land&nbsp;plants on Earth. The greenhouse gas concentration of the atmosphere was almost entirely dictated by CO2&nbsp;outgassing from volcanoes and by silicate rock weathering processes, which consume CO2.”</p>

		
		
	</div><div>
		<div><figure>

	
		

			<img src="https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2024/february/dietmar-m%C3%BCller-pointing-to-carbonates-overlying-sturt-formation-flinders-ranges-photo-by-adriana-dutkiewicz.jpg/_jcr_content/renditions/cq5dam.web.1280.1280.jpeg" alt="Professor Dietmar Müller points to carbonates overlying glacial deposits in the Flinders Ranges.">

			
			
		
	

	<figcaption>
		<p>Professor Dietmar Müller points to carbonates overlying glacial deposits in the Flinders Ranges. <em>Photo: Dr Adriana Dutkiewicz</em></p>

	</figcaption>
</figure>
</div>
		
			<p>Co-author&nbsp;<a href="https://www.sydney.edu.au/science/about/our-people/academic-staff/dietmar-muller.html">Professor Dietmar Müller</a>&nbsp;from the University of Sydney said: "Geology ruled climate at this time. We think the Sturtian ice age kicked in due to a double whammy: a plate tectonic reorganisation brought volcanic degassing to a minimum, while simultaneously a continental volcanic province in Canada started eroding away, consuming atmospheric CO2.</p>
<p>“The result was that atmospheric CO2&nbsp;fell to a level where glaciation kicks in – which we estimate to be below 200 parts per million, less than half today’s level.”</p>
<p>The team's work raises intriguing questions about Earth's long-term future.&nbsp; A&nbsp;<a href="https://www.nature.com/articles/s41561-023-01259-3">recent theory proposed</a>&nbsp;that over the next 250 million years, Earth would evolve towards Pangea Ultima, a supercontinent so hot that mammals might become extinct.</p>
<p>However, the Earth is also currently on a trajectory of lower volcanic CO2&nbsp;emissions, as continental collisions increase and the plates slow down. So, perhaps Pangea Ultima will turn into a snowball again.</p>
<p>Dr Dutkiewicz said: “Whatever the future holds, it is important to note that geological climate change, of the type studied here, happens extremely slowly.&nbsp;<a href="https://climate.nasa.gov/evidence/">According to NASA</a>, human-induced climate change is happening at a pace 10 times faster than we have seen before.”</p>
<h2>Research</h2>
<p>‘Duration of Sturtian “Snowball Earth” glaciation linked to exceptionally low mid-ocean ridge outgassing’, Dutkiewicz, A. et al (<em>Geology</em>, 2024). DOI: 10.1130/G51669.1</p>
<h2>EarthByte Group<br>
</h2>
<p>This work was enabled by the&nbsp;<a href="https://www.gplates.org/">GPlates</a>&nbsp;plate tectonic software, developed by the&nbsp;<a href="https://www.earthbyte.org/">EarthByte Group</a>&nbsp;at the University of Sydney, which has been the basis of a slew of discoveries over the past decade, contributing significant knowledge to how geology is a central long-term driver of climate and biodiversity. GPlates development is supported by the AuScope National Collaborative Research Infrastructure System (NCRIS) program.</p>
<h2>Declaration</h2>
<p>The authors declare no competing interests. Research was in part funded by the Australian Research Council.</p>

		
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xonsh: Python-powered, cross-platform, Unix-gazing shell (110 pts)]]></title>
            <link>https://github.com/xonsh/xonsh</link>
            <guid>39368586</guid>
            <pubDate>Wed, 14 Feb 2024 11:14:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xonsh/xonsh">https://github.com/xonsh/xonsh</a>, See on <a href="https://news.ycombinator.com/item?id=39368586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><h2 tabindex="-1" dir="auto">xonsh</h2>
<p dir="auto"><strong>xonsh</strong> is a Python-powered, cross-platform, Unix-gazing shell language and command prompt.</p>
<p dir="auto">The language is a superset of Python 3.6+ with additional shell primitives.
xonsh (pronounced <em>conch</em>) is meant for the daily use of experts and novices alike.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/xonsh/xonsh/main/docs/_static/what_is_xonsh.png"><img alt="What is xonsh?" src="https://raw.githubusercontent.com/xonsh/xonsh/main/docs/_static/what_is_xonsh.png"></a></p>
<p dir="auto">If you like xonsh, ⭐ the repo, <a href="https://twitter.com/intent/tweet?text=xonsh%20is%20a%20Python-powered,%20cross-platform,%20Unix-gazing%20shell%20language%20and%20command%20prompt.&amp;url=https://github.com/xonsh/xonsh" rel="nofollow">write a tweet</a> and stay tuned by watching releases.</p>
<a href="https://gitter.im/xonsh/xonsh?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" rel="nofollow"><img alt="Join the chat at https://gitter.im/xonsh/xonsh" src="https://camo.githubusercontent.com/b8ab3219443241e4c23062a442187e5bb3ca34f1d071237e1aeb45ffcba8713b/68747470733a2f2f6261646765732e6769747465722e696d2f786f6e73682f786f6e73682e737667" data-canonical-src="https://badges.gitter.im/xonsh/xonsh.svg">
</a>
<a href="https://travis-ci.org/xonsh/xonsh" rel="nofollow"><img alt="Travis" src="https://camo.githubusercontent.com/35732d8d096fd79dc3363946e8b4ed88f327057db06d804da2744e5f3e9e419e/68747470733a2f2f7472617669732d63692e6f72672f786f6e73682f786f6e73682e7376673f6272616e63683d6d61696e" data-canonical-src="https://travis-ci.org/xonsh/xonsh.svg?branch=main"></a>
<a href="https://ci.appveyor.com/project/xonsh/xonsh" rel="nofollow"><img alt="Appveyor" src="https://camo.githubusercontent.com/f412619487e5e015776325b40e2d063a7dbcceb5724bd73dfc9eb2d64dbb89ed/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f786f6e73682f786f6e73683f7376673d74727565" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/xonsh/xonsh?svg=true"></a>
<a href="https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/xonsh/xonsh.git" rel="nofollow"><img alt="Open in Google Cloud Shell" src="https://camo.githubusercontent.com/0c0c5d76144ebcd95e5a4da68c8481c98000486e066f4bf3d03eee6958863c1a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476f6f676c65253230436c6f75642532305368656c6c2d786f6e73682d677265656e" data-canonical-src="https://img.shields.io/badge/Google%20Cloud%20Shell-xonsh-green"></a>
<a href="https://codecov.io/github/xonsh/xonsh?branch=main" rel="nofollow"><img alt="codecov.io" src="https://camo.githubusercontent.com/09365076d9337b6df7b2cf868efa2f4069e57273962b7d90073e94743cfab142/68747470733a2f2f636f6465636f762e696f2f67682f786f6e73682f786f6e73682f6272616e63682f6d61737465722f6772617068732f62616467652e7376673f6272616e63683d6d61696e" data-canonical-src="https://codecov.io/gh/xonsh/xonsh/branch/master/graphs/badge.svg?branch=main"></a>
<a href="https://repology.org/project/xonsh/versions" rel="nofollow"><img alt="repology.org" src="https://camo.githubusercontent.com/a90f19dfec618ffe152d6678e79d0c6046d00d8a78f632d5a0c153df9a5731f1/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f74696e792d7265706f732f786f6e73682e737667" data-canonical-src="https://repology.org/badge/tiny-repos/xonsh.svg">
</a>
<a name="user-content-first-steps"></a>
<h2 tabindex="-1" dir="auto">First steps</h2>
<p dir="auto">Install xonsh from pip:</p>
<pre lang="xonshcon">python -m pip install 'xonsh[full]'
</pre>
<p dir="auto">And visit <a href="https://xon.sh/" rel="nofollow">https://xon.sh</a> for more information:</p>
<ul dir="auto">
<li><a href="https://xon.sh/contents.html#installation" rel="nofollow">Installation</a> - using packages, docker or AppImage.</li>
<li><a href="https://xon.sh/tutorial.html" rel="nofollow">Tutorial</a> - step by step introduction in xonsh.</li>
</ul>
<a name="user-content-extensions"></a>
<h2 tabindex="-1" dir="auto">Extensions</h2>
<p dir="auto">Xonsh has the certain term for extensions and additional materials - xontrib - the short version of "contribution" word.</p>
<ul dir="auto">
<li><a href="https://github.com/topics/xontrib">Xontribs on Github</a></li>
<li><a href="https://github.com/xonsh/awesome-xontribs">Awesome xontribs</a></li>
<li><a href="https://xon.sh/api/_autosummary/xontribs/xontrib.html" rel="nofollow">Core xontribs</a></li>
<li><a href="https://github.com/xonsh/xontrib-template">Create a xontrib step by step from template</a></li>
</ul>
<a name="user-content-projects-that-use-xonsh-or-compatible"></a>
<h2 tabindex="-1" dir="auto">Projects that use xonsh or compatible</h2>
<ul dir="auto">
<li><a href="https://github.com/donnemartin/gitsome">gitsome</a>: Supercharged Git/shell autocompleter with GitHub integration.</li>
<li><a href="https://github.com/xxh/xxh">xxh</a>: Using xonsh wherever you go through the SSH.</li>
<li><a href="https://regro.github.io/rever-docs/" rel="nofollow">rever</a>: Cross-platform software release tool.</li>
<li><a href="https://github.com/regro/cf-scripts">Regro autotick bot</a>: Regro Conda-Forge autoticker.</li>
</ul>
<p dir="auto">Jupyter-based interactive notebooks via <a href="https://github.com/xonsh/xontrib-jupyter">xontrib-jupyter</a>:</p>
<ul dir="auto">
<li><a href="https://jupyter.org/" rel="nofollow">jupyter and jupyterlab</a>: Interactive notebook platform.</li>
<li><a href="https://github.com/joouha/euporie">euporie</a>: Terminal based interactive computing environment.</li>
</ul>
<a name="user-content-the-xonsh-shell-community"></a>
<h2 tabindex="-1" dir="auto">The xonsh shell community</h2>
<p dir="auto">The xonsh shell is developed by a community of volunteers. There are few ways to help the xonsh shell:</p>
<ul dir="auto">
<li><a href="https://github.com/sponsors/xonsh">Become a sponsor to xonsh</a>.</li>
<li><a href="https://twitter.com/intent/tweet?text=xonsh%20is%20a%20Python-powered,%20cross-platform,%20Unix-gazing%20shell%20language%20and%20command%20prompt.&amp;url=https://github.com/xonsh/xonsh" rel="nofollow">Write a tweet</a>, post or an article to spread the good word about xonsh in the world.</li>
<li>Solve a <a href="https://github.com/xonsh/xonsh/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc">popular issue</a>.</li>
<li>Solve a <a href="https://github.com/xonsh/xonsh/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+sort%3Areactions-%2B1-desc">good first issue</a>.</li>
<li>Get the <a href="https://github.com/xonsh/xontrib-template/issues?q=is%3Aopen+is%3Aissue+label%3Aidea+sort%3Areactions-%2B1-desc">idea</a> and <a href="https://github.com/xonsh/xontrib-template#why-use-this-template">create new xontrib</a>.</li>
<li>Become xonsh core by deep diving into xonsh and improve the threading and subprocess logic.</li>
<li>Give a star to xonsh repository and to <a href="https://github.com/topics/xontrib">xontribs</a> you like.</li>
</ul>
<p dir="auto">We welcome new contributors!</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Matrix Trashfire (252 pts)]]></title>
            <link>https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html</link>
            <guid>39368561</guid>
            <pubDate>Wed, 14 Feb 2024 11:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html">https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html</a>, See on <a href="https://news.ycombinator.com/item?id=39368561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>For reasons, I tried to evaluate the distributed Matrix chat and their clients.
That did not work out very well.</p>
<h2 id="onboarding-experience">
    <a href="#onboarding-experience">
	Onboarding experience
    </a>
</h2>
<p>I was told that the default Matrix chat client is called Elements, so I looked it up on the iOS App store.
Unfortunately, there are two, “Element” and “Element X.”
No explanation is given, and no preference is stated.
“Element” is categorized business, “Element X” is in “Social Networking.”
Are they not the same?
They seem to be from the same company, though.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-01.jpg" alt="">
</p>


<p><em>Element and Element X in the app store. Which one to use?</em></p>
<p>Ok, let’s open the descriptions.
They are identical, except for one sentence at the start:
“Element X is the future Element.”
So it’s a beta?
Why is it not labeled as a Beta?</p>
<p>On the desktop, going to <a href="https://matrix.org/" target="_blank" rel="noopener">Matrix.org</a>

 plus two additional clicks take you to
<a href="https://matrix.org/ecosystem/clients/" target="_blank" rel="noopener">the client page</a>

, which offers</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-02.jpg" alt="">
</p>


<p><em>The client page offers you, among others, both clients and also states which is available on what platform.</em></p>
<p>So apparently “Element X” is beta and not yet available on all platforms. I open the macOS App Store and…</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-03.jpg" alt="">
</p>


<p><em>macOS does not offer Element, only Element X.</em></p>
<p>Apparently matrix.org lied to me.
Element X is available on iOS and macOS, Element is not.</p>
<p>Ok, let’s install Element X and try:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-04.jpg" alt="">
</p>


<p><em>Element X wants me to sign in to matrix.org. There is no ‘sign up’ Button. There is no sign-up menu.</em></p>
<p>The client wants me to log in to matrix.org. There is no button to make an account. There is no menu to make an account.
There is zero onboarding for new users.</p>
<p>Ok, let’s go to matrix.org again, and see.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-05.jpg" alt="">
</p>


<p><em>The matrix.org Website is not very helpful. But when you notice the burger menu, there is actually a “Try Matrix” button.</em></p>
<p>The matrix.org website is a very empty clean screen that is not very helpful. There is a burger menu, though,
and if you open it, you get a “Try Matrix” button.
This leads to another screen that tells you to use your organizations server instance (What organization? I’m alone!),
or install a server,
or choose a public server.
If you opt for Public Servers, you land here:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-06.jpg" alt="">
</p>


<p><em>matrix.org server instances, alphabetically sorted, with little additional information.</em></p>
<p>Matrix.org is conspicuously absent from this list.
The rest I do not know anything about.</p>
<p>I can now research what server instance I want to join.
Unfortunately, I do not get information about what their country is.
I can’t see if they are subject to GDPR rules.
I don’t know if they are owned by a company or run by a single private person.
There is no indication how many users they have.</p>
<p>I can dig through their privacy policies and rules, except that some don’t provide any.</p>
<p>Scrolling down, I end up with the option to onboard to this:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-07.jpg" alt="">
</p>


<p><em>Servers marked as vulnerable, unavailable and with profanity in their name.</em></p>
<p>Why in heaven or earth would anybody put unavailable or vulnerable servers into an onboarding listing?
Isn’t this supposed a “secure” messenger?</p>
<h2 id="trying-to-use-it-nontheless">
    <a href="#trying-to-use-it-nontheless">
	Trying to use it, nontheless
    </a>
</h2>
<p>I made an “isotopp” account at <a href="https://chat.tchncs.de/#/login" target="_blank" rel="noopener">tchncs.de</a>

.
The password is generated and stored in Bitwarden.
A validation mail is sent to a unique address at koehntopp.de and arrives.</p>
<p>I try to login not being validated, using Bitwarden.
The login is rejected.</p>
<p>I validate the email.
The server says I am validated.</p>
<p>I try to login, using Bitwarden.
The login is rejected.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-09.jpg" alt="">
</p>


<p><em>I am trying to recover the password for the account which I just validated, using the email from the verification mail.
The account is unknown.</em></p>
<p>I click on “forgotten password”, and supply the mail adress the validation mail was sent to.
“This email address was not found.”</p>
<p>Okay, since my account does not exist, I create it again:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-10.jpg" alt="">
</p>


<p><em>I recreate my account, using the same mail address. As you can see, the first registration mail still is in the account.
I take the validation URL, which is longer than 80 characters, and use it to successfully validate, again.</em></p>
<p>I create the account again, using the same parameters.
The account validation mail is sent to my address.
The old account validation mail is also still in the account.
I take the new URL, which is longer than 80 characters, and use it to successfully validate my account, again.</p>
<p>This time I accidentally left the “create account” window open.
This window is now suddenly logged in.
Turns out, you MUST NOT, UNDER ANY CIRCUMSTANCES, close the “create account” window until the account is validated,
or it is simply not created.
This is not stated anywhere.</p>
<p>To confirm the account works and the password in Bitwarden is stored successfully,
I log out and log in again.</p>
<p>I get this:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-11.jpg" alt="">
</p>


<ul>
<li><strong>Unable to verify this device</strong>
It looks like you don’t have a Security Key or any other devices you can verify against.
This device will not be able to access old encrypted messages.
In order to verify your identity on this device, you’ll need to reset your verification keys.*</li>
</ul>
<p>What does that even mean?</p>
<h2 id="trying-element-x-with-my-account">
    <a href="#trying-element-x-with-my-account">
	Trying Element X with my account
    </a>
</h2>
<p>Starting Element X, it tries to onboard me to Matrix.org.
I select “Change Server”, and get a form field where it says “matrix.org”.
I am overwriting it with “chat.tchncs.de”, which supposedly is my server.
At least that is what it says in the web client.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-12.jpg" alt="">
</p>


<p>That is not accepted.</p>
<p>I take the URL from the browser and paste that instead.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-13.jpg" alt="">
</p>


<p>That is also not accepted, but I can learn more.
I click.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-14.jpg" alt="">
</p>


<p>The what?</p>
<p>Turns out, while the Chat is running on “chat.tchncs.de”, this is not the “Identity Provider.”
That one is called “tchncs.de”.
You only learn this when you open your config menu in the web chat and look at Identifer shown there.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-15.jpg" alt="">
</p>


<p>Once you enter this, Element X and the web chat get hectic.
There is a new client, and both clients want to authenticate that the new device is legit.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-16.jpg" alt="">
</p>


<p>For that purpose, they display a set of Emojis, which look differently in the web client and the application,
and ask me if they are the same.
Helpful Emoji names are shown under the Emoji, and they are identical.
I simply click yes.</p>
<p>After that, both clients can see my Chat, but the Element X Client still has no access to any chat history.
That is, because the client is unverified (so is the web client).</p>
<p>When I close any client, I have to re-login, re-compare the Emojis, and all chat history is gone.</p>
<h2 id="after-onboarding">
    <a href="#after-onboarding">
	After onboarding
    </a>
</h2>
<p>Why have I been trying this?</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-08.jpg" alt="">
</p>


<p><em>A friend was trying to use a Matrix messenger on their phone, and waited 9 hours for this to complete.</em></p>
<p>A friend of mine was trying to re-install a Matrix messenger on their phone, and landed on the screen above.
This hung for 9 hours without any message or failure indication.
The application cannot detect if somebody is using the wrong recovery key for a different account.</p>
<p>The friend tried to use an Android application, but the application was complaining about the account not being verified.
That is, the mail address in use was not confirmed, and for that reason the client would not be showing any chats.
At the same time, these chats were being sent to the unconfirmed mail address,
unencrypted,
as a reminder that he was missing out.</p>
<p>According to him, you can’t delete a half-made unconfirmed account.
You also can’t rename an account.</p>
<p>Apparently, you cannot create invite links for private chat rooms,
only invite people.
To do that, vector.im uses the very same dark patterns that LinkedIn uses to convince you to share your address book.</p>
<p>With the unique mail-address used to sign up to Matrix, I am unfindable because only Matrix uses this specific mail address.</p>
<p>Outside of Element, there are very few clients, most of them very old and not being updated within the last few years.</p>
<p>All in all, this is a mess, and my recommendation is to avoid Matrix for at least two years.
It is not secure, it is actively user-hostile, and looks not well managed.</p>
<p>This is a project in severe need of management changes, a thorough UX evaluation.
The design needs changes that make onboarding and usage smoother, encourage secure workflows,
keep accounts available, and encourage secure practice.
It also needs careful curation of servers and clients.
At the moment it is a trash fire.</p>
<h2 id="matrix-responds">
    <a href="#matrix-responds">
	Matrix responds
    </a>
</h2>
<p>Added on 14-Feb-2024:
People at Matrix.org and Matrix developers have picked this up and responded in a very constructive way.
They cannot address all things because they are not in the realm of Matrix, but part of Element.
So far, no responses from Element.</p>
<p><a href="https://mastodon.matrix.org/@matrix/111924190165706931" target="_blank" rel="noopener">Matrix writes</a>

:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-17.jpg" alt="">
</p>


<blockquote>
<p>well, this is a trashfire indeed.
Thanks for writing this up.
You’ve caught Element in the middle of their migration to Element X, and there’s a lot of legit feedback here:</p>
<ul>
<li>Both E &amp; EX should be in the macOS app store.</li>
<li>EX should clearly be labelled WIP in appstores.
-It’s a mistake that matrix.org hurls people to servers.joinmatrix.org (which is not run by us);
until recently it defaulted to matrix.org for convenience.</li>
<li>Keeping the “create account” window open is a pure bug.</li>
</ul>
</blockquote>
<p><a href="https://mastodon.matrix.org/@matrix/111924227099676114" target="_blank" rel="noopener">The continue</a>

</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-18.jpg" alt="">
</p>


<blockquote>
<ul>
<li>Verification UX in Element is a disaster, and being reworked in EX:
<a href="https://github.com/element-hq/element-meta/blob/develop/docs/FTUE.md" target="_blank" rel="noopener">Github link</a>

</li>
<li>Element Android failing to compute a recovery key is clearly a bug too.</li>
</ul>
<p>Your other complaints about Element UX (e.g. user discovery by email;
specifying the server URL) are also very familiar.</p>
<p>It’s not true to say vector.im uses “the very same dark patterns as LinkedIn” for contact discovery though;
<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/hs/hash-identity/proposals/2134-identity-hash-lookup.md" target="_blank" rel="noopener">Github link</a>


explains how it works (and is strictly opt-in).</p>
</blockquote>
<p>Matrix Director of Program Development <a href="https://mamot.fr/@thibaultamartin/111924256997285624" target="_blank" rel="noopener">Thibault A. Martin responds</a>

</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-19.jpg" alt="">
</p>


<blockquote>
<p>Hej @isotopp I’m one of the maintainers of the matrix.org website.</p>
<p>Your post provides a very valuable perspective.
I gathered the following gripes that we can address on the website itself in this issue:
<a href="https://github.com/matrix-org/matrix.org/issues/2178" target="_blank" rel="noopener">Matrix.Org Issue 2178</a>

</p>
<p>If you have the time to let me know if I got things right,
that would be very useful!</p>
</blockquote>
<p>Thanks for picking this up, people!
I very much hope that Matrix and Element eventually turn into something useful.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I grew my Substack from 439 to 451 free subscribers in just 11 months (209 pts)]]></title>
            <link>https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to</link>
            <guid>39368370</guid>
            <pubDate>Wed, 14 Feb 2024 10:27:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to">https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to</a>, See on <a href="https://news.ycombinator.com/item?id=39368370">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>A lot of people have been talking recently about how to grow their platform on Substack. And since I’m something of an expert on Substack growth, I figured I’d chime in. Because I’ve grown my Substack from 439 free subscribers to 451 free subscribers in just 11 months.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png" width="766" height="591" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:591,&quot;width&quot;:766,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:48735,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>I know what you’re thinking: no fiddle-dee-freaking way, hombre. But it’s true. I gained 11 new subscribers in less than a year and I have the stats to prove it. You, too, can hit numbers like mine (1 new subscriber </span><em>per month</em><span>!) if you just follow these simple steps. </span><em>And</em><span> are in a financial situation that allows the kind of free time you’ll need to grow this bad boy. </span><em>And</em><span> are willing to put in a butt ton of hours on a project that, statistically speaking, won’t succeed. Okay, let’s dive in!</span></p><p><span>I personally don’t know a single writer who works hard enough, and it shows. Writers come to me for advice all the time saying things like “Carlos, I just don’t get it. I wrote four Substack posts during my 9-month-long vacation in Turks &amp; Caicos and yet I’ve only gained 3 new subscribers.” And I have to tell them, “Listen, buddy boy, you’re never going anywhere with those kinds of numbers. You have to post at least </span><em>twice</em><span> that often!” And then they look at me, crestfallen, their dreams of writerly success fading before their eyes.&nbsp;</span></p><p>But, sure enough, the writers that do heed my advice see the kinds of double digit growth I’ve achieved. It’s possible, but you have to PUT. IN. THE. WORK. I’ve published 19 POSTS in just under a year. That’s over 1.5 times PER MONTH.&nbsp;</p><p><span>Side note: I never take vacations, but even if I did, Turks &amp; Caicos is </span><em>so over</em><span>, baby. Anyone who’s anyone is going to St. Kitts &amp; Nevis now. That’s the Caribbean ampersand island nation du jour.&nbsp;&nbsp;&nbsp;</span></p><p>When I launched Shades of Greaves in January, I had a clear mission:&nbsp;</p><p><em>Start a Substack, I guess, because that’s what other writers I know are doing.&nbsp;</em></p><p>I thought long and hard about what I should focus on, and ultimately landed on a concise concept for what my Substack would be about:&nbsp;</p><p><em>Shades of Greaves will feature topical satire, evergreen humor pieces, craft essays, self-publishing advice, occasional life updates, and any pieces that The New Yorker and McSweeney’s passed on.</em></p><p><span>Sure, the focus was a bit singular, but if I were to wander into, say, gardening advice, or home buying tips, or marketing strategy, then the focus would start to be too broad. Actually, come to think of it, there’s a bit of all of those things in the Substack, too. So I take back what I said earlier about having a clear vision. The key to Substack growth is the exact opposite: </span><em>spray and pray!</em></p><p>As you can see, I put a ton of hours into crafting the Shades of Greaves logo:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg" width="500" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:22099,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Whether you like it or not, Notes is here to stay. And, sure, like any social-media-style feed, it’s time consuming, mentally exhausting, and a great place to get harassed by the most heinous people on planet Earth. But that’s a small price to pay for occasionally meeting someone cool. So, in addition to my prolific newsletter posts (1.5x a month, need I remind you) I also frequently write, comment on, and restack Notes. AT LEAST once every two months (sometimes three months if I forget).</p><p>I have no idea if this is true, but everyone else says it is, so I’m guessing it’s true.</p><p><span>At the end of the day, it’s important to remember that the most successful people all put tons and tons of hours worth of work into their projects. It’s also important to remember that plenty of non-successful people </span><em>also</em><span> put tons and tons of hours worth of work into their projects and failed anyway! Most people never make a living wage from creative pursuits because we live in a chaotic world governed by probability. So any success on this topsy-turvy stochastic planet is, in part, due to being at the right place at the right time, appealing to humanity’s notoriously fickle, ever-changing tastes at just the right moment, being born with Lebron James-like preternatural abilities, and the alignment of Mercury relative to Earth. And even if you have all of those things, working your whole entire ass off is (DUH) also a prerequisite.&nbsp;</span></p><p>So, considering that you’re likely going to fail, at least pick something you’re going to enjoy failing at! It’s the only way to overcome the psychological carpet bombing that is putting your heart and soul into your creative work only for it to FALL INTO THE VOID TIME AND TIME AGAIN! Or maybe it won’t this time! You’ll never know until you put WAY TOO MUCH FUCKING ENERGY into it! Good luck!&nbsp;&nbsp;</p><p>I hope all of the advice above helps you achieve the kind of stellar growth I’ve achieved on Substack these past 11 months. I don’t know about you, but I’m feeling energized to put in even more work into my Substack in 2024. I daresay, I may even hit 468 or even 479 subscribers by this same time next year!</p><p><span>And, if all else fails, you can always become an alt-right Nazi troll. They seem to be </span><a href="https://www.theatlantic.com/ideas/archive/2023/11/substack-extremism-nazi-white-supremacy-newsletters/676156/" rel="">thriving</a><span> on Substack.</span></p><p>Okay, was that fun? I hope you found it as cathartic to read as it was to write. Now, I just want to be super, super, super clear – this post isn’t intended to bash any writers who have written about growing their platforms recently. If you’ve perused Substack over the past few weeks, you’ve likely come across a few of the pieces I poked fun at above. But I assure you, my intent is not to put other writers on blast. This was just a silly way for those of us who are on the other side of the growth equation to have a laugh and let off a little steam. For the record, I’ve actually found those posts about Substack growth to be both informative and inspiring, and I appreciate those writers sharing their insights.</p><p>My only pet peeve I have about these kinds of advice posts is when writers (or any successful person, for that matter) tells other people that they need to “work harder.” You mean I have to work hard? If only I’d thought of that! Here I was being a lazy sack of shit this whole time thinking that was the key to success.&nbsp;</p><p><span>I don’t know about you, but I personally don’t know a single writer who </span><em>isn’t</em><span> working their absolute, wordsmithing ass off. The only difference is that what they’re working their asses off on might be anything from writing books, to teaching, to raising children, to working a non-writing day job that pays the bills. Not everyone has the time or resources to devote to growing a platform — that’s just the reality of the world we live in — so attributing one’s own success to working hard, though undoubtedly true, never sits right with me. It’s like saying that to be a writer you need to drink water and remember to keep breathing oxygen. True, yes, but it hardly bears repeating.&nbsp;</span></p><p>So that’s the only bit of advice I take issue with, which is a common thread I saw in many of the posts I came across. And I know that wasn’t their intent, but the satirist in me tends to interpret people’s words in the least generous way possible if it means getting to make a little joke out of it.</p><p><span>What I </span><em>do</em><span> think is spot on is that, to grow your platform, you have to deliver something of value to readers. And developing the writing skills to do that can take years. Many of the Substacks I see growing quickly are from authors with multiple books under their belts and decades of experience. And that does, of course, take </span><em>work</em><span>. So that I wholeheartedly agree with.</span></p><p>Also, I want to be clear, I don’t think you need Lebron James-like natural ability to succeed. But I do think that embracing the randomness of life is freeing. You really do have to love the work for the sake of the work, and that’s one of the hardest things to do as a writer when you also want to, you know, make enough money to eat. But putting constant pressure on yourself doesn’t do a bit of good.&nbsp;</p><p><span>Most importantly, I hope this piece serves as a self-deprecating look at my own failures (okay, “failures” is too harsh. “Non-successes,” maybe?) when it comes to growing my Substack over the past year. A what </span><em>not</em><span> to do, if you will. The blame for why my Substack hasn’t grown as much as I might’ve liked it to lies squarely with me. Life got in the way. I got busy with </span><a href="https://www.amazon.com/dp/B0CF47Z8JG?maas=maas_adg_7C9BAC2EFA2585AA6123C15055227C59_afap_abs&amp;ref_=aa_maas&amp;tag=maas" rel="">my book</a><span>, and starting a new job, and thus my Substack went by the wayside for parts of the year.&nbsp;</span></p><p>Even so, I managed to grow my Substack from 320 to 451 subscribers (yes, I exaggerated earlier for comedic effect) in less than a year and I'm grateful for that! I do intend to post more regularly and make a concerted effort to build community here in 2024, so hopefully I can stick to that (feel free to slide into my chats to hound me if you feel I’m not delivering on that).</p><p><span>As for why someone might consider subscribing, if there's anything I offer on Substack that you can’t get elsewhere it's that A) I’m a satirist and therefore my writing is (hopefully) relatively funny and entertaining to read, and B) I’m sharing what I’m learning as I’m learning it. So, in that sense, this Substack is a journey we’re going on </span><em>together</em><span> as opposed to me just passing on advice. So if that sounds like your jam, come say hi! And if you’re already a subscriber, come say hi more often! I love discussing all things humor and writing and my chats, notes, and comments are always open.&nbsp;</span></p><p>Until the right-wing trolls find me, of course, then I may have to lay low for a bit.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Popular XMPP App "Conversations" Removed from PlayStore by Google (272 pts)]]></title>
            <link>https://gultsch.social/@daniel/111929074071688694</link>
            <guid>39368233</guid>
            <pubDate>Wed, 14 Feb 2024 09:54:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gultsch.social/@daniel/111929074071688694">https://gultsch.social/@daniel/111929074071688694</a>, See on <a href="https://news.ycombinator.com/item?id=39368233">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not all TLDs are Created Equal (173 pts)]]></title>
            <link>https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html</link>
            <guid>39367540</guid>
            <pubDate>Wed, 14 Feb 2024 07:51:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html">https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html</a>, See on <a href="https://news.ycombinator.com/item?id=39367540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">

				
				<p>
					Posted: Tue, 13 February 2024
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html">permalink</a>
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html#comments">
						
							No comments
						
					</a>
				</p>
<p>In light of the recent <a href="https://akko.erincandescent.net/notice/AenvYJ0yiHfspKM8uW">cancellation of the <code>queer.af</code> domain registration by the Taliban</a>, the fragile and difficult nature of country-code top-level domains (ccTLDs) has once again been comprehensively demonstrated.
Since many people may not be aware of the risks, I thought I’d give a solid explainer of the whole situation, and explain why you should, in general, not have anything to do with domains which are registered under ccTLDs.</p>

<h2 id="top-level-what-now">Top-level What-Now?</h2>

<p>A top-level domain (TLD) is the last part of a domain name (the collection of words, separated by periods, after the <code>https://</code> in your web browser’s location bar).
It’s the “com” in <code>example.com</code>, or the “af” in <code>queer.af</code>.</p>

<p>There are two kinds of TLDs: country-code TLDs (ccTLDs) and generic TLDs (gTLDs).
Despite all being TLDs, they’re very different beasts under the hood.</p>

<h2 id="whats-the-difference">What’s the Difference?</h2>

<p>Generic TLDs are what most organisations and individuals register their domains under: old-school technobabble like “com”, “net”, or “org”, historical oddities like “gov”, and the new-fangled world of words like “tech”, “social”, and “bank”.
These gTLDs are all regulated under a set of rules created and administered by ICANN (the “Internet Corporation for Assigned Names and Numbers”), which try to ensure that things aren’t a complete wild-west, limiting things like price hikes (well, sometimes, anyway), and providing means for disputes over names<sup id="fnref:1"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:1">1</a></sup>.</p>

<p>Country-code TLDs, in contrast, are all two letters long<sup id="fnref:2"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:2">2</a></sup>, and are given out to countries to do with as they please.
While ICANN kinda-sorta has something to do with ccTLDs (in the sense that it makes them exist on the Internet), it has no authority to control how a ccTLD is managed.
If a country decides to raise prices by 100x, or cancel all registrations that were made on the 12th of the month, there’s nothing anyone can do about it.</p>

<p>If that sounds bad, that’s because it is.
Also, it’s not a theoretical problem – the Taliban deciding to asssert its bigotry over the little corner of the Internet namespace it has taken control of is far from the first time that ccTLDs have caused grief.</p>

<h2 id="shifting-sands">Shifting Sands</h2>

<p>The <code>queer.af</code> cancellation is interesting because, at the time the domain was reportedly registered, 2018, Afghanistan had what one might describe as, at least, a <em>different</em> political climate.
Since then, of course, things have changed, and the new bosses have decided to get a bit more active.</p>

<p>Those running <code>queer.af</code> seem to have seen the writing on the wall, and were planning on moving to another, less fraught, domain, but hadn’t completed that move when the Taliban came knocking.</p>

<h2 id="the-curious-case-of-brexit">The Curious Case of Brexit</h2>

<p>When the United Kingdom decided to leave the European Union, it fell foul of the EU’s rules for the registration of domains under the “eu” ccTLD<sup id="fnref:3"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:3">3</a></sup>.
To register (and maintain) a domain name ending in <code>.eu</code>, you have to be a resident of the EU.
When the UK ceased to be part of the EU, residents of the UK were no longer EU residents.</p>

<p>Cue much unhappiness, wailing, and gnashing of teeth when this was pointed out to Britons.
Some decided to give up their domains, and move to other parts of the Internet, while others managed to hold onto them by various legal sleight-of-hand (like having an EU company maintain the registration on their behalf).</p>

<p>In any event, all very unpleasant for everyone involved.</p>

<h2 id="geopolitics-on-the-internet">Geopolitics… on the Internet?!?</h2>

<p>After Russia invaded Ukraine in February 2022, the Ukranian Vice Prime Minister <a href="https://eump.org/media/2022/Goran-Marby.pdf">asked ICANN to suspend ccTLDs associated with Russia</a>.
While ICANN said that it wasn’t going to do that, because it wouldn’t do anything useful, some domain registrars (the companies you pay to register domain names) ceased to deal in Russian ccTLDs, and some websites restricted links to domains with Russian ccTLDs.</p>

<p>Whether or not you agree with the sort of activism implied by these actions, the fact remains that even the actions of a government that <em>aren’t</em> directly related to the Internet can have grave consequences for your domain name if it’s registered under a ccTLD.
I don’t <em>think</em> any gTLD operator will be invading a neighbouring country any time soon.</p>

<h2 id="money-money-money-must-be-funny">Money, Money, Money, Must Be Funny</h2>

<p>When you register a domain name, you pay a registration fee to a registrar, who does administrative gubbins and causes you to be able to control the domain name in the DNS.
However, you don’t “own” that domain name<sup id="fnref:4"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:4">4</a></sup> – you’re only <em>renting</em> it.
When the registration period comes to an end, you have to renew the domain name, or you’ll cease to be able to control it.</p>

<p>Given that a domain name is typically your “brand” or “identity” online, the chances are you’d prefer to keep it over time, because moving to a new domain name is a <em>massive</em> pain, having to tell all your customers or users that now you’re somewhere else, plus having to accept the risk of someone registering the domain name you used to have and capturing your traffic… it’s all a gigantic hassle.</p>

<p>For gTLDs, ICANN has various rules around price increases and bait-and-switch pricing that tries to keep a lid on the worst excesses of registries.
While there are any number of reasonable criticisms of the rules, and the Internet community has to stay on their toes to keep ICANN from <a href="https://domainnamewire.com/2019/03/18/icann-proposes-lifting-price-controls-on-org-info-domains/">totally succumbing to regulatory capture</a>, at least in the gTLD space there’s some degree of control over price gouging.</p>

<p>On the other hand, ccTLDs have no effective controls over their pricing.
For example, in 2008 the Seychelles increased the price of <code>.sc</code> domain names from <a href="https://web.archive.org/web/20071113061947/http://www.afilias-grs.info:80/public/policies/sc">US$25</a> to <a href="https://web.archive.org/web/20080308114828/http://www.afilias-grs.info:80/public/policies/sc">US$75</a>.  No reason, no warning, just “pay up”.</p>

<h2 id="who-is-even-getting-that-money">Who Is Even Getting That Money?</h2>

<p>A closely related concern about ccTLDs is that some of the “cool” ones are assigned to countries that are… not great.</p>

<p>The poster child for this is almost certainly Libya, which has the ccTLD “ly”.
While Libya was being run by a <a href="https://en.wikipedia.org/wiki/Muammar_Gaddafi">terrorist-supporting extremist</a>, companies thought it was a great idea to have domain names that ended in <code>.ly</code>.
These domain registrations weren’t (and aren’t) cheap, and it’s hard to imagine that at least some of that money wasn’t going to benefit the Gaddafi regime.</p>

<p>Similarly, the British Indian Ocean Territory, which has the “io” ccTLD, was created in a <a href="https://theconversation.com/how-the-us-and-uk-worked-together-to-recolonise-the-chagos-islands-and-evict-chagossians-177636">colonialist piece of chicanery that expelled thousands of native Chagossians from Diego Garcia</a>.
Money from the registration of <code>.io</code> domains doesn’t go to the (former) residents of the Chagos islands, instead <a href="https://web.archive.org/web/20200314085443/gigaom.com/2014/06/30/the-dark-side-of-io-how-the-u-k-is-making-web-domain-profits-from-a-shady-cold-war-land-deal/">it gets paid to the UK government</a>.</p>

<p>Again, I’m not trying to suggest that all gTLD operators are wonderful people, but it’s not particularly likely that the direct beneficiaries of the operation of a gTLD stole an island chain and evicted the residents.</p>

<h2 id="are-cctlds-ever-useful">Are ccTLDs Ever Useful?</h2>

<p>The answer to that question is an unqualified “maybe”.
I certainly don’t think it’s a good idea to register a domain under a ccTLD for “vanity” purposes: because it makes a word, is the same as a file extension you like, or because it looks cool.</p>

<p>Those ccTLDs that clearly represent and are associated with a particular country are more likely to be OK, because there is less impetus for the registry to try a naked cash grab.
Unfortunately, ccTLD registries have a disconcerting habit of changing their minds on whether they serve their geographic locality, such as when auDA decided to declare an open season in the <code>.au</code> namespace some years ago.
Essentially, while a ccTLD may have geographic connotations <em>now</em>, there’s not a lot of guarantee that they won’t fall victim to scope creep in the future.</p>

<p>Finally, it <em>might</em> be somewhat safer to register under a ccTLD if you live in the location involved.
At least then you might have a better idea of whether your domain is likely to get pulled out from underneath you.
Unfortunately, as the <code>.eu</code> example shows, living somewhere today is no guarantee you’ll still be living there tomorrow, even if you don’t move house.</p>

<p>In short, I’d suggest sticking to gTLDs.
They’re at least <em>lower</em> risk than ccTLDs.</p>

<h2 id="helpful">“+1, Helpful”</h2>

<p>If you’ve found this post informative, why not <a href="https://ko-fi.com/tobermorytech">buy me a refreshing beverage</a>?
My typing fingers (both of them) thank you in advance for your generosity.</p>

<hr>





<hr>
			
			

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple has not fixed the macOS audio left/right balance bug for nearly 10 years (230 pts)]]></title>
            <link>https://twitter.com/ffaebi/status/1757669861377949930</link>
            <guid>39367460</guid>
            <pubDate>Wed, 14 Feb 2024 07:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ffaebi/status/1757669861377949930">https://twitter.com/ffaebi/status/1757669861377949930</a>, See on <a href="https://news.ycombinator.com/item?id=39367460">Hacker News</a></p>
Couldn't get https://twitter.com/ffaebi/status/1757669861377949930: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[UC Berkley: World Model on Million-Length Video and Language with RingAttention (163 pts)]]></title>
            <link>https://largeworldmodel.github.io/</link>
            <guid>39367141</guid>
            <pubDate>Wed, 14 Feb 2024 06:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://largeworldmodel.github.io/">https://largeworldmodel.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=39367141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div>
      <h2>Abstract</h2>
      <div><p>
          Current language models fall short in understanding aspects of the world not easily described in words, and struggle with complex, long-form tasks. Video sequences offer valuable temporal information absent in language and static images, making them attractive for joint modeling with language. Such models could develop a understanding of both human textual knowledge and the physical world, enabling broader AI capabilities for assisting humans. However, learning from millions of tokens of video and language sequences poses challenges due to memory constraints, computational complexity, and limited datasets. To address these challenges, we curate a large dataset of diverse videos and books, utilize the RingAttention technique to scalably train on long sequences, and gradually increase context size from 4K to 1M tokens. This paper makes the following contributions: (a) Largest context size neural network: We train one of the largest context size transformers on long video and language sequences, setting new benchmarks in difficult retrieval tasks and long video understanding. (b) Solutions for overcoming vision-language training challenges, including using masked sequence packing for mixing different sequence lengths, loss weighting to balance language and vision, and model-generated QA dataset for long sequence chat. (c) A highly-optimized implementation with RingAttention, masked sequence packing, and other key features for training on millions-length multimodal sequences. (d) Fully open-sourced a family of 7B parameter models capable of processing long text documents (LWM-Text, LWM-Text-Chat) and videos (LWM, LWM-Chat) of over 1M tokens.
          This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.
          </p></div>
    </div>
<!-- End paper abstract -->


<!-- 1M Vision-Language figure -->
<div>
    <h2>Question Answering Over 1 Hour Video.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_main.png" alt="1M video chat" width="820"></p><p><b>Figure 1. Long video understanding.</b> LWM can answer questions about over 1 hour YouTube video.</p>
      </div>
    </div>
<!-- End 1M Vision-Language figure -->

<!-- 1M Language figure -->
<div>
    <h2>Fact Retrieval Over 1M Context.</h2>
    <div>
      <div>
        <p><img src="https://largeworldmodel.github.io/materials/needle_comparison_baselines_log_linear_mix_rot.png" alt="1M fact retrieval" width="850"></p><p><b>Figure 2. Needle retrieval task.</b> LWM achieves high accuracy across 1M context window and outperforms GPT-4V and Gemini Pro.</p>
      </div>
      <br>
      <div>
        <p><img src="https://largeworldmodel.github.io/materials/single_needle_1M.png" alt="1M fact retrieval" width="900"></p><p><b>Figure 3. Needle retrieval task.</b> LWM achieves high accuracy for varying context sizes and positions in the context window.</p>
      </div>
      <!-- <div class="image-container" style="display: flex; justify-content: center; gap: 5px;">
        <div class="image">
          <img src="./materials/single_needle_1M.png" alt="Image 1" width="200" height="100">
        </div>
        <div class="image">
          <img src="./materials/multi_needle.png" alt="Image 2" width="200" height="100">
        </div>
      </div> -->
    </div>
    </div>

<!-- End 1M Language figure -->


<!-- Model figure -->
<div>
    <h2>Long Sequence Any-to-Any AR Prediction.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/model.png" alt="Model" width="700"></p><p><b>Figure 4. Any-to-Any Long Sequence Prediction.</b> RingAttention enables the use of a very large context window for training across diverse formats such as video-text, text-video, image-text, text-image, pure video, pure image, and pure text. See <a href="https://arxiv.org/abs/2402.08268" target="_blank">the LWM paper</a> for key features, including masked sequence packing and loss weighting, which allow effective video-language training.</p>
      </div>
    </div>
<!-- End model figure -->

<!-- Data figure. -->
<div>
    <h2>Modeling Diverse Videos and Books With RingAttention.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/data.png" alt="Data Mixture" width="900"></p><p><b>Figure 5. Context Extension and Vision-Language Training.</b> Expanding context size from 4K to 1M on books using RingAttention, followed by vision-language training on diverse forms of visual contents of lengths 32K to 1M. The lower panel shows interactive capabilities in understanding and responding to queries about complex multimodal world.</p>
    </div>
    </div>
<!-- End data figure -->


<!-- Image Generation figure -->
<div>
    <h2>Text-Image Generation.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_gen/set_1.png" alt="Fact retrieval" width="800">
      </p>
    </div>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_gen/set_2.png" alt="Fact retrieval" width="800"></p><p><b>Figure 6. Text to Image.</b> LWM generates images based on text prompts, autoregressively.</p>
      </div>
    </div>
<!-- End Image Generation figure -->


<!-- Text-Video figure -->
<div>
    <h2>Text-Video Generation.</h2>
    <div>
        <div>
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
                <source src="https://largeworldmodel.github.io/materials/video_gen/fireworks.mp4" type="video/mp4">
                </video>
              <center>
                <p>Fireworks exploding in the sky</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/waves.mp4" type="video/mp4">
              </video>
              <center>
                <p>Waves crashing against the shore</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/street.mp4" type="video/mp4">
              </video>
              <center>
                <p>A bustling street in London with red telephone booths and Big Ben in the background</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/mangoes.mp4" type="video/mp4">
              </video>
              <center>
                <p>Camera pans left to right on mago slices sitting on a table</p>
                </center>
          </div>
        </div>
        <div>
          
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/flowers.mp4" type="video/mp4">
              </video>
              <center>
                <p>Slow motion flower petals falling on the ground</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/campfire.mp4" type="video/mp4">
              </video>
              <center>
                <p>A burning campire in a forest</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/boat_storm.mp4" type="video/mp4">
              </video>
              <center>
              <p>A boat sailing on a stormy ocean</p>
              </center>
          </div>
        </div>
        <p><b>Figure 5. Text to Video.</b> LWM generates videos based on text prompts, autoregressively.</p>
      </div>
    </div>
<!-- Text-Video figure -->


<!-- Short Video Chat figure -->
<!-- <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3" style="white-space: nowrap;">Video-Based Conversation (30s - 5min).</h2>
    <div class="content has-text-justified">
      <div style="text-align: center;">
        <div style="width: 100%; overflow: hidden;">
          <div style="width: 35%; float: left;">
              <iframe src="https://www.youtube.com/embed/hkbJ75oei18?start=0&end=120" frameborder="0" allowfullscreen></iframe>
          </div>
          <div style="width: 2%;"> </div>
          <div style="width: 60%; float: right;">
            <img src="./materials/video_chat_comparison_1.png" width="100%">
          </div>
        </div>
        <br>
        <div style="width: 100%; overflow: hidden;">
          <div style="width: 35%; float: left;">
              <iframe src="https://www.youtube.com/embed/hkbJ75oei18?start=0&end=120" frameborder="0" allowfullscreen></iframe>
          </div>
          <div style="width: 2%;"> </div>
          <div style="width: 60%; float: right;">
            <img src="./materials/video_chat_comparison_2.png" width="100%">
          </div>
        </div>
        <p class="caption" style="width: 100%; text-align: center;"><b>Figure 7. Short Video Chat.</b> LWM answers questions about short videos and performs similarly to GPT-4V and Gemini Pro.</p>
      </div>
    </div>
    <br><br>
  </div>
</div> -->
<!-- End Short Video Chat figure -->

<!-- Image chat figure -->
<div>
    <h2>Image Based Conversation.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_chat.png" alt="1M video chat" width="820"></p><p><b>Figure 6. Image understanding.</b> LWM can answer questions about images.</p>
      </div>
    </div>
<!-- End image chat figure -->

<!-- Long Video Chat figure -->
<div>
    <h2>Video Chat Over 1 Hour YouTube Video.</h2>
    <div>
        <div>
          <p>
              <iframe src="https://www.youtube.com/embed/NgTV5bxK8Cs" frameborder="0" allowfullscreen=""></iframe>
          </p>
          
          <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_1.png" width="100%">
          </p>
        </div>
        <br>
        <div>
          <p>
              <iframe src="https://www.youtube.com/embed/ZrRMYgws-s4" frameborder="0" allowfullscreen=""></iframe>
          </p>
          
          <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_2.png" width="100%">
          </p>
        </div>
        <p><b>Figure 7. Long Video Chat.</b> LWM answers questions about 1 hour long YouTube video even if state-of-the-art commercial models GPT-4V and Gemini Pro both fail. The relevant clips for each example are at timestamps 9:56 (top) and 6:49 (bottom).</p>
      </div>
    </div>
<!-- End Short Video Chat figure -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quarto (152 pts)]]></title>
            <link>https://quarto.org/</link>
            <guid>39367103</guid>
            <pubDate>Wed, 14 Feb 2024 06:27:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quarto.org/">https://quarto.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39367103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hello-quarto-tabcontent">
<div id="python" role="tabpanel" aria-labelledby="python-tab">
<p>Combine Jupyter notebooks with flexible options to produce production quality output in a wide variety of formats. Author using traditional notebook UIs or with a plain text markdown representation of notebooks.</p>
<div>
<p><img src="https://quarto.org/images/demo-jupyter-plain.png" alt="Example Jupyter notebook entitled Palmer Penguins with code cells, text, and a scatterplot." height="605"></p>
<p><img src="https://quarto.org/images/demo-jupyter-output.png" alt="Output of example Jupyter notebook, Palmer Penguins, in HTML showing title, metadata, text, code, and scatterplot. At the top there is a dropdown option to show or hide the code."></p>
</div>
</div>
<div id="knitr" role="tabpanel" aria-labelledby="knitr-tab">
<p>Quarto is a multi-language, next generation version of R Markdown from Posit, with many new new features and capabilities. Like R Markdown, Quarto uses <a href="https://yihui.org/knitr/">knitr</a> to execute R code, and is therefore able to render most existing Rmd files without modification.</p>
<div>
<div id="cb1"><pre><code><span id="cb1-1"><span>---</span></span>
<span id="cb1-2"><span>title:</span><span> "ggplot2 demo"</span></span>
<span id="cb1-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb1-4"><span>date:</span><span> "5/22/2021"</span></span>
<span id="cb1-5"><span>format:</span><span> </span></span>
<span id="cb1-6"><span>  html:</span></span>
<span id="cb1-7"><span>    fig-width: 8</span></span>
<span id="cb1-8"><span>    fig-height: 4</span></span>
<span id="cb1-9"><span>    code-fold: true</span></span>
<span id="cb1-10"><span>---</span></span>
<span id="cb1-11"></span>
<span id="cb1-12"><span>## Air Quality</span></span>
<span id="cb1-13"></span>
<span id="cb1-14">@fig-airquality further explores the impact of temperature on ozone level.</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span>```{r}</span></span>
<span id="cb1-17"><span>#| label: fig-airquality</span></span>
<span id="cb1-18"><span>#| fig-cap: "Temperature and ozone level."</span></span>
<span id="cb1-19"><span>#| warning: false</span></span>
<span id="cb1-20"></span>
<span id="cb1-21"><span>library(ggplot2)</span></span>
<span id="cb1-22"><span>ggplot(airquality, aes(Temp, Ozone)) + </span></span>
<span id="cb1-23"><span>  geom_point() + </span></span>
<span id="cb1-24"><span>  geom_smooth(method = "loess")</span></span>
<span id="cb1-25"><span>```</span></span>
<span id="cb1-26"></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-knitr.png" alt="Example output with title (ggplot2 demo), author (Norah Jones), and date (5/22/2021). Below is a header reading Air Quality followed by body text (Figure 1 further explores the impact of temperature on ozone level.) with a toggleable code field, and figure with caption Figure 1 Temperature and ozone level."></p>
</div>
</div>
<div id="julia" role="tabpanel" aria-labelledby="julia-tab">
<p>Combine markdown and Julia code to create dynamic documents that are fully reproducible. Quarto executes Julia code via the <a href="https://github.com/JuliaLang/IJulia.jl">IJulia</a> Jupyter kernel, enabling you to author in plain text (as shown below) or render existing Jupyter notebooks.</p>
<div>
<div id="cb2"><pre><code><span id="cb2-1"><span>---</span></span>
<span id="cb2-2"><span>title:</span><span> "Plots Demo"</span></span>
<span id="cb2-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb2-4"><span>date:</span><span> "5/22/2021"</span></span>
<span id="cb2-5"><span>format:</span></span>
<span id="cb2-6"><span>  html:</span></span>
<span id="cb2-7"><span>    code-fold: true</span></span>
<span id="cb2-8"><span>jupyter:</span><span> julia-1.8</span></span>
<span id="cb2-9"><span>---</span></span>
<span id="cb2-10"></span>
<span id="cb2-11"><span>## Parametric Plots</span></span>
<span id="cb2-12"></span>
<span id="cb2-13">Plot function pair (x(u), y(u)). </span>
<span id="cb2-14">See @fig-parametric for an example.</span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>```{julia}</span></span>
<span id="cb2-17"><span>#| label: fig-parametric</span></span>
<span id="cb2-18"><span>#| fig-cap: "Parametric Plots"</span></span>
<span id="cb2-19"></span>
<span id="cb2-20"><span>using Plots</span></span>
<span id="cb2-21"></span>
<span id="cb2-22"><span>plot(sin, </span></span>
<span id="cb2-23"><span>     x-&gt;sin(2x), </span></span>
<span id="cb2-24"><span>     0, </span></span>
<span id="cb2-25"><span>     2π, </span></span>
<span id="cb2-26"><span>     leg=false, </span></span>
<span id="cb2-27"><span>     fill=(0,:lavender))</span></span>
<span id="cb2-28"><span>```</span></span>
<span id="cb2-29"></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-julia.png" alt="Example Plots Demo output with title, author, date published and main section on Parametric plots which contains text, a toggleable code field, and the output of the plot, with the caption Figure 1 Parametric Plots."></p>
</div>
</div>
<div id="observable" role="tabpanel" aria-labelledby="observable-tab">
<p>Quarto includes native support for Observable JS, a set of JavaScript enhancements created by Mike Bostock (the author of D3). Observable JS uses a reactive execution model, and is especially well suited for interactive data exploration and analysis.</p>
<div>
<div id="cb3"><pre><code><span id="cb3-1"><span>---</span></span>
<span id="cb3-2"><span>title:</span><span> "observable plot"</span></span>
<span id="cb3-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb3-4"><span>format:</span><span> </span></span>
<span id="cb3-5"><span>  html: </span></span>
<span id="cb3-6"><span>    code-fold: true</span></span>
<span id="cb3-7"><span>---</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>## Seattle Precipitation by Day (2012 to 2016)</span></span>
<span id="cb3-10"></span>
<span id="cb3-11"><span>```{ojs}</span></span>
<span id="cb3-12"><span>data = FileAttachment("seattle-weather.csv")</span></span>
<span id="cb3-13"><span>  .csv({typed: true})</span></span>
<span id="cb3-14"><span>  </span></span>
<span id="cb3-15"><span>Plot.plot({</span></span>
<span id="cb3-16"><span>  width: 800, height: 500, padding: 0,</span></span>
<span id="cb3-17"><span>  color: { scheme: "blues", type: "sqrt"},</span></span>
<span id="cb3-18"><span>  y: { tickFormat: i =&gt; "JFMAMJJASOND"[i] },</span></span>
<span id="cb3-19"><span>  marks: [</span></span>
<span id="cb3-20"><span>    Plot.cell(data, Plot.group({fill: "mean"}, {</span></span>
<span id="cb3-21"><span>      x: d =&gt; new Date(d.date).getDate(),</span></span>
<span id="cb3-22"><span>      y: d =&gt; new Date(d.date).getMonth(),</span></span>
<span id="cb3-23"><span>      fill: "precipitation", </span></span>
<span id="cb3-24"><span>      inset: 0.5</span></span>
<span id="cb3-25"><span>    }))</span></span>
<span id="cb3-26"><span>  ]</span></span>
<span id="cb3-27"><span>})</span></span>
<span id="cb3-28"><span>```</span></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-observable.png" alt="Example output with title, author, and date. Below, the main section reads Seattle Precipitation by Day (2012 to 2016) with a toggleable section to show code and a heatmap of the precipitation by day."></p>
</div>
</div>
</div><div>
<section id="dynamic-documents">
<h3>Dynamic Documents</h3>
<p>Generate dynamic output using Python, R, Julia, and Observable. Create reproducible documents that can be regenerated when underlying assumptions or data change.</p>

</section>
<section id="beautiful-publications">
<h3>Beautiful Publications</h3>
<p>Publish high-quality articles, reports, presentations, websites, and books in HTML, PDF, MS Word, ePub, and more. Use a single source document to target multiple formats.</p>

</section>
<section id="scientific-markdown">
<h3>Scientific Markdown</h3>
<p>Pandoc markdown has excellent support for LaTeX equations and citations. Quarto adds extensions for cross-references, figure panels, callouts, advanced page layout, and more.</p>

</section>
<section id="authoring-tools">
<h3>Authoring Tools</h3>
<p>Use your favorite tools including VS Code, RStudio, Jupyter Lab, or any text editor. Use the Quarto visual markdown editor for long-form documents.</p>

</section>
<section id="interactivity">
<h3>Interactivity</h3>
<p>Engage readers by adding interactive data exploration to your documents using Jupyter Widgets, htmlwidgets for R, Observable JS, and Shiny.</p>

</section>
<section id="websites-and-books">
<h3>Websites and Books</h3>
<p>Publish collections of documents as a blog or full website. Create books and manuscripts in both print formats (PDF and MS Word) and online formats (HTML and ePub).</p>

</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hi everyone yes, I left OpenAI yesterday (694 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1757600075281547344</link>
            <guid>39365935</guid>
            <pubDate>Wed, 14 Feb 2024 03:08:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1757600075281547344">https://twitter.com/karpathy/status/1757600075281547344</a>, See on <a href="https://news.ycombinator.com/item?id=39365935">Hacker News</a></p>
Couldn't get https://twitter.com/karpathy/status/1757600075281547344: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Andrej Karpathy Departs OpenAI (174 pts)]]></title>
            <link>https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs</link>
            <guid>39365288</guid>
            <pubDate>Wed, 14 Feb 2024 01:35:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs">https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs</a>, See on <a href="https://news.ycombinator.com/item?id=39365288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="fade-wrapper"><p><span>Andrej Karpathy, one</span> of the founding members of OpenAI, has left the company, a spokesperson confirmed.</p><p>Karpathy, a prominent artificial intelligence researcher, was developing a product he has described as an AI assistant and worked closely with the company’s research chief, Bob McGrew. While ChatGPT has been a hit with consumers, <a href="https://www.theinformation.com/org-charts/openai?rc=c48ukx">OpenAI</a> wants to launch software that can automate complex computer-based tasks, like filling out expense reports and entering them in accounting software, The Information <a href="https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?rc=1tesbi">reported</a> last week.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[100 Years Ago, IBM Was Born (304 pts)]]></title>
            <link>https://spectrum.ieee.org/ibm-history</link>
            <guid>39365187</guid>
            <pubDate>Wed, 14 Feb 2024 01:20:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ibm-history">https://spectrum.ieee.org/ibm-history</a>, See on <a href="https://news.ycombinator.com/item?id=39365187">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="100 Years Ago, IBM Was Born" data-elid="2667228583" data-post-url="https://spectrum.ieee.org/ibm-history" data-authors="James W. Cortada" data-page-title="100 Years Ago, IBM Was Born - IEEE Spectrum"><p>Happy birthday, IBM! You’re 100 years old! Or are you?</p><p>It’s true that the businesses that formed IBM began in the late 1800s. But it’s also true that a birth occurred in February 1924, with the renaming of the Computing-Tabulating-Recording Co. as the International Business Machines Corp. And a hundred years after that event, it serves as an important reminder that the world of computing and IT that IBM played a pivotal role in building has a longer history than we are likely to think. “Data processing” was coined over a century ago, while “office appliance” was in use in the 1880s. From the 19th century, through the 20th, and into the 21st, IBM was there, making HP, <a href="https://spectrum.ieee.org/tag/microsoft">Microsoft</a>, and Apple appear more like children or grandchildren of the IT world; <a href="https://spectrum.ieee.org/tag/facebook">Facebook</a>, <a href="https://spectrum.ieee.org/tag/google">Google</a>, and Twitter/X more like great-grandchildren. So let’s take a moment to contemplate the origins of an iconic corporation.</p><h2>The Assembling of IBM’s Parts</h2><p>Back in the late 19th century, as the U.S. economy gave birth to important large enterprises—telecommunications, railroads, manufacturing—the need to coordinate the work of individuals and dispersed locations led to the mechanization of information. Hence the emergence of typewriters, adding machines, and cash registers. Time-recording devices tracked when workers arrived and left, while scales weighed everything from meat at a butcher shop to industrial machine parts. For the 1890 U.S. census, Herman Hollerith’s punch-card tabulators calculated the nation’s population.</p><p><img alt="Black and white photo of women standing in line and watching as one woman turns the handle on a large dial. " data-rm-shortcode-id="0835b05aed29e173cfa4351a5613b076" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-women-standing-in-line-and-watching-as-one-woman-turns-the-handle-on-a-large-dial.jpg?id=51435036&amp;width=980" height="749" id="f344b" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-women-standing-in-line-and-watching-as-one-woman-turns-the-handle-on-a-large-dial.jpg?id=51435036&amp;width=980" width="1200"><small placeholder="Add Photo Caption...">Workers punched in and out on a dial recorder, sold by C-T-R’s International Time Recording Co.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>To provide these various products, countless little companies popped up, most of them lost to history. But at least three survived. One came into being in 1900 as the <a href="https://www.ibm.com/history/international-time-recording" rel="noopener noreferrer" target="_blank">International Time Recording Co.</a>, in Endicott, N.Y. ITR soon became known as <em>the</em> company for time-recording products in the United States and Canada. It had been formed and shaped by <a href="https://en.wikipedia.org/wiki/Charles_Ranlett_Flint" rel="noopener noreferrer" target="_blank">Charles Flint</a>, a dynamic character known for consolidating several companies into U.S. Rubber and several other companies into the American Chicle Co.—a.k.a the Chewing Gum Trust—and for his love of sailing and airplanes. </p><p>In 1901, Flint acquired the Computing Scale Co., which made tabletop scales popular with grocers in the Midwest. Over time, the company added cheese slicers and office furniture.</p><p><img alt="Black and white photo of a shop window displaying various scales and clocks. Across the top, it reads International Business Machines. " data-rm-shortcode-id="5e27d79acb17c77005289c2728254ea1" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-shop-window-displaying-various-scales-and-clocks-across-the-top-it-reads-international-business-mac.jpg?id=51435037&amp;width=980" height="832" id="aa273" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-shop-window-displaying-various-scales-and-clocks-across-the-top-it-reads-international-business-mac.jpg?id=51435037&amp;width=980" width="1332"><small placeholder="Add Photo Caption...">This showroom in Melbourne, Australia, displayed products from all three of IBM’s founding companies: scales, time recorders, and tabulating machines.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>In 1911, the Washington, D.C.–based Tabulating Machine Co. came into Flint’s orbit. Created in the 1880s and widely successful almost from its birth, TMC—maker of Hollerith’s punch-card tabulating equipment—produced the kind of breakthrough technology that large enterprises and government agencies desperately needed, to support massive undertakings like the census as well as inventory control and logistics. </p><p><img alt="Black and white photo of a wooden apparatus that looks like an upright piano and has rows of round dials across the top." data-rm-shortcode-id="5cba1a5a7ce6a5e71a65e08cbf5c55ae" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-wooden-apparatus-that-looks-like-an-upright-piano-and-has-rows-of-round-dials-across-the-top.jpg?id=51435038&amp;width=980" height="956" id="f9679" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-wooden-apparatus-that-looks-like-an-upright-piano-and-has-rows-of-round-dials-across-the-top.jpg?id=51435038&amp;width=980" width="1280"><small placeholder="Add Photo Caption...">Herman Hollerith’s punch-card tabulators were used in the 1890 U.S. Census.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>That same year, Flint smashed the three pieces together to form an entity that he unimaginatively called the Computing-Tabulating-Recording Co., or C-T-R. The scales business was okay, the time-recording business was booming, and the tabulating business had enormous potential but had yet to demonstrate it could keep up with demand. The creation of C-T-R yielded a company with promise, but the three entities didn’t coordinate or leverage each other’s assets and talents.</p><p><img alt="On the left, a black and white photo of a serious looking white man with an enormous mustache and wearing a suit. On the right a round logo with decorative letters that say CTR Co." data-rm-shortcode-id="b930b05cd23214821e4ec8f21fa51c31" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/on-the-left-a-black-and-white-photo-of-a-serious-looking-white-man-with-an-enormous-mustache-and-wearing-a-suit-on-the-right-a.jpg?id=51435040&amp;width=980" height="979" id="ea878" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/on-the-left-a-black-and-white-photo-of-a-serious-looking-white-man-with-an-enormous-mustache-and-wearing-a-suit-on-the-right-a.jpg?id=51435040&amp;width=980" width="1386"><small placeholder="Add Photo Caption...">Charles Flint [left] acquired the three companies that became the Computing-Tabulating-Recording Co., or C-T-R, and he hired Thomas J. Watson Sr. to build the business. </small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>Flint convinced his board of directors to hire a professional manager to see what could be done to grow the entire business. Enter <a href="https://www.ibm.com/history/thomas-watson-sr" rel="noopener noreferrer" target="_blank">Thomas Watson Sr.</a> in 1914. A highly successful sales executive who had recently spent two decades working at the <a href="https://www.ncr.com/about/history" rel="noopener noreferrer" target="_blank">National Cash Register Co.</a>—considered one of the best-run “cool” companies of the early 20th century. He was 42 when he arrived at C-T-R. Hollywood handsome, smart, mature, and confident in his skills as an executive working in the high-tech end of the economy, he quickly sized up the situation and went to work.</p><p><img alt="Black and white photo of a middle-aged white man in a suit sitting at his desk and looking at papers." data-rm-shortcode-id="7d79ff70f5089d086c604c34d1a4b168" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-middle-aged-white-man-in-a-suit-sitting-at-his-desk-and-looking-at-papers.jpg?id=51435043&amp;width=980" height="1010" id="ddf7c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-middle-aged-white-man-in-a-suit-sitting-at-his-desk-and-looking-at-papers.jpg?id=51435043&amp;width=980" width="1447"><small placeholder="Add Photo Caption...">Thomas J. Watson Sr., hired in 1914, propelled C-T-R into a high-tech data-processing enterprise.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>Watson brought in technical and sales colleagues from NCR, figured out who in C-T-R to take seriously, dismissed dissidents and incompetents, and sought ways to integrate all three pieces of the company. He concluded that the greatest potential for growth lay with Hollerith’s tabulators, so he focused on growing that market. Meanwhile, ITR had a popular product and, almost as important, a presence in Europe. The scales business, though, was a ho-hum opportunity as far as Watson was concerned, so he paid far less attention to it.</p><p>Watson integrated sales—his strong suit—across all three businesses, and trained the team to become a highly skilled, professional staff. His newly hired engineers, meanwhile, improved manufacturing operations.</p><p>The start of World War I blocked sales in Europe, but not in the United States. When the United States entered the war in 1917, government and private sector demand for C-T-R’s products grew rapidly. The end of the war opened up Europe’s huge market, and smaller ones in South America and parts of Asia.</p><h2>Birth of a Corporate Culture</h2><p>Slowly and steadily, Watson was creating a new corporate culture of ethics, paired with competent sales, solid technology, and a growing international perspective. The previously disjointed three-legged operation increasingly embraced his notion of “speed, accuracy, and flexibility,” in which the customer always came first. Despite a short recession at the start of the 1920s, C-T-R was emerging as a serious and well-run high-tech data-processing enterprise.</p><p><img alt="Image of an old-fashioned stock certificate for the Computing-Tabulating-Recording Co." data-rm-shortcode-id="d874d48aee7a120930a8773b8d49467b" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/image-of-an-old-fashioned-stock-certificate-for-the-computing-tabulating-recording-co.jpg?id=51435044&amp;width=980" height="973" id="ad240" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/image-of-an-old-fashioned-stock-certificate-for-the-computing-tabulating-recording-co.jpg?id=51435044&amp;width=980" width="1440"><small placeholder="Add Photo Caption...">Under Watson’s leadership, C-T-R’s revenue, staff, and product lines continued to grow. </small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>In 1914, the company had generated US $4 million in revenues (about $120 million today) with 1,346 employees; in 1920, revenues were $14 million, with 2,731 employees. In 1922, a recession year, C-T-R brought in only $9 million, but its staff had climbed to 3,043—solid evidence that Watson considered the recession a mere bump in the road. And for the next six decades, the company continued to grow. Not until the late 1980s did the company again face declining revenues (then measured in the billions of dollars) and a shrinking labor force (then in excess of 400,000).</p><p>In 1923, Watson, his executives, and employees collectively looked toward a future without immediate threats of war, where large organizations had embraced the concept of data processing powered by mechanical devices. Watson oversaw a rapidly expanding company that was grabbing market share away from competitors. He concluded that C-T-R’s future lay in pursuing a worldwide strategy, one for which he now had enough factories, sales offices, and trained employees. To be sure—and this is an important lesson for today’s startups—it had taken him a decade to reach the point where he could sit comfortably in his office in New York and imagine the next phase of C-T-R. </p><p>As a preamble to that future, he decided that the company’s image and reputation required some burnishing. He considered what the public knew about the firm, what the company stood for, what its brand would be, and how its reputation should be shaped. It was time, Watson decided, for a name upgrade.</p><h2>IBM Gets Its Name</h2><p>On 15 February 1924, <em>The</em><em>Wall Street Journal</em> published a short article on page 3, announcing that the “International Business Machines Corp. has been incorporated under the laws of New York to take over business and assets of Computing-Tabulating-Recording Co.” That’s how the world learned about the existence of IBM (that is, unless they worked in Canada, where employees had known their employer as <a href="https://www.ibm.com/ibm/ca/en/ibmcanada100/" rel="noopener noreferrer" target="_blank">IBM since 1917</a>).</p><p><img alt="Black and white logo with the words &quot;International Business Machines&quot; shaped into a globe" data-rm-shortcode-id="229adf65709226d31ff502b363f94bbd" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-logo-with-the-words-international-business-machines-shaped-into-a-globe.jpg?id=51435046&amp;width=980" height="755" id="3f643" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-logo-with-the-words-international-business-machines-shaped-into-a-globe.jpg?id=51435046&amp;width=980" width="1208"><small placeholder="Add Photo Caption...">In a 13 February 1924 letter to employees, Thomas Watson unveiled IBM’s new name.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>When Watson had been remaking C-T-R, he already thought the company’s name was awkward and uninspiring, but too many other issues required his urgent attention. In early 1924, though, he decided it was time. On 13 February 1924, Watson published a letter addressed to all employees to announce the change, explaining: “Our new name is particularly adaptable and suitable to our business, in view of the fact of our increasing growth, the consistent development of additions to our line, and our products covering such a wide range in the field of business machinery.” He concluded, “We are confident that this change in name will be beneficial to the business, and that the members of our field organization will find it of direct value in introducing our company and the products which we manufacture and distribute.”</p><p>The name change was also significant to C-T-R’s customers and vendors, and IBM salesmen rushed to explain how wonderful it would be. Then there was this little story in the <em>Wall Street Journal</em> three months after IBM’s incorporation. It may not have been true, but it suggests that everything comes down to execution. The article began by stating that some people were confused by the name, which it called “unwieldy,” and maybe this episode really did happen:</p><blockquote>The other day an uptown merchant called up a friend in Wall Street and inquired if he had ever heard of a new concern called the International Business Machines Corp.<p>“We have a big order from them,” he said, “and I am trying to check up on their credit rating. My partner has just gone downtown to demand a balance sheet from them.”</p><p>“Well,” said the broker, “in their last balance sheet they showed $800,000 cash and about $8,000,000 current assets. Their position seems pretty good. How big was the order?”</p><p>“About $100,” said the merchant. “Wait a minute, I want to head off my partner.”</p></blockquote><p>Implicit in that story was the real business problem of retaining the positive reputation of C-T-R while leveraging its new name to build business momentum. Watson and his colleagues spent the rest of the 1920s and 1930s creating a brand image that reflected their positive view and plans for the future but that also translated into transactions, profits, growth, and prestige. They battled ignorance of what their products could do, invented new products, hired people, expanded operations, overcame the worldwide tragedy of the Great Depression, and endured an antitrust challenge in the 1930s, the first of several.</p><p>The name change ultimately signaled a larger transformation under way. Whether the firm should have had a different name than IBM was less important than that Thomas Watson felt it was time to declare a grander purpose for the company. The tone of his comments, the nature of the company’s communications, and the way its staff interacted with the media and with customers evolved almost as a step change after the adoption of the new name. Watson was declaring that IBM wanted to become a major player in its industry and a leading international corporation. And so it did.<br></p><p><em>This article is adapted from excerpts of the author’s award-winning book, </em><a href="https://mitpress.mit.edu/9780262547826/ibm/" target="_blank">IBM: The Rise and Fall and Reinvention of a Global Icon</a><em>(MIT Press, 2019).</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bioluminescent petunias now available for U.S. market (247 pts)]]></title>
            <link>https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/</link>
            <guid>39365142</guid>
            <pubDate>Wed, 14 Feb 2024 01:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/">https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/</a>, See on <a href="https://news.ycombinator.com/item?id=39365142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


			
<p><img width="800" height="450" src="https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800.png" alt="Light Bio to introduce bioluminescent petunias into U.S. market" decoding="async" fetchpriority="high" srcset="https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800.png 800w, https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800-300x169.png 300w" sizes="(max-width: 800px) 100vw, 800px"></p>








<div>
<p><span>Light Bio, a synthetic biology startup, announced that it is now selling its bioluminescent petunias in the U.S.</span></p>
<p><span>With support from biotech leaders such as NFX and Ginkgo Bioworks, </span><span>Light Bio is reimagining the horticultural industry by introducing a new category of plants that emit an ethereal glow.&nbsp;</span></p>
<p><span>People are fascinated with glowing plants, and scientists have now revealed how to make these much brighter. This significant achievement, </span><a href="https://www.nature.com/articles/s41592-023-02152-y" target="_blank" rel="noopener"><span>documented in Nature Methods</span></a><span>, details genetic modifications that enhance bioluminescence in a variety of plants by up to 100 times. The team of 26 scientists created the brighter plants by optimizing genes isolated from multiple species of luminous mushrooms.</span></p>
<p><span>The new research builds on </span><span>an earlier discovery </span><span>for creating continuously glowing plants by inserting DNA obtained from the mushrooms. Those researchers had revealed a surprising similarity between mushroom bioluminescence and plant metabolism, allowing for more visible light than was previously possible. In this new report, the scientists have adapted the inserted genes to further boost luminescence.</span></p>
<p><span>Beginning in April, glowing petunias will be available under the brand Firefly Petunia, so named because the bright buds resemble fireflies. Last September, the </span><span>USDA reportedly determined</span> <span>through its independent evaluation that Light Bio’s genetically engineered Firefly Petunia may be safely grown and bred in the U.S.</span></p>
<p><span>Light Bio is taking orders at </span><a href="http://www.light.bio/" target="_blank" rel="noopener"><span>light.bio</span></a><span>.</span></p>

<br clear="all">

</div>
<br clear="all">


<br clear="all">


		
							

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Play the game I'm developing directly on its website (257 pts)]]></title>
            <link>https://athenacrisis.com</link>
            <guid>39365135</guid>
            <pubDate>Wed, 14 Feb 2024 01:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://athenacrisis.com">https://athenacrisis.com</a>, See on <a href="https://news.ycombinator.com/item?id=39365135">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Protein biomarkers predict dementia 15 years before diagnosis in new study (214 pts)]]></title>
            <link>https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b</link>
            <guid>39365104</guid>
            <pubDate>Wed, 14 Feb 2024 01:09:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b">https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b</a>, See on <a href="https://news.ycombinator.com/item?id=39365104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="news_8a17841a8d79730b018d9e2bbb0e054b">

                <div><p>In the largest study of its kind, scientists have shown how protein “biomarkers” predict dementia 15 years before diagnosis.</p></div>
<div><p>The research, published today in Nature Aging, shows how profiles of proteins in the blood accurately predict dementia up to 15 years prior to clinical diagnosis. These are known as biomarkers, which are molecules found in blood, other body fluids, or tissues that is a sign of a normal or abnormal process, or of a condition or disease.</p></div>
<div><p>In the study, scientists from The University of Warwick and Fudan University, Shanghai used the largest cohort of blood proteomics and dementia to date, including blood samples from 52,645 healthy participants recruited from UK Biobank – a population-based study cohort.</p></div>
<div><p>Blood samples collected between 2006 and 2010 were frozen and then analysed 10-15 years later by the research team who analysed them between April 2021 and February 2022. Until March 2023, a total of 1,417 participants went on to develop dementia – and these people’s blood showed dysregulation of protein biomarkers.</p></div>
<div><p>Of 1,463 proteins analysed, aided by with a type of artificial intelligence known as machine learning, 11 proteins were identified and combined as a protein panel, which the researchers have shown to be highly accurate at predicting future dementia. Further incorporation of conventional risk factors of age, sex, education level and genetics, showed for the first time the high accuracy of the predictive model, measured at over 90%*, indicating its potential future use in community-based dementia screening programs.</p></div>
<div><p>Proteins (for example Glial Fibrillary acidic protein, GFAP) had previously been identified as potential biomarkers for dementia in smaller studies, but this new research was much larger and conducted over several years. Known as a longitudinal analysis (a study conducted on a sample of participants over a number of years), the researchers were able to show the differences and trajectories between those with dementia and controls across 15 years.</p></div>
<div><p>An early diagnosis is critical for those with dementia. New drug technology can slow, or even reverse the progress of Alzheimer’s, but only if the disease is detected early enough. The drug lecanemab is one of two new treatments for the disease.</p></div>
<div><p>Lead author Professor Jianfeng Feng, from the Department of Computer Science, University of Warwick, hopes future drugs may be developed to interact with the proteins identified in the study.</p></div>
<div><p>Professor Feng emphasised that the combination of artificial intelligence and protein analysis offers a promising avenue for precision medicine. This is highly important for screening mid-aged to older individuals within the community who are at high risk of dementia. “This model could be seamlessly integrated into the NHS and used as a screening tool by GPs”, said Professor Feng.</p></div>
<div><p>Professor Wei Cheng, a co-corresponding author from Fudan University, explained that this research builds on the team’s previously developed dementia prediction model which used variables, such as age, presence of a certain gene and mother’s age at death. “Compared to our previous work, the newly developed protein-based model is obviously a breakthrough”, he said.</p></div>
<div><p>Another corresponding author Professor Jintai Yu, a neurovegetative disease specialist from Fudan University, added: “The proteomic biomarkers are more easily to access and non-invasive, and they can substantially facilitate the application of large-scale population screening”.</p></div>
<div><p>He also pointed drawbacks of previous risk models, which were primarily depended on intricate and difficult-to-obtain biomarkers using procedures such as lumbar puncture or complex imaging methods meaning their widespread use is hindered because of the invasive procedures and the high cost of carrying them out.</p></div>

<p><b>Notes to Editors</b></p>
<div><p>The University of Warwick signed a Memorandum of Understanding with Fudan University in 2022 and the two Universities work together designing and developing new research projects and run staff and student exchanges. </p></div>
<div><p>*The Area Under the Curve (AUC) figure is used to measure how good a model performs. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. this study had an AUC of over 0.9.</p></div>
<p><b>Case studies</b></p>
<div><p>The University works closely with people with dementia and their families at a Dementia Café, set up by Warwick Medical School. Should you wish to speak to a case study, please get in touch.</p></div>
<p><span><b>Media contact</b></span><span>&nbsp;</span></p>
<p><span>University of Warwick press office contact:</span><span>&nbsp;</span></p>
<p><span>Annie Slinn 07876876934</span><span>&nbsp;</span></p>
<p><span>Communications Officer | Press &amp; Media Relations | University of Warwick Email: </span><a href="mailto:annie.slinn@warwick.ac.uk" target="_blank" rel="noopener"><span>annie.slinn@warwick.ac.uk</span><span>Link opens in a new window</span></a><span>&nbsp;<p><strong>12 February 2024</strong></p></span></p>



            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Handwriting but not typewriting leads to widespread brain connectivity (283 pts)]]></title>
            <link>https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full</link>
            <guid>39364576</guid>
            <pubDate>Wed, 14 Feb 2024 00:00:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full</a>, See on <a href="https://news.ycombinator.com/item?id=39364576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <h2>Introduction</h2>
<p>Digital devices are more and more replacing traditional handwriting (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref25">Kiefer et al., 2015</a>), and as both writing and reading are becoming increasingly digitized in the classroom, we need to examine the implications of this practice (<a href="#ref35">Mangen and Balsvik, 2016</a>; <a href="#ref39">Patterson and Patterson, 2017</a>). Using a keyboard is now often recommended for young children as it is less demanding and frustrating (<a href="#ref15">Cunningham and Stanovich, 1990</a>; <a href="#ref17">Fears and Lockman, 2018</a>), allowing them to express themselves in written form earlier (<a href="#ref22">Hultin and Westman, 2013</a>). Be that as it may, handwriting training has not only been found to improve spelling accuracy (<a href="#ref15">Cunningham and Stanovich, 1990</a>) and better memory and recall (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref53">Smoker et al., 2009</a>; <a href="#ref36">Mueller and Oppenheimer, 2014</a>), but also to facilitate letter recognition and understanding (<a href="#ref33">Longcamp et al., 2005</a>, <a href="#ref31">2008</a>; <a href="#ref30">Li and James, 2016</a>). Such benefits for learning have been reported irrespective of when writing by hand using a traditional pen or pencil or using a digital pen (<a href="#ref38">Osugi et al., 2019</a>). Also, brain research shows that it is not just any motor activity that facilitates learning, but that accurately coordinating the complex hand movements while carefully shaping each letter when using a pen, is crucial (<a href="#ref40">Pei et al., 2021</a>). Apparently, the pen causes different underlying neurological processes that provide the brain with optimal conditions for learning and remembering (<a href="#ref4">Askvik et al., 2020</a>).</p>
<p>Recent findings in neuroscience reveal that neural processes are not as localized and static as is commonly believed, but that the brain is organized in a highly dynamic functional manner (<a href="#ref34">Lopes da Silva, 1991</a>; <a href="#ref52">Singer, 1993</a>). Under normal circumstances, several brain systems are continually working together (<a href="#ref12">Buzsáki, 2006</a>), showing an extremely flexible organization with structurally different neural tissue being involved in neural circuits that are only temporarily assembled so as to enable a given task (<a href="#ref16">Edelman and Gally, 2013</a>; <a href="#ref57">Van der Weel et al., 2019</a>). In such a view, neurons can change function entirely when incorporated in different systems (<a href="#ref2">Anderson, 2014</a>). <a href="#ref10">Bullmore and Sporns (2009)</a> refer to this type of flexible organization of the brain as functional connectivity as against structural connectivity.</p>
<p>Electroencephalography is well suited to studying brain electrical activity as a function of handwriting and typewriting in the millisecond scale. It permits the investigation of changes in the status of the underlying active networks (<a href="#ref34">Lopes da Silva, 1991</a>) and can reveal the everchanging spatial patterns of activations that are specific to any given task (<a href="#ref45">Pfurtscheller et al., 1996</a>). In particular, studies of cortical oscillations detected with high-density EEG are now considered an indispensable aspect of contemporary systems neuroscience (<a href="#ref18">Fröhlich, 2016</a>).</p>
<p>Brain oscillations can be considered as the interplay between the cortex and the thalamus and are generated by changes involved in the control of oscillations in neural networks (<a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>). The complex interactions and the resulting particular frequencies are thought to reflect distinct cognitive processes (<a href="#ref29">Klimesch et al., 1994</a>; <a href="#ref6">Berens and Horner, 2017</a>). The temporal organization of neuronal firing is crucial as it is assumed to be fundamental when forming long-term memories in the hippocampus (<a href="#ref6">Berens and Horner, 2017</a>).</p>
<p>Frequency-specific changes in EEG recordings can be observed as event-related synchronization (ERS) or event-related desynchronization (ERD; <a href="#ref42">Pfurtscheller and Aranibar, 1977</a>; <a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>). Spectral analyses are used to detect differences in a given frequency band (<a href="#ref44">Pfurtscheller et al., 1994</a>; <a href="#ref49">Salmelin and Hari, 1994</a>; <a href="#ref28">Klimesch et al., 1996</a>), by calculating the temporal dynamics of EEG oscillations and quantifying event-related amplifications and/or suppressions of rhythms.</p>
<p>A recent EEG-study from our lab showed that drawing by hand causes more activity and involves larger areas in the brain as opposed to typing on a keyboard (<a href="#ref56">Van der Meer and Van der Weel, 2017</a>). We concluded that the involvement of fine and intricate hand movements in notetaking, in contrast with pressing keys on a keyboard that all require the same simple finger movement, may be more advantageous for learning (<a href="#ref56">Van der Meer and Van der Weel, 2017</a>). A follow-up study observed event-related synchronized activity in the theta range in both children and students in parietal and central brain regions, but only when writing by hand (<a href="#ref4">Askvik et al., 2020</a>). As these studies have found evidence that writing by hand facilitates learning, the present study further investigated the neurobiological differences related to cursive writing and typewriting in the young adult brain. Specifically, we investigated how the various brain regions interconnect via neural networks when writing by hand as opposed to typing on a keyboard using frequency modulation and the latest in brain connectivity analysis (c.f., <a href="#ref54">Solomon et al., 2017</a>).</p> <h2>Methods</h2>
<h3>Participants</h3>
<p>Forty university students in their early twenties took part in the study at the Developmental Neuroscience Laboratory, Norwegian University of Science and Technology (NTNU). HD EEG data from 36 students were of good enough quality and sufficiently artifact-free to be included in the analyses. The data from 12 adult participants were already used in analyses in the time-frequency domain (<a href="#ref4">Askvik et al., 2020</a>). The present study performed a brain connectivity analysis to investigate the underlying neural networks involved in tasks of handwriting and typewriting. Participants were mostly students and were recruited at the university campus. They received a $15 cinema ticket for taking part. To avoid crossover effects between the two hemispheres, only right-handed participants were included, as determined by the Edinburgh Handedness Inventory (<a href="#ref37">Oldfield, 1971</a>). Allowing the use of (the fingers of) both hands would cause many unforeseen effects on the brain, which would make it hard to interpret the results. Participants gave their informed written consent, and it was made clear that they could withdraw from the experiment at any time without consequences. The Regional Committee for Medical and Health Ethics (Central Norway) approved the study.</p>
<h3>Experimental stimuli and EEG data acquisition</h3>
<p>E-prime 2.0 was used to individually display 15 different Pictionary words on a Microsoft Surface Studio. The participants used a digital pen to write in cursive by hand directly on the touchscreen, and a keyboard to typewrite the presented words.</p>
<p>The experiment comprised a total of 30 trials, where each word appeared in two different conditions, presented in a randomized order. For each trial, participants were instructed to either (a) <i>write in cursive</i> with their right hand the presented word with a digital pen directly on the screen, or (b) <i>type</i> the presented word using the right index finger on the keyboard. Before each trial, the instruction <i>write</i> or <i>type</i> appeared before one of the target words appeared, and the participants were given 25 s to either write by hand or type the word multiple times, separated by a space. EEG data were recorded only during the first 5 s of each trial. To prevent artifacts produced by head and eye movements caused by shifting gaze between the screen and the keyboard, typed words did not appear on the screen while the participant was typewriting. The writings produced by the participants (see <a href="#fig1">Figure 1</a> for example) were stored for offline analyses.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg" name="figure1" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig1" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 1</b>. Task design, behavioral performance, and sequence of the connectivity analyses. Visually presented words were either written by hand with a digital pen or typed on a keyboard while participants were wearing a 256-channel sensor array. EEG recordings were analyzed in terms of their functional connectivity, resulting in detailed network measures.</p></div>  
<p>A Geodesic Sensor Net (GSN; <a href="#ref55">Tucker et al., 1994</a>) with 256 evenly distributed electrodes was used to record EEG activity from the participant’s scalp at 500 Hz. The signals were amplified using a high-input EGI amplifier (<a href="#ref46">Picton et al., 2000</a>).</p>
<h3>Procedure</h3>
<p>On arrival in the lab, a consent form with all necessary information was given to the participants to sign. While the participant completed the handedness test, an appropriately sized net was soaked in a saline electrolyte for 15 min to optimize electrical conductivity. The participant was sitting comfortably in an adjustable chair in front of a table. The screen was placed on the table as closely as possible to the participant. A keyboard was also placed in a preferred position for the participant, and a digital pen was used for writing on the touchscreen. A pre-test was completed before the experiment started, where one of the experimenters was present in the room with the participant.</p>
<h3>Brain data pre-analyses</h3>
<p>Brain Electrical Source Analysis (BESA version 7.0) research software and BESA Connectivity (version 1.0) were used to analyze the EEG data. Epoch and filter settings were the same as in <a href="#ref4">Askvik et al. (2020)</a>.</p>
<p>Channels contaminated by movement artifacts were either removed or interpolated using spherical spline interpolation (<a href="#ref41">Perrin et al., 1989</a>; <a href="#ref46">Picton et al., 2000</a>). Up to 10% of channels could be defined as bad. Artifact correction was applied using manual and semi-automatic artifact correction with fitting spatial filters (<a href="#ref7">Berg and Scherg, 1994</a>; <a href="#ref23">Ille et al., 2002</a>; <a href="#ref19">Fujioka et al., 2011</a>).</p>
<p>The mean number of accepted trials out of 15 was 14.1 (<i>SD</i> = 1.1) for handwriting and 13.3 (<i>SD</i> = 1.3) for typewriting. To analyze oscillatory brain activity, a time-frequency analysis in brain space was then performed on accepted trials, see <a href="#ref4">Askvik et al. (2020)</a> for details. Optimal separation of brain activity was achieved using source montages derived from a multiple source model where waveforms separated different brain activities (<a href="#ref50">Scherg and Berg, 1991</a>). Using this procedure, the time-frequency content of different brain regions can be separated even if their activities severely overlap at the surface of the scalp (<a href="#ref21">Hoechstetter et al., 2004</a>). Then, the connectivity measure of Coherence was applied, resulting in a symmetric connectivity matrix with the upper and lower triangular matrix showing pairwise clusters symmetrical to the diagonal.</p>
<h3>Statistical analyses</h3>
<p>Probability of significance in connectivity values was tested with BESA Statistics 2.0, where connectivity measures for all participants were computed and the significant connectivity regions were used as guides in finding the extent of connectivity between the two experimental conditions of writing and typing. A combination of permutation tests and data clustering was employed. Permutation tests were applied to each set of time samples belonging to one frequency bin (<a href="#ref51">Simes, 1986</a>). Data clusters that showed a significant effect between conditions were assigned initial cluster values. Using within-group ANOVA’s, these initial cluster values were passed through permutation and assigned new clusters so that the significance of the initial cluster could be determined. A Bonferroni correction was used for multiple comparisons. As in <a href="#ref4">Askvik et al. (2020)</a>, cluster alpha, the significance level for building clusters in time and/or frequency, was set at 0.01 and the number of permutations was set at 10.000. Low- and high cut-offs for frequency were kept at 2 Hz and 60 Hz respectively, and epochs were set from −250 to 4,500 ms.</p> <h2>Results</h2>
<p>High-density EEGs were recorded during the experimental handwriting and typing conditions. Artifacts were removed from the raw EEG recordings, then the inverse problem was solved by using a 4-shell ellipsoidal head model to analyze the brain regions of interest. The time series of the reconstructed sources were obtained and transformed into the frequency domain using complex demodulation. The functional connectivity between the reconstructed sources was computed using the coherence method. A high-resolution functional connectivity matrix was obtained, and the corresponding functional brain network was visualized. Network measures were then extracted from the network (<a href="#fig1">Figure 1</a>).</p>
<p>A time-frequency display is shown for three important brain regions in <a href="#fig2">Figure 2</a> where the power/amplitude for each time is normalized to the mean power/amplitude of the baseline epoch for that frequency. The x-axis shows the time relative to the event, the y-axis shows the frequencies. The intensities are displayed as a color-coded plot.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg" name="figure2" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig2" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 2</b>. Grand average coherence results. Displayed are only three selected connectivity areas of interest for the two experimental conditions handwriting and typewriting (left panels), together with the difference in coherence between writing and typing and their permutation results (right panels). Connectivity areas of large significant difference between handwriting and typewriting included brain regions CR-PM (central right-parietal midline, top two panels on the left) and CL-PM (central left-parietal midline, middle two panels on the left), as well as CM-CR (central midline-central right, bottom two panels on the left), in frequencies ranging from theta (2 Hz) and up to gamma (60 Hz). The x-axes display the time interval from baseline to 4,500 ms of recordings of the trial. The signal magnitude reflects the estimated neural connectivity strength between the various brain areas during the experimental conditions compared to baseline activity (−250 to 0 ms). Positive connectivity is shown as (shades of) red-colored contours in handwriting/typewriting plots (panels on the left) and difference plots between handwriting and typewriting/permutation results (panels on the right). Positive connectivity is significantly more prominent in lower frequencies (theta 3.5–7.5 Hz and alpha 8–12.5) for handwriting (0 ≤ <i>p</i> &lt; 0.05, see also <a href="#fig4">Figure 4</a>).</p></div>  
<p><a href="#fig2">Figure 2</a> displays the results of grand average coherence results from just three selected connectivity areas of interest for clarity, for the two experimental conditions handwriting and typewriting (left panels), together with the difference in coherence between writing and typing and their permutation results (right panels). Connectivity areas of large significant difference between writing and typing included central and parietal brain regions in frequencies ranging from theta (2 Hz) and up to gamma (60 Hz). The signal magnitude reflects estimated connectivity strength between brain areas compared to baseline (−250 to 0 ms) activity. Positive connectivity patterns are shown in (shades of) red. In the central and parietal areas, positive coherence patterns were more prominent in the lower frequencies (theta 3.5–7.5 Hz and alpha 7.5–12.5 Hz) for handwriting as opposed to typewriting. For handwriting, this activity appeared between 1,000 to 2000 ms and lasted throughout the trial.</p>
<h3>The connectivity matrix of writing over typing</h3>
<p>Comparisons between the two conditions handwriting and typewriting were computed for each participant with time-frequency displays (changes in amplitude over time). TSE displays were limited between frequency cut-offs of 2–60 Hz, while frequency and time were sampled at 1 Hz and 50 ms, respectively. Symmetric connectivity measures were then obtained from BESA Connectivity and a high-resolution functional connectivity matrix between the reconstructed sources was computed using the coherence method (<a href="#ref48">Rosenberg et al., 1989</a>). Here, the number of in-phase components of two brain source signals at a specific frequency were described, and the corresponding functional brain network was visualized in <a href="#fig3">Figure 3</a>. Finally, network measures were extracted from the network and presented in <a href="#fig4">Figure 4</a>.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg" name="figure3" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig3" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 3</b>. Connectivity results of writing over typing. <b>(A)</b> Grand average connectivity matrix results show widespread theta/alpha coherence results (in red) between PL, PM, PR and CL, CM, CR brain regions when writing by hand, but not when typing. The y-axes display frequencies from 2 to 60 Hz. The x-axes display the time interval from baseline to 4,500 ms of recordings of the trial for all involved brain regions. The signal magnitude (coherence) reflects the estimated neural connectivity between the various brain regions during the writing condition compared to baseline activity (−250 to 0 ms). <b>(B)</b> Further illustration of connectivity patterns revealing a concentration of 16 significant connections for handwriting compared to typewriting. Connection lines in red indicate connectivity in the theta range whereas lines in blue indicate connectivity in the alpha range. Levels of significance in connectivity strength for handwriting, but not for typewriting are further indicated by solid (&lt;0.0001), dashed (&lt;0.005), and dotted (&lt;0.05) connection lines.</p></div>  
 <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg" name="figure4" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig4" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 4</b>. Symmetric connectivity matrix with <i>t</i>-values <b>(A)</b> and significance Table <b>(B)</b> with significant data clusters in the various sources of interest when handwriting is compared to typewriting in all participants. Thirty-two significant cluster differences marked in orange in <b>(A)</b> and fully described in <b>(B)</b> were found in the matrix and came out particularly significant in the parietal left (PL), parietal midline (PM), and parietal right (PR) areas.</p></div>  
<p><a href="#fig3">Figure 3A</a> displays the grand average connectivity matrix for writing compared to typing. The matrix offers a compact description of the pairwise connectivity between all separate regions of the brain. Throughout the matrix there is evidence for widespread theta/alpha coherence results (in red) particularly between areas parietal-right, parietal-mid, and parietal-left and between areas central-right and central-left. These connectivity patterns are further illustrated in <a href="#fig3">Figure 3B</a> revealing a concentration of no less than 32 significant clusters (see <a href="#fig4">Figure 4</a> for details) for handwriting, but not for typewriting. A pair of clusters will represent a single link between the corresponding pair of sources. The 32 significant clusters thus represent 16 significant connections.</p>
<h3>Main statistical effects</h3>
<p>Analyses were run to test for statistical differences in brain activity between handwriting and typewriting. <a href="#fig4">Figure 4</a> displays the detailed effects (<i>t</i>-tests) of the permutation results. These results showed 32 significant cluster differences between the two experimental conditions. The <i>t</i>-tests revealed significant differences in connectivity primarily in the theta (3.5–7.5 Hz) and alpha (8–12.5 Hz) range within three positive clusters (in orange), namely in the parietal left (PL), parietal midline (PM), and parietal right (PR) areas (see also <a href="#fig3">Figure 3</a>). These positive clusters suggest separate processes (differences in band power) between handwriting and typewriting mainly in the parietal but also in the central regions.</p>
<p>As can be seen in <a href="#fig4">Figure 4</a>, significant clusters of differences in band power were found mainly in parietal and central brain regions.</p>
<h3>Network measures</h3>
<p><a href="#fig5">Figure 5</a> shows the adjacency matrix for handwriting in the form of a hub, nodes, and edges of a simplified theoretical network (<a href="#fig5">Figure 5A</a>). Hubs have a higher degree of involvement in the network than nodes as expressed through their functional connectivity values (edges). <a href="#fig5">Figure 5B</a> shows the brain connectivity network results of handwriting compared to typewriting in this experiment. Proposed hubs (in red, ≥ 4 departures/arrivals) and nodes (in black, ≤ 3 departures/arrivals) interacting between brain regions PL, PM, PR and CL, CM, CR show widespread theta/alpha coherence patterns indicating stronger connectivity when writing as opposed to typing (<a href="#fig5">Figure 5C</a>).</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg" name="figure5" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig5" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 5</b>. The adjacency matrix for handwriting. <b>(A)</b> Hub, nodes, and edges of a simplified theoretical network. <b>(B)</b> Brain connectivity network of handwriting compared to typewriting in this experiment. <b>(C)</b> Hubs (in red, ≥ 4 departures/arrivals) and nodes (in black, ≤ 3 departures/arrivals) interacting between brain regions PL, PM, PR and CL, CM, CR show widespread theta/alpha connectivity patterns when writing by hand, but not when typing.</p></div>   <h2>General discussion</h2>
<p>This study investigated brain electrical connectivity as a function of handwriting and typewriting using high-density EEG in young adults. Participants used a digital pen to write visually presented words directly on a touchscreen and used a keyboard to type the words. Going beyond our previous study where we reported synchronized theta oscillations in parietal and central brain regions when children and students wrote by hand (<a href="#ref4">Askvik et al., 2020</a>), the present study performed connectivity analyses on the brain data of 36 students to explore underlying differences in coherence patterns when participants were typing versus writing by hand.</p>
<p>Focusing on brain connectivity that has shown to facilitate learning and memory (<a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>), we investigated parietal and central areas in specific frequency bands. These brain areas have been associated with attentional mechanisms and cognitive processes in visual perception (<a href="#ref44">Pfurtscheller et al., 1994</a>; <a href="#ref59">Vilhelmsen et al., 2019</a>) and language (<a href="#ref9">Brownsett and Wise, 2010</a>; <a href="#ref5">Benedek et al., 2014</a>), and have strong links to sensorimotor cortex (<a href="#ref58">Velasques et al., 2007</a>). We set out to investigate whether it is actually the act of forming the letters by hand itself that brings about larger connectivity in the brain, since perceptual, motor, and higher cognitive areas are more involved during handwriting as opposed to typewriting.</p>
<h3>Increased connectivity in theta/alpha range for handwriting</h3>
<p>The present findings revealed increased connectivity for handwriting over typewriting, suggesting that different underlying cognitive processes are involved in the two tasks. Increased connectivity within the theta (3.5–7.5 Hz) and alpha (8–12.5 Hz) frequency bands has been linked to mechanisms underlying sensorimotor integration (<a href="#ref8">Bland and Oddie, 2001</a>). As increased connectivity in the brain was observed only when writing by hand and not when simply pressing keys on the keyboard, our findings can be taken as evidence that handwriting promotes learning. Interestingly, the increased connectivity between the various brain regions seems to be linked to the specific sensorimotor processes that are so typical in handwriting.</p>
<p>The theta/alpha connectivity patterns found in the present study may indicate that different neural networks are involved in handwriting and typewriting. Interestingly, whereas connectivity in the alpha band is considered highly task-specific and is said to correspond to long-term memory performance, theta connectivity seems to be related to working memory and the ability to apprehend novel information (<a href="#ref29">Klimesch et al., 1994</a>, <a href="#ref28">1996</a>, <a href="#ref27">2001</a>; <a href="#ref26">Klimesch, 1999</a>; <a href="#ref47">Raghavachari et al., 2001</a>; <a href="#ref14">Clouter et al., 2017</a>). Thus, the enhanced brain connectivity for handwriting appears not to be related to differences in muscular involvement. It has also been proposed that hippocampal activity is reflected within the theta band (<a href="#ref29">Klimesch et al., 1994</a>), adding further support for the benefits of handwriting in terms of learning and memory formation.</p>
<p>Lower frequencies are considered especially suited for facilitating communication over longer distances in the brain, and are often reported to “gate” the occurrence of faster oscillations, for example when theta oscillations in humans are proposed to gate gamma (&gt; 30 Hz) oscillations (<a href="#ref13">Canolty et al., 2006</a>; <a href="#ref20">Halgren et al., 2018</a>). In general, this theta-to-gamma cross-frequency coupling can be linked to gamma networks desynchronizing and theta networks synchronizing during encoding, retrieval, and episodic memory formation (<a href="#ref11">Burke et al., 2013</a>). Others have suggested that theta connectivity activity (see <a href="#fig3">Figure 3</a>) is positively correlated with a brain region’s gamma power, suggesting a potent low-frequency mechanism for communication between brain regions (<a href="#ref54">Solomon et al., 2017</a>). Exploring these interactions may disclose the relationship between a brain region’s functional connectivity and local processing. Our results reflect such a low-frequency mechanism for interregional communication. Present findings of theta synchrony for handwriting suggest that low-frequency connections support the integration of information during memory formation, and follow from earlier studies that have reported low-frequency entrainment to be essential to cognition (<a href="#ref54">Solomon et al., 2017</a>).</p>
<h3>The importance of handwriting practice in a learning environment</h3>
<p>Handwriting requires fine motor control over the fingers, and it forces students to pay attention to what they are doing. Typing, on the other hand, requires mechanical and repetitive movements that trade awareness for speed. Our results reveal that whenever handwriting movements are included as a learning strategy, more of the brain gets stimulated, resulting in the formation of more complex neural network connectivity. It appears that the movements related to typewriting do not activate these connectivity networks the same way that handwriting does. The concurrent spatiotemporal pattern from vision, motor commands, and proprioceptive feedback provided through fine hand and finger movements, is lacking in typewriting, where only a simple key press is required to produce the entire wanted form (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref24">James, 2010</a>; <a href="#ref60">Vinci-Booher et al., 2016</a>, <a href="#ref61">2021</a>). In the present study, participants only used their right index finger for typing to prevent undesired crossover effects between the two hemispheres.</p>
<p>Thus, the ongoing substitution of handwriting by typewriting in almost every educational setting may seem somewhat misguided as it could affect the learning process in a negative way (<a href="#ref1">Alonso, 2015</a>; <a href="#ref35">Mangen and Balsvik, 2016</a>; <a href="#ref3">Arnold et al., 2017</a>). The present findings suggest that the intricate and precisely controlled handwriting movements have a beneficial impact on the brain’s connectivity patterns related to learning and remembering. The present study did not find evidence of such positive activation patterns when using a keyboard.</p>
<p>Even though maintaining handwriting practice in school is crucial, it is also important to keep up in the ever-developing digital world. Children should receive handwriting training at school to learn to write by hand successfully, and, at the same time learn to use a keyboard, depending on the task at hand. The present study shows that the neural connectivity patterns underlying handwriting and typewriting are distinctly different. Hence, being aware of when to write by hand or use a digital device is crucial, whether it is to take lecture notes to learn new concepts or to write longer essays.</p> <h2>Data availability statement</h2>
<p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p> <h2>Ethics statement</h2>
<p>The studies involving human participants were reviewed and approved by the Norwegian Data Protection Services for Research and by the Regional Committee for Medical and Health Ethics (Central Norway). The participants gave their written informed consent. Written informed consent was obtained from the individual(s) for the publication of any identifiable images or data included in this article.</p> <h2>Author contributions</h2>
<p>FW and AM contributed equally to all aspects of the study. All authors contributed to the article and approved the submitted version.</p> <h2>Funding</h2>
<p>The APC for this article was covered under one of NTNU's open publication agreements.</p> <h2>Conflict of interest</h2>
<p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p> <h2>Publisher’s note</h2>
<p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p> <h2>References</h2>
<div>
<p><a name="ref1" id="ref1"></a>Alonso, M. A. P. (2015). Metacognition and sensorimotor components underlying the process of handwriting and keyboarding and their impact on learning: an analysis from the perspective of embodied psychology. <i>Procedia Soc. Behav. Sci.</i> 176, 263–269. doi: 10.1016/j.sbspro.2015.01.470</p>
<p><a href="https://doi.org/10.1016/j.sbspro.2015.01.470" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+A.+P.+Alonso&amp;publication_year=2015&amp;title=Metacognition+and+sensorimotor+components+underlying+the+process+of+handwriting+and+keyboarding+and+their+impact+on+learning:+an+analysis+from+the+perspective+of+embodied+psychology&amp;journal=Procedia+Soc.+Behav.+Sci.&amp;volume=176&amp;pages=263-269" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref2" id="ref2"></a>Anderson, M. L. (2014). <i>After phrenology: Neural reuse and the interactive brain</i>. Cambridge, MA: MIT Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=M.+L.+Anderson&amp;publication_year=2014&amp;journal=After+phrenology:+Neural+reuse+and+the+interactive+brain&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref3" id="ref3"></a>Arnold, K. M., Umanath, S., Thio, K., Reilly, W. B., McDaniel, M. A., and Marsch, E. J. (2017). Understanding the cognitive processes involved in writing to learn. <i>J. Exp. Psychol. Appl.</i> 23, 115–127. doi: 10.1037/xap0000119</p>
<p><a href="https://doi.org/10.1037/xap0000119" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+M.+Arnold&amp;author=S.+Umanath&amp;author=K.+Thio&amp;author=W.+B.+Reilly&amp;author=M.+A.+McDaniel&amp;author=E.+J.+Marsch&amp;publication_year=2017&amp;title=Understanding+the+cognitive+processes+involved+in+writing+to+learn&amp;journal=J.+Exp.+Psychol.+Appl.&amp;volume=23&amp;pages=115-127" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref4" id="ref4"></a>Askvik, E. O., Van der Weel, F. R., and Van der Meer, A. L. H. (2020). The importance of cursive handwriting over typewriting for learning in the classroom. <i>Front. Psychol.</i> 11:1810. doi: 10.3389/fp-syg.2020.01810</p>
<p><a href="https://doi.org/10.3389/fp-syg.2020.01810" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+O.+Askvik&amp;author=F.+R.+Van+der+Weel&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2020&amp;title=The+importance+of+cursive+handwriting+over+typewriting+for+learning+in+the+classroom&amp;journal=Front.+Psychol.&amp;volume=11&amp;pages=1810" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref5" id="ref5"></a>Benedek, M., Schickel, R. J., Jauk, E., Fink, A., and Neubauer, A. C. (2014). Alpha power increases in right parietal cortex reflects focused internal attention. <i>Neuropsychologia</i> 56, 393–400. doi: 10.1016/j.neuropsychologia.2014.02.010 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24561034" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuropsychologia.2014.02.010" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Benedek&amp;author=R.+J.+Schickel&amp;author=E.+Jauk&amp;author=A.+Fink&amp;author=A.+C.+Neubauer&amp;publication_year=2014&amp;title=Alpha+power+increases+in+right+parietal+cortex+reflects+focused+internal+attention&amp;journal=Neuropsychologia&amp;volume=56&amp;pages=393-400" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref7" id="ref7"></a>Berg, P., and Scherg, M. (1994). A multiple source approach to the correction of eye artifacts. <i>Electroencephalogr. Clin. Neurophysiol.</i> 90, 229–241. doi: 10.1016/0013-4694(94)90094-9 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/7511504" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(94)90094-9" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=1994&amp;title=A+multiple+source+approach+to+the+correction+of+eye+artifacts&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=90&amp;pages=229-241" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref8" id="ref8"></a>Bland, B. H., and Oddie, S. D. (2001). Theta band oscillations and synchrony in the hippocampal formation and associated structures: the case for its role in sensorimotor integration. <i>Behav. Brain Res.</i> 127, 119–136. doi: 10.1016/S0166-4328(01)00358-8</p>
<p><a href="https://doi.org/10.1016/S0166-4328(01)00358-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=B.+H.+Bland&amp;author=S.+D.+Oddie&amp;publication_year=2001&amp;title=Theta+band+oscillations+and+synchrony+in+the+hippocampal+formation+and+associated+structures:+the+case+for+its+role+in+sensorimotor+integration&amp;journal=Behav.+Brain+Res.&amp;volume=127&amp;pages=119-136" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref10" id="ref10"></a>Bullmore, E., and Sporns, O. (2009). Complex brain networks: graph theoretical analysis of structural and functional systems. <i>Nat. Rev. Neurosci.</i> 10, 186–198. doi: 10.1038/nrn2575</p>
<p><a href="https://doi.org/10.1038/nrn2575" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+Bullmore&amp;author=O.+Sporns&amp;publication_year=2009&amp;title=Complex+brain+networks:+graph+theoretical+analysis+of+structural+and+functional+systems&amp;journal=Nat.+Rev.+Neurosci.&amp;volume=10&amp;pages=186-198" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref11" id="ref11"></a>Burke, J. F., Zaghloul, K. A., Jacobs, J., Williams, R. B., Sperling, M. R., Sharan, A. D., et al. (2013). Synchronous and asynchronous theta and gamma activity during episodic memory formation. <i>J. Neurosci.</i> 33, 292–304. doi: 10.1523/JNEUROSCI.2057-12.2013</p>
<p><a href="https://doi.org/10.1523/JNEUROSCI.2057-12.2013" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+F.+Burke&amp;author=K.+A.+Zaghloul&amp;author=J.+Jacobs&amp;author=R.+B.+Williams&amp;author=M.+R.+Sperling&amp;author=A.+D.+Sharan&amp;publication_year=2013&amp;title=Synchronous+and+asynchronous+theta+and+gamma+activity+during+episodic+memory+formation&amp;journal=J.+Neurosci.&amp;volume=33&amp;pages=292-304" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref12" id="ref12"></a>Buzsáki, G. (2006). <i>Rhythms of the brain</i>. New York, NY: Oxford University Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=G.+Buzs%C3%A1ki&amp;publication_year=2006&amp;journal=Rhythms+of+the+brain&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref13" id="ref13"></a>Canolty, R. T., Edwards, E., Dalal, S. S., Soltani, M., Nagarajan, S. S., Kirsch, H. E., et al. (2006). High gamma power is phase-locked to theta oscillations in human neocortex. <i>Science</i> 313, 1626–1628. doi: 10.1126/science.1128115 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/16973878" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1126/science.1128115" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+T.+Canolty&amp;author=E.+Edwards&amp;author=S.+S.+Dalal&amp;author=M.+Soltani&amp;author=S.+S.+Nagarajan&amp;author=H.+E.+Kirsch&amp;publication_year=2006&amp;title=High+gamma+power+is+phase-locked+to+theta+oscillations+in+human+neocortex&amp;journal=Science&amp;volume=313&amp;pages=1626-1628" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref14" id="ref14"></a>Clouter, A., Shapiro, K. L., and Hanslmayr, S. (2017). Theta phase synchronization is the glue that binds human associative memory. <i>Curr. Biol.</i> 27, 3143–3148.e6. doi: 10.1016/j.cub.2017.09.001 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28988860" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2017.09.001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Clouter&amp;author=K.+L.+Shapiro&amp;author=S.+Hanslmayr&amp;publication_year=2017&amp;title=Theta+phase+synchronization+is+the+glue+that+binds+human+associative+memory&amp;journal=Curr.+Biol.&amp;volume=27&amp;pages=3143-3148.e6" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref15" id="ref15"></a>Cunningham, A. E., and Stanovich, K. E. (1990). Early spelling acquisition: writing beats the computer. <i>J. Educ. Psychol.</i> 82, 159–162. doi: 10.1037/0022-0663.82.1.159</p>
<p><a href="https://doi.org/10.1037/0022-0663.82.1.159" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+E.+Cunningham&amp;author=K.+E.+Stanovich&amp;publication_year=1990&amp;title=Early+spelling+acquisition:+writing+beats+the+computer&amp;journal=J.+Educ.+Psychol.&amp;volume=82&amp;pages=159-162" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref17" id="ref17"></a>Fears, N. E., and Lockman, J. J. (2018). How beginning handwriting is influenced by letter knowledge: visual-motor coordination during children’s form copying. <i>J. Exp. Child Psychol.</i> 171, 55–70. doi: 10.1016/j.jecp.2018.01.017</p>
<p><a href="https://doi.org/10.1016/j.jecp.2018.01.017" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=N.+E.+Fears&amp;author=J.+J.+Lockman&amp;publication_year=2018&amp;title=How+beginning+handwriting+is+influenced+by+letter+knowledge:+visual-motor+coordination+during+children%E2%80%99s+form+copying&amp;journal=J.+Exp.+Child+Psychol.&amp;volume=171&amp;pages=55-70" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref18" id="ref18"></a>Fröhlich, F. (2016). <i>Network neuroscience</i>. London, UK: Academic Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=F.+Fr%C3%B6hlich&amp;publication_year=2016&amp;journal=Network+neuroscience&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref19" id="ref19"></a>Fujioka, T., Mourad, N., He, C., and Trainor, L. J. (2011). Comparison of artifact correction methods for infant EEG applied to extraction of event-related potential signals. <i>Clin. Neurophysiol.</i> 122, 43–51. doi: 10.1016/j.clinph.2010.04.036 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/20580601" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.clinph.2010.04.036" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+Fujioka&amp;author=N.+Mourad&amp;author=C.+He&amp;author=L.+J.+Trainor&amp;publication_year=2011&amp;title=Comparison+of+artifact+correction+methods+for+infant+EEG+applied+to+extraction+of+event-related+potential+signals&amp;journal=Clin.+Neurophysiol.&amp;volume=122&amp;pages=43-51" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref20" id="ref20"></a>Halgren, M., Fabó, D., Ulbert, I., Madsen, J. R., Eröss, L., Doyle, W. K., et al. (2018). Superficial slow rhythms integrate cortical processing in humans. <i>Sci. Rep.</i> 8:2055. doi: 10.1038/s41598-018-20662-0 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/29391596" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s41598-018-20662-0" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Halgren&amp;author=D.+Fab%C3%B3&amp;author=I.+Ulbert&amp;author=J.+R.+Madsen&amp;author=L.+Er%C3%B6ss&amp;author=W.+K.+Doyle&amp;publication_year=2018&amp;title=Superficial+slow+rhythms+integrate+cortical+processing+in+humans&amp;journal=Sci.+Rep.&amp;volume=8&amp;pages=2055" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref21" id="ref21"></a>Hoechstetter, K., Bornfleth, H., Weckesser, D., Ille, N., Berg, P., and Scherg, M. (2004). BESA source coherence: a new method to study cortical oscillatory coupling. <i>Brain Topogr.</i> 16, 233–238. doi: 10.1023/B:BRAT.0000032857.55223.5d </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15379219" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1023/B:BRAT.0000032857.55223.5d" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Hoechstetter&amp;author=H.+Bornfleth&amp;author=D.+Weckesser&amp;author=N.+Ille&amp;author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=2004&amp;title=BESA+source+coherence:+a+new+method+to+study+cortical+oscillatory+coupling&amp;journal=Brain+Topogr.&amp;volume=16&amp;pages=233-238" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref22" id="ref22"></a>Hultin, E., and Westman, M. (2013). Early literacy practices go digital. <i>Lit. Inf. Comput. Educ. J.</i> 4, 1096–1104. doi: 10.20533/licej.2040.2589.2013.0145</p>
<p><a href="https://doi.org/10.20533/licej.2040.2589.2013.0145" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+Hultin&amp;author=M.+Westman&amp;publication_year=2013&amp;title=Early+literacy+practices+go+digital&amp;journal=Lit.+Inf.+Comput.+Educ.+J.&amp;volume=4&amp;pages=1096-1104" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref23" id="ref23"></a>Ille, N., Berg, P., and Scherg, M. (2002). Artifact correction of the ongoing EEG using spatial filters based on artifact and brain signal topographies. <i>J. Clin. Neurophysiol.</i> 19, 113–124. doi: 10.1097/00004691-200203000-00002 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11997722" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1097/00004691-200203000-00002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=N.+Ille&amp;author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=2002&amp;title=Artifact+correction+of+the+ongoing+EEG+using+spatial+filters+based+on+artifact+and+brain+signal+topographies&amp;journal=J.+Clin.+Neurophysiol.&amp;volume=19&amp;pages=113-124" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref25" id="ref25"></a>Kiefer, M., Schuler, S., Mayer, C., Trumpp, N. M., Hille, K., and Sachse, S. (2015). Handwriting or typewriting? The influence of pen- or keyboard-based writing training on reading and writing performance in preschool children. <i>Adv.Cogn. Psychol.</i> 11, 136–146. doi: 10.5709/acp-0178-7 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/26770286" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.5709/acp-0178-7" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Kiefer&amp;author=S.+Schuler&amp;author=C.+Mayer&amp;author=N.+M.+Trumpp&amp;author=K.+Hille&amp;author=S.+Sachse&amp;publication_year=2015&amp;title=Handwriting+or+typewriting?+The+influence+of+pen-+or+keyboard-based+writing+training+on+reading+and+writing+performance+in+preschool+children&amp;journal=Adv.Cogn.+Psychol.&amp;volume=11&amp;pages=136-146" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref26" id="ref26"></a>Klimesch, W. (1999). EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis. <i>Brain Res. Rev.</i> 29, 169–195. doi: 10.1016/S0165-0173(98)00056-3 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10209231" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0165-0173(98)00056-3" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;publication_year=1999&amp;title=EEG+alpha+and+theta+oscillations+reflect+cognitive+and+memory+performance:+a+review+and+analysis&amp;journal=Brain+Res.+Rev.&amp;volume=29&amp;pages=169-195" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref27" id="ref27"></a>Klimesch, W., Doppelmayr, M., Yonelinas, A., Kroll, N. E., Lazzara, M., Röhm, D., et al. (2001). Theta synchronization during episodic retrieval: neural correlates of conscious awareness. <i>Cogn. Brain Res.</i> 12, 33–38. doi: 10.1016/S0926-6410(01)00024-6 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11489606" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0926-6410(01)00024-6" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=M.+Doppelmayr&amp;author=A.+Yonelinas&amp;author=N.+E.+Kroll&amp;author=M.+Lazzara&amp;author=D.+R%C3%B6hm&amp;publication_year=2001&amp;title=Theta+synchronization+during+episodic+retrieval:+neural+correlates+of+conscious+awareness&amp;journal=Cogn.+Brain+Res.&amp;volume=12&amp;pages=33-38" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref28" id="ref28"></a>Klimesch, W., Schimke, H., Doppelmayr, M., Ripper, B., Schwaiger, J., and Pfurtscheller, G. (1996). Event-related desynchronization (ERD) and the Dm-effect: does alpha desynchronization during encoding predict later recall performance? <i>Int. J. Psychophysiol.</i> 24, 47–60. doi: 10.1016/S0167-8760(96)00054-2 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8978435" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0167-8760(96)00054-2" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=H.+Schimke&amp;author=M.+Doppelmayr&amp;author=B.+Ripper&amp;author=J.+Schwaiger&amp;author=G.+Pfurtscheller&amp;publication_year=1996&amp;title=Event-related+desynchronization+(ERD)+and+the+Dm-effect:+does+alpha+desynchronization+during+encoding+predict+later+recall+performance?&amp;journal=Int.+J.+Psychophysiol.&amp;volume=24&amp;pages=47-60" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref29" id="ref29"></a>Klimesch, W., Schimke, H., and Schwaiger, J. (1994). Episodic and semantic memory: an analysis in the EEG theta and alpha band. <i>Electroencephalogr. Clin. Neurophysiol.</i> 91, 428–441. doi: 10.1016/0013-4694(94)90164-3 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/7529682" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(94)90164-3" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=H.+Schimke&amp;author=J.+Schwaiger&amp;publication_year=1994&amp;title=Episodic+and+semantic+memory:+an+analysis+in+the+EEG+theta+and+alpha+band&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=91&amp;pages=428-441" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref31" id="ref31"></a>Longcamp, M., Boucard, C., Gilhodes, J. C., and Anton, J. L. (2008). Learning through hand- or typewriting influences visual recognition of new graphic shapes: behavioral and functional imaging evidence. <i>J. Cogn. Neurosci.</i> 20, 802–815. doi: 10.1162/jocn.2008.20504</p>
<p><a href="https://doi.org/10.1162/jocn.2008.20504" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=C.+Boucard&amp;author=J.+C.+Gilhodes&amp;author=J.+L.+Anton&amp;publication_year=2008&amp;title=Learning+through+hand-+or+typewriting+influences+visual+recognition+of+new+graphic+shapes:+behavioral+and+functional+imaging+evidence&amp;journal=J.+Cogn.+Neurosci.&amp;volume=20&amp;pages=802-815" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref32" id="ref32"></a>Longcamp, M., Boucard, C., Gilhodes, J. C., and Velay, J. L. (2006). Remembering the orientation of newly learned characters depends on the associated writing knowledge: a comparison between handwriting and typing. <i>Hum. Mov. Sci.</i> 25, 646–656. doi: 10.1016/j.humov.2006.07.007 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17011660" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.humov.2006.07.007" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=C.+Boucard&amp;author=J.+C.+Gilhodes&amp;author=J.+L.+Velay&amp;publication_year=2006&amp;title=Remembering+the+orientation+of+newly+learned+characters+depends+on+the+associated+writing+knowledge:+a+comparison+between+handwriting+and+typing&amp;journal=Hum.+Mov.+Sci.&amp;volume=25&amp;pages=646-656" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref33" id="ref33"></a>Longcamp, M., Zerbato-Poudou, M. T., and Velay, J. L. (2005). The influence of writing practice on letter recognition in preschool children: a comparison between handwriting and typing. <i>Acta Psychol.</i> 119, 67–79. doi: 10.1016/j.actpsy.2004.10.019 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15823243" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.actpsy.2004.10.019" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=M.+T.+Zerbato-Poudou&amp;author=J.+L.+Velay&amp;publication_year=2005&amp;title=The+influence+of+writing+practice+on+letter+recognition+in+preschool+children:+a+comparison+between+handwriting+and+typing&amp;journal=Acta+Psychol.&amp;volume=119&amp;pages=67-79" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref34" id="ref34"></a>Lopes da Silva, F. H. (1991). Neural mechanisms underlying brain waves: from neural membranes to networks. <i>Electroencephalogr. Clin. Neurophysiol.</i> 79, 81–93. doi: 10.1016/0013-4694(91)90044-5 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/1713832" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(91)90044-5" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+H.+Lopes+da+Silva&amp;publication_year=1991&amp;title=Neural+mechanisms+underlying+brain+waves:+from+neural+membranes+to+networks&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=79&amp;pages=81-93" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref35" id="ref35"></a>Mangen, A., and Balsvik, L. (2016). Pen or keyboard in beginning writing instruction? Some perspectives from embodied cognition. <i>Trends Neurosci. Educ.</i> 5, 99–106. doi: 10.1016/j.tine.2016.06.003</p>
<p><a href="https://doi.org/10.1016/j.tine.2016.06.003" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Mangen&amp;author=L.+Balsvik&amp;publication_year=2016&amp;title=Pen+or+keyboard+in+beginning+writing+instruction?+Some+perspectives+from+embodied+cognition&amp;journal=Trends+Neurosci.+Educ.&amp;volume=5&amp;pages=99-106" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref36" id="ref36"></a>Mueller, P. A., and Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: advantages of longhand over laptop note taking. <i>Psychol. Sci.</i> 25, 1159–1168. doi: 10.1177/0956797614524581 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24760141" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1177/0956797614524581" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=P.+A.+Mueller&amp;author=D.+M.+Oppenheimer&amp;publication_year=2014&amp;title=The+pen+is+mightier+than+the+keyboard:+advantages+of+longhand+over+laptop+note+taking&amp;journal=Psychol.+Sci.&amp;volume=25&amp;pages=1159-1168" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref37" id="ref37"></a>Oldfield, R. C. (1971). The assessment and analysis of handedness: the Edinburgh inventory. <i>Neuropsychologia</i> 9, 97–113. doi: 10.1016/0028-3932(71)90067-4</p>
<p><a href="https://doi.org/10.1016/0028-3932(71)90067-4" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+C.+Oldfield&amp;publication_year=1971&amp;title=The+assessment+and+analysis+of+handedness:+the+Edinburgh+inventory&amp;journal=Neuropsychologia&amp;volume=9&amp;pages=97-113" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref38" id="ref38"></a>Osugi, K., Ihara, A. S., Nakajima, K., Kake, A., Ishimaru, K., Yokota, Y., et al. (2019). Differences in brain activity after learning with the use of a digital pen vs. an ink pen: an electroencephalography study. <i>Front. Hum. Neurosci.</i> 13:275. doi: 10.3389/fnhum.2019.00275 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/31447662" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.3389/fnhum.2019.00275" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Osugi&amp;author=A.+S.+Ihara&amp;author=K.+Nakajima&amp;author=A.+Kake&amp;author=K.+Ishimaru&amp;author=Y.+Yokota&amp;publication_year=2019&amp;title=Differences+in+brain+activity+after+learning+with+the+use+of+a+digital+pen+vs.+an+ink+pen:+an+electroencephalography+study&amp;journal=Front.+Hum.+Neurosci.&amp;volume=13&amp;pages=275" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref39" id="ref39"></a>Patterson, R. W., and Patterson, R. M. (2017). Computers and productivity: evidence from laptop use in the college classroom. <i>Econ. Educ. Rev.</i> 57, 66–79. doi: 10.1016/j.econedurev.2017.02.004</p>
<p><a href="https://doi.org/10.1016/j.econedurev.2017.02.004" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+W.+Patterson&amp;author=R.+M.+Patterson&amp;publication_year=2017&amp;title=Computers+and+productivity:+evidence+from+laptop+use+in+the+college+classroom&amp;journal=Econ.+Educ.+Rev.&amp;volume=57&amp;pages=66-79" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref40" id="ref40"></a>Pei, L., Longcamp, M., Leung, F. K.-S., and Ouyang, G. (2021). Temporally resolved neural dynamics underlying handwriting. <i>NeuroImage</i> 244:118578. doi: 10.1016/j.neuroimage.2021.118578 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/34534659" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2021.118578" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=L.+Pei&amp;author=M.+Longcamp&amp;author=F.+K.-S.+Leung&amp;author=G.+Ouyang&amp;publication_year=2021&amp;title=Temporally+resolved+neural+dynamics+underlying+handwriting&amp;journal=NeuroImage&amp;volume=244&amp;pages=118578" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref41" id="ref41"></a>Perrin, F., Pernier, J., Bertrand, O., and Echallier, J. F. (1989). Spherical splines for scalp potential and current density mapping. <i>Electroencephalogr. Clin. Neurophysiol.</i> 72, 184–187. doi: 10.1016/0013-4694(89)90180-6 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/2464490" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(89)90180-6" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+Perrin&amp;author=J.+Pernier&amp;author=O.+Bertrand&amp;author=J.+F.+Echallier&amp;publication_year=1989&amp;title=Spherical+splines+for+scalp+potential+and+current+density+mapping&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=72&amp;pages=184-187" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref42" id="ref42"></a>Pfurtscheller, G., and Aranibar, A. (1977). Event-related cortical desynchronization detected by power measurements of scalp EEG. <i>Electroencephalogr. Clin. Neurophysiol.</i> 42, 817–826. doi: 10.1016/0013-4694(77)90235-8 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/67933" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(77)90235-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=A.+Aranibar&amp;publication_year=1977&amp;title=Event-related+cortical+desynchronization+detected+by+power+measurements+of+scalp+EEG&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=42&amp;pages=817-826" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref43" id="ref43"></a>Pfurtscheller, G., and Lopes da Silva, F. H. (1999). Event-related EEG/MEG synchronization and desynchronization: basic principles. <i>Clin. Neurophysiol.</i> 110, 1842–1857. doi: 10.1016/S1388-2457(99)00141-8 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10576479" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S1388-2457(99)00141-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=F.+H.+Lopes+da+Silva&amp;publication_year=1999&amp;title=Event-related+EEG/MEG+synchronization+and+desynchronization:+basic+principles&amp;journal=Clin.+Neurophysiol.&amp;volume=110&amp;pages=1842-1857" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref44" id="ref44"></a>Pfurtscheller, G., Neuper, C., and Mohl, W. (1994). Event-related desynchronization (ERD) during visual processing. <i>Int. J. Psychophysiol.</i> 16, 147–153. doi: 10.1016/0167-8760(89)90041-x</p>
<p><a href="https://doi.org/10.1016/0167-8760(89)90041-x" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=C.+Neuper&amp;author=W.+Mohl&amp;publication_year=1994&amp;title=Event-related+desynchronization+(ERD)+during+visual+processing&amp;journal=Int.+J.+Psychophysiol.&amp;volume=16&amp;pages=147-153" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref45" id="ref45"></a>Pfurtscheller, G., Stancak, A. J., and Neuper, C. (1996). Event-related synchronization (ERS) in the alpha band - an electrophysiological correlate of cortical idling: a review. <i>Int. J. Psychophysiol.</i> 24, 39–46. doi: 10.1016/S0167-8760(96)00066-9 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8978434" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0167-8760(96)00066-9" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=A.+J.+Stancak&amp;author=C.+Neuper&amp;publication_year=1996&amp;title=Event-related+synchronization+(ERS)+in+the+alpha+band+-+an+electrophysiological+correlate+of+cortical+idling:+a+review&amp;journal=Int.+J.+Psychophysiol.&amp;volume=24&amp;pages=39-46" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref46" id="ref46"></a>Picton, T. W., Bentin, S., Berg, P., Donchin, E., Hillyard, S. A., Johnson, R. J., et al. (2000). Guidelines for using human event-related potentials to study cognition: recording standards and publication criteria. <i>Psychophysiology</i> 37, 127–152. doi: 10.1111/1469-8986.3720127</p>
<p><a href="https://doi.org/10.1111/1469-8986.3720127" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+W.+Picton&amp;author=S.+Bentin&amp;author=P.+Berg&amp;author=E.+Donchin&amp;author=S.+A.+Hillyard&amp;author=R.+J.+Johnson&amp;publication_year=2000&amp;title=Guidelines+for+using+human+event-related+potentials+to+study+cognition:+recording+standards+and+publication+criteria&amp;journal=Psychophysiology&amp;volume=37&amp;pages=127-152" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref47" id="ref47"></a>Raghavachari, S., Kahana, M. J., Rizzuto, D. S., Caplan, J. B., Kirschen, M. P., Bourgeois, B., et al. (2001). Gating of human theta oscillations by a working memory task. <i>J. Neurosci.</i> 21, 3175–3183. doi: 10.1523/jneurosci.21-09-03175.2001 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11312302" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/jneurosci.21-09-03175.2001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Raghavachari&amp;author=M.+J.+Kahana&amp;author=D.+S.+Rizzuto&amp;author=J.+B.+Caplan&amp;author=M.+P.+Kirschen&amp;author=B.+Bourgeois&amp;publication_year=2001&amp;title=Gating+of+human+theta+oscillations+by+a+working+memory+task&amp;journal=J.+Neurosci.&amp;volume=21&amp;pages=3175-3183" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref48" id="ref48"></a>Rosenberg, J. R., Amjad, A. M., Breeze, P., Brillinger, D. R., and Halliday, D. M. (1989). The fourier approach to the identification of functional coupling between neuronal spike trains. <i>Prog. Biophys. Mol. Biol.</i> 53, 1–31. doi: 10.1016/0079-6107(89)90004-7</p>
<p><a href="https://doi.org/10.1016/0079-6107(89)90004-7" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+R.+Rosenberg&amp;author=A.+M.+Amjad&amp;author=P.+Breeze&amp;author=D.+R.+Brillinger&amp;author=D.+M.+Halliday&amp;publication_year=1989&amp;title=The+fourier+approach+to+the+identification+of+functional+coupling+between+neuronal+spike+trains&amp;journal=Prog.+Biophys.+Mol.+Biol.&amp;volume=53&amp;pages=1-31" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref49" id="ref49"></a>Salmelin, R., and Hari, R. (1994). Spatiotemporal characteristics of sensorimotor neuromagnetic rhythms related to thumb movement. <i>Neuroscience</i> 60, 537–550. doi: 10.1016/0306-4522(94)90263-1 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8072694" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0306-4522(94)90263-1" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+Salmelin&amp;author=R.+Hari&amp;publication_year=1994&amp;title=Spatiotemporal+characteristics+of+sensorimotor+neuromagnetic+rhythms+related+to+thumb+movement&amp;journal=Neuroscience&amp;volume=60&amp;pages=537-550" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref51" id="ref51"></a>Simes, R. J. (1986). An improved Bonferroni procedure for multiple tests of significance. <i>Biometrica</i> 73, 751–754. doi: 10.1093/biomet/73.3.751</p>
<p><a href="https://doi.org/10.1093/biomet/73.3.751" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+J.+Simes&amp;publication_year=1986&amp;title=An+improved+Bonferroni+procedure+for+multiple+tests+of+significance&amp;journal=Biometrica&amp;volume=73&amp;pages=751-754" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref52" id="ref52"></a>Singer, W. (1993). Synchronization of cortical activity and its putative role in information processing and learning. <i>Annu. Rev. Physiol.</i> 55, 349–374. doi: 10.1146/annurev.ph.55.030193.002025 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8466179" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1146/annurev.ph.55.030193.002025" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Singer&amp;publication_year=1993&amp;title=Synchronization+of+cortical+activity+and+its+putative+role+in+information+processing+and+learning&amp;journal=Annu.+Rev.+Physiol.&amp;volume=55&amp;pages=349-374" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref53" id="ref53"></a>Smoker, T. J., Murphy, C. E., and Rockwell, A. K. (2009). Comparing memory for handwriting versus typing. <i>Proc. Hum. Factors Ergon. Soc. Annu. Meet.</i> 53, 1744–1747. doi: 10.1518/107118109X12524444081755</p>
<p><a href="https://doi.org/10.1518/107118109X12524444081755" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+J.+Smoker&amp;author=C.+E.+Murphy&amp;author=A.+K.+Rockwell&amp;publication_year=2009&amp;title=Comparing+memory+for+handwriting+versus+typing&amp;journal=Proc.+Hum.+Factors+Ergon.+Soc.+Annu.+Meet.&amp;volume=53&amp;pages=1744-1747" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref54" id="ref54"></a>Solomon, E. A., Kragel, J. E., Sperling, M. R., Sharan, A., Worrell, G., Kucewicz, M., et al. (2017). Widespread theta synchrony and high-frequency desynchronization underlies enhanced cognition. <i>Nat. Commun.</i> 8:1704. doi: 10.1038/s41467-017-01763-2 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/29167419" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s41467-017-01763-2" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+A.+Solomon&amp;author=J.+E.+Kragel&amp;author=M.+R.+Sperling&amp;author=A.+Sharan&amp;author=G.+Worrell&amp;author=M.+Kucewicz&amp;publication_year=2017&amp;title=Widespread+theta+synchrony+and+high-frequency+desynchronization+underlies+enhanced+cognition&amp;journal=Nat.+Commun.&amp;volume=8&amp;pages=1704" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref55" id="ref55"></a>Tucker, D. M., Liotti, M., Potts, G. F., Russell, G. S., and Posner, M. I. (1994). Spatiotemporal analysis of brain electrical fields. <i>Hum. Brain Mapp.</i> 1, 134–152. doi: 10.1002/hbm.460010206</p>
<p><a href="https://doi.org/10.1002/hbm.460010206" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=D.+M.+Tucker&amp;author=M.+Liotti&amp;author=G.+F.+Potts&amp;author=G.+S.+Russell&amp;author=M.+I.+Posner&amp;publication_year=1994&amp;title=Spatiotemporal+analysis+of+brain+electrical+fields&amp;journal=Hum.+Brain+Mapp.&amp;volume=1&amp;pages=134-152" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref56" id="ref56"></a>Van der Meer, A. L. H., and Van der Weel, F. R. (2017). Only three fingers write, but the whole brain works: a high-density EEG study showing advantages of drawing over typing for learning. <i>Front. Psychol.</i> 8:706. doi: 10.3389/fpsyg.2017.00706 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28536546" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.3389/fpsyg.2017.00706" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+L.+H.+Van+der+Meer&amp;author=F.+R.+Van+der+Weel&amp;publication_year=2017&amp;title=Only+three+fingers+write+but+the+whole+brain+works:+a+high-density+EEG+study+showing+advantages+of+drawing+over+typing+for+learning&amp;journal=Front.+Psychol.&amp;volume=8&amp;pages=706" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref57" id="ref57"></a>Van der Weel, F. R., Agyei, S. B., and Van der Meer, A. L. H. (2019). Infants’ brain responses to looming danger: degeneracy of neural connectivity patterns. <i>Ecol. Psychol.</i> 31, 182–197. doi: 10.1080/10407413.2019.1615210</p>
<p><a href="https://doi.org/10.1080/10407413.2019.1615210" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+R.+Van+der+Weel&amp;author=S.+B.+Agyei&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2019&amp;title=Infants%E2%80%99+brain+responses+to+looming+danger:+degeneracy+of+neural+connectivity+patterns&amp;journal=Ecol.+Psychol.&amp;volume=31&amp;pages=182-197" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref58" id="ref58"></a>Velasques, B., Machado, S., Portella, C. E., Silva, J. G., Basile, L. F. H., Cagy, M., et al. (2007). Electrophysiological analysis of a sensorimotor integration task. <i>Neurosci. Lett.</i> 426, 155–159. doi: 10.1016/j.neulet.2007.08.061 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17900806" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neulet.2007.08.061" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=B.+Velasques&amp;author=S.+Machado&amp;author=C.+E.+Portella&amp;author=J.+G.+Silva&amp;author=L.+F.+H.+Basile&amp;author=M.+Cagy&amp;publication_year=2007&amp;title=Electrophysiological+analysis+of+a+sensorimotor+integration+task&amp;journal=Neurosci.+Lett.&amp;volume=426&amp;pages=155-159" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref59" id="ref59"></a>Vilhelmsen, K., Agyei, S. B., Van der Weel, F. R., and Van der Meer, A. L. H. (2019). A high-density EEG study of differentiation between two speeds and directions of simulated optic flow in adults and infants. <i>Psychophysiology</i> 56:e13281. doi: 10.1111/psyp.13281 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/30175487" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1111/psyp.13281" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Vilhelmsen&amp;author=S.+B.+Agyei&amp;author=F.+R.+Van+der+Weel&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2019&amp;title=A+high-density+EEG+study+of+differentiation+between+two+speeds+and+directions+of+simulated+optic+flow+in+adults+and+infants&amp;journal=Psychophysiology&amp;volume=56&amp;pages=e13281" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref60" id="ref60"></a>Vinci-Booher, S., James, T. W., and James, K. H. (2016). Visual-motor functional connectivity in preschool children emerges after handwriting experience. <i>Trends Neurosci. Educ.</i> 5, 107–120. doi: 10.1016/j.tine.2016.07.006</p>
<p><a href="https://doi.org/10.1016/j.tine.2016.07.006" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Vinci-Booher&amp;author=T.+W.+James&amp;author=K.+H.+James&amp;publication_year=2016&amp;title=Visual-motor+functional+connectivity+in+preschool+children+emerges+after+handwriting+experience&amp;journal=Trends+Neurosci.+Educ.&amp;volume=5&amp;pages=107-120" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref61" id="ref61"></a>Vinci-Booher, S., James, T. W., and James, K. H. (2021). Visual-motor contingency during symbol production contributes to short term changes in the functional connectivity during symbol perception and long-term gains in symbol recognition. <i>NeuroImage</i> 227, 1–14. doi: 10.1016/j.neuroimage.2020.117554 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/33359354" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2020.117554" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Vinci-Booher&amp;author=T.+W.+James&amp;author=K.+H.+James&amp;publication_year=2021&amp;title=Visual-motor+contingency+during+symbol+production+contributes+to+short+term+changes+in+the+functional+connectivity+during+symbol+perception+and+long-term+gains+in+symbol+recognition&amp;journal=NeuroImage&amp;volume=227&amp;pages=1-14" target="_blank">Google Scholar</a></p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A bird's eye view of Polars (188 pts)]]></title>
            <link>https://pola.rs/posts/polars_birds_eye_view/</link>
            <guid>39363675</guid>
            <pubDate>Tue, 13 Feb 2024 22:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pola.rs/posts/polars_birds_eye_view/">https://pola.rs/posts/polars_birds_eye_view/</a>, See on <a href="https://news.ycombinator.com/item?id=39363675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A good library abstracts away many complexities for its user. Polars is no different in this regard, as it maintains a philosophy that queries you write should be performant by default without knowing any of the internals. However, many users are interested in what happens under the hood either as a learning experience or to squeeze that last bit of performance out of their queries. In this blog post, we will provide a bird’s eye view of how Polars works and in future posts we will deep dive into each of its components.</p>
<h2 id="high-level-overview">High level overview</h2>
<p>So, what is Polars? A short description would be “a query engine with a DataFrame frontend”. This is too high level even for a bird’s eye view. So let’s dive into the two elements, DataFrame and query engine, a bit more by looking at how a query gets executed. By taking a step-by-step journey through the execution of a query, we can observe each component in action and understand its role and purpose.</p>
<p>From a bird’s eye view, the execution of a query goes as follows. First we parse the query and validate it into a logical plan. The plan describes what the user intends to do, but not the how. Then our query optimizer traverses this plan (several times) to optimize any unnecessary work and produces an optimized logical plan. Following this optimization phase, the query planner transforms this logical plan into a physical plan, which outlines how the query is to be executed. This finalized physical plan serves as the ultimate input for the actual execution of the query and runs our compute kernels.</p>
<p><img alt="" src="https://pola.rs/_astro/birds-eye-overview.6f8aa92d_ZVHkQh.webp" width="3074" height="209" loading="lazy" decoding="async"></p>
<h2 id="query">Query</h2>
<p>When you interact with Polars, you use our DataFrame API. This API is specifically designed to allow for parallel execution and with performance in mind. Writing a Polars query in that sense is writing a small program (or this case query) in a domain-specific language (<a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>) designed by Polars. This DSL has its own set of rules governing which queries are valid and which ones are not.</p>
<p>For this post, let’s use the famous NYE taxi dataset with taxi trips<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>. In the example below we calculate the average cost per minute for a trip over 25 dollars by zone. This case is simple enough to be easily understood while containing enough depth to showcase the purpose of the query engine.</p>
<pre tabindex="0"><code><span><span>import</span><span> polars </span><span>as</span><span> pl</span></span>
<span></span>
<span><span>query </span><span>=</span><span> (</span></span>
<span><span>    pl</span><span>.</span><span>scan_parquet</span><span>(</span><span>"yellow_tripdata_2023-01.parquet"</span><span>)</span></span>
<span><span>    .</span><span>join</span><span>(pl.</span><span>scan_csv</span><span>(</span><span>"taxi_zones.csv"</span><span>), left_on</span><span>=</span><span>"PULocationID"</span><span>, right_on</span><span>=</span><span>"LocationID"</span><span>)</span></span>
<span><span>    .</span><span>filter</span><span>(pl.</span><span>col</span><span>(</span><span>"total_amount"</span><span>) </span><span>&gt;</span><span> 25</span><span>)</span></span>
<span><span>    .</span><span>group_by</span><span>(</span><span>"Zone"</span><span>)</span></span>
<span><span>    .</span><span>agg</span><span>(</span></span>
<span><span>        (pl.</span><span>col</span><span>(</span><span>"total_amount"</span><span>) </span><span>/</span></span>
<span><span>        (pl.</span><span>col</span><span>(</span><span>"tpep_dropoff_datetime"</span><span>) </span><span>-</span><span> pl.</span><span>col</span><span>(</span><span>"tpep_pickup_datetime"</span><span>)).dt.</span><span>total_minutes</span><span>()</span></span>
<span><span>        ).</span><span>mean</span><span>().</span><span>alias</span><span>(</span><span>"cost_per_minute"</span><span>)</span></span>
<span><span>    ).</span><span>sort</span><span>(</span><span>"cost_per_minute"</span><span>,descending</span><span>=</span><span>True</span><span>)</span></span>
<span><span>)</span></span></code></pre>
<p>The query above is of type <code>LazyFrame</code>. It returns instantly while the NY taxi trips dataset is over 3 million rows, so what has happened? The statement defines the query, but does not yet execute it. This concept is known as lazy evaluation and is one of the key strengths of Polars. If you look into the data structure on the Rust side, you will see it contains two elements: a <code>logical_plan</code> and configuration flags for the optimizer <code>opt_state</code>.</p>
<pre tabindex="0"><code><span><span>pub</span><span> struct</span><span> LazyFrame</span><span> {</span></span>
<span><span>    pub</span><span> logical_plan</span><span>:</span><span> LogicalPlan</span><span>,</span></span>
<span><span>    pub</span><span>(</span><span>crate</span><span>) opt_state</span><span>:</span><span> OptState</span><span>,</span></span>
<span><span>}</span></span></code></pre>
<p>The logical plan is a tree with the data sources as leaves of the tree and the transformations as nodes. The plan describes the structure of a query and the expressions it contains.</p>
<pre tabindex="0"><code><span><span>pub</span><span> enum</span><span> LogicalPlan</span><span> {</span></span>
<span><span>    /// Filter on a boolean mask</span></span>
<span><span>    Selection</span><span> {</span></span>
<span><span>        input</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        predicate</span><span>:</span><span> Expr</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>    /// Column selection</span></span>
<span><span>    Projection</span><span> {</span></span>
<span><span>        expr</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        input</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        schema</span><span>:</span><span> SchemaRef</span><span>,</span></span>
<span><span>        options</span><span>:</span><span> ProjectionOptions</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>    /// Join operation</span></span>
<span><span>    Join</span><span> {</span></span>
<span><span>        input_left</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        input_right</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        schema</span><span>:</span><span> SchemaRef</span><span>,</span></span>
<span><span>        left_on</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        right_on</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        options</span><span>:</span><span> Arc</span><span>&lt;</span><span>JoinOptions</span><span>&gt;,</span></span>
<span><span>    },</span></span>
<span><span>    ...</span></span>
<span><span>}</span></span></code></pre>
<p>One important step when converting your query into a logical plan is validation. Polars knows the schema of the data upfront and can validate if the transformations are correct. This ensures you don’t run into any errors halfway through executing a query. For instance, defining a query where you select a column that does not exist returns an error before execution</p>
<pre tabindex="0"><code><span><span>pl</span><span>.</span><span>LazyFrame</span><span>([]).</span><span>select</span><span>(pl.</span><span>col</span><span>(</span><span>"does_not_exist"</span><span>))</span></span></code></pre>
<pre tabindex="0"><code><span><span>polars.exceptions.ColumnNotFoundError: column_does_not_exist</span></span>
<span><span></span></span>
<span><span>Error originated just after this operation:</span></span>
<span><span>DF []; PROJECT */0 COLUMNS; SELECTION: "None"</span></span></code></pre>
<p>We can view the logical plan by calling <code>show_graph</code> on a <code>LazyFrame</code>:</p>
<pre tabindex="0"><code><span><span>query</span><span>.</span><span>show_graph</span><span>(optimized</span><span>=</span><span>False</span><span>)</span></span></code></pre>
<p><img alt="non optimized query plan" src="https://pola.rs/_astro/non-optimized.82896225_ZbNItr.svg" width="984" height="383" loading="lazy" decoding="async"></p>
<h2 id="query-optimization">Query Optimization</h2>
<p>The goal of the query optimizer is to optimize the <code>LogicalPlan</code> for performance. It does this by traversing the tree structure and modifying/adding/removing nodes.There are many types of optimizations that will lead to faster execution, for instance changing the order of operations. Generally, you want <code>filter</code> operations to occur as early as possible as it allows you to throw away any unused data and avoid unnessary work. In the example we can show our optimized logical plan with the same <code>show_graph</code> function:</p>
<pre tabindex="0"><code><span><span>query</span><span>.</span><span>show_graph</span><span>()</span></span></code></pre>
<p><img alt="optimized query plan" src="https://pola.rs/_astro/optimized.e46e3f3c_ZSiab5.svg" width="1083" height="383" loading="lazy" decoding="async"></p>
<p>At first glance, it might look like both plans (optimized vs non optimized) are the same. However, two important optimizations have occured <strong>Projection pushdown</strong> and <strong>Predicate pushdown</strong>.</p>
<p>Polars has analyzed the query and noted that only use a small set of columns is used. For the trip data there are four columns. For the zone data there are two columns. Reading in the entire dataset would be wasteful as there is no need for the other columns. Therefore, by analyzing your query, <strong>Projection Pushdown</strong> will speed up reading in the data significantly. You can see the optimization in the leaf nodes under $\pi$  4/19 and $\pi$ 2/4.</p>
<p>With <strong>Predicate pushdown</strong> Polars filters data as close to the source as possible. This avoids reading in data that a later stage in the query will be discarded. The filter node has been moved to the parquet reader under $\sigma$ which indicates our reader will immediately remove rows which do not match our filter. The next join operation will a lot faster as there is less data coming in.</p>
<p>Polars supports a range of optimizations which can be viewed <a href="https://docs.pola.rs/user-guide/lazy/optimizations/">here</a>.</p>
<h2 id="query-execution">Query Execution</h2>
<p>Once the logical plan has been optimized, it is time for execution. The logical plan is a blueprint for what the user wants to execute, not the how. This is where the physical plan comes into play. A naive solution would be to have one join algorithm and one sort algorithm; that way, you could execute the logical plan directly. However, this comes at a huge performance cost, because knowing the characteristics of your data and the environment you run in allows Polars to select more specialized algorithms. Thus there is not one join algorithm, but multiple, each with their own unique style and performance. The query planner converts the LogicalPlan into a PhysicalPlan and picks the best algorithms for the query. Then our compute engine performs the operations. This post will not go into much detail about the execution model of our engines or how it is able to work so fast. That is left for another time.</p>
<p>When we look the performance difference of both plans (optimized vs non-optimized), we can see a 4x improvement. This is the power of lazy execution and using a query engine instead of eagerly evaluating every expression in order. It allows the engine to optimize and avoid unnecessary work. This whole improvement comes at zero cost for the user as all they have to do is write the query. All the complexity is hidden inside the query engine.</p>
<pre tabindex="0"><code><span><span>%%</span><span>time</span></span>
<span><span>query</span><span>.</span><span>collect</span><span>(no_optimization</span><span>=</span><span>True</span><span>)</span><span>;</span></span></code></pre>
<pre tabindex="0"><code><span><span>CPU times: user 2.45 s, sys: 1.18 s, total: 3.62 s</span></span>
<span><span>Wall time: 544 ms</span></span></code></pre>
<pre tabindex="0"><code><span><span>%%</span><span>time</span></span>
<span><span>query</span><span>.</span><span>collect</span><span>()</span><span>;</span></span></code></pre>
<pre tabindex="0"><code><span><span>CPU times: user 616 ms, sys: 54.2 ms, total: 670 ms</span></span>
<span><span>Wall time: 135 ms</span></span></code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>During this post we covered the main components of Polars. Hopefully by now you will have a better understanding of how Polars works from its API down to execution. The next posts will dive deeper into every component, so stay tuned!</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>The NYE taxi trip dataset is available at <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">nyc.gov</a>. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fly.io Has GPUs Now (532 pts)]]></title>
            <link>https://fly.io/blog/fly-io-has-gpus-now/</link>
            <guid>39363499</guid>
            <pubDate>Tue, 13 Feb 2024 22:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/fly-io-has-gpus-now/">https://fly.io/blog/fly-io-has-gpus-now/</a>, See on <a href="https://news.ycombinator.com/item?id=39363499">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Xe Iaso" src="https://fly.io/static/images/xe.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Xe Iaso
                 </dd>
                  <dt>pony.social/@cadey</dt>
                  <dd>
                    <a href="https://pony.social/@cadey" target="_blank">
                      pony.social/@cadey
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/fly-io-has-gpus-now/assets/llama-portal-cover.webp" alt="A cartoon illustration of a green haired woman with a ponytail looks into a portal in a datacentre to see a graceful llama.">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>We’re Fly.io, we’re a new public cloud that lets you put your compute where it matters: near your users. Today we’re announcing that you can do this with GPUs too, allowing you to do AI workloads on the edge. Want to find out more? Keep reading.</p><h2 id="ai-is-pretty-fly"><a href="#ai-is-pretty-fly" aria-label="Anchor"></a>AI is pretty fly</h2>
<p>AI is apparently a bit of a <em>thing</em> (maybe even <em>an thing</em> come to think about it). We’ve seen entire industries get transformed in the wake of ChatGPT existing (somehow it’s only been around for a year, I can’t believe it either). It’s likely to leave a huge impact on society as a whole in the same way that the Internet did once we got search engines. Like any good venture-capital funded infrastructure provider, we want to enable you to do hilarious things with AI using industrial-grade muscle.</p>

<p>Fly.io lets you run a full-stack app - or an entire dev platform based on the <a href="https://fly.io/docs/machines/">Fly Machines API</a> - close to your users. Fly.io GPUs let you attach an <a href="https://www.nvidia.com/en-us/data-center/a100/">Nvidia A100</a> to whatever you’re building, harnessing the full power of CUDA with more VRAM than your local 4090 can shake a ray-traced stick at. With these cards (or whatever you call a GPU attached to SXM fabric), AI/ML workloads are at your fingertips. You can <a href="https://fly.io/blog/transcribing-on-fly-gpu-machines/">recognize speech</a>, segment text, summarize articles, synthesize images, and more at speeds that would make your homelab blush. You can even set one up as your programming companion with <a href="https://github.com/deepseek-ai/DeepSeek-Coder">your model of choice</a> in case you’ve just not been feeling it with the output of <em>other</em> models changing over time.</p>

<p>If you want to find out more about what these cards are and what using them is like, check out <a href="https://fly.io/blog/what-are-these-gpus-really/">What are these “GPUs” really?</a> It covers the history of GPUs and why it’s ironic that the cards we offer are called “Graphics Processing Units” in the first place.</p>
<h2 id="fly-io-gpus-in-action"><a href="#fly-io-gpus-in-action" aria-label="Anchor"></a>Fly.io GPUs in Action</h2>
<p>We want you to deploy your own code with your favorite models on top of Fly.io’s cloud backbone. Fly.io GPUs make this really easy.</p>

<p>You can get a GPU app running <a href="https://ollama.ai/">Ollama</a> (our friends in text generation) in two steps:</p>

<ol>
<li>Put this in your <code>fly.toml</code>:
</li></ol>
<div>
  <pre><code><span>app</span> <span>=</span> <span>"sandwich_ai"</span>
<span>primary_region</span> <span>=</span> <span>"ord"</span>
<span>vm.size</span> <span>=</span> <span>"a100-40gb"</span>

<span>[build]</span>
  <span>image</span> <span>=</span> <span>"ollama/ollama"</span>

<span>[mounts]</span>
  <span>source</span> <span>=</span> <span>"models"</span>
  <span>destination</span> <span>=</span> <span>"/root/.ollama"</span>
  <span>initial_size</span> <span>=</span> <span>"100gb"</span>
</code></pre>
</div>

<ol>
<li>Run <code>fly apps create sandwich_ai &amp;&amp; fly deploy</code>.
</li></ol>

<p>If you want to read more about how to start your new sandwich empire, check out <a href="https://fly.io/blog/scaling-llm-ollama/">Scaling Large Language Models to zero with Ollama</a>, it explains how to set up Ollama so that it <em>automatically scales itself down</em> when it’s not in use.</p>
<h2 id="the-speed-of-light-is-only-so-fast"><a href="#the-speed-of-light-is-only-so-fast" aria-label="Anchor"></a>The speed of light is only so fast</h2>
<p>Being able to spin up GPUs is great, but where Fly.io really shines is inference at the edge.</p>

<p>Let’s say you have an app that lets users enter ingredients they have in their kitchen and receive a sandwich recipe. Your users expect their recipes <em>instantly</em> (or at least as fast as the other leading apps). Seconds count when you need an emergency sandwich.</p>
<div><p>


It’s depressingly customary in the AI industry to cherry-pick outputs. This was not cherry-picked. I used <a href="https://ollama.ai/library/yi:34b">yi:34b</a> to generate this recipe. I’m not sure what a taco salad sandwich is, but I might be willing to try it.</p>
</div>
<p><img alt="A conversation between a user and an artificial intelligence. The user asks: &quot;What kind of sandwich can I make with an egg, a taco shell, and a pound of ground beef?&quot; The AI responds: &quot; You can make a breakfast taco or a taco salad sandwich with the ingredients you have. Here's how to prepare each: for the breakfast taco. Cook the pound of ground beef in a pan until browned. Season with salt, pepper, and any other desired spices like chili powder or taco seasoning. While the beef is cooking, fry an egg (or scramble it if you prefer) in another pan. Warm up the taco shell in the oven or microwave according to the package instructions. Assemble the taco by placing the ground cooked beef in the taco shell followed by the fried egg. You can also add any additional toppings like diced onions avocados, avocado, salsa or cheese if you have them. Serve with a side of hot sauce or sour cream if desired. For the taco salad sandwich: Prepare the ground beef as in the breakfast taco recipe above. Instead of frying an egg, you can cook it sunny side up or over easy depending on your preference. Crumble the taco shell into small pieces and mix them with the cooked ground beef. Assemble the sandwich by layering the crumbled taco shell mixture and ground beef in two slices of bread. Top with the fried egg and any additional toppings you like such as shredded lettuce, diced tomatoes, or sliced olives. Serve with a side of salsa or ranch dressing if desired. Both options are hardy and can be easily customized based on your taste preferences. Enjoy!&quot;" src="https://fly.io/blog/fly-io-has-gpus-now/assets/sandwich-recipes.webp"></p>

<p>In the previous snippet, we deployed our app to ord (<code>primary_region = "ord"</code>). The good news is that our model returns a result really quickly and users in Chicago get instant sandwich recipes. It’s a good experience for users near your datacentre, and you can do this on any half decent cloud provider.</p>

<p>But surely people outside of Chicago need sandwiches too. Amsterdam has sandwich fiends as well. And sometimes it takes too long to have their requests leap across the pond. The speed of light is only so fast after all. Don’t worry, we’ve got your back. Fly.io has GPUs in datacentres all over the world. Even more, we’ll let you run <em>the same program</em> with the same public IP address and the same TLS certificates in any regions with GPU support.</p>

<p>Don’t believe us? See how you can scale your app up in Amsterdam with one command:</p>
<div>
  <pre><code>fly scale count 2 --region ams
</code></pre>
</div>

<p>It’s that easy.</p>
<h2 id="actually-on-demand"><a href="#actually-on-demand" aria-label="Anchor"></a>Actually On-Demand</h2>
<p>GPUs are powerful parallel processing packages, but they’re not cheap! Once we have enough people wanting to turn their fridge contents into tasty sandwiches, keeping a GPU or two running makes sense. But we’re just a small app still growing our user base while also funding the latest large sandwich model research. We want to only pay for GPUs when a user makes a request.</p>

<p>Let’s open up that <code>fly.toml</code> again, and add a section called <code>services</code>, and we’ll include instructions on how we want our app to scale up and down:</p>
<div>
  <pre><code><span>[[services]]</span>
  <span>internal_port</span> <span>=</span> <span>8080</span>
  <span>protocol</span> <span>=</span> <span>"tcp"</span>
  <span>auto_stop_machines</span> <span>=</span> <span>true</span>
  <span>auto_start_machines</span> <span>=</span> <span>true</span>
  <span>min_machines_running</span> <span>=</span> <span>0</span>
</code></pre>
</div>

<p>Now when no one needs sandwich recipes, you don’t pay for GPU time.</p>
<h2 id="the-deets"><a href="#the-deets" aria-label="Anchor"></a>The Deets</h2>
<p>We have GPUs ready to use in several US and EU regions and Sydney. You can deploy your sandwich, music generation, or AI illustration apps to:</p>

<ul>
<li><a href="https://www.nvidia.com/en-us/data-center/a100/">Ampere A100s</a> with 40gb of RAM for $2.50/hr
</li><li><a href="https://www.nvidia.com/en-us/data-center/a100/">Ampere A100s</a> with 80gb of RAM for $3.50/hr
</li><li><a href="https://www.nvidia.com/en-us/data-center/l40/">Lovelace L40s</a> are coming soon (pricing TBD)
</li></ul>

<p>By default, anything you deploy to GPUs will use eight heckin’ <a href="https://www.amd.com/en/processors/epyc-server-cpu-family">AMD EPYC</a> CPU cores, and you can attach volumes up to 500 gigabytes. We’ll even give you discounts for reserved instances and dedicated hosts if you ask nicely.</p>

<p>We hope you have fun with these new cards and we’d love to see what you can do with them! Reach out to us on X (formerly Twitter) or <a href="https://community.fly.io/">the community forum</a> and share what you’ve been up to. We’d love to see what we can make easier!</p>

          
        </section>
        <dl>
            <dt>
              Next post  ↑
            </dt>
            <dd>
              <a href="https://fly.io/blog/fks/">
                Introducing Fly Kubernetes
              </a>
            </dd>
            <dt>
              Previous post  ↓
            </dt>
            <dd>
              <a href="https://fly.io/blog/what-are-these-gpus-really/">
                What are these "GPUs" really?
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla downsizes as it refocuses on Firefox and AI (176 pts)]]></title>
            <link>https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo/</link>
            <guid>39362481</guid>
            <pubDate>Tue, 13 Feb 2024 20:34:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo/">https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo/</a>, See on <a href="https://news.ycombinator.com/item?id=39362481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">After <a href="https://blog.mozilla.org/en/mozilla/a-new-chapter-for-mozilla-laura-chambers-expanded-role/" target="_blank" rel="noopener">installing</a> a new interim CEO earlier this month, Mozilla, the organization behind the Firefox browser, is making some major changes to its product strategy, TechCrunch has learned.</p>
<p>Specifically, Mozilla plans to scale back its investment in a number of products, including its VPN, Relay and, somewhat remarkably, its Online Footprint Scrubber, which launched <a href="https://techcrunch.com/2024/02/06/mozilla-monitors-new-service-removes-your-personal-info-from-data-broker-sites-automatically/">only a week ago</a>. Mozilla will also shut down <a href="https://hubs.mozilla.com/" target="_blank" rel="noopener">Hubs</a>, the 3D virtual world it <a href="https://blog.mozvr.com/introducing-hubs-a-new-way-to-get-together-online/" target="_blank" rel="noopener">launched</a> back in 2018, and scale back its investment in its <a href="http://mozilla.social/" target="_blank" rel="noopener">mozilla.social</a> Mastodon instance. The layoffs will affect roughly 60 employees. Bloomberg previously reported <a href="https://finance.yahoo.com/news/firefox-maker-mozilla-cutting-60-191639445.html" target="_blank" rel="noopener">the layoffs.</a></p>
<p>Going forward, the company said in an internal memo, Mozilla will focus on bringing “trustworthy AI into Firefox.” To do so, it will bring together the teams that work on Pocket, Content and AI/Ml.</p>
<p>Mozilla started expanding its product portfolio in recent years, all while its flagship product, Firefox, kept losing market share. And while the organization was often sharply criticized for this, its leadership argued that diversifying its product portfolio beyond Firefox was necessary to ensure Mozilla’s survival in the long run. Firefox, after all, provided the vast majority of Mozilla’s income, but it also meant the organization was essentially dependent on Google to continue this deal. With these changes, it now looks like Mozilla may refocus on Firefox once more, something that will surely make many hardcore Firefox fans quite happy.</p>
<p>Here is the full internal memo:</p>
<blockquote><p><strong>Scaling back investment <a href="http://mozilla.social/" target="_blank" rel="noopener noreferrer" data-stringify-link="http://mozilla.social/" data-sk="tooltip_parent">mozilla.social</a></strong>: With&nbsp;<a href="http://mozilla.social/" target="_blank" rel="noopener noreferrer" data-stringify-link="http://mozilla.social/" data-sk="tooltip_parent">mozilla.social</a>, we made a big bet in 2023 to build a safer, better social media experience, based on Mastodon and the Fediverse. Our initial approach was based on a belief that Mozilla needed to quickly reach large scale in order to effectively shape the future of social media. It was a noble idea but one we struggled to execute. While we resourced&nbsp;<a href="http://mozilla.social/" target="_blank" rel="noopener noreferrer" data-stringify-link="http://mozilla.social/" data-sk="tooltip_parent">mozilla.social</a>&nbsp;heavily to pursue this ambitious idea, in retrospect a more modest approach would have enabled us to participate in the space with considerably greater agility. The actions we’re taking today will make this strategic correction, working through a much smaller team to participate in the Mastodon ecosystem and more rapidly bring smaller experiments to people that choose to live on the&nbsp;<a href="http://mozilla.social/" target="_blank" rel="noopener noreferrer" data-stringify-link="http://mozilla.social/" data-sk="tooltip_parent">mozilla.social</a>&nbsp;instance.</p>
<p><strong>Protection Experimentation &amp; Identity (PXI)</strong>: We’re scaling back investment in some of our standalone consumer products in the Security and Privacy space. We are reducing investment in market segments that competitors crowd and where it is challenging to deliver a differentiated offering. Specifically, we plan to reduce our investments in VPN, Relay, and Online Footprint Scrubber. We will maintain investment in products addressing customer needs in growing market segments.</p>
<p><strong>Hubs</strong>: Since early 2023, we have experienced a shift in the market for 3D virtual worlds. With the exception of gaming, education, and a handful of niche use cases, demand has moved away from 3D virtual worlds. This is impacting all industry players. Hubs’ user and customer bases are not robust enough to justify continuing to dedicate resources against the headwinds of the unfavorable shift in demand. We will wind down the service and communicate a graceful exit plan to customers.</p>
<p><strong>Right-sizing the People Team</strong><br>
Given the reduction in staffing and lower headcount budget moving forward in MozProd, some roles have been consolidated in the People and other support services orgs so that we are offering the right level of support to our product portfolio. Optimizing our org to sharpen focus.</p>
<p>In 2023, generative AI began rapidly shifting the industry landscape. Mozilla seized an opportunity to bring trustworthy AI into Firefox, largely driven by the Fakespot acquisition and the product integration work that followed. Additionally, finding great content is still a critical use case for the internet. Therefore, as part of the changes today, we will be bringing together Pocket, Content, and the AI/ML teams supporting content with the Firefox Organization. More details on the specific organizational changes will follow shortly. Within MozProd, there are no changes within MDN, Ads, or Fakespot. There are also no changes to Legal/Policy, Finance &amp; Business Operations, Marketing, or Strategy &amp; Operations.</p></blockquote>

			</div></div>]]></description>
        </item>
    </channel>
</rss>