<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 05 Jul 2023 17:00:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Firefox 115 can silently remotely disable my extension on any site (109 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2023/7/1.html</link>
            <guid>36602193</guid>
            <pubDate>Wed, 05 Jul 2023 15:52:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2023/7/1.html">https://lapcatsoftware.com/articles/2023/7/1.html</a>, See on <a href="https://news.ycombinator.com/item?id=36602193">Hacker News</a></p>
<div id="readability-page-1" class="page">
<nav>
Previous: <a href="https://lapcatsoftware.com/articles/2023/6/4.html">My thoughts on Apple Vision Pro</a>
<br><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a></nav>
<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://appdot.net/@lapcatsoftware" title="@lapcatsoftware@appdot.net">Mastodon</a>)</header>

<h3>July 5 2023</h3>

<p>Firefox version 115.0 was released on July 4, but I'm not celebrating. I'm concerned about a new "feature" in the <a href="https://www.mozilla.org/en-US/firefox/115.0/releasenotes/">release notes</a>.</p>
<blockquote><p>Certain Firefox users may come across a message in the extensions panel indicating that their add-ons are not allowed on the site currently open. We have introduced a new back-end feature to only <a href="https://support.mozilla.org/kb/quarantined-domains">allow some extensions monitored by Mozilla to run on specific websites</a> for various reasons, including security concerns.</p></blockquote>
<p>For various reasons. That's quite uninformative and mysterious.</p>
<p>I'm all in favor of giving users control over which extensions are allowed to load on which sites. Safari already has this feature on both macOS and iOS. My concern is not about user control—little of which even exists in Firefox 115, as I'll show later—but rather about the remote control that Mozilla has now given itself, as mentioned in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1832791" title="Implement a Remote Settings for the Quarantined Domains pref">a Bugzilla report</a>.</p>
<blockquote>
<p>We need to have ability to set the list of quarantined domains remotely.  The pref should be a string with the same format as <code>extensions.webextensions.restrictedDomains</code>.</p>
<p>The pref will be <code>extensions.webextensions.quarantinedDomains</code>, and it will have a default value set in a patch for <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1745823" title="ASSIGNED - Implement negative permissions">bug 1745823</a> (to include a couple real but "test" subdomains from badssl.com).</p>
<p>Filing as confidential for now, until we ship the system addon.</p>
</blockquote>
<p>You have to wonder why an open source project required confidentiality about this. Incidentally, neither Safari nor Chrome, or any other browser as far as I know, has such a remote domain-specific kill switch for extensions, so you have to wonder why it was necessary in Firefox.</p>
<p>I believe that Mozilla already had the capability to remotely disable an individual extension, if it turned out to be malware. After all, every Firefox extension needs to be uploaded to Mozilla for analysis and cryptographically code signed before it can be installed in Firefox. <b>[Edit: I've now <a href="https://support.mozilla.org/kb/add-ons-cause-issues-are-on-blocklist" title="Add-ons that cause stability or security issues are put on a blocklist">confirmed</a> that Mozilla has an extensions blocklist.]</b> Given this preexisting capability, it's unclear why there should be a list of domains where all except a lucky few chosen extensions are disabled, regardless of whether the disabled extensions have shown signs of misbehavior.</p>
<p>The Firefox quarantined domains list is currently empty. Mozilla hasn't said which domains it intends to add, or even why a domain-specific list is required. I find this troubling. It's a feature with no apparent motivation, supposedly for "security concerns"—among other "various reasons"—but what <em>are</em> the specific security concerns here, that would be addressed by a remotely controlled domain list? Mozilla's opacity and vagueness feels almost deliberate, undermining our trust.</p>
<p>Let's see how the user interface actually works in Firefox 115. Although the quarantined domains list is empty by default, you can edit the list manually in the <code>about:config</code> page.</p>
<p><img src="https://lapcatsoftware.com/articles/2023/7/1-1.png" width="810" height="440" alt="Firefox about:config extensions.quarantinedDomains.list www.youtube.com"></p>
<p>I've added the domain <code>www.youtube.com</code> to the list. After relaunching Firefox, you can see the warning in the Extensions popup.</p>
<p><img src="https://lapcatsoftware.com/articles/2023/7/1-2.png" width="810" height="440" alt="Some extensions are not allowed. Only some extensions monitored by Mozilla are allowed on this site to protect your data."></p>
<p>My own extension <a href="https://underpassapp.com/StopTheMadness/">StopTheMadness</a>, which is not "monitored by Mozilla", is "Not allowed by Mozilla" on YouTube. (This warning is inaccurate, of course, since it was me rather than Mozilla who added YouTube to the domains list.) Apparently <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">uBlock Origin</a> is monitored by Mozilla, for it is allowed on YouTube despite my quarantined domains list. It's nice to be big, I guess.</p>
<p>Note that the warning appears <em>in</em> the Extensions popup rather than <em>on</em> the Extensions icon, so you wouldn't know that StopTheMadness was disabled on YouTube unless you opened the popup (or unless you saw the autoplaying videos on YouTube that StopTheMadness would otherwise stop.)</p>
<p>What happens, though, if you pin the extensions to the toolbar for easy access to their settings?</p>
<p><img src="https://lapcatsoftware.com/articles/2023/7/1-3.png" width="810" height="440" alt="StopTheMadness and uBlock Origin pinned to Firefox toolbar"></p>
<p>It turns out that when you pin an extension to the toolbar, it no longer appears in the Extensions popup! Consequently, the quarantined domains warning no longer appears in the Extensions popup either. In fact, there's no longer an Extensions popup: clicking the Extensions toolbar icon simply opens the <code>about:addons</code> page, which doesn't show the quarantined domains warning anywhere.</p>
<p><img src="https://lapcatsoftware.com/articles/2023/7/1-4.png" width="810" height="440" alt="Firefox Add-ons Manager"></p>
<p>This is a terrible user interface design for the new so-called "security" feature, silently disabling extensions while hiding the warning from the user. And remember, the quarantined domains list can be changed remotely at any time by Mozilla, without needing a Firefox software update. Firefox just has to "phone home" to Mozilla. (Another reason to install <a href="https://www.obdev.at/products/littlesnitch/">Little Snitch</a>. <b>[Edit: I believe the domain is <a href="https://support.mozilla.org/kb/domains-allow-firefox" title="Domains to Allow for Firefox">firefox.settings.services.mozilla.com</a> in this case.]</b>)</p>
<p>We have no idea how Mozilla intends to use the quarantined domains list. Some people are speculating, with no evidence, about "banking". But there are innumerable banks in the world. What is Mozilla supposed to do, make and maintain a list of every banking web site in the world? While it makes sense for users to have the ability to manually exclude their own banking sites from extension access if they prefer, what sense does it make for Mozilla to arbitrarily select certain web site domains for general exclusion? Another question: is it impossible for the user to purposely exclude extensions that are "monitored by Mozilla" and given special treatment by Firefox?</p>
<p>My own extension StopTheMadness stops web sites from disabling your browser's built-in paste and autofill features, a kind of madness commonly implemented by sites that have a misguided, ignorant notion about what makes a login form "secure". Thus, it would be a disservice rather than a service to users for Mozilla to remotely disable user extensions on some arbitrarily selected banking sites.</p>
<p>As a little indie software developer, I'm disappointed and irritated that Mozilla, a little developer compared to its competitors—corporate giant browser vendors Apple, Google, and Microsoft—would choose to create a two-tier system in which only the biggest extension developers get exclusive access and exemptions. I know that users love uBlock Origin, but I hate the idea of a world where uBlock Origin is the <em>only</em> extension allowed. That's the type of consumer and power centralization that Firefox and Mozilla are supposed to be fighting against. I don't like an extension monopoly any more than I like a browser monopoly.</p>

<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://appdot.net/@lapcatsoftware" title="@lapcatsoftware@appdot.net">Mastodon</a>)</header>
<nav><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a><br>
Previous: <a href="https://lapcatsoftware.com/articles/2023/6/4.html">My thoughts on Apple Vision Pro</a>
</nav>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI weights are not open “source” (104 pts)]]></title>
            <link>https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/</link>
            <guid>36601622</guid>
            <pubDate>Wed, 05 Jul 2023 15:18:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/">https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=36601622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p><strong>Published:</strong> Jun 27, 2023
        </p>
        <p><strong>By:</strong> Sid Sijbrandij
        </p>
        
        <p>AI licensing is extremely complex. Unlike software licensing, AI isn’t as simple as applying current proprietary/open source software licenses. AI has multiple components—the source code, weights, data, etc.—that are licensed differently. AI also poses socio-ethical consequences that don’t exist on the same scale as computer software, necessitating more restrictions like behavioral use restrictions, in some cases, and distribution restrictions. Because of these complexities, AI licensing has many layers, including multiple components and additional licensing considerations.&nbsp;</p>
<p><img src="https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/feature.png" alt="img"></p>
<p>With <a href="https://heathermeeker.com/">Heather Meeker’s</a> input, I’ve created a set of categories to standardize how we talk about AI licensing. The table above names different categories of license types based on the function they serve and which component they apply to. Typical software licensing falls into two categories: proprietary and open source. Some people have the perspective that if a license isn’t open source, it’s proprietary. I think it’s more nuanced than that and believe there are three more license types worth naming: non-commercial NDA, non-commercial public, and ethical. There is no standard license for any of these categories, so I suggest we categorize existing licenses as proprietary, collaborator, available, ethical, and open.</p>
<p>“Open Weights” is already gaining traction as the default name for “open source” AI weights. Meeker and Joseph Jacks of OSS Capital recently <a href="https://heathermeeker.com/2023/06/08/toward-an-open-weights-definition/">announced</a> an Open Weights <a href="https://github.com/Open-Weights/Definition/blob/main/Definition.md">definition</a> and <a href="https://github.com/Open-Weights/Definition/blob/main/Open%20Weights%20License.MD">licensing framework</a> focused on “the original idea of openness, and preserving the original goals of Freedom Zero of free software and the non-discrimination principles of open source.” Eventually, we will need standard definitions and licensing frameworks for each category.</p>
<h2 id="license-categories">License categories</h2>
<p>The <em>proprietary license</em> category captures fully closed licenses that can’t be used for any purposes without explicit permission from the original author.</p>
<p>A <em>non-commercial, NDA license</em> is a mostly closed license that allows non-commercial use with a non-disclosure agreement. Meta applied this license type to its AI model weights when it released LLaMA, allowing certain academic researchers, laboratories, and government agencies to download the weights. The purpose of this license, <a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">according to Meta</a>, is to allow certain, pre-defined, and approved groups to collaborate on improving the model and support further research without compromising the integrity or opening it up to misuse. Because this license type is limited to specific collaborators, I’ve named the category “collaborator.” You could argue that this should be combined with the next license, “non-commercial, public” but for now, we think that having the weights out in public is a big enough difference.</p>
<p>A <em>non-commercial, public license</em> is similar to the Creative Commons Noncommercial license but for AI. Source code and weights are available to anyone to download and use (not just select collaborators) but can’t be used commercially. I’ve named this category “available” because it makes the component available to the public for personal use.</p>
<p>The <em>ethical license</em> category applies to licenses that allow commercial use of the component but includes field of endeavor and/or behavioral use restrictions set by the licensor. Naming these licenses as “ethical” distinguishes them from true open source licenses. The RAIL license is an example of an ethical license that <a href="https://static1.squarespace.com/static/5c2a6d5c45776e85d1482a7e/t/6308bb4bba3a2a045b72a4b0/1661516619868/BigScience+Open+RAIL-M+License.pdf">includes restrictions</a> that require the user to agree not to use the model in any way that violates the law, to exploit or harm minors in any way, or to generate verifiably false information for the purpose of harming others. While the RAIL organization suggests adding the word “Open” to RAIL licenses that include similar open-access and free-use as open source (i.e. OpenRAIL-M), this is confusing since the license is not open source so long as it includes usage restrictions. A better name would be EthicalRAIL-M. Using the term “ethical” to describe this category license clearly indicates its functional difference from open source licenses.</p>
<p>The <em>open source license</em> category is reserved for licenses that adhere to the specific open source <a href="https://opensource.org/osd/">definition set by the Open Source Initiative (OSI)</a>. Only licenses which meet the 10 criteria described should carry the “open” designation. Meeker and OSS Capital have started the effort to define Open Weights, stating, “We need a standard for Open Weights that recognizes the unique nature of NNWs and provides legal and practical guidelines for their use, distribution, and sharing.”</p>
<h2 id="separating-source-from-weights">Separating source from weights</h2>
<p>Source code and weights are two different things. It doesn’t make sense to call weights “open source” when it’s not source code. Code is instructions on how to do something, while weights are the output of training runs on data and are hard to decipher. Licenses designed for source code created by humans don’t directly translate to AI weights that are only readable by computers. A separate category of licenses designed specifically for weights is needed.</p>
<p>While the licensing principles can be similar when applied to different components, a distinction should be made when referencing licenses that apply to source code versus weights, data, etc. The Responsible AI Licenses (RAIL) initiative <a href="https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses">has adopted a similar naming convention</a> by adding representative letters to its RAIL license (RAIL-D for data, RAIL-M for model). The same categories of licenses can be applied to each component individually, but the nomenclature should include the specific licensed component.</p>
<h2 id="better-definitions-to-avoid-open-washing">Better definitions to avoid “open washing”</h2>
<p>The OSI’s definition of open source is specific, strict, and intentionally does not allow discrimination against any persons, groups, or fields of endeavor. This is intended to uphold the principles and integrity of open source. AI poses different challenges than computer software, making it necessary, to some, to restrict certain potentially harmful uses. This is understandable, but it can’t be called “open source.” Using the term ethical to describe licenses that allow free and open use, similar to open source, prevents “<a href="https://openwashing.org/">open washing</a>” and provides clarity to users of the model.</p>
<p>It’s important to make these distinctions so that it’s extremely clear which component is being discussed and its intended use is explicit. The terms “open” and “open source” are being <a href="http://marble.onl/posts/software-licenses-masquerading-as-open-source.html">mistakenly applied</a> to model weights that are not actually open source but have some level of openness. For example, it’s common for people to call AI weights “open source” when (1) they are actually referring to weights, not source code, and (2) the weights are non-commercial public, not open source. Non-commericial, public licensed weights should be called “Available weights.” It’s also common to see ethical licenses (like Rails M) called open source, but it is problematic because they include behavioral use restrictions that are not open source according to the OSI definition. I propose calling this category “Ethical Weights” to distinguish it from “Open Weights” licenses which follow the OSI open source definition as it applies to weights.</p>
<p>Many AI weights with the label “open” are not open source. They aren’t source code at all. Using the right nomenclature, like “Open Weights” and “Ethical Weights,” will ultimately help the industry move forward in developing standards around each of these categories.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Regex Engine Internals as a Library (183 pts)]]></title>
            <link>https://blog.burntsushi.net/regex-internals/</link>
            <guid>36600263</guid>
            <pubDate>Wed, 05 Jul 2023 13:36:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.burntsushi.net/regex-internals/">https://blog.burntsushi.net/regex-internals/</a>, See on <a href="https://news.ycombinator.com/item?id=36600263">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      

      <article>
      <p>Over the last several years, I’ve rewritten <a href="https://github.com/rust-lang/regex/">Rust’s <code>regex</code>
crate</a> to enable better internal composition, and to make it
easier to add optimizations while maintaining correctness. In the course of
this rewrite I created a new crate, <a href="https://github.com/rust-lang/regex/tree/master/regex-automata"><code>regex-automata</code></a>, which exposes much
of the <code>regex</code> crate internals as their own APIs for others to use. To my
knowledge, this is the first regex library to expose its internals to the
degree done in <code>regex-automata</code> as a separately versioned library.</p>
<p>This blog post discusses the problems that led to the rewrite, how the rewrite
solved them and a guided tour of <code>regex-automata</code>’s API.</p>
<p><strong>Target audience</strong>: Rust programmers and anyone with an interest in how one
particular finite automata regex engine is implemented. Prior experience with
regular expressions is assumed.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#brief-history">Brief history</a></li>
<li><a href="#the-problems">The problems</a>
<ul>
<li><a href="#problem-composition-was-difficult">Problem: composition was difficult</a></li>
<li><a href="#problem-testing-was-difficult">Problem: testing was difficult</a></li>
<li><a href="#problem-requests-for-niche-apis">Problem: requests for niche APIs</a></li>
<li><a href="#problem-fully-compiled-dfas">Problem: fully compiled DFAs</a></li>
</ul>
</li>
<li><a href="#follow-along-with-regex-cli">Follow along with regex-cli</a></li>
<li><a href="#flow-of-data">Flow of data</a></li>
<li><a href="#literal-optimizations">Literal optimizations</a>
<ul>
<li><a href="#motivating-literal-optimizations">Motivating literal optimizations</a></li>
<li><a href="#literal-extraction">Literal extraction</a></li>
<li><a href="#searching-for-literals">Searching for literals</a></li>
</ul>
</li>
<li><a href="#the-nfa-data-type">The NFA data type</a>
<ul>
<li><a href="#a-simple-nfa-example">A simple NFA example</a></li>
<li><a href="#nfa-optimization-sparse-states">NFA optimization: sparse states</a></li>
<li><a href="#nfa-optimization-minimal-utf-8-automata">NFA optimization: minimal UTF-8 automata</a></li>
<li><a href="#nfa-optimization-literal-trie">NFA optimization: literal trie</a></li>
<li><a href="#nfa-future-work">NFA future work</a></li>
</ul>
</li>
<li><a href="#regex-engines">Regex engines</a>
<ul>
<li><a href="#common-elements-among-regex-engines">Common elements among regex engines</a></li>
<li><a href="#engine-pike-vm">Engine: Pike VM</a></li>
<li><a href="#engine-bounded-backtracker">Engine: bounded backtracker</a></li>
<li><a href="#engine-one-pass-dfa">Engine: one-pass DFA</a></li>
<li><a href="#engine-dfa">Engine: DFA</a></li>
<li><a href="#engine-hybrid-nfadfa">Engine: hybrid NFA/DFA</a></li>
<li><a href="#the-meta-regex-engine">The meta regex engine</a></li>
</ul>
</li>
<li><a href="#differences-with-re2">Differences with RE2</a></li>
<li><a href="#testing-strategy">Testing strategy</a></li>
<li><a href="#benchmarking">Benchmarking</a></li>
<li><a href="#costs">Costs</a></li>
<li><a href="#wrap-up">Wrap up</a></li>
</ul>
<h2 id="brief-history">Brief history</h2>
<p>In September 2012, an <a href="https://github.com/rust-lang/rust/issues/3591">issue was filed on the Rust
repository</a> requesting that a regex library be added to the
Rust Distribution. Graydon Hoare later <a href="https://github.com/rust-lang/rust/issues/3591#issuecomment-17009497">commented in that thread</a>
that they preferred RE2. For those that don’t know, <a href="https://github.com/google/re2">RE2</a> is a regex engine
that uses finite automata to guarantee <code>O(m * n)</code> worst case search time
while providing a Perl-like syntax that excludes features that are not known
how to implement efficiently. RE2’s design is described by its author, Russ
Cox, in a <a href="https://swtch.com/~rsc/regexp/">series of articles on implementing a regex engine using finite
automata</a>.</p>
<p>In April 2014, I <a href="https://github.com/rust-lang/rust/issues/3591#issuecomment-39582811">showed up and said I was working on a regex engine inspired
by RE2</a>. I treated Cox’s articles as a blueprint for how to
build a regex library. Soon there after, I <a href="https://github.com/rust-lang/rfcs/pull/42">published an RFC to add a regex
library to the “Rust Distribution.”</a> This was before Rust 1.0
and Cargo (the second version, not <a href="https://github.com/rust-lang/rust/pull/1149">the first</a>), and the “Rust
Distribution” referred to <code>rustc</code>, <code>std</code> and several “supporting” libraries
that were all bundled together. This RFC proposed adding a <code>regex</code> crate to
that list of supporting libraries.</p>
<p>Ten days later, <a href="https://github.com/rust-lang/rfcs/pull/42#issuecomment-41104032">the RFC was approved</a>. The next
day, I <a href="https://github.com/rust-lang/rust/pull/13700">submitted a pull request to <code>rust-lang/rust</code></a>,
adding it to the Rust distribution. Things moved fast back then. Notice also
that I had originally called the crate <code>regexp</code>. The PR to Rust involved a
discussion about naming that eventually resulted in it being called <code>regex</code>
instead.</p>
<p>Two years later in May 2016, I <a href="https://github.com/rust-lang/rfcs/pull/1620">wrote an RFC to release <code>regex 1.0</code></a>. That took a few months to be approved, but it wasn’t
until a couple years later in May 2018 that I <a href="https://github.com/rust-lang/regex/pull/471">actually released <code>regex 1.0</code></a>.</p>
<p>Before <code>regex 1.0</code> was released, I had been steadily working on a complete
re-imagining of the crate internals. From a <a href="https://github.com/rust-lang/regex/commit/715a8072890af65d2095d39f534b4b3dc4caeae2">commit message in March
2018</a>:</p>
<blockquote>
<p>The [regex-syntax] rewrite is intended to be the first phase in an effort to
overhaul the entire regex crate.</p>
</blockquote>
<p>I didn’t know exactly where I was going at that point in time, but in
March 2020, I started work in earnest on rewriting the actual matching
engines. A little more than three years later, <a href="https://github.com/rust-lang/regex/blob/master/CHANGELOG.md#190-2023-07-05"><code>regex 1.9</code> has been
released</a> with the completed rewrite.</p>
<h2 id="the-problems">The problems</h2>
<p>What kinds of problems were facing the <code>regex</code> crate that warranted a full
rewrite? And moreover, why publish the rewritten internals as its own crate?</p>
<p>There are a host of things to discuss here.</p>
<h3 id="problem-composition-was-difficult">Problem: composition was difficult</h3>
<p>Following in the <a href="https://swtch.com/~rsc/regexp/">tradition of RE2</a>, the <code>regex</code> crate contains a
number of different strategies that it can use to implement a search. Sometimes
<em>multiple</em> strategies are used in a single search call.</p>
<p>There are generally two dimensions, often at odds with one another, to each
strategy: performance and functionality. Faster strategies tend to be more
limited in functionality. For example, a fast strategy might be able to report
the start and end of a match but not the offsets for each capture group in the
regex. Conversely, a slower strategy might be needed to report the offsets of
each capture group.</p>
<p>When I originally wrote the <code>regex</code> crate, I implemented a single strategy
(the <code>PikeVM</code>) and didn’t do any thoughtful design work for how to incorporate
alternative strategies. Eventually, new strategies were added organically:</p>
<ul>
<li>A <code>BoundedBacktracker</code> that can report capture group offsets like the
<code>PikeVM</code>, but does so using a backtracking strategy. Its main limitation is the
memory used to ensure its backtracking is bounded to <code>O(m * n)</code>, so it can only
be used for small haystacks/regexes. Its main upside is that its usually faster
than the <code>PikeVM</code>.</li>
<li>A hybrid NFA/DFA (also know as a “lazy DFA”) that can execute very quickly,
but can only report the start and end of a match. It ignores capture groups
completely.</li>
<li>A literal strategy where a regex corresponds to a language that is both
finite and small. Examples: <code>foo</code>, <code>foo{2}</code>, <code>foo|bar</code>, <code>foo[1-3]</code>. In this
case, we could just use a single or multi-substring search algorithm without
any kind of regex engine at all.</li>
</ul>
<p>(We’ll get into why these strategies have these trade offs in more detail later
in the blog.)</p>
<p>And with the above strategies came the composition of them:</p>
<ul>
<li>When the caller requests capture group offsets, it is usually faster to
run the lazy DFA first to find the bounds of a match, and then only run the
<code>PikeVM</code> or <code>BoundedBacktracker</code> to find the capture group offsets. In this
way, especially for cases where matches are somewhat rare, most of the work is
done by the much faster lazy DFA.</li>
<li>When a regex begins with a prefix that corresponds to a small finite
language, we can implement a <em>prefilter</em> that searches for occurrences of
that language. Each occurrence corresponds to a <em>candidate match</em> for the
overall regex. For each such candidate match, we run the full regex engine to
confirm whether it’s an actual match or not. So for example, <code>foo\w+</code> would
look for occurrences of <code>foo</code> in a haystack, and then run the regex <code>foo\w+</code>
at the offset at which the occurrence of <code>foo</code> began. If there’s a match, stop
and report it. Otherwise, restart the search for <code>foo</code> after the previous
occurrence of <code>foo</code>.</li>
</ul>
<p>Over time, I wanted to add both more strategies <em>and</em> add more ways of
composing them. But in an organically grown infrastructure, the <code>regex</code>
crate was beginning to buckle under its weight. Loosely speaking, all of the
following were problems:</p>
<ul>
<li>Not all strategies were necessarily designed to be composed with others.
The <code>PikeVM</code>, for example, was the first strategy and it suffered from this.
Specifically, it could not deal with starting and stopping a search in a
subsequence of a slice, which is necessary in order to compose it with the lazy
DFA. For example, at one point, the <code>PikeVM</code> would say that <code>\babc\b</code> matched
in <code>abcxyz</code> if its search started at offset <code>0</code> and ended at offset <code>3</code>. But
the trailing <code>\b</code> should not match after <code>c</code> because a <code>x</code> follows it.</li>
<li>It was difficult to reason about which strategy would be used for any given
regex.</li>
<li>There were repeated <code>match</code> expressions re-implementing various logic that
was easy to go out of sync.</li>
<li>The construction of a regex did not holistically account for the fact that
some strategies don’t need to be constructed at all. For example, I at one
point added an optimization to the <code>regex</code> crate (prior to the rewrite) that
just used <a href="https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm">Aho-Corasick</a> for regexes like <code>foo1|foo2|...|fooN</code>, but it was
extremely hacky to do that in a way that didn’t <em>also</em> result in a <a href="https://en.wikipedia.org/wiki/Thompson%27s_construction">Thompson
NFA</a> being unnecessarily built that would never actually be used.</li>
</ul>
<p>Basically, at the very least, many of the strategies needed a makeover and the
infrastructure that composes them probably needed to be rewritten.</p>
<h3 id="problem-testing-was-difficult">Problem: testing was difficult</h3>
<p>While the <code>regex</code> crate exposes a public interface that acts as a single regex
engine, as we just discussed, it uses multiple strategies internally depending
on the situation. Many of these strategies are regex engines themselves, and it
is absolutely critical that they behave the same on the same inputs.</p>
<p>As one example, a common case is when the caller requests the offsets of each
capture group in a match. The way this usually works is to run the lazy DFA
to find the bounds of the match, and then a slower regex engine like the
<code>PikeVM</code> or the <code>BoundedBacktracker</code> on the bounds of the match to report the
capture group offsets. What happens then, if the lazy DFA finds a match where
the other engines don’t? Oops. It’s a bug.</p>
<p>The problem here is that prior to <code>regex 1.9</code>, all of the strategies used
internally are not part of any public API, and that makes them difficult to
independently test. One can of course test the public API, but the logic for
selecting which internal regex engines to use is complicated enough that there
isn’t always a clear and obvious mapping between the pattern itself and which
regex engine will be used internally. Moreover, that mapping can change as the
logic evolves. So writing tests just against the public API is not something
that gives us clear coverage over all of the internal engines. And even if one
could do it, it would make debugging test failures more annoying than necessary
because you have to reason through the logic for which strategies are selected.</p>
<p>One approach to this is to put all tests inside the crate so that tests have
access to internal APIs. But you really want to leverage the same tests
across all of the engines, so doing this requires defining the tests in some
structured format, looping over them and running them on each engine. Since the
test infrastructure was not written with testing each individual strategy in
mind, I ended up not going this route.</p>
<p>Instead, I did some unholy hacks to make the existing test suite work:</p>
<ul>
<li>I exposed <a href="https://github.com/rust-lang/regex/blob/5a34a39b72d85730065d3ffe4ce3715f2731e49a/src/lib.rs#L790-L801">some internal APIs</a> to make it possible
to configure and build the internal strategies from outside the crate.</li>
<li>I made it so one could actually build the main <code>Regex</code> type from those
internal APIs using an <a href="https://github.com/rust-lang/regex/blob/5a34a39b72d85730065d3ffe4ce3715f2731e49a/src/re_unicode.rs#L174-L179">undocumented <code>From</code> implementation</a>.</li>
<li>I wrote the tests using <a href="https://github.com/rust-lang/regex/blob/5a34a39b72d85730065d3ffe4ce3715f2731e49a/tests/fowler.rs#L5">macros</a>.</li>
<li>I created test targets for each internal regex engine I wanted to test,
and each test target was responsible for <a href="https://github.com/rust-lang/regex/blob/5a34a39b72d85730065d3ffe4ce3715f2731e49a/tests/test_backtrack.rs#L3-L11">defining the aforementioned
macros</a> in a way that used the regex engine I wanted to
test.</li>
</ul>
<p>This was overall a hacky mess and it really needed a rethink. Exposing the
internal engines in their own public API was not strictly a requirement to
improve the situation, but it does make it possible to run a test suite across
all engines without either relying on undocumented APIs or putting the tests
inside the crate itself.</p>
<h3 id="problem-requests-for-niche-apis">Problem: requests for niche APIs</h3>
<p>Over the years, there were several requests for additional APIs to the <code>regex</code>
crate, but were ones I considered too niche to be worth expanding the API
surface, or where I wasn’t totally clear on what the API ought to be.</p>
<p>One of the most popular such requests was better multi-pattern support. Namely,
the <code>regex</code> crate provides a <a href="https://docs.rs/regex/latest/regex/struct.RegexSet.html"><code>RegexSet</code></a> API that permits one to search for
possibly overlapping matches of zero or more regexes. The catch is that the API
only reports which patterns matched anywhere in the haystack. One cannot use
the API to get either the match offsets or the offsets of capture groups. While
useful, it isn’t as useful as it could be if it supported the full <code>Regex</code> API.</p>
<p>As with adding multiple internal regex engines and the testing strategy, the
<code>RegexSet</code> API was bolted on to the existing implementation in a fairly hacky
way. Making it capable of reporting match offsets would require either a major
refactoring of all existing engines or a rewrite.</p>
<p>But separately from that, it wasn’t totally clear to me how to expose APIs that
report match offsets in the context of the overlapping search done by the
<code>RegexSet</code> APIs. Having more room to experiment with alternative APIs, for
example, a <code>RegexSet</code> that does non-overlapping searches and reports match
offsets, would be something that others could use without needing to complicate
the <code>regex</code> crate API.</p>
<p>There have been other requests for additional APIs too:</p>
<ul>
<li>The ability to execute an anchored search without needing to put a <code>^</code> in the
pattern. This is especially useful in the context of running a regex on a
<em>part</em> of the haystack that you know matches, but where you want to extract
capture groups. It’s also useful in the context of an iterator that only
reports adjacent matches. The <code>regex</code> crate could be augmented to support this,
but there’s no easy way of extending existing APIs without either duplicating
all of the search routines, or unnecessarily making “anchored mode” an option
that one can pass to the regex. (Which, at that point, you might as well just
put <code>^</code> at the beginning of the pattern.)</li>
<li>The ability to run a regex search without it doing synchronization internally
to get mutable scratch spaced used for a search. One might want to do this
to avoid those synchronization costs in some cases. But to do it would in turn
also require duplicating search APIs and exposing a new type that represents
the “mutable scratch space.”</li>
<li>Executing a <a href="https://github.com/rust-lang/regex/issues/425">regex on streams and/or non-contiguous
haystacks</a>. This is especially useful for running a regex on
data structures like ropes, which are often found in text editors. This is a
big topic and not a problem I’ve even attempted to approach, but my hope is
that with more of the <code>regex</code> crate internals exposed, it might be tractable
for others to more easily experiment with solutions to this problem.</li>
</ul>
<p>By publishing a new separately versioned crate that contains much of the
<code>regex</code> crate internals, it provides “breathing room” for more APIs that folks
want without needing to clutter up the general purpose regex API that services
the vast majority of all regex use cases. Namely, by targeting the crate toward
“expert” use cases, we make no show of trying to keep the API small and simple.
Indeed, as we’ll see, the API of <code>regex-automata</code> is sprawling and complex. And
by making it separately versioned, we can put out breaking change releases at a
much faster cadence than what we do for the <code>regex</code> crate.</p>
<p>This line of reasoning is not too dissimilar from the line of reasoning that
led to the publication of the <a href="https://docs.rs/regex-syntax"><code>regex-syntax</code></a> crate. Namely, folks (including
myself) wanted access to a regex parser for their own projects. I certainly
didn’t want to expose a parser in the <code>regex</code> crate itself because of the added
complexity and the fact that I wanted to be able to evolve the parser and its
data types independently of the <code>regex</code> crate. (That is, <code>regex-syntax</code> has
breaking change releases more frequently than <code>regex</code> itself.) By putting it
into a separate crate, I could simultaneously use it as an implementation
detail of the <code>regex</code> crate while also making it available for others to use.</p>
<h3 id="problem-fully-compiled-dfas">Problem: fully compiled DFAs</h3>
<p>The birth of <code>regex-automata</code> was not actually the result of my crusade to
rewrite the regex crate. Its birth coincided with a desire to build fully
compiled DFAs, serialize them and then provide a barebones search runtime that
could zero-copy deserialize those DFAs and use them for a search. I used the
original version of <code>regex-automata</code> to <a href="https://github.com/BurntSushi/bstr/tree/b3cab1905c46ad7de78a032a61eef0437ed7fb58/src/unicode/fsm">build DFAs</a> for implementing
various Unicode algorithms inside of <a href="https://github.com/BurntSushi/bstr"><code>bstr</code></a>.</p>
<p>In the course of building the initial version of <code>regex-automata</code>, I realized
that I needed to rebuild an NFA data structure and a compiler for it that was
very similar to one found in the <code>regex</code> crate. At a certain point, I began
wondering whether it might be possible to share that code since it is quite
non-trivial and a place where a lot of interesting optimizations occur.</p>
<p>I had briefly considered building a new crate like <code>regex-nfa</code> that both the
<code>regex</code> crate and <code>regex-automata</code> could depend upon. But after more thought,
it became apparent that there was more code that could be shared between
<code>regex-automata</code> and <code>regex</code>. For example, a lot of the <a href="https://en.wikipedia.org/wiki/Powerset_construction">determinization</a>
process can be written generically such that it works for both fully compiled
DFAs and for lazy DFAs.</p>
<p>At that point, the right abstraction boundary seemed like it was closer to
“regex engine” than it was “an NFA.” So I reframed <code>regex-automata</code> as less
about <em>just</em> DFAs and more about a menagerie of regex engines. The plan at that
point was, roughly, to put all of the regex engines in <code>regex-automata</code> and
make the <code>regex</code> crate itself just a thin wrapper around <code>regex-automata</code>. By
setting things up this way, it should reduce the friction from migrating from
the <code>regex</code> crate to <code>regex-automata</code> if one should need access to the lower
level APIs.</p>
<p>In this way, we can build fully compiled DFAs using precisely the same code
that the <code>regex</code> crate uses for its lazy DFA. And precisely the same code that
the <code>regex</code> crate uses to convert the parsed representation of a regex pattern
into an NFA. Heck, this even makes it possible to use fully compiled DFAs in
the <code>regex</code> crate in some cases. (This is normally a big no-no in a general
purpose regex engine because fully compiled DFAs are not only quite bloated,
but they take worst case exponential time to build. That is very inappropriate
for a regex engine you might use to compile untrusted patterns, or even in
cases where you just need compilation time of a regex to be “reasonable.”
Building a DFA may not be reasonable, especially when Unicode is involved.)</p>
<h2 id="follow-along-with-regex-cli">Follow along with regex-cli</h2>
<p><code>regex-cli</code> is a program maintained as part of <code>regex</code> crate that provides
convenient command line access to many of the APIs exposed in <code>regex-syntax</code>,
<code>regex-automata</code> and <code>regex</code>. It also includes some useful utilities, such as
serializing fully compiled DFAs to a file and generating Rust code to read
them.</p>
<p>I will use <code>regex-cli</code> at points thoughout this blog post, so if you’d like to
follow along, you can install it straight from the <code>regex</code> crate repository:</p>
<pre tabindex="0"><code>$ cargo install regex-cli
</code></pre><p>Here’s a pair of examples that shows the impact that Unicode has on the
<code>.</code> regex. First, the version with Unicode enabled:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson '.' --no-table

thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 10
 000003: \x80-\xBF =&gt; 11
 000004: \xA0-\xBF =&gt; 3
 000005: \x80-\xBF =&gt; 3
 000006: \x80-\x9F =&gt; 3
 000007: \x90-\xBF =&gt; 5
 000008: \x80-\xBF =&gt; 5
 000009: \x80-\x8F =&gt; 5
 000010: sparse(\x00-\t =&gt; 11, \x0B-\x7F =&gt; 11, \xC2-\xDF =&gt; 3, \xE0 =&gt; 4, \xE1-\xEC =&gt; 5, \xED =&gt; 6, \xEE-\xEF =&gt; 5, \xF0 =&gt; 7, \xF1-\xF3 =&gt; 8, \xF4 =&gt; 9)
 000011: capture(pid=0, group=0, slot=1) =&gt; 12
 000012: MATCH(0)

transition equivalence classes: ByteClasses(0 =&gt; [\x00-\t], 1 =&gt; [\n], 2 =&gt; [\x0B-\x7F], 3 =&gt; [\x80-\x8F], 4 =&gt; [\x90-\x9F], 5 =&gt; [\xA0-\xBF], 6 =&gt; [\xC0-\xC1], 7 =&gt; [\xC2-\xDF], 8 =&gt; [\xE0], 9 =&gt; [\xE1-\xEC], 10 =&gt; [\xED], 11 =&gt; [\xEE-\xEF], 12 =&gt; [\xF0], 13 =&gt; [\xF1-\xF3], 14 =&gt; [\xF4], 15 =&gt; [\xF5-\xFF], 16 =&gt; [EOI])
)
</code></pre><p>And now the version with Unicode disabled:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson '(?-u:.)' --no-table --no-utf8-syntax

thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 3
 000003: sparse(\x00-\t =&gt; 4, \x0B-\xFF =&gt; 4)
 000004: capture(pid=0, group=0, slot=1) =&gt; 5
 000005: MATCH(0)

transition equivalence classes: ByteClasses(0 =&gt; [\x00-\t], 1 =&gt; [\n], 2 =&gt; [\x0B-\xFF], 3 =&gt; [EOI])
)
</code></pre><p>The output here shows the Thompson NFA compiled by <code>regex-automata</code> for the
regex pattern given. The <code>regex-cli debug</code> command can print lots of different
data types from the regex crate ecosystem:</p>
<pre tabindex="0"><code>$ regex-cli debug
Prints the debug representation of various things from regex-automata and
regex-syntax.

This is useful for ad hoc interactions with objects on the command line. In
general, most objects support the full suite of configuration available in code
via the crate.

USAGE:
    regex-cli debug &lt;command&gt; ...

COMMANDS:
    ast        Print the debug representation of an AST.
    dense      Print the debug representation of a dense DFA.
    hir        Print the debug representation of an HIR.
    literal    Print the debug representation of extracted literals.
    onepass    Print the debug representation of a one-pass DFA.
    sparse     Print the debug representation of a sparse DFA.
    thompson   Print the debug representation of a Thompson NFA.
</code></pre><p>There is also a <code>regex-cli find</code> command that can run ad hoc searches. For
example, to run a multi-pattern search with capture groups using the meta regex
engine:</p>
<pre tabindex="0"><code>$ regex-cli find capture meta \
   -p '(?&lt;email&gt;[.\w]+@(?&lt;domain&gt;[.\w]+))' \
   -p '(?&lt;phone&gt;(?&lt;areacode&gt;[0-9]{3})-[0-9]{3}-[0-9]{4})' \
   -y 'foo@example.com, 111-867-5309'
     parse time:  20.713µs
 translate time:  22.116µs
build meta time:  834.731µs
    search time:  142.537µs
  total matches:  2
0:{ 0: 0..15/foo@example.com, 1/email: 0..15/foo@example.com, 2/domain: 4..15/example.com }
1:{ 0: 17..29/111-867-5309, 1/phone: 17..29/111-867-5309, 2/areacode: 17..20/111 }
</code></pre><p>See the <a href="https://github.com/rust-lang/regex/blob/4f47b14d60e82e85a880513833362d5fb485ffa8/regex-cli/README.md"><code>regex-cli</code> README</a> for a few other examples.</p>
<h2 id="flow-of-data">Flow of data</h2>
<p>Before diving into details, it’s worth pausing for a moment first to introduce
some terms and briefly describe the flow of data through the regex engine.
That is, when you call <code>Regex::new</code> with a pattern string, we’ll trace the
transformations done on the pattern string that turn it into something that can
search haystacks.</p>
<ul>
<li>A pattern string is first parsed into an <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/ast/enum.Ast.html"><code>Ast</code></a>. An <code>Ast</code> is a structured
representation of the pattern.</li>
<li>An <code>Ast</code> is translated into an <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/hir/struct.Hir.html"><code>Hir</code></a>. An <code>Hir</code> is another structured
representation of the pattern, but contains a lot less detail than an <code>Ast</code>.
Things like Unicode case folding and Unicode character class references are
all expanded as part of translation.</li>
<li>An <code>Hir</code> is then used to build two things. First is a <a href="https://docs.rs/regex-syntax/0.7.2/regex_syntax/hir/literal/struct.Seq.html">literal sequence</a>,
which corresponds to a sequence of literals extracted from the pattern that
are used to optimize regex searches in some cases. If possible, a literal
sequence is used to build a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/util/prefilter/struct.Prefilter.html"><code>Prefilter</code></a>. Secondly, an <code>Hir</code> is used to
construct an <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/struct.NFA.html"><code>NFA</code></a>.</li>
<li>At this point, an <code>NFA</code> is used to build a variety of regex engines:
<ul>
<li>A <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/pikevm/struct.PikeVM.html"><code>PikeVM</code></a> can handle all possible regexes that are supported by parsing.
A <code>PikeVM</code> can also report offsets for matching capture groups.</li>
<li>A <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/backtrack/struct.BoundedBacktracker.html"><code>BoundedBacktracker</code></a> uses backtracking but explicitly bounds itself
to avoid repeating work. Like the <code>PikeVM</code>, it can report offsets for
matching capture groups.</li>
<li>A <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/onepass/struct.DFA.html">one-pass DFA</a> that supports a very limited subset of regexes, but can
report offsets for matching capture groups very quickly.</li>
<li>A fully compiled <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/dense/struct.DFA.html">dense DFA</a>. It can only report the overall start and end
of a match (when combined with a second reverse DFA), but is very fast. The
main downside is that its construction algorithm has worst case <code>O(2^m)</code>
time and space complexity.</li>
<li>A <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/hybrid/dfa/struct.DFA.html">lazy DFA</a> that builds itself during a search from an <code>NFA</code>. In some
cases it can be slower than a <code>PikeVM</code>, but in most cases is as fast as
a fully compiled <code>DFA</code> and lacks the downside of <code>O(2^m)</code> worst case
construction time/space.</li>
</ul>
</li>
<li>All of the above regex engines, including a <code>Prefilter</code> if one was
constructed, are composed into a single <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/meta/struct.Regex.html">meta regex engine</a>.</li>
<li>The <code>regex</code> crate itself is a thin wrapper around the meta regex engine from
the <code>regex-automata</code> crate.</li>
</ul>
<p>We’ll discuss each of these things in more detail throughout the blog, but
it’s difficult to avoid referencing some of these things before they get a
full treatment. For that reason, the above is meant to give you a very general
blueprint of <code>regex</code> crate internals.</p>
<h2 id="literal-optimizations">Literal optimizations</h2>
<p>In this section, we will begin our journey into the <code>regex</code> crate internals
by talking about a critical optimization technique that it uses: literal
extraction from regexes. For example, the regex <code>(foo|bar|quux)(\s+\w+)</code>
describes a regular language where all elements in the language start with one
of <code>foo</code>, <code>bar</code> or <code>quux</code>. That is, every match of that regex is guaranteed to
begin with one of those three literals.</p>
<h3 id="motivating-literal-optimizations">Motivating literal optimizations</h3>
<p>Why does this matter? Why do we care about literals at all? We care about them
because of the following two observations:</p>
<ol>
<li>There exist algorithms for searching for one or a small number of literals
that are extremely fast. Speed is usually obtained by exploiting the
“simplicity” of searching for plain literals and using <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">vector instructions</a> to
process many bytes in a haystack in a single step.</li>
<li>In <em>very</em> broad strokes, general algorithms for searching for matches of a
regular expression cannot be accelerated easily.</li>
</ol>
<p>The key observation is that while there are certainly many different techniques
to implementing a regex engine (which we will cover a subset of in more depth
later), none of them can consistently be as fast as a well optimized substring
search implementation that uses vector instructions. In practice, I’ve often
found that the difference is at least one order of magnitude, and sometimes
more.</p>

<p>Let’s show some examples. For this, we can utilize <code>regex-cli</code>, as it exposes
a <code>regex-cli debug literal</code> sub-command for extracting literals from regexes.
Let’s start simple:</p>
<pre tabindex="0"><code>$ regex-cli debug literal 'bar'
           parse time:  13.967µs
       translate time:  7.008µs
      extraction time:  405ns
    optimization time:  1.479µs
                  len:  Some(1)
           is finite?:  true
            is exact?:  true
      min literal len:  Some(3)
      max literal len:  Some(3)
longest common prefix:  Some("bar")
longest common suffix:  Some("bar")

E("bar")
</code></pre><p>In the future, I’ll trim the output since there is a lot of extra information
shown. But let’s go through them:</p>
<ul>
<li>Parse time refers to the time it takes to turn the <code>bar</code> pattern into a
structured <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/ast/enum.Ast.html"><code>Ast</code></a> value.</li>
<li>Translate time refers to the time it takes to turn the <code>Ast</code> value into
an <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/hir/struct.Hir.html"><code>Hir</code></a> value.</li>
<li>Extraction time refers to the time it takes to turn the <code>Hir</code> value into
a <a href="https://docs.rs/regex-syntax/0.7.2/regex_syntax/hir/literal/struct.Seq.html">literal sequence</a>.</li>
<li>Optimization time refers to the time it takes to “optimize” the literal
sequence. This might be as simple as removing duplicate literals and as
aggressive as shrinking the sequence in various ways based on heuristics. We’ll
see more examples of this later.</li>
<li><code>len</code> is the number of literals in the sequence extracted.</li>
<li>Finite refers to whether the sequence has a finite number of elements. An
infinite sequence represents the sequence of all possible literals, and usually
means that literal optimizations aren’t possible or aren’t believed to be
fruitful.</li>
<li>Exact refers to whether every element in the literal sequence is exact or
not. An exact literal refers to a literal that reached a match state from the
place where literal extraction began. Since this command extracts prefixes, an
exact literal corresponds to an overall match of the regex. If a literal is
not exact, then it is said to be inexact.</li>
<li>Minimum literal length refers to the length, in bytes, of the shortest
literal in the sequence.</li>
<li>Maximum literal length refers to the length, in bytes, of the longest
literal in the sequence.</li>
<li>Longest common prefix represents a single literal that is a prefix of all
elements in the sequence. Infinite sequences and finite sequences containing
zero elements lack a common prefix. All other sequences have a common prefix of
at least the empty string.</li>
<li>Longest common suffix represents a single literal that is a suffix of all
elements in the sequence. Infinite sequences and finite sequences containing
zero elements lack a common suffix. All other sequences have a common suffix of
at least the empty string.</li>
</ul>
<p>Finally, after the above meta data, the extracted sequence is shown. Since the
regex is just the literal <code>bar</code>, the sequence contains a single exact element
corresponding to <code>bar</code>. If <code>bar</code> were a strict prefix, then the sequence would
be the same but <code>bar</code> will be inexact:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table 'bar+'
I("bar")
</code></pre><p>In this case, <code>bar</code> is inexact because the <code>r</code> at the end can match one or more
times. In fact, because of the unbounded repetition operator being applied
to a non-empty string, the language described by this regex is infinite. It
therefore follows that one cannot enumerate all literals and that at least some
of them extracted must be inexact (if any are extracted at all).</p>
<p>But one does not need to write a regex that describes an infinite language
in order to get an inexact literal. Here’s an example of a regex that describes
a finite language, but for which only inexact literals are extracted:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table 'bar[a-z]'
I("bar")
</code></pre><p>Literal extraction <em>could</em> have enumerated every literal, for example,
<code>bara</code>, <code>barb</code>, <code>barc</code>, …, <code>barz</code>. But instead it didn’t. Why? It turns out
that literal extraction is one big heuristic. A dark art, if you will. We have
to go back to <em>why</em> we’re doing literal extraction at all in the first place:
to identify candidate matches in a haystack very quickly before using a slower
regex engine to confirm whether a match exists at that location.</p>
<p>The trick here is that the choice of <em>what</em> literals to search for might be
just as important as choosing <em>how</em> to search for them. The algorithm with the
highest throughput in the world isn’t going to help you if your haystack is
1,000,000 <code>a</code>s and your regex is just the literal <code>a</code>. The key here is that a
good literal optimization achieves both of the following things:</p>
<ul>
<li>Minimizes the false positive rate of candidates. That is, most candidates it
reports lead to a match.</li>
<li>Minimizes its impact on the latency of the search. That is, when a prefilter
is active, it ideally results in running the regex engine on only a small
portion of the haystack. If a prefilter reports candidates frequently, then
even if it has a 0% false positive rate, its impact on latency is likely to be
hurting overall search times.</li>
</ul>
<p>The reason why I called literal optimizations a <em>dark art</em> is because it is
impossible to know, before a search begins, how to optimally choose the above
two things. The reason is because they both depend on the haystack itself, and
scanning the haystack to “study” it is almost certainly going to result in a
net negative for overall search times. Therefore, we have to guess at how to
minimize the false positive rate while reducing our impact on latency. That’s
why it’s a dark art.</p>
<p>Thankfully, there are some guidelines we can follow that usually give us a good
result:</p>
<ul>
<li>A smaller sequence of literals is usually better than a larger sequence,
but not if this results in elements that are extremely short. That is, 1 or 2
bytes in length. Short elements are likely to match much more frequently, and
so we’d rather not have them. For example, if we had 5,000 literals that were
all limited to lowercase ASCII letters, we could trivially shrink the number of
literals to at most 26 by taking the first byte of each literal. But this new
sequence of literals is likely to match a lot more frequently, and thus result
in a higher hit to latency and a higher false positive rate. It would be better
to shrink the sequence while retaining longer literals that are less likely to
match.</li>
<li>Longer literals are generally better than short literals, but not if it would
result in a large sequence. Longer literals are usually more discriminative,
that is, they lead to a lower false positive rate since they are less likely to
match by chance. But one doesn’t want to prioritize long literals arbitrarily.
For example, you might have a sequence containing the literals <code>foobar</code>,
<code>foobaz</code>, <code>fooquux</code>, but a better sequence would probably be <code>foo</code> even though
it’s shorter than all three literals in the sequence. A single element sequence
is nice because it means we can potentially use a single-substring search
algorithm (which is probably fast).</li>
</ul>
<p>Literal extraction tries to adhere to the above guidelines as much as possible,
but there are some other heuristics that often come into play. For example, the
ASCII space character, <code>U+0020</code>, is unusually common. If a sequence would
otherwise contain a space, then the sequence is made infinite when optimized,
and this effectively disables literal optimizations. For example, this regex
has three prefix literals extracted:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table '(?:foo|z|bar)[a-z]+'
I("foo")
I("z")
I("bar")
</code></pre><p>But this one doesn’t. The only difference is that the <code>z</code> was replaced with a
space:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table '(?:foo| |bar)[a-z]+'
Seq[∞]
</code></pre><p>This heuristic takes place during the “optimization” pass of a literal
sequence. The heuristic notices that one of the literals is just a space
character, assumes this will lead to a high false positive rate and makes the
sequence infinite. When a sequence is infinite, it communicates that there
is no small set of finite literals that would (likely) serve as a good
prefilter. If we disable optimization, we can see that the space character is
included:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table --no-optimize '(?:foo| |bar)[a-z]+'
I("foo")
I(" ")
I("bar")
</code></pre><p>To make matters more complicated, if we use a different regex that leads to
a small finite sequence of literals that are all exact, then the literal
containing the space character doesn’t result in the overall sequence being
made infinite:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table 'foo| |bar'
E("foo")
E(" ")
E("bar")
</code></pre><p>This is useful because when all the literals are exact, the regex engine can
be skipped completely. In this case, there doesn’t have to be any prefilter
at all. One can just use the multi-substring algorithm directly to report
matches. Therefore, the concern about a high false positive rate is irrelevant,
because every match produced by searching for the literals is a real match.</p>
<p>At this point, we should cover why I’m using the term literal <em>sequence</em>
instead of literal <em>set</em>. Namely, the order of the literals extracted matters.
It matters because the <code>regex</code> crate tries to simulate Perl-like semantics.
That is, that the matches reported are done <em>as if</em> employing a backtracking
search. This is also called leftmost-first matching, and in this context, the
<code>|</code> operator is not commutative. For example:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table 'sam|samwise'
E("sam")

$ regex-cli debug literal --no-table 'samwise|sam'
E("samwise")
E("sam")
</code></pre><p>These are two different sequences. Both are minimal with respect to the
corresponding regexes. In the first case, <code>sam|samwise</code> will only ever match
<code>sam</code>, since <code>sam</code> is a prefix of <code>samwise</code> and comes before <code>samwise</code> in the
pattern. Therefore, a literal sequence consisting of just <code>sam</code> is correct,
since <code>samwise</code> can never match. In the second case, <code>samwise|sam</code> can match
either branch. Even though <code>sam</code> is a prefix of <code>samwise</code>, since <code>samwise</code>
appears first, it will be preferred when <code>samwise</code> is in the haystack.</p>
<p>(Note: POSIX regex engines don’t implement regexes this way. Instead, they have
leftmost-longest semantics, where the longest possible match always wins. In
this case, <code>|</code> is a commutative operator. Some other regex engines, such as
<a href="https://github.com/intel/hyperscan">Hyperscan</a>, implement “report all matches” or “earliest match” semantics. In
that case, <code>abc|a</code> would match both <code>a</code> and <code>abc</code> in the haystack <code>abc</code>.)</p>
<p>Our last examples show that literal extraction is somewhat intelligent. For
example:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table 'abc?de?[x-z]ghi'
I("abcde")
I("abcdx")
I("abcdy")
I("abcdz")
I("abdex")
I("abdey")
I("abdez")
I("abdxg")
I("abdyg")
I("abdzg")
</code></pre><p>That is, literal extraction knows how to expand things like <code>?</code> and even small
character classes. This works as long as the literal sequence size stays
under <a href="https://docs.rs/regex-syntax/latest/regex_syntax/hir/literal/struct.Extractor.html">several different heuristic limits</a>. (Notice also
that literal extraction could have enumerated every element in the language
described by this regex, in full, but optimization chose to shrink it in
accordance with its heuristics.)</p>
<p>Another example of “intelligence” is that case insensitivity, including
Unicode awareness, is taken into account as well:</p>
<pre tabindex="0"><code>$ regex-cli debug literal --no-table '(?i)She'
E("SHE")
E("SHe")
E("ShE")
E("She")
E("sHE")
E("sHe")
E("shE")
E("she")
E("ſHE")
E("ſHe")
E("ſhE")
E("ſhe")
</code></pre><p>This actually isn’t a result of literal extraction implementing Unicode case
folding, but rather due to the translation from an <code>Ast</code> to an <code>Hir</code> doing the
case folding for us:</p>
<pre tabindex="0"><code>$ regex-cli debug hir --no-table '(?i)She'
Concat(
    [
        Class(
            {
                'S'..='S',
                's'..='s',
                'ſ'..='ſ',
            },
        ),
        Class(
            {
                'H'..='H',
                'h'..='h',
            },
        ),
        Class(
            {
                'E'..='E',
                'e'..='e',
            },
        ),
    ],
)
</code></pre><p>That is, literal extraction sees this regex as one that is equivalent to
<code>[Ssſ][Hh][Ee]</code>. All it does is expand the classes as it would any other regex.</p>
<h3 id="searching-for-literals">Searching for literals</h3>
<p>Once you’ve extracted some literals, you now need to figure out how to search
for them.</p>
<p>The single substring case is somewhat easy: you pick the fastest algorithm
you can for finding a substring in a haystack. There’s not much more to it.
You don’t need to care about the order of literals at this point since there
is only one of them. For this case, the <code>regex</code> crate uses the
<a href="https://docs.rs/memchr/2.*/memchr/memmem/index.html"><code>memmem</code></a> module from the <a href="https://docs.rs/memchr/2.*/memchr/"><code>memchr</code></a> crate.</p>
<p>There are several different aspects to the algorithm used in <code>memchr::memmem</code>:</p>
<ul>
<li>Its principal algorithm is <a href="https://en.wikipedia.org/wiki/Two-way_string-matching_algorithm">Two-Way</a>, which runs in <code>O(n)</code> worst case time
and constant space.</li>
<li>In cases where the needle and haystack are both very short, <a href="https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm">Rabin-Karp</a>
is used in an effort to minimize latency.</li>
<li>On <code>x86_64</code>, a variant of the “<a href="http://0x80.pl/articles/simd-strfind.html">generic SIMD</a>” algorithm is used. Basically,
two bytes are chosen from the needle, and occurrences for those two bytes in
their proper positions are searched for using vector instructions. When a
match of those two bytes is found, then a full match of the needle is checked.
(Notice that this is just another variant of the prefilter mechanism. We pick
an operation that can quickly find candidates and then perform a more expensive
verification step.)</li>
</ul>
<p>For the generic SIMD algorithm, instead of always choosing the first and last
bytes in the needle, we choose two bytes that we believe are “rare” according
to a background frequency distribution of bytes. That is, we assume that bytes
like <code>Z</code> are far less common than bytes like <code>a</code>. It isn’t always true, but
we’re in heuristic-land here. It’s true commonly enough that it works well in
practice. By choosing bytes that are probably rarely occurring from the needle,
we hope to maximize the amount of time spent in the vector operations that
detect candidates, and minimize the number of verifications we need to perform.</p>
<p>The multi-substring case is a bit trickier. Here, we need to make sure we
treat the literals as a sequence and prioritize matches for literals earlier
in the sequence over literals that come later. It’s also typically true that
multi-substring search will be slower than single-substring case, because
there’s just generally more work to be done. Here, the principal algorithm
employed is <a href="https://github.com/BurntSushi/aho-corasick/tree/97e48b6dbdf9ebd50168540276fa3f14f403d42b/src/packed/teddy">Teddy</a>, which is an algorithm that I ported out of <a href="https://github.com/intel/hyperscan">Hyperscan</a>.
At a high level, it uses vector instructions to detect candidates quickly and
then a verification step to confirm those candidates as a match.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm">Aho-Corasick</a> algorithm is also used in some cases, although usually the
regex engine will just prefer to construct a lazy DFA since performance is
similar. Aho-Corasick can still help as a prefilter when the lazy DFA cannot be
used though. Aho-Corasick will also typically do better than a lazy DFA when
the number of literals is extremely large (around tens of thousands).</p>
<p>There is a lot more work I hope to do in the multi-substring case going
forward.</p>
<h2 id="the-nfa-data-type">The NFA data type</h2>
<p>If there was a central data type inside the <code>regex</code> crate, it would probably be
the <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/struct.NFA.html"><code>NFA</code></a>. More specifically, it is a Thompson NFA, which means it was built
by an algorithm similar to <a href="https://en.wikipedia.org/wiki/Thompson%27s_construction">Thompson’s construction</a>. Thompson’s construction
builds an NFA from a structured representation of a regex in <code>O(m)</code> time, where
<code>m</code> is proportional to the size of the regex after counted repetitions have
been expanded. (For example, <code>a{5}</code> is <code>aaaaa</code>.) The algorithm works by mapping
each type of regex expression to a mini NFA unto itself, and then defining
rules for composing those mini NFAs into one big NFA.</p>
<p>NFAs are a central data type because they can be used directly, as-is,
to implement a regex engine. But they can also be transformed into other
types (such as DFAs) which are in turn used to implement different regex
engines. Basically, at present, if you want to build a regex engine with
<code>regex-automata</code>, then you have to start with a Thompson NFA.</p>
<p>Before exploring NFAs in more detail, let’s look at a simple example.</p>
<h3 id="a-simple-nfa-example">A simple NFA example</h3>
<p>As with literal extraction, <code>regex-cli</code> can be helpful here by letting us print
a debug representation of an NFA when given a regex:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson 'a'
        parse time:  9.856µs
    translate time:  3.005µs
  compile nfa time:  18.51µs
            memory:  700
            states:  6
       pattern len:  1
       capture len:  1
        has empty?:  false
          is utf8?:  true
       is reverse?:  false
   line terminator:  "\n"
       lookset any:  ∅
lookset prefix any:  ∅
lookset prefix all:  ∅

thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 3
 000003: a =&gt; 4
 000004: capture(pid=0, group=0, slot=1) =&gt; 5
 000005: MATCH(0)

transition equivalence classes: ByteClasses(0 =&gt; [\x00-`], 1 =&gt; [a], 2 =&gt; [b-\xFF], 3 =&gt; [EOI])
)
</code></pre><p>In the future, I’ll trim the output to just the NFA itself. So let’s explain
what the rest of the output means here:</p>
<ul>
<li>The parse and translate timings are the same as they were for literal
extraction. That is, the time to build <code>Ast</code> and <code>Hir</code> values, respectively.</li>
<li>Compilation time refers to the time it takes to compile an <code>Hir</code> value into
an <code>NFA</code>.</li>
<li>Memory refers to the number of bytes of heap memory used by the NFA.</li>
<li>States is the number of states in the NFA.</li>
<li>Pattern length is the number of patterns in the NFA.</li>
<li>Capture length is the number of capture groups compiled into the NFA. When
capture groups are enabled (they are by default), then there is always at least
1 group corresponding to the overall match.</li>
<li>“has empty” refers to whether the NFA can match the empty string or not.</li>
<li>“is utf8” refers to whether the NFA is guaranteed to never match any
invalid UTF-8. This includes <em>not</em> matching the empty string between code
units in a UTF-8 encoded codepoint. For example, <code>💩</code> is UTF-8 encoded as
<code>\xF0\x9F\x92\xA9</code>. While the empty regex will match at every position, when
the NFA is in UTF-8 mode, the only matches it would report are immediately
before the <code>\xF0</code> and immediately after <code>\xA9</code>.</li>
<li>“is reverse” refers to whether the NFA matches the regex in reverse. This
means that it matches the language described by the original regex, but with the
elements in the language reversed.</li>
<li>Line terminator refers to the line terminator used for the <code>(?m:^)</code>, <code>(?m:$)</code>
and <code>.</code> regexes.</li>
<li>“lookset any” is the set of all look-around assertions in the regex.</li>
<li>“lookset prefix any” is the set of all look-around assertions that occur in
the prefix of the regex. Every match may match zero or more of these.</li>
<li>At the end, the “transition equivalence classes” refers to a partitioning of
all possible byte values into sets of equivalence class. The rule is that each
byte in an equivalence class can be treated as equivalent to one another with
respect to whether a match occurs.</li>
</ul>
<p>Other than that, the main output is the NFA itself. Let’s walk through it:</p>
<pre tabindex="0"><code>&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 3
 000003: a =&gt; 4
 000004: capture(pid=0, group=0, slot=1) =&gt; 5
 000005: MATCH(0)
</code></pre><p>The <code>^</code> before state <code>2</code> indicates that it is the “anchored” starting state,
while the <code>&gt;</code> before state <code>0</code> indicates that it is the “unanchored” starting
state. The former is used when running an anchored search and the latter is
used for an unanchored search.</p>
<p>An unanchored search starts with <code>binary-union(2, 1)</code>. This indicates that
NFA traversal should first go to state <code>2</code> (a <code>capture</code> state), and only if
that path fails should it try going to state <code>1</code>. In this case, state <code>1</code>
matches any byte and loops back around to state <code>2</code>. In effect, states <code>0</code> and
<code>1</code> represent an implicit <code>(?s-u:.)*?</code> prefix at the beginning of the regex,
effectively making it possible for it to match anywhere in the haystack.</p>
<p>A <code>capture</code> state is an unconditional epsilon transition that only exists to
cause a side effect: it instructs the virtual machine executing the NFA to
store the current offset in the slot included in the <code>capture</code> state. If one is
doing NFA traversal outside the context of a virtual machine (or something else
that cares about capture groups), the <code>capture</code> states are effectively ignored
by treating them as unconditional epsilon transitions with no side effects. For
example, this is how they are handled during <a href="https://en.wikipedia.org/wiki/Powerset_construction">determinization</a> (the process of
converting an NFA to a DFA).</p>
<p>Once at state <code>3</code>, one must check whether the byte at the current position is
equivalent to <code>a</code>, and if so, moves to state <code>4</code>, which is another <code>capture</code>
state. Traversal finally moves to state <code>5</code>, which is a match state for the
pattern with identifier <code>0</code>.</p>
<h3 id="nfa-optimization-sparse-states">NFA optimization: sparse states</h3>
<p>One of the main problems with a Thompson NFA comes from the thing that makes it
a decent choice for a general purpose regex engine: its construction time is
worst case <code>O(m)</code>, but this is achieved through liberal use of <em>epsilon
transitions</em>. Epsilon transitions are transitions in the NFA that are taken
without consuming any input. They are one of two ways that a search via an NFA
simulation can wind up in multiple states simultaneously. (The other way is for
a single NFA state to have multiple outgoing transitions for the same haystack
symbol.)</p>
<p>Why are espilon transitions a problem? Well, when performing an NFA traversal
(whether it’s for a search or for building some other object such as a DFA), an
epsilon transition represents an added cost you must pay whenever one is found.
In particular, every NFA state has something called an epsilon closure, which
is the set of states reachable via following epsilon transitions recursively.
Depending on where it occurs in the NFA, an epsilon closure may be re-computed
many times. The epsilon closure for a particular state may change during
traversal because some epsilon transitions may be conditional, such as the ones
corresponding to anchor assertions like <code>^</code>, <code>$</code> and <code>\b</code>.</p>
<p>Let’s take a look at one relatively simple optimization that I made in the
new NFA compiler. First, let’s see how <code>regex &lt;1.9</code> compiled the regex
<code>[A-Za-z0-9]</code>:</p>
<pre tabindex="0"><code>$ regex-debug compile --bytes '[A-Za-z0-9]'
0000 Save(0) (start)
0001 Split(2, 3)
0002 Bytes(0, 9) (goto: 6)
0003 Split(4, 5)
0004 Bytes(A, Z) (goto: 6)
0005 Bytes(a, z)
0006 Save(1)
0007 Match(0)
</code></pre><p>(Note: <code>regex-debug</code> is an older hacky version of a command line tool for
interacting with the <code>regex</code> crate. It is no longer available, although you can
always check out an older tag in the <code>regex</code> crate repository and build it.)</p>
<p>The <code>Split</code> instruction corresponds to an NFA state with two unconditional
epsilon transitions (it’s the same as the <code>binary-union</code> instruction in the
previous section). The <code>Save</code> instruction is for capture groups and <code>Bytes</code>
is for checking whether a single byte or a contiguous ranges of bytes matches
the current haystack symbol. In this case, the character class is implemented
with multiple <code>Split</code> instructions. Notice, for example, that the epsilon
closure of state <code>0</code> is <code>{1, 2, 3, 4, 5}</code>.</p>
<p>Now let’s see what the new NFA compiler does:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table '[A-Za-z0-9]'
thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 3
 000003: sparse(0-9 =&gt; 4, A-Z =&gt; 4, a-z =&gt; 4)
 000004: capture(pid=0, group=0, slot=1) =&gt; 5
 000005: MATCH(0)
)
</code></pre><p>(We can ignore states <code>0</code> and <code>1</code>, the old NFA doesn’t have an equivalent
prefix for unrelated reasons.)</p>
<p>Here, instead of epsilon transitions, we just have a single <code>sparse</code> NFA
state. The name <code>sparse</code> refers to the fact that the state contains more
than one contiguous range of bytes, with each range potentially pointing to
a different state. <code>sparse</code> is used because the representation used doesn’t
permit a constant time determination of whether a particular haystack symbol
has a matching transition. (i.e., One has to use a linear or binary search.)
It accomplishes the same thing as the <code>Split</code> instructions in the old NFA,
but without any explicit epsilon transitions. This results in less overhead
because there’s no need to compute an epsilon closure through multiple <code>Split</code>
instructions. There’s just one state, and finding the next transition requires
looking up which range, if any, the current haystack symbol matches.</p>
<p>The main downside of this particular optimization is that the <code>sparse</code> state
(in the current representation of the NFA) uses indirection to support this. So
it may have harmful cache effects and may result in more heap memory used in
some cases. But the overhead of dealing with all of the epsilon transitions, in
practice, tends to trump that. It’s possible this indirection will be removed
in the future.</p>
<h3 id="nfa-optimization-minimal-utf-8-automata">NFA optimization: minimal UTF-8 automata</h3>
<p>One interesting aspect of the old NFA compiler is that it could produce two
different kinds of NFAs: an NFA whose alphabet was defined over Unicode code
points and an NFA whose alphabet was defined over arbitrary bytes. (Not just
UTF-8 code units. Even bytes that can never be a valid UTF-8 code unit,
like <code>\xFF</code>, are permitted in this byte oriented NFA.) The Unicode NFA is
principally used when using an NFA regex engine (the PikeVM or the bounded
backtracker, we’ll get to those later), where as the byte oriented NFA is
used whenever the lazy DFA engine is used. A byte oriented NFA is required
for use with the lazy DFA because a lazy DFA really wants its alphabet to be
defined over bytes. Otherwise, you wind up with difficult to solve performance
problems. (A byte oriented NFA can be used with the NFA regex engines, but this
only occurs when the regex can match invalid UTF-8. In this case, a Unicode
alphabet cannot be used.)</p>
<p>This led to at least three problems. First is that the byte oriented NFA was
often slower, primarily because of the epsilon transition problem we talked
about in the previous section. That is, a byte oriented NFA usually had more
<code>Split</code> instructions where as the Unicode NFA would look more like the <code>sparse</code>
state in the new NFA compiler. For example:</p>
<pre tabindex="0"><code>$ regex-debug compile '[A-Za-z0-9]'
0000 Save(0) (start)
0001 '0'-'9', 'A'-'Z', 'a'-'z'
0002 Save(1)
0003 Match(0)
</code></pre><p>Notice that there are no <code>Split</code> instructions at all.</p>
<p>The second problem follows from the first. Since the byte oriented NFA is
usually slower, we would actually compile both a Unicode NFA and a byte
oriented NFA. That way, we could use the Unicode NFA with the NFA regex engines
and the byte oriented NFA with the lazy DFA. It works, but it’s wasteful.</p>
<p>The third problem is that the NFA regex engines need to work on both the
Unicode and byte oriented versions of the NFA. This complicates things and has
been the reason for bugs. This problem could likely be mitigated to an extent
with better design, but it’s a complication.</p>
<p>So what does this have to do with UTF-8 automata? Well, a byte oriented NFA
still needs to be able to deal with Unicode classes. But if the alphabet is
bytes and not codepoints, how does it do it? It does it by building UTF-8
automata into the NFA. For example, here’s an NFA (from the new compiler) that
can match the UTF-8 encoding of any Unicode scalar value:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table '(?s:.)'
thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 10
 000003: \x80-\xBF =&gt; 11
 000004: \xA0-\xBF =&gt; 3
 000005: \x80-\xBF =&gt; 3
 000006: \x80-\x9F =&gt; 3
 000007: \x90-\xBF =&gt; 5
 000008: \x80-\xBF =&gt; 5
 000009: \x80-\x8F =&gt; 5
 000010: sparse(\x00-\x7F =&gt; 11, \xC2-\xDF =&gt; 3, \xE0 =&gt; 4, \xE1-\xEC =&gt; 5, \xED =&gt; 6, \xEE-\xEF =&gt; 5, \xF0 =&gt; 7, \xF1-\xF3 =&gt; 8, \xF4 =&gt; 9)
 000011: capture(pid=0, group=0, slot=1) =&gt; 12
 000012: MATCH(0)
)
</code></pre><p>The way this is achieved is by starting from a contiguous range of Unicode
codepoints and then generating a sequence of byte oriented character classes
that match the UTF-8 encoding of that range of codepoints. This functionality
is provided by <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/utf8/index.html"><code>regex-syntax</code>’s <code>utf8</code> module</a>. So for example,
<code>(?s:.)</code> would look like this:</p>
<pre tabindex="0"><code>[0-7F]
[C2-DF][80-BF]
[E0][A0-BF][80-BF]
[E1-EC][80-BF][80-BF]
[ED][80-9F][80-BF]
[EE-EF][80-BF][80-BF]
[F0][90-BF][80-BF][80-BF]
[F1-F3][80-BF][80-BF][80-BF]
[F4][80-8F][80-BF][80-BF]
</code></pre><p>Translating that into an NFA can be done by just treating it as an alternation,
like this:</p>
<pre tabindex="0"><code>[0-7F]|[C2-DF][80-BF]|...|[F4][80-8F][80-BF][80-BF]
</code></pre><p>And that will work and it’s correct. The problem is that it will generate
very large NFAs for some very common cases. See, the problem with Unicode is
that it tends to introduce extremely large character classes into a regex.
Classes like <code>\w</code>, for example, match 139,612 distinct codepoints (at time of
writing). The ASCII version of <code>\w</code> only matches 63 codepoints. This is a
categorical difference, and there are plenty of tricks that will work for a
small number like 63 that just won’t scale to numbers like 139,612.</p>
<p>The old regex crate did not naively compile UTF-8 automata like the approach
above. Indeed, there is a lot of redundant structure in the classes produced
by the <code>utf8</code> module above. The old regex crate noticed this and tried to factor
out common suffixes so that they were shared whenever possible. But this still
led to extremely large NFAs:</p>
<pre tabindex="0"><code>$ regex-debug compile --bytes '\w' | tail -n20
3545 Bytes(\xb0, \xb0) (goto: 3466)
3546 Bytes(\xf0, \xf0) (goto: 3545)
3547 Split(3550, 3551)
3548 Bytes(\x80, \x8c) (goto: 28)
3549 Bytes(\xb1, \xb1) (goto: 3548)
3550 Bytes(\xf0, \xf0) (goto: 3549)
3551 Split(3554, 3555)
3552 Bytes(\x8d, \x8d) (goto: 2431)
3553 Bytes(\xb1, \xb1) (goto: 3552)
3554 Bytes(\xf0, \xf0) (goto: 3553)
3555 Split(3558, 3562)
3556 Bytes(\x84, \x86) (goto: 28)
3557 Bytes(\xa0, \xa0) (goto: 3556)
3558 Bytes(\xf3, \xf3) (goto: 3557)
3559 Bytes(\x80, \xaf) (goto: 3563)
3560 Bytes(\x87, \x87) (goto: 3559)
3561 Bytes(\xa0, \xa0) (goto: 3560)
3562 Bytes(\xf3, \xf3) (goto: 3561)
3563 Save(1)
3564 Match(0)
</code></pre><p>Notice here that we’re only showing the last 20 lines of output. But the NFA
produced has 3,564 states. Wow. And there are epsilon transitions everywhere.
It’s truly a mess, and the only reason why the old regex crate does as well as
it does is because the lazy DFA usually bails it out by compiling some subset
of what is actually used into a DFA.</p>
<p>Now let’s look at what the new NFA compiler does:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table '\w' | tail -n20
 000292: \xB0-\xB9 =&gt; 310
 000293: sparse(\x84 =&gt; 115, \x85 =&gt; 291, \x86 =&gt; 210, \xAF =&gt; 292)
 000294: \x80-\x9F =&gt; 310
 000295: sparse(\x80-\x9A =&gt; 5, \x9B =&gt; 294, \x9C-\xBF =&gt; 5)
 000296: sparse(\x80-\x9B =&gt; 5, \x9C =&gt; 282, \x9D-\x9F =&gt; 5, \xA0 =&gt; 55, \xA1-\xBF =&gt; 5)
 000297: sparse(\x80-\xA1 =&gt; 310, \xB0-\xBF =&gt; 310)
 000298: sparse(\x80-\xB9 =&gt; 5, \xBA =&gt; 297, \xBB-\xBF =&gt; 5)
 000299: \x80-\xA0 =&gt; 310
 000300: sparse(\x80-\xAE =&gt; 5, \xAF =&gt; 299)
 000301: \x80-\x9D =&gt; 310
 000302: sparse(\xA0-\xA7 =&gt; 5, \xA8 =&gt; 301)
 000303: sparse(\x80-\x8A =&gt; 310, \x90-\xBF =&gt; 310)
 000304: sparse(\x80-\x8C =&gt; 5, \x8D =&gt; 303, \x8E-\xBF =&gt; 5)
 000305: sparse(\x80-\x8D =&gt; 5, \x8E =&gt; 236)
 000306: sparse(\x90 =&gt; 193, \x91 =&gt; 231, \x92 =&gt; 235, \x93 =&gt; 238, \x94 =&gt; 239, \x96 =&gt; 247, \x97 =&gt; 118, \x98 =&gt; 248, \x9A =&gt; 250, \x9B =&gt; 256, \x9C =&gt; 257, \x9D =&gt; 276, \x9E =&gt; 290, \x9F =&gt; 293, \xA0-\xA9 =&gt; 118, \xAA =&gt; 295, \xAB =&gt; 296, \xAC =&gt; 298, \xAD =&gt; 118, \xAE =&gt; 300, \xAF =&gt; 302, \xB0 =&gt; 118, \xB1 =&gt; 304, \xB2 =&gt; 305)
 000307: sparse(\x84-\x86 =&gt; 5, \x87 =&gt; 236)
 000308: \xA0 =&gt; 307
 000309: sparse(0-9 =&gt; 310, A-Z =&gt; 310, _ =&gt; 310, a-z =&gt; 310, \xC2 =&gt; 3, \xC3 =&gt; 4, \xC4-\xCA =&gt; 5, \xCB =&gt; 6, \xCC =&gt; 5, \xCD =&gt; 7, \xCE =&gt; 8, \xCF =&gt; 9, \xD0-\xD1 =&gt; 5, \xD2 =&gt; 10, \xD3 =&gt; 5, \xD4 =&gt; 11, \xD5 =&gt; 12, \xD6 =&gt; 13, \xD7 =&gt; 14, \xD8 =&gt; 15, \xD9 =&gt; 16, \xDA =&gt; 5, \xDB =&gt; 17, \xDC =&gt; 18, \xDD =&gt; 19, \xDE =&gt; 20, \xDF =&gt; 21, \xE0 =&gt; 53, \xE1 =&gt; 93, \xE2 =&gt; 109, \xE3 =&gt; 116, \xE4 =&gt; 117, \xE5-\xE9 =&gt; 118, \xEA =&gt; 137, \xEB-\xEC =&gt; 118, \xED =&gt; 140, \xEF =&gt; 155, \xF0 =&gt; 306, \xF3 =&gt; 308)
 000310: capture(pid=0, group=0, slot=1) =&gt; 311
 000311: MATCH(0)
</code></pre><p>There are not only far fewer states, but there are <em>zero</em> epsilon transitions.
While this is due in part to the use of the <code>sparse</code> state optimization
described in the previous section, it does not account for all of it.</p>
<p>The new NFA compiler achieves this by using <a href="https://blog.burntsushi.net/transducers/#references">Daciuk’s algorithm</a> for computing
minimal DFAs from a sorted sequence of non-overlapping elements. That’s exactly
what we get from the <code>utf8</code> module. In practice, we don’t necessarily generate
minimal DFAs because of the memory usage required, but instead sacrifice strict
minimality in favor of using a bounded amount of memory. But it’s usually close
enough.</p>
<p>The reverse case is not as easy. The reverse case cannot be handled so easily
because there is no simple way to reverse sort the output of the <code>utf8</code> module
in a way that works with Daciuk’s algorithm (as far as I know). To work around
this, I built a bespoke data structure called a <a href="https://github.com/rust-lang/regex/blob/4f47b14d60e82e85a880513833362d5fb485ffa8/regex-automata/src/nfa/thompson/range_trie.rs">range trie</a> that re-partitions
the output of the <code>utf8</code> module in reverse such that it’s sorted and non-overlapping.
Once this is done, we can use Daciuk’s algorithm just like we do for forward
case. The problem, though, is that this can increase the time it takes to build
an NFA quite a bit. Because of that, one needs to opt into it. First, without
the reverse shrinkng:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table --no-captures '\w' -r | tail -n20
 001367: \xB1 =&gt; 722
 001368: \x80-\x8C =&gt; 1367
 001369: \x80-\xBF =&gt; 1368
 001370: \x8D =&gt; 1367
 001371: \x80-\x8A =&gt; 1370
 001372: \x90-\xBF =&gt; 1370
 001373: \x8E-\xBF =&gt; 1367
 001374: \x80-\xBF =&gt; 1373
 001375: \xB2 =&gt; 722
 001376: \x80-\x8D =&gt; 1375
 001377: \x80-\xBF =&gt; 1376
 001378: \x8E =&gt; 1375
 001379: \x80-\xAF =&gt; 1378
 001380: \xF3 =&gt; 1386
 001381: \xA0 =&gt; 1380
 001382: \x84-\x86 =&gt; 1381
 001383: \x80-\xBF =&gt; 1382
 001384: \x87 =&gt; 1381
 001385: \x80-\xAF =&gt; 1384
 001386: MATCH(0)
</code></pre><p>And now with it:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table --no-captures '\w' -r --shrink | tail -n20
 000469: sparse(\x90 =&gt; 2, \x92 =&gt; 2, \x97 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488,
 \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000470: sparse(\x97 =&gt; 2, \x9A =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC
=&gt; 488)
 000471: sparse(\x80 =&gt; 3, \x81 =&gt; 387, \x82 =&gt; 6, \x83 =&gt; 387, \x84 =&gt; 397, \x85 =&gt; 451, \x86 =&gt; 174, \x87 =&gt; 6, \x88 =&gt; 100, \x89 =&gt; 100, \x8A =&gt; 13, \x8B =&gt; 348, \x8C =&gt; 14, \x8D =&gt; 45
2, \x8E =&gt; 16, \x8F =&gt; 88, \x90 =&gt; 19, \x91 =&gt; 62, \x92 =&gt; 20, \x93 =&gt; 343, \x94 =&gt; 21, \x95 =&gt; 62, \x96 =&gt; 23, \x97 =&gt; 61, \x98 =&gt; 179, \x99 =&gt; 27, \x9A =&gt; 27, \x9B =&gt; 441, \x9C =&gt; 446,
\x9D =&gt; 236, \x9E =&gt; 28, \x9F =&gt; 461, \xA0 =&gt; 454, \xA1 =&gt; 442, \xA2 =&gt; 31, \xA3 =&gt; 428, \xA4 =&gt; 33, \xA5 =&gt; 467, \xA6 =&gt; 35, \xA7 =&gt; 330, \xA8 =&gt; 455, \xA9 =&gt; 468, \xAA =&gt; 388, \xAB =&gt; 4
43, \xAC =&gt; 43, \xAD =&gt; 414, \xAE =&gt; 84, \xAF =&gt; 447, \xB0 =&gt; 438, \xB1 =&gt; 416, \xB2 =&gt; 363, \xB3 =&gt; 457, \xB4 =&gt; 67, \xB5 =&gt; 340, \xB6 =&gt; 199, \xB7 =&gt; 141, \xB8 =&gt; 465, \xB9 =&gt; 374, \xBA
 =&gt; 53, \xBB =&gt; 417, \xBC =&gt; 459, \xBD =&gt; 56, \xBE =&gt; 469, \xBF =&gt; 470, \xC3 =&gt; 488, \xC4-\xCA =&gt; 488, \xCC =&gt; 488, \xCD =&gt; 488, \xCE =&gt; 488, \xCF =&gt; 488, \xD0-\xD1 =&gt; 488, \xD2 =&gt; 488, \
xD3 =&gt; 488, \xD4 =&gt; 488, \xD5 =&gt; 488, \xD6 =&gt; 488, \xD8 =&gt; 488, \xD9 =&gt; 488, \xDA =&gt; 488, \xDC =&gt; 488, \xDD =&gt; 488, \xDF =&gt; 488)
 000472: sparse(\x91 =&gt; 2, \x92 =&gt; 2, \x93 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \x9F =&gt; 2, \xA0 =&gt; 7, \xA1-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \
xB2 =&gt; 2, \xE1 =&gt; 488, \xE2 =&gt; 488, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488, \xED =&gt; 488)
 000473: sparse(\x92 =&gt; 2, \x94 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \x9D =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE1 =&gt; 488, \xE3 =&gt; 48
8, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEB-\xEC =&gt; 488, \xED =&gt; 488)
 000474: sparse(\x91 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE2 =&gt; 488, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488,
 \xEA =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000475: sparse(\x90 =&gt; 2, \x91 =&gt; 2, \x96 =&gt; 2, \x97 =&gt; 2, \x9C =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE1 =&gt; 488, \xE3 =&gt;
488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488)
 000476: sparse(\x90 =&gt; 2, \x96 =&gt; 2, \x97 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488,
 \xEA =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000477: sparse(\x80 =&gt; 218, \x81 =&gt; 387, \x82 =&gt; 6, \x83 =&gt; 387, \x84 =&gt; 472, \x85 =&gt; 451, \x86 =&gt; 174, \x87 =&gt; 387, \x88 =&gt; 12, \x89 =&gt; 100, \x8A =&gt; 13, \x8B =&gt; 348, \x8C =&gt; 14, \x8D =&gt;
 452, \x8E =&gt; 16, \x8F =&gt; 426, \x90 =&gt; 19, \x91 =&gt; 62, \x92 =&gt; 20, \x93 =&gt; 473, \x94 =&gt; 21, \x95 =&gt; 62, \x96 =&gt; 23, \x97 =&gt; 61, \x98 =&gt; 179, \x99 =&gt; 157, \x9A =&gt; 27, \x9B =&gt; 441, \x9C =&gt;
446, \x9D =&gt; 236, \x9E =&gt; 28, \x9F =&gt; 461, \xA0 =&gt; 454, \xA1 =&gt; 442, \xA2 =&gt; 31, \xA3 =&gt; 428, \xA4 =&gt; 33, \xA5 =&gt; 467, \xA6 =&gt; 305, \xA7 =&gt; 317, \xA8 =&gt; 463, \xA9 =&gt; 468, \xAA =&gt; 388, \xA
B =&gt; 443, \xAC =&gt; 223, \xAD =&gt; 414, \xAE =&gt; 43, \xAF =&gt; 447, \xB0 =&gt; 438, \xB1 =&gt; 474, \xB2 =&gt; 363, \xB3 =&gt; 457, \xB4 =&gt; 140, \xB5 =&gt; 340, \xB6 =&gt; 266, \xB7 =&gt; 141, \xB8 =&gt; 465, \xB9 =&gt; 2
01, \xBA =&gt; 108, \xBB =&gt; 417, \xBC =&gt; 475, \xBD =&gt; 476, \xBE =&gt; 77, \xBF =&gt; 470, \xC3 =&gt; 488, \xC4-\xCA =&gt; 488, \xCC =&gt; 488, \xCE =&gt; 488, \xCF =&gt; 488, \xD0-\xD1 =&gt; 488, \xD2 =&gt; 488, \xD3
=&gt; 488, \xD4 =&gt; 488, \xD5 =&gt; 488, \xD8 =&gt; 488, \xD9 =&gt; 488, \xDA =&gt; 488, \xDC =&gt; 488, \xDD =&gt; 488)
 000478: sparse(\x97 =&gt; 2, \x9D =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488,
 \xEB-\xEC =&gt; 488)
 000479: sparse(\x91 =&gt; 2, \x96 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xAF =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE3 =&gt; 48
8, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488)
 000480: sparse(\x96 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xAF =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE
9 =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000481: sparse(\x90 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \x9D =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE1 =&gt; 488, \xE3 =&gt;
488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000482: sparse(\x91 =&gt; 2, \x97 =&gt; 2, \x98 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xAE =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE1 =&gt; 488, \xE3 =&gt; 488, \xE4 =
&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000483: sparse(\x91 =&gt; 2, \x97 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE1 =&gt; 488, \xE2 =&gt; 488, \xE3 =&gt; 488, \xE4 =&gt; 488, \x
E5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488)
 000484: sparse(\x91 =&gt; 2, \x97 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE0 =&gt; 488, \xE1 =&gt; 488, \xE2 =&gt; 488, \xE3 =&gt; 488, \xE4 =&gt; 488, \x
E5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488, \xEF =&gt; 488)
 000485: sparse(\x97 =&gt; 2, \xA0-\xA9 =&gt; 2, \xAA =&gt; 2, \xAB =&gt; 2, \xAC =&gt; 2, \xAD =&gt; 2, \xB0 =&gt; 2, \xB1 =&gt; 2, \xE3 =&gt; 488, \xE4 =&gt; 488, \xE5-\xE9 =&gt; 488, \xEA =&gt; 488, \xEB-\xEC =&gt; 488)
 000486: sparse(\x80 =&gt; 4, \x81 =&gt; 396, \x82 =&gt; 6, \x83 =&gt; 387, \x84 =&gt; 472, \x85 =&gt; 451, \x86 =&gt; 174, \x87 =&gt; 387, \x88 =&gt; 12, \x89 =&gt; 100, \x8A =&gt; 195, \x8B =&gt; 348, \x8C =&gt; 14, \x8D =&gt;
452, \x8E =&gt; 16, \x8F =&gt; 426, \x90 =&gt; 19, \x91 =&gt; 62, \x92 =&gt; 20, \x93 =&gt; 473, \x94 =&gt; 114, \x95 =&gt; 62, \x96 =&gt; 23, \x97 =&gt; 61, \x98 =&gt; 179, \x99 =&gt; 27, \x9A =&gt; 27, \x9B =&gt; 441, \x9C =&gt; 4
46, \x9D =&gt; 236, \x9E =&gt; 28, \x9F =&gt; 478, \xA0 =&gt; 462, \xA1 =&gt; 442, \xA2 =&gt; 31, \xA3 =&gt; 479, \xA4 =&gt; 33, \xA5 =&gt; 467, \xA6 =&gt; 305, \xA7 =&gt; 480, \xA8 =&gt; 481, \xA9 =&gt; 399, \xAA =&gt; 482, \xAB
 =&gt; 443, \xAC =&gt; 43, \xAD =&gt; 414, \xAE =&gt; 43, \xAF =&gt; 447, \xB0 =&gt; 438, \xB1 =&gt; 474, \xB2 =&gt; 363, \xB3 =&gt; 457, \xB4 =&gt; 483, \xB5 =&gt; 484, \xB6 =&gt; 108, \xB7 =&gt; 141, \xB8 =&gt; 465, \xB9 =&gt; 374
, \xBA =&gt; 108, \xBB =&gt; 417, \xBC =&gt; 71, \xBD =&gt; 476, \xBE =&gt; 57, \xBF =&gt; 485, \xC3 =&gt; 488, \xC4-\xCA =&gt; 488, \xCC =&gt; 488, \xCD =&gt; 488, \xCE =&gt; 488, \xCF =&gt; 488, \xD0-\xD1 =&gt; 488, \xD2 =&gt;
488, \xD3 =&gt; 488, \xD4 =&gt; 488, \xD5 =&gt; 488, \xD6 =&gt; 488, \xD8 =&gt; 488, \xD9 =&gt; 488, \xDA =&gt; 488, \xDB =&gt; 488, \xDC =&gt; 488, \xDD =&gt; 488)
^000487: sparse(0-9 =&gt; 488, A-Z =&gt; 488, _ =&gt; 488, a-z =&gt; 488, \x80 =&gt; 58, \x81 =&gt; 72, \x82 =&gt; 78, \x83 =&gt; 86, \x84 =&gt; 96, \x85 =&gt; 111, \x86 =&gt; 123, \x87 =&gt; 136, \x88 =&gt; 143, \x89 =&gt; 153,
\x8A =&gt; 165, \x8B =&gt; 172, \x8C =&gt; 177, \x8D =&gt; 186, \x8E =&gt; 194, \x8F =&gt; 202, \x90 =&gt; 217, \x91 =&gt; 222, \x92 =&gt; 224, \x93 =&gt; 227, \x94 =&gt; 233, \x95 =&gt; 238, \x96 =&gt; 244, \x97 =&gt; 251, \x98
=&gt; 257, \x99 =&gt; 258, \x9A =&gt; 269, \x9B =&gt; 274, \x9C =&gt; 279, \x9D =&gt; 285, \x9E =&gt; 295, \x9F =&gt; 298, \xA0 =&gt; 312, \xA1 =&gt; 315, \xA2 =&gt; 320, \xA3 =&gt; 322, \xA4 =&gt; 328, \xA5 =&gt; 333, \xA6 =&gt; 33
8, \xA7 =&gt; 341, \xA8 =&gt; 345, \xA9 =&gt; 351, \xAA =&gt; 360, \xAB =&gt; 365, \xAC =&gt; 368, \xAD =&gt; 375, \xAE =&gt; 383, \xAF =&gt; 385, \xB0 =&gt; 395, \xB1 =&gt; 402, \xB2 =&gt; 408, \xB3 =&gt; 411, \xB4 =&gt; 418, \x
B5 =&gt; 425, \xB6 =&gt; 429, \xB7 =&gt; 435, \xB8 =&gt; 440, \xB9 =&gt; 444, \xBA =&gt; 450, \xBB =&gt; 460, \xBC =&gt; 466, \xBD =&gt; 471, \xBE =&gt; 477, \xBF =&gt; 486)
 000488: MATCH(0)
</code></pre><p>So shrinking in the reverse case still helps quite a bit in terms of generating
tighter NFAs with fewer states. But because of the extra compile time hit,
it is currently disabled by default. Therefore, the minimal UTF-8 automata
optimization only applies to forward NFAs. (Reverse NFAs are created for use
with DFAs, since a DFA requires a reverse scan to find the start of each
match.) However, we do still look for redundant suffixes and share them in the
reverse case when this extra NFA shrinking isn’t enabled.</p>
<h3 id="nfa-optimization-literal-trie">NFA optimization: literal trie</h3>
<p>If you haven’t noticed a theme by now, one of the biggest problems with a
Thompson NFA is its epsilon transitions. It is really the critical thing about
a Thompson NFA that makes it scale poorly with respect to the size of a regex.
This is why, when using Thompson based regex engines, increasing the size
of the regex can impact search times. Because of that, Thompson based regex
engines often (but not always) have alternative engines that mitigate this
weakness in one way or another. For example, by using a lazy DFA. However, a
lazy DFA cannot be used in every circumstance, and even a lazy DFA can become
overwhelmed by a large enough regex.</p>
<p>So in this section, we’ll talk about another NFA optimization that works to
reduce epsilon transitions. In this case, we’re going to be limiting ourselves
to an alternation of literals. Let’s take a look at an example using the old
NFA compiler:</p>
<pre tabindex="0"><code>$ regex-debug compile 'zap|z|zapper'
0000 Save(0) (start)
0001 Split(2, 5)
0002 'z'
0003 'a'
0004 'p' (goto: 13)
0005 Split(6, 7)
0006 'z' (goto: 13)
0007 'z'
0008 'a'
0009 'p'
0010 'p'
0011 'e'
0012 'r'
0013 Save(1)
0014 Match(0)
</code></pre><p>Here, we’re building an NFA for the regex <code>zap|z|zapper</code>. The way it’s compiled
is with nested <code>Split</code> instructions. It starts with a <code>Split(2, 5)</code> that points
to the beginning of <code>zap</code> and another <code>Split(6, 7)</code> instruction. This second
instruction then points to the beginning of <code>z</code> and <code>zapper</code>. So for this
regex, when looking for a match, the epsilon closure of all these splits is
enumerated for every character in the haystack.</p>
<p>In contrast, let’s look at what the new NFA compiler does:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table 'zap|z|zapper'
thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 11
 000003: p =&gt; 12
 000004: a =&gt; 3
 000005: r =&gt; 12
 000006: e =&gt; 5
 000007: p =&gt; 6
 000008: p =&gt; 7
 000009: a =&gt; 8
 000010: union(4, 12, 9)
 000011: z =&gt; 10
 000012: capture(pid=0, group=0, slot=1) =&gt; 13
 000013: MATCH(0)
</code></pre><p>(Again, ignore states <code>0</code> and <code>1</code>, which correspond to the optional unanchored
<code>(?s-u:.)*?</code> prefix. The old NFA compiler doesn’t emit those states for
unrelated reasons.)</p>
<p>Here, before an epsilon transition is seen at all, a <code>z</code> must first be matched
in state <code>11</code>. Only after that is the <code>union(4, 12, 9)</code> state seen. (This
<code>union</code> is equivalent to the nested <code>Split</code> instructions in the old NFA
compiler, but combines them all into one state.) If this NFA were used for a
search, one wouldn’t need to compute a beefy epsilon closure for every byte in
the haystack. One would only need to do it after a <code>z</code> byte is seen, which is
much more rare. In effect, the regex was rewritten to <code>z(?:ap||apper)</code>.</p>
<p>So what’s going on here? In this particular case, it almost looks like a common
prefix has been factored out. But the optimization at work here is a bit more
general than that. Consider the regex <code>abc|xyz</code>. There are no common prefixes
here. First, let’s see what the old NFA compiler does:</p>
<pre tabindex="0"><code>$ regex-debug compile 'abc|xyz'
0000 Save(0) (start)
0001 Split(2, 5)
0002 'a'
0003 'b'
0004 'c' (goto: 8)
0005 'x'
0006 'y'
0007 'z'
0008 Save(1)
0009 Match(0)
</code></pre><p>Here, we see a <code>Split</code> instruction again that forks out to the start of <code>abc</code>
and then <code>xyz</code>.</p>
<p>Now the new NFA compiler:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson --no-table 'abc|xyz'
thompson::NFA(
&gt;000000: binary-union(2, 1)
 000001: \x00-\xFF =&gt; 0
^000002: capture(pid=0, group=0, slot=0) =&gt; 7
 000003: c =&gt; 8
 000004: b =&gt; 3
 000005: z =&gt; 8
 000006: y =&gt; 5
 000007: sparse(a =&gt; 4, x =&gt; 6)
 000008: capture(pid=0, group=0, slot=1) =&gt; 9
 000009: MATCH(0)
)
</code></pre><p>Here there are no epsilon transitions at all. The <code>a</code> and <code>x</code> have been lifted
out into the same sparse state, with each them forking off to their respective
suffixes, <code>bc</code> and <code>yz</code>.</p>
<p>What’s happening here is that the NFA compiler is recognizing an alternation
of literals, <a href="https://github.com/rust-lang/regex/blob/4f47b14d60e82e85a880513833362d5fb485ffa8/regex-automata/src/nfa/thompson/literal_trie.rs">compiling it into a trie</a>, and then converting
that trie to an NFA directly in a way that minimizes epsilon transitions. The
key trick to this optimization is ensuring that leftmost-first semantics are
preserved. For example, in the <code>zap|z|zapper</code> example above, one might be
tempted to rewrite it as <code>z(?:ap(?:per)?)?</code>. But this does not have the same
matches! This regex will match <code>zapper</code> in the haystack <code>zapper</code>, but the
original <code>zap|z|zapper</code> will match <code>zap</code>. The literal trie achieves this by
partitioning the transitions in each trie state into chunks, where a chunk is
created whenever a match (of one of the literals) is seen. If a normal trie was
created, then the preference order required by leftmost-first semantics would
be lost when translating the trie back to an NFA.</p>
<h3 id="nfa-future-work">NFA future work</h3>
<p>There are two aspects I’d like to explore for future work on NFAs.</p>
<p>First is the <a href="https://en.wikipedia.org/wiki/Glushkov%27s_construction_algorithm">Glushkov NFA</a>. A Glushkov NFA has a worse time complexity
for compilation, but it comes with the advantage of not having any epsilon
transitions. (Instead, it is an NFA by virtue of permitting a state to have
multiple transitions defined for the same haystack symbol.) Because of the
worse compilation time complexity, a Glushkov NFA probably can’t be used in
every case, but it’s certainly plausible to use it for a subset of smaller
regexes. A Glushkov NFA is possibly more amenable to bit-parallel techniques
that are sadly underused in the <code>regex</code> crate at present. One of the big
questions marks for me here is how well a Glushkov NFA will fair with big
Unicode classes. (Perhaps such things will be a disqualifiying criterion.)</p>
<p>Second is storing an NFA in a single contiguous allocation. This might make
access patterns faster and more cache friendly, but perhaps more importantly,
it could permit zero-copy serialization and deserialization. The downside of
doing this is code complexity and potentially more use of <code>unsafe</code>, but there
are some potentially nice benefits too.</p>
<h2 id="regex-engines">Regex engines</h2>
<p>Like <a href="https://github.com/google/re2">RE2</a>, the <code>regex</code> crate is internally composed of several different regex
engines. Most of them have already been mentioned so far. In this section, we
will do a bit of a deeper dive on each of them and explain why they exist.
Finally, we’ll wrap up by exploring the meta regex engine, which combines all
of the regex engines into a single engine.</p>
<p>But why have so many regex engines? The reason is essentially engineering: the
implementation of regex engines with more functionality tends to search more
slowly than regex engines that have less functionality. We could use only a
single regex engine that supports all the functionality we want, namly the
<a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/pikevm/struct.PikeVM.html"><code>PikeVM</code></a>, but the search performance would likely be disappointing to a lot
of users. This fundamentally drives the addition of other engines. None of
the other engines can support the full range of functionality provided by the
<code>regex</code> crate, and so buck stops with the <code>PikeVM</code>.</p>
<p>In addition to using <code>regex-cli</code> to show how to run each regex engine, we’ll
also look at short example Rust programs. To follow along with the Rust
program examples, you’ll want to setup a Cargo project and add <code>regex-automata</code>
as a dependency:</p>
<pre tabindex="0"><code>$ cargo init --bin
$ cargo add 'regex-automata@0.3'
</code></pre><p>Then you can edit <code>src/main.rs</code> to add source code and run the program with
<code>cargo run</code>.</p>
<h3 id="common-elements-among-regex-engines">Common elements among regex engines</h3>
<p>While there are many regex engines in the <code>regex-automata</code> crate, all of them
share very similar APIs. Because of that, it’s worth covering a few of those
common elements first.</p>
<p>The three most important types are <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/struct.Input.html"><code>Input</code></a>, <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/struct.Match.html"><code>Match</code></a> and <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/struct.MatchError.html"><code>MatchError</code></a>.</p>
<p><code>Input</code> is a small abstraction for setting the parameters of a single search.
Its only required parameter is a haystack, that is, the sequence of bytes to
search. Most search APIs accept anything that implements the <code>Into&lt;Input&gt;</code>
trait, and both <code>&amp;[u8]</code> and <code>&amp;str</code> implement <code>Into&lt;Input&gt;</code>. Optional parameters
consist of the span of the haystack to search, whether to execute an anchored
search and whether to stop the search early as soon as a match is found instead
of greedily trying to match as much as possible.</p>
<p><code>Match</code> represents the data reported whenever a match is found in a
haystack. The data consists of two elements. The first is the span of
byte offsets in the haystack where the match was found. The second is the
<a href="https://docs.rs/regex-automata/0.3.*/regex_automata/struct.PatternID.html"><code>PatternID</code></a> corresponding to the pattern that matched. (Every regex engine
in <code>regex-automata</code> has first class multi-pattern support. Pattern IDs are
assigned, starting from zero, in an auto-incrementing fashion based on the
order of the patterns given to the regex engine constructor.)</p>
<p><code>MatchError</code> represents an error that occurred during a search. When an error
occurs, it is not possible to determine whether a match exists or not. That is,
the result is indeterminate. For this reason, many of the basic search APIs
have a return type of <code>Result&lt;Option&lt;Match&gt;, MatchError&gt;</code>. Errors can occur
during a search for a variety of reasons. For example, a DFA can be configured
to quit immediately whenever a certain byte is seen. Another example is the
<a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/backtrack/struct.BoundedBacktracker.html"><code>BoundedBacktracker</code></a>, which will fail if the length of the haystack exceeds a
configured limit. One of the main features of the <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/meta/struct.Regex.html">meta regex engine</a>, as we’ll
discuss later, is providing a facade on top of a composition of regex engines
that never results in an error being returned to the caller.</p>
<p>There are some other themes common to most regex engines. For example, the
construction of most engines is done by a <code>Builder</code> and configured by one or
more <code>Config</code> values. We’ll talk about these more as they come up. See also the
<a href="https://docs.rs/regex-automata/0.3.*/regex_automata/#api-themes">API themes</a> section in the <code>regex-automata</code> crate documentation.</p>
<h3 id="engine-pike-vm">Engine: Pike VM</h3>
<p>As mentioned above, the buck stops with the <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/pikevm/struct.PikeVM.html"><code>PikeVM</code></a>. That is, the <code>PikeVM</code>
supports the full suite of regex functionality that one can parse with
<code>regex-syntax</code>, and it supports this for any haystack of any length. Other
regex engines have various limitations. For example:</p>
<ul>
<li>The <code>BoundedBacktracker</code> only works in cases where <code>len(haystack) * len(regex)</code> is below a configured limit. In practice, this often means one can
only use it with short haystacks.</li>
<li>The one-pass DFA only works a small subset of NFAs that satisfy the
“one-pass” criterion.</li>
<li>The lazy DFA and full DFA cannot match Unicode word boundaries. Both have
heuristics for treating a Unicode word boundary as an ASCII word boundary when
the haystack only consists of ASCII, but if a non-ASCII byte is seen, both can
quit and return an error instead of completing the search.</li>
</ul>
<p>Other than a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/pikevm/struct.Cache.html"><code>Cache</code></a> value, a <code>PikeVM</code> can be built directly
from an NFA without any additional work. That is, its search works by a
“simulation” of the NFA itself. (Confusingly, this is sometimes referred to
as the “DFA algorithm.”) The actual implementation is structured similarly to
a virtual machine, with each NFA state acting as an instruction. The <code>PikeVM</code>
works by moving from NFA state to the next, and computing epsilon closures
on the fly. Since it’s possible to be in multiple NFA states simultaneously,
the <code>PikeVM</code> keeps track of every active state. The transition function then
applies to each of those states. The <code>PikeVM</code> also keeps track of capture group
positions.</p>
<p>The main problem with the <code>PikeVM</code> is performance, and its poor performance is
primarily rooted in having to keep track of so much state. The capture group
positions are required to report the start and end match offsets, while the
currently active states must be tracked in order to guarantee worst case
<code>O(m * n)</code> time. That is, in contrast to a backtracking approach, the <code>PikeVM</code>
visits each byte in the haystack at most a constant number of times, and it
does so by computing all possible active states in lock-step. This adds quite
a bit of overhead, and it can be exacerbated by regexes with a lot of epsilon
transitions. (This is one of the reasons why, earlier in this blog, we spent so
much time talking about optimizations in the NFA to elide epsilon transitions.)</p>
<p>Now that we’ve talked a little about how the <code>PikeVM</code> works, let’s look at a
few examples. Here’s a lightly annotated Rust program showing how to use it for
a search:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>nfa</span>::<span>thompson</span>::<span>pikevm</span>::<span>PikeVM</span><span>,</span><span> </span><span>Match</span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// This creates a PikeVM directly from a pattern string. But one can also
</span></span></span><span><span><span></span><span>    </span><span>// build a PikeVM directly from an NFA using `PikeVM::builder()`.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>PikeVM</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>// Most regex engines in regex-automata require some kind of mutable
</span></span></span><span><span><span></span><span>    </span><span>// scratch space that can be written to during a search. The meta regex
</span></span></span><span><span><span></span><span>    </span><span>// engine has APIs that hide this fact from you, but when you use the
</span></span></span><span><span><span></span><span>    </span><span>// underlying regex engines directly, you must create and pass around these
</span></span></span><span><span><span></span><span>    </span><span>// cache values explicitly.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>it</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find_iter</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>"Σέρλοκ Χολμς"</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>12</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>13</span><span>..</span><span>23</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>None</span><span>,</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find match pikevm --no-table -p '\b\w+\b' -y 'Σέρλοκ Χολμς'
0:0:12:Σέρλοκ
0:13:23:Χολμς
</code></pre><p>Notice the use of Unicode word boundaries on a non-ASCII haystack. Only the
<code>PikeVM</code>, <code>BoundedBacktracker</code> and one-pass DFA support this. The lazy DFA
and fully compiled DFA would return an error in this case.</p>
<p>The other important thing to notice here is that the search APIs do not
return an error. Indeed, the <code>PikeVM</code> can never return an error under any
circumstances (nor will it ever panic). This is actually a unique property
among the regex engines in <code>regex-automata</code>. Every other regex engine can
return an error during a search for one reason or another.</p>
<p>We can also make use of multi-pattern support with capture groups
simultaneously. (This is something that the <code>regex</code> crate cannot do, and many
have requested this support from its <code>RegexSet</code> API. That still doesn’t exist,
but you can now at least drop down to <code>regex-automata</code> and do it. This same
example also works with the meta regex engine.)</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>nfa</span>::<span>thompson</span>::<span>pikevm</span>::<span>PikeVM</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>PikeVM</span>::<span>new_many</span><span>(</span><span>&amp;</span><span>[</span><span>
</span></span></span><span><span><span>        </span><span>r</span><span>"(?&lt;email&gt;[.\w]+@(?&lt;domain&gt;[.\w]+))"</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>r</span><span>"(?&lt;phone&gt;(?&lt;areacode&gt;[0-9]{3})-[0-9]{3}-[0-9]{4})"</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>])</span><span>
</span></span></span><span><span><span>    </span><span>.</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>hay</span><span> </span><span>=</span><span> </span><span>"foo@example.com, 111-867-5309"</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>it</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>captures_iter</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>hay</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>caps</span><span> </span><span>=</span><span> </span><span>it</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>0</span><span>,</span><span> </span><span>caps</span><span>.</span><span>pattern</span><span>().</span><span>unwrap</span><span>().</span><span>as_usize</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>"example.com"</span><span>,</span><span> </span><span>&amp;</span><span>hay</span><span>[</span><span>caps</span><span>.</span><span>get_group_by_name</span><span>(</span><span>"domain"</span><span>).</span><span>unwrap</span><span>()]);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>caps</span><span> </span><span>=</span><span> </span><span>it</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>1</span><span>,</span><span> </span><span>caps</span><span>.</span><span>pattern</span><span>().</span><span>unwrap</span><span>().</span><span>as_usize</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>"111"</span><span>,</span><span> </span><span>&amp;</span><span>hay</span><span>[</span><span>caps</span><span>.</span><span>get_group_by_name</span><span>(</span><span>"areacode"</span><span>).</span><span>unwrap</span><span>()]);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>assert!</span><span>(</span><span>it</span><span>.</span><span>next</span><span>().</span><span>is_none</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find capture pikevm --no-table \
   -p '(?&lt;email&gt;[.\w]+@(?&lt;domain&gt;[.\w]+))' \
   -p '(?&lt;phone&gt;(?&lt;areacode&gt;[0-9]{3})-[0-9]{3}-[0-9]{4})' \
   -y 'foo@example.com, 111-867-5309'
0:{ 0: 0..15/foo@example.com, 1/email: 0..15/foo@example.com, 2/domain: 4..15/example.com }
1:{ 0: 17..29/111-867-5309, 1/phone: 17..29/111-867-5309, 2/areacode: 17..20/111 }
</code></pre><p>Notice how the capture groups are different for each pattern. The caller is
responsible for using the correct capture group name based on which pattern
matches.</p>
<h3 id="engine-bounded-backtracker">Engine: bounded backtracker</h3>
<p>The <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/nfa/thompson/backtrack/struct.BoundedBacktracker.html"><code>BoundedBacktracker</code></a> uses a backtracking algorithm to execute a search
using a Thompson NFA directly. This is sometimes also (confusingly) referred
to as the “NFA algorithm.” The key difference between the backtracking
implementation in <code>regex-automata</code> and most other implementations is that
it uses additional state to avoid re-tracing steps already taken during
backtracking. This allows us to guarantee worst case <code>O(m * n)</code> time, but at
the expense of <code>O(m * n)</code> space.</p>
<p>(Classical backtracking is also technically bounded theoretically, but the
“bounded” in the name “bounded backtracker” refers to the explicit bound used
in the implementation to guarantee worst case <code>O(m * n)</code> time.)</p>
<p>The benefit of a the bounded backtracker is purely that it is usually faster
than the <code>PikeVM</code>. In rough experiments, it’s usually about twice as fast.</p>
<p>Here’s a quick example, like the <code>PikeVM</code> example previously, but using the
bounded backtracker:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>nfa</span>::<span>thompson</span>::<span>backtrack</span>::<span>BoundedBacktracker</span><span>,</span><span> </span><span>Match</span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>BoundedBacktracker</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>// A bounded backtracker needs a cache just like the PikeVM. The Cache
</span></span></span><span><span><span></span><span>    </span><span>// keeps track of work already done, and also contains scratch space for
</span></span></span><span><span><span></span><span>    </span><span>// backtracking's call stack, which is stored on the heap.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Unlike the PikeVM, the bounded backtracker can fail to run a search.
</span></span></span><span><span><span></span><span>    </span><span>// This occurs when `len(regex) * len(haystack)` exceeds the configured
</span></span></span><span><span><span></span><span>    </span><span>// visited capacity. We'll see an example of this below.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>it</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>try_find_iter</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>"Σέρλοκ Χολμς"</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Ok</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>12</span><span>))),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Ok</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>13</span><span>..</span><span>23</span><span>))),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>None</span><span>,</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find match backtrack --no-table -p '\b\w+\b' -y 'Σέρλοκ Χολμς'
0:0:12:Σέρλοκ
0:13:23:Χολμς
</code></pre><p>This exame should look almost identical to the <code>PikeVM</code> example. One important
difference is that instead of calling <code>re.find_iter(..)</code>, we instead called
<code>re.try_find_iter(..)</code>. Namely, as mentioned above, the bounded backtracker can
return an error when a search would require more memory than what is configured.
The relevant configuration knob is <a href="https://docs.rs/regex-automata/0.3.*/regex/regex_automata/nfa/thompson/backtrack/struct.Config.html#method.visited_capacity"><code>Config::visited_capacity</code></a>. We can also
query just how big of a haystack a bounded backtracker can search without
failing:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>nfa</span>::<span>thompson</span>::<span>backtrack</span>::<span>BoundedBacktracker</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>BoundedBacktracker</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>"</span><span>{:?}</span><span>"</span><span>,</span><span> </span><span>re</span><span>.</span><span>max_haystack_len</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>At the time of writing, the output of this program on my machine is <code>6635</code>.
That might seem pretty short, and that’s because the regex is perhaps bigger
than you might think it is. Namely, since <code>\w</code> is Unicode-aware by default,
<code>\w</code> matches over 100,000 distinct codepoints. While we could increase the
maximum haystack length that we could search by setting a bigger value for
<code>Config::visited_capacity</code>, we can <em>also</em> increase it by decreasing the size of
our regex by disabling Unicode mode:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>nfa</span>::<span>thompson</span>::<span>backtrack</span>::<span>BoundedBacktracker</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>BoundedBacktracker</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>"</span><span>{:?}</span><span>"</span><span>,</span><span> </span><span>re</span><span>.</span><span>max_haystack_len</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>The output of this program on my machine is now <code>233015</code>. That’s nearly two
orders of magnitude difference!</p>
<p>Overall, when possible, one should prefer using the bounded backtracker over
the <code>PikeVM</code>. They both have the same time complexity guarantees, but the
bounded backtracker tends to be faster in practice.</p>
<h3 id="engine-one-pass-dfa">Engine: one-pass DFA</h3>
<p>Before talking about the <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/onepass/struct.DFA.html">one-pass DFA</a>, it makes sense to motivate its
existence in a bit more detail. Namely, one important aspect of both the
<code>PikeVM</code> and the bounded backtracker is that they support reporting the offsets
of matching capture groups in the pattern. For example, using the <code>PikeVM</code> with
<code>regex-cli</code>:</p>
<pre tabindex="0"><code>$ regex-cli find capture pikevm --no-table \
   -p '(?&lt;year&gt;[0-9]{4})-(?&lt;month&gt;[0-9]{2})-(?&lt;day&gt;[0-9]{2})' \
   -y '2023-07-02'
0:{ 0: 0..10/2023-07-02, 1/year: 0..4/2023, 2/month: 5..7/07, 3/day: 8..10/02 }
</code></pre><p>Capture groups are quite useful because they permit de-composing a regex match
down into constituent parts that are independently useful. As in the above
example, we didn’t <em>just</em> match a date, we matched the individual components
of that date and made each of those components easily available via APIs. For
example, using the <code>regex</code> crate itself:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex</span>::<span>Regex</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>pat</span><span> </span><span>=</span><span> </span><span>r</span><span>"(?&lt;year&gt;[0-9]{4})-(?&lt;month&gt;[0-9]{2})-(?&lt;day&gt;[0-9]{2})"</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>Regex</span>::<span>new</span><span>(</span><span>pat</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>Some</span><span>(</span><span>caps</span><span>)</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>captures</span><span>(</span><span>"2023-07-02"</span><span>)</span><span> </span><span>else</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>};</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>" year: </span><span>{:?}</span><span>"</span><span>,</span><span> </span><span>&amp;</span><span>caps</span><span>[</span><span>"year"</span><span>]);</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>"month: </span><span>{:?}</span><span>"</span><span>,</span><span> </span><span>&amp;</span><span>caps</span><span>[</span><span>"month"</span><span>]);</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>"  day: </span><span>{:?}</span><span>"</span><span>,</span><span> </span><span>&amp;</span><span>caps</span><span>[</span><span>"day"</span><span>]);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Without capture groups, regexes become a lot less convenient.</p>
<p>The problem with capture groups is that they aren’t something that cleanly fit
into the theoretical model of regular languages and finite automata. (They
require something more expressive known as <a href="https://arxiv.org/abs/1907.08837">tagged finite automata</a>.) As a
result, capture groups are bolted on to the classical NFA simulation, and
the result is named <code>PikeVM</code>. Capture groups are also part of the classic
“NFA algorithm” or backtracking, as the matching offsets of each group can be
recorded as the backtracking search progresses through the haystack.</p>
<p>But that’s generally where capture groups stop being supported. DFAs simply
do not support them, and there is no obvious way to make them support capture
groups in general without evolving to something like tagged finite automata.</p>
<p>However, there is one case where we can bolt capture groups into something that
executes like a DFA: a one-pass NFA. One can think of a one-pass NFA as an NFA
that can be converted into a DFA where each DFA state maps to at most one NFA
state. That is, when performing a search using an NFA simulation, then at each
possible character in the haystack there is at most one NFA state to transition
to.</p>
<p>The intuition behind this special case is that only one copy of the matching
capture groups needs to be kept. (In the <code>PikeVM</code>, there are up to <code>len(regex)</code>
copies of capture groups kept, as there is no way to know which capture groups
will wind up being part of the final match.) If one can detect this case, then
a new DFA can be constructed from the NFA in the linear time, and this DFA can
execute a search such that a constant number of CPU instructions are used to
process each character in the haystack.</p>
<p>The end result of this is a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/onepass/struct.DFA.html">one-pass DFA</a> and it generally runs quite a bit
faster than either the <code>PikeVM</code> or the bounded backtracker. In other words, it
represents the fastest way to report the offsets of matching capture groups in
the <code>regex</code> crate.</p>
<p>The problem with a one-pass DFA is that, as a DFA, it uses a lot more memory.
(The memory problem is mitigated by giving one-pass DFA construction a
configurable fixed budget of memory, and if it’s exceeded, one-pass DFA
construction fails.) Additionally, many regexes are not one-pass. For example,
all unanchored searches in the <code>regex</code> crate are done by adding an implicit
<code>(?s-u:.)*?</code> prefix to the beginning of the regex. That prefix is itself not
one-pass when followed by any non-empty regex. Therefore, a one-pass DFA only
supports anchored searches.</p>
<p>The “only anchored” search limitation might make it seem like the one-pass
DFA has very limited utility, but as we’ll see in more detail, the meta regex
engine uses anchored searches quite a bit even if the original regex itself
isn’t anchored. This can occur when the caller asked for the offsets of
matching capture groups. The meta regex engine starts by looking for an overall
match using a DFA engine, and then once a match is found, an anchored search
is used on only the matched part of the haystack to report offsets for each
matching capture group. In this way, the utility of the one-pass DFA is quite
high.</p>
<p>Using the one-pass DFA directly is possible, and it looks similar to past
examples but with some small deviations because of the one-pass DFA’s more
limited API:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>dfa</span>::<span>onepass</span>::<span>DFA</span><span>,</span><span> </span><span>Match</span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>DFA</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// A one-pass DFA doesn't expose any iterator APIs directly because it only
</span></span></span><span><span><span></span><span>    </span><span>// supports anchored matches. Thus, any iterator that would be returned
</span></span></span><span><span><span></span><span>    </span><span>// would only support adjacent matches. Such a thing is a valid use case,
</span></span></span><span><span><span></span><span>    </span><span>// but it wouldn't match the semantics of every other iterator in
</span></span></span><span><span><span></span><span>    </span><span>// regex-automata.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>Some</span><span>(</span><span>m</span><span>)</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>"Σέρλοκ Χολμς"</span><span>)</span><span> </span><span>else</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>};</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>12</span><span>),</span><span> </span><span>m</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find match onepass --no-table --anchored \
   -p '\b\w+\b' \
   -y 'Σέρλοκ Χολμς'
0:0:12:Σέρλοκ
</code></pre><p>Notice how we pass the <code>--anchored</code> flag to <code>regex-cli</code>. Without it, the
one-pass DFA search would return an error.</p>
<p>We can execute multiple searches as well. Even though the regex itself isn’t
anchored, we don’t have to limit ourselves to searches beginning at offset <code>0</code>:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>dfa</span>::<span>onepass</span>::<span>DFA</span><span>,</span><span> </span><span>Input</span><span>,</span><span> </span><span>Match</span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>hay</span><span> </span><span>=</span><span> </span><span>"Σέρλοκ Χολμς"</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>DFA</span>::<span>new</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>Some</span><span>(</span><span>m</span><span>)</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>hay</span><span>)</span><span> </span><span>else</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>};</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>12</span><span>),</span><span> </span><span>m</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>input</span><span> </span><span>=</span><span> </span><span>Input</span>::<span>new</span><span>(</span><span>hay</span><span>).</span><span>range</span><span>(</span><span>13</span><span>..</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>Some</span><span>(</span><span>m</span><span>)</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>input</span><span>)</span><span> </span><span>else</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>};</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>13</span><span>..</span><span>23</span><span>),</span><span> </span><span>m</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>The <code>Input</code> abstraction can be used in the same way with any other regex engine
as well.</p>
<p>It can be quite tricky to reason about whether a particular regex is one-pass
or not. For example, a regex can be one-pass when Unicode is disabled and not
one-pass when Unicode is enabled. For example:</p>
<pre tabindex="0"><code>$ regex-cli find match onepass --no-table --anchored \
   -p '\w+\s+\w+' \
   -y 'Σέρλοκ Χολμς'
failed to compile onepass DFA: one-pass DFA could not be built because pattern is not one-pass: conflicting transition
</code></pre><p>But if we disable Unicode mode, then the regex becomes one-pass:</p>
<pre tabindex="0"><code>$ regex-cli find match onepass --no-table --anchored \
   -p '(?-u)\w+\s+\w+' \
   -y 'Sherlock Holmes'
0:0:15:Sherlock\x20Holmes
</code></pre><p>This happens because, when Unicode mode is enabled, <code>\w</code> and <code>\s</code> partially
overlap. They of course do not overlap <em>logically</em>, as taking the codepoint
sets from each of <code>\w</code> and <code>\s</code> and intersecting them would produce the empty
set:</p>
<pre tabindex="0"><code>$ regex-cli debug hir --no-table '[\w&amp;&amp;\s]'
Class(
    {},
)
</code></pre><p>The overlap is actually at the byte level, and the byte level is how the
transitions in a one-pass DFA are defined. This overlap means that the DFA for
<code>\w+\s+\w+</code> when Unicode mode is enabled doesn’t satisfy the property that
every state in the DFA maps to at most one NFA state. That is, there exists
codepoints in both <code>\w</code> and <code>\s</code> which start with the same leading UTF-8 code
units.</p>
<p>But when Unicode mode is disabled, not only do the codepoint sets not have any
overlap, but they don’t have any overlap at the byte level either. Why? Because
the codepoints in <code>\w</code> and <code>\s</code> when Unicode is disabled are limited to ASCII
codepoints, and each ASCII codepoint is always encoded as a single UTF-8 code
unit corresponding to the ASCII codepoint number.</p>
<p>One should prefer a one-pass DFA over both the <code>PikeVM</code> and the bounded
backtracker because it is faster, although it can take longer to build and may
use more memory. However, because it can only be built from a very limited set
of regexes, one must be ready to deal with construction failing and falling
back to a different engine.</p>
<h3 id="engine-dfa">Engine: DFA</h3>
<p>The <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/regex/struct.Regex.html">DFA regex engine</a> is made up of two <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/dense/struct.DFA.html">dense DFAs</a>. One DFA is
responsible for a forward scan that finds the end of a match and the other DFA
is used to perform an anchored scan backwards from the end of a match to find
the start of a match. (This second DFA is built by reversing the concatenations
in an <a href="https://docs.rs/regex-syntax/0.7.*/regex_syntax/hir/struct.Hir.html"><code>Hir</code></a>, building an NFA from that and then determinizing that reverse
NFA into a DFA.) We call these DFAs “dense” to distinguish them from <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/sparse/struct.DFA.html">sparse
DFAs</a>. A dense DFA uses a representation that optimizes for
search speed at the expense of more memory usage, while a sparse DFA uses a
representation that optimizes for less memory usage at the expense of search
speed.</p>
<p>Fully compiled DFAs are usually not found in general purpose regex engines
because building them has worst case <code>O(2^m)</code> time and space (where <code>m</code> is
proportional to <code>len(regex)</code>). For example, <code>[01]*1[01]{N}</code> compiles to an NFA
with approximately <code>N</code> states, and as <code>N</code> grows, the NFA grows linearly. But
the corresponding DFA has approximately <code>2^N</code> states, and as the DFA grows, the
number of states grows exponentially.</p>
<p>But the problem with a DFA is not just limited to its theoretical worst case
behavior. DFAs, especially dense DFAs, tend to use a lot of memory because each
state supports computing the next transition for any byte in constant time.
This fundamentally requires more memory to provide constant time random access.
When you combine this with large Unicode character classes, the result can be
disastrous. For example, let’s compare some sizes for the regex <code>\w</code>. First
up is the NFA (which, remember, can be used directly as a regex engine in the
case of the <code>PikeVM</code> and bounded backtracker):</p>
<pre tabindex="0"><code>$ regex-cli debug thompson '\w' -q
[.. snip ..]
            memory:  17668
[.. snip ..]
</code></pre><p>So here, the NFA uses 17KB. That’s not exactly small, but watch what happens
when we determinize the NFA into a DFA:</p>
<pre tabindex="0"><code>$ regex-cli debug dense dfa '\w' --start-kind unanchored -q
[.. snip ..]
          memory:  159296
[.. snip ..]
</code></pre><p>Memory balloons to about 160KB! (I’ve limited the DFA to just an unanchored
DFA. If one used <code>--start-kind both</code> instead, the default, then memory usage
would double.) And spending extra time to minimize the DFA doesn’t help:</p>
<pre tabindex="0"><code>$ regex-cli debug dense dfa '\w' --start-kind unanchored --minimize -q
[.. snip ..]
          memory:  159296
[.. snip ..]
</code></pre><p>Sometimes minimization helps, but in this case, since we used <a href="https://blog.burntsushi.net/transducers/#references">Daciuk’s
algorithm</a> to build a minimal UTF-8 automaton into the NFA for <code>\w</code>, it follows
that determinizing that NFA into a DFA itself already results in a minimal DFA.
The real problem here is a result of our dense representation and the fact that
our alphabet is defined over bytes. We can make it a little better by switching
to a sparse representation:</p>
<pre tabindex="0"><code>$ regex-cli debug sparse dfa '\w' --start-kind unanchored -q
[.. snip ..]
          memory:  102257
[.. snip ..]
</code></pre><p>But we’re still at over 100KB. Unicode character classes and fully compiled
DFAs just don’t mix well. And in practice, it’s often the case that one doesn’t
need the full class compiled since it’s somewhat rare to search haystacks with
a lot of difference scripts. More to the point, most searches are probably fine
with just the ASCII definition of <code>\w</code>, which is much smaller:</p>
<pre tabindex="0"><code>$ regex-cli debug thompson '(?-u)\w' -q
[.. snip ..]
            memory:  732
[.. snip ..]

$ regex-cli debug dense dfa '(?-u)\w' --start-kind unanchored -q
[.. snip ..]
          memory:  384
[.. snip ..]
</code></pre><p>In this case, the dense DFA is actually smaller than the corresponding NFA.</p>
<p>So with all of that said, why does a general purpose regex engine like
the <code>regex</code> crate have a DFA engine with such huge downsides? Doesn’t the
exorbitant memory usage make it a non-starter? There are two angles to this.</p>
<p>First is that the DFA engine is actually disabled by default. One must opt
into it by enabling the <code>perf-dfa-full</code> feature. I did this because fully
compiled DFAs don’t carry a ton of weight in the <code>regex</code> crate, since the lazy
DFA (discussed in the next section) is a better choice in the vast majority of
cases. However, fully compiled DFAs do provide some optimization opportunities
that are difficult for a lazy DFA to take advantage of. For example, in
the regex <code>(?m)^.*$</code>, a fully compiled DFA will notice that <code>.</code> doesn’t
match a <code>\n</code>. It knows this by looking for states where most transitions are
self-transitions (transitions that loop back to the same state). It follows
that there are only a limited number of ways to leave that state. The DFA finds
these states and “accelerates” them by running <code>memchr</code> to find the bytes
in the haystack corresponding to non-self-transitions. You can see this in
practice with <code>regex-cli</code> with a little ad hoc benchmarking. First we’ll start
with DFA state acceleration enabled (it’s enabled by default):</p>
<pre tabindex="0"><code>$ regex-cli find match dense -bB -q --repeat 1000000 \
   -p '(?m-u)^.*$' \
   -y 'this is a long line about the quick brown fox that jumped over the lazy dog'
[.. snip ..]
                 search time:  56.600473ms
[.. snip ..]
</code></pre><p>And now with DFA state acceleration disabled:</p>
<pre tabindex="0"><code>$ regex-cli find match dense -bB -q --repeat 1000000 --no-accelerate \
   -p '(?m-u)^.*$' \
   -y 'this is a long line about the quick brown fox that jumped over the lazy dog'
[.. snip ..]
                 search time:  199.044059ms
[.. snip ..]
</code></pre><p>The search time with acceleration enabled is quite a bit faster. Notice
also that we’ve disabled Unicode. When Unicode is enabled, <code>.</code> matches the
UTF-8 encoding of any Unicode scalar value. This in turn makes the DFA more
complicated and inhibits the acceleration optimization in this case:</p>
<pre tabindex="0"><code>$ regex-cli find match dense -q --repeat 1000000 \
   -p '(?m)^.*$' \
   -y 'this is a long line about the quick brown fox that jumped over the lazy dog'
[.. snip ..]
                 search time:  204.897593ms
[.. snip ..]
</code></pre><p>While this form of DFA state acceleration is quite useful, it is somewhat
limited in the regexes it can be applied to in part because of Unicode. It is
also limited because the meta regex engine only chooses to use the DFA engine
when the regex is very small. Otherwise we open ourselves up to exorbitant
memory usage and exponentials while building a regex. The <code>regex</code> crate isn’t
the fastest at compiling a regex, but taking exponential time is a big no-no.</p>
<p>Because of its somewhat limited utility and since the DFA engine adds a lot of
code that in turn increases compile times and binary size substantially, full
DFAs are disabled by default.</p>
<p>The second angle as to why full DFAs exist at all is because their search
runtime is extremely basic. They are the only regex engine in <code>regex-automata</code>
to not require any mutable <code>Cache</code> space while executing a search. Indeed,
let’s take a look at an example:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>
</span></span></span><span><span><span>    </span><span>dfa</span>::<span>{</span><span>dense</span><span>,</span><span> </span><span>regex</span>::<span>Regex</span><span>},</span><span>
</span></span></span><span><span><span>    </span><span>Match</span><span>,</span><span>
</span></span></span><span><span><span></span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>Regex</span>::<span>builder</span><span>()</span><span>
</span></span></span><span><span><span>        </span><span>// We need to enable heuristic Unicode word boundary support,
</span></span></span><span><span><span></span><span>        </span><span>// or else the regex below will fail to compile. Why? Because
</span></span></span><span><span><span></span><span>        </span><span>// \b is Unicode-aware by default, and the DFA engines don't
</span></span></span><span><span><span></span><span>        </span><span>// support it on haystacks with non-ASCII Unicode codepoints.
</span></span></span><span><span><span></span><span>        </span><span>// Enabling this comes with the downside of making it possible
</span></span></span><span><span><span></span><span>        </span><span>// for a search to return an error. Namely, when the DFA sees
</span></span></span><span><span><span></span><span>        </span><span>// a non-ASCII byte, it transitions to a special sentinel quit
</span></span></span><span><span><span></span><span>        </span><span>// state, which in turn causes the search to stop and return an
</span></span></span><span><span><span></span><span>        </span><span>// error.
</span></span></span><span><span><span></span><span>        </span><span>.</span><span>dense</span><span>(</span><span>dense</span>::<span>Config</span>::<span>new</span><span>().</span><span>unicode_word_boundary</span><span>(</span><span>true</span><span>))</span><span>
</span></span></span><span><span><span>        </span><span>.</span><span>build</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>)</span><span>
</span></span></span><span><span><span>        </span><span>.</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Note that `find_iter` will panic if the underyling search returns
</span></span></span><span><span><span></span><span>    </span><span>// an error! You can handle the error by using fallible APIs such as
</span></span></span><span><span><span></span><span>    </span><span>// Regex::try_search.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>it</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find_iter</span><span>(</span><span>"Sherlock Holmes"</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>8</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>9</span><span>..</span><span>15</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>None</span><span>,</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find match dense --no-table --unicode-word-boundary \
   -p '\b\w+\b' \
   -y 'Sherlock Holmes'
0:0:8:Sherlock
0:9:15:Holmes
</code></pre><p>Notice that no <code>Cache</code> is required. Indeed, because of how simple the search
runtime is for a DFA, and because the DFA internals were designed with this use
case in mind, a DFA can be <a href="https://github.com/rust-lang/regex/tree/ag/regex-automata/regex-cli#example-serialize-a-dfa">serialized to raw bytes</a>. That
same DFA can be deserialized and used to execute a search in a free-standing
environment. That is, you don’t need Rust’s <code>std</code> or <code>alloc</code> libraries. Only
<code>core</code> is needed.</p>
<p>(The DFA serialization use case was what motivated the initial <code>regex-automata 0.1</code> release. It’s currently used in the <a href="https://github.com/BurntSushi/bstr"><code>bstr</code></a> crate for implementing some
of the Unicode segmentation algorithms.)</p>
<p>Fully compiled DFAs are most useful when your regexes don’t make use of Unicode
features, or if you need access to lower level APIs. For example, this shows
how one can compute the transitions manually on a DFA:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>
</span></span></span><span><span><span>    </span><span>dfa</span>::<span>{</span><span>dense</span>::<span>DFA</span><span>,</span><span> </span><span>Automaton</span><span>},</span><span>
</span></span></span><span><span><span>    </span><span>Anchored</span><span>,</span><span>
</span></span></span><span><span><span></span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>DFA</span>::<span>new</span><span>(</span><span>r</span><span>"\W"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// DFAs can have multiple start states, but only when there are look-around
</span></span></span><span><span><span></span><span>    </span><span>// assertions. When there aren't any look-around assertions, as in this
</span></span></span><span><span><span></span><span>    </span><span>// case, we can ask for a start state without providing any of the
</span></span></span><span><span><span></span><span>    </span><span>// haystack.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>universal_start_state</span><span>(</span><span>Anchored</span>::<span>No</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>// The UTF-8 encoding of 💩 is \xF0\x9F\x92\xA9.
</span></span></span><span><span><span></span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>sid</span><span>,</span><span> </span><span>0xF0</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>sid</span><span>,</span><span> </span><span>0x9F</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>sid</span><span>,</span><span> </span><span>0x92</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>sid</span><span>,</span><span> </span><span>0xA9</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_eoi_state</span><span>(</span><span>sid</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>assert!</span><span>(</span><span>re</span><span>.</span><span>is_match_state</span><span>(</span><span>sid</span><span>));</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>In this example, we walked the DFA manually and fed the DFA one byte at a time.
This example is a little contrived, but it demonstrates some of the APIs that
provide low level control. There are many more examples documented on the
<a href="https://docs.rs/regex-automata/0.3.*/regex_automata/dfa/trait.Automaton.html"><code>Automaton</code></a> trait, which defines all of the lower level DFA routines that
dense and sparse DFAs implement.</p>
<h3 id="engine-hybrid-nfadfa">Engine: hybrid NFA/DFA</h3>
<p>The hybrid NFA/DFA or <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/hybrid/regex/struct.Regex.html">“lazy DFA” regex engine</a> is
exactly like the DFA engine, except its transition table is built at search
time. In other words, while a full DFA is “ahead-of-time compiled,” the lazy
DFA is “just-in-time compiled.”</p>
<p>(Calling it a JIT would be somewhat misleading. In this domain, a JIT usually
refers to compiling a regex into machine code at runtime, such as the JIT in
PCRE2. That is not what’s happening here.)</p>
<p>The lazy DFA generally has the same API as the fully compiled DFA, except that,
like the other regex engines, you need to pass a mutable <code>Cache</code> argument. The
<code>Cache</code> is where the transition table (among other things) is stored:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>
</span></span></span><span><span><span>    </span><span>hybrid</span>::<span>{</span><span>dfa</span><span>,</span><span> </span><span>regex</span>::<span>Regex</span><span>},</span><span>
</span></span></span><span><span><span>    </span><span>Match</span><span>,</span><span>
</span></span></span><span><span><span></span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>Regex</span>::<span>builder</span><span>()</span><span>
</span></span></span><span><span><span>        </span><span>// As with the fully compiled DFA, we need to enable heuristic
</span></span></span><span><span><span></span><span>        </span><span>// Unicode word boundary support for the lazy DFA as well. It
</span></span></span><span><span><span></span><span>        </span><span>// will return an error if a non-ASCII codepoint is seen when
</span></span></span><span><span><span></span><span>        </span><span>// the regex contains a Unicode word boundary, just like the
</span></span></span><span><span><span></span><span>        </span><span>// full DFA.
</span></span></span><span><span><span></span><span>        </span><span>.</span><span>dfa</span><span>(</span><span>dfa</span>::<span>Config</span>::<span>new</span><span>().</span><span>unicode_word_boundary</span><span>(</span><span>true</span><span>))</span><span>
</span></span></span><span><span><span>        </span><span>.</span><span>build</span><span>(</span><span>r</span><span>"\b\w+\b"</span><span>)</span><span>
</span></span></span><span><span><span>        </span><span>.</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Note that find_iter will panic if the underyling search returns
</span></span></span><span><span><span></span><span>    </span><span>// an error! You can handle the error by using fallible APIs such
</span></span></span><span><span><span></span><span>    </span><span>// as Regex::try_search.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>it</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>find_iter</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>"Sherlock Holmes"</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>0</span><span>..</span><span>8</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>Some</span><span>(</span><span>Match</span>::<span>must</span><span>(</span><span>0</span><span>,</span><span> </span><span>9</span><span>..</span><span>15</span><span>)),</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>assert_eq!</span><span>(</span><span>None</span><span>,</span><span> </span><span>it</span><span>.</span><span>next</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>And the equivalent <code>regex-cli</code> command:</p>
<pre tabindex="0"><code>$ regex-cli find match hybrid --no-table --unicode-word-boundary \
   -p '\b\w+\b' \
   -y 'Sherlock Holmes'
0:0:8:Sherlock
0:9:15:Holmes
</code></pre><p>This example is nearly identical to the full DFA, but with a <code>Cache</code> parameter.
The similarities extend to lower level APIs as well:</p>
<div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>regex_automata</span>::<span>{</span><span>hybrid</span>::<span>dfa</span>::<span>DFA</span><span>,</span><span> </span><span>Input</span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>re</span><span> </span><span>=</span><span> </span><span>DFA</span>::<span>new</span><span>(</span><span>r</span><span>"\W"</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>cache</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>create_cache</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// DFAs can have multiple start states, but only when there are
</span></span></span><span><span><span></span><span>    </span><span>// look-around assertions. When there aren't any look-around
</span></span></span><span><span><span></span><span>    </span><span>// assertions, as in this case, we can ask for a start state
</span></span></span><span><span><span></span><span>    </span><span>// without providing any of the haystack. Full DFAs have a
</span></span></span><span><span><span></span><span>    </span><span>// dedicated routine for this because the universality can be
</span></span></span><span><span><span></span><span>    </span><span>// checked for us. But lazy DFAs don't compute all of their start
</span></span></span><span><span><span></span><span>    </span><span>// states up front. So we just kind of fake it and ask for a start
</span></span></span><span><span><span></span><span>    </span><span>// state given some dummy haystack.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>start_state_forward</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>&amp;</span><span>Input</span>::<span>new</span><span>(</span><span>""</span><span>)).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>// The UTF-8 encoding of 💩 is \xF0\x9F\x92\xA9.
</span></span></span><span><span><span></span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>sid</span><span>,</span><span> </span><span>0xF0</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>sid</span><span>,</span><span> </span><span>0x9F</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>sid</span><span>,</span><span> </span><span>0x92</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_state</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>sid</span><span>,</span><span> </span><span>0xA9</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>sid</span><span> </span><span>=</span><span> </span><span>re</span><span>.</span><span>next_eoi_state</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cache</span><span>,</span><span> </span><span>sid</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>assert!</span><span>(</span><span>sid</span><span>.</span><span>is_match</span><span>());</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Other than passing a <code>Cache</code> explicitly, these APIs are almost the same. The
main difference is that each of the operations might fail. Namely, depending on
the method, they can return either a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/struct.MatchError.html"><code>MatchError</code></a> or a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/hybrid/struct.CacheError.html"><code>CacheError</code></a>. A
<code>MatchError</code> occurs when the start state can’t be computed because it enters
a quit state. (Which means the search must terminate with an error. This, for
example, occurs when heuristic Unicode word boundary support is enabled and a
non-ASCII byte is seen when computing the start state.) A <code>CacheError</code> occurs
when the <code>Cache</code> provided exhausts its capacity.</p>
<p>At this point, it’s worth talking a little more about the <code>Cache</code> because it is
both the lazy DFA’s greatest strength and its greatest weakness. The lazy DFA,
as mentioned, works by building its transition table during a search. More
specifically, the following happens:</p>
<ol>
<li>A maximum cache capacity is configured at construction time. The capacity is
not fully allocated up front. It’s just a number establishing an upper bound on
how much heap memory can be used.</li>
<li>When the caller asks to compute the transition for the current state and
character from the haystack, the lazy DFA consults its <code>Cache</code>. If the transition
has already been computed and stored in the <code>Cache</code>, then it is returned as-is
immediately. Otherwise, the transition—and only that transition—is computed
by doing NFA powerset construction. This process takes worst case <code>O(m)</code> time.</li>
<li>If the cache fills up, it is cleared and thus transitions previously computed
will need to be-recomputed.</li>
<li>Optional configuration can be set to cause the lazy DFA to return an error
if the <code>Cache</code> is being used inefficiently. Efficiency is measured in terms
of how many bytes are searched per each DFA state computed. If few bytes are
searched compared to the number of DFA states in the <code>Cache</code>, then it’s likely
that even the <code>PikeVM</code> would execute the search more quickly. (Other heuristics
are used here as well, such as the total number of times the <code>Cache</code> has been
cleared.)</li>
</ol>
<p>In this way, at most one DFA state and transition is created for each byte of
haystack searched. Thus, the worst case search time for the lazy DFA is
<code>O(m * n)</code> and its worst case space usage is the fixed capacity set at
construction time. Since building a lazy DFA itself does not require the
construction of any DFA states (except for a few basic sentinel states), it
follows that the lazy DFA mitigates the theoretical worst case time and space
complexities for full DFAs. That is, we avoid the exponential construction
time. In the common case, most states/transitions are cached, and so the lazy
DFA runs in average case <code>O(n)</code> time. In practice, for most regexes, the lazy
DFA and the fully compiled DFA have the same search performance.</p>
<p>The lazy DFA also mitigates the exorbitant space usage for large Unicode
character classes. Since a lazy DFA only computes what it needs based on the
actual bytes searched, searching for a Unicode-aware <code>\w</code> in an ASCII-only
haystack only requires building the ASCII portion of <code>\w</code> into a DFA. This ends
up working amazingly well in practice.</p>
<p>The lazy DFA tends to do poorly for regexes that fill up its cache and cause
it to be cleared repeatedly. This might just be a result of the regex being
large or even a result of the haystack forcing a large portion of the DFA to
be constructed. (A regex can easily become large through counted repetitions
or even by adding a lot of patterns. A single lazy DFA gets built for a
multi-pattern regex.) In these cases, heuristics usually detect it and force
the lazy DFA to return an error. At this point, in the context of the meta
regex engine, the search will be retried with a different engine (usually the
<code>PikeVM</code>).</p>
<h3 id="the-meta-regex-engine">The meta regex engine</h3>
<p>The <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/meta/struct.Regex.html">meta regex engine</a> brings all of the aforementioned regex engines together
and exposes one single infallible API that tries to do the best possible thing
in any given situation. The API it exposes also absolves the caller of needing
to explicitly create and pass <code>Cache</code> values to each search call. Instead, the
meta regex engine handles this for you by keeping an internal thread safe pool
of <code>Cache</code> values. (The meta regex engine does expose lower level APIs that
permit passing a <code>Cache</code> explicitly. These are useful if one wants to avoid
the synchronization costs of the thread safe pool used internally.)</p>
<p>The end result here is that the meta regex engine very closely corresponds
to the top-level API in the <code>regex</code> crate. Indeed, <code>regex::Regex</code>,
<code>regex::RegexSet</code>, <code>regex::bytes::Regex</code> and <code>regex::bytes::RegexSet</code> are all
very thin wrappers around the meta regex engine. This is by design, because it
makes it easier to drop down from the high level convenience API that serves
99% of use cases to the lower level API that exposes a lot more knobs.</p>
<p>Internally, the meta regex engine implements roughly the following logic:</p>
<ul>
<li>If a regex engine isn’t needed at all and the search can be performed using
single or multi-substring search algorithms directly, then the construction of
a regex (including an <code>NFA</code>) is avoided entirely.</li>
<li>If possible, extract a small literal sequence from the prefix of the regex
that can be used as a <a href="https://docs.rs/regex-automata/0.3.*/regex_automata/util/prefilter/struct.Prefilter.html"><code>Prefilter</code></a>.</li>
<li>If possible, choose a “reverse” optimization:
<ul>
<li>If a regex is anchored at the end via <code>$</code>, then a search can proceed by
doing a reverse scan from the end of the haystack. This is called the
“reverse anchored” optimization.</li>
<li>If no suitable <code>Prefilter</code> has been found and a literal sequence can be
extracted from the suffix of the regex, then we can scan for occurrences of
that literal sequence and match the regex in reverse from each candidate
position. This is called the “reverse suffix” optimization.</li>
<li>If no suitable prefix or suffix literal sequence could be found but a
literal sequence could be extracted from an inner part of the regex that
cleanly partitions the regex, then we can scan for occurrences of that
inner literal sequence. We split the regex in half at the point where the
inner literal sequence was extracted. The first half gets compiled into a
reverse regex and the second half gets compiled into a forward regex. When
a candidate is found, we can look for the start of the match by scanning
backwards with the first half, and then look for the end of the match by
scanning forwards with the second half.</li>
</ul>
</li>
<li>Otherwise, fall back to the “core” search strategy. The core strategy makes
use of all available regex engines: the <code>PikeVM</code>, the bounded backtracker, the
one-pass DFA, the lazy DFA and the full DFA. Only the <code>PikeVM</code> is required. The
way these engines compose together is roughly as follows:
<ul>
<li>Whenever possible, use the lazy DFA (or full DFA if available) to find
the overall bounds of the match. If the DFA fails, then we fall back to
either the <code>PikeVM</code>, the bounded backtracker or the one-pass DFA. The DFA
can fail either because the regex contained a Unicode word boundary and the
haystack contained a non-ASCII codepoint, or because the the lazy DFA was
used and its <code>Cache</code> usage was inefficient according to some heuristic.</li>
<li>When capture groups are requested, then after the full match is found,
either the <code>PikeVM</code>, bounded backtracker or one-pass DFA is used to report
the offsets of each matching capture group. The order of preference is:
one-pass DFA, bounded backtracker and then the <code>PikeVM</code>.</li>
</ul>
</li>
</ul>
<p>If one were to summarize the overall strategy, it can probably be distilled
down to these two points:</p>
<ul>
<li>Search for literals whenever possible.</li>
<li>Avoid the <code>PikeVM</code> as much as possible.</li>
</ul>
<p>That’s pretty much it. In general, the more time we can spend in substring
search algorithms, the better. And the less time we can spend in specifically
the <code>PikeVM</code>, the better.</p>
<p>Many regex engines do some kind of literal optimization, and indeed, most
popular production grade regex engines spend a fair bit of effort in doing
so. <a href="https://github.com/intel/hyperscan">Hyperscan</a> is the gold standard here, but as far as I’m aware, most
other general purpose regex engines don’t go to the lengths described above.
(One could argue about whether Hyperscan is a “general purpose” regex engine
or not. One of my own personal arguments against considering it one is its
match semantics. For example, <code>\w+</code> matches <code>abc</code> 3 times because Hyperscan
reports matches as they’re seen. An undoubtedly correct choice given its
target domain.) The reverse suffix and reverse inner optimizations are
particularly tricky. They look easy, but there’s a subtle performance problem
with them: they open you up to worst case quadratic behavior (in the size of
the haystack).</p>
<p>Consider the regex <code>[A-Z].*bcdefghijklmnopq</code> on a haystack of
<code>bcdefghijklmnopq</code> repeated over and over. There is no “good” prefix literal
sequence that can be extracted from this, so according to the logic above,
the meta regex engine will try the “reverse suffix” optimization by using
<code>bcdefghijklmnopq</code> as the suffix. This particular benchmark was devised to have
a worst case false positive rate: candidates are reported frequently and none
of them lead to a match. But that’s just a bad heuristic. It doesn’t in and of
itself lead to violating our time complexitiy guarantee (which is <code>O(m * n)</code>).
The problem here is that each time the suffix matches, a reverse scan includes
the <code>.*</code>, and that in turn scans all the way back to the beginning of the
haystack. So each candidate reported by the suffix match results in a complete
re-scan of the haystack back to the beginning. This changes our search routine
to have worst case <code>O(m * n^2)</code> time complexity. That’s bad.</p>
<p>While it is possible to do syntactic analysis on a regex to determine whether
this quadratic behavior is possible, it doesn’t predict it perfectly. For
example, one can clearly see that the suffix <code>bcdefghijklmnopq</code> overlaps with
the expression immediately before it, <code>.*</code>. That in turn means some kind of
quadratic behavior might be possible. But that doesn’t mean it is inevitable.</p>
<p>Instead, the meta regex engine mitigates this by defining its own bespoke regex
search routines based on the DFA engines. Namely, it defines its own search
routine that will stop its reverse scan if it gets to a certain offset in the
haystack. That offset corresponds to the end of the last suffix match. So if
the search would otherwise exceed that offset, then we’re exposed to quadratic
behavior. The meta regex engine detects this error case and falls back to the
“core” strategy described above, thus abandoning the optimization when it would
otherwise sacrifice our time complexity guarantees.</p>
<p>Roughly the same logic applies to the “reverse inner” optimization as well.</p>
<p>In summary, if you don’t need low level access to individual regex engines but
you do want control over the many knobs exposed by the regex engine or want
to do multi-pattern matching, then the meta regex engine is a good choice.
Namely, all of the regex engines described before this each have their own
little caveats that make them less than ideal for general use in every case.</p>
<h2 id="differences-with-re2">Differences with RE2</h2>
<p>If you’ve read <a href="https://swtch.com/~rsc/regexp/">Russ Cox’s article series on regular expressions</a>,
then some portion of the previous section is likely to sound familiar.
Namely, RE2 has a <a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/nfa.cc">PikeVM</a> (called just an “NFA”), a <a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/bitstate.cc">bounded
backtracker</a> (called a “bitstate backtracker” in RE2), a
<a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/onepass.cc">one-pass DFA</a> (called a “one-pass NFA” in RE2) and a <a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/dfa.cc">lazy
DFA</a>. It also has a <a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/re2.cc#L648-L906">meta regex engine</a> (although that term
isn’t used) that composes its internal regex engines in a similar fashion as
described above. The only engine described above that RE2 doesn’t have is a
fully compiled DFA.</p>
<p>So what, if any, are the differences between RE2 and the <code>regex</code> crate?</p>
<p>The similarities between them are much greater than the differences, but here’s
a high level list of differences:</p>
<ul>
<li>RE2 supports leftmost-longest semantics as an option in addition to
leftmost-first. Leftmost-longest semantics are what POSIX regex engines use.</li>
<li>RE2 has less support for Unicode. A full accounting of this is tricky
because RE2 does permit linking with <a href="https://icu.unicode.org/">ICU</a> to add support for more Unicode
properties. However, RE2 does not have an option to make <code>\w</code>, <code>\s</code>, <code>\d</code> and
<code>\b</code> use Unicode definitions. RE2 also does not support character class set
operations beyond union. For example, it’s harder to write something like
<code>[\pL&amp;&amp;\p{Greek}]</code> in RE2, which corresponds to the subset of codepoints
considered letters that are also in the Greek script. (Character class set
operations other than union aren’t strictly Unicode specific features, but they
are most useful in the context of large Unicode character classes.)</li>
<li>RE2 has a likely more memory efficient version of the PikeVM.</li>
<li>RE2 has some limited support for literal optimizations, but overall does
a lot less here than what the <code>regex</code> crate does. RE2 does have a <a href="https://github.com/google/re2/blob/2d39b703d02645076fead8fa409a1711f0e84381/re2/filtered_re2.h">Filtered
RE2</a> which permits the caller to do a limited form of their own literal
optimizations.</li>
<li>RE2 uses the same transition cache across multiple threads for the lazy DFA
engine, which requires synchronization. Conversely, the <code>regex</code> crate requires
a distinct cache for each thread, which requires more memory.</li>
<li>The <code>regex</code> crate now exposes both <code>regex-syntax</code> and <code>regex-automata</code> as
separately versioned libraries that provide access to its internals. RE2 does
not support this.</li>
<li>The <code>regex-automata</code> library has first class support for multi-pattern
regexes in all engines. RE2 does have a “regex set,” but it only reports which
patterns match in a haystack. <code>regex-automata</code>, on the other hand, can also
report match and capture group offsets for each matching pattern.</li>
</ul>
<p>In the future, I hope to add more engines to <code>regex-automata</code>. Specifically,
I’d like to explore <a href="https://en.wikipedia.org/wiki/Glushkov%27s_construction_algorithm">Glushkov NFAs</a> and a bit parallel regex
engine. I’d also like to explore <a href="https://gist.github.com/pervognsen/218ea17743e1442e59bb60d29b1aa725">shift DFAs</a>.</p>
<h2 id="testing-strategy">Testing strategy</h2>
<p>As described near the opening of this blog, testing had become a problem for
the <code>regex</code> crate. The macro hacks used to test each internal engine were
growing quite strained and they were generally difficult to work with and, more
importantly, understand.</p>
<p>My idea for revamping how the regex crate was tested was tied with the idea
that each internal engine would have its own first class API that could be
tested independently from the “main” regex engine. I also wanted to make the
tests consumable from any context instead of burying them in macros or Rust
source code. To that end, this is the strategy I settled upon:</p>
<ul>
<li>All regex tests are specified in TOML files.</li>
<li>I published a crate, <a href="https://docs.rs/regex-test/0.1.*/regex_test/"><code>regex-test</code></a>, that knows how to read these TOML files
into a structured representation.</li>
<li>I defined a single Rust unit test for each configuration of each regex engine
that I wanted to test. Inside this single unit test, all of the tests from
the TOML files that are applicable to the engine being tested are executed.</li>
</ul>
<p>A little extra infrastructure was required in order to make this nice to use
because Rust’s unit testing framework is not currently extensible. That means
I had to define my own environment variables for filtering on which tests to
run. (For example, if you’re working on a single bug that causes many tests to
fail, it’s often useful to just have one of those tests run.)</p>
<p>There are also oodles of other kinds of tests as well. For example, there are
over 450 documentation tests in <code>regex-automata</code> alone.</p>
<p>Finally, in the run up to the <code>regex 1.9</code>, I added a lot of additional fuzz
testing targets. I had a <strong>ton</strong> of help from <a href="https://github.com/addisoncrump">Addison Crump</a> and there were
at least a few bugs I wouldn’t have found if it weren’t for him.</p>
<h2 id="benchmarking">Benchmarking</h2>
<p>At this point, this blog is already my longest one ever, and I haven’t even
begun to discuss benchmarking. While I originally wanted to spend more time
on this topic in this blog—particularly given all of the talk about
optimizations—it just wasn’t practical to do so.</p>
<p>Instead, I’ve published a regex barometer called <a href="https://github.com/BurntSushi/rebar">rebar</a>. It isn’t just limited
to benchmarking the <code>regex</code> crate. It also benchmarks many other regex engines
as well. I believe it is the most comprehensive regex benchmark published to
date.</p>
<p>Across 242 benchmarks, <code>regex 1.9</code> is on average 1.5 times faster than <code>regex 1.7.3</code> for search times. (I compared with <code>1.7</code> instead of <code>1.8</code> because <code>1.8</code>
reflects a transition release that has some of the work described in this blog
post included. The <code>1.9</code> release just completes the transition.)</p>
<pre tabindex="0"><code>$ rebar rank record/all/2023-07-02/*.csv \
   --intersection \
   -M compile \
   -e '^(rust/regex|rust/regexold)$'
Engine         Version  Geometric mean of speed ratios  Benchmark count
------         -------  ------------------------------  ---------------
rust/regex     1.8.4    1.08                            242
rust/regexold  1.7.3    2.61                            242
</code></pre><p>But the time it takes to build a regex has regressed somewhat:</p>
<pre tabindex="0"><code>$ rebar rank record/all/2023-07-02/*.csv \
   --intersection \
   -m compile \
   -e '^(rust/regex|rust/regexold)$'
Engine         Version  Geometric mean of speed ratios  Benchmark count
------         -------  ------------------------------  ---------------
rust/regexold  1.7.3    1.07                            28
rust/regex     1.8.4    1.46                            28
</code></pre><p>The geometric mean reported above is a very crude aggregate statistic. I’m not
sure it really captures the extent of the improvements here. If you want to look
at individual benchmark differences, one can replace <code>rebar rank</code> with <code>rebar cmp</code>
in the above command. (And run it from the root of a checkout of the <a href="https://github.com/BurntSushi/rebar">rebar</a>
repository.)</p>
<pre tabindex="0"><code>$ rebar cmp record/all/2023-07-02/*.csv \
   --threshold-min 2 \
   --intersection \
   -M compile \
   -e '^(rust/regex|rust/regexold)$'
</code></pre><p>I’ve added <code>--threshold-min 2</code> to the above command to limit the comparisons
to ones where there is at least a 2x difference.</p>
<h2 id="costs">Costs</h2>
<p>No good deed goes unpunished. What has this rewrite cost me?</p>
<p>First and foremost, it has used up the vast majority of my free time for the
past several years. Compounding the problem, I have <a href="https://github.com/BurntSushi/blog/commit/8ea55788f2eb8226343fdbefaaee189412bd3c1c">a lot less of that free
time than I used to</a>. So projects like ripgrep haven’t seen a release
for quite some time.</p>
<p>Secondly, this has introduced a fair bit more code. Building reusable abstractions
for others to use is a different beast than internal abstractions that only
<code>regex</code> crate hackers need to worry about. It usually results in more code,
which means bigger binary sizes and higher compile times.</p>
<p>Thirdly, those abstractions are now published and separately versioned. That
means I can’t just break the APIs of those internal engines without publishing
an appropriate breaking change release of <code>regex-automata</code>. I won’t be nearly
as conservative as doing so as I am with the <code>regex</code> crate, but it isn’t free
to do. This will also impact contributors. Instead of just being able to
refactor code as necessary, one must now contend with the pressures of public
API design.</p>
<p>Because the <code>regex</code> crate already had a reputation for less-than-ideal binary
sizes and compile times, and since these changes were going to make that
<em>worse</em>, I decided on two different mitigations:</p>
<ol>
<li>As discussed above, I made the fully compiled DFA regex engine opt-in. This
engine brings in quite a bit of code, but its impact on search performance is
modest.</li>
<li>I published a new crate, <a href="https://docs.rs/regex-lite"><code>regex-lite</code></a>, that acts <em>nearly</em> as a drop-in
replacement for the <code>regex</code> crate. Its design is based on optimizing almost
exclusively for binary size and compile time, at the expense of functionality
(namely, Unicode) and performance. You still get the <code>O(m * n)</code> time complexity
guarantee, but you don’t get any of the fancy Unicode support and you don’t get
fast search times. But the binary size and compile times are a lot better.
<code>regex-lite</code> has zero dependencies. It shares zero code—including rolling its
own regex parser—with the <code>regex</code> crate.</li>
</ol>
<p>The <code>regex-lite</code> mitigation is still somewhat of an experiment, but it just
goes to show that making code artbitrarily reducible is difficult. Even though
the <code>regex</code> crate has a bunch of features for disabling both optimizations and
Unicode functionality, it still can’t get anywhere close to the binary size
and compile times of <code>regex-lite</code>.</p>
<h2 id="wrap-up">Wrap up</h2>
<p>In this blog, I tried to focus on telling a story about the biggest components
of the <code>regex</code> crate internals. This higher level description can be difficult
to get from just reading the API documentation. With that said, this blog is
still just scratch the surface. I encourage you to peruse the <a href="https://docs.rs/regex-automata/0.3.*/"><code>regex-automata</code>
API documentation</a> for a lot more details and tons of code examples.</p>
<p>I encourage any and all questions on <a href="https://github.com/rust-lang/regex/discussions">GitHub Discussions</a>.</p>
      </article>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[News is bad for you – and giving up reading it will make you happier (2013) (216 pts)]]></title>
            <link>https://www.theguardian.com/media/2013/apr/12/news-is-bad-rolf-dobelli</link>
            <guid>36600020</guid>
            <pubDate>Wed, 05 Jul 2023 13:16:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/media/2013/apr/12/news-is-bad-rolf-dobelli">https://www.theguardian.com/media/2013/apr/12/news-is-bad-rolf-dobelli</a>, See on <a href="https://news.ycombinator.com/item?id=36600020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span><span>I</span></span>n the past few decades, the fortunate among us have recognised the hazards of living with an overabundance of food (obesity, diabetes) and have started to change our diets. But most of us do not yet understand that news is to the mind what sugar is to the body. News is easy to digest. The media feeds us small bites of&nbsp;trivial matter, tidbits that don't really concern our lives and don't require thinking. That's why we experience almost no saturation. Unlike reading books and long magazine articles (which require thinking), we can swallow limitless quantities of news flashes, which are bright-coloured candies for the mind. Today, we have reached the same point in relation to information that we faced 20 years ago in regard to food. We are beginning to recognise how&nbsp;toxic news can be.</p><p><strong>News misleads.</strong> Take the following event (borrowed from Nassim Taleb). A&nbsp;car drives over a bridge, and the bridge collapses. What does the news media focus on? The car. The person in the car. Where he came from. Where he planned to go. How he experienced the crash (if he survived). But that is all irrelevant. What's relevant? The structural stability of the bridge. That's the underlying risk that has been lurking, and could lurk in other bridges. But the car is flashy, it's dramatic, it's a&nbsp;person (non-abstract), and it's news that's cheap to produce. News leads us to walk around with the completely wrong risk map in our heads. So terrorism is over-rated. Chronic stress is under-rated. The collapse of Lehman Brothers is overrated. Fiscal irresponsibility is under-rated. Astronauts are over-rated. Nurses are under-rated.</p><p>We are not rational enough to be exposed to the press. Watching an airplane crash on television is going to&nbsp;change your attitude toward that risk,&nbsp;regardless of its real probability. If&nbsp;you think you can compensate with&nbsp;the strength of your own inner contemplation, you are wrong. Bankers and economists – who have powerful incentives to compensate for news-borne hazards – have shown that they cannot. The only solution: cut yourself off from news consumption entirely.</p><p><strong>News is irrelevant.</strong> Out of the approximately 10,000 news stories you have read in the last 12 months, name one that – because you consumed it – allowed you to make a better decision about a serious matter affecting your life, your career or your business. The point is: the consumption of news is irrelevant to you. But people find it very difficult to recognise what's relevant. It's&nbsp;much easier to recognise what's new. The relevant versus the new is the fundamental battle of the current age. Media organisations want you to believe that news offers you some sort of a competitive advantage. Many fall for that. We get anxious when we're cut off from the flow of news. In reality, news consumption is a competitive disadvantage. The less news you consume, the bigger the advantage you have.</p><p><strong>News has no explanatory power.</strong> News items are bubbles popping on the&nbsp;surface of a deeper world. Will accumulating facts help you understand the world? Sadly, no. The relationship is inverted. The important stories are non-stories: slow, powerful movements that develop below journalists' radar but have a transforming effect. The more "news factoids" you digest, the less of the big picture you will understand. If&nbsp;more information leads to higher economic success, we'd expect journalists to be at the top of the pyramid. That's not the case.</p><p><strong>News is toxic to your body. </strong>It constantly triggers the <a href="https://www.theguardian.com/science/neurophilosophy/2012/may/16/neuroscience-psychology">limbic system</a>. Panicky stories spur the release of cascades of glucocorticoid (cortisol). This deregulates your immune system and inhibits the release of growth hormones. In other words, your body finds itself in a state of chronic stress. High glucocorticoid levels cause impaired digestion, lack of growth (cell,&nbsp;hair, bone), nervousness and susceptibility to infections. The other&nbsp;potential side-effects include fear,&nbsp;aggression, tunnel-vision and&nbsp;desensitisation.</p><p><strong>News increases cognitive errors.</strong> News feeds the mother of all cognitive errors: confirmation bias. In the words of Warren Buffett: "What the human being is best at doing is interpreting all new information so that their prior conclusions remain intact." News exacerbates this flaw. We become prone to overconfidence, take stupid risks and misjudge opportunities. It also exacerbates another cognitive error: the story bias. Our brains crave stories that "make sense" – even if they don't correspond to reality. Any journalist who writes, "The market moved because of X" or "the company went bankrupt because of Y" is an idiot. I am fed up with this cheap way of "explaining" the world.</p><p><strong>News inhibits thinking.</strong> Thinking requires concentration. Concentration requires uninterrupted time. News pieces are specifically engineered to interrupt you. They are like viruses that steal attention for their own purposes. News makes us shallow thinkers. But it's worse than that. News severely affects memory. There are two types of memory. Long-range memory's capacity is nearly infinite, but working memory is limited to a certain amount of slippery data. The path from short-term to long-term memory is a choke-point in the brain, but anything you want to understand must pass through it. If this passageway is disrupted, nothing gets through. Because news disrupts concentration, it weakens comprehension. Online news has an even worse impact. <a href="http://www.wired.com/magazine/2010/05/ff_nicholas_carr/">In a 2001 study two scholars in Canada</a> showed that comprehension declines as the number of hyperlinks in a document increases. Why? Because whenever a link appears, your brain has to at least make the choice not to click, which in itself is distracting. News is an intentional interruption system.</p><p><strong>News works like a drug. </strong>As stories develop, we want to know how they continue. With hundreds of arbitrary storylines in our heads, this craving is increasingly compelling and hard to ignore. Scientists used to think that the dense connections formed among the 100 billion neurons inside our skulls were largely fixed by the time we reached adulthood. Today we know that this is not the case. Nerve cells routinely break old connections and form new ones. The more news we consume, the more we exercise the neural circuits devoted to skimming and multitasking while ignoring those used for reading deeply and thinking with profound focus. Most news consumers – even if they used to be avid book readers – have lost the ability to absorb lengthy articles or books. After four, five pages they get tired, their concentration vanishes, they become restless. It's not because they got older or their schedules became more onerous. It's because the physical structure of their brains has changed.</p><p><strong>News wastes time.</strong> If you read the newspaper for 15 minutes each morning, then check the news for 15 minutes during lunch and 15 minutes before you go to bed, then add five minutes here and there when you're at work, then count distraction and refocusing time, you will lose at least half a day every week. Information is no longer a scarce commodity. But attention is. You are not&nbsp;that irresponsible with your money, reputation or health. Why give away your mind?</p><p><strong>News makes us passive.</strong> News stories are overwhelmingly about things you cannot influence. The daily repetition of news about things we can't act upon makes us passive. It grinds us down until we adopt a worldview that is pessimistic, desensitised, sarcastic and fatalistic. The scientific term is "learned helplessness". It's a bit of a stretch, but I&nbsp;would not be surprised if news consumption, at least partially contributes to the widespread disease of depression.</p><p><strong>News kills creativity.</strong> Finally, things we already know limit our creativity. This is one reason that mathematicians, novelists, composers and entrepreneurs often produce their most creative works at a young age. Their brains enjoy a wide, uninhabited space that emboldens them to come up with and pursue novel ideas. I don't know a single truly creative mind who is a news junkie – not a writer, not a composer, mathematician, physician, scientist, musician, designer, architect or painter. On the other hand, I&nbsp;know a bunch of viciously uncreative minds who consume news like drugs. If you want to come up with old solutions, read news. If you are looking for new solutions, don't.</p><p>Society needs journalism – but in a&nbsp;different way. Investigative journalism is always relevant. We need reporting that polices our institutions and uncovers truth. But important findings don't have to arrive in the form of news. Long journal articles and in-depth books are good, too.</p><p>I have now gone without news for four years, so I can see, feel and report the effects of this freedom first-hand: less disruption, less anxiety, deeper thinking, more time, more insights. It's not easy, but it's worth it.</p><p><em>This is an edited extract from an essay first published at </em><a href="http://dobelli.com/"><em>dobelli.com</em></a><em>. The Art of Thinking Clearly: Better Thinking, Better Decisions by Rolf Dobelli is published by Sceptre, £9.99. Buy it for £7.99 at </em><a href="http://www.guardianbookshop.co.uk/BerteShopWeb/viewProduct.do?ISBN=9781444759549"><em>guardianbookshop.co.uk</em></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn how to design systems at scale and prepare for system design interviews (105 pts)]]></title>
            <link>https://github.com/karanpratapsingh/system-design</link>
            <guid>36599706</guid>
            <pubDate>Wed, 05 Jul 2023 12:51:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karanpratapsingh/system-design">https://github.com/karanpratapsingh/system-design</a>, See on <a href="https://news.ycombinator.com/item?id=36599706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">System Design Course</h2>
<p dir="auto">Hey, welcome to the course. I hope this course provides a great learning experience.</p>
<p dir="auto"><em>This course is also available on my <a href="https://karanpratapsingh.com/courses/system-design" rel="nofollow">website</a> and as an ebook on <a href="https://leanpub.com/systemdesign" rel="nofollow">leanpub</a>. Please leave a <g-emoji alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png">⭐</g-emoji> as motivation if this was helpful!</em></p>
<h2 tabindex="-1" dir="auto">Table of contents</h2>
<ul dir="auto">
<li>
<p dir="auto"><strong>Getting Started</strong></p>
<ul dir="auto">
<li><a href="#what-is-system-design">What is system design?</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Chapter I</strong></p>
<ul dir="auto">
<li><a href="#ip">IP</a></li>
<li><a href="#osi-model">OSI Model</a></li>
<li><a href="#tcp-and-udp">TCP and UDP</a></li>
<li><a href="#domain-name-system-dns">Domain Name System (DNS)</a></li>
<li><a href="#load-balancing">Load Balancing</a></li>
<li><a href="#clustering">Clustering</a></li>
<li><a href="#caching">Caching</a></li>
<li><a href="#content-delivery-network-cdn">Content Delivery Network (CDN)</a></li>
<li><a href="#proxy">Proxy</a></li>
<li><a href="#availability">Availability</a></li>
<li><a href="#scalability">Scalability</a></li>
<li><a href="#storage">Storage</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Chapter II</strong></p>
<ul dir="auto">
<li><a href="#databases-and-dbms">Databases and DBMS</a></li>
<li><a href="#sql-databases">SQL databases</a></li>
<li><a href="#nosql-databases">NoSQL databases</a></li>
<li><a href="#sql-vs-nosql-databases">SQL vs NoSQL databases</a></li>
<li><a href="#database-replication">Database Replication</a></li>
<li><a href="#indexes">Indexes</a></li>
<li><a href="#normalization-and-denormalization">Normalization and Denormalization</a></li>
<li><a href="#acid-and-base-consistency-models">ACID and BASE consistency models</a></li>
<li><a href="#cap-theorem">CAP theorem</a></li>
<li><a href="#pacelc-theorem">PACELC Theorem</a></li>
<li><a href="#transactions">Transactions</a></li>
<li><a href="#distributed-transactions">Distributed Transactions</a></li>
<li><a href="#sharding">Sharding</a></li>
<li><a href="#consistent-hashing">Consistent Hashing</a></li>
<li><a href="#database-federation">Database Federation</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Chapter III</strong></p>
<ul dir="auto">
<li><a href="#n-tier-architecture">N-tier architecture</a></li>
<li><a href="#message-brokers">Message Brokers</a></li>
<li><a href="#message-queues">Message Queues</a></li>
<li><a href="#publish-subscribe">Publish-Subscribe</a></li>
<li><a href="#enterprise-service-bus-esb">Enterprise Service Bus (ESB)</a></li>
<li><a href="#monoliths-and-microservices">Monoliths and Microservices</a></li>
<li><a href="#event-driven-architecture-eda">Event-Driven Architecture (EDA)</a></li>
<li><a href="#event-sourcing">Event Sourcing</a></li>
<li><a href="#command-and-query-responsibility-segregation-cqrs">Command and Query Responsibility Segregation (CQRS)</a></li>
<li><a href="#api-gateway">API Gateway</a></li>
<li><a href="#rest-graphql-grpc">REST, GraphQL, gRPC</a></li>
<li><a href="#long-polling-websockets-server-sent-events-sse">Long polling, WebSockets, Server-Sent Events (SSE)</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Chapter IV</strong></p>
<ul dir="auto">
<li><a href="#geohashing-and-quadtrees">Geohashing and Quadtrees</a></li>
<li><a href="#circuit-breaker">Circuit breaker</a></li>
<li><a href="#rate-limiting">Rate Limiting</a></li>
<li><a href="#service-discovery">Service Discovery</a></li>
<li><a href="#sla-slo-sli">SLA, SLO, SLI</a></li>
<li><a href="#disaster-recovery">Disaster recovery</a></li>
<li><a href="#virtual-machines-vms-and-containers">Virtual Machines (VMs) and Containers</a></li>
<li><a href="#oauth-20-and-openid-connect-oidc">OAuth 2.0 and OpenID Connect (OIDC)</a></li>
<li><a href="#single-sign-on-sso">Single Sign-On (SSO)</a></li>
<li><a href="#ssl-tls-mtls">SSL, TLS, mTLS</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Chapter V</strong></p>
<ul dir="auto">
<li><a href="#system-design-interviews">System Design Interviews</a></li>
<li><a href="#url-shortener">URL Shortener</a></li>
<li><a href="#whatsapp">WhatsApp</a></li>
<li><a href="#twitter">Twitter</a></li>
<li><a href="#netflix">Netflix</a></li>
<li><a href="#uber">Uber</a></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Appendix</strong></p>
<ul dir="auto">
<li><a href="#next-steps">Next Steps</a></li>
<li><a href="#references">References</a></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">What is system design?</h2>
<p dir="auto">Before we start this course, let's talk about what even is system design.</p>
<p dir="auto">System design is the process of defining the architecture, interfaces, and data
for a system that satisfies specific requirements. System design meets the needs
of your business or organization through coherent and efficient systems. It requires
a systematic approach to building and engineering systems. A good system design requires
us to think about everything, from infrastructure all the way down to the data and how it's stored.</p>
<h2 tabindex="-1" dir="auto">Why is System Design so important?</h2>
<p dir="auto">System design helps us define a solution that meets the business requirements. It is
one of the earliest decisions we can make when building a system. Often it is essential
to think from a high level as these decisions are very difficult to correct later. It
also makes it easier to reason about and manage architectural changes as the system evolves.</p>
<h2 tabindex="-1" dir="auto">IP</h2>
<p dir="auto">An IP address is a unique address that identifies a device on the internet or a local network. IP stands for <em>"Internet Protocol"</em>, which is the set of rules governing the format of data sent via the internet or local network.</p>
<p dir="auto">In essence, IP addresses are the identifier that allows information to be sent between devices on a network. They contain location information and make devices accessible for communication. The internet needs a way to differentiate between different computers, routers, and websites. IP addresses provide a way of doing so and form an essential part of how the internet works.</p>
<h2 tabindex="-1" dir="auto">Versions</h2>
<p dir="auto">Now, let's learn about the different versions of IP addresses:</p>
<h3 tabindex="-1" dir="auto">IPv4</h3>
<p dir="auto">The original Internet Protocol is IPv4 which uses a 32-bit numeric dot-decimal notation that only allows for around 4 billion IP addresses. Initially, it was more than enough but as internet adoption grew, we needed something better.</p>
<p dir="auto"><em>Example: <code>102.22.192.181</code></em></p>
<h3 tabindex="-1" dir="auto">IPv6</h3>
<p dir="auto">IPv6 is a new protocol that was introduced in 1998. Deployment commenced in the mid-2000s and since the internet users have grown exponentially, it is still ongoing.</p>
<p dir="auto">This new protocol uses 128-bit alphanumeric hexadecimal notation. This means that IPv6 can provide about ~340e+36 IP addresses. That's more than enough to meet the growing demand for years to come.</p>
<p dir="auto"><em>Example: <code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code></em></p>
<h2 tabindex="-1" dir="auto">Types</h2>
<p dir="auto">Let's discuss types of IP addresses:</p>
<h3 tabindex="-1" dir="auto">Public</h3>
<p dir="auto">A public IP address is an address where one primary address is associated with your whole network. In this type of IP address, each of the connected devices has the same IP address.</p>
<p dir="auto"><em>Example: IP address provided to your router by the ISP.</em></p>
<h3 tabindex="-1" dir="auto">Private</h3>
<p dir="auto">A private IP address is a unique IP number assigned to every device that connects to your internet network, which includes devices like computers, tablets, and smartphones, which are used in your household.</p>
<p dir="auto"><em>Example: IP addresses generated by your home router for your devices.</em></p>
<h3 tabindex="-1" dir="auto">Static</h3>
<p dir="auto">A static IP address does not change and is one that was manually created, as opposed to having been assigned. These addresses are usually more expensive but are more reliable.</p>
<p dir="auto"><em>Example: They are usually used for important things like reliable geo-location services, remote access, server hosting, etc.</em></p>
<h3 tabindex="-1" dir="auto">Dynamic</h3>
<p dir="auto">A dynamic IP address changes from time to time and is not always the same. It has been assigned by a <a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol" rel="nofollow">Dynamic Host Configuration Protocol (DHCP)</a> server. Dynamic IP addresses are the most common type of internet protocol address. They are cheaper to deploy and allow us to reuse IP addresses within a network as needed.</p>
<p dir="auto"><em>Example: They are more commonly used for consumer equipment and personal use.</em></p>
<h2 tabindex="-1" dir="auto">OSI Model</h2>
<p dir="auto">The OSI Model is a logical and conceptual model that defines network communication used by systems open to interconnection and communication with other systems. The Open System Interconnection (OSI Model) also defines a logical network and effectively describes computer packet transfer by using various layers of protocols.</p>
<p dir="auto">The OSI Model can be seen as a universal language for computer networking. It's based on the concept of splitting up a communication system into seven abstract layers, each one stacked upon the last.</p>
<h2 tabindex="-1" dir="auto">Why does the OSI model matter?</h2>
<p dir="auto">The Open System Interconnection (OSI) model has defined the common terminology used in networking discussions and documentation. This allows us to take a very complex communications process apart and evaluate its components.</p>
<p dir="auto">While this model is not directly implemented in the TCP/IP networks that are most common today, it can still help us do so much more, such as:</p>
<ul dir="auto">
<li>Make troubleshooting easier and help identify threats across the entire stack.</li>
<li>Encourage hardware manufacturers to create networking products that can communicate with each other over the network.</li>
<li>Essential for developing a security-first mindset.</li>
<li>Separate a complex function into simpler components.</li>
</ul>
<h2 tabindex="-1" dir="auto">Layers</h2>
<p dir="auto">The seven abstraction layers of the OSI model can be defined as follows, from top to bottom:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png" alt="osi-model"></a></p>
<h3 tabindex="-1" dir="auto">Application</h3>
<p dir="auto">This is the only layer that directly interacts with data from the user. Software applications like web browsers and email clients rely on the application layer to initiate communication. But it should be made clear that client software applications are not part of the application layer, rather the application layer is responsible for the protocols and data manipulation that the software relies on to present meaningful data to the user. Application layer protocols include HTTP as well as SMTP.</p>
<h3 tabindex="-1" dir="auto">Presentation</h3>
<p dir="auto">The presentation layer is also called the Translation layer. The data from the application layer is extracted here and manipulated as per the required format to transmit over the network. The functions of the presentation layer are translation, encryption/decryption, and compression.</p>
<h3 tabindex="-1" dir="auto">Session</h3>
<p dir="auto">This is the layer responsible for opening and closing communication between the two devices. The time between when the communication is opened and closed is known as the session. The session layer ensures that the session stays open long enough to transfer all the data being exchanged, and then promptly closes the session in order to avoid wasting resources. The session layer also synchronizes data transfer with checkpoints.</p>
<h3 tabindex="-1" dir="auto">Transport</h3>
<p dir="auto">The transport layer (also known as layer 4) is responsible for end-to-end communication between the two devices. This includes taking data from the session layer and breaking it up into chunks called segments before sending it to the Network layer (layer 3). It is also responsible for reassembling the segments on the receiving device into data the session layer can consume.</p>
<h3 tabindex="-1" dir="auto">Network</h3>
<p dir="auto">The network layer is responsible for facilitating data transfer between two different networks. The network layer breaks up segments from the transport layer into smaller units, called packets, on the sender's device, and reassembles these packets on the receiving device. The network layer also finds the best physical path for the data to reach its destination this is known as routing. If the two devices communicating are on the same network, then the network layer is unnecessary.</p>
<h3 tabindex="-1" dir="auto">Data Link</h3>
<p dir="auto">The data link layer is very similar to the network layer, except the data link layer facilitates data transfer between two devices on the same network. The data link layer takes packets from the network layer and breaks them into smaller pieces called frames.</p>
<h3 tabindex="-1" dir="auto">Physical</h3>
<p dir="auto">This layer includes the physical equipment involved in the data transfer, such as the cables and switches. This is also the layer where the data gets converted into a bit stream, which is a string of 1s and 0s. The physical layer of both devices must also agree on a signal convention so that the 1s can be distinguished from the 0s on both devices.</p>
<h2 tabindex="-1" dir="auto">TCP and UDP</h2>
<h2 tabindex="-1" dir="auto">TCP</h2>
<p dir="auto">Transmission Control Protocol (TCP) is connection-oriented, meaning once a connection has been established, data can be transmitted in both directions. TCP has built-in systems to check for errors and to guarantee data will be delivered in the order it was sent, making it the perfect protocol for transferring information like still images, data files, and web pages.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png" alt="tcp"></a></p>
<p dir="auto">But while TCP is instinctively reliable, its feedback mechanisms also result in a larger overhead, translating to greater use of the available bandwidth on the network.</p>
<h2 tabindex="-1" dir="auto">UDP</h2>
<p dir="auto">User Datagram Protocol (UDP) is a simpler, connectionless internet protocol in which error-checking and recovery services are not required. With UDP, there is no overhead for opening a connection, maintaining a connection, or terminating a connection. Data is continuously sent to the recipient, whether or not they receive it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png" alt="udp"></a></p>
<p dir="auto">It is largely preferred for real-time communications like broadcast or multicast network transmission. We should use UDP over TCP when we need the lowest latency and late data is worse than the loss of data.</p>
<h2 tabindex="-1" dir="auto">TCP vs UDP</h2>
<p dir="auto">TCP is a connection-oriented protocol, whereas UDP is a connectionless protocol. A key difference between TCP and UDP is speed, as TCP is comparatively slower than UDP. Overall, UDP is a much faster, simpler, and more efficient protocol, however, retransmission of lost data packets is only possible with TCP.</p>
<p dir="auto">TCP provides ordered delivery of data from user to server (and vice versa), whereas UDP is not dedicated to end-to-end communications, nor does it check the readiness of the receiver.</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>TCP</th>
<th>UDP</th>
</tr>
</thead>
<tbody>
<tr>
<td>Connection</td>
<td>Requires an established connection</td>
<td>Connectionless protocol</td>
</tr>
<tr>
<td>Guaranteed delivery</td>
<td>Can guarantee delivery of data</td>
<td>Cannot guarantee delivery of data</td>
</tr>
<tr>
<td>Re-transmission</td>
<td>Re-transmission of lost packets is possible</td>
<td>No re-transmission of lost packets</td>
</tr>
<tr>
<td>Speed</td>
<td>Slower than UDP</td>
<td>Faster than TCP</td>
</tr>
<tr>
<td>Broadcasting</td>
<td>Does not support broadcasting</td>
<td>Supports broadcasting</td>
</tr>
<tr>
<td>Use cases</td>
<td>HTTPS, HTTP, SMTP, POP, FTP, etc</td>
<td>Video streaming, DNS, VoIP, etc</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Domain Name System (DNS)</h2>
<p dir="auto">Earlier we learned about IP addresses that enable every machine to connect with other machines. But as we know humans are more comfortable with names than numbers. It's easier to remember a name like <code>google.com</code> than something like <code>122.250.192.232</code>.</p>
<p dir="auto">This brings us to Domain Name System (DNS) which is a hierarchical and decentralized naming system used for translating human-readable domain names to IP addresses.</p>
<h2 tabindex="-1" dir="auto">How DNS works</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png" alt="how-dns-works"></a></p>
<p dir="auto">DNS lookup involves the following eight steps:</p>
<ol dir="auto">
<li>A client types <a href="http://example.com/" rel="nofollow">example.com</a> into a web browser, the query travels to the internet and is received by a DNS resolver.</li>
<li>The resolver then recursively queries a DNS root nameserver.</li>
<li>The root server responds to the resolver with the address of a Top-Level Domain (TLD).</li>
<li>The resolver then makes a request to the <code>.com</code> TLD.</li>
<li>The TLD server then responds with the IP address of the domain's nameserver, <a href="http://example.com/" rel="nofollow">example.com</a>.</li>
<li>Lastly, the recursive resolver sends a query to the domain's nameserver.</li>
<li>The IP address for <a href="http://example.com/" rel="nofollow">example.com</a> is then returned to the resolver from the nameserver.</li>
<li>The DNS resolver then responds to the web browser with the IP address of the domain requested initially.</li>
</ol>
<p dir="auto">Once the IP address has been resolved, the client should be able to request content from the resolved IP address. For example, the resolved IP may return a webpage to be rendered in the browser.</p>
<h2 tabindex="-1" dir="auto">Server types</h2>
<p dir="auto">Now, let's look at the four key groups of servers that make up the DNS infrastructure.</p>
<h3 tabindex="-1" dir="auto">DNS Resolver</h3>
<p dir="auto">A DNS resolver (also known as a DNS recursive resolver) is the first stop in a DNS query. The recursive resolver acts as a middleman between a client and a DNS nameserver. After receiving a DNS query from a web client, a recursive resolver will either respond with cached data, or send a request to a root nameserver, followed by another request to a TLD nameserver, and then one last request to an authoritative nameserver. After receiving a response from the authoritative nameserver containing the requested IP address, the recursive resolver then sends a response to the client.</p>
<h3 tabindex="-1" dir="auto">DNS root server</h3>
<p dir="auto">A root server accepts a recursive resolver's query which includes a domain name, and the root nameserver responds by directing the recursive resolver to a TLD nameserver, based on the extension of that domain (<code>.com</code>, <code>.net</code>, <code>.org</code>, etc.). The root nameservers are overseen by a nonprofit called the <a href="https://www.icann.org/" rel="nofollow">Internet Corporation for Assigned Names and Numbers (ICANN)</a>.</p>
<p dir="auto">There are 13 DNS root nameservers known to every recursive resolver. Note that while there are 13 root nameservers, that doesn't mean that there are only 13 machines in the root nameserver system. There are 13 types of root nameservers, but there are multiple copies of each one all over the world, which use <a href="https://en.wikipedia.org/wiki/Anycast" rel="nofollow">Anycast routing</a> to provide speedy responses.</p>
<h3 tabindex="-1" dir="auto">TLD nameserver</h3>
<p dir="auto">A TLD nameserver maintains information for all the domain names that share a common domain extension, such as <code>.com</code>, <code>.net</code>, or whatever comes after the last dot in a URL.</p>
<p dir="auto">Management of TLD nameservers is handled by the <a href="https://www.iana.org/" rel="nofollow">Internet Assigned Numbers Authority (IANA)</a>, which is a branch of <a href="https://www.icann.org/" rel="nofollow">ICANN</a>. The IANA breaks up the TLD servers into two main groups:</p>
<ul dir="auto">
<li><strong>Generic top-level domains</strong>: These are domains like <code>.com</code>, <code>.org</code>, <code>.net</code>, <code>.edu</code>, and <code>.gov</code>.</li>
<li><strong>Country code top-level domains</strong>: These include any domains that are specific to a country or state. Examples include <code>.uk</code>, <code>.us</code>, <code>.ru</code>, and <code>.jp</code>.</li>
</ul>
<h3 tabindex="-1" dir="auto">Authoritative DNS server</h3>
<p dir="auto">The authoritative nameserver is usually the resolver's last step in the journey for an IP address. The authoritative nameserver contains information specific to the domain name it serves (e.g. <a href="http://google.com/" rel="nofollow">google.com</a>) and it can provide a recursive resolver with the IP address of that server found in the DNS A record, or if the domain has a CNAME record (alias) it will provide the recursive resolver with an alias domain, at which point the recursive resolver will have to perform a whole new DNS lookup to procure a record from an authoritative nameserver (often an A record containing an IP address). If it cannot find the domain, returns the NXDOMAIN message.</p>
<h2 tabindex="-1" dir="auto">Query Types</h2>
<p dir="auto">There are three types of queries in a DNS system:</p>
<h3 tabindex="-1" dir="auto">Recursive</h3>
<p dir="auto">In a recursive query, a DNS client requires that a DNS server (typically a DNS recursive resolver) will respond to the client with either the requested resource record or an error message if the resolver can't find the record.</p>
<h3 tabindex="-1" dir="auto">Iterative</h3>
<p dir="auto">In an iterative query, a DNS client provides a hostname, and the DNS Resolver returns the best answer it can. If the DNS resolver has the relevant DNS records in its cache, it returns them. If not, it refers the DNS client to the Root Server or another Authoritative Name Server that is nearest to the required DNS zone. The DNS client must then repeat the query directly against the DNS server it was referred.</p>
<h3 tabindex="-1" dir="auto">Non-recursive</h3>
<p dir="auto">A non-recursive query is a query in which the DNS Resolver already knows the answer. It either immediately returns a DNS record because it already stores it in a local cache, or queries a DNS Name Server which is authoritative for the record, meaning it definitely holds the correct IP for that hostname. In both cases, there is no need for additional rounds of queries (like in recursive or iterative queries). Rather, a response is immediately returned to the client.</p>
<h2 tabindex="-1" dir="auto">Record Types</h2>
<p dir="auto">DNS records (aka zone files) are instructions that live in authoritative DNS servers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain.</p>
<p dir="auto">These records consist of a series of text files written in what is known as <em>DNS syntax</em>. DNS syntax is just a string of characters used as commands that tell the DNS server what to do. All DNS records also have a <em>"TTL"</em>, which stands for time-to-live, and indicates how often a DNS server will refresh that record.</p>
<p dir="auto">There are more record types but for now, let's look at some of the most commonly used ones:</p>
<ul dir="auto">
<li><strong>A (Address record)</strong>: This is the record that holds the IP address of a domain.</li>
<li><strong>AAAA (IP Version 6 Address record)</strong>: The record that contains the IPv6 address for a domain (as opposed to A records, which stores the IPv4 address).</li>
<li><strong>CNAME (Canonical Name record)</strong>: Forwards one domain or subdomain to another domain, does NOT provide an IP address.</li>
<li><strong>MX (Mail exchanger record)</strong>: Directs mail to an email server.</li>
<li><strong>TXT (Text Record)</strong>: This record lets an admin store text notes in the record. These records are often used for email security.</li>
<li><strong>NS (Name Server records)</strong>: Stores the name server for a DNS entry.</li>
<li><strong>SOA (Start of Authority)</strong>: Stores admin information about a domain.</li>
<li><strong>SRV (Service Location record)</strong>: Specifies a port for specific services.</li>
<li><strong>PTR (Reverse-lookup Pointer records)</strong>: Provides a domain name in reverse lookups.</li>
<li><strong>CERT (Certificate record)</strong>: Stores public key certificates.</li>
</ul>
<h2 tabindex="-1" dir="auto">Subdomains</h2>
<p dir="auto">A subdomain is an additional part of our main domain name. It is commonly used to logically separate a website into sections. We can create multiple subdomains or child domains on the main domain.</p>
<p dir="auto">For example, <code>blog.example.com</code> where <code>blog</code> is the subdomain, <code>example</code> is the primary domain and <code>.com</code> is the top-level domain (TLD). Similar examples can be <code>support.example.com</code> or <code>careers.example.com</code>.</p>
<h2 tabindex="-1" dir="auto">DNS Zones</h2>
<p dir="auto">A DNS zone is a distinct part of the domain namespace which is delegated to a legal entity like a person, organization, or company, who is responsible for maintaining the DNS zone. A DNS zone is also an administrative function, allowing for granular control of DNS components, such as authoritative name servers.</p>
<h2 tabindex="-1" dir="auto">DNS Caching</h2>
<p dir="auto">A DNS cache (sometimes called a DNS resolver cache) is a temporary database, maintained by a computer's operating system, that contains records of all the recent visits and attempted visits to websites and other internet domains. In other words, a DNS cache is just a memory of recent DNS lookups that our computer can quickly refer to when it's trying to figure out how to load a website.</p>
<p dir="auto">The Domain Name System implements a time-to-live (TTL) on every DNS record. TTL specifies the number of seconds the record can be cached by a DNS client or server. When the record is stored in a cache, whatever TTL value came with it gets stored as well. The server continues to update the TTL of the record stored in the cache, counting down every second. When it hits zero, the record is deleted or purged from the cache. At that point, if a query for that record is received, the DNS server has to start the resolution process.</p>
<h2 tabindex="-1" dir="auto">Reverse DNS</h2>
<p dir="auto">A reverse DNS lookup is a DNS query for the domain name associated with a given IP address. This accomplishes the opposite of the more commonly used forward DNS lookup, in which the DNS system is queried to return an IP address. The process of reverse resolving an IP address uses PTR records. If the server does not have a PTR record, it cannot resolve a reverse lookup.</p>
<p dir="auto">Reverse lookups are commonly used by email servers. Email servers check and see if an email message came from a valid server before bringing it onto their network. Many email servers will reject messages from any server that does not support reverse lookups or from a server that is highly unlikely to be legitimate.</p>
<p dir="auto"><em>Note: Reverse DNS lookups are not universally adopted as they are not critical to the normal function of the internet.</em></p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">These are some widely used managed DNS solutions:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/route53" rel="nofollow">Route53</a></li>
<li><a href="https://www.cloudflare.com/dns" rel="nofollow">Cloudflare DNS</a></li>
<li><a href="https://cloud.google.com/dns" rel="nofollow">Google Cloud DNS</a></li>
<li><a href="https://azure.microsoft.com/en-in/services/dns" rel="nofollow">Azure DNS</a></li>
<li><a href="https://ns1.com/products/managed-dns" rel="nofollow">NS1</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Load Balancing</h2>
<p dir="auto">Load balancing lets us distribute incoming network traffic across multiple resources ensuring high availability and reliability by sending requests only to resources that are online. This provides the flexibility to add or subtract resources as demand dictates.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png" alt="load-balancing"></a></p>
<p dir="auto">For additional scalability and redundancy, we can try to load balance at each layer of our system:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png" alt="load-balancing-layers"></a></p>
<h2 tabindex="-1" dir="auto">But why?</h2>
<p dir="auto">Modern high-traffic websites must serve hundreds of thousands, if not millions, of concurrent requests from users or clients. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers.</p>
<p dir="auto">A load balancer can sit in front of the servers and route client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization. This ensures that no single server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts sending requests to it.</p>
<h2 tabindex="-1" dir="auto">Workload distribution</h2>
<p dir="auto">This is the core functionality provided by a load balancer and has several common variations:</p>
<ul dir="auto">
<li><strong>Host-based</strong>: Distributes requests based on the requested hostname.</li>
<li><strong>Path-based</strong>: Using the entire URL to distribute requests as opposed to just the hostname.</li>
<li><strong>Content-based</strong>: Inspects the message content of a request. This allows distribution based on content such as the value of a parameter.</li>
</ul>
<h2 tabindex="-1" dir="auto">Layers</h2>
<p dir="auto">Generally speaking, load balancers operate at one of the two levels:</p>
<h3 tabindex="-1" dir="auto">Network layer</h3>
<p dir="auto">This is the load balancer that works at the network's transport layer, also known as layer 4. This performs routing based on networking information such as IP addresses and is not able to perform content-based routing. These are often dedicated hardware devices that can operate at high speed.</p>
<h3 tabindex="-1" dir="auto">Application layer</h3>
<p dir="auto">This is the load balancer that operates at the application layer, also known as layer 7. Load balancers can read requests in their entirety and perform content-based routing. This allows the management of load based on a full understanding of traffic.</p>
<h2 tabindex="-1" dir="auto">Types</h2>
<p dir="auto">Let's look at different types of load balancers:</p>
<h3 tabindex="-1" dir="auto">Software</h3>
<p dir="auto">Software load balancers usually are easier to deploy than hardware versions. They also tend to be more cost-effective and flexible, and they are used in conjunction with software development environments. The software approach gives us the flexibility of configuring the load balancer to our environment's specific needs. The boost in flexibility may come at the cost of having to do more work to set up the load balancer. Compared to hardware versions, which offer more of a closed-box approach, software balancers give us more freedom to make changes and upgrades.</p>
<p dir="auto">Software load balancers are widely used and are available either as installable solutions that require configuration and management or as a managed cloud service.</p>
<h3 tabindex="-1" dir="auto">Hardware</h3>
<p dir="auto">As the name implies, a hardware load balancer relies on physical, on-premises hardware to distribute application and network traffic. These devices can handle a large volume of traffic but often carry a hefty price tag and are fairly limited in terms of flexibility.</p>
<p dir="auto">Hardware load balancers include proprietary firmware that requires maintenance and updates as new versions, and security patches are released.</p>
<h3 tabindex="-1" dir="auto">DNS</h3>
<p dir="auto">DNS load balancing is the practice of configuring a domain in the Domain Name System (DNS) such that client requests to the domain are distributed across a group of server machines.</p>
<p dir="auto">Unfortunately, DNS load balancing has inherent problems limiting its reliability and efficiency. Most significantly, DNS does not check for server and network outages, or errors. It always returns the same set of IP addresses for a domain even if servers are down or inaccessible.</p>
<h2 tabindex="-1" dir="auto">Routing Algorithms</h2>
<p dir="auto">Now, let's discuss commonly used routing algorithms:</p>
<ul dir="auto">
<li><strong>Round-robin</strong>: Requests are distributed to application servers in rotation.</li>
<li><strong>Weighted Round-robin</strong>: Builds on the simple Round-robin technique to account for differing server characteristics such as compute and traffic handling capacity using weights that can be assigned via DNS records by the administrator.</li>
<li><strong>Least Connections</strong>: A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections.</li>
<li><strong>Least Response Time</strong>: Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections.</li>
<li><strong>Least Bandwidth</strong>: This method measures traffic in megabits per second (Mbps), sending client requests to the server with the least Mbps of traffic.</li>
<li><strong>Hashing</strong>: Distributes requests based on a key we define, such as the client IP address or the request URL.</li>
</ul>
<h2 tabindex="-1" dir="auto">Advantages</h2>
<p dir="auto">Load balancing also plays a key role in preventing downtime, other advantages of load balancing include the following:</p>
<ul dir="auto">
<li>Scalability</li>
<li>Redundancy</li>
<li>Flexibility</li>
<li>Efficiency</li>
</ul>
<h2 tabindex="-1" dir="auto">Redundant load balancers</h2>
<p dir="auto">As you must've already guessed, the load balancer itself can be a single point of failure. To overcome this, a second or <code>N</code> number of load balancers can be used in a cluster mode.</p>
<p dir="auto">And, if there's a failure detection and the <em>active</em> load balancer fails, another <em>passive</em> load balancer can take over which will make our system more fault-tolerant.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png" alt="redundant-load-balancing"></a></p>
<h2 tabindex="-1" dir="auto">Features</h2>
<p dir="auto">Here are some commonly desired features of load balancers:</p>
<ul dir="auto">
<li><strong>Autoscaling</strong>: Starting up and shutting down resources in response to demand conditions.</li>
<li><strong>Sticky sessions</strong>: The ability to assign the same user or device to the same resource in order to maintain the session state on the resource.</li>
<li><strong>Healthchecks</strong>: The ability to determine if a resource is down or performing poorly in order to remove the resource from the load balancing pool.</li>
<li><strong>Persistence connections</strong>: Allowing a server to open a persistent connection with a client such as a WebSocket.</li>
<li><strong>Encryption</strong>: Handling encrypted connections such as TLS and SSL.</li>
<li><strong>Certificates</strong>: Presenting certificates to a client and authentication of client certificates.</li>
<li><strong>Compression</strong>: Compression of responses.</li>
<li><strong>Caching</strong>: An application-layer load balancer may offer the ability to cache responses.</li>
<li><strong>Logging</strong>: Logging of request and response metadata can serve as an important audit trail or source for analytics data.</li>
<li><strong>Request tracing</strong>: Assigning each request a unique id for the purposes of logging, monitoring, and troubleshooting.</li>
<li><strong>Redirects</strong>: The ability to redirect an incoming request based on factors such as the requested path.</li>
<li><strong>Fixed response</strong>: Returning a static response for a request such as an error message.</li>
</ul>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Following are some of the load balancing solutions commonly used in the industry:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/elasticloadbalancing" rel="nofollow">Amazon Elastic Load Balancing</a></li>
<li><a href="https://azure.microsoft.com/en-in/services/load-balancer" rel="nofollow">Azure Load Balancing</a></li>
<li><a href="https://cloud.google.com/load-balancing" rel="nofollow">GCP Load Balancing</a></li>
<li><a href="https://www.digitalocean.com/products/load-balancer" rel="nofollow">DigitalOcean Load Balancer</a></li>
<li><a href="https://www.nginx.com/" rel="nofollow">Nginx</a></li>
<li><a href="http://www.haproxy.org/" rel="nofollow">HAProxy</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Clustering</h2>
<p dir="auto">At a high level, a computer cluster is a group of two or more computers, or nodes, that run in parallel to achieve a common goal. This allows workloads consisting of a high number of individual, parallelizable tasks to be distributed among the nodes in the cluster. As a result, these tasks can leverage the combined memory and processing power of each computer to increase overall performance.</p>
<p dir="auto">To build a computer cluster, the individual nodes should be connected to a network to enable internode communication. The software can then be used to join the nodes together and form a cluster. It may have a shared storage device and/or local storage on each node.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png" alt="cluster"></a></p>
<p dir="auto">Typically, at least one node is designated as the leader node and acts as the entry point to the cluster. The leader node may be responsible for delegating incoming work to the other nodes and, if necessary, aggregating the results and returning a response to the user.</p>
<p dir="auto">Ideally, a cluster functions as if it were a single system. A user accessing the cluster should not need to know whether the system is a cluster or an individual machine. Furthermore, a cluster should be designed to minimize latency and prevent bottlenecks in node-to-node communication.</p>
<h2 tabindex="-1" dir="auto">Types</h2>
<p dir="auto">Computer clusters can generally be categorized into three types:</p>
<ul dir="auto">
<li>Highly available or fail-over</li>
<li>Load balancing</li>
<li>High-performance computing</li>
</ul>
<h2 tabindex="-1" dir="auto">Configurations</h2>
<p dir="auto">The two most commonly used high availability (HA) clustering configurations are active-active and active-passive.</p>
<h3 tabindex="-1" dir="auto">Active-Active</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png" alt="active-active"></a></p>
<p dir="auto">An active-active cluster is typically made up of at least two nodes, both actively running the same kind of service simultaneously. The main purpose of an active-active cluster is to achieve load balancing. A load balancer distributes workloads across all nodes to prevent any single node from getting overloaded. Because there are more nodes available to serve, there will also be an improvement in throughput and response times.</p>
<h3 tabindex="-1" dir="auto">Active-Passive</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png" alt="active-passive"></a></p>
<p dir="auto">Like the active-active cluster configuration, an active-passive cluster also consists of at least two nodes. However, as the name <em>active-passive</em> implies, not all nodes are going to be active. For example, in the case of two nodes, if the first node is already active, then the second node must be passive or on standby.</p>
<h2 tabindex="-1" dir="auto">Advantages</h2>
<p dir="auto">Four key advantages of cluster computing are as follows:</p>
<ul dir="auto">
<li>High availability</li>
<li>Scalability</li>
<li>Performance</li>
<li>Cost-effective</li>
</ul>
<h2 tabindex="-1" dir="auto">Load balancing vs Clustering</h2>
<p dir="auto">Load balancing shares some common traits with clustering, but they are different processes. Clustering provides redundancy and boosts capacity and availability. Servers in a cluster are aware of each other and work together toward a common purpose. But with load balancing, servers are not aware of each other. Instead, they react to the requests they receive from the load balancer.</p>
<p dir="auto">We can employ load balancing in conjunction with clustering, but it also is applicable in cases involving independent servers that share a common purpose such as to run a website, business application, web service, or some other IT resource.</p>
<h2 tabindex="-1" dir="auto">Challenges</h2>
<p dir="auto">The most obvious challenge clustering presents is the increased complexity of installation and maintenance. An operating system, the application, and its dependencies must each be installed and updated on every node.</p>
<p dir="auto">This becomes even more complicated if the nodes in the cluster are not homogeneous. Resource utilization for each node must also be closely monitored, and logs should be aggregated to ensure that the software is behaving correctly.</p>
<p dir="auto">Additionally, storage becomes more difficult to manage, a shared storage device must prevent nodes from overwriting one another and distributed data stores have to be kept in sync.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Clustering is commonly used in the industry, and often many technologies offer some sort of clustering mode. For example:</p>
<ul dir="auto">
<li>Containers (e.g. <a href="https://kubernetes.io/" rel="nofollow">Kubernetes</a>, <a href="https://aws.amazon.com/ecs" rel="nofollow">Amazon ECS</a>)</li>
<li>Databases (e.g. <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Cassandra</a>, <a href="https://www.mongodb.com/" rel="nofollow">MongoDB</a>)</li>
<li>Cache (e.g. <a href="https://redis.io/docs/manual/scaling" rel="nofollow">Redis</a>)</li>
</ul>
<h2 tabindex="-1" dir="auto">Caching</h2>
<p dir="auto"><em>"There are only two hard things in Computer Science: cache invalidation and naming things." - Phil Karlton</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png" alt="caching"></a></p>
<p dir="auto">A cache's primary purpose is to increase data retrieval performance by reducing the need to access the underlying slower storage layer. Trading off capacity for speed, a cache typically stores a subset of data transiently, in contrast to databases whose data is usually complete and durable.</p>
<p dir="auto">Caches take advantage of the locality of reference principle <em>"recently requested data is likely to be requested again".</em></p>
<h2 tabindex="-1" dir="auto">Caching and Memory</h2>
<p dir="auto">Like a computer's memory, a cache is a compact, fast-performing memory that stores data in a hierarchy of levels, starting at level one, and progressing from there sequentially. They are labeled as L1, L2, L3, and so on. A cache also gets written if requested, such as when there has been an update and new content needs to be saved to the cache, replacing the older content that was saved.</p>
<p dir="auto">No matter whether the cache is read or written, it's done one block at a time. Each block also has a tag that includes the location where the data was stored in the cache. When data is requested from the cache, a search occurs through the tags to find the specific content that's needed in level one (L1) of the memory. If the correct data isn't found, more searches are conducted in L2.</p>
<p dir="auto">If the data isn't found there, searches are continued in L3, then L4, and so on until it has been found, then, it's read and loaded. If the data isn't found in the cache at all, then it's written into it for quick retrieval the next time.</p>
<h2 tabindex="-1" dir="auto">Cache hit and Cache miss</h2>
<h3 tabindex="-1" dir="auto">Cache hit</h3>
<p dir="auto">A cache hit describes the situation where content is successfully served from the cache. The tags are searched in the memory rapidly, and when the data is found and read, it's considered a cache hit.</p>
<p dir="auto"><strong>Cold, Warm, and Hot Caches</strong></p>
<p dir="auto">A cache hit can also be described as cold, warm, or hot. In each of these, the speed at which the data is read is described.</p>
<p dir="auto">A hot cache is an instance where data was read from the memory at the <em>fastest</em> possible rate. This happens when the data is retrieved from L1.</p>
<p dir="auto">A cold cache is the <em>slowest</em> possible rate for data to be read, though, it's still successful so it's still considered a cache hit. The data is just found lower in the memory hierarchy such as in L3, or lower.</p>
<p dir="auto">A warm cache is used to describe data that's found in L2 or L3. It's not as fast as a hot cache, but it's still faster than a cold cache. Generally, calling a cache warm is used to express that it's slower and closer to a cold cache than a hot one.</p>
<h3 tabindex="-1" dir="auto">Cache miss</h3>
<p dir="auto">A cache miss refers to the instance when the memory is searched, and the data isn't found. When this happens, the content is transferred and written into the cache.</p>
<h2 tabindex="-1" dir="auto">Cache Invalidation</h2>
<p dir="auto">Cache invalidation is a process where the computer system declares the cache entries as invalid and removes or replaces them. If the data is modified, it should be invalidated in the cache, if not, this can cause inconsistent application behavior. There are three kinds of caching systems:</p>
<h3 tabindex="-1" dir="auto">Write-through cache</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png" alt="write-through-cache"></a></p>
<p dir="auto">Data is written into the cache and the corresponding database simultaneously.</p>
<p dir="auto"><strong>Pro</strong>: Fast retrieval, complete data consistency between cache and storage.</p>
<p dir="auto"><strong>Con</strong>: Higher latency for write operations.</p>
<h3 tabindex="-1" dir="auto">Write-around cache</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png" alt="write-around-cache"></a></p>
<p dir="auto">Where write directly goes to the database or permanent storage, bypassing the cache.</p>
<p dir="auto"><strong>Pro</strong>: This may reduce latency.</p>
<p dir="auto"><strong>Con</strong>: It increases cache misses because the cache system has to read the information from the database in case of a cache miss. As a result, this can lead to higher read latency in the case of applications that write and re-read the information quickly. Read happen from slower back-end storage and experiences higher latency.</p>
<h3 tabindex="-1" dir="auto">Write-back cache</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png" alt="write-back-cache"></a></p>
<p dir="auto">Where the write is only done to the caching layer and the write is confirmed as soon as the write to the cache completes. The cache then asynchronously syncs this write to the database.</p>
<p dir="auto"><strong>Pro</strong>: This would lead to reduced latency and high throughput for write-intensive applications.</p>
<p dir="auto"><strong>Con</strong>: There is a risk of data loss in case the caching layer crashes. We can improve this by having more than one replica acknowledging the write in the cache.</p>
<h2 tabindex="-1" dir="auto">Eviction policies</h2>
<p dir="auto">Following are some of the most common cache eviction policies:</p>
<ul dir="auto">
<li><strong>First In First Out (FIFO)</strong>: The cache evicts the first block accessed first without any regard to how often or how many times it was accessed before.</li>
<li><strong>Last In First Out (LIFO)</strong>: The cache evicts the block accessed most recently first without any regard to how often or how many times it was accessed before.</li>
<li><strong>Least Recently Used (LRU)</strong>: Discards the least recently used items first.</li>
<li><strong>Most Recently Used (MRU)</strong>: Discards, in contrast to LRU, the most recently used items first.</li>
<li><strong>Least Frequently Used (LFU)</strong>: Counts how often an item is needed. Those that are used least often are discarded first.</li>
<li><strong>Random Replacement (RR)</strong>: Randomly selects a candidate item and discards it to make space when necessary.</li>
</ul>
<h2 tabindex="-1" dir="auto">Distributed Cache</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png" alt="distributed-cache"></a></p>
<p dir="auto">A distributed cache is a system that pools together the random-access memory (RAM) of multiple networked computers into a single in-memory data store used as a data cache to provide fast access to data. While most caches are traditionally in one physical server or hardware component, a distributed cache can grow beyond the memory limits of a single computer by linking together multiple computers.</p>
<h2 tabindex="-1" dir="auto">Global Cache</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png" alt="global-cache"></a></p>
<p dir="auto">As the name suggests, we will have a single shared cache that all the application nodes will use. When the requested data is not found in the global cache, it's the responsibility of the cache to find out the missing piece of data from the underlying data store.</p>
<h2 tabindex="-1" dir="auto">Use cases</h2>
<p dir="auto">Caching can have many real-world use cases such as:</p>
<ul dir="auto">
<li>Database Caching</li>
<li>Content Delivery Network (CDN)</li>
<li>Domain Name System (DNS) Caching</li>
<li>API Caching</li>
</ul>
<p dir="auto"><strong>When not to use caching?</strong></p>
<p dir="auto">Let's also look at some scenarios where we should not use cache:</p>
<ul dir="auto">
<li>Caching isn't helpful when it takes just as long to access the cache as it does to access the primary data store.</li>
<li>Caching doesn't work as well when requests have low repetition (higher randomness), because caching performance comes from repeated memory access patterns.</li>
<li>Caching isn't helpful when the data changes frequently, as the cached version gets out of sync, and the primary data store must be accessed every time.</li>
</ul>
<p dir="auto"><em>It's important to note that a cache should not be used as permanent data storage. They are almost always implemented in volatile memory because it is faster, and thus should be considered transient.</em></p>
<h2 tabindex="-1" dir="auto">Advantages</h2>
<p dir="auto">Below are some advantages of caching:</p>
<ul dir="auto">
<li>Improves performance</li>
<li>Reduce latency</li>
<li>Reduce load on the database</li>
<li>Reduce network cost</li>
<li>Increase Read Throughput</li>
</ul>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Here are some commonly used technologies for caching:</p>
<ul dir="auto">
<li><a href="https://redis.io/" rel="nofollow">Redis</a></li>
<li><a href="https://memcached.org/" rel="nofollow">Memcached</a></li>
<li><a href="https://aws.amazon.com/elasticache" rel="nofollow">Amazon Elasticache</a></li>
<li><a href="https://aerospike.com/" rel="nofollow">Aerospike</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Content Delivery Network (CDN)</h2>
<p dir="auto">A content delivery network (CDN) is a geographically distributed group of servers that work together to provide fast delivery of internet content. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png" alt="cdn-map"></a></p>
<h2 tabindex="-1" dir="auto">Why use a CDN?</h2>
<p dir="auto">Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs and improving security. Serving content from CDNs can significantly improve performance as users receive content from data centers close to them and our servers do not have to serve requests that the CDN fulfills.</p>
<h2 tabindex="-1" dir="auto">How does a CDN work?</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png" alt="cdn"></a></p>
<p dir="auto">In a CDN, the origin server contains the original versions of the content while the edge servers are numerous and distributed across various locations around the world.</p>
<p dir="auto">To minimize the distance between the visitors and the website's server, a CDN stores a cached version of its content in multiple geographical locations known as edge locations. Each edge location contains several caching servers responsible for content delivery to visitors within its proximity.</p>
<p dir="auto">Once the static assets are cached on all the CDN servers for a particular location, all subsequent website visitor requests for static assets will be delivered from these edge servers instead of the origin, thus reducing the origin load and improving scalability.</p>
<p dir="auto">For example, when someone in the UK requests our website which might be hosted in the USA, they will be served from the closest edge location such as the London edge location. This is much quicker than having the visitor make a complete request to the origin server which will increase the latency.</p>
<h2 tabindex="-1" dir="auto">Types</h2>
<p dir="auto">CDNs are generally divided into two types:</p>
<h3 tabindex="-1" dir="auto">Push CDNs</h3>
<p dir="auto">Push CDNs receive new content whenever changes occur on the server. We take full responsibility for providing content, uploading directly to the CDN, and rewriting URLs to point to the CDN. We can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.</p>
<p dir="auto">Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.</p>
<h3 tabindex="-1" dir="auto">Pull CDNs</h3>
<p dir="auto">In a Pull CDN situation, the cache is updated based on request. When the client sends a request that requires static assets to be fetched from the CDN if the CDN doesn't have it, then it will fetch the newly updated assets from the origin server and populate its cache with this new asset, and then send this new cached asset to the user.</p>
<p dir="auto">Contrary to the Push CDN, this requires less maintenance because cache updates on CDN nodes are performed based on requests from the client to the origin server. Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.</p>
<h2 tabindex="-1" dir="auto">Disadvantages</h2>
<p dir="auto">As we all know good things come with extra costs, so let's discuss some disadvantages of CDNs:</p>
<ul dir="auto">
<li><strong>Extra charges</strong>: It can be expensive to use a CDN, especially for high-traffic services.</li>
<li><strong>Restrictions</strong>: Some organizations and countries have blocked the domains or IP addresses of popular CDNs.</li>
<li><strong>Location</strong>: If most of our audience is located in a country where the CDN has no servers, the data on our website may have to travel further than without using any CDN.</li>
</ul>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Here are some widely used CDNs:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/cloudfront" rel="nofollow">Amazon CloudFront</a></li>
<li><a href="https://cloud.google.com/cdn" rel="nofollow">Google Cloud CDN</a></li>
<li><a href="https://www.cloudflare.com/cdn" rel="nofollow">Cloudflare CDN</a></li>
<li><a href="https://www.fastly.com/products/cdn" rel="nofollow">Fastly</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Proxy</h2>
<p dir="auto">A proxy server is an intermediary piece of hardware/software sitting between the client and the backend server. It receives requests from clients and relays them to the origin servers. Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compression).</p>
<h2 tabindex="-1" dir="auto">Types</h2>
<p dir="auto">There are two types of proxies:</p>
<h3 tabindex="-1" dir="auto">Forward Proxy</h3>
<p dir="auto">A forward proxy, often called a proxy, proxy server, or web proxy is a server that sits in front of a group of client machines. When those computers make requests to sites and services on the internet, the proxy server intercepts those requests and then communicates with web servers on behalf of those clients, like a middleman.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png" alt="forward-proxy"></a></p>
<p dir="auto"><strong>Advantages</strong></p>
<p dir="auto">Here are some advantages of a forward proxy:</p>
<ul dir="auto">
<li>Block access to certain content</li>
<li>Allows access to <a href="https://en.wikipedia.org/wiki/Geo-blocking" rel="nofollow">geo-restricted</a> content</li>
<li>Provides anonymity</li>
<li>Avoid other browsing restrictions</li>
</ul>
<p dir="auto">Although proxies provide the benefits of anonymity, they can still track our personal information. Setup and maintenance of a proxy server can be costly and requires configurations.</p>
<h3 tabindex="-1" dir="auto">Reverse Proxy</h3>
<p dir="auto">A reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients. When clients send requests to the origin server of a website, those requests are intercepted by the reverse proxy server.</p>
<p dir="auto">The difference between a forward and reverse proxy is subtle but important. A simplified way to sum it up would be to say that a forward proxy sits in front of a client and ensures that no origin server ever communicates directly with that specific client. On the other hand, a reverse proxy sits in front of an origin server and ensures that no client ever communicates directly with that origin server.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png" alt="reverse-proxy"></a></p>
<p dir="auto">Introducing reverse proxy results in increased complexity. A single reverse proxy is a single point of failure, configuring multiple reverse proxies (i.e. a failover) further increases complexity.</p>
<p dir="auto"><strong>Advantages</strong></p>
<p dir="auto">Here are some advantages of using a reverse proxy:</p>
<ul dir="auto">
<li>Improved security</li>
<li>Caching</li>
<li>SSL encryption</li>
<li>Load balancing</li>
<li>Scalability and flexibility</li>
</ul>
<h2 tabindex="-1" dir="auto">Load balancer vs Reverse Proxy</h2>
<p dir="auto">Wait, isn't reverse proxy similar to a load balancer? Well, no as a load balancer is useful when we have multiple servers. Often, load balancers route traffic to a set of servers serving the same function, while reverse proxies can be useful even with just one web server or application server. A reverse proxy can also act as a load balancer but not the other way around.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Below are some commonly used proxy technologies:</p>
<ul dir="auto">
<li><a href="https://www.nginx.com/" rel="nofollow">Nginx</a></li>
<li><a href="http://www.haproxy.org/" rel="nofollow">HAProxy</a></li>
<li><a href="https://doc.traefik.io/traefik" rel="nofollow">Traefik</a></li>
<li><a href="https://www.envoyproxy.io/" rel="nofollow">Envoy</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Availability</h2>
<p dir="auto">Availability is the time a system remains operational to perform its required function in a specific period. It is a simple measure of the percentage of time that a system, service, or machine remains operational under normal conditions.</p>
<h2 tabindex="-1" dir="auto">The Nine's of availability</h2>
<p dir="auto">Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. It is generally measured in the number of 9s.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Availability = \frac{Uptime}{(Uptime + Downtime)}
$$</math-renderer></p>
<p dir="auto">If availability is 99.00% available, it is said to have "2 nines" of availability, and if it is 99.9%, it is called "3 nines", and so on.</p>
<table>
<thead>
<tr>
<th>Availability (Percent)</th>
<th>Downtime (Year)</th>
<th>Downtime (Month)</th>
<th>Downtime (Week)</th>
</tr>
</thead>
<tbody>
<tr>
<td>90% (one nine)</td>
<td>36.53 days</td>
<td>72 hours</td>
<td>16.8 hours</td>
</tr>
<tr>
<td>99% (two nines)</td>
<td>3.65 days</td>
<td>7.20 hours</td>
<td>1.68 hours</td>
</tr>
<tr>
<td>99.9% (three nines)</td>
<td>8.77 hours</td>
<td>43.8 minutes</td>
<td>10.1 minutes</td>
</tr>
<tr>
<td>99.99% (four nines)</td>
<td>52.6 minutes</td>
<td>4.32 minutes</td>
<td>1.01 minutes</td>
</tr>
<tr>
<td>99.999% (five nines)</td>
<td>5.25 minutes</td>
<td>25.9 seconds</td>
<td>6.05 seconds</td>
</tr>
<tr>
<td>99.9999% (six nines)</td>
<td>31.56 seconds</td>
<td>2.59 seconds</td>
<td>604.8 milliseconds</td>
</tr>
<tr>
<td>99.99999% (seven nines)</td>
<td>3.15 seconds</td>
<td>263 milliseconds</td>
<td>60.5 milliseconds</td>
</tr>
<tr>
<td>99.999999% (eight nines)</td>
<td>315.6 milliseconds</td>
<td>26.3 milliseconds</td>
<td>6 milliseconds</td>
</tr>
<tr>
<td>99.9999999% (nine nines)</td>
<td>31.6 milliseconds</td>
<td>2.6 milliseconds</td>
<td>0.6 milliseconds</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Availability in Sequence vs Parallel</h2>
<p dir="auto">If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.</p>
<h3 tabindex="-1" dir="auto">
Sequence</h3>
<p dir="auto">Overall availability decreases when two components are in sequence.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Availability \space (Total) = Availability \space (Foo) * Availability \space (Bar)
$$</math-renderer></p>
<p dir="auto">For example, if both <code>Foo</code> and <code>Bar</code> each had 99.9% availability, their total availability in sequence would be 99.8%.</p>
<h3 tabindex="-1" dir="auto">
Parallel</h3>
<p dir="auto">Overall availability increases when two components are in parallel.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Availability \space (Total) = 1 - (1 - Availability \space (Foo)) * (1 - Availability \space (Bar))
$$</math-renderer></p>
<p dir="auto">For example, if both <code>Foo</code> and <code>Bar</code> each had 99.9% availability, their total availability in parallel would be 99.9999%.</p>
<h2 tabindex="-1" dir="auto">
Availability vs Reliability</h2>
<p dir="auto">If a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve high availability even with an unreliable system.</p>
<h2 tabindex="-1" dir="auto">
High availability vs Fault Tolerance</h2>
<p dir="auto">Both high availability and fault tolerance apply to methods for providing high uptime levels. However, they accomplish the objective differently.</p>
<p dir="auto">A fault-tolerant system has no service interruption but a significantly higher cost, while a highly available system has minimal service interruption. Fault-tolerance requires full hardware redundancy as if the main system fails, with no loss in uptime, another system should take over.</p>
<h2 tabindex="-1" dir="auto">
Scalability</h2>
<p dir="auto">Scalability is the measure of how well a system responds to changes by adding or removing resources to meet demands.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png" alt="scalability"></a></p>
<p dir="auto">Let's discuss different types of scaling:</p>
<h2 tabindex="-1" dir="auto">
Vertical scaling</h2>
<p dir="auto">Vertical scaling (also known as scaling up) expands a system's scalability by adding more power to an existing machine. In other words, vertical scaling refers to improving an application's capability via increasing hardware capacity.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<ul dir="auto">
<li>Simple to implement</li>
<li>Easier to manage</li>
<li>Data consistent</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<ul dir="auto">
<li>Risk of high downtime</li>
<li>Harder to upgrade</li>
<li>Can be a single point of failure</li>
</ul>
<h2 tabindex="-1" dir="auto">
Horizontal scaling</h2>
<p dir="auto">Horizontal scaling (also known as scaling out) expands a system's scale by adding more machines. It improves the performance of the server by adding more instances to the existing pool of servers, allowing the load to be distributed more evenly.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<ul dir="auto">
<li>Increased redundancy</li>
<li>Better fault tolerance</li>
<li>Flexible and efficient</li>
<li>Easier to upgrade</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<ul dir="auto">
<li>Increased complexity</li>
<li>Data inconsistency</li>
<li>Increased load on downstream services</li>
</ul>
<h2 tabindex="-1" dir="auto">
Storage</h2>
<p dir="auto">Storage is a mechanism that enables a system to retain data, either temporarily or permanently. This topic is mostly skipped over in the context of system design, however, it is important to have a basic understanding of some common types of storage techniques that can help us fine-tune our storage components. Let's discuss some important storage concepts:</p>
<h2 tabindex="-1" dir="auto">
RAID</h2>
<p dir="auto">RAID (Redundant Array of Independent Disks) is a way of storing the same data on multiple hard disks or solid-state drives (SSDs) to protect data in the case of a drive failure.</p>
<p dir="auto">There are different RAID levels, however, and not all have the goal of providing redundancy. Let's discuss some commonly used RAID levels:</p>
<ul dir="auto">
<li>
<strong>RAID 0</strong>: Also known as striping, data is split evenly across all the drives in the array.</li>
<li>
<strong>RAID 1</strong>: Also known as mirroring, at least two drives contains the exact copy of a set of data. If a drive fails, others will still work.</li>
<li>
<strong>RAID 5</strong>: Striping with parity. Requires the use of at least 3 drives, striping the data across multiple drives like RAID 0, but also has a parity distributed across the drives.</li>
<li>
<strong>RAID 6</strong>: Striping with double parity. RAID 6 is like RAID 5, but the parity data are written to two drives.</li>
<li>
<strong>RAID 10</strong>: Combines striping plus mirroring from RAID 0 and RAID 1. It provides security by mirroring all data on secondary drives while using striping across each set of drives to speed up data transfers.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Comparison</h3>
<p dir="auto">Let's compare all the features of different RAID levels:</p>
<table>
<thead>
<tr>
<th>Features</th>
<th>RAID 0</th>
<th>RAID 1</th>
<th>RAID 5</th>
<th>RAID 6</th>
<th>RAID 10</th>
</tr>
</thead>
<tbody>
<tr>
<td>Description</td>
<td>Striping</td>
<td>Mirroring</td>
<td>Striping with Parity</td>
<td>Striping with double parity</td>
<td>Striping and Mirroring</td>
</tr>
<tr>
<td>Minimum Disks</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>Read Performance</td>
<td>High</td>
<td>High</td>
<td>High</td>
<td>High</td>
<td>High</td>
</tr>
<tr>
<td>Write Performance</td>
<td>High</td>
<td>Medium</td>
<td>High</td>
<td>High</td>
<td>Medium</td>
</tr>
<tr>
<td>Cost</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
<td>Low</td>
<td>High</td>
</tr>
<tr>
<td>Fault Tolerance</td>
<td>None</td>
<td>Single-drive failure</td>
<td>Single-drive failure</td>
<td>Two-drive failure</td>
<td>Up to one disk failure in each sub-array</td>
</tr>
<tr>
<td>Capacity Utilization</td>
<td>100%</td>
<td>50%</td>
<td>67%-94%</td>
<td>50%-80%</td>
<td>50%</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Volumes</h2>
<p dir="auto">Volume is a fixed amount of storage on a disk or tape. The term volume is often used as a synonym for the storage itself, but it is possible for a single disk to contain more than one volume or a volume to span more than one disk.</p>
<h2 tabindex="-1" dir="auto">
File storage</h2>
<p dir="auto">File storage is a solution to store data as files and present it to its final users as a hierarchical directories structure. The main advantage is to provide a user-friendly solution to store and retrieve files. To locate a file in file storage, the complete path of the file is required. It is economical and easily structured and is usually found on hard drives, which means that they appear exactly the same for the user and on the hard drive.</p>
<p dir="auto">Example: <a href="https://aws.amazon.com/efs" rel="nofollow">Amazon EFS</a>, <a href="https://azure.microsoft.com/en-in/services/storage/files" rel="nofollow">Azure files</a>, <a href="https://cloud.google.com/filestore" rel="nofollow">Google Cloud Filestore</a>, etc.</p>
<h2 tabindex="-1" dir="auto">
Block storage</h2>
<p dir="auto">Block storage divides data into blocks (chunks) and stores them as separate pieces. Each block of data is given a unique identifier, which allows a storage system to place the smaller pieces of data wherever it is most convenient.</p>
<p dir="auto">Block storage also decouples data from user environments, allowing that data to be spread across multiple environments. This creates multiple paths to the data and allows the user to retrieve it quickly. When a user or application requests data from a block storage system, the underlying storage system reassembles the data blocks and presents the data to the user or application</p>
<p dir="auto">Example: <a href="https://aws.amazon.com/ebs" rel="nofollow">Amazon EBS</a>.</p>
<h2 tabindex="-1" dir="auto">
Object Storage</h2>
<p dir="auto">Object storage, which is also known as object-based storage, breaks data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems.</p>
<p dir="auto">Example: <a href="https://aws.amazon.com/s3" rel="nofollow">Amazon S3</a>, <a href="https://azure.microsoft.com/en-in/services/storage/blobs" rel="nofollow">Azure Blob Storage</a>, <a href="https://cloud.google.com/storage" rel="nofollow">Google Cloud Storage</a>, etc.</p>
<h2 tabindex="-1" dir="auto">
NAS</h2>
<p dir="auto">A NAS (Network Attached Storage) is a storage device connected to a network that allows storage and retrieval of data from a central location for authorized network users. NAS devices are flexible, meaning that as we need additional storage, we can add to what we have. It's faster, less expensive, and provides all the benefits of a public cloud on-site, giving us complete control.</p>
<h2 tabindex="-1" dir="auto">
HDFS</h2>
<p dir="auto">The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. It has many similarities with existing distributed file systems.</p>
<p dir="auto">HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks, all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance.</p>
<h2 tabindex="-1" dir="auto">
Databases and DBMS</h2>
<h2 tabindex="-1" dir="auto">
What is a Database?</h2>
<p dir="auto">A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a Database Management System (DBMS). Together, the data and the DBMS, along with the applications that are associated with them, are referred to as a database system, often shortened to just database.</p>
<h2 tabindex="-1" dir="auto">
What is DBMS?</h2>
<p dir="auto">A database typically requires a comprehensive database software program known as a Database Management System (DBMS). A DBMS serves as an interface between the database and its end-users or programs, allowing users to retrieve, update, and manage how the information is organized and optimized. A DBMS also facilitates oversight and control of databases, enabling a variety of administrative operations such as performance monitoring, tuning, and backup and recovery.</p>
<h2 tabindex="-1" dir="auto">
Components</h2>
<p dir="auto">Here are some common components found across different databases:</p>
<h3 tabindex="-1" dir="auto">
Schema</h3>
<p dir="auto">The role of a schema is to define the shape of a data structure, and specify what kinds of data can go where. Schemas can be strictly enforced across the entire database, loosely enforced on part of the database, or they might not exist at all.</p>
<h3 tabindex="-1" dir="auto">
Table</h3>
<p dir="auto">Each table contains various columns just like in a spreadsheet. A table can have as meager as two columns and upwards of a hundred or more columns, depending upon the kind of information being put in the table.</p>
<h3 tabindex="-1" dir="auto">
Column</h3>
<p dir="auto">A column contains a set of data values of a particular type, one value for each row of the database. A column may contain text values, numbers, enums, timestamps, etc.</p>
<h3 tabindex="-1" dir="auto">
Row</h3>
<p dir="auto">Data in a table is recorded in rows. There can be thousands or millions of rows in a table having any particular information.</p>
<h2 tabindex="-1" dir="auto">
Types</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png" alt="database-types"></a></p>
<p dir="auto">Below are different types of databases:</p>
<ul dir="auto">
<li><strong><a href="https://karanpratapsingh.com/courses/system-design/sql-databases" rel="nofollow">SQL</a></strong></li>
<li>
<strong><a href="https://karanpratapsingh.com/courses/system-design/nosql-databases" rel="nofollow">NoSQL</a></strong>
<ul dir="auto">
<li>Document</li>
<li>Key-value</li>
<li>Graph</li>
<li>Timeseries</li>
<li>Wide column</li>
<li>Multi-model</li>
</ul>
</li>
</ul>
<p dir="auto">SQL and NoSQL databases are broad topics and will be discussed separately in <a href="https://karanpratapsingh.com/courses/system-design/sql-databases" rel="nofollow">SQL databases</a> and <a href="https://karanpratapsingh.com/courses/system-design/nosql-databases" rel="nofollow">NoSQL databases</a>. Learn how they compare to each other in <a href="https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases" rel="nofollow">SQL vs NoSQL databases</a>.</p>
<h2 tabindex="-1" dir="auto">
Challenges</h2>
<p dir="auto">Some common challenges faced while running databases at scale:</p>
<ul dir="auto">
<li>
<strong>Absorbing significant increases in data volume</strong>: The explosion of data coming in from sensors, connected machines, and dozens of other sources.</li>
<li>
<strong>Ensuring data security</strong>: Data breaches are happening everywhere these days, it's more important than ever to ensure that data is secure but also easily accessible to users.</li>
<li>
<strong>Keeping up with demand</strong>: Companies need real-time access to their data to support timely decision-making and to take advantage of new opportunities.</li>
<li>
<strong>Managing and maintaining the database and infrastructure</strong>: As databases become more complex and data volumes grow, companies are faced with the expense of hiring additional talent to manage their databases.</li>
<li>
<strong>Removing limits on scalability</strong>: A business needs to grow if it's going to survive, and its data management must grow along with it. But it's very difficult to predict how much capacity the company will need, particularly with on-premises databases.</li>
<li>
<strong>Ensuring data residency, data sovereignty, or latency requirements</strong>: Some organizations have use cases that are better suited to run on-premises. In those cases, engineered systems that are pre-configured and pre-optimized for running the database are ideal.</li>
</ul>
<h2 tabindex="-1" dir="auto">
SQL databases</h2>
<p dir="auto">A SQL (or relational) database is a collection of data items with pre-defined relationships between them. These items are organized as a set of tables with columns and rows. Tables are used to hold information about the objects to be represented in the database. Each column in a table holds a certain kind of data and a field stores the actual value of an attribute. The rows in the table represent a collection of related values of one object or entity.</p>
<p dir="auto">Each row in a table could be marked with a unique identifier called a primary key, and rows among multiple tables can be made related using foreign keys. This data can be accessed in many different ways without re-organizing the database tables themselves. SQL databases usually follow the <a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid" rel="nofollow">ACID consistency model</a>.</p>
<h2 tabindex="-1" dir="auto">
Materialized views</h2>
<p dir="auto">A materialized view is a pre-computed data set derived from a query specification and stored for later use. Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view. This performance difference can be significant when a query is run frequently or is sufficiently complex.</p>
<p dir="auto">It also enables data subsetting and improves the performance of complex queries that run on large data sets which reduces network loads. There are other uses of materialized views, but they are mostly used for performance and replication.</p>
<h2 tabindex="-1" dir="auto">
N+1 query problem</h2>
<p dir="auto">The N+1 query problem happens when the data access layer executes N additional SQL statements to fetch the same data that could have been retrieved when executing the primary SQL query. The larger the value of N, the more queries will be executed, the larger the performance impact.</p>
<p dir="auto">This is commonly seen in GraphQL and ORM (Object-Relational Mapping) tools and can be addressed by optimizing the SQL query or using a dataloader that batches consecutive requests and makes a single data request under the hood.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's look at some advantages of using relational databases:</p>
<ul dir="auto">
<li>Simple and accurate</li>
<li>Accessibility</li>
<li>Data consistency</li>
<li>Flexibility</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Below are the disadvantages of relational databases:</p>
<ul dir="auto">
<li>Expensive to maintain</li>
<li>Difficult schema evolution</li>
<li>Performance hits (join, denormalization, etc.)</li>
<li>Difficult to scale due to poor horizontal scalability</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Here are some commonly used relational databases:</p>
<ul dir="auto">
<li><a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a></li>
<li><a href="https://www.mysql.com/" rel="nofollow">MySQL</a></li>
<li><a href="https://mariadb.org/" rel="nofollow">MariaDB</a></li>
<li><a href="https://aws.amazon.com/rds/aurora" rel="nofollow">Amazon Aurora</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
NoSQL databases</h2>
<p dir="auto">NoSQL is a broad category that includes any database that doesn't use SQL as its primary data access language. These types of databases are also sometimes referred to as non-relational databases. Unlike in relational databases, data in a NoSQL database doesn't have to conform to a pre-defined schema. NoSQL databases follow <a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base" rel="nofollow">BASE consistency model</a>.</p>
<p dir="auto">Below are different types of NoSQL databases:</p>
<h3 tabindex="-1" dir="auto">
Document</h3>
<p dir="auto">A document database (also known as a document-oriented database or a document store) is a database that stores information in documents. They are general-purpose databases that serve a variety of use cases for both transactional and analytical applications.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Intuitive and flexible</li>
<li>Easy horizontal scaling</li>
<li>Schemaless</li>
</ul>
<p dir="auto"><strong>Disadvantages</strong></p>
<ul dir="auto">
<li>Schemaless</li>
<li>Non-relational</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://www.mongodb.com/" rel="nofollow">MongoDB</a></li>
<li><a href="https://aws.amazon.com/documentdb" rel="nofollow">Amazon DocumentDB</a></li>
<li><a href="https://couchdb.apache.org/" rel="nofollow">CouchDB</a></li>
</ul>
<h3 tabindex="-1" dir="auto">
Key-value</h3>
<p dir="auto">One of the simplest types of NoSQL databases, key-value databases save data as a group of key-value pairs made up of two data items each. They're also sometimes referred to as a key-value store.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Simple and performant</li>
<li>Highly scalable for high volumes of traffic</li>
<li>Session management</li>
<li>Optimized lookups</li>
</ul>
<p dir="auto"><strong>Disadvantages</strong></p>
<ul dir="auto">
<li>Basic CRUD</li>
<li>Values can't be filtered</li>
<li>Lacks indexing and scanning capabilities</li>
<li>Not optimized for complex queries</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://redis.io/" rel="nofollow">Redis</a></li>
<li><a href="https://memcached.org/" rel="nofollow">Memcached</a></li>
<li><a href="https://aws.amazon.com/dynamodb" rel="nofollow">Amazon DynamoDB</a></li>
<li><a href="https://aerospike.com/" rel="nofollow">Aerospike</a></li>
</ul>
<h3 tabindex="-1" dir="auto">
Graph</h3>
<p dir="auto">A graph database is a NoSQL database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data instead of tables or documents.</p>
<p dir="auto">The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Query speed</li>
<li>Agile and flexible</li>
<li>Explicit data representation</li>
</ul>
<p dir="auto"><strong>Disadvantages</strong></p>
<ul dir="auto">
<li>Complex</li>
<li>No standardized query language</li>
</ul>
<p dir="auto"><strong>Use cases</strong></p>
<ul dir="auto">
<li>Fraud detection</li>
<li>Recommendation engines</li>
<li>Social networks</li>
<li>Network mapping</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://neo4j.com/" rel="nofollow">Neo4j</a></li>
<li><a href="https://www.arangodb.com/" rel="nofollow">ArangoDB</a></li>
<li><a href="https://aws.amazon.com/neptune" rel="nofollow">Amazon Neptune</a></li>
<li><a href="https://janusgraph.org/" rel="nofollow">JanusGraph</a></li>
</ul>
<h3 tabindex="-1" dir="auto">
Time series</h3>
<p dir="auto">A time-series database is a database optimized for time-stamped, or time series, data.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Fast insertion and retrieval</li>
<li>Efficient data storage</li>
</ul>
<p dir="auto"><strong>Use cases</strong></p>
<ul dir="auto">
<li>IoT data</li>
<li>Metrics analysis</li>
<li>Application monitoring</li>
<li>Understand financial trends</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://www.influxdata.com/" rel="nofollow">InfluxDB</a></li>
<li><a href="https://druid.apache.org/" rel="nofollow">Apache Druid</a></li>
</ul>
<h3 tabindex="-1" dir="auto">
Wide column</h3>
<p dir="auto">Wide column databases, also known as wide column stores, are schema-agnostic. Data is stored in column families, rather than in rows and columns.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Highly scalable, can handle petabytes of data</li>
<li>Ideal for real-time big data applications</li>
</ul>
<p dir="auto"><strong>Disadvantages</strong></p>
<ul dir="auto">
<li>Expensive</li>
<li>Increased write time</li>
</ul>
<p dir="auto"><strong>Use cases</strong></p>
<ul dir="auto">
<li>Business analytics</li>
<li>Attribute-based data storage</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://cloud.google.com/bigtable" rel="nofollow">BigTable</a></li>
<li><a href="https://cassandra.apache.org/" rel="nofollow">Apache Cassandra</a></li>
<li><a href="https://www.scylladb.com/" rel="nofollow">ScyllaDB</a></li>
</ul>
<h3 tabindex="-1" dir="auto">
Multi-model</h3>
<p dir="auto">Multi-model databases combine different database models (i.e. relational, graph, key-value, document, etc.) into a single, integrated backend. This means they can accommodate various data types, indexes, queries, and store data in more than one model.</p>
<p dir="auto"><strong>Advantages</strong></p>
<ul dir="auto">
<li>Flexibility</li>
<li>Suitable for complex projects</li>
<li>Data consistent</li>
</ul>
<p dir="auto"><strong>Disadvantages</strong></p>
<ul dir="auto">
<li>Complex</li>
<li>Less mature</li>
</ul>
<p dir="auto"><strong>Examples</strong></p>
<ul dir="auto">
<li><a href="https://www.arangodb.com/" rel="nofollow">ArangoDB</a></li>
<li><a href="https://azure.microsoft.com/en-in/services/cosmos-db" rel="nofollow">Azure Cosmos DB</a></li>
<li><a href="https://www.couchbase.com/" rel="nofollow">Couchbase</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
SQL vs NoSQL databases</h2>
<p dir="auto">In the world of databases, there are two main types of solutions, SQL (relational) and NoSQL (non-relational) databases. Both of them differ in the way they were built, the kind of information they store, and how they store it. Relational databases are structured and have predefined schemas while non-relational databases are unstructured, distributed, and have a dynamic schema.</p>
<h2 tabindex="-1" dir="auto">
High-level differences</h2>
<p dir="auto">Here are some high-level differences between SQL and NoSQL:</p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">SQL stores data in tables, where each row represents an entity and each column represents a data point about that entity.</p>
<p dir="auto">NoSQL databases have different data storage models such as key-value, graph, document, etc.</p>
<h3 tabindex="-1" dir="auto">
Schema</h3>
<p dir="auto">In SQL, each record conforms to a fixed schema, meaning the columns must be decided and chosen before data entry and each row must have data for each column. The schema can be altered later, but it involves modifying the database using migrations.</p>
<p dir="auto">Whereas in NoSQL, schemas are dynamic. Fields can be added on the fly, and each <em>record</em> (or equivalent) doesn't have to contain data for each <em>field</em>.</p>
<h3 tabindex="-1" dir="auto">
Querying</h3>
<p dir="auto">SQL databases use SQL (structured query language) for defining and manipulating the data, which is very powerful.</p>
<p dir="auto">In a NoSQL database, queries are focused on a collection of documents. Different databases have different syntax for querying.</p>
<h3 tabindex="-1" dir="auto">
Scalability</h3>
<p dir="auto">In most common situations, SQL databases are vertically scalable, which can get very expensive. It is possible to scale a relational database across multiple servers, but this is a challenging and time-consuming process.</p>
<p dir="auto">On the other hand, NoSQL databases are horizontally scalable, meaning we can add more servers easily to our NoSQL database infrastructure to handle large traffic. Any cheap commodity hardware or cloud instances can host NoSQL databases, thus making it a lot more cost-effective than vertical scaling. A lot of NoSQL technologies also distribute data across servers automatically.</p>
<h3 tabindex="-1" dir="auto">
Reliability</h3>
<p dir="auto">The vast majority of relational databases are ACID compliant. So, when it comes to data reliability and a safe guarantee of performing transactions, SQL databases are still the better bet.</p>
<p dir="auto">Most of the NoSQL solutions sacrifice ACID compliance for performance and scalability.</p>
<h2 tabindex="-1" dir="auto">
Reasons</h2>
<p dir="auto">As always we should always pick the technology that fits the requirements better. So, let's look at some reasons for picking SQL or NoSQL based database:</p>
<p dir="auto"><strong>For SQL</strong></p>
<ul dir="auto">
<li>Structured data with strict schema</li>
<li>Relational data</li>
<li>Need for complex joins</li>
<li>Transactions</li>
<li>Lookups by index are very fast</li>
</ul>
<p dir="auto"><strong>For NoSQL</strong></p>
<ul dir="auto">
<li>Dynamic or flexible schema</li>
<li>Non-relational data</li>
<li>No need for complex joins</li>
<li>Very data-intensive workload</li>
<li>Very high throughput for IOPS</li>
</ul>
<h2 tabindex="-1" dir="auto">
Database Replication</h2>
<p dir="auto">Replication is a process that involves sharing information to ensure consistency between redundant resources such as multiple databases, to improve reliability, fault-tolerance, or accessibility.</p>
<h2 tabindex="-1" dir="auto">
Master-Slave Replication</h2>
<p dir="auto">The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png" alt="master-slave-replication"></a></p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<ul dir="auto">
<li>Backups of the entire database of relatively no impact on the master.</li>
<li>Applications can read from the slave(s) without impacting the master.</li>
<li>Slaves can be taken offline and synced back to the master without any downtime.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<ul dir="auto">
<li>Replication adds more hardware and additional complexity.</li>
<li>Downtime and possibly loss of data when a master fails.</li>
<li>All writes also have to be made to the master in a master-slave architecture.</li>
<li>The more read slaves, the more we have to replicate, which will increase replication lag.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Master-Master Replication</h2>
<p dir="auto">Both masters serve reads/writes and coordinate with each other. If either master goes down, the system can continue to operate with both reads and writes.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png" alt="master-master-replication"></a></p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<ul dir="auto">
<li>Applications can read from both masters.</li>
<li>Distributes write load across both master nodes.</li>
<li>Simple, automatic, and quick failover.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<ul dir="auto">
<li>Not as simple as master-slave to configure and deploy.</li>
<li>Either loosely consistent or have increased write latency due to synchronization.</li>
<li>Conflict resolution comes into play as more write nodes are added and as latency increases.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Synchronous vs Asynchronous replication</h2>
<p dir="auto">The primary difference between synchronous and asynchronous replication is how the data is written to the replica. In synchronous replication, data is written to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized.</p>
<p dir="auto">In contrast, asynchronous replication copies the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis and it is more cost-effective.</p>
<h2 tabindex="-1" dir="auto">
Indexes</h2>
<p dir="auto">Indexes are well known when it comes to databases, they are used to improve the speed of data retrieval operations on the data store. An index makes the trade-offs of increased storage overhead, and slower writes (since we not only have to write the data but also have to update the index) for the benefit of faster reads. Indexes are used to quickly locate data without having to examine every row in a database table. Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access to ordered records.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png" alt="indexes"></a></p>
<p dir="auto">An index is a data structure that can be perceived as a table of contents that points us to the location where actual data lives. So when we create an index on a column of a table, we store that column and a pointer to the whole row in the index. Indexes are also used to create different views of the same data. For large data sets, this is an excellent way to specify different filters or sorting schemes without resorting to creating multiple additional copies of the data.</p>
<p dir="auto">One quality that database indexes can have is that they can be <strong>dense</strong> or <strong>sparse</strong>. Each of these index qualities comes with its own trade-offs. Let's look at how each index type would work:</p>
<h2 tabindex="-1" dir="auto">
Dense Index</h2>
<p dir="auto">In a dense index, an index record is created for every row of the table. Records can be located directly as each record of the index holds the search key value and the pointer to the actual record.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png" alt="dense-index"></a></p>
<p dir="auto">Dense indexes require more maintenance than sparse indexes at write-time. Since every row must have an entry, the database must maintain the index on inserts, updates, and deletes. Having an entry for every row also means that dense indexes will require more memory. The benefit of a dense index is that values can be quickly found with just a binary search. Dense indexes also do not impose any ordering requirements on the data.</p>
<h2 tabindex="-1" dir="auto">
Sparse Index</h2>
<p dir="auto">In a sparse index, records are created only for some of the records.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png" alt="sparse-index"></a></p>
<p dir="auto">Sparse indexes require less maintenance than dense indexes at write-time since they only contain a subset of the values. This lighter maintenance burden means that inserts, updates, and deletes will be faster. Having fewer entries also means that the index will use less memory. Finding data is slower since a scan across the page typically follows the binary search. Sparse indexes are also optional when working with ordered data.</p>
<h2 tabindex="-1" dir="auto">
Normalization and Denormalization</h2>
<h2 tabindex="-1" dir="auto">
Terms</h2>
<p dir="auto">Before we go any further, let's look at some commonly used terms in normalization and denormalization.</p>
<h3 tabindex="-1" dir="auto">
Keys</h3>
<p dir="auto"><strong>Primary key</strong>: Column or group of columns that can be used to uniquely identify every row of the table.</p>
<p dir="auto"><strong>Composite key</strong>: A primary key made up of multiple columns.</p>
<p dir="auto"><strong>Super key</strong>: Set of all keys that can uniquely identify all the rows present in a table.</p>
<p dir="auto"><strong>Candidate key</strong>: Attributes that identify rows uniquely in a table.</p>
<p dir="auto"><strong>Foreign key</strong>: It is a reference to a primary key of another table.</p>
<p dir="auto"><strong>Alternate key</strong>: Keys that are not primary keys are known as alternate keys.</p>
<p dir="auto"><strong>Surrogate key</strong>: A system-generated value that uniquely identifies each entry in a table when no other column was able to hold properties of a primary key.</p>
<h3 tabindex="-1" dir="auto">
Dependencies</h3>
<p dir="auto"><strong>Partial dependency</strong>: Occurs when the primary key determines some other attributes.</p>
<p dir="auto"><strong>Functional dependency</strong>: It is a relationship that exists between two attributes, typically between the primary key and non-key attribute within a table.</p>
<p dir="auto"><strong>Transitive functional dependency</strong>: Occurs when some non-key attribute determines some other attribute.</p>
<h3 tabindex="-1" dir="auto">
Anomalies</h3>
<p dir="auto">Database anomaly happens when there is a flaw in the database due to incorrect planning or storing everything in a flat database. This is generally addressed by the process of normalization.</p>
<p dir="auto">There are three types of database anomalies:</p>
<p dir="auto"><strong>Insertion anomaly</strong>: Occurs when we are not able to insert certain attributes in the database without the presence of other attributes.</p>
<p dir="auto"><strong>Update anomaly</strong>: Occurs in case of data redundancy and partial update. In other words, a correct update of the database needs other actions such as addition, deletion, or both.</p>
<p dir="auto"><strong>Deletion anomaly</strong>: Occurs where deletion of some data requires deletion of other data.</p>
<p dir="auto"><strong>Example</strong></p>
<p dir="auto">Let's consider the following table which is not normalized:</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Name</th>
<th>Role</th>
<th>Team</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Peter</td>
<td>Software Engineer</td>
<td>A</td>
</tr>
<tr>
<td>2</td>
<td>Brian</td>
<td>DevOps Engineer</td>
<td>B</td>
</tr>
<tr>
<td>3</td>
<td>Hailey</td>
<td>Product Manager</td>
<td>C</td>
</tr>
<tr>
<td>4</td>
<td>Hailey</td>
<td>Product Manager</td>
<td>C</td>
</tr>
<tr>
<td>5</td>
<td>Steve</td>
<td>Frontend Engineer</td>
<td>D</td>
</tr>
</tbody>
</table>
<p dir="auto">Let's imagine, we hired a new person "John" but they might not be assigned a team immediately. This will cause an <em>insertion anomaly</em> as the team attribute is not yet present.</p>
<p dir="auto">Next, let's say Hailey from Team C got promoted, to reflect that change in the database, we will need to update 2 rows to maintain consistency which can cause an <em>update anomaly</em>.</p>
<p dir="auto">Finally, we would like to remove Team B but to do that we will also need to remove additional information such as name and role, this is an example of a <em>deletion anomaly</em>.</p>
<h2 tabindex="-1" dir="auto">
Normalization</h2>
<p dir="auto">Normalization is the process of organizing data in a database. This includes creating tables and establishing relationships between those tables according to rules designed both to protect the data and to make the database more flexible by eliminating redundancy and inconsistent dependency.</p>
<h3 tabindex="-1" dir="auto">
Why do we need normalization?</h3>
<p dir="auto">The goal of normalization is to eliminate redundant data and ensure data is consistent. A fully normalized database allows its structure to be extended to accommodate new types of data without changing the existing structure too much. As a result, applications interacting with the database are minimally affected.</p>
<h3 tabindex="-1" dir="auto">
Normal forms</h3>
<p dir="auto">Normal forms are a series of guidelines to ensure that the database is normalized. Let's discuss some essential normal forms:</p>
<p dir="auto"><strong>1NF</strong></p>
<p dir="auto">For a table to be in the first normal form (1NF), it should follow the following rules:</p>
<ul dir="auto">
<li>Repeating groups are not permitted.</li>
<li>Identify each set of related data with a primary key.</li>
<li>Set of related data should have a separate table.</li>
<li>Mixing data types in the same column is not permitted.</li>
</ul>
<p dir="auto"><strong>2NF</strong></p>
<p dir="auto">For a table to be in the second normal form (2NF), it should follow the following rules:</p>
<ul dir="auto">
<li>Satisfies the first normal form (1NF).</li>
<li>Should not have any partial dependency.</li>
</ul>
<p dir="auto"><strong>3NF</strong></p>
<p dir="auto">For a table to be in the third normal form (3NF), it should follow the following rules:</p>
<ul dir="auto">
<li>Satisfies the second normal form (2NF).</li>
<li>Transitive functional dependencies are not permitted.</li>
</ul>
<p dir="auto"><strong>BCNF</strong></p>
<p dir="auto">Boyce-Codd normal form (or BCNF) is a slightly stronger version of the third normal form (3NF) used to address certain types of anomalies not dealt with by 3NF as originally defined. Sometimes it is also known as the 3.5 normal form (3.5NF).</p>
<p dir="auto">For a table to be in the Boyce-Codd normal form (BCNF), it should follow the following rules:</p>
<ul dir="auto">
<li>Satisfied the third normal form (3NF).</li>
<li>For every functional dependency X → Y, X should be the super key.</li>
</ul>
<p dir="auto"><em>There are more normal forms such as 4NF, 5NF, and 6NF but we won't discuss them here. Check out this <a href="https://www.youtube.com/watch?v=GFQaEYEc8_8" rel="nofollow">amazing video</a> that goes into detail.</em></p>
<p dir="auto">In a relational database, a relation is often described as <em>"normalized"</em> if it meets the third normal form. Most 3NF relations are free of insertion, update, and deletion anomalies.</p>
<p dir="auto">As with many formal rules and specifications, real-world scenarios do not always allow for perfect compliance. If you decide to violate one of the first three rules of normalization, make sure that your application anticipates any problems that could occur, such as redundant data and inconsistent dependencies.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Here are some advantages of normalization:</p>
<ul dir="auto">
<li>Reduces data redundancy.</li>
<li>Better data design.</li>
<li>Increases data consistency.</li>
<li>Enforces referential integrity.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Let's look at some disadvantages of normalization:</p>
<ul dir="auto">
<li>Data design is complex.</li>
<li>Slower performance.</li>
<li>Maintenance overhead.</li>
<li>Require more joins.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Denormalization</h2>
<p dir="auto">Denormalization is a database optimization technique in which we add redundant data to one or more tables. This can help us avoid costly joins in a relational database. It attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins.</p>
<p dir="auto">Once data becomes distributed with techniques such as federation and sharding, managing joins across the network further increases complexity. Denormalization might circumvent the need for such complex joins.</p>
<p dir="auto"><em>Note: Denormalization does not mean reversing normalization.</em></p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Let's look at some advantages of denormalization:</p>
<ul dir="auto">
<li>Retrieving data is faster.</li>
<li>Writing queries is easier.</li>
<li>Reduction in number of tables.</li>
<li>Convenient to manage.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Below are some disadvantages of denormalization:</p>
<ul dir="auto">
<li>Expensive inserts and updates.</li>
<li>Increases complexity of database design.</li>
<li>Increases data redundancy.</li>
<li>More chances of data inconsistency.</li>
</ul>
<h2 tabindex="-1" dir="auto">
ACID and BASE consistency models</h2>
<p dir="auto">Let's discuss the ACID and BASE consistency models.</p>
<h2 tabindex="-1" dir="auto">
ACID</h2>
<p dir="auto">The term ACID stands for Atomicity, Consistency, Isolation, and Durability. ACID properties are used for maintaining data integrity during transaction processing.</p>
<p dir="auto">In order to maintain consistency before and after a transaction relational databases follow ACID properties. Let us understand these terms:</p>
<h3 tabindex="-1" dir="auto">
Atomic</h3>
<p dir="auto">All operations in a transaction succeed or every operation is rolled back.</p>
<h3 tabindex="-1" dir="auto">
Consistent</h3>
<p dir="auto">On the completion of a transaction, the database is structurally sound.</p>
<h3 tabindex="-1" dir="auto">
Isolated</h3>
<p dir="auto">Transactions do not contend with one another. Contentious access to data is moderated by the database so that transactions appear to run sequentially.</p>
<h3 tabindex="-1" dir="auto">
Durable</h3>
<p dir="auto">Once the transaction has been completed and the writes and updates have been written to the disk, it will remain in the system even if a system failure occurs.</p>
<h2 tabindex="-1" dir="auto">
BASE</h2>
<p dir="auto">With the increasing amount of data and high availability requirements, the approach to database design has also changed dramatically. To increase the ability to scale and at the same time be highly available, we move the logic from the database to separate servers. In this way, the database becomes more independent and focused on the actual process of storing data.</p>
<p dir="auto">In the NoSQL database world, ACID transactions are less common as some databases have loosened the requirements for immediate consistency, data freshness, and accuracy in order to gain other benefits, like scale and resilience.</p>
<p dir="auto">BASE properties are much looser than ACID guarantees, but there isn't a direct one-for-one mapping between the two consistency models. Let us understand these terms:</p>
<h3 tabindex="-1" dir="auto">
Basic Availability</h3>
<p dir="auto">The database appears to work most of the time.</p>
<h3 tabindex="-1" dir="auto">
Soft-state</h3>
<p dir="auto">Stores don't have to be write-consistent, nor do different replicas have to be mutually consistent all the time.</p>
<h3 tabindex="-1" dir="auto">
Eventual consistency</h3>
<p dir="auto">The data might not be consistent immediately but eventually, it becomes consistent. Reads in the system are still possible even though they may not give the correct response due to inconsistency.</p>
<h2 tabindex="-1" dir="auto">
ACID vs BASE Trade-offs</h2>
<p dir="auto">There's no right answer to whether our application needs an ACID or a BASE consistency model. Both the models have been designed to satisfy different requirements. While choosing a database we need to keep the properties of both the models and the requirements of our application in mind.</p>
<p dir="auto">Given BASE's loose consistency, developers need to be more knowledgeable and rigorous about consistent data if they choose a BASE store for their application. It's essential to be familiar with the BASE behavior of the chosen database and work within those constraints.</p>
<p dir="auto">On the other hand, planning around BASE limitations can sometimes be a major disadvantage when compared to the simplicity of ACID transactions. A fully ACID database is the perfect fit for use cases where data reliability and consistency are essential.</p>
<h2 tabindex="-1" dir="auto">
CAP Theorem</h2>
<p dir="auto">CAP theorem states that a distributed system can deliver only two of the three desired characteristics Consistency, Availability, and Partition tolerance (CAP).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png" alt="cap-theorem"></a></p>
<p dir="auto">Let's take a detailed look at the three distributed system characteristics to which the CAP theorem refers.</p>
<h3 tabindex="-1" dir="auto">
Consistency</h3>
<p dir="auto">Consistency means that all clients see the same data at the same time, no matter which node they connect to. For this to happen, whenever data is written to one node, it must be instantly forwarded or replicated across all the nodes in the system before the write is deemed "successful".</p>
<h3 tabindex="-1" dir="auto">
Availability</h3>
<p dir="auto">Availability means that any client making a request for data gets a response, even if one or more nodes are down.</p>
<h3 tabindex="-1" dir="auto">
Partition tolerance</h3>
<p dir="auto">Partition tolerance means the system continues to work despite message loss or partial failure. A system that is partition-tolerant can sustain any amount of network failure that doesn't result in a failure of the entire network. Data is sufficiently replicated across combinations of nodes and networks to keep the system up through intermittent outages.</p>
<h2 tabindex="-1" dir="auto">
Consistency-Availability Tradeoff</h2>
<p dir="auto">We live in a physical world and can't guarantee the stability of a network, so distributed databases must choose Partition Tolerance (P). This implies a tradeoff between Consistency (C) and Availability (A).</p>
<h3 tabindex="-1" dir="auto">
CA database</h3>
<p dir="auto">A CA database delivers consistency and availability across all nodes. It can't do this if there is a partition between any two nodes in the system, and therefore can't deliver fault tolerance.</p>
<p dir="auto"><strong>Example</strong>: <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a>, <a href="https://mariadb.org/" rel="nofollow">MariaDB</a>.</p>
<h3 tabindex="-1" dir="auto">
CP database</h3>
<p dir="auto">A CP database delivers consistency and partition tolerance at the expense of availability. When a partition occurs between any two nodes, the system has to shut down the non-consistent node until the partition is resolved.</p>
<p dir="auto"><strong>Example</strong>: <a href="https://www.mongodb.com/" rel="nofollow">MongoDB</a>, <a href="https://hbase.apache.org/" rel="nofollow">Apache HBase</a>.</p>
<h3 tabindex="-1" dir="auto">
AP database</h3>
<p dir="auto">An AP database delivers availability and partition tolerance at the expense of consistency. When a partition occurs, all nodes remain available but those at the wrong end of a partition might return an older version of data than others. When the partition is resolved, the AP databases typically re-syncs the nodes to repair all inconsistencies in the system.</p>
<p dir="auto"><strong>Example</strong>: <a href="https://cassandra.apache.org/" rel="nofollow">Apache Cassandra</a>, <a href="https://couchdb.apache.org/" rel="nofollow">CouchDB</a>.</p>
<h2 tabindex="-1" dir="auto">
PACELC Theorem</h2>
<p dir="auto">The PACELC theorem is an extension of the CAP theorem. The CAP theorem states that in the case of network partitioning (P) in a distributed system, one has to choose between Availability (A) and Consistency (C).</p>
<p dir="auto">PACELC extends the CAP theorem by introducing latency (L) as an additional attribute of a distributed system. The theorem states that else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).</p>
<p dir="auto"><em>The PACELC theorem was first described by <a href="https://scholar.google.com/citations?user=zxeEF2gAAAAJ" rel="nofollow">Daniel J. Abadi</a>.</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png" alt="pacelc-theorem"></a></p>
<p dir="auto">PACELC theorem was developed to address a key limitation of the CAP theorem as it makes no provision for performance or latency.</p>
<p dir="auto">For example, according to the CAP theorem, a database can be considered Available if a query returns a response after 30 days. Obviously, such latency would be unacceptable for any real-world application.</p>
<h2 tabindex="-1" dir="auto">
Transactions</h2>
<p dir="auto">A transaction is a series of database operations that are considered to be a <em>"single unit of work"</em>. The operations in a transaction either all succeed, or they all fail. In this way, the notion of a transaction supports data integrity when part of a system fails. Not all databases choose to support ACID transactions, usually because they are prioritizing other optimizations that are hard or theoretically impossible to implement together.</p>
<p dir="auto"><em>Usually, relational databases support ACID transactions, and non-relational databases don't (there are exceptions).</em></p>
<h2 tabindex="-1" dir="auto">
States</h2>
<p dir="auto">A transaction in a database can be in one of the following states:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png" alt="transaction-states"></a></p>
<h3 tabindex="-1" dir="auto">
Active</h3>
<p dir="auto">In this state, the transaction is being executed. This is the initial state of every transaction.</p>
<h3 tabindex="-1" dir="auto">
Partially Committed</h3>
<p dir="auto">When a transaction executes its final operation, it is said to be in a partially committed state.</p>
<h3 tabindex="-1" dir="auto">
Committed</h3>
<p dir="auto">If a transaction executes all its operations successfully, it is said to be committed. All its effects are now permanently established on the database system.</p>
<h3 tabindex="-1" dir="auto">
Failed</h3>
<p dir="auto">The transaction is said to be in a failed state if any of the checks made by the database recovery system fails. A failed transaction can no longer proceed further.</p>
<h3 tabindex="-1" dir="auto">
Aborted</h3>
<p dir="auto">If any of the checks fail and the transaction has reached a failed state, then the recovery manager rolls back all its write operations on the database to bring the database back to its original state where it was prior to the execution of the transaction. Transactions in this state are aborted.</p>
<p dir="auto">The database recovery module can select one of the two operations after a transaction aborts:</p>
<ul dir="auto">
<li>Restart the transaction</li>
<li>Kill the transaction</li>
</ul>
<h3 tabindex="-1" dir="auto">
Terminated</h3>
<p dir="auto">If there isn't any roll-back or the transaction comes from the <em>committed state</em>, then the system is consistent and ready for a new transaction and the old transaction is terminated.</p>
<h2 tabindex="-1" dir="auto">
Distributed Transactions</h2>
<p dir="auto">A distributed transaction is a set of operations on data that is performed across two or more databases. It is typically coordinated across separate nodes connected by a network, but may also span multiple databases on a single server.</p>
<h2 tabindex="-1" dir="auto">
Why do we need distributed transactions?</h2>
<p dir="auto">Unlike an ACID transaction on a single database, a distributed transaction involves altering data on multiple databases. Consequently, distributed transaction processing is more complicated, because the database must coordinate the committing or rollback of the changes in a transaction as a self-contained unit.</p>
<p dir="auto">In other words, all the nodes must commit, or all must abort and the entire transaction rolls back. This is why we need distributed transactions.</p>
<p dir="auto">Now, let's look at some popular solutions for distributed transactions:</p>
<h2 tabindex="-1" dir="auto">
Two-Phase commit</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png" alt="two-phase-commit"></a></p>
<p dir="auto">The two-phase commit (2PC) protocol is a distributed algorithm that coordinates all the processes that participate in a distributed transaction on whether to commit or abort (roll back) the transaction.</p>
<p dir="auto">This protocol achieves its goal even in many cases of temporary system failure and is thus widely used. However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome.</p>
<p dir="auto">This protocol requires a coordinator node, which basically coordinates and oversees the transaction across different nodes. The coordinator tries to establish the consensus among a set of processes in two phases, hence the name.</p>
<h3 tabindex="-1" dir="auto">
Phases</h3>
<p dir="auto">Two-phase commit consists of the following phases:</p>
<p dir="auto"><strong>Prepare phase</strong></p>
<p dir="auto">The prepare phase involves the coordinator node collecting consensus from each of the participant nodes. The transaction will be aborted unless each of the nodes responds that they're <em>prepared</em>.</p>
<p dir="auto"><strong>Commit phase</strong></p>
<p dir="auto">If all participants respond to the coordinator that they are <em>prepared</em>, then the coordinator asks all the nodes to commit the transaction. If a failure occurs, the transaction will be rolled back.</p>
<h3 tabindex="-1" dir="auto">
Problems</h3>
<p dir="auto">Following problems may arise in the two-phase commit protocol:</p>
<ul dir="auto">
<li>What if one of the nodes crashes?</li>
<li>What if the coordinator itself crashes?</li>
<li>It is a blocking protocol.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Three-phase commit</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png" alt="three-phase-commit"></a></p>
<p dir="auto">Three-phase commit (3PC) is an extension of the two-phase commit where the commit phase is split into two phases. This helps with the blocking problem that occurs in the two-phase commit protocol.</p>
<h3 tabindex="-1" dir="auto">
Phases</h3>
<p dir="auto">Three-phase commit consists of the following phases:</p>
<p dir="auto"><strong>Prepare phase</strong></p>
<p dir="auto">This phase is the same as the two-phase commit.</p>
<p dir="auto"><strong>Pre-commit phase</strong></p>
<p dir="auto">Coordinator issues the pre-commit message and all the participating nodes must acknowledge it. If a participant fails to receive this message in time, then the transaction is aborted.</p>
<p dir="auto"><strong>Commit phase</strong></p>
<p dir="auto">This step is also similar to the two-phase commit protocol.</p>
<h3 tabindex="-1" dir="auto">
Why is the Pre-commit phase helpful?</h3>
<p dir="auto">The pre-commit phase accomplishes the following:</p>
<ul dir="auto">
<li>If the participant nodes are found in this phase, that means that <em>every</em> participant has completed the first phase. The completion of prepare phase is guaranteed.</li>
<li>Every phase can now time out and avoid indefinite waits.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Sagas</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png" alt="sagas"></a></p>
<p dir="auto">A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.</p>
<h3 tabindex="-1" dir="auto">
Coordination</h3>
<p dir="auto">There are two common implementation approaches:</p>
<ul dir="auto">
<li>
<strong>Choreography</strong>: Each local transaction publishes domain events that trigger local transactions in other services.</li>
<li>
<strong>Orchestration</strong>: An orchestrator tells the participants what local transactions to execute.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Problems</h3>
<ul dir="auto">
<li>The Saga pattern is particularly hard to debug.</li>
<li>There's a risk of cyclic dependency between saga participants.</li>
<li>Lack of participant data isolation imposes durability challenges.</li>
<li>Testing is difficult because all services must be running to simulate a transaction.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Sharding</h2>
<p dir="auto">Before we discuss sharding, let's talk about data partitioning:</p>
<h2 tabindex="-1" dir="auto">
Data Partitioning</h2>
<p dir="auto">Data partitioning is a technique to break up a database into many smaller parts. It is the process of splitting up a database or a table across multiple machines to improve the manageability, performance, and availability of a database.</p>
<h3 tabindex="-1" dir="auto">
Methods</h3>
<p dir="auto">There are many different ways one could use to decide how to break up an application database into multiple smaller DBs. Below are two of the most popular methods used by various large-scale applications:</p>
<p dir="auto"><strong>Horizontal Partitioning (or Sharding)</strong></p>
<p dir="auto">In this strategy, we split the table data horizontally based on the range of values defined by the <em>partition key</em>. It is also referred to as <strong><em>database sharding</em></strong>.</p>
<p dir="auto"><strong>Vertical Partitioning</strong></p>
<p dir="auto">In vertical partitioning, we partition the data vertically based on columns. We divide tables into relatively smaller tables with few elements, and each part is present in a separate partition.</p>
<p dir="auto">In this tutorial, we will specifically focus on sharding.</p>
<h2 tabindex="-1" dir="auto">
What is sharding?</h2>
<p dir="auto">Sharding is a database architecture pattern related to <em>horizontal partitioning</em>, which is the practice of separating one table's rows into multiple different tables, known as <em>partitions</em> or <em>shards</em>. Each partition has the same schema and columns, but also a subset of the shared data. Likewise, the data held in each is unique and independent of the data held in other partitions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png" alt="sharding"></a></p>
<p dir="auto">The justification for data sharding is that, after a certain point, it is cheaper and more feasible to scale horizontally by adding more machines than to scale it vertically by adding powerful servers. Sharding can be implemented at both application or the database level.</p>
<h2 tabindex="-1" dir="auto">
Partitioning criteria</h2>
<p dir="auto">There are a large number of criteria available for data partitioning. Some most commonly used criteria are:</p>
<h3 tabindex="-1" dir="auto">
Hash-Based</h3>
<p dir="auto">This strategy divides the rows into different partitions based on a hashing algorithm rather than grouping database rows based on continuous indexes.</p>
<p dir="auto">The disadvantage of this method is that dynamically adding/removing database servers becomes expensive.</p>
<h3 tabindex="-1" dir="auto">
List-Based</h3>
<p dir="auto">In list-based partitioning, each partition is defined and selected based on the list of values on a column rather than a set of contiguous ranges of values.</p>
<h3 tabindex="-1" dir="auto">
Range Based</h3>
<p dir="auto">Range partitioning maps data to various partitions based on ranges of values of the partitioning key. In other words, we partition the table in such a way that each partition contains rows within a given range defined by the partition key.</p>
<p dir="auto">Ranges should be contiguous but not overlapping, where each range specifies a non-inclusive lower and upper bound for a partition. Any partitioning key values equal to or higher than the upper bound of the range are added to the next partition.</p>
<h3 tabindex="-1" dir="auto">
Composite</h3>
<p dir="auto">As the name suggests, composite partitioning partitions the data based on two or more partitioning techniques. Here we first partition the data using one technique, and then each partition is further subdivided into sub-partitions using the same or some other method.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">But why do we need sharding? Here are some advantages:</p>
<ul dir="auto">
<li>
<strong>Availability</strong>: Provides logical independence to the partitioned database, ensuring the high availability of our application. Here individual partitions can be managed independently.</li>
<li>
<strong>Scalability</strong>: Proves to increase scalability by distributing the data across multiple partitions.</li>
<li>
<strong>Security</strong>: Helps improve the system's security by storing sensitive and non-sensitive data in different partitions. This could provide better manageability and security to sensitive data.</li>
<li>
<strong>Query Performance</strong>: Improves the performance of the system. Instead of querying the whole database, now the system has to query only a smaller partition.</li>
<li>
<strong>Data Manageability</strong>: Divides tables and indexes into smaller and more manageable units.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<ul dir="auto">
<li>
<strong>Complexity</strong>: Sharding increases the complexity of the system in general.</li>
<li>
<strong>Joins across shards</strong>: Once a database is partitioned and spread across multiple machines it is often not feasible to perform joins that span multiple database shards. Such joins will not be performance efficient since data has to be retrieved from multiple servers.</li>
<li>
<strong>Rebalancing</strong>: If the data distribution is not uniform or there is a lot of load on a single shard, in such cases, we have to rebalance our shards so that the requests are as equally distributed among the shards as possible.</li>
</ul>
<h2 tabindex="-1" dir="auto">
When to use sharding?</h2>
<p dir="auto">Here are some reasons why sharding might be the right choice:</p>
<ul dir="auto">
<li>Leveraging existing hardware instead of high-end machines.</li>
<li>Maintain data in distinct geographic regions.</li>
<li>Quickly scale by adding more shards.</li>
<li>Better performance as each machine is under less load.</li>
<li>When more concurrent connections are required.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Consistent Hashing</h2>
<p dir="auto">Let's first understand the problem we're trying to solve.</p>
<h2 tabindex="-1" dir="auto">
Why do we need this?</h2>
<p dir="auto">In traditional hashing-based distribution methods, we use a hash function to hash our partition keys (i.e. request ID or IP). Then if we use the modulo against the total number of nodes (server or databases). This will give us the node where we want to route our request.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png" alt="simple-hashing"></a></p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\begin{align*}
&amp; Hash(key_1) \to H_1 \bmod N = Node_0 \\
&amp; Hash(key_2) \to H_2 \bmod N = Node_1 \\
&amp; Hash(key_3) \to H_3 \bmod N = Node_2 \\
&amp; ... \\
&amp; Hash(key_n) \to H_n \bmod N = Node_{n-1}
\end{align*}
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>key</code>: Request ID or IP.</p>
<p dir="auto"><code>H</code>: Hash function result.</p>
<p dir="auto"><code>N</code>: Total number of nodes.</p>
<p dir="auto"><code>Node</code>: The node where the request will be routed.</p>
<p dir="auto">The problem with this is if we add or remove a node, it will cause <code>N</code> to change, meaning our mapping strategy will break as the same requests will now map to a different server. As a consequence, the majority of requests will need to be redistributed which is very inefficient.</p>
<p dir="auto">We want to uniformly distribute requests among different nodes such that we should be able to add or remove nodes with minimal effort. Hence, we need a distribution scheme that does not depend directly on the number of nodes (or servers), so that, when adding or removing nodes, the number of keys that need to be relocated is minimized.</p>
<p dir="auto">Consistent hashing solves this horizontal scalability problem by ensuring that every time we scale up or down, we do not have to re-arrange all the keys or touch all the servers.</p>
<p dir="auto">Now that we understand the problem, let's discuss consistent hashing in detail.</p>
<h2 tabindex="-1" dir="auto">
How does it work</h2>
<p dir="auto">Consistent Hashing is a distributed hashing scheme that operates independently of the number of nodes in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png" alt="consistent-hashing"></a></p>
<p dir="auto">Using consistent hashing, only <code>K/N</code> data would require re-distributing.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
R = K/N
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>R</code>: Data that would require re-distribution.</p>
<p dir="auto"><code>K</code>: Number of partition keys.</p>
<p dir="auto"><code>N</code>: Number of nodes.</p>
<p dir="auto">The output of the hash function is a range let's say <code>0...m-1</code> which we can represent on our hash ring. We hash the requests and distribute them on the ring depending on what the output was. Similarly, we also hash the node and distribute them on the same ring as well.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\begin{align*}
&amp; Hash(key_1) = P_1 \\
&amp; Hash(key_2) = P_2 \\
&amp; Hash(key_3) = P_3 \\
&amp; ... \\
&amp; Hash(key_n) = P_{m-1}
\end{align*}
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>key</code>: Request/Node ID or IP.</p>
<p dir="auto"><code>P</code>: Position on the hash ring.</p>
<p dir="auto"><code>m</code>: Total range of the hash ring.</p>
<p dir="auto">Now, when the request comes in we can simply route it to the closest node in a clockwise (can be counterclockwise as well) manner. This means that if a new node is added or removed, we can use the nearest node and only a <em>fraction</em> of the requests need to be re-routed.</p>
<p dir="auto">In theory, consistent hashing should distribute the load evenly however it doesn't happen in practice. Usually, the load distribution is uneven and one server may end up handling the majority of the request becoming a <em>hotspot</em>, essentially a bottleneck for the system. We can fix this by adding extra nodes but that can be expensive.</p>
<p dir="auto">Let's see how we can address these issues.</p>
<h2 tabindex="-1" dir="auto">
Virtual Nodes</h2>
<p dir="auto">In order to ensure a more evenly distributed load, we can introduce the idea of a virtual node, sometimes also referred to as a VNode.</p>
<p dir="auto">Instead of assigning a single position to a node, the hash range is divided into multiple smaller ranges, and each physical node is assigned several of these smaller ranges. Each of these subranges is considered a VNode. Hence, virtual nodes are basically existing physical nodes mapped multiple times across the hash ring to minimize changes to a node's assigned range.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png" alt="virtual-nodes"></a></p>
<p dir="auto">For this, we can use <code>k</code> number of hash functions.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\begin{align*}
&amp; Hash_1(key_1) = P_1 \\
&amp; Hash_2(key_2) = P_2 \\
&amp; Hash_3(key_3) = P_3 \\
&amp; . . . \\
&amp; Hash_k(key_n) = P_{m-1}
\end{align*}
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>key</code>: Request/Node ID or IP.</p>
<p dir="auto"><code>k</code>: Number of hash functions.</p>
<p dir="auto"><code>P</code>: Position on the hash ring.</p>
<p dir="auto"><code>m</code>: Total range of the hash ring.</p>
<p dir="auto">As VNodes help spread the load more evenly across the physical nodes on the cluster by diving the hash ranges into smaller subranges, this speeds up the re-balancing process after adding or removing nodes. This also helps us reduce the probability of hotspots.</p>
<h2 tabindex="-1" dir="auto">
Data Replication</h2>
<p dir="auto">To ensure high availability and durability, consistent hashing replicates each data item on multiple <code>N</code> nodes in the system where the value <code>N</code> is equivalent to the <em>replication factor</em>.</p>
<p dir="auto">The replication factor is the number of nodes that will receive the copy of the same data. In eventually consistent systems, this is done asynchronously.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's look at some advantages of consistent hashing:</p>
<ul dir="auto">
<li>Makes rapid scaling up and down more predictable.</li>
<li>Facilitates partitioning and replication across nodes.</li>
<li>Enables scalability and availability.</li>
<li>Reduces hotspots.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Below are some disadvantages of consistent hashing:</p>
<ul dir="auto">
<li>Increases complexity.</li>
<li>Cascading failures.</li>
<li>Load distribution can still be uneven.</li>
<li>Key management can be expensive when nodes transiently fail.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Let's look at some examples where consistent hashing is used:</p>
<ul dir="auto">
<li>Data partitioning in <a href="https://cassandra.apache.org/" rel="nofollow">Apache Cassandra</a>.</li>
<li>Load distribution across multiple storage hosts in <a href="https://aws.amazon.com/dynamodb" rel="nofollow">Amazon DynamoDB</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Database Federation</h2>
<p dir="auto">Federation (or functional partitioning) splits up databases by function. The federation architecture makes several distinct physical databases appear as one logical database to end-users.</p>
<p dir="auto">All of the components in a federation are tied together by one or more federal schemas that express the commonality of data throughout the federation. These federated schemas are used to specify the information that can be shared by the federation components and to provide a common basis for communication among them.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png" alt="database-federation"></a></p>
<p dir="auto">Federation also provides a cohesive, unified view of data derived from multiple sources. The data sources for federated systems can include databases and various other forms of structured and unstructured data.</p>
<h2 tabindex="-1" dir="auto">
Characteristics</h2>
<p dir="auto">Let's look at some key characteristics of a federated database:</p>
<ul dir="auto">
<li>
<strong>Transparency</strong>: Federated database masks user differences and implementations of underlying data sources. Therefore, the users do not need to be aware of where the data is stored.</li>
<li>
<strong>Heterogeneity</strong>: Data sources can differ in many ways. A federated database system can handle different hardware, network protocols, data models, etc.</li>
<li>
<strong>Extensibility</strong>: New sources may be needed to meet the changing needs of the business. A good federated database system needs to make it easy to add new sources.</li>
<li>
<strong>Autonomy</strong>: A Federated database does not change existing data sources, interfaces should remain the same.</li>
<li>
<strong>Data integration</strong>: A federated database can integrate data from different protocols, database management systems, etc.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Here are some advantages of federated databases:</p>
<ul dir="auto">
<li>Flexible data sharing.</li>
<li>Autonomy among the database components.</li>
<li>Access heterogeneous data in a unified way.</li>
<li>No tight coupling of applications with legacy databases.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Below are some disadvantages of federated databases:</p>
<ul dir="auto">
<li>Adds more hardware and additional complexity.</li>
<li>Joining data from two databases is complex.</li>
<li>Dependence on autonomous data sources.</li>
<li>Query performance and scalability.</li>
</ul>
<h2 tabindex="-1" dir="auto">
N-tier architecture</h2>
<p dir="auto">N-tier architecture divides an application into logical layers and physical tiers. Layers are a way to separate responsibilities and manage dependencies. Each layer has a specific responsibility. A higher layer can use services in a lower layer, but not the other way around.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png" alt="n-tier-architecture"></a></p>
<p dir="auto">Tiers are physically separated, running on separate machines. A tier can call to another tier directly, or use asynchronous messaging. Although each layer might be hosted in its own tier, that's not required. Several layers might be hosted on the same tier. Physically separating the tiers improves scalability and resiliency and adds latency from the additional network communication.</p>
<p dir="auto">An N-tier architecture can be of two types:</p>
<ul dir="auto">
<li>In a closed layer architecture, a layer can only call the next layer immediately down.</li>
<li>In an open layer architecture, a layer can call any of the layers below it.</li>
</ul>
<p dir="auto">A closed-layer architecture limits the dependencies between layers. However, it might create unnecessary network traffic, if one layer simply passes requests along to the next layer.</p>
<h2 tabindex="-1" dir="auto">
Types of N-Tier architectures</h2>
<p dir="auto">Let's look at some examples of N-Tier architecture:</p>
<h3 tabindex="-1" dir="auto">
3-Tier architecture</h3>
<p dir="auto">3-Tier is widely used and consists of the following different layers:</p>
<ul dir="auto">
<li>
<strong>Presentation layer</strong>: Handles user interactions with the application.</li>
<li>
<strong>Business Logic layer</strong>: Accepts the data from the application layer, validates it as per business logic and passes it to the data layer.</li>
<li>
<strong>Data Access layer</strong>: Receives the data from the business layer and performs the necessary operation on the database.</li>
</ul>
<h3 tabindex="-1" dir="auto">
2-Tier architecture</h3>
<p dir="auto">In this architecture, the presentation layer runs on the client and communicates with a data store. There is no business logic layer or immediate layer between client and server.</p>
<h3 tabindex="-1" dir="auto">
Single Tier or 1-Tier architecture</h3>
<p dir="auto">It is the simplest one as it is equivalent to running the application on a personal computer. All of the required components for an application to run are on a single application or server.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Here are some advantages of using N-tier architecture:</p>
<ul dir="auto">
<li>Can improve availability.</li>
<li>Better security as layers can behave like a firewall.</li>
<li>Separate tiers allow us to scale them as needed.</li>
<li>Improve maintenance as different people can manage different tiers.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Below are some disadvantages of N-tier architecture:</p>
<ul dir="auto">
<li>Increased complexity of the system as a whole.</li>
<li>Increased network latency as the number of tiers increases.</li>
<li>Expensive as every tier will have its own hardware cost.</li>
<li>Difficult to manage network security.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Message Brokers</h2>
<p dir="auto">A message broker is a software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to <em>"talk"</em> with one another directly, even if they were written in different languages or implemented on different platforms.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png" alt="message-broker"></a></p>
<p dir="auto">Message brokers can validate, store, route, and deliver messages to the appropriate destinations. They serve as intermediaries between other applications, allowing senders to issue messages without knowing where the receivers are, whether or not they are active, or how many of them there are. This facilitates the decoupling of processes and services within systems.</p>
<h2 tabindex="-1" dir="auto">
Models</h2>
<p dir="auto">Message brokers offer two basic message distribution patterns or messaging styles:</p>
<ul dir="auto">
<li>
<strong><a href="https://karanpratapsingh.com/courses/system-design/message-queues" rel="nofollow">Point-to-Point messaging</a></strong>: This is the distribution pattern utilized in message queues with a one-to-one relationship between the message's sender and receiver.</li>
<li>
<strong><a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" rel="nofollow">Publish-subscribe messaging</a></strong>: In this message distribution pattern, often referred to as <em>"pub/sub"</em>, the producer of each message publishes it to a topic, and multiple message consumers subscribe to topics from which they want to receive messages.</li>
</ul>
<p dir="auto"><em>We will discuss these messaging patterns in detail in the later tutorials.</em></p>
<h2 tabindex="-1" dir="auto">
Message brokers vs Event streaming</h2>
<p dir="auto">Message brokers can support two or more messaging patterns, including message queues and pub/sub, while event streaming platforms only offer pub/sub-style distribution patterns. Designed for use with high volumes of messages, event streaming platforms are readily scalable. They're capable of ordering streams of records into categories called <em>topics</em> and storing them for a predetermined amount of time. Unlike message brokers, however, event streaming platforms cannot guarantee message delivery or track which consumers have received the messages.</p>
<p dir="auto">Event streaming platforms offer more scalability than message brokers but fewer features that ensure fault tolerance like message resending, as well as more limited message routing and queueing capabilities.</p>
<h2 tabindex="-1" dir="auto">
Message brokers vs Enterprise Service Bus (ESB)</h2>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/enterprise-service-bus" rel="nofollow">Enterprise Service Bus (ESB)</a> infrastructure is complex and can be challenging to integrate and expensive to maintain. It's difficult to troubleshoot them when problems occur in production environments, they're not easy to scale, and updating is tedious.</p>
<p dir="auto">Whereas message brokers are a <em>"lightweight"</em> alternative to ESBs that provide similar functionality, a mechanism for inter-service communication, at a lower cost. They're well-suited for use in the <a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" rel="nofollow">microservices architectures</a> that have become more prevalent as ESBs have fallen out of favor.</p>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Here are some commonly used message brokers:</p>
<ul dir="auto">
<li><a href="https://nats.io/" rel="nofollow">NATS</a></li>
<li><a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a></li>
<li><a href="https://www.rabbitmq.com/" rel="nofollow">RabbitMQ</a></li>
<li><a href="https://activemq.apache.org/" rel="nofollow">ActiveMQ</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Message Queues</h2>
<p dir="auto">A message queue is a form of service-to-service communication that facilitates asynchronous communication. It asynchronously receives messages from producers and sends them to consumers.</p>
<p dir="auto">Queues are used to effectively manage requests in large-scale distributed systems. In small systems with minimal processing loads and small databases, writes can be predictably fast. However, in more complex and large systems writes can take an almost non-deterministic amount of time.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png" alt="message-queue"></a></p>
<h2 tabindex="-1" dir="auto">
Working</h2>
<p dir="auto">Messages are stored in the queue until they are processed and deleted. Each message is processed only once by a single consumer. Here's how it works:</p>
<ul dir="auto">
<li>A producer publishes a job to the queue, then notifies the user of the job status.</li>
<li>A consumer picks up the job from the queue, processes it, then signals that the job is complete.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's discuss some advantages of using a message queue:</p>
<ul dir="auto">
<li>
<strong>Scalability</strong>: Message queues make it possible to scale precisely where we need to. When workloads peak, multiple instances of our application can add all requests to the queue without the risk of collision.</li>
<li>
<strong>Decoupling</strong>: Message queues remove dependencies between components and significantly simplify the implementation of decoupled applications.</li>
<li>
<strong>Performance</strong>: Message queues enable asynchronous communication, which means that the endpoints that are producing and consuming messages interact with the queue, not each other. Producers can add requests to the queue without waiting for them to be processed.</li>
<li>
<strong>Reliability</strong>: Queues make our data persistent, and reduce the errors that happen when different parts of our system go offline.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Features</h2>
<p dir="auto">Now, let's discuss some desired features of message queues:</p>
<h3 tabindex="-1" dir="auto">
Push or Pull Delivery</h3>
<p dir="auto">Most message queues provide both push and pull options for retrieving messages. Pull means continuously querying the queue for new messages. Push means that a consumer is notified when a message is available. We can also use long-polling to allow pulls to wait a specified amount of time for new messages to arrive.</p>
<h3 tabindex="-1" dir="auto">
FIFO (First-In-First-Out) Queues</h3>
<p dir="auto">In these queues, the oldest (or first) entry, sometimes called the <em>"head"</em> of the queue, is processed first.</p>
<h3 tabindex="-1" dir="auto">
Schedule or Delay Delivery</h3>
<p dir="auto">Many message queues support setting a specific delivery time for a message. If we need to have a common delay for all messages, we can set up a delay queue.</p>
<h3 tabindex="-1" dir="auto">
At-Least-Once Delivery</h3>
<p dir="auto">Message queues may store multiple copies of messages for redundancy and high availability, and resend messages in the event of communication failures or errors to ensure they are delivered at least once.</p>
<h3 tabindex="-1" dir="auto">
Exactly-Once Delivery</h3>
<p dir="auto">When duplicates can't be tolerated, FIFO (first-in-first-out) message queues will make sure that each message is delivered exactly once (and only once) by filtering out duplicates automatically.</p>
<h3 tabindex="-1" dir="auto">
Dead-letter Queues</h3>
<p dir="auto">A dead-letter queue is a queue to which other queues can send messages that can't be processed successfully. This makes it easy to set them aside for further inspection without blocking the queue processing or spending CPU cycles on a message that might never be consumed successfully.</p>
<h3 tabindex="-1" dir="auto">
Ordering</h3>
<p dir="auto">Most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once.</p>
<h3 tabindex="-1" dir="auto">
Poison-pill Messages</h3>
<p dir="auto">Poison pills are special messages that can be received, but not processed. They are a mechanism used in order to signal a consumer to end its work so it is no longer waiting for new inputs, and are similar to closing a socket in a client/server model.</p>
<h3 tabindex="-1" dir="auto">
Security</h3>
<p dir="auto">Message queues will authenticate applications that try to access the queue, this allows us to encrypt messages over the network as well as in the queue itself.</p>
<h3 tabindex="-1" dir="auto">
Task Queues</h3>
<p dir="auto">Tasks queues receive tasks and their related data, run them, then deliver their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.</p>
<h2 tabindex="-1" dir="auto">
Backpressure</h2>
<p dir="auto">If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. Backpressure can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with <a href="https://en.wikipedia.org/wiki/Exponential_backoff" rel="nofollow">exponential backoff</a> strategy.</p>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Following are some widely used message queues:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/sqs" rel="nofollow">Amazon SQS</a></li>
<li><a href="https://www.rabbitmq.com/" rel="nofollow">RabbitMQ</a></li>
<li><a href="https://activemq.apache.org/" rel="nofollow">ActiveMQ</a></li>
<li><a href="https://zeromq.org/" rel="nofollow">ZeroMQ</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Publish-Subscribe</h2>
<p dir="auto">Similar to a message queue, publish-subscribe is also a form of service-to-service communication that facilitates asynchronous communication. In a pub/sub model, any message published to a topic is pushed immediately to all the subscribers of the topic.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png" alt="publish-subscribe"></a></p>
<p dir="auto">The subscribers to the message topic often perform different functions, and can each do something different with the message in parallel. The publisher doesn't need to know who is using the information that it is broadcasting, and the subscribers don't need to know where the message comes from. This style of messaging is a bit different than message queues, where the component that sends the message often knows the destination it is sending to.</p>
<h2 tabindex="-1" dir="auto">
Working</h2>
<p dir="auto">Unlike message queues, which batch messages until they are retrieved, message topics transfer messages with little or no queuing and push them out immediately to all subscribers. Here's how it works:</p>
<ul dir="auto">
<li>A message topic provides a lightweight mechanism to broadcast asynchronous event notifications and endpoints that allow software components to connect to the topic in order to send and receive those messages.</li>
<li>To broadcast a message, a component called a <em>publisher</em> simply pushes a message to the topic.</li>
<li>All components that subscribe to the topic (known as <em>subscribers</em>) will receive every message that was broadcasted.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's discuss some advantages of using publish-subscribe:</p>
<ul dir="auto">
<li>
<strong>Eliminate Polling</strong>: Message topics allow instantaneous, push-based delivery, eliminating the need for message consumers to periodically check or <em>"poll"</em> for new information and updates. This promotes faster response time and reduces the delivery latency which can be particularly problematic in systems where delays cannot be tolerated.</li>
<li>
<strong>Dynamic Targeting</strong>: Pub/Sub makes the discovery of services easier, more natural, and less error-prone. Instead of maintaining a roster of peers where an application can send messages, a publisher will simply post messages to a topic. Then, any interested party will subscribe its endpoint to the topic, and start receiving these messages. Subscribers can change, upgrade, multiply or disappear and the system dynamically adjusts.</li>
<li>
<strong>Decoupled and Independent Scaling</strong>: Publishers and subscribers are decoupled and work independently from each other, which allows us to develop and scale them independently.</li>
<li>
<strong>Simplify Communication</strong>: The Publish-Subscribe model reduces complexity by removing all the point-to-point connections with a single connection to a message topic, which will manage subscriptions and decide what messages should be delivered to which endpoints.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Features</h2>
<p dir="auto">Now, let's discuss some desired features of publish-subscribe:</p>
<h3 tabindex="-1" dir="auto">
Push Delivery</h3>
<p dir="auto">Pub/Sub messaging instantly pushes asynchronous event notifications when messages are published to the message topic. Subscribers are notified when a message is available.</p>
<h3 tabindex="-1" dir="auto">
Multiple Delivery Protocols</h3>
<p dir="auto">In the Publish-Subscribe model, topics can typically connect to multiple types of endpoints, such as message queues, serverless functions, HTTP servers, etc.</p>
<h3 tabindex="-1" dir="auto">
Fanout</h3>
<p dir="auto">This scenario happens when a message is sent to a topic and then replicated and pushed to multiple endpoints. Fanout provides asynchronous event notifications which in turn allows for parallel processing.</p>
<h3 tabindex="-1" dir="auto">
Filtering</h3>
<p dir="auto">This feature empowers the subscriber to create a message filtering policy so that it will only get the notifications it is interested in, as opposed to receiving every single message posted to the topic.</p>
<h3 tabindex="-1" dir="auto">
Durability</h3>
<p dir="auto">Pub/Sub messaging services often provide very high durability, and at least once delivery, by storing copies of the same message on multiple servers.</p>
<h3 tabindex="-1" dir="auto">
Security</h3>
<p dir="auto">Message topics authenticate applications that try to publish content, this allows us to use encrypted endpoints and encrypt messages in transit over the network.</p>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Here are some commonly used publish-subscribe technologies:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/sns" rel="nofollow">Amazon SNS</a></li>
<li><a href="https://cloud.google.com/pubsub" rel="nofollow">Google Pub/Sub</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Enterprise Service Bus (ESB)</h2>
<p dir="auto">An Enterprise Service Bus (ESB) is an architectural pattern whereby a centralized software component performs integrations between applications. It performs transformations of data models, handles connectivity, performs message routing, converts communication protocols, and potentially manages the composition of multiple requests. The ESB can make these integrations and transformations available as a service interface for reuse by new applications.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png" alt="enterprise-service-bus"></a></p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">In theory, a centralized ESB offers the potential to standardize and dramatically simplify communication, messaging, and integration between services across the enterprise. Here are some advantages of using an ESB:</p>
<ul dir="auto">
<li>
<strong>Improved developer productivity</strong>: Enables developers to incorporate new technologies into one part of an application without touching the rest of the application.</li>
<li>
<strong>Simpler, more cost-effective scalability</strong>: Components can be scaled independently of others.</li>
<li>
<strong>Greater resilience</strong>: Failure of one component does not impact the others, and each microservice can adhere to its own availability requirements without risking the availability of other components in the system.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">While ESBs were deployed successfully in many organizations, in many other organizations the ESB came to be seen as a bottleneck. Here are some disadvantages of using an ESB:</p>
<ul dir="auto">
<li>Making changes or enhancements to one integration could destabilize others who use that same integration.</li>
<li>A single point of failure can bring down all communications.</li>
<li>Updates to the ESB often impact existing integrations, so there is significant testing required to perform any update.</li>
<li>ESB is centrally managed which makes cross-team collaboration challenging.</li>
<li>High configuration and maintenance complexity.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Below are some widely used Enterprise Service Bus (ESB) technologies:</p>
<ul dir="auto">
<li><a href="https://azure.microsoft.com/en-in/services/service-bus" rel="nofollow">Azure Service Bus</a></li>
<li><a href="https://www.ibm.com/in-en/cloud/app-connect" rel="nofollow">IBM App Connect</a></li>
<li><a href="https://camel.apache.org/" rel="nofollow">Apache Camel</a></li>
<li><a href="https://www.redhat.com/en/technologies/jboss-middleware/fuse" rel="nofollow">Fuse ESB</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Monoliths and Microservices</h2>
<h2 tabindex="-1" dir="auto">
Monoliths</h2>
<p dir="auto">A monolith is a self-contained and independent application. It is built as a single unit and is responsible for not just a particular task, but can perform every step needed to satisfy a business need.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png" alt="monolith"></a></p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Following are some advantages of monoliths:</p>
<ul dir="auto">
<li>Simple to develop or debug.</li>
<li>Fast and reliable communication.</li>
<li>Easy monitoring and testing.</li>
<li>Supports ACID transactions.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Some common disadvantages of monoliths are:</p>
<ul dir="auto">
<li>Maintenance becomes hard as the codebase grows.</li>
<li>Tightly coupled application, hard to extend.</li>
<li>Requires commitment to a particular technology stack.</li>
<li>On each update, the entire application is redeployed.</li>
<li>Reduced reliability as a single bug can bring down the entire system.</li>
<li>Difficult to scale or adopt new technologies.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Modular Monoliths</h2>
<p dir="auto">A Modular Monolith is an approach where we build and deploy a single application (that's the <em>Monolith</em> part), but we build it in a way that breaks up the code into independent modules for each of the features needed in our application.</p>
<p dir="auto">This approach reduces the dependencies of a module in such as way that we can enhance or change a module without affecting other modules. When done right, this can be really beneficial in the long term as it reduces the complexity that comes with maintaining a monolith as the system grows.</p>
<h2 tabindex="-1" dir="auto">
Microservices</h2>
<p dir="auto">A microservices architecture consists of a collection of small, autonomous services where each service is self-contained and should implement a single business capability within a bounded context. A bounded context is a natural division of business logic that provides an explicit boundary within which a domain model exists.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png" alt="microservices"></a></p>
<p dir="auto">Each service has a separate codebase, which can be managed by a small development team. Services can be deployed independently and a team can update an existing service without rebuilding and redeploying the entire application.</p>
<p dir="auto">Services are responsible for persisting their own data or external state (database per service). This differs from the traditional model, where a separate data layer handles data persistence.</p>
<h3 tabindex="-1" dir="auto">
Characteristics</h3>
<p dir="auto">The microservices architecture style has the following characteristics:</p>
<ul dir="auto">
<li>
<strong>Loosely coupled</strong>: Services should be loosely coupled so that they can be independently deployed and scaled. This will lead to the decentralization of development teams and thus, enabling them to develop and deploy faster with minimal constraints and operational dependencies.</li>
<li>
<strong>Small but focused</strong>: It's about scope and responsibilities and not size, a service should be focused on a specific problem. Basically, <em>"It does one thing and does it well"</em>. Ideally, they can be independent of the underlying architecture.</li>
<li>
<strong>Built for businesses</strong>: The microservices architecture is usually organized around business capabilities and priorities.</li>
<li>
<strong>Resilience &amp; Fault tolerance</strong>: Services should be designed in such a way that they still function in case of failure or errors. In environments with independently deployable services, failure tolerance is of the highest importance.</li>
<li>
<strong>Highly maintainable</strong>: Service should be easy to maintain and test because services that cannot be maintained will be rewritten.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Here are some advantages of microservices architecture:</p>
<ul dir="auto">
<li>Loosely coupled services.</li>
<li>Services can be deployed independently.</li>
<li>Highly agile for multiple development teams.</li>
<li>Improves fault tolerance and data isolation.</li>
<li>Better scalability as each service can be scaled independently.</li>
<li>Eliminates any long-term commitment to a particular technology stack.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Microservices architecture brings its own set of challenges:</p>
<ul dir="auto">
<li>Complexity of a distributed system.</li>
<li>Testing is more difficult.</li>
<li>Expensive to maintain (individual servers, databases, etc.).</li>
<li>Inter-service communication has its own challenges.</li>
<li>Data integrity and consistency.</li>
<li>Network congestion and latency.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Best practices</h3>
<p dir="auto">Let's discuss some microservices best practices:</p>
<ul dir="auto">
<li>Model services around the business domain.</li>
<li>Services should have loose coupling and high functional cohesion.</li>
<li>Isolate failures and use resiliency strategies to prevent failures within a service from cascading.</li>
<li>Services should only communicate through well-designed APIs. Avoid leaking implementation details.</li>
<li>Data storage should be private to the service that owns the data</li>
<li>Avoid coupling between services. Causes of coupling include shared database schemas and rigid communication protocols.</li>
<li>Decentralize everything. Individual teams are responsible for designing and building services. Avoid sharing code or data schemas.</li>
<li>Fail fast by using a <a href="https://karanpratapsingh.com/courses/system-design/circuit-breaker" rel="nofollow">circuit breaker</a> to achieve fault tolerance.</li>
<li>Ensure that the API changes are backward compatible.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Pitfalls</h3>
<p dir="auto">Below are some common pitfalls of microservices architecture:</p>
<ul dir="auto">
<li>Service boundaries are not based on the business domain.</li>
<li>Underestimating how hard is to build a distributed system.</li>
<li>Shared database or common dependencies between services.</li>
<li>Lack of Business Alignment.</li>
<li>Lack of clear ownership.</li>
<li>Lack of idempotency.</li>
<li>Trying to do everything <a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models" rel="nofollow">ACID instead of BASE</a>.</li>
<li>Lack of design for fault tolerance may result in cascading failures.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Beware of the distributed monolith</h2>
<p dir="auto">Distributed Monolith is a system that resembles the microservices architecture but is tightly coupled within itself like a monolithic application. Adopting microservices architecture comes with a lot of advantages. But while making one, there are good chances that we might end up with a distributed monolith.</p>
<p dir="auto">Our microservices are just a distributed monolith if any of these apply to it:</p>
<ul dir="auto">
<li>Requires low latency communication.</li>
<li>Services don't scale easily.</li>
<li>Dependency between services.</li>
<li>Sharing the same resources such as databases.</li>
<li>Tightly coupled systems.</li>
</ul>
<p dir="auto">One of the primary reasons to build an application using microservices architecture is to have scalability. Therefore, microservices should have loosely coupled services which enable every service to be independent. The distributed monolith architecture takes this away and causes most components to depend on one another, increasing design complexity.</p>
<h2 tabindex="-1" dir="auto">
Microservices vs Service-oriented architecture (SOA)</h2>
<p dir="auto">You might have seen <em>Service-oriented architecture (SOA)</em> mentioned around the internet, sometimes even interchangeably with microservices, but they are different from each other and the main distinction between the two approaches comes down to <em>scope</em>.</p>
<p dir="auto">Service-oriented architecture (SOA) defines a way to make software components reusable via service interfaces. These interfaces utilize common communication standards and focus on maximizing application service reusability whereas microservices are built as a collection of various smallest independent service units focused on team autonomy and decoupling.</p>
<h2 tabindex="-1" dir="auto">
Why you don't need microservices</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png" alt="architecture-range"></a></p>
<p dir="auto">So, you might be wondering, monoliths seem like a bad idea to begin with, why would anyone use that?</p>
<p dir="auto">Well, it depends. While each approach has its own advantages and disadvantages, it is advised to start with a monolith when building a new system. It is important to understand, that microservices are not a silver bullet, instead, they solve an organizational problem. Microservices architecture is about your organizational priorities and team as much as it's about technology.</p>
<p dir="auto">Before making the decision to move to microservices architecture, you need to ask yourself questions like:</p>
<ul dir="auto">
<li><em>"Is the team too large to work effectively on a shared codebase?"</em></li>
<li><em>"Are teams blocked on other teams?"</em></li>
<li><em>"Does microservices deliver clear business value for us?"</em></li>
<li><em>"Is my business mature enough to use microservices?"</em></li>
<li><em>"Is our current architecture limiting us with communication overhead?"</em></li>
</ul>
<p dir="auto">If your application does not require to be broken down into microservices, you don't need this. There is no absolute necessity that all applications should be broken down into microservices.</p>
<p dir="auto">We frequently draw inspiration from companies such as Netflix and their use of microservices, but we overlook the fact that we are not Netflix. They went through a lot of iterations and models before they had a market-ready solution, and this architecture became acceptable for them when they identified and solved the problem they were trying to tackle.</p>
<p dir="auto">That's why it's essential to understand in-depth if your business <em>actually</em> needs microservices. What I'm trying to say is microservices are solutions to complex concerns and if your business doesn't have complex issues, you don't need them.</p>
<h2 tabindex="-1" dir="auto">
Event-Driven Architecture (EDA)</h2>
<p dir="auto">Event-Driven Architecture (EDA) is about using events as a way to communicate within a system. Generally, leveraging a message broker to publish and consume events asynchronously. The publisher is unaware of who is consuming an event and the consumers are unaware of each other. Event-Driven Architecture is simply a way of achieving loose coupling between services within a system.</p>
<h2 tabindex="-1" dir="auto">
What is an event?</h2>
<p dir="auto">An event is a data point that represents state changes in a system. It doesn't specify what should happen and how the change should modify the system, it only notifies the system of a particular state change. When a user makes an action, they trigger an event.</p>
<h2 tabindex="-1" dir="auto">
Components</h2>
<p dir="auto">Event-driven architectures have three key components:</p>
<ul dir="auto">
<li>
<strong>Event producers</strong>: Publishes an event to the router.</li>
<li>
<strong>Event routers</strong>: Filters and pushes the events to consumers.</li>
<li>
<strong>Event consumers</strong>: Uses events to reflect changes in the system.</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png" alt="event-driven-architecture"></a></p>
<p dir="auto"><em>Note: Dots in the diagram represents different events in the system.</em></p>
<h2 tabindex="-1" dir="auto">
Patterns</h2>
<p dir="auto">There are several ways to implement the event-driven architecture, and which method we use depends on the use case but here are some common examples:</p>
<ul dir="auto">
<li><a href="https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas" rel="nofollow">Sagas</a></li>
<li><a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" rel="nofollow">Publish-Subscribe</a></li>
<li><a href="https://karanpratapsingh.com/courses/system-design/event-sourcing" rel="nofollow">Event Sourcing</a></li>
<li><a href="https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation" rel="nofollow">Command and Query Responsibility Segregation (CQRS)</a></li>
</ul>
<p dir="auto"><em>Note: Each of these methods is discussed separately.</em></p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's discuss some advantages:</p>
<ul dir="auto">
<li>Decoupled producers and consumers.</li>
<li>Highly scalable and distributed.</li>
<li>Easy to add new consumers.</li>
<li>Improves agility.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Challenges</h2>
<p dir="auto">Here are some challenges of event-drive architecture:</p>
<ul dir="auto">
<li>Guaranteed delivery.</li>
<li>Error handling is difficult.</li>
<li>Event-driven systems are complex in general.</li>
<li>Exactly once, in-order processing of events.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Use cases</h2>
<p dir="auto">Below are some common use cases where event-driven architectures are beneficial:</p>
<ul dir="auto">
<li>Metadata and metrics.</li>
<li>Server and security logs.</li>
<li>Integrating heterogeneous systems.</li>
<li>Fanout and parallel processing.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Here are some widely used technologies for implementing event-driven architectures:</p>
<ul dir="auto">
<li><a href="https://nats.io/" rel="nofollow">NATS</a></li>
<li><a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a></li>
<li><a href="https://aws.amazon.com/eventbridge" rel="nofollow">Amazon EventBridge</a></li>
<li><a href="https://aws.amazon.com/sns" rel="nofollow">Amazon SNS</a></li>
<li><a href="https://cloud.google.com/pubsub" rel="nofollow">Google PubSub</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Event Sourcing</h2>
<p dir="auto">Instead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png" alt="event-sourcing"></a></p>
<p dir="auto">This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.</p>
<h2 tabindex="-1" dir="auto">
Event sourcing vs Event-Driven Architecture (EDA)</h2>
<p dir="auto">Event sourcing is seemingly constantly being confused with <a href="https://karanpratapsingh.com/courses/system-design/event-driven-architecture" rel="nofollow">Event-driven Architecture (EDA)</a>. Event-driven architecture is about using events to communicate between service boundaries. Generally, leveraging a message broker to publish and consume events asynchronously within other boundaries.</p>
<p dir="auto">Whereas, event sourcing is about using events as a state, which is a different approach to storing data. Rather than storing the current state, we're instead going to be storing events. Also, event sourcing is one of the several patterns to implement an event-driven architecture.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's discuss some advantages of using event sourcing:</p>
<ul dir="auto">
<li>Excellent for real-time data reporting.</li>
<li>Great for fail-safety, data can be reconstituted from the event store.</li>
<li>Extremely flexible, any type of message can be stored.</li>
<li>Preferred way of achieving audit logs functionality for high compliance systems.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Following are the disadvantages of event sourcing:</p>
<ul dir="auto">
<li>Requires an extremely efficient network infrastructure.</li>
<li>Requires a reliable way to control message formats, such as a schema registry.</li>
<li>Different events will contain different payloads.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Command and Query Responsibility Segregation (CQRS)</h2>
<p dir="auto">Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system's actions into commands and queries. It was first described by <a href="https://twitter.com/gregyoung" rel="nofollow">Greg Young</a>.</p>
<p dir="auto">In CQRS, a <em>command</em> is an instruction, a directive to perform a specific task. It is an intention to change something and doesn't return a value, only an indication of success or failure. And, a <em>query</em> is a request for information that doesn't change the system's state or cause any side effects.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png" alt="command-and-query-responsibility-segregation"></a></p>
<p dir="auto">The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.</p>
<h2 tabindex="-1" dir="auto">
CQRS with Event Sourcing</h2>
<p dir="auto">The CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.</p>
<p dir="auto">When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.</p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's discuss some advantages of CQRS:</p>
<ul dir="auto">
<li>Allows independent scaling of read and write workloads.</li>
<li>Easier scaling, optimizations, and architectural changes.</li>
<li>Closer to business logic with loose coupling.</li>
<li>The application can avoid complex joins when querying.</li>
<li>Clear boundaries between the system behavior.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Below are some disadvantages of CQRS:</p>
<ul dir="auto">
<li>More complex application design.</li>
<li>Message failures or duplicate messages can occur.</li>
<li>Dealing with eventual consistency is a challenge.</li>
<li>Increased system maintenance efforts.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Use cases</h2>
<p dir="auto">Here are some scenarios where CQRS will be helpful:</p>
<ul dir="auto">
<li>The performance of data reads must be fine-tuned separately from the performance of data writes.</li>
<li>The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly.</li>
<li>Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn't affect the availability of the others.</li>
<li>Better security to ensure that only the right domain entities are performing writes on the data.</li>
</ul>
<h2 tabindex="-1" dir="auto">
API Gateway</h2>
<p dir="auto">The API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png" alt="api-gateway"></a></p>
<h2 tabindex="-1" dir="auto">
Why do we need an API Gateway?</h2>
<p dir="auto">The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management.</p>
<h2 tabindex="-1" dir="auto">
Features</h2>
<p dir="auto">Below are some desired features of an API Gateway:</p>
<ul dir="auto">
<li>Authentication and Authorization</li>
<li><a href="https://karanpratapsingh.com/courses/system-design/service-discovery" rel="nofollow">Service discovery</a></li>
<li><a href="https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy" rel="nofollow">Reverse Proxy</a></li>
<li><a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">Caching</a></li>
<li>Security</li>
<li>Retry and <a href="https://karanpratapsingh.com/courses/system-design/circuit-breaker" rel="nofollow">Circuit breaking</a>
</li>
<li><a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">Load balancing</a></li>
<li>Logging, Tracing</li>
<li>API composition</li>
<li>
<a href="https://karanpratapsingh.com/courses/system-design/rate-limiting" rel="nofollow">Rate limiting</a> and throttling</li>
<li>Versioning</li>
<li>Routing</li>
<li>IP whitelisting or blacklisting</li>
</ul>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Let's look at some advantages of using an API Gateway:</p>
<ul dir="auto">
<li>Encapsulates the internal structure of an API.</li>
<li>Provides a centralized view of the API.</li>
<li>Simplifies the client code.</li>
<li>Monitoring, analytics, tracing, and other such features.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Here are some possible disadvantages of an API Gateway:</p>
<ul dir="auto">
<li>Possible single point of failure.</li>
<li>Might impact performance.</li>
<li>Can become a bottleneck if not scaled properly.</li>
<li>Configuration can be challenging.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Backend For Frontend (BFF) pattern</h2>
<p dir="auto">In the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by <a href="https://samnewman.io/" rel="nofollow">Sam Newman</a>.</p>
<p dir="auto">Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png" alt="backend-for-frontend"></a></p>
<p dir="auto">The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.</p>
<p dir="auto"><em><a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql" rel="nofollow">GraphQL</a> performs really well as a backend for frontend (BFF).</em></p>
<h3 tabindex="-1" dir="auto">
When to use this pattern?</h3>
<p dir="auto">We should consider using a Backend For Frontend (BFF) pattern when:</p>
<ul dir="auto">
<li>A shared or general purpose backend service must be maintained with significant development overhead.</li>
<li>We want to optimize the backend for the requirements of a specific client.</li>
<li>Customizations are made to a general-purpose backend to accommodate multiple interfaces.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Following are some widely used gateways technologies:</p>
<ul dir="auto">
<li><a href="https://aws.amazon.com/api-gateway" rel="nofollow">Amazon API Gateway</a></li>
<li><a href="https://cloud.google.com/apigee" rel="nofollow">Apigee API Gateway</a></li>
<li><a href="https://azure.microsoft.com/en-in/services/api-management" rel="nofollow">Azure API Gateway</a></li>
<li><a href="https://konghq.com/kong" rel="nofollow">Kong API Gateway</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
REST, GraphQL, gRPC</h2>
<p dir="auto">A good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC.</p>
<h2 tabindex="-1" dir="auto">
What's an API?</h2>
<p dir="auto">Before we even get into API technologies, let's first understand what is an API.</p>
<p dir="auto">API stands for Application Programming Interface. It is a set of definitions and protocols for building and integrating application software. It's sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.</p>
<p dir="auto">In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.</p>
<h2 tabindex="-1" dir="auto">
REST</h2>
<p dir="auto">A <a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm" rel="nofollow">REST API</a> (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by <a href="https://roy.gbiv.com/" rel="nofollow">Roy Fielding</a> in the year 2000.</p>
<p dir="auto"><em>In REST API, the fundamental unit is a resource.</em></p>
<h3 tabindex="-1" dir="auto">
Concepts</h3>
<p dir="auto">Let's discuss some concepts of a RESTful API.</p>
<p dir="auto"><strong>Constraints</strong></p>
<p dir="auto">In order for an API to be considered <em>RESTful</em>, it has to conform to these architectural constraints:</p>
<ul dir="auto">
<li>
<strong>Uniform Interface</strong>: There should be a uniform way of interacting with a given server.</li>
<li>
<strong>Client-Server</strong>: A client-server architecture managed through HTTP.</li>
<li>
<strong>Stateless</strong>: No client context shall be stored on the server between requests.</li>
<li>
<strong>Cacheable</strong>: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side.</li>
<li>
<strong>Layered system</strong>: An application architecture needs to be composed of multiple layers.</li>
<li>
<strong>Code on demand</strong>: Return executable code to support a part of your application. <em>(optional)</em>
</li>
</ul>
<p dir="auto"><strong>HTTP Verbs</strong></p>
<p dir="auto">HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as <em>HTTP verbs</em>. Each of them implements a different semantic, but some common features are shared by a group of them.</p>
<p dir="auto">Below are some commonly used HTTP verbs:</p>
<ul dir="auto">
<li>
<strong>GET</strong>: Request a representation of the specified resource.</li>
<li>
<strong>HEAD</strong>: Response is identical to a <code>GET</code> request, but without the response body.</li>
<li>
<strong>POST</strong>: Submits an entity to the specified resource, often causing a change in state or side effects on the server.</li>
<li>
<strong>PUT</strong>: Replaces all current representations of the target resource with the request payload.</li>
<li>
<strong>DELETE</strong>: Deletes the specified resource.</li>
<li>
<strong>PATCH</strong>: Applies partial modifications to a resource.</li>
</ul>
<p dir="auto"><strong>HTTP response codes</strong></p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes" rel="nofollow">HTTP response status codes</a> indicate whether a specific HTTP request has been successfully completed.</p>
<p dir="auto">There are five classes defined by the standard:</p>
<ul dir="auto">
<li>1xx - Informational responses.</li>
<li>2xx - Successful responses.</li>
<li>3xx - Redirection responses.</li>
<li>4xx - Client error responses.</li>
<li>5xx - Server error responses.</li>
</ul>
<p dir="auto">For example, HTTP 200 means that the request was successful.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Let's discuss some advantages of REST API:</p>
<ul dir="auto">
<li>Simple and easy to understand.</li>
<li>Flexible and portable.</li>
<li>Good caching support.</li>
<li>Client and server are decoupled.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Let's discuss some disadvantages of REST API:</p>
<ul dir="auto">
<li>Over-fetching of data.</li>
<li>Sometimes multiple round trips to the server are required.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Use cases</h3>
<p dir="auto">REST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios.</p>
<h3 tabindex="-1" dir="auto">
Example</h3>
<p dir="auto">Here's an example usage of a REST API that operates on a <strong>users</strong> resource.</p>
<table>
<thead>
<tr>
<th>URI</th>
<th>HTTP verb</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>/users</td>
<td>GET</td>
<td>Get all users</td>
</tr>
<tr>
<td>/users/{id}</td>
<td>GET</td>
<td>Get a user by id</td>
</tr>
<tr>
<td>/users</td>
<td>POST</td>
<td>Add a new user</td>
</tr>
<tr>
<td>/users/{id}</td>
<td>PATCH</td>
<td>Update a user by id</td>
</tr>
<tr>
<td>/users/{id}</td>
<td>DELETE</td>
<td>Delete a user by id</td>
</tr>
</tbody>
</table>
<p dir="auto"><em>There is so much more to learn when it comes to REST APIs, I will highly recommend looking into <a href="https://en.wikipedia.org/wiki/HATEOAS" rel="nofollow">Hypermedia as the Engine of Application State (HATEOAS)</a>.</em></p>
<h2 tabindex="-1" dir="auto">
GraphQL</h2>
<p dir="auto"><a href="https://graphql.org/" rel="nofollow">GraphQL</a> is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by <a href="https://engineering.fb.com/" rel="nofollow">Facebook</a> and later open-sourced in 2015.</p>
<p dir="auto">GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.</p>
<p dir="auto"><em>In GraphQL, the fundamental unit is a query.</em></p>
<h3 tabindex="-1" dir="auto">
Concepts</h3>
<p dir="auto">Let's briefly discuss some key concepts in GraphQL:</p>
<p dir="auto"><strong>Schema</strong></p>
<p dir="auto">A GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.</p>
<p dir="auto"><strong>Queries</strong></p>
<p dir="auto">A query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a <a href="https://graphql.org/learn/queries/#mutations" rel="nofollow">mutation</a> which provides a way to modify server-side data.</p>
<p dir="auto"><strong>Resolvers</strong></p>
<p dir="auto">Resolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Let's discuss some advantages of GraphQL:</p>
<ul dir="auto">
<li>Eliminates over-fetching of data.</li>
<li>Strongly defined schema.</li>
<li>Code generation support.</li>
<li>Payload optimization.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Let's discuss some disadvantages of GraphQL:</p>
<ul dir="auto">
<li>Shifts complexity to server-side.</li>
<li>Caching becomes hard.</li>
<li>Versioning is ambiguous.</li>
<li>N+1 problem.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Use cases</h3>
<p dir="auto">GraphQL proves to be essential in the following scenarios:</p>
<ul dir="auto">
<li>Reducing app bandwidth usage as we can query multiple resources in a single query.</li>
<li>Rapid prototyping for complex systems.</li>
<li>When we are working with a graph-like data model.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Example</h3>
<p dir="auto">Here's a GraphQL schema that defines a <code>User</code> type and a <code>Query</code> type.</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Query {
  getUser: User
}

type User {
  id: ID
  name: String
  city: String
  state: String
}"><pre><span>type</span> <span>Query</span> {
  <span>getUser</span>: <span>User</span>
}

<span>type</span> <span>User</span> {
  <span>id</span>: <span>ID</span>
  <span>name</span>: <span>String</span>
  <span>city</span>: <span>String</span>
  <span>state</span>: <span>String</span>
}</pre></div>
<p dir="auto">Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  getUser {
    id
    name
    city
  }
}"><pre>{
  <span>getUser</span> {
    <span>id</span>
    <span>name</span>
    <span>city</span>
  }
}</pre></div>
<p dir="auto">This will give the following response to the client.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;getUser&quot;: {
    &quot;id&quot;: 123,
    &quot;name&quot;: &quot;Karan&quot;,
    &quot;city&quot;: &quot;San Francisco&quot;
  }
}"><pre>{
  <span>"getUser"</span>: {
    <span>"id"</span>: <span>123</span>,
    <span>"name"</span>: <span><span>"</span>Karan<span>"</span></span>,
    <span>"city"</span>: <span><span>"</span>San Francisco<span>"</span></span>
  }
}</pre></div>
<p dir="auto"><em>Learn more about GraphQL at <a href="https://graphql.org/" rel="nofollow">graphql.org</a>.</em></p>
<h2 tabindex="-1" dir="auto">
gRPC</h2>
<p dir="auto"><a href="https://grpc.io/" rel="nofollow">gRPC</a> is a modern open-source high-performance <a href="https://en.wikipedia.org/wiki/Remote_procedure_call" rel="nofollow">Remote Procedure Call (RPC)</a> framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more.</p>
<h3 tabindex="-1" dir="auto">
Concepts</h3>
<p dir="auto">Let's discuss some key concepts of gRPC.</p>
<p dir="auto"><strong>Protocol buffers</strong></p>
<p dir="auto">Protocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It's like JSON, except it's smaller and faster, and it generates native language bindings.</p>
<p dir="auto"><strong>Service definition</strong></p>
<p dir="auto">Like many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the <a href="https://en.wikipedia.org/wiki/Interface_description_language" rel="nofollow">Interface Definition Language (IDL)</a> for describing both the service interface and the structure of the payload messages.</p>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Let's discuss some advantages of gRPC:</p>
<ul dir="auto">
<li>Lightweight and efficient.</li>
<li>High performance.</li>
<li>Built-in code generation support.</li>
<li>Bi-directional streaming.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Let's discuss some disadvantages of gRPC:</p>
<ul dir="auto">
<li>Relatively new compared to REST and GraphQL.</li>
<li>Limited browser support.</li>
<li>Steeper learning curve.</li>
<li>Not human readable.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Use cases</h3>
<p dir="auto">Below are some good use cases for gRPC:</p>
<ul dir="auto">
<li>Real-time communication via bi-directional streaming.</li>
<li>Efficient inter-service communication in microservices.</li>
<li>Low latency and high throughput communication.</li>
<li>Polyglot environments.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Example</h3>
<p dir="auto">Here's a basic example of a gRPC service defined in a <code>*.proto</code> file. Using this definition, we can easily code generate the <code>HelloService</code> service in the programming language of our choice.</p>
<div dir="auto" data-snippet-clipboard-copy-content="service HelloService {
  rpc SayHello (HelloRequest) returns (HelloResponse);
}

message HelloRequest {
  string greeting = 1;
}

message HelloResponse {
  string reply = 1;
}"><pre><span>service</span> <span>HelloService</span> {
  <span>rpc</span> <span>SayHello</span> (<span>HelloRequest</span>) <span>returns</span> (<span>HelloResponse</span>);
}

<span>message</span> <span>HelloRequest</span> {
  <span>string</span> <span>greeting</span> <span>=</span> <span>1</span>;
}

<span>message</span> <span>HelloResponse</span> {
  <span>string</span> <span>reply</span> <span>=</span> <span>1</span>;
}</pre></div>
<h2 tabindex="-1" dir="auto">
REST vs GraphQL vs gRPC</h2>
<p dir="auto">Now that we know how these API designing techniques work, let's compare them based on the following parameters:</p>
<ul dir="auto">
<li>Will it cause tight coupling?</li>
<li>How <em>chatty</em> (distinct API calls to get needed information) are the APIs?</li>
<li>What's the performance like?</li>
<li>How complex is it to integrate?</li>
<li>How well does the caching work?</li>
<li>Built-in tooling and code generation?</li>
<li>What's API discoverability like?</li>
<li>How easy is it to version APIs?</li>
</ul>
<table>
<thead>
<tr>
<th>Type</th>
<th>Coupling</th>
<th>Chattiness</th>
<th>Performance</th>
<th>Complexity</th>
<th>Caching</th>
<th>Codegen</th>
<th>Discoverability</th>
<th>Versioning</th>
</tr>
</thead>
<tbody>
<tr>
<td>REST</td>
<td>Low</td>
<td>High</td>
<td>Good</td>
<td>Medium</td>
<td>Great</td>
<td>Bad</td>
<td>Good</td>
<td>Easy</td>
</tr>
<tr>
<td>GraphQL</td>
<td>Medium</td>
<td>Low</td>
<td>Good</td>
<td>High</td>
<td>Custom</td>
<td>Good</td>
<td>Good</td>
<td>Custom</td>
</tr>
<tr>
<td>gRPC</td>
<td>High</td>
<td>Medium</td>
<td>Great</td>
<td>Low</td>
<td>Custom</td>
<td>Great</td>
<td>Bad</td>
<td>Hard</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">
Which API technology is better?</h3>
<p dir="auto">Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API.</p>
<h2 tabindex="-1" dir="auto">
Long polling, WebSockets, Server-Sent Events (SSE)</h2>
<p dir="auto">Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let's discuss some approaches to overcome this problem.</p>
<h2 tabindex="-1" dir="auto">
Long polling</h2>
<p dir="auto">HTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.</p>
<p dir="auto">In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png" alt="long-polling"></a></p>
<p dir="auto">Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.</p>
<h3 tabindex="-1" dir="auto">
Working</h3>
<p dir="auto">Let's understand how long polling works:</p>
<ol dir="auto">
<li>The client makes an initial request and waits for a response.</li>
<li>The server receives the request and delays sending anything until an update is available.</li>
<li>Once an update is available, the response is sent to the client.</li>
<li>The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.</li>
</ol>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Here are some advantages of long polling:</p>
<ul dir="auto">
<li>Easy to implement, good for small-scale projects.</li>
<li>Nearly universally supported.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">A major downside of long polling is that it is usually not scalable. Below are some of the other reasons:</p>
<ul dir="auto">
<li>Creates a new connection each time, which can be intensive on the server.</li>
<li>Reliable message ordering can be an issue for multiple requests.</li>
<li>Increased latency as the server needs to wait for a new request.</li>
</ul>
<h2 tabindex="-1" dir="auto">
WebSockets</h2>
<p dir="auto">WebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.</p>
<p dir="auto">The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png" alt="websockets"></a></p>
<p dir="auto">This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.</p>
<h3 tabindex="-1" dir="auto">
Working</h3>
<p dir="auto">Let's understand how WebSockets work:</p>
<ol dir="auto">
<li>The client initiates a WebSocket handshake process by sending a request.</li>
<li>The request also contains an <a href="https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header" rel="nofollow">HTTP Upgrade</a> header that allows the request to switch to the WebSocket protocol (<code>ws://</code>).</li>
<li>The server sends a response to the client, acknowledging the WebSocket handshake request.</li>
<li>A WebSocket connection will be opened once the client receives a successful handshake response.</li>
<li>Now the client and server can start sending data in both directions allowing real-time communication.</li>
<li>The connection is closed once the server or the client decides to close the connection.</li>
</ol>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<p dir="auto">Below are some advantages of WebSockets:</p>
<ul dir="auto">
<li>Full-duplex asynchronous messaging.</li>
<li>Better origin-based security model.</li>
<li>Lightweight for both client and server.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Let's discuss some disadvantages of WebSockets:</p>
<ul dir="auto">
<li>Terminated connections aren't automatically recovered.</li>
<li>Older browsers don't support WebSockets (becoming less relevant).</li>
</ul>
<h2 tabindex="-1" dir="auto">
Server-Sent Events (SSE)</h2>
<p dir="auto">Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png" alt="server-sent-events"></a></p>
<p dir="auto">It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.</p>
<h3 tabindex="-1" dir="auto">
Working</h3>
<p dir="auto">Let's understand how server-sent events work:</p>
<ol dir="auto">
<li>The client makes a request to the server.</li>
<li>The connection between client and server is established and it remains open.</li>
<li>The server sends responses or events to the client when new data is available.</li>
</ol>
<h3 tabindex="-1" dir="auto">
Advantages</h3>
<ul dir="auto">
<li>Simple to implement and use for both client and server.</li>
<li>Supported by most browsers.</li>
<li>No trouble with firewalls.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<ul dir="auto">
<li>Unidirectional nature can be limiting.</li>
<li>Limitation for the maximum number of open connections.</li>
<li>Does not support binary data.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Geohashing and Quadtrees</h2>
<h2 tabindex="-1" dir="auto">
Geohashing</h2>
<p dir="auto">Geohashing is a <a href="https://en.wikipedia.org/wiki/Address_geocoding" rel="nofollow">geocoding</a> method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by <a href="https://twitter.com/gniemeyer" rel="nofollow">Gustavo Niemeyer</a> in 2008.</p>
<p dir="auto">For example, San Francisco with coordinates <code>37.7564, -122.4016</code> can be represented in geohash as <code>9q8yy9mf</code>.</p>
<h3 tabindex="-1" dir="auto">
How does Geohashing work?</h3>
<p dir="auto">Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png" alt="geohashing"></a></p>
<p dir="auto">Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes <code>9q8yy9mf</code> and <code>9q8yy9vx</code> are spatially closer as they share the prefix <code>9q8yy9</code>.</p>
<p dir="auto">Geohashing can also be used to provide a degree of anonymity as we don't need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.</p>
<p dir="auto">The cell sizes of the geohashes of different lengths are as follows:</p>
<table>
<thead>
<tr>
<th>Geohash length</th>
<th>Cell width</th>
<th>Cell height</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>5000 km</td>
<td>5000 km</td>
</tr>
<tr>
<td>2</td>
<td>1250 km</td>
<td>1250 km</td>
</tr>
<tr>
<td>3</td>
<td>156 km</td>
<td>156 km</td>
</tr>
<tr>
<td>4</td>
<td>39.1 km</td>
<td>19.5 km</td>
</tr>
<tr>
<td>5</td>
<td>4.89 km</td>
<td>4.89 km</td>
</tr>
<tr>
<td>6</td>
<td>1.22 km</td>
<td>0.61 km</td>
</tr>
<tr>
<td>7</td>
<td>153 m</td>
<td>153 m</td>
</tr>
<tr>
<td>8</td>
<td>38.2 m</td>
<td>19.1 m</td>
</tr>
<tr>
<td>9</td>
<td>4.77 m</td>
<td>4.77 m</td>
</tr>
<tr>
<td>10</td>
<td>1.19 m</td>
<td>0.596 m</td>
</tr>
<tr>
<td>11</td>
<td>149 mm</td>
<td>149 mm</td>
</tr>
<tr>
<td>12</td>
<td>37.2 mm</td>
<td>18.6 mm</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">
Use cases</h3>
<p dir="auto">Here are some common use cases for Geohashing:</p>
<ul dir="auto">
<li>It is a simple way to represent and store a location in a database.</li>
<li>It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes.</li>
<li>We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Examples</h3>
<p dir="auto">Geohashing is widely used and it is supported by popular databases.</p>
<ul dir="auto">
<li><a href="https://www.mysql.com/" rel="nofollow">MySQL</a></li>
<li><a href="http://redis.io/" rel="nofollow">Redis</a></li>
<li><a href="https://aws.amazon.com/dynamodb" rel="nofollow">Amazon DynamoDB</a></li>
<li><a href="https://cloud.google.com/firestore" rel="nofollow">Google Cloud Firestore</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
Quadtrees</h2>
<p dir="auto">A quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of <a href="https://en.wikipedia.org/wiki/Octree" rel="nofollow">Octrees</a> which are used to partition three-dimensional space.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png" alt="quadtree"></a></p>
<h3 tabindex="-1" dir="auto">
Types of Quadtrees</h3>
<p dir="auto">Quadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees:</p>
<ul dir="auto">
<li>Point quadtrees</li>
<li>Point-region (PR) quadtrees</li>
<li>Polygonal map (PM) quadtrees</li>
<li>Compressed quadtrees</li>
<li>Edge quadtrees</li>
</ul>
<h3 tabindex="-1" dir="auto">
Why do we need Quadtrees?</h3>
<p dir="auto">Aren't latitudes and longitudes enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using <a href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="nofollow">euclidean distance</a>, for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png" alt="quadtree-subdivision"></a></p>
<p dir="auto">Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the <a href="https://en.wikipedia.org/wiki/Hilbert_curve" rel="nofollow">Hilbert curve</a>, we can easily improve range query performance.</p>
<h3 tabindex="-1" dir="auto">
Use cases</h3>
<p dir="auto">Below are some common uses of quadtrees:</p>
<ul dir="auto">
<li>Image representation, processing, and compression.</li>
<li>Spacial indexing and range queries.</li>
<li>Location-based services like Google Maps, Uber, etc.</li>
<li>Mesh generation and computer graphics.</li>
<li>Sparse data storage.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Circuit breaker</h2>
<p dir="auto">The circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png" alt="circuit-breaker"></a></p>
<p dir="auto">The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we'll also want some kind of monitor alert if the circuit breaker trips.</p>
<h2 tabindex="-1" dir="auto">
Why do we need circuit breaking?</h2>
<p dir="auto">It's common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What's worse is if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems.</p>
<h2 tabindex="-1" dir="auto">
States</h2>
<p dir="auto">Let's discuss circuit breaker states:</p>
<h3 tabindex="-1" dir="auto">
Closed</h3>
<p dir="auto">When everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state.</p>
<h3 tabindex="-1" dir="auto">
Open</h3>
<p dir="auto">In this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified.</p>
<h3 tabindex="-1" dir="auto">
Half-open</h3>
<p dir="auto">In this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state.</p>
<h2 tabindex="-1" dir="auto">
Rate Limiting</h2>
<p dir="auto">Rate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png" alt="rate-limiting"></a></p>
<h2 tabindex="-1" dir="auto">
Why do we need Rate Limiting?</h2>
<p dir="auto">Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following:</p>
<ul dir="auto">
<li>Avoid resource starvation as a result of Denial of Service (DoS) attacks.</li>
<li>Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills.</li>
<li>Rate limiting can be used as defense or mitigation against some common attacks.</li>
<li>For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Algorithms</h2>
<p dir="auto">There are various algorithms for API rate limiting, each with its advantages and disadvantages. Let's briefly discuss some of these algorithms:</p>
<h3 tabindex="-1" dir="auto">
Leaky Bucket</h3>
<p dir="auto">Leaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked).</p>
<h3 tabindex="-1" dir="auto">
Token Bucket</h3>
<p dir="auto">Here we use a concept of a <em>bucket</em>. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period.</p>
<h3 tabindex="-1" dir="auto">
Fixed Window</h3>
<p dir="auto">The system uses a window size of <code>n</code> seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold.</p>
<h3 tabindex="-1" dir="auto">
Sliding Log</h3>
<p dir="auto">Sliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.</p>
<h3 tabindex="-1" dir="auto">
Sliding Window</h3>
<p dir="auto">Sliding Window is a hybrid approach that combines the fixed window algorithm's low processing cost and the sliding log's improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window's request rate based on the current timestamp to smooth out bursts of traffic.</p>
<h2 tabindex="-1" dir="auto">
Rate Limiting in Distributed Systems</h2>
<p dir="auto">Rate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:</p>
<h3 tabindex="-1" dir="auto">
Inconsistencies</h3>
<p dir="auto">When using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.</p>
<p dir="auto">The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like <a href="https://redis.io/" rel="nofollow">Redis</a> but this will increase latency and cause race conditions.</p>
<h3 tabindex="-1" dir="auto">
Race Conditions</h3>
<p dir="auto">This issue happens when we use a naive <em>"get-then-set"</em> approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model's problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.</p>
<p dir="auto">One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a <em>"set-then-get"</em> approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.</p>
<h2 tabindex="-1" dir="auto">
Service Discovery</h2>
<p dir="auto">Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.</p>
<h2 tabindex="-1" dir="auto">
Why do we need Service Discovery?</h2>
<p dir="auto">In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.</p>
<h2 tabindex="-1" dir="auto">
Implementations</h2>
<p dir="auto">There are two main service discovery patterns:</p>
<h3 tabindex="-1" dir="auto">
Client-side discovery</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png" alt="client-side-service-discovery"></a></p>
<p dir="auto">In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.</p>
<h3 tabindex="-1" dir="auto">
Server-side discovery</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png" alt="server-side-service-discovery"></a></p>
<p dir="auto">In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.</p>
<h2 tabindex="-1" dir="auto">
Service Registry</h2>
<p dir="auto">A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.</p>
<h2 tabindex="-1" dir="auto">
Service Registration</h2>
<p dir="auto">We also need a way to obtain service information, often known as service registration. Let's look at two possible service registration approaches:</p>
<h3 tabindex="-1" dir="auto">
Self-Registration</h3>
<p dir="auto">When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat&nbsp;requests to keep its registration alive.</p>
<h3 tabindex="-1" dir="auto">
Third-party Registration</h3>
<p dir="auto">The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.</p>
<h2 tabindex="-1" dir="auto">
Service mesh</h2>
<p dir="auto">Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. <a href="https://istio.io/latest/about/service-mesh" rel="nofollow">Istio</a> and <a href="https://www.envoyproxy.io/" rel="nofollow">envoy</a> are some of the most commonly used service mesh technologies.</p>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">Here are some commonly used service discovery infrastructure tools:</p>
<ul dir="auto">
<li><a href="https://etcd.io/" rel="nofollow">etcd</a></li>
<li><a href="https://www.consul.io/" rel="nofollow">Consul</a></li>
<li><a href="https://thrift.apache.org/" rel="nofollow">Apache Thrift</a></li>
<li><a href="https://zookeeper.apache.org/" rel="nofollow">Apache Zookeeper</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
SLA, SLO, SLI</h2>
<p dir="auto">Let's briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.</p>
<h2 tabindex="-1" dir="auto">
Why are they important?</h2>
<p dir="auto">SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.</p>
<h2 tabindex="-1" dir="auto">
SLA</h2>
<p dir="auto">An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.</p>
<p dir="auto"><em>SLAs are often written by a company's business or legal team.</em></p>
<h2 tabindex="-1" dir="auto">
SLO</h2>
<p dir="auto">An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.</p>
<h2 tabindex="-1" dir="auto">
SLI</h2>
<p dir="auto">An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI's value must always meet or exceed the value determined by the SLO.</p>
<h2 tabindex="-1" dir="auto">
Disaster recovery</h2>
<p dir="auto">Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.</p>
<p dir="auto">Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.</p>
<p dir="auto"><em>Disaster Recovery is often not actively discussed during system design interviews but it's important to have some basic understanding of this topic. You can learn more about disaster recovery from <a href="https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html" rel="nofollow">AWS Well-Architected Framework</a>.</em></p>
<h2 tabindex="-1" dir="auto">
Why is disaster recovery important?</h2>
<p dir="auto">Disaster recovery can have the following benefits:</p>
<ul dir="auto">
<li>Minimize interruption and downtime</li>
<li>Limit damages</li>
<li>Fast restoration</li>
<li>Better customer retention</li>
</ul>
<h2 tabindex="-1" dir="auto">
Terms</h2>
<p dir="auto">Let's discuss some important terms relevantly for disaster recovery:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png" alt="disaster-recovery"></a></p>
<h3 tabindex="-1" dir="auto">
RTO</h3>
<p dir="auto">Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.</p>
<h3 tabindex="-1" dir="auto">
RPO</h3>
<p dir="auto">Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.</p>
<h2 tabindex="-1" dir="auto">
Strategies</h2>
<p dir="auto">A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.</p>
<h3 tabindex="-1" dir="auto">
Back-up</h3>
<p dir="auto">This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.</p>
<h3 tabindex="-1" dir="auto">
Cold Site</h3>
<p dir="auto">In this type of disaster recovery, an organization sets up basic infrastructure in a second site.</p>
<h3 tabindex="-1" dir="auto">
Hot site</h3>
<p dir="auto">A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.</p>
<h2 tabindex="-1" dir="auto">
Virtual Machines (VMs) and Containers</h2>
<p dir="auto">Before we discuss virtualization vs containerization, let's learn what are virtual machines (VMs) and Containers.</p>
<h2 tabindex="-1" dir="auto">
Virtual Machines (VM)</h2>
<p dir="auto">A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine's resources from the hardware and provisions them appropriately so they can be used by the VM.</p>
<p dir="auto">VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.</p>
<h3 tabindex="-1" dir="auto">
What is a Hypervisor?</h3>
<p dir="auto">A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.</p>
<h3 tabindex="-1" dir="auto">
Why use a Virtual Machine?</h3>
<p dir="auto">Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.</p>
<p dir="auto">A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won't interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.</p>
<h2 tabindex="-1" dir="auto">
Containers</h2>
<p dir="auto">A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.</p>
<h3 tabindex="-1" dir="auto">
Why do we need containers?</h3>
<p dir="auto">Let's discuss some advantages of using containers:</p>
<p dir="auto"><strong>Separation of responsibility</strong></p>
<p dir="auto">Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.</p>
<p dir="auto"><strong>Workload portability</strong></p>
<p dir="auto">Containers can run virtually anywhere, greatly easing development and deployment.</p>
<p dir="auto"><strong>Application isolation</strong></p>
<p dir="auto">Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.</p>
<p dir="auto"><strong>Agile development</strong></p>
<p dir="auto">Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.</p>
<p dir="auto"><strong>Efficient operations</strong></p>
<p dir="auto">Containers are lightweight and allow us to use just the computing resources we need.</p>
<h2 tabindex="-1" dir="auto">
Virtualization vs Containerization</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png" alt="virtualization-vs-containerization"></a></p>
<p dir="auto">In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.</p>
<p dir="auto">Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.</p>
<h2 tabindex="-1" dir="auto">
OAuth 2.0 and OpenID Connect (OIDC)</h2>
<h2 tabindex="-1" dir="auto">
OAuth 2.0</h2>
<p dir="auto">OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user's credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user's data.</p>
<h3 tabindex="-1" dir="auto">
Concepts</h3>
<p dir="auto">The OAuth 2.0 protocol defines the following entities:</p>
<ul dir="auto">
<li>
<strong>Resource Owner</strong>: The user or system that owns the protected resources and can grant access to them.</li>
<li>
<strong>Client</strong>: The client is the system that requires access to the protected resources.</li>
<li>
<strong>Authorization Server</strong>: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.</li>
<li>
<strong>Resource Server</strong>: A server that protects the user's resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.</li>
<li>
<strong>Scopes</strong>: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.</li>
<li>
<strong>Access Token</strong>: A piece of data that represents the authorization to access resources on behalf of the end-user.</li>
</ul>
<h3 tabindex="-1" dir="auto">
How does OAuth 2.0 work?</h3>
<p dir="auto">Let's learn how OAuth 2.0 works:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png" alt="oauth2"></a></p>
<ol dir="auto">
<li>The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.</li>
<li>The Authorization Server authenticates the client and verifies that the requested scopes are permitted.</li>
<li>The resource owner interacts with the authorization server to grant access.</li>
<li>The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.</li>
<li>With the Access Token, the client can request access to the resource from the Resource Server.</li>
</ol>
<h3 tabindex="-1" dir="auto">
Disadvantages</h3>
<p dir="auto">Here are the most common disadvantages of OAuth 2.0:</p>
<ul dir="auto">
<li>Lacks built-in security features.</li>
<li>No standard implementation.</li>
<li>No common set of scopes.</li>
</ul>
<h2 tabindex="-1" dir="auto">
OpenID Connect</h2>
<p dir="auto">OAuth 2.0 is designed only for <em>authorization</em>, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.</p>
<p dir="auto">When an Authorization Server supports OIDC, it is sometimes called an identity provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.</p>
<h3 tabindex="-1" dir="auto">
Concepts</h3>
<p dir="auto">The OpenID Connect (OIDC) protocol defines the following entities:</p>
<ul dir="auto">
<li>
<strong>Relying Party</strong>: The current application.</li>
<li>
<strong>OpenID Provider</strong>: This is essentially an intermediate service that provides a one-time code to the Relying Party.</li>
<li>
<strong>Token Endpoint</strong>: A web server that accepts the One-Time Code (OTC) and provides an access code that's valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).</li>
<li>
<strong>UserInfo Endpoint</strong>: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user</li>
</ul>
<p dir="auto">Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.</p>
<h2 tabindex="-1" dir="auto">
Single Sign-On (SSO)</h2>
<p dir="auto">Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.</p>
<p dir="auto">The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.</p>
<p dir="auto">Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.</p>
<h2 tabindex="-1" dir="auto">
Components</h2>
<p dir="auto">Let's discuss some key components of Single Sign-On (SSO).</p>
<h3 tabindex="-1" dir="auto">
Identity Provider (IdP)</h3>
<p dir="auto">User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.</p>
<p dir="auto">The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user's identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.</p>
<h3 tabindex="-1" dir="auto">
Service Provider</h3>
<p dir="auto">A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.</p>
<h3 tabindex="-1" dir="auto">
Identity Broker</h3>
<p dir="auto">An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.</p>
<h2 tabindex="-1" dir="auto">
SAML</h2>
<p dir="auto">Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.</p>
<p dir="auto">SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.</p>
<h2 tabindex="-1" dir="auto">
How does SSO work?</h2>
<p dir="auto">Now, let's discuss how Single Sign-On works:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png" alt="sso"></a></p>
<ol dir="auto">
<li>The user requests a resource from their desired application.</li>
<li>The application redirects the user to the Identity Provider (IdP) for authentication.</li>
<li>The user signs in with their credentials (usually, username and password).</li>
<li>Identity Provider (IdP) sends a Single Sign-On response back to the client application.</li>
<li>The application grants access to the user.</li>
</ol>
<h2 tabindex="-1" dir="auto">
SAML vs OAuth 2.0 and OpenID Connect (OIDC)</h2>
<p dir="auto">There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.</p>
<p dir="auto">OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.</p>
<p dir="auto">OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.</p>
<p dir="auto">OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.</p>
<p dir="auto"><em>Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience.</em></p>
<h2 tabindex="-1" dir="auto">
Advantages</h2>
<p dir="auto">Following are the benefits of using Single Sign-On:</p>
<ul dir="auto">
<li>Ease of use as users only need to remember one set of credentials.</li>
<li>Ease of access without having to go through a lengthy authorization process.</li>
<li>Enforced security and compliance to protect sensitive data.</li>
<li>Simplifying the management with reduced IT support cost and admin time.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Disadvantages</h2>
<p dir="auto">Here are some disadvantages of Single Sign-On:</p>
<ul dir="auto">
<li>Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.</li>
<li>The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Examples</h2>
<p dir="auto">These are some commonly used Identity Providers (IdP):</p>
<ul dir="auto">
<li><a href="https://www.okta.com/" rel="nofollow">Okta</a></li>
<li><a href="https://cloud.google.com/architecture/identity/single-sign-on" rel="nofollow">Google</a></li>
<li><a href="https://auth0.com/" rel="nofollow">Auth0</a></li>
<li><a href="https://www.onelogin.com/" rel="nofollow">OneLogin</a></li>
</ul>
<h2 tabindex="-1" dir="auto">
SSL, TLS, mTLS</h2>
<p dir="auto">Let's briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a <em>"big picture"</em> system design perspective, this topic is not very important but still good to know about.</p>
<h2 tabindex="-1" dir="auto">
SSL</h2>
<p dir="auto">SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).</p>
<h3 tabindex="-1" dir="auto">
Why is it called an SSL certificate if it is deprecated?</h3>
<p dir="auto">Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.</p>
<h3 tabindex="-1" dir="auto">
Why was SSL so important?</h3>
<p dir="auto">Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.</p>
<h2 tabindex="-1" dir="auto">
TLS</h2>
<p dir="auto">Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.</p>
<p dir="auto">There are three main components to what the TLS protocol accomplishes:</p>
<ul dir="auto">
<li>
<strong>Encryption</strong>: hides the data being transferred from third parties.</li>
<li>
<strong>Authentication</strong>: ensures that the parties exchanging information are who they claim to be.</li>
<li>
<strong>Integrity</strong>: verifies that the data has not been forged or tampered with.</li>
</ul>
<h2 tabindex="-1" dir="auto">
mTLS</h2>
<p dir="auto">Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.</p>
<h3 tabindex="-1" dir="auto">
Why use mTLS?</h3>
<p dir="auto">mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization's network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.</p>
<p dir="auto">Nowadays, mTLS is commonly used by microservices or distributed systems in a <a href="https://en.wikipedia.org/wiki/Zero_trust_security_model" rel="nofollow">zero trust security model</a> to verify each other.</p>
<h2 tabindex="-1" dir="auto">
System Design Interviews</h2>
<p dir="auto">System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they're not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.</p>
<p dir="auto">Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who's new in the industry. As a result, it's hard to come up with a single strategy that will help us stay organized during the interview.</p>
<p dir="auto">Let's look at some common strategies for system design interviews:</p>
<h2 tabindex="-1" dir="auto">
Requirements clarifications</h2>
<p dir="auto">System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<p dir="auto">These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.</p>
<p dir="auto">For example:</p>
<ul dir="auto">
<li>"What are the features that we need to design for this system?"</li>
<li>"What are the edge cases we need to consider, if any, in our design?"</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-functional requirements</h3>
<p dir="auto">These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.</p>
<p dir="auto">For example:</p>
<ul dir="auto">
<li>"Each request should be processed with the minimum latency"</li>
<li>"System should be highly available"</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<p dir="auto">These are basically "nice to have" requirements that might be out of the scope of the system.</p>
<p dir="auto">For example:</p>
<ul dir="auto">
<li>"Our system should record metrics and analytics"</li>
<li>"Service health and performance monitoring?"</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Estimate the scale of the system we're going to design. It is important to ask questions such as:</p>
<ul dir="auto">
<li>"What is the desired scale that this system will need to handle?"</li>
<li>"What is the read/write ratio of our system?"</li>
<li>"How many requests per second?"</li>
<li>"How much storage will be needed?"</li>
</ul>
<p dir="auto">These questions will help us scale our design later.</p>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them.</p>
<ul dir="auto">
<li>"What are the different entities in the system?"</li>
<li>"What are the relationships between these entities?"</li>
<li>"How many tables do we need?"</li>
<li>"Is NoSQL a better choice here?"</li>
</ul>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don't have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.</p>
<p dir="auto">For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="createUser(name: string, email: string): User"><pre><span>createUser</span><span>(</span><span>name</span>: <span>string</span><span>,</span> <span>email</span>: <span>string</span><span>)</span>: <span>User</span></pre></div>
<p dir="auto">It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.</p>
<h2 tabindex="-1" dir="auto">
High-level component design</h2>
<p dir="auto">Now we have established our data model and API design, it's time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system.</p>
<ul dir="auto">
<li>"Is it best to design a monolithic or a microservices architecture?"</li>
<li>"What type of database should we use?"</li>
</ul>
<p dir="auto">Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client's perspective.</p>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">Now it's time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.</p>
<p dir="auto">Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional.</p>
<ul dir="auto">
<li>"How should we partition our data?"</li>
<li>"What about load distribution?"</li>
<li>"Should we use cache?"</li>
<li>"How will we handle a sudden spike in traffic?"</li>
</ul>
<p dir="auto">Also, try not to be too opinionated about certain technologies, statements like "I believe that NoSQL databases are just better, SQL databases are not scalable" reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.</p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto">Finally, it's time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask:</p>
<ul dir="auto">
<li>"Do we have enough database replicas?"</li>
<li>"Is there any single point of failure?"</li>
<li>"Is database sharding required?"</li>
<li>"How can we make our system more robust?"</li>
<li>"How to improve the availability of our cache?"</li>
</ul>
<p dir="auto">Make sure to read the engineering blog of the company you're interviewing with. This will help you get a sense of what technology stack they're using and which problems are important to them.</p>
<h2 tabindex="-1" dir="auto">
URL Shortener</h2>
<p dir="auto">Let's design a URL shortener, similar to services like <a href="https://bitly.com/" rel="nofollow">Bitly</a>, <a href="https://tinyurl.com/app" rel="nofollow">TinyURL</a>.</p>
<h2 tabindex="-1" dir="auto">
What is a URL Shortener?</h2>
<p dir="auto">A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.</p>
<p dir="auto">For example, the following long URL can be changed to a shorter URL.</p>
<p dir="auto"><strong>Long URL</strong>: <a href="https://karanpratapsingh.com/courses/system-design/url-shortener" rel="nofollow">https://karanpratapsingh.com/courses/system-design/url-shortener</a></p>
<p dir="auto"><strong>Short URL</strong>: <a href="https://bit.ly/3I71d3o" rel="nofollow">https://bit.ly/3I71d3o</a></p>
<h2 tabindex="-1" dir="auto">
Why do we need a URL shortener?</h2>
<p dir="auto">URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.</p>
<h2 tabindex="-1" dir="auto">
Requirements</h2>
<p dir="auto">Our URL shortening system should meet the following requirements:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<ul dir="auto">
<li>Given a URL, our service should generate a <em>shorter and unique</em> alias for it.</li>
<li>Users should be redirected to the original URL when they visit the short link.</li>
<li>Links should expire after a default timespan.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-functional requirements</h3>
<ul dir="auto">
<li>High availability with minimal latency.</li>
<li>The system should be scalable and efficient.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<ul dir="auto">
<li>Prevent abuse of services.</li>
<li>Record analytics and metrics for redirections.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Let's start with the estimation and constraints.</p>
<p dir="auto"><em>Note: Make sure to check any scale or traffic related assumptions with your interviewer.</em></p>
<h3 tabindex="-1" dir="auto">
Traffic</h3>
<p dir="auto">This will be a read-heavy system, so let's assume a <code>100:1</code> read/write ratio with 100 million links generated per month.</p>
<p dir="auto"><strong>Reads/Writes Per month</strong></p>
<p dir="auto">For reads per month:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \times 100 \space million = 10 \space billion/month
$$</math-renderer></p>
<p dir="auto">Similarly for writes:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
1 \times 100 \space million = 100 \space million/month
$$</math-renderer></p>
<p dir="auto"><strong>What would be Requests Per Second (RPS) for our system?</strong></p>
<p dir="auto">100 million requests per month translate into 40 requests per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$</math-renderer></p>
<p dir="auto">And with a <code>100:1</code> read/write ratio, the number of redirections will be:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Bandwidth</h3>
<p dir="auto">Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
40 \times 500 \space bytes = 20 \space KB/second
$$</math-renderer></p>
<p dir="auto">Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$</math-renderer></p>
<p dir="auto">Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Cache</h3>
<p dir="auto">For caching, we will follow the classic <a href="https://en.wikipedia.org/wiki/Pareto_principle" rel="nofollow">Pareto principle</a> also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.</p>
<p dir="auto">Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$</math-renderer></p>
<p dir="auto">Hence, we will need around 35GB of memory per day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
High-level estimate</h3>
<p dir="auto">Here is our high-level estimate:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Writes (New URLs)</td>
<td>40/s</td>
</tr>
<tr>
<td>Reads (Redirection)</td>
<td>4K/s</td>
</tr>
<tr>
<td>Bandwidth (Incoming)</td>
<td>20 KB/s</td>
</tr>
<tr>
<td>Bandwidth (Outgoing)</td>
<td>2 MB/s</td>
</tr>
<tr>
<td>Storage (10 years)</td>
<td>6 TB</td>
</tr>
<tr>
<td>Memory (Caching)</td>
<td>~35 GB/day</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">Next, we will focus on the data model design. Here is our database schema:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png" alt="url-shortener-datamodel"></a></p>
<p dir="auto">Initially, we can get started with just two tables:</p>
<p dir="auto"><strong>users</strong></p>
<p dir="auto">Stores user's details such as <code>name</code>, <code>email</code>, <code>createdAt</code>, etc.</p>
<p dir="auto"><strong>urls</strong></p>
<p dir="auto">Contains the new short URL's properties such as <code>expiration</code>, <code>hash</code>, <code>originalURL</code>, and <code>userID</code> of the user who created the short URL. We can also use the <code>hash</code> column as an <a href="https://karanpratapsingh.com/courses/system-design/indexes" rel="nofollow">index</a> to improve the query performance.</p>
<h3 tabindex="-1" dir="auto">
What kind of database should we use?</h3>
<p dir="auto">Since the data is not strongly relational, NoSQL databases such as <a href="https://aws.amazon.com/dynamodb" rel="nofollow">Amazon DynamoDB</a>, <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Apache Cassandra</a>, or <a href="https://www.mongodb.com/" rel="nofollow">MongoDB</a> will be a better choice here, if we do decide to use an SQL database then we can use something like <a href="https://azure.microsoft.com/en-in/products/azure-sql/database" rel="nofollow">Azure SQL Database</a> or <a href="https://aws.amazon.com/rds" rel="nofollow">Amazon RDS</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases" rel="nofollow">SQL vs NoSQL</a>.</em></p>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Let us do a basic API design for our services:</p>
<h3 tabindex="-1" dir="auto">
Create URL</h3>
<p dir="auto">This API should create a new short URL in our system given an original URL.</p>
<div dir="auto" data-snippet-clipboard-copy-content="createURL(apiKey: string, originalURL: string, expiration?: Date): string"><pre><span>createURL</span><span>(</span><span>apiKey</span>: <span>string</span><span>,</span> <span>originalURL</span>: string<span>,</span> <span>expiration</span>?: <span>Date</span><span>)</span>: <span>string</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">API Key (<code>string</code>): API key provided by the user.</p>
<p dir="auto">Original URL (<code>string</code>): Original URL to be shortened.</p>
<p dir="auto">Expiration (<code>Date</code>): Expiration date of the new URL <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Short URL (<code>string</code>): New shortened URL.</p>
<h3 tabindex="-1" dir="auto">
Get URL</h3>
<p dir="auto">This API should retrieve the original URL from a given short URL.</p>
<div dir="auto" data-snippet-clipboard-copy-content="getURL(apiKey: string, shortURL: string): string"><pre><span>getURL</span><span>(</span><span>apiKey</span>: <span>string</span><span>,</span> <span>shortURL</span>: string<span>)</span>: <span>string</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">API Key (<code>string</code>): API key provided by the user.</p>
<p dir="auto">Short URL (<code>string</code>): Short URL mapped to the original URL.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Original URL (<code>string</code>): Original URL to be retrieved.</p>
<h3 tabindex="-1" dir="auto">
Delete URL</h3>
<p dir="auto">This API should delete a given shortURL from our system.</p>
<div dir="auto" data-snippet-clipboard-copy-content="deleteURL(apiKey: string, shortURL: string): boolean"><pre><span>deleteURL</span><span>(</span><span>apiKey</span>: <span>string</span><span>,</span> <span>shortURL</span>: string<span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">API Key (<code>string</code>): API key provided by the user.</p>
<p dir="auto">Short URL (<code>string</code>): Short URL to be deleted.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Why do we need an API key?</h3>
<p dir="auto">As you must've noticed, we're using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.</p>
<h2 tabindex="-1" dir="auto">
High-level design</h2>
<p dir="auto">Now let us do a high-level design of our system.</p>
<h3 tabindex="-1" dir="auto">
URL Encoding</h3>
<p dir="auto">Our system's primary goal is to shorten a given URL, let's look at different approaches:</p>
<p dir="auto"><strong>Base62 Approach</strong></p>
<p dir="auto">In this approach, we can encode the original URL using <a href="https://en.wikipedia.org/wiki/Base62" rel="nofollow">Base62</a> which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Number \space of \space URLs = 62^N
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>N</code>: Number of characters in the generated URL.</p>
<p dir="auto">So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \\
62^6 = \sim 56.8 \space billion \space URLs \\
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$</math-renderer></p>
<p dir="auto">This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.</p>
<p dir="auto"><strong>MD5 Approach</strong></p>
<p dir="auto">The <a href="https://en.wikipedia.org/wiki/MD5" rel="nofollow">MD5 message-digest algorithm</a> is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
MD5(original_url) \rightarrow base62encode \rightarrow hash
$$</math-renderer></p>
<p dir="auto">However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It's better to look for more scalable approaches.</p>
<p dir="auto"><strong>Counter Approach</strong></p>
<p dir="auto">In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$</math-renderer></p>
<p dir="auto">The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it's essentially a distributed system.</p>
<p dir="auto">To solve this issue we can use a distributed system manager such as <a href="https://zookeeper.apache.org/" rel="nofollow">Zookeeper</a> which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\begin{align*}
&amp; Range \space 1: \space 1 \rightarrow 1,000,000 \\
&amp; Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \\
&amp; Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \\
&amp; ...
\end{align*}
$$</math-renderer></p>
<p dir="auto">Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.</p>
<h3 tabindex="-1" dir="auto">
Key Generation Service (KGS)</h3>
<p dir="auto">As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.</p>
<p dir="auto"><strong>How to handle concurrent access?</strong></p>
<p dir="auto">Once the key is used, we can mark it in the database to make sure we don't reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.</p>
<p dir="auto">The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.</p>
<p dir="auto"><strong>KGS database estimations</strong></p>
<p dir="auto">As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$</math-renderer></p>
<p dir="auto">While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.</p>
<h3 tabindex="-1" dir="auto">
Caching</h3>
<p dir="auto">Now, let's talk about <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">caching</a>. As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> servers alongside our API server.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">caching</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Design</h3>
<p dir="auto">Now that we have identified some core components, let's do the first draft of our system design.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png" alt="url-shortener-basic-design"></a></p>
<p dir="auto">Here's how it works:</p>
<p dir="auto"><strong>Creating a new URL</strong></p>
<ol dir="auto">
<li>When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).</li>
<li>Key Generation Service provides a unique key to the API server and marks the key as used.</li>
<li>API server writes the new URL entry to the database and cache.</li>
<li>Our service returns an HTTP 201 (Created) response to the user.</li>
</ol>
<p dir="auto"><strong>Accessing a URL</strong></p>
<ol dir="auto">
<li>When a client navigates to a certain short URL, the request is sent to the API servers.</li>
<li>The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.</li>
<li>If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.</li>
</ol>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">It's time to discuss the finer details of our design.</p>
<h3 tabindex="-1" dir="auto">
Data Partitioning</h3>
<p dir="auto">To scale out our databases we will need to partition our data. Horizontal partitioning (aka <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a>) can be a good first step. We can use partitions schemes such as:</p>
<ul dir="auto">
<li>Hash-Based Partitioning</li>
<li>List-Based Partitioning</li>
<li>Range Based Partitioning</li>
<li>Composite Partitioning</li>
</ul>
<p dir="auto">The above approaches can still cause uneven data and load distribution, we can solve this using <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent hashing</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a> and <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent Hashing</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Database cleanup</h3>
<p dir="auto">This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:</p>
<p dir="auto"><strong>Active cleanup</strong></p>
<p dir="auto">In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a <a href="https://en.wikipedia.org/wiki/Cron" rel="nofollow">cron job</a>.</p>
<p dir="auto"><strong>Passive cleanup</strong></p>
<p dir="auto">For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.</p>
<h3 tabindex="-1" dir="auto">
Cache</h3>
<p dir="auto">Now let us talk about <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">caching</a>.</p>
<p dir="auto"><strong>Which cache eviction policy to use?</strong></p>
<p dir="auto">As we discussed before, we can use solutions like <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?</p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="nofollow">Least Recently Used (LRU)</a> can be a good policy for our system. In this policy, we discard the least recently used key first.</p>
<p dir="auto"><strong>How to handle cache miss?</strong></p>
<p dir="auto">Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.</p>
<h3 tabindex="-1" dir="auto">
Metrics and Analytics</h3>
<p dir="auto">Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor's country, platform, the number of views, etc alongside the URL entry in our database.</p>
<h3 tabindex="-1" dir="auto">
Security</h3>
<p dir="auto">For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.</p>
<p dir="auto">We can also use an <a href="https://karanpratapsingh.com/courses/system-design/api-gateway" rel="nofollow">API Gateway</a> as they can support capabilities like authorization, rate limiting, and load balancing out of the box.</p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png" alt="url-shortener-advanced-design"></a></p>
<p dir="auto">Let us identify and resolve bottlenecks such as single points of failure in our design:</p>
<ul dir="auto">
<li>"What if the API service or Key Generation Service crashes?"</li>
<li>"How will we distribute our traffic between our components?"</li>
<li>"How can we reduce the load on our database?"</li>
<li>"What if the key database used by KGS fails?"</li>
<li>"How to improve the availability of our cache?"</li>
</ul>
<p dir="auto">To make our system more resilient we can do the following:</p>
<ul dir="auto">
<li>Running multiple instances of our Servers and Key Generation Service.</li>
<li>Introducing <a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">load balancers</a> between clients, servers, databases, and cache servers.</li>
<li>Using multiple read replicas for our database as it's a read-heavy system.</li>
<li>Standby replica for our key database in case it fails.</li>
<li>Multiple instances and replicas for our distributed cache.</li>
</ul>
<h2 tabindex="-1" dir="auto">
WhatsApp</h2>
<p dir="auto">Let's design a <a href="https://whatsapp.com/" rel="nofollow">WhatsApp</a> like instant messaging service, similar to services like <a href="https://www.messenger.com/" rel="nofollow">Facebook Messenger</a>, and <a href="https://www.wechat.com/" rel="nofollow">WeChat</a>.</p>
<h2 tabindex="-1" dir="auto">
What is WhatsApp?</h2>
<p dir="auto">WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.</p>
<h2 tabindex="-1" dir="auto">
Requirements</h2>
<p dir="auto">Our system should meet the following requirements:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<ul dir="auto">
<li>Should support one-on-one chat.</li>
<li>Group chats (max 100 people).</li>
<li>Should support file sharing (image, video, etc.).</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-functional requirements</h3>
<ul dir="auto">
<li>High availability with minimal latency.</li>
<li>The system should be scalable and efficient.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<ul dir="auto">
<li>Sent, Delivered, and Read receipts of the messages.</li>
<li>Show the last seen time of users.</li>
<li>Push notifications.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Let's start with the estimation and constraints.</p>
<p dir="auto"><em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.</em></p>
<h3 tabindex="-1" dir="auto">
Traffic</h3>
<p dir="auto">Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 4 different people every day. This gives us 2 billion messages per day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
50 \space million \times 40 \space messages = 2 \space billion/day
$$</math-renderer></p>
<p dir="auto">Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 100 million files we would need to store.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
5 \space percent \times 2 \space billion = 100 \space million/day
$$</math-renderer></p>
<p dir="auto"><strong>What would be Requests Per Second (RPS) for our system?</strong></p>
<p dir="auto">2 billion requests per day translate into 24K requests per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$</math-renderer></p>
<p dir="auto">As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 100 KB on average, we will require 10 TB of storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$</math-renderer></p>
<p dir="auto">And for 10 years, we will require about 38 PB of storage.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Bandwidth</h3>
<p dir="auto">As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
High-level estimate</h3>
<p dir="auto">Here is our high-level estimate:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Daily active users (DAU)</td>
<td>50 million</td>
</tr>
<tr>
<td>Requests per second (RPS)</td>
<td>24K/s</td>
</tr>
<tr>
<td>Storage (per day)</td>
<td>~10.2 TB</td>
</tr>
<tr>
<td>Storage (10 years)</td>
<td>~38 PB</td>
</tr>
<tr>
<td>Bandwidth</td>
<td>~120 MB/s</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">This is the general data model which reflects our requirements.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png" alt="whatsapp-datamodel"></a></p>
<p dir="auto">We have the following tables:</p>
<p dir="auto"><strong>users</strong></p>
<p dir="auto">This table will contain a user's information such as <code>name</code>, <code>phoneNumber</code>, and other details.</p>
<p dir="auto"><strong>messages</strong></p>
<p dir="auto">As the name suggests, this table will store messages with properties such as <code>type</code> (text, image, video, etc.), <code>content</code>, and timestamps for message delivery. The message will also have a corresponding <code>chatID</code> or <code>groupID</code>.</p>
<p dir="auto"><strong>chats</strong></p>
<p dir="auto">This table basically represents a private chat between two users and can contain multiple messages.</p>
<p dir="auto"><strong>users_chats</strong></p>
<p dir="auto">This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.</p>
<p dir="auto"><strong>groups</strong></p>
<p dir="auto">This table represents a group made up of multiple users.</p>
<p dir="auto"><strong>users_groups</strong></p>
<p dir="auto">This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.</p>
<h3 tabindex="-1" dir="auto">
What kind of database should we use?</h3>
<p dir="auto">While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.</p>
<p dir="auto">We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a> or a distributed NoSQL database such as <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Apache Cassandra</a> for our use case.</p>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Let us do a basic API design for our services:</p>
<h3 tabindex="-1" dir="auto">
Get all chats or groups</h3>
<p dir="auto">This API will get all chats or groups for a given <code>userID</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="getAll(userID: UUID): Chat[] | Group[]"><pre><span>getAll</span><span>(</span><span>userID</span>: <span>UUID</span><span>)</span>: <span>Chat</span><span>[</span><span>]</span> <span>|</span> <span>Group</span><span>[</span><span></span><span>]</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the current user.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>Chat[] | Group[]</code>): All the chats and groups the user is a part of.</p>
<h3 tabindex="-1" dir="auto">
Get messages</h3>
<p dir="auto">Get all messages for a user given the <code>channelID</code> (chat or group id).</p>
<div dir="auto" data-snippet-clipboard-copy-content="getMessages(userID: UUID, channelID: UUID): Message[]"><pre><span>getMessages</span><span>(</span><span>userID</span>: <span>UUID</span><span>,</span> <span>channelID</span>: <span>UUID</span><span>)</span>: <span>Message</span><span>[</span><span></span><span>]</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the current user.</p>
<p dir="auto">Channel ID (<code>UUID</code>): ID of the channel (chat or group) from which messages need to be retrieved.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Messages (<code>Message[]</code>): All the messages in a given chat or group.</p>
<h3 tabindex="-1" dir="auto">
Send message</h3>
<p dir="auto">Send a message from a user to a channel (chat or group).</p>
<div dir="auto" data-snippet-clipboard-copy-content="sendMessage(userID: UUID, channelID: UUID, message: Message): boolean"><pre><span>sendMessage</span><span>(</span><span>userID</span>: <span>UUID</span><span>,</span> <span>channelID</span>: <span>UUID</span><span>,</span> <span>message</span>: <span>Message</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the current user.</p>
<p dir="auto">Channel ID (<code>UUID</code>): ID of the channel (chat or group) user wants to send a message to.</p>
<p dir="auto">Message (<code>Message</code>): The message (text, image, video, etc.) that the user wants to send.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Join or leave a channel</h3>
<p dir="auto">Allows the user to join or leave a channel (chat or group).</p>
<div dir="auto" data-snippet-clipboard-copy-content="joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean"><pre><span>joinGroup</span><span>(</span><span>userID</span>: <span>UUID</span><span>,</span> <span>channelID</span>: <span>UUID</span><span>)</span>: <span>boolean</span>
<span>leaveGroup</span><span>(</span><span>userID</span>: <span>UUID</span><span>,</span> <span>channelID</span>: <span>UUID</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the current user.</p>
<p dir="auto">Channel ID (<code>UUID</code>): ID of the channel (chat or group) the user wants to join or leave.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h2 tabindex="-1" dir="auto">
High-level design</h2>
<p dir="auto">Now let us do a high-level design of our system.</p>
<h3 tabindex="-1" dir="auto">
Architecture</h3>
<p dir="auto">We will be using <a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" rel="nofollow">microservices architecture</a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.</p>
<p dir="auto"><strong>User Service</strong></p>
<p dir="auto">This is an HTTP-based service that handles user-related concerns such as authentication and user information.</p>
<p dir="auto"><strong>Chat Service</strong></p>
<p dir="auto">The chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.</p>
<p dir="auto"><strong>Notification Service</strong></p>
<p dir="auto">This service will simply send push notifications to the users. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Presence Service</strong></p>
<p dir="auto">The presence service will keep track of the <em>last seen</em> status of all users. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Media service</strong></p>
<p dir="auto">This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.</p>
<p dir="auto"><strong>What about inter-service communication and service discovery?</strong></p>
<p dir="auto">Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" rel="nofollow">gRPC</a> which is more lightweight and efficient.</p>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/service-discovery" rel="nofollow">Service discovery</a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" rel="nofollow">REST, GraphQL, gRPC</a> and how they compare with each other.</em></p>
<h3 tabindex="-1" dir="auto">
Real-time messaging</h3>
<p dir="auto">How do we efficiently send and receive messages? We have two different options:</p>
<p dir="auto"><strong>Pull model</strong></p>
<p dir="auto">The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling" rel="nofollow">Long polling</a>.</p>
<p dir="auto"><strong>Push model</strong></p>
<p dir="auto">The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" rel="nofollow">WebSockets</a> or <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" rel="nofollow">Server-Sent Events (SSE)</a> for this.</p>
<p dir="auto">The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" rel="nofollow">WebSockets</a> is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" rel="nofollow">Server-Sent Events (SSE)</a> which are only unidirectional.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events" rel="nofollow">Long polling, WebSockets, Server-Sent Events (SSE)</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Last seen</h3>
<p dir="auto">To implement the last seen functionality, we can use a <a href="https://en.wikipedia.org/wiki/Heartbeat_(computing)" rel="nofollow">heartbeat</a> mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows:</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>User A</td>
<td>2022-07-01T14:32:50</td>
</tr>
<tr>
<td>User B</td>
<td>2022-07-05T05:10:35</td>
</tr>
<tr>
<td>User C</td>
<td>2022-07-10T04:33:25</td>
</tr>
</tbody>
</table>
<p dir="auto">This will give us the last time the user was active. This functionality will be handled by the presence service combined with <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> as our cache.</p>
<p dir="auto">Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as <em>"user hasn't performed any action in the last 30 seconds"</em>, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.</p>
<h3 tabindex="-1" dir="auto">
Notifications</h3>
<p dir="auto">Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user's active connection and last seen into consideration.</p>
<p dir="auto">If the recipient is not active, the chat service will add an event to a <a href="https://karanpratapsingh.com/courses/system-design/message-queues" rel="nofollow">message queue</a> with additional metadata such as the client's device platform which will be used to route the notification to the correct platform later on.</p>
<p dir="auto">The notification service will then consume the event from the message queue and forward the request to <a href="https://firebase.google.com/docs/cloud-messaging" rel="nofollow">Firebase Cloud Messaging (FCM)</a> or <a href="https://developer.apple.com/documentation/usernotifications" rel="nofollow">Apple Push Notification Service (APNS)</a> based on the client's device platform (Android, iOS, web, etc). We can also add support for email and SMS.</p>
<p dir="auto"><strong>Why are we using a message queue?</strong></p>
<p dir="auto">Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once which is an important part of our service functionality.</p>
<p dir="auto">While this seems like a classic <a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" rel="nofollow">publish-subscribe</a> use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like <a href="https://aws.amazon.com/sqs" rel="nofollow">Amazon SQS</a> or <a href="https://www.rabbitmq.com/" rel="nofollow">RabbitMQ</a> to support this functionality.</p>
<h3 tabindex="-1" dir="auto">
Read receipts</h3>
<p dir="auto">Handling read receipts can be tricky, for this use case we can wait for some sort of <a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)" rel="nofollow">Acknowledgment (ACK)</a> from the client to determine if the message was delivered and update the corresponding <code>deliveredAt</code> field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding <code>seenAt</code> timestamp field.</p>
<h3 tabindex="-1" dir="auto">
Design</h3>
<p dir="auto">Now that we have identified some core components, let's do the first draft of our system design.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png" alt="whatsapp-basic-design"></a></p>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">It's time to discuss our design decisions in detail.</p>
<h3 tabindex="-1" dir="auto">
Data Partitioning</h3>
<p dir="auto">To scale out our databases we will need to partition our data. Horizontal partitioning (aka <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a>) can be a good first step. We can use partitions schemes such as:</p>
<ul dir="auto">
<li>Hash-Based Partitioning</li>
<li>List-Based Partitioning</li>
<li>Range Based Partitioning</li>
<li>Composite Partitioning</li>
</ul>
<p dir="auto">The above approaches can still cause uneven data and load distribution, we can solve this using <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent hashing</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a> and <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent Hashing</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Caching</h3>
<p dir="auto">In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.</p>
<p dir="auto">Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.</p>
<p dir="auto"><strong>Which cache eviction policy to use?</strong></p>
<p dir="auto">We can use solutions like <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?</p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="nofollow">Least Recently Used (LRU)</a> can be a good policy for our system. In this policy, we discard the least recently used key first.</p>
<p dir="auto"><strong>How to handle cache miss?</strong></p>
<p dir="auto">Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">Caching</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Media access and storage</h3>
<p dir="auto">As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.</p>
<p dir="auto">But where can we store files at scale? Well, <a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" rel="nofollow">object storage</a> is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as <a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" rel="nofollow">HDFS</a> or <a href="https://www.gluster.org/" rel="nofollow">GlusterFS</a>.</p>
<p dir="auto"><em>Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user.</em></p>
<p dir="auto">We can use object stores like <a href="https://aws.amazon.com/s3" rel="nofollow">Amazon S3</a>, <a href="https://azure.microsoft.com/en-in/services/storage/blobs" rel="nofollow">Azure Blob Storage</a>, or <a href="https://cloud.google.com/storage" rel="nofollow">Google Cloud Storage</a> for this use case.</p>
<h3 tabindex="-1" dir="auto">
Content Delivery Network (CDN)</h3>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" rel="nofollow">Content Delivery Network (CDN)</a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like <a href="https://aws.amazon.com/cloudfront" rel="nofollow">Amazon CloudFront</a> or <a href="https://www.cloudflare.com/cdn" rel="nofollow">Cloudflare CDN</a> for this use case.</p>
<h3 tabindex="-1" dir="auto">
API gateway</h3>
<p dir="auto">Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an <a href="https://karanpratapsingh.com/courses/system-design/api-gateway" rel="nofollow">API Gateway</a> that supports multiple protocols without any issues.</p>
<p dir="auto">API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.</p>
<p dir="auto">We can use services like <a href="https://aws.amazon.com/api-gateway" rel="nofollow">Amazon API Gateway</a> or <a href="https://azure.microsoft.com/en-in/services/api-management" rel="nofollow">Azure API Gateway</a> for this use case.</p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png" alt="whatsapp-advanced-design"></a></p>
<p dir="auto">Let us identify and resolve bottlenecks such as single points of failure in our design:</p>
<ul dir="auto">
<li>"What if one of our services crashes?"</li>
<li>"How will we distribute our traffic between our components?"</li>
<li>"How can we reduce the load on our database?"</li>
<li>"How to improve the availability of our cache?"</li>
<li>"Wouldn't API Gateway be a single point of failure?"</li>
<li>"How can we make our notification system more robust?"</li>
<li>"How can we reduce media storage costs"?</li>
<li>"Does chat service has too much responsibility?"</li>
</ul>
<p dir="auto">To make our system more resilient we can do the following:</p>
<ul dir="auto">
<li>Running multiple instances of each of our services.</li>
<li>Introducing <a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">load balancers</a> between clients, servers, databases, and cache servers.</li>
<li>Using multiple read replicas for our databases.</li>
<li>Multiple instances and replicas for our distributed cache.</li>
<li>We can have a standby replica of our API Gateway.</li>
<li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated <a href="https://karanpratapsingh.com/courses/system-design/message-brokers" rel="nofollow">message broker</a> such as <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> or <a href="https://nats.io/" rel="nofollow">NATS</a> to make our notification system more robust.</li>
<li>We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.</li>
<li>We can create a group service separate from the chat service to further decouple our services.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Twitter</h2>
<p dir="auto">Let's design a <a href="https://twitter.com/" rel="nofollow">Twitter</a> like social media service, similar to services like <a href="https://facebook.com/" rel="nofollow">Facebook</a>, <a href="https://instagram.com/" rel="nofollow">Instagram</a>, etc.</p>
<h2 tabindex="-1" dir="auto">
What is Twitter?</h2>
<p dir="auto">Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.</p>
<h2 tabindex="-1" dir="auto">
Requirements</h2>
<p dir="auto">Our system should meet the following requirements:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<ul dir="auto">
<li>Should be able to post new tweets (can be text, image, video, etc.).</li>
<li>Should be able to follow other users.</li>
<li>Should have a newsfeed feature consisting of tweets from the people the user is following.</li>
<li>Should be able to search tweets.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-Functional requirements</h3>
<ul dir="auto">
<li>High availability with minimal latency.</li>
<li>The system should be scalable and efficient.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<ul dir="auto">
<li>Metrics and analytics.</li>
<li>Retweet functionality.</li>
<li>Favorite tweets.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Let's start with the estimation and constraints.</p>
<p dir="auto"><em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.</em></p>
<h3 tabindex="-1" dir="auto">
Traffic</h3>
<p dir="auto">This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$</math-renderer></p>
<p dir="auto">Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$</math-renderer></p>
<p dir="auto"><strong>What would be Requests Per Second (RPS) for our system?</strong></p>
<p dir="auto">1 billion requests per day translate into 12K requests per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$</math-renderer></p>
<p dir="auto">We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \space million \times 50 \space KB = 5 \space TB/day
$$</math-renderer></p>
<p dir="auto">And for 10 years, we will require about 19 PB of storage.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Bandwidth</h3>
<p dir="auto">As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
High-level estimate</h3>
<p dir="auto">Here is our high-level estimate:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Daily active users (DAU)</td>
<td>100 million</td>
</tr>
<tr>
<td>Requests per second (RPS)</td>
<td>12K/s</td>
</tr>
<tr>
<td>Storage (per day)</td>
<td>~5.1 TB</td>
</tr>
<tr>
<td>Storage (10 years)</td>
<td>~19 PB</td>
</tr>
<tr>
<td>Bandwidth</td>
<td>~60 MB/s</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">This is the general data model which reflects our requirements.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png" alt="twitter-datamodel"></a></p>
<p dir="auto">We have the following tables:</p>
<p dir="auto"><strong>users</strong></p>
<p dir="auto">This table will contain a user's information such as <code>name</code>, <code>email</code>, <code>dob</code>, and other details.</p>
<p dir="auto"><strong>tweets</strong></p>
<p dir="auto">As the name suggests, this table will store tweets and their properties such as <code>type</code> (text, image, video, etc.), <code>content</code>, etc. We will also store the corresponding <code>userID</code>.</p>
<p dir="auto"><strong>favorites</strong></p>
<p dir="auto">This table maps tweets with users for the favorite tweets functionality in our application.</p>
<p dir="auto"><strong>followers</strong></p>
<p dir="auto">This table maps the followers and <a href="https://en.wiktionary.org/wiki/followee" rel="nofollow">followees</a> as users can follow each other (N:M relationship).</p>
<p dir="auto"><strong>feeds</strong></p>
<p dir="auto">This table stores feed properties with the corresponding <code>userID</code>.</p>
<p dir="auto"><strong>feeds_tweets</strong></p>
<p dir="auto">This table maps tweets and feed (N:M relationship).</p>
<h3 tabindex="-1" dir="auto">
What kind of database should we use?</h3>
<p dir="auto">While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.</p>
<p dir="auto">We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a> or a distributed NoSQL database such as <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Apache Cassandra</a> for our use case.</p>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Let us do a basic API design for our services:</p>
<h3 tabindex="-1" dir="auto">
Post a tweet</h3>
<p dir="auto">This API will allow the user to post a tweet on the platform.</p>
<div dir="auto" data-snippet-clipboard-copy-content="postTweet(userID: UUID, content: string, mediaURL?: string): boolean"><pre><span>postTweet</span><span>(</span><span>userID</span>: <span>UUID</span><span>,</span> <span>content</span>: string<span>,</span> <span>mediaURL</span>?: string<span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the user.</p>
<p dir="auto">Content (<code>string</code>): Contents of the tweet.</p>
<p dir="auto">Media URL (<code>string</code>): URL of the attached media <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Follow or unfollow a user</h3>
<p dir="auto">This API will allow the user to follow or unfollow another user.</p>
<div dir="auto" data-snippet-clipboard-copy-content="follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean"><pre><span>follow</span><span>(</span><span>followerID</span>: <span>UUID</span><span>,</span> <span>followeeID</span>: <span>UUID</span><span>)</span>: <span>boolean</span>
<span>unfollow</span><span>(</span><span>followerID</span>: <span>UUID</span><span>,</span> <span>followeeID</span>: <span>UUID</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Follower ID (<code>UUID</code>): ID of the current user.</p>
<p dir="auto">Followee ID (<code>UUID</code>): ID of the user we want to follow or unfollow.</p>
<p dir="auto">Media URL (<code>string</code>): URL of the attached media <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Get newsfeed</h3>
<p dir="auto">This API will return all the tweets to be shown within a given newsfeed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="getNewsfeed(userID: UUID): Tweet[]"><pre><span>getNewsfeed</span><span>(</span><span>userID</span>: <span>UUID</span><span>)</span>: <span>Tweet</span><span>[</span><span></span><span>]</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">User ID (<code>UUID</code>): ID of the user.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Tweets (<code>Tweet[]</code>): All the tweets to be shown within a given newsfeed.</p>
<h2 tabindex="-1" dir="auto">
High-level design</h2>
<p dir="auto">Now let us do a high-level design of our system.</p>
<h3 tabindex="-1" dir="auto">
Architecture</h3>
<p dir="auto">We will be using <a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" rel="nofollow">microservices architecture</a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.</p>
<p dir="auto"><strong>User Service</strong></p>
<p dir="auto">This service handles user-related concerns such as authentication and user information.</p>
<p dir="auto"><strong>Newsfeed Service</strong></p>
<p dir="auto">This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Tweet Service</strong></p>
<p dir="auto">The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.</p>
<p dir="auto"><strong>Search Service</strong></p>
<p dir="auto">The service is responsible for handling search-related functionality. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Media service</strong></p>
<p dir="auto">This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Notification Service</strong></p>
<p dir="auto">This service will simply send push notifications to the users.</p>
<p dir="auto"><strong>Analytics Service</strong></p>
<p dir="auto">This service will be used for metrics and analytics use cases.</p>
<p dir="auto"><strong>What about inter-service communication and service discovery?</strong></p>
<p dir="auto">Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" rel="nofollow">gRPC</a> which is more lightweight and efficient.</p>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/service-discovery" rel="nofollow">Service discovery</a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" rel="nofollow">REST, GraphQL, gRPC</a> and how they compare with each other.</em></p>
<h3 tabindex="-1" dir="auto">
Newsfeed</h3>
<p dir="auto">When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let's divide our problem into two parts:</p>
<p dir="auto"><strong>Generation</strong></p>
<p dir="auto">Let's assume we want to generate the feed for user A, we will perform the following steps:</p>
<ol dir="auto">
<li>Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.</li>
<li>Fetch the relevant tweets for each of the retrieved IDs.</li>
<li>Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.</li>
<li>Return the ranked tweets data to the client in a paginated manner.</li>
</ol>
<p dir="auto">Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.</p>
<p dir="auto"><strong>Publishing</strong></p>
<p dir="auto">Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches:</p>
<ul dir="auto">
<li>Pull Model (or Fan-out on load)</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png" alt="newsfeed-pull-model"></a></p>
<p dir="auto">When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.</p>
<p dir="auto">The downside of this approach is that the users will not be able to view recent feeds unless they "pull" the data from the server, which will increase the number of read operations on the server.</p>
<ul dir="auto">
<li>Push Model (or Fan-out on write)</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png" alt="newsfeed-push-model"></a></p>
<p dir="auto">In this model, once a user creates a tweet, it is "pushed" to all the follower's feeds immediately. This prevents the system from having to go through a user's entire followers list to check for updates.</p>
<p dir="auto">However, the downside of this approach is that it would increase the number of write operations on the database.</p>
<ul dir="auto">
<li>Hybrid Model</li>
</ul>
<p dir="auto">A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.</p>
<p dir="auto">The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.</p>
<h3 tabindex="-1" dir="auto">
Ranking Algorithm</h3>
<p dir="auto">As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.</p>
<p dir="auto">For example, Facebook used to utilize an <a href="https://en.wikipedia.org/wiki/EdgeRank" rel="nofollow">EdgeRank</a> algorithm. Here, the rank of each feed item is described by:</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
Rank = Affinity \times Weight \times Decay
$$</math-renderer></p>
<p dir="auto">Where,</p>
<p dir="auto"><code>Affinity</code>: is the "closeness" of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.</p>
<p dir="auto"><code>Weight</code>: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.</p>
<p dir="auto"><code>Decay</code>: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.</p>
<p dir="auto">Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.</p>
<h3 tabindex="-1" dir="auto">
Retweets</h3>
<p dir="auto">Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the <code>type</code> enum and <code>content</code> property of the new tweet to link it with the original tweet.</p>
<p dir="auto">For example, the <code>type</code> enum property can be of type tweet, similar to text, video, etc and <code>content</code> can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet.</p>
<table>
<thead>
<tr>
<th>id</th>
<th>userID</th>
<th>type</th>
<th>content</th>
<th>createdAt</th>
</tr>
</thead>
<tbody>
<tr>
<td>ad34-291a-45f6-b36c</td>
<td>7a2c-62c4-4dc8-b1bb</td>
<td>text</td>
<td>Hey, this is my first tweet…</td>
<td>1658905644054</td>
</tr>
<tr>
<td>f064-49ad-9aa2-84a6</td>
<td>6aa2-2bc9-4331-879f</td>
<td>tweet</td>
<td>ad34-291a-45f6-b36c</td>
<td>1658906165427</td>
</tr>
</tbody>
</table>
<p dir="auto">This is a very basic implementation. To improve this we can create a separate table itself to store retweets.</p>
<h3 tabindex="-1" dir="auto">
Search</h3>
<p dir="auto">Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. <a href="https://www.elastic.co/" rel="nofollow">Elasticsearch</a> can help us with this use case.</p>
<p dir="auto"><a href="https://www.elastic.co/" rel="nofollow">Elasticsearch</a> is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of <a href="https://lucene.apache.org/" rel="nofollow">Apache Lucene</a>.</p>
<p dir="auto"><strong>How do we identify trending topics?</strong></p>
<p dir="auto">Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last <code>N</code> seconds and update them every <code>M</code> seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.</p>
<h3 tabindex="-1" dir="auto">
Notifications</h3>
<p dir="auto">Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> with the notification service to dispatch requests to <a href="https://firebase.google.com/docs/cloud-messaging" rel="nofollow">Firebase Cloud Messaging (FCM)</a> or <a href="https://developer.apple.com/documentation/usernotifications" rel="nofollow">Apple Push Notification Service (APNS)</a> which will handle the delivery of the push notifications to user devices.</p>
<p dir="auto"><em>For more details, refer to the <a href="https://karanpratapsingh.com/courses/system-design/whatsapp#notifications" rel="nofollow">WhatsApp</a> system design where we discuss push notifications in detail.</em></p>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">It's time to discuss our design decisions in detail.</p>
<h3 tabindex="-1" dir="auto">
Data Partitioning</h3>
<p dir="auto">To scale out our databases we will need to partition our data. Horizontal partitioning (aka <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a>) can be a good first step. We can use partitions schemes such as:</p>
<ul dir="auto">
<li>Hash-Based Partitioning</li>
<li>List-Based Partitioning</li>
<li>Range Based Partitioning</li>
<li>Composite Partitioning</li>
</ul>
<p dir="auto">The above approaches can still cause uneven data and load distribution, we can solve this using <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent hashing</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a> and <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent Hashing</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Mutual friends</h3>
<p dir="auto">For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as <a href="https://neo4j.com/" rel="nofollow">Neo4j</a> and <a href="https://www.arangodb.com/" rel="nofollow">ArangoDB</a>.</p>
<p dir="auto">This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.</p>
<h3 tabindex="-1" dir="auto">
Metrics and Analytics</h3>
<p dir="auto">Recording analytics and metrics is one of our extended requirements. As we will be using <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> to publish all sorts of events, we can process these events and run analytics on the data using <a href="https://spark.apache.org/" rel="nofollow">Apache Spark</a> which is an open-source unified analytics engine for large-scale data processing.</p>
<h3 tabindex="-1" dir="auto">
Caching</h3>
<p dir="auto">In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.</p>
<p dir="auto">To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.</p>
<p dir="auto"><strong>Which cache eviction policy to use?</strong></p>
<p dir="auto">We can use solutions like <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?</p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="nofollow">Least Recently Used (LRU)</a> can be a good policy for our system. In this policy, we discard the least recently used key first.</p>
<p dir="auto"><strong>How to handle cache miss?</strong></p>
<p dir="auto">Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">Caching</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Media access and storage</h3>
<p dir="auto">As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.</p>
<p dir="auto">But where can we store files at scale? Well, <a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" rel="nofollow">object storage</a> is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as <a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" rel="nofollow">HDFS</a> or <a href="https://www.gluster.org/" rel="nofollow">GlusterFS</a>.</p>
<h3 tabindex="-1" dir="auto">
Content Delivery Network (CDN)</h3>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" rel="nofollow">Content Delivery Network (CDN)</a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like <a href="https://aws.amazon.com/cloudfront" rel="nofollow">Amazon CloudFront</a> or <a href="https://www.cloudflare.com/cdn" rel="nofollow">Cloudflare CDN</a> for this use case.</p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png" alt="twitter-advanced-design"></a></p>
<p dir="auto">Let us identify and resolve bottlenecks such as single points of failure in our design:</p>
<ul dir="auto">
<li>"What if one of our services crashes?"</li>
<li>"How will we distribute our traffic between our components?"</li>
<li>"How can we reduce the load on our database?"</li>
<li>"How to improve the availability of our cache?"</li>
<li>"How can we make our notification system more robust?"</li>
<li>"How can we reduce media storage costs"?</li>
</ul>
<p dir="auto">To make our system more resilient we can do the following:</p>
<ul dir="auto">
<li>Running multiple instances of each of our services.</li>
<li>Introducing <a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">load balancers</a> between clients, servers, databases, and cache servers.</li>
<li>Using multiple read replicas for our databases.</li>
<li>Multiple instances and replicas for our distributed cache.</li>
<li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated <a href="https://karanpratapsingh.com/courses/system-design/message-brokers" rel="nofollow">message broker</a> such as <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> or <a href="https://nats.io/" rel="nofollow">NATS</a> to make our notification system more robust.</li>
<li>We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Netflix</h2>
<p dir="auto">Let's design a <a href="https://netflix.com/" rel="nofollow">Netflix</a> like video streaming service, similar to services like <a href="https://www.primevideo.com/" rel="nofollow">Amazon Prime Video</a>, <a href="https://www.disneyplus.com/" rel="nofollow">Disney Plus</a>, <a href="https://www.hulu.com/" rel="nofollow">Hulu</a>, <a href="https://youtube.com/" rel="nofollow">Youtube</a>, <a href="https://vimeo.com/" rel="nofollow">Vimeo</a>, etc.</p>
<h2 tabindex="-1" dir="auto">
What is Netflix?</h2>
<p dir="auto">Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.</p>
<h2 tabindex="-1" dir="auto">
Requirements</h2>
<p dir="auto">Our system should meet the following requirements:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<ul dir="auto">
<li>Users should be able to stream and share videos.</li>
<li>The content team (or users in YouTube's case) should be able to upload new videos (movies, tv shows episodes, and other content).</li>
<li>Users should be able to search for videos using titles or tags.</li>
<li>Users should be able to comment on a video similar to YouTube.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-Functional requirements</h3>
<ul dir="auto">
<li>High availability with minimal latency.</li>
<li>High reliability, no uploads should be lost.</li>
<li>The system should be scalable and efficient.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<ul dir="auto">
<li>Certain content should be <a href="https://en.wikipedia.org/wiki/Geo-blocking" rel="nofollow">geo-blocked</a>.</li>
<li>Resume video playback from the point user left off.</li>
<li>Record metrics and analytics of videos.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Let's start with the estimation and constraints.</p>
<p dir="auto"><em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.</em></p>
<h3 tabindex="-1" dir="auto">
Traffic</h3>
<p dir="auto">This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$</math-renderer></p>
<p dir="auto">Assuming a <code>200:1</code> read/write ratio, about 5 million videos will be uploaded every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{1}{200} \times 1 \space billion = 5 \space million/day
$$</math-renderer></p>
<p dir="auto"><strong>What would be Requests Per Second (RPS) for our system?</strong></p>
<p dir="auto">1 billion requests per day translate into 12K requests per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">If we assume each video is 100 MB on average, we will require about 500 TB of storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
5 \space million \times 100 \space MB = 500 \space TB/day
$$</math-renderer></p>
<p dir="auto">And for 10 years, we will require an astounding 1,825 PB of storage.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
500 \space TB \times 365 \space days \times 10 \space years = \sim 1,825 \space PB
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Bandwidth</h3>
<p dir="auto">As our system is handling 500 TB of ingress every day, we will require a minimum bandwidth of around 5.8 GB per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{500 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5.8 \space GB/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
High-level estimate</h3>
<p dir="auto">Here is our high-level estimate:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Daily active users (DAU)</td>
<td>200 million</td>
</tr>
<tr>
<td>Requests per second (RPS)</td>
<td>12K/s</td>
</tr>
<tr>
<td>Storage (per day)</td>
<td>~500 TB</td>
</tr>
<tr>
<td>Storage (10 years)</td>
<td>~1,825 PB</td>
</tr>
<tr>
<td>Bandwidth</td>
<td>~5.8 GB/s</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">This is the general data model which reflects our requirements.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png" alt="netflix-datamodel"></a></p>
<p dir="auto">We have the following tables:</p>
<p dir="auto"><strong>users</strong></p>
<p dir="auto">This table will contain a user's information such as <code>name</code>, <code>email</code>, <code>dob</code>, and other details.</p>
<p dir="auto"><strong>videos</strong></p>
<p dir="auto">As the name suggests, this table will store videos and their properties such as <code>title</code>, <code>streamURL</code>, <code>tags</code>, etc. We will also store the corresponding <code>userID</code>.</p>
<p dir="auto"><strong>tags</strong></p>
<p dir="auto">This table will simply store tags associated with a video.</p>
<p dir="auto"><strong>views</strong></p>
<p dir="auto">This table helps us to store all the views received on a video.</p>
<p dir="auto"><strong>comments</strong></p>
<p dir="auto">This table stores all the comments received on a video (like YouTube).</p>
<h3 tabindex="-1" dir="auto">
What kind of database should we use?</h3>
<p dir="auto">While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.</p>
<p dir="auto">We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a> or a distributed NoSQL database such as <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Apache Cassandra</a> for our use case.</p>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Let us do a basic API design for our services:</p>
<h3 tabindex="-1" dir="auto">
Upload a video</h3>
<p dir="auto">Given a byte stream, this API enables video to be uploaded to our service.</p>
<div dir="auto" data-snippet-clipboard-copy-content="uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean"><pre><span>uploadVideo</span><span>(</span><span>title</span>: <span>string</span><span>,</span> <span>description</span>: string<span>,</span> <span>data</span>: <span>Stream</span><span>&lt;</span><span>byte</span><span>&gt;</span><span>,</span> <span>tags</span>?: <span>string</span><span>[</span><span></span><span>]</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Title (<code>string</code>): Title of the new video.</p>
<p dir="auto">Description (<code>string</code>): Description of the new video.</p>
<p dir="auto">Data (<code>Byte[]</code>): Byte stream of the video data.</p>
<p dir="auto">Tags (<code>string[]</code>): Tags for the video <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Streaming a video</h3>
<p dir="auto">This API allows our users to stream a video with the preferred codec and resolution.</p>
<div dir="auto" data-snippet-clipboard-copy-content="streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream"><pre><span>streamVideo</span><span>(</span><span>videoID</span>: <span>UUID</span><span>,</span> <span>codec</span>: <span>Enum</span><span>&lt;</span><span>string</span><span>&gt;</span><span>,</span> <span>resolution</span>: <span>Tuple</span><span>&lt;</span><span>int</span><span>&gt;</span><span>,</span> <span>offset</span>?: <span>int</span><span>)</span>: <span>VideoStream</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Video ID (<code>UUID</code>): ID of the video that needs to be streamed.</p>
<p dir="auto">Codec (<code>Enum&lt;string&gt;</code>): Required <a href="https://en.wikipedia.org/wiki/Video_codec" rel="nofollow">codec</a> of the requested video, such as <code>h.265</code>, <code>h.264</code>, <code>VP9</code>, etc.</p>
<p dir="auto">Resolution (<code>Tuple&lt;int&gt;</code>): <a href="https://en.wikipedia.org/wiki/Display_resolution" rel="nofollow">Resolution</a> of the requested video.</p>
<p dir="auto">Offset (<code>int</code>): Offset of the video stream in seconds to stream data from any point in the video <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Stream (<code>VideoStream</code>): Data stream of the requested video.</p>
<h3 tabindex="-1" dir="auto">
Search for a video</h3>
<p dir="auto">This API will enable our users to search for a video based on its title or tags.</p>
<div dir="auto" data-snippet-clipboard-copy-content="searchVideo(query: string, nextPage?: string): Video[]"><pre><span>searchVideo</span><span>(</span><span>query</span>: <span>string</span><span>,</span> <span>nextPage</span>?: string<span>)</span>: <span>Video</span><span>[</span><span></span><span>]</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Query (<code>string</code>): Search query from the user.</p>
<p dir="auto">Next Page (<code>string</code>): Token for the next page, this can be used for pagination <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Videos (<code>Video[]</code>): All the videos available for a particular search query.</p>
<h3 tabindex="-1" dir="auto">
Add a comment</h3>
<p dir="auto">This API will allow our users to post a comment on a video (like YouTube).</p>
<div dir="auto" data-snippet-clipboard-copy-content="comment(videoID: UUID, comment: string): boolean"><pre><span>comment</span><span>(</span><span>videoID</span>: <span>UUID</span><span>,</span> <span>comment</span>: string<span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">VideoID (<code>UUID</code>): ID of the video user wants to comment on.</p>
<p dir="auto">Comment (<code>string</code>): The text content of the comment.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h2 tabindex="-1" dir="auto">
High-level design</h2>
<p dir="auto">Now let us do a high-level design of our system.</p>
<h3 tabindex="-1" dir="auto">
Architecture</h3>
<p dir="auto">We will be using <a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" rel="nofollow">microservices architecture</a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.</p>
<p dir="auto"><strong>User Service</strong></p>
<p dir="auto">This service handles user-related concerns such as authentication and user information.</p>
<p dir="auto"><strong>Stream Service</strong></p>
<p dir="auto">The stream service will handle video streaming-related functionality.</p>
<p dir="auto"><strong>Search Service</strong></p>
<p dir="auto">The service is responsible for handling search-related functionality. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Media service</strong></p>
<p dir="auto">This service will handle the video uploads and processing. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Analytics Service</strong></p>
<p dir="auto">This service will be used for metrics and analytics use cases.</p>
<p dir="auto"><strong>What about inter-service communication and service discovery?</strong></p>
<p dir="auto">Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" rel="nofollow">gRPC</a> which is more lightweight and efficient.</p>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/service-discovery" rel="nofollow">Service discovery</a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" rel="nofollow">REST, GraphQL, gRPC</a> and how they compare with each other.</em></p>
<h3 tabindex="-1" dir="auto">
Video processing</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png" alt="video-processing-pipeline"></a></p>
<p dir="auto">There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.</p>
<p dir="auto">Here's how we can process videos once they're uploaded by the content team (or users in YouTube's case) and are queued for processing in our <a href="https://karanpratapsingh.com/courses/system-design/message-queues" rel="nofollow">message queue</a>.</p>
<p dir="auto">Let's discuss how this works:</p>
<ul dir="auto">
<li><strong>File Chunker</strong></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png" alt="file-chunking"></a></p>
<p dir="auto">This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.</p>
<p dir="auto">Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved.</p>
<ul dir="auto">
<li><strong>Content Filter</strong></li>
</ul>
<p dir="auto">This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to <a href="https://en.wikipedia.org/wiki/Motion_picture_content_rating_system" rel="nofollow">content rating</a> of the media or can be strictly enforced like by YouTube.</p>
<p dir="auto">This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a <a href="https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues" rel="nofollow">dead-letter queue (DLQ)</a> and someone from the moderation team can do further inspection.</p>
<ul dir="auto">
<li><strong>Transcoder</strong></li>
</ul>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Transcoding" rel="nofollow">Transcoding</a> is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different <a href="https://en.wikipedia.org/wiki/Video_codec" rel="nofollow">codecs</a> to perform bitrate adjustment, image downsampling, or re-encoding the media.</p>
<p dir="auto">This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as <a href="https://ffmpeg.org/" rel="nofollow">FFmpeg</a> or cloud-based solutions like <a href="https://aws.amazon.com/mediaconvert" rel="nofollow">AWS Elemental MediaConvert</a> can be used to implement this step of the pipeline.</p>
<ul dir="auto">
<li><strong>Quality Conversion</strong></li>
</ul>
<p dir="auto">This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.</p>
<p dir="auto">It allows us to fetch the desired quality of the video as per the user's request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as <a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" rel="nofollow">HDFS</a>, <a href="https://www.gluster.org/" rel="nofollow">GlusterFS</a>, or an <a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" rel="nofollow">object storage</a> such as <a href="https://aws.amazon.com/s3" rel="nofollow">Amazon S3</a> for later retrieval during streaming.</p>
<p dir="auto"><em>Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline.</em></p>
<p dir="auto"><strong>Why are we using a message queue?</strong></p>
<p dir="auto">Processing videos as a long-running task and using a <a href="https://karanpratapsingh.com/courses/system-design/message-queues" rel="nofollow">message queue</a> makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like <a href="https://aws.amazon.com/sqs" rel="nofollow">Amazon SQS</a> or <a href="https://www.rabbitmq.com/" rel="nofollow">RabbitMQ</a> to support this.</p>
<h3 tabindex="-1" dir="auto">
Video streaming</h3>
<p dir="auto">Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don't re-fetch the same content, we can use a <a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" rel="nofollow">Content Delivery Network (CDN)</a>.</p>
<p dir="auto">Netflix takes this a step further with its <a href="https://openconnect.netflix.com/" rel="nofollow">Open Connect</a> program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.</p>
<p dir="auto"><strong>What is the difference between Netflix's Open Connect and a traditional Content Delivery Network (CDN)?</strong></p>
<p dir="auto">Netflix Open Connect is a purpose-built <a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" rel="nofollow">Content Delivery Network (CDN)</a> responsible for serving Netflix's video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.</p>
<p dir="auto">Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.</p>
<p dir="auto">Additionally, we can use <a href="https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming" rel="nofollow">Adaptive bitrate streaming</a> protocols such as <a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming" rel="nofollow">HTTP Live Streaming (HLS)</a> which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.</p>
<p dir="auto">Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the <code>offset</code> property we stored in the <code>views</code> table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.</p>
<h3 tabindex="-1" dir="auto">
Searching</h3>
<p dir="auto">Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. <a href="https://www.elastic.co/" rel="nofollow">Elasticsearch</a> can help us with this use case.</p>
<p dir="auto"><a href="https://www.elastic.co/" rel="nofollow">Elasticsearch</a> is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of <a href="https://lucene.apache.org/" rel="nofollow">Apache Lucene</a>.</p>
<p dir="auto"><strong>How do we identify trending content?</strong></p>
<p dir="auto">Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last <code>N</code> seconds and update them every <code>M</code> seconds using some sort of batch job mechanism.</p>
<h3 tabindex="-1" dir="auto">
Sharing</h3>
<p dir="auto">Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.</p>
<p dir="auto"><em>For more details, refer to the <a href="https://karanpratapsingh.com/courses/system-design/url-shortener" rel="nofollow">URL Shortener</a> system design.</em></p>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">It's time to discuss our design decisions in detail.</p>
<h3 tabindex="-1" dir="auto">
Data Partitioning</h3>
<p dir="auto">To scale out our databases we will need to partition our data. Horizontal partitioning (aka <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a>) can be a good first step. We can use partitions schemes such as:</p>
<ul dir="auto">
<li>Hash-Based Partitioning</li>
<li>List-Based Partitioning</li>
<li>Range Based Partitioning</li>
<li>Composite Partitioning</li>
</ul>
<p dir="auto">The above approaches can still cause uneven data and load distribution, we can solve this using <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent hashing</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a> and <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent Hashing</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Geo-blocking</h3>
<p dir="auto">Platforms like Netflix and YouTube use <a href="https://en.wikipedia.org/wiki/Geo-blocking" rel="nofollow">Geo-blocking</a> to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.</p>
<p dir="auto">We can determine the user's location either using their <a href="https://karanpratapsingh.com/courses/system-design/ip" rel="nofollow">IP</a> or region settings in their profile then use services like <a href="https://aws.amazon.com/cloudfront" rel="nofollow">Amazon CloudFront</a> which supports a geographic restrictions feature or a <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html" rel="nofollow">geolocation routing policy</a> with <a href="https://aws.amazon.com/route53" rel="nofollow">Amazon Route53</a> to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.</p>
<h3 tabindex="-1" dir="auto">
Recommendations</h3>
<p dir="auto">Netflix uses a machine learning model which uses the user's viewing history to predict what the user might like to watch next, an algorithm like <a href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="nofollow">Collaborative Filtering</a> can be used.</p>
<p dir="auto">However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as:</p>
<ul dir="auto">
<li>User profile information like age, gender, and location.</li>
<li>Browsing and scrolling behavior of the user.</li>
<li>Time and date a user watched a title.</li>
<li>The device which was used to stream the content.</li>
<li>The number of searches and what terms were searched.</li>
</ul>
<p dir="auto"><em>For more detail, refer to <a href="https://research.netflix.com/research-area/recommendations" rel="nofollow">Netflix recommendation research</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Metrics and Analytics</h3>
<p dir="auto">Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using <a href="https://spark.apache.org/" rel="nofollow">Apache Spark</a> which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.</p>
<h3 tabindex="-1" dir="auto">
Caching</h3>
<p dir="auto">In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> but what kind of cache eviction policy would best fit our needs?</p>
<p dir="auto"><strong>Which cache eviction policy to use?</strong></p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="nofollow">Least Recently Used (LRU)</a> can be a good policy for our system. In this policy, we discard the least recently used key first.</p>
<p dir="auto"><strong>How to handle cache miss?</strong></p>
<p dir="auto">Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">Caching</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Media streaming and storage</h3>
<p dir="auto">As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.</p>
<p dir="auto">We will use distributed file storage such as <a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" rel="nofollow">HDFS</a>, <a href="https://www.gluster.org/" rel="nofollow">GlusterFS</a>, or an <a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" rel="nofollow">object storage</a> such as <a href="https://aws.amazon.com/s3" rel="nofollow">Amazon S3</a> for storage and streaming of the content.</p>
<h3 tabindex="-1" dir="auto">
Content Delivery Network (CDN)</h3>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" rel="nofollow">Content Delivery Network (CDN)</a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like <a href="https://aws.amazon.com/cloudfront" rel="nofollow">Amazon CloudFront</a> or <a href="https://www.cloudflare.com/cdn" rel="nofollow">Cloudflare CDN</a> for this use case.</p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png" alt="netflix-advanced-design"></a></p>
<p dir="auto">Let us identify and resolve bottlenecks such as single points of failure in our design:</p>
<ul dir="auto">
<li>"What if one of our services crashes?"</li>
<li>"How will we distribute our traffic between our components?"</li>
<li>"How can we reduce the load on our database?"</li>
<li>"How to improve the availability of our cache?"</li>
</ul>
<p dir="auto">To make our system more resilient we can do the following:</p>
<ul dir="auto">
<li>Running multiple instances of each of our services.</li>
<li>Introducing <a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">load balancers</a> between clients, servers, databases, and cache servers.</li>
<li>Using multiple read replicas for our databases.</li>
<li>Multiple instances and replicas for our distributed cache.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Uber</h2>
<p dir="auto">Let's design an <a href="https://uber.com/" rel="nofollow">Uber</a> like ride-hailing service, similar to services like <a href="https://www.lyft.com/" rel="nofollow">Lyft</a>, <a href="https://www.olacabs.com/" rel="nofollow">OLA Cabs</a>, etc.</p>
<h2 tabindex="-1" dir="auto">
What is Uber?</h2>
<p dir="auto">Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.</p>
<h2 tabindex="-1" dir="auto">
Requirements</h2>
<p dir="auto">Our system should meet the following requirements:</p>
<h3 tabindex="-1" dir="auto">
Functional requirements</h3>
<p dir="auto">We will design our system for two types of users: Customers and Drivers.</p>
<p dir="auto"><strong>Customers</strong></p>
<ul dir="auto">
<li>Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.</li>
<li>Customers should be able to book a cab to a destination.</li>
<li>Customers should be able to see the location of the driver.</li>
</ul>
<p dir="auto"><strong>Drivers</strong></p>
<ul dir="auto">
<li>Drivers should be able to accept or deny the customer-requested ride.</li>
<li>Once a driver accepts the ride, they should see the pickup location of the customer.</li>
<li>Drivers should be able to mark the trip as complete on reaching the destination.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Non-Functional requirements</h3>
<ul dir="auto">
<li>High reliability.</li>
<li>High availability with minimal latency.</li>
<li>The system should be scalable and efficient.</li>
</ul>
<h3 tabindex="-1" dir="auto">
Extended requirements</h3>
<ul dir="auto">
<li>Customers can rate the trip after it's completed.</li>
<li>Payment processing.</li>
<li>Metrics and analytics.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Estimation and Constraints</h2>
<p dir="auto">Let's start with the estimation and constraints.</p>
<p dir="auto"><em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.</em></p>
<h3 tabindex="-1" dir="auto">
Traffic</h3>
<p dir="auto">Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.</p>
<p dir="auto">If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$</math-renderer></p>
<p dir="auto"><strong>What would be Requests Per Second (RPS) for our system?</strong></p>
<p dir="auto">1 billion requests per day translate into 12K requests per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Storage</h3>
<p dir="auto">If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$</math-renderer></p>
<p dir="auto">And for 10 years, we will require about 1.4 PB of storage.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
Bandwidth</h3>
<p dir="auto">As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="702a6f7bf05f27df4139c1901d6b2c8e">$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$</math-renderer></p>
<h3 tabindex="-1" dir="auto">
High-level estimate</h3>
<p dir="auto">Here is our high-level estimate:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Daily active users (DAU)</td>
<td>100 million</td>
</tr>
<tr>
<td>Requests per second (RPS)</td>
<td>12K/s</td>
</tr>
<tr>
<td>Storage (per day)</td>
<td>~400 GB</td>
</tr>
<tr>
<td>Storage (10 years)</td>
<td>~1.4 PB</td>
</tr>
<tr>
<td>Bandwidth</td>
<td>~5 MB/s</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">
Data model design</h2>
<p dir="auto">This is the general data model which reflects our requirements.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png" alt="uber-datamodel"></a></p>
<p dir="auto">We have the following tables:</p>
<p dir="auto"><strong>customers</strong></p>
<p dir="auto">This table will contain a customer's information such as <code>name</code>, <code>email</code>, and other details.</p>
<p dir="auto"><strong>drivers</strong></p>
<p dir="auto">This table will contain a driver's information such as <code>name</code>, <code>email</code>, <code>dob</code> and other details.</p>
<p dir="auto"><strong>trips</strong></p>
<p dir="auto">This table represents the trip taken by the customer and stores data such as <code>source</code>, <code>destination</code>, and <code>status</code> of the trip.</p>
<p dir="auto"><strong>cabs</strong></p>
<p dir="auto">This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.</p>
<p dir="auto"><strong>ratings</strong></p>
<p dir="auto">As the name suggests, this table stores the <code>rating</code> and <code>feedback</code> for the trip.</p>
<p dir="auto"><strong>payments</strong></p>
<p dir="auto">The payments table contains the payment-related data with the corresponding <code>tripID</code>.</p>
<h3 tabindex="-1" dir="auto">
What kind of database should we use?</h3>
<p dir="auto">While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.</p>
<p dir="auto">We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a> or a distributed NoSQL database such as <a href="https://cassandra.apache.org/_/index.html" rel="nofollow">Apache Cassandra</a> for our use case.</p>
<h2 tabindex="-1" dir="auto">
API design</h2>
<p dir="auto">Let us do a basic API design for our services:</p>
<h3 tabindex="-1" dir="auto">
Request a Ride</h3>
<p dir="auto">Through this API, customers will be able to request a ride.</p>
<div dir="auto" data-snippet-clipboard-copy-content="requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride"><pre><span>requestRide</span><span>(</span><span>customerID</span>: <span>UUID</span><span>,</span> <span>source</span>: <span>Tuple</span><span>&lt;</span><span>float</span><span>&gt;</span><span>,</span> <span>destination</span>: <span>Tuple</span><span>&lt;</span><span>float</span><span>&gt;</span><span>,</span> <span>cabType</span>: <span>Enum</span><span>&lt;</span><span>string</span><span>&gt;</span><span>,</span> <span>paymentMethod</span>: <span>Enum</span><span>&lt;</span><span>string</span><span>&gt;</span><span>)</span>: <span>Ride</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Customer ID (<code>UUID</code>): ID of the customer.</p>
<p dir="auto">Source (<code>Tuple&lt;float&gt;</code>): Tuple containing the latitude and longitude of the trip's starting location.</p>
<p dir="auto">Destination (<code>Tuple&lt;float&gt;</code>): Tuple containing the latitude and longitude of the trip's destination.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>Ride</code>): Associated ride information of the trip.</p>
<h3 tabindex="-1" dir="auto">
Cancel the Ride</h3>
<p dir="auto">This API will allow customers to cancel the ride.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cancelRide(customerID: UUID, reason?: string): boolean"><pre><span>cancelRide</span><span>(</span><span>customerID</span>: <span>UUID</span><span>,</span> <span>reason</span>?: <span>string</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Customer ID (<code>UUID</code>): ID of the customer.</p>
<p dir="auto">Reason (<code>UUID</code>): Reason for canceling the ride <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Accept or Deny the Ride</h3>
<p dir="auto">This API will allow the driver to accept or deny the trip.</p>
<div dir="auto" data-snippet-clipboard-copy-content="acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean"><pre><span>acceptRide</span><span>(</span><span>driverID</span>: <span>UUID</span><span>,</span> <span>rideID</span>: <span>UUID</span><span>)</span>: <span>boolean</span>
<span>denyRide</span><span>(</span><span>driverID</span>: <span>UUID</span><span>,</span> <span>rideID</span>: <span>UUID</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Driver ID (<code>UUID</code>): ID of the driver.</p>
<p dir="auto">Ride ID (<code>UUID</code>): ID of the customer requested ride.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Start or End the Trip</h3>
<p dir="auto">Using this API, a driver will be able to start and end the trip.</p>
<div dir="auto" data-snippet-clipboard-copy-content="startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean"><pre><span>startTrip</span><span>(</span><span>driverID</span>: <span>UUID</span><span>,</span> <span>tripID</span>: <span>UUID</span><span>)</span>: <span>boolean</span>
<span>endTrip</span><span>(</span><span>driverID</span>: <span>UUID</span><span>,</span> <span>tripID</span>: <span>UUID</span><span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Driver ID (<code>UUID</code>): ID of the driver.</p>
<p dir="auto">Trip ID (<code>UUID</code>): ID of the requested trip.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h3 tabindex="-1" dir="auto">
Rate the Trip</h3>
<p dir="auto">This API will enable customers to rate the trip.</p>
<div dir="auto" data-snippet-clipboard-copy-content="rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean"><pre><span>rateTrip</span><span>(</span><span>customerID</span>: <span>UUID</span><span>,</span> <span>tripID</span>: <span>UUID</span><span>,</span> <span>rating</span>: <span>int</span><span>,</span> <span>feedback</span>?: string<span>)</span>: <span>boolean</span></pre></div>
<p dir="auto"><strong>Parameters</strong></p>
<p dir="auto">Customer ID (<code>UUID</code>): ID of the customer.</p>
<p dir="auto">Trip ID (<code>UUID</code>): ID of the completed trip.</p>
<p dir="auto">Rating (<code>int</code>): Rating of the trip.</p>
<p dir="auto">Feedback (<code>string</code>): Feedback about the trip by the customer <em>(optional)</em>.</p>
<p dir="auto"><strong>Returns</strong></p>
<p dir="auto">Result (<code>boolean</code>): Represents whether the operation was successful or not.</p>
<h2 tabindex="-1" dir="auto">
High-level design</h2>
<p dir="auto">Now let us do a high-level design of our system.</p>
<h3 tabindex="-1" dir="auto">
Architecture</h3>
<p dir="auto">We will be using <a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" rel="nofollow">microservices architecture</a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.</p>
<p dir="auto"><strong>Customer Service</strong></p>
<p dir="auto">This service handles customer-related concerns such as authentication and customer information.</p>
<p dir="auto"><strong>Driver Service</strong></p>
<p dir="auto">This service handles driver-related concerns such as authentication and driver information.</p>
<p dir="auto"><strong>Ride Service</strong></p>
<p dir="auto">This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Trip Service</strong></p>
<p dir="auto">This service handles trip-related functionality in our system.</p>
<p dir="auto"><strong>Payment Service</strong></p>
<p dir="auto">This service will be responsible for handling payments in our system.</p>
<p dir="auto"><strong>Notification Service</strong></p>
<p dir="auto">This service will simply send push notifications to the users. It will be discussed in detail separately.</p>
<p dir="auto"><strong>Analytics Service</strong></p>
<p dir="auto">This service will be used for metrics and analytics use cases.</p>
<p dir="auto"><strong>What about inter-service communication and service discovery?</strong></p>
<p dir="auto">Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" rel="nofollow">gRPC</a> which is more lightweight and efficient.</p>
<p dir="auto"><a href="https://karanpratapsingh.com/courses/system-design/service-discovery" rel="nofollow">Service discovery</a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" rel="nofollow">REST, GraphQL, gRPC</a> and how they compare with each other.</em></p>
<h3 tabindex="-1" dir="auto">
How is the service expected to work?</h3>
<p dir="auto">Here's how our service is expected to work:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png" alt="uber-working"></a></p>
<ol dir="auto">
<li>Customer requests a ride by specifying the source, destination, cab type, payment method, etc.</li>
<li>Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).</li>
<li>The request is then broadcasted to the nearby drivers for them to accept or deny.</li>
<li>If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.</li>
<li>The customer is picked up and the driver can start the trip.</li>
<li>Once the destination is reached, the driver will mark the ride as complete and collect payment.</li>
<li>After the payment is complete, the customer can leave a rating and feedback for the trip if they like.</li>
</ol>
<h3 tabindex="-1" dir="auto">
Location Tracking</h3>
<p dir="auto">How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:</p>
<p dir="auto"><strong>Pull model</strong></p>
<p dir="auto">The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling" rel="nofollow">Long polling</a>.</p>
<p dir="auto"><strong>Push model</strong></p>
<p dir="auto">The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" rel="nofollow">WebSockets</a> or <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" rel="nofollow">Server-Sent Events (SSE)</a> for this.</p>
<p dir="auto">The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" rel="nofollow">WebSockets</a> is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" rel="nofollow">Server-Sent Events (SSE)</a> which are only unidirectional.</p>
<p dir="auto">Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.</p>
<p dir="auto"><em>Note: Learn more about <a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events" rel="nofollow">Long polling, WebSockets, Server-Sent Events (SSE)</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Ride Matching</h3>
<p dir="auto">We need a way to efficiently store and query nearby drivers. Let's explore different solutions we can incorporate into our design.</p>
<p dir="auto"><strong>SQL</strong></p>
<p dir="auto">We already have access to the latitude and longitude of our customers, and with databases like <a href="https://www.postgresql.org/" rel="nofollow">PostgreSQL</a> and <a href="https://www.mysql.com/" rel="nofollow">MySQL</a> we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).</p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R"><pre><span>SELECT</span> <span>*</span> <span>FROM</span> locations <span>WHERE</span> lat BETWEEN X<span>-</span>R <span>AND</span> X<span>+</span>R <span>AND</span> long BETWEEN Y<span>-</span>R <span>AND</span> Y<span>+</span>R</pre></div>
<p dir="auto">However, this is not scalable, and performing this query on large datasets will be quite slow.</p>
<p dir="auto"><strong>Geohashing</strong></p>
<p dir="auto"><a href="https://github.com/karanpratapsingh/system-design/blob/main/courses/sytem-design/geohashing-and-quadtrees#geohashing">Geohashing</a> is a <a href="https://en.wikipedia.org/wiki/Address_geocoding" rel="nofollow">geocoding</a> method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by <a href="https://twitter.com/gniemeyer" rel="nofollow">Gustavo Niemeyer</a> in 2008.</p>
<p dir="auto">Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png" alt="geohashing"></a></p>
<p dir="auto">For example, San Francisco with coordinates <code>37.7564, -122.4016</code> can be represented in geohash as <code>9q8yy9mf</code>.</p>
<p dir="auto">Now, using the customer's geohash we can determine the nearest available driver by simply comparing it with the driver's geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.</p>
<p dir="auto"><strong>Quadtrees</strong></p>
<p dir="auto">A <a href="https://github.com/karanpratapsingh/system-design/blob/main/courses/sytem-design/geohashing-and-quadtrees#quadtrees">Quadtree</a> is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of <a href="https://en.wikipedia.org/wiki/Octree" rel="nofollow">Octrees</a> which are used to partition three-dimensional space.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png" alt="quadtree"></a></p>
<p dir="auto">Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.</p>
<p dir="auto">We can save further computation by only subdividing a node after a certain threshold.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png" alt="quadtree-subdivision"></a></p>
<p dir="auto"><a href="https://github.com/karanpratapsingh/system-design/blob/main/courses/sytem-design/geohashing-and-quadtrees#quadtrees">Quadtree</a> seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as <a href="https://redis.io/" rel="nofollow">Redis</a> to cache the latest updates. And with the application of mapping algorithms such as the <a href="https://en.wikipedia.org/wiki/Hilbert_curve" rel="nofollow">Hilbert curve</a>, we can perform efficient range queries to find nearby drivers for the customer.</p>
<p dir="auto"><strong>What about race conditions?</strong></p>
<p dir="auto">Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)" rel="nofollow">Mutex</a> to avoid any race conditions. Furthermore, every action should be transactional in nature.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/transactions" rel="nofollow">Transactions</a> and <a href="https://karanpratapsingh.com/courses/system-design/distributed-transactions" rel="nofollow">Distributed Transactions</a>.</em></p>
<p dir="auto"><strong>How to find the best drivers nearby?</strong></p>
<p dir="auto">Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.</p>
<p dir="auto"><strong>Dealing with high demand</strong></p>
<p dir="auto">In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.</p>
<p dir="auto"><em>For more details, learn how <a href="https://www.uber.com/us/en/drive/driver-app/how-surge-works" rel="nofollow">surge pricing works</a> with Uber.</em></p>
<h3 tabindex="-1" dir="auto">
Payments</h3>
<p dir="auto">Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like <a href="https://stripe.com/" rel="nofollow">Stripe</a> or <a href="https://www.paypal.com/" rel="nofollow">PayPal</a>. Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a <a href="https://en.wikipedia.org/wiki/Webhook" rel="nofollow">webhook</a> to capture all the payment-related data.</p>
<h3 tabindex="-1" dir="auto">
Notifications</h3>
<p dir="auto">Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> with the notification service to dispatch requests to <a href="https://firebase.google.com/docs/cloud-messaging" rel="nofollow">Firebase Cloud Messaging (FCM)</a> or <a href="https://developer.apple.com/documentation/usernotifications" rel="nofollow">Apple Push Notification Service (APNS)</a> which will handle the delivery of the push notifications to user devices.</p>
<p dir="auto"><em>For more details, refer to the <a href="https://karanpratapsingh.com/courses/system-design/whatsapp#notifications" rel="nofollow">WhatsApp</a> system design where we discuss push notifications in detail.</em></p>
<h2 tabindex="-1" dir="auto">
Detailed design</h2>
<p dir="auto">It's time to discuss our design decisions in detail.</p>
<h3 tabindex="-1" dir="auto">
Data Partitioning</h3>
<p dir="auto">To scale out our databases we will need to partition our data. Horizontal partitioning (aka <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a>) can be a good first step. We can shard our database either based on existing <a href="https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria" rel="nofollow">partition schemes</a> or regions. If we divide the locations into regions using let's say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent hashing</a>.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/sharding" rel="nofollow">Sharding</a> and <a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" rel="nofollow">Consistent Hashing</a>.</em></p>
<h3 tabindex="-1" dir="auto">
Metrics and Analytics</h3>
<p dir="auto">Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using <a href="https://spark.apache.org/" rel="nofollow">Apache Spark</a> which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.</p>
<h3 tabindex="-1" dir="auto">
Caching</h3>
<p dir="auto">In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like <a href="https://redis.io/" rel="nofollow">Redis</a> or <a href="https://memcached.org/" rel="nofollow">Memcached</a> but what kind of cache eviction policy would best fit our needs?</p>
<p dir="auto"><strong>Which cache eviction policy to use?</strong></p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="nofollow">Least Recently Used (LRU)</a> can be a good policy for our system. In this policy, we discard the least recently used key first.</p>
<p dir="auto"><strong>How to handle cache miss?</strong></p>
<p dir="auto">Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.</p>
<p dir="auto"><em>For more details, refer to <a href="https://karanpratapsingh.com/courses/system-design/caching" rel="nofollow">Caching</a>.</em></p>
<h2 tabindex="-1" dir="auto">
Identify and resolve bottlenecks</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png"><img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png" alt="uber-advanced-design"></a></p>
<p dir="auto">Let us identify and resolve bottlenecks such as single points of failure in our design:</p>
<ul dir="auto">
<li>"What if one of our services crashes?"</li>
<li>"How will we distribute our traffic between our components?"</li>
<li>"How can we reduce the load on our database?"</li>
<li>"How to improve the availability of our cache?"</li>
<li>"How can we make our notification system more robust?"</li>
</ul>
<p dir="auto">To make our system more resilient we can do the following:</p>
<ul dir="auto">
<li>Running multiple instances of each of our services.</li>
<li>Introducing <a href="https://karanpratapsingh.com/courses/system-design/load-balancing" rel="nofollow">load balancers</a> between clients, servers, databases, and cache servers.</li>
<li>Using multiple read replicas for our databases.</li>
<li>Multiple instances and replicas for our distributed cache.</li>
<li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated <a href="https://karanpratapsingh.com/courses/system-design/message-brokers" rel="nofollow">message broker</a> such as <a href="https://kafka.apache.org/" rel="nofollow">Apache Kafka</a> or <a href="https://nats.io/" rel="nofollow">NATS</a> to make our notification system more robust.</li>
</ul>
<h2 tabindex="-1" dir="auto">
Next Steps</h2>
<p dir="auto">Congratulations, you've finished the course!</p>
<p dir="auto">Now that you know the fundamentals of System Design, here are some additional resources:</p>
<ul dir="auto">
<li>
<a href="https://www.youtube.com/watch?v=UEAMfLPZZhE&amp;list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB" rel="nofollow">Distributed Systems</a> (by Dr. Martin Kleppmann)</li>
<li><a href="https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF" rel="nofollow">System Design Interview: An Insider's Guide</a></li>
<li>
<a href="https://microservices.io/" rel="nofollow">Microservices</a> (by Chris Richardson)</li>
<li><a href="https://en.wikipedia.org/wiki/Serverless_computing" rel="nofollow">Serverless computing</a></li>
<li><a href="https://kubernetes.io/" rel="nofollow">Kubernetes</a></li>
</ul>
<p dir="auto">It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale:</p>
<ul dir="auto">
<li><a href="https://engineering.microsoft.com/" rel="nofollow">Microsoft Engineering</a></li>
<li><a href="http://googleresearch.blogspot.com/" rel="nofollow">Google Research Blog</a></li>
<li><a href="http://techblog.netflix.com/" rel="nofollow">Netflix Tech Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/aws" rel="nofollow">AWS Blog</a></li>
<li><a href="https://www.facebook.com/Engineering" rel="nofollow">Facebook Engineering</a></li>
<li><a href="http://eng.uber.com/" rel="nofollow">Uber Engineering Blog</a></li>
<li><a href="http://nerds.airbnb.com/" rel="nofollow">Airbnb Engineering</a></li>
<li><a href="https://github.blog/category/engineering" rel="nofollow">GitHub Engineering Blog</a></li>
<li><a href="https://software.intel.com/en-us/blogs" rel="nofollow">Intel Software Blog</a></li>
<li><a href="http://engineering.linkedin.com/blog" rel="nofollow">LinkedIn Engineering</a></li>
<li><a href="https://medium.com/paypal-engineering" rel="nofollow">Paypal Developer Blog</a></li>
<li><a href="https://blog.twitter.com/engineering" rel="nofollow">Twitter Engineering</a></li>
</ul>
<p dir="auto">Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.</p>
<p dir="auto">I hope this course was a great learning experience. I would love to hear feedback from you.</p>
<p dir="auto">Wishing you all the best for further learning!</p>
<h2 tabindex="-1" dir="auto">
References</h2>
<p dir="auto">Here are the resources that were referenced while creating this course.</p>
<ul dir="auto">
<li><a href="https://www.cloudflare.com/learning" rel="nofollow">Cloudflare learning center</a></li>
<li><a href="https://www.ibm.com/blogs" rel="nofollow">IBM Blogs</a></li>
<li><a href="https://www.fastly.com/blog" rel="nofollow">Fastly Blogs</a></li>
<li><a href="https://ns1.com/blog" rel="nofollow">NS1 Blogs</a></li>
<li><a href="https://www.educative.io/courses/grokking-the-system-design-interview" rel="nofollow">Grokking the System Design Interview</a></li>
<li><a href="https://github.com/donnemartin/system-design-primer">System Design Primer</a></li>
<li><a href="https://aws.amazon.com/blogs" rel="nofollow">AWS Blogs</a></li>
<li><a href="https://martinfowler.com/" rel="nofollow">Martin Fowler</a></li>
<li><a href="https://www.pagerduty.com/resources" rel="nofollow">PagerDuty resources</a></li>
<li><a href="https://blogs.vmware.com/learning" rel="nofollow">VMWare Blogs</a></li>
</ul>
<p dir="auto"><em>All the diagrams were made using <a href="https://excalidraw.com/" rel="nofollow">Excalidraw</a> and are available <a href="https://github.com/karanpratapsingh/system-design/tree/main/diagrams">here</a>.</em></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astro framework lowers competitors by ~40% on performance graph to looks better (193 pts)]]></title>
            <link>https://twitter.com/sigma__dev/status/1676505365935005696</link>
            <guid>36599217</guid>
            <pubDate>Wed, 05 Jul 2023 12:07:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/sigma__dev/status/1676505365935005696">https://twitter.com/sigma__dev/status/1676505365935005696</a>, See on <a href="https://news.ycombinator.com/item?id=36599217">Hacker News</a></p>
Couldn't get https://twitter.com/sigma__dev/status/1676505365935005696: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Germany Achieves Record 57.7% Renewable Energy Share for First Half of 2023 (137 pts)]]></title>
            <link>https://www.ise.fraunhofer.de/en/press-media/press-releases/2023/german-net-power-generation-in-first-half-of-2023-renewable-energy-share-of-57-percent.html</link>
            <guid>36598618</guid>
            <pubDate>Wed, 05 Jul 2023 11:04:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ise.fraunhofer.de/en/press-media/press-releases/2023/german-net-power-generation-in-first-half-of-2023-renewable-energy-share-of-57-percent.html">https://www.ise.fraunhofer.de/en/press-media/press-releases/2023/german-net-power-generation-in-first-half-of-2023-renewable-energy-share-of-57-percent.html</a>, See on <a href="https://news.ycombinator.com/item?id=36598618">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-emptytext="linklist_add_items"><article>
    <div>
<p>The first half of 2023 saw a normalization of energy prices, with natural gas prices and electricity exchange prices returning to pre-Ukraine war levels but still above 2021 prices. The impact of the nuclear phase-out, with the shutdown of the last nuclear power plants Isar2, Emsland and Neckarwestheim2 in April 2023, has been absorbed well. Factors such as increasing production from renewable sources, weather and higher production in neighboring European countries are significantly stronger than the effect of shutting down the three nuclear plants. The approximately 30 TWh from the reactors was offset by reduced exports, increased imports, and the addition of solar and wind capacity.<br> </p> 
<p>Load was 234 TWh in the first half of the year (H1 2023: 250 TWh), continuing the declining trend. Electricity production decreased from 252 TWh to 225 TWh compared to the first half of 2022. Exports of electricity to France decreased after the French nuclear reactors came back online. Exports to Austria and Switzerland decreased due to the countries' higher in-house generation and lower consumption. In the first quarter of 2023, more electricity than usual was imported because electricity prices in neighboring countries were favorable.</p> 
 
<h4>Constant generation from sun and wind</h4> 
<p>Wind energy was by far the most important renewable energy source. Wind turbines produced 67 TWh in the first half of 2023, down slightly from the first half of 2022 (about 68 TWh). February was a weak wind month, lowering the overall result. Photovoltaic systems fed approximately 30 TWh into the public grid in the first half of the year, a slight decrease from the previous year's 31 TWh, for which the weak month of March was mainly responsible. Solar power plants thus accounted for 12.5 percent of net public power generation. On May 4, they set a record: for the first time, solar plants in Germany fed more than 40 GW of power into the grid. With about 15 TWh of solar and wind power generation, June set a new monthly record for a June month. Hydropower produced 9.3 TWh in the first half of the year, up from 8.2 TWh a year earlier. Biomass power generation was on par with last year at 21 TWh.<br> </p> 
<p>In total, solar, wind, hydro, and biomass renewables produced about 130 TWh in the first half of 2023, down slightly from 131 TWh a year earlier. The share of net public electricity generation, i.e., the mix of electricity that actually comes out of the socket, was about 57.7 percent, well above the first half of 2022 (51.8 percent).<br> </p> 
 
<h4>Decline in nuclear and fossil generation</h4> 
<p>The last three nuclear power plants generated 6.7 TWh until their shutdown on April 15. In the first half of 2022, the figure was 15.8 TWh.<br> </p> 
<p>Coal-fired power generation also fell: Lignite-fired power plants generated about 41.2 TWh, a sharp decline of 21 percent from 2022 (52.1 TWh). Net production from coal-fired power plants also decreased by 23 percent, from 26.2 TWh in 2022 down to 20.1 TWh in 2023. Electricity generation from natural gas decreased only slightly from 24.3 TWh to 23.4 TWh. In addition to gas-fired power plants for the public power supply, gas-fired plants in the mining and manufacturing sectors also supply the industrial own consumption. These approximately produced an additional 24 TWh for industrial captive use.</p> 
 
<h4>Prices for electricity and natural gas decline</h4> 
<p>The volume-weighted average electricity price in the day-ahead auction was 100.54 euros/MWh. This is a significant decrease compared to the first half of 2022 with 181.28 Euro/MWh.<br> </p> 
<p>The average price for natural gas in the first half of 2023 was 45.29 euros/MWh. In the first half of 2022, the price was 99.84 euros/MWh.</p> 
<p>The average CO₂ certificate price per metric ton of CO₂ in Germany has risen to 86.97 euros, double the 2021 amount, while the volume-weighted average electricity price in the day-ahead auction was 100.37 euros/MWh.</p> 
 
<h4>Solar and wind capacity grow unevenly</h4> 
<p>The addition of photovoltaic capacity is currently within the target corridor of the German climate protection goals: From January to May alone, 5 GW was added, which would meet the target of 9 GW in 2023. Wind expansion, on the other hand, is not on track: By the end of May, 1 GW had been installed onshore and 0.23 GW offshore, indicating that the target of 4 GW will not be reached.<br> </p> 
<p>There has been great movement in the field of battery storage. In the first half of 2023, 1.7 GW of storage capacity with a storage capacity of 2.4 GWh was added, so that 5.6 GW of capacity with 8.3 GWh of capacity is now installed in Germany. By the end of the year, this capacity will increase to 10 to 11 GWh.</p></div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ariane 5 User’s Manual (2011) [pdf] (103 pts)]]></title>
            <link>https://www.arianespace.com/wp-content/uploads/2015/09/Ariane5_users_manual_Issue5_July2011.pdf</link>
            <guid>36598062</guid>
            <pubDate>Wed, 05 Jul 2023 09:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.arianespace.com/wp-content/uploads/2015/09/Ariane5_users_manual_Issue5_July2011.pdf">https://www.arianespace.com/wp-content/uploads/2015/09/Ariane5_users_manual_Issue5_July2011.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36598062">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The hardest part of building software is not coding, it's requirements (202 pts)]]></title>
            <link>https://stackoverflow.blog/2023/06/26/the-hardest-part-of-building-software-is-not-coding-its-requirements/</link>
            <guid>36597709</guid>
            <pubDate>Wed, 05 Jul 2023 09:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackoverflow.blog/2023/06/26/the-hardest-part-of-building-software-is-not-coding-its-requirements/">https://stackoverflow.blog/2023/06/26/the-hardest-part-of-building-software-is-not-coding-its-requirements/</a>, See on <a href="https://news.ycombinator.com/item?id=36597709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p>With all the articles about just how amazing all the developments in AI have been, there’s plenty of hand wringing around the possibility that we, as software developers, could soon be out of a job, replaced by artificial intelligence. They imagine all the business execs and product researchers will bypass most or all of their software developers and asking AI directly to build exactly what they think they want or need. As someone who’s spent 15 years creating software from the specs these folks create, I find it hard to take all the worrying seriously.&nbsp;</p>



<p>Coding can be a challenge, but I’ve never had spent more than two weeks trying to figure out what is wrong with the code. Once you get the hang of the syntax, logic, and techniques, it’s a pretty straightforward process—most of the time. The real problems are usually centered around what the software is supposed to do. The hardest part about creating software is not writing code—it’s creating the requirements, and those software requirements are still defined by humans.</p>



<p>This article will talk about the relationship between requirements and software, as well as what an AI needs to produce good results.&nbsp;</p>



<h2 id="h-it-s-not-a-bug-it-s-feature-no-wait-it-s-a-bug">It’s not a bug, it’s feature…no wait, it’s a bug</h2>



<p>Early in my software career, I was placed on a project midstream in order to help increase the velocity of the team. The main purpose of the software was to configure custom products on ecommerce sites.</p>



<p>I was tasked with generating dynamic terms and conditions. There was conditional verbiage that depended on the type of product being purchased, as well as which US state the customer was located in due to legal requirements.</p>



<p>At some point, I thought I found a potential defect. A user would pick one product type, which would generate the appropriate terms and conditions, but further along the workflow it would allow the user to pick a different product type and predefined terms and conditions. It would violate one of the features explicitly agreed on in the business requirement that had the client’s signature.</p>



<p>I naively asked the client,&nbsp; “Should I remove the input that allowed a user to override the right terms and conditions?” The response I got has been seared inside my brain ever since. His exact words were spoken with complete and total confidence;</p>



<p><em>“That will never happen”</em></p>



<p>This was a senior executive who had been at the company for years, knew the company’s business processes, and was chosen to oversee the software for a reason. The ability to override the default terms and conditions was explicitly requested by the same person. Who the heck was I to question anyone, much less a senior executive of a company that was paying us money to build this product? I shrugged it off and promptly forgot about it.</p>



<p>Months later, just a few weeks before the software was to go live, a tester on the client side had found a defect, and it was assigned to me. When I saw the details of the defect, I laughed out loud.</p>



<p>That concern I had about overriding default terms and conditions, the thing I was told would never happen? Guess what was happening? Guess who was blamed for it, and who was asked to fix it?</p>



<p>The fix was relatively easy, and the consequences of the bug were low, but this experience has been a recurring theme in my career building software. I’ve talked to enough fellow software engineers to know I’m not alone. The problems have become bigger, harder to fix, and more costly, but the source of the problem is usually the same: the requirements were unclear, inconsistent, or wrong.</p>



<figure><img decoding="async" src="https://lh3.googleusercontent.com/YZErrcpfauOH-94JNOf9DHn-pmh0AuPcCui3a7EIcYWGf34stpuXwqX0iVyYJP9i3ZKq7LuHKABtPwz175B3IWKvFQZqrKLQM43BI4yqsoh7tlgRncg959aTYgkbm-f8UfwFZkWouGaZuqRZIBP4d9o" alt=""></figure>



<h2 id="h-ai-right-now-chess-versus-self-driving-cars">AI right now: Chess versus self-driving cars</h2>



<p>The concept of artificial intelligence has been around for quite some time, although the high profile advances have raised concerns in the media <a href="https://www.npr.org/2023/05/15/1175776384/congress-wants-regulate-ai-artificial-intelligence-lot-of-catching-up-to-do">as well as Congress</a>. Artificial intelligence has already been very successful in certain areas. The first one that comes to mind is chess.</p>



<p>AI has been applied to chess as far back as the 1980s. It is widely accepted that AI has exceeded human’s ability to win at chess. It’s also not surprising, as the parameters of chess are FINITE (<a href="https://chess.stackexchange.com/questions/13522/is-chess-a-solved-game">but the game has not yet been solved</a>).</p>



<p>Chess always starts with 32 pieces on 64 squares, has well documented officially agreed upon rules, and most importantly has a clearly defined objective. In each turn, there are a finite number of possible moves. Playing chess is just following a rules engine.&nbsp; AI systems can calculate the repercussions of every move to select the move most likely outcome to capture an opponent’s piece or gain position, and ultimately win.</p>



<p>There has been another front where AI has been very active – self driving cars. Manufacturers have been promising self-driving cars for quite some time. Some have the capacity to self-drive, but there are caveats. In many situations the car requires active supervision; the driver may need to keep their hands on the wheel, the self-driving feature is not autonomous.</p>



<p>Like chess-playing AI programs, self-driving cars largely use <a href="https://www.oreilly.com/radar/podcast/the-technology-behind-self-driving-vehicles/">rules-based engines</a> to make decisions. Unlike the chess programs, the rules on how to navigate every possible situation are not clearly defined. There are thousands of little judgments drivers make in a given trip avoiding pedestrians, navigating around double-parked cars, and turning in busy intersections. Getting those judgments right means the difference between arriving at the mall safely or arriving at the hospital.</p>



<p>In technology, the standard is <a href="https://www.skmurphy.com/blog/2009/09/01/achieving-six-nines-when-you-launch/">five or even six 9s for availability</a>—a website or service is available 99.999% (or 99.9999%) of the time. The cost to achieve the first 99% isn’t that high. It means that your website or service can be down for more than three days—87.6 hours—a year. However for each 9 you add at the end, the cost to get there grows exponentially. By the time you reach 99.9999%, you can only allow for 31.5 seconds of downtime a year. It requires significantly more planning and effort and of course is more expensive. Getting the first 99% may not be easy, but proportionally it’s a lot easier and cheaper than that last tiny fraction.</p>



<p>365 X 24 X 60 minutes = 525,600 minutes a year</p>



<p>99% availability -&gt; down for 5256 minutes, 87.6 hours<br>99.9% availability -&gt; down 526 minutes, 8.76 hours<br>99.99% -&gt; 52 minutes, less than 1 hour<br>99.999% -&gt; 5.2 minutes<br>99.9999% -&gt; 0.52 minutes, roughly 31.5 seconds</p>



<p>No matter how close AI gets to being good enough, there’s always the risk of accidents and fatalities. Those risks and consequences happen every day with humans behind the wheel. I don’t know what rate of accidents and fatalities will be acceptable by governments, but you have to think it needs to be at least as good as human beings.</p>



<p>The reason it’s so difficult to get that acceptable level of safety is because driving a car entails significantly more variables than chess, and those variables are NOT FINITE. The first 95% or 99% might be predictable and easy to account for. However, there are so many edge cases after that first 99%, and each one may share some traits but each one is unique; other vehicles on the road driven by other human beings, road closures, construction, accidents, weather events, How many times have you driven after a road has been paved over but the paint for the dividing lines on the road has not been applied. It’s significantly harder to get your AI model to be able to account for and recognize those anomalies and edge cases, and more importantly how to respond appropriately without getting into an accident. Each edge case may share some traits, but rarely are they identical, which makes it harder for AI identify the appropriate way to respond.</p>



<h2 id="h-ai-can-t-create-software-only-code">AI can’t create software, only code</h2>



<p>Creating and maintaining software has a lot more in common with driving than playing chess. There are far more variables involved and the rules are based on judgment calls. You may have a desired outcome when you are building software, but it’s unlikely that it’s as singular as chess. Software is rarely done; features get added and bugs are fixed; it’s an ongoing exercise. Unlike software, once a chess game is won or lost it’s over.&nbsp;</p>



<p>In software development, we do have a tool to get our software designs closer to the tightly-controlled rules engine of chess: <a href="https://stackoverflow.blog/2020/04/06/a-practical-guide-to-writing-technical-specs/">technical specifications</a>. At their best, specs walk through expected user behaviors and program flows. Here’s how a user buys an e-sandwich: click this button, create this data structure, run this service. However, that’s rarely what we get. Too often, we’re handed wishlists as feature specs, back-of-the-napkin wireframes, and unclear requirements documents and told to make our best judgments.&nbsp;</p>



<p>Worse yet, requirements change or are ignored. Recently I was asked to help a team build something that could help people get information on health issues related to COVID 19. The application was going to be for an area of the globe that did not have reliable WIFI. The team wanted me to help build an application that could do surveys via SMS—phone text messages. Initially I was excited to be involved.</p>



<p>Once I started hearing the team describe what they thought they wanted, I realized this was going to be a problem. It’s one thing for a retail company to ask you on a scale of 1-10 how likely you are to shop in their store again. It’s very different to ask multistep surveys with multiple choice questions about the symptoms you’re experiencing with a possible COVID infection. I never said no, but I did bring up all the possible points of failure in this process and wanted the team to clearly define how we would handle incoming answers for all questions. Would it be comma separated numbers mapped to each answer? What happens if a submitted answer does not map to any of the options given?</p>



<p>After all these questions, the team came to the same conclusion. We decided it would be best not to go through with it. Believe it or not, I’d say this was actually a successful outcome. It would have been more wasteful to have gone ahead without a clear resolution for all of the potential errors when invalid user data was submitted.</p>



<p>Is the idea behind using AI to create software to just let those same stakeholders talk directly to a computer to create a SMS based survey? Is AI going to ask probing questions about how to handle all the possible issues of collecting survey data via SMS? Is it going to account for all the things that we as human beings might do incorrectly along the way and how to handle those missteps?</p>



<p>In order to produce a functional piece of software from AI, you need to know what you want and be able to clearly and precisely define it. There are times when I’m writing software just for myself where I don’t realize some of the difficulties and challenges until I actually start writing code.</p>



<p>Over the past decade, the software industry has transitioned from the waterfall methodology to <a href="https://stackoverflow.blog/2023/06/13/the-meeting-that-changed-how-we-build-software-ep-579/">agile</a>. Waterfall defines exactly what you want before any code is written, while agile allows enough flexibility so you can make adjustments along the way.</p>



<p>So many software projects using waterfall have failed because the stakeholders thought they knew what they wanted and thought they could accurately describe it and document it, only to be very disappointed when the final product was delivered. Agile software development is supposed to be an antidote to this process.</p>



<p>AI might be best suited to rewrite the software we already have but need to rewrite it to use newer hardware or a more modern programming language. There are still a lot of institutions with software written in <a href="https://stackoverflow.blog/2020/04/20/brush-up-your-cobol-why-is-a-60-year-old-language-suddenly-in-demand/">COBOL</a>, but there are fewer programmers learning how to use it. If you know exactly what you want, maybe you could get AI to produce software faster and cheaper than a team of human programmers. I believe AI could create the software that has already been created faster than human programmers but that’s because someone figured out what that software should do along the way.</p>



<p>AI might actually do pretty well building software using the waterfall process, which is also affectionately known as death march. You know who is terrible at waterfall? We are, human beings. And it’s not because of the part where the signed documents are handed over to a team of programmers so they can write the code. It’s everything before that. Artificial intelligence can do some extraordinary things, but it can’t read your mind or tell you what you should want.</p><p>
    Tags: <a href="https://stackoverflow.blog/tag/ai/" rel="tag">ai</a>, <a href="https://stackoverflow.blog/tag/ai-assistant/" rel="tag">ai assistant</a>, <a href="https://stackoverflow.blog/tag/llm/" rel="tag">llm</a>, <a href="https://stackoverflow.blog/tag/requirements/" rel="tag">requirements</a>, <a href="https://stackoverflow.blog/tag/software-engineering/" rel="tag">software engineering</a>  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PhD Simulator (398 pts)]]></title>
            <link>https://research.wmz.ninja/projects/phd/index.html</link>
            <guid>36597534</guid>
            <pubDate>Wed, 05 Jul 2023 08:39:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.wmz.ninja/projects/phd/index.html">https://research.wmz.ninja/projects/phd/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=36597534">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Demoscene accepted as UNESCO cultural heritage in The Netherlands (717 pts)]]></title>
            <link>http://demoscene-the-art-of-coding.net/2023/07/03/unescodemoscene-accepted-as-unesco-cultural-heritage-in-the-netherlands/</link>
            <guid>36597460</guid>
            <pubDate>Wed, 05 Jul 2023 08:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://demoscene-the-art-of-coding.net/2023/07/03/unescodemoscene-accepted-as-unesco-cultural-heritage-in-the-netherlands/">http://demoscene-the-art-of-coding.net/2023/07/03/unescodemoscene-accepted-as-unesco-cultural-heritage-in-the-netherlands/</a>, See on <a href="https://news.ycombinator.com/item?id=36597460">Hacker News</a></p>
Couldn't get http://demoscene-the-art-of-coding.net/2023/07/03/unescodemoscene-accepted-as-unesco-cultural-heritage-in-the-netherlands/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Open Letter from Security Researchers in Relation to the Online Safety Bill [pdf] (223 pts)]]></title>
            <link>https://haddadi.github.io/UKOSBOpenletter.pdf</link>
            <guid>36596610</guid>
            <pubDate>Wed, 05 Jul 2023 07:05:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haddadi.github.io/UKOSBOpenletter.pdf">https://haddadi.github.io/UKOSBOpenletter.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36596610">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[That Time I Posted Myself Out Of a Job (186 pts)]]></title>
            <link>https://cohost.org/stillinbeta/post/1847579-that-time-i-posted-m</link>
            <guid>36596193</guid>
            <pubDate>Wed, 05 Jul 2023 06:21:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cohost.org/stillinbeta/post/1847579-that-time-i-posted-m">https://cohost.org/stillinbeta/post/1847579-that-time-i-posted-m</a>, See on <a href="https://news.ycombinator.com/item?id=36596193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-post-body="true" data-testid="post-body"><p>
The year was 2019, the place San Diego. I was attending KubeCon on behalf of my then-employer, VMware. Kubecon is the Kubernetes Conference; If you don’t know what Kubernetes is don’t worry about it. It’s just a computers. 
<!-- --></p>
<!-- --><p>
I tended to tweet a lot at conferences, as was the style at the time. Any particularly interesting talks I’d live-tweet, and generally I took a lot of photos around the event. 
<!-- --></p>
<!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/e7bc2314-0432-41c8-81c1-d07c2465e795/pentesting.png?width=337&amp;height=415&amp;fit=crop&amp;auto=webp&amp;dpr=2" alt="Screenshot from my twitter: Extremely hype for Ian Coldwater's keynote! Talking about pentesting Kubernetes">
  <!-- --><figcaption>I don’t remember this talk but Ian is always incredible.
<!-- --></figcaption>
<!-- --></figure>
<!-- --><p>
Most of the tweets were pretty neutral, but some were a little more pointed. 
<!-- --></p>
<!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/081190db-eed6-4061-9bc5-2c4dd2fbcd73/walmartscale.png" alt="&quot;When we say walmart, the first thing that comes to mind is scale&quot; I guess if forcing workers onto foodstamps and brutally repressing unions counts as scaling #KubeCon">
  <!-- --><figcaption>Walmart is sort of like if they made Amazon in real life
<!-- --></figcaption>
<!-- --></figure>
<!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/ee8e399a-237a-4da7-a520-38330d706b60/notechforice.png" alt="&quot;No Tech For ICE&quot; written in Legos on a wall">
  <!-- --><figcaption>Trans rights
<!-- --></figcaption>
<!-- --></figure>
<!-- --><h2>Inciting Incident<!-- --></h2>
<!-- --><p>
<!-- --><em>&lt;extremely <!-- --><a href="https://www.youtube.com/channel/UCPxHg4192hLDpTI2w7F9rPg" target="_blank" rel="nofollow noopener noreferrer">Justin Roczniak voice<!-- --></a>&gt;<!-- --></em> At 8:08 AM on November 21st, 2019, I posted the following tweets:
<!-- --></p>
<!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/2b3f2974-5c38-4caf-9926-b6d428e3d74f/pasted%20image%200.png" alt="quote tweeting &quot;If kubernetes is good enough for DoD weapon systems, it's definitely good enough for your business&quot; with &quot;Fuck you&quot;">
  <!-- --><figcaption>I don’t even usually swear much
<!-- --></figcaption>
<!-- --></figure><p>
And follewed it up with
</p><!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/2dd68775-45c5-467f-8ef2-384af9b34989/bloodwashesoff.png" alt="Thanks for this @NichChaillan, I'd shake your hand but y'know, blood never washes off">
  <!-- --><figcaption>Anger does not really become me, but boy was I mad. <!-- --></figcaption>
<!-- --></figure>
<!-- --><p>
I think absolutely nothing of this. It was a tweet-heavy day! My thumbs were sore at the end of it!
<!-- --></p>
<!-- --><p>
But the next day, right before my flight home, I get a DM from a helpful colleague:
<!-- --></p>
<!-- --><figure>
  <!-- --><img src="https://staging.cohostcdn.org/attachment/c8ab3389-fd41-46b9-bf3d-5ffc81fbabfc/vmwarefederal.png" alt="I saw your reply to Nic Chaillan's tweet earlier. It was pretty hilarious. However, Nic got miffed and complained to VMWARE federal about it. I don't think they are going to do anything about it, but I just wanted to warn you, just in case">
  <!-- --><figcaption>I’m sure this is fine<!-- --></figcaption>
<!-- --></figure>
<!-- -->
<!-- --><h2>They Do Something About It<!-- --></h2>
<!-- -->
<!-- --><p>
And then after I landed, who should slide into my DMs but <!-- --><em>a VMware Vice President<!-- --></em>, my grand boss of a large number of levels, requested a quick chat with him and an HR representative. 
<!-- --></p>
<!-- --><p>
Being as I’m not an idiot, I elect to bring a witness of my own (<!-- --><a data-testid="mention" href="https://cohost.org/lizthegrey">@<!-- -->lizthegrey<!-- --></a> ). She slightly livetweeted that conversation until VP VMware tells her to stop.  The two VMwares mention the social media guidelines. I hadn’t seen them, but they contain gems like “Avoid topics involving age, sex, race, religion, ethnicity, politics or disabilities.” 
<!-- --></p>
<!-- --><p>
I’ll get right on that. 
<!-- --></p>
<!-- --><p>
On the 24th, my first normal day back at work, I got another meeting request from Vice President VMware. Having learned their lesson they tell me not to bring in external witnesses. I instead invited a colleague of mine to be my witness. 
<!-- --></p>
<!-- --><p>
We talked a little more about the social media guidelines, and I reiterated the impossibility of complying with how the guidelines were written. I mentioned I’d be willing to help improve them, and the guy seemed to be pretty happy with that. A few hours later I got an email from HR saying they didn’t need any more information from them. 
<!-- --></p>
<!-- --><p>
At this point I’m feeling pretty good! I got chastised but mostly I won an opportunity to help improve some social media guidelines! That seemed like a pretty great outcome to me.
<!-- --></p>
<!-- --><h2>A less than great outcome<!-- --></h2>
<!-- -->
<!-- --><p>
A week or so later, though, I’m pulled into another meeting with HR, and they present me with a “written warning,” and I have to sign a bunch of stuff saying I agreed to follow a bunch of documents I was already supposed to sign. 
<!-- --></p>
<!-- --><p>
I pointed out the social media guidelines were basically impossible to follow, and they agreed to strike them.
<!-- --></p>
<!-- --><p>
At this point I’d seen the writing on the wall and I’d retained a labour lawyer. He and I look over the written warning they want me to sign, and we agree I’m basically not giving anything up. So I came back and signed the document, less the provisions I didn’t think I could follow if I tried
<!-- --></p>
<!-- --><p>
Surprise, though! Two days later Vice President VMware once again DMs me (lol) to summon me for a before-working-hours meeting. In it, they inform me they will be “accepting my resignation.” 
<!-- --></p>
<!-- --><p>
The reason given for my termination in the meeting is explicitly my refusal to agree to the social media guidelines, the same ones their own VP agreed I could not follow. 
<!-- --></p>
<!-- --><p>
I say something to this effect, ask if this is really how this is going down, and when they confirm it is, I hang up. Good thing I already have a lawyer on retainer. 
<!-- --></p>
<!-- --><h2>it is time for some JURISPRUDENCE my dudes<!-- --></h2>
<!-- -->
<!-- --><p>
Thing was, I’d joined VMware via an acquisition, which meant I had a pretty generous retention package. Bunch of stock and the like. The severance agreement obviously didn’t include any of that.
<!-- --></p>
<!-- --><p>
Now, talking about political conditions of work is <!-- --><em>sometimes<!-- --></em> protected speech. So together with my lawyer and one from the NLRB, I wrote up a very detailed complaint (which has been very helpful for making this chost honestly).
<!-- --></p>
<!-- --><p>
Unfortunately we were still in the Trump administration, and even though it was the lame duck period his appointees still controlled the NLRB. We had very little leverage and not much room to negotiate. They made a big deal of not giving me a nondisclosure clause, but there was still a nondisparagement clause. Given the impossibility of telling this story in a way that makes VMware look anything but terrible, those clauses amounted to the same thing. 
<!-- --></p>
<!-- --><p>
My excellent lawyer almost doubled my cash payout but the non disparagement clause stayed. I decided being able to tell this ridiculous story wasn’t worth giving up $40k, so I took the offer and only groused about this dude in private.
<!-- --></p>
<!-- --><h2>UNTIL NOW<!-- --></h2>
<!-- -->
<!-- --><p>
Recently, there was news about an <!-- --><a href="https://www.nlrb.gov/news-outreach/news-story/board-rules-that-employers-may-not-offer-severance-agreements-requiring" target="_blank" rel="nofollow noopener noreferrer">NLRB decision<!-- --></a> that specifically impacted non disparagement clauses! And after consulting with my lawyer from this case, we agree it’s highly unlikely VMware will bring charges against me now, and even if they did it’s unlikely they’d prevail. So now I am once again free to Post. 
<!-- --></p><p><em>Your situation may be different, this is not legal advice<!-- --></em></p>
<!-- -->
<!-- --><h2>So Why’d This Happen<!-- --></h2>
<!-- -->
<!-- --><p>
My lawyer went through great pains to explain that I could in theory, still be liable for libel against Mr Air Force. So legally Speaking, I don’t know for sure that Nic Chaillan, then a US Government employee, pressured a private company to fire a single employee because she tweeted at him and hurt his feelings.
<!-- --></p>
<!-- --><p>
What I <!-- --><em>do <!-- --></em>know is that at least one firm has <!-- --><a href="https://www.oxebridge.com/emma/oxebridge-files-ethics-complaint-against-usaf-chief-software-officer/" target="_blank" rel="nofollow noopener noreferrer">filed a complaint against him<!-- --></a> alleging he did exactly that to other parties, threatening to sic an “army of lawyers” on someone who was mean to him online. Multiple reports corroborate this.
<!-- --></p>
<!-- --><p>
He is also known to be a <!-- --><a href="https://www.oxebridge.com/emma/op-ed-usafs-chaillan-knausenberger-must-resign-over-suspected-ethics-violations/" target="_blank" rel="nofollow noopener noreferrer">very bad poster<!-- --></a> (see the “Misuse of Position” section). And when he <!-- --><a href="https://www.oxebridge.com/emma/breaking-usaf-cso-nicolas-chaillan-resigns/" target="_blank" rel="nofollow noopener noreferrer">publicly resigned<!-- --></a> in 2021 he worried about how in the future “China has the drastic advantage of population over the U.S.” 
<!-- --></p>
<!-- --><p>
I invite you to draw your own conclusions about this guy.
<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bret Victor update (259 pts)]]></title>
            <link>http://worrydream.com/July2023/</link>
            <guid>36596095</guid>
            <pubDate>Wed, 05 Jul 2023 06:07:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://worrydream.com/July2023/">http://worrydream.com/July2023/</a>, See on <a href="https://news.ycombinator.com/item?id=36596095">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Is the aircraft in this image real? (189 pts)]]></title>
            <link>https://aviation.stackexchange.com/questions/99788/is-the-aircraft-in-this-image-real</link>
            <guid>36595711</guid>
            <pubDate>Wed, 05 Jul 2023 05:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aviation.stackexchange.com/questions/99788/is-the-aircraft-in-this-image-real">https://aviation.stackexchange.com/questions/99788/is-the-aircraft-in-this-image-real</a>, See on <a href="https://news.ycombinator.com/item?id=36595711">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>I am 100% sure this is fake.</p>
<p>I found the same picture on <a href="https://twitter.com/aeroconcepts1/status/1387227601098268672" rel="noreferrer">Twitter in a tweet from April 28,2020</a> , but in higher resolution:</p>
<p><a href="https://i.stack.imgur.com/DQdIY.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/DQdIY.jpg" alt="The same picture on Twitter, higher resolution"></a></p>
<p>You can see the registration on the aircraft clearly: D-AVXA. This registration is an Airbus Test registration, used by Airbus in Hamburg. Below the registration, you can read the Manufacturer Serial Number (MSN) 8557.</p>
<p>The <a href="https://www.airfleets.net/ficheapp/plane-a321-8557.htm" rel="noreferrer">aircraft with MSN 8557</a> is a A321 which was given Test registration D-AVX<strong>F</strong> during production and testing. It was produced for Indigo as passenger version and delivered with registration VT-IUA. The last two letters (UA) of that registration can be seen on the nose gear doors of the freighter aircraft.</p>
<p>Clearly, something does not add up here, and that is only the first indication.</p>
<p>Then, I found a very similar picture of aircraft MSN 8557 in passenger configuration on <a href="https://www.planespotters.net/photo/898071/d-avxf-indigo-airbus-a321-271nx" rel="noreferrer">planespotters.net</a>. It also has the letters UA on the nose gear doors. Note almost the same position on Hamburg Finkenwerder airport (Airbus Assembly site), including the same shades of leaves in the trees (clearly an autumn setting, which matches the date on the planespotters picuture 16 November 2018).</p>
<p>The picture with the split scimitar winglets is dated in April, which does not match the background.</p>
<p>Zooming in on the lower part of the split scimitar winglet, it looks suspicious monochrome. <a href="https://i.stack.imgur.com/zegas.png" rel="noreferrer"><img src="https://i.stack.imgur.com/zegas.png" alt="Zoomed-in part of the photo, showing winglet and registration"></a></p>
<p>Also note that the Indian registration in front of the Indian flag is part of the paint job, and during testing this is covered with a white sticker. The sticker would overlap the Indigo CarGo Truck logo, but here the logo overlaps the sticker. The outline of the original sticker is still vagely visible in the edited photo.</p>
<p>Finally: the Twitter profile of the Twitter post says in the bio:</p>
<blockquote>
<p><em><strong>Skilled to Transform Your Wild Aeronautical Imaginations Into Digital Reality</strong></em></p>
</blockquote>
<p>That really gives it away.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Functions and algorithms implemented purely with TypeScript's type system (159 pts)]]></title>
            <link>https://github.com/ronami/meta-typing</link>
            <guid>36595512</guid>
            <pubDate>Wed, 05 Jul 2023 04:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ronami/meta-typing">https://github.com/ronami/meta-typing</a>, See on <a href="https://news.ycombinator.com/item?id=36595512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><g-emoji alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png">📚</g-emoji> Meta-Typing</h2>
<blockquote>
<p dir="auto">Functions and algorithms implemented purely with TypeScript's type system</p>
</blockquote>
<h3 tabindex="-1" dir="auto">Introduction</h3>
<p dir="auto"><a href="https://github.com/Microsoft/TypeScript">TypeScript</a>'s type system lets us catch bugs and errors in our code as we write it, instead of later on when the code runs. But... that's the obvious way to use the type system... 😜</p>
<p dir="auto">This project attempts to push TypeScript's type system to its limits by actually implementing various functions and algorithms, purely on top of the type system.</p>
<p dir="auto">Every implementation includes comments describing in detail what's going on. Some functions and algorithms use creative (and sometimes not officially supported) solutions to overcome <a href="https://github.com/microsoft/TypeScript/issues/26223#issuecomment-513187373" data-hovercard-type="issue" data-hovercard-url="/microsoft/TypeScript/issues/26223/hovercard">some limitations</a> of the type system.</p>
<p dir="auto"><em><g-emoji alias="point_up" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/261d.png">☝</g-emoji> Please note that this project is meant to be used for fun and learning purposes and not for practical use.</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ronami/meta-typing/blob/master/assets/showcase.gif"><img src="https://github.com/ronami/meta-typing/raw/master/assets/showcase.gif" alt="showcase" data-animated-image=""></a></p>
<h3 tabindex="-1" dir="auto">Try running the code</h3>
<p dir="auto">Start by installing dependencies:</p>

<p dir="auto">Open a file of any function or algorithm and hover over the types to see the results of "running" that function with some input (try hovering the resulting type).</p>
<p dir="auto">You can also run tests (written with <a href="https://github.com/SamVerschueren/tsd">tsd</a>) with:</p>

<h3 tabindex="-1" dir="auto">Functions and algorithms:</h3>
<ul dir="auto">
<li>
<p dir="auto"><strong>Math</strong>:</p>
<ul dir="auto">
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/utils/math.d.ts">Basic arithmetic</a> - add one and decrease by one.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/add/index.d.ts">Add</a> - adds two numbers.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/subtract/index.d.ts">Subtract</a> - subtracts two numbers.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/multiply/index.d.ts">Multiply</a> - multiplies two numbers.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/divide/index.d.ts">Divide</a> - divides two numbers.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/gte/index.d.ts">Greater than or equal</a> - checks if a value is greater than or equal to another value.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/lte/index.d.ts">Less than or equal</a> - checks if a value is less than or equal to another value.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/max/index.d.ts">Max</a> - computes the maximum value of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/min/index.d.ts">Min</a> - computes the minimum value of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/sum/index.d.ts">Sum</a> - computes the sum of the values in array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/remainder/index.d.ts">Remainder</a> - return the remainder (%) when one number is divided by a second number.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Lists</strong></p>
<ul dir="auto">
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/head/index.d.ts">Head</a> - gets the first element of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/tail/index.d.ts">Tail</a> - gets all but the first element of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/reverse/index.d.ts">Reverse</a> - Reverses an array so that the first element becomes the last, the second element becomes the second to last, and so on.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/size/index.d.ts">Size</a> - gets the size of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/concat/index.d.ts">Concat</a> - creates a new array by concatenating two arrays together.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/drop/index.d.ts">Drop</a> - creates a slice of an array with <code>n</code> elements dropped from the beginning.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/take/index.d.ts">Take</a> - creates a slice of an array with <code>n</code> elements taken from the beginning.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/uniq/index.d.ts">Uniq</a> - creates a duplicate-free version of an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/includes/index.d.ts">Includes</a> - checks if a value is an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/indexOf/index.d.ts">IndexOf</a> - gets the index at which the first occurrence of a value is found in an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/difference/index.d.ts">Difference</a> - creates an array of values from the first array that are not included in the other given arrays.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/intersection/index.d.ts">Intersection</a> - creates an array of unique values that are included in all given arrays.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/slice/index.d.ts">Slice</a> - creates a slice of an array from start up to, but not including, end.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/flatten/index.d.ts">Flatten</a> - flattens an array a single level deep.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/pull/index.d.ts">Pull</a> - removes all given values from an array.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/chunk/index.d.ts">Chunk</a> - creates an array of elements split into groups the length of size.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/zip/index.d.ts">Zip</a> - creates an array of grouped elements, the first of which contains the first elements of the given arrays, the second of which contains the second elements of the given arrays, and so on.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/range/index.d.ts">Range</a> - creates an array of numbers progressing from start up to, but not including, end.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Sorting</strong></p>
<ul dir="auto">
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/quickSort/index.d.ts">Quick-sort</a> - an efficient sorting algorithm.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/mergeSort/index.d.ts">Merge-sort</a> - another efficient sorting algorithm.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/insertionSort/index.d.ts">Insertion-sort</a> - a simple sorting algorithm that builds the final sorted array (or list) one item at a time.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Utility</strong></p>
<ul dir="auto">
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/isEqual/index.d.ts">IsEqual</a> - compares between two values to determine if they are equivalent.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Puzzles</strong></p>
<ul dir="auto">
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/nQueens/index.d.ts">N-Queens</a> - the problem of placing N chess queens on an N×N chessboard so that no two queens threaten each other.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/maze/index.d.ts">Maze-solving</a> - find the shortest path to solve a maze with obstacles.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/binaryTrees/index.d.ts">Binary trees</a> - a tree data structure in which each node has at most two children.</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/rotateMatrix/index.d.ts">Square Matrix Rotation</a> - you are given an N×N 2D matrix (representing an image). Rotate the matrix by 90 degrees (clockwise and counter-clockwise).</li>
<li><a href="https://github.com/ronami/meta-typing/blob/master/src/hanoi/index.d.ts">Towers of Hanoi</a> - a mathematical game or puzzle that consists of three rods and a number of disks of different sizes.</li>
</ul>
</li>
</ul>
<h3 tabindex="-1" dir="auto">Additional links</h3>
<ul dir="auto">
<li><a href="https://www.typescriptlang.org/docs/handbook/utility-types.html" rel="nofollow">Utility TypeScript types</a></li>
<li><a href="https://www.typescriptlang.org/docs/handbook/advanced-types.html" rel="nofollow">Advanced TypeScript types</a></li>
<li><a href="https://gal.hagever.com/posts/typing-the-technical-interview-in-typescript/" rel="nofollow">Typing the Technical Interview in TypeScript</a></li>
<li><a href="https://github.com/microsoft/TypeScript/issues/14833" data-hovercard-type="issue" data-hovercard-url="/microsoft/TypeScript/issues/14833/hovercard">TypeScripts Type System is Turing Complete</a></li>
<li><a href="https://gist.github.com/acutmore/9d2ce837f019608f26ff54e0b1c23d6e">Emulating a 4-Bit Virtual Machine in TypeScript's type system</a></li>
<li><a href="https://github.com/trekhleb/javascript-algorithms">Algorithms and data structures implemented in JavaScript</a></li>
<li><a href="https://github.com/pirix-gh/medium/blob/master/types-curry-ramda/src/index.ts">How to master advanced TypeScript patterns</a></li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lobotomizing Gnome (2018) (103 pts)]]></title>
            <link>https://eklitzke.org/lobotomizing-gnome</link>
            <guid>36594985</guid>
            <pubDate>Wed, 05 Jul 2023 02:46:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eklitzke.org/lobotomizing-gnome">https://eklitzke.org/lobotomizing-gnome</a>, See on <a href="https://news.ycombinator.com/item?id=36594985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>I have pretty basic needs from my desktop. I do 99% of my work using just three
programs: a terminal emulator, Emacs, and Firefox. I don't want a lot of bells
and whistles in my desktop, and I really just want it to get out of the way so I
can do my work.</p>
<p>But just because my needs are basic doesn't mean that I want a 1990's window
manager experience. I want good text rendering and windows and buttons with
rounded corners. I want my laptop to work correctly when connecting it to
external displays or projectors without a lot of futzing around. I want vsync to
work with my monitor out of the box, I want to be able to watch video without
tearing, and I want a desktop that has first class support for high-DPI
displays. I also want to have some basic integration with the other system
features provided by my distro, which increasingly means high-quality
integration with NetworkManager and different systemd components. I want to get
integrated notifications when a program segfaults on my computer or in case
there's an SELinux AVC denial.</p>
<p>In my opinion, in these areas GNOME is far ahead of everything else. The stock
GNOME configuration is beautiful but minimal---I get a discreet black bar across
the top of my screen that shows the time and date, and lets me control the
fundamentals like network access. I think that GNOME Shell is the most
attractive and useful window manager for any operating system out there. And
GNOME has <em>really good</em> integration with the other parts of my system, which
makes sense because it's the default desktop environment on my distro (Fedora)
and most others, including Debian and Ubuntu. GNOME is also light-years ahead of
everything else in terms of Wayland support. Fedora has been shipping Wayland as
the default GNOME display backend since Fedora 25 (2016), and it works
incredibly well. The most compelling user-visible feature that has come out of
this is GNOME's "fractional scaling" feature, which is a quantum leap in terms
of how content is scaled on high-DPI screens.</p>
<p>But I'll be honest: GNOME is huge and kind of bloated, and it's hard to disable
various unwanted components. GNOME Shell is amazing, but a lot of the other
components of GNOME are simply unwanted. This is what turns a lot of power users
away from GNOME, which I think is a shame given all of the other amazing things
about GNOME. While you won't find these instructions in the GNOME manuals, if
you know what you're doing modern GNOME releases make it very easy to lobotomize
a lot of the unneeded and unwanted features.</p>
<h2>Configuration With <code>dconf</code></h2>
<p>The first step in improving the GNOME user experience is toggling basic features
on or off. You can do this either by clicking around in the GUI, or using the
<code>dconf</code> command line tool. One of the interesting things about GNOME is that it
has a lot of hidden options that either not at all exposed in the GUI, or only
accessible through a tool like <code>gnome-tweaks</code>. But if you know what you're doing
you can change a lot of GNOME behavior.</p>
<p>Most people are already in the habit of keeping their dot files in a git repo
somewhere. I recently took this up a notch, and I now maintain my whole desktop
configuration (including my dot files) using
<a href="https://www.ansible.com/">Ansible</a>. To illustrate my GNOME configuration I'll
be posting snippets from current Ansible configuration. If you're not familiar
with Ansible don't worry: it's just YAML, and can easily be translated into
command line invocations.</p>
<p>Here's what my GNOME <code>dconf</code> settings look like in Ansible:</p>
<pre><code>- name: update gnome dconf settings
  dconf:
    key: "{{item.key}}"
    value: "{{item.value}}"
  loop:
    - {key: '/org/gnome/desktop/input-sources/xkb-options', value: "['caps:ctrl_modifier']"}
    - {key: '/org/gnome/desktop/interface/clock-show-date', value: 'true'}
    - {key: '/org/gnome/desktop/interface/cursor-blink', value: 'false'}
    - {key: '/org/gnome/desktop/interface/gtk-theme', value: "'Adwaita-dark'"}
    - {key: '/org/gnome/desktop/privacy/old-files-age', value: 'uint32 7'}
    - {key: '/org/gnome/desktop/privacy/remove-old-trash-files', value: 'true'}
    - {key: '/org/gnome/desktop/privacy/report-technical-problems', value: 'false'}
    - {key: '/org/gnome/desktop/search-providers/disable-external', value: 'true'}
    - {key: '/org/gnome/desktop/wm/preferences/audible-bell', value: 'false'}
    - {key: '/org/gnome/desktop/wm/preferences/focus-mode', value: "'sloppy'"}
    - {key: '/org/gnome/settings-daemon/plugins/color/night-light-enabled', value: 'true'}
    - {key: '/org/gnome/settings-daemon/plugins/xsettings/antialiasing', value: "'rgba'"}
    - {key: '/org/gnome/shell/disable-user-extensions', value: 'true'}
    - {key: '/org/gnome/software/allow-updates', value: 'false'}
    - {key: '/org/gnome/software/download-updates', value: 'false'}
    - {key: '/org/gnome/terminal/legacy/default-show-menubar', value: 'false'}
</code></pre>
<p>You can probably guess what most of these options do based on the key name. A
lot of them turn off various options, or change basic features of the window
manager (such as setting "sloppy" focus, a must-have for me).</p>
<p>There's one I want to call out in particular though: I set
<code>/org/gnome/shell/disable-user-extensions</code> to <code>false</code>, which completely disables
the user extensions feature of GNOME. User extensions are a mechanism that allow
users to write GNOME extensions in Javascript, similar to how Chrome and Firefox
extensions work. In my opinion this idea has dubious merit, and my personal
feeling is the less Javascript in my life the better. I felt somewhat vindicated
about this decision during recent
<a href="https://phoronix.com/scan.php?page=news_item&amp;px=GNOME-Shell-Memory-Leak-Fix">coverage</a>
of a memory leak in GNOME Shell. The underlying issue was related to the
Javascript garbage collector in GNOME Shell not collecting object references in
a timely manner. I'm not sure that disabling user extensions actually disables
the Javascript engine completely, but it definitely minimizes it to the least
possible scope.</p>
<p>You might wonder how you're actually supposed to find these options in the first
place---how are you supposed to know what keys are available, and what values
they take? In practice I found most of these in a kind of hacky way. The <code>dconf</code>
command lets you dump the entire database using <code>dconf dump /</code>. So what I did to
find most of these options was some process kind of like the following:</p>
<pre><code># Get the initial dconf state.
$ dconf dump / &gt;a

# Click around in the GUI, change things in gnome-tweaks, etc.

# Dump the final dconf state.
$ dconf dump / &gt;b

# Manually look at the diff of the two states.
$ diff -u a b
</code></pre>
<p>This is simple and effective, and just takes a minute or so of work. The more
robust (but much more labor intensive) way to do this is to look at the GNOME
settings schemas. GNOME packages install files ending in a <code>.gschema.xml</code>
extension, which are XML descriptions of all of the possible options supported
by the application, a description of what the options do, and their default
values. In principle you could discover all of these options by digging around
in <code>/usr/share/glib-2.0/schemas</code> and reading a bunch of XML schema descriptions.
In practice I do this very rarely, really only when if I need to read the
complete documentation for an option.</p>
<h2>Removing Unneeded Components</h2>
<p>GNOME bundles a lot of components that I find to be really annoying and
unwelcome. These are the biggest offenders:</p>
<ul>
<li><p><a href="https://wiki.gnome.org/Projects/Tracker/">Tracker</a> is a file daemon that is
supposed to work like Spotlight on macOS. I don't want this. Between <code>find</code>
and <code>locate</code> I can find all of my files quickly. I don't need yet another
thing trying to index my files.</p>
</li>
<li><p><a href="https://wiki.gnome.org/Apps/Evolution">Evolution</a> is the standard GNOME
email application, which I don't want to use. If Evolution was just an email
program I could ignore that would be fine. Unfortunately, Evolution evolved
into a weird half-baked clone of Microsoft Exchange complete with contact
integration, calendar capabilities, and a host of other office productivity
features that are not useful to me. Evolution provides a component called
<code>evolution-data-server</code> that is a daemon that ties these things together.</p>
</li>
<li><p><a href="https://wiki.gnome.org/Projects/GnomeOnlineAccounts">GNOME Online Accounts</a>
is a feature that lets you connect your GNOME account to things like your
Google or Facebook login. The idea is supposed to be that you can connect
things like your Google calendar and email to the GNOME calendar and
Evolution. It's a cool idea, but I'm not comfortable with the idea of giving
my online credentials to a bundle of tens or hundreds of thousands of lines
of hand-written C code with manual memory management.</p>
</li>
<li><p><a href="https://wiki.gnome.org/Apps/Software">GNOME Software</a> is this weird app
store that I don't care to use. It always gives me notifications about GNOME
updates that don't actually correlate with updates in my distro package
manager. The <code>dconf</code> configuration I showed above will actually tell GNOME
Software not to do this, but I don't really want GNOME Software running at
all.</p>
</li>
</ul>
<p>It turns out that you can remove a <em>lot</em> of these components without breaking
anything. I remove as much of these as possible, as well as a number of programs
that I know I don't plan on using. The following list is specific to Fedora 28,
but shows what I remove:</p>
<pre><code># remove unwanted gnome packages
- name: dnf remove gnome bloat
  dnf:
    name:
      - cheese
      - evolution
      - evolution-ews
      - evolution-help
      - gfbgraph
      - gnome-boxes
      - gnome-calendar
      - gnome-contacts
      - gnome-dictionary
      - gnome-documents
      - gnome-getting-started-docs
      - gnome-initial-setup
      - gnome-maps
      - gnome-online-miners
      - gnome-photos
      - gnome-software
      - gnome-user-docs
      - gnome-user-share
      - gnome-video-effects
      - gnome-weather
      - simple-scan
      - totem
      - tracker-miners
      - yelp
    state: absent
</code></pre>
<p>Some of these are harmless programs that don't actually install session daemons,
but are also programs I don't plan on using. In other cases (e.g.
<code>gnome-software</code>) uninstalling the program actually removes daemons that are run
by default in the session, so removing those components actually causes less
programs to run and waste memory.</p>
<p>They key thing here is to make sure you don't remove dependencies of any of the
core components, which includes <code>gnome-shell</code> but also some other programs like
<code>nautilus</code>. To double check that I didn't actually break anything, I also have
the following stanza in my config. This is just a sanity check to make sure that
nothing critical was accidentally removed.</p>
<pre><code># double-check that we still have the basics
- name: ensure core gnome packages are installed
  dnf:
    name:
      - eog
      - evince
      - evolution-data-server
      - flatpak
      - gdm
      - gnome-keyring
      - gnome-menus
      - gnome-screenshot
      - gnome-shell
      - gnome-terminal
      - gnome-tweaks
      - nautilus
      - redhat-menus
    state: present
</code></pre>
<p>I'm removing a lot of stuff here, including some things you might want to keep.
So look at the list for yourself and apply caution before removing anything.
After removing these packages there are still a few annoying components like
<code>evolution-data-server</code> and <code>tracker</code> that still remain because they can't be
completely uninstalled without breaking critical components. But they can still
be disabled in user sessions, as I'll explain below.</p>
<h2>Disabling <code>evolution-data-server</code>, Tracker, and other bloat</h2>
<p>GNOME used to have a horribly complicated system that was used to manage start
user session services, and in the past it was very difficult or impossible to
disable certain components. As part of the Wayland effort, GNOME moved to
managing user services using systemd. This is <em>really awesome</em> because it means
you can control GNOME startup services using <code>systemctl</code> just like regular
system services.</p>
<p>On Wayland GNOME services run as part of your systemd user session. To see these
services, use one of the following commands:</p>
<pre><code># Show running user services.
$ systemctl --user status

# Show all user units and their status.
$ systemctl --user list-unit-files
</code></pre>
<p>From these commands I identified various services I want to disable. The trick
to disabling these is to use the <code>systemctl --user mask</code> command, which inhibits
the system installed service units from running. In theory masking services
could cause problems, but at least for the set presented here I haven't observed
any issues.</p>
<p>Here's my Ansible code:</p>
<pre><code>- name: mask unwanted gnome services
  systemd:
    name: "{{item}}"
    user: yes
    masked: yes
    state: stopped
  loop:
    - evolution-addressbook-factory.service
    - evolution-calendar-factory.service
    - evolution-source-registry.service
    - gvfs-goa-volume-monitor.service
    - tracker-store.service
</code></pre>
<p>This list lobotomizes <code>evolution-data-server</code>, GNOME Online Accounts, and
Tracker. I also have an Ansible command to ensure that the tracker database is
completely removed from my system:</p>
<pre><code>- name: remove tracker databases
  file:
    name: ~/.cache/tracker
    state: absent
</code></pre>
<p>I'll note that even after removing these services there are still a lot of GNOME
user services running in my session. If you wanted to you could mask a lot more
services. In general the approach I take is to only mask services whose behavior
I understand. Most of the remaining services in my GNOME session are daemons
that use very little memory and zero CPU, so I don't mind keeping them around.</p>
<h2>Firefox/GNOME Integration</h2>
<p>I version control my Firefox preferences using Firefox's obscure
<a href="http://kb.mozillazine.org/User.js_file">user.js</a> feature, which essentially
lets you put <code>about:config</code> preferences in a Javascript file. I have a fairly
extensive user.js file that is a relaxed version of options suggested by
<a href="https://github.com/pyllyukko/user.js">pyllyukko/user.js</a>, which I might write
about in more detail another time. Two of the options I set in this file are
specific to GNOME, so I'll cover them here.</p>
<p>The <a href="https://extensions.gnome.org/">GNOME Extensions</a> site lets you install
GNOME extensions from Firefox. This is done using a native plugin, meaning that
unlike normal extensions it runs in a privileged context that allows it to
interact with GNOME. Since I have user extensions disabled anyway this serves no
purpose, and could possibly do nasty things if a security flaw is found in it
later. Therefore I disable this plugin:</p>
<pre><code>// Disable GNOME browser plugin.
user_pref("plugin.state.libgnome-shell-browser-plugin", 0);
</code></pre>
<p>The second option is related to a Firefox bug (present as of Firefox 60.0)
related to GNOME 3.28 when using the Adwaita dark theme. When using this theme
Firefox will render certain widgets/text areas with inverted colors. This is
more than just strange looking: in some cases it can cause things to be
completely unreadable (e.g. a white text color can get applied to text in a
white text area). This can be fixed by forcing Firefox to render widgets use the
Adwaita light theme:</p>
<pre><code>// Force Adwaita light theme.
user_pref("widget.content.gtk-theme-override", "Adwaita:light");
</code></pre>
<h2>Parting Thoughts</h2>
<p>The configuration listed above is the accumulation of a few years of efforts for
me. Things change from release to release, and therefore I revisit things from
time to time. Generally though I'm very happy with the direction GNOME has been
doing, and it's a much more pleasant experience dealing with certain aspects of
it today than it was a few years ago. I hope the information presented here is
useful, and I hope to see more great things from the GNOME project in the
future.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Unix Chat (346 pts)]]></title>
            <link>https://the-dam.org/docs/explanations/suc.html</link>
            <guid>36594916</guid>
            <pubDate>Wed, 05 Jul 2023 02:34:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://the-dam.org/docs/explanations/suc.html">https://the-dam.org/docs/explanations/suc.html</a>, See on <a href="https://news.ycombinator.com/item?id=36594916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<p>
The title oversells the content a bit:
</p>
<ul>
<li>first, Slack (or Mattermost, or even the Internet Relay Chat (IRC)) offer
slightly more features than the <i>Simple Unix Chat</i> system (<code>suc</code>), the topic
of this piece;</li>
<li>then, <code>suc</code>’s actual line count exceeds five.</li>
</ul>

<p>
Nevertheless, <code>suc</code>’s core indeed consists of five lines of bash;
and <code>suc</code> provides Slack, Mattermost, <i>etc.</i>’s core features:
</p>
<ul>
<li>Real-time, rich-text chat,</li>
<li>File sharing,</li>
<li>Fine-grained access control,</li>
<li>Straightforward automation and integration with other tools,</li>
<li>Data encryption in transit</li>
<li>and optionally at rest,</li>
<li>state-of-the-art user authentication.</li>
</ul>


<p>
This paper shows how <code>suc</code> implements those features.
<code>suc</code> stays small by leveraging the consistent and composable primitives offered by modern UNIX implementations
<sup><a id="fnr.1" href="#fn.1" role="doc-backlink">1</a></sup>.
</p>

<div id="outline-container-orgefe782e">
<h2 id="orgefe782e">Line count matters</h2>
<div id="text-orgefe782e">
<blockquote>
<p>
One of my most productive days was throwing away 1000 lines of code.
– Ken Thompson, <a href="https://skeptics.stackexchange.com/questions/43800/did-the-creator-of-unix-say-one-of-my-most-productive-days-was-throwing-away-10">apparently</a>
</p>
</blockquote>
<blockquote>
<p>
Measuring programming progress by lines of code is like measuring aircraft
building progress by weight.
– Bill Gates, (probably apocryphal)
</p>
</blockquote>
<blockquote>
<p>
Some of the managers decided that it would be a good idea to track the progress
of each individual engineer in terms of the amount of code that they wrote from
week to week.
[…]
When he got to the lines of code part, [Bill Atkinson] […] wrote in the number: -2000.
– <a href="https://www.folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt">https://www.folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt</a>
</p>
</blockquote>
<blockquote>
<p>
Their fundamental design flaws are completely hidden by their superficial design
flaws.
– Douglas Adams
</p>
</blockquote>
<blockquote>
<p>
There are two ways of constructing a software design: One way is to make it so
simple that there are obviously no deficiencies, and the other way is to make it
so complicated that there are no obvious deficiencies.
– Tony Hoare
</p>
</blockquote>
<p>
Despite the wide consensus among competent programmers that <a href="https://wiki.c2.com/?SoftwareAsLiability">code is a liability</a>,
almost every widely-distributed piece of software is a complexity behemoth.
</p>

<p>
Case in point, let’s examine Mattermost’s line count:
</p>
<div>
<pre><span>cd</span> /tmp
<span>git</span> clone --depth=<span>1</span> https://github.com/mattermost/mattermost-server
<span>cd</span> mattermost-server
guix shell cloc -- cloc --quiet --timeout <span>0</span> .
</pre>
</div>

<pre id="org6c7ec21">github.com/AlDanial/cloc v 1.96  T=14.34 s (606.7 files/s, 139790.0 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Go                            1805          96705          26782         501249
JSON                           177              5              0         492604
TypeScript                    4125          74236          24557         480491
JavaScript                     811          21494          20745          68653
SCSS                           557           9164            359          51464
HTML                            54           6108           1167          37814
JSX                             92           3473           1054          29707
SQL                            807           3553           2253          18266
Text                            11           3824              0          10638
YAML                            45            126             96           7972
SVG                             68              6             12           2586
Markdown                        73            906             88           2168
make                             8            234             68            974
GraphQL                          4             65              2            596
XML                             29             10              1            572
Bourne Shell                    18            128             17            492
CSS                              5             70              0            385
Dockerfile                       4             14              8             46
CSV                              2              0              0             25
diff                             2              1             13              9
INI                              1              2              0              7
-------------------------------------------------------------------------------
SUM:                          8698         220124          77222        1706718
-------------------------------------------------------------------------------
</pre>

<p>
<b><b>Half a million lines</b></b> of Go, and again <b><b>half a million</b></b> lines of
TypeScript. Just for the server !
</p>

<p>
Let’s compare with <code>suc</code>:
</p>
<div>
<pre><span>cd</span> /tmp
<span>git</span> clone --depth=<span>1</span>  https://gitlab.com/edouardklein/suc
<span>cd</span> suc
guix shell cloc -- cloc --quiet --timeout <span>0</span> .
</pre>
</div>

<pre id="orga4ac3ca">github.com/AlDanial/cloc v 1.96  T=0.01 s (475.8 files/s, 8207.6 lines/s)
--------------------------------------------------------------------------------
Language                      files          blank        comment           code
--------------------------------------------------------------------------------
Bourne Again Shell                1              2              2             19
C                                 1              3              3             17
make                              1              3              0             14
Bourne Shell                      1              0              1              5
--------------------------------------------------------------------------------
SUM:                              4              8              6             55
--------------------------------------------------------------------------------
</pre>
<p>
<code>suc</code> can implement Mattermost’s core features <b><b>with 0.005% of the code</b></b>. This is madness !
</p>
</div>
</div>
<div id="outline-container-orga8279f6">
<h2 id="orga8279f6"><code>suc</code>’s core loop</h2>
<div id="text-orga8279f6">
<p>
Behold the five lines of bash that do as much as half a million lines of Go:
</p>
<div>
<pre><span>while</span> /usr/bin/true
<span>do</span>
    <span>read</span> -r line || <span>exit</span> <span>0</span>  <span># </span><span>EOF</span>
    /usr/bin/echo <span>"</span><span>$(/usr/bin/date --iso-8601=seconds)</span><span>"</span><span>\</span>
        <span>"</span><span>$(printf "%-9s" "$(/usr/bin/id --user --name --real)</span><span>")"</span> <span>\</span>
        <span>"</span><span>$</span><span>line</span><span>"</span> &gt;&gt; /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span>
<span>done</span>
</pre>
</div>
<p>
This infinite loop:
</p>
<ul>
<li>reads a line from standard input,</li>
<li>prefixes it with:
<ul>
<li>the date,</li>
<li>the real user name,</li>
</ul></li>
<li>and appends it to a file in <code>/var/lib/suc/</code></li>
</ul>


<p>
Surely, you think, this cannot do. What about authentication, access control, encryption, rich text, <i>etc.</i> ?
</p>

<p>
<code>suc</code> does all that by leveraging SSH, UNIX’s access control API, and UNIX’s text-based modularity.
</p>
</div>
</div>
<div id="outline-container-org14b6181">
<h2 id="org14b6181">Authentication</h2>
<div id="text-org14b6181">
<p>
The <code>suc</code> process can only be launched by an authenticated user
<sup><a id="fnr.2" href="#fn.2" role="doc-backlink">2</a></sup>.
Therefore, <code>suc</code> contains no authentication code at all.
All the authentication stuff happens before <code>suc</code> even starts.
</p>

<p>
As with almost all UNIX servers nowadays,
remote authentication is handled by <code>ssh</code>.
Before granting them the ability to start <code>suc</code>, <code>ssh</code> requires users to prove their identity.
</p>

<p>
This proof can take the form
</p>
<ul>
<li>of a shared secret (<i>i.e.</i> a password),</li>
<li>of a cryptographic challenge (as is the case on <a href="https://the-dam.org/">the dam</a>),</li>
<li>of the use of a One-Time-Passord (OTP) generating device,</li>
<li>or of any combination of the above (also known as Multi-Factor Authentication, MFA).</li>
</ul>


<p>
<code>ssh</code> also authenticates the server to the client,
thus preventing <i>Man-in-the-Middle</i> (MitM) attacks.
</p>

<p>
Last but not least, <code>ssh</code> encrypts all data between the clients and the server.
</p>

<p>
A successful installation of <code>suc</code> therefore depends on a correct configuration
of the UNIX host and its <code>ssh</code> server.
To use <code>suc</code>, a user needs to exist on the system;
and the <code>ssh</code> server needs to be configured to let her remotely log in.
</p>

<p>
Most UNIX distribution provide the <code>useradd</code>, <code>passwd</code>, <i>etc.</i> commands for user management
(creation, deletion, assignation to one or more groups, <i>etc.</i>).
The <code>ssh</code> server reads its configuration from a text file in <code>/etc/</code>
(typically <code>/etc/ssh/sshd_config</code>), and from public key files
(typically in <code>/home/&lt;user&gt;/.ssh/authorized_keys</code>).
</p>

<p>
<a href="https://the-dam.org/">The dam</a> server uses GNU Guix.
GNU Guix differs from almost all other UNIX distributions,
because it uses declarative configuration.
This means that <code>root</code> just has to say what she wishes the configuration to be.
The system then complies and reconfigures itself to match <code>root</code>’s declaration.
</p>

<p>
For example, granting <code>ssh</code> access to <code>alice</code> on a GNU Guix system
<sup><a id="fnr.3" href="#fn.3" role="doc-backlink">3</a></sup>
requires only the following line in the system’s configuration file:
</p>
<div>
<pre> (ssh-user <span>"alice"</span> <span>#:groups</span> '(<span>"c3n"</span> <span>"frenchies"</span>)
                   <span>#:keys</span> '((plain-file <span>"alice.pub"</span> <span>"SOMESSHKEY"</span>)))
</pre>
</div>
<p>
User <code>alice</code> exists on the system only as long as the line exists in the configuration file.
When the line disappears, the reconfiguration process removes user <code>alice</code>, and she can no longer log in.
</p>

<p>
Some big advantages of declarative configuration systems include:
</p>
<ul>
<li>removing the need for clean up actions when removing functionality:
once it is no longer part of the declaration,
it will be removed from the system automatically.</li>
<li>the ability to clone a specific configuration
by just replicating the declaration;
useful for back-ups, failovers, <i>etc.</i>.</li>
</ul>


<p>
Among the disadvantages,
one counts an increased difficulty for quick and dirty setups
(usually for a quick test to try out a piece of software).
New tools (such as e.g. <code>guix shell</code>) allows one to sidestep this difficulty.
</p>

<p>
In such a declarative system,
<code>suc</code>’s overhead per user is limited to a single line in the global configuration file.
One cannot need less,
and current chat systems need more.
</p>
</div>
</div>
<div id="outline-container-orgc7dc063">
<h2 id="orgc7dc063">Access control</h2>
<div id="text-orgc7dc063">
<p>
As with authentication, <code>suc</code> contains no access control code whatsoever.
This combination of caring about neither authentication nor access control is called <i>security agnosticism</i>.
<i>Security anosticism</i> allows <code>suc</code> to be lean,
and therefore more probably correct (and so, paradoxically, more secure) than its heavier counterparts.
</p>

<p>
On UNIX, software can afford to be <i>security agnostic</i>
because the system provides a clean and powerful API for access control:
the kernel knows about
</p>
<ul>
<li>users and groups,</li>
<li>processes and files.</li>
</ul>


<p>
Let’s dive in.
</p>

<p>
UNIX veterans will have noticed that <code>suc</code> prefixes the user’s messages with her <i>real</i> name.
Indeed, files have an owner (a user),
whereas processes have two owners (two users). The <i>real</i> one and the <i>effective</i> one.
</p>

<p>
Most of the time, <i>real</i> and <i>effective</i> owners are the same.
<code>suc</code>’s ownership differs:  it <i>effectively</i> belongs to a special user also named <code>suc</code>;
it <i>really</i> belongs to whoever (<i>e.g.</i> user <code>alice</code>) launched the <code>suc</code> command
<sup><a id="fnr.4" href="#fn.4" role="doc-backlink">4</a></sup>.
</p>

<p>
The kernel examines the <i>effective</i> ownership of a process
to determine said process’ ability to read or write to files.
</p>

<p>
With that in mind, let’s examine the content of <code>/var/lib/suc</code> on <a href="https://the-dam.org/">the dam</a>:
</p>
<div>
<pre>ssh -i ~/.ssh/id_rsa edk@the-dam.org <span>ls</span> -l /var/lib/suc
</pre>
</div>

<pre>total 92
-rw-r----- 1 suc c3n            44368 Apr 13 19:18 banane
-rw-r----- 1 suc forbiddenlands  6234 Apr 13 21:04 forbiddenlands
-rw-r----- 1 suc frenchies         62 Apr 21 22:23 frenchies
-rw-r----- 1 suc guixdevs           0 Apr 22 15:39 guix
-rw-r----- 1 suc iwp9            4181 Apr 21 21:46 iwp9
-rw-r----- 1 suc users          18241 Jun 30 07:14 the-dam
-rw-r----- 1 suc wb3c             188 May 10 11:56 wb3c
</pre>


<p>
The files in <code>/var/lib/suc</code> belong to <code>suc</code>;
only <code>suc</code> can read and write those files
<sup><a id="fnr.5" href="#fn.5" role="doc-backlink">5</a></sup>.
</p>

<p>
Any other user, such as <code>alice</code>, may read some of the files (e.g. <code>banane</code>),
provided she belongs to the appropriate <i>group</i> (e.g. <code>c3n</code>).
</p>

<p>
With this configuration,
<code>suc</code> does not need to care about access control at all.
For example <code>suc</code> need not match a user against the list of authorized readers or writers of a <i>channel</i>.
</p>

<p>
Instead, <code>usuc</code><sup><a id="fnr.6" href="#fn.6" role="doc-backlink">6</a></sup>
will just happily always <i>try</i> to read or write the file.
The kernel will do the matching and prevent any unauthorized access.
</p>

<p>
On <a href="https://the-dam.org/">the dam</a>, everyone can start <code>suc</code>, whose <i>effective</i> owner will be the user
<code>suc</code>, who has the right to write into any channel. By design, any user on <a href="https://the-dam.org/">the dam</a>
can request membership into a group by blindly writing a request to the
group’s channel.
</p>

<p>
Less loosely-managed communities may wish to restrict channel write access to members only.
<code>root</code> achieves this by maintaining multiple copies of the <code>suc</code> binary.
</p>

<p>
Let’s assume that
</p>
<ul>
<li><code>alice</code> and <code>bob</code> belong to the <code>blue</code> group,</li>
<li>while <code>eve</code> and <code>mallory</code> belong to the <code>red</code> group.</li>
</ul>


<p>
<code>root</code> creates <code>nobody</code>-like<sup><a id="fnr.7" href="#fn.7" role="doc-backlink">7</a></sup> users <code>red</code> and <code>blue</code>. She then creates two copies of <code>suc</code>, one for
each group:
</p>
<div>
<pre><span>ls</span> -l /usr/bin/suc*
total <span>32</span>
-rwsr-xr-- <span>1</span> red     red      <span>15624</span> Jun  <span>4</span> 10:51 suc_red
-rwsr-xr-- <span>1</span> blue    blue     <span>15624</span> Jun  <span>4</span> 10:56 suc_blue
</pre>
</div>
<p>
And she also creates one channel for each team:
</p>
<div>
<pre><span>ls</span> -l /var/lib/suc/
total <span>16</span>
-rw-r----- <span>1</span> blue     blue     <span>11027</span> Jun  <span>4</span> 11:30 blue
-rw-r----- <span>1</span> red      red      <span>17</span>    Jun  <span>4</span> 10:53 red
</pre>
</div>
<p>
One can see that:
</p>
<ul>
<li><code>alice</code> and <code>bob</code> belong to group <code>blue</code>.
<ul>
<li>They can read the <code>blue</code> channel. Indeed the file <code>/var/lib/suc/blue</code>
belongs to group <code>blue</code> and has mode <code>-rw-r-----</code> : the second <code>r</code> means
that members of the owning group (here, <code>blue</code>), can read the file (but not
write to it).</li>
<li>They cannot directly write to the file.
Only user <code>blue</code> can.</li>
<li>They can however launch the <code>/usr/bin/suc_blue</code> program,
because group <code>blue</code> owns it,
and it has mode <code>-rwsr-xr--</code> .
The <code>x</code> means that members of the owning group (here, <code>blue</code>) can start the program.</li>
<li>This program will run with user <code>blue</code> as the <i>effective</i> owner:
User <code>blue</code> owns the file
and <code>root</code> has set its setuid bit
(the <code>s</code> in the mode line says so).</li>
<li>Therefore, <code>alice</code> and <code>bob</code>, being members of the <code>blue</code> group, can launch the <code>/usr/bin/suc_blue</code> program,
which being <i>effectively</i> owned by user <code>blue</code>
(despite being launched by <code>alice</code> or <code>bob</code> who will be the <i>real</i>, but not <i>effective</i> owner)
can write to the <code>/var/lib/suc/blue</code> file.</li>
</ul></li>
<li><code>eve</code> and <code>mallory</code> belong to group <code>red</code> (but not group <code>blue</code>).
<ul>
<li>They cannot read the <code>blue</code> channel.
Indeed, people other than user <code>blue</code> or members of group <code>blue</code> have no rights on the <code>/var/lib/suc/blue</code> file
(the end of its mode line is <code>---</code>).</li>
<li>They cannot write to the <code>blue</code> channel directly,
only user <code>blue</code> can.</li>
<li>They cannot start the <code>/usr/bin/suc_blue</code> program,
because they do not belong to group <code>blue</code>.
The only thing they can do to this file is read it (its mode line ends in <code>r--</code>).</li>
<li>Therefore they can neither read nor write the <code>blue</code> channel.</li>
</ul></li>
</ul>


<p>
To relieve <code>root</code> from the cumbersome and error-prone process of setting this all up,
<code>suc</code> provides an 80-something-lines long helper script called <a href="https://gitlab.com/edouardklein/suc/-/blob/master/suc_channel.sh"><code>suc_channel.sh</code></a>.
</p>

<p>
GNU Guix users can create a <code>suc</code> channel by
adding a single line to the system’s configuration file:
</p>
<pre>(suc-private-channel "red" "red")
</pre>

<p>
This line takes care of creating the necessary
</p>
<ul>
<li><code>suc_red</code> setuid binary,</li>
<li><code>red</code> user</li>
<li><code>red</code> group</li>
<li><code>red</code> channel file.</li>
</ul>


<p>
Here, GNU Guix’s declarative configuration paradigm shines again. The
<code>suc_channel.sh</code> script may fail halfway, leaving the system in an undetermined
state, whereas GNU Guix provides <i>transactional</i> updates: either the transition
happens fully or it does not at all. The system always stays in a known clean
state. One can even roll-back to a previous working state (see <a href="https://guix.gnu.org/en/blog/2018/multi-dimensional-transactions-and-rollbacks-oh-my/">Multi-dimensional
transactions and rollbacks, oh my!</a>).
</p>

<p>
GNU Guix also automatically computes which groups, users, and setuid binaries
should exist on the system. When <code>root</code> removes a private channel (e.g. <code>red</code>),
she must assess whether the associated group (also named <code>red</code>), user (also
<code>red</code>), and setuid binary (<code>suc_red</code>) should stay or go. That entails looking at
the other channels to see if any of them is still owned by user <code>red</code> or group
<code>red</code>. Again, a cumbersome and error prone task whereas on GNU Guix, <code>root</code> just
removes the channel’s line from the system declaration. The <code>red</code> group, <code>red</code>
user, and <code>suc_red</code> binary will stay if and only if another part of the system
needs them.
</p>

<p>
As an illustration, here is a full system declaration for the above example. One
can hardly be simpler than that.
</p>
<div>
<pre>(<span>begin</span> (use-modules
        (gnu packages base)
        (guix gexp)
        (beaver system)
        (beaver packages plan9)
        (beaver functional-services))
       (-&gt; (minimal-ovh)
           (ssh-user <span>"alice"</span>   <span>#:groups</span> '(<span>"suc"</span> <span>"blue"</span>) <span>#:keys</span> '())
           (ssh-user <span>"bob"</span>     <span>#:groups</span> '(<span>"suc"</span> <span>"blue"</span>) <span>#:keys</span> '())
           (ssh-user <span>"eve"</span>     <span>#:groups</span> '(<span>"suc"</span> <span>"red"</span>)  <span>#:keys</span> '())
           (ssh-user <span>"mallory"</span> <span>#:groups</span> '(<span>"suc"</span> <span>"red"</span>)  <span>#:keys</span> '())
           (suc-private-channel <span>"red"</span> <span>"red"</span>)
           (suc-private-channel <span>"blue"</span> <span>"blue"</span>)
           (suc-public-channel <span>"purple"</span>)))
</pre>
</div>
</div>
</div>
<div id="outline-container-org76ce31c">
<h2 id="org76ce31c">Fancy text</h2>
<div id="text-org76ce31c">
<p>
We have seen how <code>suc</code> is <i>security-agnostic</i>, relying on:
</p>
<ul>
<li><code>ssh</code> for authentication,</li>
<li>UNIX’s file and process ownership and permission model for access control.</li>
</ul>


<p>
Let’s now dive into the featureful side of things by first looking at some bells
and whistles: rich text.
</p>

<p>
Most chat applications nowadays piggyback on an HTML engine to render the chat’s
text. For example <a href="https://github.com/mattermost/desktop">mattermost’s client</a> uses <a href="https://www.electronjs.org/">Electron</a>. There go another few tens of
thousand of lines of code.
</p>

<p>
On the one hand, this adds tremendous complexity and increases the attack
surface of the application. On the other hand it lets the chat display elements
in a complex layout, or embed interactive widgets within the messages (such as
emoji reactions), etc.
</p>

<p>
<code>suc</code> uses one file per channel. This text file is meant to be displayed to the
user with a command-line tool such as <code>tail</code> or <code>cat</code>.
</p>

<p>
Before everything got shoehorned into an HTML rendering engine, people managed
to display rich text, boxes, and even primitive graphics on their terminals.
These capabilities more-or-less coalesced into something called ANSI escape
codes<sup><a id="fnr.8" href="#fn.8" role="doc-backlink">8</a></sup>. Almost all terminal emulators support
those. Together with proper UTF-8 support, they allow for the colorful,
emoji-filled experience of your average corporate slack channel, with ~5% of the
memory footprint.
</p>

<p>
If you paid attention to the 5 lines of bash that <code>suc</code> consists of, you have
noticed that while <code>suc</code> writes into the channel file, it does not read from it.
</p>

<p>
This job befalls to <code>usuc</code>. Why two separate binaries ? Because <code>suc</code> is a
privileged binary, which runs under the powerful effective ownership of whoever
can write to a channel. One must be careful to keep the logic and external
dependencies of <code>suc</code> to a bare minimum to minimize the attack surface, and
avoid any complex logic where bugs like to hide.
</p>

<p>
<code>usuc</code>, conversely, runs with both effective and real owners set to the
calling user. It can go crazy with the features, as whatever happens can not
impact the channel file, except through <code>suc</code>, whose logic is so simple
there should not be any bugs in it.
</p>

<p>
Here is as of <span><span>&lt;2023-06-29 Thu&gt; </span></span> the code for usuc:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>set</span> -euo pipefail

<span># </span><span>Autowrap self in rlwrap</span>
<span>if</span> [ -z <span>"</span><span>$</span><span>{RLWRAP:-}</span><span>"</span> ]
<span>then</span>
    <span>RLWRAP</span>=<span>1</span> rlwrap <span>"</span><span>$</span><span>0</span><span>"</span> <span>"</span><span>$</span><span>@</span><span>"</span>
    <span>exit</span> <span>0</span>
<span>fi</span>

<span>chan_owner</span>=$(<span>ls</span> -l /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span> | cut -d<span>' '</span> -f <span>3</span>)
<span>if</span> [ <span>"</span><span>$</span><span>chan_owner</span><span>"</span> != suc ]
<span>then</span>
    <span>SUC</span>=suc_<span>"</span><span>$</span><span>chan_owner</span><span>"</span>
<span>else</span>
    <span>SUC</span>=suc
<span>fi</span>
<span># </span><span>Tail the channel</span>
tail -f -n <span>20</span> /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span>&amp;
<span>while</span> true
<span>do</span>
    <span>read</span> -r line || <span>exit</span> <span>0</span>
    <span>if</span> [ <span>"</span><span>$</span><span>{line::1}</span><span>"</span> == <span>":"</span> ]
    <span>then</span>
        <span>echo</span> <span>'*runs* `'</span> <span>"</span><span>$</span><span>{line:1}</span><span>"</span> <span>'`'</span> | pygmentize -l md -f <span>256</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
        bash -c <span>"</span><span>$</span><span>{line:1}</span><span>"</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
    <span>else</span>
        <span>echo</span> <span>"</span><span>$</span><span>line</span><span>"</span> | pygmentize -l md -f <span>256</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
    <span>fi</span>
<span>done</span>
</pre>
</div>
<p>
<code>usuc</code>:
</p>
<ul>
<li>makes sure to prefix its own call with <code>rlwrap</code>, which provides history and line
editing capabilities,</li>
<li>selects the correct setuid <code>suc</code> binary to run depending on who owns the channel file,</li>
<li>calls <code>tail -f</code>, displaying the last 20 lines of the channel and then
anything that get subsequently written to it,</li>
<li>check whether the line typed by the user starts with “:” (see the next section),</li>
<li>pipe anything the user typed through <code>pygmentize</code>.</li>
</ul>


<p>
Pygmentize is a nifty Python module for syntax coloring. Here it runs expecting
markdown on its standard input, and outputting ANSI color coded text on its
standard output. That way, a user can use markup syntax like <code>**bold**</code>, and get
<b>bold</b> output. <code>suc</code> gets markdown support in a single line of code.
</p>
</div>
</div>
<div id="outline-container-orgabf779c">
<h2 id="orgabf779c">Chat commands</h2>
<div id="text-orgabf779c">
<p>
Other tools can, like <code>pygmentize</code>, output ANSI-styled text. One of those is e.g.
<a href="https://github.com/charmbracelet/gum"><code>gum</code></a>.
</p>

<p>
To invoke <code>gum</code> directly from the chat interface, one just has to start a
message with <code>:</code>. <code>usuc</code> will catch that and will not pipe the text to <code>suc</code>
like it would for a normal message. It will instead run the command, and pipe
its <i>output</i> to <code>suc</code>.
</p>

<p>
One can therefore type:
</p>
<pre>: gum style --border=rounded --bold --foreground=#F00 "Hello World !"
</pre>

<p>
as a <code>suc</code> message and see something that looks like the following appear in the channel:
</p>
<pre>╭─────────────╮
│<span>Hello World !</span>│
╰─────────────╯
</pre>

<p>
Any command that exists in the namespace of the user who called <code>usuc</code> can run
that way. Its output will appear in the chat.
</p>

<p>
We use that on <a href="https://the-dam.org/">the dam</a> to roll dice when we play table-top role playing games:
</p>
<pre>: roll 2d6
2023-04-13T21:04:57+00:00 gm        *runs* ` roll 2d6 `
2023-04-13T21:04:58+00:00 gm        [6, 2]
</pre>


<p>
Again, it all happens in the namespace of the user. Any user can customize
her environment to keep useful chat macros on hand, without any impact on the
other users.
</p>
</div>
</div>
<div id="outline-container-orgd2b464b">
<h2 id="orgd2b464b">Piping text to <code>suc</code></h2>
<div id="text-orgd2b464b">
<p>
Instead of using <code>usuc</code>’s command-calling facility, one can pipe right into
<code>suc</code> the output of any command, from one’s shell.
</p>

<p>
For example if you want to pretty-print a piece of source code to a relevant
channel, you can invoke <a href="https://github.com/sharkdp/bat"><code>bat</code></a>:
</p>
<pre>bat --force-colorization --paging=never --style=full toto.c | suc greybeards
</pre>

<p>
and you will get a syntactically-colored listing of your code in the channel.
</p>

<p>
Complex chat system like Mattermost, Slack, etc. offer many
<a href="https://mattermost.com/integrations-overview/">integrations</a>, that is, ways to interact with other software.
</p>

<p>
<code>suc</code> is text-based ; integrating it with other tools feels natural in a UNIX
environment. For example consider the following bash one-liner:
</p>
<div>
<pre><span>make</span> test &gt; testlog || (suc devops &lt; testlog ; <span>exit</span> <span>1</span>)
</pre>
</div>
<p>
This code will run the tests of a software project, and send the logs to the
<code>devops</code> channel on failure.
</p>

<p>
With the necessary boilerplate, this oneliner fits into the <a href="https://www.atlassian.com/git/tutorials/git-hooks">git hook</a> <code>update</code> of
a git repo:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>set</span> -euxo pipefail
<span>newrev</span>=<span>"</span><span>$</span><span>3</span><span>"</span>

<span>GIT_DIR</span>=$(realpath <span>"</span><span>$</span><span>GIT_DIR</span><span>"</span>)
<span>cd</span> <span>"</span><span>$(mktemp -d)</span><span>"</span>
<span>git</span> clone <span>"</span><span>$</span><span>GIT_DIR</span><span>"</span> .
<span>git</span> checkout <span>"</span><span>$</span><span>newrev</span><span>"</span>

<span>make</span> test &gt; test_log || (suc devops &lt; test_log ;  <span>exit</span> <span>1</span>)
<span>exit</span> <span>0</span>
</pre>
</div>
<p>
And voilà ! You get a <code>git/suc</code> integration in 11 lines of bash. Any push to
the repo will trigger the test, reject the update on failure, and ring the
DevOps team so they can solve the problem.
</p>
</div>
</div>
<div id="outline-container-org26050c9">
<h2 id="org26050c9">Reading from a <code>suc</code> channel</h2>
<div id="text-org26050c9">
<p>
<code>suc</code> users continually update a text file (the channel). By calling <code>tail -f</code>
on that text file, you can process the new lines as they arrive.
</p>

<p>
For example, to get notified when a new message gets posted in a channel, just run:
</p>
<div>
<pre>tail -n0 -f /var/lib/suc/some-chan | (<span>while</span> true;
                                      <span>do </span><span>read</span> -r line;
                                         notify-send <span>"</span><span>$</span><span>line</span><span>"</span>;
                                      <span>done</span>)
</pre>
</div>

<p>
Too many notifications ? Reduce the noise by grepping for keywords:
</p>
<div>
<pre>tail -n0 -f /var/lib/suc/some-chan | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -E <span>"(myname|build failure|fire)"</span> | <span>\</span>
    (<span>while</span> true; <span>do </span><span>read</span> -r line; notify-send <span>"</span><span>$</span><span>line</span><span>"</span>; <span>done</span>)
</pre>
</div>

<p>
Don’t want to open as many windows as channels you follow ? Coalesce them all in
a single feed:
</p>
<pre>tail -f /var/lib/suc/*
</pre>

<p>
Or use the more powerful <a href="https://lnav.org/">lnav</a> (a log file viewer), which will
</p>
<ul>
<li>remember where you left off,</li>
<li>set bookmarks,</li>
<li>assign a color to each channel,</li>
<li>parse the date, username, or any custom field that may appear in the text,</li>
<li>let you filter the messages,</li>
<li>run SQL queries on the messages.</li>
</ul>


<p>
Try to do that with Slack…
</p>
</div>
</div>
<div id="outline-container-orgfc27392">
<h2 id="orgfc27392">Bots</h2>
<div id="text-orgfc27392">
<p>
If you can write and read to a <code>suc</code> channel, you can do both at once. Chat
systems often host bots and semi-automated “assistants”. These provide a text-based
interface to e.g. tickets, continuous integration, corporate directory, server
logs, etc. Have a look below at the code of a bot that convert into meters any
length given in feet:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>feet_to_meters</span> (){
    <span>feetexpr</span>=<span>"</span><span>$</span><span>1</span><span>"</span>
    <span>echo</span> -e <span>"</span><span>$</span><span>feetexpr</span><span> \n m"</span> | units | <span>grep</span> -Eo <span>"\* [0-9.]*"</span> | tr -d <span>'*'</span>
}

tail -n0 -f /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span> | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -v <span>"metric_bot"</span>  | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -Eo <span>"[0-9]+[[:blank:]]*(feet|ft)"</span> | <span>\</span>
    (<span>while</span> true;
     <span>do </span><span>read</span> -r line;
        <span>echo</span> <span>"[metric_bot] </span><span>$</span><span>line</span><span> is </span><span>$(feet_to_meters "</span><span>$</span><span>line</span><span>")</span><span> meters."</span> | suc <span>"</span><span>$</span><span>1</span><span>"</span>
     <span>done</span>)
</pre>
</div>
<pre id="org5024b6d">2023-06-30T11:20:47+02:00 edouard   The plane flew at 33000 ft.
2023-06-30T11:20:47+02:00 bots      [metric_bot] 33000 ft is  10058.4 meters.
</pre>
</div>
</div>
<div id="outline-container-org2edb71a">
<h2 id="org2edb71a">Conclusion</h2>
<div id="text-org2edb71a">
<p>
<code>suc</code> piggybacks on SSH for authentication and on UNIX for access control and
composability. It provides almost all the features offered by Mattermost,
Slack, <i>etc.</i> with such a ridiculously small fraction of the code that one
wonders why such complex systems even exist.
</p>

<p>
Using text files as the base for <code>suc</code> channels lets user leverage UNIX tools
for reading (<code>tail</code>, <code>bat</code>, <code>lnav</code>, <code>less</code>, <code>grep</code>, etc.), writing (<code>gum</code>,
<code>bat</code>, <code>pygmentize</code>, etc.), or semi-automated extension with bots, hooks, and
scripts.
</p>

<p>
Tools can be written in any language, as long as they read and write text.
</p>
</div>
</div>
<div id="outline-container-org26136f6">
<h2 id="org26136f6">Advertisement</h2>
<div id="text-org26136f6">
<p>
If you want to play with <code>suc</code> but don’t want to bother with installing it, or
if you don’t have any friends to share a <code>suc</code> instance with, come and join us
at <a href="https://the-dam.org/">the dam</a> ! For a measly 10€/year, you can enjoy sharing <code>suc</code> on a GNU Guix
server with people from all over the world.
</p>

<p>
If you would like your own instance of <code>suc</code>, don’t hesitate and rent a VPS from
<a href="https://guix-hosting.com/">Guix hosting</a> ! For 100€/year, you get a GNU Guix VPS. Adding <code>suc</code> is just one
line of configuration away. There are no usage-based restrictions, your data
stays yours, and you can use your VPS to provide other services as well.
</p>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Our Journey with Apache Arrow (Part 2): Adaptive Schemas and Sorting (119 pts)]]></title>
            <link>https://arrow.apache.org/blog/2023/06/26/our-journey-at-f5-with-apache-arrow-part-2/</link>
            <guid>36594695</guid>
            <pubDate>Wed, 05 Jul 2023 01:53:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arrow.apache.org/blog/2023/06/26/our-journey-at-f5-with-apache-arrow-part-2/">https://arrow.apache.org/blog/2023/06/26/our-journey-at-f5-with-apache-arrow-part-2/</a>, See on <a href="https://news.ycombinator.com/item?id=36594695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <main role="main">
        

<hr>



<p>
  <span>Published</span>
  <span>
    26 Jun 2023
  </span>
  <br>
  <span>By</span>
  
    Laurent Quérel
  

  
</p>


        <!--

-->

<p>In the previous <a href="https://arrow.apache.org/blog/2023/04/11/our-journey-at-f5-with-apache-arrow-part-1/">article</a>, we discussed our use of Apache Arrow within the context of the OpenTelemetry project. We investigated various techniques to maximize the efficiency of Apache Arrow, aiming to find the optimal balance between data compression ratio and queryability. The compression results speak for themselves, boasting improvements ranging from 1.5x to 5x better than the original OTLP protocol. In this article, we will delve into three techniques that have enabled us to enhance both the compression ratio and memory usage of Apache Arrow buffers within the current version of the <a href="https://github.com/f5/otel-arrow-adapter">OTel Arrow protocol</a>.</p>

<p>The first technique we’ll discuss aims to optimize schemas in terms of memory usage. As you’ll see, the gains can be substantial, potentially halving memory usage in certain cases. The second section will delve more deeply into the various approaches that can be used to handle recursive schema definitions. Lastly, we’ll emphasize that the design of your schema(s), coupled with the sorts you can apply at the record level, play a pivotal role in maximizing the benefits of Apache Arrow and its columnar representation.</p>

<h2 id="handling-dynamic-and-unknown-data-distributions">Handling dynamic and unknown data distributions</h2>

<p>In certain contexts, the comprehensive definition of an Arrow schema can end up being overly broad and complex in order to cover all possible cases that you intend to represent in columnar form. However, as is often the case with complex schemas, only a subset of this schema will actually be utilized for a specific deployment. Similarly, it’s not always possible to determine the optimal dictionary encoding for one or more fields in advance. Employing a broad and very general schema that covers all cases is usually more memory-intensive. This is because, for most implementations, a column without value still continues to consume memory space. Likewise, a column with dictionary encoding that indexes a uint64 will occupy four times more memory than the same column with a dictionary encoding based on a uint8.</p>

<p>To illustrate this more concretely, let’s consider an OTel collector positioned at the output of a production environment, receiving a telemetry data stream produced by a large and dynamic set of servers. Invariably, the content of this telemetry stream will change in volume and nature over time. It’s challenging to predict the optimal schema in such a scenario, and it’s equally difficult to know in advance the distribution of a particular attribute of the telemetry data passing through this point.</p>

<p>To optimize such scenarios, we have adopted an intermediary approach that we have named <strong>dynamic Arrow schema</strong>, aiming to gradually adapt the schema based on the observed data. The general principle is relatively simple. We start with a general schema defining the maximum envelope of what should be represented. Some fields of this schema will be declared optional, while other fields will be encoded with multiple possible options depending on the observed distribution. In theory, this principle can be applied to other types of transformations (e.g., recursive column creation) but we will let your imagination explore these other options. So if you encounter data streams where certain fields are not utilized, some union variants remain unused, and/or the value distribution of a field cannot be determined a priori, it may be worthwhile to invest time in implementing this model. This can lead to improved efficiency in terms of compression ratio, memory usage, and processing speed.</p>

<p>The following Go Arrow schema definition provides an example of such a schema, instrumented with a collection of annotations. These annotations will be processed by an enhanced Record Builder, equipped with the ability to dynamically adapt the schema. The structure of this system is illustrated in Figure 1.</p>

<div><pre><code><span>var</span> <span>(</span>
  <span>// Arrow schema for the OTLP Arrow Traces record (without attributes, links, and events).</span>
  <span>TracesSchema</span> <span>=</span> <span>arrow</span><span>.</span><span>NewSchema</span><span>([]</span><span>arrow</span><span>.</span><span>Field</span><span>{</span>
      <span>// Nullabe:true means the field is optional, in this case of 16 bit unsigned integers</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>ID</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint16</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Resource</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>StructOf</span><span>([]</span><span>arrow</span><span>.</span><span>Field</span><span>{</span>
        <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>ID</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint16</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
        <span>// --- Use dictionary with 8 bit integers initially ----</span>
        <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>SchemaUrl</span><span>,</span><span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span><span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
        <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DroppedAttributesCount</span><span>,</span><span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint32</span><span>,</span><span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>}</span><span>...</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Scope</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>StructOf</span><span>([]</span><span>arrow</span><span>.</span><span>Field</span><span>{</span>
          <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>ID</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint16</span><span>,</span> <span>Metadata</span><span>:</span> <span>acommon</span><span>.</span><span>Metadata</span><span>(</span><span>acommon</span><span>.</span><span>DeltaEncoding</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
          <span>// --- Use dictionary with 8 bit integers initially ----</span>
          <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Name</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>acommon</span><span>.</span><span>Metadata</span><span>(</span><span>acommon</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
          <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Version</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>acommon</span><span>.</span><span>Metadata</span><span>(</span><span>acommon</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
          <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DroppedAttributesCount</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint32</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>}</span><span>...</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>SchemaUrl</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>StartTimeUnixNano</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>FixedWidthTypes</span><span>.</span><span>Timestamp_ns</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DurationTimeUnixNano</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>FixedWidthTypes</span><span>.</span><span>Duration_ms</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>)},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>TraceId</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>FixedSizeBinaryType</span><span>{</span><span>ByteWidth</span><span>:</span> <span>16</span><span>}},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>SpanId</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>FixedSizeBinaryType</span><span>{</span><span>ByteWidth</span><span>:</span> <span>8</span><span>}},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>TraceState</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>ParentSpanId</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>FixedSizeBinaryType</span><span>{</span><span>ByteWidth</span><span>:</span> <span>8</span><span>},</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Name</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>)},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>KIND</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Int32</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DroppedAttributesCount</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint32</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DroppedEventsCount</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint32</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>DroppedLinksCount</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint32</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Status</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>StructOf</span><span>([]</span><span>arrow</span><span>.</span><span>Field</span><span>{</span>
        <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>StatusCode</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Int32</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
        <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>StatusMessage</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>,</span> <span>Metadata</span><span>:</span> <span>schema</span><span>.</span><span>Metadata</span><span>(</span><span>schema</span><span>.</span><span>Dictionary8</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
      <span>}</span><span>...</span><span>),</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
    <span>},</span> <span>nil</span><span>)</span>
  <span>)</span>
</code></pre></div>

<p>In this example, Arrow field-level metadata are employed to designate when a field is optional (Nullable: true) or to specify the minimal dictionary encoding applicable to a particular field (Metadata Dictionary8/16/…). Now let’s imagine a scenario utilizing this schema in a straightforward scenario, wherein only a handful of fields are actually in use, and the cardinality of most dictionary-encoded fields is low (i.e., below 2^8). Ideally, we’d want a system capable of dynamically constructing the following simplified schema, which, in essence, is a strict subset of the original schema.</p>

<div><pre><code><span>var</span> <span>(</span>
  <span>// Simplified schema definition generated by the Arrow Record encoder based on</span>
  <span>// the data observed.</span>
  <span>TracesSchema</span> <span>=</span> <span>arrow</span><span>.</span><span>NewSchema</span><span>([]</span><span>arrow</span><span>.</span><span>Field</span><span>{</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>ID</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint16</span><span>,</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>StartTimeUnixNano</span><span>,</span> <span>Type</span><span>:</span> <span>arrow</span><span>.</span><span>FixedWidthTypes</span><span>.</span><span>Timestamp_ns</span><span>},</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>TraceId</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>FixedSizeBinaryType</span><span>{</span><span>ByteWidth</span><span>:</span> <span>16</span><span>}},</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>SpanId</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>FixedSizeBinaryType</span><span>{</span><span>ByteWidth</span><span>:</span> <span>8</span><span>}},</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>Name</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>DictionaryType</span> <span>{</span>
      <span>IndexType</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint8</span><span>,</span>
      <span>ValueType</span><span>:</span> <span>arrow</span><span>.</span><span>BinaryTypes</span><span>.</span><span>String</span><span>}},</span>
    <span>{</span><span>Name</span><span>:</span> <span>constants</span><span>.</span><span>KIND</span><span>,</span> <span>Type</span><span>:</span> <span>&amp;</span><span>arrow</span><span>.</span><span>DictionaryType</span> <span>{</span>
      <span>IndexType</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Uint8</span><span>,</span>
      <span>ValueType</span><span>:</span> <span>arrow</span><span>.</span><span>PrimitiveTypes</span><span>.</span><span>Int32</span><span>,</span>
    <span>},</span> <span>Nullable</span><span>:</span> <span>true</span><span>},</span>
  <span>},</span> <span>nil</span><span>)</span>
<span>)</span>
</code></pre></div>

<p>Additionally, we desire a system capable of automatically adapting the aforementioned schema if it encounters new fields or existing fields with a cardinality exceeding the size of the current dictionary definition in future batches. In extreme scenarios, if the cardinality of a specific field surpasses a certain threshold, we would prefer the system to automatically revert to the non-dictionary representation (mechanism of dictionary overflow). That is precisely what we will elaborate on in the remainder of this section.</p>

<p>An overview of the different components and events used to implement this approach is depicted in figure 1.</p>

<figure>
  <img src="https://arrow.apache.org/img/journey-apache-arrow/adaptive-schema-architecture.svg" width="100%" alt="Fig 1: Adaptive Arrow schema architecture overview.">
  <figcaption>Fig 1: Adaptive Arrow schema architecture overview.</figcaption>
</figure>

<p>The overall Adaptive Arrow schema component takes a data stream segmented into batches and produces one or multiple streams of Arrow Records (one schema per stream). Each of these records is defined with an Arrow schema, which is based both on the annotated Arrow schema and the shape of fields observed in the incoming data.</p>

<p>More specifically, the process of the Adaptive Arrow schema component consists of four main phases</p>

<p><strong>Initialization phase</strong></p>

<p>During the initialization phase, the Arrow Record Encoder reads the annotated Arrow schema (i.e. the reference schema) and generates a collection of transformations. When these transformations are applied to the reference schema, they yield the first minimal Arrow schema that adheres to the constraints depicted by these annotations. In this initial iteration, all optional fields are eliminated, and all dictionary-encoded fields are configured to utilize the smallest encoding as defined by the annotation (only <code>Dictionary8</code> in the previous example). These transformations form a tree, reflecting the structure of the reference schema.</p>

<p><strong>Feeding phase</strong></p>

<p>Following the initialization is the feeding phase. Here, the Arrow Record Encoder scans the batch and attempts to store all the fields in an Arrow Record Builder, which is defined by the schema created in the prior step. If a field exists in the data but is not included in the schema, the encoder will trigger a <code>missing field</code> event. This process continues until the current batch is completely processed. An additional internal check is conducted on all dictionary-encoded fields in the Arrow Record builder to ensure there’s no dictionary overflow (i.e. more unique entries than the cardinality of the index permits). <code>Dictionary overflow</code> events are generated if such a situation is detected. Consequently, by the end, all unknown fields and dictionary overflow would have been detected, or alternatively, no discrepancies would have surfaced if the data aligns perfectly with the schema.</p>

<p><strong>Corrective phase</strong></p>

<p>If at least one event has been generated, a corrective phase will be initiated to fix the schema. This optional stage considers all the events generated in the previous stage and adjusts the transformation tree accordingly to align with the observed data. A <code>missing field</code> event will remove a NoField transformation for the corresponding field. A <code>dictionary overflow</code> event will modify the dictionary transformation to mirror the event (e.g. changing the index type from uint8 to uint16, or if the maximum index size has been reached, the transformation will remove the dictionary-encoding and revert to the original non-dictionary-encoded type). The updated transformation tree is subsequently used to create a new schema and a fresh Arrow Record Builder. This Record Builder is then utilized to replay the preceding feeding phase with the batch that wasn’t processed correctly.</p>

<p><strong>Routing phase</strong></p>

<p>Once a Record Builder has been properly fed, an Arrow Record is created, and the system transitions into the routing phase. The router component calculates a schema signature of the record and utilizes this signature to route the record to an existing Arrow stream compatible with the signature, or it initiates a new stream if there is no match.</p>

<p>This four-phase process should gradually adapt and stabilize the schema to a structure and definition that is optimized for a specific data stream. Unused fields will never unnecessarily consume memory. Dictionary-encoded fields will be defined with the most optimal index size based on the observed data cardinality, and fields with a cardinality exceeding a certain threshold (defined by configuration) will automatically revert to their non-dictionary-encoded versions.</p>

<p>To effectively execute this approach, you must ensure that there is a sufficient level of flexibility on the receiver side. It’s crucial that your downstream pipeline remains functional even when some fields are missing in the schema or when various dictionary index configurations are employed. While this may not always be feasible without implementing additional transformations upon reception, it proves worthwhile in certain scenarios.</p>

<p>The following results highlight the significant memory usage reduction achieved through the application of various optimization techniques. These results were gathered using a schema akin to the one previously presented. The considerable memory efficiency underscores the effectiveness of this approach.</p>

<figure>
  <img src="https://arrow.apache.org/img/journey-apache-arrow/memory-usage-25k-traces.png" width="100%" alt="Fig 2: Comparative analysis of memory usage for different schema optimizations.">
  <figcaption>Fig 2: Comparative analysis of memory usage for different schema optimizations.</figcaption>
</figure>

<p>The concept of a transformation tree enables a generalized approach to perform various types of schema optimizations based on the knowledge acquired from the data. This architecture is highly flexible; the current implementation allows for the removal of unused fields, the application of the most specific dictionary encoding, and the optimization of union type variants. In the future, there is potential for introducing additional optimizations that can be expressed as transformations on the initial schema. An implementation of this approach is available <a href="https://github.com/f5/otel-arrow-adapter/tree/main/pkg/otel/common/schema">here</a>.</p>

<h2 id="handling-recursive-schema-definition">Handling recursive schema definition</h2>

<p>Apache Arrow does not support recursive schema definitions, implying that data structures with variable depth cannot be directly represented. Figure 3 exemplifies such a recursive definition where the value of an attribute can either be a simple data type, a list of values, or a map of values. The depth of this definition cannot be predetermined.</p>

<figure>
  <img src="https://arrow.apache.org/img/journey-apache-arrow/recursive-def-otel-attributes.svg" width="100%" alt="Fig 3: Recursive definition of OTel attributes.">
  <figcaption>Fig 3: Recursive definition of OTel attributes.</figcaption>
</figure>

<p>Several strategies can be employed to circumvent this limitation. Technically, the dynamic schema concept we’ve presented could be expanded to dynamically update the schema to include any missing level of recursion. However, for this use case, this method is complex and has the notable downside of not offering any assurance on the maximum size of the schema. This lack of constraint can pose security issues; hence, this approach isn’t elaborated upon.</p>

<p>The second approach consists of breaking the recursion by employing a serialization format that supports the definition of a recursive schema. The result of this serialization can then be integrated into the Arrow record as a binary type column, effectively halting the recursion at a specific level. To fully leverage the advantages of columnar representation, it is crucial to apply this ad-hoc serialization as deeply within the data structure as feasible. In the context of OpenTelemetry, this is performed at the attribute level – more specifically, at the second level of attributes.</p>

<p>A variety of serialization formats, such as protobuf or CBOR, can be employed to encode recursive data. Without particular treatment, these binary columns may not be easily queryable by the existing Arrow query engines. Therefore, it’s crucial to thoughtfully ascertain when and where to apply such a technique. While I’m not aware of any attempts to address this limitation within the Arrow system, it doesn’t seem insurmountable and would constitute a valuable extension. This would help reduce the complexity of integrating Arrow with other systems that rely on such recursive definitions.</p>

<h2 id="importance-of-sorting">Importance of sorting</h2>

<p>In our preceding <a href="https://arrow.apache.org/blog/2023/04/11/our-journey-at-f5-with-apache-arrow-part-1/">article</a>, we explored a variety of strategies to represent hierarchical data models, including nested structures based on struct/list/map/union, denormalization and flattening representations, as well as a multi-record approach. Each method presents its unique advantages and disadvantages. However, in this last section, we’ll delve deeper into the multi-record approach, focusing specifically on its ability to offer versatile sorting options and how these options contribute to an enhanced compression ratio.</p>

<p>In the OTel Arrow protocol, we leverage the multi-record approach to represent metrics, logs, and traces. The following entity-relationship diagram offers a simplified version of various record schemas and illustrates their relationships, specifically those used to represent gauges and sums. A comprehensive description of the Arrow data model employed in OpenTelemetry can be accessed <a href="https://github.com/f5/otel-arrow-adapter/blob/main/docs/data_model.md">here</a>.</p>

<p>These Arrow records, also referred to as tables, form a hierarchy with <code>METRICS</code> acting as the primary entry point. Each table can be independently sorted according to one or more columns. This sorting strategy facilitates the grouping of duplicated data, thereby improving the compression ratio.</p>

<figure>
  <img src="https://arrow.apache.org/img/journey-apache-arrow/metric-dp-data-model.png" width="100%" alt="Fig 4: A simplified entity-relationship diagram representing OTel sum &amp; gauge metrics.">
  <figcaption>Fig 4: A simplified entity-relationship diagram representing OTel sum &amp; gauge metrics.</figcaption>
</figure>

<p>The relationship between the primary <code>METRICS</code> table and the secondary <code>RESOURCE_ATTRS</code>, <code>SCOPE_ATTRS</code>, and <code>NUMBER_DATA_POINTS</code> tables is established through a unique <code>id</code> in the main table and a <code>parent_id</code> column in each of the secondary tables. This {id,parent_id} pair represents an overhead that should be minimized to the greatest extent possible post-compression.</p>

<p>To achieve this, the ordering process for the different tables adheres to the hierarchy, starting from the main table down to the leaf. The main table is sorted (by one or multiple columns), and then an incremental id is assigned to each row. This numerical id is stored using delta-encoding, which is implemented on top of Arrow.</p>

<p>The secondary tables directly connected to the main table are sorted using the same principle, but the <code>parent_id</code> column is consistently utilized as the last column in the sort statement. Including the <code>parent_id</code> column in the sort statement enables the use of a variation of delta encoding. The efficiency of this approach is summarized in the chart below.</p>

<figure>
  <img src="https://arrow.apache.org/img/journey-apache-arrow/compressed-message-size.png" width="100%" alt="Fig 5: Comparative analysis of compression ratios - OTLP Protocol vs. Two variations of the OTel Arrow Protocol with multivariate metrics stream. (lower percentage is better)">
  <figcaption>Fig 5: Comparative analysis of compression ratios - OTLP Protocol vs. Two variations of the OTel Arrow Protocol with multivariate metrics stream. (lower percentage is better)</figcaption>
</figure>

<p>The second column presents the average size of the OTLP batch both pre- and post-ZSTD compression for batches of varying sizes. This column serves as a reference point for the ensuing two columns. The third column displays results for the OTel Arrow protocol without any sorting applied, while the final column showcases results for the OTel Arrow protocol with sorting enabled.</p>

<p>Before compression, the average batch sizes for the two OTel Arrow configurations are predictably similar. However, post-compression, the benefits of sorting each individual table on the compression ratio become immediately apparent. Without sorting, the OTel Arrow protocol exhibits a compression ratio that’s 1.40 to 1.67 times better than the reference. When sorting is enabled, the OTel Arrow protocol outperforms the reference by a factor ranging from 4.94 to 7.21 times!</p>

<p>The gains in terms of compression obviously depend on your data and the redundancy of information present in your data batches. According to our observations, the choice of a good sort generally improves the compression ratio by a factor of 1.5 to 8.</p>

<p>Decomposing a complex schema into multiple simpler schemas to enhance sorting capabilities, coupled with a targeted approach to efficiently encode the identifiers representing the relationships, emerges as an effective strategy for enhancing overall data compression. This method also eliminates complex Arrow data types, such as lists, maps, and unions. Consequently, it not only improves but also simplifies data query-ability. This simplification proves beneficial for existing query engines, which may struggle to operate on intricate schemas.</p>

<h2 id="conclusion-and-next-steps">Conclusion and next steps</h2>

<p>This article concludes our two-part series on Apache Arrow, wherein we have explored various strategies to maximize the utility of Apache Arrow within specific contexts. The adaptive schema architecture presented in the second part of this series paves the way for future optimization possibilities. We look forward to seeing what the community can add based on this contribution.</p>

<p>Apache Arrow is an exceptional project, continually enhanced by a thriving ecosystem. However, throughout our exploration, we have noticed certain gaps or points of friction that, if addressed, could significantly enrich the overall experience.</p>
<ul>
  <li>Designing an efficient Arrow schema can, in some cases, prove to be a challenging task. Having the <strong>ability to collect statistics</strong> at the record level could facilitate this design phase (data distribution per field, dictionary stats, Arrow array sizes before/after compression, and so on). These statistics would also assist in identifying the most effective columns on which to base the record sorting.</li>
  <li><strong>Native support for recursive schemas</strong> would also increase adoption by simplifying the use of Arrow in complex scenarios. While I’m not aware of any attempts to address this limitation within the Arrow system, it doesn’t seem insurmountable and would constitute a valuable extension. This would help reduce the complexity of integrating Arrow with other systems that rely on such recursive definitions.</li>
  <li><strong>Harmonizing the support for data types as well as IPC stream capabilities</strong> would also be a major benefit. Predominant client libraries support nested and hierarchical schemas, but their use is limited due to a lack of full support across the rest of the ecosystem. For example, list and/or union types are not well supported by query engines or Parquet bridges. Also, the advanced dictionary support within IPC streams is not consistent across different implementations (i.e. delta dictionaries and replacement dictionaries are not supported by all implementations).</li>
  <li><strong>Optimizing the support of complex schemas</strong> in terms of memory consumption and compression rate could be improved by natively integrating the concept of the dynamic schema presented in this article.</li>
  <li><strong>Detecting dictionary overflows</strong> (index level) is not something that is easy to test on the fly. The API could be improved to indicate this overflow as soon as an insertion occurs.</li>
</ul>

<p>Our effort to utilize Apache Arrow in conjunction with OpenTelemetry has produced encouraging results. While this has necessitated considerable investment in terms of development, exploration, and benchmarking, we hope that these articles will aid in accelerating your journey with Apache Arrow. Looking ahead, we envision an end-to-end integration with Apache Arrow and plan to significantly extend our use of the Arrow ecosystem. This extension involves providing a bridge with Parquet and integrating with a query engine such as DataFusion, with the goal of processing telemetry streams within the collector.</p>

      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Hate the News (2006) (109 pts)]]></title>
            <link>http://www.aaronsw.com/weblog/hatethenews</link>
            <guid>36593249</guid>
            <pubDate>Tue, 04 Jul 2023 22:20:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.aaronsw.com/weblog/hatethenews">http://www.aaronsw.com/weblog/hatethenews</a>, See on <a href="https://news.ycombinator.com/item?id=36593249">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Some people start their day by reading <em>The New York Times</em>. Others end it by watching the nightly news. Some get it from <em>The Daily Show</em>. Others download it from a variety weblogs. Some keep up-to-the-minute by following CNN. Others have instant news updates automatically text messaged to their phone. But everybody seems to agree: it’s a citizen’s responsibility to keep up with the news. Everybody except me.</p><p>I think following the news is a waste of time.</p><p>Some people agree with me on a small scale. Some point out that the cable channels are obsessed with bizarre crimes that have little larger impact, that they worry too much about horse-race coverage of politics, that too much of the news is filled with PR-inserted nonsense. But they do this because they think these are aberrations; that underneath all this, the news is worth saving. I simply go one step further: I think none of it is worthwhile.</p><p>Let us look at the front page of today’s <em>New York Times</em>, the gold standard in news. In the top spot there is a story about Republicans feuding among themselves. There is a photo of soldiers in Iraq. A stock exchange chief must return $100M. There is a concern about some doctors over-selling a nerve testing system. There is a threat from China against North Korea. There is a report that violence in Iraq is rising. And there is concern about virtual science classes replacing real ones.</p><p>None of these stories have relevance to my life. Reading them may be enjoyable, but it’s an enjoyable waste of time. They will have no impact on my actions one way or another.</p><p>Most people will usually generally concede this point, but suggest that there’s something virtuous about knowing it anyway, that it makes me a better citizen. They point out that newspapers are a key part of our democracy, that by exposing wrong-doing to the people, they force the wrong-doers to stop.</p><p>This seems to be true, but the curious thing is that I’m never involved. The government commits a crime, the <em>New York Times</em> prints it on the front page, the people on the cable chat shows foam at the mouth about it, the government apologizes and commits the crime more subtly. It’s a valuable system — I certainly support the government being more subtle about committing crimes (well, for the sake of argument, at least) — but you notice how it never involves me? It seems like the whole thing would work just as well even if nobody ever read the <em>Times</em> or watched the cable chat shows. It’s a closed system.</p><p>There is voting, of course, but to become an informed voter all one needs to do is read a short guide about the candidates and issues before the election. There’s no need to have to suffer through the daily back-and-forth of allegations and counter-allegations, of scurrilous lies and their refutations. Indeed, reading a voter’s guide is much better: there’s no recency bias (where you only remember the crimes reported in the past couple months), you get to hear both sides of the story after the investigation has died down, you can actually think about the issues instead of worrying about the politics.</p><p>Others say that sure, most of the stuff in the news isn’t of use, but occasionally you’ll come across some story that will lead you to actually change what you’ve been working on. But really, how plausible is this? Most people’s major life changes don’t come from reading an article in the newspaper; they come from reading longer-form essays or thoughtful books, which are much more convincing and detailed.</p><p>Which brings me to my second example of people agreeing with me on the small scale. You’ll often hear TV critics say that CNN’s up-to-the-minute reporting is absurd. Instead of saying, “We have unconfirmed reports that—This just in! We now have confirmed reports that those unconfirmed reports have been denied. No, wait! There’s a new report denying the confirmation of the denial of the unconfirmed report.” and giving viewers whiplash, they suggest that the reporters simply wait until a story is confirmed before reporting it and do commentary in the meantime.</p><p>But if that’s true on a scale of minutes, why longer? Instead of watching hourly updates, why not read a daily paper? Instead of reading the back and forth of a daily, why not read <a href="http://harpers.org/WeeklyReview.html">a weekly review</a>? Instead of a weekly review, why not read a monthly magazine? Instead of a monthly magazine, why not read an annual book?</p><p>With the time people waste reading a newspaper every day, they could have read an entire book about most subjects covered and thereby learned about it with far more detail and far more impact than the daily doses they get dribbled out by the paper. But people, of course, wouldn’t read a book about most subjects covered in the paper, because most of them are simply irrelevant.</p><p>But finally, I’d like to argue that following the news isn’t just a waste of time, it’s actively unhealthy. Edward Tufte notes that when he used to read the <em>New York Times</em> in the morning, it scrambled his brain with so many different topics that he couldn’t get any real intellectual work done the rest of the day.</p><p>The news’s obsession with having a little bit of information on a wide variety of subjects means that it actually gets most of those subjects wrong. (One need only read the blatant errors reported in the corrections page to get some sense of the more thorough-going errors that must lie beneath them. And, indeed, anyone who has ever been in the news will tell you that the news always gets the story wrong.) Its obsession with the criminal and the deviant makes us less trusting people. Its obsession with the hurry of the day-to-day makes us less reflective thinkers. Its obsession with surfaces makes us shallow.</p><p>This is not simply an essay meant to provoke; I genuinely believe what I write. I have not followed the news at least since I was 13 (with occasional lapses on particular topics). My life does not seem to be impoverished for it; indeed, I think it has been greatly enhanced. But I haven’t found many other people who are willing to take the plunge.</p><div id="comments_body">




<div id="c1">
<p>I’d distinguish what’s relevant from what’s interesting. E.g., a local zoning board dispute is more relevant to me than interesting.  You’re still interested in matters that are only marginally relevant to you. You’re just widening your sample as a noise filter, and it just becomes a matter of finding the optimum time period.  So if journalism is the first draft of history, maybe we should wait for the second draft, huh?</p>

<p>posted by Mike Sierra
 on October 20, 2006 <a href="#c1" rel="bookmark">#</a></p>
</div>
<div id="c2">
<p>This essay is kinda funny considering that Aaron works on a website that is all about sharing democratizing news…</p>

<p>posted by johnnyboy
 on October 20, 2006 <a href="#c2" rel="bookmark">#</a></p>
</div>
<div id="c3">
<p>johnnyboy: Is that what Aaron’s blog is about? Hmmm…I thought it was about making fun of people. That’s why I read it, anyway. Though you are right, this one was pretty funny too.</p>

<p>posted by ged
 on October 20, 2006 <a href="#c3" rel="bookmark">#</a></p>
</div>
<div id="c4">
<p>Wow, this post plays to so many of my own prejudices about the news, I almost want to disqualify myself from commenting! LOL Anyway, I have a challenge I’ve posted to friends and strangers over the past 25 years, and I have yet to have a “winner.”  Here it is: if you, personally (first-hand knowledge only!) have been involved in a situation that was reported in the newspaper, did they get it correct, 100 percent? Every name spelled correctly?  The numbers right? The very simplest of details that would have been easy to check and verify?  Because of the several hundred (admittedly small sample) I’ve asked, no one has answered in the affirmative.  From the smallest local story to the national ones.  I just think that’s bizarre, and I don’t understand it, knowing how obsessive some reporters and writers can be about details.  Any explanations?</p>

<p>posted by Reg Aubry
 on October 20, 2006 <a href="#c4" rel="bookmark">#</a></p>
</div>
<div id="c5">
<p>Stop reminding me of Theodore Sturgeon short stories dangit! If you haven’t read “And Now The News…” (the story in the book of the same title) you must go read it now! Go!</p>

<p>posted by <a rel="nofollow" href="http://mccarthy.vg/">Jamie McCarthy</a>
 on October 20, 2006 <a href="#c5" rel="bookmark">#</a></p>
</div>
<div id="c6">
<p>One morning about 5 years ago, for reasons which I have never fully understood, I clicked on the morning news for the first time ever. The date was 9/11/2001. The result was so bad that I never repeated the experiment.</p>

<p>posted by Gordon
 on October 20, 2006 <a href="#c6" rel="bookmark">#</a></p>
</div>
<div id="c7">
<p>By the same argument, we probably shouldn’t read blogs either, except ones that have time-sensitive, relative information.</p>

<p>posted by <a rel="nofollow" href="http://slesinsky.org/brian/">Brian Slesinsky</a>
 on October 21, 2006 <a href="#c7" rel="bookmark">#</a></p>
</div>
<div id="c8">
<p>@Reg Aubry:</p>

<p>Consider how unreliable eyewitness testimony is. People who witness crimes often have very different accounts of what happened — not just trivia like whether the assailant was wearing green-on-red plaid or red-on-green plaid, but how many people were involved, the sequence of events, the skin color and other obvious physical characteristics of the people involved, etc.</p>

<p>What’s my point? The news is made by people who rely on other people and their memories and explanations of what happened.</p>

<p>And that is not even considering the intentional dishonesty of parties involved in the events.</p>

<p>posted by joseph knecht
 on October 21, 2006 <a href="#c8" rel="bookmark">#</a></p>
</div>
<div id="c9">
<p>actually, nassim taleb (author of Fooled by Randomness, which is an awesome book about luck and financial markets) also talks about information pollution (more in the context of financial commentators on things like CNBC and Bloomberg).</p>

<p>posted by <a rel="nofollow" href="http://fireshui.com/">B.Z.</a>
 on October 21, 2006 <a href="#c9" rel="bookmark">#</a></p>
</div>
<div id="c10">
<blockquote>
  <p>None of these stories have relevance to my life. 
  Reading them may be enjoyable, but it’s an 
  enjoyable waste of time. They will have no impact 
  on my actions one way or another.</p>
</blockquote>

<p>You’re basically arguing against Chomsky and denying the influence of media on public opinion. This is very interesting for several reasons, one would be that you’ve just found out that spending money in political campaigns is a waste - though somehow this goes against every piece of study done in that field; OK, maybe it is in fact only the bumpersticker and the flag that make difference, not the news-media.</p>

<p>But seriously: I think you are arguing, that it doesn’t make any sense for YOU to read the news, because you already made up your mind on all the things you’re going to do. You know who you’re voting for, you know that you’ll not be taking part in any revolutions toppling the government, you know already what you want to believe about the policies of certain politicians, or parties. In such a case of course it doesn’t help to read the news. Neither for you, nor for followers of the Bush cult, or religious nuts etc. (forgive me for juxtaposing you with those groups; I know that unlike them you are from the reality-based community and will change your perceptions in accordance with reality).</p>

<p>However the conclusion that it is unnecessary for you, does not mean it is unnecesary for everybody. I agree that watching the news daily is more for entertainment, but I think getting a weekly overview over what is happening is important, for the same reason for <em>not</em> letting all tax-related stuff pile up until shortly before the deadlines; it’s easier to “get done”, it feels less like a chore). And yes, due to things I have read in the news, I have actualy taken action, like taking part in demonstrations for/against certain ideas/concepts/policies. It’s not like there is a dichotomy between reading long essays/books and reading newspapers. There is in fact a) some overlap and b) plenty of reason to do both, because I do not beforehand what topics I want (or should be) reading long books/essays on.</p>

<blockquote>
  <p>But if that’s true on a scale of minutes, why 
  longer? Instead of watching hourly updates, why 
  not read a daily paper? Instead of reading the 
  back and forth of a daily, why not read a weekly
   review? Instead of a weekly review, why not 
  read a monthly magazine? Instead of a monthly 
  magazine, why not read an annual book?</p>
</blockquote>

<p>That’s a very poor argument, in fact it’s not an argument it’s a slippery slope fallacy. And I am surprised that you’d stoop so low. Here see how much sense it makes:
“If having sex every minute of your life is not a good way to live your life and might lead to harmful side-effects, then why would it be a good idea to have sex once a day? or once a week? Or once a year or once in your life? If having sex every minute in your life is bad, then surely having sex even once in your life is bad as well. Remeber: If the glove doesn’t fit, you must acquit.”
Doesn’t make much sense, does it…</p>

<blockquote>
  <p>The news’s obsession with having a little bit of
  information on a wide variety of subjects means 
  that it actually gets most of those subjects 
  wrong.</p>
</blockquote>

<p>This seems similar to one of the commenters saying:</p>

<blockquote>
  <p>that was reported in the newspaper, did they get
  it correct, 100 percent?</p>
</blockquote>

<p>It’s probably true that often things are not 100% correct. It’s also true that of the many decision that I face as a human every day not all are 100% correct, yet I somehow manage to get by and even think of my life as being somewhat decent. Could it be that the same goes for newspapers? That while they may not be 100%correct  on any subject, that they manage to be decent enough to be useful for the people readin them? Sure, I’d prefer to have an oracle that is 100% correct; but I sure as hell would not pay the price for that with respect to news. You probably know the difference of cost between a datacenter that guarantuees 99% availability, and the one that offers 99,999% availability (the costs explode). For my purposes the former has been decent enough, thank you. As a politician making crucial decision about life or death, you certainl want higher precision, and they do in fact pay a lot more for their reports and intelligence, than what I pay for a newspaper. In any case: Are you honestly suggesting that the simple and obvious fact that a newspaper is not an oracle makes them useless?</p>

<blockquote>
  <p>It’s a valuable system — I certainly support 
  the government being more subtle about 
  committing crimes (well, for the sake of 
  argument, at least) — but you notice how it 
  never involves me? It seems like the whole thing
   would work just as well even if nobody ever 
  read the Times or watched the cable chat shows. 
  It’s a closed system.</p>
</blockquote>

<p>You can say the same thing about voting in a represantative democracy. Surely one singe vote is not going to make a difference. And even if only the people voted that actually hold office, and the rest of the population wouldn’t, it wouldn’t make a difference, would it? Legitimacy, Schmeticimacy, that’s not important. After all it’s only the brand that counts, right? If  somebody bought the “Times” and never published something to the pubic, and only made their claims to the officials in government, it would keep on working the same way. Much like when dictators claim they live and rule in a democracy and have free press, and freedom for the people, then that makes it true, at least as long as they bought the “true democracy brand”, like Iraq is currently doing. Certainly it doesn’t involve any of the actual people living there to do or say anything.</p>

<p>The reason that the “closed system” works, is because there is some legitimacy in it. That legitimacy is gone when people stop participating in it. For a newspaper participation comes from the readers it is reaching, and for a democracy it is the people voting. Claiming that it’s a “closed system” and works the same way when you take away the people is absurd.</p>

<p>What you <em>can</em> claim is that taking away one person is not going to make the system collapse. In game theory I believe this is called the free rider’s dilemma. Surely the country is not going down the drain, when one person is not paying his taxes. Surely public transit is not going bankrupt, if I decide not pay today. etc. etc.</p>

<blockquote>
  <p>Most people’s major life changes don’t come from
  reading an article in the newspaper; they come 
  from reading longer-form essays or thoughtful 
  books, which are much more convincing and 
  detailed.</p>
</blockquote>

<p>What does that say about your weblog?</p>

<p>I think what you are really trying to say, is that the act of delivering and the act of absorbing a list of facts about lots of unrelated little stories is not helpful. That’s true for a certain kind of “journalism” (in quotes) that feeds on the same instinct that makes peope slow down and look at accident-scenes. That’s indeed little helpful. But to reduce news, newspapers or the media to just that is dismissing the reality of the world we live in.</p>

<p>posted by Anonymous
 on October 21, 2006 <a href="#c10" rel="bookmark">#</a></p>
</div>
<div id="c11">
<p>Reading the news may, and probably does, make you a better citizen. But so what? I don’t want to be a (good) citizen, i.e. an (obedient) subject of a state. As the saying goes, “the only nation worth paying any allegiance to, is imagination”.</p>

<p>With regard to the news themselves, I just scan the headlines (RSS) to see what’s going on, and it won’t waste many minutes of my time a day. That’s usually quite enough to infer the content, most of which is totally uninteresting. Occasionally there’s a more interesting story worth reading, but only very occasionally.</p>

<p>One could actually almost “survive” on free newspapers here, as every few months some newspaper tries to lure you to order it, by offering it for free for a month or two. Some years ago I once took the free newspaper, but all I got was fed up with hauling the papers to the paper recycling bin, so I haven’t accepted any newspaper offers, free or otherwise, since then.</p>

<p>posted by <a rel="nofollow" href="http://iki.fi/tuomov/">tuomov</a>
 on October 21, 2006 <a href="#c11" rel="bookmark">#</a></p>
</div>
<div id="c12">
<p>I own a television, but it is literally wrapped up in a wooden box which has a lock on it, and for good reason. I also gave up on the news after a brief stint in the wake of 9-11 when every military anything had a TV tuned to CNN non-stop: having taken news consumption to its limit, and having a job, simultaneously, to find information, it became painfully clear that the news, and television in general, was a waste of time. I rely on friends and blogs to keep me informed of current events and I spend my ‘news’ time searching out other viewpoints. With those provisios, let me tack on to Anonymous about this:</p>

<blockquote>The news’s obsession with having a little bit of information on a wide variety of subjects means that it actually gets most of those subjects wrong.</blockquote>

<p>This is true, but it is also true that <a href="http://medicine.plosjournals.org/perlserv?request=get-document&amp;doi=10.1371/journal.pmed.0020124" rel="nofollow">most scientific findings are false</a>. This is a deep but practical reason that it is necessary to doubt, not to reject journalism.</p>

<p>posted by <a rel="nofollow" href="http://nielsolson.us/">Niels Olson</a>
 on October 21, 2006 <a href="#c12" rel="bookmark">#</a></p>
</div>
<div id="c13">
<p>Do you vote?
Are your choices when voting influenced by what you read in the news?</p>

<p>If so it is no longer a closed system and you are involved. The reason that the government reacts when the cable channels, etc froth at the mouth is that they are concerned that that votes are at stake. If no one ever read the papers, or watched the news, then the motivation for the goverment to ‘commit crimes more subtly” would not exist. It is not a closed system, but it can feel that way, as the actions of voters are only significant when viewed in large blocks.</p>

<p>I would agree that following the news on an hourly, or daily basis is a waste of time for the average person, but when the time comes to vote for a representative , knowledge of how they have performed in the past is valuable.</p>

<p>posted by <a rel="nofollow" href="http://blog.odonnell.nu/">Sean O'Donnell</a>
 on October 22, 2006 <a href="#c13" rel="bookmark">#</a></p>
</div>
<div id="c14">
<p>Maybe it’s not <em>reading</em> the Times that helps, but <em>buying</em> it — you’re paying the salaries of the reporters that expose politicians doing bad stuff.</p>

<p>posted by Chris
 on October 22, 2006 <a href="#c14" rel="bookmark">#</a></p>
</div>
<div id="c15">
<p>http://en.wikipedia.org/wiki/Solipsism</p>

<p>posted by hmmm
 on October 22, 2006 <a href="#c15" rel="bookmark">#</a></p>
</div>
<div id="c16">
<p><a href="http://www.aaronsw.com/weblog/hatethenews#c2" rel="nofollow">johnnyboy:</a> I considered adding a bit about myself in the last paragraph on that topic, but it seemed too self-indulgent.</p>

<p><a href="http://www.aaronsw.com/weblog/hatethenews#c10" rel="nofollow">Anonymous:</a> (and <a href="http://www.aaronsw.com/weblog/hatethenews#c13" rel="nofollow">Sean</a>) If you comment is only about voting, then all I need to do is read a voter guide shortly before the election. Why do I need to get daily updates on the back and forth? I’ve added a paragraph to this effect.</p>

<p>A slippery slope argument isn’t a fallacy, because sometimes it’s true. In any event, this isn’t a slippery slope argument — it’s a “if you agree there’s a line, where do you draw it?” argument.</p>

<p>I’m not saying newspapers are useless; I’m saying they’re worse than the alternative.</p>

<p><a href="http://www.aaronsw.com/weblog/hatethenews#c12" rel="nofollow">Niels:</a> The scientific findings are false in a very different way than newspapers are false. The scientific findings are false because in experiments you can’t rule out random chance. The newspaper findings are</p>

<p>posted by <a rel="nofollow" href="http://www.aaronsw.com/">Aaron Swartz</a>
 on October 22, 2006 <a href="#c16" rel="bookmark">#</a></p>
</div>
<div id="c17">
<p>“…to become an informed voter all one needs to do is read a short guide about the candidates and issues before the election.”
Will those of you who believe this PLEASE-STOP-VOTING.
Thanks.</p>

<p>posted by DaveA
 on October 22, 2006 <a href="#c17" rel="bookmark">#</a></p>
</div>
<div id="c18">
<p>Aaron, when considering a voter guide , then our opinions are much closer. The sad fact is that (over here in Ireland at least) voter guides are few and far between. On top of that where does the voter guide come from? Who compiled it? What are their biases? Now I need a voter guide guide to boot. Its a nice scenario , but impractical.</p>

<p>In the abscence of reliable, unbiased guides, the news is my only source of information. That said I agree that keeping up regularly is uneccessary. I use the large variety of news sources to help control the biases. I buy a paper perhaps once every 2 weeks, and watch television news with roughly the same frequency. If I find an issue of particular concern on one of these rare dips into the news stream that might result in a period of more intense attention than normal. If a serious national/european issue arises, It will become impossible to miss. And if something more specialist arises It will do doubt be raised in one of the many blogs on topics of interest that I subscribe.</p>

<p>For example when the EUCD started reared its ugly head that resulted in me paying particular attention to all news outlets that might carry any information on the subject at all. And close to key voting dates my attention was indeed hourly. All the better to lobby my MEP’s and combat any last minute PR by the opposing side.</p>

<p>But at the moment there is nothing particularly alarming happening that I wish to involve myself in, so its been weeks since I have watched TV news or read the papers.</p>

<p>I suppose this brings me to a second point. Why are you not involved? Why do you not contact your representatives? I will admit that the first time I did it I did not believe that it would actually accomplish anything, I almost viewed it as a symbolic protest, and with some representatives that was indeed the case. But in the majority of cases I was actually pleasantly suprised that the act of one voter calling, phoning or writing (email seems to be very ineffective) seemed to have a real impact.</p>

<p>posted by <a rel="nofollow" href="http://blog.odonnell.nu/">Sean O'Donnell</a>
 on October 22, 2006 <a href="#c18" rel="bookmark">#</a></p>
</div>
<div id="c19">
<p>Hi Aaron,</p>

<p>I enjoy your blog, and I love your honesty and disclosure. Really good.</p>

<p>Have you considered that because your opportunity-rich young life is at least partly a product of your country’s position in the world, you might have a responsibility to understand the cost externalities of this lifestyle? (In other words, to read good quality international news). Maybe ignorance is blissful self-indulgence?</p>

<p>Don’t mean to sound patronising, and I’m not trying to tell you what to do ;-) but it’s at least one argument in favour of reading the news, through whatever medium. On the other hand, personal experience suggests that this strategy does not tend to happiness, but hey!</p>

<p>Just my 2c.</p>

<p>posted by Lee Bryant
 on October 22, 2006 <a href="#c19" rel="bookmark">#</a></p>
</div>
<div id="c20">
<p>I’m incredibly concerned about the privilege I receive as a beneficiary of US imperialism and the costs to the rest of the world. That’s because I read books; not because I read the paper.</p>

<p>posted by <a rel="nofollow" href="http://www.aaronsw.com/">Aaron Swartz</a>
 on October 22, 2006 <a href="#c20" rel="bookmark">#</a></p>
</div>
<div id="c21">
<p>All counts. Books(new and old), papers, tvs, documentaries, movies, what you see on the street. How you talk to your Chinese, Argentinian, and Lebanese friends - Iraqi landlords - or even Jewish contractors - how the 20th century was for their family and people - and how it’s going - etc.</p>

<p>It’s harmful to think books are better than newspapers. For local and current issue, local papers and phone directory comes in handy, esp when things are not working that well in the local govts.</p>

<p>We all got basic intelligence to grasp how things are working in the world, problem is we haven’t sorted out the framework to design ‘dashboard’ for each and all of us - as a driver and passenger - but we have all kind of meters and warning lights piling up almost at random in front of our eyes.</p>

<p>But base should be that we all got enough intelligence to grasp what’s going on. The rest is like competition snotty kids having in classroom. Get it out. It’s a pettiness over the privilege.</p>

<p>posted by a.kusaka
 on October 23, 2006 <a href="#c21" rel="bookmark">#</a></p>
</div>
<div id="c22">
<p>I know you’re concerned and connected in a good way, and wasn’t trying to imply otherwise :-)</p>

<p>Books are great, but they can only tell you what has happened, not what is about to happen. Also, in my experience, where books use secondary or tertiary sources to reconstruct events, they sometimes get it wrong just like the ‘papers.</p>

<p>There are some great reporters out there who are writing great books page by page whilst covering events around the world, and without their primary materials based on sharing the experiences of real people, history books would be a lot more remote from real life.</p>

<p>posted by Lee Bryant
 on October 23, 2006 <a href="#c22" rel="bookmark">#</a></p>
</div>
<div id="c23">
<p>While i hail your strategy for following the news as a wise choice, i would like to emphasize that it may not be the best strategy for all people at all times.  To say “None of these stories have relevance to my life … They will have no impact on my actions one way or another” is true (or not) by personal choice and not of necessity.  For the most part i have followed the same strategy as have you; and me thinks it has served me well … obsession with what passes for mainstream news these days is most certainly the waste of time of a obsessive voyeur.  Yet from time to time it is wise to adapt and change the focus of your attention.  If there is a fire in the house, you must watch out.  Me thinks that is actually the case we have in the world today.  The urgent matter, of course, being the Bush Doctrine.  That is a fire that must be extinguished.  Involvement in that political story with the objective of taking control of the US congress away form the administration is an urgent matter with which every right minded citizen of the United States should be concerned … or so me thinks.</p>

<p>posted by <a rel="nofollow" href="http://fastblogit.com/seth">Seth Russell</a>
 on October 23, 2006 <a href="#c23" rel="bookmark">#</a></p>
</div>
<div id="c24">
<p><a href="http://www.aaronsw.com/weblog/hatethenews#c18" rel="nofollow">Sean:</a> So voter guides might be biased, but we can all trust newspapers?</p>

<p>I spent a long time contating my representatives; it’s never had an impact. So I decided to build a system to let lots of people contact their representatives, but then I found that didn’t have an impact either. So now I’m working on an even bigger system.</p>

<p><a href="http://www.aaronsw.com/weblog/hatethenews#c22" rel="nofollow">Lee:</a> Nobody is suggesting people shouldn’t do journalism and publish it in books. Nor that books are always right. But when do you care about what is just about to happen?</p>

<p>posted by <a rel="nofollow" href="http://www.aaronsw.com/">Aaron Swartz</a>
 on October 23, 2006 <a href="#c24" rel="bookmark">#</a></p>
</div>
<div id="c25">
<p>Aaron, as I said, I use the large variety of news sources to help control the biases. While this isnt perfect, no source of information (no matter how hard the author may honestly try) is completely free of bias, the only reasonable solution to that is to try and get as many sides of the opinion as possible. For voter guides to become a practical solution to the problem , the number being increased  would have to increase dramatically.</p>

<p>posted by <a rel="nofollow" href="http://blog.odonnell.nu/">Sean O'Donnell</a>
 on October 23, 2006 <a href="#c25" rel="bookmark">#</a></p>
</div>
<div id="c26">
<p>I’ll offer two counter-points:</p>

<p>1) Part of what makes news interesting is also what makes <em>Lost</em> and the Detroit Tigers interesting — it’s fun to talk about. That is, it’s conversationally fun to be aware of current events and develop hypotheses on their outcomes.</p>

<p>2) The book version of news seems to miss the point. News is a <em>process</em>, a narrative — not a finished complete product. That’s what makes it fun.</p>

<p>posted by <a rel="nofollow" href="http://www.fimoculous.com/">Rex</a>
 on October 24, 2006 <a href="#c26" rel="bookmark">#</a></p>
</div>
<div id="c27">
<p>Part of the Australian Yr 12 HSC English course is Representation of the Truth.
Most of the classwork is sitting around watching news and current affairs shows and discussing how they lied about what they just showed and who is influencing them. After doing that unit of work, we basically learned to question everything about the news anyway.</p>

<p>Thankfully, last Monday I finished english forever :P</p>

<p>posted by Duck
 on October 24, 2006 <a href="#c27" rel="bookmark">#</a></p>
</div>
<div id="c28">
<p>There’s a difference between News, information, and the Media. I have been cut off from the news for a year now since giving up TV. I was never  fond of newspapers, and I was generally tired of what was out there. My half full glass was emptied everytime I started reading or listening. The only thing I may regret about the experience is my inability to compete at Trivia Pursuit in a couple years.</p>

<p>posted by <a rel="nofollow" href="http://biggirlunderoos.blogspot.com/">Sassy Pants</a>
 on October 26, 2006 <a href="#c28" rel="bookmark">#</a></p>
</div>
<div id="c29">
<p>While I can’t agree with your proudly apathetic stance, I do think there’s a germ of truth to it - especially given the sad, sensationalistic nature of modern news.   As Ben Hecht said ”
“Trying to determine what is going on in the world by reading newspapers is like trying to tell the time by watching the second hand of a clock.”</p>

<p>posted by joseph
 on October 27, 2006 <a href="#c29" rel="bookmark">#</a></p>
</div>
<div id="c30">
<p>While I can’t agree with your proudly apathetic stance, I do think there’s a germ of truth to it - especially given the sad, sensationalistic nature of modern news.   As Ben Hecht said ”
“Trying to determine what is going on in the world by reading newspapers is like trying to tell the time by watching the second hand of a clock.”</p>

<p>posted by joseph
 on October 27, 2006 <a href="#c30" rel="bookmark">#</a></p>
</div>
<div id="c31">
<p>More news, not less. More sources, not less. More choice, not less. More often, not less. You’re either open or closed, dynamic or static, moving or still. Alive or dead.</p>

<p>News is not about citizenship, it’s about survival.</p>

<p>posted by <a rel="nofollow" href="http://www.niallflaherty.com/">Niall</a>
 on October 28, 2006 <a href="#c31" rel="bookmark">#</a></p>
</div>
<div id="c32">
<p>Hi Aaron,</p>

<p>You asked “when do you care about what is just about to happen?”</p>

<p>Well, sometimes you do. If you retro-analyse attacks on civil liberties or other changes that can impact on our lives, you can probably find a pattern of signals in prior coverage. If you live in Iran, you presumably read the evil empire’s statements about Iranian nuclear technology very closely, as they could mean the difference between living a normal life and being bombed back to the stone age. There are many more examples I can think of, some too personal to relate here, where a better news radar could have saved peoples’ lives if they knew when to get out of a particular place or situation.</p>

<p>Also, perhaps when you have expended your entrepreneurial energies inventing things and starting companies, you might end up holding stock in the companies that buy your ventures ;-) In that case, you may want to track the news to find out what is about to happen.</p>

<p>Anyway - it’s all RSS these days. Just write an early warning algorithm based on text analysis and get a nabaztag bunny to notify you when to pack your bags and get the hell out of Dodge ;-)</p>

<p>posted by <a rel="nofollow" href="http://www.headshift.com/">Lee Bryant</a>
 on October 28, 2006 <a href="#c32" rel="bookmark">#</a></p>
</div>
<div id="c47">
<p>Great article! I’ve written something similar a few months ago (in my native, non-english language), was published and got similar responses as you. It seems people defend their daily news habit as if it was sacred. ;)</p>

<p>posted by Mark
 on April 17, 2007 <a href="#c47" rel="bookmark">#</a></p>
</div>
<div id="c48">
<p>The unexamined life is not worth living.  Examination shows that conventional news isn’t worthwhile.  So throw it out.  I don’t understand what’s the big deal with this, I guess I throw out lots of things like “news” and it doesn’t seem particularly remarkable, it seems quite normal.  Is the point here to produce a diff list of what people who examine their lives do differently from what people who don’t examine their lives do?  (Although arguably even people who “don’t examine their lives” probably do examine their lives and are happy with them!)  In any case, that diff list would be a pretty cool list, I’d like to see that.</p>

<p>posted by <a rel="nofollow" href="http://www.connellybarnes.com/">Connelly Barnes</a>
 on May 10, 2007 <a href="#c48" rel="bookmark">#</a></p>
</div>
<div id="c49">
<p>Miscellaneous list of other things to reject: Mocking the right brain, doing pretty much anything our culture implores such as worshiping individuals, working, acting rationally, pretending to support something and then acting contrarily (for example, people pretend to support community and then buy books, movies, software, etc), pretending that the public is idiotic while contributing nothing other than deploring the public’s idiocy and endlessly discussing events which one considers idiotic, leaving no exit from “idiocy,” acting as a type, dishonesty, quoting or repeating things ad verbatim rather than thinking for oneself, discouraging others from thinking or creating of themselves by being excessively critical and holding all works to the same “standard,” discouraging others from experimenting even in ways that appear to be stupid.  These are all just based on what Noam Chomsky called the minimal plausible rule of ethics, the “rule of the Gospels:” do unto others as you would have others do unto you.  Of course one could go further if one was inclined.  And I’m not saying that any of these are necessary, they’re just things that I tend to do because I feel uncomfortable when I’m excessively hypocritical.</p>

<p>posted by <a rel="nofollow" href="http://www.connellybarnes.com/">Connelly Barnes</a>
 on May 11, 2007 <a href="#c49" rel="bookmark">#</a></p>
</div>
<div id="c62">
<p>I agree with everything you said. I hate when all my family can talk about at the dinner table is the shit they read in the newspaper today or heard on CNN. I just want to yell out, “Why do you give a shit? How does it effect you? How is it relevant to your life?”</p>

<p>Earlier this year during the dreadful, nonstop coverage of the rebellions in the middle east, my class was having a long, drawn out discussion on the topic. I couldn’t take it anymore so I raised my hand and said, “excuse me, but why do you guys care so much about this? how does it effect your lives in any way? If you didn’t hear about it on the radio or watch it on TV, you wouldn’t even know it was happening, and it would have the same effect on your life: absolutely none whatsoever.” Of course, I was attacked by everyone in the classroom and was basically labeled an uncaring, heartless ignoramus.</p>

<p>Such is the way of the world…</p>

<p>posted by gimmedatsammich
 on June 24, 2011 <a href="#c62" rel="bookmark">#</a></p>
</div>

<p>You can also <a href="mailto:weblog@aaronsw.com">send comments by email</a>.</p> 




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How many people have ever lived on Earth? (110 pts)]]></title>
            <link>https://www.prb.org/articles/how-many-people-have-ever-lived-on-earth/</link>
            <guid>36593206</guid>
            <pubDate>Tue, 04 Jul 2023 22:16:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.prb.org/articles/how-many-people-have-ever-lived-on-earth/">https://www.prb.org/articles/how-many-people-have-ever-lived-on-earth/</a>, See on <a href="https://news.ycombinator.com/item?id=36593206">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hide="">
					<p>In any case, life was short. Life expectancy at birth probably averaged only about 10 years for most of human history. Average life expectancy in Iron Age France (from 800 B.C.E. to about 100 C.E.) has been estimated at only 10 or 12 years. Under these conditions, the birth rate would have to be about 80 live births per 1,000 people just for the species to survive. To put that in perspective, a high birth rate today is about 35 to 45 live births per 1,000 population, and it is observed in only some sub-Saharan African countries.</p>
<p>These short life expectancies mean that the human population had a hard time increasing. One estimate of the population of the Roman Empire, spanning Spain to Asia Minor, in 14 C.E. is 45 million. Other historians, however, set the figure twice as high, suggesting how imprecise population estimates of early historical periods can be.</p>
<p>By 1650, the world’s population rose to about 500 million—not a large increase from the estimate of 300 million in 1 C.E. The average annual rate of growth was actually lower in this period than the rate suggested for 8000 B.C.E. to 1 C.E. One reason for the unusually slower growth was the Black Death. This dreaded plague was not limited to 14th-century Europe but may have begun in western Asia in about 542 C.E. and spread from there. Experts believe that half the Byzantine Empire was destroyed by plague in the sixth century, a total of 100 million deaths. Such large fluctuations in population size over long periods greatly compound the difficulty of estimating the number of people who have ever lived.</p>
<p>By 1800, however, the world population passed the 1 billion mark and has since continued to grow to its current 8 billion (our most recent estimate as of 2022). This growth is driven in large part by advances in public health, medicine, and nutrition that have lowered death rates, allowing more people to live far into their reproductive years.<strong>&nbsp;</strong></p>
<h2>Assumptions Help Us Estimate Human Population History</h2>
<p>Guesstimating the number of people ever born requires determining population sizes for different points in human prehistory and history and applying assumed birth rates to each period. We start at the very, very beginning—with just two people (a minimalist approach!). Although it is unlikely that humans descended from two people, this approach simplifies our estimation.</p>
<p>One complicating factor is the pattern of population growth. Did it rise to some level and then fluctuate wildly in response to famines and changes in climate? Or did it grow at a constant rate? We cannot know the answers to these questions, although paleontologists have produced a variety of theories. For the purposes of this exercise, we assumed a constant growth rate applied to each period up to modern times. Birth rates were set at 80 per 1,000 population annually through 1 C.E. and at 60 per 1,000 from 2 C.E. to 1750. Rates then declined to below the 20s by the modern period (see Table 1).</p>
<p>This semi-scientific approach yields an estimate of about 117 billion births since the dawn of modern humankind. Clearly, the period 190,000 B.C.E. to 1 C.E. is key to our estimate but, unfortunately, little is known about that era’s population size. If we were to challenge our conclusion at all, it might be that our method underestimates the number of births to some degree. The assumption of constant rather than highly fluctuating population growth in the earlier period may underestimate the average population size at the time.</p>
<h2>We Account for a Large Percentage of People Who Have Ever Lived</h2>
<p>Given a current global population of about 8 billion, the estimated 117 billion total births means that those alive in 2022 represent nearly 7% of the total number of people&nbsp; who have ever lived (see Table 2). Because we have existed on Earth for approximately 200,000 years, that’s actually a fairly large percentage.</p>

<h5>TABLE 2. Snapshot of Population History</h5>
<table>
<tbody>
<tr>
<td>Estimated number of people ever born</td>
<td>117,020,448,575</td>
</tr>
<tr>
<td>World population in mid-2022</td>
<td>7,963,000,000</td>
</tr>
<tr>
<td>Percentage of those ever born who are living in 2022</td>
<td>6.8</td>
</tr>
</tbody>
</table>
									</div><div data-hide="">
					<p>As new archaeological discoveries are made and analyzed using increasingly innovative methods, our understanding of human population history will likely expand further, allowing us to improve on this ever-intriguing proposition!</p>

<hr>
<h3>Featured Resources</h3>
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bottles – Easily run Windows software on Linux (297 pts)]]></title>
            <link>https://usebottles.com/</link>
            <guid>36592930</guid>
            <pubDate>Tue, 04 Jul 2023 21:47:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://usebottles.com/">https://usebottles.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36592930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a rel="me" href="https://mastodon.online/@usebottles">


</a><section><a rel="me" href="https://mastodon.online/@usebottles">
</a>
</section>
<div>
<div>
<h2>Gaming <u>ready</u></h2>
<p>Bottles' Gaming Environment comes preconfigured to support a large set of Windows video games on Linux.</p>
<p>Thanks to our <span>installers</span> you can have immediate access to the most famous game stores (e.g. Epic Games Store,
EA Launcher, Battle.net etc.) and then play your favorite games, just like on Windows.</p>
<p><a href="https://usebottles.com/gaming">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-gaming.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-gaming-dark.png">
</p></div>
<div>
<div>
<h2>Empowered by <u>environments</u></h2>
<p>Bottles introduces a new way to handle Windows prefixes using
environments, a combination of ready-to-use settings, libraries and
dependencies.</p>
<p>Choose between <span>Gaming</span> and
<span>Software</span> environment based on the type of
software you want to start.</p>
<p>More advanced users can choose the <span>Custom</span>
environment to configure the bottle on their own.</p>
<p><a href="https://docs.usebottles.com/getting-started/environments">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-environments.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-environments-dark.png">
</p></div>
<div>
<div>
<h2>Highly <u>tweakable</u></h2>
<p>Customize your Windows environment with ease.</p>
<p>Choose whether to use dxvk, vkd3d, gamemode, esync, fsync or other,
Bottles will handle it all for you.</p>
<p>Change runners on the fly or install new ones for all your tests.</p>
<p><a href="https://docs.usebottles.com/bottles/preferences">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-customizable.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-customizable-dark.png">
</p></div>
<div>
<div>
<h2>Integrated <u>dependency manager</u></h2>
<p>Windows software need dependencies to work properly.</p>
<p>Bottles comes with a powerful and easy-to-use dependency manager that
automates this task.</p>
<p>Just look for the package you need and then "install", Bottles will
take care of everything for you.</p>
<p><a href="https://docs.usebottles.com/bottles/dependencies">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-dependencies-manager.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-dependencies-manager-dark.png">
</p></div>
<div>
<div>
<h2>Install programs <u>in one click</u><span>New</span></h2>
<p>Installers (introduced in 2022.2.14) are an easy way to install games
and applications into your bottles.</p>
<p>Installers are instruction sets written by our community, which
automate the entire dependency setup and installation process. You
won't have to worry about anything anymore.</p>
<p><a href="https://docs.usebottles.com/bottles/installers">
More about</a>
<a href="https://usebottles.com/appstore">
Apps</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-installers.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-installers-dark.png">
</p></div>
<div>
<div>
<h2>Easy <u>to restore</u></h2>
<p>The Snapshots manager allows you to easily restore a previous state
of your bottle.</p>
<p>If enabled, Bottles will automatically create a new snapshot when you
install a new dependency.</p>
<p>If something goes wrong, go to the Snapshots section of your bottle
and restore the previous state.</p>
<p><a href="https://docs.usebottles.com/bottles/versioning">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-versioning.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-versioning-dark.png">
</p></div>
<div>
<h2>
<ion-icon name="shield-checkmark-outline"></ion-icon>
Safe. <u>Sandboxed.</u>
</h2>
<p>Your bottles are isolated from the system and will only hit your
personal files when you decide.</p>
<p>The full-sandbox is provided and pre-configured only using the
<a href="https://flathub.org/apps/details/com.usebottles.bottles">
Flatpak package</a> (highly recommended).</p>
<p>All other packages still have access to the partial sandbox which
isolates the bottle files and prevents them from accessing your
homedir.</p>
<p><a href="https://docs.usebottles.com/flatpak/expose-directories">
More about</a>
</p></div>
<div>
<h2>Sponsors</h2>

<p>Plus all the donations from the awesome users who support Bottles!</p>
<p><a href="https://usebottles.com/funding/">
Show more</a>
</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LXD is now under Canonical (210 pts)]]></title>
            <link>https://linuxcontainers.org/lxd/</link>
            <guid>36592343</guid>
            <pubDate>Tue, 04 Jul 2023 20:48:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxcontainers.org/lxd/">https://linuxcontainers.org/lxd/</a>, See on <a href="https://news.ycombinator.com/item?id=36592343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
            <h2 id="lxd-is-now-under-canonical">LXD is now under Canonical<a href="#lxd-is-now-under-canonical" title="Permanent link">¶</a></h2>
<p>The LXD project is no longer part of the LinuxContainers project but can now be found directly on Canonical's websites.</p>
<p>Website: <a href="https://ubuntu.com/lxd">https://ubuntu.com/lxd</a><br>
Github: <a href="https://github.com/canonical/lxd">https://github.com/canonical/lxd</a><br>
Forum: <a href="https://discourse.ubuntu.com/c/lxd/">https://discourse.ubuntu.com/c/lxd/</a><br>
Documentation: <a href="https://documentation.ubuntu.com/lxd/">https://documentation.ubuntu.com/lxd/</a></p>
<h2 id="project-announcement">Project announcement<a href="#project-announcement" title="Permanent link">¶</a></h2>
<p>Date: 4th of July 2023</p>
<p>Hello,</p>
<p>Canonical, the creator and main contributor of the LXD project has decided that after over 8 years as part of the Linux Containers community, the project would now be better served directly under Canonical’s own set of projects.</p>
<p>While the team behind Linux Containers regrets that decision and will be missing LXD as one of its projects, it does respect Canonical’s decision and is now in the process of moving the project over.</p>
<p>Concretely, the expected changes are:</p>
<ul>
<li><a href="https://github.com/lxc/lxd">https://github.com/lxc/lxd</a> will now become <a href="https://github.com/canonical/lxd">https://github.com/canonical/lxd</a></li>
<li><a href="https://linuxcontainers.org/lxd">https://linuxcontainers.org/lxd</a> will disappear and be replaced with a mention directing users to <a href="https://canonical.com/lxd">https://ubuntu.com/lxd</a></li>
<li>The LXD YouTube channel will be handed over to the Canonical team</li>
<li>The LXD section on the LinuxContainers community forum will slowly be sunset in favor of the Ubuntu Discourse forum run by Canonical</li>
<li>The LXD CI infrastructure will be moved under Canonical’s care</li>
<li>Image building for Linux Containers will no longer be relying on systems provided by Canonical, limiting image building to <code>x86_64</code> and <code>aarch64</code>.</li>
</ul>
<p>What will not be changing:</p>
<ul>
<li>The rest of the Linux Containers projects remain unaffected</li>
<li>The image server, currently used by both LXC and LXD will keep operating as normal, though with less architectures available as mentioned above</li>
</ul>
<p>Those changes will likely all happen pretty rapidly as everything is relatively tightly integrated together. As a result, you may notice a bit of bumpiness while Canonical sets up the replacement infrastructure.</p>
<p>Sincerely,</p>
<p>The Linux Containers team</p>
<p>&nbsp;&nbsp;  Christian Brauner<br>
&nbsp;&nbsp;  Serge Hallyn<br>
&nbsp;&nbsp;  Stéphane Graber</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“How is your thesis going?” Students’ perspectives on mental health and stress (117 pts)]]></title>
            <link>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103</link>
            <guid>36592033</guid>
            <pubDate>Tue, 04 Jul 2023 20:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103</a>, See on <a href="https://news.ycombinator.com/item?id=36592033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">

<header>





<ul id="almSignposts">
  <li id="loadingMetrics">
    <p>Loading metrics</p>
  </li>
</ul>







    <div>
  <p id="licenseShort">Open Access</p>
  <p id="peerReviewed">Peer-reviewed</p>

<p id="artType">Research Article</p>


</div>
    <div>



<div>
  

<ul data-js-tooltip="tooltip_container" id="author-list">



<li data-js-tooltip="tooltip_trigger">
       
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="1">
Anna Bareis,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="2">
Moritz Bross,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="3">
Zoé Bürger,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="4">
Álvaro Cortés Rodríguez,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="5">
Nina Effenberger,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="6">
Markus Kleinhansl,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="7">
Fabienne Kremer,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="8">
Cornelius Schröder</a>    
</li>

</ul>


</div>


<div id="floatTitleTop" data-js-floater="title_author" role="presentation">
    <div>
      <h2><!--?xml version="1.0" encoding="UTF-8"?-->“How is your thesis going?”–Ph.D. students’ perspectives on mental health and stress in academia</h2>

<ul id="floatAuthorList" data-js-floater="floated_authors">

  <li data-float-index="1">Julian Friedrich,&nbsp;

  </li>
  <li data-float-index="2">Anna Bareis,&nbsp;

  </li>
  <li data-float-index="3">Moritz Bross,&nbsp;

  </li>
  <li data-float-index="4">Zoé Bürger,&nbsp;

  </li>
  <li data-float-index="5">Álvaro Cortés Rodríguez,&nbsp;

  </li>
  <li data-float-index="6">Nina Effenberger,&nbsp;

  </li>
  <li data-float-index="7">Markus Kleinhansl,&nbsp;

  </li>
  <li data-float-index="8">Fabienne Kremer,&nbsp;

  </li>
  <li data-float-index="9">Cornelius Schröder

  </li>

</ul>



    </div>
    <div id="titleTopCloser">
      <p><img src="https://journals.plos.org/resource/img/logo-plos.png" alt="PLOS"></p><p>x</p>
    </div>
  </div>

      <ul>
        <li id="artPubDate">Published: July 3, 2023</li>
        <li id="artDoi">
<a href="https://doi.org/10.1371/journal.pone.0288103">https://doi.org/10.1371/journal.pone.0288103</a>
        </li>
        <li></li>
      </ul>

    </div>
  
</header>
  <div>






<div id="figure-carousel-section">
  <h2>Figures</h2>

  
</div>





        <div id="artText">
          



<div xmlns:plos="http://plos.org"><h2>Abstract</h2><div><p>Mental health issues among Ph.D. students are prevalent and on the rise, with multiple studies showing that Ph.D. students are more likely to experience symptoms of mental health-related issues than the general population. However, the data is still sparse. This study aims to investigate the mental health of 589 Ph.D. students at a public university in Germany using a mixed quantitative and qualitative approach. We administered a web-based self-report questionnaire to gather data on the mental health status, investigated mental illnesses such as depression and anxiety, and potential areas for improvement of the mental health and well-being of Ph.D. students. Our results revealed that one-third of the participants were above the cut-off for depression and that factors such as perceived stress and self-doubt were prominent predictors of the mental health status of Ph.D. students. Additionally, we found job insecurity and low job satisfaction to be predictors of stress and anxiety. Many participants in our study reported working more than full-time while being employed part-time. Importantly, deficient supervision was found to have a negative effect on Ph.D. students’ mental health. The study’s results are in line with those of earlier investigations of mental health in academia, which likewise reveal significant levels of depression and anxiety among Ph.D. students. Overall, the findings provide a greater knowledge of the underlying reasons and potential interventions required for advancing the mental health problems experienced by Ph.D. students. The results of this research can guide the development of effective strategies to support the mental health of Ph.D. students.</p>
</div></div>


<div xmlns:plos="http://plos.org"><p><strong>Citation: </strong>Friedrich J, Bareis A, Bross M, Bürger Z, Cortés Rodríguez Á, Effenberger N, et al.  (2023) “How is your thesis going?”–Ph.D. students’ perspectives on mental health and stress in academia. PLoS ONE 18(7):
           e0288103.
        
        https://doi.org/10.1371/journal.pone.0288103</p><p><strong>Editor: </strong>Khader Ahmad Almhdawi, Jordan University of Science and Technology Faculty of Applied Medical Science, JORDAN</p><p><strong>Received: </strong>March 23, 2023; <strong>Accepted: </strong>June 20, 2023; <strong>Published: </strong> July 3, 2023</p><p><strong>Copyright: </strong> © 2023 Friedrich et al. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Data Availability: </strong>The anonymized data set is available at <a href="https://doi.org/10.23668/psycharchives.12914">https://doi.org/10.23668/psycharchives.12914</a>. All code for the analysis can be found at <a href="https://github.com/coschroeder/mental_health_analysis">https://github.com/coschroeder/mental_health_analysis</a>.</p><p><strong>Funding: </strong>We acknowledge support by the Open Access Publishing Fund of University of Tübingen. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p><p><strong>Competing interests: </strong> The authors have declared that no competing interests exist.</p></div>





<div xmlns:plos="http://plos.org" id="section1"><h2>Introduction</h2><p>Work situations can be demanding and have a profound influence on employees’ mental health and well-being across different sectors and disciplines [<a href="#pone.0288103.ref001">1</a>]. Multiple studies show that the mental health status of people working in academia and especially that of Ph.D. students seems to be particularly detrimental when compared to the public [e.g., <a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref003">3</a>]. Disorders such as anxiety and depression are on the rise in the general population [<a href="#pone.0288103.ref004">4</a>,<a href="#pone.0288103.ref005">5</a>]. Multiple studies show that this is even more severe in academia [<a href="#pone.0288103.ref006">6</a>–<a href="#pone.0288103.ref010">10</a>] and in particular Ph.D. students are affected by mental health problems [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>]. Worldwide surveys grant support for Ph.D. students’ suboptimal and alarming mental health situations [<a href="#pone.0288103.ref013">13</a>,<a href="#pone.0288103.ref014">14</a>].</p>
<p>A comprehensive study with more than 2000 participants (90% Ph.D. students, 10% Master students) from over 200 institutions across different countries showed that graduate students were more than six times more likely to experience symptoms of depression and anxiety than the general public [<a href="#pone.0288103.ref002">2</a>]. Furthermore, a global-scale meta-analysis [<a href="#pone.0288103.ref003">3</a>] and several other studies concerned with the mental health of Ph.D. students in different countries, e.g., the United States [<a href="#pone.0288103.ref007">7</a>,<a href="#pone.0288103.ref009">9</a>], the United Kingdom [<a href="#pone.0288103.ref006">6</a>], France [<a href="#pone.0288103.ref015">15</a>], Poland [<a href="#pone.0288103.ref008">8</a>], Belgium [<a href="#pone.0288103.ref016">16</a>] or Germany [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>] voice concerns about the mental health situation of Ph.D. students. Recent research conducted in Belgium has consistently found a higher prevalence of mental health problems among Ph.D. students compared to different groups of other highly educated individuals [<a href="#pone.0288103.ref016">16</a>]. In the same study, 50% of the Ph.D. students reported that they suffer from some form of mental health problem, and every third is at risk of a common psychiatric disorder [<a href="#pone.0288103.ref016">16</a>]. A similar picture is forming in Germany. For example, the prevalence of at least moderate depression among doctoral researchers at the Max Planck Society, one of the biggest academic societies in Germany, was between 9.6% and 11.6% higher than in the age-related general population [<a href="#pone.0288103.ref011">11</a>].</p>

<div id="section1"><h3>Increasing numbers of anxiety and depression among Ph.D. students</h3>
<p>Recent studies describe not only a high prevalence but also a rising tendency of mental health issues among Ph.D. students. In a study from 2017, 12% of the respondents reported seeking help for depression or anxiety related to their Ph.D. [<a href="#pone.0288103.ref013">13</a>], while in 2019, the result was even more drastic, as 36% of the respondents reported that having searched for help for those same reasons [<a href="#pone.0288103.ref014">14</a>]. Several studies among doctoral researchers within the Max Planck Society show similar results. For instance, a survey in 2019 showed that the average of the Ph.D. students were at risk for an anxiety disorder and another sample from 2020 provided even more robust support for this claim [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>]. Furthermore, the mean depression score increased from 2019 to 2020 in both samples [<a href="#pone.0288103.ref011">11</a>].</p>
</div>

<div id="section2"><h3>Risk factors and resources</h3>
<p>Given these alarming statistics, several studies addressed risks and resources for increased mental health issues. Other studies have revealed that gender, perceived work-life balance, and mentorship quality are correlated with mental health issues [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref017">17</a>]. Specifically, female gender [<a href="#pone.0288103.ref017">17</a>] and transgender/gender-nonconforming Ph.D. students are, on average, more likely to suffer from mental health issues [<a href="#pone.0288103.ref002">2</a>]. In contrast, a positive and supportive mentoring relationship or a supervisor’s leadership style, and a good work-life balance are positively associated with better mental health [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref016">16</a>]. While some authors [<a href="#pone.0288103.ref018">18</a>] reported a negative correlation between the Ph.D. stage and mental health, with students at later stages disclosing greater levels of distress, others [<a href="#pone.0288103.ref016">16</a>] did not find significant differences in this regard. Moreover, another report identified that Ph.D. students’ satisfaction levels strongly correlate with their relationship with their supervisors, number of publications, hours worked, and received guidance from advisors [<a href="#pone.0288103.ref019">19</a>]. Furthermore, several studies showed a positive correlation between job satisfaction [<a href="#pone.0288103.ref020">20</a>,<a href="#pone.0288103.ref021">21</a>] as well as a negative correlation between job insecurity [<a href="#pone.0288103.ref022">22</a>] and mental health or perceived stress, also in Ph.D. students.</p>
</div>

<div id="section3"><h3>Aim and research questions</h3>
<p>Taken together, the alarming findings on the psychological status of Ph.D. students around the globe cannot be denied. However, data on the situation of Ph.D. students in Germany are scarce [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>,<a href="#pone.0288103.ref023">23</a>]; thus, comparisons of different universities within a country can hardly be made. However, addressing those differences is particularly relevant since the working conditions, concerning contract types, financial situations or supervision vary strongly among different countries, geographical regions and universities or institutions [<a href="#pone.0288103.ref024">24</a>]. Furthermore, little is known about the reasons for this precarious situation and where exactly the need for action lies [<a href="#pone.0288103.ref025">25</a>]. Therefore, the aim of this study was to conduct a survey among Ph.D. students at a university in the southwest of Germany to assess Ph.D. students’ mental health status. Additionally, the present study also reveals information on the extent of the need for additional support services and pinpoints the specific areas where these services ought to be emphasized. In order to help identify relevant indicators, this investigation provides empirically sound findings on the mental health situation of Ph.D. students in Germany.</p>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section2"><h2>Materials and methods</h2>
<div id="section1"><h3>Sample and procedure</h3>
<p>Overall, 589 participants (60.3% female, 0.8% of diverse gender, <em>M</em><sub>Age</sub> = 28.8, <em>SD</em><sub>Age</sub> = 3.48, range 17–48 years) out of a total of enrolled 2552 Ph.D. students (response rate: 23.1%; actual numbers of Ph.D. students at the University of Tübingen higher as some Ph.D. students are not enrolled) took part in an online survey from October to December 2021. Instructions, items, and scales were all presented in English. Participants could answer the open questions in German or English and were comprised of Ph.D. students across various stages of their Ph.D. at the University of Tübingen without further exclusion criteria. The online questionnaire was sent to Ph.D. students’ email addresses via mailing distribution lists in cooperation with the central institution for strategic researcher development (Graduate Academy) of the University of Tübingen and with Ph.D. representatives of different faculties. Ethics approval was obtained by the “Ethics Committee of the Faculty of Economics and Social Science of the University of Tübingen” and written informed consent was given by the participants.</p>
<p>The distribution of faculty affiliation of the participants was heterogeneous with shares of 61.8% Science, 12.4% Humanities, 11.7% Economics and Social Sciences. These numbers reflect the different sizes of faculties and are roughly aligned with the relative numbers of students (41.7% Science, 24.8% Medicine, 16.2% Humanities, 7.5% Economics and Social Sciences), with a clear underrepresentation of the Medical Faculty. Faculties with less than 20 participants or participants with multiple answers were grouped into one category for further analysis (Others 14.1%, see <a href="#pone.0288103.s001">S1 Table</a>). 67.9% of the participants were German and in total, 82.9% came from European countries. During data collection, the participants were at different stages of their Ph.D. ranging from 0 to over 130 months with a mean time of two and a half years (30.0 months) of Ph.D. progress.</p>
</div>

<div id="section2"><h3>Measures</h3>
<p>First, demographic data and background information on the current Ph.D. situation were collected. In a second part, to get a differentiated view, we included different measures to operationalize the mental health status of Ph.D. students. The quantitative questionnaire assessed 1) general health, generalized anxiety disorder, as well as internally reviewed self-generated questions, 2) life and job satisfaction, and quantitative job insecurity, and 3) stressors (institutional and systemic), causes of stress and potential solutions. This study also collected information regarding the degree of participants’ familiarity with the mental health resources available at the university, e.g., points of contacts for counseling, in order to evaluate whether Ph.D. students make use of these services. Moreover, participants were asked to name additional services that they may consider necessary.</p>

<div id="section1"><h4>General health and stressors.</h4><p>General health was assessed by two items of the Perceived Health Questionnaire (PHQ-2) [<a href="#pone.0288103.ref026">26</a>]. Participants were asked to indicate how frequently they had experienced depressed moods and anhedonia over the past four weeks on a scale from 1 (not at all) to 4 (nearly every day). Additionally, they were presented with seven items of the Generalized Anxiety Disorder scale (GAD-7) [<a href="#pone.0288103.ref027">27</a>] capturing the severity of various anxiety signs like nervousness, restlessness, and easy irritation on a scale from 1 (not at all) to 4 (nearly every day). Both scales were used in this combination in a previous study in German higher education [<a href="#pone.0288103.ref028">28</a>]. Furthermore, we included two binary questions on whether the participants are currently in psychotherapy and if they have ever been diagnosed with a mental disorder.</p>
<p>The condensed version of the Perceived Stress Scale (PSS) [<a href="#pone.0288103.ref029">29</a>] was used to get the degree of stressful situations in life in the last twelve months or since the start of the Ph.D. [<a href="#pone.0288103.ref030">30</a>]. The response scale ranged from 0 (never) to 4 (very often), the following being a sample item: “… how often have you felt that you were unable to control the important things in your life?” To check the internal consistency of the four items, we calculated Cronbach’s alpha which was .79.</p>
</div>

<div id="section2"><h4>Job satisfaction and life satisfaction.</h4><p>Three items on a scale from 1 (strongly disagree) to 5 (strongly agree) were used to measure job satisfaction [<a href="#pone.0288103.ref031">31</a>], where a higher mean score indicated higher job satisfaction. A sample item is: “I am satisfied with my job.” Cronbach’s alpha was .86. Additionally, we added one item concerning general life satisfaction [adapted from <a href="#pone.0288103.ref032">32</a>] with the same response categories to get a more holistic insight.</p>
</div>

<div id="section3"><h4>Job insecurity.</h4><p>To assess the fear of losing the job itself, quantitative job insecurity was measured with three items (e.g., “I am worried about having to leave my job before I would like to.”) [<a href="#pone.0288103.ref033">33</a>] on a scale from 1 (strongly disagree) to 5 (strongly agree). We calculated a mean score with higher scores indicating higher job insecurity. Cronbach’s alpha was .80.</p>
</div>

<div id="section4"><h4>Institutional and systemic stressors.</h4><p>For institutional stressors, we focused mainly on the role of supervision and included eight questions, four were framed using positive wording and four with negative wording, each with a scale from 1 (not at all) to 5 (all of the time). We summarized these questions in two constructs (positive support/negative support) which had Cronbach’s alphas of .85 and .76, respectively. As for systemic stressors, we included two questions on long-term contracts and on future perspectives, again using a scale from 1 (strongly disagree) to 5 (strongly agree).</p>
</div>

<div id="section5"><h4>COVID-19.</h4><p>To cover the potential impacts of the COVID-19 pandemic and the implemented regulations, we included two questions to evaluate whether the pandemic affected the students’ general situation. On the one hand, participants were asked to pick the statement that best describes the effects of the pandemic in general (“yes, it improved my general situation”, “yes, it worsened my general situation”, “yes, but it neither worsened nor improved my general situation”, “no”), and on the other hand, they were asked to evaluate whether the particular answers provided in this survey had been affected by the pandemic from 1 (very likely) to 5 (very unlikely).</p>
</div>
</div>

<div id="section3"><h3>Rating procedure and open answers</h3>

<div id="section1"><h4>Causes of stress and potential solutions.</h4><p>We included three open-ended questions in the questionnaire to get a deeper understanding of the perceived causes of stress, potential ways to improve mental health, and ways to improve the overall situation of Ph.D. students. The questions were: (1) “What is/are the cause(s) of your stress?” (2) “What would need to change to improve your mental health status?” (3) “What could be done to improve your situation?” Participants could mention as many points as they wanted (without any word limit). To analyze these questions, we built categories by following the model of inductive category development [<a href="#pone.0288103.ref034">34</a>]. Two raters screened the first and last 20 responses in the data set and created categories for reoccurring topics (for a list containing all categories see <a href="#pone.0288103.s005">S5</a>–<a href="#pone.0288103.s007">S7</a> Tables). In the next steps, two new raters rated all open answers with the developed categories and added additional categories if needed. Applicable categories were rated with 1 (“category was mentioned”) or 0 (“category was not mentioned”). For example, the following response to question (1) “[My] supervisor is on maternity leave with open end, i.e. I have no one to talk to about my topic and have almost nothing so far […] I feel like I’m not good enough at this, not sure I will be able to succeed–everyone else has other projects and publications except me–no topic-related network” was rated with 1 in the following four categories: supervision (quality &amp; quantity), social integration &amp; interactions (private &amp; professional), self-perception (internal factors), and perceived lack of relevant competences &amp; experience–(sense) of progress and success. The full list of categories and inter-rater reliability as measured by Krippendorf’s Alpha is reported in <a href="#pone-0288103-t003">Table 3</a> [<a href="#pone.0288103.ref035">35</a>].</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section3"><h2>Results</h2>
<div id="section1"><h3>Descriptive statistics of work environment and workload</h3>
<p>The largest part of the participants (65.5%) was temporarily employed, 12.1% got a scholarship, 7.6% were permanently employed, and 6.5% were not employed at all. The mean for total contract length was 34.3 months, with a range between two and 72 months. About 10.5% of the participants had a contract for only 12 months or shorter. A similar large variation was found in the percentage of employment with a mean of 63%, ranging from 10% to 100% of employment. For workload, we found a mean of 36.0 hours of Ph.D.-related work per week with a standard deviation of 15.6 hours. After taking a closer look at high workloads, we found that 31.3% of the participants work 45 hours or more (21.5% work 50 hours and more) per week. On top of their Ph.D. work, many Ph.D. students work in other jobs, which combined with the hours spent for Ph.D.-related work, summed up to the mean of 44.1 overall working hours per week. A detailed description can be found in <a href="#pone.0288103.s001">S1 Table</a>.</p>
</div>

<div id="section2"><h3>Faculty-wise comparison</h3>
<p>In an explorative manner, we compared the mean differences of the most important variables between different faculties. Most of the analyzed variables did not show significant differences. Still, we want to stress that the highly imbalanced sample sizes (see <a href="#pone.0288103.s003">S3 Table</a>) could lead to false negative outcomes due to the small numbers of participants in some groups. However, we found that the mean job insecurity was significantly different between faculties (<em>p</em> &lt; .001, Kruskal-Wallis rank sum test) with comparable low job insecurity in the faculties of law (<em>M</em> = 2.10, <em>SD</em> = 1.22) and theology (<em>M</em> = 2.38, <em>SD</em> = 1.19) and high insecurity in the faculty of humanities (<em>M</em> = 3.32, <em>SD</em> = 0.91).</p>
</div>

<div id="section3"><h3>COVID-19</h3>
<p>In total, 41.9% of the participants stated that their general situation worsened due to the pandemic, while 28.5% stated that the pandemic affected but it neither worsened nor improved their general situation. 33.5% of the participants stated that their responses in this study were “very likely” or “likely” to be affected by the pandemic, with a mean of 2.97 (<em>SD</em> = 1.26).</p>
</div>

<div id="section4"><h3>General health and stressors</h3>
<p>The mean of the sum score for PHQ-2 in our study was 2.32 which is below the cut-off of three for major depression [<a href="#pone.0288103.ref026">26</a>]. Yet, 33.1% of the participants were above the cut-off. For the GAD-7, the sum score for the study’s sample was 8.49. Cut points of 5 might be interpreted as mild, cut points of 10 as moderate and 15 as severe levels of anxiety [<a href="#pone.0288103.ref027">27</a>], which implies a mild risk level for generalized anxiety with the suggestion of a follow-up examination in this sample. When asking for mental disorders, we found that 19.9% of the participants (<em>n</em> = 99) have already been diagnosed with a mental disorder and 15.5% (<em>n</em> = 77) are currently in psychotherapy. The sum score for the Perceived Stress Scale (PSS) of 7.79 (with <em>Min</em> = 0, <em>Max</em> = 15) was above the total sum score compared to a representative British sample (6.11) [<a href="#pone.0288103.ref036">36</a>] and a representative German community sample (4.79 for PSS-4) [<a href="#pone.0288103.ref037">37</a>]. Job satisfaction of our participants with a total sum score of 10.06 was lower compared to a sum score of 12.79 in a German sample of workers in small- and medium sized enterprises [<a href="#pone.0288103.ref038">38</a>]. The mean score for job satisfaction was 3.35, also lower than in a sample of Ph.D. students in Belgium (3.9) [<a href="#pone.0288103.ref039">39</a>]. Job insecurity was with a total sum score of 8.76 higher compared to the German small- and medium sized enterprises sample (5.67) [<a href="#pone.0288103.ref038">38</a>]. Consistently, more than 80% of the Ph.D. students in our study were worried about the lack of permanent or long-term contracts in academia (<em>M</em> = 4.25, <em>SD</em> = 1.09; 5 indicating a strong agreement). Nevertheless, around half of the participants (54.5%) believed that having a Ph.D. would help them find a good job (<em>M</em> = 3.49, <em>SD</em> = 0.97). We found a mean score of 3.48 (<em>SD</em> = 0.98) for the positive support questions which is above average over response levels. Around 57.1% of the Ph.D. students felt supported by their supervisor “most” or “all of the time”. Around 55.7% felt comfortable when contacting the supervisor for support. The negative support construct was with a mean score of 2.18 below average: 46.7% of the participants had never felt looked down, and 62.6% had never felt mistreated by their supervisor. Nevertheless, 28.6% of the Ph.D. students answered feelings of degradation and 19.1% felt mistreated more than “some of the time”. When it comes to the frequency of the meetings with the supervisor, the mean reported a value of 2.4 laying somewhere between having meetings once a month (2) and at least every three months (3). However, 18.2% reported meeting their supervisor only once every six months or less. For sample items and detailed values see <a href="#pone.0288103.s002">S2 Table</a>.</p>
<p>When we analyzed the relationship between the studied outcomes, we found that all major constructs correlated significantly (see <a href="#pone-0288103-t001">Table 1</a>). High correlations occurred between the items of the related PHQ-2 and GAD-7 as well as their connections to the PSS. Understandably, the two institutional support dimensions were highly correlated (<em>r</em> = -.69).</p>
</div>

<div id="section5"><h3>Regression for perceived stress, depression, and anxiety</h3>
<p>To predict potential driving factors for the two more direct mental health measurements, namely depression and anxiety, and for perceived stress, we employed linear regression models with these three constructs as response variables controlling for age and gender. We included relevant risk factors and stressors such as job insecurity, perceived stress, negative support and resources such as job and life satisfaction, and positive support to get a comprehensible overview over predictors. All analyses were carried out in R statistics version 4.1.3.</p>
<p>For depression, significant predictors were job satisfaction (β = -0.1, <em>SE</em> = 0.04, <em>p</em> &lt; .05), life satisfaction (β = -0.3, <em>SE</em> = 0.04, <em>p</em> &lt; .001), perceived stress (β = 0.4, <em>SE</em> = 0.05, <em>p</em> &lt; .001) and negative institutional support (β = 0.11, <em>SE</em> = 0.05, <em>p</em> &lt; .05, see <a href="#pone-0288103-t002">Table 2</a>). The model explained 46.7% of the variance, <em>F</em>(8, 482) = 54.5, <em>p</em> &lt; .01.</p>
<p>For anxiety, all studied variables except job satisfaction and positive support were significant predictors with a variance explanation of 36.0%, <em>F</em>(8, 392) = 29.5, <em>p</em> &lt; .01 (see <a href="#pone-0288103-t002">Table 2</a>). Noticeable was the strong influence of perceived stress on anxiety. Specifically, we observed that with an increase of one unit in perceived stress, the level of GAD-7 increased by 2.02 units and was in line with the high correlation (<em>r</em> = .52, <em>p</em> &lt; .01, <a href="#pone-0288103-t002">Table 2</a>).</p>
<p>For perceived stress, we found that job insecurity (β = 0.15, <em>SE</em> = 0.02, <em>p</em> &lt; .01), life satisfaction (β = -0.32, <em>SE</em> = 0.03, <em>p</em> &lt; .01) as well as negative institutional support (β = 0.13, <em>SE</em> = 0.04, <em>p</em> &lt; .01) were significant predictors with a model variance explanation of 42.7%, <em>F</em>(4, 486) = 53.5, <em>p</em> &lt; .01. The detailed results for this regression analysis can be found in <a href="#pone.0288103.s004">S4 Table</a>.</p>
</div>

<div id="section6"><h3>Qualitative answers</h3>
<p>In the following, we report the main categories with short sample quotes as well as the mean frequency of the two raters (see <a href="#pone-0288103-t003">Table 3</a>; details in <a href="#pone.0288103.s005">S5</a>–<a href="#pone.0288103.s007">S7</a> Tables). The inter-rater reliability as indicated by Krippendorff’s alpha for the top five categories of all questions was above α ≥ .67, except for the category <em>Manageable Workload</em> for question MH06_1 (see <a href="#pone-0288103-t003">Table 3</a>) with α = .62; CI [0.50; 0.74]. A threshold of .67 is commonly considered as the lower conceivable limit that still allows tentative conclusions [<a href="#pone.0288103.ref040">40</a>].</p>

<div id="section1"><h4>Causes of stress.</h4><p>The question “What is/are the cause(s) of your stress?” was answered by <em>n</em> = 446 participants. To cover the breadth of the responses, we built 18 categories. The most frequently mentioned categories were <em>Workload &amp; Time Pressure</em> (mean rating frequency = 211), <em>Self-Perception</em> (<em>M</em> = 132.5), <em>Job-Insecurity</em> (<em>M</em> = 93), <em>Social Integration &amp; Interactions</em> (<em>M</em> = 91), and <em>Supervision Quality &amp; Quantity</em> (<em>M</em> = 88.5). The category <em>Workload &amp; Time Pressure</em> includes all responses referring to the amount of work and/or deadlines. The category <em>Self-Perception</em> includes responses that indicate a perceived lack of competences or other personal doubts, concerns, and worries (e.g., “Since I started my Ph.D. I have almost constantly felt stupid”, “feeling like not belonging in academia, lack of self-confidence, feeling of making too little progress”). The category <em>Job Insecurity</em> reflects responses regarding contract length and general uncertainty about future employment (e.g., “scholarship is to be ended”, “Not knowing how things will work out after the PhD”, “Hopelessness of scientific career because there are too few full-time positions”). The category <em>Social Integration &amp; Interactions</em> covers responses regarding the integration and sense of belonging in the work environment (e.g., “not valued by colleagues”, “being socially isolated at work”) as well as social issues in the private life (e.g., “Mostly my personal life, or often the lack thereof”, “problems with parents”). The category <em>Supervision Quality &amp; Quantity</em> was used to capture all supervision-related responses including comments about the lack of support, feedback, frequency of meetings, or supervisors’ interest in the topics (e.g., “no clear communication with supervisor”, “lack of support from supervisor, even gossiping about me behind my back”).</p>
</div>

<div id="section2"><h4>Potential ways to improve the mental health status.</h4><p>When asked “What would need to change to improve your mental health status?”, the Ph.D. students’ responses (<em>n</em> = 307) included various topics, some addressing compensation and income-related aspects, others highlighting supportive supervision. Overall, the responses lead to twelve different categories. Most answers referred to <em>Supportive Supervision</em> (<em>M</em> = 98.5), followed by <em>Job Security/Contract</em> (<em>M</em> = 59). Sample quotes with respect to supervision are e.g., “more feedback from supervisor or even more interest in my topic” or “more regular support by supervisor”. The category <em>Job Security/Contract</em> contains comments with respect to contract length and aspects for future employment (e.g., “no more worries about not being able to get my contract renewed”). The category <em>Manageable Workload</em> (<em>M</em> = 56.5) includes all responses around work-life balance (e.g., “having also activities beside work”, “clear work hours”). The fourth category was <em>Compensation &amp; Financial Security</em> (<em>M</em> = 35) and included all income- and compensation-related aspects of the job (e.g., “Be paid 100% would be a start”, “Get paid for all the time at work”). The category <em>Less Additional Tasks</em> (<em>M</em> = 27.5) was used to specifically cover responses mentioning the number of additional tasks within the job (“Less work in teaching/work unrelated to PhD”).</p>
</div>

<div id="section3"><h4>Ways to improve the personal situation.</h4><p>In addition to the previous question, which focused on general ways to improve the mental health status, we asked the Ph.D. students the following question: “What could be done to improve your situation?” Based on the themes and topics mentioned in the responses (<em>n</em> = 281) we built eleven categories. The categories mentioned the most were <em>Job-Security &amp; Compensation</em> (<em>M</em> = 85.5), followed by <em>Supportive Supervision</em> (<em>M</em> = 68), <em>Services and Support System</em> (<em>M</em> = 39.5), <em>Decrease Pressure to Perform</em> (<em>M</em> = 39.5), and <em>Manageable Workload</em> (<em>M</em> = 36). The category <em>Job-Security &amp; Compensation</em> includes responses like “chances of getting a long-term job in academia, not just the three-year programs” or “Fair payment (half of students get 50% others 65% even at the same institute)”. For the category <em>Supportive Supervision</em> “Regular meetings with people who are supportive &amp; have an expertise in my research topic” can serve as a sample quote. The category <em>Services and Support System</em> was built to cover the responses named a solution outside the working group and team, such as “it would be helpful to see a university-based psychologist outside of the regular working hours” or “more courses (or better communications about them) about stress management”. The next category was labeled <em>Decrease Pressure to Perform</em> and included all responses that highlighted a high level of perceived pressure, such as “the performance pressure (every talk at a seminar is a job talk) is a big problem” or “Instead of pressuring academics to publish as much as possible, there should be more focus on the quality instead of the quantity of their articles/publication”. The last category, <em>Manageable Workload</em>, contained answers with respect to the amount of work (e.g., “Normal working hours, having really free-time without having the feeling that I should be working, it should be normal to take all vacation days”).</p>
</div>

<div id="section4"><h4>Summary of the qualitative answers.</h4><p>With respect to the open answers, it can be summarized that the factors named as causes for stress and the possible solutions cover a wide range of topics. However, there are reoccurring topics across all three questions, such as supervision, workload, and job security. The role of supervision is a reemerging motif in the qualitative content analysis. While the quality and quantity of supervision were seen as a cause of stress, supportive supervision has a positive impact on the mental health status as well as the whole situation of the Ph.D. students. Furthermore, job insecurity was mentioned as an important stressor, while stable contracts and appropriate compensation for the work and fewer extra tasks were also added for improvement. Workload and time pressure were the most often stated causes of stress, followed by self-doubts and worries about not having enough competencies for the job. A manageable workload, fewer additional tasks, and a lower pressure to perform were indicated by the participants as valuable improvements.</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section4"><h2>Discussion</h2>
<div id="section1"><h3>Summary of the main findings</h3>
<p>The conducted survey investigates the mental health of Ph.D. students at a university in the southwest of Germany and gives insights into what causes stress and mental health disorders and where there is a need for further support services. Our qualitative and quantitative analyses revealed interesting and consistent results on the alarming situation of the mental health of Ph.D. students.</p>
<p>First, our quantitative results revealed that one-third of the participants were above the cut-off for depression which is an indicator of a high risk of depression that should be checked by a health professional. On average, the surveyed Ph.D. students were at a mild risk level for an anxiety disorder. While our study design does not allow us to diagnose mental illnesses, it identifies problems that need to be pursued further. It reveals some unhealthy working conditions and increased risks for mental illnesses. Our qualitative and quantitative results showed consistently that many of the most prominent issues for our study’s participants are personal factors such as perceived stress, life satisfaction and self-doubt, but modulated by structural deficits such as financial and job security as well as workload and time pressure. The quantitative analyses revealed that life satisfaction, perceived stress and negative support are the main predictors for anxiety disorders as well as depression. Additionally, low job satisfaction was a significant predictor of depression and job insecurity for anxiety. Furthermore, we identified job insecurity, life satisfaction as well as negative institutional support as predictors for perceived stress.</p>
<p>Second and besides mental health problems, our quantitative analyses showed how supervision and the work environment played a role in the mental health and general well-being of Ph.D. students. Deficient supervision could affect Ph.D. students’ perceived job insecurity and job dissatisfaction. Although good supervision was not a predictor for satisfaction, being comfortable with contacting the supervisor could lower the perceived stress. This shows the importance of the supervisor-student relationship and highlights the importance of the social work environment, which was also mentioned by study participants in the open-end questions. While the categories in the qualitative analyses mainly served to find recurring themes, they can also be used to distinguish between different levels. Some participants reflected causes of stress on a personal level (e.g., self-perception). In contrast, others set the focus on the supervisor level or working group level, or even on the more structural abstract level of the academic system.</p>
<p>Third, our study does not only investigate the mental health situation of Ph.D. students, but we also analyze how the situation and mental health status could be improved. Many suggestions were straightforward given the results of the causes of stress, i.e., bad supervision should be improved, and a secure income should be guaranteed. However, we were also able to show that Ph.D. students wish to make use of services and support systems that could be provided by the university. Furthermore, less pressure to perform and a manageable workload with fewer additional tasks besides the Ph.D. project might decrease the stress level and improve mental health status.</p>
<p>Overall, detrimental mental health is a known problem in academia, and we show another example of its extent as well as opportunities for improvement at a German university.</p>
</div>

<div id="section2"><h3>Comparison to other studies</h3>
<p>Data on Ph.D. students’ situation in Germany are scarce, and we, therefore, perform a broader comparison with Ph.D. students around the world. However, the results of this comparison should be taken with caution as our questionnaire and time of survey conduction are unique. We focus mainly on PHQ-2 [<a href="#pone.0288103.ref026">26</a>] and GAD-7 [<a href="#pone.0288103.ref027">27</a>], for which other studies in Germany during the pandemic showed that–compared to pre-COVID-19 reference values–these measurements were significantly increased [<a href="#pone.0288103.ref041">41</a>]. Two studies conducted during the COVID-19 pandemic include the same scales [<a href="#pone.0288103.ref041">41</a>,<a href="#pone.0288103.ref042">42</a>] and reveal similar results for the general population in Germany, while in our later study from October to December 2021, the risk for anxiety and depression is slightly higher. In our study, one-third of the participants (33.1%) was above the cut-off for major depression, compared to the studies in a 1.5-year earlier timeframe, where 14.1% (March to May 2020; <em>n</em> = 15704, 70.7% female gender; 42.6% university education) [<a href="#pone.0288103.ref042">42</a>] and 21.4% (March to July 2020; <em>n</em> = 16918; 69.7% female gender; 42.4% university education [<a href="#pone.0288103.ref041">41</a>] of the participants with diverse occupations were above the cut-off. Furthermore, in our study, 39.2% of the participants were at the mild risk level for anxiety compared to 27.4% of the participants in an earlier study [<a href="#pone.0288103.ref041">41</a>]. This shows the increase in depression and anxiety during the pandemic and even higher numbers in our study compared with the German general population. Nevertheless, compared to a survey at public research universities in the United States from May to July 2020, the number of doctoral students screened for major depressive disorder symptoms with the same measurements PHQ-2 was higher with 36% [<a href="#pone.0288103.ref043">43</a>], indicating high numbers of mental issues in academia in several countries.</p>
<p>While using the same scales and items for job satisfaction and job insecurity, our study showed worse sum scores compared to a sample of employers and employees in small- and medium sized enterprises in Germany (December 2020 to May 2021; <em>n</em> = 828; 53.7% female gender, <em>M</em> = 41.5 years; 38.8% higher education entrance qualification) [<a href="#pone.0288103.ref038">38</a>]. It seems that Ph.D. students have higher job insecurity and job dissatisfaction compared to workers in diverse branches and occupations. This may result from different contract types, as workers, especially in industrial sectors, have long-term contracts. The recurrent factor of time pressure and workload, also mentioned in the open-end questions, is backed up by the raw numbers of the contract types and working hours, which may also lead to job dissatisfaction. Although the mean contract type in our study is 63%, the mean number of hours dedicated to Ph.D. work (<em>M</em> = 36.0, <em>SD</em> = 15.6 hours) is almost in the range of a full-time position. What is more, the participants reported a total weekly workload (<em>M</em> = 44.1, <em>SD</em> = 11.4 hours) that exceeds a typical full-time position in Germany [<a href="#pone.0288103.ref044">44</a>]. The discrepancy between Ph.D. work and corresponding contract types results in a mean of 12.1 hours of overwork per week (based on a 38.5-hour full-time contract, which is the standard contract for Ph.D. students in Germany). This is in line with previous studies where the authors found a mean of 12.6 hours of overwork per week for Ph.D. students in Science, Technology, Engineering, and Mathematics disciplines in Germany [<a href="#pone.0288103.ref045">45</a>]. However, the authors did not include any further work obligations and corrected for contract types with low percentages, and thus the results are difficult to compare directly. Furthermore, we used gender as a control variable, which turned out to be statistically significant for anxiety and stress. This is in line with related work where the female gender was reported to be higher correlated with mental disorders [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref017">17</a>,<a href="#pone.0288103.ref046">46</a>,<a href="#pone.0288103.ref047">47</a>].</p>
</div>

<div id="section3"><h3>Strengths and limitations</h3>

<div id="section1"><h4>Generalization.</h4><p>While we aimed for our study to reflect the current situation for Ph.D. students as best as possible, there are points that are limiting the generalization of the results or are beyond the scope of this survey. First, we collected the data between October and December 2021, a time at which the ordinance on protection against risks of infection with the SARS-CoV-2 virus (“Coronavirus-Schutzverordnung”) [<a href="#pone.0288103.ref048">48</a>] was still in place in Germany and influenced private and working life. About one-third (33.5%) of our study population stated that it is very likely or likely that the pandemic affected their answers. Nonetheless, a pandemic is a situation that can reoccur and is only one more reason to proactively set up a resilient Ph.D. graduation system. Another research group [<a href="#pone.0288103.ref049">49</a>] investigated how mental health care should change as a consequence of the COVID-19 pandemic and concluded that the pandemic could even be seen as a chance to improve mental health services [<a href="#pone.0288103.ref049">49</a>]. Nevertheless, we would like to point out that generalizing from a mental health study conducted during a pandemic may be difficult.</p>
<p>Overall, around 23% of all Ph.D. students at the University of Tübingen [<a href="#pone.0288103.ref050">50</a>] participated in our study, which is slightly below the response rate in other similar studies [e.g., <a href="#pone.0288103.ref016">16</a>]. Considering that university students are very frequently invited to various questionnaires and studies, and given that our survey lasted approximately 20 minutes, it can be argued that the participants were motivated to invest time into their responses. However, our study population remains small compared to the total number of Ph.D. students in Germany. Moreover, we want to emphasize the likely sample bias in our data. We recruited participants mainly via mailing lists and our project therefore probably has especially appealed to people who are already interested in health or aware of mental health issues. However, given our relatively large coverage of almost a quarter of all Ph.D. students at the University of Tübingen, even a selective sample can give us insights into overall tendencies. The transferability of our results to other German universities or even universities in other countries is also not guaranteed as the academic systems can largely differ. Additionally, the results of this study are influenced by the overall living conditions the Ph.D. students experience. As Tübingen is a small town in the southwest of Germany, a comparison to larger cities or other countries might not be viable as the conditions probably differ largely.</p>
<p>Finally, even within one university, the generalization of our results is further limited by the uneven distribution of the participants across faculties. Most participants (61.8%) were from the Science Faculty, which is also the largest department (in terms of the highest total number of students) at the University of Tübingen. This skewness limits the faculty-wise comparisons, and we would expect to find interesting insights into the different graduate programs by conducting detailed comparisons. These differences could not only arise from different academic traditions but also from the highly varying expectations on the scope of a Ph.D. thesis. It follows that more detailed and systematic monitoring and data collection in national and international surveys are needed.</p>
</div>

<div id="section2"><h4>Methodology.</h4><p>In a cross-sectional study, we investigate the current situation of Ph.D. students. While this is a valid and important instrument to access the current state, it cannot give us information about the dynamic changes in the transition phase between undergraduate studies and the Ph.D. as well as across the Ph.D. [<a href="#pone.0288103.ref051">51</a>]. To track these changes or make comparisons over time, a longitudinal study design or propensity score matching procedures [<a href="#pone.0288103.ref052">52</a>] could give further insights. It is therefore desirable to establish regular surveys and monitoring systems either on a university level or in a national survey to provide information on the impact of undertaken actions and implemented changes. We used a mixed quantitative and qualitative research approach. While this provides information on distinct levels, there are some pitfalls. For example, the open answer categories were defined post-hoc. While this gives the possibility for the participants to express their thoughts freely, it makes a systematic analysis more difficult, and the analysis might be biased by the evaluators. Overall, it is important to summarize and statistically analyze our study results on an overall level, but it must not be forgotten that every person and Ph.D. project is individual.</p>
</div>
</div>

<div id="section4"><h3>Implications for research and practice</h3>

<div id="section1"><h4>Research.</h4><p>The overall scarce data, paired with worrisome flashlights on the mental health situation of Ph.D. students in different countries, highlights the need for more systematic monitoring of mental health in academia. For this purpose, standardized as well as domain-specific scales for Ph.D. students need to be established and longitudinal data needs to be collected. This would enable researchers to measure the effect of larger environmental changes (such as the COVID-19 pandemic or economic developments) and to measure the impact of interventions targeted to improve the situation. At the same time, we propose including qualitative measurements to assess unknown variables and the unique situation each Ph.D. student faces. These could also inform the development of additional quantitative measurable constructs to reflect the dynamic situation in academia. Such monitoring systems can either be implemented at the university level to give detailed insights into the situation at a specific university or on a national level to get an overall impression of Ph.D. students’ health issues. Optimally, a survey should be promoted from an independent self-governing institution dedicated to advancing science and research. While the demands for a better mental health situation for Ph.D. students are obvious, systematical and political changes need to be addressed in the research community and in academia.</p>
</div>

<div id="section2"><h4>Practice.</h4><p>Our mixed methods research approach allows us not only to find out more about the issues of Ph.D. students but also to draw conclusions about what is needed to improve their situation. However, finding solutions to a recognized problem is not a straightforward task, and complex problems often require a step-by-step solution. Therefore, we assume that more practical implications, which could be indicated by an established monitoring system, will be necessary once the first steps have been taken.</p>
<p>In general, we can group interventions into at least four levels that can influence each other: the Ph.D. students themselves, the supervisors, the universities or research institutions, and the greater political context and academic culture. Building on the responses about potential improvements and additional services, we identified the following practical implications:</p>
<p>On an individual level, the main interventions could happen in capacity building (e.g., in time/project management, self-reflection or mental health awareness) but also by being more proactive about changing working modes (e.g., establishing collaborations or a peer counseling system) or by improving the social environment. This could additionally lead to a change in self-perception, for which direct interventions might be more difficult. At this point, we want to highlight that changes on the individual level aim to prevent the development of mental health problems and strengthen the resilience of Ph.D. students. They can at no point replace professional support once such problems have been manifested.</p>
<p>The level of supervision seems to be the most urgent and promising target for an improvement of Ph.D. students’ situation. As supervisors are usually defining a project and its goals, but also additional teaching or other tasks, they are responsible for setting the workload and time constraints. Not only the hard constraints of the working conditions but also the quality of supervision was often mentioned to be highly deficient. Possible interventions could target improving the skills in personnel management of supervisors. But also, clear supervision requirements and guidelines could be imposed by the university. Such agreements (including expectations on the thesis, supervision times and conciliation mechanisms) might be an option to enhance the agreements in a supervisor-student relationship. While these suggestions are not new, and some of them are theoretically established in some university departments, our study results suggest that they are often ignored or not properly implemented, and more binding agreements and control mechanisms need to be made. Establishing additional external supervision, where for example the personnel management is reflected, might also give new perspectives and enhance demanding situations. At this point, it has to be considered that there are strong dependencies between Ph.D. students and their supervisors since, in many cases, it is the supervisors who have a major impact on the outcome of a Ph.D. thesis, such as the final grade. It remains challenging how Ph.D. students can criticize the supervising situation without negatively impacting the personal relationship with their supervisors.</p>
<p>Further interventions on the level of universities and research institutions might include support in bureaucratic processes and providing more information on different contact points (e.g., for mental health services). It is obvious that the aforementioned interventions (such as capacity building courses for Ph.D. students and supervisors) are dependent on the support of the central facilities of the research institution. Furthermore, highlighting the high prevalence of mental health problems, for example, at mandatory introductory sessions for Ph.D. students, might help to raise awareness about this topic. This could help unexperienced young researchers to notice signs of anxiety and depression early on before these mental disorders manifest. Finally, public events on this topic could reduce the stigma associated with it, making it easier for affected Ph.D. students to seek help. Such events might also be used to remind the students that it is important to take care not only of their physical but also mental health, for instance, by strengthening social relationships and pursuing hobbies which are not work-related.</p>
<p>Lastly, there are also changes in the political setting and academic culture needed. This includes a fair payment system, reasonable control of contract lengths and extensions, and more perspectives for long-term positions in academia. Considering that the vast majority of Ph.D. students will end up in positions outside of academia, it could be beneficial to better prepare students for careers in alternative job markets, such as industry. Such interventions might directly influence the job insecurity and job dissatisfaction of Ph.D. students. In Germany, the current regulations for temporary academic employment are being evaluated [<a href="#pone.0288103.ref053">53</a>], but even propositions from the conference of university rectors [<a href="#pone.0288103.ref054">54</a>] seem not to be sufficient for fundamental changes. These changes would also need a shift in the academic culture [<a href="#pone.0288103.ref055">55</a>], in which “publish or perish” is still a guiding theme leading to high pressure to perform. Working on a cultural shift is a task for all scientists. This will lead to a more sustainable work culture from which all stakeholders might benefit.</p>
<p>All in all, there is an interplay and dependence of all mentioned levels. Importantly, most problems mentioned in the survey can result from shortcomings on multiple levels, and therefore interventions on more than one level are needed for a satisfying solution. For example, changes to improve the mental health situation on an individual level can be dependent on the consent of the supervisor and can also be negatively impacted by already existing mental health issues. In addition to individual responsibility for health, it is important to systematically target prevention and change the system on the aforementioned levels so that Ph.D. students are better and more quickly supported when mental health problems arise.</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section5"><h2>Conclusion</h2><p>This study shows once again the detrimental mental health situation of Ph.D. students in academia. By analyzing the mental health of Ph.D. students at a German university, we found alarming hints of depressive and anxious tendencies that are in line with other comparable studies. Furthermore, we have identified main stressors, such as perceived stress or self-doubts, and resources, such as a positive student-supervisor relationship. Understanding conditional factors and being able to improve the situation depend on such identifications. With our study, we provide first insights of the status quo for the University chair, the Graduate Academy, and other stakeholders in the academic system. We invite them to inspect the results and suggestions responsibly so that actions to assess and improve the conditions for Ph.D. students’ mental health and well-being can be taken in the future. Based on our data, additional offers for Ph.D. students, as well as their supervisors, should be created and existing ones sustainably modified. Positive conditions and resources for mental health and well-being will not restrict to academia but will affect all areas of life. While an increased mental health state is an indispensable value on its own, additional benefits can be created for research, teaching, practice, and society. As such, mental health is a big part of sustainable living and should have a high priority for all people. While this is already acknowledged in the sustainable development goals, further steps need to be taken to raise awareness and provide support throughout society.</p>
</div>

<div xmlns:plos="http://plos.org" id="section6"><h2>Supporting information</h2></div>





<div xmlns:plos="http://plos.org"><h2>Acknowledgments</h2>
<p>We would like to express our gratitude to all participants of the survey as well to the <em>sustainAbility</em> Ph.D. initiative at the University of Tübingen. We thank Dr. Stephanie Rosenstiel for support with the ethics approval and Prof. Dr. Birgit Derntl and Prof. Dr. Andreas Fallgatter for their helpful feedback on the conception of the questionnaire. We thank Mumina Javed and Monja Neuser for their support in the early phase of the project.</p>
</div><div xmlns:plos="http://plos.org"><h2>References</h2><ol><li id="ref1"><span>1.
            </span><a name="pone.0288103.ref001" id="pone.0288103.ref001"></a>World Health Organization, editor. Mental health: facing the challenges, building solutions: report from the WHO European Ministerial Conference. Copenhagen, Denmark: World Health Organization, Regional Office for Europe; 2005. <ul></ul></li><li id="ref2"><span>2.
            </span><a name="pone.0288103.ref002" id="pone.0288103.ref002"></a>Evans TM, Bira L, Gastelum JB, Weiss LT, Vanderford NL. Evidence for a mental health crisis in graduate education. Nat Biotechnol. 2018;36(3): 282284.  pmid:29509732 <ul data-doi="10.1038/nbt.4089"><li><a href="https://doi.org/10.1038/nbt.4089" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/29509732" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Evidence+for+a+mental+health+crisis+in+graduate+education+Evans+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref3"><span>3.
            </span><a name="pone.0288103.ref003" id="pone.0288103.ref003"></a>Satinsky EN, Kimura T, Kiang MV, Abebe R, Cunningham S, Lee H, et al. Systematic review and meta-analysis of depression, anxiety, and suicidal ideation among Ph.D. students. Sci Rep. 2021;11(1): 14370.  pmid:34257319 <ul data-doi="10.1038/s41598-021-93687-7"><li><a href="https://doi.org/10.1038/s41598-021-93687-7" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34257319" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Systematic+review+and+meta-analysis+of+depression%2C+anxiety%2C+and+suicidal+ideation+among+Ph.D.+students+Satinsky+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref4"><span>4.
            </span><a name="pone.0288103.ref004" id="pone.0288103.ref004"></a>Baxter AJ, Scott KM, Vos T, Whiteford HA. Global prevalence of anxiety disorders: a systematic review and meta-regression. Psychol Med. 2013;43(5): 897–910.  pmid:22781489 <ul data-doi="10.1017/S003329171200147X"><li><a href="https://doi.org/10.1017/S003329171200147X" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/22781489" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Global+prevalence+of+anxiety+disorders%3A+a+systematic+review+and+meta-regression+Baxter+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref5"><span>5.
            </span><a name="pone.0288103.ref005" id="pone.0288103.ref005"></a>Ferrari AJ, Somerville AJ, Baxter AJ, Norman R, Patten SB, Vos T, et al. Global variation in the prevalence and incidence of major depressive disorder: a systematic review of the epidemiological literature. Psychol Med. 2013;43(3): 471–481.  pmid:22831756 <ul data-doi="10.1017/S0033291712001511"><li><a href="https://doi.org/10.1017/S0033291712001511" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/22831756" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Global+variation+in+the+prevalence+and+incidence+of+major+depressive+disorder%3A+a+systematic+review+of+the+epidemiological+literature+Ferrari+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref6"><span>6.
            </span><a name="pone.0288103.ref006" id="pone.0288103.ref006"></a>Byrom NC, Dinu L, Kirkman A, Hughes G. Predicting stress and mental wellbeing among doctoral researchers. Journal of Mental Health. 2020; 1–9.  pmid:32967498 <ul data-doi="10.1080/09638237.2020.1818196"><li><a href="https://doi.org/10.1080/09638237.2020.1818196" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32967498" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Predicting+stress+and+mental+wellbeing+among+doctoral+researchers+Byrom+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref7"><span>7.
            </span><a name="pone.0288103.ref007" id="pone.0288103.ref007"></a>El-Ghoroury NH, Galper DI, Sawaqdeh A, Bufka LF. Stress, coping, and barriers to wellness among psychology graduate students. Training and Education in Professional Psychology. 2012;6(2): 122–134. <ul><li><a href="#" data-author="El-Ghoroury" data-cit="El-GhorouryNH%2C%20GalperDI%2C%20SawaqdehA%2C%20BufkaLF.%20Stress%2C%20coping%2C%20and%20barriers%20to%20wellness%20among%20psychology%20graduate%20students.%20Training%20and%20Education%20in%20Professional%20Psychology.%202012%3B6%282%29%3A%20122%E2%80%93134." data-title="Stress%2C%20coping%2C%20and%20barriers%20to%20wellness%20among%20psychology%20graduate%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Stress%2C+coping%2C+and+barriers+to+wellness+among+psychology+graduate+students+El-Ghoroury+2012" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref8"><span>8.
            </span><a name="pone.0288103.ref008" id="pone.0288103.ref008"></a>Kowalczyk M, Karbownik MS, Kowalczyk E, Sienkiewicz M, Talarowska M. Mental Health of PhD Students at Polish Universities–Before the COVID-19 Outbreak. IJERPH. 2021;18(22): 12068.  pmid:34831821 <ul data-doi="10.3390/ijerph182212068"><li><a href="https://doi.org/10.3390/ijerph182212068" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34831821" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Mental+Health+of+PhD+Students+at+Polish+Universities%E2%80%93Before+the+COVID-19+Outbreak+Kowalczyk+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref9"><span>9.
            </span><a name="pone.0288103.ref009" id="pone.0288103.ref009"></a>Smith E, Brooks Z. Graduate Student Mental Health (University of Arizona). National Association of Graduate-Professional Students [Internet]. 2015. Available from: <a href="http://nagps.org/wordpress/wp-content/uploads/2015/06/NAGPS_Institute_mental_health_survey_report_2015.pdf">http://nagps.org/wordpress/wp-content/uploads/2015/06/NAGPS_Institute_mental_health_survey_report_2015.pdf</a>. <ul><li><a href="#" data-author="Smith" data-cit="SmithE%2C%20BrooksZ.%20Graduate%20Student%20Mental%20Health%20%28University%20of%20Arizona%29.%20National%20Association%20of%20Graduate-Professional%20Students%20%5BInternet%5D.%202015.%20Available%20from%3A%20http%3A%2F%2Fnagps.org%2Fwordpress%2Fwp-content%2Fuploads%2F2015%2F06%2FNAGPS_Institute_mental_health_survey_report_2015.pdf." data-title="Graduate%20Student%20Mental%20Health%20%28University%20of%20Arizona%29" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Graduate+Student+Mental+Health+%28University+of+Arizona%29+Smith+2015" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref10"><span>10.
            </span><a name="pone.0288103.ref010" id="pone.0288103.ref010"></a>Williams S. 2019 Postgraduate Research Experience Survey [Internet]. 2019. Available from: <a href="https://s3.eu-west-2.amazonaws.com/assets.creode.advancehe-document-manager/documents/advance-he/AdvanceHE-Postgraduate_Research_%20Survey_%202019_1574338111.pdf">https://s3.eu-west-2.amazonaws.com/assets.creode.advancehe-document-manager/documents/advance-he/AdvanceHE-Postgraduate_Research_%20Survey_%202019_1574338111.pdf</a>. <ul></ul></li><li id="ref11"><span>11.
            </span><a name="pone.0288103.ref011" id="pone.0288103.ref011"></a>Majev PG, Vieira RM, Carollo A, Liu H, Stutz D, Fahrenwaldt A, et al. PhDnet Report 2020. 2021. <ul><li><a href="#" data-author="Majev" data-cit="MajevPG%2C%20VieiraRM%2C%20CarolloA%2C%20LiuH%2C%20StutzD%2C%20FahrenwaldtA%2C%20et%20al.%20PhDnet%20Report%202020.%202021." data-title="PhDnet%20Report%202020" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=PhDnet+Report+2020+Majev+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref12"><span>12.
            </span><a name="pone.0288103.ref012" id="pone.0288103.ref012"></a>Olsthoorn LHM, Heckmann LA, Filippi A, Vieira RM, Varanasi RS, Lasser J, et al. PhDnet Report 2019. 2020. <ul><li><a href="#" data-author="Olsthoorn" data-cit="OlsthoornLHM%2C%20HeckmannLA%2C%20FilippiA%2C%20VieiraRM%2C%20VaranasiRS%2C%20LasserJ%2C%20et%20al.%20PhDnet%20Report%202019.%202020." data-title="PhDnet%20Report%202019" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=PhDnet+Report+2019+Olsthoorn+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref13"><span>13.
            </span><a name="pone.0288103.ref013" id="pone.0288103.ref013"></a>Woolston C. Graduate survey: A love–hurt relationship. Nature. 2017;550(7677): 549–552. <ul><li><a href="#" data-author="Woolston" data-cit="WoolstonC.%20Graduate%20survey%3A%20A%20love%E2%80%93hurt%20relationship.%20Nature.%202017%3B550%287677%29%3A%20549%E2%80%93552." data-title="Graduate%20survey%3A%20A%20love%E2%80%93hurt%20relationship" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Graduate+survey%3A+A+love%E2%80%93hurt+relationship+Woolston+2017" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref14"><span>14.
            </span><a name="pone.0288103.ref014" id="pone.0288103.ref014"></a>Woolston C. PhDs: the tortuous truth. Nature. 2019;575(7782): 403–406.  pmid:31723297 <ul data-doi="10.1038/d41586-019-03459-7"><li><a href="https://doi.org/10.1038/d41586-019-03459-7" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/31723297" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=PhDs%3A+the+tortuous+truth+Woolston+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref15"><span>15.
            </span><a name="pone.0288103.ref015" id="pone.0288103.ref015"></a>Marais GAB, Shankland R, Haag P, Fiault R, Juniper B. A Survey and a Positive Psychology Intervention on French PhD Student Well-being. IJDS. 2018;13: 109–138. <ul><li><a href="#" data-author="Marais" data-cit="MaraisGAB%2C%20ShanklandR%2C%20HaagP%2C%20FiaultR%2C%20JuniperB.%20A%20Survey%20and%20a%20Positive%20Psychology%20Intervention%20on%20French%20PhD%20Student%20Well-being.%20IJDS.%202018%3B13%3A%20109%E2%80%93138." data-title="A%20Survey%20and%20a%20Positive%20Psychology%20Intervention%20on%20French%20PhD%20Student%20Well-being" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+Survey+and+a+Positive+Psychology+Intervention+on+French+PhD+Student+Well-being+Marais+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref16"><span>16.
            </span><a name="pone.0288103.ref016" id="pone.0288103.ref016"></a>Levecque K, Anseel F, De Beuckelaer A, Van der Heyden J, Gisle L. Work organization and mental health problems in PhD students. Research Policy. 2017;46(4): 868–879. <ul><li><a href="#" data-author="Levecque" data-cit="LevecqueK%2C%20AnseelF%2C%20De%20BeuckelaerA%2C%20Van%20der%20HeydenJ%2C%20GisleL.%20Work%20organization%20and%20mental%20health%20problems%20in%20PhD%20students.%20Research%20Policy.%202017%3B46%284%29%3A%20868%E2%80%93879." data-title="Work%20organization%20and%20mental%20health%20problems%20in%20PhD%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Work+organization+and+mental+health+problems+in+PhD+students+Levecque+2017" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref17"><span>17.
            </span><a name="pone.0288103.ref017" id="pone.0288103.ref017"></a>Auerbach RP, Mortier P, Bruffaerts R, Alonso J, Benjet C, Cuijpers P, et al. WHO World Mental Health Surveys International College Student Project: Prevalence and distribution of mental disorders. Journal of Abnormal Psychology. 2018;127(7): 623638.  pmid:30211576 <ul data-doi="10.1037/abn0000362"><li><a href="https://doi.org/10.1037/abn0000362" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/30211576" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=WHO+World+Mental+Health+Surveys+International+College+Student+Project%3A+Prevalence+and+distribution+of+mental+disorders+Auerbach+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref18"><span>18.
            </span><a name="pone.0288103.ref018" id="pone.0288103.ref018"></a>Sverdlik A, Hall NC. Not just a phase: Exploring the role of program stage on well-being and motivation in doctoral students. Journal of Adult and Continuing Education. 2020;26(1): 97–124. <ul><li><a href="#" data-author="Sverdlik" data-cit="SverdlikA%2C%20HallNC.%20Not%20just%20a%20phase%3A%20Exploring%20the%20role%20of%20program%20stage%20on%20well-being%20and%20motivation%20in%20doctoral%20students.%20Journal%20of%20Adult%20and%20Continuing%20Education.%202020%3B26%281%29%3A%2097%E2%80%93124." data-title="Not%20just%20a%20phase%3A%20Exploring%20the%20role%20of%20program%20stage%20on%20well-being%20and%20motivation%20in%20doctoral%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Not+just+a+phase%3A+Exploring+the+role+of+program+stage+on+well-being+and+motivation+in+doctoral+students+Sverdlik+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref19"><span>19.
            </span><a name="pone.0288103.ref019" id="pone.0288103.ref019"></a>The mental health of PhD researchers demands urgent attention. Nature. 2019;575(7782): 257–258.  pmid:31723298 <ul data-doi="10.1038/d41586-019-03489-1"><li><a href="https://doi.org/10.1038/d41586-019-03489-1" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/31723298" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+mental+health+of+PhD+researchers+demands+urgent+attention++2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref20"><span>20.
            </span><a name="pone.0288103.ref020" id="pone.0288103.ref020"></a>Mark G, Smith AP. Effects of occupational stress, job characteristics, coping, and attributional style on the mental health and job satisfaction of university employees. Anxiety, Stress &amp; Coping. 2012;25(1): 63–78.  pmid:21271408 <ul data-doi="10.1080/10615806.2010.548088"><li><a href="https://doi.org/10.1080/10615806.2010.548088" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/21271408" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Effects+of+occupational+stress%2C+job+characteristics%2C+coping%2C+and+attributional+style+on+the+mental+health+and+job+satisfaction+of+university+employees+Mark+2012" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref21"><span>21.
            </span><a name="pone.0288103.ref021" id="pone.0288103.ref021"></a>Pyhältö K, Stubb J, Lonka K. Developing scholarly communities as learning environments for doctoral students. International Journal for Academic Development. 2009;14(3): 221–232. <ul><li><a href="#" data-author="Pyh%C3%A4lt%C3%B6" data-cit="Pyh%C3%A4lt%C3%B6K%2C%20StubbJ%2C%20LonkaK.%20Developing%20scholarly%20communities%20as%20learning%20environments%20for%20doctoral%20students.%20International%20Journal%20for%20Academic%20Development.%202009%3B14%283%29%3A%20221%E2%80%93232." data-title="Developing%20scholarly%20communities%20as%20learning%20environments%20for%20doctoral%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Developing+scholarly+communities+as+learning+environments+for+doctoral+students+Pyh%C3%A4lt%C3%B6+2009" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref22"><span>22.
            </span><a name="pone.0288103.ref022" id="pone.0288103.ref022"></a>Urbanaviciute I, Christina Roll L, Tomas J, Witte H. Proactive strategies for countering the detrimental outcomes of qualitative job insecurity in academia. Stress and Health. 2021;37(3): 557571.  pmid:33377270 <ul data-doi="10.1002/smi.3023"><li><a href="https://doi.org/10.1002/smi.3023" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/33377270" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Proactive+strategies+for+countering+the+detrimental+outcomes+of+qualitative+job+insecurity+in+academia+Urbanaviciute+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref23"><span>23.
            </span><a name="pone.0288103.ref023" id="pone.0288103.ref023"></a>Dadaczynski K, Okan O, Messer M, Rathmann K. University students’ sense of coherence, future worries and mental health: findings from the German COVID-HL-survey. Health Promotion International. 2022;37(1): daab070.  pmid:34214156 <ul data-doi="10.1093/heapro/daab070"><li><a href="https://doi.org/10.1093/heapro/daab070" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34214156" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=University+students%E2%80%99+sense+of+coherence%2C+future+worries+and+mental+health%3A+findings+from+the+German+COVID-HL-survey+Dadaczynski+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref24"><span>24.
            </span><a name="pone.0288103.ref024" id="pone.0288103.ref024"></a>Nicholls H, Nicholls M, Tekin S, Lamb D, Billings J. The impact of working in academia on researchers’ mental health and well-being: A systematic review and qualitative meta-synthesis. Serraino GF, editor. PLoS ONE. 2022;17(5): e0268890.  pmid:35613147 <ul data-doi="10.1371/journal.pone.0268890"><li><a href="https://doi.org/10.1371/journal.pone.0268890" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/35613147" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+impact+of+working+in+academia+on+researchers%E2%80%99+mental+health+and+well-being%3A+A+systematic+review+and+qualitative+meta-synthesis+Nicholls+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref25"><span>25.
            </span><a name="pone.0288103.ref025" id="pone.0288103.ref025"></a>Mackie SA, Bates GW. Contribution of the doctoral education environment to PhD candidates’ mental health problems: a scoping review. Higher Education Research &amp; Development. 2019;38(3): 565–578. <ul><li><a href="#" data-author="Mackie" data-cit="MackieSA%2C%20BatesGW.%20Contribution%20of%20the%20doctoral%20education%20environment%20to%20PhD%20candidates%E2%80%99%20mental%20health%20problems%3A%20a%20scoping%20review.%20Higher%20Education%20Research%20%26%20Development.%202019%3B38%283%29%3A%20565%E2%80%93578." data-title="Contribution%20of%20the%20doctoral%20education%20environment%20to%20PhD%20candidates%E2%80%99%20mental%20health%20problems%3A%20a%20scoping%20review" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Contribution+of+the+doctoral+education+environment+to+PhD+candidates%E2%80%99+mental+health+problems%3A+a+scoping+review+Mackie+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref26"><span>26.
            </span><a name="pone.0288103.ref026" id="pone.0288103.ref026"></a>Kroenke K, Spitzer RL, Williams JBW. The Patient Health Questionnaire-2: Validity of a Two-Item Depression Screener. Medical Care. 2003;41(11): 1284–1292.  pmid:14583691 <ul data-doi="10.1097/01.MLR.0000093487.78664.3C"><li><a href="https://doi.org/10.1097/01.MLR.0000093487.78664.3C" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/14583691" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+Patient+Health+Questionnaire-2%3A+Validity+of+a+Two-Item+Depression+Screener+Kroenke+2003" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref27"><span>27.
            </span><a name="pone.0288103.ref027" id="pone.0288103.ref027"></a>Spitzer RL, Kroenke K, Williams JBW, Löwe B. A Brief Measure for Assessing Generalized Anxiety Disorder: The GAD-7. Arch Intern Med. 2006;166(10): 1092.  pmid:16717171 <ul data-doi="10.1001/archinte.166.10.1092"><li><a href="https://doi.org/10.1001/archinte.166.10.1092" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/16717171" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+Brief+Measure+for+Assessing+Generalized+Anxiety+Disorder%3A+The+GAD-7+Spitzer+2006" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref28"><span>28.
            </span><a name="pone.0288103.ref028" id="pone.0288103.ref028"></a>Bach M. Substance use for neuroenhancement or coping with stress: An epidemiological study on university students and clients of a University counseling service in Germany [Internet]. RWTH Aachen; 2016. Available from: <a href="http://publications.rwth-aachen.de/record/679004/files/679004.pdf">http://publications.rwth-aachen.de/record/679004/files/679004.pdf</a>. <ul><li><a href="#" data-author="Bach" data-cit="BachM.%20Substance%20use%20for%20neuroenhancement%20or%20coping%20with%20stress%3A%20An%20epidemiological%20study%20on%20university%20students%20and%20clients%20of%20a%20University%20counseling%20service%20in%20Germany%20%5BInternet%5D.%20RWTH%20Aachen%3B%202016.%20Available%20from%3A%20http%3A%2F%2Fpublications.rwth-aachen.de%2Frecord%2F679004%2Ffiles%2F679004.pdf." data-title="Substance%20use%20for%20neuroenhancement%20or%20coping%20with%20stress%3A%20An%20epidemiological%20study%20on%20university%20students%20and%20clients%20of%20a%20University%20counseling%20service%20in%20Germany" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Substance+use+for+neuroenhancement+or+coping+with+stress%3A+An+epidemiological+study+on+university+students+and+clients+of+a+University+counseling+service+in+Germany+Bach+2016" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref29"><span>29.
            </span><a name="pone.0288103.ref029" id="pone.0288103.ref029"></a>Cohen S, Kamarck T, Mermelstein R. A Global Measure of Perceived Stress. Journal of Health and Social Behavior. 1983;24(4): 385–396. pmid:6668417 <ul><li><a href="#" data-author="Cohen" data-cit="CohenS%2C%20KamarckT%2C%20MermelsteinR.%20A%20Global%20Measure%20of%20Perceived%20Stress.%20Journal%20of%20Health%20and%20Social%20Behavior.%201983%3B24%284%29%3A%20385%E2%80%93396.%206668417" data-title="A%20Global%20Measure%20of%20Perceived%20Stress" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/6668417" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+Global+Measure+of+Perceived+Stress+Cohen+1983" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref30"><span>30.
            </span><a name="pone.0288103.ref030" id="pone.0288103.ref030"></a>Büssing A. Translation of Cohen’s 10 Item Perceived Stress Scale (PSS). University of Witten/Herdecke; 2011. <ul></ul></li><li id="ref31"><span>31.
            </span><a name="pone.0288103.ref031" id="pone.0288103.ref031"></a>Hellgren J, Sjöberg A, Sverke M. Intention to quit: Effects of job satisfaction and job perceptions. In: Avallone F, Arnold J, de Witte K, editors. Feelings work in Europe. Milano: Guerini; 1997. pp. 415–423. <ul><li><a href="#" data-author="Hellgren" data-cit="HellgrenJ%2C%20Sj%C3%B6bergA%2C%20SverkeM.%20Intention%20to%20quit%3A%20Effects%20of%20job%20satisfaction%20and%20job%20perceptions.%20In%3A%20AvalloneF%2C%20ArnoldJ%2C%20de%20WitteK%2C%20editors.%20Feelings%20work%20in%20Europe.%20Milano%3A%20Guerini%3B%201997.%20pp.%20415%E2%80%93423." data-title="Intention%20to%20quit%3A%20Effects%20of%20job%20satisfaction%20and%20job%20perceptions" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Intention+to+quit%3A+Effects+of+job+satisfaction+and+job+perceptions+Hellgren+1997" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref32"><span>32.
            </span><a name="pone.0288103.ref032" id="pone.0288103.ref032"></a>Ahrendt D, Anderson R, Dubois H, Jungblut JM, Leončikas T, Pöntinen L, et al. European quality of live survey 2016: quality of life, quality of public services, and quality of society. Luxembourg: Publications Office of the European Union; 2017. <ul></ul></li><li id="ref33"><span>33.
            </span><a name="pone.0288103.ref033" id="pone.0288103.ref033"></a>Hellgren J, Sverke M, Isaksson K. A Two-dimensional Approach to Job Insecurity: Consequences for Employee Attitudes and Well-being. European Journal of Work and Organizational Psychology. 1999;8(2): 179–195. <ul><li><a href="#" data-author="Hellgren" data-cit="HellgrenJ%2C%20SverkeM%2C%20IsakssonK.%20A%20Two-dimensional%20Approach%20to%20Job%20Insecurity%3A%20Consequences%20for%20Employee%20Attitudes%20and%20Well-being.%20European%20Journal%20of%20Work%20and%20Organizational%20Psychology.%201999%3B8%282%29%3A%20179%E2%80%93195." data-title="A%20Two-dimensional%20Approach%20to%20Job%20Insecurity%3A%20Consequences%20for%20Employee%20Attitudes%20and%20Well-being" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+Two-dimensional+Approach+to+Job+Insecurity%3A+Consequences+for+Employee+Attitudes+and+Well-being+Hellgren+1999" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref34"><span>34.
            </span><a name="pone.0288103.ref034" id="pone.0288103.ref034"></a>Mayring P. Qualitative Inhaltsanalyse: Grundlagen und Techniken. 13., überarbeitete Auflage. Weinheim Basel: Beltz; 2022. <ul></ul></li><li id="ref35"><span>35.
            </span><a name="pone.0288103.ref035" id="pone.0288103.ref035"></a>Hayes AF, Krippendorff K. Answering the Call for a Standard Reliability Measure for Coding Data. Communication Methods and Measures. 2007;1(1): 77–89. <ul><li><a href="#" data-author="Hayes" data-cit="HayesAF%2C%20KrippendorffK.%20Answering%20the%20Call%20for%20a%20Standard%20Reliability%20Measure%20for%20Coding%20Data.%20Communication%20Methods%20and%20Measures.%202007%3B1%281%29%3A%2077%E2%80%9389." data-title="Answering%20the%20Call%20for%20a%20Standard%20Reliability%20Measure%20for%20Coding%20Data" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Answering+the+Call+for+a+Standard+Reliability+Measure+for+Coding+Data+Hayes+2007" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref36"><span>36.
            </span><a name="pone.0288103.ref036" id="pone.0288103.ref036"></a>Warttig SL, Forshaw MJ, South J, White AK. New, normative, English-sample data for the Short Form Perceived Stress Scale (PSS-4). J Health Psychol. 2013;18(12): 1617–1628.  pmid:24155195 <ul data-doi="10.1177/1359105313508346"><li><a href="https://doi.org/10.1177/1359105313508346" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/24155195" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=New%2C+normative%2C+English-sample+data+for+the+Short+Form+Perceived+Stress+Scale+%28PSS-4%29+Warttig+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref37"><span>37.
            </span><a name="pone.0288103.ref037" id="pone.0288103.ref037"></a>Klein EM, Brähler E, Dreier M, Reinecke L, Müller KW, Schmutzer G, et al. The German version of the Perceived Stress Scale–psychometric characteristics in a representative German community sample. BMC Psychiatry. 2016;16(1): 1–10. <ul><li><a href="#" data-author="Klein" data-cit="KleinEM%2C%20Br%C3%A4hlerE%2C%20DreierM%2C%20ReineckeL%2C%20M%C3%BCllerKW%2C%20SchmutzerG%2C%20et%20al.%20The%20German%20version%20of%20the%20Perceived%20Stress%20Scale%E2%80%93psychometric%20characteristics%20in%20a%20representative%20German%20community%20sample.%20BMC%20Psychiatry.%202016%3B16%281%29%3A%201%E2%80%9310." data-title="The%20German%20version%20of%20the%20Perceived%20Stress%20Scale%E2%80%93psychometric%20characteristics%20in%20a%20representative%20German%20community%20sample" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=The+German+version+of+the+Perceived+Stress+Scale%E2%80%93psychometric+characteristics+in+a+representative+German+community+sample+Klein+2016" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref38"><span>38.
            </span><a name="pone.0288103.ref038" id="pone.0288103.ref038"></a>Friedrich J, Münch AK, Thiel A, Voelter-Mahlknecht S, Sudeck G. Occupational Health Literacy Scale (OHLS): development and validation of a domain-specific measuring instrument. Health Promotion International. 2023;38(1): daac182.  pmid:36738454 <ul data-doi="10.1093/heapro/daac182"><li><a href="https://doi.org/10.1093/heapro/daac182" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/36738454" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Occupational+Health+Literacy+Scale+%28OHLS%29%3A+development+and+validation+of+a+domain-specific+measuring+instrument+Friedrich+2023" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref39"><span>39.
            </span><a name="pone.0288103.ref039" id="pone.0288103.ref039"></a>Levecque K, De Beuckelaer A, Van Overbeke K, Mortier A. How satisfied are PhD students with their job? A focus on Flanders. ECCOM-brief. 2019;18: 1–5. <ul><li><a href="#" data-author="Levecque" data-cit="LevecqueK%2C%20De%20BeuckelaerA%2C%20Van%20OverbekeK%2C%20MortierA.%20How%20satisfied%20are%20PhD%20students%20with%20their%20job%3F%20A%20focus%20on%20Flanders.%20ECCOM-brief.%202019%3B18%3A%201%E2%80%935." data-title="How%20satisfied%20are%20PhD%20students%20with%20their%20job%3F%20A%20focus%20on%20Flanders" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=How+satisfied+are+PhD+students+with+their+job%3F+A+focus+on+Flanders+Levecque+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref40"><span>40.
            </span><a name="pone.0288103.ref040" id="pone.0288103.ref040"></a>Krippendorff K. Content Analysis: An Introduction to Its Methodology [Internet]. SAGE Publications; 2019 [cited 2023 Jun 6]. Available from: <a href="https://methods.sagepub.com/book/content-analysis-4e">https://methods.sagepub.com/book/content-analysis-4e</a>. <ul></ul></li><li id="ref41"><span>41.
            </span><a name="pone.0288103.ref041" id="pone.0288103.ref041"></a>Skoda EM, Spura A, De Bock F, Schweda A, Dörrie N, Fink M, et al. Veränderung der psychischen Belastung in der COVID-19-Pandemie in Deutschland: Ängste, individuelles Verhalten und die Relevanz von Information sowie Vertrauen in Behörden. Bundesgesundheitsbl. 2021r;64(3): 322–333. <ul><li><a href="#" data-author="Skoda" data-cit="SkodaEM%2C%20SpuraA%2C%20De%20BockF%2C%20SchwedaA%2C%20D%C3%B6rrieN%2C%20FinkM%2C%20et%20al.%20Ver%C3%A4nderung%20der%20psychischen%20Belastung%20in%20der%20COVID-19-Pandemie%20in%20Deutschland%3A%20%C3%84ngste%2C%20individuelles%20Verhalten%20und%20die%20Relevanz%20von%20Information%20sowie%20Vertrauen%20in%20Beh%C3%B6rden.%20Bundesgesundheitsbl.%202021r%3B64%283%29%3A%20322%E2%80%93333." data-title="Ver%C3%A4nderung%20der%20psychischen%20Belastung%20in%20der%20COVID-19-Pandemie%20in%20Deutschland%3A%20%C3%84ngste%2C%20individuelles%20Verhalten%20und%20die%20Relevanz%20von%20Information%20sowie%20Vertrauen%20in%20Beh%C3%B6rden" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Ver%C3%A4nderung+der+psychischen+Belastung+in+der+COVID-19-Pandemie+in+Deutschland%3A+%C3%84ngste%2C+individuelles+Verhalten+und+die+Relevanz+von+Information+sowie+Vertrauen+in+Beh%C3%B6rden+Skoda+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref42"><span>42.
            </span><a name="pone.0288103.ref042" id="pone.0288103.ref042"></a>Bäuerle A, Steinbach J, Schweda A, Beckord J, Hetkamp M, Weismüller B, et al. Mental Health Burden of the COVID-19 Outbreak in Germany: Predictors of Mental Health Impairment. J Prim Care Community Health. 2020 Jan;11: 1–8.  pmid:32865107 <ul data-doi="10.1177/2150132720953682"><li><a href="https://doi.org/10.1177/2150132720953682" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32865107" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Mental+Health+Burden+of+the+COVID-19+Outbreak+in+Germany%3A+Predictors+of+Mental+Health+Impairment+B%C3%A4uerle+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref43"><span>43.
            </span><a name="pone.0288103.ref043" id="pone.0288103.ref043"></a>Chrikov I, Soria KM, Horgos B, Jones-White D. Undergraduate and graduate students’ mental health during the COVID-19 pandemic. [Internet]. University of California—Berkeley and University of Minnesota: SERU Consortium; 2020. Available from: <a href="https://hdl.handle.net/11299/215271">https://hdl.handle.net/11299/215271</a>. <ul><li><a href="#" data-author="Chrikov" data-cit="ChrikovI%2C%20SoriaKM%2C%20HorgosB%2C%20Jones-WhiteD.%20Undergraduate%20and%20graduate%20students%E2%80%99%20mental%20health%20during%20the%20COVID-19%20pandemic.%20%5BInternet%5D.%20University%20of%20California%E2%80%94Berkeley%20and%20University%20of%20Minnesota%3A%20SERU%20Consortium%3B%202020.%20Available%20from%3A%20https%3A%2F%2Fhdl.handle.net%2F11299%2F215271." data-title="Undergraduate%20and%20graduate%20students%E2%80%99%20mental%20health%20during%20the%20COVID-19%20pandemic" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Undergraduate+and+graduate+students%E2%80%99+mental+health+during+the+COVID-19+pandemic+Chrikov+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref44"><span>44.
            </span><a name="pone.0288103.ref044" id="pone.0288103.ref044"></a>Federal Statistical Office. Qualität der Arbeit: Wöchentliche Arbeitszeit [Internet]. Wiesbaden: Statistisches Bundesamt; 2021. Available from: <a href="https://www.destatis.de/DE/Themen/Arbeit/Arbeitsmarkt/Qualitaet-Arbeit/Dimension-3/woechentliche-arbeitszeitl.html">https://www.destatis.de/DE/Themen/Arbeit/Arbeitsmarkt/Qualitaet-Arbeit/Dimension-3/woechentliche-arbeitszeitl.html</a>. <ul></ul></li><li id="ref45"><span>45.
            </span><a name="pone.0288103.ref045" id="pone.0288103.ref045"></a>Frei I, Grund C. Antecedents of overtime work: The case of junior academics. German Journal of Human Resource Management. 2020;34(4): 371–397. <ul><li><a href="#" data-author="Frei" data-cit="FreiI%2C%20GrundC.%20Antecedents%20of%20overtime%20work%3A%20The%20case%20of%20junior%20academics.%20German%20Journal%20of%20Human%20Resource%20Management.%202020%3B34%284%29%3A%20371%E2%80%93397." data-title="Antecedents%20of%20overtime%20work%3A%20The%20case%20of%20junior%20academics" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Antecedents+of+overtime+work%3A+The+case+of+junior+academics+Frei+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref46"><span>46.
            </span><a name="pone.0288103.ref046" id="pone.0288103.ref046"></a>Mauvais-Jarvis F, Bairey Merz N, Barnes PJ, Brinton RD, Carrero JJ, DeMeo DL, et al. Sex and gender: modifiers of health, disease, and medicine. The Lancet. 2020;396(10250): 565–582.  pmid:32828189 <ul data-doi="10.1016/S0140-6736(20)31561-0"><li><a href="https://doi.org/10.1016/S0140-6736(20)31561-0" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32828189" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Sex+and+gender%3A+modifiers+of+health%2C+disease%2C+and+medicine+Mauvais-Jarvis+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref47"><span>47.
            </span><a name="pone.0288103.ref047" id="pone.0288103.ref047"></a>Prowse R, Sherratt F, Abizaid A, Gabrys RL, Hellemans KGC, Patterson ZR, et al. Coping With the COVID-19 Pandemic: Examining Gender Differences in Stress and Mental Health Among University Students. Front Psychiatry. 2021;12: 650759.  pmid:33897499 <ul data-doi="10.3389/fpsyt.2021.650759"><li><a href="https://doi.org/10.3389/fpsyt.2021.650759" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/33897499" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Coping+With+the+COVID-19+Pandemic%3A+Examining+Gender+Differences+in+Stress+and+Mental+Health+Among+University+Students+Prowse+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref48"><span>48.
            </span><a name="pone.0288103.ref048" id="pone.0288103.ref048"></a>Federal Ministry of Health. Ordinance on protection against infection risks related to entry to Germany with regard to novel mutations of the SARS-CoV-2 coronavirus subsequent to the determination of an epidemic situation of national significance by the German Bundestag (Coronavirus-Schutzverordnung–CoronaSchV) [Internet]. Berlin: Federal Ministry of Health; 2021. Available from: <a href="https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/3_Downloads/C/Coronavirus/Verordnungen/EN_Corona-Schutzverordnung_konsolidierte_Reinfassung_BAnz_bf.pdf">https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/3_Downloads/C/Coronavirus/Verordnungen/EN_Corona-Schutzverordnung_konsolidierte_Reinfassung_BAnz_bf.pdf</a>. <ul></ul></li><li id="ref49"><span>49.
            </span><a name="pone.0288103.ref049" id="pone.0288103.ref049"></a>Moreno C, Wykes T, Galderisi S, Nordentoft M, Crossley N, Jones N, et al. How mental health care should change as a consequence of the COVID-19 pandemic. The Lancet Psychiatry. 2020;7(9): 813–824.  pmid:32682460 <ul data-doi="10.1016/S2215-0366(20)30307-2"><li><a href="https://doi.org/10.1016/S2215-0366(20)30307-2" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32682460" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=How+mental+health+care+should+change+as+a+consequence+of+the+COVID-19+pandemic+Moreno+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref50"><span>50.
            </span><a name="pone.0288103.ref050" id="pone.0288103.ref050"></a>Eberhard Karls Universität Tübingen. Studierendenstatistik Wintersemester 2021/2022 [Internet]. Tübingen: Eberhard Karls Universität; 2021. Available from: <a href="https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2NzI4MzQ4NTgsImV4cCI6MTY3MjkyNDg0OCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0RlemVybmF0ZVwvRGV6ZXJuYXRfSUlcL3N0dWRlbnRlbnN0YXRpc3Rpa2VuXC9zdGF0aXN0aWstd3MtMjAyMTIwMjIucGRmIiwicGFnZSI6NTk3fQ.4gH9ESxTCgdSWpi0dMxRLnZPB_xrL4MVm46k8wtB3IY/statistik-ws-20212022.pdf">https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2NzI4MzQ4NTgsImV4cCI6MTY3MjkyNDg0OCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0RlemVybmF0ZVwvRGV6ZXJuYXRfSUlcL3N0dWRlbnRlbnN0YXRpc3Rpa2VuXC9zdGF0aXN0aWstd3MtMjAyMTIwMjIucGRmIiwicGFnZSI6NTk3fQ.4gH9ESxTCgdSWpi0dMxRLnZPB_xrL4MVm46k8wtB3IY/statistik-ws-20212022.pdf</a>. <ul></ul></li><li id="ref51"><span>51.
            </span><a name="pone.0288103.ref051" id="pone.0288103.ref051"></a>Scarf D, Winter T, Riordan B, Hunter J, Tustin K, Gollop M, et al. A longitudinal study of mental wellbeing in students that transition into PhD study. PsyArXiv [Preprint]. 2021 [cited 2023 Jun 6]. Available from: <a href="https://osf.io/eq6xg">https://osf.io/eq6xg</a>. <ul><li><a href="#" data-author="Scarf" data-cit="ScarfD%2C%20WinterT%2C%20RiordanB%2C%20HunterJ%2C%20TustinK%2C%20GollopM%2C%20et%20al.%20A%20longitudinal%20study%20of%20mental%20wellbeing%20in%20students%20that%20transition%20into%20PhD%20study.%20PsyArXiv%20%5BPreprint%5D.%202021%20%5Bcited%202023%20Jun%206%5D.%20Available%20from%3A%20https%3A%2F%2Fosf.io%2Feq6xg." data-title="A%20longitudinal%20study%20of%20mental%20wellbeing%20in%20students%20that%20transition%20into%20PhD%20study" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+longitudinal+study+of+mental+wellbeing+in+students+that+transition+into+PhD+study+Scarf+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref52"><span>52.
            </span><a name="pone.0288103.ref052" id="pone.0288103.ref052"></a>Rosenbaum PR, Rubin DB. The central role of the propensity score in observational studies for causal effects. Biometrika. 1983;70(1): 41–55. <ul><li><a href="#" data-author="Rosenbaum" data-cit="RosenbaumPR%2C%20RubinDB.%20The%20central%20role%20of%20the%20propensity%20score%20in%20observational%20studies%20for%20causal%20effects.%20Biometrika.%201983%3B70%281%29%3A%2041%E2%80%9355." data-title="The%20central%20role%20of%20the%20propensity%20score%20in%20observational%20studies%20for%20causal%20effects" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=The+central+role+of+the+propensity+score+in+observational+studies+for+causal+effects+Rosenbaum+1983" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref53"><span>53.
            </span><a name="pone.0288103.ref053" id="pone.0288103.ref053"></a>Sommer J, Jongmanns G, Book A, Rennert C. Evaluation des novellierten Wissenschaftszeitvertragsgesetzes [Internet]. Hannover: HIS-Institut für Hochschulentwicklung e. V.; 2022. Available from: <a href="https://www.bmbf.de/SharedDocs/Downloads/de/2022/abschlussbericht-evaluation-wisszeitvg.pdf?__blob=publicationFile&amp;v=2">https://www.bmbf.de/SharedDocs/Downloads/de/2022/abschlussbericht-evaluation-wisszeitvg.pdf?__blob=publicationFile&amp;v=2</a>. <ul><li><a href="#" data-author="Sommer" data-cit="SommerJ%2C%20JongmannsG%2C%20BookA%2C%20RennertC.%20Evaluation%20des%20novellierten%20Wissenschaftszeitvertragsgesetzes%20%5BInternet%5D.%20Hannover%3A%20HIS-Institut%20f%C3%BCr%20Hochschulentwicklung%20e.%20V.%3B%202022.%20Available%20from%3A%20https%3A%2F%2Fwww.bmbf.de%2FSharedDocs%2FDownloads%2Fde%2F2022%2Fabschlussbericht-evaluation-wisszeitvg.pdf%3F__blob%3DpublicationFile%26v%3D2." data-title="Evaluation%20des%20novellierten%20Wissenschaftszeitvertragsgesetzes" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Evaluation+des+novellierten+Wissenschaftszeitvertragsgesetzes+Sommer+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref54"><span>54.
            </span><a name="pone.0288103.ref054" id="pone.0288103.ref054"></a>Hochschulrektorenkonferenz. Diskussionsvorschlag der Mitgliedergruppe Universitäten der Hochschulrektorenkonferenz zur Weiterentwicklung des Wissenschaftszeitvertragsgesetzes (Berlin, 06.07.2022) [Internet]. Bonn: Stiftung zur Förderung der Hochschulrektorenkonferenz; 2022. Available from: <a href="https://www.hrk.de/fileadmin/redaktion/hrk/02-Dokumente/02-01-Beschluesse/20220706_MGU_WissZeitVG_Diskussionsvorschlag.pdf">https://www.hrk.de/fileadmin/redaktion/hrk/02-Dokumente/02-01-Beschluesse/20220706_MGU_WissZeitVG_Diskussionsvorschlag.pdf</a>. <ul></ul></li><li id="ref55"><span>55.
            </span><a name="pone.0288103.ref055" id="pone.0288103.ref055"></a>Hall S. A mental-health crisis is gripping science–toxic research culture is to blame. Nature. 2023;617(7962): 666–668.  pmid:37221336 <ul data-doi="10.1038/d41586-023-01708-4"><li><a href="https://doi.org/10.1038/d41586-023-01708-4" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/37221336" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+mental-health+crisis+is+gripping+science%E2%80%93toxic+research+culture+is+to+blame+Hall+2023" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li></ol></div>



          

        </div>
      </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Iridescent crystal with raymarching and signed distance fields (150 pts)]]></title>
            <link>https://varun.ca/ray-march-sdf/</link>
            <guid>36591767</guid>
            <pubDate>Tue, 04 Jul 2023 19:52:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varun.ca/ray-march-sdf/">https://varun.ca/ray-march-sdf/</a>, See on <a href="https://news.ycombinator.com/item?id=36591767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="-1" id="___gatsby"><nav></nav><article><header><time datetime="2023-06-03T00:00:00.000Z" color="neutral.2" font-size="1" font-family="systemSans">3rd June, 2023</time></header><p font-family="systemSans" color="neutral.0" font-size="2,3">When building a 3D scene using libraries such as Three.js we generally use meshes. You define a geometry attach some material to it to create a mesh. Then add that mesh to the scene to render it. This is also how 3D modelling software like Blender and Cinema4D work. However, in the demoscene world—where the goal of is to create stuff using extremely small and self-contained computer programs—this approach didn’t work. They’d have to package a 3D library or engine along with the demo code which takes up a lot of memory. So, those folks came up with a pretty innovative approach. They used signed distance fields (SDFs) to define the geometry and then use raymarching to render the scene. The whole thing runs in a single shader program.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">If you’ve ever come across demos on <a href="https://www.shadertoy.com/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Shadertoy</a> or <a href="http://glslsandbox.com/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">GLSL Sandbox</a>, you’ve seen this approach in action. While the initial goal was a small file size, it also allows you to create some <a href="https://www.shadertoy.com/user/tdhooper/sort=popular&amp;from=0&amp;num=8" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">really cool effects</a> and use boolean operations to create complex shapes. In this article, I’ll show you how to create an iridescent crystal using raymarching and SDFs.</p><p font-size="2" color="neutral.1" font-family="systemSans">ℹ️ This post assumes foundational knowledge of shaders. If you're not familiar with shaders or the GLSL API, check out:<!-- --> <a href="https://typefully.com/DanHollick/gpnhhud" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Dan Hollick's twitter thread</a> <!-- -->for a brief overview,<!-- --> <a href="https://youtu.be/f4s1h2YETNY" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">kishimisu's intro tutorial</a> that breaks down basic GLSL concepts, or<!-- --> <a href="https://blog.maximeheckel.com/posts/the-study-of-shaders-with-react-three-fiber/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Maxime Heckel's tutorial</a> <!-- -->on shaders with React Three Fiber.</p><h2 id="ray-marching" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#ray-marching" aria-label="ray marching permalink" color="brand.main" font-family="systemSans"></a>Ray Marching</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Ray Marching is a rendering technique that involves sending rays into a scene and checking for collisions with objects. Here’s how it works:</p><p font-family="systemSans" color="neutral.0" font-size="2,3">First, we select a position for the camera. Then, we send rays from the camera to each pixel in the output image. Along each ray, we step bit by bit, checking if there is a collision with an object in the scene. If a collision occurs, we’re done! If not, we continue stepping along the ray up to a maximum number of steps.</p><figure><img src="https://varun.ca/static/ray-march-41bd80ce90cdf1dde6084381abf07d6f.svg" alt="" width="100%,75%,50%" display="block"><figcaption font-size="1" font-family="systemSans" color="neutral.0"><a href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">from "Ray tracing" on Wikipedia</a></figcaption></figure><p font-family="systemSans" color="neutral.0" font-size="2,3">The other important distinction is that we’re not using vertices &amp; triangles to define the geometry. If you’ve done any kind of 3D work, you’re probably familiar with the idea of defining geometry using vertices. For example, a cube is defined by 8 vertices and 12 triangles. But with raymarching, we use something called “signed distance field” to represent the geometry.</p><h3 id="signed-distance-field-sdf" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#signed-distance-field-sdf" aria-label="signed distance field sdf permalink" color="brand.main" font-family="systemSans"></a>Signed Distance Field (SDF)</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">While the term SDF may sound daunting, it’s just a function that calculates the shortest distance from any point in space to a shape’s surface. The distance is negative for points within the shape, positive for points outside the shape, and zero for points exactly on the surface of the shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">For example, a circle can be defined by the following function:</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCircle</span><span>(</span><span>vec2</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">You can find functions for various <a href="https://iquilezles.org/articles/distfunctions2d/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">2D</a> and <a href="https://iquilezles.org/articles/distfunctions/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">3D</a> SDFs on Inigo Quilez’s website. Or use the <a href="https://github.com/marklundin/glsl-sdf-primitives" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">glsl-sdf-primitives</a> library. I’ll explain how to use these functions later in the article.</p><p width="50%" font-family="systemSans" color="neutral.0" font-size="2,3">
  <img src="https://varun.ca/baf8094ed68d7efbc78649ba655b5a69/sdf-marching.svg" alt="" display="block">
</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Back to raymarching. When stepping along the ray, the obvious option is to take a tiny step at a time and check for collisions. But since SDF provides us with the distance to the surface, we know that we can step by that distance without going through the surface. Doing so both speeds up the process and improves accuracy.</p><p font-size="2" color="neutral.1" font-family="systemSans">🤔 <b>Raytracing vs Raymarching</b><br>Raytracing is a very similar process to raymarching, the key difference is that geometry is typically defined as triangles, spheres, etc. To find the intersection between the view ray and the scene, we conduct a series of geometric intersection tests. For example, does the ray intersect with a triangle and, if so, which part of the triangle.</p><h2 id="implementing-a-raymarched-scene" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#implementing-a-raymarched-scene" aria-label="implementing a raymarched scene permalink" color="brand.main" font-family="systemSans"></a>Implementing a raymarched scene</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Alright, onto the crystal. Let’s take the technique I shared above and implement it in GLSL. We’ll start with a basic shader scene, add raymarching to it, and then implement lighting and materials.</p><div><figure display="none,none,block" width="400"></figure><div display="none,none,block"><h3 id="basic-shader-scene" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#basic-shader-scene" aria-label="basic shader scene permalink" color="brand.main" font-family="systemSans"></a>Basic shader scene</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My goto tool for creative coding is <a href="https://github.com/mattdesl/canvas-sketch" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">canvas-sketch</a>. It offers a <a href="https://github.com/mattdesl/canvas-sketch-util/blob/master/docs/shader.md#shader--createshaderopt" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">utility function</a> that creates a full-screen GLSL shader renderer using <a href="https://regl.party/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">regl</a>. You can pass in your shader code and uniforms and it takes care of the rest. Here’s an example of a shader that renders a gradient.</p><div data-language="js"><pre><code><span>const</span> canvasSketch <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch'</span><span>)</span><span>;</span>
<span>const</span> createShader <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch-util/shader'</span><span>)</span><span>;</span>
<span>const</span> glsl <span>=</span> <span>require</span><span>(</span><span>'glslify'</span><span>)</span><span>;</span>

<span>const</span> settings <span>=</span> <span>{</span>
  dimensions<span>:</span> <span>[</span><span>1080</span><span>,</span> <span>1080</span><span>]</span><span>,</span>
  context<span>:</span> <span>'webgl'</span><span>,</span>
  animate<span>:</span> <span>true</span><span>,</span>
<span>}</span><span>;</span>

<span>const</span> frag <span>=</span> <span>glsl</span><span>(</span><span><span>`</span><span>
  precision highp float;

  uniform float time;
  varying vec2 vUv;

  void main () {
    vec3 col = 0.5 + 0.5 * cos(time + vUv.xyx + vec3(0,2,4));
    gl_FragColor = vec4(col, 1.0);
  }
</span><span>`</span></span><span>)</span><span>;</span>

<span>const</span> <span>sketch</span> <span>=</span> <span>(</span><span><span>{</span> gl<span>,</span> canvas <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>createShader</span><span>(</span><span>{</span>
    gl<span>,</span>
    frag<span>,</span>
    uniforms<span>:</span> <span>{</span>
      <span>resolution</span><span>:</span> <span>(</span><span><span>{</span> width<span>,</span> height <span>}</span></span><span>)</span> <span>=&gt;</span> <span>[</span>width<span>,</span> height<span>]</span><span>,</span>
      <span>time</span><span>:</span> <span>(</span><span><span>{</span> time <span>}</span></span><span>)</span> <span>=&gt;</span> time<span>,</span>
      <span>playhead</span><span>:</span> <span>(</span><span><span>{</span> playhead <span>}</span></span><span>)</span> <span>=&gt;</span> playhead<span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>canvasSketch</span><span>(</span>sketch<span>,</span> settings<span>)</span><span>;</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Couple of things to note here. <code>createShader</code> bootstraps a default vertex shader (see below) that provides a varying <code>vUv</code>. This essentially maps the pixel coordinates to a value between 0 and 1. You can override this by specifying a custom vertex shader. But for most cases, this is sufficient.</p><p>vert.glsl</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>attribute</span> <span>vec3</span> position<span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>

<span>void</span> <span>main</span> <span>(</span><span>)</span> <span>{</span>
  gl_Position <span>=</span> <span>vec4</span><span>(</span>position<span>.</span>xyz<span>,</span> <span>1.0</span><span>)</span><span>;</span>
  vUv <span>=</span> gl_Position<span>.</span>xy <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">I’m also using a tool called <code>glslify</code> to wrap the shader code. This enables us to import GLSL modules into our shader. We’ll use it to import SDF functions and other raymarching utilities.</p><h3 id="the-raymarching-algorithm" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#the-raymarching-algorithm" aria-label="the raymarching algorithm permalink" color="brand.main" font-family="systemSans"></a>The Raymarching Algorithm</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Below is an implementation of the ray marching algorithm. The camera is positioned as the <code>rayOrigin</code>, and pointed towards the <code>rayTarget</code>—the center of the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The <code>rayDirection</code> is a vector that points from the origin towards a a pixel on the screen, while accounting for the camera’s orientation and field of view. It requires a bit of fancy math to figure out this direction. We’ll be using the <code>glsl-camera-ray</code> module to run that calculation.</p><p><img src="https://varun.ca/static/ray-direction-8b0a68215b4c83cd9236ca43e204a9da.svg" alt="Ray starts at the camera, goes through the pixel on the screen and moves through the scene" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">Once we obtain the ray direction, we proceed along it, checking for collisions. If a collision is detected, the distance to the surface is returned. Otherwise, we return <code>-1.0</code> to signify that no collision was found.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>

<span>float</span> <span>sdSphere</span><span>(</span><span>vec3</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span>

<span>const</span> <span>int</span> steps <span>=</span> <span>90</span><span>;</span>
<span>const</span> <span>float</span> maxdist <span>=</span> <span>20.0</span><span>;</span>
<span>const</span> <span>float</span> precis <span>=</span> <span>0.001</span><span>;</span>

<span>float</span> <span>raymarch</span><span>(</span><span>vec3</span> rayOrigin<span>,</span> <span>vec3</span> rayDir<span>)</span> <span>{</span>
  <span>float</span> latest <span>=</span> precis <span>*</span> <span>2.0</span><span>;</span>
  <span>float</span> dist <span>=</span> <span>0.0</span><span>;</span>
  <span>float</span> res <span>=</span> <span>-</span><span>1.0</span><span>;</span>

  <span>// March along the ray</span>
  <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> steps<span>;</span> i<span>++</span><span>)</span> <span>{</span>
    <span>// Break if we're close enough or too far away</span>
    <span>if</span> <span>(</span>latest <span>&lt;</span> precis <span>||</span> dist <span>&gt;</span> maxdist<span>)</span> <span>break</span><span>;</span>
    <span>// Get the SDF distance</span>
    <span>float</span> latest <span>=</span> <span>sdSphere</span><span>(</span>rayOrigin <span>+</span> rayDir <span>*</span> dist<span>,</span> <span>1.0</span><span>)</span><span>;</span>
    <span>// Increment by the latest SDF distance</span>
    dist <span>+=</span> latest<span>;</span>
  <span>}</span>
  <span>// if we're still within bounds,</span>
  <span>// set the result to the distance</span>
  <span>if</span> <span>(</span>dist <span>&lt;</span> maxdist<span>)</span> <span>{</span>
    res <span>=</span> dist<span>;</span>
  <span>}</span>

  <span>return</span> res<span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>

  <span>// Bootstrap a raymarching scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0.</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>float</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3"><code>lensLength</code> here determines the field of view. Try changing it to see how it affects the scene.</p><h3 id="using-glsl-modules-for-raymarching" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#using-glsl-modules-for-raymarching" aria-label="using glsl modules for raymarching permalink" color="brand.main" font-family="systemSans"></a>Using GLSL modules for raymarching</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Implementing your own raymarching function is cool. It’s especially useful when you want to tweak the inner workings to achieve a specific effect. However, in most cases, you can probably just use an off-the-shelf module.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Below, I’ve updated the sketch to use the <code>glsl-raytrace</code> module. Additionally, I’m using a <code>glsl-sdf-primitives</code> module to generate a torus and <code>glsl-rotate</code> to rotate it.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The mechanics remain largely similar. The key difference is that geometry is now defined within a function called <code>doModel</code>, and raymarch returns a <code>vec2</code> containing the distance and material index. This is useful if you want to render multiple types of objects in a scene.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>
<span>uniform</span> <span>float</span> time<span>;</span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span><span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> raymarch <span>=</span> <span>require</span><span>(</span></span><span>'glsl-raytrace'</span><span><span>,</span> map <span>=</span> doModel<span>,</span> steps <span>=</span> <span>90</span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> sdTorus <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-primitives/sdTorus'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> rotate <span>=</span> <span>require</span><span>(</span></span><span>'glsl-rotate/rotate'</span><span><span>)</span></span></span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>// Spin the shape</span>
  p<span>.</span>xy <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>xy<span>,</span> time<span>)</span><span>;</span>
  p<span>.</span>yz <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>yz<span>,</span> time<span>)</span><span>;</span>
  <span>// Calculate SDF distance</span>
  <span>float</span> d <span>=</span> <span>sdTorus</span><span>(</span>p<span>,</span> <span>vec2</span><span>(</span><span>0.75</span><span>,</span> <span>0.35</span><span>)</span><span>)</span><span>;</span>
  <span>return</span> <span>vec2</span><span>(</span>d<span>,</span> <span>0.0</span><span>)</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>
  <span>// Bootstrap a raytracing scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Check it out! We’ve got a spinning donut 🍩 But it looks kinda flat. Let’s add some depth to the scene.</p><h3 id="calculating-normals" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#calculating-normals" aria-label="calculating normals permalink" color="brand.main" font-family="systemSans"></a>Calculating normals</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">For the classic material and lighting combination, we need to calculate surface normals. That is, a vector that points away from the surface at a given point.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">With SDFs, we calculate the normal by taking the gradient of the SDF function (f) at a specific point, denoted as ∇f. I don’t know about you, but the last time I took a gradient was in <a href="https://apps.ualberta.ca/catalogue/course/mec_e/537" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">MEC E 537 - Aerodynamics</a>. And that was a while ago 😅</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Luckily for us, we can use the <code>glsl-sdf-normal</code> module to compute normals for us. The module uses the same <code>doModel</code> function that we defined for raymarching. If you’re curious about the underlying math, check out <a href="https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#surface-normals-and-lighting" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Jamie Wong’s explanation</a>.</p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> normal <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-normal'</span><span><span>,</span> map <span>=</span> doModel<span>)</span></span></span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>
  <span>// Convert the normal to a color</span>
  color <span>=</span> nor <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span>

<span>// ...</span></code></pre></div><h3 id="phong-lighting" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#phong-lighting" aria-label="phong lighting permalink" color="brand.main" font-family="systemSans"></a>Phong lighting</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My personal philosophy is very much:</p><p><img alt="Fuck around find out" src="https://varun.ca/static/fuck-around-find-out-cc2e14bf2895e5634f02f2f2475d8531.jpg" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">It’s important to understand how things work, but I’m less focused on implementing everything from scratch and more intrigued by applying those concepts to create my own sketches and scenes. That’s why I was super excited to come across <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl/packages</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The stackgl ecosystem is full of little GLSL modules that you can glue these together to create all kinds of effects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Interested in adding lighting to the scene? What type would you prefer? Lambert, Phong, Beckmann, or Specular? Just grab the associated module and plug it into the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I chose <code>glsl-specular-blinn-phong</code></p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> blinnPhongSpec <span>=</span> <span>require</span><span>(</span></span><span>'glsl-specular-blinn-phong'</span><span><span>)</span></span></span>

<span>// ...</span>

<span>vec3</span> lightPos <span>=</span> <span>vec3</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>vec3</span> tint <span>=</span> <span>vec3</span><span>(</span><span>0.05</span><span>,</span> <span>0.0</span><span>,</span> <span>0.97</span><span>)</span><span>;</span> <span>// color of the shape</span>

<span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

<span>// If the ray collides, draw the surface</span>
<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>// Calculate light intensity</span>
  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>// light intensity * color of the shape</span>
  color <span>=</span> power <span>*</span> tint<span>;</span>
<span>}</span></code></pre></div><h3 id="iridescent-material" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#iridescent-material" aria-label="iridescent material permalink" color="brand.main" font-family="systemSans"></a>Iridescent material</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Stackgl isn’t the only place where you can find useful code. My other favourite option is Shadertoy. I’m not going to lie, most things on shadertoy were too daunting for me. I couldn’t even begin to figure out what the code was doing.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">That is, until I discovered that most work on shadertoy uses a combo of raymarching + SDF. This was certainly a lightbulb moment for me. It’s like suddenly this cryptic code was deciphered and I could understand what it said.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I’ve been obsessed with iridescence and have been bookmarking cool shaders. Once I learnt the raymarching technique, that was it. I could revisit these shaders and try to understand how they work.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">One such shader was <a href="https://www.shadertoy.com/view/llcXWM" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Thomas Hooper’s Crystals</a>. It’s way more complex than our scene but the general structure is the same. There’s a function for generating the geometry, there’s raymarching loop and after checking for collision is the bit where the iridescence effect is applied.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Let’s add that to our scene.</p><div data-language="glsl"><pre><code><span>vec3</span> <span>pal</span><span>(</span> <span>in</span> <span>float</span> t<span>,</span> <span>in</span> <span>vec3</span> a<span>,</span> <span>in</span> <span>vec3</span> b<span>,</span> <span>in</span> <span>vec3</span> c<span>,</span> <span>in</span> <span>vec3</span> d <span>)</span> <span>{</span>
  <span>return</span> a <span>+</span> b<span>*</span><span>cos</span><span>(</span> <span>6.28318</span><span>*</span><span>(</span>c<span>*</span>t<span>+</span>d<span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>spectrum</span><span>(</span><span>float</span> n<span>)</span> <span>{</span>
  <span>return</span> <span>pal</span><span>(</span> n<span>,</span> <span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>1.0</span><span>,</span><span>1.0</span><span>,</span><span>1.0</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.0</span><span>,</span><span>0.33</span><span>,</span><span>0.67</span><span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>const</span> <span>float</span> GAMMA <span>=</span> <span>2.2</span><span>;</span>

<span>vec3</span> <span>gamma</span><span>(</span><span>vec3</span> color<span>,</span> <span>float</span> g<span>)</span> <span>{</span>
  <span>return</span> <span>pow</span><span>(</span>color<span>,</span> <span>vec3</span><span>(</span>g<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>linearToScreen</span><span>(</span><span>vec3</span> linearRGB<span>)</span> <span>{</span>
  <span>return</span> <span>gamma</span><span>(</span>linearRGB<span>,</span> <span>1.0</span> <span>/</span> GAMMA<span>)</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>

  <span>// Iridescent lighting</span>
  <span>vec3</span> reflection <span>=</span> <span>reflect</span><span>(</span>rayDirection<span>,</span> nor<span>)</span><span>;</span>
  <span>vec3</span> dome <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// base layer</span>
  <span>vec3</span> perturb <span>=</span> <span>sin</span><span>(</span>pos <span>*</span> <span>10.</span><span>)</span><span>;</span>
  color <span>=</span> <span>spectrum</span><span>(</span><span>dot</span><span>(</span>nor <span>+</span> perturb <span>*</span> <span>.05</span><span>,</span> eyeDirection<span>)</span> <span>*</span> <span>2.</span><span>)</span><span>;</span>
  <span>// specular</span>
  <span>float</span> specular <span>=</span> <span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>;</span>
  specular <span>=</span> <span>pow</span><span>(</span><span>(</span><span>sin</span><span>(</span>specular <span>*</span> <span>20.</span> <span>-</span> <span>3.</span><span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>.5</span><span>)</span> <span>+</span> <span>.1</span><span>,</span> <span>32.</span><span>)</span> <span>*</span> specular<span>;</span>
  specular <span>*=</span> <span>.1</span><span>;</span>
  specular <span>+=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span> <span>+</span> <span>.3</span><span>,</span> <span>8.</span><span>)</span> <span>*</span> <span>.1</span><span>;</span>
  <span>// shadow</span>
  <span>float</span> shadow <span>=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>nor<span>,</span> dome<span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>1.2</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>,</span> <span>3.</span><span>)</span><span>;</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">There are three layers to the iridescent material: the base layer (the funky gradients), a little bit of shadow and specular (the concentric light bands). Try toggling them on and off with the slider see their effects.</p><h3 id="mix-phong-and-iridescence" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#mix-phong-and-iridescence" aria-label="mix phong and iridescence permalink" color="brand.main" font-family="systemSans"></a>Mix Phong and Iridescence</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">One last little tweak with the lighting. We can actually blend the phong and iridescence effects. Which enables you to have tinted iridescent objects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">There’s not a whole lot to it. Calculate the colors for the two effects and then blend them with the <code>mix</code> function.</p><div data-language="glsl"><pre><code><span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>// Basic blinn phong lighting</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>vec3</span> baseColor <span>=</span> power <span>*</span> tint<span>;</span>

  <span>// Iridescent lighting</span>
  <span>// ...</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// mix blinn phong lighting and iridescent lighting</span>
  color <span>=</span> <span>mix</span><span>(</span>baseColor<span>,</span> color<span>,</span> mixBaseAndIridescent<span>)</span><span>;</span>
  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><h3 id="crystal-geometry" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#crystal-geometry" aria-label="crystal geometry permalink" color="brand.main" font-family="systemSans"></a>Crystal geometry</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">We’ve nailed the look, but what about the crystal shape?</p><p font-family="systemSans" color="neutral.0" font-size="2,3">You can file this under “stuff I don’t quite understand, but that’s not going to stop me from using it.” The crystal geometry is a Rhombic Triacontahedron, which I discovered in a <a href="https://www.youtube.com/watch?v=0RWaR7zApEo&amp;t=50s" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">The Art Of Code tutorial</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">This shape is created by folding a plane onto itself using some “magic numbers” and along a “magic direction.” We repeat the process a few times until we achieve the desired crystal shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Try using the slider to observe how the shape changes with each fold.</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCrystal</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>float</span> c <span>=</span> <span>cos</span><span>(</span><span>3.1415</span><span>/</span><span>5.</span><span>)</span><span>,</span> s<span>=</span><span>sqrt</span><span>(</span><span>0.75</span><span>-</span>c<span>*</span>c<span>)</span><span>;</span> <span>// magic numbers</span>
  <span>vec3</span> n <span>=</span> <span>vec3</span><span>(</span><span>-</span><span>0.5</span><span>,</span> <span>-</span>c<span>,</span> s<span>)</span><span>;</span> <span>// magic direction</span>

  <span>// fold the space to add symmetry</span>
  p <span>=</span> <span>abs</span><span>(</span>p<span>)</span><span>;</span>
  <span>// fold along the n direction</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// fold the space again and along the n direction</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// repeat the process</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// distance to the surface</span>
  <span>float</span> d <span>=</span> p<span>.</span>z <span>-</span> <span>1.</span><span>;</span>
  <span>return</span> d<span>;</span>
<span>}</span></code></pre></div></div><div display="block,block,none"><h3 id="basic-shader-scene" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#basic-shader-scene" aria-label="basic shader scene permalink" color="brand.main" font-family="systemSans"></a>Basic shader scene</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My goto tool for creative coding is <a href="https://github.com/mattdesl/canvas-sketch" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">canvas-sketch</a>. It offers a <a href="https://github.com/mattdesl/canvas-sketch-util/blob/master/docs/shader.md#shader--createshaderopt" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">utility function</a> that creates a full-screen GLSL shader renderer using <a href="https://regl.party/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">regl</a>. You can pass in your shader code and uniforms and it takes care of the rest. Here’s an example of a shader that renders a gradient.</p><div data-language="js"><pre><code><span>const</span> canvasSketch <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch'</span><span>)</span><span>;</span>
<span>const</span> createShader <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch-util/shader'</span><span>)</span><span>;</span>
<span>const</span> glsl <span>=</span> <span>require</span><span>(</span><span>'glslify'</span><span>)</span><span>;</span>

<span>const</span> settings <span>=</span> <span>{</span>
  dimensions<span>:</span> <span>[</span><span>1080</span><span>,</span> <span>1080</span><span>]</span><span>,</span>
  context<span>:</span> <span>'webgl'</span><span>,</span>
  animate<span>:</span> <span>true</span><span>,</span>
<span>}</span><span>;</span>

<span>const</span> frag <span>=</span> <span>glsl</span><span>(</span><span><span>`</span><span>
  precision highp float;

  uniform float time;
  varying vec2 vUv;

  void main () {
    vec3 col = 0.5 + 0.5 * cos(time + vUv.xyx + vec3(0,2,4));
    gl_FragColor = vec4(col, 1.0);
  }
</span><span>`</span></span><span>)</span><span>;</span>

<span>const</span> <span>sketch</span> <span>=</span> <span>(</span><span><span>{</span> gl<span>,</span> canvas <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>createShader</span><span>(</span><span>{</span>
    gl<span>,</span>
    frag<span>,</span>
    uniforms<span>:</span> <span>{</span>
      <span>resolution</span><span>:</span> <span>(</span><span><span>{</span> width<span>,</span> height <span>}</span></span><span>)</span> <span>=&gt;</span> <span>[</span>width<span>,</span> height<span>]</span><span>,</span>
      <span>time</span><span>:</span> <span>(</span><span><span>{</span> time <span>}</span></span><span>)</span> <span>=&gt;</span> time<span>,</span>
      <span>playhead</span><span>:</span> <span>(</span><span><span>{</span> playhead <span>}</span></span><span>)</span> <span>=&gt;</span> playhead<span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>canvasSketch</span><span>(</span>sketch<span>,</span> settings<span>)</span><span>;</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Couple of things to note here. <code>createShader</code> bootstraps a default vertex shader (see below) that provides a varying <code>vUv</code>. This essentially maps the pixel coordinates to a value between 0 and 1. You can override this by specifying a custom vertex shader. But for most cases, this is sufficient.</p><p>vert.glsl</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>attribute</span> <span>vec3</span> position<span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>

<span>void</span> <span>main</span> <span>(</span><span>)</span> <span>{</span>
  gl_Position <span>=</span> <span>vec4</span><span>(</span>position<span>.</span>xyz<span>,</span> <span>1.0</span><span>)</span><span>;</span>
  vUv <span>=</span> gl_Position<span>.</span>xy <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">I’m also using a tool called <code>glslify</code> to wrap the shader code. This enables us to import GLSL modules into our shader. We’ll use it to import SDF functions and other raymarching utilities.</p><h3 id="the-raymarching-algorithm" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#the-raymarching-algorithm" aria-label="the raymarching algorithm permalink" color="brand.main" font-family="systemSans"></a>The Raymarching Algorithm</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Below is an implementation of the ray marching algorithm. The camera is positioned as the <code>rayOrigin</code>, and pointed towards the <code>rayTarget</code>—the center of the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The <code>rayDirection</code> is a vector that points from the origin towards a a pixel on the screen, while accounting for the camera’s orientation and field of view. It requires a bit of fancy math to figure out this direction. We’ll be using the <code>glsl-camera-ray</code> module to run that calculation.</p><p><img src="https://varun.ca/static/ray-direction-8b0a68215b4c83cd9236ca43e204a9da.svg" alt="Ray starts at the camera, goes through the pixel on the screen and moves through the scene" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">Once we obtain the ray direction, we proceed along it, checking for collisions. If a collision is detected, the distance to the surface is returned. Otherwise, we return <code>-1.0</code> to signify that no collision was found.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>

<span>float</span> <span>sdSphere</span><span>(</span><span>vec3</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span>

<span>const</span> <span>int</span> steps <span>=</span> <span>90</span><span>;</span>
<span>const</span> <span>float</span> maxdist <span>=</span> <span>20.0</span><span>;</span>
<span>const</span> <span>float</span> precis <span>=</span> <span>0.001</span><span>;</span>

<span>float</span> <span>raymarch</span><span>(</span><span>vec3</span> rayOrigin<span>,</span> <span>vec3</span> rayDir<span>)</span> <span>{</span>
  <span>float</span> latest <span>=</span> precis <span>*</span> <span>2.0</span><span>;</span>
  <span>float</span> dist <span>=</span> <span>0.0</span><span>;</span>
  <span>float</span> res <span>=</span> <span>-</span><span>1.0</span><span>;</span>

  <span>// March along the ray</span>
  <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> steps<span>;</span> i<span>++</span><span>)</span> <span>{</span>
    <span>// Break if we're close enough or too far away</span>
    <span>if</span> <span>(</span>latest <span>&lt;</span> precis <span>||</span> dist <span>&gt;</span> maxdist<span>)</span> <span>break</span><span>;</span>
    <span>// Get the SDF distance</span>
    <span>float</span> latest <span>=</span> <span>sdSphere</span><span>(</span>rayOrigin <span>+</span> rayDir <span>*</span> dist<span>,</span> <span>1.0</span><span>)</span><span>;</span>
    <span>// Increment by the latest SDF distance</span>
    dist <span>+=</span> latest<span>;</span>
  <span>}</span>
  <span>// if we're still within bounds,</span>
  <span>// set the result to the distance</span>
  <span>if</span> <span>(</span>dist <span>&lt;</span> maxdist<span>)</span> <span>{</span>
    res <span>=</span> dist<span>;</span>
  <span>}</span>

  <span>return</span> res<span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>

  <span>// Bootstrap a raymarching scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0.</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>float</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3"><code>lensLength</code> here determines the field of view. Try changing it to see how it affects the scene.</p><h3 id="using-glsl-modules-for-raymarching" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#using-glsl-modules-for-raymarching" aria-label="using glsl modules for raymarching permalink" color="brand.main" font-family="systemSans"></a>Using GLSL modules for raymarching</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Implementing your own raymarching function is cool. It’s especially useful when you want to tweak the inner workings to achieve a specific effect. However, in most cases, you can probably just use an off-the-shelf module.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Below, I’ve updated the sketch to use the <code>glsl-raytrace</code> module. Additionally, I’m using a <code>glsl-sdf-primitives</code> module to generate a torus and <code>glsl-rotate</code> to rotate it.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The mechanics remain largely similar. The key difference is that geometry is now defined within a function called <code>doModel</code>, and raymarch returns a <code>vec2</code> containing the distance and material index. This is useful if you want to render multiple types of objects in a scene.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>
<span>uniform</span> <span>float</span> time<span>;</span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span><span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> raymarch <span>=</span> <span>require</span><span>(</span></span><span>'glsl-raytrace'</span><span><span>,</span> map <span>=</span> doModel<span>,</span> steps <span>=</span> <span>90</span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> sdTorus <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-primitives/sdTorus'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> rotate <span>=</span> <span>require</span><span>(</span></span><span>'glsl-rotate/rotate'</span><span><span>)</span></span></span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>// Spin the shape</span>
  p<span>.</span>xy <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>xy<span>,</span> time<span>)</span><span>;</span>
  p<span>.</span>yz <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>yz<span>,</span> time<span>)</span><span>;</span>
  <span>// Calculate SDF distance</span>
  <span>float</span> d <span>=</span> <span>sdTorus</span><span>(</span>p<span>,</span> <span>vec2</span><span>(</span><span>0.75</span><span>,</span> <span>0.35</span><span>)</span><span>)</span><span>;</span>
  <span>return</span> <span>vec2</span><span>(</span>d<span>,</span> <span>0.0</span><span>)</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>
  <span>// Bootstrap a raytracing scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Check it out! We’ve got a spinning donut 🍩 But it looks kinda flat. Let’s add some depth to the scene.</p><h3 id="calculating-normals" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#calculating-normals" aria-label="calculating normals permalink" color="brand.main" font-family="systemSans"></a>Calculating normals</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">For the classic material and lighting combination, we need to calculate surface normals. That is, a vector that points away from the surface at a given point.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">With SDFs, we calculate the normal by taking the gradient of the SDF function (f) at a specific point, denoted as ∇f. I don’t know about you, but the last time I took a gradient was in <a href="https://apps.ualberta.ca/catalogue/course/mec_e/537" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">MEC E 537 - Aerodynamics</a>. And that was a while ago 😅</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Luckily for us, we can use the <code>glsl-sdf-normal</code> module to compute normals for us. The module uses the same <code>doModel</code> function that we defined for raymarching. If you’re curious about the underlying math, check out <a href="https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#surface-normals-and-lighting" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Jamie Wong’s explanation</a>.</p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> normal <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-normal'</span><span><span>,</span> map <span>=</span> doModel<span>)</span></span></span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>
  <span>// Convert the normal to a color</span>
  color <span>=</span> nor <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span>

<span>// ...</span></code></pre></div><h3 id="phong-lighting" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#phong-lighting" aria-label="phong lighting permalink" color="brand.main" font-family="systemSans"></a>Phong lighting</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My personal philosophy is very much:</p><p><img alt="Fuck around find out" src="https://varun.ca/static/fuck-around-find-out-cc2e14bf2895e5634f02f2f2475d8531.jpg" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">It’s important to understand how things work, but I’m less focused on implementing everything from scratch and more intrigued by applying those concepts to create my own sketches and scenes. That’s why I was super excited to come across <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl/packages</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The stackgl ecosystem is full of little GLSL modules that you can glue these together to create all kinds of effects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Interested in adding lighting to the scene? What type would you prefer? Lambert, Phong, Beckmann, or Specular? Just grab the associated module and plug it into the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I chose <code>glsl-specular-blinn-phong</code></p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> blinnPhongSpec <span>=</span> <span>require</span><span>(</span></span><span>'glsl-specular-blinn-phong'</span><span><span>)</span></span></span>

<span>// ...</span>

<span>vec3</span> lightPos <span>=</span> <span>vec3</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>vec3</span> tint <span>=</span> <span>vec3</span><span>(</span><span>0.05</span><span>,</span> <span>0.0</span><span>,</span> <span>0.97</span><span>)</span><span>;</span> <span>// color of the shape</span>

<span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

<span>// If the ray collides, draw the surface</span>
<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>// Calculate light intensity</span>
  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>// light intensity * color of the shape</span>
  color <span>=</span> power <span>*</span> tint<span>;</span>
<span>}</span></code></pre></div><h3 id="iridescent-material" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#iridescent-material" aria-label="iridescent material permalink" color="brand.main" font-family="systemSans"></a>Iridescent material</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Stackgl isn’t the only place where you can find useful code. My other favourite option is Shadertoy. I’m not going to lie, most things on shadertoy were too daunting for me. I couldn’t even begin to figure out what the code was doing.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">That is, until I discovered that most work on shadertoy uses a combo of raymarching + SDF. This was certainly a lightbulb moment for me. It’s like suddenly this cryptic code was deciphered and I could understand what it said.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I’ve been obsessed with iridescence and have been bookmarking cool shaders. Once I learnt the raymarching technique, that was it. I could revisit these shaders and try to understand how they work.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">One such shader was <a href="https://www.shadertoy.com/view/llcXWM" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Thomas Hooper’s Crystals</a>. It’s way more complex than our scene but the general structure is the same. There’s a function for generating the geometry, there’s raymarching loop and after checking for collision is the bit where the iridescence effect is applied.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Let’s add that to our scene.</p><div data-language="glsl"><pre><code><span>vec3</span> <span>pal</span><span>(</span> <span>in</span> <span>float</span> t<span>,</span> <span>in</span> <span>vec3</span> a<span>,</span> <span>in</span> <span>vec3</span> b<span>,</span> <span>in</span> <span>vec3</span> c<span>,</span> <span>in</span> <span>vec3</span> d <span>)</span> <span>{</span>
  <span>return</span> a <span>+</span> b<span>*</span><span>cos</span><span>(</span> <span>6.28318</span><span>*</span><span>(</span>c<span>*</span>t<span>+</span>d<span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>spectrum</span><span>(</span><span>float</span> n<span>)</span> <span>{</span>
  <span>return</span> <span>pal</span><span>(</span> n<span>,</span> <span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>1.0</span><span>,</span><span>1.0</span><span>,</span><span>1.0</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.0</span><span>,</span><span>0.33</span><span>,</span><span>0.67</span><span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>const</span> <span>float</span> GAMMA <span>=</span> <span>2.2</span><span>;</span>

<span>vec3</span> <span>gamma</span><span>(</span><span>vec3</span> color<span>,</span> <span>float</span> g<span>)</span> <span>{</span>
  <span>return</span> <span>pow</span><span>(</span>color<span>,</span> <span>vec3</span><span>(</span>g<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>linearToScreen</span><span>(</span><span>vec3</span> linearRGB<span>)</span> <span>{</span>
  <span>return</span> <span>gamma</span><span>(</span>linearRGB<span>,</span> <span>1.0</span> <span>/</span> GAMMA<span>)</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>

  <span>// Iridescent lighting</span>
  <span>vec3</span> reflection <span>=</span> <span>reflect</span><span>(</span>rayDirection<span>,</span> nor<span>)</span><span>;</span>
  <span>vec3</span> dome <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// base layer</span>
  <span>vec3</span> perturb <span>=</span> <span>sin</span><span>(</span>pos <span>*</span> <span>10.</span><span>)</span><span>;</span>
  color <span>=</span> <span>spectrum</span><span>(</span><span>dot</span><span>(</span>nor <span>+</span> perturb <span>*</span> <span>.05</span><span>,</span> eyeDirection<span>)</span> <span>*</span> <span>2.</span><span>)</span><span>;</span>
  <span>// specular</span>
  <span>float</span> specular <span>=</span> <span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>;</span>
  specular <span>=</span> <span>pow</span><span>(</span><span>(</span><span>sin</span><span>(</span>specular <span>*</span> <span>20.</span> <span>-</span> <span>3.</span><span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>.5</span><span>)</span> <span>+</span> <span>.1</span><span>,</span> <span>32.</span><span>)</span> <span>*</span> specular<span>;</span>
  specular <span>*=</span> <span>.1</span><span>;</span>
  specular <span>+=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span> <span>+</span> <span>.3</span><span>,</span> <span>8.</span><span>)</span> <span>*</span> <span>.1</span><span>;</span>
  <span>// shadow</span>
  <span>float</span> shadow <span>=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>nor<span>,</span> dome<span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>1.2</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>,</span> <span>3.</span><span>)</span><span>;</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">There are three layers to the iridescent material: the base layer (the funky gradients), a little bit of shadow and specular (the concentric light bands). Try toggling them on and off with the slider see their effects.</p><h3 id="mix-phong-and-iridescence" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#mix-phong-and-iridescence" aria-label="mix phong and iridescence permalink" color="brand.main" font-family="systemSans"></a>Mix Phong and Iridescence</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">One last little tweak with the lighting. We can actually blend the phong and iridescence effects. Which enables you to have tinted iridescent objects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">There’s not a whole lot to it. Calculate the colors for the two effects and then blend them with the <code>mix</code> function.</p><div data-language="glsl"><pre><code><span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>// Basic blinn phong lighting</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>vec3</span> baseColor <span>=</span> power <span>*</span> tint<span>;</span>

  <span>// Iridescent lighting</span>
  <span>// ...</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// mix blinn phong lighting and iridescent lighting</span>
  color <span>=</span> <span>mix</span><span>(</span>baseColor<span>,</span> color<span>,</span> mixBaseAndIridescent<span>)</span><span>;</span>
  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><h3 id="crystal-geometry" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#crystal-geometry" aria-label="crystal geometry permalink" color="brand.main" font-family="systemSans"></a>Crystal geometry</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">We’ve nailed the look, but what about the crystal shape?</p><p font-family="systemSans" color="neutral.0" font-size="2,3">You can file this under “stuff I don’t quite understand, but that’s not going to stop me from using it.” The crystal geometry is a Rhombic Triacontahedron, which I discovered in a <a href="https://www.youtube.com/watch?v=0RWaR7zApEo&amp;t=50s" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">The Art Of Code tutorial</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">This shape is created by folding a plane onto itself using some “magic numbers” and along a “magic direction.” We repeat the process a few times until we achieve the desired crystal shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Try using the slider to observe how the shape changes with each fold.</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCrystal</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>float</span> c <span>=</span> <span>cos</span><span>(</span><span>3.1415</span><span>/</span><span>5.</span><span>)</span><span>,</span> s<span>=</span><span>sqrt</span><span>(</span><span>0.75</span><span>-</span>c<span>*</span>c<span>)</span><span>;</span> <span>// magic numbers</span>
  <span>vec3</span> n <span>=</span> <span>vec3</span><span>(</span><span>-</span><span>0.5</span><span>,</span> <span>-</span>c<span>,</span> s<span>)</span><span>;</span> <span>// magic direction</span>

  <span>// fold the space to add symmetry</span>
  p <span>=</span> <span>abs</span><span>(</span>p<span>)</span><span>;</span>
  <span>// fold along the n direction</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// fold the space again and along the n direction</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// repeat the process</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// distance to the surface</span>
  <span>float</span> d <span>=</span> p<span>.</span>z <span>-</span> <span>1.</span><span>;</span>
  <span>return</span> d<span>;</span>
<span>}</span></code></pre></div></div></div><h2 id="and-thats-that" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#and-thats-that" aria-label="and thats that permalink" color="brand.main" font-family="systemSans"></a>And that’s that!</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Raymarching with SDF isn’t better than the conventional mesh based approach; it’s just different. However, it offers the ability to create unique and visually striking effects, making it a fantastic tool to have in your creative coding toolbox. Plus, with glslify and the <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl ecosystem</a> you can use off-the-shelf modules to get going quickly.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Checkout the <a href="https://github.com/winkerVSbecks/shader-sketches/blob/main/sketches/sdf-iridescent-crystal.js" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">full source</a> for the crystal sketch on Github. Want to take it a step further? I’ve expanded this sketch to combine refraction and iridescence to make a <a href="https://github.com/winkerVSbecks/shader-sketches/blob/main/sketches/refraction-iridescent.js" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">see through crystal</a>.</p><h3 id="reference" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#reference" aria-label="reference permalink" color="brand.main" font-family="systemSans"></a>Reference</h3><ul><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://jasmcole.com/2019/10/03/signed-distance-fields/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Signed distance fields by Jason Cole</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://iquilezles.org/articles/distfunctions/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">3D distance functions by Inigo Quilez</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://www.shadertoy.com/view/ldfSWs" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Raymarching template</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://youtu.be/NCpaaLkmXI8" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Bending Light by The Art of Code (part 1)</a> &amp; <a href="https://youtu.be/0RWaR7zApEo" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">part 2</a></li></ul></article><p font-size="2" font-family="systemSans" color="neutral.0">Questions, Comments or Suggestions?<!-- --> <a href="https://github.com/winkerVSbecks/varun.ca/issues/new?title=Iridescent%20crystal%20with%20raymarching%20and%20signed%20distance%20fields" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Open an Issue</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monday was hottest day for global average temperature, as climate crisis bites (140 pts)]]></title>
            <link>https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites</link>
            <guid>36591402</guid>
            <pubDate>Tue, 04 Jul 2023 19:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites">https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites</a>, See on <a href="https://news.ycombinator.com/item?id=36591402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>This Monday, 3 July 2023, was the hottest day ever recorded globally, according to data from the US National Centers for Environmental Prediction.</p><p>The average global temperature reached 17.01C (62.62F), surpassing the August 2016 record of 16.92C (62.46F), as heatwaves sizzled around the world.</p><figure id="80976557-4cfe-4dfe-a401-391b7535fb9d" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/environment/2023/jul/04/climate-heating-el-nino-has-arrived-and-threatens-lives-declares-un&quot;,&quot;text&quot;:&quot;Climate-heating El Niño has arrived and threatens lives, declares UN&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;80976557-4cfe-4dfe-a401-391b7535fb9d&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}"></gu-island></figure><p>The southern US has <a href="https://www.theguardian.com/us-news/2023/jul/01/texas-extreme-heat-heatwave">been suffering</a> under an <a href="https://www.theguardian.com/us-news/2023/jul/03/heat-dome-keeps-new-orleans-broiling-with-heat-index-as-high-as-110f">intense heat dome</a> in recent weeks amid <a href="https://www.theguardian.com/world/extreme-weather">extreme weather</a>, probably driven by the human-caused climate crisis, <a href="https://www.theguardian.com/environment/2023/jun/27/heatwave-human-caused-climate-crisis-texas-louisiana-mexico">experts said</a>. In parts of China, an <a href="https://www.theguardian.com/world/2023/jun/30/as-beijing-swelters-activists-hope-the-heat-will-prompt-climate-action">enduring heatwave</a> continued, with temperatures above 35C (95F). North Africa has seen temperatures near 50C (122F), with, in the Middle East, <a href="https://www.theguardian.com/world/2023/jun/30/thousands-suffer-heat-stress-on-hajj-pilgrimage-as-temperatures-reach-48c">thousands suffering</a> from unusually scorching heat during the hajj religious pilgrimage in Saudi Arabia.</p><p>And even <a href="https://www.theguardian.com/world/antarctica">Antarctica</a>, currently in its winter, registered anomalously high temperatures, as <a href="https://www.theguardian.com/science/2023/may/25/slowing-ocean-current-caused-by-melting-antarctic-ice-could-have-drastic-climate-impact-study-says">glacier melt</a> accelerates and the sun intensifies. Ukraine’s Vernadsky research base, in the vast frozen continent’s Argentine Islands, recently broke its July temperature record with a reading of 8.7C (47.6F).</p><p>Jeni Miller, executive director of the California-based Global Climate and Health Alliance, an international consortium of health organizations, said: “People around the world are already enduring climate impacts, from heatwaves, wildfires and air pollution to floods and extreme storms. Global warming is also exacerbating crop losses and the spread of infectious diseases, as well as migration.”</p><p>She added: “The extraction and use of coal, oil and gas harm people’s health, are the primary driver of warming and are incompatible with a healthy climate future. That’s all the more reason that governments must prepare to deliver a commitment at <a href="https://www.theguardian.com/environment/cop28">Cop28</a> to phase out all fossil fuels, and a just transition to renewable energy for all.”</p><p>Climate scientist Friederike Otto of the Grantham Institute for Climate Change and the Environment at Britain’s Imperial College London, said: “It’s a death sentence for people and ecosystems.”</p><p>Scientists lamented the climate crisis, accelerated by the <a href="https://www.theguardian.com/environment/2023/jul/04/climate-heating-el-nino-has-arrived-and-threatens-lives-declares-un">El Niño weather pattern</a>, the latest of which the United Nations’ World Meteorological Organization (WMO) warned this week had begun. The last major <a href="https://www.theguardian.com/environment/elnino">El Niño</a> was in 2016, which was the hottest year on record – until now.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-9">skip past newsletter promotion</a><p id="EmailSignup-skip-link-9" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Of the new temperature record announced on Tuesday, Zeke Hausfather, a research scientist at Berkeley Earth, said: “Unfortunately, it promises to only be the first in a series of new records set this year as increasing emissions of [carbon dioxide] and greenhouse gases, coupled with a growing El Niño event, push temperatures to new highs.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Type system updates: moving from research into development (258 pts)]]></title>
            <link>https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/</link>
            <guid>36591313</guid>
            <pubDate>Tue, 04 Jul 2023 19:11:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/</a>, See on <a href="https://news.ycombinator.com/item?id=36591313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p>A year ago, at ElixirConf EU 2022, we announced an effort to research
and develop a type system for Elixir (<a href="https://www.youtube.com/watch?v=Jf5Hsa1KOc8">video presentation</a>)
(<a href="https://elixir-lang.org/blog/2022/10/05/my-future-with-elixir-set-theoretic-types/">written report</a>).</p>

<p>This work is happening under the lead of <a href="https://www.irif.fr/~gc/">Giuseppe Castagna</a>,
CNRS Senior Researcher, and taken by
<a href="https://www.irif.fr/users/gduboc/index">Guillaume Duboc</a> as part of his
PhD studies, with further guidance from myself (José Valim).</p>

<p>This article is a summary of where we are in our efforts and where we
are going.</p>

<h2 id="out-of-research">Out of research</h2>

<p>Our main goal during research is to find a type system that can model
most of Elixir’s functional semantics and develop brand new theory on
the areas we found to be incompatible or lacking. We believe we were
able to achieve this goal with a gradual set-theoretic type system
and we are now ready to head towards development. Over the last 2 months,
we have published plenty of resources on our results:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2306.06391">A technical report on the design principles of the Elixir type system</a></li>
  <li><a href="https://youtube.com/watch?v=gJJH7a2J9O8">A technical presentation by Guillaume Duboc at ElixirConf 2023 on the work above</a></li>
  <li><a href="https://smartlogic.io/podcast/elixir-wizards/s10-e12-jose-guillaume-giuseppe-types-elixir/">An informal discussion with Giuseppe Castagna, Guillaume Duboc, and José Valim on the SmartLogic podcast</a></li>
  <li><a href="https://www.twitch.tv/videos/1841707383">An informal Q&amp;A with Guillaume Duboc, José Valim, and the community on Twitch</a></li>
</ul>

<p>Our focus so far has been on the semantics. While we have introduced a
new syntax capable of expressing the semantics of the new set-theoretic
type system, the syntax is not final as there are still no concrete
plans for user-facing changes to the language. Once we are confident
those changes will happen, we will have plenty of discussion with the
community about the type system interface and its syntax.</p>

<p>The work so far has been made possible thanks to a partnership between
the <a href="https://www.cnrs.fr/fr">CNRS</a> and <a href="https://remote.com/">Remote</a>,
with sponsorships from <a href="https://www.fresha.com/">Fresha</a>,
<a href="https://supabase.com/">Supabase</a>, and <a href="https://dashbit.co/">Dashbit</a>.</p>



<p>While there is still on-going research, our focus for the second semester
of 2023 onwards is on development.</p>

<p>Incorporating a type system into a language used at scale can be a daunting
task. Our concerns range from how the community will interact and use the
type system to how it will perform on large codebases. Therefore, our plan
is to gradually introduce our gradual (pun intended) type system into the
Elixir compiler.</p>

<p>In the first release, types will be used just internally by the compiler.
The type system will extract type information from patterns and guards to
find the most obvious mistakes, such as typos in field names or type
mismatches from attempting to add an integer to a string, without introducing
any user-facing changes to the language. At this stage, our main goal is
to assess the performance impact of the type system and the quality of
the reports we can generate in case of typing violations. If we are
unhappy with the results, we still have time to reassess our work or drop
the initiative altogether.</p>

<p>The second milestone is to introduce type annotations only in structs,
which are named and statically-defined in Elixir codebases. Elixir programs
frequently pattern match on structs, which reveals information about
the struct fields, but it knows nothing about their respective types.
By propagating types from structs and their fields throughout the program,
we will increase the type system’s ability to find errors while further
straining our type system implementation.</p>

<p>The third milestone is to introduce the (most likely) <code>$</code>-prefixed type
annotations for functions, with no or very limited type reconstruction:
users can annotate their code with types, but any untyped parameter
will be assumed to be of the <code>dynamic()</code> type. If successful, then we
will effectively have introduced a type system into the language.</p>

<p>This new exciting development stage is sponsored by <a href="https://www.fresha.com/">Fresha</a> (<a href="https://www.fresha.com/careers/openings?department=engineering">they are hiring!</a>),
<a href="https://starfish.team/">Starfish*</a> (<a href="https://starfish.team/jobs/experienced-elixir-developer">they are hiring!</a>),
and <a href="https://dashbit.co/">Dashbit</a>.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Designing a Language Without a Parser (107 pts)]]></title>
            <link>https://thunderseethe.dev/posts/type-inference/</link>
            <guid>36591079</guid>
            <pubDate>Tue, 04 Jul 2023 18:52:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thunderseethe.dev/posts/type-inference/">https://thunderseethe.dev/posts/type-inference/</a>, See on <a href="https://news.ycombinator.com/item?id=36591079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="intro">Intro
<a href="#intro">
<span>Link to heading</span></a></h2><p>I’d like to design a language, more specifically implement a compiler for a programming language I’ve made up. This is not the first time I’ve wanted to do this. In fact, I’ve had the <a href="https://github.com/thunderseethe/waht" target="_blank" rel="noopener">itch</a> <a href="https://github.com/thunderseethe/panera" target="_blank" rel="noopener">quite a</a> <a href="https://github.com/thunderseethe/brainfuck_interpreter" target="_blank" rel="noopener">few</a> <a href="https://github.com/thunderseethe/false_interpreter" target="_blank" rel="noopener">times</a> <a href="https://github.com/thunderseethe/tiger" target="_blank" rel="noopener">before</a>. I can’t tell you why I keep returning to this venture when I’ve failed at it so many times. What I can tell you is why I always fail. Every time I begin a sparkly new project with fresh eyes and quickly whip together a lexer.</p><p>However, once I start constructing a parser, progress slows to a crawl. I endlessly struggle with bikeshedding my syntax or fret to figure out my operator precedence. Without fail by the time I’ve managed to produce an Abstract Syntax Tree (AST) I’ve lost all steam. The language is added to my ever-growing pile of incomplete side projects doomed to forever be an empty repository of listless aspirations. The more attempts I’ve made the clearer this pattern has become to me.</p><p>So let’s take a step back, why do I start with the lexer and parser at all? Compiler construction can be thought of as a couple of big steps where the output of each step is fed as input into the next step:</p><p><img src="https://thunderseethe.dev/img/compiler_pipeline.svg" alt="Infographic for Compiler Pipeline"></p><p>Because the compiler executes these steps in order when it runs, it’s natural to think about creating them in order. The problem is compounded by the educational material on creating languages. Teaching material focuses a <strong>lot</strong> on the many methods by which you can parse text. It’s to the point that the wonderful <a href="https://craftinginterpreters.com/" target="_blank" rel="noopener">Crafting Interpreters</a> felt the need to include <a href="https://craftinginterpreters.com/compiling-expressions.html#design-note" target="_blank" rel="noopener">a note</a> explaining why they are brushing over parsing. This over emphasis on parsing could lead one (certainly led me) to believe that parsing is the best place to start on a new language. However, there’s no rule that states things have to be created in this order. In fact, doing things this way is impractical if you’re designing a language from scratch. Trying to create syntax for your language without first knowing its semantics is a trap. It’s like trying to design a vehicle’s interior without knowing how many wheels it will have or how its engine will power them. You might design the interior to comfortably seat 4, but if you discover down the line you’re designing a motorcycle you’re in trouble!</p><p>So how do I overcome my parsing problem? I’ll simply not write a lexer or parser. I can’t get stuck writing a parser if I don’t start writing one. I can come back later and add a parser once I’ve designed more of the internals of my language. My hope is having the other steps (Type Checking, Code Generation, etc.) will provide a guiding hand for what my parser should look like when I do eventually write one. The goal of writing a parser is to produce an AST. But we don’t have to parse our AST out of text during prototyping, we can design an AST and then construct it ad hoc where we need it. Then the question is, if we’re not starting with lexing/parsing, then what step do we start with? The answer is type inference (surprise), but it’s relevant to answer why we’re starting with type inference.</p><p>To understand why we’re starting with our types, look no further than the explanation in <a href="http://www.cs.cmu.edu/~rwh/pfpl.html" target="_blank" rel="noopener">Practical Foundations for Programming Languages</a>:</p><blockquote><p>Types are the central organizing principle of the theory of programming languages. Language features are the manifestations of type structure. The syntax of a language is governed by the constructs that define its types, and its semantics is determined by the interactions among those constructs.</p></blockquote><p>Types inform every other part of our language design, so it’s important we nail them down first. Conversely, once we’ve designed our types the syntax and semantics of our language should easily fall out of our type system.</p><h2 id="background">Background
<a href="#background">
<span>Link to heading</span></a></h2><p>This article will not be a great introduction to programming language design in general. There are already a lot of great resources for that:</p><ul><li><a href="https://craftinginterpreters.com/" target="_blank" rel="noopener">Crafting Interpreters</a></li><li><a href="https://www.cis.upenn.edu/~bcpierce/tapl/" target="_blank" rel="noopener">Types and Programming Languages</a></li></ul><p>We’re focused on implementing type inference (For brevity, we won’t even cover definitions of types, polymorphism, or ASTs). None of the ideas I’m covering here are new. My aspirations with this post are to coalesce good ideas I’ve found in disparate sources. I’ve cobbled together an idea of how to do type inference from reading these sources, and looking at the source code of rustc and GHC. I couldn’t find a good resource that tied all the concepts together, so I decided to write one.</p><p>We’ll build our language in Rust. One might wonder why we’d pick a low level language like Rust, and why not a higher level language that is less verbose such as Haskell or OCaml. These languages are often featured in literature on compilers, and for good reason. They make expressing the tree traversals involved in compilation very natural. However, I don’t know OCaml. I’m more familiar with Haskell, but our type inference will make heavy use of mutation which makes the immutable purity of Haskell a poor fit. Rust has enough features to be functional for our tree traversals while still allowing for mutation. So we’ll be using Rust, if you’re unfamiliar <a href="https://cheats.rs/" target="_blank" rel="noopener">cheats.rs</a> has a dense rundown to get you up to speed.</p><h2 id="abstract-syntax-tree-ast">Abstract Syntax Tree (AST)
<a href="#abstract-syntax-tree-ast">
<span>Link to heading</span></a></h2><p>The whole point of parsing is to convert a text file into an AST. Since we’re skipping over parsing, we’ll start with an AST already constructed. If you’d like a refresher on ASTs check out <a href="https://ruslanspivak.com/lsbasi-part7/" target="_blank" rel="noopener">this blog post</a>. Our language is new, so we’ll start small and add more fancy AST nodes incrementally. Initially, our AST will have just 4 nodes: variables, integer literals, function literals, and function application:</p><div><pre tabindex="0"><code data-lang="rs"><span><span><span>enum</span> <span>Ast</span><span>&lt;</span>V<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>  </span><span>/// A local variable
</span></span></span><span><span><span></span><span>  </span>Var(V),<span>
</span></span></span><span><span><span>  </span><span>/// An integer literal
</span></span></span><span><span><span></span><span>  </span>Int(<span>isize</span>),<span>
</span></span></span><span><span><span>  </span><span>/// A function literal 
</span></span></span><span><span><span></span><span>  </span><span>/// (lambda, closure, etc.)
</span></span></span><span><span><span></span><span>  </span>Fun(V,<span> </span>Box<span>&lt;</span>Self<span>&gt;</span>),<span>
</span></span></span><span><span><span>  </span><span>/// Function application
</span></span></span><span><span><span></span><span>  </span>App(Box<span>&lt;</span>Self<span>&gt;</span>,<span> </span>Box<span>&lt;</span>Self<span>&gt;</span>),<span> 
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>It doesn’t get much simpler than this. This isn’t really enough for a usable language, although it is Turing complete. For our purposes, it’s plenty to get a minimal type inference system set up. We parameterize our AST by a type parameter <code>V</code>. <code>V</code> will be the variable of our AST used in <code>Var</code> and <code>Fun</code>. Initially our AST variable type parameter will be:</p><p>For simplicity, we’ll represent variables as a <code>usize</code>. We can imagine these might be interned strings in a more sophisticated compiler. Once we type check our AST, each variable will be annotated with its type:</p><div><pre tabindex="0"><code data-lang="rs"><span><span><span>struct</span> <span>TypedVar</span>(Var,<span> </span>Type);<span>
</span></span></span></code></pre></div><p>Rust requires a layer of indirection for recursive types. Boxing values will make our code samples pretty noisy, let’s define some helper methods to hide that noise:</p><div><pre tabindex="0"><code data-lang="rs"><span><span><span>impl</span><span>&lt;</span>V<span>&gt;</span><span> </span>Ast<span>&lt;</span>V<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>  </span><span>fn</span> <span>fun</span>(<span>
</span></span></span><span><span><span>    </span>arg: <span>V</span>,<span> 
</span></span></span><span><span><span>    </span>body: <span>Self</span><span>
</span></span></span><span><span><span>  </span>)<span> </span>-&gt; <span>Self</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Self::Fun(<span>
</span></span></span><span><span><span>      </span>arg,<span> 
</span></span></span><span><span><span>      </span>Box::new(body))<span>
</span></span></span><span><span><span>  </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>fn</span> <span>app</span>(<span>
</span></span></span><span><span><span>    </span>fun: <span>Self</span>,<span> 
</span></span></span><span><span><span>    </span>arg: <span>Self</span><span>
</span></span></span><span><span><span>  </span>)<span> </span>-&gt; <span>Self</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Self::App(<span>
</span></span></span><span><span><span>      </span>Box::new(fun),<span> 
</span></span></span><span><span><span>      </span>Box::new(arg))<span>
</span></span></span><span><span><span>  </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><h2 id="type">Type
<a href="#type">
<span>Link to heading</span></a></h2><p>Before we can begin inferring types, we have to know what types can be inferred. Our <code>Type</code> type (ha) is determined by our <code>Ast</code>. We need a type to cover each possible value our <code>Ast</code> could produce. Since our <code>Ast</code> only has 4 cases, we can check each one and determine what values they can produce:</p><ul><li><code>Var</code> - it produces any value <code>AST</code> produces (but is not a value itself)</li><li><code>Int</code> - Integer literals are values and will need a type, the type of integers</li><li><code>Fun</code> - Function literals are also values and will need a type, the type of functions</li><li><code>App</code> - Function application will return a value when evaluated, but the application case itself is not a value.</li></ul><p>So we have two values we can produce from our <code>Ast</code>: <code>Int</code>, and <code>Fun</code>. We need two types for these values. We also need a type for type variables; these won’t be for any values but allow us to support polymorphism. Knowing all this we can lay out <code>Type</code>:</p><div><pre tabindex="0"><code data-lang="rs"><span><span><span>struct</span> <span>TypeVar</span>(<span>u32</span>);<span>
</span></span></span><span><span><span></span><span>enum</span> <span>Type</span><span> </span>{<span>
</span></span></span><span><span><span>  </span><span>// A type variable
</span></span></span><span><span><span></span><span>  </span>Var(TypeVar),<span>
</span></span></span><span><span><span>  </span><span>// Type of integers
</span></span></span><span><span><span></span><span>  </span>Int,<span>
</span></span></span><span><span><span>  </span><span>// Type of functions
</span></span></span><span><span><span></span><span>  </span>Fun(Box<span>&lt;</span>Self<span>&gt;</span>,<span> </span>Box<span>&lt;</span>Self<span>&gt;</span>),<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Similar to <code>Var</code>, our <code>TypeVar</code> is just a number under the hood. Our <code>Type</code> is a recursive tree, same as <code>AST</code>, so we have to box our nodes. We introduce similar helper methods to alleviate the boxing:</p><div><pre tabindex="0"><code data-lang="rs"><span><span><span>impl</span><span> </span>Type<span> </span>{<span>
</span></span></span><span><span><span>  </span><span>fn</span> <span>fun</span>(<span>
</span></span></span><span><span><span>    </span>arg: <span>Self</span>,<span> 
</span></span></span><span><span><span>    </span>ret: <span>Self</span><span>
</span></span></span><span><span><span>  </span>)<span> </span>-&gt; <span>Self</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Self::Fun(<span>
</span></span></span><span><span><span>      </span>Box::new(arg),<span> 
</span></span></span><span><span><span>      </span>Box::new(ret))<span>
</span></span></span><span><span><span>  </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><h2 id="type-inference-algorithm">Type Inference Algorithm
<a href="#type-inference-algorithm">
<span>Link to heading</span></a></h2><p>At a high level, the goal of type inference is to use contextual information from our AST to infer the type of each AST node. In trivial cases this is very easy when we see an <code>Int</code> AST node we know it always has type <code>Int</code>. It’s not always so straightforward, though. If we want to know the type of an <code>App</code> node, we have to look at the return type of the function of that <code>App</code> node. However, we may not know the type of that function yet. The function might be a variable that refers to an input parameter to our overall AST term. In that case we can’t know the type of our function until we know the type of our whole term, which seems circular. The way to break up this circular reasoning is by waiting to infer our type until we have enough information to do so. Instead of inferring a type immediately, when we encounter a type we don’t know, we’ll track some constraints about that type. Then once we’ve walked our entire AST we should have enough constraints to infer all our types.</p><p>That sounds a little hand wavy; how can we be sure we’ll always generate enough constraints to figure out our types? The answer is <strong>math</strong>! I won’t go into details here, but we’ll lean on some very nifty proofs a lot of folks worked on to guide us to a type system that is always inferrable. For more information, look into the <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system" target="_blank" rel="noopener">Hindley-Milner (HM) type system</a>.</p><p>So we’re going to track information about types. We do this on our type variables since they represent unknown types. When we encounter a node, we’ll give it a fresh type variable and emit a constraint on that variable. Any other nodes that rely on that node will reuse its type variable, producing their own constraints on that variable. This is the basis for implementations of the HM type system such as <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Algorithm_J" target="_blank" rel="noopener">Algorithm J</a>, or its cousin Algorithm W. There’s a key difference between those implementations and ours though. Algorithm J attempts to solve constraints as soon as it encounters them and uses a clever data structure to avoid the circular reasoning we saw earlier. Our implementation will instead generate all constraints in one pass and then solve them all in a separate pass. We can visualize this as 3 separate passes: constraint generation, constraint solving, and a final type substitution.</p><p><img src="https://thunderseethe.dev/img/type_inference_algorithm.svg" alt="Type Inference Algorithm"></p><p>This split into constraint generation followed by constraint solving offers some nice properties over the “solve as you go” solution. Because we generate a set of constraints from the AST and then solve them, constraint solving only has to know about constraints and nothing about the AST. This means constraint solving requires no modifications when we change our AST. Right now while we have 4 AST nodes the benefit is small, but most languages have 100+ AST nodes. Being able to handle all these cases in constraint generation and not have them bleed over into constraint solving is a huge win for managing complexity. An explicit list of constraints can also make error reporting easier. We can associate a span with each constraint. Then use these spans help to print smarter error messages on a type error. LambdaAle has a great talk by Simon Peyton Jones <a href="https://www.youtube.com/watch?v=-TJGhGa04F8&amp;t=2731s" target="_blank" rel="noopener">Type Inference as Constraint Solving</a> that goes over the benefits in more detail.</p><p>We’ll put a pin our type inference aspirations here. Our AST, Type, and type inference algorithm provide a strong foundation for our implementation. In our <a href="https://thunderseethe.dev/posts/bidirectional-constraint-generation">next post</a> we’ll implement constraint generation using a bidirectional type system.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to build a website without frameworks and tons of libraries (438 pts)]]></title>
            <link>https://www.kodingkitty.com/blog/how-to-build-a-website/</link>
            <guid>36591032</guid>
            <pubDate>Tue, 04 Jul 2023 18:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kodingkitty.com/blog/how-to-build-a-website/">https://www.kodingkitty.com/blog/how-to-build-a-website/</a>, See on <a href="https://news.ycombinator.com/item?id=36591032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
An innocent question <a href="https://www.indiehackers.com/post/21-websites-for-free-illustrations-29a45232db" target="_blank">was posted</a> on IndieHackers the other day:
<span>"I'm asking what did you use to build your website"</span>.
    </p><p>
The question also had a second part.
So just to be fair, here it is in its entirety: <span>"I'm asking what did you use to build your website, I really love the design and feeling of kodingkitty."</span></p><p>
But this post is not about people loving our website.
Although we're obviously happy about that.
    </p><p>
Too lazy to read? <a href="#kittys-tool-chain">Check out Koding Kitty's simple toolchain</a>.
      </p><h2>The shocking truth</h2><p>
The question sparked an idea to write about the tech stack that KodingKitty team uses for its own web.
And we warn you beforehand: it's so simple that some of you might find it shocking.
    </p><p>
You have been warned.
    </p><h2>Hype is just a coincidence</h2><p>
Our tech stack has nothing to do with the current hype about lightweight or simplified web development.
Not everyone rides that wave, and that's fine.
    </p><p>
On the other hand, we believe that in many cases, "back to the roots" or "simplicity is the ultimate perfection" is a better solution for customers than convoluted web of overused frameworks and libraries.
    </p><p>
To put it another way, the solution we designed for our website and the current hype is just a coincidence.
Our stack is simple because we wanted something pragmatic with minimal friction for the developers.
    </p><p>
And even though we wanted Koding Kitty website to have a distinctive yet subtle design, it is important to mention that it could have been achieved in many other ways.
    </p><h2>Comparing options</h2><p>
Our website and the way it is built comes from our past experience.
    </p><p>
We had the chance to work with different web frameworks in the past.
We know this is a luxury not everyone has.
It has allowed us to compare different technologies and decide what works best for us.
    </p><p>
From the beginning we agreed to start with a static website.
After all, what does a kitty's web really need?
A front page, a showcase, a blog ... and probably not much more.
At least in the beginning.
    </p><h2>Our requirements</h2><p>
We set the following set of requirements:
    </p><ul><li>Fast website</li><li>Fast to develop</li><li>Inexpensive hosting</li><li>Minimal complexity</li></ul><p>
What are the options today to have a website with the above requirements?
    </p><h2>Wordpress (and similar CMS)</h2><p>
Nothing against WordPress, it's done a tremendous job for the internet but&nbsp;...<br>
...&nbsp;honestly, it's a bit overkill for our modest needs.
    </p><p>
We don't need to store our content in a database.
We don't need to deal with plugins.
We don't need a visual editor to write our content.
    </p><h2>No-Code</h2><p>
Yes, that's one area where there's a lot of the hype these days.
    </p><p>
But to be a web coder and use a no-code tool?
Seriously?
It sounds weird.
    </p><p>
We want to own our content.
We want to do whatever we want with our web.
We can code a website faster than we can build it in the no-code WYSIWYG editor.
    </p><p>
The last point is that such tool still requires initial (and then ongoing) learning.
    </p><h2>Frameworks</h2><p>
We have an experience with frameworks.
    </p><p>
But, did we want to do the whole setup?
Although it can be done quickly, we would end up with too many parts.
Like a database, configuration, libraries, admin, and so on.
Yes, it is a fully customizable solution, but we would end up with something that resembles WordPress.
    </p><p>
And that's not what we wanted.
    </p><h2>Jamstack (aka Site generators)</h2><p>
Static site generators look like a tempting option for our needs, don't they?
    </p><p>
Just pick a programming language, do some coding, press a button (or run a script) and voila&nbsp;...<br>
...&nbsp;your fast static site is generated.
    </p><p>
Unfortunately, Jamstack tools require an initial setup and an initial (and continuous) learning.
    </p><p>
We understand, that writing a blog in markdown is convenient, but taking all things into consideration we decided for simpler solution.
    </p><h2>KittyStack</h2><p>
Our solution is obvious, when you review our requirements (repeated below for your convenience):
    </p><ul><li>Fast website</li><li>Fast to develop</li><li>Inexpensive hosting</li><li>Minimal complexity</li></ul><p>
Let's discuss them one by one:
    </p><h2>Fast website</h2><p>
Is a static website fast?<br>
Yes, it is!
    </p><h2>Fast development</h2><p>
Now, you may be thinking: "If you're not writing your content in markdown, you're not using a fancy editor, then what are you using?"
    </p><p>
We write our content in HTML!
    </p><p>
Take a look at our website.
For the kind of posts we publish there, HTML is ideal.
We mix the text with HTML/CSS/JS widgets, so it makes sense to have a post written directly in HTML.
    </p><h2>Inexpensive hosting</h2><p>
Is hosting a static site inexpensive?
    </p><p>
It depends on the provider and all the bells and whistles you decide you need.
    </p><p>
We decided to go with the absolute minimum, because hosting static sites doesn't require a massive hardware setup.
    </p><p>
Mind you, Hetzner <a href="https://www.hetzner.com/webhosting" target="_blank">webhosting</a> starts at 2 EUR!
How crazy is that?
    </p><p>
And if you are worried that your site will not survive a massive spike in traffic - like when your post hits the front page of Hacker News - it probably will.
At least our site did.
    </p><h2>Minimal complexity</h2><p>
We insisted on minimal complexity, but some of our pages and posts have repeating patterns.
    </p><p>
While it is possible to use a copy+paste routine, it can quickly get out of control.
Using some form of loops would help a lot.
Also, the ability to include some blocks of code - like header, footer, and the alike - would be beneficial.
    </p><h2>Templating to the rescue</h2><p>
And so we come to the last piece of the puzzle.
    </p><p>
Meet <a href="https://palletsprojects.com/p/jinja/" target="_blank">Jinja</a> templates, which make our life much easier.
Jinja allows us to use loops, include files (navigation bar, footer, etc.) and much more.
    </p><p>
Plus, we didn't have to learn a new system as we were already using frameworks based on Jinja before.
    </p><h2 id="kittys-tool-chain">A simple toolchain</h2><p>
Now you might be wondering how we generate the final, static page.
    </p><p>
We use a short Python script with exactly 45 lines of code.
<span>Including comments and blank lines.</span></p><p>
In summary, this is the simple toolchain for building our web:
    </p><ul><li>Developer updates index.src.html</li><li>Watchdog.py detects the file change and ...</li><li>... renders Jinja template into index.html and ...</li><li>... calls <a href="https://tailwindcss.com/blog/standalone-cli" target="_blank">Tailwind CSS CLI</a> to generate styles.min.css.</li></ul><!-- Widget --><div><svg viewBox="0 0 24 24" stroke-width="0.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10 2l-.15 .005a2 2 0 0 0 -1.85 1.995v6.999l-2.586 .001a2 2 0 0 0 -1.414 3.414l6.586 6.586a2 2 0 0 0 2.828 0l6.586 -6.586a2 2 0 0 0 .434 -2.18l-.068 -.145a2 2 0 0 0 -1.78 -1.089l-2.586 -.001v-6.999a2 2 0 0 0 -2 -2h-4z" stroke-width="0" fill="currentColor"></path></svg><div><svg viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10.325 4.317c.426 -1.756 2.924 -1.756 3.35 0a1.724 1.724 0 0 0 2.573 1.066c1.543 -.94 3.31 .826 2.37 2.37a1.724 1.724 0 0 0 1.065 2.572c1.756 .426 1.756 2.924 0 3.35a1.724 1.724 0 0 0 -1.066 2.573c.94 1.543 -.826 3.31 -2.37 2.37a1.724 1.724 0 0 0 -2.572 1.065c-.426 1.756 -2.924 1.756 -3.35 0a1.724 1.724 0 0 0 -2.573 -1.066c-1.543 .94 -3.31 -.826 -2.37 -2.37a1.724 1.724 0 0 0 -1.065 -2.572c-1.756 -.426 -1.756 -2.924 0 -3.35a1.724 1.724 0 0 0 1.066 -2.573c-.94 -1.543 .826 -3.31 2.37 -2.37c1 .608 2.296 .07 2.572 -1.065z"></path><path d="M9 12a3 3 0 1 0 6 0a3 3 0 0 0 -6 0"></path></svg><p><span>watchdog.py</span><span>renders Jinja template</span><span>calls Tailwind CLI</span></p></div><svg viewBox="0 0 24 24" stroke-width="0.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10 2l-.15 .005a2 2 0 0 0 -1.85 1.995v6.999l-2.586 .001a2 2 0 0 0 -1.414 3.414l6.586 6.586a2 2 0 0 0 2.828 0l6.586 -6.586a2 2 0 0 0 .434 -2.18l-.068 -.145a2 2 0 0 0 -1.78 -1.089l-2.586 -.001v-6.999a2 2 0 0 0 -2 -2h-4z" stroke-width="0" fill="currentColor"></path></svg></div><p>
It's also important to mention following:
    </p><ul><li>During development, <a href="https://www.npmjs.com/package/live-server" target="_blank">Live Server</a> serves files and reloads them as they change.</li><li>When it's time to publish, the files are uploaded <span>manually</span> via <a href="https://en.wikipedia.org/wiki/File_Transfer_Protocol" target="_blank">FTP</a>.</li></ul><h2>Conclusion</h2><p>
Web development can be kept simple without sacrificing too much.
    </p><p>
In fact, it can be liberating to limit yourself to just a few options.
And based on what we've seen so far, many customers would benefit from having solutions that are faster, simpler and cheaper.
    </p><p>
But don't just take our word for it.
Take a look around the web and ask yourself: could the same result be achieved using a less complex tech stack?
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: MongoDB Protocol for SQLite (137 pts)]]></title>
            <link>https://github.com/FerretDB/FerretDB</link>
            <guid>36590834</guid>
            <pubDate>Tue, 04 Jul 2023 18:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FerretDB/FerretDB">https://github.com/FerretDB/FerretDB</a>, See on <a href="https://news.ycombinator.com/item?id=36590834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">FerretDB</h2>
<p dir="auto"><a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow"><img src="https://camo.githubusercontent.com/300b5958449c8a6351a204c43e55669a0befcfb8c6fe925a1d73487636421088/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f46657272657444422f46657272657444422f66657272657464622e737667" alt="Go Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/FerretDB/FerretDB/ferretdb.svg"></a></p>
<p dir="auto"><a href="https://github.com/FerretDB/FerretDB/actions/workflows/go.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/go.yml/badge.svg?branch=main" alt="Go"></a>
<a href="https://codecov.io/gh/FerretDB/FerretDB" rel="nofollow"><img src="https://camo.githubusercontent.com/e3b356c5102c6a029736b7b9995e1efc212f16c550eab9c4f54c99e0820b12e4/68747470733a2f2f636f6465636f762e696f2f67682f46657272657444422f46657272657444422f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d4a5a353658465433444d" alt="codecov" data-canonical-src="https://codecov.io/gh/FerretDB/FerretDB/branch/main/graph/badge.svg?token=JZ56XFT3DM"></a></p>
<p dir="auto"><a href="https://github.com/FerretDB/FerretDB/actions/workflows/security.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/security.yml/badge.svg?branch=main" alt="Security"></a>
<a href="https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml/badge.svg?branch=main" alt="Packages"></a>
<a href="https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml/badge.svg?branch=main" alt="Docs"></a></p>
<p dir="auto">FerretDB was founded to become the de-facto open-source substitute to MongoDB.
FerretDB is an open-source proxy, converting the MongoDB 6.0+ wire protocol queries to SQL -
using PostgreSQL or SQLite as a database engine.</p>
<h2 tabindex="-1" dir="auto">Why do we need FerretDB?</h2>
<p dir="auto">MongoDB was originally an eye-opening technology for many of us developers,
empowering us to build applications faster than using relational databases.
In its early days, its ease-to-use and well-documented drivers made MongoDB one of the simplest database solutions available.
However, as time passed, MongoDB abandoned its open-source roots;
changing the license to <a href="https://www.mongodb.com/licensing/server-side-public-license" rel="nofollow">SSPL</a> - making it unusable for many open source and early-stage commercial projects.</p>
<p dir="auto">Most MongoDB users do not require any advanced features offered by MongoDB;
however, they need an easy-to-use open-source document database solution.
Recognizing this, FerretDB is here to fill that gap.</p>
<h2 tabindex="-1" dir="auto">Scope and current state</h2>
<p dir="auto">FerretDB is compatible with MongoDB drivers and popular MongoDB tools.
It functions as a drop-in replacement for MongoDB 6.0+ in many cases.
Features are constantly being added to further increase compatibility and performance.</p>
<p dir="auto">We welcome all contributors.
See our <a href="https://github.com/orgs/FerretDB/projects/2/views/1">public roadmap</a>,
a list of <a href="https://docs.ferretdb.io/diff/" rel="nofollow">known differences with MongoDB</a>,
and <a href="https://github.com/FerretDB/FerretDB/blob/main/CONTRIBUTING.md">contributing guidelines</a>.</p>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">Run this command to start FerretDB with PostgreSQL backend:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d --rm --name ferretdb -p 27017:27017 ghcr.io/ferretdb/all-in-one"><pre>docker run -d --rm --name ferretdb -p 27017:27017 ghcr.io/ferretdb/all-in-one</pre></div>
<p dir="auto">Alternatively, run this command to start FerretDB with SQLite backend:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d --rm --name ferretdb -p 27017:27017 \
  -v ./data:/data/ -e FERRETDB_HANDLER=sqlite -e FERRETDB_SQLITE_URL=file:/data/ \
  ghcr.io/ferretdb/all-in-one"><pre>docker run -d --rm --name ferretdb -p 27017:27017 \
  -v ./data:/data/ -e FERRETDB_HANDLER=sqlite -e FERRETDB_SQLITE_URL=file:/data/ \
  ghcr.io/ferretdb/all-in-one</pre></div>
<p dir="auto">This command will start a container with FerretDB, PostgreSQL, and MongoDB Shell for quick testing and experiments.
However, it is unsuitable for production use cases because it keeps all data inside and loses it on shutdown.
See our <a href="https://docs.ferretdb.io/quickstart-guide/docker/" rel="nofollow">Docker quickstart guide</a> for instructions
that don't have those problems.</p>
<p dir="auto">With that container running, you can:</p>
<ul dir="auto">
<li>Connect to it with any MongoDB client application using MongoDB URI <code>mongodb://127.0.0.1:27017/</code>.</li>
<li>Connect to it using MongoDB Shell by just running <code>mongosh</code>.
If you don't have it installed locally, you can run <code>docker exec -it ferretdb mongosh</code>.</li>
<li>For PostgreSQL backend, connect to it by running <code>docker exec -it ferretdb psql -U username ferretdb</code>.
FerretDB uses PostgreSQL schemas for MongoDB databases.
So, if you created some collections in the <code>test</code> database using any MongoDB client,
you can switch to it by running <code>SET search_path = 'test';</code> query
and see a list of PostgreSQL tables by running <code>\d</code> <code>psql</code> command.</li>
<li>For the SQLite backend, database files will be created on a host in the <code>data</code> directory.
You can access them by running <code>sqlite3 data/&lt;filename&gt;.sqlite</code> after some data is inserted into FerretDB.</li>
</ul>
<p dir="auto">You can stop the container with <code>docker stop ferretdb</code>.</p>
<p dir="auto">We also provide binaries and packages for various Linux distributions,
as well as <a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow">Go library package</a> that embeds FerretDB into your application.
See <a href="https://docs.ferretdb.io/quickstart-guide/" rel="nofollow">our documentation</a> for more details.</p>
<h2 tabindex="-1" dir="auto">Building and packaging</h2>
<p dir="auto">We strongly advise users not to build FerretDB themselves.
Instead, use binaries, Docker images, or <code>.deb</code>/<code>.rpm</code> packages provided by us.</p>
<p dir="auto">If you want to package FerretDB for your operating system or distribution,
the recommended way to build the binary is to use the <code>build-release</code> task;
see our <a href="https://github.com/FerretDB/FerretDB/blob/main/CONTRIBUTING.md">instructions for contributors</a> for more details.
FerretDB could also be built as any other Go program,
but a few generated files and build tags could affect it.
See <a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/build/version" rel="nofollow">there</a> for more details.</p>
<h2 tabindex="-1" dir="auto">Managed FerretDB at cloud providers</h2>
<ul dir="auto">
<li><a href="https://www.civo.com/" rel="nofollow">Civo</a> (see <a href="https://www.civo.com/marketplace/FerretDB" rel="nofollow">here</a>).</li>
<li><a href="https://www.scaleway.com/" rel="nofollow">Scaleway</a> (request access <a href="https://www.scaleway.com/en/betas/#managed-document-database" rel="nofollow">here</a>).</li>
</ul>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<ul dir="auto">
<li><a href="https://docs.ferretdb.io/" rel="nofollow">Documentation for users</a>.</li>
<li><a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow">Documentation for Go developers about embeddable FerretDB</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">Community</h2>
<ul dir="auto">
<li>Website and blog: <a href="https://ferretdb.io/" rel="nofollow">https://ferretdb.io</a>.</li>
<li>Twitter: <a href="https://twitter.com/ferret_db" rel="nofollow">@ferret_db</a>.</li>
<li>Mastodon: <a href="https://techhub.social/@ferretdb" rel="nofollow">@ferretdb@techhub.social</a>.</li>
<li><a href="https://join.slack.com/t/ferretdb/shared_invite/zt-zqe9hj8g-ZcMG3~5Cs5u9uuOPnZB8~A" rel="nofollow">Slack chat</a> for quick questions.</li>
<li><a href="https://github.com/FerretDB/FerretDB/discussions">GitHub Discussions</a> for longer topics.</li>
<li><a href="https://github.com/FerretDB/FerretDB/issues">GitHub Issues</a> for bugs and missing features.</li>
<li><a href="https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=NjNkdTkyN3VoNW5zdHRiaHZybXFtb2l1OWtfMjAyMTEyMTNUMTgwMDAwWiBjX24zN3RxdW9yZWlsOWIwMm0wNzQwMDA3MjQ0QGc&amp;tmsrc=c_n37tquoreil9b02m0740007244%40group.calendar.google.com&amp;scp=ALL" rel="nofollow">Open Office Hours meeting</a>
every Monday at 18:00 UTC at <a href="https://meet.google.com/mcb-arhw-qbq" rel="nofollow">Google Meet</a>.</li>
</ul>
<p dir="auto">If you want to contact FerretDB Inc., please use <a href="https://www.ferretdb.io/contact/" rel="nofollow">this form</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dark Waters of Self-Delusion: The crash of Transair flight 810 (161 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00</link>
            <guid>36590806</guid>
            <pubDate>Tue, 04 Jul 2023 18:32:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00">https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00</a>, See on <a href="https://news.ycombinator.com/item?id=36590806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://admiralcloudberg.medium.com/?source=post_page-----a4eeb033bc00--------------------------------"><div aria-hidden="false"><p><img alt="Admiral Cloudberg" src="https://miro.medium.com/v2/resize:fill:88:88/2*pZPMtIONqtJYi2xHYD_Ivg.jpeg" width="44" height="44" loading="lazy"></p></div></a></div><figure><figcaption>The forward fuselage of Transair flight 810, as seen at the bottom of the sea. (NTSB)</figcaption></figure><p id="92bd">On the 2nd of July 2021, a Boeing 737–200 hauling cargo between the Hawaiian Islands lost power in one engine shortly after takeoff from Honolulu. As the pilots attempted to turn back toward the airport, they reported the unthinkable: their second engine was going too, and they weren’t going to make it. While the Coast Guard scrambled to respond, the crew carried out an extraordinary ditching at sea in the dark of night, successfully bringing their 737 down on the heaving waters of Mamala Bay, 3.3 kilometers off the coast of Oahu. Although the plane broke into two pieces on impact, both pilots managed to escape, and in a harrowing rescue they were plucked from the water just as the remains of the airplane slipped beneath the waves.</p><p id="193e">Two years later, the publication of the National Transportation Safety Board’s final report has confirmed what many long suspected: that the crash of Transair flight 810 was not a story of exemplary airmanship, but quite the opposite, as a relatively minor engine failure snowballed into a dangerous ditching that need never have been attempted. The unfortunate truth was that the pilots never properly addressed the emergency, and in their confusion, reduced power on their functioning engine — a tale as old as the very concept of multi-engine airplanes. The cockpit voice recording and interviews with the pilots revealed the factors which may or may not have contributed, from their muddled attempts to declare an emergency, to an incomplete control handover, to simple stress, as the captain delivered a heated and sometimes sexist 32-minute pre-flight monologue about a fellow pilot. In any case, the findings raised questions about the safety culture at Transair, a scrappy (and now defunct) cargo airline operating 50-year-old airplanes — and highlighted how a breakdown in communication and critical thinking can turn a minor failure into a potentially deadly crash.</p><p id="1194">◊◊◊</p><figure><figcaption>Transair 737s on the ramp in Honolulu. (Transair)</figcaption></figure><p id="c619">In the archipelago of Hawaii, modern life depends on the fast and efficient transfer of goods between the state’s seven inhabited islands, especially by air. Numerous small companies have historically competed for this market, including — until recently — Rhoades Aviation, better known under its public-facing name Transair, which branded itself as “Hawaii’s leader in interisland air cargo.” Founded in 1982 by Iranian-born businessman Teimour Riahi, the airline slowly grew from a few small turboprops to a fleet of several first-generation Boeing 737–200 jets, surviving for decades despite its small size and even a failed attempt to expand into passenger services in 2005.</p><p id="2cbd">For Transair pilots, the pay was mediocre and the hours were unpredictable, but by the 2020s, Transair was one of at most two or three remaining operators of the ancient Boeing 737–200 left in the United States, and anyone who wanted to fly the classic jets would have had few other options. Others were simply attracted by the promise of working in Hawaii, including one of the main characters of this story, 58-year-old Captain Henry Okai. Born in the West African nation of Ghana, he came to the United States decades ago to pursue his dream of flying, which was met with success as he passed pilot training and got a job with regional carrier Allegheny Airlines. Over the years he flew for a variety of companies, both in the United States and abroad, until he finally landed with Transair, having been drawn to the airline in a spur-of-the-moment decision.</p><figure><figcaption>N810TA, the aircraft involved in the accident. (Li Cheng Tsai)</figcaption></figure><p id="9353">Just after midnight on the 2nd of July, 2021, Captain Okai reported for duty at Honolulu International Airport to fly Transair flight 810, a regular service from Hawaii’s capital and largest city, to Kahului, the largest town on the island of Maui. Joining him was 50-year-old First Officer Gregory Ryan, founder of the local Honolulu law firm Greg Ryan and Associates. Ryan first flew for commuter carrier Mesa Airlines from 1991 to 1995, before switching careers to become a divorce lawyer. In 2019, however, he decided to get back into flying, and for the last two years he had been splitting his time between Transair and his legal practice.</p><p id="72f6">That night they would be flying a Boeing 737–200 built in 1975 and registered as N810TA (at Transair, the flight number was based on the registration number — any route that N810TA happened to be flying was “flight 810”). When they arrived at the ramp, cargo handlers were loading the plane with several tons of frozen seafood, pharmaceuticals, and other perishable items typically shipped by air in Hawaii. After performing the pre-flight checks, the pilots sat down in the cockpit to wait for the cargo loading to finish, at which point Captain Okai began to vent about an incident that had allegedly occurred on July 1st, less than 24 hours previously. First Officer Ryan appears to have been already aware of what happened, suggesting that the conversation may actually have begun earlier, but what is known is that the issue would come to dominate the cockpit conversation almost until the moment of takeoff.</p><p id="45da">Most of the information about what happened comes from Captain Okai’s own statements captured by the cockpit voice recorder, but what is known is that on the morning of the 1st, Okai had been rostered to fly with the airline’s sole female First Officer, identified as Gina Moore. After a fraught disagreement over procedures, the two apparently found themselves in a shouting match in the cockpit, at which point Moore announced that she would not fly with Captain Okai, and walked away from the flight in the middle of the after start checklist. A new first officer had to be found, and the flight was delayed. (According to Moore’s own testimony, which is very sparse in detail, she did not ask to be replaced — rather, the Chief Pilot replaced her as soon as she told him she was uncomfortable with Captain Okai. Okai may have been unaware of this.)</p><figure><figcaption>Another photo of N810TA at Honolulu International Airport. (Chris Hoare)</figcaption></figure><p id="3c87">From the transcript, Captain Okai clearly had not mentally moved on from the incident. The conflict seemed to have arisen because Okai and Moore had different interpretations of the procedures in the manual, and neither was willing to compromise with the other, a hallmark of poor crew resource management. As First Officer Ryan listened, interjecting only occasionally to affirm his captain, Okai described his interpretation of the procedures, then discussed how Moore walked out in the middle of the checklist, which apparently prompted him to say a number of hostile words, including “what’s wrong with you,” “this is a joke,” and “you’re going to finish the checklist.” A shouting match ensued, which Ryan recognized as a safety issue, although neither pilot pointed out Okai’s own role in the altercation. In fact, he said, “<em>This is the way we work when I am with her, you know, you have to yell at her to force her to do things.”</em></p><p id="ca03">This incident had apparently been escalated all the way to the airline’s owner, but Okai accused the Chief Pilot of favoring Moore at his expense. He then professed a belief that First Officers needed to acquiesce to their captains regardless of what they thought “the book” said. Again, not a hallmark of an effective team player.</p><p id="68c6">At around quarter past 1:00, the cargo loading concluded, and the pilots paused the conversation to conduct the departure briefing, complete the before start checklist, and start the engines — although Okai interrupted the checklist to mention that he was going to use his cell phone to send pictures of the wording in the manual to the Chief Pilot in order to prove Moore wrong.</p><p id="b372">Several minutes later, the flight was ready to taxi, and the pilots proceeded toward the runway — only for Okai’s mind to come back to Moore again. Spotting a pothole in the runway, Okai began to describe how he accidently ran through that same pothole during a landing rollout because he was distracted arguing with Moore. “This girl is driving me crazy, you know!” he said.</p><p id="9272">Moments later, he brought the rant to a new level, graduating from personal animosity to outright misogyny. “These are the kind of women you don’t wanna get married to,” he said. “You know, some men, they lose their temper and the next thing you know, the wife is dead, you know… they start punching them and kicking them, and they lost their minds, you know… they kill the woman… it’s the woman who can drive you to do crazy stuff, you know?”</p><blockquote><p id="3de9">(Public service announcement: if a husband murders his wife because he thinks she’s annoying, that’s the husband’s fault. I shouldn’t need to say this.)</p></blockquote><p id="2704">◊◊◊</p><p id="89f1">Minutes later, at 1:33 a.m., flight 810 arrived at the head of the runway with takeoff clearance in hand, and Captain Okai handed over control to First Officer Ryan. Working together, they pushed the thrust levers to takeoff power, and the engine instruments responded normally. Okai observed that the exhaust gas temperatures, or EGTs, were hovering very close to the yellow “caution” zone on the gauge, but he had seen this indication many times before on multiple Transair planes, and he wasn’t concerned.</p><p id="e467">As the 737 accelerated down the runway, Okai made the standard callout, “Eighty knots,” followed by “V1,” or decision speed, and then “rotate.” Ryan pulled the nose back, and the plane lifted off, prompting Okai to call out, “positive rate.”</p><p id="e1b7">“Gear up,” Ryan ordered, and Okai complied.</p><p id="59a9">Then, just as the gear finished retracting, a loud “thud” was heard, accompanied by vibrations and a long “whooshing” sound, like an engine rolling back.</p><p id="b2fa">“Oh shit,” Ryan exclaimed.</p><p id="40e9">“Lost an engine, you got it?” Okai asked.</p><p id="1ad6">“Okay, I got it, yep,” Ryan said, instinctively stepping on the rudder to counteract the developing asymmetric thrust.</p><p id="2ee7">“Yep, you lost number…” Okai started to say, trying to determine which engine had failed.</p><p id="d720">“Number two, yep,” said Ryan, referring to the right engine.</p><p id="21e9">“Number two,” Okai agreed.</p><figure><figcaption>The damage to the turbine blades that precipitated the emergency. (NTSB)</figcaption></figure><p id="a09a">The pilots’ assessment was correct. Inside the high pressure turbine within the right (№2) engine, corrosion had been eating away at two of the turbine blades from the inside, expanding outward around each blade’s internal lightening holes — voids in the material designed to reduce the weight of the blades. The corrosion steadily weakened the blades, until one or both failed under the stresses of normal operation. The broken blade tips were then sucked back through the low pressure turbine, causing further damage that reduced the engine’s ability to produce power. In fact, within seconds of the failure, the Engine Pressure Ratio, or EPR, for the right engine — a proxy for its power output — decreased from 1.97, which is approximately takeoff power, to 1.43, which is closer to cruise.</p><p id="ceef">When an engine failure occurs on takeoff in a twin-engine jet like the 737, the procedure is to declare an emergency, climb to a safe altitude, level off, identify which engine has failed, complete the “engine failure or shutdown” checklist, and then return to the airport. Therefore, to start things off, Captain Okai jumped on the radio and said, “Rhoades eight ten, we have an emergency, stand by.”</p><p id="04f4">“Rhoades Express eight ten, radar contact, fly heading of one one zero to join victor two, resume own navigation,” the controller said, having apparently missed the content of the transmission.</p><p id="e4aa">“Eight twenty [sic] has emergency, on a two twenty heading, stand by,” Okai repeated. Turning to his first officer, he added, “Okay, you can inch up to two thousand.” 2,000 feet would be an excellent safe altitude at which to level off while they completed the engine failure procedure.</p><p id="fb7d">About 12 seconds later, Okai said, “Okay, coming up on two thousand, we’ll level at two thousand… you have two twenty heading, right?”</p><p id="0edd">In addition to flying with less power on the right side, First Officer Ryan was also navigating through a procedure turn to the right following takeoff, but he seemed to be handling it just fine, so he simply said, “Yes.”</p><p id="b11b">Moments later, the flight reached 2,000 feet, and Ryan began leveling the plane. At the same time, the controller called them again to repeat her earlier clearance. “Rhoades Express eight ten, radar contact, turn left heading zero niner zero, join victor two, resume own navigation, climb and maintain one three thousand, say altitude,” she said.</p><p id="6fa4">Wondering whether the controller wasn’t able to hear them, Okai said, “Okay, Rhoaaades eight ten, radio check, how do you read?”</p><p id="9f9b">“Rhoades Express eight ten, loud and clear, how do you hear? Turn left heading one eight zero,” the controller replied, again without mentioning the emergency. The simple truth, which Okai would later realize, was that the controller was handling a large volume of traffic, and other planes were stepping on his transmissions, making them hard to understand. But in the moment, her failure to appreciate the emergency declaration was probably frustrating.</p><p id="359b">“Okay, Rhoades eight ten, we’ve lost an engine, we are on a two twenty heading, maintaining two thousand, declaring an emergency, how do you read?” Okai repeated.</p><p id="a674">But the controller was in the middle of talking to their sister aircraft, Transair flight 809, and when Okai stopped talking, he heard only the end of their conversation: “…say again, heading two four zero?”</p><p id="4ea2">“Okay, two four zero heading, Rhoades eight ten,” Okai replied, thinking the transmission was for him.</p><p id="449b">“No, Rhoades eight oh nine, Rhoades eight oh nine, left two four zero,” the controller clarified. Then, finally recognizing that flight 810 was in trouble, she added, “Rhoades Express eight ten, you are cleared visual approach runway four right, you can turn in towards the airport.”</p><p id="a709">“Okay, Rhoades eight ten, we’re gonna have to run a checklist, if we can get a delay vector and uh, we’ll let you know when we’re ready to come into the airport,” Okai replied.</p><p id="a97d">“Just keep me advised and maintain two thousand if that’s the altitude you’d like,” said the controller.</p><p id="2fbb">“Okay, two thousand is good for now,” said Okai. “We’ll stay around fifteen miles from the airport and uh, maintaining two thousand, Rhoades eight ten.”</p><figure><figcaption>The EPR gauges on the accident airplane, which would have been the primary instrument indication of engine performance. The values depicted are not what was shown at any point during the accident sequence; the photo is illustrative of the concept only. (NTSB)</figcaption></figure><p id="f7d4">By the time the conversation concluded, a minute and forty seconds had passed with little to no discussion between the pilots. First Officer Ryan spent that time leveling off at 2,000 feet and trying to achieve the target airspeed for an engine-out scenario, which was about 220 knots. He initially overshot both, climbing to 2,100 feet and reaching a speed of 250 knots, so he began incrementally reducing power in both engines in order to slow down. In accordance with standard procedures, he moved both thrust levers together, since they had not formally carried out the identification process for the failed engine.</p><p id="da2a">Returning his attention to the cockpit, Captain Okai now said, “Okay, let’s uh… two forty heading.” He appeared not to have understood that this heading was not for him. He then added a question: “You want me to take over, or you got it?”</p><p id="aa5d">“No, I’m okay, thank you,” said Ryan.</p><p id="1cf9">In an emergency, it’s normal for the First Officer to fly while the Captain develops a strategy and completes the abnormal checklists. This was not an official rule nor was it set in stone, but Okai’s offer contradicted it nonetheless.</p><p id="4267">At that moment, the controller called again. “Rhoades Express eight ten, uh, when you get a chance can I get the nature of the emergency, I know you said an engine out, which one? Uh, how many souls on board, and fuel?”</p><p id="17b6">“Okay, all that is good, we’ll give you all that in a little bit, in a little bit, Rhoades eight ten,” Okai replied. Turning back to First Officer Ryan, he said, “Okay, so we’ll plan for two.. say two twenty speed, eh?”</p><p id="c734">“Kay,” said Ryan. By now, both thrust levers had been rolled all the way back to flight idle, the lowest flight setting, and the left and right EPRs had dropped to 1.05 and 1.09 respectively, indicating very little forward thrust. Their speed was dropping nicely toward 220 knots, which was what they wanted.</p><p id="e59f">Now, about 45 seconds after his first offer to take control, Okai said, “Let me take over briefly, and you…”</p><p id="efb2">“Okay,” First Officer Ryan agreed. He would later state that he perceived Okai’s statement as an order, so he agreed to hand over control, even though he was having no issues flying the plane. In fact, with both engines at idle, the asymmetric thrust had disappeared, and it was trivial to keep the plane straight and level.</p><p id="eb32">“You set your things up, I have control,” said Captain Okai.</p><p id="6855">“Okay, you have control,” Ryan acknowledged.</p><figure><figcaption>This 3-D reconstruction shows how the plane began slowly losing altitude just minutes after takeoff. (FlightAware)</figcaption></figure><p id="254a">Now that he was flying the plane, Okai immediately noticed that not all was as it should be. Their speed had dropped to the target of 220 knots, but they were losing altitude, having fallen from 2,100 down to 1,700 feet. Okai tried pitching up to regain their planned altitude, but as a result their speed dropped even more, to 196 knots, and the plane barely climbed. Of course, the reason was because First Officer Ryan had set both thrust levers to idle, and because of the control handover, no one pushed them back up again. But Okai didn’t realize that. Instead, he said, “Okay, let’s see what is the problem. Which one… what’s going on with the gauges? Read the gauges and see which one… who one… which… who has the EGT?”</p><p id="58f8">Glancing over at the engine gauges, First Officer Ryan attempted to determine which engine had abnormal parameters, including but not limited to the exhaust gas temperature (EGT). But with both engines still running at idle power, it was quite difficult to tell. Out of the indicated parameters, engine pressure ratio (EPR) was usually the biggest clue, but the EPR for both engines was almost the same. Instead, Ryan attempted to recall what symptoms he had noticed when the engine first failed: he heard a sound which seemed to come from the left, and the plane yawed left — didn’t it? So it must have been the left engine. Its indicated EPR, slightly below that of the right engine, was consistent with such an interpretation. And so he said, “Yep, so it looks like the number one.”</p><p id="34d2">“Number one is gone?” Okai asked.</p><p id="53b6">“It’s gone, yep,” said Ryan. “So we have number two.”</p><p id="810e">“So we have number two, okay,” said Okai.</p><p id="8443">You might have already noticed what’s wrong with this picture. When the failure first happened, didn’t both pilots identify the problem as being with the right engine? First Officer Ryan even used the rudder to prevent the plane from yawing right! But, as it turns out, human memory is more fallible than we would sometimes like to admit, and in the intervening four minutes, both pilots had somehow entirely forgotten their initial impressions. First Officer Ryan even seemingly forgot that the left engine was at idle power because he put it there himself not even two minutes earlier. If at that moment some outside observer had asked Ryan why he thought the number one (left) engine was faulty, he might not even have been able to give a straight answer, and yet in the moment he expressed his determination with unquestioned conviction, and Captain Okai, believing Ryan to be a competent and trustworthy pilot, accepted his conclusion unconditionally.</p><figure><figcaption>The 737–200 Engine Failure or Shutdown checklist. (NTSB)</figcaption></figure><p id="00f4">Having concluded that the left engine was at fault, Okai advanced the right thrust lever in order to stabilize their flight path, then moved to their next priority: completing the engine failure checklist. His plan was to fly 15 miles out from the airport on their assigned heading before turning back, which would give them plenty of time to complete the procedure, so he said, “Alright, uh, two forty heading, I have control.”</p><p id="ceb1">“Okay, should we head back toward the airport though, before we get too far away?”</p><p id="1164">“Yeah, we’ll stay within fifteen… alright, I have controls, you run the checklist, let’s do the engine failure shutdown checklist.”</p><p id="3a69">First Officer Ryan would later assert that he disagreed with the decision to spend so much time in the air, but that Okai was the captain, so he obeyed him. Besides, given their earlier conversation, he surely knew where arguing with Okai would get him (which was nowhere). Okai, for his part, would later note that he had been reprimanded by the Chief Pilot for landing without performing the checklist after a previous engine failure, and had promised not to do so again.</p><p id="e5c0">Some 30 seconds later, Okai asked air traffic control for permission to begin turning in, and received a new heading. Meanwhile, First Officer Ryan started reading off the conditions for performing the checklist. “Okay, engine failure or shutdown,” he recited. “When these occurs… engine failure, engine flameout, or another checklist directs an engine failure…”</p><p id="59e1">At that moment, Ryan seemed to notice that the EGT on the right engine was abnormally high, almost inside the red “warning” zone on the gauge. If they let the exhaust gas temperature climb into the red zone, severe engine damage could occur. Of course, the reason for this was that the right engine was already damaged and was not running properly, causing its internal temperature to rise, but in the moment it appeared to First Officer Ryan that they were simply demanding too much of the old, somewhat underpowered engine. “We’re… we’re red line here, we should pull the right one back a little bit,” he said.</p><p id="ce16">Captain Okai immediately recognized that this was a serious issue. He had already moved the right thrust lever to a reasonable power setting, but the EPR was much lower than it should have been, only about 1.22, which was not enough to keep them airborne for long. And yet even at this low power setting, the engine was overheating. His immediate conclusion was that they were about to lose thrust in both engines, and that they needed to get on the ground as soon as possible, so he said, “Okay, shoot, we should head towards the airport.”</p><figure><figcaption>The location and appearance of the exhaust gas temperature (EGT) gauges on a Boeing 737–200. (Chris Brady)</figcaption></figure><p id="6aa3">As the gravity of the situation set in, First Officer Ryan began setting up for the approach, while Captain Okai informed air traffic control that they were turning in and did not have the airport in sight.</p><p id="ab6d">“Rhoades Express eight ten, fly heading of zero two zero and would you like to intercept the localizer or do you want vectors?” the controller asked.</p><p id="aad8">“No, vectors straight to the airport,” Okai said. “We might lose the other engine too.”</p><p id="5c4d">Back in the cockpit, Okai asked, “We are clean, right?” His concern was that the flaps or landing gear might be extended, causing drag that was reducing their performance (a plane with no flaps or gear is referred to as “clean”). But they were in fact clean, so that wasn’t the problem.</p><p id="5d77">“Okay,” said Ryan.“Just have to watch this though, the number two.”</p><p id="2230">By now they had fallen to 1,000 feet, their speed was down to 157 knots, and both parameters were still decreasing. “Damn,” Okai said. Suddenly, the stick shaker activated, warning that they were flying too slowly and could stall if they didn’t increase their airspeed. With their only working engine redlined — or so they thought — the only way to gain speed was by pitching down, but that would only hasten their already alarming descent.</p><p id="3df3">“What’s this?” Okai exclaimed. “Hey man, we can’t keep going down!”</p><p id="23ec">“We’re descending,” Ryan agreed.</p><p id="a48b">Okai advanced the right thrust lever even more, and the EPR crept up to a still meager 1.37, but the temperature only continued rising into the red zone, until finally it reached the maximum that gauge could indicate.</p><p id="7f6e">“Okay, see, see if you can see the airport now,” Okay said, growing worried.</p><p id="03eb">“Uh, we’re descending, we have to climb!” said Ryan.</p><p id="e0dd">“Double check the airplane is cleaned up,” said Okai.</p><p id="290b">“Yeah, flaps are up, speedbrakes…” Ryan replied.</p><p id="f650">“How is the EGT?” Okai asked.</p><p id="a1e5">“It’s max, it’s beyond max,” said Ryan.</p><p id="cdd6">“Okay, we’re barely holding altitude,” Okai said. “Okay, see what you can do in the checklist, finish as much as possible.”</p><p id="c1df">“This says, uh, airframe vibrations, abnormal engines exist…” Ryan said, speed reading the checklist introductions. “It says do the engine shutdown only when flight conditions — we have to fly the airplane though.”</p><p id="5c09">The full phrase was “when flight conditions allow” — and in Ryan’s view, that meant when their altitude and speed were stable, which they were not. And that meant flying the airplane had to come before finishing the checklist.</p><p id="414f">“Okay,” said Okai. “Damn.”</p><p id="aaa0">“We’re losing altitude,” Ryan repeated.</p><p id="b519">“Yeah. Fifteen miles out,” Okai said. They were on their way back to the airport now, but they were so low that it was difficult to make out the airport lights on the horizon, and they were still dropping. Unless they managed to find some more thrust, they weren’t going to make it. Of course, if someone had simply advanced the left thrust lever, all their problems would have been solved, but nobody even thought to try, so down they went.</p><figure><figcaption>The full annotated flight path of flight 810. (NTSB)</figcaption></figure><p id="b8ec">Desperate now to avoid losing altitude, First Officer Ryan thought it was time to start deploying the flaps, knowing that while they would allow them to fly at a lower speed, they would also increase drag. “Do we go flaps, flaps one?” he asked.</p><p id="6bcb">“No no, not yet,” said Okai.</p><p id="13ef">“Kay, we’re, we’re very slow though,” said Ryan. If they didn’t deploy the flaps, Okai would have to keep pitching down to avoid stalling.</p><p id="88b6">“Shoot, okay, flaps one,” Okai agreed.</p><p id="94ed">“Five hundred,” an automated voice called out, reciting their height above the water. It was followed by a callout from the Enhanced Ground Proximity Warning System, or EGPWS: “TOO LOW, GEAR!”</p><p id="aa09">Keying his mic, Captain Okai said to air traffic control, “Okay, Rhoades eight ten, uh situation, we’ve lost number one engine and um, we’re coming straight to the airport… we’re gonna need the fire department, there’s a chance we’re gonna lose the other engine too, it’s running very hot. And um, speed is um, we’re pretty low on the speed and it doesn’t look good out here… you might want to let the Coast Guard know as well.” This request would probably end up being the best decision Captain Okai made during the entire emergency.</p><p id="75c0">“TOO LOW, GEAR!” the EGPWS repeated.</p><p id="0e80">“Just fly, fly the airplane please!” said Ryan.</p><p id="6a3c">“TOO LOW, TERRAIN,” said the EGPWS. “TOO LOW, GEAR! TERRAIN! TERRAIN!</p><p id="7b36">“Do you have the airport?” Okai desperately asked.</p><p id="940b">“PULL UP,” the EGPWS blared.</p><p id="c1fc">“Pull up, we’re low!” Ryan repeated.</p><p id="ffad">“PULL UP! PULL UP!”</p><p id="09f8">“Rhoades Express eight ten, do you have the airport in sight?” the controller asked.</p><p id="157c">“Negative!” Ryan replied.</p><p id="7aea">“And Rhoades Express eight ten, low altitude alert, are you able to climb at all?”</p><p id="3603">“No, negative,” Ryan again replied.</p><p id="690e">“Rhoades Express eight ten, roger, proceed direct to the airport and you are cleared to land any runway,” the controller said, followed by a heading. But they were running out of time.</p><figure><figcaption>A graph of the engine pressure ratios over time shows how both engines were reduced to near idle, before the right thrust lever was advanced again. (NTSB)</figcaption></figure><p id="5e9a">As flight 810 dropped the last few hundred feet toward the ocean, the EGPWS continued to blare: “TOO LOW, TERRAIN! Three hundred! TOO LOW, GEAR!”</p><p id="056d">“Rhoades Express eight ten, the trucks are rolling,” said the controller.</p><p id="24a8">Jumping on the radio again, Okai replied, “Roger, you wanna — you wanna let the Coast — Coast Guard know as well?</p><p id="5895">“Say that again?”</p><p id="194a">“Can you let the Coast Guard know, we cannot maintain altitude,” Okai repeated.</p><p id="3591">“We will,” said the controller.</p><p id="983a">At that moment, the EPR on the right engine increased to over 1.4, and for a brief moment the plane seemed to level off, before entering an extremely shallow climb. “Hold that please, it’s climbing, hold that, hold that,” First Officer Ryan exclaimed. “Pull back, we’ve got a climb! Pull back to the stick shaker!”</p><p id="93f2">“Shoot, the three hundred feet…” Captain Okai started to say.</p><p id="8240">“It’s okay, we’re climbing — ” Ryan began, but at that moment the right engine started losing power again, and they began descending once more, having gained only 50 feet. “Oh, we’re not climbing, damn,” Ryan concluded.</p><p id="4665">“How’s the EGT?” Okai asked again.</p><p id="9104">“Hot, way over,” said Ryan.</p><p id="44c4">“TOO LOW, TERRAIN!” said the EGPWS. “TOO LOW, GEAR! TOO LOW, GEAR! TOO LOW, GEAR!”</p><p id="4c09">“Rhoades Express eight ten, the Coast Guard is on the way,” said the controller.</p><p id="c814">“TOO LOW, GEAR! TOO LOW, TERRAIN!”</p><p id="ef86">“Pull back please!” said Ryan.</p><p id="dc4a">“Rhoades Express eight ten, if you can get to runway eight right or Kalaeloa, do you want Kalaeloa?” the controller asked, referring to a military airfield off their left side. It was closer than Honolulu International, but probably still too far away.</p><p id="37fe">“We’d like the closest airport runway please,” Ryan replied.</p><p id="016f">“Anything we can land on,” Okai interjected.</p><p id="29ec">“[Kalaeloa air]port is three miles north of you, uh, off your nine to ten o’clock,” said the controller.</p><p id="258f">“Wanna go there?” Ryan asked. The stick shaker stall warning activated for two seconds, prompting Okai to pitch down again.</p><p id="b70f">“Can you get that, Rhoades Express eight ten, it’s three uh, to your left about three miles northwest of you,” the controller said.</p><p id="33bf">“TOO LOW, GEAR! TOO LOW, GEAR!”</p><p id="0f38">“Okay, give me a heading,” Captain Okai transmitted.</p><p id="e9ab">“TOO LOW, GEAR! TOO LOW, GEAR!” the EGPWS blared, followed again by the stick shaker.</p><p id="77f9">“Rhoades Express eight ten, uh the airport is about a three one zero heading from you,” said the controller.</p><p id="5b4e">But it was too late even for this last-ditch effort. As Captain Okai turned left toward the airbase, the pace of the EGPWS alerts became even more frenetic: “TERRAIN! TERRAIN! PULL UP! PULL UP!”</p><p id="0df6">“Three one zero, thank you,” Okai said to the controller. It would be the last transmission from flight 810.</p><p id="1b57">“PULL UP,” the EGPWS screamed. “PULL UP! PULL UP! PULL UP! PULL UP!”</p><p id="09f6">“You have control and you have control!” Okai exclaimed. It’s unclear what he meant, since he retained control of the plane and neither pilot would be able to recall the statement later.</p><p id="5633">“PULL UP!”</p><p id="419b">“Okay,” said Ryan.</p><p id="b608">“Shoot, this is the water, we in the water,” Okai said, spotting the shining black waters of Mamala Bay rising beneath them.</p><p id="5f52">“PULL UP!” The stick shaker rattled briefly again. “PULL UP! PULL UP! PULL UP! TOO LOW, TERRAIN!”</p><p id="f257">“Oh man, we’re in the water, we’re in the water, we can’t…” Okai said, on the verge of hyperventilation.</p><p id="3ce1">The stick shaker started rattling continuously now, punctuated by more EGPWS alerts: “TERRAIN! TERRAIN! PULL UP!”</p><p id="3c76">“Damn!” Okai shouted.</p><p id="eac7">The EGPWS mustered one last “pull up,” and then, with a tremendous shudder, the plane hit the water.</p><figure><figcaption>First Officer Ryan’s seat collapsed forward, causing him to strike his head. It was found still in that position when the plane was recovered. (NTSB)</figcaption></figure><p id="2ea2">The impact was hard, and over quickly. Within seconds, the plane ground to a halt, but its fuselage had cracked in two just ahead of the wings, and water was pouring in. By the time Captain Okai managed to undo his seatbelt, the water outside the plane was half way up his window, and it came rushing into the cockpit when he slid it open. Fighting against the inflow, he forced his way out the window and into the heaving ocean. Meanwhile, First Officer Ryan’s seat had collapsed forward on impact, causing him to strike his head, but he too managed to open his window and clamber out into the watery darkness. Now only one objective remained: to survive.</p><p id="ca82">In search of something to hang onto, Captain Okai swam toward the tail section, but no cargo or panels had come loose, so he simply grabbed the automatic direction finder antenna on the vertical stabilizer and hauled himself onto the top of the sinking empennage, where he clung to the tail as waves crashed over him. At the same time, First Officer Ryan held onto the nose section, but as it began to slip beneath the surface, he spotted a loose cargo pallet and climbed aboard, using it as a makeshift raft. He called his captain’s name, and Okai called his name in return, but Okai was in trouble, as waves repeatedly knocked him off his perch, forcing him to swim back again.</p><figure><figcaption>A Coast Guard helicopter and boat respond to the scene of the crash. (US Coast Guard)</figcaption></figure><p id="6569">Suddenly, the roar of a helicopter overcame the rumble of the waves, and floodlights illuminated the desperate scene. The Coast Guard had arrived! At that moment, a wave again swept Captain Okai into the water, but this time he became disoriented; he could no longer find the tail, which was rapidly sinking. Floundering in the heaving sea, he began inhaling water and jet fuel. Realizing that his captain’s life was in danger, First Officer Ryan pointed the helicopter toward the tail section, and the rescuers got the message. An elite rescue swimmer jumped from the hovering helicopter and swam to Okai’s aid, pulling him back from the brink at the last possible moment. The swimmer and the unconscious captain were then winched back aboard — at which point the rescue swimmer jumped right back in again to save First Officer Ryan. With Captain Okai in apparently critical condition, the helicopter departed without them, but the Coast Guard had a plan B: a rescue boat, which was just now arriving at the scene. Grabbing onto the First Officer’s cargo pallet, the rescue swimmer swam through the ocean, pushing the improvised raft ahead of him, until they reached the boat and were hoisted aboard.</p><p id="5445">Against all odds, having ditched their plane in the ocean in the middle of the night, both pilots had been saved in the nick of time.</p><p id="24ce">◊◊◊</p><figure><figcaption>The aft section of N810TA as seen on the bottom of the ocean. (NTSB)</figcaption></figure><p id="6b1c">When National Transportation Safety Board investigators arrived in Hawaii later that day, they knew from the publicly available air traffic control tapes that the pilots of flight 810 reported an inability to maintain altitude and a possible dual engine failure, leading to a forced landing on water at night. Although it was clear that the pilots were lucky to be alive — in fact both were released from hospital within 48 hours — little else about the nature of the events was immediately obvious. And with the plane, and its black boxes, sitting somewhere on the bottom of Mamala Bay, the only way to find out what happened was to ask the two men who were there.</p><p id="ff31">The interviews with the pilots, which have been publicly released, provide a glimpse into what the crew thought was going on during the emergency. Captain Okai reported believing that the number two (right) engine had failed, but that when First Officer Ryan told him the faulty engine was number one (left), he had no reason to disbelieve him. After all, Ryan was the one flying the plane, so he would have been in a better position to detect which side was lacking thrust. First Officer Ryan, for his part, stated in full confidence that the sound of the “thud” came from the left side, that the plane yawed to the left, and that he had always known it was the left engine that failed. Only after this did it become clear that the right engine was running very hot and was not producing enough thrust to keep them in the air. But both pilots agreed on one thing: they had no idea why the plane wouldn’t fly, and were eager to find out.</p><figure><figcaption>The forward fuselage and cockpit of N810TA came to rest some distance away. (NTSB)</figcaption></figure><p id="33d0">The recovery of the plane from under 110 to 130 meters (360 to 420 feet) of water ultimately took four months, but when the NTSB finally received the flight data and cockpit voice recordings, their contents underscored just how unreliable witness testimony can often be. In fact, the data showed that the right engine suddenly lost power about 7 seconds after liftoff, confirming Captain Okai’s initial impression that this engine had failed. Furthermore, the resulting yaw to the right was countered correctly by First Officer Ryan, showing that he knew which side had lost thrust. The cockpit voice recorder was even more unequivocal: in fact, both pilots explicitly stated that the right engine had failed. This was confirmed by metallurgical analysis, which showed that corrosion had led to at least one blade failure in the right engine’s high pressure turbine, but that no defects were present in the left engine until it hit the water.</p><p id="eaad">The error chain began minutes after the initial failure, when First Officer Ryan began reducing thrust on both engines toward idle in order to slow the plane from 250 to 220 knots. After this occurred, the pilots again revisited the question of which engine had failed, and came to a startlingly different conclusion. In his interview, Ryan said that in addition to the symptoms described earlier, he saw that the left engine’s EPR and other parameters had fallen to idle, leading him to a conclusion that this engine had failed. But the left engine was at idle because he put it there! How was it possible for him to have become so confused? In the end, we may never know for sure — but it is possible to say a lot more about why Captain Okai failed to notice.</p><figure><figcaption>Part of one of N810TA’s two JT8D engines lies on the sea floor. (NTSB)</figcaption></figure><p id="cbca">As pilot monitoring during the takeoff, it was Captain Okai’s primary responsibility to watch the instruments and note any abnormalities. But almost as soon as the failure occurred, he took it upon himself to declare an emergency to air traffic control, an effort which he admitted “became a project.” In fact, Okai spent one minute and 40 seconds in a confused exchange with the oversaturated controller before he finally returned his attention to the cockpit, demonstrating rather poor task prioritization. Ideally, he should have analyzed the situation first and declared an emergency second, and if the controller did not hear his emergency declaration, he could have used the transponder to “squawk” 7700, the universal emergency code, instead of wasting more time on the radio. But he did not.</p><p id="1e83">By the time Captain Okai returned his attention to the cockpit, First Officer Ryan had already rolled back both engines to idle and leveled off at 2,000 feet, eliminating the most salient clues as to which engine had failed. At this point, they found themselves outside the boundaries of the assumptions built into their training scenarios and emergency checklists. The procedures for responding to an engine failure on takeoff assumed two things: first, that one engine would stop producing power entirely, resulting in warnings and zeroes on gauges; and second, that the adverse yaw from the asymmetric thrust would persist, providing a powerful clue about which engine had failed. But in this case, neither of these assumptions held, because the right engine only suffered a partial loss of power, and by the time the pilots got around to formally identifying the failed engine some four minutes after takeoff, both engines were producing the same amount of thrust (very little), so the adverse yaw was gone. At that point the only obvious difference between the two sets of gauges would have been a higher temperature on the right engine. As a result, there was nothing to obviously indicate to Captain Okai that First Officer Ryan’s conclusion about the failed engine was wrong. There was nothing to indicate that it was right, either, but Okai’s trust in Ryan was apparently good enough. Had he attempted to verify this by advancing both thrust levers in turn, which is a prescribed procedure for identifying a failed engine, he would have realized that the left engine was fine, but he never tried.</p><figure><figcaption>A closer view of the damaged nose section. (NTSB)</figcaption></figure><p id="8224">Because the pilots never increased power on the left engine, the plane did not have enough thrust to maintain altitude, even with the right thrust lever fully forward, because they were relying only on the damaged right engine. At any point, the pilots could have averted the accident by simply moving the left thrust lever forward, which would be a sensible thing to do when one is about to hit the water, even if one believes that that engine has failed. After all, the worst that can happen is it doesn’t work, and in the best case scenario, it could save lives. But when the NTSB conducted follow-up interviews in March 2022 to clarify why, among other points, the pilots did not move the left thrust lever, both replied that it simply never occurred to them. By the time it had become clear that they could not maintain altitude, both pilots were suffering from tunnel vision, and were singularly focused on flying the airplane to the end, rather than thinking outside the box for solutions. And with their focus so consumed by the task of flying, no one even looked at the thrust levers, let alone considered moving them.</p><p id="66fa">Had the pilots completed the engine failure and shutdown checklist, which required moving the affected thrust lever to idle before cutting fuel, the pilots might have noticed that the left thrust lever had been at idle the whole time, and might have tried advancing it. But in the event, they never actually started the checklist, because by the time they got around to it, their flight path was no longer stable, and First Officer Ryan had decided that flying the plane was a higher priority. Captain Okai, for his part, told the NTSB that he thought the checklist would be useless once the second engine started to fail, so he didn’t order Ryan to finish it.</p><figure><figcaption>The aft section of N810TA is recovered from the water in November 2021. (NTSB)</figcaption></figure><p id="f4e3">In the end, the fact that the pilots rolled back the wrong engine was attributed to poor communication and insufficient procedural discipline. The flight operations manual included the following prescient warning: “<em>Any time an engine shutdown is required in flight, good crew coordination is essential. Airplane incidents have turned into airplane accidents as a result of the flight crew shutting down the incorrect engine. When the flight path is under complete control, the crew should proceed with a deliberate, systematic process that identifies the correct engine and ensures that the operating engine is not shut down.”</em> In the event, the flight path was stable at 2,000 feet for several minutes, but no “deliberate” or “systematic” attempt to identify the correct engine was ever carried out. Ultimately, this was the pilots’ biggest and most unfortunate mistake.</p><p id="899f">The NTSB also criticized Captain Okai for demonstrating poor task prioritization (communicating with ATC instead of analyzing the situation, failing to ensure that the checklist was performed in a timely manner); poor crew resource management (failing to trust but verify, failing to monitor his First Officer’s actions); and poor leadership (failing to establish a plan, failing to enforce adherence to procedures). However, investigators also wrote that many of his mistakes could have been influenced by stress, which is known to have effects similar to fatigue, including inhibited decision-making and reduced ability to conduct critical thinking.</p><p id="27a5">Although the NTSB pointed to the nature of the emergency itself as the possible source of his stress, it’s also worth noting that the cockpit voice recorder transcript supports a hypothesis that Captain Okai was already stressed before the flight even took off. He had been in a shouting match with another pilot less than 24 hours earlier and may have felt hurt or insulted by her refusal to fly with him. The salience of this event was clear, given that Okai spent a total of 32 minutes before the flight talking about his experiences with First Officer Moore, including after starting the engines and during taxi, in violation of the sterile cockpit rule, which prohibits off-topic conversations between engine start and 10,000 feet. This violation almost certainly had no effect on the course of events, but it did suggest that Okai was having difficulty focusing on the task at hand. In the end, the NTSB declined to mention these conversations in its final report, which is normal — most of the time, the agency doesn’t wade into pilots’ personal disputes — but when taken in context, it’s difficult to ignore.</p><p id="fa8b">◊◊◊</p><figure><figcaption>The nose section is loaded onto a barge. (NTSB)</figcaption></figure><p id="b3e4">Although the crash was the direct result of the flight crew’s actions, it’s worth summarizing the mechanical aspects before bowing out. The final report and its supporting documentation are light on details, but the cause of the failure seems to have been simple corrosion of either one or two high pressure turbine blades. The question of whether this corrosion was detectable during routine inspections, and why the corrosion appeared in the first place, don’t seem to have been addressed. However, given that the corrosion was internal to the blades, it’s possible that it was difficult to detect, which is supported by the NTSB’s explicit conclusion, stated in its report, that “maintenance was not a factor in this accident.” Furthermore, corrosion is an inevitability on airplanes and engines operating in Hawaii’s humid, salty climate, especially over long timeframes. The engine that failed was built in 1968 and was 53 years old at the time of the crash, plenty long enough to develop all manner of problems, especially if the maintenance was not always up to par.</p><p id="3bc1">There was plenty of circumstantial evidence to suggest that maintenance was a major problem area for Transair. Captain Okai said he had experienced five engine failures while flying 737s for Transair, which is a lot, and issues like high engine temperatures on takeoff were common. The airline’s chief maintenance inspector had also resigned two weeks before the crash, citing insufficient staffing, time, and experience. And according to a colleague, First Officer Ryan had previously called the airline’s safety culture “screwed up” and “beyond help.” These problems had been brewing in the background for some time, and in May 2022, the Federal Aviation Administration revoked Rhoades Aviation’s air operator certificate, permanently grounding Transair, after an investigation found numerous maintenance violations, including 33 flights performed with unairworthy engines. However, the investigation and its findings were said to have nothing to do with the accident, which was caused by an apparently undetectable issue.</p><p id="4122">◊◊◊</p><figure><figcaption>The underside of the nose section was heavily damaged during the impact. (NTSB)</figcaption></figure><p id="5789">With Transair having ceased to exist by the time the investigation concluded, and with very few Boeing 737–200s remaining in service in the United States, the NTSB did not issue any safety recommendations as a result of the accident. Nevertheless, as the latest example in a series of crashes involving shutdown of an incorrect engine, it’s worth extracting some lessons anyway. The crash of Transair flight 810 in particular evokes the 1989 disaster involving <a rel="noopener" href="https://admiralcloudberg.medium.com/lefts-rights-and-wrongs-the-crash-of-british-midland-flight-92-or-the-kegworth-air-disaster-a3989feb4d3a#:%7E:text=On%20the%208th%20of%20January,height%20of%20just%20900%20feet">British Midland flight 92</a>, another Boeing 737 that suffered a partial engine failure, only to crash short of the airport after the pilots mistakenly shut down the wrong engine. The reasons for the engine failures and for the pilots’ mistakes in both crashes were different — for instance, the British Midland investigation cited poorly designed gauges that were not installed on earlier 737–200s like that involved in the Transair crash. However, both cases were characterized by a lack of due care in determining the failed engine, including captains who uncritically believed their first officers’ unsupported and incorrect determinations.</p><figure><figcaption>An NTSB investigator examines the recovered nose section. (NTSB)</figcaption></figure><p id="967e">The fact that the same mistakes could occur again after 32 years underscores the need for pilots to double and triple check which engine has failed, but it also highlights the limitations of better training and words of caution in manuals as a solution to this recurring issue. As I mentioned in my article on the British Midland crash, the most effective way to prevent this kind of accident is by fitting airplanes with an Engine Indicating and Crew Alerting System, known as EICAS, or similar equipment. These systems automatically monitor engine performance and, should an engine fail, will produce a message informing the pilots which engine is the cause of the problem, dramatically reducing the probability of an incorrect identification. However, retrofitting the systems onto older 737s, which are most at risk, is not required and may be impractical or impossible. For that reason, as long as first and second generation 737s continue to fly, a safety risk still exists, and now that the findings of the Transair investigation have been released, that fact bears repeating: as long as pilots rely on context clues to determine which engine has failed, the opportunity for this type of error will remain. Let us merely be thankful that this latest warning did not come to us at the cost of lives — and let us not squander it.</p><p id="482b">_______________________________________________________________</p><p id="2a7e"><a href="https://www.reddit.com/r/CatastrophicFailure/comments/14nxu5c/2021_the_crash_of_transair_flight_810_a_boeing/?" rel="noopener ugc nofollow" target="_blank">Join the discussion of this article on Reddit</a></p><p id="72db"><a href="https://www.patreon.com/Admiral_Cloudberg" rel="noopener ugc nofollow" target="_blank">Support me on Patreon</a> (Note: I do not earn money from views on Medium!)</p><p id="b1bb"><a href="https://twitter.com/KyraCloudy" rel="noopener ugc nofollow" target="_blank">Follow me on Twitter</a></p><p id="5a52">Visit <a href="https://www.reddit.com/r/AdmiralCloudberg/" rel="noopener ugc nofollow" target="_blank">r/admiralcloudberg</a> to read and discuss over 240 similar articles</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What gets to the front page of Hacker News? (138 pts)]]></title>
            <link>https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news</link>
            <guid>36590226</guid>
            <pubDate>Tue, 04 Jul 2023 17:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news">https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news</a>, See on <a href="https://news.ycombinator.com/item?id=36590226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img src="https://randomshit.dev/images/hacker-news/front-page.png"></p>
<p>In my job as technical writer / marketer<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>, the most common question I get from companies I work with is “how do we get to the front page of Hacker News?” And as someone whose writing has been on said front page many times, I’ll tell you: <strong>I have no clue!</strong></p>
<p>Sometimes it seems like good, high quality writing always finds its way to the front page; other times, it feels like the mods are out to get you. So I started (very manually) collecting data on what the top 30 posts on HN are at the end of any given day.</p>
<p>Here are the highlights (FP = Front Page):</p>
<ul>
<li><strong>Blog posts</strong> (45%) are the most popular type of content on the FP</li>
<li>A blog post from a <strong>corporate entity</strong> only has a 8% shot at making the FP</li>
<li>25% of FP posts are blog posts from engineers on their <strong>personal blogs/sites or OSS</strong></li>
<li>36% of FP posts are <strong>news articles</strong>, and the (slight) majority of them are actually not about software/hardware</li>
<li>ShowHN posts almost never make the front page (&lt;2%)</li>
</ul>
<p>Here’s the breakdown more visually:</p>
<p><img src="https://randomshit.dev/images/hacker-news/top-30-by-category.png"></p>
<p>Before some more analysis and a few more charts, I want to preface this post by saying that I don’t mean to comment on the <em>inherent value</em> of getting your content to the front page of Hacker News. Whether this is the right goal, or if perhaps you should pursue a different goal like number of upvotes, or maybe comments, or maybe <em>angry</em> comments, is a discussion for another post.</p>
<h2>How I gathered and categorized the data</h2>
<p>The way I gathered this (small) data set was by manually<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> combing through the top 30 posts on Hacker News using the <a href="https://news.ycombinator.com/front"><code>past</code></a> feature. For each post, I clicked on the link to see what the content was about, who published it, and where. Partially in advance, and then partially on the fly the more stuff I saw, I classified each post into a category. Since my main focus is technical writing and marketing, the categories I chose relate to that lens:</p>
<ul>
<li>News / opinion articles in media publications</li>
<li>Academic journals and papers</li>
<li>Blog posts
<ul>
<li>Personal blog vs. a corporate blog vs. an open source entity</li>
<li>Types of content: tutorials, thought leadership, etc.</li>
</ul>
</li>
<li>Hiring announcements</li>
<li>ShowHN</li>
<li>Misc.
<ul>
<li>Repo links</li>
<li>Non-blog websites</li>
<li>Tweets, Reddit posts, etc.</li>
</ul>
</li>
</ul>
<p>These categories have excellent coverage (Misc. &lt;5%) despite them being oddly specific. You can see that I wasn’t particularly concerned with the <em>subject matter</em> per se (everything is about Rust anyway) but more the format and the authoring entity.</p>
<p>The astute reader will note several limitations of the data set. </p>
<p>First, the data I collected represents what <em>finished</em> the day on the front page of Hacker News. But many items will <em>be</em> on the front page over the course of a given day, and then end the day somewhere else (perhaps number 35, or 67). What “gets to” the front page – a group that contains, and exceeds the size of, what “ends” on the front page - is a richer data set but I do not have access to it / it may not exist.</p>
<p>Second, and perhaps more importantly, the dataset doesn’t record the <em>attempts</em> made to get to the front page, i.e. all posts on Hacker News in a given day. It’s possible that there are orders of magnitude more blog posts <em>posted</em>  but fewer that <em>make</em> the FP, whereas 95% of any academic paper submitted makes the front page (extreme figures used for illustrative purposes). So for simplicity, I’ll say “the likelihood of making the FP” which assumes a constant rate of conversion from post to FP across different categories.</p>
<p>Limitations aside, the results started to converge very clearly after only 5 or 6 days of data, although there were a few outlier days with spikes in a particular category. In total I collected and sifted through 30 days worth of data, and hope to add more in the future.</p>
<h2>What kinds of blog posts get to the front page?</h2>
<p>Statistically, your best shot of getting your writing to the front page of Hacker News is by writing something (with nothing to promote) on your personal website or blog. 26% of total FP posts are blogs like this, while only 11% of total FP posts (or 24% of FP <em>blog</em> posts) came from corporate<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> entities on their corporate blogs or websites. 20% of blog posts are from some sort of open source entity (usually launches).</p>
<p>On the subject of what to post, <a href="https://news.ycombinator.com/newsguidelines.html">the Hacker News guidelines</a> say:</p>
<blockquote>
<p><em>On-Topic: Anything that good hackers would find interesting. That includes more than hacking and startups. If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity.</em></p>
</blockquote>
<p>and this is pretty much the story with what blog posts make the FP. </p>
<p><img src="https://randomshit.dev/images/hacker-news/blog-posts.png"></p>
<p>Of those corporate blog posts, about 40% of them are product announcements or launches; the rest are less promotional content formats like technical tutorials. A common question I get is “how do we get our product launch on the front page of HackerNews?” and the answer is that it’s statistically<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> highly unlikely (~4%) for that to happen. And of those product announcements that made the FP, a good deal of them are (a) from established companies and products like Apple, (b) posted organically by the community, and (c) about hardware and gaming. Not your software startup.</p>
<p>Personal blog posts, though, are highly popular on the FP. They span the gamut from tutorials to “how I built ___” type posts, and of course the perennial “I made a thing.” Here are a few examples of personal blog posts that made the FP:</p>
<ul>
<li><a href="https://tavianator.com/2023/futex.html">You could have invented Futexes</a></li>
<li><a href="https://jingnanshi.com/blog/groebner_basis.html">Use Gröbner Bases To Solve Polynomial Equations</a></li>
<li><a href="https://www.milanvit.net/post/my-ultimate-shell-setup-with-fish-shell-and-tmux/">My ultimate shell setup with Fish shell and Tmux</a></li>
<li><a href="https://ariadne.space/2023/04/13/writing-portable-arm64-assembly/">Writing portable ARM64 assembly</a></li>
</ul>
<p>The common thread is that they’re non-promotional, and typically focus on a personal pursuit of the author<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>.</p>
<p>My personal experience writing for corporate entities says that useful tutorials and interesting stories do the best. The most recent post I wrote that made it to #1 was a tutorial for PlanetScale about how database sharding works (HN post <a href="https://news.ycombinator.com/item?id=35476518">here</a>). A few others I wrote that made the FP were all non-promotional:</p>
<ul>
<li>My two stories for Retool about why Accenture (<a href="https://news.ycombinator.com/item?id=26969364">link</a>) and Oracle (<a href="https://news.ycombinator.com/item?id=29004597">link</a>) are worth so much money</li>
<li>My blog post for WorkOS about best practices for building webhooks (<a href="https://news.ycombinator.com/item?id=26401838">link</a>)</li>
<li>My “thought leadership” for PlanetScale about DBA experience (<a href="https://news.ycombinator.com/item?id=28330297">link</a>)</li>
</ul>
<p>These successes live next door to a massive graveyard of blog posts I’ve written that <em>I</em> thought were really good, but Hacker News did not. Or perhaps randomness just reared its ugly head. </p>
<h2>What kinds of news gets to the front page?</h2>
<p>The second biggest category of posts that make the front page of Hacker News is (shocker) news, which I define here as a story or opinion piece published by a media organization. 36% of FP items are news, which is a lot!</p>
<p>While almost all of the news that makes the FP is STEM related, the majority of it (well, by a few percentage points) doesn’t relate to software or hardware. There are a lot of articles about space exploration and rockets, biology and chemistry, and physics, but fewer about code and SaaS and things like that. </p>
<p><img src="https://randomshit.dev/images/hacker-news/news.png"></p>
<p>It’s worth noting that I didn’t see a single article from TechCrunch in the entire dataset I gathered, despite there being plenty of articles for places like the Verge, Wired, etc. A cursory search using <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;query=techcrunch&amp;sort=byPopularity&amp;type=story">Algolia’s Search HackerNews tool</a>, ordered by number of upvotes, reveals that HackerNews really does not like TechCrunch very much.</p>
<p><img src="https://randomshit.dev/images/hacker-news/techcrunch.png"></p>
<h2>Miscellaneous findings and other things</h2>
<p>6% of items on the front page are academic papers, which is more than I thought.</p>
<p>ShowHN is very valuable, but is not likely to land your product on the front page.</p>
<p>Tweets and tweet threads sometimes make the front page.</p>
<p>It’s uncommon for hiring or launch posts - the two types of posts that are reserved for YC companies, and “artificially” promoted by moderators - to make the front page.</p>
<p>You can access the underlying dataset <a href="https://docs.google.com/spreadsheets/d/1iUYmm4PRFbRi6KmDztRyCDiaHOLjsze4zT6Ts4-qbxk/edit?usp=sharing">here</a>.</p>
<p>I want to thank <a href="https://github.com/minimaxir">Max Woolf</a> (who may recall interviewing me for a Data Science job at Buzzfeed that I thankfully did not take) for the excellent <a href="https://github.com/minimaxir/hacker-news-undocumented">“Hacker News Undocumented”</a> resource. It was tremendously helpful. </p>
<hr>
<h2>Footnotes</h2>
<section data-footnotes="">
<p id="user-content-fn-1">1. With an undergrad Data Science degree for some reason <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-2">2. For the empathetic reader wondering why I did this manually when there are tons of ways for the author (who, as mentioned in the previous footnote, has a Data Science degree) to access historical Hacker News data via <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news?project=flowing-bonito-366719">BigQuery</a>, <a href="https://github.com/HackerNews/API">API</a>, etc. – the amount of effort it would have taken to train a classifier would have been highly impractical, plus I’d need to manually label the data anyway. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-3">3. By this I mean closed source, basically. Anything written on the blog of a company that is selling something. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-4">4. Noting once again that this framing isn’t entirely fair, since the dataset is missing attempts. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-5">5. Which makes me wonder if the best “front page strategy” might be to encourage your engineering team to work on their personal blogs? <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</section>
</div></div>]]></description>
        </item>
    </channel>
</rss>