<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 17 Jan 2026 12:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[You have three minutes to escape the perpetual underclass – geohot (101 pts)]]></title>
            <link>https://geohot.github.io//blog/jekyll/update/2026/01/17/three-minutes.html</link>
            <guid>46656256</guid>
            <pubDate>Sat, 17 Jan 2026 08:23:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geohot.github.io//blog/jekyll/update/2026/01/17/three-minutes.html">https://geohot.github.io//blog/jekyll/update/2026/01/17/three-minutes.html</a>, See on <a href="https://news.ycombinator.com/item?id=46656256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I had a dream last night I went to work at Amazon. Joining the Bezos neofeudal empire. This post is directed at anyone with talent who works at a tech company ushering in this future.</p>

<hr>


<p>Have you thought about how this is going to play out? I understand you may be at a place where you are insecure about money, and that insecurity is what drives you. But why do you think having more money will fix that insecurity?</p>

<p>In the future, when labor is fully marginalized and capital is the only force, you will not be able to afford GPT$$$ (it’s $1B per month), only the billionaires will. GPT$$$ is surely smart enough to separate you from whatever you have, be that with targeting advertising, a scam you fall for, or lobbying your government to take it from you.</p>

<p>A pile of money will buy you nothing in the neofeudal world.</p>

<hr>


<p>Historically, there has been some loyalty to the subjects of a feudal empire because labor had some value. You needed the peasants to grow the grain so you could tax it and take it and have leverage over others by having grain to offer them. When the grain is produced by machines, the peasants are cut out of the loop.</p>

<p>The solution to this is not to accumulate grain, buy shares in a granary, or anything else like that. They will find a way to make whatever you have worthless. Because the feudal world didn’t operate on capitalist principles, and neither will the neofeudal world.</p>

<hr>


<p>If you work at a large company, if you work according to the principles of modern capitalism, where all the fish will be eaten by the bigger fish, and all will be eaten by the sharks, and all the sharks will be eaten by bigger sharks, you are actively bringing about the system that will kill you.</p>

<p><b>Have you considered not participating?</b> If you participate, we all lose. We will either all be in the underclass together or not.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FLUX.2 [Klein]: Towards Interactive Visual Intelligence (164 pts)]]></title>
            <link>https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence</link>
            <guid>46653721</guid>
            <pubDate>Fri, 16 Jan 2026 23:46:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence">https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence</a>, See on <a href="https://news.ycombinator.com/item?id=46653721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><strong>FLUX.2 [klein]: Towards Interactive Visual Intelligence</strong></h2><p>Today, we release the FLUX.2 [klein] model family, our fastest image models to date. FLUX.2 [klein] unifies generation and editing in a single compact architecture, delivering state-of-the-art quality with end-to-end inference as low as under a second. Built for applications that require real-time image generation without sacrificing quality, and runs on consumer hardware with as little as 13GB VRAM.</p><p><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein#try-demo"><strong><span>Try it now for free here</span></strong></a></p><p><img alt="" draggable="false" loading="lazy" width="1280" height="720" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=1920&amp;q=75 1x, https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=3840&amp;q=75 2x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=3840&amp;q=75"></p><p><em>Demo showing editing with FLUX.2 [klein]</em></p><h3><strong>Why go [klein]?</strong></h3><p>Visual Intelligence is entering a new era. As AI agents become more capable, they need visual generation that can keep up; models that respond in real-time, iterate quickly, and run efficiently on accessible hardware.</p><p>The <em>klein</em> name comes from the German word for "small", reflecting both the compact model size and the minimal latency. But FLUX.2 [klein] is anything but limited. These models deliver exceptional performance in text-to-image generation, image editing and multi-reference generation, typically reserved for much larger models.</p><h3><strong>What's New</strong></h3><ul><li><span>Sub-second inference. Generate or edit images in under 0.5s on modern hardware.</span></li><li><span>Photorealistic outputs and high diversity, especially in the base variants.</span></li><li><span>Unified generation and editing. Text-to-image, image editing, and multi-reference support in a single model while delivering frontier performance.</span></li><li><span>Runs on consumer GPUs. The 4B model fits in ~13GB VRAM (RTX 3090/4070 and above).</span></li><li><span>Developer-friendly &amp; Accessible: Apache 2.0 on 4B models, open weights for 9B models. Full open weights for customization and fine-tuning.</span></li><li><span>API and open weights. Production-ready API or run locally with full weights.</span></li></ul><p><em>Note: The “FLUX [dev] Non-Commercial License” has been renamed to “FLUX Non-Commercial License” and will apply to the 9B Klein models. No material changes have been made to the license.</em></p><p><img alt="" draggable="false" loading="lazy" width="2127" height="1400" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F41055678178f6fe75ca618b854b195e48dfc55ed-2127x1400.jpg&amp;w=3840&amp;q=75 1x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F41055678178f6fe75ca618b854b195e48dfc55ed-2127x1400.jpg&amp;w=3840&amp;q=75"></p><p><em>Text to Image collage using FLUX.2 [klein]</em></p><h3><strong>The FLUX.2 [klein] Model Family</strong></h3><h4><strong>FLUX.2 [klein] 9B</strong></h4><p>Our flagship small model. Defines the Pareto frontier for quality vs. latency across text-to-image, single-reference editing, and multi-reference generation. Matches or exceeds models 5x its size - in under half a second. Built on a 9B flow model with 8B Qwen3 text embedder, step-distilled to 4 inference steps.</p><p>Combine multiple input images, blend concepts, and iterate on complex compositions - all at sub-second speed with frontier-level quality. No model this fast has ever done this well.</p><p><strong>License</strong>: FLUX NCL</p><p><img alt="" draggable="false" loading="lazy" width="4544" height="2805" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F86adb8bf9ea077f3aebe392af1077f0337ed9c48-4544x2805.jpg&amp;w=3840&amp;q=75 1x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F86adb8bf9ea077f3aebe392af1077f0337ed9c48-4544x2805.jpg&amp;w=3840&amp;q=75"></p><p><em>Imagine editing collage using FLUX.2 [klein]</em></p><h4><strong><br>FLUX.2 [klein] 4B:</strong></h4><p>Fully open under Apache 2.0. Our most accessible model, it runs on consumer GPUs like the RTX 3090/4070. Compact but capable: supports T2I, I2I, and multi-reference at quality that punches above its size. Built for local development and edge deployment.</p><p><strong>License</strong>: Apache 2.0<br></p><h4><strong>FLUX.2 [klein] Base 9B / 4B:</strong></h4><p>The full-capacity foundation models. Undistilled, preserving complete training signal for maximum flexibility. Ideal for fine-tuning, LoRA training, research, and custom pipelines where control matters more than speed. Higher output diversity than the distilled models.</p><p><strong>License</strong>: 4B Base under Apache 2.0, 9B Base under FLUX NCL</p><p><img alt="" draggable="false" loading="lazy" width="2127" height="1400" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F900de0722995119df9f27d799bdfed194d2112ac-2127x1400.jpg&amp;w=3840&amp;q=75 1x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F900de0722995119df9f27d799bdfed194d2112ac-2127x1400.jpg&amp;w=3840&amp;q=75"></p><p><em>Output Diversity using FLUX.2 [klein]<br></em></p><h4><strong>Quantized versions</strong></h4><p>We are also releasing FP8 and NVFP4 versions of all [klein] variants, developed in collaboration with NVIDIA for optimized inference on RTX GPUs. Same capabilities, smaller footprint - compatible with even more hardware.</p><ul><li><span><strong>FP8:</strong> Up to 1.6x faster, up to 40% less VRAM</span></li><li><span><strong>NVFP4:</strong> Up to 2.7x faster, up to 55% less VRAM</span></li></ul><p><em>Benchmarks on RTX 5080/5090, T2I at 1024×1024<br></em>Same licenses apply: Apache 2.0 for 4B variants, FLUX NCL for 9B.</p><h4><strong><br>Performance Analysis</strong></h4><p><img alt="" draggable="false" loading="lazy" width="3548" height="1173" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F8ece18115cc75a4d34c42eda81a68bbd78048666-3548x1173.jpg&amp;w=3840&amp;q=75 1x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F8ece18115cc75a4d34c42eda81a68bbd78048666-3548x1173.jpg&amp;w=3840&amp;q=75"></p><p><img alt="" draggable="false" loading="lazy" width="3541" height="1173" decoding="async" data-nimg="1" srcset="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2Fc29dea8ec862d79ecdc82e8013f37ee22a148cb8-3541x1173.jpg&amp;w=3840&amp;q=75 1x" src="https://bfl.ai/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2Fc29dea8ec862d79ecdc82e8013f37ee22a148cb8-3541x1173.jpg&amp;w=3840&amp;q=75"></p><p><strong><em>FLUX.2 [klein] Elo vs Latency (top) and VRAM (bottom) across Text-to-Image, Image-to-Image Single Reference, and Multi-Reference tasks.</em></strong>&nbsp;<em>FLUX.2 [klein] matches or exceeds Qwen's quality at a fraction of the latency and VRAM, and outperforms Z-Image while supporting both text-to-image generation and (multi-reference) image editing in a unified model. The base variants trade some speed for full customizability and fine-tuning, making them better suited for research and adaptation to specific use cases. Speed is measured on a GB200 in bf16.</em></p><h3><strong>Into the New</strong></h3><p>FLUX.2 [klein] is more than a faster model. It's a step toward our vision of interactive visual intelligence. We believe the future belongs to creators and developers with AI that can see, create, and iterate in real-time. Systems that enable new categories of applications: real-time design tools, agentic visual reasoning, interactive content creation.</p><h3><strong>Resources</strong></h3><p><strong>Try it</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein#try-demo">Demo</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/play">Playground</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://huggingface.co/spaces/black-forest-labs/FLUX.2-klein-9B">HF Space for [klein] 9B</a>, <a target="_blank" rel="noindex nofollow" href="https://huggingface.co/spaces/black-forest-labs/FLUX.2-klein-4B">HF Space for [klein] 4B</a></span></li></ul><p><strong>Build with it</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://docs.bfl.ai/flux_2/flux2_overview#flux-2-%5Bklein%5D-models">Documentation</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://github.com/black-forest-labs/flux2">GitHub</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://huggingface.co/collections/black-forest-labs/flux2">Model Weights</a></span></li></ul><p><strong>Learn more</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein">https://bfl.ai/models/flux-2-klein</a></span></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation (126 pts)]]></title>
            <link>https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables</link>
            <guid>46652617</guid>
            <pubDate>Fri, 16 Jan 2026 21:42:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables">https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables</a>, See on <a href="https://news.ycombinator.com/item?id=46652617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb" data-is-cws-richtext="true"><h3><span>Introduction</span></h3>
<p><span>Mandiant is </span><a href="https://research.google/resources/datasets/?dataset_types=other&amp;search=Net-NTLMv1&amp;" rel="noopener" target="_blank"><span>publicly releasing</span></a><span> a comprehensive dataset of Net-NTLMv1 rainbow tables to underscore the urgency of migrating away from this outdated protocol. Despite Net-NTLMv1 being deprecated and known to be insecure for over two decades—with cryptanalysis dating back to 1999—Mandiant consultants continue to identify its use in active environments. This legacy protocol leaves organizations vulnerable to trivial credential theft, yet it remains prevalent due to inertia and a lack of demonstrated immediate risk.</span></p>
<p><span>By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1. While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys. The release of this dataset allows defenders and researchers to recover keys in under 12 hours using consumer hardware costing less than $600 USD. This initiative highlights the amplified impact of combining Mandiant's frontline expertise with Google Cloud's resources to eliminate entire classes of attacks.</span></p>
<p><span>This post details the generation of the tables, provides access to the dataset for community use, and outlines critical remediation steps to disable Net-NTLMv1 and prevent authentication coercion attacks.</span></p>
<h3><span>Background</span></h3>
<p><span>Net-NTLMv1 has been widely known to be insecure since at least 2012, following presentations at DEFCON 20, with cryptanalysis of the underlying protocol </span><a href="https://www.schneier.com/academic/archives/1999/09/cryptanalysis_of_mic_1.html" rel="noopener" target="_blank"><span>dating back to at least 1999</span></a><span>. On Aug. 30, 2016, Hashcat </span><a href="https://github.com/hashcat/hashcat/commit/71a8459d851d246945343ea59effa1d46b965bf8" rel="noopener" target="_blank"><span>added support</span></a><span> for cracking Data Encryption Standard (DES) keys using known plaintext, further democratizing the ability to attack this protocol. Rainbow tables are almost as old, with the initial paper on rainbow tables published in </span><a href="https://infoscience.epfl.ch/record/99512/files/Oech03.pdf" rel="noopener" target="_blank"><span>2003 by Philippe Oechslin</span></a><span>, citing an earlier iteration of a time-memory trade-off from </span><a href="http://www-ee.stanford.edu/~hellman/publications/36.pdf" rel="noopener" target="_blank"><span>1980 by Martin Hellman</span></a><span>.</span></p>
<p><span>Essentially, if an attacker can obtain a Net-NTLMv1 hash without Extended Session Security (ESS) for the known plaintext of </span><code>1122334455667788</code><span>, a cryptographic attack, referred to as a known plaintext attack (KPA), can be applied. This guarantees recovery of the key material used. Since the key material is the password hash of the authenticating Active Directory (AD) object—user or computer—the attack results can quickly be used to compromise the object, often leading to privilege escalation.</span></p>
<p><span>A common chain attackers use is authentication coercion from a highly privileged object, such as a domain controller (DC). Recovering the password hash of the DC machine account allows for DCSync privileges to compromise any other account in AD.</span></p>
<h3><span>Dataset Release</span></h3>
<p><span>The unsorted dataset can be downloaded using <code>gsutil -m cp -r gs://net-ntlmv1-tables/tables .</code>&nbsp;or through the </span><a href="https://research.google/resources/datasets/?dataset_types=other&amp;search=Net-NTLMv1&amp;" rel="noopener" target="_blank"><span>Google Cloud Research Dataset portal</span></a><span>.&nbsp;</span></p>
<p><span>The SHA512 hashes of the tables can be checked by first downloading the checksums <code>gsutil -m cp gs://net-ntlmv1-tables/tables.sha512 .</code> then checked by <code>sha512sum -c tables.sha512</code>. </span><span>The password cracking community has already created derivative work and is also hosting the ready to use tables.</span></p>
<h3><span>Use of the Tables</span></h3>
<p><span>Once a Net-NTLMv1 hash has been obtained, the tables can be used with historical or modern reinventions of rainbow table searching software such as </span><a href="https://www.kali.org/tools/rainbowcrack/" rel="noopener" target="_blank"><span>rainbowcrack (rcrack)</span></a><span>, or </span><a href="https://github.com/inAudible-NG/RainbowCrack-NG" rel="noopener" target="_blank"><span>RainbowCrack-NG</span></a><span> on central processing units (CPUs) or a </span><a href="https://github.com/blurbdust/rainbowcrackalack" rel="noopener" target="_blank"><span>fork</span></a><span> of </span><a href="https://github.com/jtesta/rainbowcrackalack" rel="noopener" target="_blank"><span>rainbowcrackalack</span></a><span> on graphics processing units (GPUs). The Net-NTLMv1 hash needs to be preprocessed to the DES components using </span><a href="https://github.com/evilmog/ntlmv1-multi" rel="noopener" target="_blank"><span>ntlmv1-multi</span></a><span> as shown in the next section</span><span>.</span></p>
<h3><span>Obtaining a Net-NTLMv1 Hash</span></h3>
<p><span>Most attackers will use </span><a href="https://github.com/lgandx/Responder" rel="noopener" target="_blank"><span>Responder</span></a><span> with the <code>--lm</code> and <code>--disable-ess</code>&nbsp;flags and set the authentication to a static value of <code>1122334455667788</code> to only allow for connections with Net-NTLMv1 as a possibility. Attackers can then wait for incoming connections or coerce authentication using a tool such as </span><a href="https://github.com/topotam/PetitPotam" rel="noopener" target="_blank"><span>PetitPotam</span></a><span> or </span><a href="https://github.com/Wh04m1001/DFSCoerce" rel="noopener" target="_blank"><span>DFSCoerce</span></a><span> to generate incoming connections from DCs or lower privilege hosts that are useful for objective completion. Responses can be cracked to retrieve password hashes of either users or computer machine accounts. A sample workflow for an attacker is shown below in Figure 1, Figure 2, and Figure 3.</span></p></div><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig1.max-800x800.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig1.max-800x800.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 1: DFSCoerce against a DC</p></div></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig2.max-600x600.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig2.max-600x600.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 2: Net-NTLMv1 hash obtained for DC machine account</p></div></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig3.max-800x800.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig3.max-800x800.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 3: Parse Net-NTLMv1 hash to DES parts</p></div></section><section><p><span>Figure 4 illustrates the processing of the Net-NTLMv1 hash to the DES ciphertexts.</span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig4.max-2100x2100.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig4.max-2100x2100.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 4: Net-NTLMv1 hash to DES ciphertexts</p></div></section><section><p><span>An attacker then takes the split-out ciphertexts to crack the keys used based on the known plaintext of <code>1122334455667788</code> with the steps of loading the tables shown in Figure 5 and cracking results in Figure 6 and Figure 7.</span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig5.max-1100x1100.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig5.max-1100x1100.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 5: Loading DES components for cracking</p></div></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig6.max-500x500.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig6.max-500x500.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 6: First hash cracked</p></div></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig7.max-1400x1400.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig7.max-1400x1400.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 7: Second hash cracked and run statistics</p></div></section><section><p><span>An attacker can then calculate the last remaining key with ntlmv1-multi once again, or look it up with </span><a href="https://github.com/sensepost/assless-chaps" rel="noopener" target="_blank"><span>twobytes</span></a><span>, to recreate the full NT hash for the DC account with the last key part shown in Figure 8.</span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig8.max-600x600.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig8.max-600x600.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 8: Calculate remaining key</p></div></section><section><p><span>The result can be checked with hashcat's </span><a href="https://github.com/hashcat/hashcat/pull/2607" rel="noopener" target="_blank"><span>NT hash shucking mode</span></a><span>, <code>-m 27000</code>, as shown in Figure 9.</span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig9.max-800x800.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig9.max-800x800.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 9: Keys checked with hash shucking</p></div></section><section><p><span>An attacker can then use the hash to perform a </span><a href="http://attack.mitre.org/techniques/T1003/006/" rel="noopener" target="_blank"><span>DCSync attack</span></a><span> targeting a DC and authenticating as the now compromised machine account. The attack flow uses </span><a href="https://github.com/fortra/impacket/blob/master/examples/secretsdump.py" rel="noopener" target="_blank"><span>secretsdump.py</span></a><span> from the </span><a href="https://github.com/fortra/impacket" rel="noopener" target="_blank"><span>Impacket</span></a><span> toolsuite and is shown in Figure 10.</span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig10.max-1100x1100.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/net-ntlmv1-fig10.max-1100x1100.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Figure 10: DCSync attack performed</p></div></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/topics/threat-intelligence" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/threat-intelligence" track-metadata-module="tag list" track-metadata-module_headline="posted in">Threat Intelligence</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LWN is currently under the heaviest scraper attack seen yet (184 pts)]]></title>
            <link>https://social.kernel.org/notice/B2JlhcxNTfI8oDVoyO</link>
            <guid>46651887</guid>
            <pubDate>Fri, 16 Jan 2026 20:37:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.kernel.org/notice/B2JlhcxNTfI8oDVoyO">https://social.kernel.org/notice/B2JlhcxNTfI8oDVoyO</a>, See on <a href="https://news.ycombinator.com/item?id=46651887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>
Conversation
  </p>

<div id="selected">
  <div>
    <a href="https://social.kernel.org/users/corbet" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a0f71e0fdbdc366c471a559808722f7a26efbc44f8ee40047d004619e50e636d.jpg" title="corbet" alt="corbet">
      </p>
    </a>
  </div>
  <div><p>
So <span><a data-user="AtYuB7yJ6QP99m4p2u" href="https://fedi.lwn.net/@lwn" rel="ugc">@<span>lwn</span></a></span> is currently under the heaviest scraper attack seen yet.  It is a DDOS attack involving tens of thousands of addresses, and that is affecting the responsiveness of the site, unfortunately.</p><p>There are many things I would like to do with my time.  Defending LWN from AI shitheads is rather far from the top of that list.  I *really* don't want to put obstacles between LWN and its readers, but it may come to that.</p><p>(Another grumpy day, sorry)


        </p></div>
</div>


<div>
  <div>
    <a href="https://toot.community/@tmcfarlane" rel="author noopener">
      <p><img width="48" height="48" src="https://static.toot.community/accounts/avatars/109/304/599/835/735/989/original/adadebc48e5f4ade.jpg" title="tmcfarlane@toot.community" alt="tmcfarlane@toot.community">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> this, combined with search engines prioritising the stolen content!<br>  This is why I think the web is genuinely doomed. It's not enough to steal the content, for search engines to kill click thtoughs and ad revenues, they are literally killing the ability of original authors to serve the traffic to the few real users that might want to see it.<br>  Devastating.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://discuss.systems/@allan_christoffersen" rel="author noopener">
      <p><img width="48" height="48" src="https://fd.discuss.systems/accounts/avatars/112/252/599/873/823/251/original/322aac261aac9ad7.png" title="allan_christoffersen@discuss.systems" alt="allan_christoffersen@discuss.systems">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <br>As a avid longtime subscriber and reader, I can only give thanks and hope you will survive also this blast of willfully wrong behaviour. Thank you for your openness.</p>

    </div>
</div>


<div>
    <a href="https://fosstodon.org/@nirik" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.fosstodon.org/accounts/avatars/000/291/057/original/a54ec97321f8a7e8.jpg" title="nirik@fosstodon.org" alt="nirik@fosstodon.org">
      </p>
    </a>
  </div>


<div>
  <div>
    <a href="https://mastodon.nz/@foxylad" rel="author noopener">
      <p><img width="48" height="48" src="https://o.mastodon.nz/accounts/avatars/109/243/033/803/743/777/original/37f897a22740874f.jpg" title="foxylad@mastodon.nz" alt="foxylad@mastodon.nz">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> Any inkling which AI (Arsehole Incorporated) it is? The crash can't come soon enough.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://social.kernel.org/users/corbet" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a0f71e0fdbdc366c471a559808722f7a26efbc44f8ee40047d004619e50e636d.jpg" title="corbet" alt="corbet">
      </p>
    </a>
  </div>
  <div>

        <p><span><a data-user="AQ4eVxiZShOc1eVrLk" href="https://mastodon.nz/@foxylad" rel="ugc">@<span>foxylad</span></a></span> <span><a data-user="AtYuB7yJ6QP99m4p2u" href="https://fedi.lwn.net/@lwn" rel="ugc">@<span>lwn</span></a></span> There is no way to know who is after the data.  The actual attack is likely perpetrated by Bright Data or one of its equally vile competitors.


        </p>

    </div>
</div>


<div>
  <div>
    <a href="https://metroholografix.ca/@sb" rel="author noopener">
      <p><img width="48" height="48" src="https://metroholografix.ca/system/accounts/avatars/113/693/497/687/169/085/original/1c93c78540d71a29.png" title="sb@metroholografix.ca" alt="sb@metroholografix.ca">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <br>Just speaking with my user hat on here, but given the circumstances I don't mind the ever-so-slight inconvenience of an <a href="https://metroholografix.ca/tags/anubus" rel="tag">#<span>anubus</span></a> challenge.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://pony.social/@cadey" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.pony.social/accounts/avatars/106/500/315/995/032/015/original/c44f58f46bbe9097.jpg" title="cadey@pony.social" alt="cadey@pony.social">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> If you need help, email me. I can work with you in case there's low hanging fruit that you missed.</p>

    </div>
</div>


<div>
    <a href="https://social.tchncs.de/@wuffel" rel="author noopener">
      <p><img width="48" height="48" src="https://f2.tchncs.de/accounts/avatars/000/155/160/original/2c9818a8cb01e936.png" title="wuffel@social.tchncs.de" alt="wuffel@social.tchncs.de">
      </p>
    </a>
  </div>


<div>
  <div>
    <a href="https://mstdn.party/@sheep" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a9fd291a909d161561d7e31470fbdd45ca9c30d040507611013af367d8da0686.png" title="sheep@mstdn.party" alt="sheep@mstdn.party">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> Obviously that sucks, but I am super happy with the RSS integration that I get with my lwn subscription. People who are affected by the outage should check that out. Not really a solution, but maybe part of one.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://social.ayushnix.com/@ayushnix" rel="author noopener">
      <p><img width="48" height="48" src="https://social.ayushnix.com/fileserver/01WH8ESJVCBZV23NQP6JV947XQ/attachment/original/01JZM8JR5JVXPZEP8P43ZBCESK.jpeg" title="ayushnix@social.ayushnix.com" alt="ayushnix@social.ayushnix.com">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> I'm not sure how people in the kernel community reconcile using LLMs with the effect these LLMs have on small businesses and individuals hosting their websites for fun and it's not as if the kernel community itself isn't affected by these incessant DDoS attacks.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://society.oftrolls.com/@suihkulokki" rel="author noopener">
      <p><img width="48" height="48" src="https://society.oftrolls.com/system/accounts/avatars/000/017/391/original/8844460ac49b95ba.jpg" title="suihkulokki@society.oftrolls.com" alt="suihkulokki@society.oftrolls.com">
      </p>
    </a>
  </div>
  <div>
<p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> subscriber.lwn.net that is only available for subscribers. One can either join the que with AI bots for lwn.net or subscribe and enjoy the snappy subscriber server.</p><p>I mean that's not a great solution, but it's the only one that works.</p>


        </div>
</div>


<div>
    <a href="https://mastodon.social/@1div0" rel="author noopener">
      <p><img width="48" height="48" src="https://files.mastodon.social/accounts/avatars/000/598/376/original/8fab022a3689800d.png" title="1div0@mastodon.social" alt="1div0@mastodon.social">
      </p>
    </a>
  </div>


<div>
  <div>
    <a href="https://mastodon.social/@Alonely0" rel="author noopener">
      <p><img width="48" height="48" src="https://files.mastodon.social/accounts/avatars/110/681/847/424/236/626/original/a96103531485c6b0.jpeg" title="Alonely0@mastodon.social" alt="Alonely0@mastodon.social">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> at this point we might as well be offensive. If the client seems even slightly sus, just send them gibberish data talking about how good Chihuahua muffins are. Ideally LLM-generated (yes, gross) because this doesn't add new information (linear algebra yay) and makes models collapse (aka AI inbreeding).</p>

    </div>
</div>


<div>
  <div>
    <a href="https://chaos.social/@eazy" rel="author noopener">
      <p><img width="48" height="48" src="https://assets.chaos.social/accounts/avatars/000/080/887/original/ec17aae91074229b.jpg" title="eazy@chaos.social" alt="eazy@chaos.social">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> feel you. Same with my Podcast Directory</p>

    </div>
</div>


<div>
  <div>
    <a href="https://mastodon.ie/@dec23k" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.masto.host/mastodonie/accounts/avatars/109/294/420/470/083/565/original/e4aa324b482bd55c.png" title="dec23k@mastodon.ie" alt="dec23k@mastodon.ie">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://pony.social/@cadey">@<span>cadey</span></a></span> <span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <br>I recently saw a traffic spike to a small HTML-only website that never had WP on it, but was suddenly getting failed wp-admin logins and hundreds of PHP vuln scans, non stop. All from MSFT IP addresses. Abuse reports were sent, but there was no response, and the abuse kept happening.<br>So now I'm blocking every MSFT CIDR block that I can find, server-wide.</p>

    </div>
</div>


<div>
  <div>
    <a href="https://c.im/@sbb" rel="author noopener">
      <p><img width="48" height="48" src="https://s3.c.im/accounts/avatars/111/129/674/717/500/119/original/314a224dd5980b68.jpg" title="sbb@c.im" alt="sbb@c.im">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> I've been experiencing about 20x more website traffic than normal, myself. It's very likely this scraper bot traffic as well. Things are holding, but only because I took pains to use static site generation (absolutely minimal Javascript, designed to be lightweight).</p>

    </div>
</div>


<div>
  <div>
    <a href="https://social.kernel.org/users/corbet" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a0f71e0fdbdc366c471a559808722f7a26efbc44f8ee40047d004619e50e636d.jpg" title="corbet" alt="corbet">
      </p>
    </a>
  </div>
  <div>
<p><span><a data-user="AQ8XbCUm1bVwG4RwZs" href="https://society.oftrolls.com/@suihkulokki" rel="ugc">@<span>suihkulokki</span></a></span> <span><a data-user="AtYuB7yJ6QP99m4p2u" href="https://fedi.lwn.net/@lwn" rel="ugc">@<span>lwn</span></a></span> The problem with that solution is that it may well make it harder for us to bring in new subscribers, which is something we definitely want to do.  First impressions matter, so giving new folks a poor experience seems ... not great.</p><p>It may yet come to that, though.


        </p></div>
</div>


<div>
  <div>
    <a href="https://floss.social/@jani" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.masto.host/floss/accounts/avatars/114/414/267/336/681/853/original/2d6785bd4aafc2c8.png" title="jani@floss.social" alt="jani@floss.social">
      </p>
    </a>
  </div>
  <div>
<p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <span><a href="https://society.oftrolls.com/@suihkulokki">@<span>suihkulokki</span></a></span> </p><p>Maybe it doesn't need to be subscriber only, just registered users only? Which can also be a PITA, but if there's no enshittification for non-registered users other than the bandwidth being shared with bots, maybe it's tolerable? Could even have a banner about this explaining the benefits of registering, and how LWN won't sell your data.</p>


        </div>
</div>


<div>
  <div>
    <a href="https://social.kernel.org/users/corbet" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a0f71e0fdbdc366c471a559808722f7a26efbc44f8ee40047d004619e50e636d.jpg" title="corbet" alt="corbet">
      </p>
    </a>
  </div>
  <div>
<p><span><a data-user="AtYFKz4ovs7aLQhkbg" href="https://floss.social/@jani" rel="ugc">@<span>jani</span></a></span> <span><a data-user="AtYuB7yJ6QP99m4p2u" href="https://fedi.lwn.net/@lwn" rel="ugc">@<span>lwn</span></a></span> <span><a data-user="AQ8XbCUm1bVwG4RwZs" href="https://society.oftrolls.com/@suihkulokki" rel="ugc">@<span>suihkulokki</span></a></span> Such things have crossed our minds, certainly.  The gotcha there is that we've already had troubles with bots creating accounts; I don't think they would hesitate to do more of that if that would improve their access.</p><p>That and, of course, the fact that everybody starts as an unregistered user.  As long as we can avoid making the experience worse for them, I think we should.


        </p></div>
</div>


<div>
  <div>
    <a href="https://floss.social/@jani" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.masto.host/floss/accounts/avatars/114/414/267/336/681/853/original/2d6785bd4aafc2c8.png" title="jani@floss.social" alt="jani@floss.social">
      </p>
    </a>
  </div>
  <div>
<p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <span><a href="https://society.oftrolls.com/@suihkulokki">@<span>suihkulokki</span></a></span> </p><p>Yeah, it's hard to argue against that.</p><p>And maybe you weren't seeking for "helpful" advice anyway, but, uh, you know your audience. :)</p>


        </div>
</div>


<div>
  <div>
    <a href="https://social.kernel.org/users/corbet" rel="author noopener">
      <p><img width="48" height="48" src="https://social.kernel.org/media/a0f71e0fdbdc366c471a559808722f7a26efbc44f8ee40047d004619e50e636d.jpg" title="corbet" alt="corbet">
      </p>
    </a>
  </div>
  <div>

        <p><span><a data-user="AtYFKz4ovs7aLQhkbg" href="https://floss.social/@jani" rel="ugc">@<span>jani</span></a></span> <span><a data-user="AtYuB7yJ6QP99m4p2u" href="https://fedi.lwn.net/@lwn" rel="ugc">@<span>lwn</span></a></span> <span><a data-user="AQ8XbCUm1bVwG4RwZs" href="https://society.oftrolls.com/@suihkulokki" rel="ugc">@<span>suihkulokki</span></a></span> Suggestions are much appreciated!  It's not as if we've figured all this stuff out...


        </p>

    </div>
</div>


<div>
  <div>
    <a href="https://society.oftrolls.com/@suihkulokki" rel="author noopener">
      <p><img width="48" height="48" src="https://society.oftrolls.com/system/accounts/avatars/000/017/391/original/8844460ac49b95ba.jpg" title="suihkulokki@society.oftrolls.com" alt="suihkulokki@society.oftrolls.com">
      </p>
    </a>
  </div>
  <div>
<p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> The "harder to onboard new users" part is certainly one reason why that solution isn't great </p><p>I just don't really see anything else working long term. Everything else is just kind whack-a-mole where the mole keeps getting more clever.</p>


        </div>
</div>


<div>
    <a href="https://social.treehouse.systems/@mupuf" rel="author noopener">
      <p><img width="48" height="48" src="https://cache.treehouse.systems/accounts/avatars/114/404/123/165/197/547/original/bcec43caeff8ce6f.png" title="mupuf@social.treehouse.systems" alt="mupuf@social.treehouse.systems">
      </p>
    </a>
  </div>


<div>
    <a href="https://floss.social/@jani" rel="author noopener">
      <p><img width="48" height="48" src="https://cdn.masto.host/floss/accounts/avatars/114/414/267/336/681/853/original/2d6785bd4aafc2c8.png" title="jani@floss.social" alt="jani@floss.social">
      </p>
    </a>
  </div>


<div>
  <div>
    <a href="https://social.treehouse.systems/@mupuf" rel="author noopener">
      <p><img width="48" height="48" src="https://cache.treehouse.systems/accounts/avatars/114/404/123/165/197/547/original/bcec43caeff8ce6f.png" title="mupuf@social.treehouse.systems" alt="mupuf@social.treehouse.systems">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://floss.social/@jani">@<span>jani</span></a></span> <span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <span><a href="https://society.oftrolls.com/@suihkulokki">@<span>suihkulokki</span></a></span> Sorry, I was being too optimistic... I was thinking they wanted sources with high SNR... But you are probably right...</p>

    </div>
</div>


<div>
  <div>
    <a href="https://metalhead.club/@lkundrak" rel="author noopener">
      <p><img width="48" height="48" src="https://media.metalhead.club/accounts/avatars/111/414/337/428/922/859/original/f446360b650617aa.png" title="lkundrak@metalhead.club" alt="lkundrak@metalhead.club">
      </p>
    </a>
  </div>
  <div>

        <p><span><a href="https://social.kernel.org/users/corbet">@<span>corbet</span></a></span> <span><a href="https://fedi.lwn.net/@lwn">@<span>lwn</span></a></span> <span><a href="https://floss.social/@jani">@<span>jani</span></a></span> <span><a href="https://society.oftrolls.com/@suihkulokki">@<span>suihkulokki</span></a></span> one day the photocopiers will get busy after the office hours again, but this time it's going to be linux weekly news instead of the punk fanzines</p>

    </div>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slop is everywhere for those with eyes to see (274 pts)]]></title>
            <link>https://www.fromjason.xyz/p/notebook/slop-is-everywhere-for-those-with-eyes-to-see/</link>
            <guid>46651443</guid>
            <pubDate>Fri, 16 Jan 2026 20:03:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fromjason.xyz/p/notebook/slop-is-everywhere-for-those-with-eyes-to-see/">https://www.fromjason.xyz/p/notebook/slop-is-everywhere-for-those-with-eyes-to-see/</a>, See on <a href="https://news.ycombinator.com/item?id=46651443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   

<p>The size of your plate can influence how much food you eat. The absence of a clock on a casino wall can keep you gambling through the early morning. On social media, our For You Pages give us the illusion of infinite content. How our environments are designed influences how we consume. And wouldn't you know it, everything around us is designed for maximum consumption.</p>
<p>Open TikTok, and you can easily burn through a hundred videos or more before you glance at the time. It doesn't help that the For You Page <a href="https://www.wired.com/story/tiktok-time/">hides the time</a> on our phones.</p>
<p>We are over consuming content on the FYP. The sudden surge of low-quality, AI-generated content, i.e. “AI slop,” is a byproduct of that overconsumption. We don't see it because, well, we're conditioned not to, but slop always arrives on time. Slop is inevitable. Slop is quintessential. Slop is everywhere for those with eyes to see.</p>
<p>Olive oil, wasabi, saffron, vanilla, Wagyu, honey, champagne, and truffle,...reality TV, all hold examples of what happens when <em>demand</em> exceeds <em>supply</em>— companies fill the gap with slop. The free market loves a good filler. So, why should the digital realm be any different?</p>
<p>The For You page is designed to keep us playing the dopamine slot machine for as long as possible. The Average Time on Site metric is still the goose that lays the golden eggs, and both TikTok and Meta are reporting that their egg baskets have never been fuller.</p>
<p>But, there's a problem. On any given platform, only 1-3% of users publish content. It's called the <a href="https://www.nngroup.com/articles/participation-inequality/">90-9-1 rule</a>, and platforms that rely on free user generated content have been trying to solve this problem since the beginning of the commercialized web. The introduction of the For You Page, and the illusion of endless content, has only exasperated the inequity.</p>
<p>Curation used to be part of our media consumption process. We would hop from website to website looking for a laugh. We used to <em>click on hyperlinks</em> for Christ's sake. Now, all we must do is sit at the trough￼ and let daddy Zuck feed us.</p>
<p>In a <a href="https://www.joanwestenberg.com/how-convenience-kills-curiosity/">recent essay</a>, Joan Westenberg makes a complementary argument that the algorithm has “flattened” curiosity by eliminating the need to “hunt” for our content. They go on to say:</p>
<blockquote>
<p>There’s a concept in behavioral science called the “effort heuristic.” It’s the idea that we tend to value information more if we worked for it. The more effort something requires, the more meaning we assign to the result. When all knowledge is made effortless, it’s treated as disposable. There’s no awe, no investment, no delight in the unexpected—only consumption.</p>
</blockquote>
<p>(I'm reminded of the scene in Jurassic Park when the tour Jeep pulls up to the Tyrannosaurus rex exhibit. Doctor Grant says￼ <em>“The T-Rex doesn't want to be fed. It wants to hunt.”</em>)</p>
<p>￼This type of mindless consumption is not only harming our curiosity, it's helping to cheapen creativity for the people who produce what we consume.</p>
<p>Creativity isn't scalable. Content creation has a hard productivity ceiling. Every human-created video on our feeds require some level of writing, production, and editing. Yet the For You Page has made the content consumption so efficient, that perhaps demand has exceeded supply.</p>
<p>If you're a product manager for a social media platform, you can reduce the friction of publishing content to the app, or ship better editing tools, but you can't optimize creative spark. You can't treat humans like content-generating machines (as much as they have tried). Despite the illusion of infinite scrolling thanks to the FYP, art remains a finite resource bound to the whims of human creativity.</p>
<p>You see their problem.</p>
<p>Mark Zuckerberg wants us on his platforms, flicking our thumbs, for as long as possible. But the more we open Instagram, the more creators he needs posting multiple times each day. Mark has very little control over this variable. Creators could suddenly post less, or simply stop posting all together, and there's nothing he could do about it. What's worse, creators could demand Meta pay them for their art.</p>
<p><em>Could you imagine?</em></p>
<p>Actually, yes. And it turns out, you could rather effectively kill a platform if you got a small group of top creators organized and angry.</p>
<h2 id="twenty-on-the-vine" tabindex="-1">Twenty on the Vine <a href="#twenty-on-the-vine">#</a></h2>
<p>In the summer of 2016, twenty social media personalities took down one of the largest mobile video apps on the internet. They wanted money for their labor. The executives at Vine said no. The gang of twenty, who were the highest performing creators on the app, walked away. They stopped posting entertaining content to Vine, and instead repeatedly implored their followers to find them on competing apps.</p>
<p>Vine shut down for good just months later.</p>
<p>From <em><a href="https://archive.ph/eNqBI">Inside the secret meeting of Vine stars that ushered in the app’s demise</a></em>:</p>
<blockquote>
<p>Vine’s spectacular rise and fall showed the power of online creators. Its demise offers crucial lessons for platforms trying to engage with power users — and a deeper understanding of who ultimately controls a social product.</p>
</blockquote>
<p>Vine creators exposed and exploited a weakness in Vine's conventional approach to social media. Follower count had power. Old-style discovery algorithms could be easily manipulated. Vine creators used that power to take over the app, and convinced users to migrate to other platforms.</p>
<p>You see why follower counts are less important today, and why black-box algorithms have full control over who goes viral and who gets “shadow banned.” TikTok saw the mistakes of its predecessor, and made it so content creators could never exercise collective influence again.</p>
<p>Because virality now feels more like gambling, I suspect people post more content today than a decade ago. But it's not enough. Our insatiable appetites for content is pushing for corporations to meet that demand with slop. ￼</p>
<p>If it were up to TikTok and Meta, our feeds would be exclusively robot-made. Humans are a variable they cannot control, and I think they despise us for it.</p>
<p>Anyway, I have good news. Outside of our FYPs you'll find a surplus of art, essays, articles, and videos just waiting to be discovered. And best of all, these artists and writers are making things on their own terms. We, too, can enjoy the products of their labor on our terms, while not giving a dime of our attention to big tech.</p>
<p>This is the open web. Or the social web. Or the open social web. Or the-- you get the point. To find it, you must reacquaint yourself with the lost art of surfing the web.</p>
<p>Surfing the web is very different than scrolling the FYP. You don't often hear the words ”mindful” and “internet” together but, surfing the web was an art of mindful consumption that doesn't much exist today. Not to get all <em>old man yells at cloud</em> at you, but maybe we should bring it back?</p>
<p>Up next: <em>The Lost Art of Surfing The Web</em> (coming soon)</p>

 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reading across books with Claude Code (108 pts)]]></title>
            <link>https://pieterma.es/syntopic-reading-claude/</link>
            <guid>46650347</guid>
            <pubDate>Fri, 16 Jan 2026 18:49:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pieterma.es/syntopic-reading-claude/">https://pieterma.es/syntopic-reading-claude/</a>, See on <a href="https://news.ycombinator.com/item?id=46650347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>LLMs are overused to summarise and underused to help us read deeper.</p>
<p>To explore how they can enrich rather than reduce, I set Claude Code up with tools to mine a library of 100 non-fiction books.
It found sequences of excerpts connected by an interesting idea, or <em>trails</em>.</p>

<p>Here’s a part of one such trail, linking deception in the startup world to the social psychology of mass movements (I’m especially pleased by the jump from Jobs to Theranos):</p>

<h2 id="how-it-works">How it works</h2>
<p><img src="https://pieterma.es/_astro/pipeline.Bl0o8nI__2728Xv.webp" alt="Pipeline diagram" loading="lazy" decoding="async" fetchpriority="auto" width="3396" height="1194"> </p>
<p>The books were selected from Hacker News’ favourites, which I previously <a href="https://hnbooks.pieterma.es/" rel="nofollow" target="_blank">scraped and visualized</a>.</p>
<p>Claude browses the books a chunk at a time. A chunk is a segment of roughly 500 words that aligns with paragraphs when possible.
This length is a good balance between saving tokens and providing enough context for ideas to breathe.</p>
<p>Chunks are indexed by topic, and topics are themselves indexed for search. This makes it easy to look up all passages in the corpus that relate to, say, <em>deception</em>.</p>
<p>This works well when you know what to look for, but search alone can’t tell you which topics are present to begin with.
There are over 100,000 extracted topics, far too many to be browsed directly. To support exploration, they are grouped into a hierarchical tree structure.</p>
<p>This yields around 1,000 top-level topics. They emerge from combining lower-level topics, and not all of them are equally useful:</p>
<ul>
<li><em>Incidents that frustrated Ev Williams</em></li>
<li><em>Names beginning with “Da”</em></li>
<li><em>Events between 1971 &amp; 1974</em></li>
</ul>
<p>However, this <a href="https://en.wikipedia.org/wiki/The_Analytical_Language_of_John_Wilkins" rel="nofollow" target="_blank">Borgesian</a> taxonomy is good enough for Claude to piece together what the books are about.</p>
<p>Claude uses the topic tree and the search via a few CLI tools.<br>
They allow it to:</p>
<ul>
<li>Find all chunks associated with a topic similar to a query.</li>
<li>Find topics which occur in a window of chunks around a given topic.</li>
<li>Find topics that co-occur in multiple books.</li>
<li>Browse topics and chunks that are siblings in the topic tree.</li>
</ul>
<p>To generate the trails, the agent works in stages.</p>
<p><img src="https://pieterma.es/_astro/agent_steps.CPyESBEq_Z2rjTaW.webp" alt="Generate ideas, research a trail, connect the highlights" loading="lazy" decoding="async" fetchpriority="auto" width="1553" height="228"></p>
<ol>
<li>First, it scans the library and the existing trails, and proposes novel trail ideas. It mainly browses the topic tree to find unexplored areas and rarely reads full chunks in depth.</li>
<li>Then, it takes a specific idea and turns it into a trail. It receives seed topics from the previous stage and browses many chunks.
It extracts excerpts, specific sequences of sentences, and decides on how best to order them to support an insight.</li>
<li>Finally, it adds highlights and edges between consecutive excerpts.</li>
</ol>
<h2 id="what-i-learned">What I learned</h2>
<h3 id="claude-code-is-great-for-non-coding-tasks">Claude Code is great for non-coding tasks</h3>
<p>Even though I’ve been using Claude Code to develop for months, my first instinct for this project was to consider it as a traditional pipeline of several discrete stages.
My initial attempt at this system consisted of multiple LLM modules with carefully hand-assembled contexts.</p>
<p>On a whim, I ran Claude with access to the debugging tools I’d been using and a minimal prompt: <em>“find something interesting.”</em>
It immediately did a better job at pulling in what it needed than the pipeline I was trying to tune by hand, while requiring much less orchestration.
It was a clear improvement to push as much of the work into the agent’s loop as possible.</p>
<p>I ended up using Claude as my main interface to the project.<br>
Initially I did so because it inferred the sequence of CLI calls I wanted to run faster than I could recall them.
Then, I used it to automate tasks which weren’t rigid enough to be scripted traditionally.</p>
<p>The latter opened up options that I wouldn’t have considered before.
For example, I changed my mind on how short I wanted excerpts to be.
I communicated my new preference to Claude, which then looked through all the existing trails and edited them as necessary, balancing the way the overall meaning of the trail changed.
Previously, I would’ve likely considered all previous trails to be outdated and generated new ones, because the required edits would’ve been too nuanced to specify.</p>
<p>In general, agents have widened my ambitions.<br>
By taking care of the boilerplate, I no longer shy away from the tedious parts.
Revision is cheap, so I don’t need to plow ahead with suboptimal choices just because it’d be too costly to undo them.
This, in turn, keeps up the momentum and lets me focus on the joyful, creative aspects of the work.</p>
<h3 id="ask-the-agent-what-it-needs">Ask the agent what it needs</h3>
<p>My focus went from optimising prompts to implementing better tools for Claude to use, moving up a rung on the abstraction ladder.</p>
<p>My mental model of the AI component changed: from a function mapping input to output, to a coworker I was assisting.
I spent my time thinking about the affordances that would make the workflow better, as if I were designing them for myself.
That they were to be used by an agent was a mere detail.</p>
<p>This worked because the agent is now intelligent enough that the way it uses these tools overlaps with my own mental model.
It is generally easy to empathise with it and predict what it will do.</p>
<p>Initially I watched Claude’s logs closely and tried to guess where it was lacking a certain ability.
Then I realised I could simply ask it to provide feedback at the end and list the functionality it wished it had.
Claude was excellent at proposing new commands and capabilities that would make the work more efficient.</p>
<p>Claude suggested improvements, which Claude implemented, so Claude could do the work better.
At least I’m still needed to pay for the tokens — for now.</p>
<h3 id="novelty-is-a-useful-guide">Novelty is a useful guide</h3>
<p>It’s hard to quantify <em>interestingness</em> as an objective to optimise for.<br>
<a href="https://trails.pieterma.es/book/13/" rel="nofollow" target="_blank">Why Greatness Cannot Be Planned</a> makes the case that chasing <em>novelty</em> is often a more fruitful approach.
While its conclusions are debated, I’ve found this idea to be a good fit for this project.</p>
<p>As a sign of the times, this novelty search was implemented in two ways:</p>
<ol>
<li>By biasing the search algorithm towards under-explored topics and books.</li>
<li>By asking Claude nicely.</li>
</ol>
<p>A topic’s novelty score was calculated as the mean distance from its embedding’s <em>k</em> nearest neighbors. A book’s novelty score is the average novelty of the unique topics that it contains.
This value was used to rank search results, so that those which were both relevant and novel were more likely to be seen.</p>
<p>On a prompting level, Claude starts the ideation phase by looking at all the existing trails and is asked to avoid any conceptual overlap.
This works fairly well, though it is often distracted by any topics related to secrecy, systems theory, or tacit knowledge.</p>
<p>It’s as if the very act of finding connections in a corpus summons the spirit of Umberto Eco and amps up the conspiratorial thinking.</p>
<h2 id="how-its-implemented">How it’s implemented</h2>
<p><img src="https://pieterma.es/_astro/implementation.CNN37YWY_Z1HGHsR.webp" alt="Implementation diagram" loading="lazy" decoding="async" fetchpriority="auto" width="1591" height="1959"></p>
<ul>
<li>EPUBs are parsed using <a href="https://github.com/rushter/selectolax" rel="nofollow" target="_blank"><code>selectolax</code></a>, which I picked over BeautifulSoup for its speed and simpler API.</li>
<li>Everything from the plain text to the topic tree is stored in SQLite. Embeddings are stored using <a href="https://github.com/asg017/sqlite-vec" rel="nofollow" target="_blank"><code>sqlite-vec</code></a>.</li>
<li>The text is split into sentences using <a href="https://github.com/superlinear-ai/wtpsplit-lite" rel="nofollow" target="_blank"><code>wtpsplit</code></a> (the <code>sat-6l-sm</code> model).
Those sentences are then grouped into chunks, trying to get up to 500 words without breaking up paragraphs.</li>
<li>I used <a href="https://dspy.ai/" rel="nofollow" target="_blank"><code>DSPy</code></a> to call LLMs. It worked well for the structured data extraction and it was easy to switch out different models to experiment.
I tried its prompt optimizers before I went full agentic, and their results were very promising.</li>
<li>I settled on Gemini 2.5 Flash Lite for topic extraction.
The model gets passed a chunk and is asked to return 3-5 topics. It is also asked whether the chunk is <em>useful</em>, in order to filter out index entries, acknowledgements, orphan headers, etc.
I was surprised at how stable these extracted topics were: similar chunks often shared some of the exact same topic labels.
Processing 100 books used about 60M input tokens and ~£10 in total.</li>
<li>After a couple books got indexed, I shared the results with Claude Opus along with the original prompt and asked it to improve it.
This is a half-baked single iteration of the type of prompt optimisation DSPy implements, and it worked rather well.</li>
<li>Topic pairs with a distance below a threshold get merged together. This takes care of near-duplicates such as <em>“Startup founder”</em>, <em>“Startup founders”</em>, and <em>“Founder of startups”</em>.</li>
<li>The CLI output uses a semi-XML format. In order to stimulate navigating, most output is nested with related content. For example, when searching for a topic, chunks are shown with the other topics they contain.
This allows us to get a sense of what the chunk is about, as well as which other topics might be interesting.
There’s probably more token-efficient formats, but I never hit the limit of the context window.</li>
</ul>
<pre tabindex="0" data-language="xml"><code><span><span>&lt;</span><span>topics</span><span> query</span><span>=</span><span>"</span><span>deception</span><span>"</span><span> count</span><span>=</span><span>"</span><span>1</span><span>"</span><span>&gt;</span></span>
<span><span>  &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>47193</span><span>"</span><span> books</span><span>=</span><span>"</span><span>7</span><span>"</span><span> score</span><span>=</span><span>"</span><span>0.0173</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Deception</span><span>"</span><span>&gt;</span></span>
<span><span>    &lt;</span><span>chunk</span><span> id</span><span>=</span><span>"</span><span>186</span><span>"</span><span> book</span><span>=</span><span>"</span><span>1</span><span>"</span><span>&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>47192</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Business deal</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>47108</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Internal conflict</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>46623</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Startup founders</span><span>"</span><span>/&gt;</span></span>
<span><span>    &lt;/</span><span>chunk</span><span>&gt;</span></span>
<span><span>    &lt;</span><span>chunk</span><span> id</span><span>=</span><span>"</span><span>1484</span><span>"</span><span> book</span><span>=</span><span>"</span><span>4</span><span>"</span><span>&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>51835</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Gawker Media</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>53006</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Legal Action</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>52934</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Maskirovka</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>52181</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Strategy</span><span>"</span><span>/&gt;</span></span>
<span><span>    &lt;/</span><span>chunk</span><span>&gt;</span></span>
<span><span>    &lt;</span><span>chunk</span><span> id</span><span>=</span><span>"</span><span>2913</span><span>"</span><span> book</span><span>=</span><span>"</span><span>9</span><span>"</span><span>&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>59348</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Blood testing system</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>59329</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Elizabeth Holmes</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>59352</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Investor demo</span><span>"</span><span>/&gt;</span></span>
<span><span>      &lt;</span><span>topic</span><span> id</span><span>=</span><span>"</span><span>59349</span><span>"</span><span> label</span><span>=</span><span>"</span><span>Theranos</span><span>"</span><span>/&gt;</span></span>
<span><span>    &lt;/</span><span>chunk</span><span>&gt;</span></span>
<span><span>  &lt;/</span><span>topic</span><span>&gt;</span></span>
<span><span>&lt;/</span><span>topics</span><span>&gt;</span></span></code></pre>
<ul>
<li>
<p>Topics are embedded using <code>google/embeddinggemma-300m</code> and reranked using <code>BAAI/bge-reranker-v2-m3</code>.</p>
</li>
<li>
<p>Many CLI tools require loading the embedding model and other expensive state. The first call transparently starts a separate server process which loads all these resources once and holds onto them for a while.
Subsequent CLI calls use this server through Python’s <code>multiprocessing.connection</code>.</p>
</li>
<li>
<p>The topic collection is turned into a graph (backed by <code>igraph</code>) by adding edges based on the similarity of their embeddings and the point-wise mutual information of their co-occurrences.</p>
</li>
<li>
<p>The graph is turned into a tree by applying <a href="https://leidenalg.readthedocs.io/en/stable/" rel="nofollow" target="_blank">Leiden</a> partitioning recursively until a minimum size is reached.
I tried the Surprise quality function because it had no parameters to tweak, and found it to be good enough. Each group is labelled by Gemini based on all the topics that it contains.</p>
</li>
<li>
<p>Excerpts are cleaned by Gemini to remove EPUB artifacts, parsing errors, headers, footnotes, etc.
Doing this only for excerpts that are actually shown, instead of during pre-processing, saved a lot of tokens.</p>
</li>
</ul> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Our approach to advertising and expanding access to ChatGPT (247 pts)]]></title>
            <link>https://openai.com/index/our-approach-to-advertising-and-expanding-access/</link>
            <guid>46649577</guid>
            <pubDate>Fri, 16 Jan 2026 18:02:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/our-approach-to-advertising-and-expanding-access/">https://openai.com/index/our-approach-to-advertising-and-expanding-access/</a>, See on <a href="https://news.ycombinator.com/item?id=46649577">Hacker News</a></p>
Couldn't get https://openai.com/index/our-approach-to-advertising-and-expanding-access/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[STFU (871 pts)]]></title>
            <link>https://github.com/Pankajtanwarbanna/stfu</link>
            <guid>46649142</guid>
            <pubDate>Fri, 16 Jan 2026 17:32:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Pankajtanwarbanna/stfu">https://github.com/Pankajtanwarbanna/stfu</a>, See on <a href="https://news.ycombinator.com/item?id=46649142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">STFU 🤫</h2><a id="user-content-stfu-" aria-label="Permalink: STFU 🤫" href="#stfu-"></a></p>
<p dir="auto">i was at bombay airport. some dude was watching reels on full volume and laughing loudly. asking nicely doesn't work anymore. me being me, didn't have the courage to speak up.</p>
<p dir="auto">so i built a tiny app that plays back the same audio it hears, delayed by ~2 seconds. asked claude, it spat out a working version in one prompt. surprisingly WORKS.</p>
<p dir="auto">discussion - <a href="https://x.com/the2ndfloorguy/status/2011734249871954188" rel="nofollow">https://x.com/the2ndfloorguy/status/2011734249871954188</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">the science (probably)</h2><a id="user-content-the-science-probably" aria-label="Permalink: the science (probably)" href="#the-science-probably"></a></p>
<p dir="auto">something something auditory feedback loop something something cognitive dissonance. idk i'm not a neuroscientist. all i know is it makes people shut up and that's good enough for me.</p>
<blockquote>
<p dir="auto">straight up honest - originally called this "make-it-stop" but then saw <a href="https://x.com/TimDarcet" rel="nofollow">@TimDarcet</a> also built <a href="https://tim.darcet.fr/shutthefuckup/" rel="nofollow">similar</a> and named it STFU. wayyyyy better name. so stole it. sorry not sorry.</p>
</blockquote>
<hr>
<p dir="auto">made with spite and web audio api. do whatever you want with it.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[East Germany balloon escape (547 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/East_Germany_balloon_escape</link>
            <guid>46648916</guid>
            <pubDate>Fri, 16 Jan 2026 17:16:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/East_Germany_balloon_escape">https://en.wikipedia.org/wiki/East_Germany_balloon_escape</a>, See on <a href="https://news.ycombinator.com/item?id=46648916">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/East_Germany_balloon_escape: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Dell UltraSharp 52 Thunderbolt Hub Monitor (239 pts)]]></title>
            <link>https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories</link>
            <guid>46648885</guid>
            <pubDate>Fri, 16 Jan 2026 17:14:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories">https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories</a>, See on <a href="https://news.ycombinator.com/item?id=46648885">Hacker News</a></p>
Couldn't get https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Canada slashes 100% tariffs on Chinese EVs to 6% (420 pts)]]></title>
            <link>https://electrek.co/2026/01/16/canada-breaks-with-us-slashes-100-tariffs-chinese-evs/</link>
            <guid>46648778</guid>
            <pubDate>Fri, 16 Jan 2026 17:05:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2026/01/16/canada-breaks-with-us-slashes-100-tariffs-chinese-evs/">https://electrek.co/2026/01/16/canada-breaks-with-us-slashes-100-tariffs-chinese-evs/</a>, See on <a href="https://news.ycombinator.com/item?id=46648778">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="777" src="https://electrek.co/wp-content/uploads/sites/3/2026/01/Canada-China-trade-deal.png?w=1600" alt="Canada China trade deal" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Canada-China-trade-deal.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Canada-China-trade-deal.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Canada-China-trade-deal.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Canada-China-trade-deal.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>In a massive shift in North American trade policy, Prime Minister Mark Carney announced today a new “strategic partnership” with China that effectively reopens the Canadian border to Chinese electric vehicles.</p>



<p>The move marks a significant departure from the United States’ hardline protectionist stance and could bring affordable EV options like the BYD Seagull to Canadian roads as early as this year.</p>



<p>For the last two years, Canada has largely walked in lockstep with the US regarding Chinese EV tariffs. Following the Biden administration’s move to impose 100% tariffs on Chinese EVs, Canada implemented similar surtaxes, effectively freezing companies like BYD, Nio, and Zeekr out of the market.</p>



<p>Today, that ice is breaking.</p>	
	



<p>As part of a broader trade agreement secured by Prime Minister Carney in Beijing this week, Canada has agreed to allow an annual quota of <strong>49,000 Chinese electric vehicles</strong> into the country at the tariff rate of just <strong>6.1%</strong>.</p>



<p>According to the <a target="_blank" rel="noreferrer noopener" href="https://www.pm.gc.ca/en/news/news-releases/2026/01/16/prime-minister-carney-forges-new-strategic-partnership-peoples">Prime Minister’s office</a>, this volume represents less than 3% of the Canadian new vehicle market. However, the deal explicitly targets the low end of the market, with the government anticipating that within five years, “more than 50% of these vehicles will be affordable EVs with an import price of less than $35,000.”</p>



<p>In exchange for opening the EV floodgates (or at least starting to break the dam), China has agreed to lower tariffs on Canadian canola seed from roughly 85% to 15% and to lift restrictions on Canadian lobster and crab.</p>



<p>The Canadian government claims this isn’t just about imports. The text of the agreement states that the deal is expected to “drive considerable new Chinese joint-venture investment in Canada” to build out the domestic EV supply chain.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>While 49,000 vehicles might sound like a small number compared to the total market, it’s a specific, targeted wedge that changes the entire dynamic of the North American EV market.</p>



<p>For years, we at <em>Electrek</em> have argued that protectionism, while perhaps protecting legacy automaker jobs in the short term, ultimately hurts consumers and slows down the transition to sustainable transport.</p>




	<p>Meanwhile, protecting domestic automakers from Chinese competition in their home market makes them less competitive on the global stage, virtually giving the global market to China.</p>



<p>The reality is that Chinese automakers are currently building some of the best, most affordable EVs in the world. Keeping them out entirely not only hurts consumers but also hurts innovation.</p>



<p>Of course, this is going to make Washington furious. The US has been trying to build a “Fortress North America” against Chinese EVs. By letting 49,000 units in tariff-free (or near tariff-free), Canada is effectively saying it values affordable climate solutions (and canola exports) more than complete alignment with US industrial policy, which is understandable since the US was the one to go hostile on trade with Canada.</p>



<p>The interesting detail here is the “Joint Venture” language. It looks like Carney is taking a page out of China’s own playbook. Canada seems to be using this quota as a carrot to get companies like BYD or CATL to set up shop in Canada and maybe help Canadian companies learn from those giants.</p>
	<p><a target="_blank" rel="nofollow" href="https://google.com/preferences/source?q=https://electrek.co" aria-label="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-dark.png" alt="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-light.png" alt="Add Electrek as a preferred source on Google">
		</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[6-Day and IP Address Certificates Are Generally Available (426 pts)]]></title>
            <link>https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability</link>
            <guid>46647491</guid>
            <pubDate>Fri, 16 Jan 2026 15:37:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability">https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability</a>, See on <a href="https://news.ycombinator.com/item?id=46647491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        
      
      
      
        <p>
          By Matthew McPherrin · 
          
            
            
            <time datetime="2026-01-15T00:00:00+00:00">January 15, 2026</time>
          
        </p>
      
      
    </div><div>
      <p>Short-lived and IP address certificates are now generally available from Let’s Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‘shortlived’ <a href="https://letsencrypt.org/docs/profiles/">certificate profile</a> in their ACME client.</p>
<p>Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate’s private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate’s expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced.</p>
<p>Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well.</p>
<p>Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, <a href="https://letsencrypt.org/2025/12/02/from-90-to-45">as previously announced</a>.</p>
<p>IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let’s Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our <a href="https://letsencrypt.org/2025/07/01/issuing-our-first-ip-address-certificate">post announcing our first IP Certificate</a>.</p>
<p>We’d like to thank the Open Technology Fund and Sovereign Tech Agency, along with our <a href="https://www.abetterinternet.org/sponsors/">Sponsors</a> and Donors, for supporting the development of this work.</p>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Read_once(), Write_once(), but Not for Rust (126 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1053142/8ec93e58d5d3cc06/</link>
            <guid>46647059</guid>
            <pubDate>Fri, 16 Jan 2026 15:04:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1053142/8ec93e58d5d3cc06/">https://lwn.net/SubscriberLink/1053142/8ec93e58d5d3cc06/</a>, See on <a href="https://news.ycombinator.com/item?id=46647059">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>

<h2>[LWN subscriber-only content]</h2>
</p><div>
<p>
The </p><tt>READ_ONCE()</tt><p> and </p><tt>WRITE_ONCE()</tt><p> macros are heavily used
within the kernel; there are nearly 8,000 call sites for
</p><tt>READ_ONCE()</tt><p>.  They are key to the implementation of many <a href="https://lwn.net/Articles/844224/">lockless algorithms</a> and can be necessary for some
types of device-memory access.  So one might think that, as the
amount of Rust code in the kernel increases, there would be a place for
Rust versions of these macros as well.  The truth of the matter, though, is
that the Rust community seems to want to take a different approach to
concurrent data access.
</p><p>
An understanding of <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> is
important for kernel developers who will be dealing with any sort of
concurrent access to data.  So, naturally, they are almost entirely absent
from the kernel's documentation.  A description of sorts can be found at
the top of <a href="https://elixir.bootlin.com/linux/v6.18.3/source/include/asm-generic/rwonce.h"><tt>include/asm-generic/rwonce.h</tt></a>:
</p><blockquote>
	Prevent the compiler from merging or refetching reads or
 	writes. The compiler is also forbidden from reordering successive
 	instances of READ_ONCE and WRITE_ONCE, but only when the compiler
 	is aware of some particular ordering. One way to make the compiler
 	aware of ordering is to put the two invocations of READ_ONCE or
 	WRITE_ONCE in different C statements.
</blockquote>
<p>
In other words, a <tt>READ_ONCE()</tt> call will force the compiler to read
from the indicated location exactly one time, with no optimization tricks
that would cause the read to be either elided or repeated;
<tt>WRITE_ONCE()</tt> will force a write under those terms.  They will also
ensure that the access is atomic; if one task reads a location with
<tt>READ_ONCE()</tt> while another is writing that location, the read will
return the value as it existed either before or after the write, but not
some random combination of the two.  These macros, other than as described
above, impose no ordering constraints on the compiler or the CPU, making
them different from macros like <tt>smp_load_acquire()</tt>, which have
stronger ordering requirements.
</p><blockquote>
The <a href="https://lwn.net/ksdb/">LWN kernel-source database</a> is the definitive source of information about kernel releases.  <a href="https://lwn.net/Promo/KSDB/claim">Try a one-month free trial subscription</a> for immediate access to LWN's kernel content and KSDB as well.
</blockquote>
<p>
The <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> macros were <a href="https://git.kernel.org/linus/230fa253df635">added for the 3.18
release</a> in 2014.  <tt>WRITE_ONCE()</tt> was initially called
<tt>ASSIGN_ONCE()</tt>, but that name was <a href="https://git.kernel.org/linus/43239cbe79fc3">changed</a> during the
3.19 development cycle.
</p><p>
On the last day of 2025, Alice Ryhl posted <a href="https://lwn.net/ml/all/20251231-rwonce-v1-0-702a10b85278@google.com">a patch
series</a> adding implementations of <tt>READ_ONCE()</tt> and
<tt>WRITE_ONCE()</tt> for Rust.  There are places in the code, she said,
where volatile reads could be replaced with these calls, once they were
available; among other changes, the series <a href="https://lwn.net/ml/all/20251231-rwonce-v1-5-702a10b85278@google.com">changed access
to the <tt>struct file</tt> <tt>f_flags</tt> field</a> to use
<tt>READ_ONCE()</tt>.  The <a href="https://lwn.net/ml/all/20251231-rwonce-v1-2-702a10b85278@google.com">implementation</a>
of these macros involves a bunch of Rust macro magic, but in the end they come
down to calls to the Rust <a href="https://doc.rust-lang.org/std/ptr/fn.read_volatile.html"><tt>read_volatile()</tt></a>
and <a href="https://doc.rust-lang.org/stable/std/ptr/fn.write_volatile.html"><tt>write_volatile()</tt></a> functions.
</p><p>
Some of the other kernel Rust developers objected to this change, though.
Gary Guo <a href="https://lwn.net/ml/all/20251231151216.23446b64.gary@garyguo.net">said</a> that he
would rather not expose <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> and
suggested using relaxed operations from <strike><a href="https://doc.rust-lang.org/std/sync/atomic/">the Rust <tt>Atomic</tt>
crate</a></strike> the kernel's <a href="https://rust.docs.kernel.org/next/kernel/sync/atomic/struct.Atomic.html"><tt>Atomic</tt></a>
module instead.  Boqun Feng <a href="https://lwn.net/ml/all/aVXKP8vQ6uAxtazT@tardis-2.local">expanded on</a> the
objection:
</p><blockquote>
	The problem of READ_ONCE() and WRITE_ONCE() is that the semantics
	is complicated. Sometimes they are used for atomicity, sometimes
	they are used for preventing data race. So yes, we are using LKMM
	[the Linux kernel memory model] in Rust as well, but whenever
	possible, we need to clarify the intention of the API, using
	Atomic::from_ptr().load(Relaxed) helps on that front.
<p>
	IMO, READ_ONCE()/WRITE_ONCE() is like a "band aid" solution to a
	few problems, having it would prevent us from developing a more
	clear view for concurrent programming.
</p></blockquote>
<p>
In other words, using the <tt>Atomic</tt> crate allows developers to
specify more precisely which guarantees an operation needs, making the
expectations (and requirements) of the code more clear.
This point of view would appear to have won out, and Ryhl has stopped
pushing for this addition to the kernel's Rust code — for now, at least.
</p><p>
There are a couple of interesting implications from this outcome, should it
hold.  The first of those is that, as Rust code reaches more deeply into the
core kernel, its code for concurrent access to shared data will look
significantly different from the equivalent C code, even though the code on
both sides may be working with the same data.  Understanding lockless data
access is challenging enough when dealing with one API; developers may now
have to understand two APIs, which will not make the task easier.
</p><p>
Meanwhile, this discussion is drawing some attention to code on the C side
as well.  As Feng <a href="https://lwn.net/ml/all/aV0JkZdrZn97-d7d@tardis-2.local">pointed
out</a>, there is still C code in the kernel that assumes a plain write
will be atomic in many situations, even though the C standard explicitly
says otherwise.  Peter Zijlstra <a href="https://lwn.net/ml/all/20260106145622.GB3707837@noisy.programming.kicks-ass.net">answered</a>
that all such code should be updated to use <tt>WRITE_ONCE()</tt> properly.
Simply finding that code may be a challenge (though <a href="https://docs.kernel.org/dev-tools/kcsan.html">KCSAN</a> can help);
updating it all may take a while.  The conversation also <a href="https://lwn.net/ml/all/87ikdej4s1.fsf@t14s.mail-host-address-is-not-set">identified</a>
a place in the (C) high-resolution-timer code that is missing a needed
<tt>READ_ONCE()</tt> call.  This is another example of the Rust work
leading to improvements in the C code.
</p><p>
In past discussions on the design of Rust abstractions, there has been
resistance to the creation of Rust interfaces that look substantially
different from their C counterparts; see <a href="https://lwn.net/Articles/958072/">this
2024 article</a>, for example.  If the Rust developers come up with a
better design for an interface, the thinking went, the C side should be
improved to match this new design.  If one accepts the idea that the Rust
approach to <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> is better than
the original, then one might conclude that  a similar process should be
followed here.  Changing thousands of low-level concurrency primitives to
specify more precise semantics would not be a task for the faint of heart,
though.  This may end up being a case where code in the two languages just
does things differently.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Development_tools-Rust">Development tools/Rust</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Lockless_algorithms">Lockless algorithms</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[America could have $4 lunch bowls like Japan but for zoning laws (165 pts)]]></title>
            <link>https://abio.substack.com/p/america-could-have-4-lunch-bowls</link>
            <guid>46646970</guid>
            <pubDate>Fri, 16 Jan 2026 14:56:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abio.substack.com/p/america-could-have-4-lunch-bowls">https://abio.substack.com/p/america-could-have-4-lunch-bowls</a>, See on <a href="https://news.ycombinator.com/item?id=46646970">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>In Japan, workers rely on healthy lunch bowls for under $4. Japanese media literally tracks these prices because they're a daily staple for working people. The Japanese media reported on a surge in their price from </span><a href="https://www.thestar.com.my/aseanplus/aseanplus-news/2024/01/17/japans-salarymen-turn-to-cheaper-options-as-rise-in-food-prices-bite#:~:text=A%20July%202023%20survey%20of,day%20for%20lunch%20on%20average" rel="">$2.63 to $4.25 in 2021</a><span>.</span></p><p>In America, we track grocery prices. Restaurants are luxury goods.</p><p>The U.S. lacks this budget restaurant tier! There's obviously demand for it. We'd buy $4 balanced meals if we had the option.</p><p>How does Japan’s restaurant market do this?</p><p><span>It’s not grocery prices; Japan’s </span><a href="https://www.westernunion.com/blog/en/us/the-cost-of-living-in-japan-vs-the-united-states/#:~:text=The%20price%20of%20groceries%20in%20Japan%20are%20approximately%2018%25%20higher%20than%20the%20United%20States.%20Restaurant%20prices%20in%20the%20United%20States%20are%20approximately%2045%25%20higher%20than%20in%20Japan." rel="">grocery prices are ~18%</a><span> higher than the United States.</span></p><p>It’s not hourly wages. Japan’s minimum wage ($6.68 an hour) is similar to America’s ($7.25).</p><p>Japan allows businesses that are only a few feet wide. Japanese restaurants can operate in small spaces, like one floor of a narrow single-stair case building (no wasted space or resources on a shared lobby).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!fEi8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!fEi8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 424w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 848w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!fEi8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg" width="803" height="731" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:731,&quot;width&quot;:803,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!fEi8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 424w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 848w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!fEi8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb46e4e1-9061-4dc3-b506-f0bb4f58d023_803x731.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>"</span><a href="https://commons.wikimedia.org/w/index.php?curid=7706106" rel="">Koreatown manhattan 2009</a><span>" by chensiyuan, </span><a href="https://creativecommons.org/licenses/by-sa/4.0/?ref=openverse" rel="">CC BY-SA 4.0</a><span>. Grabbed from </span><a href="https://www.noahpinion.blog/p/a-better-way-to-build-a-downtown" rel="">Noah Smith</a><span>.</span></em></p><p><span>In Japan, someone can even build a tiny </span><a href="https://substack.com/home/post/p-166181413" rel="">coffeeshop</a><span> </span><em>in front of their home</em><span>.</span></p><p><span>Because of small setups like these, many Japanese restaurants have only one or two staff. Some restaurants are physically so small that they can only seat two to five people. In some, you even eat </span><a href="https://livejapan.com/en/in-tokyo/in-pref-tokyo/in-ueno/article-a0002702/" rel="">standing up</a><span>.</span></p><p>A tiny restaurant staffed by just a single person, their stove, and a rice cooker can sell you lunch for a similar price you'd pay at home.</p><p>The overhead is minimal.</p><p>But in the US, tiny restaurants are illegal.</p><p><strong>Our zoning laws</strong><span> require almost every business to:</span></p><ul><li><p>Maintain a large building footprint</p></li><li><p><span>Provide </span><a href="https://www.strongtowns.org/journal/2024/1/30/a-slow-and-steady-but-bittersweet-victory-against-arcane-parking-mandates" rel="">2-4 parking spaces</a><span> per business</span></p></li><li><p>Operate at a scale that requires multiple employees</p></li></ul><p><span>Food trucks could help if they were allowed at scale. But the restaurant industry fights to limit food trucks. On average, food trucks must handle 45 separate regulatory procedures and spend </span><a href="https://manhattan.institute/article/d-c-s-burdensome-food-truck-regulations" rel="">$28,276 on associated fees</a><span>.           </span></p><p><strong>Relatedly, our health code regulations</strong><span> also effectively outlaw people from opening restaurants in small spaces. Most jurisdictions require at least 3-4 different sinks—one for washing dishes (usually a large three-part sink), separate ones for washing hands, one for mopping, and often another for prepping food. This makes small commercial kitchens in under 200 square feet much harder.</span></p><p><span>America’s food regulations are also not set up for a single person to manage. The U.S. has </span><a href="https://www.fda.gov/food/guidance-regulation-food-and-dietary-supplements/retail-food-protection" rel="">3,000 different agencies</a><span> handling food regulations. The whole system, </span><a href="https://x.com/KelseyTuoc/status/1902806006306062405" rel="">scattered across eight places in the municipal code</a><span>, is basically uncoordinated and varies depending on where you are.</span></p><p><strong>When you force every restaurant to be big, expensive, and car-dependent, cheap daily food becomes harder.</strong></p><p><span>Singapore has </span><a href="https://eatbook.sg/cheap-3-dollar-dishes/" rel="">$3 hawker center</a><span> meals. Hong Kong serves </span><a href="https://www.nytimes.com/2022/05/02/world/asia/hong-kong-inexpensive-dining.html" rel="">$4 lunch boxes</a><span>. Even Manhattan has </span><a href="https://www.bloomberg.com/news/articles/2023-01-12/how-inflation-devoured-nyc-s-last-great-bargain-cheap-pizza#:~:text=From%202014%20to,by%20Quigley%E2%80%99s%20calculation." rel="">99 cent pizza slices</a><span>. These use a tiny storefront model that maximizes foot-traffic volume.</span></p><p><strong>Foot traffic from dense neighborhoods provides a constant source of customers, so restaurants can profit from high volumes of sales, rather than high prices.</strong></p><p>Japanese cities let restaurants cluster in mixed-use buildings where people live, work, and transit. A 20-seat ramen shop near a station sees hundreds of potential customers during lunch rush.</p><p><span>American zoning typically </span><em>separates</em><span> commercial and residential areas.</span></p><p>Outside of New York City, most U.S. restaurants need customers to make destination trips via car. That friction means fewer total customers, requiring higher prices to stay profitable.</p><p><span>Half of Americans spend </span><a href="https://www.thenationalherald.com/americans-spend-52-minutes-a-day-in-the-kitchen-5-ways-to-make-those-minutes-matter/" rel="">nearly an hour a day</a><span> cooking, partly because there's no sub-$4 option. A lot of us hate cooking but don’t want to spend $11 at Chipotle.</span></p><p>This category of restaurant is a form of basic infrastructure in Singapore, Hong Kong, and Japan.</p><p>When regulations prevent everyday people from starting businesses on small lots, we don't just lose those businesses. We lose the price points they make possible.</p><p>Individual regulations, each reasonable in isolation, can combine to lock out exactly the small-scale solutions that would help working families most. We can rewrite the rules to enable the neighborhood businesses that working families actually need.</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cursor's latest "browser experiment" implied success without evidence (587 pts)]]></title>
            <link>https://embedding-shapes.github.io/cursor-implied-success-without-evidence/</link>
            <guid>46646777</guid>
            <pubDate>Fri, 16 Jan 2026 14:37:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://embedding-shapes.github.io/cursor-implied-success-without-evidence/">https://embedding-shapes.github.io/cursor-implied-success-without-evidence/</a>, See on <a href="https://news.ycombinator.com/item?id=46646777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>
        2026-01-16
      </p>
      <h2 id="cursors-latest-browser-experiment-implied-success-without-evidence">Cursor's
latest "browser experiment" implied success without evidence</h2>
<p>On January 14th 2026, Cursor published a blog post titled "Scaling
long-running autonomous coding" (<a href="https://cursor.com/blog/scaling-agents">https://cursor.com/blog/scaling-agents</a>)</p>
<p>In the blog post, they talk about their experiments with running
"coding agents autonomously for weeks" with the explicit goal of</p>
<blockquote>
<p>understand[ing] how far we can push the frontier of agentic coding
for projects that typically take human teams months to complete</p>
</blockquote>
<p>They talk about some approaches they tried, why they think those
failed, and how to address the difficulties.</p>
<p>Finally they arrived at a point where something "solved most of our
coordination problems and let us scale to very large projects without
any single agent", which then led to this:</p>
<blockquote>
<p>To test this system, we pointed it at an ambitious goal: building a
web browser from scratch. The agents ran for close to a week, writing
over 1 million lines of code across 1,000 files. You can explore the
source code on GitHub (<a href="https://github.com/wilsonzlin/fastrender">https://github.com/wilsonzlin/fastrender</a>)</p>
</blockquote>
<p>This is where things get a bit murky and unclear. They claim "Despite
the codebase size, new agents can still understand it and make
meaningful progress" and "Hundreds of workers run concurrently, pushing
to the same branch with minimal conflicts", but they never actually say
if this is successful or not, is it actually working? Can you run this
browser yourself? We don't know and they never say explicitly.</p>
<p>After this, they embed the following video:</p>
<p><video src="https://embedding-shapes.github.io/content/cursor-screenshots.webm" controls=""><a href="https://embedding-shapes.github.io/content/cursor-screenshots.webm">Video</a></video></p>
<p>And below it, they say "While it might seem like a simple screenshot,
building a browser from scratch is extremely difficult.".</p>
<h3 id="they-never-actually-claim-this-browser-is-working-and-functional">They
never actually claim this browser is working and functional</h3>
<blockquote>
<p>error: could not compile 'fastrender' (lib) due to 34 previous
errors; 94 warnings emitted</p>
</blockquote>
<p>And if you try to compile it yourself, you'll see that it's very far
away from being a functional browser at all, and seemingly, it never
actually was able to build.</p>
<p>Multiple recent GitHub Actions runs on <code>main</code> show
failures (including workflow-file errors), and independent build
attempts report dozens of compiler errors, recent PRs were all merged
with failing CI, and going back in the Git history from most recent
commit back 100 commits,<br><a href="https://gist.github.com/embedding-shapes/f5d096dd10be44ff82b6e5ccdaf00b29">I
couldn't find a single commit that compiled cleanly</a>.</p>
<p>I'm not sure what the "agents" they unleashed on this codebase
actually did, but they seemingly never ran "cargo build" or even less
"cargo check", because both of those commands surface 10s of errors
(which surely would balloon should we solve them) and about 100
warnings. There is an open GitHub issue in their repository about this
right now: <a href="https://github.com/wilsonzlin/fastrender/issues/98">https://github.com/wilsonzlin/fastrender/issues/98</a></p>
<p>And diving into the codebase, if the compilation errors didn't make
that clear already, makes it very clear to any software developer that
none of this is actually engineered code. It is what is typically known
as "AI slop", low quality <em>something</em> that surely represents
<em>something</em>, but it doesn't have intention behind it, and it
doesn't even compile at this point.</p>
<p>They later start to talk about what's next, but not a single word
about how to run it, what to expect, how it's working or anything else.
Cursor's blog post provides no reproducible demo and no known-good
revision (tag/release/commit) to verify the screenshots, beyond linking
the repo.</p>
<p>Regardless of intent, Cursor's blog post creates the impression of a
functioning prototype while leaving out the basic reproducibility
markers one would expect from such claim. They never explicitly claim
it's actually working, so no one can say they lied at least.</p>
<p>They finish off the article saying:</p>
<blockquote>
<p>But the core question, can we scale autonomous coding by throwing
more agents at a problem, has a more optimistic answer than we
expected.</p>
</blockquote>
<p>Which seems like a really strange conclusion to arrive at, when all
they've proved so far, is that agents can output millions of tokens and
still not end up with something that actually works.</p>
<p>A "browser experiment" doesn't need to rival Chrome. A reasonable
minimum bar is: it compiles on a supported toolchain and can render a
trivial HTML file. Cursor's post doesn’t demonstrate that bar, and
current public build attempts fail at this too.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Cursor never says "this browser is production-ready", but they do
frame it as "building a web browser from scratch" and "meaningful
progress" and then use a screenshot and "extremely difficult" language,
wanting to give the impression that this experiment actually was a
success.</p>
<p>The closest they get to implying that this was a success, is this
part:</p>
<blockquote>
<p>Hundreds of agents can work together on a single codebase for weeks,
making real progress on ambitious projects.</p>
</blockquote>
<p>But this extraordinary claim isn't backed up by any evidence. In the
blog post they never provide a working commit, build instructions or
even a demo that can be reproduced.</p>
<p>I don't think anyone expects this browser to be the next Chrome, but
I do think that if you claim you've built a browser, it should at least
be able to demonstrate being able to be compiled + loading a basic HTML
file at the very least.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astro Joining Cloudflare (845 pts)]]></title>
            <link>https://astro.build/blog/joining-cloudflare/</link>
            <guid>46646645</guid>
            <pubDate>Fri, 16 Jan 2026 14:25:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astro.build/blog/joining-cloudflare/">https://astro.build/blog/joining-cloudflare/</a>, See on <a href="https://news.ycombinator.com/item?id=46646645">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p>The Astro Technology Company — the company behind the Astro web framework — is joining Cloudflare! Adoption of the Astro web framework continues to double every year, and <a href="https://astro.build/blog/astro-6-beta/">Astro 6</a> is right around the corner. With Cloudflare’s support, we’ll have more resources and fewer distractions to continue our mission to build the best framework for content-driven websites.</p>
<p><strong>What this means for Astro:</strong></p>
<ul>
<li>Astro stays open-source and MIT-licensed</li>
<li>Astro continues to be actively maintained</li>
<li>Astro continues to support a wide set of deployment targets, not just Cloudflare</li>
<li>Astro’s open governance and current roadmap remain in place.</li>
<li>All full-time employees of The Astro Technology Company are now employees of Cloudflare, and will continue to work on Astro full-time.</li>
</ul>
<h2 id="how-astro-started">How Astro started</h2>
<p>In 2021, Astro was born out of frustration. The trend at the time was that every website should be architected as an application, and then shipped to the user’s browser to render. This was not very performant, and we’ve spent the last decade coming up with more and more complex solutions to solve for that performance problem. SSR, ISR, RSC, PPR, TTI optimizations via code-splitting, tree-shaking, lazy-loading, all to generate a blocking double-data hydration payload from a pre-warmed server running halfway around the world.</p>
<p>Our mission to design a web framework specifically for building websites — what we call <em>content-driven websites,</em> to better distinguish from data-driven, stateful web applications — resonated. Now Astro is downloaded almost 1,000,000 times per week, and has been used by 100,000s of developers to build fast, beautiful websites. Today you’ll find Astro all over the web, powering major websites and even entire developer platforms for companies like Webflow, Wix, Microsoft, and Google.</p>
<p><strong>Along the way, we also tried to grow a business.</strong> In 2021 we raised some money and formed The Astro Technology Company. Our larger vision was that a well-designed framework like Astro could sit at the center of a massive developer platform, with optional hosted primitives (database, storage, analytics) designed in lockstep with the framework.</p>
<p>We were never able to realize this vision. Attempts to introduce paid, hosted primitives into our ecosystem fell flat, and rarely justified their own existence. We considered going more directly after first-class hosting or content management for Astro, but knew we’d spend much of our time playing catchup to well-funded, savvy competitors. We kept exploring different ideas, but nothing every clicked with users the same way Astro did.</p>
<p>It wasn’t all bad. <a href="https://docs.astro.build/en/guides/astro-db/">Astro DB</a> (our attempt to build a hosted database product for Astro projects) eventually evolved into the open, built-in Astro database client that still lives in core today. Our exploration into building an e-commerce layer with Astro was eventually <a href="https://github.com/withastro/storefront">open-sourced</a>. It was rewarding work, but over the years the distraction took its toll. Each attempt at a new paid product or offering took myself and others on the project away from working on the Astro framework that developers were using and loving every day.</p>
<h2 id="returning-to-focus"><strong>Returning to Focus</strong></h2>
<p>Last year, Dane (Cloudflare CTO) and I began to talk more seriously about the future of the web. Those conversations quickly grew into something bigger: What does the next decade look like? How do frameworks adapt to a world of AI coding and agents?</p>
<p>It became clear that even as web technologies evolve, <strong>content remains at the center.</strong> We realized that we’ve each been working toward this same vision from different angles:</p>
<ul>
<li><strong>Cloudflare</strong> has been solving it from the <strong>infrastructure</strong> side: betting on a platform that is global by default, with fast startup, low latency, and security built-in.</li>
<li><strong>Astro</strong> has been solving it from the <strong>framework</strong> side: betting on a web framework that makes it easy to build sites that are fast by default, without overcomplicating things.</li>
</ul>
<p>The overlap is obvious. By working together, Cloudflare gives us the backing we need to keep innovating for our users. Now we can stop spending cycles worrying about building a business on top of Astro, and start focusing 100% on the code, with a shared vision to move the web forward.</p>
<h2 id="cloudflare-️-astro"><strong>Cloudflare ❤️ Astro</strong></h2>
<p>Cloudflare has been a long-time sponsor and champion of Astro. They have a proven track record of supporting great open-source projects like Astro, TanStack, and Hono without trying to capture or lock anything down. Staying open to all was a non-negotiable requirement for both us and for Cloudflare.</p>
<p>That is why Astro will remain free, open-source, and MIT-licensed. We will continue to run our project in the open, with an open governance model for contributors and an open community roadmap that anyone can participate in. We remain fully committed to maintaining Astro as a platform-agnostic framework, meaning we will continue to support and improve deployments for all targets—not just Cloudflare.</p>
<p>With Cloudflare’s resources and support, we can now return our focus fully towards building the best web framework for content-driven websites. The web is changing fast, and the bar keeps rising: performance, scale, reliability, and a better experience for the teams shipping content on the web.</p>
<p>You’ll see that focus reflected across our roadmap, as we prepare for the upcoming Astro 6 release (beta out now!) and our 2026 roadmap. Stay tuned!</p>
<h2 id="thank-you">Thank you</h2>
<p>I want to extend a huge thank you to the agencies, companies, sponsors, partners, and theme authors who chose to work with us over the years. Thank you to our initial investors — Haystack, Gradient, Uncorrelated, Lightspeed — without whom Astro likely wouldn’t exist. Thank you to everyone in our open source community who continues to help make Astro better every day. And finally, thank you to everyone who uses Astro and puts their trust in us to help them build for the web.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Michelangelo's First Painting, Created When He Was Only 12 or 13 Years Old (351 pts)]]></title>
            <link>https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html</link>
            <guid>46646263</guid>
            <pubDate>Fri, 16 Jan 2026 13:44:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html">https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html</a>, See on <a href="https://news.ycombinator.com/item?id=46646263">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img loading="lazy" fetchpriority="high" decoding="async" src="https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1.jpg" alt="" width="1872" height="2560" srcset="https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1.jpg 1872w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-263x360.jpg 263w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-749x1024.jpg 749w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-176x240.jpg 176w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-768x1050.jpg 768w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-1123x1536.jpg 1123w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-1498x2048.jpg 1498w" sizes="(max-width: 1872px) 100vw, 1872px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1.jpg" data-srcset="https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1.jpg 1872w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-263x360.jpg 263w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-749x1024.jpg 749w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-176x240.jpg 176w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-768x1050.jpg 768w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-1123x1536.jpg 1123w, https://cdn8.openculture.com/2026/01/14225354/1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1-1498x2048.jpg 1498w"></p>
<p>Think back, if you will, to the works of art you cre­at­ed at age twelve or thir­teen. For many, per­haps most of us, our out­put at that stage of ado­les­cence amount­ed to direc­tion­less doo­dles, chaot­ic comics, and a few unsteady-at-best school projects. But then, most of us did­n’t grow up to be Michelan­ge­lo. In the late four­teen-eight­ies, when that tow­er­ing Renais­sance artist was still what we would now call a “tween,” he paint­ed <a href="https://www.metmuseum.org/exhibitions/listings/2009/michelangelo"><em>The Tor­ment of Saint Antho­ny</em></a>, a depic­tion of the tit­u­lar reli­gious fig­ure beset by demons in the desert. Though based on&nbsp;a wide­ly known engrav­ing, it nev­er­the­less shows evi­dence of rapid­ly advanc­ing tech­nique, inspi­ra­tion, and even&nbsp;cre­ativ­i­ty — espe­cial­ly when placed under the infrared scan­ner.</p>
<p>For about half a mil­len­ni­um, <em>The Tor­ment of Saint Antho­ny&nbsp;</em>was­n’t thought to have been paint­ed by Michelan­ge­lo. As explained in <a href="https://www.youtube.com/watch?v=YtUWFNPoxJM">the video from Inspi­rag­gio just below</a>, when the paint­ing sold at Sothe­by’s in 2008, the buy­er took it to the Met­ro­pol­i­tan Muse­um of Art for exam­i­na­tion and clean­ing.</p>


<p>“Beneath the lay­ers of dirt accu­mu­lat­ed over the cen­turies,” says the nar­ra­tor, “a very par­tic­u­lar col­or palette appeared. “The tones, the blends, the way the human fig­ure was treat­ed: all of it began to resem­ble the style Michelan­ge­lo would use years lat­er in none oth­er than <a href="https://www.openculture.com/2025/05/take-a-3d-virtual-tour-of-the-sistine-chapel.html">the Sis­tine Chapel</a>.” Infrared reflec­tog­ra­phy sub­se­quent­ly turned up&nbsp;<em>pen­ti­men­ti</em>, or cor­rec­tion marks, a com­mon indi­ca­tion that “a paint­ing is not a copy, but an orig­i­nal work cre­at­ed with artis­tic free­dom.”</p>
<div>
<p><span><iframe title="YouTube video player" type="text/html" width="640" height="505" src="//www.youtube.com/embed/YtUWFNPoxJM?wmode=transparent&amp;fs=1&amp;hl=en&amp;showsearch=0&amp;rel=0&amp;theme=dark" frameborder="0" allowfullscreen="" loading="lazy"></iframe></span>
	</p>
</div>

<p>It was the <a href="https://kimbellart.org/exhibition/michelangelos-first-painting">Kim­bell Art Muse­um</a> in Fort Worth, Texas that first bet big on the prove­nance of <em>The Tor­ment of Saint Antho­ny</em>. Its new­ly hired direc­tor pur­chased the paint­ing after turn­ing up “not a sin­gle con­vinc­ing argu­ment against the attri­bu­tion.” Thus acquired, it became “the only paint­ing by Michelan­ge­lo locat­ed any­where in the Amer­i­c­as, and also just one of four easel paint­ings attrib­uted to him through­out his entire career,” dur­ing most of which he dis­par­aged oil paint­ing itself. About a decade lat­er, and after fur­ther analy­sis, the art his­to­ri­an Gior­gio Bon­san­ti put his con­sid­er­able author­i­ty behind a defin­i­tive con­fir­ma­tion that it is indeed the work of the young Michelan­ge­lo. There remain doubters, of course, and even the noto­ri­ous­ly uncom­pro­mis­ing artist him­self may have con­sid­ered it an imma­ture work unwor­thy of his name. But who else could have cre­at­ed an imma­ture work like it?</p>
<p><strong>Relat­ed Con­tent:</strong></p>
<p><a href="https://www.openculture.com/2015/12/original-portrait-of-the-mona-lisa-found-beneath-the-paint-layers-of-da-vincis-masterpiece.html">Orig­i­nal Por­trait of the <em>Mona Lisa</em> Found Beneath the Paint Lay­ers of Leonar­do da Vinci’s Mas­ter­piece</a></p>
<p><a href="https://www.openculture.com/2025/09/michelangelo-fort-designs.html">When Michelan­ge­lo Cre­at­ed Artis­tic Designs for Mil­i­tary For­ti­fi­ca­tions to Pro­tect Flo­rence (1529–1530)</a></p>
<p><a href="https://www.openculture.com/2025/07/how-four-masters-michelangelo-donatello-verrocchio-bernini-sculpted-david.html">How Four Mas­ters — Michelan­ge­lo, Donatel­lo, Ver­roc­chio &amp; Berni­ni — Sculpt­ed David</a></p>
<p><a href="https://www.openculture.com/2023/11/a-secret-room-with-drawings-attributed-to-michelangelo-opens-to-visitors-in-florence.html">A Secret Room with Draw­ings Attrib­uted to Michelan­ge­lo Opens to Vis­i­tors in Flo­rence</a></p>
<p><a href="https://www.openculture.com/2021/11/michelangelo-entered-a-competition-to-put-a-missing-arm-back-on-laocoon-and-his-sons-and-lost.html">Michelan­ge­lo Entered a Com­pe­ti­tion to Put a Miss­ing Arm Back on Lao­coön and His Sons — and Lost</a></p>
<p><a href="https://www.openculture.com/2023/02/michelangelos-illustrated-grocery-list-2.html">Michelangelo’s Illus­trat­ed Gro­cery List</a></p>
<p><em>Based in Seoul,&nbsp;</em><em><a href="http://blog.colinmarshall.org/">Col­in</a></em><em><a href="http://blog.colinmarshall.org/">&nbsp;M</a></em><em><a href="http://blog.colinmarshall.org/">a</a></em><em><a href="http://blog.colinmarshall.org/">rshall</a>&nbsp;writes and broad­cas</em><em>ts on cities, lan­guage, and cul­ture. He’s the author of the newslet­ter</em>&nbsp;<a href="https://colinmarshall.substack.com/">Books on Cities</a><em> as well as the books </em><a href="https://product.kyobobook.co.kr/detail/S000212263515" rel="">한국 요약 금지</a><em> (No Sum­ma­riz­ing Korea) and </em><a href="https://www.amazon.com/Korean-Newtro-Where-Youth-Tradition/dp/156591533X" rel="">Kore­an Newtro</a><em>.</em>&nbsp;<em>Fol­low him on the social net­work for­mer­ly known as Twit­ter at&nbsp;<a href="https://twitter.com/#%21/colinmarshall" rel="nofollow">@colinm</a></em><em><a href="https://twitter.com/#%21/colinmarshall" rel="nofollow">a</a></em><em><a href="https://twitter.com/#%21/colinmarshall" rel="nofollow">rshall</a>.</em></p>
<br>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dev-owned testing: Why it fails in practice and succeeds in theory (138 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/3780063.3780066</link>
            <guid>46646226</guid>
            <pubDate>Fri, 16 Jan 2026 13:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/3780063.3780066">https://dl.acm.org/doi/10.1145/3780063.3780066</a>, See on <a href="https://news.ycombinator.com/item?id=46646226">Hacker News</a></p>
Couldn't get https://dl.acm.org/doi/10.1145/3780063.3780066: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>