<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 10 Sep 2023 19:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Peredvizhnikov Engine is a fully lock-free game engine written in C++20 (187 pts)]]></title>
            <link>https://github.com/eduard-permyakov/peredvizhnikov-engine</link>
            <guid>37456471</guid>
            <pubDate>Sun, 10 Sep 2023 15:03:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine">https://github.com/eduard-permyakov/peredvizhnikov-engine</a>, See on <a href="https://news.ycombinator.com/item?id=37456471">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/docs/images/peredvizhnikov-engine-logo.png"><img src="https://github.com/eduard-permyakov/peredvizhnikov-engine/raw/master/docs/images/peredvizhnikov-engine-logo.png" alt="logo"></a></h2>
<p dir="auto">Peredvizhnikov Engine is a fully lock-free game engine written in C++20. It implements the <em>actor model</em> of concurrent computation on top of the language's coroutine primitives.</p>
<p dir="auto">Using the <em>actor model</em> abstraction, it is possible to develop complex, parallel logic while being wholly isolated from the details of inter-thread synchronization. A completely lock-free implementation of the model brings with it many advantages, namely guaranteed progress even in the presence of arbitrary thread termination, deadlock-freedom, predictable latency in reacting to critical events, and fault-tolerance.</p>
<p dir="auto">In fact, the degree of fault-tolerance in Peredvizhnikov Engine is so great, that the engine is guaranteed to continue running even when any of the worker threads is asynchronously killed. You may <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/test/test_fault_tolerance.cpp">verify this yourself</a>.</p>
<p dir="auto">The implementation is founded upon a mix of classical and novel ideas in lock-free programming. It includes <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_struct.cpp">a novel implementation of Software Transactional Memory</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/lockfree_sequenced_queue.cpp">a new kind of lock-free queue</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_work.cpp">an original lock-free serialization primitive</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/atomic_shared_ptr.cpp">a lock-free std::atomic_shared_ptr</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/scheduler.cpp">a lock-free scheduler</a>, <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/src/alloc.cpp">a lock-free memory allocator</a> and plenty more!</p>
<p dir="auto">For a detailed breakdown of all the lock-free algorithms that went into realizing the engine, rationale for the design, benchmarks, and more, please take a look at the accompanying document: <a href="https://github.com/eduard-permyakov/peredvizhnikov-engine/blob/master/docs/lockfree.pdf">Peredvizhnikov Engine: Design and Implementation of a Completely Lock-Free Scheduler</a>.</p>
<h2 tabindex="-1" dir="auto">Building Peredvizhnikov Engine</h2>
<p dir="auto">At the moment, the only supported platform is Linux. Clang++ 16 is required to build the sources.</p>
<ol dir="auto">
<li><code>git clone https://github.com/eduard-permyakov/peredvizhnikov-engine.git</code></li>
<li><code>cd peredvizhnikov-engine</code></li>
<li><code>make -j16 DEBUG=0</code></li>
</ol>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">The source code of Peredvizhnikov Engine is freely available under the GPLv3 license. However, I may grant permission to use parts or all of the code under a different license on a case-by-case basis. Please inquire by e-mail.</p>
<h2 tabindex="-1" dir="auto">Contact</h2>
<p dir="auto">You may contact me with any questions, comments, or concerns pertaining to the source code or the underlying algorithms.</p>
<p dir="auto">In addition, I am currently actively seeking employment. Please don't hesitate to reach out regarding any suitable opportunities.</p>
<p dir="auto">My e-mail is: <a href="mailto:edward.permyakov@gmail.com">edward.permyakov@gmail.com</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How does Linux NAT a ping? (147 pts)]]></title>
            <link>https://devnonsense.com/posts/how-does-linux-nat-a-ping/</link>
            <guid>37455621</guid>
            <pubDate>Sun, 10 Sep 2023 13:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devnonsense.com/posts/how-does-linux-nat-a-ping/">https://devnonsense.com/posts/how-does-linux-nat-a-ping/</a>, See on <a href="https://news.ycombinator.com/item?id=37455621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>A few months ago, I found myself wondering how a command like <code>ping 1.1.1.1</code> works from within a private network.</p><p>In most private networks, multiple hosts connect to the Internet through a router. For IPv4, the router performs network address translation (NAT) by rewriting the original host’s source address to the router’s public IP address. The router can lookup the correct host for a reply packet based on the packet’s <em>port</em> field, at least for protocols like TCP and UDP.</p><p>But a command like <code>ping</code> doesn’t use TCP or UDP; it uses ICMP, and those packets do <em>not</em> have a port field. So how does NAT work for ICMP packets?</p><p>This led me down a deep rabbit hole: running experiments in network namespaces, capturing packets, reading RFCs, and tracing through the Linux source code. This post summarizes what I did and learned along the way.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p><em>Before these experiments, I hadn’t spent much time in the Linux networking code – this is something new I’m learning. If I’ve made any mistakes please <a href="https://devnonsense.com/contact">let me know</a> so I can correct them.</em></p><details open=""><summary><b>Table of contents</b></summary><nav id="TableOfContents"><ul><li><a href="#experiment-setup">Experiment setup</a><ul><li><a href="#step-1-connect-two-clients-to-a-bridge">Step 1: Connect two clients to a bridge</a></li><li><a href="#step-2-connect-natbox-and-server">Step 2: Connect natbox and server</a></li><li><a href="#step-3-configure-routing-and-nat">Step 3: Configure routing and NAT</a></li></ul></li><li><a href="#packet-capture">Packet capture</a></li><li><a href="#rfc-792">RFC 792</a></li><li><a href="#ping-source-code">Ping source code</a></li><li><a href="#id-conflict">ID conflict</a></li><li><a href="#netfilter-conntrack-and-nat">Netfilter, conntrack, and NAT</a></li><li><a href="#bpftrace">bpftrace</a></li><li><a href="#conclusion">Conclusion</a></li></ul></nav></details><h2 id="experiment-setup">Experiment setup</h2><p>One of the best ways to understand Linux networking is through experimentation. These days, it’s easy to run experiments using <a href="https://www.man7.org/linux/man-pages/man7/network_namespaces.7.html">network namespaces</a> to simulate multiple devices on a single Linux machine.</p><p>This is the setup I wanted to test:</p><p><img src="https://devnonsense.com/img/icmp-nat-setup.svg" alt="Diagram showing the setup of the experiment"></p><p>There are two clients (client1 and client2) connected to a router (natbox) performing NAT from private network 192.168.99.0/24 to public network 10.0.100.0/24. The clients, natbox, and server are each separate network namespaces. Once everything is ready, a <code>ping</code> from either client to the server at <code>10.0.100.2</code> should get a reply!</p><p>For these experiments, I used a Fedora 38 Server VM running version 6.2.9 of the Linux kernel. Most of the below commands (<code>ip</code>, <code>iptables</code>, <code>tcpdump</code>, etc.) were run as the root user.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><h3 id="step-1-connect-two-clients-to-a-bridge">Step 1: Connect two clients to a bridge</h3><p>The first step is to create two clients connected to a bridge, like this:
<img src="https://devnonsense.com/img/icmp-nat-clients-and-bridge.svg" alt="Diagram showing two clients connected to a bridge"></p><p>To set it up:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># Create a network namespace for each client.</span>
</span></span><span><span>ip netns add <span>"client1"</span>
</span></span><span><span>ip netns add <span>"client2"</span>
</span></span><span><span>
</span></span><span><span><span># Create a virtual bridge.</span>
</span></span><span><span>ip link add name <span>"br0"</span> <span>type</span> bridge
</span></span><span><span>ip link <span>set</span> dev <span>"br0"</span> up
</span></span><span><span>
</span></span><span><span><span># Disable iptables processing for bridges so rules don't block traffic over br0.</span>
</span></span><span><span>sysctl -w net.bridge.bridge-nf-call-iptables<span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span># Connect client1 to the bridge with a veth pair and assign IP address 192.168.99.1</span>
</span></span><span><span>ip link add dev <span>"vethclient1"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"client1"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient1"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient1"</span> up
</span></span><span><span>ip -n <span>"client1"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.1/24"</span>
</span></span><span><span>ip -n <span>"client1"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span><span><span>
</span></span><span><span><span># Same for client2, with IP address 192.168.99.2</span>
</span></span><span><span>ip link add dev <span>"vethclient2"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"client2"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient2"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethclient2"</span> up
</span></span><span><span>ip -n <span>"client2"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.2/24"</span>
</span></span><span><span>ip -n <span>"client2"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span></code></pre></div><p>If this worked, then:</p><ul><li><code>ip netns</code> should show <code>client1</code> and <code>client2</code>.</li><li><code>ip -n client1 addr</code> and <code>ip -n client2 addr</code> should show <code>192.168.99.1</code> and <code>192.168.99.2</code> respectively, and the <code>eth0</code> interface should show “state UP”.</li></ul><p>Now the two clients can ping each other over the bridge:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping client1 -&gt; client2</span>
</span></span><span><span>ip netns <span>exec</span> client1 ping 192.168.99.2
</span></span><span><span>
</span></span><span><span><span># ping client2 -&gt; client1</span>
</span></span><span><span>ip netns <span>exec</span> client2 ping 192.168.99.1
</span></span></code></pre></div><h3 id="step-2-connect-natbox-and-server">Step 2: Connect natbox and server</h3><p>Next, create network namespaces for the natbox and server:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns add <span>"natbox"</span>
</span></span><span><span>ip netns add <span>"server"</span>
</span></span></code></pre></div><p>Then connect the natbox to the bridge:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip link add dev <span>"vethnatbox"</span> <span>type</span> veth peer name <span>"eth0"</span> netns <span>"natbox"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethnatbox"</span> master <span>"br0"</span>
</span></span><span><span>ip link <span>set</span> <span>"vethnatbox"</span> up
</span></span><span><span>ip -n <span>"natbox"</span> addr add dev <span>"eth0"</span> <span>"192.168.99.3/24"</span>
</span></span><span><span>ip -n <span>"natbox"</span> link <span>set</span> dev <span>"eth0"</span> up
</span></span></code></pre></div><p>The natbox needs a second interface in the 10.0.100.0/24 network, so add that and call it “eth1”. Since there’s only one server, there’s no need for a bridge – just connect the natbox and server directly with a veth pair:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip -n <span>"natbox"</span> link add <span>"eth1"</span> <span>type</span> veth peer name <span>"eth1"</span> netns <span>"server"</span>
</span></span><span><span>ip -n <span>"natbox"</span> addr add dev <span>"eth1"</span> <span>"10.0.100.1/24"</span>
</span></span><span><span>ip -n <span>"natbox"</span> link <span>set</span> dev <span>"eth1"</span> up
</span></span><span><span>ip -n <span>"server"</span> addr add dev <span>"eth1"</span> <span>"10.0.100.2/24"</span>
</span></span><span><span>ip -n <span>"server"</span> link <span>set</span> dev <span>"eth1"</span> up
</span></span></code></pre></div><p>Now the natbox can reach both clients and the server. Test it with ping:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping natbox -&gt; client1</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 192.168.99.1
</span></span><span><span>
</span></span><span><span><span># ping natbox -&gt; client2</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 192.168.99.2
</span></span><span><span>
</span></span><span><span><span># ping natbox -&gt; server</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span></code></pre></div><p>At this point, every network namespace, interface, and veth pair has been created:
<img src="https://devnonsense.com/img/icmp-nat-setup.svg" alt="Diagram showing the setup of the experiment"></p><p>However, the client cannot yet ping the server because the natbox isn’t forwarding traffic between its interfaces or performing NAT.</p><h3 id="step-3-configure-routing-and-nat">Step 3: Configure routing and NAT</h3><p>Add a default route in each client to send traffic to the natbox:</p><pre tabindex="0"><code>ip -n client1 route add 0.0.0.0/0 via 192.168.99.3
ip -n client2 route add 0.0.0.0/0 via 192.168.99.3
</code></pre><p>For security reasons, Linux does not forward packets between interfaces unless specifically enabled. So configure the natbox to forward traffic by setting <code>net.ipv4.ip_forward</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> natbox sysctl <span>"net.ipv4.ip_forward=1"</span>
</span></span></code></pre></div><p>At this point, packets from a client will reach the server. However, these packets will retain the original source IP in the 192.168.99.0/24 network, so replies from the server back to this IP will go… nowhere. Fix it by configuring the natbox to NAT the traffic from a client IP (in network 192.168.99.0/24) to the natbox’s public IP (10.0.100.1/24). The easiest way to do this is to add a MASQUERADE rule to the iptables “nat” chain:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> natbox iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE
</span></span></code></pre></div><p>At last, clients can reach the server through the natbox! Test it with ping:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping client1 -&gt; server via natbox</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span><span><span>
</span></span><span><span><span># ping client2 -&gt; server via natbox</span>
</span></span><span><span>ip netns <span>exec</span> natbox ping 10.0.100.2
</span></span></code></pre></div><h2 id="packet-capture">Packet capture</h2><p>Now capture ICMP packets from both client and server network namespaces.</p><div><pre tabindex="0"><code data-lang="bash"><span><span>ip netns <span>exec</span> client1 tcpdump -n icmp
</span></span><span><span>ip netns <span>exec</span> server tcpdump -n icmp
</span></span></code></pre></div><p>This is the tcpdump for client1:</p><pre tabindex="0"><code>08:01:33.549598 IP 192.168.99.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64
08:01:33.549661 IP 10.0.100.2 &gt; 192.168.99.1: ICMP echo reply, id 31428, seq 1, length 64
08:01:34.610605 IP 192.168.99.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64
08:01:34.610654 IP 10.0.100.2 &gt; 192.168.99.1: ICMP echo reply, id 31428, seq 2, length 64
</code></pre><p>… and the corresponding tcpdump for the server:</p><pre tabindex="0"><code>08:01:33.549643 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64
08:01:33.549654 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 31428, seq 1, length 64
08:01:34.446611 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 33391, seq 1, length 64
08:01:34.446619 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 33391, seq 1, length 64
08:01:34.610635 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64
08:01:34.610646 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 31428, seq 2, length 64
08:01:35.506411 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 33391, seq 2, length 64
08:01:35.506423 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 33391, seq 2, length 64
</code></pre><p>These captures show that:</p><ul><li>Traffic is being NAT’d. By the time an ICMP echo request reaches the server (10.0.100.2), its source IP has been rewritten to the IP of the natbox (10.0.100.1).</li><li>Each client has a different “id” field (in the capture above, client1 has ID 31428 and client2 has ID 33391).</li></ul><p>The “id” field seemed like it might allow the natbox to distinguish reply packets destined for each client. But what does the “id” field mean, and how is it chosen?</p><h2 id="rfc-792">RFC 792</h2><p>ICMP is a very, very old protocol. It is defined in <a href="https://datatracker.ietf.org/doc/html/rfc792">RFC 792</a>, which was published in 1981. The RFC specifies the exact structure of an ICMP echo and echo reply message:</p><pre tabindex="0"><code>    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |     Type      |     Code      |          Checksum             |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |           Identifier          |        Sequence Number        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |     Data ...
   +-+-+-+-+-
</code></pre><p>The “type” field distinguishes an echo request (8) from an echo reply (1). Code is always 0 (I guess it isn’t used for anything?). What about “sequence number” and “identifier”?</p><blockquote><p>If code = 0, an identifier to aid in matching echos and replies,
may be zero…</p><p>If code = 0, a sequence number to aid in matching echos and
replies, may be zero…</p><p>The identifier and sequence number may be used by the echo sender
to aid in matching the replies with the echo requests. For
example, the identifier might be used like a port in TCP or UDP to
identify a session, and the sequence number might be incremented
on each echo request sent. The echoer returns these same values
in the echo reply.</p></blockquote><p>The RFC doesn’t say anything about how the IDs are actually chosen. That’s not part of the protocol specification, so the next step is to look at an implementation – in this case, the source code for the <code>ping</code> command.</p><h2 id="ping-source-code">Ping source code</h2><p>The <code>ping</code> command is part of the “iputils” package, with source code available at <a href="https://github.com/iputils/iputils">github.com/iputils/iputils</a>. There is a <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L1511-L1519">comment</a> just before <code>ping4_send_probe</code>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>/*
</span></span></span><span><span><span> * pinger --
</span></span></span><span><span><span> * 	Compose and transmit an ICMP ECHO REQUEST packet.  The IP packet
</span></span></span><span><span><span> * will be added on by the kernel.  The ID field is a random number,
</span></span></span><span><span><span> * and the sequence number is an ascending integer.  The first several bytes
</span></span></span><span><span><span> * of the data portion are used to hold a UNIX "timeval" struct in VAX
</span></span></span><span><span><span> * byte-order, to compute the round-trip time.
</span></span></span><span><span><span> */</span>
</span></span></code></pre></div><p>So <code>ping</code> chooses the identifier randomly. It’s a bit difficult to see where this actually happens in the code, but from what I understand:</p><ol><li>There is a <code>struct ping_rts</code> that has a field <code>ident</code>.</li><li>The <code>ident</code> field <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L327C9-L327C9">defaults to <code>-1</code></a>, but can be <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L375-L378">overridden by the CLI flag “-e”</a> to any value between zero and <code>IDENTIFIER_MAX</code> (0xFFFF).</li><li>When <code>rts-&gt;ident == -1</code>, <code>ping</code> binds to a socket with type <code>SOCK_DGRAM</code> and protocol <code>IPPROTO_ICMP</code>. <a href="https://github.com/iputils/iputils/blob/b50711313236696e322b38fb34c0b11cc13cc526/ping/ping.c#L893-L895">In this configuration, it does not modify <code>source.sin_port</code></a>, so the source port is zero.</li></ol><p>I didn’t find much documentation for how Linux implements <code>SOCK_DGRAM</code> sockets with <code>IPPROTO_ICMP</code>, except for this description from the <a href="https://lore.kernel.org/lkml/20110413113204.GB6948@albatros/T/">mailing list “net: ipv4: add IPPROTO_ICMP socket kind”</a>:</p><blockquote><p>ICMP headers given to send() are checked and sanitized. The type must be
ICMP_ECHO and the code must be zero (future extensions might relax this,
see below). <strong>The id is set to the number (local port) of the socket</strong>, the
checksum is always recomputed.</p></blockquote><p>I suspect that when <code>ping</code> doesn’t specify a source port (<code>source.sin_port == 0</code>), then the Linux kernel chooses a free port at random. This port then gets used as the ID for ICMP packets.</p><h2 id="id-conflict">ID conflict</h2><p>What happens if two <code>ping</code> processes on different hosts both choose the exact same ID? Test it using <code>ping -e</code> to explicitly set the ICMP ID to the same value for both clients:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># ping from client1 -&gt; server with ICMP ID 999</span>
</span></span><span><span>ip netns <span>exec</span> client1 ping 10.0.100.2 -e <span>999</span>
</span></span><span><span>
</span></span><span><span><span># ping from client2 -&gt; server with ICMP ID 999</span>
</span></span><span><span>ip netns <span>exec</span> client2 ping 10.0.100.2 -e <span>999</span>
</span></span></code></pre></div><p>This time, the packet capture from the server shows something different:</p><pre tabindex="0"><code>10:22:18.807289 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 1, length 64
10:22:18.807300 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 1, length 64
10:22:19.838650 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 2, length 64
10:22:19.838661 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 2, length 64
10:22:20.011677 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 30218, seq 1, length 64
10:22:20.011687 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 30218, seq 1, length 64
10:22:20.862591 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 999, seq 3, length 64
10:22:20.862603 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 999, seq 3, length 64
10:22:21.054598 IP 10.0.100.1 &gt; 10.0.100.2: ICMP echo request, id 30218, seq 2, length 64
10:22:21.054614 IP 10.0.100.2 &gt; 10.0.100.1: ICMP echo reply, id 30218, seq 2, length 64
</code></pre><p>One of the clients is using ID 999, but the other one is using ID 30218. Where did that second ID come from? Time to go to the Linux source code.</p><h2 id="netfilter-conntrack-and-nat">Netfilter, conntrack, and NAT</h2><p>The kernel subsystem responsible for implementing iptables rules is called “netfilter.” The iptables MASQUERADE rule is responsible for NAT’ing packets, so the NAT implementation for ICMP must be in netfilter. Grep’ing through the <code>net/netfilter</code> directory in the Linux repository, I found a few places where the ICMP “id” field is used:</p><ul><li>In “nf_nat_core.c” the function <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L580"><code>nf_nat_setup_info</code></a> calls <code>get_unique_tuple</code>, which calls <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L380"><code>nf_nat_l4proto_unique_tuple</code></a>. There is a switch statement with a case for <code>IPPROTO_ICMP</code>, and a reference to <code>&amp;tuple-&gt;src.u.icmp.id</code>.</li><li>In “nf_nat_proto.c” the function <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_proto.c#L419"><code>nf_nat_manip_pkt</code></a> calls <code>nf_nat_ipv4_manip_pkt</code>, which calls <code>l4proto_manip_pkt</code>. When the protocol is <code>IPPROTO_ICMP</code> this calls <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_proto.c#L223"><code>icmp_manip_pkt</code>, which has a line <code>hdr-&gt;un.echo.id = tuple-&gt;src.u.icmp.id</code></a>.</li></ul><p>In order to NAT packets, netfilter needs to store something called a <em>connection</em>. For TCP, not surprisingly, this represents the TCP connection, uniquely identified by the 5-tuple (src IP, src port, dst IP, dst port, L4 protocol). However, in netfilter the term “connection” has a broader meaning: it can correlate outgoing and incoming packets <em>even for connectionless protocols</em> like UDP and ICMP.</p><p>Examining the <a href="https://elixir.bootlin.com/linux/v6.2.9/source/include/net/netfilter/nf_conntrack.h#L75"><code>nf_conn</code></a> data structure:</p><ul><li><code>nf_conn</code> has a field <code>struct nf_conntrack_tuple_hash tuplehash[IP_CT_DIR_MAX]</code>. There are two tuple hashes, one for outgoing packets and one for incoming packets (<code>IP_CT_DIR_ORIGINAL</code> and <code>IP_CT_DIR_REPLY</code> respectively).</li><li>Each <code>nf_conntrack_tuple_hash</code> has a field <code>nf_conntrack_tuple tuple</code> with the tuple uniquely identifying the connection.</li><li>Each tuple is split into a part that can be manipulated, called <code>src</code>, and a part that is immutable called <code>dst</code>.<ul><li><code>src</code> has type <code>struct nf_conntrack_man</code>, which has an IP address (<code>union nf_inet_addr u3</code>) and protocol-specific fields (<code>union nf_conntrack_man_proto u</code>). For ICMP, the protocol-specific field is <code>__be16 id</code>.</li><li><code>dst</code> has the unmodified IP address as well as the ICMP <code>type</code> and <code>code</code> fields.</li></ul></li></ul><p>Connection tracking and NAT are closely related. To NAT a packet, netfilter needs to “remember” how it modified the outgoing packet so it can reverse those modifications on the reply packet. It does so by representing the modifications in a connection.</p><p>For ICMP, I believe netfilter works like this:</p><ol><li>When natbox receives an ICMP echo, <code>nf_nat_setup_info</code> creates a new connection. This is where it chooses whether it needs to rewrite the source IP address and/or the ICMP id field on the outgoing packet.</li><li>For each incoming and outgoing ICMP packet, the function <code>nf_nat_manip_pkt</code> sets the source IP and ICMP id field to whatever is set in the connection. The argument <code>ip_conntrack_dir dir</code> determines whether the packet is treated as an outgoing echo (rewrite the source IP) or incoming reply (rewrite the destination IP).</li></ol><p><a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L580"><code>nf_nat_setup_info</code></a> is responsible for choosing the ICMP ID for the NAT’d packets. The NAT rewrites happen in <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L504"><code>get_unique_tuple</code></a>.</p><p>Here are the key steps:</p><ol><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L541">line 541</a>, <code>find_best_ips_proto(zone, tuple, range, ct, maniptype)</code> rewrites the source IP address.</li><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L548">lines 548-560</a>, <code>nf_nat_used_tuple(tuple, ct)</code> checks whether the tuple is already being used; if not, the current tuple is returned. This explains why when two clients use <em>different</em> ICMP IDs, those IDs are preserved in the NAT’d packets.</li><li>On <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L563">line 563</a>, <code>nf_nat_l4proto_unique_tuple</code> is called to perform protocol-specific NAT (in this case manipulating the ICMP ID field).</li><li>In <code>nf_nat_l4proto_unique_tuple</code> <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L393">lines 393-403</a> set <code>keyptr = &amp;tuple-&gt;src.u.icmp.id</code> to choose the ICMP ID field as the “key” to NAT, then jumps to <code>find_free_id</code> at the end of the function.</li><li><code>find_free_id</code> on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L471">line 471</a> calls <code>get_random_u16()</code> to generate a random ID, adjusts the value into the range<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of valid ICMP IDs (on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L485">line 485</a>), then checks if it’s used (another call to <code>nf_nat_used_tuple</code> on <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L486">line 486</a>).</li><li>If a tuple with the random ID not yet used, then it gets returned. Otherwise, netfilter searches for an unused ID from progressively smaller ranges starting at random offsets (<a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L483">lines 483-494</a>).</li><li>If an unused tuple cannot be found within a maximum number of attempts, then <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L491"><code>nf_nat_l4_proto_unique_tuple</code> returns</a>, leaving the duplicate ID in the connection. Later, <a href="https://elixir.bootlin.com/linux/v6.2.9/source/net/netfilter/nf_nat_core.c#L502">__nf_conntrack_confirm will detect the duplicate and drop the packet</a>.</li></ol><h2 id="bpftrace">bpftrace</h2><p>To verify my understanding of the netfilter code, I used a tool called <a href="https://github.com/iovisor/bpftrace/"><code>bpftrace</code></a>.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> After much tinkering, I ended up with this program to trace the kernel functions <code>nf_nat_setup_info</code> and <code>nf_nat_manip_pkt</code>:</p><pre tabindex="0"><code>// from linux/socket.h
#define AF_INET		2	/* Internet IP Protocol 	*/

// from net/netfilter/nf_nat.h
enum nf_nat_manip_type {
	NF_NAT_MANIP_SRC,
	NF_NAT_MANIP_DST
};

// from include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
// Use #define instead of enum so we can use these in bpftrace array indices.
#define IP_CT_DIR_ORIGINAL 0
#define IP_CT_DIR_REPLY 1

kprobe:nf_nat_setup_info {
	// nf_nat_setup_info gets called twice, once in the prerouting chain
	// to modify the destination (actually a no-op), and once in the output
	// chain to modify the source (which is what we care about).
	$mtype = arg2;
	if ($mtype != NF_NAT_MANIP_SRC) {
		return;
	}

	$conn = (struct nf_conn *)arg0;
	if ($conn-&gt;tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.protonum == IPPROTO_ICMP) {
		@setupConn[tid] = $conn;
	}
}

kretprobe:nf_nat_setup_info {
	if (@setupConn[tid] == none) {
		return;
	}
	$conn = (struct nf_conn *)@setupConn[tid];
	$origTuple = $conn-&gt;tuplehash[IP_CT_DIR_ORIGINAL].tuple;
	$replyTuple = $conn-&gt;tuplehash[IP_CT_DIR_REPLY].tuple;
	printf("nf_nat_setup_info: origTuple.addr=%s, origTuple.id=%d, replyTuple.addr=%s, replyTuple.id=%d\n",
		ntop(AF_INET, $origTuple.src.u3.ip),
		bswap($origTuple.src.u.icmp.id),
		ntop(AF_INET, $replyTuple.src.u3.ip),
		bswap($replyTuple.src.u.icmp.id));
	delete(@setupConn[tid]);
}

kprobe:nf_nat_manip_pkt {
	$mtype = arg2;
	$skb = (struct sk_buff *)arg0;
	$iphdr = (struct iphdr *)$skb-&gt;data;
	$icmphdr = (struct icmphdr *)($skb-&gt;data + $iphdr-&gt;ihl * 4);
	printf("nf_nat_manip_pkt before: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\n",
		$mtype,
		ntop(AF_INET, $iphdr-&gt;saddr),
		ntop(AF_INET, $iphdr-&gt;daddr),
		bswap($icmphdr-&gt;type),
		bswap($icmphdr-&gt;un.echo.id));
	@manipType[tid] = $mtype;
	@manipSkb[tid] = $skb
}

kretprobe:nf_nat_manip_pkt {
	$mtype = @manipType[tid];
	$skb = @manipSkb[tid];
	$iphdr = (struct iphdr *)$skb-&gt;data;
	$icmphdr = (struct icmphdr *)($skb-&gt;data + $iphdr-&gt;ihl * 4);
	printf("nf_nat_manip_pkt after: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\n",
		$mtype,
		ntop(AF_INET, $iphdr-&gt;saddr),
		ntop(AF_INET, $iphdr-&gt;daddr),
		bswap($icmphdr-&gt;type),
		bswap($icmphdr-&gt;un.echo.id));
	delete(@manipType[tid]);
	delete(@manipSkb[tid]);
}
</code></pre><p>The important parts are:</p><ul><li><p><code>kprobe</code> traces when a kernel function is called, and <code>kretprobe</code> traces when the function returns.</p></li><li><p><code>kretprobe</code> cannot access function arguments directly, so store the arguments in a BPF map on entry and retrieve them on exit. For example, <code>kprobe:nf_nat_setup_info</code> writes the netfilter connection argument to <code>@setupConn[tid]</code> (a BPF map keyed by thread ID). Then <code>kretprobe:nf_nat_setup_info</code> reads the connection from the map and deletes the entry.</p></li><li><p><code>struct sk_buff</code> is how the Linux kernel <a href="https://docs.kernel.org/networking/skbuff.html">represents a packet</a>.</p></li><li><p><code>bswap</code> reverses byte order, which is used to convert from big endian (network byte order) to little endian.</p></li><li><p><code>ntop</code> returns the string representation of an IP address.</p></li><li><p>The BPF program can reference kernel data structures like <code>sk_buff</code> and <code>nf_conn</code> without including any headers. This is the magic of BPF Type Format (BTF) available in recent versions of the Linux kernel.</p></li><li><p>I tested this program on Linux kernel version 6.2.9. It may or may not work on other kernel versions.</p></li></ul><p>To execute the program, I saved the above code to a file called <code>trace.bt</code> then ran <code>bpftrace trace.bt</code> as root. This is what the output looks like with two clients pinging the server using the same ICMP ID (999):</p><pre tabindex="0"><code>$ bpftrace trace.bt
Attaching 4 probes...
nf_nat_setup_info: origTuple.addr=192.168.99.1, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=999
nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=999
nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.1, icmp.type=0, icmp.id=999
nf_nat_setup_info: origTuple.addr=192.168.99.2, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=32809
nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.2, daddr=10.0.100.2, icmp.type=8, icmp.id=999
nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=32809
nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=32809
nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.2, icmp.type=0, icmp.id=999
</code></pre><p>The output shows that <code>nf_nat_setup_info</code> gets called twice, once for each client.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> For the first client (IP 192.168.99.1), both the original and reply tuple have the ICMP ID sent by the client (999). For the second client (IP 192.168.99.2), however, the reply tuple has been <em>rewritten</em> to ID 32809. For both clients, the source IP address has been rewritten to the IP of the natbox (10.0.100.2).</p><p>Once <code>nf_nat_setup_info</code> has created the connection, <code>nf_nat_manip_pkt</code> modifies the echo and echo reply ICMP packets. For the echo packet, <code>mtype=0</code> (<code>NF_NAT_MANIP_SRC</code>) because the source IP is rewritten. Likewise, the reply packet has <code>mtype=1</code> (<code>NF_NAT_MANIP_DST</code>) to rewrite the destination IP of the incoming reply back to the original client IP.</p><h2 id="conclusion">Conclusion</h2><p>So that is how Linux NATs a ping! In the end, maybe the answer isn’t very surprising – and, in fact, I discovered much later that most of this behavior is documented in the <a href="https://netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO-4.html#ss4.4">Netfilter Hacking HOWTO</a>. But it was a fun journey, and it’s nice to know exactly where this magic happens in the code.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google no longer offers new domain registrations (136 pts)]]></title>
            <link>https://domains.google/</link>
            <guid>37455574</guid>
            <pubDate>Sun, 10 Sep 2023 13:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://domains.google/">https://domains.google/</a>, See on <a href="https://news.ycombinator.com/item?id=37455574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><span aria-level="2" role="heading">
          An update on domains
    </span>
      </p>
      <p><span>
          Google no longer offers new domain registrations, but try&nbsp;Squarespace
    </span></p>
      <div>
            <p><a href="https://domains.squarespace.com/?channel=bd&amp;subchannel=google-domain&amp;campaign=&amp;subcampaign=&amp;source=google_domain_referral&amp;utm_source=google_domain_referral&amp;utm_medium=bd&amp;utm_content=google-domain&amp;utm_term=&amp;utm_campaign=" rel="noreferrer noopener" target="_blank" data-ga4-event="dahlia_select" data-ga4-eventparams="{&quot;contentType&quot;: &quot;cta&quot;, &quot;moduleName&quot;: &quot;purchase domain squarespace&quot;, &quot;itemId&quot;: &quot;purchase domain squarespace - hero&quot;}">
      <span>
          Get a new domain from&nbsp;Squarespace
    </span>
  </a>

      </p></div>
      <p><span>
          On September 7, 2023 Squarespace acquired all domain registrations and related customer accounts from Google Domains. Customers and domains will be transitioned over the next few months. <a href="https://support.google.com/domains/answer/13689670">Learn&nbsp;more.</a>
    </span></p>
      <div>
            <p><a href="https://domains.google.com/registrar" rel="noreferrer noopener" target="_blank" data-ga4-event="dahlia_select" data-ga4-eventparams="{&quot;contentType&quot;: &quot;link&quot;, &quot;moduleName&quot;: &quot;manage domains&quot;, &quot;itemId&quot;: &quot;manage domains - hero&quot;}">
      Already a Google Domains customer? Manage&nbsp;your&nbsp;current&nbsp;domains
  </a>

      </p></div>
      <p><span>
          This is an affiliate link. If you make a purchase from Squarespace, we may earn a&nbsp;commission.
    </span>
      </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Earth had hottest 3-months on record; unprecedented sea temps & extreme weather (329 pts)]]></title>
            <link>https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface</link>
            <guid>37455534</guid>
            <pubDate>Sun, 10 Sep 2023 13:14:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface">https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface</a>, See on <a href="https://news.ycombinator.com/item?id=37455534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><strong>Bonn and Geneva, 6 September 2023 (ECMWF and WMO)</strong> -&nbsp;Earth just had its hottest three months on record, according to the European Union-funded&nbsp;<a href="https://wmo.us9.list-manage.com/track/click?u=618614864060486033e4590d6&amp;id=fa16212f5d&amp;e=3e6d95b4e5">Copernicus Climate Change Service (C3S)</a> implemented by ECMWF. Global sea surface temperatures are at unprecedented highs for the third consecutive month and Antarctic sea ice extent remains at a record low for the time of year.</p>

<p>It was the hottest August on record – by a large margin – and the second hottest ever month after July 2023, according to the Copernicus Climate Change Service ERA 5 dataset. August as a whole is estimated to have been around 1.5°C warmer than the preindustrial average for 1850-1900, <a href="https://climate.copernicus.eu/summer-2023-hottest-record">according to the C3S monthly climate bulletin.</a></p>

<p>The year so far (January to August) is the second warmest on record behind 2016, when there was a powerful warming El Niño event.</p>

<p>August as a whole saw the highest global monthly average sea surface temperatures on record across all months, at 20.98°C. Temperatures exceeded the previous record (March 2016) every single day in August.</p>

<p>Antarctic sea ice extent remained at a record low level for the time of year, with a monthly value 12% below average, by far the largest negative anomaly for August since satellite observations began in the late 1970s. Arctic sea ice extent was 10% below average, but well above the record minimum of August 2012.</p>

<p>WMO consolidates data from C3S and five other international datasets for its climate monitoring activities and its State of the Climate reports<em>.&nbsp;</em></p>

<p>A report in May from WMO and the UK's Met Office predicted&nbsp;that there is a 98% likelihood that at least one of the next five years will be the warmest on record and a 66% chance of&nbsp;temporarily&nbsp;exceeding 1.5°C above the 1850-1900 average for at least one of the five years.&nbsp;This does not mean that we will permanently exceed the 1.5°C level specified in the Paris Agreement which refers to long-term warming over many years.</p>



<p>&nbsp;&nbsp;<img alt="red chart on black background" title="Copernicus ECMWF: warmest months on record" data-delta="1" typeof="foaf:Image" src="https://ane4bf-datap1.s3-eu-west-1.amazonaws.com/wmocms/s3fs-public/ckeditor/files/6b8d528f-36ee-43c2-920e-44fec02063f9.png?ni8DG4pTlOSP8XsKWzThg.Qp8pa0Rrfi" width="1893" height="1225"></p>



<p><strong>Commentary</strong></p>

<p>“Our planet has just endured a season of simmering -- the hottest summer on record. Climate breakdown has begun.&nbsp;Scientists have long warned what our fossil fuel addiction will unleash. Surging temperatures demand a surge in action. Leaders must turn up the heat now for climate solutions. We can still avoid the worst of climate chaos – and we don’t have a moment to lose,&nbsp;“<strong> <em>said UN Secretary-General António Guterres.</em></strong><em>&nbsp;</em></p>

<p>“The northern hemisphere just had a summer of extremes – with repeated heatwaves fuelling devastating wildfires, harming health, disrupting daily lives and wreaking a lasting toll on the environment. In the southern hemisphere Antarctic sea ice extent was literally off the charts, and the global sea surface temperature was once again at a new record. It is worth noting that this is happening BEFORE we see the full warming impact of the El Niño event, which typically plays out in the second year after it develops” s<em>ays <strong>World Meteorological Organization Secretary-General Prof. Petteri Taalas.</strong></em></p>

<p>“Eight months into 2023, so far we are experiencing the second warmest year to date, only fractionally cooler than 2016, and August was estimated to be around 1.5°C warmer than pre-industrial levels. What we are observing, not only new extremes but the persistence of these record-breaking conditions, and the impacts these have on both people and planet, are a clear consequence of the warming of the climate system,” <em>comments <strong>Carlo Buontempo, Director of the Copernicus Climate Change Service, ECMWF.</strong></em></p>



<p>&nbsp;<img alt="red, white and blue chart on black background " title="Copernicus ECMWF sea surface temperature anamolies" data-delta="3" typeof="foaf:Image" src="https://ane4bf-datap1.s3-eu-west-1.amazonaws.com/wmocms/s3fs-public/ckeditor/files/timeseries_era5_daily_sst_60S-60N_1940-2023_0.png?VQ1ajBah_dEP8011aB6lGYOICJWwlNp1" width="2550" height="1650"></p>



<p>Notes for Editors</p>

<p><em>The World Meteorological Organization is the UN system's authoritative voice on weather climate and water.</em></p>

<p><em>C3S, implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) on behalf of the European Commission, routinely monitors climate and has also been closely following recent development of global air and sea surface temperatures. The monthly report and associated assets is <a href="https://climate.copernicus.eu/summer-2023-hottest-record">here</a>.</em></p>

<p>More information on the sea surface temperatures in August 2023 can be found&nbsp;<a data-auth="NotApplicable" data-linkindex="7" href="https://climate.copernicus.eu/record-high-global-sea-surface-temperatures-continue-august?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here.</a></p>

<p>More information about climate variables in August and climate updates of previous months as well as high-resolution graphics and the video can be downloaded&nbsp;<a data-auth="NotApplicable" data-linkindex="8" href="https://climate.copernicus.eu/climate-bulletins?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here</a>.</p>

<p>Answers to frequently asked questions regarding temperature monitoring can be found&nbsp;<a data-auth="NotApplicable" data-linkindex="9" href="https://climate.copernicus.eu/temperature-qas?utm_source=press&amp;utm_medium=referral&amp;utm_campaign=CBaugust23" rel="noopener noreferrer" target="_blank">here</a>.</p>








  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“Make” as a Static Site Generator (2022) (186 pts)]]></title>
            <link>https://www.karl.berlin/static-site.html</link>
            <guid>37454853</guid>
            <pubDate>Sun, 10 Sep 2023 11:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.karl.berlin/static-site.html">https://www.karl.berlin/static-site.html</a>, See on <a href="https://news.ycombinator.com/item?id=37454853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Static site generators are in fashion for good reasons. The resulting pages are easy to host, fast and extremely low on maintenance while being sufficient for many use cases.
As I learned when <a href="https://www.karl.berlin/blog.html">setting up my blog</a>, writing a simple script myself is faster and more satisfying than learning one of the other site builders and customizing it to my needs.
This time, I only need a plain site without automatically updated timestamps or an RSS-feed, so I can go even simpler than by blog script.</p>
<h2>Basic setup</h2>
<p>To get the site into a working state, I require the following functionality:</p>

<ul>
<li>All input files reside in the <code>source</code> directory, in the same layout as I want them in the output.</li>
<li>During processing, add a header to all HTML files.</li>
<li>Copy all other files to the <code>build</code> directory as they are.</li>
</ul>
<p>Each of these points results in one rule in the Makefile:</p>
<pre><code># The `build` target depends on all output files in the `build` directory. It
# does not do anything by itself, but causes one of the following rules to be
# applied for each file.
build: $(patsubst source/%,build/%,$(shell find source -type f))

# For each .html file do `cat header.html $input &gt; $output`.
build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	cat header.html $&lt; &gt; $@

# Copy all other files without changes.
build/%: source/%
	cp $&lt; $@
</code></pre>
<p>With a corresponding <code>header.html</code> and these rules in place, calling <code>make build</code> will create a <code>build</code> directory that can be browsed locally or uploaded to any web server.</p>
<h2>Variations</h2>
<p>This is really all you need, but the real strength of this approach is that it is so simple, that you can trivially extend it to fit different needs. Let me show you a few examples!</p>
<h3>Mark Current Page</h3>
<p>It is helpful to highlight the current page in the navigation so that the visitor sees where he is within the site at a glance. To do this, we search for the link within the navigation and replace the link with a highlighted version. The specifics vary depending on your markup. I'm using the following code to add the <code>current</code> class to the link tag:</p>
<pre><code>build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	sed -E 's|(href="$(subst source,,$&lt;))|class="current" \1|' header.html | cat - $&lt; &gt; $@
</code></pre>
<h3>Generate Page From Markdown</h3>
<p>If you dislike writing HTML or if you have existing content in markdown format, you can pipe your markdown content through a markdown-to-HTML converter of you choice (I like <a href="https://github.com/karlb/smu">smu</a>).</p>
<pre><code>build/%.html: source/%.html header.html Makefile
	@mkdir -p $(dir $@)
	smu $&lt; | cat header.html - &gt; $@
</code></pre>
<p>Since we still assume that <code>build/foo.html</code> is built from <code>source/foo.html</code>, you should keep the <code>.html</code> suffix for the markdown files or modify the rules to look for <code>.md</code> files as input.</p>
<h2>Little Helpers</h2>
<p>You can not only modify the site generation itself. Convenience features can also be added as additional make targets.</p>
<h3>Serve Site Locally</h3>
<p>Not all sites can be accurately previewed by opening the local files in your browser.
The most common reason for this is using absolute links instead of relative ones.
In those cases, you will want to run a small test web server locally to preview your site.
Python is already installed on many systems and comes with a web server this is suitable for the task.</p>
<pre><code>serve:
	python -m http.server -d build
</code></pre>
<h3>Rebuild on Change</h3>
<p>If you work a lot on your site, manually rebuilding after each change is a hassle.
Just use <a href="https://eradman.com/entrproject/"><code>entr</code></a> (or <a href="https://linux.die.net/man/1/inotifywait"><code>inotifywait</code></a> if you want to avoid the dependency) to rebuild automatically when a file in the source directory changes.</p>
<pre><code>watch:
	find source header.html Makefile | entr make build
</code></pre>
<h3>Upload to GitHub Pages</h3>
<p>I store my repositories on GitHub, so using GitHub Pages to host the resulting HTML is a natural choice.
Getting the commands just right so that you don't have to care about git details when publishing is a bit tricky, but easy enough in the end.
The approach is based on <a href="https://sangsoonam.github.io/2019/02/08/using-git-worktree-to-deploy-github-pages.html">Sangsoo Nam's post</a>.</p>
<pre><code>deploy:
	git worktree add public_html gh-pages
	cp -rf build/* public_html
	cd public_html &amp;&amp; \
	  git add --all &amp;&amp; \
	  git commit -m "Deploy to github pages" &amp;&amp; \
	  git push origin gh-pages
	git worktree remove public_html
</code></pre>
<h2>Summary</h2>
<p>Having your own static site generator in only six simple lines in a Makefile is great!
There are no exotic dependencies, nothing to maintain and you can quickly adapt it to your needs.
A page I built using this approach is available at <a href="https://github.com/karlb/astridbartel.de">https://github.com/karlb/astridbartel.de</a> and can serve as a real world example.</p>
<small>Written on 2022-06-14.</small>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I wired up my bike's GPS to order me pizza during a gravel race (202 pts)]]></title>
            <link>https://steele.blue/geofence-pizza-ordering/</link>
            <guid>37454766</guid>
            <pubDate>Sun, 10 Sep 2023 11:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steele.blue/geofence-pizza-ordering/">https://steele.blue/geofence-pizza-ordering/</a>, See on <a href="https://news.ycombinator.com/item?id=37454766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As harvest season begins here in the Midwest, I once again celebrate by grinding Nebraska gravel at the <a href="https://www.gravel-worlds.com/the-long-voyage">Gravel Worlds Long Voyage</a> bike race.
As in previous years (<a href="https://steele.blue/gravel-worlds">2021</a>) (<a href="https://steele.blue/serverless-bike-gps">2022</a>), I spent more time writing code for a marginally-useful project than I did training. But hey, I finished!</p>
<p><span>
      <a href="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b4e28/matt-gw.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/3e828/matt-gw.webp 192w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/e6f2f/matt-gw.webp 384w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/8b983/matt-gw.webp 768w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b2d4b/matt-gw.webp 1152w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/0abaa/matt-gw.webp 1536w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/11d0e/matt-gw.webp 4005w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/7809d/matt-gw.jpg 192w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/4ecad/matt-gw.jpg 384w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/212bf/matt-gw.jpg 768w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/5ef17/matt-gw.jpg 1152w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/ac99c/matt-gw.jpg 1536w,
https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/b4e28/matt-gw.jpg 4005w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/9edd5fd38a7e5307edffcc6c56066780/212bf/matt-gw.jpg" alt="Matt riding on Gravel Worlds" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<h2>Fueled by Pizza</h2>
<p>My goal this year involved optimizing my food choices during the race: pizza from <a href="https://www.caseys.com/">Casey's General Store</a>.
These convenience stores are S-Tier options when out in the middle of nowhere.
In addition to snacks and drinks, most Casey's have a kitchen, and have pretty decent grab 'n go slices of pizza.</p>
<p><span>
      <a href="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/3e828/self-serve-pizza.webp 192w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/e6f2f/self-serve-pizza.webp 384w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/c1dc5/self-serve-pizza.webp 650w" sizes="(max-width: 650px) 100vw, 650px" type="image/webp">
          <source srcset="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/7809d/self-serve-pizza.jpg 192w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/4ecad/self-serve-pizza.jpg 384w,
https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg 650w" sizes="(max-width: 650px) 100vw, 650px" type="image/jpeg">
          <img src="https://steele.blue/static/7a9200edb092ed758a6ad507f4287d98/6aca1/self-serve-pizza.jpg" alt="A sample of the pizza on offer at a Casey's" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>My problem: last year, there were so many faster riders ahead of me, that <strong>all the pizza was taken by the time I made it to the stops.</strong> This is an outrage!</p>
<p>This year, I knew I had to do better. But with time winding down on improving my fitness, I had to resort to the latent superpower of software hackery.
My thought: <strong>why not have a fresh pizza ordered ahead of time, scheduled precisely for when I arrived?</strong></p>
<p>More precisely, I could write a script that ordered a pizza for me, GPS-triggered by my bike leaving a geofence about an hour from the stop. Building this <a href="https://steele.blue/serverless-bike-gps">on top of the serverless GPS tracker I made last year</a> should fit into the architecture pretty well.</p>
<h2>Casey's Pizza API When</h2>
<p><span>
      <a href="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/3e828/pizza-diagram.webp 192w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e6f2f/pizza-diagram.webp 384w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/c0989/pizza-diagram.webp 691w" sizes="(max-width: 691px) 100vw, 691px" type="image/webp">
          <source srcset="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/8514f/pizza-diagram.png 192w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/804b2/pizza-diagram.png 384w,
https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png 691w" sizes="(max-width: 691px) 100vw, 691px" type="image/png">
          <img src="https://steele.blue/static/f1fdd6640cd5211fda59075e28ff7c6e/e185b/pizza-diagram.png" alt="Architecture diagram" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>The overall design: I setup a geofence within the AWS Location service, which was monitoring my GPS tracker.
When my tracker exited the geofence, it would trigger a Lambda function that calculates an ETA for my next stop, and orders the pizza.</p>
<p>The problem: Casey's doesn't have a public API for online ordering.
So I had to resort to alternate approaches. More specifically, I fell back to <strong>screen scraping the website</strong>, everyone's favorite hack.
I've had to screen-scrape for other projects (such as <a href="https://steele.blue/secret-strava">updating privacy on Strava activities</a>), but since Casey's website was a complex React app that rendered everything on the client, I had to use a more powerful scraper; this time powered by <a href="https://playwright.dev/">Playwright</a>.</p>
<p>Getting Playwright to run in a Lambda was An Experience. Full writeup <a href="https://steele.blue/playwright-on-lambda">here</a>.</p>
<p>To keep track of the status, I also setup a push notification to be delivered to my phone (and watch) on a success or failure. Configuring Web Push to work on iOS devices is probably worthy of its own post.</p>
<h2>Pizza False Positive</h2>
<p>I had the triggering geofence configured around mile 180 of the race, with the pizza setup to be delivered at mile 200.</p>
<p><span>
      <a href="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b17f8/pizza-watch.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/3e828/pizza-watch.webp 192w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/e6f2f/pizza-watch.webp 384w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/8b983/pizza-watch.webp 768w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b2d4b/pizza-watch.webp 1152w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/0abaa/pizza-watch.webp 1536w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/fad48/pizza-watch.webp 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/7809d/pizza-watch.jpg 192w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/4ecad/pizza-watch.jpg 384w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/212bf/pizza-watch.jpg 768w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/5ef17/pizza-watch.jpg 1152w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/ac99c/pizza-watch.jpg 1536w,
https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/b17f8/pizza-watch.jpg 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/e1196b964a5d4a318c649926731f0d76/212bf/pizza-watch.jpg" alt="A push notification indicating pizza was delivered" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>As I left the geofence, I got a push notification on my watch saying that the pizza had been successfully ordered.</p>
<p>But when I made it to the stop, <strong>there was nothing at the counter, and they had no record of an order</strong>. And sure enough, I checked my account, and no order had been placed.
<strong>False positive.</strong></p>
<p>There were a few pre-made slices available, so I picked those up. They left a bitter taste in my mouth, not just because they weren't especially fresh. Through the rest of the 300-mile race, all I could think about was what might have went wrong with my function.</p>
<p><span>
      <a href="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b17f8/pizza-slices.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/3e828/pizza-slices.webp 192w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/e6f2f/pizza-slices.webp 384w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/8b983/pizza-slices.webp 768w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b2d4b/pizza-slices.webp 1152w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/0abaa/pizza-slices.webp 1536w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/fad48/pizza-slices.webp 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
          <source srcset="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/7809d/pizza-slices.jpg 192w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/4ecad/pizza-slices.jpg 384w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/212bf/pizza-slices.jpg 768w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/5ef17/pizza-slices.jpg 1152w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/ac99c/pizza-slices.jpg 1536w,
https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/b17f8/pizza-slices.jpg 1600w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
          <img src="https://steele.blue/static/dc526fd97ae4db5306832ed8945751be/212bf/pizza-slices.jpg" alt="A pair of dirty legs, eating slices of pre-made pizza" title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>After finishing the race, I made it to a computer and quickly checked the logs to see what had gone wrong. But to my chagrin, there was nothing in the logs indicating what caused the failure; it was just a silent success. I had nothing to go on to try and debug.</p>
<p>A few days later, I enhanced the Lambda to capture a video of the browser in action and upload it to an S3 bucket for analysis. Running a test of the updated behavior, <strong>it finally worked</strong>. I picked up a fresh Hawaiian pizza, and we enjoyed the pie from the comfort of our home.</p>
<p>I'm still not entirely sure why it worked. My going theory is that the Lambda had terminated processing as soon as the final <code>form.submit()</code> went through in the embedded Playwright browser. It's quite possible that the online ordering website saw that the browser never received a Success response, and didn't fully process the order.
My guess is that the additional time spent processing and uploading the video gave the browser sufficient time to clean up properly, with serendipity in timing.</p>
<h2>Pizza Lessons</h2>
<p>While I was bummed the pizza ordering functionality didn't run, I think it's in a good spot to try again in upcoming races.
I also learned a lot while building this out:</p>
<ul>
<li>Consistently screen-scraping a React client-side app with a browser running in the cloud: possible, but boy howdy is it finicky. If I were to redo project, I may opt for reverse engineering one of their native apps, focusing on triggering their APIs directly</li>
<li>Having a good workflow to simulate geospatial behavior is necessary. At first, I setup a geofence around my house for testing, but having to leave for a walk at 11pm gets pretty old, pretty fast</li>
<li>That said, don't skimp on real-world testing. Prior to the race, I was mostly testing the function by running it on my local workstation, not in a Lambda. The successes of the local functions gave me false confidence that everything was working as expected</li>
<li>If you're worried about running out of Casey's pizza during a gravel race, another option is to just let the groups ahead of you get more than 30 minutes ahead, so they have plenty of time to make more slices</li>
</ul>
<p>The code is available on GitHub: <a href="https://github.com/mattdsteele/spot-tracker-tracker/tree/main/pizza-function">https://github.com/mattdsteele/spot-tracker-tracker/tree/main/pizza-function</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nginx Unit – Universal web app server (436 pts)]]></title>
            <link>https://github.com/nginx/unit</link>
            <guid>37453854</guid>
            <pubDate>Sun, 10 Sep 2023 08:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nginx/unit">https://github.com/nginx/unit</a>, See on <a href="https://news.ycombinator.com/item?id=37453854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">NGINX Unit</h2>
<h2 tabindex="-1" dir="auto">Universal Web App Server</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nginx/unit/blob/master/docs/unitlogo.svg"><img src="https://github.com/nginx/unit/raw/master/docs/unitlogo.svg" alt="NGINX Unit Logo"></a></p>
<p dir="auto">NGINX Unit is a lightweight and versatile open-source server that has
two primary capabilities:</p>
<ul dir="auto">
<li>serves static media assets,</li>
<li>runs application code in seven languages.</li>
</ul>
<p dir="auto">Unit compresses several layers of the modern application stack into a potent,
coherent solution with a focus on performance, low latency, and scalability. It
is intended as a universal building block for any web architecture regardless
of its complexity, from enterprise-scale deployments to your pet's homepage.</p>
<p dir="auto">Its native <a href="#openapi-specification">RESTful JSON API</a> enables dynamic
updates with zero interruptions and flexible configuration, while its
out-of-the-box productivity reliably scales to production-grade workloads. We
achieve that with a complex, asynchronous, multithreading architecture
comprising multiple processes to ensure security and robustness while getting
the most out of today's computing platforms.</p>
<h2 tabindex="-1" dir="auto">Quick Installation</h2>
<h3 tabindex="-1" dir="auto">macOS</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ brew install nginx/unit/unit"><pre>$ <span>brew install nginx/unit/unit</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#homebrew" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Docker</h3>

<p dir="auto">For a description of image tags, see the
<a href="https://unit.nginx.org/installation/#docker-images" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Amazon Linux, Fedora, RedHat</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit &amp;&amp; chmod +x setup-unit
# ./setup-unit repo-config &amp;&amp; yum install unit
# ./setup-unit welcome"><pre>$ <span>wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit <span>&amp;&amp;</span> chmod +x setup-unit</span>
# <span>./setup-unit repo-config <span>&amp;&amp;</span> yum install unit</span>
# <span>./setup-unit welcome</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#official-packages" rel="nofollow">docs</a>.</p>
<h3 tabindex="-1" dir="auto">Debian, Ubuntu</h3>
<div dir="auto" data-snippet-clipboard-copy-content="$ wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit &amp;&amp; chmod +x setup-unit
# ./setup-unit repo-config &amp;&amp; apt install unit
# ./setup-unit welcome"><pre>$ <span>wget https://raw.githubusercontent.com/nginx/unit/master/tools/setup-unit <span>&amp;&amp;</span> chmod +x setup-unit</span>
# <span>./setup-unit repo-config <span>&amp;&amp;</span> apt install unit</span>
# <span>./setup-unit welcome</span></pre></div>
<p dir="auto">For details and available language packages, see the
<a href="https://unit.nginx.org/installation/#official-packages" rel="nofollow">docs</a>.</p>
<h2 tabindex="-1" dir="auto">Running a Hello World App</h2>
<p dir="auto">Unit runs apps in a
<a href="https://unit.nginx.org/howto/samples/" rel="nofollow">variety of languages</a>.
Let's consider a basic example,
choosing PHP for no particular reason.</p>
<p dir="auto">Suppose you saved a PHP script as <code>/www/helloworld/index.php</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<?php echo &quot;Hello, PHP on Unit!&quot;; ?>"><pre><span>&lt;?php</span> <span>echo</span> "<span>Hello, PHP on Unit!</span>"; <span>?&gt;</span></pre></div>
<p dir="auto">To run it on Unit with the <code>unit-php</code> module installed, first set up an
application object. Let's store our first config snippet in a file called
<code>config.json</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;helloworld&quot;: {
        &quot;type&quot;: &quot;php&quot;,
        &quot;root&quot;: &quot;/www/helloworld/&quot;
    }
}"><pre>{
    <span>"helloworld"</span>: {
        <span>"type"</span>: <span><span>"</span>php<span>"</span></span>,
        <span>"root"</span>: <span><span>"</span>/www/helloworld/<span>"</span></span>
    }
}</pre></div>
<p dir="auto">Saving it as a file isn't necessary, but can come in handy with larger objects.</p>
<p dir="auto">Now, <code>PUT</code> it into the <code>/config/applications</code> section of Unit's control API,
usually available by default via a Unix domain socket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl -X PUT --data-binary @config.json --unix-socket  \
       /path/to/control.unit.sock http://localhost/config/applications"><pre># <span>curl -X PUT --data-binary @config.json --unix-socket  \</span>
<span>       /path/to/control.unit.sock http://localhost/config/applications</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="
{
	&quot;success&quot;: &quot;Reconfiguration done.&quot;
}"><pre>{
	<span>"success"</span>: <span><span>"</span>Reconfiguration done.<span>"</span></span>
}</pre></div>
<p dir="auto">Next, reference the app from a listener object in the <code>/config/listeners</code>
section of the API.  This time, we pass the config snippet straight from the
command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl -X PUT -d '{&quot;127.0.0.1:8000&quot;: {&quot;pass&quot;: &quot;applications/helloworld&quot;}}'  \
       --unix-socket /path/to/control.unit.sock http://localhost/config/listeners"><pre># <span>curl -X PUT -d <span><span>'</span>{"127.0.0.1:8000": {"pass": "applications/helloworld"}}<span>'</span></span>  \</span>
<span>       --unix-socket /path/to/control.unit.sock http://localhost/config/listeners</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;success&quot;: &quot;Reconfiguration done.&quot;
}"><pre>{
    <span>"success"</span>: <span><span>"</span>Reconfiguration done.<span>"</span></span>
}</pre></div>
<p dir="auto">Now Unit accepts requests at the specified IP and port, passing them to the
application process. Your app works!</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl 127.0.0.1:8080

      Hello, PHP on Unit!"><pre>$ <span>curl 127.0.0.1:8080</span>

<span>      Hello, PHP on Unit!</span></pre></div>
<p dir="auto">Finally, query the entire <code>/config</code> section of the control API:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# curl --unix-socket /path/to/control.unit.sock http://localhost/config/"><pre># <span>curl --unix-socket /path/to/control.unit.sock http://localhost/config/</span></pre></div>
<p dir="auto">Unit's output should contain both snippets, neatly organized:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &quot;listeners&quot;: {
        &quot;127.0.0.1:8080&quot;: {
            &quot;pass&quot;: &quot;applications/helloworld&quot;
        }
    },

    &quot;applications&quot;: {
        &quot;helloworld&quot;: {
            &quot;type&quot;: &quot;php&quot;,
            &quot;root&quot;: &quot;/www/helloworld/&quot;
        }
    }
}"><pre>{
    <span>"listeners"</span>: {
        <span>"127.0.0.1:8080"</span>: {
            <span>"pass"</span>: <span><span>"</span>applications/helloworld<span>"</span></span>
        }
    },

    <span>"applications"</span>: {
        <span>"helloworld"</span>: {
            <span>"type"</span>: <span><span>"</span>php<span>"</span></span>,
            <span>"root"</span>: <span><span>"</span>/www/helloworld/<span>"</span></span>
        }
    }
}</pre></div>
<p dir="auto">For full details of configuration management, see the
<a href="https://unit.nginx.org/configuration/#configuration-management" rel="nofollow">docs</a>.</p>
<h2 tabindex="-1" dir="auto">OpenAPI Specification</h2>
<p dir="auto">Our <a href="https://github.com/nginx/unit/blob/master/docs/unit-openapi.yaml">OpenAPI specification</a> aims to simplify
configuring and integrating NGINX Unit deployments and provide an authoritative
source of knowledge about the control API.</p>
<p dir="auto">Although the specification is still in the early beta stage, it is a promising
step forward for the NGINX Unit community. While working on it, we kindly ask
you to experiment and provide feedback to help improve its functionality and
usability.</p>
<h2 tabindex="-1" dir="auto">Community</h2>
<ul dir="auto">
<li>
<p dir="auto">The go-to place to start asking questions and share your thoughts is
our <a href="https://community.nginx.org/joinslack" rel="nofollow">Slack channel</a>.</p>
</li>
<li>
<p dir="auto">Our <a href="https://github.com/nginx/unit/issues">GitHub issues page</a> offers
space for a more technical discussion at your own pace.</p>
</li>
<li>
<p dir="auto">The <a href="https://github.com/orgs/nginx/projects/1">project map</a> on
GitHub sheds some light on our current work and plans for the future.</p>
</li>
<li>
<p dir="auto">Our <a href="https://unit.nginx.org/" rel="nofollow">official website</a> may provide answers
not easily found otherwise.</p>
</li>
<li>
<p dir="auto">Get involved with the project by contributing! See the
<a href="https://github.com/nginx/unit/blob/master/CONTRIBUTING.md">contributing guide</a> for details.</p>
</li>
<li>
<p dir="auto">To reach the team directly, subscribe to the
<a href="https://mailman.nginx.org/mailman/listinfo/unit" rel="nofollow">mailing list</a>.</p>
</li>
<li>
<p dir="auto">For security issues, <a href="https://github.com/nginx/unit/blob/master/security-alert@nginx.org">email us</a>, mentioning
NGINX Unit in the subject and following the <a href="https://www.first.org/cvss/v3.1/specification-document" rel="nofollow">CVSS
v3.1</a> spec.</p>
</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Decline of Usability (2020) (187 pts)]]></title>
            <link>https://datagubbe.se/decusab/</link>
            <guid>37453616</guid>
            <pubDate>Sun, 10 Sep 2023 07:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datagubbe.se/decusab/">https://datagubbe.se/decusab/</a>, See on <a href="https://news.ycombinator.com/item?id=37453616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h2>The Decline of Usability</h2>

<p><b>In which we delve into the world of user interface design.</b></p>

<p><i>Spring 2020</i></p>

<h2>Our premise</h2>

<p>
There was a time (roughly between 1994 and 2012) when a reasonably computer-literate user could sit down in front of almost any operating system and quickly get to grips with the GUI, no matter what their home base was. Windows, MacOS, CDE, OpenStep, OS/2 and even outliers like Amiga, Atari and BeOS all had more in common than what set them apart. All windows had a title bar for dragging, easy identification and displaying current input focus. Clearly labeled drop-down menus following a set standard (File, Edit, View, Help etc.) made it easy for a newcomer to an application to browse program features and learn keyboard shortcuts. Buttons, input fields and other widget elements were clearly identifiable through various visual cues, such as 3D bevels.
</p>

<p>
A few rogue applications didn't play by the rules, but the vast majority of software did, at least in the fundamental places that really mattered.
</p>

<p>
Today, it seems we're on another track completely. Despite being endlessly fawned over by an army of professionals, Usability, or as it used to be called, "User Friendliness", is steadily declining. During the last ten years or so, adhering to basic standard concepts seems to have fallen out of fashion. On comparatively new platforms, I.E. smartphones, it's inevitable: the input mechanisms and interactions with the display are so different from desktop computers that new paradigms are warranted.
</p>

<p>
Worryingly, these paradigms have begun spreading to the desktop, where keyboards for fast typing and pixel-precision mice  effectively render them pointless. Coupled with the flat design trend, UI elements are increasingly growing both bigger and yet somehow harder to locate and tell apart from non-interactive decorations and content.
</p>

<p>
Overall, designers of desktop applications seem to have abandoned the fact that a desktop computer is capable of displaying several applications and windows at the same time and that many users are accustomed to this. Instead, we're increasingly treated to small-screen, single-app paradigms copied from smartphones. That's a turn for the worse in its own right, but perhaps more troubling and annoying is the recurring sidestepping from the tried and true UI design that is so ingrained in many users it's practically muscle memory by now.
</p>

<h2>Examples to prove a point</h2>
<br>
<h3>Window Management</h3>

<p>
Consider these title bars of a few popular Windows 10 applications:
</p>

<p><img src="https://datagubbe.se/decusab/windowtitles.png" alt="Screenshot of six heterogenous window titles stacked closely together"></p>

<p>
The image above is composed from screenshots taken on the same computer during the span of a few minutes. No settings have been changed between shots. Immediately, a plethora of UI problems become apparent.
</p>

<p>
Can you even tell how many windows there are? The answer is six - although the top three and bottom two could, when ending up stacked like this, look as if they're two single applications.
</p>

<p>
All of these title bars denote active windows. The top one, Outlook, looks exactly the same when inactive, as does Slack. Except for the command prompt (cmd.exe), the change between active and inactive on the remaining windows is so subtle that when aligned next to each other, it's virtually impossible to determine which one has the input focus.
</p>

<p>
Almost all of the title bars contain some kind of UI widget. Some have little tool icons, some have tabs, some have drop-down menus, some have combinations thereof. There is no set behavior and, more importantly, the clickable area for traditional operations (move, focus, raise) on each title bar is now of variable width. If you're accustomed to a title bar being for handling the window and nothing else, it's very easy to misclick and activate an application feature you didn't intend to. Oh, and the little Visual Studio Code logo on the second title bar from the top? Nope, not an icon. Purely decorative.
</p>

<p>
What's perhaps most jarring about this is that four of the six applications are made by Microsoft themselves, thus setting the standard for this kind of erratic design. We can already see the effects: the taking over of window title bars seems to get worse with time. Consider the latest version of Slack (click for a larger image):
</p>


<p><a href="https://datagubbe.se/decusab/slackhotspot.png"><img src="https://datagubbe.se/decusab/slackhotspot_s.png" alt="Screenshot of slack window title with UI hotspots marked in red and blue"></a></p>

<p>
Since Windows 2 (not 2000 - I'm really talking about Windows 2), users have been able to resize windows by dragging their top border and corners. Not so with Slack, anymore. The red lines in the image denote the remaining hotspots available for resizing. The blue lines denote the remaining hotspots available for moving the window. The rest is now taken up by a non-standard concoction of widgets that most users will either soon learn keyboard shortcuts for or that could very easily be incorporated into a more traditional UI.
</p>

<p>
Instead, some usability whizkid at some point decided to completely nullify the single most fundamental way of managing the window of an application mostly running on platforms where stacking, floating window management is not only the norm but pretty much the only available option.
</p>

<p><i>(Update 2020-04-22: It seems that Slack today pushed an update of their desktop version that dims the title bar slightly when the window is inactive.)</i></p>

<h3>Browsers</h3>

<p>
Microsoft and Slack aren't the only culprits. Google, for example, have gotten increasingly into some kind of A/B testing of late and their Chrome browser now features this type of tooltip when hovering on tabs:
</p>

<p><img src="https://datagubbe.se/decusab/hovertab.png" alt="Screenshot of Google Chrome tab tooltip"></p>

<p>
Usually, a browser tab will display a small, floating tooltip after having been hovered for a bit of time. This massive monstrosity pops up without delay and covers a large area of the underlying UI. The usefulness of browser tab tooltips can be discussed in itself, but this is no doubt both pointless and distracting.
</p>

<p>
Google aren't the only ones capable of producing distracting UI:s, though. The newly released Firefox version 75 features what has become known as "the megabar":
</p>

<p><img src="https://datagubbe.se/decusab/megabar.png" alt="Screenshot of Firefox URL megabar"></p>

<p>
This new take on the URL bar pops up when you least expect it, is very hard to get rid of and, as a bonus, covers the tried, tested and highly usable bookmarks toolbar below it. Just like widgets in title bars, this breaks the behavior of a UI concept in such a major way it's hard to begin describing: text input fields are ubiquitous, ancient and their basic concept has been the same since at least the early 1980:s.
</p>

<h3>Scroll bars</h3>

<p>
Another blow against recognizability and usability is harder to take a screenshot of, namely auto-hiding scroll bars. On a smartphone, it's a great invention because you can free up real estate on a small display and you've usually got your thumb resting close to the screen, ready to do a test scroll in your full screen app to see if more content is available.
</p>

<p>
On the desktop, however, a scroll bar is very useful for determining your current position in the content without having to break away from what you're presently doing and reach for the mouse. It's also useful for doing the same in windows that are currently not in focus. For example, in a tailing log file reader or command prompt with a debug stream, you might be interested in knowing if you're looking at the latest output or not. With auto-hiding scroll bars, this becomes much harder and you have to resort to other, often less apparent or more cumbersome methods.
</p>

<p>
In lieu of screenshots of hidden scroll bars, let's look at how QT5 renders them by default:
</p>

<p><img src="https://datagubbe.se/decusab/sbar.png" alt="Screenshot of QT5 scroll bar"></p>

<p>
Which part of this is the bar and which part is the tray? I know by now that the slightly brighter part is the bar, yet I frequently misclick, because the flat design makes them so hard to tell apart. Worse still is the infinitesimal contrast, so low that on older, cheaper laptop screens, it's downright impossible to tell the difference between bar and tray. New users probably don't know that with the right tools, QT5 can be configured to sport a more traditional look, so the default look should be geared towards them. Those intent on customizing the appearance of their personal desktop will usually find a way to do so anyway.
</p>

<h3>Missing Menu Bars</h3>

<p>
Another apparently unfashionable UI standard is the menu bar. It used to be a lowest common denominator between platforms and, when still present, it works basically the same on Windows, Mac and Unix-likes. For the most part, it even keeps the traditional "File, Edit, View" approach to things. The Gnome designers, however, have decided that such menus are apparently a bad feature and they should probably never have been used in the first place. To rectify more than three decades of such folly, they have created... something I'm not sure what to call.
</p>

<p>
One of the tricks up their sleeve is the hamburger menu. On smartphones, it's a great feature, but on the desktop, it's unnecessary: If there's anything we have on today's wide screen displays, it's horizontal space. In Gnome, it seems to be a catch-all for UI operations that didn't end up somewhere else. Like in Evince:
</p>

<p><img src="https://datagubbe.se/decusab/ev_menu3.png" alt="Screenshot of Evince hamburger menu"></p>

<p>
Open, Save, Print, Close. All of them reasonable tasks, except there's no adherence to standards. In Gnome-MPV, the hamburger menu looks like this:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu3.png" alt="Screenshot of Gnome-MPV hamburger menu"></p>


<p>
No Open or Close here, you silly user! What did you expect? Some kind of coherent thought? If you want to open a file, just click the little icon to the left featuring a plus sign:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu2.png" alt="Screenshot of Gnome-MPV plus sign menu"></p>

<p>
There's also a button with the Gnome-MPV icon on it. One might assume this button would contain features specific to Gnome-MPV, such as the ones found in the hamburger menu, but no. Instead it looks like this, containing options for preferences and quitting:
</p>

<p><img src="https://datagubbe.se/decusab/gmpv_menu1.png" alt="Screenshot of Gnome-MPV logo menu"></p>

<p>
In Evince, the button featuring an Evince icon produces this menu:
</p>

<p><img src="https://datagubbe.se/decusab/ev_menu1.png" alt="Screenshot of Evince logo menu"></p>

<p>
Bummer! In Evince, you clearly have to look somewhere else to find in-app preferences and a quit option: things are wildly inconsistent between applications, creating confusion and frustration for users. I also can't find a way to navigate these menus using the keyboard once they're open, as opposed to normal drop-down menus and other similar hamburger menus.
</p>

<h3>More Gnome</h3>

<p>
There are so many more examples in just these two Gnome applications alone that it's bordering on parodical. For example, they are designed for Gnome's new paradigm of incorporating toolbars into the window title bar, thus institutionalizing the crimes of the Windows applications mentioned above. The difference is of course that if you're running another window manager, it just looks silly, for example leaving you with two close gadgets. It also means that to keep a reasonably large area free for moving the window (At least that's better than Slack!), widgets that could previously have been fitted into a toolbar below the title bar now needs to be opened separately, such as this search box in Evince (click for a larger image):
</p>

<p><a href="https://datagubbe.se/decusab/ev_search.png"><img src="https://datagubbe.se/decusab/ev_search_s.png" alt="Screenshot of Evince search bar"></a></p><p>

Or this little extra toolbar for making annotations, containing a whopping total of two icons. That's one whole icon more than is used to open the toolbar itself, clearly warranting this particular design approach:

</p><p><img src="https://datagubbe.se/decusab/ev_extratoolbar.png" alt="Screenshot of Evince annotate toolbar"></p>

<h2>Wrapping up</h2>

<p>
These are just a few examples of crimes against basic concepts of desktop UI design. There are plenty more and they're present on all platforms. They are also, it seems, growing increasingly common: the times of coherency and industry standards seem to be over. I hope that with this little rant, I can plant a seed to bring them back. If not, it was at least good to blow off some steam.
</p>

<p>
I'm going to end by discussing some counter arguments I've come across when discussing modern UI design on various online forums:
</p>

<p>
<b>Technology is progressing! You can't stop change! Just deal with it!</b><br>
These and similar truisms and platitudes are commonly used when no real argument is available. It's people like you and me who decide to change UI design, not an unstoppable force of nature. Changing things doesn't necessarily imply improving them and it's improvement we should strive for, otherwise change is pointless.
</p>

<p>
<b>You're living in the past!</b><br>
Considering the apparent anachronisms in the above screenshots, I can't argue with the fact that I am.  However, that doesn't automatically mean I'm wrong. It also doesn't mean I think all modern desktop environments should look like Windows 95 or CDE. There are other roads forward and other ways to improve the look and feel of UI:s without breaking fundamental concepts.
</p>

<p>
<b>Electron apps can't follow a single platform's standard!</b><br>
Multi-platform applications will of course never fully incorporate into the host environment the way native ones do. But because of this, it's of extra importance that they at least adhere to the paradigms that are translatable between all the common target platforms of today. Drop-down menus, clean title bars and a clear indication of window focus aren't hard to implement, even if they don't look exactly like their surroundings. In fact, a multi-platform framework should make it easy for developers to implement these concepts and hard, if not impossible, to work around them.
</p>

<p>
<b>We shouldn't complain about free software! It's free!</b><br>
Yes. Yes we should. Don't get me wrong - I have a massive amount of respect and admiration for the time, skill and effort people put into FOSS projects. They are improving my personal quality of life significantly and for that I'm very grateful.
</p>

<p>
It's true that Gnome and KDE are FOSS, which is a thing of wonder. But they are also large enough to, just like Microsoft and Google, have a significant impact not only on normal end users but on aspiring designers and programmers as well. We should be able to share our views and discuss what that impact might result in.
</p>

<p>
In short: Anyone setting an example should also be held to a standard.
</p>

<p>
<b>Putting things in the title bar saves screen real estate!</b><br>
This is true to some extent, but screen real estate in general isn't much of a problem anymore. If this had been done in the days of 640x480 VGA, it could maybe have been a viable argument. Today, anyone working enough with computers to worry about a few pixels extra can buy a screen the size of a small TV with a 2560x1440 pixel resolution for around US$200. Even the cheapest of laptops come with at least a 1366x768 resolution, which is en par with the famed megapixel displays of yesteryear's professional workstations, coveted precisely for their generous amount of screen real estate.
</p>

<p>
If anything, the problem with screen real estate comes from the current trend of UI design with so much white space between elements that what used to be a simple requester is now a full-screen application, as evident in this example (click for larger image):
</p>

<p><a href="https://datagubbe.se/decusab/winpara2.png"><img src="https://datagubbe.se/decusab/winpara2_s.png" alt="Screenshot of Windows power settings"></a></p>

<p>
For those spending all their workdays coding on a 13" laptop, my tip is to stop worrying about screen real estate and start worrying about your back, neck, hands and shoulders a bit more. Trust me, RSI is a serious thing.
</p>

<p>
<b>Designing UI:s is hard and application software can't please everyone all the time!</b><br>
This is true and, as a software developer of more than 20 years, I have a huge amount of respect for the complexity of UI design. I also happen to know that such complexity is not a valid excuse for willingly and knowingly breaking UI concepts that have been proven and working for, in some cases, more than four decades. In fact, a lot of the examples above introduce more complexity for the user to cope with. The intricacies of each application and window decoration must be learned separately and time and energy is spent by repeatedly parsing the differences.
</p>

<p>
<b>What about Apple?</b><br>
I can't comment on the current state of MacOS since the time I've spent actually using a Mac during the last 8 years or so probably totals to a few hours. Apple used to be good at this, and I hear they still do a decent job at keeping things sane, even post-Jobs.
</p>

<p>
<b>You're old and angry!</b><br>
You bet! Now get off my lawn, punk.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZF makes magnet-free electric motor uniquely compact and competitive (181 pts)]]></title>
            <link>https://press.zf.com/press/en/releases/release_60480.html</link>
            <guid>37453465</guid>
            <pubDate>Sun, 10 Sep 2023 06:41:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://press.zf.com/press/en/releases/release_60480.html">https://press.zf.com/press/en/releases/release_60480.html</a>, See on <a href="https://news.ycombinator.com/item?id=37453465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>This advanced variant of a separately excited synchronous motor is thus an alternative to permanent-magnet synchronous machines (PSM). The latter are currently the motors most frequently used in electric vehicles, but they are based on magnets which require rare earth materials for their production. With the I<sup>2</sup>SM, ZF is setting a new standard for making e-motors both extremely sustainable in production and highly powerful and efficient in operation.</p><p>“With this magnet-free e-motor without rare earth materials, we have another innovation with which we are consistently improving our electric drive portfolio to create even more sustainable, efficient and resource-saving mobility,” said Dr. Holger Klein, CEO of ZF. “This is our guiding principle for all new products. And we currently see no competitor that masters this technology as well as ZF.” Compared to common SESM systems, the inductive exciter can reduce losses for the energy transmission into the rotor by 15 percent. In addition, the CO<sub>2</sub> footprint in production, which arises with PSM e-motors in particular due to magnets including rare earth materials, can be reduced by up to 50 percent.</p><p>“This uniquely compact electric motor without magnets is impressive evidence of our strategy to make e-drives more resource-efficient and sustainable, primarily through efficiency improvements,” said Stephan von Schuckmann, Member of the Board of Management of the ZF Group.</p><p>In addition to the benefits of eliminating rare earth materials in a compact and powerful package, the I<sup>2</sup>SM eliminates the drag losses created in traditional PSM e-motors. This enables better efficiency at certain operating points such as long highway trips at high speed. </p><p><b>Advanced rotor design makes e-motor very compact</b></p><p>To ensure that the magnetic field in the rotor is built up by current instead of magnets, the conventional SESM concepts currently still require sliding or brush elements in most cases, which force compromises: A dry installation space, i.e. not accessible for oil cooling and with additional seals, is necessary. As a result, conventional SESMs take up around 90 mm more space axially. As a result, manufacturers generally cannot flexibly vary between PSM and SESM variants in their model planning without additional effort.</p><p>In order to offer the advantages of separately excited synchronous machines competitively, ZF has succeeded in compensating for the design-related disadvantages of common separately excited synchronous machines. In particular, the torque density has been significantly increased compared to the state of the art thanks to an innovative rotor design. The space-neutral integration of the exciter into the rotor means that there are no axial space disadvantages. In addition, an increase in power density in the rotor leads to an improvement in performance.</p><p><b>Inductive excitation as a key technology</b></p><p>The technological prerequisite for the ZF innovation is that energy is transferred inductively, i.e. without mechanical contact, into the rotor, generating a magnetic field by means of coils. Thus, the I<sup>2</sup>SM does not require any brush elements or slip rings. Furthermore, there is no longer any need to keep this area dry by means of seals. As with permanently magnetized synchronous motor, the rotor is efficiently cooled by circulating oil. Compared to common separately excited synchronous motor, the ZF innovation requires up to 90 millimeters less axial installation space. In terms of power and torque density, however, the ZF innovation operates at the level of a PSM.</p><p>ZF plans to develop the I<sup>2</sup>SM technology to production maturity and offer it as an option within its own e-drive platform. Customers from the passenger car and commercial vehicle segments can then choose between a variant with 400-volt architecture or with 800-volt architecture for their respective applications. The latter relies on silicon carbide chips in the power electronics.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Wrote a String Type (165 pts)]]></title>
            <link>https://mcyoung.xyz/2023/08/09/yarns/</link>
            <guid>37451913</guid>
            <pubDate>Sun, 10 Sep 2023 01:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mcyoung.xyz/2023/08/09/yarns/">https://mcyoung.xyz/2023/08/09/yarns/</a>, See on <a href="https://news.ycombinator.com/item?id=37451913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><span> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> </span> <span> 2023-08-09 </span> </span></p> <p>I write compilers for fun. I can’t help it. Consequently, I also write a lot of parsers. In systems programming, it’s usually a good idea to try to share memory rather than reuse it, so as such my AST types tend to look like this.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>enum</span> <span>Expr</span><span>&lt;</span><span>'src</span><span>&gt;</span> <span>{</span>
  <span>Int</span><span>(</span><span>u32</span><span>)</span>
  <span>Ident</span><span>(</span><span>&amp;</span><span>'src</span> <span>str</span><span>),</span>
  <span>// ...</span>
<span>}</span></code></pre></figure></div> <p>Whenever we parse an identifier, rather than copy its name into a fresh <code>String</code>, we borrow from the input source string. This avoids an extra allocation, an extra copy, and saves a word in the representation. Compilers can be memory-hungry, so it helps to pick a lean representation.</p> <p>Unfortunately, it’s not so easy for quoted strings. Most strings, like <code>"all my jelly babies"</code>, are “literally” in the original source, like an identifier. But strings with escapes aren’t: <code>\n</code> is encoded in the source code with the bytes <code>[0x5c, 0x6e]</code>, but the actual “decoded” value of a string literal replaces each escape with a single <code>0x0a</code>.</p> <p>The usual solution is a <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow&lt;str&gt;</code></a>. In the more common, escape-less verison, we can use <code>Cow::Borrowed</code>, which avoids the extra allocation and copy, and in the escaped version, we decode the escapes into a <code>String</code> and wrap it in a <code>Cow::Owned</code>.</p> <p>For example, suppose that we’re writing a parser for a language that has quoted strings with escapes. The string <code>"all my jelly babies"</code> can be represented as a byte string that borrows the input source code, so we’d use the <code>Cow::Borrowed</code> variant. This is most strings in any language: escapes tend to be rare.</p> <p>For example, if we have the string <code>"not UTF-8 \xff"</code>, the actual byte string value is different from that in the source code.</p> <div><figure><pre><code data-lang="text">// Bytes in the source.
hex:   6e 6f 74 20 55 54 46 2d 38 20 5c 78 66 66
ascii: n  o  t     U  T  F  -  8     \  x  f  f

// Bytes represented by the string.
hex:   6e 6f 74 20 55 54 46 2d 38 20 ff
ascii: n  o  t     U  T  F  -  8</code></pre></figure></div> <p>Escapes are relatively rare, so most strings processed by the parser do not need to pay for an allocation.</p> <p>However, we still pay for that extra word, since <code>Cow&lt;str&gt;</code> is 24 bytes (unless otherwise specified, all byte counts assume a 64-bit system), which is eight more than our <code>&amp;str</code>. Even worse, this is bigger than the string data itself, which is 11 bytes.</p> <p>If most of your strings are small (which is not uncommon in an AST parser), you will wind up paying for significant overhead.</p> <p>Over the years I’ve implemented various optimized string types to deal with this use-case, in various contexts. I finally got around to putting all of the tricks I know into a library, which I call <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code>byteyarn</code></a>. It advertises the following nice properties.</p> <blockquote> <p>A <code>Yarn</code> is a highly optimized string type that provides a number of useful properties over <code>String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code>Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code>'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>I’d like to share how these properties are achieved through careful layout optimization.</p> <h2 id="assumptions"><a href="#assumptions">Assumptions</a></h2> <p>We’re going to start by stating assumptions about how our strings will be used:</p> <ol> <li>Most strings are not mutated most of the time.</li> <li>Most strings are small.</li> <li>Most strings are substrings.</li> </ol> <h3 id="most-strings-are-immutable"><a href="#most-strings-are-immutable">Most Strings are Immutable</a></h3> <p><code>String</code> is modeled after C++’s <code>std::string</code>, which is a growable buffer that implements amortized linear-time append. This means that if we are appending <code>n</code> bytes to the buffer, we only pay for <code>n</code> bytes of <code>memcpy</code>.</p> <p>This is a useful but often unnecessary property. For example, Go strings are immutable, and when building up a large string, you are expected to use <code>strings.Builder</code>, which is implemented as essentially a Rust <code>String</code>. Java also as a similar story for strings, which allows for highly compact representations of <code>java.lang.String</code>s.</p> <p>In Rust, this kind of immutable string is represented by a <code>Box&lt;str&gt;</code>, which is eight bytes smaller than <code>String</code>. Converting from <code>String</code> to <code>Box&lt;str&gt;</code> is just a call to <code>realloc()</code> to resize the underlying allocation (which is often cheap<sup id="fnref:size-classes" role="doc-noteref"><a href="#fn:size-classes" rel="footnote">1</a></sup>) from being <code>capacity</code> bytes long to <code>len</code> bytes long.</p> <p>Thus, this assumption means we only need to store a pointer and a length, which puts our memory footprint floor at 16 bytes.</p> <h3 id="most-strings-are-substrings"><a href="#most-strings-are-substrings">Most Strings are Substrings</a></h3> <p>Suppose again that we’re parsing some textual format. Many structural elements will be verbatim references into the textual input. Not only string literals without escapes, but also identifiers.</p> <p><code>Box&lt;str&gt;</code> cannot hold borrowed data, because it will always instruct the allocator to free its pointer when it goes out of scope. <code>Cow&lt;str&gt;</code>, as we saw above, allows us to handle maybe-owned data uniformly, but has a minimum 24 byte overhead. This can’t be made any smaller, because a <code>Cow&lt;str&gt;</code> can contain a 24-byte <code>String</code> value.</p> <p>But, we don’t want to store a capacity. Can we avoid the extra word of overhead in <code>Cow&lt;str&gt;</code>?</p> <h3 id="most-strings-are-small"><a href="#most-strings-are-small">Most Strings are Small</a></h3> <p>Consider a string that is not a substring but which is small. For example, when parsing a string literal like <code>"Hello, world!\n"</code>, the trailing <code>\n</code> (bytes <code>0x5c 0x6e</code>) must be replaced with a newline byte (<code>0x0a</code>). This means we must handle a tiny heap allocation, 14 bytes long, that is smaller than a <code>&amp;str</code> referring to it.</p> <p>This is worse for single character<sup id="fnref:character" role="doc-noteref"><a href="#fn:character" rel="footnote">2</a></sup> strings. The overhead for a <code>Box&lt;str&gt;</code> is large.</p> <ul> <li>The <code>Box&lt;str&gt;</code> struct itself has a pointer field (eight bytes), and a length field (also eight bytes). Spelled out to show all the stored bits, the length is <code>0x0000_0000_0000_0001</code>. That’s a lot of zeroes!</li> <li>The pointer itself points to a heap allocation, which will not be a single byte! Allocators are not in the business of handing out such small pieces of memory. Instead, the allocation is likely costing us another eight bytes!</li> </ul> <p>So, the string <code>"a"</code>, whose data is just a <em>single byte</em>, instead takes up 24 bytes of memory.</p> <p>It turns out that for really small strings we can avoid the allocation altogether, <em>and</em> make effective use of all those zeroes in the <code>len</code> field.</p> <h2 id="stealing-bits"><a href="#stealing-bits">Stealing Bits</a></h2> <p>Let’s say we want to stick to a budget of 16 bytes for our <code>Yarn</code> type. Is there any extra space left for data in a <code>(*mut u8, usize)</code> pair?</p> <p><em>*cracks Fermi estimation knuckles*</em></p> <p>A <code>usize</code> is 64 bits, which means that the length of an <code>&amp;str</code> can be anywhere from zero to 18446744073709551615, or around 18 exabytes. For reference, “hundreds of exabytes” is a reasonable ballpark guess for how much RAM exists in 2023 (consider: 4 billion smartphones with 4GB each). More practically, the largest quantity of RAM you can fit in a server blade is measured in terabytes (much more than your measly eight DIMs on your gaming rig).</p> <p>If we instead use one less bit, 63 bits, this halves the maximum representable memory to nine exabytes. If we take another, it’s now four exabytes. Much more memory than you will ever <em>ever</em> want to stick in a string. <a href="https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database">Wikpedia asserts</a> that Wikimedia Commons contains around 428 terabytes of media (the articles’ text with history is a measly 10 TB).</p> <p>Ah, but you say you’re programming for a 32-bit machine (today, this likely means either a low-end mobile phone, an embedded micro controller, or WASM).</p> <p>On a 32-bit machine it’s a little bit harrier: Now <code>usize</code> is 32 bits, for a maximum string size of 4 gigabytes (if you remember the 32-bit era, this limit may sound familiar). “Gigabytes” is an amount of memory that you can actually imagine having in a string.</p> <p>Even then, 1 GB of memory (if we steal two bits) on a 32-bit machine is a lot of data. You can only have four strings that big in a single address space, and every 32-bit allocator in the universe will refuse to serve an allocation of that size. If your strings are comparable in size to the whole address space, you should build your own string type.</p> <p>The upshot is that every <code>&amp;str</code> contains two bits we can reasonably assume are not used. <em>Free real-estate.</em><sup id="fnref:isize" role="doc-noteref"><a href="#fn:isize" rel="footnote">3</a></sup></p> <h3 id="a-hand-written-niche-optimization"><a href="#a-hand-written-niche-optimization">A Hand-Written Niche Optimization</a></h3> <p>Rust has the concept of <em>niches</em>, or invalid bit-patterns of a particular type, which it uses for automatic layout optimization of <code>enum</code>s. For example, references cannot be null, so the pointer bit-pattern of <code>0x0000_0000_0000_0000</code> is never used; this bit-pattern is called a “niche”. Consider:</p> <div><figure><pre><code data-lang="rust"><span>enum</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>First</span><span>(</span><span>&amp;</span><span>'a</span> <span>T</span><span>),</span>
  <span>Second</span>
<span>}</span></code></pre></figure></div> <p>An <code>enum</code> of this form will not need any “extra” space to store the value that discriminates between the two variants: if a <code>Foo</code>’s bits are all zero, it’s <code>Foo::Second</code>; otherwise it’s a <code>Foo::First</code> and the payload is formed from <code>Foo</code>’s bit-pattern. This, incidentally, is what makes <code>Option&lt;&amp;T&gt;</code> a valid representation for a “nullable pinter”.</p> <p>There are more general forms of this: <code>bool</code> is represented as a single byte, of which two bit are valid; the other 254 potential bit-patterns are niches. In Recent versions of Rust, <code>RawFd</code> has a niche for the all-ones bit-pattern, since POSIX file descriptors are always non-negative <code>int</code>s.</p> <p>By stealing two bits off of the length, we have given ourselves four niches, which essentially means we’ll have a hand-written version of something like this <code>enum</code>.</p> <div><figure><pre><code data-lang="rust"><span>enum</span> <span>Yarn</span> <span>{</span>
  <span>First</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Second</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Third</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
  <span>Fourth</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>u62</span><span>),</span>
<span>}</span></code></pre></figure></div> <p>For reasons that will become clear later, we will specifically steal the <em>high</em> bits of the length, so that to recover the length, we do two shifts<sup id="fnref:two-shifts" role="doc-noteref"><a href="#fn:two-shifts" rel="footnote">4</a></sup> to shift in two high zero bits. Here’s some code that actually implements this for the low level type our string type will be built on.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>,</span>
  <span>len</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a length, and a pointer.</span>
  <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>,</span>
      <span>len</span><span>:</span> <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the kind back out.</span>
  <span>fn</span> <span>kind</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>u8</span> <span>{</span>
    <span>(</span><span>self</span><span>.len</span> <span>&gt;&gt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>))</span> <span>as</span> <span>u8</span>
  <span>}</span>

  <span>/// Extracts the slice out (regardless of kind).</span>
  <span>unsafe</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span> <span>{</span>
    <span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>self</span><span>.ptr</span><span>,</span> <span>(</span><span>self</span><span>.len</span> <span>&lt;&lt;</span> <span>2</span><span>)</span> <span>&gt;&gt;</span> <span>2</span><span>)</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>Note that I’ve made this type <code>Copy</code>, and some functions take it by value. This is for two reasons.</p> <ol> <li> <p>There is a type of <code>Yarn</code> that is itself <code>Copy</code>, although I’m not covering it in this article.</p> </li> <li> <p>It is a two-word struct, which means that on most architectures it is eligible to be passed in a pair of registers. Passing it by value in the low-level code helps promote keeping it in registers. This isn’t always possible, as we will see when we discuss “SSO”.</p> </li> </ol> <p>Let’s chose kind <code>0</code> to mean “this is borrowed data”, and kind <code>1</code> to be “this is heap-allocated data”. We can use this to remember whether we need to call a destructor.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>struct</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>raw</span><span>:</span> <span>RawYarn</span><span>,</span>
  <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>&lt;&amp;</span><span>'a</span> <span>str</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>const</span> <span>BORROWED</span><span>:</span> <span>u8</span> <span>=</span> <span>0</span><span>;</span>
<span>const</span> <span>HEAP</span><span>:</span> <span>u8</span> <span>=</span> <span>1</span><span>;</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>borrowed</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'a</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>BORROWED</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Create a new yarn from owned data.</span>
  <span>pub</span> <span>fn</span> <span>owned</span><span>(</span><span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>HEAP</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the data.</span>
  <span>pub</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>str</span> <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>// SAFETY: initialized either from uniquely-owned data,</span>
      <span>// or borrowed data of lifetime 'a that outlives self.</span>
      <span>str</span><span>::</span><span>from_utf8</span><span>(</span><span>self</span><span>.as_slice</span><span>())</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>impl</span> <span>Drop</span> <span>for</span> <span>Yarn</span><span>&lt;</span><span>'_</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>drop</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>{</span>
    <span>if</span> <span>self</span><span>.raw</span><span>.kind</span><span>()</span> <span>==</span> <span>HEAP</span> <span>{</span>
      <span>let</span> <span>dropped</span> <span>=</span> <span>unsafe</span> <span>{</span>
        <span>// SAFETY: This is just reconstituting the box we dismantled</span>
        <span>// in Yarn::owned().</span>
        <span>Box</span><span>::</span><span>from_raw</span><span>(</span><span>self</span><span>.as_slice</span><span>())</span>
      <span>};</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This gives us a type that strongly resembles <code>Cow&lt;str&gt;</code> with only half of the bytes. We can even write code to extend the lifetime of a <code>Yarn</code>:</p> <div><figure><pre><code data-lang="rust"><span>impl</span> <span>Yarn</span><span>&lt;</span><span>'_</span><span>&gt;</span> <span>{</span>
  <span>/// Removes the bound lifetime from the yarn, allocating if</span>
  <span>/// necessary.</span>
  <span>pub</span> <span>fn</span> <span>immortalize</span><span>(</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Yarn</span><span>&lt;</span><span>'static</span><span>&gt;</span> <span>{</span>
    <span>if</span> <span>self</span><span>.raw</span><span>.kind</span><span>()</span> <span>==</span> <span>BORROWED</span> <span>{</span>
      <span>let</span> <span>copy</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span> <span>=</span> <span>self</span><span>.as_slice</span><span>()</span><span>.into</span><span>();</span>
      <span>self</span> <span>=</span> <span>Yarn</span><span>::</span><span>owned</span><span>(</span><span>copy</span><span>);</span>
    <span>}</span>

    <span>// We need to be careful that we discard the old yarn, since its</span>
    <span>// destructor may run and delete the heap allocation we created</span>
    <span>// above.</span>
    <span>let</span> <span>raw</span> <span>=</span> <span>self</span><span>.raw</span><span>;</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>self</span><span>);</span>
    <span>Yarn</span><span>::</span><span>&lt;</span><span>'static</span><span>&gt;</span> <span>{</span>
      <span>raw</span><span>,</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The remaining two niches can be put to use for optimizing small strings.</p> <h2 id="small-string-optimization"><a href="#small-string-optimization">Small String Optimization</a></h2> <p>C++’s <code>std::string</code> also makes the “most strings are small” assumption. In the <code>libc++</code> implementation of the standard library, <code>std::string</code>s of up to 23 bytes never hit the heap!</p> <p>C++ implementations do this by using most of the pointer, length, and capacity fields as a storage buffer for small strings, the so-called “small string optimization” (SSO). In <code>libc++</code>, in SSO mode, a <code>std::string</code>’s length fits in one byte, so the other 23 bytes can be used as storage. The capacity isn’t stored at all: an SSO string always has a capacity of 23.</p> <p><code>RawYarn</code> still has another two niches, so let’s dedicate one to a “small” representation. In small mode, the kind will be 2, and only the 16th byte will be the length.</p> <p>This is why we used the two <em>high</em> bits of <code>len</code> for our scratch space: no matter what mode it’s in, we can easily extract these bits<sup id="fnref:big-endian" role="doc-noteref"><a href="#fn:big-endian" rel="footnote">5</a></sup>. Some of the existing <code>RawYarn</code> methods need to be updated, though.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>&lt;*</span><span>mut</span> <span>u8</span><span>&gt;</span><span>,</span>
  <span>len</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>const</span> <span>SMALL</span><span>:</span> <span>u8</span> <span>=</span> <span>2</span><span>;</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a length, and a pointer.</span>
  <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>kind</span> <span>!=</span> <span>SMALL</span><span>);</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>new</span><span>(</span><span>ptr</span><span>),</span>
      <span>len</span><span>:</span> <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Extracts the slice out (regardless of kind).</span>
  <span>unsafe</span> <span>fn</span> <span>as_slice</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span> <span>{</span>
    <span>let</span> <span>(</span><span>ptr</span><span>,</span> <span>adjust</span><span>)</span> <span>=</span> <span>match</span> <span>self</span><span>.kind</span><span>()</span> <span>{</span>
      <span>SMALL</span> <span>=&gt;</span> <span>(</span><span>self</span> <span>as</span> <span>*</span><span>const</span> <span>Self</span> <span>as</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>8</span><span>),</span>
      <span>_</span> <span>=&gt;</span> <span>(</span><span>self</span><span>.ptr</span><span>.assume_init</span><span>(),</span> <span>0</span><span>),</span>
    <span>};</span>

    <span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ptr</span><span>,</span> <span>(</span><span>self</span><span>.len</span> <span>&lt;&lt;</span> <span>2</span><span>)</span> <span>&gt;&gt;</span> <span>(</span><span>2</span> <span>+</span> <span>adjust</span><span>))</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>In the non-<code>SMALL</code> case, we shift twice as before, but in the <code>SMALL</code> case, we need to get the high byte of the <code>len</code> field, so we need to shift down by an additional <code>usize::BITS - 8</code>. No matter what we’ve scribbled on the low bytes of <code>len</code>, we will always get just the length this way.</p> <p>We also need to use a different pointer value depending on whether we’re in <code>SMALL</code> mode. This is why <code>as_slice</code> needs to take a reference argument, since the slice data may be <em>directly</em> in <code>self</code>!</p> <p>Also, <code>ptr</code> is a <code>MaybeUninit</code> now, which will become clear in the next code listing.</p> <p>We should also provide a way to construct small strings.</p> <div><figure><pre><code data-lang="rust"><span>const</span> <span>SSO_LEN</span><span>:</span> <span>usize</span> <span>=</span> <span>size_of</span><span>::</span><span>&lt;</span><span>usize</span><span>&gt;</span><span>()</span> <span>*</span> <span>2</span> <span>-</span> <span>1</span><span>;</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Create a new small yarn. `data` must be valid for `len` bytes</span>
  <span>/// and `len` must be smaller than `SSO_LEN`.</span>
  <span>unsafe</span> <span>fn</span> <span>from_small</span><span>(</span><span>data</span><span>:</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>RawYarn</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>SSO_LEN</span><span>);</span>

    <span>// Create a yarn with an uninitialized pointer value (!!)</span>
    <span>// and a length whose high byte is packed with `small` and</span>
    <span>// `len`.</span>
    <span>let</span> <span>mut</span> <span>yarn</span> <span>=</span> <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>uninit</span><span>(),</span>
      <span>len</span><span>:</span> <span>(</span><span>SMALL</span> <span>as</span> <span>usize</span> <span>&lt;&lt;</span> <span>6</span> <span>|</span> <span>len</span><span>)</span>
          <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>8</span><span>),</span>
    <span>};</span>

    <span>// Memcpy the data to the new yarn.</span>
    <span>// We write directly onto the `yarn` variable. We won't</span>
    <span>// overwrite the high-byte length because `len` will</span>
    <span>// never be &gt;= 16.</span>
    <span>ptr</span><span>::</span><span>copy_nonoverlapping</span><span>(</span>
      <span>data</span><span>,</span>
      <span>&amp;</span><span>mut</span> <span>yarn</span> <span>as</span> <span>*</span><span>mut</span> <span>RawYarn</span> <span>as</span> <span>*</span><span>mut</span> <span>u8</span><span>,</span>
      <span>data</span><span>,</span>
    <span>);</span>

    <span>yarn</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The precise maximum size of an SSO string is a bit more subtle than what’s given above, but it captures the spirit. The <code>RawYarn::from_small</code> illustrates why the pointer value is hidden in a <code>MaybeUninit</code>: we’re above to overwrite it with garbage, and in that case it won’t be a pointer at all.</p> <p>We can update our public <code>Yarn</code> type to use the new small representation whenever possible.</p> <div><figure><pre><code data-lang="rust"><span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>borrowed</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'a</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>

    <span>if</span> <span>len</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>BORROWED</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>

  <span>/// Create a new yarn from owned data.</span>
  <span>pub</span> <span>fn</span> <span>owned</span><span>(</span><span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>str</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>if</span> <span>data</span><span>.len</span><span>()</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>data</span><span>.len</span><span>(),</span> <span>data</span><span>.as_ptr</span><span>())</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>
    <span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>HEAP</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>It’s also possible to construct a <code>Yarn</code> directly from a character now, too!</p> <div><figure><pre><code data-lang="rust"><span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>from_char</span><span>(</span><span>data</span><span>:</span> <span>char</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>buf</span> <span>=</span> <span>[</span><span>0u8</span><span>;</span> <span>4</span><span>];</span>
    <span>let</span> <span>data</span> <span>=</span> <span>data</span><span>.encode_utf8</span><span>(</span><span>&amp;</span><span>mut</span> <span>buf</span><span>);</span>
    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>(Note that we do not need to update <code>Yarn::immortalize()</code>; why?)</p> <p>What we have now is a maybe-owned string that does not require an allocation for small strings. However, we still have an extra niche…</p> <h2 id="string-constants"><a href="#string-constants">String Constants</a></h2> <p>String constants in Rust are interesting, because we can actually detect them at compile-time<sup id="fnref:leaks" role="doc-noteref"><a href="#fn:leaks" rel="footnote">6</a></sup>.</p> <p>We can use the last remaining niche, 3, to represent data that came from a string constant, which means that it does not need to be boxed to be immortalized.</p> <div><figure><pre><code data-lang="rust"><span>const</span> <span>STATIC</span><span>:</span> <span>u8</span> <span>=</span> <span>3</span><span>;</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>Yarn</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span>
  <span>/// Create a new yarn from borrowed data.</span>
  <span>pub</span> <span>fn</span> <span>from_static</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>'static</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>data</span><span>.len</span><span>();</span>
    <span>let</span> <span>ptr</span> <span>=</span> <span>data</span><span>.as_ptr</span><span>()</span><span>.cast_mut</span><span>();</span>

    <span>if</span> <span>len</span> <span>&lt;=</span> <span>SSO_LEN</span> <span>{</span>
      <span>return</span> <span>Self</span> <span>{</span>
        <span>raw</span><span>:</span> <span>unsafe</span> <span>{</span> <span>RawYarn</span><span>::</span><span>from_small</span><span>(</span><span>len</span><span>,</span> <span>ptr</span><span>)</span> <span>},</span>
        <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
      <span>}</span>
    <span>}</span>

    <span>Self</span> <span>{</span>
      <span>raw</span><span>:</span> <span>RawYarn</span><span>::</span><span>from_raw_parts</span><span>(</span><span>STATIC</span><span>,</span> <span>len</span><span>,</span> <span>ptr</span><span>),</span>
      <span>_</span><span>ph</span><span>:</span> <span>PhantomData</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This function is identical to <code>Yarn::borrowed</code>, except that <code>data</code> most now have a static lifetime, and we pass <code>STATIC</code> to <code>RawYarn::from_raw_parts()</code>.</p> <p>Because of how we’ve written all of the prior code, this does not require any special support in <code>Yarn::immortalize()</code> or in the low-level <code>RawYarn</code> code.</p> <p>The actual <code>byteyarn</code> library provides a <code>yarn!()</code> macro that has the same syntax as <code>format!()</code>. This is the primary way in which yarns are created. It is has been carefully written so that <code>yarn!("this is a literal")</code> always produces a <code>STATIC</code> string, rather than a heap-allocated string.</p>  <p>Unfortunately, because of how we’ve written it, <code>Option&lt;Yarn&gt;</code> is 24 bytes, a whole word larger than a <code>Yarn</code>. However, there’s still a little gap where we can fit the <code>None</code> variant. It turns out that because of how we’ve chosen the discriminants, <code>len</code> is zero if and only if it is an empty <code>BORROWED</code> string. But this is not the only zero: if the high byte is <code>0x80</code>, this is an empty <code>SMALL</code> string. If we simply require that no other empty string is ever constructed (by marking <code>RawYarn::from_raw_parts()</code> as unsafe and specifying it should not be passed a length of zero), we can guarantee that <code>len</code> is <em>never</em> zero.</p> <p>Thus, we can update <code>len</code> to be a <code>NonZeroUsize</code>.</p> <div><figure><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>#[derive(Copy,</span> <span>Clone)]</span>
<span>struct</span> <span>RawYarn</span> <span>{</span>
  <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>&lt;*</span><span>mut</span> <span>u8</span><span>&gt;</span><span>,</span>
  <span>len</span><span>:</span> <span>NonZeroUsize</span><span>,</span>  <span>// (!!)</span>
<span>}</span>

<span>impl</span> <span>RawYarn</span> <span>{</span>
  <span>/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span>/// a *nonzero* length, and a pointer.</span>
  <span>unsafe</span> <span>fn</span> <span>from_raw_parts</span><span>(</span><span>kind</span><span>:</span> <span>u8</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>,</span> <span>ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>)</span> <span>{</span>
    <span>debug_assert!</span><span>(</span><span>kind</span> <span>!=</span> <span>SMALL</span><span>);</span>
    <span>debug_assert!</span><span>(</span><span>len</span> <span>!=</span> <span>0</span><span>);</span>
    <span>assert</span><span>!</span><span>(</span><span>len</span> <span>&lt;=</span> <span>usize</span><span>::</span><span>MAX</span> <span>/</span> <span>4</span><span>,</span> <span>"no way you have a string that big"</span><span>);</span>

    <span>RawYarn</span> <span>{</span>
      <span>ptr</span><span>:</span> <span>MaybeUninit</span><span>::</span><span>new</span><span>(</span><span>ptr</span><span>),</span>
      <span>len</span><span>:</span> <span>NonZeroUsize</span><span>::</span><span>new_unchecked</span><span>(</span>
        <span>(</span><span>kind</span> <span>as</span> <span>usize</span> <span>&amp;</span> <span>0b11</span><span>)</span> <span>&lt;&lt;</span> <span>(</span><span>usize</span><span>::</span><span>BITS</span> <span>-</span> <span>2</span><span>)</span> <span>|</span> <span>len</span><span>),</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>This is a type especially known to the Rust compiler to have a niche bit-pattern of all zeros, which allows <code>Option&lt;Yarn&gt;</code> to be 16 bytes too. This also has the convenient property that the all zeros bit-pattern for <code>Option&lt;Yarn&gt;</code> is <code>None</code>.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>The <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code>byteyarn</code></a> blurb describes what we’ve built:</p> <blockquote> <p>A <code>Yarn</code> is a highly optimized string type that provides a number of useful properties over <code>String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code>Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code>'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>There are, of course, some trade-offs. Not only do we need the assumptions we made originally to hold, but we also need to relatively care more about memory than cycle-count performance, since basic operations like reading the length of the string require more math (but no extra branching).</p> <p>The actual implementation of <code>Yarn</code> is a bit more complicated, partly to keep all of the low-level book-keeping in one place, and partly to offer an ergonomic API that makes <code>Yarn</code> into a mostly-drop-in replacement for <code>Box&lt;str&gt;</code>.</p> <p>I hope this peek under the hood has given you a new appreciation for what can be achieved by clever layout-hacking. ◼</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coffee in a Can (278 pts)]]></title>
            <link>https://one-from-nippon.ghost.io/coffee-in-a-can/</link>
            <guid>37451728</guid>
            <pubDate>Sun, 10 Sep 2023 00:30:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://one-from-nippon.ghost.io/coffee-in-a-can/">https://one-from-nippon.ghost.io/coffee-in-a-can/</a>, See on <a href="https://news.ycombinator.com/item?id=37451728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Life’s inconveniences, when they happen to you and me, are just that. Inconveniences.</p>
<p>When they happen to some people though they end up becoming multi-billion dollar businesses.</p>
<p>This is the story of Japan’s canned coffee.</p>
<hr>
<p>One finds at least one vending machine in almost every street in Japan. In every vending machine one row is dedicated to just one product: canned coffee.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/6158690399_cea99906b1_k.jpg" alt="" loading="lazy" width="2000" height="1500" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/6158690399_cea99906b1_k.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/6158690399_cea99906b1_k.jpg 1000w, https://one-from-nippon.ghost.io/content/images/size/w1600/2023/09/6158690399_cea99906b1_k.jpg 1600w, https://one-from-nippon.ghost.io/content/images/2023/09/6158690399_cea99906b1_k.jpg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>The bottom row on this vending machine is all coffee. Blue buttons are cold coffee and red ones are hot </span><i><em>Source: </em></i><a href="https://flic.kr/p/aodU6e?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Kevin Dooley</em></i></a></figcaption></figure>
<p>Canned coffee, as it says on the tin, is ready-to-drink coffee in a can.</p>
<p>There are hundreds of variations of canned coffee and some can’t even legally be called “coffee” in Japan.</p>
<h2 id="inconveniences-and-thrifty-entrepreneurs">Inconveniences and thrifty entrepreneurs</h2>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/20200221_154959629--2-.jpg" alt="" loading="lazy" width="1600" height="900" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/20200221_154959629--2-.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/20200221_154959629--2-.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/20200221_154959629--2-.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Bottled milk coffee </span><i><em>Source: </em></i><a href="https://chemlover-musician.blogspot.com/?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>こやまうんてん</em></i></a></figcaption></figure>
<p>The year was 1969. Tadao Ueshima was at the train station.</p>
<p>In the sweltering heat of the Japanese summer he got himself a bottle of cold “coffee milk” (コーヒー牛乳) from the station’s convenience store, figuring he had a few minutes till the train left.</p>
<p>In those days you would buy your drink, drink it on the spot, and return the bottle. As luck would have it, he mistimed his coffee and his train started to pull out of the station. He hurriedly returned his half-finished bottle and ran to his train.</p>
<p>Now, Tadao had somewhat of a reputation as a frugal man. He hated seeing things go to waste. And he couldn’t shake off the frustration of the coffee. “If only there was a way I could buy and carry my coffee with me…” he reasoned.</p>
<p>Fate couldn’t have chosen a better person for this encounter.</p>
<p>Tadao Ueshima was the CEO of UCC Coffee, which sold coffee and tea in bulk to restaurants. He assembled a team at UCC and gave them an impossible mission: to create a coffee he could buy and walk away with.</p>
<p>Such a thing was unheard of.</p>
<p>The team quickly landed on using steel cans for the coffee. This way people could buy coffee anywhere there was a vending machine. This was probably the easy part.</p>
<p>After all, how hard could it be to make canned coffee? You make coffee, pour it into a can, and seal it, right?</p>
<p>That is what the team started with, but they ran into one problem after the other: the coffee and milk would separate when they left the can sit; the coffee reacted with the steel can and turned into an unappetizing black liquid; the coffee tasted weird when they sterilized the sealed cans.</p>
<p>One by one, they experimented their way out of these problems and finally in April 1969 their first mass-produced canned coffee was ready.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/12638279044_822fc073f1_k-2.jpg" alt="" loading="lazy" width="377" height="700"><figcaption><span>UCC Canned Milk Coffee </span><i><em>Source: </em></i><a href="https://flic.kr/p/kfNu3Q?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Like_the_Grand_Canyon</em></i></a></figcaption></figure>
<p>Remember I said this thing was unheard of? Well, their buyers hadn’t heard of it either and had zero faith that people would want to drink coffee out of a steel can instead of choosing a nice, cold bottle of coffee.</p>
<p>Some people even called it blasphemy to stuff coffee in a can. (<em>Yes, I know many of you think adding milk and sugar to coffee is blasphemy already.</em>)</p>
<p>UCC’s employees went store by store, opening the cold canned coffee and inviting owners to try it for themselves. But it did not move the needle much.</p>
<p>They then changed strategy and focused on the <a href="https://en.wikipedia.org/wiki/Expo_%2770?ref=one-from-nippon.ghost.io" rel="noreferrer">1970 Osaka World Fair</a>, where companies from across the world came to showcase the latest and greatest from their countries. This was a massive, 6-month long event, which over 64 million people attended.</p>
<p>UCC targeted the restaurants and shops around the 330-hectare venue and this is where they got their first taste of success. In just a few weeks, people were clamoring for the cold milk coffee to quench them in the heat of the Japanese summer.</p>
<p>This newfound recognition from the World Fair catapulted UCC and in just one year, their revenues exceeded 10 billion yen.</p>
<h2 id="%E2%80%9Creal%E2%80%9D-canned-coffee">“Real” Canned Coffee</h2>
<p>While UCC was busy taking over the world, there existed people who couldn’t take  “coffee milk” seriously. One such people was Toshikage Tanida, the CEO of a company called Pokka Lemon that made synthetic lemon juice.</p>
<p>In 1972, Toshikage stopped at a service area on the highway after a long drive and wanted a cup of coffee to freshen up. There was a long line at the service area's only coffee shop and it took him 30 minutes to get his coffee.</p>
<p>You and I would have grumbled and moved on. But not Toshikage.</p>
<p>The experience annoyed him so much that he set about looking for a way to have <em>real</em> canned coffee. Pure coffee, unadulterated by sugar and milk. <em>Hot</em> coffee.</p>
<p>By 1972 vending machines were the main channel of selling canned coffee, but most vending machines only had one mode: cold. Pokka collaborated with a vending machine manufacturer to build a “hot-and-cold” vending machine which could sell both hot and cold beverages simultaneously.</p>
<p>It took them a year to build this, but in 1973, Pokka could legitimately lay claim to creating the first canned hot <em>actually-coffee</em> coffee.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/2804520553_90a6cdc92f_k.jpg" alt="" loading="lazy" width="1536" height="2048" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/2804520553_90a6cdc92f_k.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/2804520553_90a6cdc92f_k.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/2804520553_90a6cdc92f_k.jpg 1536w" sizes="(min-width: 720px) 720px"><figcaption><span>Pokka Aromax sugarless coffee </span><i><em>Source: </em></i><a href="https://flic.kr/p/5gPUfD?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>David Pursehouse</em></i></a></figcaption></figure>
<p>I am drinking a freshly brewed cup of coffee as I write this, and I can only imagine how much of thought, work, and failed experiments went into canning something as sensitive as coffee.</p>
<p>Especially so, when you realize this coffee is heated constantly, for an indefinite amount of time in a vending machine, and <em>still</em> tastes the way it was supposed to taste! Mad respect for the people who pulled this off.</p>
<figure><img src="https://one-from-nippon.ghost.io/content/images/2023/09/13973225107_ea2056fb4d_h.jpg" alt="" loading="lazy" width="1600" height="1067" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2023/09/13973225107_ea2056fb4d_h.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2023/09/13973225107_ea2056fb4d_h.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2023/09/13973225107_ea2056fb4d_h.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Translation: "Actually, this was canned coffee. Georgia European". Seen at a coffee workshop. </span><i><em>Source: </em></i><a href="https://flic.kr/p/nhLr1g?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Hideya HAMANO</em></i></a></figcaption></figure>
<h2 id="enter-coca-cola-and-tommy-lee-jones">Enter Coca Cola and Tommy Lee Jones</h2>
<p>Most canned coffee was sold through vending machines and thanks to Pokka, Japan now had hot-and-cold vending machines. Guess who had more vending machines than everyone else in Japan? Coca Cola.</p>
<p>In 1975 Coca Cola entered the game with their “Georgia” canned coffee, named after the home state of the Coca Cola Corporation. Coca Cola’s sheer brand might and vending machine network gave it meteoric growth. So meteoric, that to this day, Coca Cola Japan’s best selling product is not Coca Cola. It’s Georgia coffee!</p>
<p>Suntory, another beverage maker jumped into the fray and took the world by storm with their brilliant advertising campaign.</p>
<p>They called their coffee “BOSS” and hired Tommy Lee Jones to be the face of the brand. Tommy was cast as an alien exploring earth, trying to understand the life of everyday humans.</p>
<p>Suntory wanted to paint BOSS as a coffee for the hardworking people on the street and with their ad campaign they succeeded <em>spectacularly</em>. Watch with the subtitles turned on and I think you will see why.</p>
<figure><iframe width="200" height="113" src="https://www.youtube.com/embed/videoseries?list=PL4F3C1016A2216AB3" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></figure>
<hr>
<p>The success of canned coffee rests on two pillars – cans and vending machines. How these coffee cans are made is a <a href="http://www.chymist.com/Aluminum%20can.pdf?ref=one-from-nippon.ghost.io" rel="noreferrer">rabbit hole</a> of its own if you’re into the sheet metal forming kind of thing. The vending machines too deserve a whole other article of their own. In fact, if you think we should write about Japanese vending machines next, comment down below!</p>
<p>To the people still shaking your head that coffee in a can can’t <em>possibly</em> be good, it can. </p>
<p>I will leave you with this video of a guy who flew to Italy and recorded the reactions of strangers (including a pair of baristas) drinking canned coffee:</p>
<figure><iframe width="200" height="113" src="https://www.youtube.com/embed/LjpMEu_IHKo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="「日本の缶コーヒー」をカフェの本場・イタリアの人たちが飲んだらこうなった"></iframe></figure>
<hr>

<p>

We hope you enjoyed this article! If you haven't already, we would love it if you subscribed to our newsletter. It would encourage us <b>greatly</b> to create more interesting posts like this. Sign up from <a href="https://one-from-nippon.ghost.io/">here</a>.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[School of SRE: Curriculum for onboarding non-traditional hires and new grads (155 pts)]]></title>
            <link>https://github.com/linkedin/school-of-sre</link>
            <guid>37451715</guid>
            <pubDate>Sun, 10 Sep 2023 00:27:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/linkedin/school-of-sre">https://github.com/linkedin/school-of-sre</a>, See on <a href="https://news.ycombinator.com/item?id=37451715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">School of SRE</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/linkedin/school-of-sre/blob/main/img/sos.png"><img src="https://github.com/linkedin/school-of-sre/raw/main/img/sos.png" width="200"></a></p>
<p dir="auto">Site Reliability Engineers (SREs)  sits at the intersection of software engineering and systems engineering. While there are potentially infinite permutations and combinations of how infrastructure and software components can be put together to achieve an objective, focusing on foundational skills allows SREs to work with complex systems and software, regardless of whether these systems are proprietary, 3rd party, open systems, run on cloud/on-prem infrastructure, etc. Particularly important is to gain a deep understanding of how these areas of systems and infrastructure relate to each other and interact with each other. The combination of software and systems engineering skills is rare and is generally built over time with exposure to a wide variety of infrastructure, systems, and software.</p>
<p dir="auto">SREs bring in engineering practices to keep the site up. Each distributed system is an agglomeration of many components. SREs validate business requirements, convert them to SLAs for each of the components that constitute the distributed system, monitor and measure adherence to SLAs, re-architect or scale out to mitigate or avoid SLA breaches, add these learnings as feedback to new systems or projects and thereby reduce operational toil. Hence SREs play a vital role right from the day 0 design of the system.</p>
<p dir="auto">In early 2019, we started visiting campuses across India to recruit the best and brightest minds to make sure LinkedIn, and all the services that make up its complex technology stack are always available for everyone. This critical function at LinkedIn falls under the purview of the Site Engineering team and Site Reliability Engineers (SREs) who are Software Engineers, specialized in reliability.</p>
<p dir="auto">As we continued on this journey we started getting a lot of questions from these campuses on what exactly the site reliability engineering role entails? And, how could someone learn the skills and the disciplines involved to become a successful site reliability engineer? Fast forward a few months, and a few of these campus students had joined LinkedIn either as interns or as full-time engineers to become a part of the Site Engineering team; we also had a few lateral hires who joined our organization who were not from a traditional SRE background. That's when a few of us got together and started to think about how we can onboard new graduate engineers to the Site Engineering team.</p>
<p dir="auto">There are very few resources out there guiding someone on the basic skill sets one has to acquire as a beginner SRE. Because of the lack of these resources, we felt that individuals have a tough time getting into open positions in the industry. We created the School Of SRE as a starting point for anyone wanting to build their career as an SRE.
In this course, we are focusing on building strong foundational skills. The course is structured in a way to provide more real life examples and how learning each of these topics can play an important role in day to day job responsibilities of an SRE. Currently we are covering the following topics under the School Of SRE:</p>
<ul dir="auto">
<li>
<p dir="auto">Level 101</p>
<ul dir="auto">
<li>Fundamentals Series
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level101/linux_basics/intro/" rel="nofollow">Linux Basics</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/git/git-basics/" rel="nofollow">Git</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/linux_networking/intro/" rel="nofollow">Linux Networking</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/python_web/intro/" rel="nofollow">Python and Web</a></li>
<li>Data
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level101/databases_sql/intro/" rel="nofollow">Relational databases(MySQL)</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/databases_nosql/intro/" rel="nofollow">NoSQL concepts</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/big_data/intro/" rel="nofollow">Big Data</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/systems_design/intro/" rel="nofollow">Systems Design</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/" rel="nofollow">Metrics and Monitoring</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level101/security/intro/" rel="nofollow">Security</a></li>
</ul>
</li>
<li>
<p dir="auto">Level 102</p>
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level102/linux_intermediate/introduction/" rel="nofollow">Linux Intermediate</a></li>
<li>Linux Advanced
<ul dir="auto">
<li><a href="https://linkedin.github.io/school-of-sre/level102/containerization_and_orchestration/intro/" rel="nofollow">Containers and orchestration</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_calls_and_signals/intro/" rel="nofollow">System Calls and Signals</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/networking/introduction/" rel="nofollow">Networking</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_design/intro/" rel="nofollow">System Design</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/system_troubleshooting_and_performance/introduction/" rel="nofollow">System troubleshooting and performance improvements</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/level102/continuous_integration_and_continuous_delivery/introduction/" rel="nofollow">Continuous Integration and Continuous Delivery</a></li>
</ul>
</li>
</ul>
<p dir="auto">We believe continuous learning will help in acquiring deeper knowledge and competencies in order to expand your skill sets, every module has added references that could be a guide for further learning. Our hope is that by going through these modules we should be able to build the essential skills required for a Site Reliability Engineer.</p>
<p dir="auto">At LinkedIn, we are using this curriculum for onboarding our non-traditional hires and new college grads into the SRE role. We had multiple rounds of successful onboarding experiences with new employees and the course helped them be productive in a very short period of time. This motivated us to open source the content for helping other organizations in onboarding new engineers into the role and provide guidance for aspiring individuals to get into the role. We realize that the initial content we created is just a starting point and we hope that the community can help in the journey of refining and expanding the content. Check out <a href="https://github.com/linkedin/school-of-sre/blob/main/CONTRIBUTING.md">the contributing guide</a> to get started.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Computer Science from the Bottom Up (104 pts)]]></title>
            <link>https://www.bottomupcs.com/</link>
            <guid>37451551</guid>
            <pubDate>Sun, 10 Sep 2023 00:00:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bottomupcs.com/">https://www.bottomupcs.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37451551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h3><span><span>Ian</span> <span>Wienand</span></span></h3></p><p><span>
      A PDF version is available at <a href="https://www.bottomupcs.com/csbu.pdf">https://www.bottomupcs.com/csbu.pdf</a>.
      A EPUB version is available at <a href="https://www.bottomupcs.com/csbu.epub">https://www.bottomupcs.com/csbu.epub</a>
      The original souces are available at <a href="https://github.com/ianw/bottomupcs">https://github.com/ianw/bottomupcs</a>
    </span></p><p>This work is licensed under the Creative Commons
      Attribution-ShareAlike License. To view a copy of this license,
      visit <a href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>
      or send a letter to Creative Commons, 559 Nathan Abbott Way,
      Stanford, California 94305, USA.
      </p><p>Copyright © <span><span>2004</span>–<span>2022</span></span> <span>Ian Wienand</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memories from Old LAN Parties (398 pts)]]></title>
            <link>https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html</link>
            <guid>37451518</guid>
            <pubDate>Sat, 09 Sep 2023 23:54:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html">https://thomask.sdf.org/blog/2023/09/09/memories-from-old-lan-parties.html</a>, See on <a href="https://news.ycombinator.com/item?id=37451518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I participated in a lot of LANs in the 2000s, sometimes at private homes and sometimes at dedicated LAN venues. Many strange and wonderful things happened at these events that wouldn’t make a lick of sense today. Here is a collection of unrelated memories which may be altered to protect the guilty.</p>

<hr>

<p>A man who runs a LAN facility will generally not give you a Windows 98 SE CD key, even if you need to reinstall Windows on your PC during an event.</p>

<p>A LAN isn’t legitimate unless at least one person has to reinstall Windows along the way.</p>

<p>Multi-round tournaments seem like a good idea but you will never get anybody into their allocated matches at the times they’re supposed to be there.</p>

<p>If you mod your ATX case so that the power button is gigantic and illuminated with a red LED, someone will come along while you’re gaming and wonder out loud “what does this button do?” while pressing it.</p>

<p>Having a PC with a window in the side of the case does in fact give you credibility.</p>

<p>If you take a 500 GB drive to a public LAN where the average drive size is 80 GB then it is possible that it will be stolen from your box while you’re taking a break go-karting.</p>

<p>If you use a crack that generates malicious traffic from your IP then you may be forced to reinstall Windows before you can reconnect to the network.</p>

<p>If you don’t have enough warez to reach the minimum share limit for the DC++ server you can always add the directories for your games installed under Program Files.</p>

<p>The desk you’re seated at may have a badge at the back telling you which static IP to use, but you can ignore that if the venue has upgraded to DHCP.</p>

<p>If you’re using a 10 Mbit hub and copy the same directory to two Windows SMB hosts simultaneously it is somehow smart enough to make the transfers coincide so it can transmit the same data to both at once. To this day I have no idea what heuristic it used but honest to god, it slowed down the earlier transfer and then went in lockstep file by file for the remainder.</p>

<p>If you throw an old motherboard onto the 11 kV power lines on a nearby pole it will toast some components but probably not cause a power outage.</p>

<p>Windows 98 SE requires that you reboot after changing your IP address settings.</p>

<p>Windows 2000 is quite good for gaming and has the added benefit that you will be prompted to press Ctrl-Alt-Del to logon, which feels corporate (or school-like) and cool.</p>

<p>If a pirated game comes with a crack.exe then you run the crack.exe. What could go wrong?</p>

<p>There were websites which aggregated downloads of keygens for various games. These worked more often than you would expect.</p>

<p>In an attempt to reduce piracy for multiplayer, game producers such as Blizzard let you install “spawn” copies of the software which could only participate in a multiplayer game and didn’t require the CD to be in the drive.</p>

<p>Alcohol 120% was the free tool of choice to emulate a CD drive for ISOs of games which required the CD to be inserted for copy protection, or rip a CD for that purpose. This only became popular once hard drives became big enough for people to spend many gigabytes imaging their CDs.</p>

<p>The cool kids had a Barton Athlon XP 2500+ and a Radeon 9600. The rich kids had a 9800.</p>

<p>Internet access wasn’t a thing until the later years. LANs which tried to provide internet had strict quotas or bandwidth limits and generally found it difficult to manage.</p>

<p>If you had the right ICQ number you could repeat it multiple times to generate a valid Starcraft CD key.</p>

<p>Sometimes LANs would get terrible sponsorship deals and nerds would fight over bounty like a CD of <a href="https://archive.org/details/X04-63221">Visual C++ 6 Enterprise Edition</a>.</p>

<p>A man who runs a LAN facility might sell you an RTL8139 PCI card for $15 if you want to upgrade to 100 Mbps. This card might work great for a decade+ after.</p>

<p>If you’re a poor high school student who wants to upgrade your home network from a hub to a switch, you could pay the lion’s share of the $55 for the right to keep it at your house between LANs.</p>

<p>WINE can basically only run Starcraft.</p>

<p>If someone has shared their installation of Warcraft III over SMB it will run much faster if you copy it to your local machine first rather than execute it directly from the network folder.</p>

<p>Motherboards had headers to connect USB ports built into the case but they were completely unstandardised so you had to slot them in pin-by-pin in the correct locations following your motherboard manual. If you got this wrong you could short out your PSU through thin wires by plugging in a USB mouse, which would create an awful whirring sound.</p>

<p>A commercial LAN venue would advertise itself on a local pop music radio station by having a dialogue of people arguing about which IP addresses to use.</p>

<p>If you had the oldest PC in your group, you might be connecting to the hub via coax and a BNC connector while everyone else is using CAT5.</p>

<p>What’s WiFi?</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sucking carbon dioxide out of the sky is moving from science fiction to reality (143 pts)]]></title>
            <link>https://www.npr.org/2023/09/08/1198373683/sucking-carbon-dioxide-out-of-the-sky-is-moving-from-science-fiction-to-reality</link>
            <guid>37451080</guid>
            <pubDate>Sat, 09 Sep 2023 22:48:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2023/09/08/1198373683/sucking-carbon-dioxide-out-of-the-sky-is-moving-from-science-fiction-to-reality">https://www.npr.org/2023/09/08/1198373683/sucking-carbon-dioxide-out-of-the-sky-is-moving-from-science-fiction-to-reality</a>, See on <a href="https://news.ycombinator.com/item?id=37451080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primaryaudio">
      <article id="res1198373684" aria-label="audio-module"><div>
      <h4>Sucking carbon dioxide out of the sky is moving from science fiction to reality </h4>
   

   
    
</div>
</article>
</div><div id="storytext">
      <p>Occidental Petroleum is investing in billion-dollar projects to suck carbon dioxide out of the sky. The effort is raising hopes — and eyebrows.</p>   
</div><div aria-label="Transcript">
    <p>DANIEL ESTRIN, HOST: </p><p> Sucking carbon dioxide out of the sky is moving from science fiction to reality. For years, this was seen as a long shot sort of thing, too hard and too expensive. But now people are spending billions of dollars to scale up this technology. And controversially, one company at the heart of this shift is an American oil company. NPR's Camila Domonoske has been reporting on this. Good morning.</p><p>CAMILA DOMONOSKE, BYLINE: Good morning, Daniel.</p><p>ESTRIN: What is this technology?</p><p>DOMONOSKE: You know, we're talking about machines that extract carbon dioxide from the atmosphere, from the air we breathe. Think giant fans. Chemical reactions suck the carbon out of the sky and then store it underground. This takes a ton of energy, all right? It's not easy. But climate groups say that we are now so far behind on climate goals that this technology will be essential. And that is on top of restoring forests and mangroves and improving agricultural practices and, crucially, cutting the use of oil.</p><p>ESTRIN: So if we also need to cut oil production, why is an oil company playing a key role here?</p><p>DOMONOSKE: Yeah. So Occidental Petroleum, a big American oil company, they are really good at a kind of oil production that involves injecting CO2 underground to squeeze more oil out of old wells. So when they heard about this technology to pull carbon out of the sky, they thought, wait; this could work for us. They plan to put some carbon underground just to store it. Companies and the government will pay for that. But they also plan to use some of that carbon to make more oil. Here's Oxy's CEO Vicki Hollub.</p><p>VICKI HOLLUB: It's really going to take oil to be produced for decades to come. And if it's produced in the way that I'm talking about, there's no reason not to produce oil and gas forever.</p><p>ESTRIN: Wow. OK, wait. Let me get this straight. An oil company that profits off of releasing carbon dioxide in the air is also going to be profiting from sucking it out of the air. Is that right?</p><p>DOMONOSKE: That's their plan, yeah.</p><p>ESTRIN: I imagine climate advocates are not very happy about that.</p><p>DOMONOSKE: Well, it depends. Oxy's expertise could scale this technology up and bring costs down. And so some groups say they welcome that. But that argument that Hollub just made - that this could justify using oil for longer - that is not what climate groups say we need to do as a planet at all. And so lots of advocates are worried that this could be a distraction that's used to avoid doing much cheaper, really effective and essential things like building clean energy. So billions of dollars are pouring into this tech. Oxy is deeply involved. But there's this really fundamental disagreement between Oxy and other groups about what we should be using it for.</p><p>ESTRIN: How concerned should we be about this development?</p><p>DOMONOSKE: The worst-case scenario is obviously really grim - right? - the idea that this could derail progress on cutting emissions. What I found interesting reporting on this is that even people who are optimistic about it, there's a lot of despair. I spoke to Jennifer Wilcox, who's at the Department of Energy. She supports these kinds of projects. She told me this.</p><p>JENNIFER WILCOX: I think if we looked back a decade ago when I first started in this field, we didn't need direct air capture.</p><p>DOMONOSKE: That is, everyone believed that we could simply cut emissions by enough. And then we didn't. As for the participation of the oil and gas industry, she says...</p><p>WILCOX: We can't do this without them. You know, we can fight. Fighting is what we did over a decade ago, and look where we are, right? That fight of leave it in the ground we're not going to win. OK?</p><p>DOMONOSKE: Some climate advocates strongly disagree with her there, but she's not alone in this. Several proponents of direct air capture told me very similar things, that they see the surge of investment in this technology as a climate win and also as a sign of failure because they only think we need it at all because we didn't cut emissions sooner.</p><p>ESTRIN: NPR's Camila Domonoske, thanks.</p><p>DOMONOSKE: Thanks.</p>

    <p>Copyright © 2023 NPR.  All rights reserved.  Visit our website <a href="https://www.npr.org/about-npr/179876898/terms-of-use">terms of use</a> and <a href="https://www.npr.org/about-npr/179881519/rights-and-permissions-information">permissions</a> pages at <a href="https://www.npr.org/">www.npr.org</a> for further information.</p>

    <p>NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR’s programming is the audio record.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lithium discovery in US volcano could be biggest deposit ever found (608 pts)]]></title>
            <link>https://www.chemistryworld.com/news/lithium-discovery-in-us-volcano-could-be-biggest-deposit-ever-found/4018032.article</link>
            <guid>37450915</guid>
            <pubDate>Sat, 09 Sep 2023 22:27:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chemistryworld.com/news/lithium-discovery-in-us-volcano-could-be-biggest-deposit-ever-found/4018032.article">https://www.chemistryworld.com/news/lithium-discovery-in-us-volcano-could-be-biggest-deposit-ever-found/4018032.article</a>, See on <a href="https://news.ycombinator.com/item?id=37450915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A world-beating deposit of <a href="https://www.chemistryworld.com/3005835.article" rel="intextlink_6">lithium</a> along the Nevada–Oregon border could meet surging demand for this metal, according to a new analysis.</p>
<p>An estimated 20 to 40 million tonnes of lithium metal lie within a volcanic crater formed around 16 million years ago. This is notably larger than the lithium deposits found beneath a Bolivian salt flat, previously considered the largest deposit in the world.</p>
<p>‘If you believe their back-of-the-envelope estimation, this is a very, very significant deposit of lithium,’ says <a href="https://www.kuleuven.be/wieiswie/en/person/00143067">Anouk Borst</a>, a geologist at KU Leuven University and the Royal Museum for Central Africa in Tervuren, Belgium. ‘It could change the dynamics of lithium globally, in terms of price, security of supply and geopolitics.’</p>
<p>New in situ analysis reveals that an unusual claystone, composed of the mineral illite, contains 1.3% to 2.4% of lithium in the volcanic crater. This is almost double the lithium present in the main lithium-bearing clay mineral, <a href="https://www.chemistryworld.com/3005842.article" rel="intextlink_3">magnesium</a> smectite, which is more common than illite.</p>
<p>Some unusual conditions created what could be a uniquely rich volcanic deposit. The crater – the McDermitt caldera – formed 16.4 million years ago when around 1000km<sup>3</sup> of magma exploded outwards. The caldera was filled with erupted products of an alkaline magma rich in <a href="https://www.chemistryworld.com/3005954.article" rel="intextlink_5">sodium</a> and <a href="https://www.chemistryworld.com/3005912.article" rel="intextlink_4">potassium</a>, as well as lithium, <a href="https://www.chemistryworld.com/3005734.article" rel="intextlink_1">chlorine</a> and <a href="https://www.chemistryworld.com/3005716.article" rel="intextlink_0">boron</a>. This quickly cooled to form a finely crystalline glassy volcanic rock, ignimbrite, which weathered to produce lithium-rich particles.</p>
<p>A lake subsequently formed in the crater, persisting for hundreds of thousands of years, with weathered volcanic and surrounding materials forming a clay-rich sediment at its bottom. The new analysis suggested that, after the lake had emptied, another bout of volcanism exposed the sediments to a hot, alkaline brine, rich in lithium and potassium.</p>
<div data-attachment="528663" data-sequence="3">
<p><img alt="A sandy coloured cliff with horizontal stripes of white and orange minerals" data-src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/6/3/528663_clayminewall_861418.jpg" sizes="(max-width: 1023px) 100vw, 780px" data-srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/6/3/528663_clayminewall_861418.jpg 480w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/600xany/6/6/3/528663_clayminewall_861418.jpg 600w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/780xany/6/6/3/528663_clayminewall_861418.jpg 780w" width="1990" height="1315" src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/6/3/528663_clayminewall_861418.jpg" srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/6/3/528663_clayminewall_861418.jpg 480w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/600xany/6/6/3/528663_clayminewall_861418.jpg 600w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/780xany/6/6/3/528663_clayminewall_861418.jpg 780w"></p>


</div>
<p>‘Previous research assumed that the illite was everywhere at depth in the caldera,’ says Thomas Benson, a geologist at Lithium Americas Corporation, and was formed when high temperatures and pressures turned smectite to illite.</p>
<p>Benson’s team proposed that a layer of illite around 40m thick was formed in the lake sediments by this hot brine. The fluid moved upwards along fractures formed as volcanic activity restarted, transforming smectite into illite in the southern part of the crater, Thacker Pass. The result was a claystone rich in lithium.</p>
<p>‘This would be a multistep alteration of lithium-bearing smectite to illite, where hydrothermal fluids enriched the clays in potassium, lithium and <a href="https://www.chemistryworld.com/3005779.article" rel="intextlink_2">fluorine</a>,’ says Borst. ‘They seem to have hit the sweet spot where the clays are preserved close to the surface, so they won’t have to extract as much rock, yet it hasn’t been weathered away yet.’</p>
<p>The material could be best described as looking ‘a bit like brown potter’s clay’, says <a href="https://nbmg.unr.edu/staff/henry.html">Christopher Henry</a>, emeritus professor of geology at the University of Nevada in Reno. ‘It is extremely uninteresting, except that it has so much lithium in it.’</p>
<p>‘There’s been a lot of searching for additional [lithium] deposits,’ Henry adds. ‘The United States has just one small lithium-producing brine operation in Nevada.’</p>
<div data-attachment="528639" data-sequence="2">
<p><img alt="A map of the world showing the location, type and size of lithium resources. it includes mainly volcano sedimentary and hard rock in North America, mainly evaporative brine in South America and mostly hard rock in Africa, Asia and Australasia" data-src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/3/9/528639_sciadv_538044.jpg" sizes="(max-width: 1023px) 100vw, 780px" data-srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/3/9/528639_sciadv_538044.jpg 480w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/600xany/6/3/9/528639_sciadv_538044.jpg 600w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/780xany/6/3/9/528639_sciadv_538044.jpg 780w" width="2100" height="816" src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/3/9/528639_sciadv_538044.jpg" srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/6/3/9/528639_sciadv_538044.jpg 480w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/600xany/6/3/9/528639_sciadv_538044.jpg 600w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/780xany/6/3/9/528639_sciadv_538044.jpg 780w"></p>


</div>
<p>Henry does not wholly agree with the newly proposed history of the crater, since isotopic dating showed that a lake existed there until 15.7 million years ago, but the volcanic system went extinct by 16.1 million years. The new timeline would require volcanic activity for longer than the evidence suggests, he explains.</p>
<p>Benson says his company expects to begin mining in 2026. It will remove clay with water and then separate out the small lithium-bearing grains from larger minerals by centrifuging. The clay will then be leached in vats of sulfuric acid to extract lithium.</p>
<p>‘If they can extract the lithium in a very low energy intensive way, or in a process that does not consume much acid, then this can be economically very significant,’ says Borst. ‘The US would have its own supply of lithium and industries would be less scared about supply shortages.’</p>
<p>Benson views the lithium-rich claystone at Thacker Pass as ‘unique’ amongst volcanic sedimentary deposits. ‘Smectite clays are relatively more abundant,’ he says. Exploration for further lithium deposits following eruptions should focus on calderas with lake sediments that have been hydrothermally altered in lakes with no outflows, he adds.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No Google Topics in Vivaldi (142 pts)]]></title>
            <link>https://vivaldi.com/blog/news/alert-no-google-topics-in-vivaldi/</link>
            <guid>37449921</guid>
            <pubDate>Sat, 09 Sep 2023 20:24:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vivaldi.com/blog/news/alert-no-google-topics-in-vivaldi/">https://vivaldi.com/blog/news/alert-no-google-topics-in-vivaldi/</a>, See on <a href="https://news.ycombinator.com/item?id=37449921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<article id="post-592563" itemscope="itemscope" itemtype="http://schema.org/Article">
				
				<header>
															<p>Spying on people’s behavior and profiling them is wrong. That is why we have made sure that Google’s Topics is disabled in two separate ways in the Vivaldi browser. </p>
										<p><img src="https://vivaldi.com/wp-content/uploads/2018/03/BACsmall.jpg" width="96" height="96" alt=""> <span itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Vivaldi Technologies"><span itemprop="logo" itemscope="" itemtype="https://www.schema.org/ImageObject"></span></span>By <time datetime="2023-09-08" itemprop="datePublished">September 8, 2023</time><time datetime="2023-09-08" itemprop="dateModified"></time><span><span>4269 views</span></span></p>				</header>
				<div>
					<p><img width="980" height="551" src="https://vivaldi.com/wp-content/uploads/Topics-980x551-3-980x551.jpeg" alt="" decoding="async" itemprop="image"></p><p>Chrome now directly tracks users, and generates a “topic” list it shares with advertisers.</p>



<div><p>And this is simply ridiculous. Topics, a part of <a href="https://privacysandbox.com/">Chrome Privacy Sandbox</a>, is something we have long known as a deceitful attempt by Google to appear to be privacy-oriented while introducing new means of spying on their users.</p><p>In short: Topics is among Google’s attempts to replace the third-party cookie as a means of identifying people online by striking a balance between preserving people’s privacy and preserving companies’ abilities to buy and sell targeted ads.&nbsp;</p></div>



<div><p>From the moment they started developing it, we have voiced our concerns about this — whether it was <a href="https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea">Floc</a> or Topics, and have sought to fully disable it in Vivaldi.  We never had any faith in the Topics API from the very start. </p><p>Read our <a href="https://vivaldi.com/blog/technology/heads-up-googles-going-off-topics-again/">blog</a> when Topics was announced. </p></div>



<h2>Google’s Topics disabled in Vivaldi.</h2>



<p>Google’s Topics API will not be enabled in Vivaldi, and it cannot work in Vivaldi. It would need two things to make it work, and we have disabled both of them.</p>







<ol>
<li>It would need a setting enabled for it to collect local profiles about you. We disable the setting by default, and we forcibly do it in a way that means that changes to Chromium cannot remotely enable it. We do not provide any settings UI to allow you to change it, and we will soon remove the new Chromium settings section for it. (Technically, you could enable it by editing your settings or installing an extension that manipulates it. However, all that would do is enable&nbsp;<strong>local</strong>&nbsp;data collection. It will not be used because of #2)<br></li>



<li>Before exposing the <a href="https://developer.chrome.com/en/docs/privacy-sandbox/topics/overview/#:~:text=The%20Topics%20API%20is%20a,the%20sites%20a%20user%20visits.">Topics API</a> information to websites, Chromium checks if the setting is enabled or disabled. We forcibly make it always return “disabled”, even if it is enabled. So that even if you somehow manage to bypass #1 and enable local profile collection, it will not expose it to Google or other websites.<br></li>
</ol>



<h2>Do you really want to be tracked? </h2>



<p>Did you ever imagine a browser that has user-tracking and ad platforms baked in? That’s Google Chrome for you. Google says it will block third-party cookies in the second half of 2024  — presumably after it makes sure the “Privacy Sandbox” will allow it to keep its profits. </p>



<div><p>We believe that having tracking and profiling baked into a browser is fundamentally wrong. Even if it can be disabled, and even if it is disabled by default but allows you to enable it on demand. Users should not be exposed to this sort of privacy invasion, and the browser should be protecting you from it.</p><p>The world’s largest tech companies generate most of their revenues from advertising, and when that advertising is driven by your data and interactions with their services, the balance is very wrong.</p><p>But at the same time, there are companies out there that have genuinely good intentions as well. As we’ve said before, what happens next is up to all of us — all of you. It all depends on what choices we make. </p><p>Our mission is to stay true to our users and respect their privacy, and we shall continue to do so. </p></div>



<div><p>Thank you, Topics. You have made our relationship with our users stronger. </p><p><em>Input from Yngve Pettersen and Julien Picalausa</em></p></div>








									</div>
				
			</article>
		</div></div>]]></description>
        </item>
    </channel>
</rss>