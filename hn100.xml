<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 04 Dec 2023 03:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[When product markets become collective traps: The case of social media (106 pts)]]></title>
            <link>https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/</link>
            <guid>38512506</guid>
            <pubDate>Mon, 04 Dec 2023 00:59:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/">https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/</a>, See on <a href="https://news.ycombinator.com/item?id=38512506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In many contexts, the individual value from consuming a product or service increases as more people consume it. The more of your peers who join TikTok, for example, the more value you probably see in joining yourself. Building on this logic, it’s possible that products like social media not only offer greater utility to users as their market share grows, but greater disutility to non-users as well. Just imagine being the sole holdout during the TikTok craze. With each friend who joins, you likely feel increasingly left out. In this paper, the authors test for these spillovers and paint a more accurate picture of how social media impacts consumers.</p><p>To study this question, the authors design a largescale, online experiment aimed at measuring consumer welfare in the presence of both network effects—the phenomenon wherein the value of joining vs. not joining increases with the number of consumers—and consumption spillovers to non-users—for example, fear of missing out on the latest TikTok trend. Their survey-based experiment focuses on TikTok and Instagram and is administered to 1,000 college students.</p><p><img decoding="async" src="https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media.jpg" alt="" width="901" height="654" srcset="https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media.jpg 901w, https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media-551x400.jpg 551w, https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media-768x557.jpg 768w" sizes="(max-width: 901px) 100vw, 901px"></p><p>The authors begin by measuring the amount of money that users would accept to deactivate their accounts for four weeks, while keeping constant others’ social media use. They next measure how much users value their accounts when other students at their university are asked to deactivate their accounts as well. Finally, the authors measure users’ preferences over the deactivation of accounts of all participating students, including themselves. They find the following:</p><ul><li>Users would need to be paid $59 to deactivate TikTok and $47 to deactivate Instagram if others in their network were to continue using their accounts.</li><li>Users would be willing to pay $28 and $10 to have others, including themselves, deactivate TikTok and Instagram, respectively. Accounting for consumption spillovers to non-users reveals that 64% of active TikTok users and 48% of active Instagram users experience negative welfare from the products’ existence. Participants who do not have accounts would be willing to pay $67 and $39 to have others deactivate their TikTok and Instagram accounts, respectively.</li><li>Taken together, these results imply the existence of a “social media trap” for a large share of consumers, whose utility from the platforms is negative but would have been even more negative if they didn’t use social media.</li><li>The authors use these results to quantify the role of network effects on social media, or the extent to which users value social media platforms more when their peers use them. They find positive and quantitatively significant network effects: users value TikTok and Instagram 33% and 24% more, respectively, when their peers are on the sites compared to when they are not.</li></ul><p>Building on these results, the authors explore whether product market traps exist in other domains as well. They field online surveys with consumers concerning their opinions on luxury goods and technology, where similar spillover effects are a plausible driver of consumption. They find the following:</p><ul><li>Among respondents who own luxury brands that they themselves bought (e.g., Gucci, Versace, Rolex), 44% prefer to live in a world without any of those brands altogether. Among respondents not owning such brands, the fraction preferring to live in a world without them is 69%.</li><li>Among iPhone owners, a striking 91% of respondents indicate that they would prefer Apple to release the iPhone every other year rather than every year. Among respondents not owning the iPhone, this fraction is even larger, at 94%.</li></ul><p>This research challenges the standard argument that the mere existence of a product implies positive welfare for its users. This could help reconcile the seemingly contradictory findings in the social media literature of a large consumer surplus coexisting with negative effects on wellbeing. It also suggests a heightened need for regulators to assess whether different products create traps for consumers and whether they generate positive welfare. For instance, large tech companies commonly use tools that might decrease non-consumer surplus, such as increasing the salience of being a non-consumer or tying together messaging apps and social media platforms and thus increasing the cost of not being a user.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What side projects landed you a job? (176 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38511280</link>
            <guid>38511280</guid>
            <pubDate>Sun, 03 Dec 2023 22:16:45 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38511280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38512291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512291" href="https://news.ycombinator.com/vote?id=38512291&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I wrote a Dropbox-like file sync and share application called Syncany [1] as a side project back in 2014/2015. While it never made it out of alpha, it had gotten some traction, and looking back, I am still proud of the architecture and design (not so much of the code, hehe).<p>One day, a developer from this random company in Connecticut (I am German and lived in Germany at the time) reached out to me in my project's IRC channel, and asked if I wanted to interview. I did, and I got the job.</p><p>I moved to the UK, then to the US with my wife, and stayed with the company for 8 years. I got promoted from senior engineer to Sr. Principal Engineer and had an amazing time there. I now have a green card and live in CT with my 2 amazing children (with German and American citizenship).</p><p>I often think back about how much that project and that person who reached out to me changed my life. How different it would be if I hadn't worked on my side project, if it hadn't become semi-popular, or if he hadn't reached out. Butterfly effect at it's finest.</p><p>[1] <a href="https://www.syncany.org/" rel="nofollow noreferrer">https://www.syncany.org</a></p><p>Edit: Fun fact: Drew Houston (Dropbox CEO) emailed me at the time and wanted to hire me, but he didn't respond when I emailed him back. And even many years later when I applied at Dropbox they didn't want me, hehe.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512481"><td></td></tr>
                  <tr id="38511682"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511682" href="https://news.ycombinator.com/vote?id=38511682&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Back in 2002 I lost my job during a regional financial crisis (I’m from Uruguay).<p>I was working at a bank (as a contractors) and some coworkers and I were working on a HA project for MySQL at the moment (to use it at work). Once I got laid off, I focused on it to the point that it became quite useful, and at some point, someone from Israel reached out with questions.</p><p>I answered with a lot of delay, and when I explained that was due to me being out of a job and not able to afford a permanent internet connection, he offered to hire me and also set me up with a permanent connection with a contract paid by him.</p><p>If you’re reading this, thank you Aric, I’m forever grateful for that chance!</p><p>Curiously, last year I switched jobs and during the interview process it turned out the hiring manager had been a user of my project back in 2003 or so, which definitely helped with the interview process.</p><p>The project’s name was mysql-ha, later renamed to highbase due to a Copyright infringement notice from Sun (who were good about it and gave me a free 1 year subscription to Enterprise MySQL when I renamed the project). I abandoned it around 2008 as better things became available around that time .
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511858"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511858" href="https://news.ycombinator.com/vote?id=38511858&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>That must give you an adrenaline rush of another level when the interviewer turns out to be your user. I want to feel that one day</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512187"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512187" href="https://news.ycombinator.com/vote?id=38512187&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>It was great though honestly, my first reaction was a bit of panic. The first thoughts that came to my mind were "will he say it sucked? maybe he used it and lost some data?". Once that didn't happen then yeah, it was thrilling, and completely unexpected for a project I hadn't worked on for over a decade!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512085" href="https://news.ycombinator.com/vote?id=38512085&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>That's a fantastic story. I hope fortune has followed you. I would be <i>thrilled</i> to find even one user of software I've wrote. To be <i>interviewed</i> by one for a job? That's amazing.<p>Good stuff!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512193"><td></td></tr>
                  <tr id="38512169"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512169" href="https://news.ycombinator.com/vote?id=38512169&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Que bueno ver otro Uruguayo aca en HN, somos pocos pero buenos!<p>Que estes bien Fernando, me alegro que prefieras quedarte en el paisito y cultivarlo ayudando a otros.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512229"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512229" href="https://news.ycombinator.com/vote?id=38512229&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>¡Muchas gracias!<p>Y si, espero que ahora que el trabajo remoto es mas aceptado, mucha mas gente pueda "irse sin irse", trabajando para donde sea pero desde acá.</p><p>¡Que estés bien también!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512312"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512312" href="https://news.ycombinator.com/vote?id=38512312&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; who were good about it and gave me a free 1 year subscription to Enterprise MySQL when I renamed the project<p>Sun really was good, huh?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512490"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512490" href="https://news.ycombinator.com/vote?id=38512490&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Considering I was (unknowingly) very obviously infringing their trademark (X for MySQL was OK, MySQL-X was not), yeah, I felt the whole thing was handled in a good way.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511760"><td></td></tr>
                <tr id="38511804"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511804" href="https://news.ycombinator.com/vote?id=38511804&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Thanks!<p>In 2009 I joined Percona and saw that, by then, it was better for me to contribute to other open source projects in the MySQL ecosystem than to continue trying to get highbase caught up with things like mysql-mmm.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511695"><td></td></tr>
                <tr id="38512332"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512332" href="https://news.ycombinator.com/vote?id=38512332&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Having done a large scale MySQL deployment (700+ servers), I still find the HA landscape in MySQL land pretty sad. It's all very manual, nad it's very easy to screw up failovers. Even with Vitesse or Orchestrator or semi-sync ...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512474"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512474" href="https://news.ycombinator.com/vote?id=38512474&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Oh, definitely, I meant things better than my project had become available. MySQL still has a long way to go in terms of friendly HA, and I’m not sure it will ever get to the level of something like cockroachdb. There’s plenty of room for improvements in that area, just not through something like what I was doing (mostly shell scripts).</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38511649"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511649" href="https://news.ycombinator.com/vote?id=38511649&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>A long time ago sonos didn't support apple airplay.<p>I did some protocol reversing and wrote a small program that pretended to be an airplay speaker to pipe audio to a sonos speaker (archive: <a href="https://github.com/stephen/airsonos">https://github.com/stephen/airsonos</a>)</p><p>I ended up getting recruiting messages from both the airplay team at apple and some folks from sonos. I didn't end up taking either offer, but it was also an interesting talking point when interviewing for the job I did take.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512408"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512408" href="https://news.ycombinator.com/vote?id=38512408&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I remember seeing this published when I worked at Sonos. In fact, I might have been the one who put it on the Slack channel.<p>It was a cool project at a time when a lot of people were saying it was insurmountable to make us AirPlay compatible.</p><p>Sorry you didn’t get the job. I hope you didn’t lose much sleep over it. I left in 2020. I wouldn’t say you’re missing much any more.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511689"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511689" href="https://news.ycombinator.com/vote?id=38511689&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; I did some protocol reversing<p>This would make for an interesting blog post.</p><p>Could you recommended resources to learn to do the same?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512117"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512117" href="https://news.ycombinator.com/vote?id=38512117&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Step 1 — study popular protocols to understand how client/server interactions typically work.<p>Step 2 — deploy the network appliance in question to your LAN and intercept its packets with wireshark.</p><p>Step 3 — begin inference of protocol from observed behavior and test hypothesis by sending hand-crafted payloads to the server in question.</p><p>Step 4 — rinse and repeat until assumptions are proven to be correct with a high degree of reliability.</p><p>A good way to ensure you’ve captured the major parts of the protocol is to record about 72 hours of traffic and then replay it through a proxy that directs traffic to your newly created service.</p><p>If you can interpret the vast majority of the messages without error, you’re getting close to a reliable implementation.</p><p>Step 5 — use this strategy to develop a deep understanding of both protocols in question.</p><p>Step 6 — write an “adapter” that can translate protocol A to protocol B and vice versa.</p><p>Step 7 — implement the adapter towards whatever use case you have in mind.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38511845"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511845" href="https://news.ycombinator.com/vote?id=38511845&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I actually forgot that I did in fact write about this! <a href="https://medium.com/@stephencwan/hacking-airplay-into-sonos-93a41a1fcfbb" rel="nofollow noreferrer">https://medium.com/@stephencwan/hacking-airplay-into-sonos-9...</a><p>A bit light on the technical details perhaps, but I recall getting stuck on getting the right airplay parameters, learning how byte endianness works... happy to try to answer any other questions as best I can remember.</p><p>EDIT: Sorry, I realized that I didn't actually answer the other question. I first got interested in reversing from console hacking, specifically this talk about wii hacking: <a href="https://youtu.be/0rjaiNIc4W8" rel="nofollow noreferrer">https://youtu.be/0rjaiNIc4W8</a> (including marcan of asahi linux fame!). Their group also had more writing at: <a href="https://fail0verflow.com/blog/" rel="nofollow noreferrer">https://fail0verflow.com/blog/</a>. Also interesting to read about mgba emulator development: <a href="https://mgba.io/tag/debugging/" rel="nofollow noreferrer">https://mgba.io/tag/debugging/</a>, v8 internals: <a href="https://mrale.ph/" rel="nofollow noreferrer">https://mrale.ph</a>, react internals: <a href="https://overreacted.io/" rel="nofollow noreferrer">https://overreacted.io/</a></p><p>Consuming a lot of literature on how different systems work helped me develop intuitions around how you might take something apart. Then it's a matter of trying things and banging your head against the wall a lot, e.g. at some point I was interested in how compilers worked so I tried hacking typescript syntax support into babel (circa 2017 maybe) - I got pretty far! and got a lot better sense of how compilers work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511876"><td></td></tr>
                <tr id="38511918"><td></td></tr>
                        <tr id="38511832"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511832" href="https://news.ycombinator.com/vote?id=38511832&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>So, respective teams from those two companies (or even other companies for that matter) are actively searching GH for any mods to their work?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511924"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511924" href="https://news.ycombinator.com/vote?id=38511924&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>More likely is employees use their own products and happen to see it while searching for a way to do the same thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511923"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511923" href="https://news.ycombinator.com/vote?id=38511923&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>In my experience it's more like people happen to stumble across your work or hear about it somehow, not a systematic search for people working on X thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511756"><td></td></tr>
            <tr id="38511827"><td></td></tr>
            <tr id="38511996"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511996" href="https://news.ycombinator.com/vote?id=38511996&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>You didn't miss out because Sonos continues to do an awful job software-wise. One of the things I'm most looking forward to as I de-IOT-ize my life is selling that system and running speaker wire like a true G.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512036"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512036" href="https://news.ycombinator.com/vote?id=38512036&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Sorry but this sounds like LARP, who the hell wouldnt jump on a job offer from apple? Even if it doesnt work out, having Apple on your resume wouldve been an insane career booster, telling people you got an offer from them but didnt take it sounds very unbelievable, atleast personally, I wouldnt have believed you</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512160"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512160" href="https://news.ycombinator.com/vote?id=38512160&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I am genuinely unsure if this is a parody comment. I am assuming that you are fairly green behind the ears? The thing about Big Tech companies is that they hire lots of developers. That’s in large part makes them Big Tech. “Having Apple on your CV” is not as prestigious as you’re making out. It doesn’t mean you have The Knowledge that makes you a ‘10x developer’ or whatever anywhere you work. In fact, it could mean that your mind has been poisoned by a Big Tech working style, and you’ve developed a bunch of habits that aren’t nearly as applicable to most other organisations.<p>I say this as someone that’s never worked for any tech company anybody has heard of, nor any hip SV startup.</p><p>It takes a particular sort of person to thrive in Big Tech. That isn’t just code for ‘really really really good’. It sounds like you still believe that it is. Plenty of ‘really really really good’ people wouldn’t do well at Apple, and plenty wouldn’t want to work there. I wouldn’t necessarily call myself ‘really really really good’, but I know that I don’t want to work at Apple. Not because I think I’m not good enough, not because k don’t think that I could keep up, and not because I don’t like their output as a company.</p><p>Putting companies in a pedestal the way that you are is ultimately damaging for the industry. It fosters the increasingly cringey “get a job at FAANG!!!” culture. I’m sick of my YouTube recommendations being poisoned with “here’s how you pass a system design interview at Google” BS. I implore you to stop putting companies on a pedestal. You need only look at accountants talking about working at the ‘big 4’ to see how utterly ridiculous it can get.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512263"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512263" href="https://news.ycombinator.com/vote?id=38512263&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>From a developers perspective youre right, most of us here probably wouldnt be able to keep up with the amount of work it takes to thrive at apple, sure. Im looking at it from a future employers view, who sees "Apple", has an iPhone, and immediately has an idea in his head about what kind of developer you are, even if its completely inaccurate- Its all marketing. But also, immediately assuming youre not gonna make it at Apple because of what you heard about their work culture alone sounds like a quitter mindset. I mean at least try. If its not right, good riddance. Its not like having been there is gonna cost anything besides the time you invested.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512390"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512390" href="https://news.ycombinator.com/vote?id=38512390&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Apple recruiters have the professionalism and organizational skills of a shady manual labor staffing firm. 5 1-hour rounds, low-balled, and treated with what felt like an ad-hoc process. Wasn't impressed with the people, nor the caliber of engineering talent.<p>The same is true of Microsoft (Azure specifically), Google, and Amazon.</p><p>Only two "traditional" big tech companies of any note for having sharp people and all-around good vibes are Meta and Netflix. Otherwise, I'd rather go with a unicorn like Snowflake or Databricks, which feels more what software engineering was like in the aughts: exploratory, pioneering, actually building things that people haven't before, rather than gluing stuff together or being drowned in the machinations of some incompetent director.</p><p>I wouldn't make it at Apple, because I would get pissed off and quit. There's more to life than money. I don't want to work with people that see "FAANG" (or use "staffed by ex-FAANG" in their recruiting pitch) and think it's a good signal to be presenting.</p><p>Putting in a stint at any of these lower end tech companies would cost me intangibles that I'm not willing to give up at this stage of my life. Namely, my sanity, spiritual well-being, and fulfillment with life.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512059"><td></td></tr>
                <tr id="38512151"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512151" href="https://news.ycombinator.com/vote?id=38512151&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Interesting projection, but to respond to your point: anyone could just put in a decade at Averagecorp inc. or even just hop around and throw together a decent resume. If a random OSS side project lands you an offer from apple thats gotta be jackpot level luck.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512058"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512058" href="https://news.ycombinator.com/vote?id=38512058&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; who the hell wouldnt jump on a job offer from apple?<p>Lots of people, including me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512153"><td></td></tr>
                <tr id="38512295"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512295" href="https://news.ycombinator.com/vote?id=38512295&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not everyone shares your goals or values.<p>I've used Apple products for years and generally like them a lot as a company, but I have no interest in working for them or any other large US tech company.</p><p>The money is good, of course, but the quality of life sacrifices aren't worth it (for me).</p><p>That's not contrarianism. That's understanding what matters to me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512344"><td></td></tr>
                  <tr id="38512350"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512350" href="https://news.ycombinator.com/vote?id=38512350&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Would you say the majority of people who claim to be contrarian aren’t actual contrarians, in your experience? I’m not sure you can infer this in general.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512370"><td></td></tr>
                        <tr id="38512076"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512076" href="https://news.ycombinator.com/vote?id=38512076&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Not everyone is willing to uproot their life on a whim, even for a theoretically great job and a theoretically great company.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512181"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512181" href="https://news.ycombinator.com/vote?id=38512181&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Im sure "uproot your life and dedicate it to Apple" isnt on the job description and apple is very flexible with this stuff. You think all 164,000 apple employees live in silicon valley?</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38512468"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512468" href="https://news.ycombinator.com/vote?id=38512468&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I made a hobby of writing intro posts on deep technical topics, from DNS to concurrency to cutting cloud cost. From 2009 ish onwards all my gigs have been at least helped if not initiated by someone reading a post and saying "we should talk to this guy".<p>Not a magic spell. I had been writing for almost ten years prior before anyone noticed, and only a fraction get any play.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512478"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512478" href="https://news.ycombinator.com/vote?id=38512478&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I made and maintained a geo-based chat app for a friend/client (<a href="https://hihey.org/" rel="nofollow noreferrer">https://hihey.org</a>, though they took it offline for now I believe). I used Matrix as the basis for it and started putting that on my resumes after finding it fun to work with and experience.<p>I got a couple of reach outs based on having that keyword on my profile alone on YC's job board and on LinkedIn that led to some paid consulting.</p><p>Not as life changing as some of the other answers but I'm amazed when this sort of thing even happens
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512463"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512463" href="https://news.ycombinator.com/vote?id=38512463&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I stopped maintaining a popular JavaScript beautifier/diff/analysis tool 4 years ago that won me several jobs.<p>Since then I have been working on a file streaming application.  Its side items in that project that have been winning me jobs lately, primarily anything to do with full duplex socket streaming and browser test automation.</p><p>As a JavaScript developer took me months this year how to sell my experience and skills from my side projects.  As a JavaScript/TypeScript developer you can do the same shit everybody else does, which is put text on screen using a giant framework.  If that is the kind of employment you are looking for be prepared to degrade yourself to working with newbs that have high insecurity, low self-esteem, and spend all their time talking about how awesome they are.  Its all marketing all the time, no original application code, and outsourcing everything to some external tool.  As a developer you are a commodity product to hire/fire just like public is to social media.  This line of work no longer interested me, so I spent months unemployed figuring this out.</p><p>Instead your alternative as a JavaScript/TypeScript developer is niche skills, which is in higher demand than it sounds.  It seems almost nobody can figure out test automation in the browser.  Having application architecture skills is a huge plus, which typically means Java/C# and HTTP session management with something like Spring, but if you can demonstrate a more generalized approach to application architecture you have a skill that you can adapt to a bunch of different things.  It also helps having things like a security clearance and security certifications.  There are a huge number of cleared developer jobs that recruiters cannot fill.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511616"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511616" href="https://news.ycombinator.com/vote?id=38511616&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Well, a very long time ago, in a company funded far far away (and since defeated by the empire), I had the "joy" of working with Sendmail.  For you youngsters, back then, back when we had dial telephones (tell us more Grandpa!), there were multiple "mail networks", not just this fancy Internet you kids have.  Sendmail was a mail processor that could not only arrange to send and receive mail, but it could translate addressing between the different networks (ARPA, Bitnet, CSNET, UUCP, etc.)  The problem was, reading a sendmail config file was something like reading assembly code except you weren't allowed to by vowels.  It was nearly all symbols -- executable line noise.  
I got tired of working with it - so I wrote my own sendmail compiler/de-compiler of sorts just to work in English prose.  Got me my job at Sun.
These days, I'm not sure if it will let me keep my job, or be the justification for my losing it, but I'm working on a programming language for teens called Onyx (after my grandson, who has NO interest in this as he's intending to a be a pilot, but it means unless she works for Boeing, I'm safe for a few more years</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511738"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511738" href="https://news.ycombinator.com/vote?id=38511738&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I used to work at Sendmail, it was my first job.  The entire premise of the company was "Sendmail is so hard to use, let us run it for you".  We had software that added a GUI for configuration and management, and Pro Services to set up big installs.<p>But also we had all the top maintainers of Sendmail.  And we ran Sendmail for our corp mail.</p><p>Once we had a problem with the network, so we had to reroute corporate mail over a phone line.  One of the maintainers came down, typed what looked like line noise for five minutes, and all of a sudden all the mail was working again.</p><p>It was crazy to watch him basically read and write raw Sendmail configs.  He didn't even use m4.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511732"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511732" href="https://news.ycombinator.com/vote?id=38511732&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not directly related, but I'm working on some short stories inspired by some of the hacker/cyberpunk literature from the 80's and since I grew up and learned programming in the late 90's early 2000's, I feel completely inadequate at writing cheesy hacker stories.<p>Keep them old timer stories a' comin'.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511656"><td></td></tr>
                  <tr id="38512047"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512047" href="https://news.ycombinator.com/vote?id=38512047&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I built <a href="https://foragoodstrftime.com/" rel="nofollow noreferrer">https://foragoodstrftime.com</a> ~10 years ago as I was sick of reading the docs for date formatting.<p>It generally gets around 1000 users a day.</p><p>Over the years, it's gotten me consulting gigs and the occasional job offer (amidst other projects).</p><p>Today, it sends a decent chunk of the traffic and sign-ups to my startup, Wafris -&gt; <a href="https://wafris.org/" rel="nofollow noreferrer">https://wafris.org</a></p><p>OP's asking for a strategy with these, and the advice I'd offer is to treat them like assets. You make these various side projects to learn something, take the extra 20% of time to package it up buy a domain, and spend $10 on a logo or something to make it a little more like a project and not just a repo.</p><p>If it's not something directly usable like this, take some screenshots and collect them into a gallery on a personal site.</p><p>You stack these assets over time (and like my example above), they pay off over years in all sorts of ways.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511593"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511593" href="https://news.ycombinator.com/vote?id=38511593&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My blog <a href="https://xeiaso.net/" rel="nofollow noreferrer">https://xeiaso.net</a> (source code: <a href="https://github.com/Xe/site">https://github.com/Xe/site</a>) and the stuff I've written for it ended up doing several things to help me get employed over the years:<p>1. Letting me have a place to write to get better at writing, which makes it easier to do my job in DevRel.</p><p>2. Lets me talk about all of the interesting projects I work on (eg: an AI novel writing experiment <a href="https://xeiaso.net/videos/2023/ai-hackathon/" rel="nofollow noreferrer">https://xeiaso.net/videos/2023/ai-hackathon/</a>) that people regularly find interesting. This gets people interested in wanting to employ me, which ends up working up well for me in the long run.</p><p>Do side projects, but write about what you did and what you learned.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511627"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511627" href="https://news.ycombinator.com/vote?id=38511627&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I've heard from many that writing can help build credibility for hiring purposes. I have committed myself to writing at least something on all future projects because of this. Thanks for the tip.<p>p.s your use of "Technophilosopher" and "chaos magician" to describe yourself is incredible
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512013"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512013" href="https://news.ycombinator.com/vote?id=38512013&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have gotten very good engagement of my blog content as I write for fun sometimes<p>I got to learn a lot of from folks who read my Content.</p><p>Also if you don’t mind me asking</p><p>How can a blog aid in finding or landing a job
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512081"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512081" href="https://news.ycombinator.com/vote?id=38512081&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Become an expert in a thing, companies that need expertise in that thing will come knocking.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512097"><td></td></tr>
                        <tr id="38511963"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511963" href="https://news.ycombinator.com/vote?id=38511963&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I've been meaning to write a longer rant about this, but I'm not an engineer. I'm a glorified product designer and marketer.<p>Also every title is made up. Some are more made up than others.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512488"><td></td></tr>
            <tr id="38511984"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511984" href="https://news.ycombinator.com/vote?id=38511984&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was one of the first backers of the Oculus Rift Kickstarter. When I got it I decided eye tracking was going to be huge for VR, so as a side project I cut a hole in my Rift and built my own eye tracker. I posted it on Hacker News: <a href="https://news.ycombinator.com/item?id=7876471">https://news.ycombinator.com/item?id=7876471</a><p>A few days later the CTO of a small eye tracking startup gave me a call. I quit Google and joined them. I built a (novel at the time) deep neural net based VR eye tracking system for them, and less than two years later Google acquired us.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512062"><td></td></tr>
                <tr id="38512228"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512228" href="https://news.ycombinator.com/vote?id=38512228&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>That's nothing, the Silicon Valley part is what happened after the acquisition. Google was so paranoid about "user data" that they forced us to delete every scrap of our training datasets, going as far as physically shredding any laptop that had contained the data. We had a memorable evening at the office with the onsite shredder truck. It couldn't shred the MacBooks due to the aluminum case and we ended up smashing them with hammers in the parking lot.<p>When we got to Google of course privacy concerns blocked new data collection until we completed an overengineered project to build a shiny new database with access controls and stuff. About a year later with no technology progress to speak of, the whole eye tracking project was shelved due to a strategy pivot from higher up (unrelated to anything we were doing) and we all went our separate ways. Fun times!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38511495"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511495" href="https://news.ycombinator.com/vote?id=38511495&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not a side project, per say, but I answered questions on my local Linux User Group almost daily. After applying for a job and not hearing back, I got a request to come in for an interview weeks afterwards. Long story short, the boss told me he saw my responses on the mailing list and it turns out I knew more than the RHCEs and CCNAs walking into his interviews.<p>That landed me my first job ever in IT as a Junior NetEng and eventually a Linux SysAd.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512419"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512419" href="https://news.ycombinator.com/vote?id=38512419&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; Not a side project, per say<p>I'd disagree with that. Community building is every bit as much work, and arguably often more impactful than just putting up yet another OSS repo on github.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511772"><td></td></tr>
                <tr id="38512200"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512200" href="https://news.ycombinator.com/vote?id=38512200&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>SO’s … ‘strict’ rules are in part informed by perceived shortcomings in communities that proceeded it. So, imagine something more chaotic :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511815"><td></td></tr>
                        <tr id="38512070"><td></td></tr>
            <tr id="38512378"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512378" href="https://news.ycombinator.com/vote?id=38512378&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>I purchased Dell's original Project Sputnik XPS 13 to be my daily driver and was dismayed at how awful the touchpad was. I couldn't disable tap-to-click, palm detection was terrible, you get the idea. I fixed it so it was bearable to use, upstreamed my patches, and ultimately got a job at Canonical thanks to the connections I made in the process.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512238"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512238" href="https://news.ycombinator.com/vote?id=38512238&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>In 2003/2004, during my undergrad, I observed a recurring trend in the university's IT department. They struggled to retain Unix/Linux engineers for more than three months, primarily due to two reasons: the university's remote location (apparently engineers loved the city life) and the local telecom companies' at the time hired anyone who could type "ls" on a Linux shell. Recognizing an opportunity, I began self-studying FreeBSD and Linux, the operating systems used by the university for their internet services like DNS, email, and proxy servers. Before completing my degree, I applied for the sysadmin position at the uni. In the interviews, I was able to explain and answer even the hardest of questions. I was hired. I eventually went to "ls" elsewhere as well but this role, which I held for eight years, provided me with a foundational knowledge that I believe influences my career even to date!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512346"><td></td></tr>
                  <tr id="38512360"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512360" href="https://news.ycombinator.com/vote?id=38512360&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>It is unclear to me whether this "landed me a job", but in advance of working at big tech, I made a presentation about Smithy (www.smithy.rs), in which there was an engineer in the audience (employed at the same big tech co). I believe he lobbied for my candidacy with the hiring committee.<p>Secondly, before taking my most recent job (at Pinterest), I had just secured a conference talk about Isograph (<a href="https://www.youtube.com/watch?v=gO65JJRqjuc" rel="nofollow noreferrer">https://www.youtube.com/watch?v=gO65JJRqjuc</a>). At both companies where I eventually got offers, I spent a good amount of interview time nerding about Isograph with the interviewers.</p><p>Ultimately, it's unclear if this tipped the balance in any case, but the side projects seemed helpful.</p><p>----</p><p>Previously, while interviewing at a previous place, I showed off a side project to the interviewers, ran into a bug, and deployed a fix in real time. I was later told that they had never seen that. I think I would've gotten that job anyway, though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512221"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512221" href="https://news.ycombinator.com/vote?id=38512221&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Back in around 2004-2005, I was doing contracting work in Australia for a big retailer, maintaining one of their monolithic webapps that was built using C++, believe it or not.  At that time, Ruby on Rails was the new hotness, and I was trying to learn that on the side.<p>When MacOS released their "dashboard widgets" framework back around 2005ish, I wrote a widget for RubyDocs and released it, and it got quite popular.</p><p>At the same time, a US company I heard about via the Rails mailing list was investing pretty heavily in Rails and, as a long shot, I applied there and mentioned I made that widget.  It turns out they were all using it, and they basically gave me a job on the spot working remotely from Australia.</p><p>The experience I got in that job led me to get an job at Microsoft in 2007, and they moved me and my family to Seattle, where I still live to this day, though I left MS over five years ago now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511598"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511598" href="https://news.ycombinator.com/vote?id=38511598&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not really a side project, but I used to be a lot more active on stackoverflow. A recruiter reached out to me through the job board that stackexchange used to host. Been with the job for about 5 years now.<p>Pretty lame that they discontinued that job board. It was a lot nicer experience than using linkedin.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511628"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511628" href="https://news.ycombinator.com/vote?id=38511628&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; Pretty lame that they discontinued that job board.<p>I used to hire people straight off of SO. Sometimes skipping the usual process of they has solid answers to the types of questions we’s ask - went straight for culture fit.</p><p>I think instead of blaming ai and other esoteric reasons for SO’a downfall leadership should look into the damage cancelling the job board has done. People helping others at least had the incentive of being given a job. Now there’s no point really.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511954"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511954" href="https://news.ycombinator.com/vote?id=38511954&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I still like to help people regardless of if it will directly benefit me. It was just a nice perk.<p>Although, since they made all of these controversial changes, it feels less like helping people and more like doing free work for a random company.</p><p>The real killer for me was limiting the data dumps to paying customers. They really let down the community who trusted SO would be a trustworthy steward of the data. The charm of the site is gone.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511929"><td></td></tr>
                  <tr id="38511426"><td></td></tr>
            <tr id="38512363"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512363" href="https://news.ycombinator.com/vote?id=38512363&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was active in various areas of OpenSolaris, contributing to design discussions, code, and code review. Most of this was in the intersection of zones, installation, and zfs. Some were just scratching an itch, like “manwhich”.<p><a href="https://www.illumos.org/opensolaris/ARChive/PSARC/2007/688/mail" rel="nofollow noreferrer">https://www.illumos.org/opensolaris/ARChive/PSARC/2007/688/m...</a></p><p>Once Oracle acquired Sun and hiring started, I was hired into the zones team. While interviewing I discussed my ongoing work on zfs dataset aliasing to virtualize the zfs dataset hierarchy in zones. After being hired I was able to get this feature prioritized to make it into Solaris 11.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512053"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512053" href="https://news.ycombinator.com/vote?id=38512053&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>In 1999 my friend's band wanted to sell their music online and so I looked at the new Microsoft DRM that had just been released (don't kill me!) and set up a test web page. I ended up getting an interview (and a job) with a company that Peter Gabriel had just started as I was practically the only person in the country that had even looked at the SDK.<p>PG gave us an opening to every record label ("Hi, Peter Gabriel would like to come visit and show you something...") where we'd show them we could sell their music legally online. Five minutes after PG leaves each building a team from Apple would show up and show off what <i>they</i> were building too. Their meetings were much shorter as we always did all the heavy lifting first. (Note, we always had to use our own equipment because the MS stuff worked way better on Windows, but all the record labels were like 99% Mac).</p><p>On another one.. it wasn't a side project, but I "hacked" a competition on a popular TV show's web site and they ended up hiring me as the co-presenter o_O
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511532"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511532" href="https://news.ycombinator.com/vote?id=38511532&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I started <a href="https://github.com/thbar/kiba#kiba-etl">https://github.com/thbar/kiba#kiba-etl</a> to scratch my own itch &amp; be able to write properly structured ETL jobs in Ruby. It was a blank-slate rewrite of something larger (activewarehouse-etl) which I could not maintain anymore.<p>This landed me not strictly a job, but long term consulting gigs with a number of companies in EU, UK &amp; US.</p><p>The job was directly related to the project: companies wanted the expertise of data engineering &amp; ETL, often with Kiba directly, but also in general.</p><p>This "side project" was totally worth it :-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512167"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512167" href="https://news.ycombinator.com/vote?id=38512167&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have worked four jobs related to <a href="https://github.com/pion/webrtc">https://github.com/pion/webrtc</a> and one for <a href="https://webrtcforthecurious.com/" rel="nofollow noreferrer">https://webrtcforthecurious.com</a><p>* Amazon was using WebRTC, didn’t care about Pion</p><p>* Apple was the same. Just cared about my knowledge of WebRTC</p><p>* Twitch I joined because they use Pion</p><p>* LiveKit uses Pion and is very open about it!</p><p>Side projects/Open Source has been so beneficial for my career I can’t recommend it enough. It also frees you from defining your career by your employer.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511499"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511499" href="https://news.ycombinator.com/vote?id=38511499&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This game I made and released on iPhone way back in the day directly led to me getting my first full-time job making mobile apps for a startup as the Lead Developer. I showed it during my interview.<p>It's no longer on the App Store as there's just been too many big changes I couldn't keep up with on that codebase. I'm working on a followup right now for Steam that I'd like to port to mobile afterwards.</p><p>Gameplay video: <a href="https://youtu.be/uy08ohBLGhE" rel="nofollow noreferrer">https://youtu.be/uy08ohBLGhE</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511629"><td></td></tr>
                <tr id="38511671"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511671" href="https://news.ycombinator.com/vote?id=38511671&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Hey quick question, how do I get a job at Amazon? ;) jk<p>I love "A job is not everything in someone’s life, but it’s very, very important to love your job." from your article. After a couple burnouts over a decade in this industry, I truly seek positions I at least <i>think</i> I'll love.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512159"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512159" href="https://news.ycombinator.com/vote?id=38512159&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Earlier this year I went to the Australian F1 GP. Between qualifying on Saturday and the race on Sunday I built an integration between a live timing API and Telegram to send me position updates every minute with lap times.<p>This was because anywhere near a screen was packed with crowds and my mobile network couldn’t keep up using the official app.</p><p>I was job searching and wrote it up and posted to LinkedIn. My now manager saw it and was trying to hire for a role building integrations. My project was enough for him to reach out and set up a chat. Without the project we wouldn’t have connected.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512217"><td></td></tr>
                  <tr id="38511432"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511432" href="https://news.ycombinator.com/vote?id=38511432&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span><a href="https://git.gavinhoward.com/gavin/bc" rel="nofollow noreferrer">https://git.gavinhoward.com/gavin/bc</a><p>It got me a C programming job that had nothing to do with the side project.</p><p>I would say that it only helped me in the interview process, but it did so in two ways:</p><p>* I could actually answer C-related questions on top of the more generic questions.</p><p>* It showed that I had skill in C.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512410"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512410" href="https://news.ycombinator.com/vote?id=38512410&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My business partner and I built AsUnit in ~2004. [0]<p>The first fully functional Unit Test framework for ActionScript. It was great fun and helped get my career off the ground.</p><p>[0] <a href="https://asunit.org/" rel="nofollow noreferrer">https://asunit.org</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512261"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512261" href="https://news.ycombinator.com/vote?id=38512261&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This has happened a few times to me.<p>First was some downhill skateboarding projects - a bushing recommendation system and a site that allowed me to search all NZ skate shops from one place.</p><p>A popular US skate shop posted on Reddit looking for interns, but they weren’t interested in  hiring so remotely.</p><p>Fast forward a week and the CTO got in touch to say that he’d interviewed a bunch of dud candidates, and meanwhile had been watching me commit exactly the code they were looking for.</p><p>Ended up contracting with them for a bit building an internal equivalent of the search tool, as well as bushing recommendations integrated with their listings.</p><p>The next is my work in the Cycle.js community (niche FRP JS framework). Mostly worked on trendy dev tools, but also did some valuable work on improving the speed, reliability and clarity of async UI tests that is still arguably close to best-in-class for JS.</p><p>That resulted in multiple job offers and an approach from Manning for a possible book deal, but none of it was that good of a fit.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511424"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511424" href="https://news.ycombinator.com/vote?id=38511424&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Working on cubesat club for my university. Helped me get 2nd round internship interview @ Mr. Beast studios. not sure if this counts since internship + haven't got job yet, but I think it played a big role in helping me advance.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512246"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512246" href="https://news.ycombinator.com/vote?id=38512246&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>My first job was at a hydroponics store. I wanted to grow some fresh fruit in my basement over the winter, and wanted to build the system rather than buying an out-of-the-box one. I asked the owner a few questions about building a system, and got some advice from him. When I came back the second time to get more materials, I was offered a job.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511678"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511678" href="https://news.ycombinator.com/vote?id=38511678&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My contributions to SerenityOS[0] helped me get my current job. My team lead (who was also my interviewer) was interested in what I did since I listed some of it in my CV, and I showed him some PRs I made and explained what went into each of them. It was really exciting because I didn't have professional experience with low-level development, and basically got the job due to hobby programming.<p>[0]: <a href="https://github.com/SerenityOS/serenity/pulls?q=is%3Apr+author%3Asin-ack+is%3Aclosed">https://github.com/SerenityOS/serenity/pulls?q=is%3Apr+autho...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512253"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512253" href="https://news.ycombinator.com/vote?id=38512253&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Way back when the Nintendo Wii was brand new and hard to find, I wrote a script to scrape Target.com for store inventory and notify me if a nearby store restocked. A few years after that I revamped it to check on inventory for newly released iPad models. I put the code up on GitHub [1] and the CTO for a company that had large-scale store inventory checking as part of their product emailed me out of the blue after seeing my repository. A little while later, I replied back, interviewed and got a pretty good job offer out of it. I wound up not taking the offer, but in hindsight I probably should have.<p>[1] <a href="https://github.com/polpo/ipad-target.py">https://github.com/polpo/ipad-target.py</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512405"><td></td></tr>
                  <tr id="38512243"><td></td></tr>
            <tr id="38511799"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511799" href="https://news.ycombinator.com/vote?id=38511799&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>20 years ago, I was a college kid who built a running log website as an alternative to keeping paper records. My college cross-country team lived all over the country, so this let us keep each other accountable during summer training. It was fairly early in the Internet, before GPS watches and not many runners had heart rate straps. It got featured in Women's Health and Runners' World (UK edition) magazines.<p>When I interviewed at Microsoft my senior year, this gave me a ton to talk about. It was real experience building a product and having customers. I could answer questions with something real and different than the other candidates. I know I bombed two of my interviews, but I ended up doing 7 interviews on the day and getting an offer.</p><p>The website is still around, but I haven't done anything to it other than delete the production log that fills up the server disk occasionally in the last 15 years. I don't know why anyone uses it, there are much better options. I still run and I certainly don't use it. But the server bills are cheap, so it lives on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512415"><td></td></tr>
            <tr id="38511441"><td></td></tr>
                <tr id="38511838"><td></td></tr>
                  <tr id="38511703"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511703" href="https://news.ycombinator.com/vote?id=38511703&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>A few years ago I got fed up with then-popular JavaScript linter, JSLint, and forked it to make JSHint. I wouldn't say JSHint was the only criteria that landed me the job but it definitely help when interviewing for positions where JavaScript was important. At the very least, it put my name thru the first filter both at Mozilla and then at Medium.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511666"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511666" href="https://news.ycombinator.com/vote?id=38511666&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My side project NumPad <a href="https://numpad.io/" rel="nofollow noreferrer">https://numpad.io</a> got me my current job at Decipad <a href="https://www.decipad.com/" rel="nofollow noreferrer">https://www.decipad.com/</a> (the similar naming scheme is a coincidence!).<p>I came across Decipad while looking for a job, and messaged the founder, highlighting my work on NumPad. They were impressed enough that the hiring process ended up being just a few interviews, I've been there for almost a year now, and it's been pretty good!</p><p>If there's a moral to this story I think it's that you should aim for work that's highly relevant to your side project experience. In my case both NumPad and Decipad have a sort of programming language that can do calculations with units.</p><p>But ignore this advice if you can't find that work, or it doesn't seem good for whatever reason. You can still highlight your side project in an application, and they might be impressed anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511692"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511692" href="https://news.ycombinator.com/vote?id=38511692&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>It's funny you say this. After struggling to find work (but mostly to find meaningful work), I've committed myself to pursuing jobs related to my curiosities/interests. I didn't really do that before. Over time, I've started to narrow down based off of what I'm genuinely interested in. That way I don't have to lie when I say I'm "passionate" about something I'm working on. :-)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511967"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511967" href="https://news.ycombinator.com/vote?id=38511967&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; I've started to narrow down based off of what I'm genuinely interested in.<p>How do you do that if you’re past work is disconnected from what you’re interested in.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512154"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512154" href="https://news.ycombinator.com/vote?id=38512154&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Maybe it didn't land me a job on its own but it helped in the interview process. I wrote a limited Slay the Spire rules engine[0]. If I could do it again I wouldn't choose PHP, but my current job had an interview round where I walked the hiring manager through something I've written and it did a great job of showcasing a variety of things like writing testable code, separating concerns, making an extensible framework in which to easily implement new cards, etc.<p>In some ways the backend at my current job is slowly coming to resemble some of the patterns I used here, funnily enough.</p><p>[0]: <a href="https://github.com/dgunay/slay">https://github.com/dgunay/slay</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512183"><td></td></tr>
                  <tr id="38512421"><td></td></tr>
            <tr id="38511630"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511630" href="https://news.ycombinator.com/vote?id=38511630&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not really a side project as I was trying to get traction on my ideas at my former employer.<p>I do contract work for a pretty niche industry and after you've done a couple big implementation projects, you've seen 80-90% of all user stories, integrations and edge cases.</p><p>I started a side project that was a combination of tooling, processes, checklists and methodology to stop reimplementing the same project work and stop approaching every client like it was greenfield work. Not fully productizing our approach but moving in that direction.</p><p>My company was not interested. During an interview I pitched my side project ideas and they immediately said they wanted to hire me. Skipped the rest of the hiring process and landed a new role doing exactly what I had wanted to do at my previous company.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511814"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511814" href="https://news.ycombinator.com/vote?id=38511814&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>did you consider making your own company? sounds like a prime opportunity.<p>looking to do the same, would appreciate any insight
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511676"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511676" href="https://news.ycombinator.com/vote?id=38511676&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>At a previous job, my interview was mostly me discussing my side project (and having given some folks on the team my testflight). I had a lot more prepared to talk about previous work projects but it wasn't needed. For context this was for a product design role, but I also built the backend and iOS app.<p>This was the side project that I ended up writing about in more detail later on: <a href="https://paulstamatiou.com/stocketa/" rel="nofollow noreferrer">https://paulstamatiou.com/stocketa/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512265"><td></td></tr>
            <tr id="38511599"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511599" href="https://news.ycombinator.com/vote?id=38511599&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My most recent post about my side project [0] got me some freelancing work as well as an internship for this summer. Project was related to both of them! Unbelievably grateful for the opportunities it’s given me.<p>I’ve got thoughts about the ability for side projects to directly demonstrate not just proficiency, but passion, which is very important in undergrad when looking for opportunities. Might end up writing a blog post about it.</p><p>[0]: <a href="https://news.ycombinator.com/item?id=38252566">https://news.ycombinator.com/item?id=38252566</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511733"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511733" href="https://news.ycombinator.com/vote?id=38511733&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>After discovering Erlang (thanks, Bruce Tate) I started following the community on Twitter and elsewhere, then created the Twitter account ErlangInfo to share news and resources about the language.<p>Because I was following multiple Erlang-related accounts I saw that Basho was hiring a tech evangelist in my region, and while I doubt there was a lot of competition for the role, my side “gig” as ErlangInfo at least didn’t hurt my chances.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512267"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512267" href="https://news.ycombinator.com/vote?id=38512267&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Recently someone reached out because of simdjzon, but I didn't write it, I just made some usage-driven changes and the actual author made me the maintainer on github xd</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511993" href="https://news.ycombinator.com/vote?id=38511993&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>A long time ago I built a business app for the company to replace our existing.  I first ran it in parallel and then had my boss do the same. They loved it and it went into production.<p>Later I applied for a job and all the work I did, backend and frontend and support and database and migrations and reports and visualizations showed my future employer that I knew every stage of work suddenly finding myself moving them into devops.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511648"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511648" href="https://news.ycombinator.com/vote?id=38511648&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>My AI sandbox game <a href="https://www.chesscraft.ca/" rel="nofollow noreferrer">https://www.chesscraft.ca</a> helped me get a great transfer within government to an AI prototyping team at Environment Canada. The job is a bit of a unicorn because it's full remote with tons of freedom.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511724"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511724" href="https://news.ycombinator.com/vote?id=38511724&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Another item (HN won't let me post a long reply), is a programming environment called Onyx.  (After my grandson in Africa, who has NO interest in it whatsoever as he intends to be a pilot -- but this is OK as, unless she works for Airbus, we're ignoring the ladies for a few more years. Sosongo Abasi as his father would say!)  Onyx is a language designed for 13-17 year olds who may not have the best command of English -- we can work in the language of the Igbo, the Yoruba and Erik.  Doesn't matter to my parser.  And it will all be free, documented, Github'ed and built with free tools.  Education is hard over there..</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511715"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511715" href="https://news.ycombinator.com/vote?id=38511715&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have only worked for two companies so far. I got both jobs through my side projects. The first job was my apprenticeship. The second was with a Swiss sensor developer.<p>[0] The first was a Minecraft server software with a web interface similar to an operating system. Players could log in, upload items, xp and trade etc.</p><p>[1] The second was a note-taking app similar to Obsidian, but completely real-time, based on a CRDT (yjs)</p><p>[0] <a href="https://github.com/iojanis/creaftOS">https://github.com/iojanis/creaftOS</a>
[1] <a href="https://lity.cc/" rel="nofollow noreferrer">https://lity.cc</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511781"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511781" href="https://news.ycombinator.com/vote?id=38511781&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>During my physics PhD I built my own Segway (and a second one with a power tool company who came to me after first asking tlb) and did a bunch of projects with a high-power laser cutter that I got funding for in our lab.  I included these on my resume and they were much easier for interviewers to talk to me about than my PhD work.  I think they also helped me stand out a bit.  Receiving positive feedback about these projects gave me confidence to sell myself as someone who could build things.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511784"><td></td></tr>
            <tr id="38511508"><td></td></tr>
            <tr id="38511553"><td></td></tr>
            <tr id="38511848"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511848" href="https://news.ycombinator.com/vote?id=38511848&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>For a few years I devstreamed on Twitch. I got one of my longest running freelance clients when he watched me integrate Django authentication into VueJS which was a part of a web based game I was making. The game didn't go anywhere but Django has been my primary focus for most of my career and that was what I did for the client!</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511910"><td></td></tr>
            <tr id="38511551"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511551" href="https://news.ycombinator.com/vote?id=38511551&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>I built an early HTML5 game engine in 2010 called CraftyJS when Facebook games were starting to become big. The project itself got me the job at a gaming startup and an offer at Zynga.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511864"><td></td></tr>
            <tr id="38511500"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511500" href="https://news.ycombinator.com/vote?id=38511500&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I’ve learned an unbelievable amount trying to systematically invest on my own.<p>All of what I have learned is levered in my career and I’ve utilized that knowledge during all interviews.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511596"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511596" href="https://news.ycombinator.com/vote?id=38511596&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Care to elaborate? Never had the money to invest but have dabbled with some very basic auto trading algos. Long story short, before I learned any math related to gambling, I didn't understand why martingale can't work in gambling or investment. Now I do. :P</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511805"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511805" href="https://news.ycombinator.com/vote?id=38511805&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Even though I haven't used Perl professionally for about 6 years or so, my Perl FOSS work has driven pretty much my entire career. Starting in around 2000 or so, I started producing a lot of Perl modules (libraries). You can see what I've uploaded to CPAN at <a href="https://metacpan.org/author/DROLSKY" rel="nofollow noreferrer">https://metacpan.org/author/DROLSKY</a>.<p>Some of those libraries became _very_ widely used in the Perl community. The number one most used is probably DateTime (<a href="https://metacpan.org/dist/DateTime" rel="nofollow noreferrer">https://metacpan.org/dist/DateTime</a>), and number two is probably (<a href="https://metacpan.org/dist/Log-Dispatch" rel="nofollow noreferrer">https://metacpan.org/dist/Log-Dispatch</a>). But some of the others also got a lot uptake.</p><p>I also contributed a lot to libraries create by others, most notably HTML::Mason and Moose, both of which were very widely used in Perl.</p><p>All of that, plus speaking at the Perl conferences, really helped me develop my professional network. If I recall correctly, all three of of my most recent jobs came about because of my Perl connections to varying degrees. Two of them were just because I posted on my blog that I was looking for work and someone I knew through Perl reached out.</p><p>Today I work in Golang at MongoDB. In 2022, I again posted that I was looking for something new and someone I knew from Perl who worked at MongoDB reached out to me. I'm really thankful he did, because working there has been great!</p><p>Nowadays I don't do much Perl any more, though I still maintain many of my modules (bug fixes and small feature requests only, though). I've also done some Golang (<a href="https://github.com/houseabsolute?q=&amp;type=public&amp;language=go">https://github.com/houseabsolute?q=&amp;type=public&amp;language=go</a>) and Rust (<a href="https://crates.io/users/autarch" rel="nofollow noreferrer">https://crates.io/users/autarch</a>).</p><p>But I think it would be _much_ harder for a young person to do the same things I did. Nowadays there are just so many freaking programmers. Someone invents a new language and five minutes later there are a huge number of foundational libraries for it. By the time I started with Go (mid-2010s), pretty much all the stuff I had done in Perl already existed in Go. And I found the same to be true with Rust when I started using it after Go.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511807"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511807" href="https://news.ycombinator.com/vote?id=38511807&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Is a different millennium did a website advertising a "film" I made with school friends. Hand coded HTML with lots of pre-rendered 3d spinning logos. Total mess that would never have loaded on an average PC but 100% was all that got me my first job.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511507"><td></td></tr>
                <tr id="38511600"><td></td></tr>
            <tr id="38511943"><td></td></tr>
                  <tr id="38512094"><td></td></tr>
            <tr id="38511690"><td></td></tr>
            <tr id="38511962"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511962" href="https://news.ycombinator.com/vote?id=38511962&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>going way back: Science Fair in High School landed me summer internships that rolled over into my first job out of college. ("Science and Engineering Fair" project was building robots with microcontrollers) I think it was the proof that I could do that kind of work in a self directed way that made them notice me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511740"><td></td></tr>
            <tr id="38511708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511708" href="https://news.ycombinator.com/vote?id=38511708&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>For current job, when I started interviewing with them, I mentioned a side project relevant to their space. I didn't learn until a few interviews in that they had started to build basically the same project. Now, that's the project I have been working on exclusively for them.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511626"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511626" href="https://news.ycombinator.com/vote?id=38511626&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was planning to go into grad school for computational biology, but an early Square engineer saw me playing with the thing I'd built on the side of a Waffle House at 2 or 3 AM [1,2].<p>We exchanged numbers, and after six or so months of talking to me, they convinced me to join them instead. I got in early and had a really good exit. Completely changed the course of my life.</p><p>My other passion (apart from biology) was film. I've made a lot of indie films over the last decade, but I always focused on film tech - volumetric video, mocap, etc. I'm currently building a startup in that space that started as one of my side projects. We're doing really well!</p><p>Side projects have <i>always</i> led to inflection points in my life. They have more pull than anything else, and they lead me down interesting problem gradients.</p><p>I'll get back to biology one day. I have some ideas there, too.</p><p>[1] <a href="https://youtu.be/5XTi-jf-ans" rel="nofollow noreferrer">https://youtu.be/5XTi-jf-ans</a></p><p>[2] <a href="https://youtu.be/x034jVB1avs" rel="nofollow noreferrer">https://youtu.be/x034jVB1avs</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512164"><td></td></tr>
            <tr id="38511816"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511816" href="https://news.ycombinator.com/vote?id=38511816&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This is cool. If it were written into some movie I’d accuse the writer of lazy writing. Kudos to you.<p>A similar coincidence happened to me early career. I had finished an internship, wasn’t sure what to do full time after, and ran into my old boss in a grocery store. He had been impressed with my internship work and seeing me reminded him of me and we started talking, soon enough he invited me to be employee #6 at his new venture. It worked out really well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gron: Make JSON greppable (111 pts)]]></title>
            <link>https://github.com/tomnomnom/gron</link>
            <guid>38511077</guid>
            <pubDate>Sun, 03 Dec 2023 21:45:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tomnomnom/gron">https://github.com/tomnomnom/gron</a>, See on <a href="https://news.ycombinator.com/item?id=38511077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">gron</h2>
<p dir="auto"><a href="https://travis-ci.org/tomnomnom/gron" rel="nofollow"><img src="https://camo.githubusercontent.com/35f67e5eeb8835ca757873718707461f5bf4fd23e98f3c53de000347f5128850/68747470733a2f2f7472617669732d63692e6f72672f746f6d6e6f6d6e6f6d2f67726f6e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tomnomnom/gron.svg?branch=master"></a></p>
<p dir="auto">Make JSON greppable!</p>
<p dir="auto">gron transforms JSON into discrete assignments to make it easier to <code>grep</code> for what you want and see the absolute 'path' to it.
It eases the exploration of APIs that return large blobs of JSON but have terrible documentation.</p>
<pre>▶ <b>gron</b> "https://api.github.com/repos/tomnomnom/gron/commits?per_page=1" | fgrep "commit.author"
json[0].commit.author = {};
json[0].commit.author.date = "2016-07-02T10:51:21Z";
json[0].commit.author.email = "mail@tomnomnom.com";
json[0].commit.author.name = "Tom Hudson";
</pre>
<p dir="auto">gron can work backwards too, enabling you to turn your filtered data back into JSON:</p>
<pre>▶ gron "https://api.github.com/repos/tomnomnom/gron/commits?per_page=1" | fgrep "commit.author" | <b>gron --ungron</b>
[
  {
    "commit": {
      "author": {
        "date": "2016-07-02T10:51:21Z",
        "email": "mail@tomnomnom.com",
        "name": "Tom Hudson"
      }
    }
  }
]
</pre>
<blockquote>
<p dir="auto">Disclaimer: the GitHub API has fantastic documentation, but it makes for a good example.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">gron has no runtime dependencies. You can just <a href="https://github.com/tomnomnom/gron/releases">download a binary for Linux, Mac, Windows or FreeBSD and run it</a>.
Put the binary in your <code>$PATH</code> (e.g. in <code>/usr/local/bin</code>) to make it easy to use:</p>
<div data-snippet-clipboard-copy-content="▶ tar xzf gron-linux-amd64-0.1.5.tgz
▶ sudo mv gron /usr/local/bin/"><pre><code>▶ tar xzf gron-linux-amd64-0.1.5.tgz
▶ sudo mv gron /usr/local/bin/
</code></pre></div>
<p dir="auto">If you're a Mac user you can also <a href="http://braumeister.org/formula/gron" rel="nofollow">install gron via brew</a>:</p>

<p dir="auto">Or if you're a Go user you can use <code>go install</code>:</p>
<div data-snippet-clipboard-copy-content="▶ go install github.com/tomnomnom/gron@latest"><pre><code>▶ go install github.com/tomnomnom/gron@latest
</code></pre></div>
<p dir="auto">It's recommended that you alias <code>ungron</code> or <code>norg</code> (or both!) to <code>gron --ungron</code>. Put something like this in your shell profile (e.g. in <code>~/.bashrc</code>):</p>
<div data-snippet-clipboard-copy-content="alias norg=&quot;gron --ungron&quot;
alias ungron=&quot;gron --ungron&quot;"><pre><code>alias norg="gron --ungron"
alias ungron="gron --ungron"
</code></pre></div>
<p dir="auto">Or you could create a shell script in your $PATH named <code>ungron</code> or <code>norg</code> to affect all users:</p>

<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">Get JSON from a file:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json 
json = {};
json.contact = {};
json.contact.email = &quot;mail@tomnomnom.com&quot;;
json.contact.twitter = &quot;@TomNomNom&quot;;
json.github = &quot;https://github.com/tomnomnom/&quot;;
json.likes = [];
json.likes[0] = &quot;code&quot;;
json.likes[1] = &quot;cheese&quot;;
json.likes[2] = &quot;meat&quot;;
json.name = &quot;Tom&quot;;"><pre><code>▶ gron testdata/two.json 
json = {};
json.contact = {};
json.contact.email = "mail@tomnomnom.com";
json.contact.twitter = "@TomNomNom";
json.github = "https://github.com/tomnomnom/";
json.likes = [];
json.likes[0] = "code";
json.likes[1] = "cheese";
json.likes[2] = "meat";
json.name = "Tom";
</code></pre></div>
<p dir="auto">From a URL:</p>
<div data-snippet-clipboard-copy-content="▶ gron http://headers.jsontest.com/
json = {};
json.Host = &quot;headers.jsontest.com&quot;;
json[&quot;User-Agent&quot;] = &quot;gron/0.1&quot;;
json[&quot;X-Cloud-Trace-Context&quot;] = &quot;6917a823919477919dbc1523584ba25d/11970839830843610056&quot;;"><pre><code>▶ gron http://headers.jsontest.com/
json = {};
json.Host = "headers.jsontest.com";
json["User-Agent"] = "gron/0.1";
json["X-Cloud-Trace-Context"] = "6917a823919477919dbc1523584ba25d/11970839830843610056";
</code></pre></div>
<p dir="auto">Or from <code>stdin</code>:</p>
<div data-snippet-clipboard-copy-content="▶ curl -s http://headers.jsontest.com/ | gron
json = {};
json.Accept = &quot;*/*&quot;;
json.Host = &quot;headers.jsontest.com&quot;;
json[&quot;User-Agent&quot;] = &quot;curl/7.43.0&quot;;
json[&quot;X-Cloud-Trace-Context&quot;] = &quot;c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147&quot;;"><pre><code>▶ curl -s http://headers.jsontest.com/ | gron
json = {};
json.Accept = "*/*";
json.Host = "headers.jsontest.com";
json["User-Agent"] = "curl/7.43.0";
json["X-Cloud-Trace-Context"] = "c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147";
</code></pre></div>
<p dir="auto">Grep for something and easily see the path to it:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep twitter
json.contact.twitter = &quot;@TomNomNom&quot;;"><pre><code>▶ gron testdata/two.json | grep twitter
json.contact.twitter = "@TomNomNom";
</code></pre></div>
<p dir="auto">gron makes diffing JSON easy too:</p>
<div data-snippet-clipboard-copy-content="▶ diff <(gron two.json) <(gron two-b.json)
3c3
< json.contact.email = &quot;mail@tomnomnom.com&quot;;
---
> json.contact.email = &quot;contact@tomnomnom.com&quot;;"><pre><code>▶ diff &lt;(gron two.json) &lt;(gron two-b.json)
3c3
&lt; json.contact.email = "mail@tomnomnom.com";
---
&gt; json.contact.email = "contact@tomnomnom.com";
</code></pre></div>
<p dir="auto">The output of <code>gron</code> is valid JavaScript:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json > tmp.js
▶ echo &quot;console.log(json);&quot; >> tmp.js
▶ nodejs tmp.js
{ contact: { email: 'mail@tomnomnom.com', twitter: '@TomNomNom' },
  github: 'https://github.com/tomnomnom/',
  likes: [ 'code', 'cheese', 'meat' ],
  name: 'Tom' }"><pre><code>▶ gron testdata/two.json &gt; tmp.js
▶ echo "console.log(json);" &gt;&gt; tmp.js
▶ nodejs tmp.js
{ contact: { email: 'mail@tomnomnom.com', twitter: '@TomNomNom' },
  github: 'https://github.com/tomnomnom/',
  likes: [ 'code', 'cheese', 'meat' ],
  name: 'Tom' }
</code></pre></div>
<p dir="auto">It's also possible to obtain the <code>gron</code> output as JSON stream via
the <code>--json</code> switch:</p>
<div data-snippet-clipboard-copy-content="▶ curl -s http://headers.jsontest.com/ | gron --json
[[],{}]
[[&quot;Accept&quot;],&quot;*/*&quot;]
[[&quot;Host&quot;],&quot;headers.jsontest.com&quot;]
[[&quot;User-Agent&quot;],&quot;curl/7.43.0&quot;]
[[&quot;X-Cloud-Trace-Context&quot;],&quot;c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147&quot;]"><pre><code>▶ curl -s http://headers.jsontest.com/ | gron --json
[[],{}]
[["Accept"],"*/*"]
[["Host"],"headers.jsontest.com"]
[["User-Agent"],"curl/7.43.0"]
[["X-Cloud-Trace-Context"],"c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147"]
</code></pre></div>
<h2 tabindex="-1" dir="auto">ungronning</h2>
<p dir="auto">gron can also turn its output back into JSON:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | gron -u
{
  &quot;contact&quot;: {
    &quot;email&quot;: &quot;mail@tomnomnom.com&quot;,
    &quot;twitter&quot;: &quot;@TomNomNom&quot;
  },
  &quot;github&quot;: &quot;https://github.com/tomnomnom/&quot;,
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ],
  &quot;name&quot;: &quot;Tom&quot;
}"><pre><code>▶ gron testdata/two.json | gron -u
{
  "contact": {
    "email": "mail@tomnomnom.com",
    "twitter": "@TomNomNom"
  },
  "github": "https://github.com/tomnomnom/",
  "likes": [
    "code",
    "cheese",
    "meat"
  ],
  "name": "Tom"
}
</code></pre></div>
<p dir="auto">This means you use can use gron with <code>grep</code> and other tools to modify JSON:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep likes | gron --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron testdata/two.json | grep likes | gron --ungron
{
  "likes": [
    "code",
    "cheese",
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">or</p>
<div data-snippet-clipboard-copy-content="▶ gron --json testdata/two.json | grep likes | gron  --json --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron --json testdata/two.json | grep likes | gron  --json --ungron
{
  "likes": [
    "code",
    "cheese",
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">To preserve array keys, arrays are padded with <code>null</code> when values are missing:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep likes | grep -v cheese
json.likes = [];
json.likes[0] = &quot;code&quot;;
json.likes[2] = &quot;meat&quot;;
▶ gron testdata/two.json | grep likes | grep -v cheese | gron --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    null,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron testdata/two.json | grep likes | grep -v cheese
json.likes = [];
json.likes[0] = "code";
json.likes[2] = "meat";
▶ gron testdata/two.json | grep likes | grep -v cheese | gron --ungron
{
  "likes": [
    "code",
    null,
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">If you get creative you can do <a href="https://github.com/tomnomnom/gron/blob/master/ADVANCED.mkd">some pretty neat tricks with gron</a>, and
then ungron the output back into JSON.</p>
<h2 tabindex="-1" dir="auto">Get Help</h2>
<div data-snippet-clipboard-copy-content="▶ gron --help
Transform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable

Usage:
  gron [OPTIONS] [FILE|URL|-]

Options:
  -u, --ungron     Reverse the operation (turn assignments back into JSON)
  -v, --values     Print just the values of provided assignments
  -c, --colorize   Colorize output (default on tty)
  -m, --monochrome Monochrome (don't colorize output)
  -s, --stream     Treat each line of input as a separate JSON object
  -k, --insecure   Disable certificate validation
  -j, --json       Represent gron data as JSON stream
      --no-sort    Don't sort output (faster)
      --version    Print version information

Exit Codes:
  0	OK
  1	Failed to open file
  2	Failed to read input
  3	Failed to form statements
  4	Failed to fetch URL
  5	Failed to parse statements
  6	Failed to encode JSON

Examples:
  gron /tmp/apiresponse.json
  gron http://jsonplaceholder.typicode.com/users/1 
  curl -s http://jsonplaceholder.typicode.com/users/1 | gron
  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron"><pre><code>▶ gron --help
Transform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable

Usage:
  gron [OPTIONS] [FILE|URL|-]

Options:
  -u, --ungron     Reverse the operation (turn assignments back into JSON)
  -v, --values     Print just the values of provided assignments
  -c, --colorize   Colorize output (default on tty)
  -m, --monochrome Monochrome (don't colorize output)
  -s, --stream     Treat each line of input as a separate JSON object
  -k, --insecure   Disable certificate validation
  -j, --json       Represent gron data as JSON stream
      --no-sort    Don't sort output (faster)
      --version    Print version information

Exit Codes:
  0	OK
  1	Failed to open file
  2	Failed to read input
  3	Failed to form statements
  4	Failed to fetch URL
  5	Failed to parse statements
  6	Failed to encode JSON

Examples:
  gron /tmp/apiresponse.json
  gron http://jsonplaceholder.typicode.com/users/1 
  curl -s http://jsonplaceholder.typicode.com/users/1 | gron
  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron
</code></pre></div>
<h2 tabindex="-1" dir="auto">FAQ</h2>
<h3 tabindex="-1" dir="auto">Wasn't this written in PHP before?</h3>
<p dir="auto">Yes it was! The original version is <a href="https://github.com/tomnomnom/gron/blob/master/original-gron.php">preserved here for posterity</a>.</p>
<h3 tabindex="-1" dir="auto">Why the change to Go?</h3>
<p dir="auto">Mostly to remove PHP as a dependency. There's a lot of people who work with JSON who don't have PHP installed.</p>
<h3 tabindex="-1" dir="auto">Why shouldn't I just use jq?</h3>
<p dir="auto"><a href="https://stedolan.github.io/jq/" rel="nofollow">jq</a> is <em>awesome</em>, and a lot more powerful than gron, but with that power comes
complexity. gron aims to make it easier to use the tools you already know, like <code>grep</code> and <code>sed</code>.</p>
<p dir="auto">gron's primary purpose is to make it easy to find the path to a value in a deeply nested JSON blob
when you don't already know the structure; much of jq's power is unlocked only once you know that structure.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Placeholder Girlfriend (164 pts)]]></title>
            <link>https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend</link>
            <guid>38510997</guid>
            <pubDate>Sun, 03 Dec 2023 21:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend">https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend</a>, See on <a href="https://news.ycombinator.com/item?id=38510997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg" width="1365" height="828" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:828,&quot;width&quot;:1365,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:404539,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>I had the feeling I was a placeholder girlfriend. That once the winter was over she wouldn’t need me anymore.&nbsp;</p><p>I had this feeling because it hadn’t started like my other relationships. I’d kept seeing her at parties with all the Toronto grad students that autumn and thought she was so different from me. Whatever the opposite of basic is. Advanced? I had the feeling she didn’t even own sweatpants, if that makes sense. She’d see me across the party and would watch me but wouldn’t return my waves. Somehow she found out I had a crush on her and it didn’t change anything. Just the stare, maybe a polite nod, then she’d go back to half-listening to whoever was trying to impress her. She was beautiful like an ice sculpture is beautiful.</p><p>I knew her thesis was on Italian autonomist feminism of the 1970s. I had no idea what that meant so I never risked talking to her and embarrassing myself. My thesis was on the history of memes. I wanted to change it but didn’t know what else I could talk about.&nbsp;</p><p>Then one night she called me. The wind of the first real snowstorm whistled through my window and made me cover my other ear while I listened to her talk to me for the first time. She told me she found me really pretty. That she’d always admired me from a distance. And would I come over?</p><p>We didn’t talk much that night or any night after. But on the subway back to my apartment in North York the next morning, in between games of Candy Crush, I realized we were going out. I had a nagging feeling I couldn’t explain though. Before she’d kissed me she’d told me that she’d been in a long distance relationship and they’d broken up that day. It flattered me that I was who she called but it wasn’t exactly romantic.&nbsp;</p><p>I only worried I was a placeholder girlfriend in the back of my mind though, like when I woke up or when videos were loading. It became real when I saw the list. When I saw the rubric.</p><p>She had been at the university and needed files off her computer. I was lazing around in her living room. I had four roommates and she had none. I should have been working on my thesis, but I enjoyed being in an apartment without roommates so much that I was just laying around listening to my Harry Potter podcasts. I didn’t know if she had rent control or was just rich but she did have an office. She was like what I imagined a grad student should be. She had me go into her office and she walked me through transferring the files. But she had left a spreadsheet open.</p><p>I tried not to look but I think that’s actually impossible. Because I saw my name at the top. And I saw numbers and a whole column of red cells. And then it clicked.</p><p>If you saw a sheet rating you in bed out of 10, with a hundred other ratings too, you would look. You would peek.</p><p>“Hey?” she said over the phone. “Did it go through?”</p><p>“Oh,” I said. I clicked through the remaining buttons. “Yeah. Yeah. There should be an email.” I swallowed dryly. “You should have everything.”</p><p>“Awesome. Okay, got it. Gotta run, bye!”</p><p>Then I was left with the sheet.</p><p>I tried not to keep reading. I tried to tell myself it was private. But it wasn’t. It was about me, so it wasn’t private. And then when I started to read it, started understanding what the numbers meant, I tried to tell myself I’d seen enough, I didn’t need to keep reading. But I did. I couldn’t stop.</p><p><em>Humor </em><strong>2.0</strong></p><p><em>Movie Taste </em><strong>5.0</strong></p><p><em>Love-making </em><strong>6.5</strong></p><p>I scrolled and scrolled. There were a hundred cells and almost every one was red. Almost every mark was shitty. The only green was:&nbsp;</p><p><em>Beauty </em><strong>8.0</strong></p><p><span>The fact that that was the only one where I passed made the whole thing even worse. Everything cut me. </span><em>Gift-giving. Punctuality. Memory.</em><span> The notes beside them only hurt more (“only funny unintentionally”, “un-self-aware Harry Potter nostalgia”, “Pillow princess”). I was mortified but I couldn’t stop reading. It even seemed like there were categories specifically invented to hurt me (</span><em>Freckles</em><strong>: 2</strong><span>). And there were others with entirely no explanation, just there to haunt (</span><em>Friends: </em><strong>4.5</strong><span>).</span></p><p><span>The worst part was that it all seemed true. It became clear as soon as I read it. I wasn’t smart enough (</span><strong>5.0</strong><span>) to create a narrative where I was actually a really good listener, I had just always hidden from myself the fact that I was a bad listener (</span><strong>3.0</strong><span>). My entire personality was getting pulled back like a hangnail.&nbsp;</span></p><p>My mind raced through thoughts until it settled on three it repeated over and over and over:</p><ul><li><p>Your girlfriend should think of you as a ten in everything.&nbsp;</p></li><li><p>No. You aren’t even supposed to think these things.</p></li><li><p>Why doesn’t she just break up with me?</p></li></ul><p>It burned through me until, finally, I reached the bottom. Then I truly broke down, staring at the big, bold, red cell:&nbsp;</p><p><strong>Status: Temporary</strong></p><p><span>If I had any </span><em>Imagination</em><span> (another </span><strong>2.0</strong><span>) I’d say something like: it made me feel like the sun laying down its judgment upon one of the barren and useless planets near it. But all I could really say is: it made me want to die. It made me cry huge gobby tears all over her desk and I should have realized that would happen because I was too </span><em>Emotional</em><span> (</span><strong>4.0</strong><span>). It made me wail like a child on the floor of her stupid, parent-paid office.</span></p><p>After minutes of this, it made me want revenge.&nbsp;</p><p>For one horrible second I contemplated killing her but that was wildly out of proportion and then I tried to pretend that I had only wished she was dead and then I just tried to forget about it.</p><p>My mom says that the best revenge is a life well lived. When I met my dad I asked him about that and he laughed oddly loudly and said once you’re thinking about getting revenge it’s too late to have a good life. Then he took pictures with me and the zoo pandas behind us and I never saw him again.</p><p><span>When I tried imagining a good life I couldn’t. I couldn’t imagine going to work thinking about my </span><em>Work ethic </em><span>(</span><strong>2.5</strong><span>) or </span><em>Problem-solving</em><span> (</span><strong>5.5</strong><span>) or </span><em>Punctuality</em><span> (</span><strong>4.0</strong><span>). I couldn’t imagine going to a party ever again with my lack of </span><em>Fashion</em><span> (</span><strong>6.0</strong><span>) and </span><em>Wit</em><span> (</span><strong>2.0</strong><span>). I’d always imagined that if I was on the run for a crime I’d hide away as a nun, but even that wouldn’t work because I had no </span><em>Patience</em><span> (</span><strong>3.0</strong><span>).</span></p><p>But then I realized that I hadn’t understood what a good life could be. I hadn’t been thinking about just how good life could be.&nbsp;</p><p><span>It’s all just numbers. It’s all just 1 to 10 (besides the 0 I got for math). If I changed, if I got everything to a 10, wouldn’t that mean that her wisdom was low? What I mean is, wouldn’t that show what an idiot she was? Right now if I told anybody about the list they’d think she was a monster. But they’d also know she was right and would reflect on how pathetic I was. But if I revealed the list after becoming a 10 in everything they’d think about how pathetic </span><em>she</em><span> was. An idiot and</span><em> </em><span>a monster. They’d say to me: who’s that girl you’re with? Is she your placeholder girlfriend? They’d say that to </span><em>me.</em></p><p><span>I got up off the floor. I went to the computer. I scrolled back to ambition, way at the beginning of her hundred row sheet. Its </span><strong>2.5</strong><span> stared at me. I changed it to a </span><strong>10</strong><span>.</span></p><p>The first thing I decided to learn was how to learn. I had to learn a lot of things so I had to do it fast and right. It was the beginning of winter and I wanted to emerge in spring like a cherry blossom or whatever kind of blossoms happen in spring. I wanted her to melt in embarrassment like the snow.</p><p>The problem was that I knew my mind just didn’t work like that. It liked going slowly. And detours. But I knew it was possible to change how your mind works, like melting an old ring into a pretty one. I went to some of the grad students and bought up the hallucinogens they were researching. Then I put all of them as far back on my tongue as I could, swallowed two big glasses of water, sat in my lightless room with my headphones on, and willed myself to become a good learner. I imagined squeezing my brain like play-doh until I could be like those robots that learn things faster than any human and it makes them powerful beyond belief.</p><p>Over the next 12 hours my mind split apart. When it reformed, it reformed softer. More ready. More malleable.</p><p><span>When I went back to the grad students the next day to swear them in as my practice partners, they joked they were worried about me but I could tell they were intrigued. Internally I changed my </span><em>Interesting</em><span> score from </span><strong>1.0</strong><span> to </span><strong>10</strong><span>.&nbsp;</span></p><p>Then began the work.</p><p>If you like, imagine a training montage. I really like the one in Harry Potter and the Order of the Phoenix when they’re all getting good at spells together. I knew I needed my own team but it had to be a secret. I had to take her by surprise. I’d meet my partners in hidden classrooms, prayer rooms, their apartments.&nbsp;</p><p>The grad students were all so curious and I knew I could use it. I swore each of them individually into secrecy. They all hated working on their theses. They were all bundled up in little apartments around the university waiting for spring like hibernating bears. It was like I could give them one little dream they didn’t understand but would always remember.</p><p><span>One guy was my </span><em>Humor</em><span> partner. I admitted to him that I didn’t really get jokes. I would just watch for other peoples’ reactions and nobody ever noticed me laughing a little late. He explained that it’s mostly about timing and the unexpected and being animated. “Like this?” I said, a little loudly and suddenly. He laughed, which I thought was good, but he said “No, you need energy. People aren’t entertained by a rock.”</span></p><p><span>So we drilled it. “Ayyyy babe,” I’d say as I walked in to a session, or “Yo!” Then I’d tease him, or myself, or our crazy mayor. I had a running joke with him about the snow (“What if we put all the global warming in Toronto?”). Very soon, he was chortling and sometimes outright laughing. </span><strong>10</strong><span>.</span></p><p><span>One girl was my </span><em>Culture</em><span> partner. I explained that I needed to become “cultured”. She asked what I meant and I admitted I didn’t know. Well, I had just come from a joke session, so what I said was “I was hoping you could tell me!” She laughed. But then she assigned me reading.</span></p><p>I had become very good at reading. Before my dark night of the soul I had only been seeing words. After that I saw ideas. I could rotate them and connect them like Lego. Reading the words was now as easy as grabbing a big handful of Lego.&nbsp;</p><p><span>I read through poetry and fiction and commentary and letters from this century and many others. The letters were my favourite because the writers didn’t take them as seriously as the books. I was big into not taking things too seriously now. Before it had bothered me that I was low on both </span><em>Ambition</em><span> and </span><em>Chill</em><span> (</span><strong>6.0</strong><span>). But now I was at </span><strong>10</strong><span> for both. I was going to humiliate my evil girlfriend. But I was chill about it because I knew it would happen.&nbsp;</span></p><p>My favourite writers were not chill. They were fucked up. I remembered that my girlfriend’s favourite writer was Sylvia Plath so I got really into her husband and the people Plath admired and considered better than her.&nbsp;</p><p><span>This didn’t take long at all. When my writing conspirator asked about my thesis on memes, I explained memetic contagion instead, including an aside on Burroughs’s assertion that language is a virus from outer space. When she asked which Beatle was best, I proved that Yoko Ono was superior. She was delighted. “I don’t know what’s going on with you. But would you review my novel when it’s ready?” I said yes, of course. </span><em>Culture</em><span>: </span><strong>10</strong><span>. And a bonus to </span><em>Selflessness</em><span> as well.</span></p><p><span>Both of those were hours in the morning. I wasn’t working on my thesis anymore. It could wait until spring. Instead I was doing eight sessions a day. When I solved a trait another one came in. At the bottom of winter, when the sun only peeks out at noon and then retreats, I added </span><em>Lovemaking</em><span>. I found a guy I had hooked up with in first year and told him I wanted to make love every weekday at 3PM. I wanted to become the best lover he could ever imagine. Because my thoughtfulness score was going up I asked him: How did that make him feel? Did any reservations come to mind? Would he like to take a few days to think about it?</span></p><p><span>He replied "Nah I'm down." So we began. I will spare you details about our progress. I will say that at first he didn’t understand the feedback phase but he came to appreciate it. I will say that he became a </span><strong>10</strong><span> lover as well.&nbsp;</span></p><p>Throughout all of this I saw my girlfriend less but not so little she’d dump me. I hid all my new powers besides the lovemaking from her. I knew that that would draw her in because she was shallow. Only shallow people make a sheet. Only shallow people rate their girlfriend’s tenderness out of 10.</p><p><span>Or at least that’s how I thought at first. Each time I hit a </span><strong>10</strong><span> I’d think about what number she’d have. She didn’t have much </span><em>Humor </em><span>either, maybe a </span><strong>5</strong><span>. She wasn’t that </span><em>Chill</em><span> — if you have a home office and desk and two monitors you aren’t </span><em>Chill</em><span>. She was only a </span><strong>10</strong><span> lover when I was a </span><strong>10</strong><span> lover with her.&nbsp;</span></p><p>Those were the hardest moments. We’d lay there gasping and I’d always tell her I’d need to clean up. But in the washroom I’d just shake and open the window and let the Toronto winter dive into my lungs and I’d wonder if I was doing the right thing. I was becoming a more thoughtful person and I knew revenge was wrong. I knew I didn’t wish my pain on anybody so why was I making an exception for her?&nbsp;</p><p><span>But I had to keep going. I had become a </span><strong>10</strong><span> in so many things that I couldn’t stop now. Thoughtfulness could be the last thing. I could even finish it a little after my big reveal. Not yet. Part of my thoughtfulness was realizing that nobody is perfect.</span></p><p>But I was getting there. I was closing in, more relentless than the blizzards that year, which came down like snow dumped from buckets.&nbsp;</p><p>I knew I was still emotional. My partner for that was an econ student. We met in her apartment on St. George Street just north of the university. I’d originally chosen her because I’d assumed an econ student would be more emotionally stable than all the humanities grads I knew. Honestly, I thought she’d be boring. I didn’t know how passionate she was.&nbsp;</p><p>She showed me pictures of dying animals and the horrible stories of how they’d become separated from their mothers. It made me weep.&nbsp;</p><p>She explained that people mostly donate to their universities and churches but for a little money you could save a child from a horrible death. It made me rage at people’s ignorance.&nbsp;</p><p>Finally, I made her tell me a story about a woman named Alice who rated her girlfriend Roberta and rated her badly. I wanted to be so emotionally strong that I could handle the greatest embarrassment of my life. But I couldn’t. It made me leave the session and wander the Annex pretending I was somebody else.</p><p>For a few days I tried becoming emotionless about these. I tried turning all my emotions off like taps. She realized what was going on. “Look. I can tell you’re still emotional even if you’re trying not to show it”. I was impressed by her wisdom. “You can have emotional responses,” she continued. “It’s healthy. These are horrible things. You just need to not let it ruin you. You need to have a plan for how to deal with it.”</p><p>The next day, when she showed me a dying bird, a single tear ran down my eye. I said: “We humans should disrupt the natural environment less.”&nbsp;</p><p>Then she showed me a child dying of malaria. I shook my head and said “Humans should try to be as effective with their charitable giving as they are with their big purchases. We have so much potential to do good in the world.”</p><p>Then she told me the story of the cruel girlfriend Alice again like I'd asked. She didn’t know it was my story, of course, but she was a good storyteller and some of the details were correct. She had Roberta (me) sobbing and everything.</p><p>When she finished I was proud. I had lasted through the whole thing. I had cried but not loudly, just little hiccup-y gasps. I looked up at her and said: "Roberta should get revenge."</p><p>“Revenge?” She looked surprised. “I get something like… I don’t know, but revenge is a leap.”</p><p>“Why not?” I asked. “Alice hurt her more than should even be possible.” The sky in the apartment windows was blue, a March-bright blue, and the glare made it hard for me to focus on her eyes, which were brighter than anybody’s I’d stared into all winter.</p><p>“Yeah but like. This says way more about her than about her girlfriend.”</p><p>“What?”</p><p>“Alice is crazy. If you make a sheet ranking a hundred attributes of your lover, you’re crazy, right?”</p><p>“Yeah, so?”</p><p>“So why would Roberta trust or care what Alice says about her? Why would Alice have a clue about any of this? I don’t think Alice knows the first thing about anything.”</p><p>I stopped myself from telling her I knew it was all true. I stopped myself from explaining that my girlfriend had known me better than I’d known myself. I was open mouthed and had nothing to say.</p><p>“Honestly, I feel sad for Alice, she’s so confused,” she continued. “I’d feel even worse for her if Roberta humiliated her. Would it be at a party or something? That would just suck.”</p><p>I stopped myself from telling her the contents of my revenge. But she was right. I had imagined it culminating in a party. I had imagined becoming the life of the party. In my first year I didn’t know anything about alcohol and when we played beer pong I was drinking pure vodka and I became drunker than anything and I suppose technically I was the life of the party because I got crazy nicknames that night. But this wouldn’t be like that at all. I’d actually be the life of the party. I’d be so interesting that people would tell each other they were going to the washroom but instead they’d come see me. If anybody got too drunk I’d lend them my spare room and appoint two trustworthy watchers. When, I’d return I’d turn it into a dance party complete with the playlist I’d been making for months. I would grab men and women and bring them to dance with me and I’d dance so well they wouldn’t be afraid to dance well too. I would make sure everybody would leave the party feeling not just that they were lucky to be there, but that I felt lucky to have them. Then I would retire with my girlfriend. I would make love to her perfectly. Then, a little while later, I would tell her she was a monster, that I was done with her, and I would call her a cab and I would never see her again.&nbsp;</p><p>I looked up at my friend now. She was waiting patiently, smiling slightly. She hadn’t judged me when I cried about the bird. She had held my hand when she told me about effective charity. Right now her long black hair was falling into her eyes the way it did when it leaned forward. I did not know if the shape of her body was beautiful under her layers but I knew the way she moved was beautiful. I began to get a curious feeling.</p><p><span>Then something horrible came over me. Numbers began floating into my mind. </span><em>Thoughtfulness</em><span>: </span><strong>10</strong><span>. </span><em>Interestingness</em><span>: </span><strong>8.0</strong><span>. </span><em>Beauty</em><span>: </span><strong>8.0</strong><span>.</span></p><p>I stood in terror and she looked surprised.&nbsp;</p><p>“Would you be around tonight?” I asked suddenly. “There’s something I have to finish. To end. Right now.”</p><p>Of course, she said. She’d be around tonight.</p><p>Winter was ending early. I ran through the campus and overheated and had to fold more and more layers to carry under my arms. I almost slipped on the melting and glistening sidewalks but I made it to my girlfriend’s house out of breath and red in the face.&nbsp;</p><p>It was not how I had imagined it. Her eyebrows rose and she looked me up and down as I panted on her porch.</p><p>“I need you to be honest,” I said. A screen separated us and I knew the same way I was constructing her image separated by the little squares of mesh, she was constructing her judgment of me out of all her tiny stupid spreadsheet cells.</p><p>Before she could reply, I said it: “I’m just your placeholder girlfriend.”</p><p>Her lips pursed and she couldn’t look at me anymore. I hadn’t asked her a question. She looked at the sidewalk and at the porch. She looked anywhere else. Then she slowly came back to me.</p><p>“I guess so. I guess you were.”</p><p>I couldn't reply. I registered that she hadn’t apologized.</p><p>“You found my sheet, didn’t you? I saw the ambition edit.”</p><p><span>Then I remembered way back at the beginning when I’d changed the </span><em>Ambition</em><span> rating to </span><strong>10</strong><span>. It had been a mistake, one I wouldn’t make now. I nodded.</span></p><p>She shrugged. “I like being real with myself about where I’m at. So I do those sheets. I’m sorry you saw it. But I can tell you’ve been working on things. I’ve admired it. The sex is great. I don’t think you’re a placeholder anymore.”</p><p>I felt several paths in front of me. I almost told her I needed a better apology. I almost told her I had hidden how much I had changed, I was basically a 10 in everything now. I almost told her she had hurt me more than she ever could have imagined.</p><p>This is what I did instead: I told her I was sorry she needed that. Then I kissed her cheek like the moon kisses the sun at the end of an eclipse. Then I left. Then I was gone.&nbsp;</p><p>It was not sweet. It was not the crowning achievement of my winter. It was just done.&nbsp;</p><p>That night I got coffee with my new friend. When her hair fell in front of her eyes, I moved it back. When she asked if everything was okay and I told her it was good now, I could feel the warmth of her happiness radiate across the table. When the date ended, I asked to see her again the next day. We could go to the ceramics museum down the street and I’d buy her blue china from the gift store where the old ladies slowly wrap and tie in layers and layers of bubble wrap. We could walk through the Annex and pick whichever restaurant was newest. We could go through High Park, through the zoo and meet the reindeer, who make me think of Christmas, and the peacocks, who make me think of the sun.&nbsp;</p><p>We decided to do it all. We were happy. I never thought about revenge again.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's learn how modern JavaScript frameworks work by building one (243 pts)]]></title>
            <link>https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/</link>
            <guid>38510209</guid>
            <pubDate>Sun, 03 Dec 2023 20:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/">https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/</a>, See on <a href="https://news.ycombinator.com/item?id=38510209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><img data-attachment-id="13496" data-permalink="https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/js-diy/" data-orig-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png" data-orig-size="2600,2600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="js-diy" data-image-description="" data-image-caption="" data-medium-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=300" data-large-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=570" src="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=570&amp;h=570" alt="Hand-drawn looking JavaScript logo saying DIY JS" srcset="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=455 455w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=910 910w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=150 150w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=300 300w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=768 768w" sizes="(max-width: 455px) 100vw, 455px"></p>
<p>In my day job, I work on a JavaScript framework (<a href="https://lwc.dev/">LWC</a>). And although I’ve been working on it for almost three years, I still feel like a dilettante. When I read about what’s going on in the larger framework world, I often feel overwhelmed by all the things I don’t know.</p>
<p>One of the best ways to learn how something works, though, is to build it yourself. And plus, we gotta keep those <a href="https://dayssincelastjavascriptframework.com/">“days since last JavaScript framework”</a> memes going. So let’s write our own modern JavaScript framework!</p>
<h2>What is a “modern JavaScript framework”?</h2>
<p>React is a great framework, and I’m not here to dunk on it. But for the purposes of this post, “modern JavaScript framework” means “a framework from the post-React era” – i.e. <a href="https://lit.dev/">Lit</a>, <a href="https://www.solidjs.com/">Solid</a>, <a href="https://svelte.dev/">Svelte</a>, <a href="https://vuejs.org/">Vue</a>, etc.</p>
<p>React has dominated the frontend landscape for so long that every newer framework has grown up in its shadow. These frameworks were all heavily inspired by React, but they’ve evolved away from it in surprisingly similar ways. And although React itself has continued innovating, I find that the post-React frameworks are more similar to each other than to React nowadays.</p>
<p>To keep things simple, I’m also going to avoid talking about server-first frameworks like <a href="https://astro.build/">Astro</a>, <a href="https://markojs.com/">Marko</a>, and <a href="https://qwik.builder.io/docs/">Qwik</a>. These frameworks are excellent in their own way, but they come from a slightly different intellectual tradition compared to the client-focused frameworks. So for this post, let’s only talk about client-side rendering.</p>
<h2>What sets modern frameworks apart?</h2>
<p>From my perspective, the post-React frameworks have all converged on the same foundational ideas:</p>
<ol>
<li>Using reactivity (e.g. <a href="https://dev.to/this-is-learning/the-evolution-of-signals-in-javascript-8ob">signals</a>) for DOM updates.</li>
<li>Using cloned templates for DOM rendering.</li>
<li>Using modern web APIs like <code>&lt;template&gt;</code> and <code>Proxy</code>, which make all of the above easier.</li>
</ol>
<p>Now to be clear, these frameworks differ a lot at the micro level, and in how they handle things like web components, compilation, and user-facing APIs. <a href="https://github.com/sveltejs/svelte/issues/2626#issuecomment-489894747">Not all frameworks</a> even use <code>Proxy</code>s. But broadly speaking, most framework authors seem to agree on the above ideas, or they’re moving in that direction.</p>
<p>So for our own framework, let’s try to do the bare minimum to implement these ideas, starting with reactivity.</p>
<h2>Reactivity</h2>
<p>It’s often said that <a href="https://dev.to/this-is-learning/how-react-isn-t-reactive-and-why-you-shouldn-t-care-152m">“React is not reactive”</a>. What this means is that React has a more pull-based rather than a push-based model. To grossly oversimplify things: React assumes that your entire virtual DOM tree needs to be rebuilt from scratch, and the only way to prevent these updates is to implement <code>useMemo</code> (or in the old days, <code>shouldComponentUpdate</code>).</p>
<p>Using a virtual DOM mitigates some of the cost of the “blow everything away and start from scratch” strategy, but it doesn’t fully solve it. And asking developers to write the correct memo code is a losing battle. (See <a href="https://react.dev/blog/2023/03/22/react-labs-what-we-have-been-working-on-march-2023">React Forget</a> for an ongoing attempt to solve this.)</p>
<p>Instead, modern frameworks use a push-based reactive model. In this model, individual parts of the component tree subscribe to state updates and only update the DOM when the relevant state changes. This prioritizes a “performant by default” design in exchange for some upfront bookkeeping cost (especially in terms of memory) to keep track of which parts of the state are tied to which parts of the UI.</p>
<p>Note that this technique is not necessarily incompatible with the virtual DOM approach: tools like <a href="https://preactjs.com/guide/v10/signals/">Preact Signals</a> and <a href="https://million.dev/">Million</a> show that you can have a hybrid system. This is useful if your goal is to keep your existing virtual DOM framework (e.g. React) but to selectively apply the push-based model for more performance-sensitive scenarios.</p>
<p>For this post, I’m not going to rehash the details of signals themselves, or subtler topics like <a href="https://dev.to/ryansolid/a-hands-on-introduction-to-fine-grained-reactivity-3ndf">fine-grained reactivity</a>, but I am going to assume that we’ll use a reactive system.</p>
<h2>Cloning DOM trees</h2>
<p>For a long time, the collective wisdom in JavaScript frameworks was that the fastest way to render the DOM is to create and mount each DOM node individually. In other words, you use APIs like <code>createElement</code>, <code>setAttribute</code>, and <code>textContent</code> to build the DOM piece-by-piece:</p>
<pre title="">const div = document.createElement('div')
div.setAttribute('class', 'blue')
div.textContent = 'Blue!'
</pre>
<p>One alternative is to just shove a big ol’ HTML string into <code>innerHTML</code> and let the browser parse it for you:</p>
<pre title="">const container = document.createElement('div')
container.innerHTML = `
  &lt;div class="blue"&gt;Blue!&lt;/div&gt;
`
</pre>
<p>This naïve approach has a big downside: if there is any dynamic content in your HTML (for instance, <code>red</code> instead of <code>blue</code>), then you would need to parse HTML strings over and over again. Plus, you are blowing away the DOM with every update, which would reset state such as the <code>value</code> of <code>&lt;input&gt;</code>s.</p>

<p>At some point, though, folks figured out that parsing the HTML <em>once</em> and then calling <code>cloneNode(true)</code> on the whole thing is pretty danged fast:</p>
<pre title="">const template = document.createElement('template')
template.innerHTML = `
  &lt;div class="blue"&gt;Blue!&lt;/div&gt;
`
template.content.cloneNode(true) // this is fast!
</pre>
<p>Here I’m using a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template"><code>&lt;template&gt;</code></a> tag, which has the advantage of creating “inert” DOM. In other words, things like <code>&lt;img&gt;</code> or <code>&lt;video autoplay&gt;</code> don’t automatically start downloading anything.</p>
<p>How fast is this compared to manual DOM APIs? To demonstrate, here’s <a href="https://github.com/nolanlawson/template-clone-demo">a small benchmark</a>. <a href="https://github.com/google/tachometer">Tachometer</a> reports that the cloning technique is about 50% faster in Chrome, 15% faster in Firefox, and 10% faster in Safari. (This will vary based on DOM size and number of iterations, but you get the gist.)</p>
<p>What’s interesting  is that <code>&lt;template&gt;</code> is a new-ish browser API, not available in IE11, and originally designed for web components. Somewhat ironically, this technique is now used in a variety of JavaScript frameworks, regardless of whether they use web components or not.</p>

<p>There is one major challenge with this technique, which is how to efficiently update dynamic content without blowing away DOM state. We’ll cover this later when we build our toy framework.</p>
<h2>Modern JavaScript APIs</h2>
<p>We’ve already encountered one new API that helps a lot, which is <code>&lt;template&gt;</code>. Another one that’s steadily gaining traction is <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy"><code>Proxy</code></a>, which can make building reactivity system much simpler.</p>
<p>When we build our toy example, we’ll also use <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates">tagged template literals</a> to create an API like this:</p>
<pre title="">const dom = html`
  &lt;div&gt;Hello ${ name }!&lt;/div&gt;
`
</pre>
<p>Not all frameworks use this tool, but notable ones include Lit, <a href="https://viperhtml.js.org/hyper.html">HyperHTML</a>, and <a href="https://www.arrow-js.com/">ArrowJS</a>. Tagged template literals can make it much simpler to build ergonomic HTML templating APIs without needing a compiler.</p>
<h2>Step 1: building reactivity</h2>
<p>Reactivity is the foundation upon which we'll build the rest of the framework. Reactivity will define how state is managed, and how the DOM updates when state changes.</p>
<p>Let's start with some <a href="https://nobackend.org/2013/05/welcome-to-noBackend.html">"dream code"</a> to illustrate what we want:</p>
<pre title="">const state = {}

state.a = 1
state.b = 2

createEffect(() =&gt; {
  state.sum = state.a + state.b
})
</pre>
<p>Basically, we want a “magic object” called <code>state</code>, with two props: <code>a</code> and <code>b</code>. And whenever those props change, we want to set <code>sum</code> to be the sum of the two.</p>
<p>Assuming we don’t know the props in advance (or have a compiler to determine them), a plain object will not suffice for this. So let’s use a <code>Proxy</code>, which can react whenever a new value is set:</p>
<pre title="">const state = new Proxy({}, {
  get(obj, prop) {
    onGet(prop)
    return obj[prop]
  },
  set(obj, prop, value) {
    obj[prop] = value
    onSet(prop, value)
    return true
  }
})
</pre>
<p>Right now, our <code>Proxy</code> doesn’t do anything interesting, except give us some <code>onGet</code> and <code>onSet</code> hooks. So let’s make it flush updates after a microtask:</p>
<pre title="">let queued = false

function onSet(prop, value) {
  if (!queued) {
    queued = true
    queueMicrotask(() =&gt; {
      queued = false
      flush()
    })
  }
}
</pre>

<p>Why flush updates? Mostly because we don’t want to run too many computations. If we update whenever both <code>a</code> and <code>b</code> change, then we’ll uselessly compute the <code>sum</code> twice. By coalescing the flush into a single microtask, we can be much more efficient.</p>
<p>Next, let’s make <code>flush</code> update the sum:</p>
<pre title="">function flush() {
  state.sum = state.a + state.b
}
</pre>
<p>This is great, but it’s not yet our “dream code.” We’ll need to implement <code>createEffect</code> so that the <code>sum</code> is computed only when <code>a</code> and <code>b</code> change (and not when something else changes!).</p>
<p>To do this, let’s use an object to keep track of which effects need to be run for which props:</p>
<pre title="">const propsToEffects = {}
</pre>
<p>Next comes the crucial part! We need to make sure that our effects can <em>subscribe</em> to the right props. To do so, we’ll run the effect, note any <code>get</code> calls it makes, and create a mapping between the prop and the effect.</p>
<p>To break it down, remember our “dream code” is:</p>
<pre title="">createEffect(() =&gt; {
  state.sum = state.a + state.b
})
</pre>
<p>When this function runs, it calls two getters: <code>state.a</code> and <code>state.b</code>. These getters should trigger the reactive system to notice that the function relies on the two props.</p>
<p>To make this happen, we’ll start with a simple global to keep track of what the “current” effect is:</p>
<pre title="">let currentEffect
</pre>
<p>Then, the <code>createEffect</code> function will set this global before calling the function:</p>
<pre title="">function createEffect(effect) {
  currentEffect = effect
  effect()
  currentEffect = undefined
}
</pre>
<p>The important thing here is that the effect is <em>immediately</em> invoked, with the <code>currentEffect</code> being set globally in advance. This is how we can track whatever getters the effect might be calling.</p>
<p>Now, we can implement the <code>onGet</code> in our <code>Proxy</code>, which will set up the mapping between the global <code>currentEffect</code> and the property:</p>
<pre title="">function onGet(prop) {
  const effects = propsToEffects[prop] ?? 
      (propsToEffects[prop] = [])
  effects.push(currentEffect)
}
</pre>
<p>After this runs once, <code>propsToEffects</code> should look like this:</p>
<pre title="">{
  "a": [theEffect],
  "b": [theEffect]
}
</pre>
<p>…where <code>theEffect</code> is the “sum” function we want to run.</p>
<p>Next, our <code>onSet</code> should add any effects that need to be run to a <code>dirtyEffects</code> array:</p>
<pre title="">const dirtyEffects = []

function onSet(prop, value) {
  if (propsToEffects[prop]) {
    dirtyEffects.push(...propsToEffects[prop])
    // ...
  }
}
</pre>
<p>At this point, we have all the pieces in place for <code>flush</code> to call all the <code>dirtyEffects</code>:</p>
<pre title="">function flush() {
  while (dirtyEffects.length) {
    dirtyEffects.shift()()
  }
}
</pre>
<p>Putting it all together, we now have a fully functional reactivity system! You can play around with it yourself and try setting <code>state.a</code> and <code>state.b</code> in the DevTools console – the <code>state.sum</code> will update whenever either one changes.</p>

<p>Now, there are plenty of advanced cases that we’re <em>not</em> covering here:</p>
<ol>
<li>Using <code>try</code>/<code>catch</code> in case an effect throws an error</li>
<li>Avoiding running the same effect twice</li>
<li>Preventing infinite cycles</li>
<li>Subscribing effects to new props on subsequent runs (e.g. if certain getters are only called in an <code>if</code> block)</li>
</ol>
<p>However, this is more than enough for our toy example. Let’s move on to DOM rendering.</p>
<h2>Step 2: DOM rendering</h2>
<p>We now have a functional reactivity system, but it’s essentially “headless.” It can track changes and compute effects, but that’s about it.</p>
<p>At some point, though, our JavaScript framework needs to actually render some DOM to the screen. (That’s kind of the whole point.)</p>
<p>For this section, let’s forget about reactivity for a moment and imagine we’re just trying to build a function that can 1) build a DOM tree, and 2) update it efficiently.</p>
<p>Once again, let’s start off with some dream code:</p>
<pre title="">function render(state) {
  return html`
    &lt;div class="${state.color}"&gt;${state.text}&lt;/div&gt;
  `
}
</pre>
<p>As I mentioned, I’m using tagged template literals, ala Lit, because I found them to be a nice way to write HTML templates without needing a compiler. (We’ll see in a moment why we might actually <em>want</em> a compiler instead.)</p>
<p>We’re re-using our <code>state</code> object from before, this time with a <code>color</code> and <code>text</code> property. Maybe the state is something like:</p>
<pre title="">state.color = 'blue'
state.text = 'Blue!'
</pre>
<p>When we pass this <code>state</code> into <code>render</code>, it should return the DOM tree with the state applied:</p>
<pre title="">&lt;div class="blue"&gt;Blue!&lt;/div&gt;
</pre>
<p>Before we go any further, though, we need a quick primer on tagged template literals. Our <code>html</code> tag is just a function that receives two arguments: the <code>tokens</code> (array of static HTML strings) and <code>expressions</code> (the evaluated dynamic expressions):</p>
<pre title="">function html(tokens, ...expressions) {
}
</pre>
<p>In this case, the <code>tokens</code> are (whitespace removed):</p>
<pre title="">[
  "&lt;div class=\"",
  "\"&gt;",
  "&lt;/div&gt;"
]
</pre>
<p>And the <code>expressions</code> are:</p>
<pre title="">[
  "blue",
  "Blue!"
]
</pre>
<p>The <code>tokens</code> array will always be exactly 1 longer than the <code>expressions</code> array, so we can trivially zip them up together:</p>
<pre title="">const allTokens = tokens
    .map((token, i) =&gt; (expressions[i - 1] ?? '') + token)
</pre>
<p>This will give us an array of strings:</p>
<pre title="">[
  "&lt;div class=\"",
  "blue",
  "\"&gt;",
  "Blue!",
  "&lt;/div&gt;"
]
</pre>
<p>We can join these strings together to make our HTML:</p>
<pre title="">const htmlString = allTokens.join('')
</pre>
<p>And then we can use <code>innerHTML</code> to parse it into a <code>&lt;template&gt;</code>:</p>
<pre title="">function parseTemplate(htmlString) {
  const template = document.createElement('template')
  template.innerHTML = htmlString
  return template
}
</pre>
<p>This template contains our inert DOM (technically a <a href="https://developer.mozilla.org/en-US/docs/Web/API/DocumentFragment"><code>DocumentFragment</code></a>), which we can clone at will:</p>
<pre title="">const cloned = template.content.cloneNode(true)
</pre>
<p>Of course, parsing the full HTML whenever the <code>html</code> function is called would not be great for performance. Luckily, tagged template literals have a built-in feature that will help out a lot here.</p>
<p>For every unique usage of a tagged template literal, the <code>tokens</code> array is <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates">always the same</a> whenever the function is called – in fact, it’s the exact same object!</p>
<p>For example, consider this case:</p>
<pre title="">function sayHello(name) {
  return html`&lt;div&gt;Hello ${name}&lt;/div&gt;`
}
</pre>
<p>Whenever <code>sayHello</code> is called, the <code>tokens</code> array will always be identical:</p>
<pre title="">[
  "&lt;div&gt;Hello ",
  "&lt;/div&gt;"
]
</pre>
<p>The only time <code>tokens</code> will be different is for completely different locations of the tagged template:</p>
<pre title="">html`&lt;div&gt;&lt;/div&gt;`
html`&lt;span&gt;&lt;/span&gt;` // Different from above
</pre>
<p>We can use this to our advantage by using a <code>WeakMap</code> to keep a mapping of the <code>tokens</code> array to the resulting <code>template</code>:</p>
<pre title="">const tokensToTemplate = new WeakMap()

function html(tokens, ...expressions) {
  let template = tokensToTemplate.get(tokens)
  if (!template) {
    // ...
    template = parseTemplate(htmlString)
    tokensToTemplate.set(tokens, template)
  }
  return template
}
</pre>
<p>This is kind of a mind-blowing concept, but the uniqueness of the <code>tokens</code> array essentially means that we can ensure that each call to <code>html`...`</code> only parses the HTML once.</p>
<p>Next, we just need a way to update the cloned DOM node with the <code>expressions</code> array (which is likely to be different every time, unlike <code>tokens</code>).</p>
<p>To keep things simple, let’s just replace the <code>expressions</code> array with a placeholder for each index:</p>
<pre title="">const stubs = expressions.map((_, i) =&gt; `__stub-${i}__`)
</pre>
<p>If we zip this up like before, it will create this HTML:</p>
<pre title="">&lt;div class="__stub-0__"&gt;
  __stub-1__
&lt;/div&gt;
</pre>
<p>We can write a simple string replacement function to replace the stubs:</p>
<pre title="">function replaceStubs (string) {
  return string.replaceAll(/__stub-(\d+)__/g, (_, i) =&gt; (
    expressions[i]
  ))
}
</pre>
<p>And now whenever the <code>html</code> function is called, we can clone the template and update the placeholders:</p>
<pre title="">const element = cloned.firstElementChild
for (const { name, value } of element.attributes) {
  element.setAttribute(name, replaceStubs(value))
}
element.textContent = replaceStubs(element.textContent)
</pre>

<p>Now, this is still not terribly efficient – notably, we are updating <code>textContent</code> and attributes that don’t necessarily need to be updated. But for our toy framework, this is good enough.</p>
<p>We can test it out by rendering with different <code>state</code>:</p>
<pre title="">document.body.appendChild(render({ color: 'blue', text: 'Blue!' }))
document.body.appendChild(render({ color: 'red', text: 'Red!' }))
</pre>
<p>This works!</p>

<h2>Step 3: combining reactivity and DOM rendering</h2>
<p>Since we already have a <code>createEffect</code> from the rendering system above, we can now combine the two to update the DOM based on the state:</p>
<pre title="">const container = document.getElementById('container')

createEffect(() =&gt; {
  const dom = render(state)
  if (container.firstElementChild) {
    container.firstElementChild.replaceWith(dom)
  } else {
    container.appendChild(dom)
  }
})
</pre>
<p>This actually works! We can combine this with the “sum” example from the reactivity section by merely creating another effect to set the <code>text</code>:</p>
<pre title="">createEffect(() =&gt; {
  state.text = `Sum is: ${state.sum}`
})
</pre>
<p>This renders “Sum is 3”:</p>

<p>You can play around with this toy example. If you set <code>state.a = 5</code>, then the text will automatically update to say “Sum is 7.”</p>
<h2>Next steps</h2>
<p>There are lots of improvements we could make to this system, especially the DOM rendering bit.</p>
<p>Most notably, we are missing a way to update content for elements inside a deep DOM tree, e.g.:</p>
<pre title="">&lt;div class="${color}"&gt;
  &lt;span&gt;${text}&lt;/span&gt;
&lt;/div&gt;
</pre>
<p>For this, we would need a way to uniquely identify every element inside of the template. There are lots of ways to do this:</p>
<ol>
<li>Lit, when parsing HTML, uses a system of <a href="https://github.com/lit/lit/blob/1af7991c27456c7e6073a3ee6f18f102c2adc026/packages/lit-html/src/lit-html.ts#L779-L857">regexes and character matching</a> to determine whether a placeholder is within an attribute or text content, plus the index of the target element (in depth-first <a href="https://developer.mozilla.org/en-US/docs/Web/API/TreeWalker"><code>TreeWalker</code></a> order).</li>
<li>Frameworks like Svelte and Solid have the luxury of parsing the entire HTML template during compilation, which provides the same information. They also generate code that calls <code>firstChild</code> and <code>nextSibling</code> to traverse the DOM to find the element to update.</li>
</ol>

<p>Whether we decided to do Lit-style client-side parsing or Svelte/Solid-style compile-time parsing, what we want is some kind of mapping like this:</p>
<pre title="">[
  {
    elementIndex: 0, // &lt;div&gt; above
    attributeName: 'class',
    stubIndex: 0 // index in expressions array
  },
  {
    elementIndex: 1 // &lt;span&gt; above
    textContent: true,
    stubIndex: 1 // index in expressions array
  }
]
</pre>
<p>These bindings would tell us exactly which elements need to be updated, which attribute (or <code>textContent</code>) needs to be set, and where to find the <code>expression</code> to replace the stub.</p>
<p>The next step would be to avoid cloning the template every time, and to just directly update the DOM based on the <code>expressions</code>. In other words, we not only want to parse once – we want to only clone and set up the bindings once. This would reduce each subsequent update to the bare minimum of <code>setAttribute</code> and <code>textContent</code> calls.</p>

<p>Another interesting pattern to implement would be iterations (or repeaters), which come with their own set of challenges, like reconciling lists between updates and handling “keys” for efficient replacement.</p>
<p>I’m tired, though, and this blog post has gone on long enough. So I leave the rest as an exercise to the reader!</p>
<h2>Conclusion</h2>
<p>So there you have it. In the span of one (lengthy) blog post, we’ve implemented our very own JavaScript framework. Feel free to use this as the foundation for your brand-new JavaScript framework, to release to the world and enrage the Hacker News crowd.</p>
<p>Personally I found this project very educational, which is partly why I did it in the first place. I was also looking to replace the current framework for <a href="https://github.com/nolanlawson/emoji-picker-element/">my emoji picker component</a> with a smaller, more custom-built solution. In the process, I managed to write <a href="https://github.com/nolanlawson/emoji-picker-element/pull/381">a tiny framework</a> that passes all the existing tests and is ~6kB smaller than the current implementation, which I’m pretty proud of.</p>
<p>In the future, I think it would be neat if browser APIs were full-featured enough to make it even easier to build a custom framework. For example, the <a href="https://github.com/WICG/webcomponents/blob/gh-pages/proposals/DOM-Parts.md">DOM Part API proposal</a> would take out a lot of the drudgery of the DOM parsing-and-replacement system we built above, while also opening the door to potential browser performance optimizations. I could also imagine (with some wild gesticulation) that an extension to <code>Proxy</code> could make it easier to build a full reactivity system without worrying about details like flushing, batching, or cycle detection.</p>
<p>If all those things were in place, then you could imagine effectively having a “Lit in the browser,” or at least a way to quickly build your own “Lit in the browser.” In the meantime, I hope that this small exercise helped to illustrate some of the things framework authors think about, and some of the machinery under the hood of your favorite JavaScript framework.</p>
<p><em>Thanks to <a href="https://pm.dartus.fr/">Pierre-Marie Dartus</a> for feedback on a draft of this post.</em></p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why does sleep become more elusive as we age? (107 pts)]]></title>
            <link>https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/</link>
            <guid>38509956</guid>
            <pubDate>Sun, 03 Dec 2023 19:31:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/">https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=38509956">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
								
																	
																
								<p>In his later life, my father-in-law routinely woke up for the day at 3 a.m. He'd become such an early bird that he morphed into a night owl, a man resigned to a post-retirement inability to clock in more than four or five hours of rest. I can recall taking his routines as a grim prophecy. And when a few years later I found myself struggling with brutal bouts of insomnia, I wondered if, along with laugh lines and macular degeneration, sleeplessness was an inevitable part of growing older for me, too.</p>

<p>There is a persistent folk wisdom that older people simply don't need as much sleep — an idea likely borne out of the idea that as our lifestyles ostensibly become less active, our requirements for the reparative benefits of rest diminish. As recently as 2008, a report in <a href="https://www.sciencedaily.com/releases/2008/07/080724123255.htm" target="_blank">Current Biology</a> found that in one experiment, older subjects got 1.5 hours less sleep on average than their younger counterparts. "The most parsimonious explanation for our results," researcher Elizabeth Klerman of Brigham and Women's Hospital &amp; Harvard Medical School said at the time, "is that older people need less sleep."</p>

<p>But what we <em>need</em> and what we actually <em>get </em>are two entirely different entities — and we are in the midst of a sleep shortage that's affecting Americans across all generational lines. The CDC notes that "<a href="https://www.cdc.gov/sleep/index.html#:~:text=A%20third%20of%20US%20adults,that%20threaten%20our%20nation's%20health." target="_blank">A third of US adults report that they usually get less than the recommended amount of sleep</a>." It's <a href="https://www.salon.com/2023/11/11/sleep-the-bedrock-of-public-health-is-eroding-this-is-how-experts-say-we-can-fix-it/" target="_blank">a crisis that can wreak havoc</a> on our physical and mental health, with sleep deprivation contributing to obesity, hypertension, diabetes, depression and stroke. And even accounting for fluctuations among different age populations, <a href="https://www.nhlbi.nih.gov/health/sleep/how-much-sleep" target="_blank">most adults need between 7 and 9 hours of sleep per night</a>. The key is just staying in a healthy range.&nbsp;</p>
<p>"A third of US adults report that they usually get less than the recommended amount of sleep."</p>
<p><a href="https://www.columbiapsychiatry.org/research-labs/sultan-lab-mental-health-informatics" target="_blank">Dr. Ryan Sultan</a>, a board-certified psychiatrist, therapist, researcher and professor at Columbia University, says that "As we age, the amount of sleep needed tends to decrease. Older adults may be well-rested and alert after 6 to 7 hours."</p>
<p>My late father-in-law may not have had much steam in him after dinnertime, but his days were as active and engaged as his solitary predawn hours. Sultan says it's just about paying attention to overall health patterns and any changes that feel off. "In my clinical experience," he says, "I have observed that older adults often face unique challenges, such as medical conditions or medications affecting sleep. Addressing these factors with a healthcare professional is crucial for developing a tailored approach to sleep improvement."</p>
<p>As Sultan puts it, "The concept of normal sleep does change as we age, and recognizing these shifts is essential for maintaining optimal health."</p>
<p>"Generally speaking, sleep ability declines as we age as the mechanisms that control sleep become less robust over time."</p>
<p>The real culprit to watch out for as we age isn't the amount of sleep, but quality of it. Older people have unique vulnerabilities around getting a deep, steady rest. A 2017 analysis in the journal <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5841578/" target="_blank">Sleep Medicine Clinics</a> explained how so-called "sleep architecture" can change with age, including "advanced sleep timing, shortened nocturnal sleep duration, increased frequency of daytime naps, increased number of nocturnal awakenings and time spent awake during the night, decreased slow wave sleep, and other changes."</p>
<p>Auckland sleep psychologist <a href="https://thebettersleepclinic.com/dan-ford-sleep-psychologist%C2%A0" target="_blank">Dan Ford, clinical director of the Better Sleep Clinic</a>, puts it simply, "Generally speaking, sleep ability declines as we age as the mechanisms that control sleep become less robust over time." But nothing is set in stone. He adds, "Healthy older adults do not necessarily show these changes in their sleep parameters."</p>
<p>Why do those gorgeous, lengthy sleeps of our younger years become so elusive as we age? There are a whole litany of reasons. <a href="https://www.salon.com/2022/11/13/dont-fear-the-hot-flash-menopause-isnt-a-disease-but-it-is-a-health-issue-we-need-to-talk-about/" target="_blank">There's menopause</a>, with its discomforts and night sweats. Bathroom issues can likewise keep a person of any gender up and down all night long. Changes in the urinary tract, along with other factors like bladder obstruction, make nocturia (frequent nighttime urination) <a href="https://pubmed.ncbi.nlm.nih.gov/10641954/#:~:text=In%20addition%2C%20aging%20is%20associated,nocturia%20as%20a%20prominent%20symptom." target="_blank">far more common </a>in adults over the age of 60.</p>
<p>There are other physical factors as well — the National Council on Aging estimates that "<a href="https://www.ncoa.org/article/sleep-apnea-in-older-adults-diagnosis-and-treatment-options" target="_blank">56% of people</a> age 65 and older have a high risk of developing obstructive sleep apnea." Our <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5272178/" target="_blank">circadian rhythms also change as we age</a>, edging us to what can make us feel like we're living in a different time zone from our family and friends. And then there are the mental health issues. Grief, loneliness, financial loss and other stressors can wreck a good night's rest, and the symptoms of <a href="https://www.cdc.gov/aging/depression/index.html#:~:text=How%20Many%20Older%20Adults%20are,11.5%25%20in%20older%20hospitalized%20patients." target="_blank">depression and anxiety often go undiagnosed</a>. A 2018 study on insomnia in the Journal of Clinical Sleep Medicine found that "<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5991956/" target="_blank">As many as 50% of older adults complain about difficulty initiating or maintaining sleep</a>."</p>
<hr>
<p><strong><em>Want more health and science stories in your inbox? Subscribe to Salon's weekly newsletter <a href="https://salon.us8.list-manage.com/subscribe?u=71cb3e8a6e9639c81023cd427&amp;id=5deda2aaa7">Lab Notes</a>.</em></strong></p>
<hr>
<p>So if you're noticing that your nights now typically involve periods of wakefulness, is playing a little catch up when possible during the day a good idea?</p>
<p>"Napping can be a helpful strategy for older adults," says Dr. Ryan Sultan, "but the timing and duration matter. Short naps of around 20 to 30 minutes can boost alertness without interfering with nighttime sleep. However, extended or late-afternoon naps might disrupt the sleep-wake cycle, making it harder to fall asleep at night." Mileage can vary even there, though — I have a friend in his late 50s who regularly konks out before making dinner. He calls it a "nappetizer."</p>
<p>For those who have a hard time resisting longer naps, <a href="https://www.emotionstherapycalgary.ca/psychologist-calgary-rod-mitchell" target="_blank">Rod Mitchell</a>, a Calgary psychologist with expertise in cognitive behavioral therapy for insomnia, recommends offsetting grogginess with a "coffee nap." He says, "Combine a small, controlled intake of caffeine (such as a half cup of coffee) followed by a short, 20-minute nap. This method can enhance the restorative effect of napping, with the caffeine kicking in just as you wake up, potentially offering a more refreshing experience."&nbsp;</p>
<p>However many candles may be on your own next birthday cake, we all need to prioritize adequate rest. We know that building healthy routines like regular bedtimes, avoiding too much caffeine and late-night doomscrolling or binge-watching and getting adequate physical activity are the best bet for a better night — even if it's all easier said than done. Our culture typically regards aging as a failure and sleep as for the weak. But the plain fact is that our bodies change over time. That doesn't mean that once you hit your AARP era,&nbsp; you suddenly can function just fine on 5 hours of sack time. Instead, if you want to feel younger, you just might actually need to sleep more.</p>
<div>

<ul>
<li><strong><a href="https://www.salon.com/2023/11/15/is-gen-zs-bed-rotting-trend-self-care-or-reckless-self-indulgence/" target="_blank">Is Gen Z's "bed rotting" trend self-care or reckless self-indulgence?</a></strong></li>
<li><strong><a href="https://www.salon.com/2023/11/11/sleep-the-bedrock-of-public-health-is-eroding-this-is-how-experts-say-we-can-fix-it/" target="_blank">Sleep, the bedrock of public health, is eroding. This is how experts say we can fix it</a></strong></li>
<li><strong><a href="https://www.salon.com/2023/11/08/is-blue-light-actually-harmful-to-your-sleep-why-the-science-isnt-so-clear-on-this-popular-belief/" target="_blank">Is blue light actually harmful to your sleep? Why the science isn't so clear on this popular belief</a></strong></li>
</ul>
</div>
							</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Audio plugin for circuit-bent MP3 compression sounds (158 pts)]]></title>
            <link>https://wildergardenaudio.com/maim/</link>
            <guid>38509173</guid>
            <pubDate>Sun, 03 Dec 2023 18:01:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wildergardenaudio.com/maim/">https://wildergardenaudio.com/maim/</a>, See on <a href="https://news.ycombinator.com/item?id=38509173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
        <h2><a href="https://wildergardenaudio.com/">Wildergarden Audio</a></h2>
        

    </header>
    <p><img src="https://wildergardenaudio.com/maim/static/images/maim-logo.svg" alt="MAIM">
        <img src="https://wildergardenaudio.com/maim/static/images/maim-logo-orange.svg" alt="MAIM">
    </p>
    <h2>MAIM Ain't an Implementation of MP3</h2>
    <p><img src="https://wildergardenaudio.com/maim/static/images/MaimGUI.png" alt="screenshot of MAIM GUI"></p><div>
            <p>MAIM is the plugin for you if you want the sound of MP3 compression. With heavily hacked real MP3
                encoders at its core, MAIM gives you the full gamut of digital distortion, from the realistic to the
                fantastical. Explore the bubbles and crunches of this unique form of digital distortion.</p>
            <ul>
                <li>MAIM features two real MP3 encoders, captured in the wild and painstakingly incorporated into a
                    real-time plugin.
                </li>
                <li>We've woven mad-science circuit bending into MAIM's MP3 encoders, to give you fine control over a
                    whole
                    palette of spectral distortions and face-melting glitches.
                </li>
                <li>All knobs can be smoothly dragged and automated, without pops or gaps in the sound.</li>
                <li>MAIM works across DAWs, on Mac (AU/VST3), Windows (VST3), and even Linux (VST3).</li>
                <li>MAIM is, and will always be, 100% free and open-source. If you are so inclined,
                    <a href="https://github.com/ArdenButterfield/Maim">check out the code</a>,
                    <a href="https://github.com/ArdenButterfield/Maim/blob/main/Docs/BUILDING.md">build MAIM
                        yourself</a>,
                    or add the next awesome feature.
                </li>
            </ul>
            <p>
                If you encounter any issues, or have an idea for something that would improve MAIM, please
                <a href="https://github.com/ArdenButterfield/Maim/issues">raise an issue</a> on the GitHub page.
            </p>
            <p>
                Maim took a long time to make. If you enjoy MAIM and want to see more plugins like it in the future,
                <a href="https://ko-fi.com/wildergardenaudio">tips</a> are always welcome.
            </p>
        </div>
    <div>
        <h2>Meet the Encoders</h2>
        <p>
            Why does MAIM have two MP3 encoders? An MP3 is an MP3, right? Not quite.
            Audio compression is as much an art as a science, and each encoder gives the track a slightly different
            tone.
        </p>
        
    </div>
    <div>
        <h2>The Sounds of MAIM</h2>
        <ul>
            <li>
                <h3>dry</h3>
                <p>just some normal drums... what will MAIM do?</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20dry.mp3">
                </audio>
            </li>
            <li>
                <h3>moderate mp3 distortion</h3>
                <p>that napster sound</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20light%20mp3%20distortion.mp3">
                </audio>
            </li>
            <li>
                <h3>muffled 8k</h3>
                <p>the lowest quality setting on the lame mp3 encoder... just 8000 bits per second!</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20muffled8k.mp3">
                </audio>
            </li>
            <li>
                <h3>blade</h3>
                <p>bubble bath for your music</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20bubblyBlade.mp3">
                </audio>
            </li>
            <li>
                <h3>eroded</h3>
                <p>a different kind of gate. memories of zoom meetings gone wrong</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20eroded.mp3">
                </audio>
            </li>
            <li>
                <h3>feedback</h3>
                <p>smeared and buzzy</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20smearedBuzzy.mp3">
                </audio>
            </li>
            <li>
                <h3>tubular</h3>
                <p>the math is hard to explain here, but imagine if a comb filter was worse</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20throughATube.mp3">
                </audio>
            </li>
            <li>
                <h3>whirled</h3>
                <p>it's a frequency shifter</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20spectralSpin.mp3">
                </audio>
            </li>
            <li>
                <h3>clunked up</h3>
                <p>all the wrong frequencies</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20crunk.mp3">
                </audio>
            </li>
        </ul>
    </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steel – An embeddable and extensible scheme dialect built in Rust (185 pts)]]></title>
            <link>https://github.com/mattwparas/steel</link>
            <guid>38508779</guid>
            <pubDate>Sun, 03 Dec 2023 17:24:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mattwparas/steel">https://github.com/mattwparas/steel</a>, See on <a href="https://news.ycombinator.com/item?id=38508779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Steel</h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mattwparas/steel/blob/master/images/styled.png"><img width="150px" src="https://github.com/mattwparas/steel/raw/master/images/styled.png"></a>
</p>

<h2 tabindex="-1" dir="auto">Getting Started</h2>
<p dir="auto">This github repository contains a cli interpreter. To try it out on the online playground, go to the <a href="https://mattwparas.github.io/steel-playground/dev" rel="nofollow">Steel playground</a>. To get started using a repl with the crates, make sure you first have rust installed.</p>
<p dir="auto">Then, clone the repo and run the following command:</p>

<p dir="auto">This will launch a REPL instance that looks something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/mattwparas/steel/blob/master/images/repl.gif"><img src="https://github.com/mattwparas/steel/raw/master/images/repl.gif" width="100%" data-animated-image=""></a>
</p>
<h3 tabindex="-1" dir="auto">Packages</h3>
<p dir="auto">If you would like to install and use packages, please set the <code>STEEL_HOME</code> environment variable. This will be the location that packages get installed to. Steel currently does not assume any default.</p>
<h2 tabindex="-1" dir="auto">About</h2>
<p dir="auto"><code>Steel</code> is an embeddable scheme interpreter, with a standalone cli included as well. Inspired largely by Racket, the language seeks to be ergonomic scheme variant helpful for embedding in applications, or to be used on its own with high performance functions implemented in Rust. The language implementation itself contains a fairly powerful macro system based on the <code>syntax-rules</code> style and a bytecode virtual machine. At the moment, it is not explicitly compliant with any individual scheme specification.</p>
<blockquote>
<p dir="auto"><strong>Warning</strong>
The API is unstable with no guarantees, and may change at any time while pre 1.0. There are undoubtedly bugs that exist, and any major bug reports will be addressed quickly. That being said, I do use it as a daily driver for many scripting tasks myself.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Limited <code>syntax-rules</code> style macros are supported</li>
<li>Easy integration with Rust functions and structs</li>
<li>Easily call a script from rust or via a separate file</li>
<li>Efficient - common functions and data structures are optimized for performance (<code>map</code>, <code>filter</code>, etc)</li>
<li>Higher order Contracts</li>
<li>Built in immutable data structures include:
<ul dir="auto">
<li>lists</li>
<li>vectors</li>
<li>hashmaps</li>
<li>hashsets</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Contracts</h2>
<p dir="auto">Inspired by Racket's higher order contracts, <code>Steel</code> implements* higher order contracts to enable design by contract, made easy with a <code>define/contract</code> macro for easier ergonomics. Racket makes use of a concept known as <em>blame</em> which seeks to identify the violating party - <code>Steel</code> does not quite have fully fleshed out blame but that is a work in progress. Here are some examples:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Simple flat contracts
(define/contract (test x y)
    (->/c even? even? odd?)
    (+ x y 1))

(test 2 2) ;; => 5

(define/contract (test-violation x y)
    (->/c even? even? odd?)
    (+ x y 1))

(test-violation 1 2) ;; contract violation
"><pre><span><span>;</span>; Simple flat contracts</span>
(define/contract (test x y)
    (-&gt;/c <span>even?</span> <span>even?</span> odd?)
    (<span>+</span> x y <span>1</span>))

(test <span>2</span> <span>2</span>) <span><span>;</span>; =&gt; 5</span>

(define/contract (test-violation x y)
    (-&gt;/c <span>even?</span> <span>even?</span> odd?)
    (<span>+</span> x y <span>1</span>))

(test-violation <span>1</span> <span>2</span>) <span><span>;</span>; contract violation</span>
</pre></div>
<p dir="auto">Contracts are implemented as <em>values</em>, so they are bound to functions. This enables the use of contract checking on functions themselves since functions can be passed around:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Higher order contracts, check on application
(define/contract (higher-order func y)
    (->/c (->/c even? odd?) even? even?)
    (+ 1 (func y)))

(higher-order (lambda (x) (+ x 1)) 2) ;; => 4

(define/contract (higher-order-violation func y)
    (->/c (->/c even? odd?) even? even?)
    (+ 1 (func y)))

(higher-order-violation (lambda (x) (+ x 2)) 2) ;; contract violation"><pre><span><span>;</span>; Higher order contracts, check on application</span>
(define/contract (higher-order func y)
    (-&gt;/c (-&gt;/c <span>even?</span> odd?) <span>even?</span> even?)
    (<span>+</span> <span>1</span> (func y)))

(higher-order (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)) <span>2</span>) <span><span>;</span>; =&gt; 4</span>

(define/contract (higher-order-violation func y)
    (-&gt;/c (-&gt;/c <span>even?</span> odd?) <span>even?</span> even?)
    (<span>+</span> <span>1</span> (func y)))

(higher-order-violation (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>2</span>)) <span>2</span>) <span><span>;</span>; contract violation</span></pre></div>
<p dir="auto">Contracts on functions do not get checked until they are applied, so a function returning a <em>contracted</em> function won't cause a violation until that function is actually used:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; More higher order contracts, get checked on application
(define/contract (output)
    (->/c (->/c string? int?))
    (lambda (x) 10))

(define/contract (accept func)
    (->/c (->/c string? int?) string?)
    &quot;cool cool cool&quot;)

(accept (output)) ;; => &quot;cool cool cool&quot;

;; different contracts on the argument
(define/contract (accept-violation func)
    (->/c (->/c string? string?) string?)
    (func &quot;applesauce&quot;)
    &quot;cool cool cool&quot;)

(accept-violation (output)) ;; contract violation

;; generates a function
(define/contract (generate-closure)
    (->/c (->/c string? int?))
    (lambda (x) 10))

;; calls generate-closure which should result in a contract violation
(define/contract (accept-violation)
    (->/c (->/c string? string?))
    (generate-closure))

((accept-violation) &quot;test&quot;) ;; contract violation"><pre><span><span>;</span>; More higher order contracts, get checked on application</span>
(define/contract (output)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10))

(define/contract (accept func)
    (-&gt;/c (-&gt;/c <span>string?</span> int?) string?)
    <span><span>"</span>cool cool cool<span>"</span></span>)

(accept (output)) <span><span>;</span>; =&gt; "cool cool cool"</span>

<span><span>;</span>; different contracts on the argument</span>
(define/contract (accept-violation func)
    (-&gt;/c (-&gt;/c <span>string?</span> string?) string?)
    (func <span><span>"</span>applesauce<span>"</span></span>)
    <span><span>"</span>cool cool cool<span>"</span></span>)

(accept-violation (output)) <span><span>;</span>; contract violation</span>

<span><span>;</span>; generates a function</span>
(define/contract (generate-closure)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10))

<span><span>;</span>; calls generate-closure which should result in a contract violation</span>
(define/contract (accept-violation)
    (-&gt;/c (-&gt;/c <span>string?</span> string?))
    (generate-closure))

((accept-violation) <span><span>"</span>test<span>"</span></span>) <span><span>;</span>; contract violation</span></pre></div>
<p dir="auto">Perhaps a more nuanced case:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(define/contract (output)
    (->/c (->/c string? int?))
    (lambda (x) 10.2))

(define/contract (accept)
    (->/c (->/c string? number?))
    (output))


((accept) &quot;test&quot;) ;; contract violation 10.2 satisfies number? but _not_ int?"><pre>(define/contract (output)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10.2))

(define/contract (accept)
    (-&gt;/c (-&gt;/c <span>string?</span> number?))
    (output))


((accept) <span><span>"</span>test<span>"</span></span>) <span><span>;</span>; contract violation 10.2 satisfies number? but _not_ int?</span></pre></div>
<p dir="auto">* Very much a work in progress</p>
<h2 tabindex="-1" dir="auto">Transducers</h2>
<p dir="auto">Inspired by clojure's transducers, <code>Steel</code> has a similar object that is somewhere half way in between transducers and iterators. Consider the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="
(mapping (lambda (x) (+ x 1))) ;; => <#iterator>
(filtering even?) ;; => <#iterator>
(taking 15) ;; => <#iterator>

(compose 
    (mapping add1)
    (filtering odd?)
    (taking 15)) ;; => <#iterator>"><pre>(mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>
(filtering even?) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>
(taking <span>15</span>) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>

(compose 
    (mapping add1)
    (filtering odd?)
    (taking <span>15</span>)) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span></pre></div>
<p dir="auto">Each of these expressions emit an <code>&lt;#iterator&gt;</code> object, which means they're compatible with  <code>transduce</code>. <code>transduce</code> takes a transducer (i.e. <code>&lt;#iterator&gt;</code>) and a collection that can be iterated (<code>list</code>, <code>vector</code>, <code>stream</code>, <code>hashset</code>, <code>hashmap</code>, <code>string</code>, <code>struct</code>) and applies the transducer.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Accepts lists
(transduce (list 1 2 3 4 5) (mapping (lambda (x) (+ x 1))) (into-list)) ;; => '(2 3 4 5 6)

;; Accepts vectors
(transduce (vector 1 2 3 4 5) (mapping (lambda (x) (+ x 1))) (into-vector)) ;; '#(2 3 4 5 6)

;; Even accepts streams!
(define (integers n)
    (stream-cons n (lambda () (integers (+ 1 n)))))

(transduce (integers 0) (taking 5) (into-list)) ;; => '(0 1 2 3 4)"><pre><span><span>;</span>; Accepts lists</span>
(transduce (<span>list</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-list)) <span><span>;</span>; =&gt; '(2 3 4 5 6)</span>

<span><span>;</span>; Accepts vectors</span>
(transduce (vector <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-vector)) <span><span>;</span>; '#(2 3 4 5 6)</span>

<span><span>;</span>; Even accepts streams!</span>
(<span>define</span> (<span>integers</span><span> n</span>)
    (stream-cons n (<span>lambda</span> () (integers (<span>+</span> <span>1</span> n)))))

(transduce (integers <span>0</span>) (taking <span>5</span>) (into-list)) <span><span>;</span>; =&gt; '(0 1 2 3 4)</span></pre></div>
<p dir="auto">Transduce accepts a reducer function as well. Above we used <code>into-list</code> and <code>into-vector</code>, but below we can use any arbitrary reducer:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; (-> transducer reducing-function initial-value iterable)
(transduce (list 0 1 2 3) (mapping (lambda (x) (+ x 1))) (into-reducer + 0)) ;; => 10"><pre><span><span>;</span>; (-&gt; transducer reducing-function initial-value iterable)</span>
(transduce (<span>list</span> <span>0</span> <span>1</span> <span>2</span> <span>3</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-reducer <span>+</span> <span>0</span>)) <span><span>;</span>; =&gt; 10</span></pre></div>
<p dir="auto">Compose just combines the iterator functions and lets us avoid intermediate allocation. The composition works left to right - it chains each value through the functions and then accumulates into the output type. See the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(define xf 
    (compose 
        (mapping add1)
        (filtering odd?)
        (taking 5)))

(transduce (range 0 100) xf (into-list)) ;; => '(1 3 5 7 9)"><pre>(<span>define</span> <span>xf</span> 
    (compose 
        (mapping add1)
        (filtering odd?)
        (taking <span>5</span>)))

(transduce (range <span>0</span> <span>100</span>) xf (into-list)) <span><span>;</span>; =&gt; '(1 3 5 7 9)</span></pre></div>
<h2 tabindex="-1" dir="auto">Syntax Choices</h2>
<p dir="auto"><code>Steel</code> is mildly opinionated in that there a few ways to define variables and functions. These choices are fairly arbitrary except for the shorthand function syntax, which I borrowed from Racket. <code>defn</code> and <code>fn</code> were really encouraged by me wanting to type less characters.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
;; All of the following are equivalent
(define (foo x) (+ x 1))
(define foo (lambda (x) (+ x 1)))
(defn (foo x) (+ x 1))
(defn foo (lambda (x) (+ x 1)))

;; All of the following are equivalent
(lambda (x) (+ x 1))
(λ (x) (+ x 1))
(fn (x) (+ x 1))"><pre><span><span>;</span>; All of the following are equivalent</span>
(<span>define</span> (<span>foo</span><span> x</span>) (<span>+</span> x <span>1</span>))
(<span>define</span> <span>foo</span> (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)))
(defn (<span>foo</span> x) (<span>+</span> x <span>1</span>))
(defn <span>foo</span> (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)))

<span><span>;</span>; All of the following are equivalent</span>
(<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))
(λ (x) (<span>+</span> x <span>1</span>))
(fn (x) (<span>+</span> x <span>1</span>))</pre></div>
<h2 tabindex="-1" dir="auto">Modules</h2>
<p dir="auto">In order to support a growing codebase, Steel has module support for projects spanning multiple files. Steel files can <code>provide</code> values (with contracts attached) and <code>require</code> modules from other files:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; main.scm
(require &quot;provide.scm&quot;)

(even->odd 10)


;; provide.scm
(provide 
    (contract/out even->odd (->/c even? odd?))
    no-contract
    flat-value)

(define (even->odd x) 
    (+ x 1))

(define (accept-number x) (+ x 10))

(define (no-contract) &quot;cool cool cool&quot;)
(define flat-value 15)

(displayln &quot;Calling even->odd with some bad inputs but its okay&quot;)
(displayln (even->odd 1))"><pre><span><span>;</span>; main.scm</span>
(require <span><span>"</span>provide.scm<span>"</span></span>)

(even-&gt;odd <span>10</span>)


<span><span>;</span>; provide.scm</span>
(provide 
    (contract/out even-&gt;odd (-&gt;/c <span>even?</span> odd?))
    no-contract
    flat-value)

(<span>define</span> (<span>even-&gt;odd</span><span> x</span>) 
    (<span>+</span> x <span>1</span>))

(<span>define</span> (<span>accept-number</span><span> x</span>) (<span>+</span> x <span>10</span>))

(<span>define</span> (<span>no-contract</span>) "cool cool cool")
(<span>define</span> <span>flat-value</span> 15)

(displayln <span><span>"</span>Calling even-&gt;odd with some bad inputs but its okay<span>"</span></span>)
(displayln (even-&gt;odd <span>1</span>))</pre></div>
<p dir="auto">Here we can see if we were to run <code>main</code> that it would include the contents of <code>provide</code>, and only provided values would be accessible from <code>main</code>. The contract is attached at the contract boundary, so inside the <code>provide</code> module, you can violate the contract, but outside the module the contract will be applied.</p>
<p dir="auto">A few notes on modules:</p>
<ul dir="auto">
<li>Cyclical dependencies are not allowed</li>
<li>Modules will be only compiled once and used across multiple files. If <code>A</code> requires <code>B</code> and <code>C</code>, and <code>B</code> requires <code>C</code>, <code>C</code> will be compiled once and shared between <code>A</code> and <code>B</code>.</li>
<li>Modules will be recompiled when changed, and any dependent files will also be recompiled as necessary</li>
</ul>
<h2 tabindex="-1" dir="auto">Performance</h2>
<p dir="auto">Preliminary benchmarks show the following on my machine:</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Steel</th>
<th>Python</th>
</tr>
</thead>
<tbody>
<tr>
<td>(fib 28)</td>
<td>63.383ms</td>
<td>65.10 ms</td>
</tr>
<tr>
<td>(ack 3 3)</td>
<td>0.303 ms</td>
<td>0.195 ms</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Examples of embedding Rust values in the virtual machine</h2>
<p dir="auto">Rust values, types, and functions are easily embedded into Steel. Using the <code>register_fn</code> call, you can embed functions easily:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use steel_vm::engine::Engine;
use steel_vm::register_fn::RegisterFn;

fn external_function(arg1: usize, arg2: usize) -> usize {
    arg1 + arg2
}

fn option_function(arg1: Option<String>) -> Option<String> {
    arg1
}

fn result_function(arg1: Option<String>) -> Result<String, String> {
    if let Some(inner) = arg1 {
        Ok(inner)
    } else {
        Err(&quot;Got a none&quot;.to_string())
    }
}

pub fn main() {
    let mut vm = Engine::new();

    // Here we can register functions
    // Any function can accept parameters that implement `FromSteelVal` and
    // return values that implement `IntoSteelVal`
    vm.register_fn(&quot;external-function&quot;, external_function);

    // See the docs for more information about `FromSteelVal` and `IntoSteelVal`
    // but we can see even functions that accept/return Option<T> or Result<T,E>
    // can be registered
    vm.register_fn(&quot;option-function&quot;, option_function);

    // Result values will map directly to errors in the VM and bubble back up
    vm.register_fn(&quot;result-function&quot;, result_function);

    vm.run(
        r#&quot;
        (define foo (external-function 10 25))
        (define bar (option-function &quot;applesauce&quot;))
        (define baz (result-function &quot;bananas&quot;))
    &quot;#,
    )
    .unwrap();

    let foo = vm.extract::<usize>(&quot;foo&quot;).unwrap();
    println!(&quot;foo: {}&quot;, foo);
    assert_eq!(35, foo);

    // Can also extract a value by specifying the type on the variable
    let bar: String = vm.extract(&quot;bar&quot;).unwrap();
    println!(&quot;bar: {}&quot;, bar);
    assert_eq!(&quot;applesauce&quot;.to_string(), bar);

    let baz: String = vm.extract(&quot;baz&quot;).unwrap();
    println!(&quot;baz: {}&quot;, baz);
    assert_eq!(&quot;bananas&quot;.to_string(), baz);
}"><pre><span>use</span> steel_vm<span>::</span>engine<span>::</span><span>Engine</span><span>;</span>
<span>use</span> steel_vm<span>::</span>register_fn<span>::</span><span>RegisterFn</span><span>;</span>

<span>fn</span> <span>external_function</span><span>(</span><span>arg1</span><span>:</span> <span>usize</span><span>,</span> <span>arg2</span><span>:</span> <span>usize</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
    arg1 + arg2
<span>}</span>

<span>fn</span> <span>option_function</span><span>(</span><span>arg1</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>)</span> -&gt; <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
    arg1
<span>}</span>

<span>fn</span> <span>result_function</span><span>(</span><span>arg1</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>)</span> -&gt; <span>Result</span><span>&lt;</span><span>String</span><span>,</span> <span>String</span><span>&gt;</span> <span>{</span>
    <span>if</span> <span>let</span> <span>Some</span><span>(</span>inner<span>)</span> = arg1 <span>{</span>
        <span>Ok</span><span>(</span>inner<span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>Err</span><span>(</span><span>"Got a none"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> vm = <span>Engine</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    <span>// Here we can register functions</span>
    <span>// Any function can accept parameters that implement `FromSteelVal` and</span>
    <span>// return values that implement `IntoSteelVal`</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"external-function"</span><span>,</span> external_function<span>)</span><span>;</span>

    <span>// See the docs for more information about `FromSteelVal` and `IntoSteelVal`</span>
    <span>// but we can see even functions that accept/return Option&lt;T&gt; or Result&lt;T,E&gt;</span>
    <span>// can be registered</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"option-function"</span><span>,</span> option_function<span>)</span><span>;</span>

    <span>// Result values will map directly to errors in the VM and bubble back up</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"result-function"</span><span>,</span> result_function<span>)</span><span>;</span>

    vm<span>.</span><span>run</span><span>(</span>
        <span>r#"</span>
<span>        (define foo (external-function 10 25))</span>
<span>        (define bar (option-function "applesauce"))</span>
<span>        (define baz (result-function "bananas"))</span>
<span>    "#</span><span>,</span>
    <span>)</span>
    <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> foo = vm<span>.</span><span>extract</span><span>::</span><span>&lt;</span><span>usize</span><span>&gt;</span><span>(</span><span>"foo"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"foo: {}"</span>, foo<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>35</span>, foo<span>)</span><span>;</span>

    <span>// Can also extract a value by specifying the type on the variable</span>
    <span>let</span> bar<span>:</span> <span>String</span> = vm<span>.</span><span>extract</span><span>(</span><span>"bar"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"bar: {}"</span>, bar<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>"applesauce"</span>.to_string<span>(</span><span>)</span>, bar<span>)</span><span>;</span>

    <span>let</span> baz<span>:</span> <span>String</span> = vm<span>.</span><span>extract</span><span>(</span><span>"baz"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"baz: {}"</span>, baz<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>"bananas"</span>.to_string<span>(</span><span>)</span>, baz<span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">We can also embed structs themselves:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use steel_vm::engine::Engine;
use steel_vm::register_fn::RegisterFn;

use steel_derive::Steel;

// In order to register a type with Steel,
// it must implement Clone, Debug, and Steel
#[derive(Clone, Debug, Steel, PartialEq)]
pub struct ExternalStruct {
    foo: usize,
    bar: String,
    baz: f64,
}

impl ExternalStruct {
    pub fn new(foo: usize, bar: String, baz: f64) -> Self {
        ExternalStruct { foo, bar, baz }
    }

    // Embedding functions that take self by value
    pub fn method_by_value(self) -> usize {
        self.foo
    }

    pub fn method_by_reference(&amp;self) -> usize {
        self.foo
    }

    // Setters should update the value and return a new instance (functional set)
    pub fn set_foo(mut self, foo: usize) -> Self {
        self.foo = foo;
        self
    }
}

pub fn main() {
    let mut vm = Engine::new();

    // Registering a type gives access to a predicate for the type
    vm.register_type::<ExternalStruct>(&quot;ExternalStruct?&quot;);

    // Structs in steel typically have a constructor that is the name of the struct
    vm.register_fn(&quot;ExternalStruct&quot;, ExternalStruct::new);

    // register_fn can be chained
    vm.register_fn(&quot;method-by-value&quot;, ExternalStruct::method_by_value)
        .register_fn(&quot;method-by-reference&quot;, ExternalStruct::method_by_reference)
        .register_fn(&quot;set-foo&quot;, ExternalStruct::set_foo);

    let external_struct = ExternalStruct::new(1, &quot;foo&quot;.to_string(), 12.4);

    // Registering an external value is fallible if the conversion fails for some reason
    // For instance, registering an Err(T) is fallible. However, most implementation outside of manual
    // ones should not fail
    vm.register_external_value(&quot;external-struct&quot;, external_struct)
        .unwrap();

    let output = vm
        .run(
            r#&quot;
            (define new-external-struct (set-foo external-struct 100))
            (define get-output (method-by-value external-struct))
            (define second-new-external-struct (ExternalStruct 50 &quot;bananas&quot; 72.6))
            &quot;last-result&quot;
        &quot;#,
        )
        .unwrap();

    let new_external_struct = vm.extract::<ExternalStruct>(&quot;new-external-struct&quot;).unwrap();
    println!(&quot;new_external_struct: {:?}&quot;, new_external_struct);
    assert_eq!(
        ExternalStruct::new(100, &quot;foo&quot;.to_string(), 12.4),
        new_external_struct
    );

    // Can also extract a value by specifying the type on the variable
    let get_output: usize = vm.extract(&quot;get-output&quot;).unwrap();
    println!(&quot;get_output: {}&quot;, get_output);
    assert_eq!(1, get_output);

    let second_new_external_struct: ExternalStruct =
        vm.extract(&quot;second-new-external-struct&quot;).unwrap();
    println!(
        &quot;second_new_external_struct: {:?}&quot;,
        second_new_external_struct
    );
    assert_eq!(
        ExternalStruct::new(50, &quot;bananas&quot;.to_string(), 72.6),
        second_new_external_struct
    );

    // We also get the output of the VM as the value of every expression run
    // we can inspect the results just by printing like so
    println!(&quot;{:?}&quot;, output);
}"><pre><span>use</span> steel_vm<span>::</span>engine<span>::</span><span>Engine</span><span>;</span>
<span>use</span> steel_vm<span>::</span>register_fn<span>::</span><span>RegisterFn</span><span>;</span>

<span>use</span> steel_derive<span>::</span><span>Steel</span><span>;</span>

<span>// In order to register a type with Steel,</span>
<span>// it must implement Clone, Debug, and Steel</span>
<span>#<span>[</span>derive<span>(</span><span>Clone</span><span>,</span> <span>Debug</span><span>,</span> <span>Steel</span><span>,</span> <span>PartialEq</span><span>)</span><span>]</span></span>
<span>pub</span> <span>struct</span> <span>ExternalStruct</span> <span>{</span>
    <span>foo</span><span>:</span> <span>usize</span><span>,</span>
    <span>bar</span><span>:</span> <span>String</span><span>,</span>
    <span>baz</span><span>:</span> <span>f64</span><span>,</span>
<span>}</span>

<span>impl</span> <span>ExternalStruct</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>foo</span><span>:</span> <span>usize</span><span>,</span> <span>bar</span><span>:</span> <span>String</span><span>,</span> <span>baz</span><span>:</span> <span>f64</span><span>)</span> -&gt; <span>Self</span> <span>{</span>
        <span>ExternalStruct</span> <span>{</span> foo<span>,</span> bar<span>,</span> baz <span>}</span>
    <span>}</span>

    <span>// Embedding functions that take self by value</span>
    <span>pub</span> <span>fn</span> <span>method_by_value</span><span>(</span><span>self</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>method_by_reference</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span>
    <span>}</span>

    <span>// Setters should update the value and return a new instance (functional set)</span>
    <span>pub</span> <span>fn</span> <span>set_foo</span><span>(</span><span>mut</span> <span>self</span><span>,</span> <span>foo</span><span>:</span> <span>usize</span><span>)</span> -&gt; <span>Self</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span> = foo<span>;</span>
        <span>self</span>
    <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> vm = <span>Engine</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    <span>// Registering a type gives access to a predicate for the type</span>
    vm<span>.</span><span>register_type</span><span>::</span><span>&lt;</span><span>ExternalStruct</span><span>&gt;</span><span>(</span><span>"ExternalStruct?"</span><span>)</span><span>;</span>

    <span>// Structs in steel typically have a constructor that is the name of the struct</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"ExternalStruct"</span><span>,</span> <span>ExternalStruct</span><span>::</span>new<span>)</span><span>;</span>

    <span>// register_fn can be chained</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"method-by-value"</span><span>,</span> <span>ExternalStruct</span><span>::</span>method_by_value<span>)</span>
        <span>.</span><span>register_fn</span><span>(</span><span>"method-by-reference"</span><span>,</span> <span>ExternalStruct</span><span>::</span>method_by_reference<span>)</span>
        <span>.</span><span>register_fn</span><span>(</span><span>"set-foo"</span><span>,</span> <span>ExternalStruct</span><span>::</span>set_foo<span>)</span><span>;</span>

    <span>let</span> external_struct = <span>ExternalStruct</span><span>::</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>"foo"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span> <span>12.4</span><span>)</span><span>;</span>

    <span>// Registering an external value is fallible if the conversion fails for some reason</span>
    <span>// For instance, registering an Err(T) is fallible. However, most implementation outside of manual</span>
    <span>// ones should not fail</span>
    vm<span>.</span><span>register_external_value</span><span>(</span><span>"external-struct"</span><span>,</span> external_struct<span>)</span>
        <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> output = vm
        <span>.</span><span>run</span><span>(</span>
            <span>r#"</span>
<span>            (define new-external-struct (set-foo external-struct 100))</span>
<span>            (define get-output (method-by-value external-struct))</span>
<span>            (define second-new-external-struct (ExternalStruct 50 "bananas" 72.6))</span>
<span>            "last-result"</span>
<span>        "#</span><span>,</span>
        <span>)</span>
        <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> new_external_struct = vm<span>.</span><span>extract</span><span>::</span><span>&lt;</span><span>ExternalStruct</span><span>&gt;</span><span>(</span><span>"new-external-struct"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"new_external_struct: {:?}"</span>, new_external_struct<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span>
        <span>ExternalStruct</span>::new<span>(</span><span>100</span>, <span>"foo"</span>.to_string<span>(</span><span>)</span>, <span>12.4</span><span>)</span>,
        new_external_struct
    <span>)</span><span>;</span>

    <span>// Can also extract a value by specifying the type on the variable</span>
    <span>let</span> get_output<span>:</span> <span>usize</span> = vm<span>.</span><span>extract</span><span>(</span><span>"get-output"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"get_output: {}"</span>, get_output<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>1</span>, get_output<span>)</span><span>;</span>

    <span>let</span> second_new_external_struct<span>:</span> <span>ExternalStruct</span> =
        vm<span>.</span><span>extract</span><span>(</span><span>"second-new-external-struct"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span>
        <span>"second_new_external_struct: {:?}"</span>,
        second_new_external_struct
    <span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span>
        <span>ExternalStruct</span>::new<span>(</span><span>50</span>, <span>"bananas"</span>.to_string<span>(</span><span>)</span>, <span>72.6</span><span>)</span>,
        second_new_external_struct
    <span>)</span><span>;</span>

    <span>// We also get the output of the VM as the value of every expression run</span>
    <span>// we can inspect the results just by printing like so</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span>, output<span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">See the examples folder for more examples on embedding values and interacting with the outside world.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">Licensed under either of</p>
<ul dir="auto">
<li>Apache License, Version 2.0
(<a href="https://github.com/mattwparas/steel/blob/master/LICENSE-APACHE">LICENSE-APACHE</a> or <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a>)</li>
<li>MIT license
(<a href="https://github.com/mattwparas/steel/blob/master/LICENSE-MIT">LICENSE-MIT</a> or <a href="http://opensource.org/licenses/MIT" rel="nofollow">http://opensource.org/licenses/MIT</a>)</li>
</ul>
<p dir="auto">at your option.</p>
<h2 tabindex="-1" dir="auto">Contribution</h2>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.</p>
<p dir="auto">See [CONTRIBUTING.md].</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All the hominins made tools (109 pts)]]></title>
            <link>https://johnhawks.net/weblog/all-the-hominins-made-tools/</link>
            <guid>38508418</guid>
            <pubDate>Sun, 03 Dec 2023 16:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://johnhawks.net/weblog/all-the-hominins-made-tools/">https://johnhawks.net/weblog/all-the-hominins-made-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=38508418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      


      <section>
        <p>The two inventors of the idea of natural selection had somewhat different viewpoints about how technology mattered to human origins. In an 1864 lecture, Alfred Russel Wallace observed that tools, weapons, and clothing all tend to remove humans from the direct action of natural selection on the form of the body. Wallace suggested that the physical features of the human body had become “fixed and permanent”. Instead, he offered, Man had been “kept in harmony with the slowly changing universe around him, by an advance in mind, rather than by a change in body.” </p><p>Charles Darwin also saw tools and weapons as highly important to human evolution. But where Wallace had suggested a major shift in natural selection away from bodies toward minds, Darwin emphasized the continuities that link humans and other primates. He discussed evidence of the use of stones by chimpanzees for cracking nuts, and mentioned that some American monkeys were easily trained to do the same. Darwin saw it as essential that people differ from other animals in degree, not in kind, and he considered this equally true for mental as for physical characteristics. For Darwin, this continuity of structure and behavior was a powerful argument that natural selection had crafted humans just as it had crafted other species. Where others imagined a gulf, Darwin invariably saw stepping stones.</p><p>This difference between Wallace and Darwin comes to mind when I look at the way that paleoanthropologists discuss evidence of tool use. Many researchers have considered stone and bone tools to be uniquely connected with the origin of our own genus, <em>Homo</em>. Like Wallace, they imagine a transition in our evolutionary trajectory: Once our ancestors began to rely more and more on technology, natural selection on the form of the body became less and less relevant. The evolution of toolmakers would be driven by natural selection on the mind. </p><p>But humans are far from unique in our use of technology. Our closest living relatives, chimpanzees and bonobos, are technical species that use a wide array of tools, mostly made from organic and perishable materials. Both bonobos and chimpanzees use tools as part of their social interactions with other individuals, and both species use tools sometimes to make themselves feel more comfortable. Chimpanzees additionally make and use a wide array of tools to help them get foods that are hard to process without tools, for example by cracking nuts, “fishing” for termites, or extracting honey from underground bee nests. Most chimpanzees do not use stone, but western chimpanzees use stones for nutcracking and a fascinating behavior known as “accumulative stone throwing”. Bonobos and chimpanzees have hands and wrists that are very different from humans, specialized for knuckle-walking on the ground and suspending below branches while climbing. These marked differences in anatomy do not impede chimpanzees or bonobos from manipulating objects, shaping them for a purpose, and using the resulting tools to accomplish their aims. </p><figure><img src="https://johnhawks.net/content/images/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg" alt="A chimpanzee blurred from motion in the action of throwing a stone at a tree" loading="lazy" width="1500" height="1170" srcset="https://johnhawks.net/content/images/size/w600/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 1000w, https://johnhawks.net/content/images/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 1500w" sizes="(min-width: 720px) 720px"><figcaption><span>Chimpanzee at Boé, Guinea-Bissau, throwing a large rock as part of the “accumulative stone throwing” behavior. Video still from Kühl and coworkers 2016.</span></figcaption></figure><p>Bonobos and chimpanzees help show how much variation in social learning of toolmaking can evolve between closely related species. Nearly all the differences between them are manifested in perishable materials, tools that would leave no trace after millions of years. Every indication from the anatomy of early hominins and their ecology points toward Darwin's insight that the technical behavior of nonhuman primates is continuous with behavior once manifested by human ancestors and early humans. </p><h3 id="many-species-made-early-stone-and-bone-tools">Many species made early stone and bone tools</h3><p>The earliest-known stone tools are from Lomekwi 3, Kenya, made around 3.3 million years ago and first described by Sonia Harmand and the West Turkana Archaeological Project in 2015. The toolmakers, whoever they were, lived a half million years before the earliest fossils that have been attributed to the genus <em>Homo. </em>The only fossil hominin identified from the Lomekwi area around this time is <em>Kenyanthropus platyops</em>. </p><figure><img src="https://johnhawks.net/content/images/2023/12/africa-sites-early-artifacts-2023.jpg" alt="Map of Africa with insets of the East African Rift System and Cradle of Humankind area of South Africa, with sites labeled" loading="lazy" width="1920" height="1080" srcset="https://johnhawks.net/content/images/size/w600/2023/12/africa-sites-early-artifacts-2023.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/africa-sites-early-artifacts-2023.jpg 1000w, https://johnhawks.net/content/images/size/w1600/2023/12/africa-sites-early-artifacts-2023.jpg 1600w, https://johnhawks.net/content/images/2023/12/africa-sites-early-artifacts-2023.jpg 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>Map of archaeological and fossil sites relevant to early associations of artifacts and fossil hominin remains. Most of these are included in the timeline below. Many other early archaeological sites exist that are not labeled here.</span></figcaption></figure><p>Fossils and artifacts are <strong>associated</strong> when both are found within the same sedimentary context, buried at around the same time in the same place. Few early archaeological sites have any hominin fossils. When a hominin fossil happens to be found at such a site, it is often only a single tooth or small fragment of bone. For example, a recent paper by Dylan Flicker and Alister Key lists ten archaeological sites with Oldowan artifacts that have been dated to the period between 2.6 million and 2.0 million years ago. Out of the ten sites, only five have any trace of hominin fossil remains, only one of the five has hominin fossils that are identifiable to the species level—in this case, <em>Paranthropus robustus</em> in Sterkfontein Member 5 East.</p><p>Earlier this year, Thomas Plummer and coworkers described the earliest association between stone artifacts and hominin fossils, from Nyayanga, Kenya. This site has now produced the oldest-known Oldowan archaeological material, between 3.03 million and 2.58 million years old. The two hominin fossils are a single isolated molar and a second tooth fragment. Both are similar to teeth of <em>Paranthropus</em>, although the teeth provide too little information to attribute them to a species. </p><p>In a recent article in <em>L'Anthropologie</em>, Sandrine Prat reviewed the record of association between stone tool evidence and fossil hominin remains, from the period between 3 million and 1.2 million years ago. The review included twenty-nine situations with artifacts and fossil hominin remains, all from Ethiopia, Kenya, or Tanzania. She also discusses sites in South Africa, while recognizing that the geological situations represented by these cave sites are not quite equivalent to the open air sedimentary deposits from the East African Rift System. </p><p>I plotted these sites all together here, adding a handful of data points from other situations that also fall within the same time range, such as Dmanisi, Republic of Georgia. I also added Lomekwi 3, despite the lack of direct association with hominin fossils, to show where later sites fit relative to these earliest known artifacts. </p><figure><img src="https://johnhawks.net/content/images/2023/11/timeline-early-stone-tool-associations-prat-2023.png" alt="Timeline of early tool evidence associated with hominin fossil material. The image shows that Paranthropus and Homo species are both associated with stone and bone tools. " loading="lazy" width="1920" height="1386" srcset="https://johnhawks.net/content/images/size/w600/2023/11/timeline-early-stone-tool-associations-prat-2023.png 600w, https://johnhawks.net/content/images/size/w1000/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1000w, https://johnhawks.net/content/images/size/w1600/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1600w, https://johnhawks.net/content/images/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The pattern is striking. <em>Paranthropus</em> and <em>Homo</em> species are both found in association with stone and bone artifacts throughout the period of their coexistence. The data provide no reason to suggest that either of these branches of hominins is more or less a toolmaker than the other. </p><p>Prat also discussed anatomical evidence from these species, particularly the form of the hand and wrist. All known hand and wrist fossils from <em>Australopithecus</em> and <em>Paranthropus</em> are consistent with the kinds of grips used in making and using stone tools. To be sure, there have been many scientific debates about the functional anatomy of hand and wrist fossils from these early hominins. But those debates have been about whether some features of the <em>Australopithecus</em> and <em>Paranthropus </em>hands may reflect a greater reliance on climbing than in <em>Homo</em>. All features of these hominin hands are consistent with fine motor control and manipulation of objects in ways consistent with tool use. That means there's no anatomical basis to say that <em>Paranthropus</em> or <em>Australopithecus</em> used tools less than <em>Homo</em>. That should be no surprise, considering the extent of tool use by chimpanzees and bonobos without the same ability to produce many of the grips used by humans.</p><h3 id="paranthropus-the-neglected-toolmaker"><em>Paranthropus: </em>the neglected toolmaker</h3><p><em>Paranthropus robustus</em> is the most common hominin represented in South African sites between 2.3 million and 1.0 million years ago. Nearly every context with fossils of <em>P. robustus</em> also has stone artifacts and bone tools. In the East African Rift System, <em>Paranthropus boisei</em> is the most common hominin species across the same range of time. Many sites with <em>P. boisei</em> also have stone artifacts, although the sedimentary exposures of the rift quite commonly have fossils that are found in isolation without other fossils or artifacts nearby. Only in the northeasternmost section of the Ethiopian Rift was <em>P. boisei</em> absent. </p><p>With this pattern of association of stone and bone artifacts with <em>Paranthropus,</em> it may seem challenging to explain why archaeologists long ignored this branch of hominins as potential tool using species. This bias can be tracked back to the 1950s, as John Robinson, C. K. Brain, and Revil Mason uncovered evidence of stone tools in the deposits of Sterkfontein. </p><figure><img src="https://johnhawks.net/content/images/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png" alt="Two Oldowan choppers, each pictured from two different directions" loading="lazy" width="2000" height="784" srcset="https://johnhawks.net/content/images/size/w600/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 600w, https://johnhawks.net/content/images/size/w1000/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 1000w, https://johnhawks.net/content/images/size/w1600/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 1600w, https://johnhawks.net/content/images/size/w2400/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Oldowan artifacts from Sterkfontein. Image from Robinson (1957)</span></figcaption></figure><p>Working under Robinson's direction, Brain and Mason opened an area of excavation at Sterkfontein that became known as the Extension Site. In the westernmost part of this area, the breccia contained many stone tools. In 1959, Robinson identified a bone tool from the site, marked by striations and polish on its tip. For twenty years, first Robert Broom and then John Robinson had found fossils of <em>Australopithecus africanus </em>at Sterkfontein. Was this species the toolmaker? </p><p>In early August of 1959, Mary Leakey excavated the first fossil skull of the species we know today as <em>Paranthropus boisei</em>, from level 22 of the FLK site at Olduvai Gorge. Louis and Mary Leakey had interpreted this level as a “living floor”, with abundant stone artifacts of the tradition they had named the Oldowan Industrial Complex. In his description of the skull, which he named <em>Zinjanthropus</em>, Louis emphasized its near-pristine preservation as a reason why this individual was different from the broken and fragmented animal bones at the site. <em>Zinjanthropus</em>, he argued, must be the maker of the tools. </p><p>Many anthropologists were happy to accept these hominins as makers of stone tools. For example, Sherwood Washburn discussed the <em>Zinjanthropus</em> discovery as confirming the discoveries by Robinson and Brain that seemed to associate <em>Australopithecus</em> with artifacts. He ridiculed the assertion by some other researchers that “no creature with so small a brain could have made tools”. Nevertheless, he wrote, the problem could only be solved by excavation. </p><blockquote>“An association in one site cannot settle the matter, and the situation is further complicated because several kinds of Australopithecus and Homo may have made tools. It is perfectly possible that different species of australopithecines and early Homo lived at the same time and <strong>all</strong> made tools.”—Sherwood Washburn</blockquote><p>One of the scientists with doubts was Robinson himself. His work made clear that the <em>Australopithecus</em> fossils from Sterkfontein were older than the Swartkrans breccia, which had fossils of <em>Paranthropus robustus</em> as well as a more humanlike form that Robinson and Robert Broom had called <em>Telanthropus capensis.</em> Robinson viewed <em>Telanthropus </em>as “an australopithecine that had attained euhominid status”—in other words, something that today we would recognize as early <em>Homo</em>. A few years later Robinson would accept <em>Telanthropus</em> as identical to <em>Homo erectus</em>, although today researchers see this as a heterogeneous group of fossils which may include some early <em>Homo</em> individuals but also some that belong to <em>P. robustus</em> or <em>Australopithecus sediba</em>. Brain had identified some quartzite artifacts in the Swartkrans breccia. As they continued to work the Sterkfontein deposits, it became clear that the artifact-bearing breccia was somewhere in the middle: later than most of the <em>Australopithecus</em> fossils from the site but earlier than Swartkrans. Still, even though the artifacts seemed to be later than most of the <em>Australopithecus</em> deposit, Robinson identified some <em>Australopithecus</em>-like fragments in the area where stone tools were found, and no other hominin remains. </p><p>Robinson admitted that it seemed logical to conclude that <em>Australopithecus</em> had made the tools. In fact, Robinson, Mason, and many others at the time accepted Raymond Dart's idea that the pattern of broken animal bones from the Makapan Limeworks site might represent an early use of bones as tools by <em>Australopithecus</em>. But Robinson considered the stone tools from Sterkfontein too advanced for the earlier species, and he noted that most of the <em>Australopithecus </em>fossils, from Sterkfontein, Taung, and Makapan, had come from contexts where no stone tools had yet been found. He thought that <em>Telanthropus</em> must surely have made the stone tools instead. The very absence of evidence became a centerpiece of his argument: </p><blockquote>“Perhaps the very fact that <em>Australopithecus</em> is common at Sterkfontein is an argument against it being a tool-maker, since in all other very early Stone Age sites remains of the tool manufacturer are extremely rare.”—John Robinson</blockquote><p>Today researchers have established that Robinson's West Pit included breccia that belongs to Member 5 West deposits, which include Oldowan artifacts and some bifaces, and likely postdates 2 million years ago. The earlier Oldowan Infill of Member 5 East is the earliest-known Oldowan assemblage from South Africa with a cosmogenic date assessment of 2.18&nbsp;±&nbsp;0.21&nbsp;Myr and currently includes only <em>Paranthropus</em> fossils. </p><p>The Olduvai Gorge picture changed markedly in 1960 with the discovery of the OH 7 mandible, partial cranium, and hand at the FLK-NN site. The OH 7 jaw was much more like <em>Australopithecus</em> than the <em>Zinjanthropus </em>skull had been, but its parietal bones suggested a larger brain size—ultimately Phillip Tobias would estimate it as 750 ml. As Mary and Louis Leakey continued to work, they found remains of more individuals with a similar dental pattern, different from <em>Zinjanthropus</em>. None of the other cranial remains reflected a brain as large as OH 7, but fossils like OH 16 and OH 13 were a bit larger in brain size than <em>Australopithecus</em> was. By 1964, Louis Leakey, Phillip Tobias, and John Napier were ready to recognize these as a transitional species between <em>Australopithecus</em> and <em>Homo erectus</em>: they named it <em>Homo habilis</em>. </p><p>Everything that Louis Leakey had said about <em>Zinjanthropus</em> being the Oldowan toolmaker, he now took back. </p><blockquote>“While it is possible that Zinjanthropus and Homo habilis both made stone tools, it is probable that the latter was the more advanced tool maker and that the Zinjanthropus skull represents an intruder (or a victim) on a Homo habilis living site.”—Louis Leakey, Phillip Tobias, and John Napier</blockquote><p><em>Homo habilis</em> was the favored hominin. <em>Zinjanthropus</em>, once vaunted as the toolmaker, was now roadkill. For many scientists, Leakey's backtracking was all they needed as proof that stone tools were the exclusive province of <em>Homo</em>. </p><p>It would take two decades for scientists to recognize the toolmaking potential of <em>Paranthropus</em>. The most important researcher behind this change was C. K. Brain. After more than twenty years working to understand the Swartkrans site, Brain had learned much about the associations of hominin fossils and their entry into the site. He found more bone tools, similar to the one noted by Robinson at Sterkfontein, and together with Pat Shipman quantified the wear that marked the tips of the tools as the possible result of digging in stony soil for underground bulbs. Later research by Lucinda Backwell and Francesco d'Errico further suggested that some of the bone artifacts had been used to puncture hard termite nests. Brain showed that <em>P. robustus</em> was the predominant hominin element in the Swartkrans assemblage, with <em>Homo</em> very rare within the deposits, yet artifacts were present throughout. The hand fossils also told a story. Analyzed by Randall Susman and reviewed by Brain, it was clear that the <em>Paranthropus</em> hand anatomy was fully capable of making and using tools. </p><blockquote>“The notion that&nbsp;toolmaking provided the&nbsp;adaptive wedge&nbsp;that separated&nbsp;the&nbsp;robust australopithecines&nbsp;from&nbsp;the gracile australopithecines and early&nbsp;<em>Homo</em> may&nbsp;be tenable&nbsp;no&nbsp;longer.”—C. K. Brain and coworkers</blockquote><h3 id="which-hominin-species-lacked-stone-or-bone-artifacts">Which hominin species lacked stone or bone artifacts?</h3><p>While today's data associating some archaeological materials with fossil hominin remains are much better than the past, they remain incomplete. Before 3 million years ago, the only known site with stone artifacts is Lomekwi 3. As discussed above, the hominin fossils from the Turkana Basin near that time have been classified as <em>Kenyanthropus platyops</em>. The more widespread <em>Australopithecus afarensis,</em> which lived much further north in the Afar triangle of Ethiopia, and further south at Kantis, Kenya, and Laetoli, Tanzania, may have been present in the Turkana Basin also. I don't think we can be sure which early species made these particular tools, nor would I bet that someone won't find even earlier artifacts. </p><p>At the very least, though, I think we must acknowledge that the use of stone artifacts was rare before 3 million years ago. Most hominins from this time, including species such as <em>Australopithecus anamensis</em> and <em>Australopithecus deyiremeda</em>, may not have used stone. That wouldn't surprise me at all: both bonobos and eastern and central chimpanzees show how extensive toolmaking can be without using stone as a raw material. But I don't think the record is strong enough to rule out stone tool use of the kind practiced by western chimpanzees, including the use of hammerstones for nutcracking and minimal transport of stone. It would be very challenging to test for this kind of behavior with the kinds of archaeological surveys that have been practical in fossil exposures from the Pliocene. </p><p>In addition to direct evidence from artifacts, there may be indirect evidence of stone tool use, such as cutmarks and puncture marks on the bones of prey animals. In 2010, Shannon McPherron and coworkers reported that 3.4-million-year-old animal bones from Dikika, Ethiopia, show cutmarks from stone tools, although they did not find the artifacts themselves. Some other researchers disputed this evidence, suggesting that crocodiles or other carnivores might have generated these marks. </p><p>A higher degree of acceptance has been given to claims of cutmarks and puncture marks on antelope and horse bones from 2.5 million years ago, at Bouri, Ethiopia. Some of these discoveries were near the BOU-VP-12 locality with fossil material of <em>Australopithecus garhi</em>. Other sites from this region, including Gona, Hadar, and Ledi-Geraru, do preserve stone artifacts from the same time or earlier, but without any associated hominin remains. Later, around 3.3 million years ago, stone tools from Hadar have been associated with a maxilla attributed to early <em>Homo</em>, but the first possible mandible of <em>Homo</em> from Ledi-Geraru is not from a locality with artifacts. </p><p><em>Australopithecus africanus</em> remains a challenging case. No stone tools have been found in contexts where <em>Au. africanus</em> fossils clearly occur, at Sterkfontein, Makapan Limeworks, or Taung. Recent work has shown that the Sterkfontein Member 4 fossils of <em>Au. africanus</em> may be older than 3.4 million years—therefore, older than any known artifacts anywhere. The Makapan and Taung sites themselves may be older than 2.8 million, and so it is possible that <em>Au. africanus</em> simply existed before stone tools were used in South Africa. Yet there remains some uncertainty. For one thing, some authors dispute the idea that Sterkfontein Member 4 is as early as 3.4 million years, preferring a date between 2.6 million and 2.1 million years ago. Another element of uncertainty comes from the StW 53 cranium, which I and many other scientists attribute to <em>Au. africanus</em>, and which has marks on its maxilla that some authors have argued are cutmarks from a stone artifact. Just as for <em>Paranthropus</em>, the anatomical evidence from the hand bones of <em>Au. africanus</em> suggests that this species had the fine precision grip and relied on hand postures that today's humans use for making and using tools. </p><figure><img src="https://johnhawks.net/content/images/2023/12/sediba-wrist-and-hand-johnhawks.jpg" alt="A view of the wrist anatomy of an articulated fossil hand" loading="lazy" width="1600" height="900" srcset="https://johnhawks.net/content/images/size/w600/2023/12/sediba-wrist-and-hand-johnhawks.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/sediba-wrist-and-hand-johnhawks.jpg 1000w, https://johnhawks.net/content/images/2023/12/sediba-wrist-and-hand-johnhawks.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Cast of the hand and wrist of MH2, </span><i><em>Australopithecus sediba</em></i><span>, from Malapa, South Africa. Photo: John Hawks</span></figcaption></figure><p>The notable late <em>Australopithecus</em> site is Malapa, with <em>Australopithecus sediba</em> at 1.977 million years ago. No artifacts have yet been reported from this locality. Still, recent work from Clément Zanolli and coworkers has shown that many dental and mandibular fossils from Swartkrans, Drimolen, and Sterkfontein Member 5 that were previously attributed to <em>Homo</em> may instead belong to <em>Paranthropus</em> or <em>Australopithecus</em>. It seems probable that many of these may be unrecognized <em>Au. sediba</em> individuals. Any of those would be associated with Oldowan artifacts and bone tools from these sites. </p><p>The well-known species of <em>Homo</em> that doesn't show up in the dataset on associations of artifacts and fossils is <em>Homo rudolfensis</em>. This is another case where only a handful of fossils are clearly associated with this species. It may be surprising, but I would argue that only four fossils might be strongly linked to <em>H. rudolfensis</em>: the KNM-ER 1470 cranium, KNM-ER 62000 subadult face, and two mandibular fossils—KNM-ER 60000 and KNM-ER 62003. None are from localities with archaeological material. There are other fossils that might conceivably belong to <em>H. rudolfensis</em>, but many of the ones that past anthropologists connected with this species, like the KNM-ER 1802 mandible or the UR 501 mandible from Uraha, Malawi, may be <em>Australopithecus</em> instead. </p><h3 id="toolmaking-ecology-across-species">Toolmaking ecology across species</h3><p>It's clear that associations of fossils and artifacts can go only so far. Robinson preferred the hypothesis that the most advanced hominin on the scene must have made any artifacts. Many researchers during the last 60 years have followed this point of view. But today's data allow us to test whether any fossil species is consistently associated with artifacts. After around 2.8 million years ago every fossil species is found with artifacts, with the few exceptions being those species that have been identified from only a single locality or—in the case of <em>H. rudolfensis</em>—a handful of localities. The two branches that are found most regularly with artifactual evidence, <em>Paranthropus</em> and <em>Homo</em>, are both represented at archaeological localities in equal measure; only <em>Paranthropus</em> is present at the earliest two Oldowan localities. </p><p>It is hard for me to improve on C. K. Brain's conclusions about tool use. By the Early Pleistocene, all hominins had the anatomical capability of making and using stone tools, and most of them did so. As in living bonobos and chimpanzees, tool use may have differed markedly between species and populations, depending upon their particular ecological situations. It was the uses of the tools that differentiated the hominins, not the capacity to use tools. </p><p>Yet maybe even this underestimates the commonalities across species. Stable isotopes and dental microwear suggest that <em>P. robustus</em> and early <em>Homo</em> in southern Africa were eating similar foods, despite what seem to be some important differences in dental morphology. If their ecologies were much the same, and their hand anatomies were much the same, it is hard to justify any assumption that they would have been different in their use of tools. </p><p>Going further, wherever both species existed they both would have encountered each other's trash. Each individual scattering stone across a landscape changed the potentialities for every other hominin. Each species existed within the ecology of the other. When one was rapping cobble on core, others heard them hundreds of meters away. They learned from each other. Their use of resources must often have converged. </p><p>Darwin wrote eloquently about the way that small steps in tool use would change the potentialities for “primeval” humans. </p><blockquote>“The Duke of Argyll&nbsp;remarks, that the fashioning of an implement for a special purpose is absolutely peculiar to man; and he considers that this forms an immeasurable gulf between him and the brutes. It is no doubt a very important distinction, but there appears to me much truth in Sir J. Lubbock's suggestion,&nbsp;that when primeval man first used flint-stones for any purpose, he would have accidentally splintered them, and would then have used the sharp fragments. From this step it would be a small one to intentionally break the flints, and not a very wide step to rudely fashion them.”—Charles Darwin</blockquote><p>Tool use does not make humans unique; it links us to our ancestors and relatives. Those links that remain are phylogenetic, but they were once living cultural links. It is true that recent humans have become reliant upon our tools in ways that early hominins would not have recognized. Before this time we lived in a world of transitions into and out of technical traditions. The steps across species in tool use were once small ones, interconnected actions that spanned differences in body size and form. </p><hr><p><em><strong>Notes:</strong> The current evidence of hand anatomy in various hominins is ably reviewed in several papers by Tracy Kivell, Matt Skinner, and many of their collaborators. The work by Cl</em>é<em>ment Zanolli and coworkers highlighting internal dental evidence for affinities of South African dental material is worth reading for its broader implications: we have little reliable information about the species identity of many isolated finds. I did not include in the references below all the works that underlie the dataset described by Sandrine Prat, or every paper related to the dating of sites discussed in the post. </em></p><p><em>I've only included a few words here about the cultural behavior of chimpanzees and bonobos. This is a rich area with deep importance for understanding early hominins, and hopefully I will be able to expand on this in an additional post. </em></p><p><em>There may be readers who suspect I am being unfair to Wallace in this comparison of views on technology. The differences between Wallace and Darwin on the extent that natural selection could explain human cultural abilities have been the subject of many historians of science, and two paragraphs inevitably oversimplify these differences. I think it's fair to say that Darwin and Wallace were concerned with different aspects of the human origins problem. </em></p><h3 id="references">References</h3><p>Brain, C. K., Churcher, C. S., Clark, J. D., Grine, F. F., Shipman, P., Susman, R. L., Turner, A. and Watson V. (1988). New evidence of early hominids, their culture and environment from the Swartkrans cave, South Africa.&nbsp;<em>South African Journal of Science</em>,&nbsp;<em>84</em>(10), 828.&nbsp;<a href="https://doi.org/10.10520/AJA00382353_6877?ref=johnhawks.net">https://doi.org/10.10520/AJA00382353_6877</a></p><p>Darwin, C. (1871).&nbsp;<em>The Descent of Man, and Selection in Relation to Sex</em>. John Murray.</p><p>Flicker, D., &amp; Key, A. (2023). Statistical assessment of the temporal and cultural relationship between the Lomekwian and Oldowan.&nbsp;<em>Journal of Archaeological Science: Reports</em>,&nbsp;<em>48</em>, 103834.&nbsp;<a href="https://doi.org/10.1016/j.jasrep.2023.103834?ref=johnhawks.net">https://doi.org/10.1016/j.jasrep.2023.103834</a></p><p>Harmand, S., Lewis, J. E., Feibel, C. S., Lepre, C. J., Prat, S., Lenoble, A., Boës, X., Quinn, R. L., Brenet, M., Arroyo, A., Taylor, N., Clément, S., Daver, G., Brugal, J.-P., Leakey, L., Mortlock, R. A., Wright, J. D., Lokorodi, S., Kirwa, C., … Roche, H. (2015). 3.3-million-year-old stone tools from Lomekwi 3, West Turkana, Kenya.&nbsp;<em>Nature</em>,&nbsp;<em>521</em>(7552), Article 7552.&nbsp;<a href="https://doi.org/10.1038/nature14464?ref=johnhawks.net">https://doi.org/10.1038/nature14464</a></p><p>Kivell, T. L., Baraki, N., Lockwood, V., Williams-Hatala, E. M., &amp; Wood, B. A. (2023). Form, function and evolution of the human hand.&nbsp;<em>American Journal of Biological Anthropology</em>,&nbsp;<em>181</em>(S76), 6–57.&nbsp;<a href="https://doi.org/10.1002/ajpa.24667?ref=johnhawks.net">https://doi.org/10.1002/ajpa.24667</a></p><p>Kühl, H. S., Kalan, A. K., Arandjelovic, M., Aubert, F., D’Auvergne, L., Goedmakers, A., Jones, S., Kehoe, L., Regnaut, S., Tickle, A., Ton, E., van Schijndel, J., Abwe, E. E., Angedakin, S., Agbor, A., Ayimisin, E. A., Bailey, E., Bessone, M., Bonnet, M., … Boesch, C. (2016). Chimpanzee accumulative stone throwing.&nbsp;<em>Scientific Reports</em>,&nbsp;<em>6</em>(1), Article 1.&nbsp;<a href="https://doi.org/10.1038/srep22219?ref=johnhawks.net">https://doi.org/10.1038/srep22219</a></p><p>Leakey, L. S. B. (1959). A New Fossil Skull From Olduvai.&nbsp;<em>Nature</em>,&nbsp;<em>184</em>(4685), Article 4685.&nbsp;<a href="https://doi.org/10.1038/184491a0?ref=johnhawks.net">https://doi.org/10.1038/184491a0</a></p><p>Leakey, L. S. B., Tobias, P. V., &amp; Napier, J. R. (1964). A New Species of The Genus Homo From Olduvai Gorge.&nbsp;<em>Nature</em>,&nbsp;<em>202</em>(4927), Article 4927.&nbsp;<a href="https://doi.org/10.1038/202007a0?ref=johnhawks.net">https://doi.org/10.1038/202007a0</a></p><p>McPherron, S. P., Alemseged, Z., Marean, C. W., Wynn, J. G., Reed, D., Geraads, D., Bobe, R., &amp; Béarat, H. A. (2010). Evidence for stone-tool-assisted consumption of animal tissues before 3.39 million years ago at Dikika, Ethiopia.&nbsp;<em>Nature</em>,&nbsp;<em>466</em>(7308), Article 7308.&nbsp;<a href="https://doi.org/10.1038/nature09248?ref=johnhawks.net">https://doi.org/10.1038/nature09248</a></p><p>Oakley, K. (1957). Tools Makyth Man.&nbsp;<em>Antiquity</em>,&nbsp;<em>31</em>(124), 199–209.&nbsp;<a href="https://doi.org/10.1017/S0003598X00028453?ref=johnhawks.net">https://doi.org/10.1017/S0003598X00028453</a></p><p>Plummer, T. W., Oliver, J. S., Finestone, E. M., Ditchfield, P. W., Bishop, L. C., Blumenthal, S. A., Lemorini, C., Caricola, I., Bailey, S. E., Herries, A. I. R., Parkinson, J. A., Whitfield, E., Hertel, F., Kinyanjui, R. N., Vincent, T. H., Li, Y., Louys, J., Frost, S. R., Braun, D. R., … Potts, R. (2023). Expanded geographic distribution and dietary strategies of the earliest Oldowan hominins and <em>Paranthropus</em>.&nbsp;<em>Science</em>,&nbsp;<em>379</em>(6632), 561–566.&nbsp;<a href="https://doi.org/10.1126/science.abo7452?ref=johnhawks.net">https://doi.org/10.1126/science.abo7452</a></p><p>Prat, S. (2023). Beyond the genus stereotype. Who were the first toolmarkers in Africa? Crossed views between archaeology and anatomy.&nbsp;<em>L’Anthropologie</em>,&nbsp;<em>127</em>(4), 103187.&nbsp;<a href="https://doi.org/10.1016/j.anthro.2023.103187?ref=johnhawks.net">https://doi.org/10.1016/j.anthro.2023.103187</a></p><p>Robinson, J. T. (1957). Occurrence of Stone Artefacts with Australopithecus at Sterkfontein: Part 1.&nbsp;<em>Nature</em>,&nbsp;<em>180</em>(4585), Article 4585.&nbsp;<a href="https://doi.org/10.1038/180521a0?ref=johnhawks.net">https://doi.org/10.1038/180521a0</a></p><p>Robinson, J. T., &amp; Mason, R. J. (1962). Australopithecines and Artefacts at Sterkfontein.&nbsp;<em>The South African Archaeological Bulletin</em>,&nbsp;<em>17</em>(66), 87–126.&nbsp;<a href="https://doi.org/10.2307/3886942?ref=johnhawks.net">https://doi.org/10.2307/3886942</a></p><p>Wallace, A. R. (1864). The Origin of Human Races and the Antiquity of Man Deduced from the Theory of “Natural Selection.”&nbsp;<em>Journal of the Anthropological Society of London</em>,&nbsp;<em>2</em>, clviii–clxxxvii.&nbsp;<a href="https://doi.org/10.2307/3025211?ref=johnhawks.net">https://doi.org/10.2307/3025211</a></p><p>Washburn, S. L. (1959). Speculations on the Interrelations of the History of Tools and Biological Evolution.&nbsp;<em>Human Biology</em>,&nbsp;<em>31</em>(1), 21–31. <a href="https://www.jstor.org/stable/41449226?ref=johnhawks.net">https://www.jstor.org/stable/41449226</a></p><p>Washburn, S. L. (1960). Tools and Human Evolution.&nbsp;<em>Scientific American</em>,&nbsp;<em>203</em>(3), 62–75.</p><p>Zanolli, C., Davies, T. W., Joannes-Boyau, R., Beaudet, A., Bruxelles, L., de Beer, F., Hoffman, J., Hublin, J.-J., Jakata, K., Kgasi, L., Kullmer, O., Macchiarelli, R., Pan, L., Schrenk, F., Santos, F., Stratford, D., Tawane, M., Thackeray, F., Xing, S., … Skinner, M. M. (2022). Dental data challenge the ubiquitous presence of Homo in the Cradle of Humankind.&nbsp;<em>Proceedings of the National Academy of Sciences</em>,&nbsp;<em>119</em>(28), e2111212119.&nbsp;<a href="https://doi.org/10.1073/pnas.2111212119?ref=johnhawks.net">https://doi.org/10.1073/pnas.2111212119</a></p>
      </section>

          <section>
            <a href="https://johnhawks.net/tag/technology/">technology</a><a href="https://johnhawks.net/tag/early-stone-age/">Early Stone Age</a><a href="https://johnhawks.net/tag/australopithecus-africanus/">Australopithecus africanus</a><a href="https://johnhawks.net/tag/australopithecus-sediba/">Australopithecus sediba</a><a href="https://johnhawks.net/tag/kenyanthropus-platyops/">Kenyanthropus platyops</a><a href="https://johnhawks.net/tag/homo-habilis/">Homo habilis</a><a href="https://johnhawks.net/tag/homo-rudolfensis/">Homo rudolfensis</a><a href="https://johnhawks.net/tag/homo-erectus/">Homo erectus</a><a href="https://johnhawks.net/tag/paranthropus-boisei/">Paranthropus boisei</a><a href="https://johnhawks.net/tag/paranthropus-robustus/">Paranthropus robustus</a>
          </section>

        
          <section>
    <p><img data-src="/content/images/size/w320/2022/02/skhul-headshot-john-hawks.jpg" alt="John Hawks" width="80" height="80" src="https://johnhawks.net/content/images/size/w320/2022/02/skhul-headshot-john-hawks.jpg"></p>

  <div>
    

      <p>I'm a paleoanthropologist exploring the world of ancient humans and our fossil relatives. </p>
  </div>
</section>
        
        <div>
                <h2>John Hawks Newsletter</h2>
                <p>Join the newsletter to receive the latest updates in your inbox.</p>
                
<form data-members-form="signup">
  <p><label for="subscribe-box-email">Your email address</label>
    
    
  </p>

  <p>Please check your inbox and click the link to confirm your subscription.</p>
  <p>Please enter a valid email address!</p>
  <p>An error occurred, please try again later.</p>
</form>              </div>

        
    </article>
  </div><div>
          <div>
  <div>
    <p><time datetime="2023-10-13">13 Oct 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/homo-erectus-keeps-getting-older/">Homo erectus keeps getting older</a>
    </h2>
    <p>New work from Melka Kunture, Ethiopia, shows the Garba IVE infant jaw is one of the oldest individuals of this longest-lasting hominin species.</p>
  </div>

    <div>
      <p><img alt="Lingual and buccal views of Garba IVE mandible fragment" data-srcset="
            /content/images/size/w730/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 612w,
            /content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg" srcset="
            https://johnhawks.net/content/images/size/w730/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 612w,
            https://johnhawks.net/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg">
      </p>
    </div>
</div>          <div>
  <div>
    <p><time datetime="2023-09-20">20 Sep 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/guide-to-australopithecus-species/">Guide to Australopithecus species</a>
    </h2>
    <p>These ancient human relatives include the first species with evidence of upright walking and running like humans. They represent more than a third of our evolutionary history.</p>
  </div>

    <div>
      <p><img alt="Five fossil skulls in three-quarter view looking toward the right" data-srcset="
            /content/images/size/w730/2023/09/australopithecus-skulls-montage.jpg 612w,
            /content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg" srcset="
            https://johnhawks.net/content/images/size/w730/2023/09/australopithecus-skulls-montage.jpg 612w,
            https://johnhawks.net/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg">
      </p>
    </div>
</div>          <div>
  <div>
    <p><time datetime="2023-09-03">3 Sep 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/real-story-myosin-jaw-muscles-ancient-brains/">The real story of myosin, jaw muscles, and ancient brains</a>
    </h2>
    <p>The provocative idea that our genus arose with a deactivated muscle gene turned out to be wrong.</p>
  </div>

    <div>
      <p><img alt="Bonobo and gorilla head and neck, showing ecorché muscles on the left side of each" data-srcset="
            /content/images/size/w730/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 612w,
            /content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png" srcset="
            https://johnhawks.net/content/images/size/w730/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 612w,
            https://johnhawks.net/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png">
      </p>
    </div>
</div>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lobsters (226 pts)]]></title>
            <link>https://github.com/lobsters/lobsters</link>
            <guid>38508282</guid>
            <pubDate>Sun, 03 Dec 2023 16:34:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lobsters/lobsters">https://github.com/lobsters/lobsters</a>, See on <a href="https://news.ycombinator.com/item?id=38508282">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h3 tabindex="-1" dir="auto">Lobsters Rails Project <a target="_blank" rel="noopener noreferrer" href="https://github.com/lobsters/lobsters/actions/workflows/check.yml/badge.svg"><img src="https://github.com/lobsters/lobsters/actions/workflows/check.yml/badge.svg" alt="build status"></a></h3>
<p dir="auto">This is the
<a href="https://web.archive.org/web/20230213161624/https://old.reddit.com/r/rails/comments/6jz7tq/source_code_lobsters_a_hacker_news_clone_built/" rel="nofollow">quite sad</a>
source code to the
<a href="https://twitter.com/webshitweekly/status/1399935275057389571" rel="nofollow">ghost town</a> at
<a href="https://lobste.rs/" rel="nofollow">https://lobste.rs</a>.
It is a Rails codebase and uses a SQL (MariaDB in production) backend for the database.</p>
<p dir="auto">You are free to use this code to start your own <a href="https://github.com/lobsters/lobsters/wiki">sister site</a>
because the code is available under a <a href="https://github.com/lobsters/lobsters/blob/master/LICENSE">permissive license</a> (3-clause BSD).
We welcome bug reports and code contributions that help use improve <a href="https://lobste.rs/" rel="nofollow">lobste.rs</a>.
As a volunteer project we're reluctant to take on work that's not useful to our site, so please understand if we don't want to adopt your custom feature.</p>
<h4 tabindex="-1" dir="auto">Contributing bugfixes and new features</h4>
<p dir="auto">We'd love to have your help.
Please see the <a href="https://github.com/lobsters/lobsters/blob/master/CONTRIBUTING.md">CONTRIBUTING</a> file for details.
If you have questions, there is usually someone in <a href="https://lobste.rs/chat" rel="nofollow">our chat room</a> who's familiar with the code.</p>
<h4 tabindex="-1" dir="auto">Initial setup</h4>
<p dir="auto">Use the steps below for a local install or
<a href="https://github.com/lobsters/lobsters-ansible">lobsters-ansible</a> for our production deployment config.
There's an external project <a href="https://github.com/utensils/docker-lobsters">docker-lobsters</a> if you want to use Docker.</p>
<ul dir="auto">
<li>
<p dir="auto">Install the Ruby version specified in <a href="https://github.com/lobsters/lobsters/blob/master/.ruby-version">.ruby-version</a></p>
</li>
<li>
<p dir="auto">Checkout the lobsters git tree from Github</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:lobsters/lobsters.git
$ cd lobsters
lobsters$"><pre>$ git clone git@github.com:lobsters/lobsters.git
$ <span>cd</span> lobsters
lobsters$</pre></div>
</li>
<li>
<p dir="auto">Install Nodejs, needed (or other execjs) for uglifier</p>
<div dir="auto" data-snippet-clipboard-copy-content="Fedora: sudo yum install nodejs
Ubuntu: sudo apt-get install nodejs
OSX: brew install nodejs"><pre>Fedora: sudo yum install nodejs
Ubuntu: sudo apt-get install nodejs
OSX: brew install nodejs</pre></div>
</li>
<li>
<p dir="auto">Run Bundler to install/bundle gems needed by the project:</p>

<ul dir="auto">
<li>If when installing the <code>mysql2</code> gem on macOS, you see
<code>ld: library not found for -l-lpthread</code> in the output, see
<a href="https://stackoverflow.com/a/44790834/204052" rel="nofollow">this solution</a> for a fix.
You might also see <code>ld: library not found for -lssl</code> if you're using
macOS 10.4+ and Homebrew <code>openssl</code>, in which case see
<a href="https://stackoverflow.com/a/39628463/1042144" rel="nofollow">this solution</a>.</li>
</ul>
</li>
<li>
<p dir="auto">Create a MySQL (other DBs supported by ActiveRecord may work, only MySQL and
MariaDB have been tested) database, username, and password and put them in a
<code>config/database.yml</code> file.  You will also want a separate database for
running tests:</p>
<div dir="auto" data-snippet-clipboard-copy-content="development:
  adapter: mysql2
  encoding: utf8mb4
  reconnect: false
  database: lobsters_dev
  socket: /tmp/mysql.sock
  username: *dev_username*
  password: *dev_password*
  
test:
  adapter: mysql2
  encoding: utf8mb4
  reconnect: false
  database: lobsters_test
  socket: /tmp/mysql.sock
  username: *test_username*
  password: *test_password*"><pre><span>development</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>encoding</span>: <span>utf8mb4</span>
  <span>reconnect</span>: <span>false</span>
  <span>database</span>: <span>lobsters_dev</span>
  <span>socket</span>: <span>/tmp/mysql.sock</span>
  <span>username</span>: <span>*dev_username*</span>
  <span>password</span>: <span>*dev_password*</span>
  
<span>test</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>encoding</span>: <span>utf8mb4</span>
  <span>reconnect</span>: <span>false</span>
  <span>database</span>: <span>lobsters_test</span>
  <span>socket</span>: <span>/tmp/mysql.sock</span>
  <span>username</span>: <span>*test_username*</span>
  <span>password</span>: <span>*test_password*</span></pre></div>
</li>
<li>
<p dir="auto">Load the schema into the new database:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lobsters$ rails db:schema:load"><pre>lobsters$ rails db:schema:load</pre></div>
</li>
<li>
<p dir="auto">On your production server, copy <code>config/initializers/production.rb.sample</code>
to <code>config/initalizers/production.rb</code> and customize it with your site's
<code>domain</code> and <code>name</code>. (You don't need this on your dev machine).</p>
</li>
<li>
<p dir="auto">Seed the database to create an initial administrator user, the <code>inactive-user</code>, and at least one tag:</p>

</li>
<li>
<p dir="auto">On your personal computer, you can add some sample data and run the Rails server in development mode.
You should be able to login to <code>http://localhost:3000</code> with your new <code>test</code> user:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lobsters$ rails fake_data
lobsters$ rails server"><pre>lobsters$ rails fake_data
lobsters$ rails server</pre></div>
</li>
<li>
<p dir="auto">Deploying the site in production requires setting up a web server and running the app in production mode.
There are more tools and options available than we can describe; find a guide or an expert.
The lobsters-ansible repo has our config files to crib from. Some app-specific notes:</p>
</li>
<li>
<p dir="auto">Set up crontab or another scheduler to run regular jobs:</p>
<div data-snippet-clipboard-copy-content="*/5 * * * *  cd /path/to/lobsters &amp;&amp; env RAILS_ENV=production sh -c 'bundle exec ruby script/mail_new_activity; bundle exec ruby script/post_to_twitter; bundle exec ruby script/traffic_range'"><pre><code>*/5 * * * *  cd /path/to/lobsters &amp;&amp; env RAILS_ENV=production sh -c 'bundle exec ruby script/mail_new_activity; bundle exec ruby script/post_to_twitter; bundle exec ruby script/traffic_range'
</code></pre></div>
</li>
<li>
<p dir="auto">See <code>config/initializers/production.rb.sample</code> for GitHub/Twitter integration help.</p>
</li>
<li>
<p dir="auto">You probably want to use <a href="https://lobste.rs/s/dbm2d4" rel="nofollow">git-imerge</a> to pull in
changes from Lobsters to your site.</p>
</li>
</ul>
<h4 tabindex="-1" dir="auto">Administration</h4>
<p dir="auto">Basic moderation happens on-site, but most other administrative tasks require use of the rails console in production.
Administrators can create and edit tags at <code>/tags</code>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Visualization (926 pts)]]></title>
            <link>https://bbycroft.net/llm</link>
            <guid>38507672</guid>
            <pubDate>Sun, 03 Dec 2023 15:22:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bbycroft.net/llm">https://bbycroft.net/llm</a>, See on <a href="https://news.ycombinator.com/item?id=38507672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>LLM Visualization</p><div><p><a href="https://bbycroft.net/">Home</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build your own WebAssembly Compiler (2019) (117 pts)]]></title>
            <link>https://blog.scottlogic.com/2019/05/17/webassembly-compiler.html</link>
            <guid>38507594</guid>
            <pubDate>Sun, 03 Dec 2023 15:11:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.scottlogic.com/2019/05/17/webassembly-compiler.html">https://blog.scottlogic.com/2019/05/17/webassembly-compiler.html</a>, See on <a href="https://news.ycombinator.com/item?id=38507594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Have you ever wanted to write your own compiler? … yes? … of course you have! I’ve always wanted to have a go at writing a compiler, and with the recent release of WebAssembly, I had the perfect excuse to have a go.</p>

<p>My original plan was to <em>invent</em> my own programming language, create a compiler that targets WebAssembly, and share my experiences at <a href="https://skillsmatter.com/conferences/11077-fullstack-nyc-2019-the-conference-on-javascript-node-and-internet-of-things">FullStackNYC</a>. The first part went to plan, I spent many-an-evening building, tinkering and refining my compiler. Unfortunately the last part of my plan didn’t go quite so well. Long delays, and an <a href="https://twitter.com/ColinEberhardt/status/1128753147969773569">eventual cancellation</a>, meant that I wasn’t going to make it to New York after all. 😔😢😭</p>

<p>So, rather than waste all that work - I thought I’d write up my talk as a blog post instead - hence the ‘19 min’ reading time for this article. So sit back, make yourself comfortable, and we’ll begin …</p>

<h2 id="what-is-webassembly-and-why-does-it-exist">What is WebAssembly? (and why does it exist?)</h2>

<p>If you haven’t heard of WebAssembly before, and want a really detailed introduction, I’d thoroughly recommend <a href="https://hacks.mozilla.org/2017/02/a-cartoon-intro-to-webassembly/">Lin Clark’s Cartoon Guide</a>.</p>

<p>You’ll learn the ‘what’ of WebAssembly throughout this blog post, but I do want to briefly touch on the ‘why’.</p>

<p>From my perspective, this diagram sums it up quite succinctly:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/wasm-execution.png"></p>

<p>The top diagram shows a simplified timeline for the execution of some JavaScript code within the browser. From left-to-right, the code (typically delivered as a minified mess!) is parsed into an AST, initially executed in an interpreter, then progressively optimised / re-optimised until it eventually runs really quite quickly. These days JavaScript is fast - it just takes a while to get up to speed.</p>

<p>The bottom diagram is the WebAssembly equivalent. Code written in a wide variety of languages (Rust, C, C#, etc …) is compiled to WebAssembly that is delivered in a binary format. This is very easily decoded, compiled and executed - giving fast and predictable performance.</p>

<h2 id="so-why-write-your-own-compiler">So why write your own compiler?</h2>

<p>WebAssembly has been causing quite a stir over the last year. So much so, that it was voted the fifth ‘most loved’ language in <a href="https://insights.stackoverflow.com/survey/2019">Stack Overflow’s developer insights survey</a>.</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/webassembly-love.png"></p>

<p>An interesting result, considering that for most people WebAssembly is a compilation target, rather than a language they will use directly.</p>

<p>This was part of my motivation for proposing the FullStackNYC talk in the first place. The technical aspects of WebAssembly are really fascinating (and remind me of 8-bit computers from a few decades back), yet most people will never get the chance to dabble with WebAssembly itself - it will just be a black box that they compile to.</p>

<p>Writing a compiler is a really good opportunity to delve into the details of WebAssembly to find it what it is and how it works. And it’s fun too!</p>

<p>One final point, it was never my aim to create a fully-featured programming language, or one that is actually any good. My goal was to create ‘enough’ of a language to allow me to write a program that renders a mandelbrot set. This language is compiled to WebAssembly using my compiler, which is written in TypeScript and runs in the browser.</p>

<p>Here it is in it’s full glory:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/wasm-mandelbrot.png"></p>

<p>I ended up calling the language <em>chasm</em> and you can <a href="https://colineberhardt.github.io/chasm/">play with it online if you like</a>.</p>

<p>Enough rambling - time for some code!</p>

<h2 id="a-minimal-wasm-module">A minimal wasm module</h2>

<p>Before tackling the compiler, we’ll start with something simpler, creating a minimal WebAssembly module.</p>

<p>Here is an emitter (the term used for the part of a compiler that outputs instructions for the target system), that creates the smallest valid WebAssembly module:</p>

<div><pre><code><span>const</span> <span>magicModuleHeader</span> <span>=</span> <span>[</span><span>0x00</span><span>,</span> <span>0x61</span><span>,</span> <span>0x73</span><span>,</span> <span>0x6d</span><span>];</span>
<span>const</span> <span>moduleVersion</span> <span>=</span> <span>[</span><span>0x01</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>];</span>

<span>export</span> <span>const</span> <span>emitter</span><span>:</span> <span>Emitter</span> <span>=</span> <span>()</span> <span>=&gt;</span>
  <span>Uint8Array</span><span>.</span><span>from</span><span>([</span>
    <span>...</span><span>magicModuleHeader</span><span>,</span>
    <span>...</span><span>moduleVersion</span>
  <span>]);</span>
</code></pre></div>

<p>It is comprised of two parts, the ‘magic’ header, which is the ASCII string <code>\0asm</code>, and a version number. These eight bytes form valid WebAssembly (or wasm) module. More typically these would be delivered to the browser as a <code>.wasm</code> file.</p>

<p>In order to execute the WebAssembly module it needs to be instantiated as follows:</p>

<div><pre><code><span>const</span> <span>wasm</span> <span>=</span> <span>emitter</span><span>();</span>
<span>const</span> <span>instance</span> <span>=</span> <span>await</span> <span>WebAssembly</span><span>.</span><span>instantiate</span><span>(</span><span>wasm</span><span>);</span>
</code></pre></div>

<p>If you run the above you’ll find that <code>instance</code> doesn’t actually do anything because our wasm module doesn’t contain any instructions!</p>

<p>If you’re interested in trying out this code for yourself, it is all on GitHub - <a href="https://github.com/ColinEberhardt/chasm/commit/26db676f9147b16a0edff38ee20dcd636389f637">with a commit for each step</a>.</p>

<h2 id="an-add-function">An add function</h2>

<p>Let’s make the wasm module do something more useful, by implementing a function that adds a couple of floating point numbers together.</p>

<p>WebAssembly is a binary format, which isn’t terribly readable (to humans at least), which is why you’ll more typically see it written in WebAssembly Text Format (WAT). Here’s a module, presented in WAT format, that defines an exported function named <code>$add</code> that takes two floating point parameters, adds them together and returns them:</p>

<pre><code>(module
 (func $add (param f32) (param f32) (result f32)
   get_local 0
   get_local 1
   f32.add)
 (export "add" (func 0))
)
</code></pre>

<p>If you just want to experiment with WAT you can use the <code>wat2wasm</code> tool from the <a href="https://github.com/WebAssembly/wabt">WebAssembly Binary Toolkit</a> to compile WAT files into wasm modules.</p>

<p>The above code reveals some interesting details around WebAssembly -</p>

<ul>
  <li>WebAssembly is a low-level language, with a small (approx 60) instruction set, where many of the instructions map quite closely to CPU instructions. This makes it easy to compile wasm modules to CPU-specific machine code.</li>
  <li>It has no built in I/O. There are no instructions for writing to the terminal, screen or network. In order to wasm modules to interact with the outside world they need to do so via their host environment, which in the case of the browser is JavaScript.</li>
  <li>WebAssembly is a stack machine, in the above example <code>get_local 0</code> gets the local variable (in this case the function param) at the zeroth index and pushes it onto the stack, as does the subsequent instruction. The <code>f3.add</code> instruction pops two values form the stack, adds them together than pushes the value back on the stack.</li>
  <li>WebAssembly has just four numeric types, two integer, two floats. More on this later …</li>
</ul>

<p>Let’s update the emitter to output this ‘hard coded’ WebAssembly module.</p>

<p>WebAssembly modules are composed of a pre-defined set of optional sections, each prefixed with a numeric identifier. These include a type section, which encode type signatures, and function section, which indicates the type of each function. I’ll not cover how these are constructed here - they are quite dull. If you’re interested, <a href="https://blog.scottlogic.com/2019/05/17/TODO">look at the next commit in the project</a>.</p>

<p>The interesting part is the code section. Here is how the above <code>add</code> function is created in binary:</p>

<div><pre><code><span>const</span> <span>code</span> <span>=</span> <span>[</span>
 <span>Opcodes</span><span>.</span><span>get_local</span> <span>/** 0x20 */</span><span>,</span>
 <span>...</span><span>unsignedLEB128</span><span>(</span><span>0</span><span>),</span>
 <span>Opcodes</span><span>.</span><span>get_local</span> <span>/** 0x20 */</span><span>,</span>
 <span>...</span><span>unsignedLEB128</span><span>(</span><span>1</span><span>),</span>
 <span>Opcodes</span><span>.</span><span>f32_add</span>   <span>/** 0x92 */</span>
<span>];</span>

<span>const</span> <span>functionBody</span> <span>=</span> <span>encodeVector</span><span>([</span>
 <span>...</span><span>encodeVector</span><span>([])</span> <span>/** locals */</span><span>,</span>
 <span>...</span><span>code</span><span>,</span>
 <span>Opcodes</span><span>.</span><span>end</span> <span>/** 0x0b */</span>
<span>]);</span>

<span>const</span> <span>codeSection</span> <span>=</span> <span>createSection</span><span>(</span><span>Section</span><span>.</span><span>code</span> <span>/** 0x0a */</span><span>,</span>
  <span>encodeVector</span><span>([</span><span>functionBody</span><span>]));</span>
</code></pre></div>

<p>I’ve defined an <code>Opcodes</code> enum (I’m using TypeScript), which contains all of the wasm instructions. The <code>unsignedLEB128</code> function is a standard <a href="https://en.wikipedia.org/wiki/LEB128">variable length encoding</a> which is used for encoding instruction parameters.</p>

<p>The instructions for a function are combined with the function’s local variables (of which there are none in this case), and an <code>end</code> opcode that signals the end of a function. Finally all the functions are encoded into a section. The <code>encodeVector</code> function simply prefixes a collection of byte arrays with the total length.</p>

<p>And there you have it, the complete module, which is about 30 bytes in total.</p>

<p>The JavaScript hosting code can now be updated to involve this exported function:</p>

<div><pre><code><span>const</span> <span>{</span> <span>instance</span> <span>}</span> <span>=</span> <span>await</span> <span>WebAssembly</span><span>.</span><span>instantiate</span><span>(</span><span>wasm</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>instance</span><span>.</span><span>exports</span><span>.</span><span>add</span><span>(</span><span>5</span><span>,</span> <span>6</span><span>));</span>
</code></pre></div>

<p>Interestingly if you inspect the exported <code>add</code> function with the Chrome Dev Tools it identifier it as a ‘native function’.</p>

<p>You can see the complete <a href="https://github.com/ColinEberhardt/chasm/tree/2ec3f7312a1d16043dccc1dae92ea22db91998d3">code for this step (with unit tests - go me!) on GitHub</a>.</p>

<h2 id="building-a-compiler">Building a compiler</h2>

<p>Now that you’ve seen how to dynamically create wasm modules, it’s time to turn our attention to the task of creating a compiler. We’ll start with a bit of terminology.</p>

<p>Here’s some <em>chasm</em> code annotated to show the key components of a language:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/language-terminology.png"></p>

<p>Rather than give a ‘textbook definition’ of each, you’ll become familiar with them as the compiler evolves.</p>

<p>The compiler itself will be formed of three parts, the <strong>tokenizer</strong> which breaks up the input program (which is a string), into discrete tokens, the <strong>parser</strong> that takes these tokens and converts them into an Abstract Syntax Tree (AST), and finally the <strong>emitter</strong> which converts the AST into wasm binary module.</p>

<p>This is a pretty standard compiler architecture:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/compiler-architecture.png"></p>

<p>Rather than dive into a complete implementation, we’ll tackle a small subset of the problem. The goal is to create a compiler for a language that just supports print statements which print simple numeric literals …</p>



<h2 id="the-tokenizer">The Tokenizer</h2>

<p>The tokenizer works by advancing through the input string, one character at a time, matching patterns that represent specific token types. The following code creates three matches (<code>number</code>, <code>keyword</code>, and <code>whitespace</code>), using simple regular expressions:</p>

<div><pre><code><span>const</span> <span>keywords</span> <span>=</span> <span>[</span><span>"</span><span>print</span><span>"</span><span>];</span>

 <span>// returns a token if the given regex matches at the current index</span>
<span>const</span> <span>regexMatcher</span> <span>=</span> <span>(</span><span>regex</span><span>:</span> <span>string</span><span>,</span> <span>type</span><span>:</span> <span>TokenType</span><span>):</span> <span>Matcher</span> <span>=&gt;</span>
  <span>(</span><span>input</span><span>:</span> <span>string</span><span>,</span> <span>index</span><span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>match</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>index</span><span>).</span><span>match</span><span>(</span><span>regex</span><span>);</span>
    <span>return</span> <span>(</span>
      <span>match</span> <span>&amp;&amp;</span> <span>{</span>
        <span>type</span><span>,</span>
        <span>value</span><span>:</span> <span>match</span><span>[</span><span>0</span><span>]</span>
      <span>}</span>
    <span>);</span>
  <span>};</span>

<span>const</span> <span>matchers</span> <span>=</span> <span>[</span>
  <span>regexMatcher</span><span>(</span><span>"</span><span>^[.0-9]+</span><span>"</span><span>,</span> <span>"</span><span>number</span><span>"</span><span>),</span>
  <span>regexMatcher</span><span>(</span><span>`^(</span><span>${</span><span>keywords</span><span>.</span><span>join</span><span>(</span><span>"</span><span>|</span><span>"</span><span>)}</span><span>)`</span><span>,</span> <span>"</span><span>keyword</span><span>"</span><span>),</span>
  <span>regexMatcher</span><span>(</span><span>"</span><span>^</span><span>\\</span><span>s+</span><span>"</span><span>,</span> <span>"</span><span>whitespace</span><span>"</span><span>)</span>
<span>];</span>
</code></pre></div>

<p>(Note, these regular expressions are not terribly robust!)</p>

<p>The <code>Matcher</code> interface defines a function that given an input string and an index returns a token if a match occurs.</p>

<p>The main body of the parser iterates over the characters of the string, finding the first match, adding the provided token to the output array:</p>

<div><pre><code><span>export</span> <span>const</span> <span>tokenize</span><span>:</span> <span>Tokenizer</span> <span>=</span> <span>input</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>tokens</span><span>:</span> <span>Token</span><span>[]</span> <span>=</span> <span>[];</span>
  <span>let</span> <span>index</span> <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span>(</span><span>index</span> <span>&lt;</span> <span>input</span><span>.</span><span>length</span><span>)</span> <span>{</span>
    <span>const</span> <span>matches</span> <span>=</span> <span>matchers</span><span>.</span><span>map</span><span>(</span><span>m</span> <span>=&gt;</span> <span>m</span><span>(</span><span>input</span><span>,</span> <span>index</span><span>)).</span><span>filter</span><span>(</span><span>f</span> <span>=&gt;</span> <span>f</span><span>)</span>
    <span>const</span> <span>match</span> <span>=</span> <span>matches</span><span>[</span><span>0</span><span>];</span>
    <span>if</span> <span>(</span><span>match</span><span>.</span><span>type</span> <span>!==</span> <span>"</span><span>whitespace</span><span>"</span><span>)</span> <span>{</span>
      <span>tokens</span><span>.</span><span>push</span><span>(</span><span>match</span><span>);</span>
    <span>}</span>
    <span>index</span> <span>+=</span> <span>match</span><span>.</span><span>value</span><span>.</span><span>length</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>tokens</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>Here is the tokenised output of the program <code>"print 23.1"</code>:</p>

<div><pre><code><span>[</span><span>
 </span><span>{</span><span>
   </span><span>"type"</span><span>:</span><span> </span><span>"keyword"</span><span>,</span><span>
   </span><span>"value"</span><span>:</span><span> </span><span>"print"</span><span>,</span><span>
   </span><span>"index"</span><span>:</span><span> </span><span>1</span><span>
 </span><span>},</span><span>
 </span><span>{</span><span>
   </span><span>"type"</span><span>:</span><span> </span><span>"number"</span><span>,</span><span>
   </span><span>"value"</span><span>:</span><span> </span><span>"23.1"</span><span>,</span><span>
   </span><span>"index"</span><span>:</span><span> </span><span>7</span><span>
 </span><span>}</span><span>
</span><span>]</span><span>
</span></code></pre></div>

<p>As you can see from the above input, the tokeniser removes whitespace as it has no meaning (for this specific language), it also ensures that everything in the input string is a valid token. However, it doesn’t make any guarantees about the input being well-formed, for example the tokeniser will happily handle <code>"print print"</code>, which is clearly incorrect.</p>

<p>The array of tokens is next fed into the parser.</p>

<h2 id="the-parser">The Parser</h2>

<p>The goal of the parser is the creation of an Abstract Syntax Tree (AST), a tree structure that encodes the relationship between these tokens, resulting in a form that could potentially be sent to an interpreter for direct execution.</p>

<p>The parser iterates through the supplied tokens, consuming them via an <code>eatToken</code> function.</p>

<div><pre><code><span>export</span> <span>const</span> <span>parse</span><span>:</span> <span>Parser</span> <span>=</span> <span>tokens</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>iterator</span> <span>=</span> <span>tokens</span><span>[</span><span>Symbol</span><span>.</span><span>iterator</span><span>]();</span>
  <span>let</span> <span>currentToken</span> <span>=</span> <span>iterator</span><span>.</span><span>next</span><span>().</span><span>value</span><span>;</span>
 
  <span>const</span> <span>eatToken</span> <span>=</span> <span>()</span> <span>=&gt;</span>
    <span>(</span><span>currentToken</span> <span>=</span> <span>iterator</span><span>.</span><span>next</span><span>().</span><span>value</span><span>);</span>

  <span>[...]</span>

  <span>const</span> <span>nodes</span><span>:</span> <span>StatementNode</span><span>[]</span> <span>=</span> <span>[];</span>
  <span>while</span> <span>(</span><span>index</span> <span>&lt;</span> <span>tokens</span><span>.</span><span>length</span><span>)</span> <span>{</span>
     <span>nodes</span><span>.</span><span>push</span><span>(</span><span>parseStatement</span><span>());</span>
  <span>}</span>

  <span>return</span> <span>nodes</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>(I’ve no idea where the concept of eating tokens comes from, it appears to be standard parser terminology, they are clearly hungry beasts!)</p>

<p>The goal of the above parser is to turn the token array into an array of statements, which are the core building blocks of this language. It expects the given tokens to conform to this pattern, and will throw an error (not shown above) if it does not.</p>

<p>The <code>parseStatement</code> function expects each statement to start with a keyword - switching on its value:</p>

<div><pre><code><span>const</span> <span>parseStatement</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span><span>currentToken</span><span>.</span><span>type</span> <span>===</span> <span>"</span><span>keyword</span><span>"</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>currentToken</span><span>.</span><span>value</span><span>)</span> <span>{</span>
    <span>case</span> <span>"</span><span>print</span><span>"</span><span>:</span>
      <span>eatToken</span><span>();</span>
      <span>return</span> <span>{</span>
        <span>type</span><span>:</span> <span>"</span><span>printStatement</span><span>"</span><span>,</span>
        <span>expression</span><span>:</span> <span>parseExpression</span><span>()</span>
      <span>};</span>
    <span>}</span>
  <span>}</span>
<span>};</span>
</code></pre></div>

<p>Currently the only supported keyword is <code>print</code>, in this case it returns an AST node of type <code>printStatement</code> parsing the associated expression.</p>

<p>And here is the expression parser:</p>

<div><pre><code><span>const</span> <span>parseExpression</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>let</span> <span>node</span><span>:</span> <span>ExpressionNode</span><span>;</span>
  <span>switch</span> <span>(</span><span>currentToken</span><span>.</span><span>type</span><span>)</span> <span>{</span>
    <span>case</span> <span>"</span><span>number</span><span>"</span><span>:</span>
      <span>node</span> <span>=</span> <span>{</span>
        <span>type</span><span>:</span> <span>"</span><span>numberLiteral</span><span>"</span><span>,</span>
        <span>value</span><span>:</span> <span>Number</span><span>(</span><span>currentToken</span><span>.</span><span>value</span><span>)</span>
      <span>};</span>
      <span>eatToken</span><span>();</span>
      <span>return</span> <span>node</span><span>;</span>
  <span>}</span>
<span>};</span>
</code></pre></div>

<p>In its present form the language only accepts expressions which are composed of a single number - i.e. a numeric literal. Therefore the above expression parser expects the next token to be a number, and when this matches, it returns a node of type <code>numberLiteral</code>.</p>

<p>Continuing the simple example of the program <code>"print 23.1"</code>, the parser outputs the following AST:</p>

<div><pre><code><span>[</span><span>
  </span><span>{</span><span>
    </span><span>"type"</span><span>:</span><span> </span><span>"printStatement"</span><span>,</span><span>
    </span><span>"expression"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"type"</span><span>:</span><span> </span><span>"numberLiteral"</span><span>,</span><span>
      </span><span>"value"</span><span>:</span><span> </span><span>23.1</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>]</span><span>
</span></code></pre></div>

<p>As you can see the AST for this language is an array of statement nodes. Parsing guarantees that the input program is syntactically correct, i.e. it is properly constructed, but it doesn’t of course guarantee that it will execute successfully, runtime errors might still be present (although for this simple language they are not possible!).</p>

<p>We’re onto the final step now …</p>

<h2 id="the-emitter">The Emitter</h2>

<p>Currently the emitter outputs a hard-coded add function. It now needs to take this AST and emit the appropriate instructions, as follows:</p>

<div><pre><code><span>const</span> <span>codeFromAst</span> <span>=</span> <span>ast</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>code</span> <span>=</span> <span>[];</span>

  <span>const</span> <span>emitExpression</span> <span>=</span> <span>node</span> <span>=&gt;</span> <span>{</span>
    <span>switch</span> <span>(</span><span>node</span><span>.</span><span>type</span><span>)</span> <span>{</span>
      <span>case</span> <span>"</span><span>numberLiteral</span><span>"</span><span>:</span>
        <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>f32_const</span><span>);</span>
        <span>code</span><span>.</span><span>push</span><span>(...</span><span>ieee754</span><span>(</span><span>node</span><span>.</span><span>value</span><span>));</span>
        <span>break</span><span>;</span>
    <span>}</span>
  <span>};</span>

  <span>ast</span><span>.</span><span>forEach</span><span>(</span><span>statement</span> <span>=&gt;</span> <span>{</span>
    <span>switch</span> <span>(</span><span>statement</span><span>.</span><span>type</span><span>)</span> <span>{</span>
      <span>case</span> <span>"</span><span>printStatement</span><span>"</span><span>:</span>
        <span>emitExpression</span><span>(</span><span>statement</span><span>.</span><span>expression</span><span>);</span>
        <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>call</span><span>);</span>
        <span>code</span><span>.</span><span>push</span><span>(...</span><span>unsignedLEB128</span><span>(</span><span>0</span><span>));</span>
        <span>break</span><span>;</span>
    <span>}</span>
  <span>});</span>

  <span>return</span> <span>code</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>The emitter iterates over the statements that form the ‘root’ of the AST, matching our only statement type - print. Notice that the first thing it does is emit the instructions for the statement expressions, recall that WebAssembly is a stack machine, hence the expression instructions must be processed first leaving the result on the stack.</p>

<p>The print function is implemented via a <code>call</code> operation, which invokes the function at index zero.</p>

<p>Previously we’ve seen how wasm modules can export functions (as per the add example above), they can also import functions, which are supplied when you instantiate the module. Here we provide an <code>env.print</code> function that logs to the console:</p>

<div><pre><code><span>const</span> <span>instance</span> <span>=</span> <span>await</span> <span>WebAssembly</span><span>.</span><span>instantiate</span><span>(</span><span>wasm</span><span>,</span> <span>{</span>
  <span>env</span><span>:</span> <span>{</span>
    <span>print</span><span>:</span> <span>console</span><span>.</span><span>log</span>
  <span>}</span>
<span>});</span>
</code></pre></div>

<p>This function is addressable by index, i.e. <code>call 0</code>.</p>

<p>You can see the complete code for the <a href="https://github.com/ColinEberhardt/chasm/tree/1edac4777e06b82da0133ef5554d1baaccea0726">compiler at this point on GitHub</a> - you can also have a play with this example via the <a href="https://colineberhardt.github.io/chasm/#cHJpbnQgMjMuMQ%3D%3D">online chasm compiler playground</a>.</p>

<p>Also, for completeness this is how the program progresses through the various compiler stages:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/print-program.png"></p>

<p>So far we’ve put quite a lot of structure in place, but not really felt the benefit. A separate tokenizer, parser and emitter is overkill for a language that only prints simple numerics. However, as the language complexity grows, this structure really starts to pay dividends.</p>

<h2 id="implementing-expressions">Implementing expressions</h2>

<p>Next up, we’ll look at implementing binary expressions, allowing the language to perform simple mathematics, for example <code>print ((42 + 10) / 2)</code>.</p>

<p>For the tokeniser the changes are quite trivial, involving adding a couple of additional regex matchers for parentheses and operators. I’ll not reproduce them here - instead, just show the resultant output:</p>

<div><pre><code><span>[</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"keyword"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"print"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"parens"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"("</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"parens"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"("</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"number"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"42"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"operator"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"+"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"number"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"10"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"parens"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>")"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"operator"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"/"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"number"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>"2"</span><span> </span><span>},</span><span>
  </span><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"parens"</span><span>,</span><span> </span><span>"value"</span><span>:</span><span> </span><span>")"</span><span> </span><span>}</span><span>
</span><span>]</span><span>
</span></code></pre></div>

<p>Next up, we’ll look at the changes to the parser - where the expression parser can encounter either <code>number</code> of <code>parens</code> tokens:</p>

<div><pre><code><span>const</span> <span>parseExpression</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>let</span> <span>node</span><span>:</span> <span>ExpressionNode</span><span>;</span>
  <span>switch</span> <span>(</span><span>currentToken</span><span>.</span><span>type</span><span>)</span> <span>{</span>
    <span>case</span> <span>"</span><span>number</span><span>"</span><span>:</span>
      <span>[...]</span>
    <span>case</span> <span>"</span><span>parens</span><span>"</span><span>:</span>
      <span>eatToken</span><span>();</span>
      <span>const</span> <span>left</span> <span>=</span> <span>parseExpression</span><span>();</span>
      <span>const</span> <span>operator</span> <span>=</span> <span>currentToken</span><span>.</span><span>value</span><span>;</span>
      <span>eatToken</span><span>();</span>
      <span>const</span> <span>right</span> <span>=</span> <span>parseExpression</span><span>();</span>
      <span>eatToken</span><span>();</span>
      <span>return</span> <span>{</span>
        <span>type</span><span>:</span> <span>"</span><span>binaryExpression</span><span>"</span><span>,</span>
        <span>left</span><span>,</span> <span>right</span><span>,</span> <span>operator</span>
      <span>};</span>
  <span>}</span>
<span>};</span>
</code></pre></div>

<p>Notice that parsing of <code>parens</code> expressions is recursive, with the nodes for the left and right invoking the <code>parseExpression</code> function once again.</p>

<p>The AST for the program <code>print ((42 + 10) / 2)</code> is given below:</p>

<div><pre><code><span>[{</span><span>
 </span><span>type:</span><span> </span><span>"printStatement"</span><span>,</span><span>
 </span><span>expression:</span><span> </span><span>{</span><span>
   </span><span>type:</span><span> </span><span>"binaryExpression"</span><span>,</span><span>
   </span><span>left:</span><span> </span><span>{</span><span>
     </span><span>type:</span><span> </span><span>"binaryExpression"</span><span>,</span><span>
     </span><span>left:</span><span> </span><span>{</span><span>
       </span><span>type:</span><span> </span><span>"numberLiteral"</span><span>,</span><span>
       </span><span>value:</span><span> </span><span>42</span><span>
     </span><span>},</span><span>
     </span><span>right:</span><span> </span><span>{</span><span>
       </span><span>type:</span><span> </span><span>"numberLiteral"</span><span>,</span><span>
       </span><span>value:</span><span> </span><span>10</span><span>
     </span><span>},</span><span>
     </span><span>operator:</span><span> </span><span>"+"</span><span>
   </span><span>},</span><span>
   </span><span>right:</span><span> </span><span>{</span><span>
     </span><span>type:</span><span> </span><span>"numberLiteral"</span><span>,</span><span>
     </span><span>value:</span><span> </span><span>2</span><span>
   </span><span>},</span><span>
   </span><span>operator:</span><span> </span><span>"/"</span><span>
 </span><span>}</span><span>
</span><span>}]</span><span>;</span><span>
</span></code></pre></div>

<p>The tree structure is becoming more obvious in this example.</p>

<p>Finally, the emitter needs to be updated in order to handle the <code>binaryExpression</code> node type, as follows:</p>

<div><pre><code><span>const</span> <span>emitExpression</span> <span>=</span> <span>(</span><span>node</span><span>)</span> <span>=&gt;</span>
  <span>traverse</span><span>(</span><span>node</span><span>,</span> <span>(</span><span>node</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>switch</span> <span>(</span><span>node</span><span>.</span><span>type</span><span>)</span> <span>{</span>
      <span>case</span> <span>"</span><span>numberLiteral</span><span>"</span><span>:</span>
        <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>f32_const</span><span>);</span>
        <span>code</span><span>.</span><span>push</span><span>(...</span><span>ieee754</span><span>(</span><span>node</span><span>.</span><span>value</span><span>));</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>"</span><span>binaryExpression</span><span>"</span><span>:</span>
        <span>code</span><span>.</span><span>push</span><span>(</span><span>binaryOpcode</span><span>[</span><span>node</span><span>.</span><span>operator</span><span>]);</span>
        <span>break</span><span>;</span>
   <span>}</span>
<span>});</span>
</code></pre></div>

<p>The <code>traverse</code> function in the above code traverses tree structures invoking the given visitor for each node. While linear structures only have one logical way to traverse them (i.e. in order), trees can be <a href="https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/">traversed in a number of different ways</a>. The traversal method used by the emitter is a depth-first post-order traversal, in other words as it encounters each node it visits left, right, then root - this order ensures that the wasm instructions are output in the correct order for the stack machine, operands then operator.</p>

<p>And that’s it, all the changes that are required to support expressions. Give it a <a href="https://colineberhardt.github.io/chasm/#cHJpbnQgKCg0MiArIDEwKSAvIDIp">go online</a>.</p>

<p>The compiler architecture is starting to prove its value!</p>

<h2 id="variables">Variables</h2>

<p>Next up, we’ll add variables, allowing for more interesting <em>chasm</em> programs …</p>



<p>Variables are declared using the <code>var</code> keyword, and can be used in expressions as identifiers.</p>

<p>We’ll not look at the changes to the tokeniser, it’s just yet more regex! The main loop of the parser, which reads successive statements from the token array, determines the statement type based on the keyword it encounters:</p>

<div><pre><code><span>const</span> <span>parseVariableDeclarationStatement</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>eatToken</span><span>();</span> <span>// var</span>
  <span>const</span> <span>name</span> <span>=</span> <span>currentToken</span><span>.</span><span>value</span><span>;</span>
  <span>eatToken</span><span>();</span>
  <span>eatToken</span><span>();</span> <span>// =</span>
  <span>return</span> <span>{</span>
    <span>type</span><span>:</span> <span>"</span><span>variableDeclaration</span><span>"</span><span>,</span>
    <span>name</span><span>,</span>
    <span>initializer</span><span>:</span> <span>parseExpression</span><span>()</span>
  <span>};</span>
<span>};</span>

<span>const</span> <span>parseStatement</span><span>:</span> <span>ParserStep</span><span>&lt;</span><span>StatementNode</span><span>&gt;</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span><span>currentToken</span><span>.</span><span>type</span> <span>===</span> <span>"</span><span>keyword</span><span>"</span><span>)</span> <span>{</span>
    <span>switch</span> <span>(</span><span>currentToken</span><span>.</span><span>value</span><span>)</span> <span>{</span>
      <span>case</span> <span>"</span><span>print</span><span>"</span><span>:</span>
        <span>return</span> <span>parsePrintStatement</span><span>();</span>
      <span>case</span> <span>"</span><span>var</span><span>"</span><span>:</span>
        <span>return</span> <span>parseVariableDeclarationStatement</span><span>();</span>
    <span>}</span>
  <span>}</span>
<span>};</span>
</code></pre></div>

<p>Variable declaration parsing is quite straight-forwards - notice that the <code>parseVariableDeclarationStatement</code> function also makes use of the expression parser, which ensures that variables can be declared and assigned an initial value from an expression, e.g. <code>var f = (1 + 4)</code>.</p>

<p>Next up, the emitter. WebAssembly functions can have local variables, these are declared at the beginning of the function definition, and are accessed via the <code>get_local</code> and <code>set_local</code> functions that also retrieve function parameters.</p>

<p>The variables in our AST are referenced via their identifier name, whereas wasm identifies locals by their index. The emitter needs to maintain this information in a symbol table, which is a simple map from the symbol name to index:</p>

<div><pre><code><span>const</span> <span>symbols</span> <span>=</span> <span>new</span> <span>Map</span><span>&lt;</span><span>string</span><span>,</span> <span>number</span><span>&gt;</span><span>();</span>

<span>const</span> <span>localIndexForSymbol</span> <span>=</span> <span>(</span><span>name</span><span>:</span> <span>string</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span><span>!</span><span>symbols</span><span>.</span><span>has</span><span>(</span><span>name</span><span>))</span> <span>{</span>
    <span>symbols</span><span>.</span><span>set</span><span>(</span><span>name</span><span>,</span> <span>symbols</span><span>.</span><span>size</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>symbols</span><span>.</span><span>get</span><span>(</span><span>name</span><span>);</span>
<span>};</span>
</code></pre></div>

<p>Within the node traversal, when a variable declaration is encountered, the expression is emitted, them <code>set_local</code> used to assign the value to the respective local variable.</p>

<div><pre><code>  <span>case</span> <span>"</span><span>variableDeclaration</span><span>"</span><span>:</span>
    <span>emitExpression</span><span>(</span><span>statement</span><span>.</span><span>initializer</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>set_local</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(...</span><span>unsignedLEB128</span><span>(</span><span>localIndexForSymbol</span><span>(</span><span>statement</span><span>.</span><span>name</span><span>)));</span>
    <span>break</span><span>;</span>
</code></pre></div>

<p>Within expressions, when identifiers are found, the <code>get_local</code> operation is used to retrieve the value:</p>

<div><pre><code>  <span>case</span> <span>"</span><span>identifier</span><span>"</span><span>:</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>get_local</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(...</span><span>unsignedLEB128</span><span>(</span><span>localIndexForSymbol</span><span>(</span><span>node</span><span>.</span><span>value</span><span>)));</span>
    <span>break</span><span>;</span>
</code></pre></div>

<p>Also, the function encoding we saw right back at the beginning is updated to add the locals for the function that the emitter builds. The <em>chasm</em> language has a single variable type, everything is a float.</p>

<p>Have a go at defining variables and using them within print statements <a href="https://colineberhardt.github.io/chasm/#dmFyIGYgPSAxMApwcmludCAoZiArIDEwKQ%3D%3D">online</a></p>

<h2 id="while-loops">while loops</h2>

<p>One of the final language constructs we need in order to achieve the goal of rendering a mandelbrot set is some kind of loop. For <em>chasm</em> I opted for a while loop, as show in this simple program that prints the numbers 0 to 9:</p>

<div><pre><code>var f = 0
while (f &lt; 10)
  print f
  f = (f + 1)
endwhile
</code></pre></div>

<p>WebAssembly has various control flow instructions (branch, if, else, loop, block). The following WAT show how a while loop can be constructed:</p>

<pre><code>(block
 (loop
   [loop condition]
   i32.eqz
   [nested statements]
   br_if 1
   br 0)
 )
</code></pre>

<p>Branching within WebAssembly is based on stack depth. The outer <code>block</code> and <code>loop</code> instructions push entries onto the control-flow stack. The <code>br_if 1</code> instruction performs a conditional branch to a stack depth of one, and <code>br 0</code> an unconditional branch to a depth of zero, repeating the <code>loop</code>.</p>

<p>Here’s how the emitter produces the same in binary format:</p>

<div><pre><code>  <span>case</span> <span>"</span><span>whileStatement</span><span>"</span><span>:</span>
    <span>// outer block</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>block</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Blocktype</span><span>.</span><span>void</span><span>);</span>
    <span>// inner loop</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>loop</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Blocktype</span><span>.</span><span>void</span><span>);</span>
    <span>// compute the while expression</span>
    <span>emitExpression</span><span>(</span><span>statement</span><span>.</span><span>expression</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>i32_eqz</span><span>);</span>
    <span>// br_if $label0</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>br_if</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(...</span><span>signedLEB128</span><span>(</span><span>1</span><span>));</span>
    <span>// the nested logic</span>
    <span>emitStatements</span><span>(</span><span>statement</span><span>.</span><span>statements</span><span>);</span>
    <span>// br $label1</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>br</span><span>);</span>
    <span>code</span><span>.</span><span>push</span><span>(...</span><span>signedLEB128</span><span>(</span><span>0</span><span>));</span>
    <span>// end loop</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>end</span><span>);</span>
    <span>// end block</span>
    <span>code</span><span>.</span><span>push</span><span>(</span><span>Opcodes</span><span>.</span><span>end</span><span>);</span>
    <span>break</span><span>;</span>
</code></pre></div>

<p>And here it is <a href="https://colineberhardt.github.io/chasm/#dmFyIGYgPSAwCndoaWxlIChmIDwgMTApCiAgcHJpbnQgZgogIGYgPSAoZiArIDEpCmVuZHdoaWxl">running in the online playground</a>.</p>

<h2 id="graphics">graphics!</h2>

<p>We’re nearly there - up to the very last step now! Currently the only way we’ve been able to see output from our <em>chasm</em> programs is via the <code>print</code> statement, which is wired to the console via a function imported by the WebAssembly module. For the mandelbrot set we somehow need to render graphics to the screen.</p>

<p>To achieve this we’ll make use of another very important component of WebAssembly modules, linear memory:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/linear-memory.png"></p>

<p>As I mentioned previously, WebAssembly only has 4 numeric data types. You might be wondering how languages with richer type systems (string, structs, arrays) can compile to WebAssembly?</p>

<p>WebAssembly modules can optionally define (or import) a block of linear memory, this is a contiguous block of memory that is shared by the wasm module and its host - in other words both can read and write to this memory. Therefore, if you want to pass a string to your WebAssembly module, you do this by <a href="https://stackoverflow.com/a/47676844/249933">writing it to linear memory</a>.</p>

<p>For <em>chasm</em> we just want some sort of display, so will use linear memory as a form of <a href="https://en.wikipedia.org/wiki/Video_RAM_(dual-ported_DRAM)">Video RAM</a>.</p>

<p>The <em>chasm</em> languages supports a simple set-pixel command which takes three expressions, the x location, y location and colour. For example, the following program fill the screen with a horizontal gradient:</p>

<div><pre><code>var y  = 0
while (y &lt; 100)
  var x  = 0
  while (x &lt; 100)
    setpixel x y (x * 2)
    x = (x + 1)
  endwhile
  y = (y + 1)
endwhile
</code></pre></div>

<p>(Try it <a href="https://colineberhardt.github.io/chasm/#dmFyIHkgID0gMAp3aGlsZSAoeSA8IDEwMCkKICB2YXIgeCAgPSAwCiAgd2hpbGUgKHggPCAxMDApCiAgICBzZXRwaXhlbCB4IHkgKHggKiAyKQogICAgeCA9ICh4ICsgMSkKICBlbmR3aGlsZQogIHkgPSAoeSArIDEpCmVuZHdoaWxlCgogICAg">online</a>)</p>

<p>The <code>setpixel</code> command is implemented using the wasm <code>store</code> instruction that writes to linear memory. On the JavaScript ‘hosting’ side, this same linear memory is read and copied to a HTML canvas. I’ll not reproduce the changes to the code here, you can <a href="https://github.com/ColinEberhardt/chasm/commit/cb4c069e3b9ad827a10ced16921cd89176271111">see them on GitHub</a></p>

<p>And with that - the <em>chasm</em> language is complete, and able to render the mandelbrot set:</p>

<p><img src="https://blog.scottlogic.com/ceberhardt/assets/wasm-compiler/wasm-mandelbrot.png"></p>

<p>(Try it <a href="https://colineberhardt.github.io/chasm/">online</a>)</p>

<h2 id="conclusions">Conclusions</h2>

<p>I hope you enjoyed this journey and have either learnt a bit more about WebAssembly or how compilers work? For me, this project was a lot of fun - I’ve never written a compiler before, but have always wanted to.</p>

<p>As you can probably imagine, I’ve not stopped there, the temptation was too great to keep going - I’ve already implemented if / else, and functions / procedures are in the pipeline. I’d also really like to explore some of the more involved topics like memory management, for example introduce string, arrays and a memory allocator for storage within linear memory.</p>

<p>All topics for a future post!</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Report Phone Spam – Shut down robocallers and text spammers (170 pts)]]></title>
            <link>https://reportphonespam.org/</link>
            <guid>38507446</guid>
            <pubDate>Sun, 03 Dec 2023 14:49:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reportphonespam.org/">https://reportphonespam.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38507446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2>Receive robocalls or text message spam? <br>Help shut the spammer down.</h2>

<p>Most reputable telecom carriers don't want unsolicited messages on their network or phone numbers. In order to disconnect their abusive customers, they need to hear about the abuse. That's where you come in.</p>
<p>Here's how to <strong>report abuse to the telecom carrier that is responsible for the spammer's phone number – so the carrier can terminate their service.</strong> As one carrier wrote back, "Please be advised that the offending traffic has been removed from our network." For more background, see <a href="#FAQ">FAQ</a>.</p>
<h2>How to report abuse</h2>

<ol>
<li><a href="#Identify-the-spammers-real-phone-number">Identify the spammer's real phone number</a></li>
<li><a href="#Find-the-telecom-carrier-responsible-for-that-number">Find the telecom carrier responsible for that number</a></li>
<li><a href="#Report-abuse-to-the-responsible-carrier">Report abuse to the responsible carrier</a></li>
</ol>

<h2 id="1-identify-the-spammers-real-phone-number"><a href="#1-identify-the-spammers-real-phone-number"></a>1. Identify the spammer's real phone number</h2>
<h4 id="if-you-received-a-phone-call-robocall-voicemail"><a href="#if-you-received-a-phone-call-robocall-voicemail"></a>If you received a phone call (robocall, voicemail)</h4>
<p><strong>Ignore the phone number that the call appears to come from (Caller ID).</strong> With phone calls, that number is usually forged ("spoofed"). Instead, <strong>report the phone number that the call instructs you to contact.</strong></p>
<h4 id="if-you-received-a-text-message-sms-imessage"><a href="#if-you-received-a-text-message-sms-imessage"></a>If you received a text message (SMS, iMessage)</h4>
<p><strong>Report the phone number that the text message appears to come from.</strong> With SMS and iMessage, the sending phone number is generally correct. It is difficult to forge. If the message instructs you to respond by texting or calling a second number, consider also reporting the second number.
<a name="Find-the-telecom-carrier-responsible-for-that-number"></a></p>

<p><strong>Look up the carrier on one of these free sites:</strong> </p>
<ul>
<li><a href="https://realphonevalidation.com/phone-validator-tool/">realphonevalidation.com</a></li>
<li><a href="https://freecarrierlookup.com/">freecarrierlookup.com</a></li>
</ul>
<p><strong>Alternatively, look up the carrier using a carrier lookup API operated by Twilio or Plivo.</strong> These APIs provide more accurate responses, allow more lookups, and have command-line tools. See <a href="#How-do-I-look-up-more-numbers">How do I look up more numbers?</a></p>

<h2 id="3-report-abuse-to-the-responsible-carrier"><a href="#3-report-abuse-to-the-responsible-carrier"></a>3. Report abuse to the responsible carrier</h2>
<p>The Web site or API response will provide the name of a telecom carrier, such as "Bandwidth," "Peerless," or "Telnyx." That is the carrier to contact about this number (see <a href="#Carrier-contacts">Carrier contacts</a>).</p>
<p>Here are example responses for 5 different phone numbers:</p>
<pre><code><span>"Bandwidth"</span>
<span>"Bandwidth/Zipwhip - Toll-Free - SVR"</span>
<span>"T-Mobile USA, Inc."</span>
<span>"Telnyx - Telnyx - SVR"</span>
<span>"Twilio - Toll-Free - SMS-Sybase365/MMS-SVR"</span></code></pre><p><strong>When the carrier name mentions multiple companies, as in some of the examples above, contact the first company named.</strong> For example, if the carrier name is "Twilio - Toll-Free - SMS-Sybase365/MMS-SVR," contact Twilio. If the carrier name is "Bandwidth/Zipwhip - Toll-Free - SVR," contact Bandwidth.com.</p>
<p><strong>Be professional and respectful.</strong> The carrier you are contacting is the carrier which routes calls and texts to this phone number. They may not have been the carrier through which the unsolicited text or robocall originated. However, they can disconnect service to the phone number. Reputable carriers disconnect customers for generating unsolicited ("opt-out") bulk calls or texts.</p>
<p>In addition, report the message to your wireless provider so that they may try to block texts or calls to their other subscribers. See <a href="#Reporting-abuse-to-your-wireless-provider">Reporting abuse to your wireless provider</a>.</p>

<h3 id="carrier-contacts"><a href="#carrier-contacts"></a>Carrier contacts</h3>
<table>
<thead>
<tr>
<th>Carrier</th>
<th>How to Report Abuse</th>
<th>Phone</th>
<th>Notes</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Bandwidth.com</strong></td>
<td><a href="https://www.bandwidth.com/legal/report-a-phone-number/">Report abuse here</a></td>
<td>855-864-7776</td>
<td>Poor response; be persistent.</td>
</tr>
<tr>
<td><strong>CallFire</strong></td>
<td>Email support at callfire.com</td>
<td>877-897-3473</td>
<td>Also called EZTexting.</td>
</tr>
<tr>
<td><strong>Commio</strong></td>
<td>Email support at commio.com</td>
<td>877-506-0747</td>
<td></td>
</tr>
<tr>
<td><strong>FlexTalk</strong></td>
<td><a href="https://www.tsgglobal.com/abuse/#report-abuse">Report abuse here</a></td>
<td>617-592-2064</td>
<td>Part of TSG Global.</td>
</tr>
<tr>
<td><strong>Inteliquent</strong></td>
<td><a href="https://www.inteliquent.com/legal/unwanted-calls">Report abuse here</a></td>
<td>855-404-4768 x1</td>
<td>Acquired by Sinch.</td>
</tr>
<tr>
<td><strong>Onvoy</strong></td>
<td><a href="https://www.sinch.com/legal/report-scams-fraud/">Report abuse here</a> or email abuse at onvoy.com</td>
<td>855-404-4768 x1</td>
<td>Acquired by Sinch.</td>
</tr>
<tr>
<td><strong>Peerless</strong></td>
<td>Email report at peerlessnetwork.com</td>
<td>800-440-9440</td>
<td>Acquired by Infobip.</td>
</tr>
<tr>
<td><strong>Sinch</strong></td>
<td><a href="https://www.sinch.com/legal/report-scams-fraud/">Report abuse here</a> or email abuse at onvoy.com</td>
<td>470-300-8394</td>
<td></td>
</tr>
<tr>
<td><strong>T-Mobile USA</strong></td>
<td>Email abuse at t-mobile.com</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Teli</strong></td>
<td>Email noc at teli.net</td>
<td>844-411-1111</td>
<td>Acquired by Commio.</td>
</tr>
<tr>
<td><strong>Telnyx</strong></td>
<td>Email abuse at telnyx.com</td>
<td>888-980-9750</td>
<td></td>
</tr>
<tr>
<td><strong>Twilio</strong></td>
<td><a href="https://www.twilio.com/help/abuse">Report abuse here</a> or email stopspam at twilio.com</td>
<td>844-814-4627</td>
<td></td>
</tr>
</tbody></table>
<p>Also see <a href="#Reporting-abuse-to-your-wireless-provider">Reporting abuse to your wireless provider</a>.</p>
<h3 id="what-to-include"><a href="#what-to-include"></a>What to include</h3>
<ul>
<li>The phone number that you want them to investigate</li>
<li>How you were contacted (phone call or text)</li>
<li>Day and time when you were contacted</li>
<li>Your phone number</li>
</ul>
<p>Optional but recommended:</p>
<ul>
<li>A clear statement that you did not provide permission for this organization to contact you</li>
<li>(If readily available) The text of the message or transcription of the voicemail</li>
</ul>
<p>When the carrier responds, make sure that they don't simply remove your phone number from the abuser's list – while ignoring the other victims and the abuse. The carrier should investigate the end customer for unacceptable use or ask their downstream customer to do so. If needed, ask the carrier to ask their customer to provide proof that you opted in.</p>

<h2 id="frequently-asked-questions"><a href="#frequently-asked-questions"></a>Frequently Asked Questions</h2>
<h2 id="how-does-this-help"><a href="#how-does-this-help"></a>How does this help?</h2>
<p>Most US-based carriers don't want phone spam to use their network or phone numbers. In order to disconnect abusive customers, they need to hear about the abuse. Here's a real reply from a carrier: "Please be advised that the offending traffic has been removed from our network."</p>
<h2 id="how-is-this-different-than"><a href="#how-is-this-different-than"></a>How is this different than…</h2>
<p><strong>How is this different than using the "Report Junk" (iOS) or "Block &amp; report spam" (Android) buttons, or a call reporting app provided by your wireless provider?</strong></p>
<p>Those reports are sent to your own wireless provider and/or the phone OS manufacturer (Apple or Google). It helps them try to block/filter similar messages, so that other subscribers are not bothered. However, those reports don't reach the carrier that is providing service to the organization that's annoying you. This page explains how to report abuse to the carrier that can actually shut off the spammer's phone numbers. </p>
<p>Also, the instructions on this page work for phone calls, while "Report" buttons or blocking the number mostly don't help with phone calls.</p>
<p><strong>How is this different than blocking the number?</strong></p>
<p>Blocking a phone number is a bit better than nothing, but not much. With phone calls, the originating phone number is usually spoofed, so blocking has almost no effect. With text messages, the originating phone number is generally not spoofed, but senders constantly rotate through outbound numbers.</p>
<h2 id="what-about-political-or-non-profit-organizations"><a href="#what-about-political-or-non-profit-organizations"></a>What about political or non-profit organizations?</h2>
<p>Most reputable telecom carriers don't allow unsolicited mass messages, regardless of content. Report it.</p>

<h2 id="how-do-i-look-up-more-numbers-obtain-more-accurate-data-or-use-an-api"><a href="#how-do-i-look-up-more-numbers-obtain-more-accurate-data-or-use-an-api"></a>How do I look up more numbers, obtain more accurate data, or use an API?</h2>
<p>Create a free account with <a href="https://www.twilio.com/try-twilio">Twilio</a> or <a href="https://console.plivo.com/accounts/register/">Plivo</a>. Then, use the Twilio or Plivo number lookup APIs to discover which carrier the abusive number(s) are routed to.</p>

<h3 id="twilio"><a href="#twilio"></a>Twilio</h3>
<p>To use <a href="https://www.twilio.com/docs/lookup/v2-api/line-type-intelligence">Twilio</a> Line Type Intelligence API, run:</p>
<pre><code>curl -X GET \
  'https://lookups.twilio.com/v2/PhoneNumbers/+14151112222?Fields=line_type_intelligence' \
  -u 'YOUR-TWILIO-ACCOUNT-SID:YOUR-TWILIO-AUTH-TOKEN'</code></pre><p>Replace <code>4151112222</code> with the phone number you want to find the carrier for. The <code>line_type_intelligence</code> hash contains a <code>carrier_name</code> field with the carrier name (<a href="https://www.twilio.com/docs/lookup/v2-api/line-type-intelligence?code-sample=code-line-type-intelligence-lookup&amp;code-language=curl&amp;code-sdk-version=json">example</a>). Your Twilio API tokens can be found <a href="https://console.twilio.com/">here</a>.</p>

<h3 id="plivo"><a href="#plivo"></a>Plivo</h3>
<p>To use <a href="https://www.plivo.com/docs/lookup/api/overview/">Plivo</a> Lookup API, run:</p>
<pre><code>curl -X GET \
 `https://lookup.plivo.com/v1/Number/+14151112222?type=carrier` \
  -u YOUR-PLIVO-AUTH-ID:YOUR-PLIVO-AUTH-TOKEN</code></pre><p>Replace <code>4151112222</code> with the phone number you want to find the carrier for. The <code>carrier</code> hash contains a <code>name</code> key with the carrier name (<a href="https://www.plivo.com/docs/lookup/api/response#response-examples">example</a>). Your Plivo API tokens can be found <a href="https://console.plivo.com/dashboard/">here</a>.</p>
<h2 id="sometimes-i-get-text-messages-from-email-addresses-not-phone-numbers-what-are-they"><a href="#sometimes-i-get-text-messages-from-email-addresses-not-phone-numbers-what-are-they"></a>Sometimes I get text messages from email addresses, not phone numbers. What are they?</h2>
<p>These could be Apple iMessages. See <a href="https://support.apple.com/en-us/HT207006">What is the difference between iMessage and SMS?</a>. Apple manages all iMessage access. For unsolicited iMessages, push "Report Junk" to send the message to Apple.</p>
<p>These could also be text messages which were relayed through your wireless provider's text-to-email gateway. Some wireless providers let outsiders send email that the wireless provider forwards to you via text message. Very few people use text-to-email gateways; if you don't, consider contacting your wireless provider to disable email-to-text functionality on your account. Learn more: <a href="https://www.att.com/support/article/wireless/KM1061254/">AT&amp;T</a>, <a href="https://community.t-mobile.com/accounts-services-4/how-can-i-block-all-text-messages-sent-from-email-addresses-14461">T-Mobile</a>, <a href="https://www.verizon.com/about/account-security/email-to-text-faqs">Verizon</a>.</p>

<h2 id="other"><a href="#other"></a>Other</h2>

<h2 id="reporting-abuse-to-your-wireless-provider"><a href="#reporting-abuse-to-your-wireless-provider"></a>Reporting abuse to your wireless provider</h2>
<p>This site is about reporting abuse to the carrier responsible for the sending phone number(s). In addition, you can and should report spam to your own wireless provider. Your reports help your wireless provider block unsolicited calls and messages from reaching other subscribers.</p>
<p>In short:</p>
<ul>
<li><strong>For unsolicited calls:</strong> Strongly consider installing the call filtering and call reporting app that your wireless provider provides: <a href="https://www.att.com/security/">AT&amp;T ActiveArmor</a>, <a href="https://www.t-mobile.com/customers/scam-shield">T-Mobile Scam Shield</a>, <a href="https://www.verizon.com/solutions-and-services/call-filter/">Verizon Call Filter</a>. Report unsolicited calls using that app.</li>
<li><strong>For text message spam:</strong> Use the "Report Junk" button (<a href="https://support.apple.com/guide/iphone/block-filter-and-report-messages-iph203ab0be4/ios">iOS</a>) or "Block &amp; report spam" (<a href="https://support.google.com/messages/answer/9061432?hl=en&amp;co=GENIE.Platform%3DAndroid">Android</a>) button. If the message does not show a report button, copy and paste the text message to 7726 (SPAM). See <a href="https://consumer.ftc.gov/articles/how-recognize-and-report-spam-text-messages#report">FTC: How To Report Spam Text Messages</a>.</li>
<li>Add your number(s) to the <a href="https://www.donotcall.gov/">National Do Not Call Registry</a>.</li>
</ul>
<h2 id="not-in-the-us-or-canada"><a href="#not-in-the-us-or-canada"></a>Not in the US or Canada?</h2>
<p>This site focuses on abuse from US/Canada phone numbers, called the "North American Numbering Plan." The process described above is likely work for telecom abuse from numbers in other countries, though different carrier lookup services may be needed. However, the lookup services mentioned in this page may work; for example, <a href="#Twilio">Twilio</a> states "Worldwide support" for their carrier lookup API. Try them and see.</p>

<h2 id="help-tech-savvy-friends"><a href="#help-tech-savvy-friends"></a>Help tech-savvy friends</h2>
<p>Help tech-savvy friends discover that they can do something meaningful about phone spam. Draft a post on:</p>
<ul>
<li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Freportphonespam.org%2F">Facebook</a></li>
<li><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Freportphonespam.org%2F">LinkedIn</a></li>
<li><a href="https://mastodonshare.com/?text=Here%27s%20how%20to%20shut%20down%20robocallers%20and%20text%20message%20spammers%3A%20https%3A%2F%2Freportphonespam.org%2F%0A%0ADon%27t%20just%20block%20them%20%E2%80%93%20report%20the%20abuse%20to%20the%20spammer%27s%20telecom%20provider%20and%20get%20their%20phone%20number%20disconnected.%20In%20about%2090%20seconds%2C%20your%20report%20can%20stop%20a%20spammer.">Mastodon</a></li>
<li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Freportphonespam.org%2F&amp;text=Here%27s%20how%20to%20shut%20down%20robocallers%20and%20text%20message%20spammers%3A%20https%3A%2F%2Freportphonespam.org%2F%0A%0ADon%27t%20just%20block%20them%20%E2%80%93%20report%20the%20abuse%20to%20the%20spammer%27s%20telecom%20provider%20and%20get%20their%20phone%20number%20disconnected.%20In%20about%2090%20seconds%2C%20your%20report%20can%20stop%20a%20spammer.">Twitter</a></li>
</ul>
<p>…&nbsp;or <a href="mailto:?subject=how%20to%20shut%20down%20robocallers%20and%20text%20message%20spammers&amp;body=Here%27s%20how%20to%20shut%20down%20robocallers%20and%20text%20message%20spammers%3A%20https%3A%2F%2Freportphonespam.org%2F%0A%0AIt%27s%20the%20next%20step%20beyond%20blocking.%20In%20about%20a%20minute%2C%20you%20can%20report%20abuse%20to%20the%20spammer%27s%20telecom%20provider%20%E2%80%93%C2%A0so%20their%20service%20gets%20disconnected.">compose an email</a> to a friend.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The worst thing about Jenkins is that it works (179 pts)]]></title>
            <link>http://twitchard.github.io/posts/2019-06-21-life-is-too-short-for-jenkins.html</link>
            <guid>38507381</guid>
            <pubDate>Sun, 03 Dec 2023 14:40:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://twitchard.github.io/posts/2019-06-21-life-is-too-short-for-jenkins.html">http://twitchard.github.io/posts/2019-06-21-life-is-too-short-for-jenkins.html</a>, See on <a href="https://news.ycombinator.com/item?id=38507381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
            <article>
    
    <section>
        <p><img src="http://twitchard.github.io/images/dropCapA.jpg" alt="A">bout nine months ago, I requested a transfer to the team working on the company’s CI tooling. In my judgement, CI was a major productivity blocker for the whole organization, and I hoped I would be able to help improve it and make a broad, positive impact.</p>
<p>At that time, CI was in Jenkins 1, which had three major problems:</p>
<ol type="1">
<li><p>Everybody’s CI pipeline was described in text boxes in the Jenkins UI, which meant they were not version controlled, discoverable, and editing/testing new configurations was a difficult experience.</p></li>
<li><p>The web interface was dated and unpleasant to use.</p></li>
<li><p>Developers had little control over the environment in which their jobs ran, because the VMs operating as Jenkins nodes were centrally managed.</p></li>
</ol>
<p>My team considered two options.</p>
<h3 id="option-1-switch-tools">Option 1: Switch tools</h3>
<p>The head of SRE championed Gitlab CI. I resisted this idea because I, the relatively inexperienced manager of a nascent team, was daunted by the prospect of trying to supplant Jenkins, Github, and JIRA all at once.</p>
<p>On a previous team I had used Concourse CI to some extent, but I wasn’t really blown away by the experience. Travis and Circle were mentioned. I was a fool. I should have committed to seriously researching some of the contenders and making a more informed decision, but I lacked the willpower and the discernment.</p>
<h3 id="option-2-upgrade-to-jenkins-2">Option 2: Upgrade to Jenkins 2</h3>
<p>On the face of it, Jenkins 2 seemed to meet all our needs. It:</p>
<ol type="1">
<li><p>Supports defining your CI job as a “declarative pipeline” that can live as a Jenkinsfile in the root of your repository. Hooray configuration as code!</p></li>
<li><p>Boasts a UX facelift called “Blue Ocean” that looks more modern.</p></li>
<li><p>Permits pipelines to request to be run on a docker “agent”, which lets application developers control the environment on which their job is run by specifying a Docker image or Dockerfile.</p></li>
</ol>
<h2 id="a-taxonomy-of-mistakes">A Taxonomy of Mistakes</h2>
<p>The worst mistakes come in two distinct flavors: catastrophic and insidious.</p>
<p>A catastrophic mistake is like triggering an outage, or deleting production data. The moment you realize what you’ve done is the worst single moment in your career. Your heart pounds in your chest. Is this a nightmare? Maybe in a second, you will wake up? No, it’s real. Hopefully, you’ve got a healthy culture at work, and you desperately describe the situation to your teammates, who rally to your side. Somebody with a cool head thinks of some way to make the best of things, and somehow – maybe that night, maybe the next day – you make it through. Things go back to normal. You write a postmortem, count your losses, and go back to work – a little less innocent, and a little wiser.</p>
<p>An insidious mistake, by contrast, does not reveal itself in a moment. It makes you suffer a little bit here, and a little bit there, until one day you wake up and you realize that there is a gaping hole where your humanity used to be. You are a miserable husk of a man, with cruelty on your lips and bile in your heart. You still greet your colleagues with that jolly smile of yours – but the sweetness in your smile is the saccharine of cynicism, not the honeyed optimism as it was in the days before, when life was cheerful and your burden was light. The light in your eyes used to be the hope for a better tomorrow. Now it is the glint of madness.</p>
<h2 id="whats-wrong-with-jenkins">What’s wrong with Jenkins</h2>
<p>Choosing Jenkins was the insidious kind of mistake. Warning – I’m going to rant for many, many paragraphs. My advice is to skim.</p>
<p>The worst thing about Jenkins is that it works. It can meet your needs. With a liiittle more effort, or by adopting sliiiightly lower standards, or with a liiiiitle more tolerance for pain, you can always get Jenkins to do aaaaalmost what you want it to. But let’s talk specifics. Jenkins features:</p>
<h3 id="high-indirection-between-you-and-the-execution-of-your-code.">High indirection between you and the execution of your code.</h3>
<p>For me, the bulk of the actual work of a CI pipeline takes the form of shell commands. are typically executed inside shell commands. In Jenkins pipeline, there is a ‘sh’ “step” that executes the shell. For example</p>
<div id="cb1"><pre><code><span id="cb1-1">  sh <span>'npm install'</span></span>
<span id="cb1-2">  sh <span>'make'</span></span></code></pre></div>
<p>So instead of writing Bash directly, you’re writing Bash inside Groovy. But:</p>
<ul>
<li>Your editor won’t syntax highlight the Bash inside Groovy.</li>
<li>You can’t run “shellcheck” (or any sort of Linter) on the Bash inside the groovy.</li>
<li>You can’t very easily execute your shell commands to test them.</li>
</ul>
<p>There are two ways to try and address this:</p>
<ol type="1">
<li>Write your shell in a separate Bash file that you execute from Groovy, avoid putting it inline in your pipeline.</li>
<li>Try to avoid writing shell at all – instead, implement everything as Groovy methods.</li>
</ol>
<p>I think #1 is actually the better approach. We started out there. The trouble was, we started wanting to abstract our pipeline steps and turn them into “shared libraries” and so we gravitated toward #2, so that we could share steps easily across pipelines.</p>
<p>The trouble is: Groovy is a much, much worse language for executing commands than Bash. Bash is interpreted, has a REPL that is great for experimentation, does require a ton of imports, and has lightweight syntax. Groovy has none of these things. The way that developers test their Groovy steps is by triggering a job on the remote Jenkins server to run them. The feedback loop is 2 orders of magnitude slower than it is for just executing Bash locally.</p>
<p>Are there ways to execute the Groovy steps locally? The way you’re supposed to do it is with <a href="https://github.com/jenkinsci/JenkinsPipelineUnit">JenkinsPipelineUnit</a> which is a very good idea – it lets you write unit tests against your Jenkins Pipeline, and gives you an interface for mocking various Jenkins things. But there are two problems:</p>
<ol type="1">
<li>As noted in the README, Groovy doesn’t run the same way on Jenkins as it does in your unit test, because the groovy DSL is “serialized” by Jenkins before running.</li>
<li>“Declarative” pipelines <a href="https://github.com/jenkinsci/JenkinsPipelineUnit/issues/10">are not supported</a> – a huge problem for us, since that’s how we’ve implemented all our stuff, since it seemed to be the newest and most modern thing to be doing.</li>
</ol>
<p>So basically, that’s a huge bust. Especially since we were not a Java shop. My team was barely able to kind of piece this together because it’s our job to work on the CI system, but there is absolutely no way that any of the PHP/Javascript/Golang/Python application developers who need to write pipelines will be able to download Gradle, figure out they need to run gradle init, install the pipeline unit testing library, figure out the proper way to initialize the “PipelineTestHelper”.</p>
<p>So we’re basically resigned to the workflow of running shell commands defined in methods used by a DSL embedded in groovy transmitted to the CI master node, serialized and passed to a CI worker node and executed there.</p>
<p>There’s a “replay script” feature that lets you edit your pipeline right in the web interface, which helps cut down on the feedback time a little bit if you don’t care about version controlling your changes or being able to use your own editor/tools. I personally am not willing to make that sacrifice.</p>
<p>TL;DR, the feedback loop sucks. You’ll never be able to effectively test any of the code running in your pipeline. Your best bet is to build it all entirely in Bash, build your own mechanism for testing it and sharing functionality. The ability to write Groovy shared libraries is a trap and leads only to misery.</p>
<h3 id="low-level-of-discoverability">Low level of discoverability</h3>
<p>A lot of functionality that Jenkins has in the web UI – especially the functionality that comes through plugins – is also possible to define in pipelines, but the means for doing this is not well-documented. For example, there’s this <a href="https://github.com/jenkinsci/throttle-concurrent-builds-plugin">plugin</a> that permits you to “throttle” a job so that multiple jobs don’t fire at once. that you can see inside the UI. After probably half a day of Googling, trial and error, and thanks to a stroke of luck, I figured out that I could accomplish what I wanted by putting the following in my Jenkinsfile:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>properties</span><span>([[</span></span>
<span id="cb2-2">        $class<span>:</span> <span>'ThrottleJobProperty'</span><span>,</span></span>
<span id="cb2-3">        maxConcurrentTotal<span>:</span> <span>5</span><span>,</span></span>
<span id="cb2-4">        throttleEnabled<span>:</span> <span>true</span><span>,</span></span>
<span id="cb2-5">        throttleOption<span>:</span> <span>'project'</span></span>
<span id="cb2-6"><span>]])</span></span></code></pre></div>
<p>Maybe if I were a Java/Groovy expert I could have read the source code for the plugin and determined this was possible. But I shouldn’t have to be. And the application developers trying to implement their own pipelines for there code <em>definitely</em> shouldn’t have to be.</p>
<p>There are two tricks I’ve developed to help the discovery of these magic incantations. Trick 1 is the “Snippet Generator”, which is basically a drop down box in the Jenkins UI with a pretty comprehensive list of options to explore and can help you find what you need maybe 15% of the time. Even if you can’t produce something usable, the snippet generator can give you an idea what to Google for.</p>
<p>Trick 2 I’ve had much more success with. Use the snippet generator or Google things just enough to find a function name or keyword relevant to whatever you’re trying to do. Then, go to <code>github.com/search</code> and put <code>filename:Jenkinsfile &lt;keyword&gt;</code>. You’ll probably find something you can copy and paste. It’s worked 90% of the time, for me.</p>
<p>Really, this experience sucks. I don’t really do any sort of other engineering like that, because sane systems have better documentation, more obvious abstractions, and better interactivity. I feel like a script kiddie, blindly typing incantations in to make magic happen through trial and error. Hugely demoralizing.</p>
<h3 id="blue-ocean-is-incomplete-and-unintuitive">Blue Ocean is Incomplete and Unintuitive</h3>
<p>Blue Ocean looks more modern than the classic Jenkins UI – I’ll give it that. Unfortunately, it’s missing functionality, so you’ll have to use and become familiar with the classic Jenkins UI anyway. It’s also just not a pleasant UI to use! I’m not much of a design person or a front-end developer, so I can’t articulate precisely what it is that makes the interface unpleasant, but it always seems to take several clicks in places I don’t expect in order to do what I’m trying to do – usually, I just want to run the build, or see the output of the build.</p>
<h3 id="docker">Docker</h3>
<p>It is possible to have your builds run inside docker containers. Jenkins 2 does let the job author specify a docker image, or dockerfile – even kubernetes configurations for autoscaling! So, in principle, the problem of letting job authors own their job’s environment is solved.</p>
<p>The only problem is that this problem is solved by incorporating the idea of a “Jenkins worker” INTO the idea of a Docker container. These two ideas don’t always play well together. For example, one thing I kind of expected/hoped for was that, defining a Jenkinsfile to use a Dockerfile, and then giving it a build step like</p>

<p>would be approximately the same thing as</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>docker</span> build . <span>-t</span> foo</span>
<span id="cb4-2"><span>docker</span> run foo make test</span></code></pre></div>
<p>But it different in one very significant way. With <code>docker run</code>, your cwd is whatever the Dockerfile defined. In a Jenkins job, the cwd is the Jenkins workspace – which is bind mounted in from the host node. Basically, Jenkins tries to <em>turn your docker container</em> into a regular old Jenkins worker. This makes a degree of sense, but has a number of inconveniences.</p>
<ol type="1">
<li>You probably can’t be root inside your docker container. If your build produces any sort of persistent artifact in the workspace, that artifact will be owned by root and will end up on the filesystem of the host. Jenkins on the host doesn’t run as root, so it doesn’t have permissions to wipe the workspace when it needs to, and you’ll get janky permissions errors.</li>
</ol>
<p>So what we ended up doing is creating a user inside the dockerfile with the same UID as the user that Jenkins runs as. Passed through via a build arg. This is not something I’d really mind doing once – but you have to do this trick for <em>every single job</em> that is defined. So it’s not just something we could solve for everybody on the CI team. Every application developer who wanted to define their own job ran up against this problem. And it’s a confusing problem – it took me days to really make sense of what Jenkins was trying to do. We documented it internally about as well as we could, but still we ended up guiding probably at least a dozen application developers through this particular confusion.</p>
<ol start="2" type="1">
<li>You’re probably going to have to define a docker image <em>just</em> for the build.</li>
</ol>
<p>One of the mostly-false promises of Docker, as it was sold to me by the true believers who introduced me to it, was that, if you do it right, you can run the same docker image, and therefore have basically the same environment in production, in CI, and on your local development machine. I’ve never actually see this happen, but I can tell you right now – you’re going to have to define a special docker image just for Jenkins, because of how strangely it interacts with the world of containers.</p>
<p>Lest this turn into a rant against Docker – a tool I am also seriously disappointed with, I’ll end here. Long story short, we used Jenkins 2. It kind of solved our problems. So now our problems are kind of solved, which is the worst kind of solved.</p>
<h3 id="postlude">Postlude</h3>
<p>It’s a month after I started writing this post. Now I work at a different, bigger company. I no longer work on CI. What’s more, one of the principles I had never even thought to question at my old company – “everybody should be writing and maintaining their own CI jobs” – is just not at play here. There’s a team that seems almost completely to own CI and all CI jobs. I’m in week 4, and I know Jenkins is there, somewhere, lurking behind the scenes. But I have never interacted with it, and it seems like there are a lot of smart people working so that I never, ever need to. What a strange new world this is.</p>
    <hr>

    
    </section>
</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Onsites.fyi - Curated Big Tech Interview Experiences (161 pts)]]></title>
            <link>https://www.onsites.fyi/</link>
            <guid>38506900</guid>
            <pubDate>Sun, 03 Dec 2023 13:29:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.onsites.fyi/">https://www.onsites.fyi/</a>, See on <a href="https://news.ycombinator.com/item?id=38506900">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Committed to Buying $51M of AI Chips from a Startup Backed by Sam Altman (233 pts)]]></title>
            <link>https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/</link>
            <guid>38506660</guid>
            <pubDate>Sun, 03 Dec 2023 12:42:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/">https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/</a>, See on <a href="https://news.ycombinator.com/item?id=38506660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Sam Altman was reinstated soon after being <a href="https://www.wired.com/story/sam-altman-officially-returns-to-openai-board-seat-microsoft/">fired as OpenAI CEO</a> last month, but still stood to gain had the company continued to develop <a href="https://www.wired.com/tag/chatgpt/">ChatGPT</a> without him. During Altman’s tenure as CEO, OpenAI signed a letter of intent to spend $51 million on AI chips from a startup called Rain AI into which he has also invested personally.</p><p>Rain is based less than a mile from OpenAI’s headquarters in San Francisco and is working on a chip it calls a <a href="https://www.technologyreview.com/2013/12/16/174934/thinking-in-silicon/">neuromorphic</a> processing unit, or NPU, designed to <a data-offer-url="https://johnkoetsier.com/artificial-brain-neuromorphic-chip/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://johnkoetsier.com/artificial-brain-neuromorphic-chip/&quot;}" href="https://johnkoetsier.com/artificial-brain-neuromorphic-chip/" rel="nofollow noopener" target="_blank">replicate features of the human brain</a>. OpenAI in 2019 signed a nonbinding agreement to spend $51 million on the chips when they became available, according to a copy of the deal and Rain disclosures to investors this year seen by WIRED. Rain told investors Altman had personally invested more than $1 million into the company. The letter of intent has not been previously reported.</p><p>The investor documents said that Rain could get its first hardware to customers as early as October next year. OpenAI and Rain declined to comment.</p><div><p>OpenAI’s letter of intent with Rain shows how Altman’s web of personal investments can entangle with his duties as OpenAI CEO. His prior position leading startup incubator Y Combinator helped Altman become one of Silicon Valley’s most prominent dealmakers, investing in dozens of startups and acting as a broker between entrepreneurs and the world’s biggest companies. But the distraction and intermingling of his myriad pursuits played some role in his recent <a href="https://www.wired.com/story/openai-ceo-sam-altman-is-out-after-losing-confidence-of-board/">firing</a> by OpenAI’s board for uncandid communications, according to people involved in the situation but not authorized to discuss it.</p><p>The Rain deal also underscores OpenAI’s willingness to spend large sums to secure supplies of chips needed to underpin pioneering AI projects. Altman has complained publicly of a <a href="https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded">“brutal crunch”</a> for AI chips and their <a data-offer-url="https://twitter.com/sama/status/1599669571795185665" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://twitter.com/sama/status/1599669571795185665&quot;}" href="https://twitter.com/sama/status/1599669571795185665" rel="nofollow noopener" target="_blank">“eye-watering”</a> costs. OpenAI taps the powerful cloud of Microsoft, <a href="https://www.wired.com/story/microsoft-emerges-as-the-winner-in-openai-chaos/">its primary investor</a>, but has regularly shut off access to features of ChatGPT due to hardware constraints. According to a blog post about a closed door meeting he held with developers, Altman <a href="https://finance.yahoo.com/news/blog-post-detailed-sam-altman-142219663.html">has said</a> the pace of AI progress may be dependent on new chip designs and supply chains.</p></div><p>Rain touted its progress to potential investors earlier this year, projecting that as soon as this month it could “tape out” a test chip, a standard milestone in chip development referring to a design ready for fabrication. But the startup also has recently reshuffled its leadership and investors after reportedly an interagency US government body that polices investments for national security risks mandated Saudi Arabia-affiliated fund Prosperity7 Ventures to sell its stake in the company. The fund led a $25 million fundraise <a data-offer-url="https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures&quot;}" href="https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures" rel="nofollow noopener" target="_blank">announced</a> by Rain in early 2022.</p><p>The forced removal of the fund, first <a href="https://www.bloomberg.com/news/articles/2023-11-30/us-compels-saudi-fund-to-exit-ai-chip-startup-backed-by-altman">reported by Bloomberg</a> Thursday and described in the documents seen by WIRED, could add to Rain’s challenges of bringing a novel chip technology to market, potentially delaying the day OpenAI can make good on its $51 million advance order. Silicon Valley-based <a data-offer-url="https://www.grepvc.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.grepvc.com/&quot;}" href="https://www.grepvc.com/" rel="nofollow noopener" target="_blank">Grep VC</a> acquired the shares; it and the Saudi fund did not respond to requests for comment.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>US concern about Prosperity7’s deal with Rain also raises questions about another effort by Altman to increase the world’s supply of AI chips. He’s talked to investors in the Middle East in recent months about raising money to start a new chip company to help OpenAI and others diversify beyond their current reliance on Nvidia GPUs and specialized chips from Google, Amazon, and a few smaller suppliers, according to two people seeking anonymity to discuss private talks.</p><p>Brain Trust</p><p>Rain, founded in 2017, has claimed that its brain-inspired NPUs will yield potentially 100 times more computing power and, for training, <a href="https://www.linkedin.com/posts/gordonhirschwilson_activity-difference-training-of-deep-neural-activity-7000595097717260288-pF04/">10,000 times</a> greater energy efficiency than GPUs, the graphics chips that are the workhorses for AI developers such as OpenAI and primarily sourced from Nvidia.</p><p>Altman led one of Rain’s seed financings in 2018, the company has said, the year before OpenAI committed to spend $51 million on its chips. Rain now has about 40 employees, including experts in both development of AI algorithms and traditional chip design, according the disclosures.</p><p>The startup appears to have quietly changed its CEO this year and now lists founding CEO Gordon Wilson as executive advisor on its website, with former white-shoe law firm attorney William Passo gaining a promotion to CEO from COO.</p><p>Wilson confirmed his exit in <a href="https://www.linkedin.com/feed/update/urn:li:activity:7135990941244411904/">a LinkedIn post</a> Thursday, but did not provide a reason. “Rain is poised to build a product that will define new AI chip markets and massively disrupt existing ones,” he wrote. “Moving forward I will continue to help Rain in every way I can.” Over 400 LinkedIn users including some whose profiles say they are Rain employees commented on Wilson's post or reacted to it with heart or thumbs up emojis—Passo wasn't among them. Wilson declined to comment for this story.</p><p>The company will search for an industry veteran to permanently replace Wilson, according to an October note to investors seen by WIRED.</p><p>Rain’s initial chips <a data-offer-url="https://rain.ai/approach" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://rain.ai/approach&quot;}" href="https://rain.ai/approach" rel="nofollow noopener" target="_blank">are based</a> on the <a href="https://www.wired.com/story/using-open-source-designs-to-create-more-specialized-chips/">RISC-V open-source architecture</a> endorsed by Google, Qualcomm, and other tech companies and aimed at what the tech industry calls edge devices, located far from data centers, such as phones, drones, cars, and robots. Rain aims to provide a chip capable of both training machine algorithms and running them once they’re ready for deployment. Most edge chip designs today, like <a href="https://www.wired.com/story/how-apple-makes-ai-chip-powering-iphones-fancy-tricks/">those found in smartphones</a>, focus on the latter, known as inference. How OpenAI would use Rain chips could not be learned.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Rain at one point has claimed to investors that it has held advanced talks to sell systems to Google, Oracle, Meta, Microsoft, and Amazon. Microsoft declined to comment, and the other companies did not respond to requests for comment.</p><p>Security Fears</p><p>The funding round led by Prosperity7 announced last year brought Rain’s total funding to $33 million as of April 2022. That was enough to operate through early 2025 and valued the company at $90 million excluding the new cash raised, according to the disclosures to investors. The documents cited Altman’s personal investment and Rain’s letter of intent with OpenAI as reasons to back the company.</p><p>In a Rain <a data-offer-url="https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape&quot;}" href="https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape" rel="nofollow noopener" target="_blank">press release</a> for the fundraise last year, Altman applauded the startup for <a data-offer-url="https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/&quot;}" href="https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/" rel="nofollow noopener" target="_blank">taping out a prototype in 2021</a> and said it “could vastly reduce the costs of creating powerful AI models and will hopefully one day help to enable true artificial general intelligence.”</p><p>Prosperity7’s investment in Rain drew the interest of the interagency Committee on Foreign Investment in the United States, which has the power to scuttle deals deemed to threaten national security.</p><p>CFIUS, as the committee is known, has long been concerned about China gaining access to advanced US semiconductors, and has grown increasingly <a href="https://www.ft.com/content/2a636cee-b0d2-45c2-a815-11ca32371763">worried about China using intermediaries in the Middle East</a> to quietly learn more about critical technology, says Nevena Simidjiyska, a partner at the law firm Fox Rothschild who helps clients with CFIUS reviews. “The government doesn’t care about the money,” she says. “It cares about access and control and the power of the foreign party.”</p><p>Rain received a small seed investment from the venture unit of Chinese search engine Baidu apparently without problems but the larger Saudi investment attracted significant concerns. Prosperity7, a unit of Aramco Ventures, which is part of state-owned Saudi Aramco, possibly could have let the oil giant and other large companies in the Middle East to become customers but also put Rain into close contact with the Saudi government.</p><p>Megan Apper, a spokesperson for CFIUS, says the panel is “committed to taking all necessary actions within its authority to safeguard U.S. national security” but that “consistent with law and practice, CFIUS does not publicly comment on transactions that it may or may not be reviewing.”</p><p>Data disclosed by CFIUS shows it <a data-offer-url="https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf&quot;}" href="https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf" rel="nofollow noopener" target="_blank">reviews hundreds of deals</a> annually and in the few cases where it has concerns typically works out safeguards, such as barring a foreign investor from taking a board seat. It couldn’t be learned why the committee required full divestment from Rain.</p><p>Three attorneys who regularly work on sensitive deals say they could not recall any previous Saudi Arabian deals fully blocked by CFIUS. “Divestment itself has been quite rare over the past 20 years and has largely been a remedy reserved for Chinese investors,” says Luciano Racco, cochair of the international trade and national security practice at law firm Foley Hoag.</p><p>OpenAI likely needs to find partners with deep-pocketed backers if it is to gain some control over its hardware needs. Competitors Amazon and Google have spent years developing their <a href="https://www.wired.com/story/new-amazon-chips-cloud-computing/">own</a> <a href="https://www.wired.com/story/fit-billions-transistors-chip-let-ai-do/">custom chips</a> for AI projects and can fund them with revenue from their lucrative core businesses. Altman <a href="https://www.businessinsider.com/sam-altman-says-cant-rule-out-openai-making-own-chips-2023-10">has refused to rule out</a> OpenAI making its own chips, but that too would require significant funding.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1960s chatbot ELIZA beat OpenAI's GPT-3.5 in a recent Turing test study (125 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/</link>
            <guid>38506175</guid>
            <pubDate>Sun, 03 Dec 2023 10:56:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/">https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/</a>, See on <a href="https://news.ycombinator.com/item?id=38506175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      transform and roll out    —
</h4>
            
            <h2 itemprop="description">AI chatbot deception paper suggests that some bots (and people) aren't very persuasive.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/turing_test_hero-800x450.jpg" alt="An illustration of a man and a robot sitting in boxes, talking.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/turing_test_hero.jpg" data-height="675" data-width="1200">Enlarge</a> <span>/</span> An artist's impression of a human and a robot talking.</p><p>Getty Images | Benj Edwards</p></figcaption>  </figure>

  




<!-- cache hit 274:single/related:75c96972efcfd5c809dcc7c1fd0a61ed --><!-- empty -->
<p>In a preprint <a href="https://arxiv.org/abs/2310.20216">research paper</a> titled "Does GPT-4 Pass the Turing Test?", two researchers from UC San Diego pitted OpenAI's <a href="https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/">GPT-4</a> AI language model against human participants, GPT-3.5, and <a href="https://en.wikipedia.org/wiki/ELIZA">ELIZA</a> to see which could trick participants into thinking it was human with the greatest success. But along the way, the study, which has not been peer-reviewed, found that human participants correctly identified other humans in only 63 percent of the interactions—and that a 1960s computer program surpassed the AI model that powers the free version of ChatGPT.</p>

<p>Even with limitations and caveats, which we'll cover below, the paper presents a thought-provoking comparison between AI model approaches and raises further questions about using the <a href="https://en.wikipedia.org/wiki/Turing_test">Turing test</a> to evaluate AI model performance.</p>
<p>British mathematician and computer scientist Alan Turing first conceived the Turing test as "The Imitation Game" <a href="http://phil415.pbworks.com/f/TuringComputing.pdf">in 1950</a>. Since then, it has become a famous but controversial benchmark for determining a machine's ability to imitate human conversation. In modern versions of the test, a human judge typically talks to either another human or a chatbot without knowing which is which. If the judge cannot reliably tell the chatbot from the human a certain percentage of the time, the chatbot is said to have passed the test. The threshold for passing the test is subjective, so there has never been a broad consensus on what would constitute a passing success rate.</p>
<p>In the recent study, <a href="https://arxiv.org/abs/2310.20216">listed on arXiv</a> at the end of October, UC San Diego researchers Cameron Jones (a PhD student in Cognitive Science) and Benjamin Bergen (a professor in the university's Department of Cognitive Science) set up a website called <a href="https://turingtest.live/">turingtest.live</a>, where they hosted a two-player implementation of the Turing test over the Internet with the goal of seeing how well GPT-4, when prompted different ways, could convince people it was human.</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/pass_rate_graph.jpg" data-height="871" data-width="1000" alt="A bar graph of success rates in the Turing test performed by Jones and Bergen, with humans on top and a GPT-4 model in the #2 slot. Ancient rules-based ELIZA outperformed GPT-3.5."><img alt="A bar graph of success rates in the Turing test performed by Jones and Bergen, with humans on top and a GPT-4 model in the #2 slot. Ancient rules-based ELIZA outperformed GPT-3.5." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/pass_rate_graph-640x557.jpg" width="640" height="557" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/11/pass_rate_graph.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/pass_rate_graph.jpg" data-height="871" data-width="1000">Enlarge</a> <span>/</span> A bar graph of success rates in the Turing test performed by Jones and Bergen, with humans on top and a GPT-4 model in the #2 slot. Ancient rules-based ELIZA outperformed GPT-3.5.</p></figcaption></figure>
<p>Through the site, human interrogators interacted with various "AI witnesses" representing either other humans or AI models that included the aforementioned GPT-4, GPT-3.5, and <a href="https://en.wikipedia.org/wiki/ELIZA">ELIZA</a>, a rules-based conversational program from the 1960s. "The two participants in human matches were randomly assigned to the interrogator and witness roles," write the researchers. "Witnesses were instructed to convince the interrogator that they were human. Players matched with AI models were always interrogators."</p>
<p>The experiment involved 652 participants who completed a total of 1,810 sessions, of which 1,405 games were analyzed after excluding certain scenarios like repeated AI games (leading to the expectation of AI model interactions when other humans weren't online) or personal acquaintance between participants and witnesses, who were sometimes sitting in the same room.</p>
<p>Surprisingly, ELIZA, developed in the mid-1960s by computer scientist Joseph Weizenbaum at MIT, scored relatively well during the study, achieving a success rate of 27 percent. GPT-3.5, depending on the prompt, scored a 14 percent success rate, below ELIZA. GPT-4 achieved a success rate of 41 percent, second only to actual humans.</p>
<p>GPT-3.5, the base model behind the free version of ChatGPT, has been conditioned by OpenAI specifically not to present itself as a human, which <a href="https://x.com/emollick/status/1728899736609149287?s=20">may partially account</a> for its poor performance. In a post on X, Princeton computer science professor Arvind Narayanan <a href="https://x.com/random_walker/status/1729115756439511119?s=20">wrote</a>, "Important context about the 'ChatGPT doesn't pass the Turing test' paper. As always, testing behavior doesn't tell us about capability." In a <a href="https://x.com/random_walker/status/1729145124561797199?s=20">reply</a>, he continued, "ChatGPT is fine-tuned to have a formal tone, not express opinions, etc, which makes it less humanlike. The authors tried to change this with the prompt, but it has limits. The best way to pretend to be a human chatting is to fine-tune on human chat logs."</p>                                            
                                                        
<p>Further, the authors speculate about the reasons for ELIZA's relative success in the study:</p>
<blockquote><p>"First, ELIZA’s responses tend to be conservative. While this generally leads to the impression of an uncooperative interlocutor, it prevents the system from providing explicit cues such as incorrect information or obscure knowledge. Second, ELIZA does not exhibit the kind of cues that interrogators have come to associate with assistant LLMs, such as being helpful, friendly, and verbose. Finally, some interrogators reported thinking that ELIZA was “too bad” to be a current AI model, and therefore was more likely to be a human intentionally being uncooperative."</p></blockquote>
<p>During the sessions, the most common strategies used by interrogators included small talk and questioning about knowledge and current events. More successful strategies involved speaking in a non-English language, inquiring about time or current events, and directly accusing the witness of being an AI model.</p>
<p>The participants made their judgments based on the responses they received. Interestingly, the study found that participants based their decisions primarily on linguistic style and socio-emotional traits, rather than the perception of intelligence alone. Participants noted when responses were too formal or informal, or when responses lacked individuality or seemed generic. The study also showed that participants' education and familiarity with large language models (LLMs) did not significantly predict their success in detecting AI.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/turing_game_instructions2.jpg" data-height="814" data-width="1072" alt="Instructions for the Turing test AI evaluation game from Jones and Bergen, 2023."><img alt="Instructions for the Turing test AI evaluation game from Jones and Bergen, 2023." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/turing_game_instructions2-640x486.jpg" width="640" height="486" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/12/turing_game_instructions2.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/turing_game_instructions2.jpg" data-height="814" data-width="1072">Enlarge</a> <span>/</span> Instructions for the Turing test AI evaluation game from Jones and Bergen, 2023.</p><p>Jones and Bergen, 2023</p></figcaption></figure>
<p>The study's authors acknowledge the study's limitations, including potential sample bias by recruiting from social media and the lack of incentives for participants, which may have led to some people not fulfilling the desired role. They also say their results (especially the performance of ELIZA) may support common criticisms of the Turing test as an inaccurate way to measure machine intelligence. "Nevertheless," they write, "we argue that the test has ongoing relevance as a framework to measure fluent social interaction and deception, and for understanding human strategies to adapt to these devices."</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/2/">2</a> <a href="https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Simulate 3D Plants in the Browser (309 pts)]]></title>
            <link>https://plant.max-richter.dev</link>
            <guid>38506166</guid>
            <pubDate>Sun, 03 Dec 2023 10:55:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plant.max-richter.dev">https://plant.max-richter.dev</a>, See on <a href="https://news.ycombinator.com/item?id=38506166">Hacker News</a></p>
<div id="readability-page-1" class="page">
		<div>       <header>  <div><div><form><h3>Login</h3>   <p><span>Username/Email</span>    </p>  <p><span>Password</span>    </p>  <div> <p>  <label for="c1z8t_QemVun-0nn8diiW"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><title>cross</title><line vector-effect="non-scaling-stroke" x1="0" y1="100" x2="100" y2="0"></line><line vector-effect="non-scaling-stroke" x1="0" y1="0" x2="100" y2="100"></line></svg></label></p><p>register</p> </div> </form></div> <div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path d="M13.172 12l-4.95-4.95 1.414-1.414L16 12l-6.364 6.364-1.414-1.414z"></path></svg> <p>Tutorials</p></div>  </div> </div> </header> <main> <div>  <canvas></canvas>   </div> </main> 
			
			
		</div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text (193 pts)]]></title>
            <link>https://arxiv.org/abs/2311.18805</link>
            <guid>38506140</guid>
            <pubDate>Sun, 03 Dec 2023 10:48:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.18805">https://arxiv.org/abs/2311.18805</a>, See on <a href="https://news.ycombinator.com/item?id=38506140">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.18805.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Qi Cao [<a href="https://arxiv.org/show-email/8edf2a0c/2311.18805">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 30 Nov 2023 18:51:38 UTC (246 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Mobile Tools suite to be acquired by Israeli adware company (161 pts)]]></title>
            <link>https://github.com/SimpleMobileTools/General-Discussion/issues/241</link>
            <guid>38505229</guid>
            <pubDate>Sun, 03 Dec 2023 06:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SimpleMobileTools/General-Discussion/issues/241">https://github.com/SimpleMobileTools/General-Discussion/issues/241</a>, See on <a href="https://news.ycombinator.com/item?id=38505229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <blockquote>
<p dir="auto">not really, thats not how it works</p>
</blockquote>
<p dir="auto">First of all, lemme prepend this by saying that I Am Not A Lawyer, meaning I may miss a detail and be wrong.</p>
<p dir="auto">I have looked around and I was not able to find a CLA or similar, meaning that any contributions to this project has not resulted in any of the contributors waving their rights to the legal owner of the project. Though, if there was indeed a CLA to sign before contributing and it stated that you waved your rights, then the following paragraphs won't be true.</p>
<p dir="auto">Once the sale is complete, if zipoapps decides to go closed source <em>and</em> keep the external contributions, any contributors will have the ability to claim license infringement and ask zipoapps to comply under the terms of the license: either by removing every of your contributions (depending on how big of a contributor you are this might be a big blow to them), or by forcing them to keep the project open-source as defined by the GPLv3 license.</p>
<p dir="auto">If zipoapps do make those apps closed source, and you're a contributor for whom it is uncomfortable, I'd recommend to consult a lawyer first to inform yourself of what you can do and the proper steps to take.<br>
Though, there's also the question of is it worth it to go after them? Maybe energy is better spent working on the fork, given who this project panders to, I don't think zipoapps will inherit much of the userbase if they go down the bad road.</p>
<p dir="auto">While I am mostly an external observer in this story, I wish a good continuation to the original author of this project, I can see how bailing out can become a desirable option when things get bad. I do find it weird it has been chosen to sell the project instead of giving it to another maintainer who could have continued the project's legacy. I guess there's some personal things that pushed to the sale, so I wouldn't hold it too much against the author. I also wish a good continuation to the fork as well.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Visualization (294 pts)]]></title>
            <link>https://bbycroft.net/llm</link>
            <guid>38505211</guid>
            <pubDate>Sun, 03 Dec 2023 06:08:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bbycroft.net/llm">https://bbycroft.net/llm</a>, See on <a href="https://news.ycombinator.com/item?id=38505211">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>LLM Visualization</p><div><p><a href="https://bbycroft.net/">Home</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Personal History of APL (1982) (110 pts)]]></title>
            <link>https://ed-thelen.org/comp-hist/APL-hist.html</link>
            <guid>38505138</guid>
            <pubDate>Sun, 03 Dec 2023 05:46:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ed-thelen.org/comp-hist/APL-hist.html">https://ed-thelen.org/comp-hist/APL-hist.html</a>, See on <a href="https://news.ycombinator.com/item?id=38505138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div name="PersonalHistory">
<p>
<br>October 1982
<br>TR-03.214
</p><center>
<h2>A PERSONAL HISTORY OF APL</h2>
<br>
by
<br>
Michael S. Montalbano


<p>

International Business Machines Corporation
<br>General Products Division
<br>Santa Teresa Laboratory
<br>San Jose, California
</p></center>
<hr>
<p>
<b>
<font=+1>A PERSONAL HISTORY OF APL
</font=+1></b>
</p><p>
<b>Introduction</b>

</p><p>
I have several reasons for calling this talk a personal history.
</p><p>
For one, I want to make it clear that the opinions I express are my own:
they are not the opinions of my employer or of any other organization,
group or person. If you agree with them, I am happy to have your
concurrence: if you disagree, I'd be happy to defend them. In any event,
the praise, blame or indifference my views may inspire in you should be
directed to me and to no one else.
</p><p>
What I plan to discuss are things I have done, seen or experienced at
first hand. Thus, this talk is merely an opinionated collection of
anecdotes. I want to emphasize this from the outset: it is my second
reason for calling this a personal history.
But my most important reason is that I feel strongly that we need a good,
thoughtful, accurate history both of APL and of computing itself. While
I'd be flattered to have this account included as part of that history, I
don't want anyone to mistake it t as an attempt at the real thing.
</p><p>
<b>
The Importance of History
</b>
</p><p>
We neglect history at our peril. The truly incredible growth of digital
computer technology has transformed our world almost overnight. This
transformation is not only continuing, it is accelerating. It gives every
promise of continuing to change our institutions and the circumstances of
our daily lives at a faster and faster rate. If we are ever to understand
where we're going, it's important that we take a long, careful look at
where we've been, where we are, and how we got from there to here. If we
don't do this, we won't be able to control events; they will control us.
As far as I'm concerned, that's what's happening right now; a runaway
technology has us at its mercy because we have not developed techniques to
understand and control it.
</p><p>
H. G. Wells described human history as a race between education and
catastrophe. This observation is more pertinent today than it ever has
been in the past. But, in the specific case of the proliferation of 
stored-program digital computers, the education-catastrophe race, in my opinion,
takes a particular form: it is a race between technology and methodology,
between gadgets and ideas.
</p><p>
We are developing gadgets at an explosive, accelerating, self-fueling rate
we shall be swamped by these gadgets if we don't hasten to develop and
apply the ideas we need to control them.
</p><p>

To me, this need defines the importance and the mission of APL. APL
provides the best set of gadget-understanding and gadget-controlling ideas
currently available. Looking to the future, it provides the best base for
the methodology we must develop if we are ever to bring our gadget-based
technology under control.
</p><p>
This opinion is based on experience. I was working with computers when
they were merely gleams in the eyes of the early designers: I was working
with APL when it was nothing but a collection of incomprehensible
characters scattered through publications with catchy titles like: The
Description of Finite Sequential Processes. In other words, I've been
working with both computers and APL since their very early days. And, in
looking back on this experience of just over 34 years, (which is my own
personal experience of computing), I find that it can best be summarized
in n terms of two key ideas:
</p><ul>
<li>
The stored-program idea: the idea that a procedure or algorithm can be
stored as a collection of switch settings in exactly the same way as
the data on which the procedure is to work and, as a consequence, that
executing such a stored procedure consists of starting it and letting
it flip switches until it is done. This was apparently first stated
explicitly in n a paper drafted by John yon Neumann in n 1945. <sup><a href="#SUP">1</a></sup>
</li><li>
The efficient-notation idea: the idea that these vast collections of
switches, changing their settings in thousandths, millionths,
billionths, trillionths,... of a second, would be pretty hard to
manage if we didn't develop a good way to describe them and think
about them. I don't know whether this idea was ever presented anywhere
in just these terms. Instead, it seemed to be implicit in the
activities and writings of many people. But, in my opinion, it
received its most effective and fruitful expression in the writings of
Kenneth Iverson and others who followed his lead. The most important
publication expounding this idea is the book from whose title the
letters APL derive their significance.<sup><a href="#SUP">2</a></sup>
</li></ul>
<p>
The stored-program idea provided, and continues to provide, the basis for
our current runaway technology. The efficient-notation idea, if we take it
seriously and do a lot of thinking and hard work, will help us curb the
runaway and direct it t into fruitful and productive channels.
</p><p>

You may find this brief summary of computing history controversial. I hope
so. We need vigorous, informed, philosophical controversy. And, as a
contribution to this controversy, let me state some of my other biases in n
as controversial a manner as I can.
</p><p>
<b>Biases of an APL Bigot</b>
</p><p>
There exists a growing class of people, of which I am happy to consider
myself a member, who are called "APL bigots" by friends and foes alike. The
friends use the term affectionately; the others do not.
</p><p>
The bigotry consists in believing that APL is the way computing should be
done. I think it's fair to say that no one can properly be called an APL
bigot who doesn't believe this.
</p><p>
In one respect, my bigotry may not be as great as that of the general run.
I believe that APL and assembler language are the way computing should be
done. To this extent, I am held suspect by true APL evangelicals.
</p><p>
In another respect, my bigotry is so much greater than theirs that, now
that I am making it t known, I fear I may be excommunicated   as a 
schismatic.

I believe that, important as APL is in computing, it is even more important 
as
an instrument for rationalizing the management process.
</p><p>
Modern management is in trouble. Don't take my word for it. Read the daily
papers, the weekly newsmagazines and the flood of books and articles that
describe management's difficulties and offer cures. Some of these, of
course, assert that Japanese management is an exception to the general
rule; the cure these people offer to nonJapanese management is to learn
from the Japanese how to do it  right.
</p><p>
I don't believe this. I believe Japanese management is in as much trouble
as any other. Its current successes are no indication that its management
isn't afflicted by the same difficulty as the management of organizations
anywhere else in the world. Expressed simply, this difficulty is:
</p><dd>Nobody knows what's going on. 

<p>
Your reaction to this assertion may be emotional. You may believe it
passionately or reject it passionately. If you have either of these 
reactions,
you may not have understood what I said, so I'll repeat it:
</p><blockquote>
The problems of modern management are primarily attributable to one
cause:
<p>
Nobody knows what's going on.
</p></blockquote>
<p>
So there you have it: the basic message that motivates this talk:
</p><ul>
<li>Management's primary difficulty is that it has no good way to describe its
processes and thus develop objective means to correct or improve them.

</li><li>Other fields have faced this problem in the past. The ones that have solved
it most effectively are those that have developed a notation appropriate to
their subject matter. The most conspicuously successful examples of
notations that have virtually created the fields they describe are, of
'course, the specialized symbologies of the so-called "hard sciences".

</li><li>The workings of management can be expressed as extensive, intricate digital
procedures. These procedures cannot be designed, analyzed or described
effectively without a notation specifically designed for the purpose.
</li><li>APL is such a notation.
</li></ul>

There are, of course, many other important difficulties that management 
faces:
obsolescent plant, intensified competition, environmental concerns, employee
morale, strained labor relations, residues of past mismanagement (reflected 
in
such things as excessive debt, inadequate capital, incompetents in key
positions,...) and so on. But these difficulties are made unmanageable by 
our
inability to describe-them in a way that promotes insight and facilitates
communication.

<p>
Clearly, in expressing this opinion, I am swimming against the tide. The
widespread current belief is that we are experiencing an "information
explosion". How can I accuse management of being inadequately informed when
virtually everyone else says that they are overinformed? How can I say that
management doesn't have enough information when everyone else says they 
have so
much information that they are swamped by it?
</p><p>
Let me be blunt: I think the "information explosion" is a myth. I do not 
deny--
how can anyone deny?--that we are generating vast quantities of paper, 
tapes,
disks, etc., with optical or magnetic symbols recorded on their surfaces. 
What
I am denying is that these recorded symbols, in themselves, are information.
They are not. They become information only if, as a minimum:
</p></dd><dd>
They are accurately calculated.
</dd><dd>
They present a true picture of reality.
</dd><dd>
They are understood by the person to whom they are presented.
<p>

Of these three conditions, only the first stands a better than even chance 
of
being satisfied. For the purposes of effective management, all too much
recorded data does not present a true picture of reality and is not 
understood
by the person it is supposed to inform.
</p><p>
What does this all have to do with APL? Let me answer by recounting the 
pre-APL
experiences (at the U. S. National Bureau of Standards, the U. S. Naval
Research Laboratory, and the Kaiser Steel Corporation) that convinced me 
that
the computing field needed, more than anything else, an efficient notation 
for
describing digital procedures. Then let me follow up with the post-APL
experiences (at IBM and Stanford) that convinced me that APL was the 
notation
we needed.

</p><p>












<b>The	U. S. National Bureau of Standards, 1948-1952</b>
</p><p>
I started to work in May, 1948 as a mathematician in the Applied Mathematics
Laboratories of the National Bureau of Standards in Washington, D. C. I was
given a job description which, like every other one I have ever had, bore no
relation whatsoever to what I actually did. My first assignment was to 
program
a division subroutine for the UNIVAC. The UNIVAC that was then being 
designed
by the Eckert-Mauchly Corporation could add, subtract and multiply but it 
could
not divide. (Division was added later. The list of computer instructions or
"order codes", to use the terminology of the times, was updated and given an
identifying C-number as the UNIVAC's design progressed. If my memory's not
playing me tricks, the- order-code 1 list list that was current when I 
started
work was C-7. )
</p><p>

I was given a description of the UNIVAC. It described acoustic delay lines,
excess-three notation and end-around carry. I had the feeling that I was
entering a dark, eerie world in which words would be used as charms and
incantations rather than to communicate definite meanings. I was right.
</p><p>
I was surprised that no one took the trouble to show me the UNIVAC for 
which I
was to program division. After a few days I learned why. The machine 
described
so confidently and completely in the literature that I had been given had 
not
yet been built. (The first UNIVAC was not delivered until three years later.
But at least it was delivered. Our group spent a lot of time programming 
what
were then called "feasibility tests" for a lot of machines that never got 
off
the drawing boards.)
</p><p>
Programming for nonexistent machines started to pall after a few months. Our
group had punched-card equipment (including the 602 calculating punch) with
which we calculated mathematical tables. I switched to this activity at just
about the time the Office of the Air Comptroller asked the Bureau of 
Standards
for assistance in using electromechanical (later electronic) equipment to
calculate Air Force budgets. With the procedures then in use, it was taking
eighteen months to prepare a-yearly budget. There was general agreement that
this was not satisfactory.
</p><p>
I was assigned the task of getting budget computation mechanized under the
direction of George Dantzig, who was in charge of the Air Force budget 
project.
His job was to devise the calculations we were required to perform, that 
is, he
told me what was needed. I wired the plugboards and, later, wrote the 
programs
that gave him what he specified.
</p><p>
The original calculations were called "triangular model" calculations (I
understand they were given the acronym TRIM after I left the project.) The
later calculations were solutions of linear-programming problems, applying 
the
simplex technique that George Dantzig originated. The name of the Air Force
project, SCOOP, (Scientific Computation Of Optimum Programs), like TRIM,
suggests that wherever a computer goes an acronym's sure to follow.
</p><p>
I programmed the triangular-model calculations for the 602, the 602A, the 
604
(the electronic calculating punch) and was about to program them for the CPC
(the Card-Programmed Calculator) when the SEAC became available and I 
switched
back to programming instead of plugboard wiring.
</p><p>
The SEAC (National Bureau of Standards Eastern Automatic Computer) was the
first stored-program digital computer to operate successfully in the United
States. (The first stored-program computer to run successfully anywhere in 
the
world was the EDSAC, designed and built by the University Mathematical
Laboratory at Cambridge, England.) I introduce this information here 
because,
computing history being what it is, it does not seem to be available 
anywhere
else.
</p><p>
Of the many memories and ideas derived from my four years at the Bureau of
Standards, three are relevant to our present purpose:
</p><ol>
<li>I learned to be cautious about how I used the solutions of large systems
of equations with uncertain coefficients. I believe the triangular model
is an extremely effective, and neglected, tool for a large class of
planning problems. But, if the coefficients used in its equations have a
large measure of variability or uncertainty, you must use its answers with
caution.


</li><li>	I learned how desperately we needed a good notation for describing
algorithms. I sat through many presentations and discussions of solution
techniques for linear programming problems. These presentations were
largely chalk dust and arm-waving. The essential ideas, which are extremely
simple once they are understood, were obscured rather than illuminated by
the terminology and notation used to describe them-.
</li><li>	1 learned that gadget development was outstripping idea development and
would continue to do so unless we did something about it. I suggested that
we do something about it. My management was receptive to the idea (or told
me it was) but said there was no money in the budget for idea development.
That, of course, was the problem. It has been the problem ever since. This
failure on the part of my management to fight for research in ideas was one
of the reasons I left the Bureau.
</li></ol>
<p>
<b>U. S. Naval Research Laboratory, 1952-1954</b>
</p><p>
At the Naval Research Laboratory, I became part of an interdisciplinary team
applying the latest operations-research techniques to the development of 
man-machine systems.]
</p><p>
Brave words.
</p><p>
The "disciplines" included physics, mathematics, philosophy, sociology, 
various
brands of psychology, naval science (represented by officers in the United
States Navy), and I don't know what all.
</p><p>
Our tasks were the obvious ones: develop ways to make naval operations more
efficient by incorporating new gadgets into systems that used them to best
advantage. A typical assignment might be either general, for example design 
of
a combat information center for a ship, a task force, or a shore-based 
control
center or specific, for example, taking a new weapon, like a homing torpedo 
to
be fired from the deck of a ship into the water near a distant submarine, 
and
deciding how best to incorporate it into a system including a ship, sensing
devices, communicating devices, and other weapons.
</p><p>

I learned many things during my two years at the Naval Research Laboratory
(among them that clinical and experimental psychologists tend to despise 
each
other) but for our present purposes the most important things I learned 
were:
</p><ul>
<li>	It's hard to plan effectively for a future you can't predict.
</li><li> No numbers are frequently better than some numbers.
</li><li> Nobody knows what's going on.<sup><a href="#SUP">3</a></sup>
</li></ul>
<p>
Predicting the future is, of course, particularly difficult for the military
since a future requiring military action is apt to be precipitated by some
catastrophic event. I attempted to develop techniques for dealing with this 
by
first describing the three states in which the Navy might have to operate:
</p><ul>
<li>	The peacetime state.




<!-- start page 06   --->




</li><li>The transition state from peace to war immediately after hostilities have
commenced.
</li><li>The wartime state.

</li></ul>
and then describing the transformations required to convert from one state 
to the other in n the most efficient way possible.
<p>
I didn't get very far with this, but, if I had the responsibility for con
contingency planning for any organization, civil or military, I would 
return to the three-state model I started to develop for the Navy and build on it.
</p><p>
And, again, I would need an efficient notation.
</p><p>
It was during the time I worked at the Naval Research Laboratory that I 
first became aware of the ease with which people can deceive themselves with
meaningless figures. This is not a criticism of the Navy. It is a criticism 
of virtually all modern management.
</p><p>
You are much better off with no numbers than meaningless ones.. The minute 
you believe numbers uncritically, that is, without understanding how they're
calculated and how well they measure whatever they're supposed to measure, 
you will generate a breed of employee who will produce numbers and not results.
Your data-processing system will then serve not to describe reality but to 
lie about it.

</p><p>
<b>Kaiser Steel Corporation, 1954-1961</b>
</p><p>
I started with Kaiser Steel as a mathematician, a new kind of employee
requiring a new job description. I started in the Fontana Procedures 
Department of the Controller's Division. The Industrial Engineering Department (which 
was in the Operations Division and thus always in a kind of uneasy rivalry with 
the Procedures Department) had the responsibility for administering job
descriptions. I learned later that the one we filed threw them into a tizzy;
they felt it was another sinister move on the part of the Controller's 
Division to take over the work they were supposed to do.
</p><p>
I left Kaiser Steel, not quite seven years later, as Director of Research 
and Computer Planning.
</p><p>
In the interim, I learned about iron and steelmaking both at Kaiser and,
through industry association meetings and literature, at other American and
Canadian steel plants. I learned about other industries by participation in 
the activities of cross-industry associations. By the time I left Kaiser Steel, 
I had had several years in which to observe management in action. The comments
I've been making, which you may have regarded as flippancies, are honest
descriptions of what I observed.
</p><p>
Consider some examples. They are from Kaiser Steel, because that is where I
worked, but I can testify that they are representative of all management.
</p><p>
<b>Precision Rounds</b>. At the time I was there, Kaiser Steel manufactured an 
alloy steel product called "precision" rounds because the diameters had to be
controlled to very close tolerances. There were two schools of thought about
the place of precision rounds in our product line. One school held that it 
was the most profitable product we made. The other said we were losing our 
shirts on it.
</p><p>
How could this be? Couldn't our cost accountants tell us whether we were 
making money or losing money?
</p><p>

The answer is: no, they couldn't. Two different groups, working off the same
set of figures, reached diametrically opposite conclusions. This was the 
first of many experiences (including attendance at a Stanford gathering of the 
most prestigious accounting firms in the world) that led me to the conclusion 
that most cost accounting is applied metaphysics of an extremely ethereal kind.
Counting angels on the head of a pin is a useful exercise in data-gathering
compared to much cost accounting.






<!-- start page 07   --->





</p><p>
The problem was, as it  always is, the basic data with with which we had 
to work. Rounds of any kind had to go through a finishing operation. Scheduling
finishing operations and describing what took place was one of the most
difficult tasks in the mill. Production figures out of the finishing 
operation were always suspect. The difference between the two schools derived 
primarily from the different ways they interpreted those figures. At least, that's the
best explanation I was ever given.
</p><p>
<b>Tin Mill Flippers</b>. We installed a management incentive plan at Kaiser Steel
while I was there. The incentive plan for the tin mill was delayed for a 
while until we straightened out a rather embarrassing problem that cast doubts on 
the accuracy of our tin mill production recording. We were reporting more tin 
plate coming out of our shears than we put into them.
</p><p>
Management was understandably hesitant about paying performance incentives 
on figures that were so obviously, stupidly wrong.
</p><p>
The difficulty arose from the way we processed rejects. As the sheared plate
went by an inspection station, it was examined for pinholes, surface 
blemishes and other defects. When a defect was detected, the inspector pressed a 
button that switched the faulty plate to a reject pile. Unfortunately, a few plates
before and after the bad one were also diverted to the reject pile. These 
were usually prime plates that we could not afford to sell at secondary prices.
</p><p>

The prime plates in the reject piles were separated from the true rejects 
by a group of women called "tin mill flippers". They worked at large tables,
examining the plated surfaces carefully and separating the plates into prime
and secondary piles. The difficulty arose here. Because of the way reporting
was done, some of the plates were counted more than once.
</p><p>
We caught this bad data because it was so obvious. A shear can't produce tin
plate; it can only cut it. To shear more tin than you were given was clearly
impossible.
</p><p>
But, of course, this kind of mistake indicated just the tip of the iceberg. 
The errors that weren't so obvious weren't caught and corrected. And they 
existed, let me assure you of that. Even worse, they were almost certainly 
manipulated by people who were better at doctoring figures than at making steel.
</p><p>
<b>Slab Inventories</b>. Steel ingots are broken down into blooms if they are to 
be processed into products like H-beams, I-Beams and the like and into slabs if
they are to be processed into hot or cold-reduced product like sheet and 
strip.
Our biggest semi-finished inventory at Kaiser Steel was in slabs; we had
between 80,000 and 100,000 tons scattered in piles over wide areas of the 
mill grounds.
</p><p>
Slabs are big, heavy chunks of steel. You'd think it would be hard to lose 
one. It's not. It happens every day. Although I've been out of the steel industry
for more than twenty years, years in which we've landed men on the moon, I'm
willing to bet that right now, somewhere in the world, a rolling mill is 
idle because it's waiting for a slab that's sitting on the ground not too far 
away.
</p><p>
My reason for discussing these examples is to illustrate the complexity of 
the activities we are trying to manage. This particular example, as it happens,
also shows how quick management is to seek a technological rather than a
methodological solution.
</p><p>
There are many reasons why, despite the existence of a huge slab inventory, 
a rolling mill has to wait until the slabs it needs are found. The problem as 
a whole is a complex one and does not lend itself to quick-fix solutions. But 
a technological quick-fix for part of the problem was proposed and, after I 
had left the company, bought and installed. It was a costly failure.
</p><p>
At the risk of teaching you more about steelmaking than you ever wanted to
know, let me describe this attempt to solve a methodological problem by
technological gadgeteering.
</p><p>





<!-- start page 08   --->





The steel produced by one open-hearth melt is called a heat. A major part 
of a slab's identification is its heat number. Since the process of producing 
slabs from ingots usually grinds impurities into some of their surfaces, 
the slabs making up a heat had to be distributed among areas called
scarfing bays where men with oxyacetylene torches would burn out the
impurities. The slabs then had to be reassembled into a heat; the heat had 
to be deposited somewhere in the slab yard; and the heat number and slab-yard
location had to be reported to the production schedulers.
</p><p>
The existence of surface impurities that required scarfing thus caused much 
of the delay and confusion that attended the progression of the heat from the 
slab mill to the reduction mill.
The technological solution proposed for this problem was called a "hot
scarfer". It burnt off all the surface of a slab immediately after it was
reduced to its final dimensions. This was supposed to eliminate the need for
splitting a heat up into scarfing bays.
</p><p>

Thus, at this point, management had a choice:

</p><ol>
<li>	Methodological. Put in the time, effort and money it would take to develop
a satisfactory, realistic scheduling and inventory control system for
slabs. This would necessarily require investigation of all the many
sources of difficulty, not just the kind of difficulty that the hot
scarfer was supposed to eliminate.
</li><li>	Technological. Buy a hot scarfer and hope the slab scheduling and
inventory problem would go away.
</li></ol>
<p>

No contest. The lure of the tangible, glamorous gadget always wins out over 
the intangible, colorless idea. They got a hot scarfer. I say "they" because 
this was done after I left; I am happy to say that I had no part in the decision.
To the best of my knowledge, the hot scarfer never worked satisfactorily. 
It is one item of evidence justifying my belief that technological quick-fixes 
seldom achieve their objectives. (This, incidentally, is even more true for data
processing than it is for steelmaking.) In this particular instance, the 
gadget was expensive to purchase and to operate, it burnt off good steel as well as
surface impurities, and did not do what it was purchased to do: reduce 
wait-for-steel time in the mills that used slabs as inputs.
</p><p>

What does all this steelmaking jargon have to do with APL?
</p><p>

In all of my computer experience, I have found that the chief obstacle to
getting anything done is the absence of any clear, concise, precise, 
formally manageable way to describe and analyze what we're actually doing and to
describe and design a transformation to what we should be doing.

</p><p>

I gave several talks on this topic at professional meetings of various 
kinds. (I later used the written form of these talks, and other papers I wrote 
during my employment at Kaiser Steel, as class notes in the Business Information
Systems classes I taught at the Stanford Graduate School of Business.) One 
of the earliest of the talks, "Formalizing Business Problems", was given at the
first Electronic Business Systems Conference held in Los Angeles in 1955. 
This aroused the interest of Murray Lesser, at what was then the newly 
established IBM facility scattered throughout several locations in downtown San Jose 
(the one that developed into the General Products Division in which I now work). 
We met to discuss what we could do to develop some of the ideas we had in 
common.
</p><p>

The result of our discussions was a joint venture, called the Business 
Language Research Project, in which employees of IBM, Kaiser Steel and Touche, Niven,
Bailey and Smart participated. My contribution to the project was something 
I called "field-and-branch identification" which I later developed into the
approach to systematic systems analysis that I describe in my book on 
decision tables.<sup><a href="#SUP">4</a></sup> I will discuss this more fully later.
</p><p>

Lest I leave you with the impression that nothing effective can be done 
about the data-processing problems of industry, let me assure you that this is not
the case. Among the accomplishments of which I'm proudest are some of 
systems I installed at Kaiser Steel. At least one of them, a tin-mill in-process
inventory and production recording system impressed





<!-- start page 09   --->





the phone company so much that, since we were using some of their equipment 
to record production and to communicate between processing points, they ran an 
ad in the Wall Street Journal featuring a picture of our tin mill and 
describing our system as an example of what could be achieved if you called in their
Production Recording Consultant. We never had the benefit of a Production
Recording Consultant's services because the phone company never told us they
had one. Maybe he was made available to some of the people who read the ad.
</p><p>

So things can get done. But getting them done is slower, more difficult and
more costly than it has to be. That is why we have the application 
programming backlogs that we do. We need a better, more systematic way of dealing with
complex digital procedures.
</p><p>

We need systematic systems analysis.
</p><p>

Now do you see the connection with APL?
</p><p>


<b>IBM, 1961-</b>

</p><p>

I started to work for IBM in the Advanced Systems Development Division, San
Jose. I have since worked in the Palo Alto Scientific Center, the Palo Alto
Systems Center and the Santa Teresa Laboratory, where I am now in APL
Development.
</p><p>

At the time I started my IBM employment, the ASDD library used to circulate 
a daily list of its acquisitions to all employees. I am a kind of pack rat 
when it comes to written material and I acquired all kinds of library offerings
that, I'm sorry to report, I never took time to read.
Among the publications that I thus acquired, scanned, and filed for future
reference were several reports containing a strange, exotic notation. I was
skeptical about the value of these reports since, by that time, I not only 
had my own ideas as to what was needed but I had also seen many attempts by many
people to develop notations, charting techniques, and other descriptive
schemes. I didn't think much of any of them. By and large, history seems to
have agreed with me; most of them are happily forgotten.
</p><p>

However, when I learned that the author of several of the papers full of 
Greek letters, slashes, little circles, curlicues, and other cabalistic symbols 
was coming out to San Jose to talk about his ideas, I decided that I'd read one 
or two of his papers as a preparation for his talk.
</p><p>

My life hasn't been the same since.
</p><p>

My first acquaintance with the notation that has since become APL (for
several years it was either "Iverson Language", "Iverson Notation", or
just plain "Iverson") started with an IBM Research Report by Kenneth Iver-
son called, <b>The Description of Finite Sequential Processes.</b>

</p><p>

I don't have the paper handy at the moment so what I'm about to tell you is 
all memory; it may be mistaken in details but not in essence. I seem to
remember that the first page was mostly given over to heading material,
possibly an abstract, so that there were only two short columns of reading
matter on it. And, again memory, it took me several hours to understand what
those two short columns were all about.
</p><p>

The author's approach was so different from anything I'd ever encountered 
that I had a difficult time adjusting to his frame of reference. At the end of 
the first page, a fair assessment of my state of mind would be that I had
glimmerings but no hope.
</p><p>

The second page took about as much reading time as the first but, since it 
had twice as much matter, I was clearly improving. The glimmerings were now 
fitful gleams. One thing had definitely chanced, however. I had no doubts about the
value of what I was reading. I was now virtually certain that the author had
something to say and that I'd better find out what it was.







<!-- start page 10   --->







The third page had an illustration that, in a few short lines, described 
George Dantzig's simplex algorithm simply and precisely.
</p><p>

That was the overwhelming, crucial experience.
</p><p>

In the previous thirteen years, I had participated in so many murky 
discussions of what was here presented with crystal clarity that I knew that what I was
reading was of enormous significance to the future of computing.
</p><p>

So, when Dr. Kenneth Iverson came out to talk to us at San Jose, I was not 
only a convert, I had a fair idea of what he had to say. In the upshot, this 
meant that I was the only one who could ask him questions. Ken had some good, 
sharp people from Research and Advanced Systems Development in his audience but 
I'm pretty sure I was the only one who had been lucky enough to read what he 
had to say beforehand so that I had a fighting chance to follow him when he did 
what he usually does: hit you with one idea after another so fast that your mind
goes numb. 
</p><p>
I had been alerted to the fact that Ken might know what he was talking 
about by a fellow employee named Don Fisher who was working in the same group that I
was. After Ken's talk, he came to visit Don and I got a chance to meet him.
It's hard to believe that that first meeting took place more than twenty 
years ago. But it's true. I've been an APL bigot for a long, long time--since 
before there was an APL, in fact.
</p><p>

Stanford, 1962-1967?
</p><p>

Shortly after I went to work for IBM, Dan Teichroew, a friend of mine from 
the Bureau of Standards days, asked if I would be interested in spending part 
of my time at Stanford, participating in a study of "Quantititative Management
Techniques" being conducted at the Graduate School of Business. Dan was a
Professor of Management at the GSB and he wanted my permission to approach 
IBM about the idea. Naturally I was delighted by his proposal and even more
delighted when my management gave its approval.
</p><p>

The next several years were among the most satisfying and productive I've 
ever spent. And, in my opinion, not only did I benefit from them but so did
everybody else who was involved: Stanford, IBM, the students who 
participated in the research program and attended my Business Information Systems classes
and, more to the point of this talk, APL itself, whose first implementation 
was a FORTRAN-based batch interpreter that was developed on the IBM 7090 in 
Pine Hall at Stanford.
</p><p>

In the <b>Formalizing Business Problems </b>talk that I had given in 1955, I 
asserted that the problems we were facing required a partnership among computer 
users, computer manufacturers and academic institutions if we were ever to develop 
the body of knowledge we needed to manage computers properly. For a while there 
at Stanford we had two-thirds of what I'd recommended and, as you will see, I
concentrated a good deal of effort on seeing that the third was represented 
as well.
</p><p>

When I started at Stanford as an Industrial Research Fellow, the present 
School of Business building did not exist. I occupied an office in Polya Hall, near
the temporary buildings used to house Business School faculty and staff. 
IBM, at that time, shared the 7090 with Stanford and thus had the use of a few
offices in Polya Hall, the building which housed the university's Computer
Science faculty and staff. I was assigned one of those offices.
</p><p>

This was ideal. I not only participated in the activities of the Graduate
Business School: I was also part of the Computer Science complex at the
university. Both of these associations had APL implications and I'd like to
tell you about them.
</p><p>

My activities at the School of Business can be described in n four parts
</p><ol>
<li>		Work with graduate students on the "Quantitative Techniques" project.

</li><li>	Guest lecturing in Business Information Systems courses taught by Dan
Teichroew and John Lubin.







<!-- start page 11   --->







</li><li>	Development of my own Business Information Systems course after Teichroew
and Lubin left the university.
</li><li>	Teaching Operations Research courses as a Lecturer in Operations and
Systems Analysis.
</li></ol>
<p> 
APL and Quantitative Techniques. My purpose in describing my preAPL history 
to you was to let you know how my ideas about what management needed were 
formed. If you were paying attention, it should come as no surprise to you that, as
soon as I was given an opportunity to do something about it, I started to
investigate the implications for management of an efficient notation for
describing, analyzing and designing digital procedures.
</p><p> 
I investigated two techniques: decision tables and APL. The latter is the 
one relevant to this talk. I've long regretted that I never wrote up what I did;
let me remedy the deficiency now.
</p><p> 
<b>A Programming_Language </b> was published just in time for me to use in my
researches at Stanford. It was a godsend. I used it to try to answer the
question:
</p><blockquote>
<b>Is it possible to write programming specifications in such a way that
ambiguities, misunderstandings and outright mistakes in programming are
minimized?</b>

</blockquote>

The	answer I got surprised even me.
<p> 
Here's what I did. For a set of problems, of increasing difficulty, I would
write a solution procedure, using the notation of <b>A Programming Language </b>
I would then ask the graduate student assigned to me to:
</p><ul>
<li>
program the procedure in any programming language he chose,
</li><li>
execute the procedure for a representative set of data values
</li><li>

give me his program and answers so that I could compare them with the
specifications I had written and the answers I had previously calculated.
</li></ul>
The	result, which I still find surprising and impressive, was:
</dd><dd>In every case, what was programmed was exactly what I specified.
<p>
I'll comment in a moment on how rare this is under any circumstances. But 
these particular circumstances were so extreme that they merit some discussion.
</p><p>
<b>A Programming Language </b>was and is crammed full of ideas. I studied it
assiduously, and enjoyed it, but it was not easy reading, at least not for
someone of my mental capacity. I was lucky that my Stanford assignment 
provided me some time to spend on it so that I could both use it and explain it when 
my students asked questions.
</p><p>
But think of them. The life of a graduate student is a busy one. They had 
less time than I had to study strange notations. How could they make sense of the
chicken scratches I said were their programming specifications?
</p><p>
Somehow, they did.
</p><p>
I gave them completely abstract procedure descriptions, even avoiding 
standard words where they might have provided clues to the nature of the procedure, 
and they programmed exactly what I specified even though they had no prior
experience with the notation and never became expert at using it.
</p><p>
Thinking back on it, I understand why an intimate familiarity with this 
strange notation would have been desirable but was not essential. The only part of 
the notation they needed to understand was the part I used. I told them to look 
up the meaning of the symbols in Ken's book but I also told them that I'd 
explain and illustrate the meanings myself if they wanted help. But I wouldn't do
anything but explain the symbols. They had to translate the symbolic
description into a program.








<!-- start page 12   --->







</p><p>
They did, with no arguments and no discussions about what the procedure was
supposed to do. The procedure was described completely abstractly. They had 
no idea what external significance it had. They were not led astray by ideas of
their own about it. They figured out what I wanted done and then did it.

Contrast this with the usual way in which a business procedure gets 
programmed. Somebody, usually called a system�s analyst, casts about, comes up with some
general ideas, puts them down as programming specifications and presents 
them to somebody else, usually called a programmer, who
</p><ul>
<li> asks the analyst lots of questions, 
</li><li> programs what he thinks the analyst wants, 

</li><li> is told that what he has done is s completely wrong, 
</li><li>quarrels with the analyst about what he said and what it implied, 
</li><li>forces a reworking of the specifications,
</li><li>tries another program,
</li><li>is wrong again, forcing another rework of the specifications,
</li><li>and so on until finally, after a long period of false starts and reruns,
</li><li>some program is accepted as an implementation of some set of
	specifications, both programmer and analyst now being so sick of the
	entire procedure that they no longer care whether what is finally
	programmed is what was originally wanted.
</li></ul>
Is what I'm describing familiar to you? Does it, perchance, occur in your
organization?

<p>
To me, specifications cannot properly be called specifications until they 
are as abstract as blueprints or mathematical formulas. Specifications using the
cords of everyday speech are always subject to misinterpretation. Most of 
the costs, delays and other inefficiencies that attend the development of data-
processing procedures are due to these misinterpretations.
The abstract APL program specifications I tested at Stanford strenghtened my
belief in the opinion I've just expressed.
</p><p>

<b>Content</b>. What did I ask the students to program? Let me select four 
examples.
</p><p>

<b>Rings-O-Seven</b>. The first example was from A Programming Language page 63,
Exercise 1.5. It was a solution of a "rings-o-seven" puzzle, in which rings 
on a bar were to be removed according to certain rules. The bar was 
represented by a logical vector in which the presence of a ring was indicated by a 1 and 
the absence by a 0.
</p><p>

This was just a warmup experiment, but it had an informative result. My
programming specifications, naturally, described the solution procedure I 
had devised. It was wrong. But it was programned exactly the way I specified it.
</p><p>

Think of it. No arguments about who misunderstood whom. The systems analyst
was wrong; the programmer was right.
</p><p>

Wouldn't you like to be able to make that determination without bickering,
recriminations or tears?
</p><p>

(After my blushes subsided, I wrote a correct procedure. It was programmed
correctly and gave the right answers. I tell you this because I'm vain and
don't want you to remember me for the only mistake I ever made in my whole
life.)
</p><p>

<b>Internal Rates of Return on Investment</b>. Financial theory at that time was
troubled by the fact that the then current procedures for calculating








<!-- start page 13   --->






rates of return on an investment gave ambiguous answers in some cases. The
difficulty arose when the cash flows that characterized the investment were 
a mixture of positive and negative amounts. This led to an equation with 
multiple roots, so that, in many cases, two equally ridiculous rates of return were
calculated.

</p><p>

Dan Teichroew felt that the difficulty lay in the assumption that the same
interest rate should be applied to the negative cash flows as to the 
positive. What he suggested was that there would be a unique, meaningful solution if 
we assumed that the rate to be applied to the negative flows, which were, after
all, borrowings, should be a putative "cost of money" which would not, in
general, be the same as the return on the investment.
</p><p>

Given this assumption, I provided a proof that an "internal rate of return" 
on the investment would be uniquely determined when a "cyst of money" was 
assumed.
</p><p>
I then specified, in "Iverson language", a procedure that determined a rate 
of
return for a fixed cost of money and a specified series of cash flows. The
actual calculation was programmed by J. P. Seagle, a graduate student. I no
longer remember what programming language Pete used, possibly a home-grown
(Stanford) assembler for the 1401. The results were reported in a couple of
papers by authors the very ponderosity of whose names (Teichroew, Robichek,
Montalbano) testified to the validity, excellence and importance of the
research they described.
</p><p>
Critical-path calculations. Critical-path and PERT calculations were all the
rage at that time, with many papers being devoted to efficient schemes for
"topological sorting" and for detecting inconsistencies in precedence
relationships.
</p><p>
I became interested in the problem and decided that the need for topological
sorting could be eliminated and that consistency checking did not require a
separate, special program. I used APL (Iverson language) to describe a 
solution procedure in which topological sorting was not required and 
consistency-checking was a fallout from the basic critical-path calculation.
</p><p>
This time, in addition to having Pete Seagle program the calculation, I
programmed it myself, in MAP, the IBM 7090 assembly language, and FORTRAN 
(for input-output subroutines). My program exploited almost every bit in the 
36-bit 7090 word. This permitted me to store enormous networks internally, so that 
I was able to achieve calculation speeds far in excess of any other method 
then available.
</p><p>
I was not then, and have not since become, an expert assembly-language
programmer. I had risen to too august an eminence at Kaiser Steel to do much
programming, though I snuck some in now and then, when no one was looking. 
My critical-path algorithm was the first programming I had ever done for the 
7090 which, like MAP and FORTRAN, was completely new to me.
</p><p>

With the precise specifications of the APL procedure as my guide, 
programming assembly language for a machine with which I had little experience went very
quickly and with no errors other than mistypings. The program I developed 
was a useful one that I later used in classes in the Business School and in the
International Center for the Advancement of Management Education at 
Stanford. I described it in a paper called High-Sped Calculation of the Critical Paths
of Large Networks that appeared both as a Palo Alto Scientific Center report
and as an IBM Systems Journal article. The algorithm presented in the paper
used the old notation (the one in the book) since the new (the one for the
typewriter) had not yet been designed.
</p><p>
So APL turned out to be a particularly useful way to specify a program for 
an
inexperienced programmer--me.
</p><p>
<b>Linear Programming</b>. The last program specification I want to discuss was 
done by a student, Don Foster, who had even less time than the general run of
student I'd been working with. I believe it was his last term at the School 
of Business. This is always a hectic time but in Don's case he had the added
distraction of planning for a European trip. Even without my assignment he 
was leading a harried life.



</p><p>
I gave him a version of the simplex algorithm (basically the one that had
originally sold me on APL) from which I'd removed all clues like, 
"unbounded", "infeasible", etc.
</p><p>
The solution was programmed in jig time, since Don was champing at the bit
anyway. The programming language was FORTRAN. The program ran the first time
it was tried. It produced the right answers.
</p><p>
What was interesting was Don's reaction when I told him what he'd 
programmed. Like all good business school students of that era, he'd received 
instruction in linear programming. But he hadn't been told how easy it was. The 
arm-waving and chalk dust had concealed the basic Simplicity from him as they had from 
me.
</p><p>
<b>Business Information Systems</b>

</p><p>
As a guest lecturer in Business School courses, I advanced the argument that
I've been advancing throughout this talk, that we need an efficient notation
for describing procedures. I illustrated some of what could be done with APL
and decision tables.
</p><p>
In my Business Information Systems course, I did the same, but I also
encouraged activities that would permit students to find out for themselves
whether or not I had valid reasons for what I was recommending. One of the
course requirements was completion of an approved project. As an example of 
the kind of project I had in mind, I would suggest that they go to a local 
company, get a copy of an important report used by several departments, and visit 
each of the departments, asking whoever got the report what he thought the report
told him, how much he knew about how the figures in the report were 
determined, what actions he based on the report, and how he decided on his actions.
</p><p>
Few of the students had had detailed business experience at that point in 
their careers. Business to them was defined by the other business school courses
they'd taken: finance, marketing, micro- and macro-economics, accounting,
theory of the firm, organizational behavior, and so on. These were good 
courses but none of them were concerned with or had the time to devote to 
determining what was happening at the working or first-line management level of an
organization.
</p><p>
The intent of my course was to forewarn my students that business was, in
practice, a good deal more disorganized than they were likely to realize 
from most academic discussions.
</p><p>
I had some skeptics in my classes, people who felt I was overstating my 
case. None of the skeptics who attempted the kind of project I suggested remained
skeptics. Some, shattered by their experiences, felt even more strongly 
than I that no one in management knew what was going on.
</p><p>
Several students caught the APL bug. They went out on missionary activities 
of various kinds after graduation. The effects of some of these are still being
felt--in, for example, organizations like IBM and American Airlines, to name
the two I know most about.
</p><p>
<b>Stanford's Computer Science Department.</b>
</p><p>
Although I was housed with members of the Computer Science Department, I had
no official connection with it. All of my interaction with faculty, staff or
students was informal.

</p><p>
From the standpoint of APL as it now is, however, this interaction was the
important one. This was not because of anything I did. It was primarily 
because I was a reminder of the existence of "Iverson language" and a kind of 
catalyst who served to bring together the right people at the right time.
</p><p>
The Computing Science Department of those days was an ALGOL stronghold. It 
had a Burroughs B5000, later upgraded to a B5500, an IBM 7090, and a









<!-- start page 15   --->







PDP-1, probably the first computer I ever saw with a cathode-ray tube 
terminal. I don't know whether "Star Wars" (the game) was developed at Stanford. I do
know that a lot of "Star Wars" was played there.
</p><p>
Stanford had developed its own version of ALGOL, called SUBALGOL, for the
Burroughs computer that had preceded the 85000. I believe the number was 
B220, but my memory might be playing me tricks. At Kaiser Steel, our first 
computer had been a B205, predecessor of the B220, if that's what it was.
</p><p>
The significance of this information from the APL standpoint is that two,
possibly three, of the people who played key roles in developing the very 
first APL system had been instrumental in producing SUBALGOL for Stanford: Larry
Breed, Roger Moore, and (the one I'm not sure about) Phil Abrams.

</p><p>
I met Larry as a result of a talk I'd given as one of a series on 
"Programming Languages" conducted by the Computer Science Department. He expressed an
interest in what I'd had to say about what I was doing in the School of
Business with the notation described in <u>A Programming Language</u>. He and Phil
Abrams took action on this interest in a very real, very Productive way when
the IBM Systems Journal article, <u?a formal="" description="" of="" system="" 360<="" u="">
appeared. What they did, and its aftermath, is described in Appendix A, an annotated
verse history of APL's early days.
</u?a></p><p>
Larry and Phil not only developed the batch APL interpreter I mention in the
verse, they did so many other things that I wish they and others involved in
APL's origins would get them down on paper. For example, one of them should
tell the story of Elsie (for Low Cost), an APL mini before there were minis.
</p><p>
But, in essence, all I did was happen to be around, saying the right things 
to the right people. Things took off when the right people got together.
</p><p>
Incidentally, one of the people involved in the Programming Languages 
seminar to which I referred above was Niklaus Wirth. Unfortunately, Klaus didn't get
the proper message from my talk. He went his own way and developed PASCAL.
</p><p>
<b>APL at IBM</b>
</p><p>
The history of APL at IBM has been a curious one. In the early days, those 
of us who believed in APL were regarded as being a little (perhaps more than a
little) strange. Since much of the strangeness was concentrated in IBM
Research, this was tolerated. Practical people (the kind of people who make
sales and meet payrolls) expect research people to be strange and are 
usually disappointed when they're not. So the strange people in Research were 
written off as overhead and left to amuse themselves with their incomprehensible,
impractical symbols.

</p><p>
What that particular Research group did, of course, was produce the most 
solid, dependable, useful time-sharing system anyone had ever seen.
</p><p>
I wish I could tell you what it felt like in those early days to have the 
use of a system that was up twenty-four hours a day, seven days a week. No one 
had ever known such a luxury. People who didn't bother to investigate never
believed us when we told them about it.
</p><p>
But some people did investigate what the researchers had developed and 
started to use it to do IBM's key bread-and-butter applications. This way of doing
business was so productive that it spread like wildfire. By the time the
practical people found out what had happened; APL was so important a part of
how IBM ran its business that it could not possibly be uprooted. The 
wild-eyed researchers had produced a moneymaker. No talks about product "strategies" 
and the evils of language proliferation prevailed against the simple fact that:
</p><ul>
<li>if  you worked for IBM and
</li><li>had access to an APL time-sharing service and





<!-- start page 16   --->



</li><li>had something you wanted to get done on a computer quickly and
economically
</li></ul>

then the best way to get it done was to use APL.
<p>
I wish someone who knows the details of how that came about would write 
about it. I can't do it. I was three thousand miles away when it took place.
APL (called VS APL for reasons beyond the ken of mortal man) is, of course, 
now an IBM program product. I don't know how much more practical than that you 
can get.
</p><p>
<b>Summary: Systematic Systems Analysis</b>
</p><p>
I could go on but I see you're falling asleep. Let me end by rephrasing 
what is either explicit or implicit in what I've already said.
</p><p>
In the preface to my book on decision tables, I say
</p><blockquote>
<b>
if you wish to use digital computers effectively, the first thing you
should do is digitize your procedure descriptions.
</b>
</blockquote>
<p>
As usual, this was something I realized I was doing after I'd finished 
writing and took time to think about what I'd written. The key idea of the book (the
potential of which, incidentally, no one has as yet successfully exploited) 
is that procedures can be digitized in the same sense that bubble-chamber and
spark-chamber pictures are digitized for analysis by a digital computer.

</p><p>
A decision table is a digitized procedure description; it describes a
correspondence between vectors of decision values and vectors of action 
values.
</p><p>
The particular form of the digitizing is not important. Decision tables may 
or may not be the most effective way to get the digitizing done. The important
thing is that it be done and done in a way that permits checking for
consistency, redundancy, completeness.
</p><p>
But how is such a digitized procedure to be developed, maintained, managed,
modeled, interpreted, translated, improved, extended,...?
</p><p>
To me, the answer is clearly APL. If we are ever to do "systems analysis"
systematically, we must
</p><ol>
<li>	Digitize our procedure descriptions
</li><li>	Manage our digitized descriptions with APL
</li></ol>
<b>We must divert our research to developing ideas rather than gadgets. Good 
ideas are at hand. Let's develop them.</b>

<p><a name="Epilogue">
<b>Epilogue - Twenty Years After</b>
</a></p><p><a name="Epilogue">

The latest IBM version of APL is an Installed User Program called APL2. For
those of us who had to bootleg our APL efforts within IBM for a long time, 
the announcement of APL2 is gratifying because it indicates the kind of 
management backing and recognition that we missed when We felt that APL was regarded 
as a limited tool for a small, specialized audience.
</a></p><p><a name="Epilogue">
Management put its support on record in another significant way. IBM 
recently instituted awards for outstanding technical achievements. The first of 
these to anyone at the Santa Teresa Laboratory was just awarded to Jim Brown, 
manager of the group that developed APL2.
</a></p><p><a name="Epilogue">
I haven't had a chance to use APL2 very much yet. I've been too busy 
writing a workspace manual for VS APL. So I  can't pretend to an extensive







<!-- start page 17   --->






knowledge of its details. But, recently, I used APL2 to do something that I
haven't been able to do for 20 years.

Page 19 of <u>A Programming Language</u> describes a bank ledger that has three
columns: the first column contains customer names, the second account 
numbers, the third balances. Unassigned account numbers had the entry "none" in the
corresponding row of the name column.
</a></p><p><a name="Epilogue">
Until APL2, no system available to me within IBM would allow me to form an
array of that kind. Nor could I write, in any straightforward fashion, the 
four programs, producing reports from that ledger, that appear as one-liners in 
the book with which, twenty years ago, I started my investigation of 
"Quantitative Techniques in Management" at the Stanford Graduate School of Business.
</a></p><p><a name="Epilogue">
With APL2, I was able to do precisely that. As a way of rounding out twenty
years of APL history, I thought I'd show you what I did. It's contained in
Appendix B.





<!-- start page 19   --->





</a><a name="A">
</a></p><hr><a name="A">
<h3>APPENDIX A. APL BLOSSOM TIME -A HISTORY IN VERSE</h3>
<p>

My contribution to APL 81 was the verse that I discuss below. The most I'd
expected, when I wrote it, was that Jim Brown might play it at some informal
gathering. I couldn't anticipate what actually happened. A group including 
Jim Brown, Larry Breed, John Bunda, Diana Dloughy, A1 O'Hara and Rob Skinner
rehearsed their guitars and voices until they were of a truly harmonious
sweetness and sang "APL Blossom Time" at the APL 81 banquet as part of the
evening's entertainment. I. P. Sharp's Peter Wooster prepared overhead
transparencies that made it possible for the audience to sing along. And I'm
sure other people whose names I was never told contributed to what was, for 
me, an extremely heartwarming experience: the sound of people singing, laughing 
and giving every evidence of enjoying the words I'd written.
</p><p>
Despite its frivolity, <u>APL Blossom Time</u> is authentic history. I thought it
might be useful to get the details on record by annotating each section of 
the verse.

</p><center>
<b>APL BLOSSOM TIME</b>
</center>

A nostalgic reminiscence of the early days of APL, remembered to the tune of
The Battle of New Orleans.
<div>
<pre>Back in the old days, in 1962, 
A feller named Ken Iverson decided what to do. 
He gathered all the papers he'd been writing fer a spell 
And he put them in a little book and called it APL.

Well... 
    He got him a jot and he got him a ravel 
    And he revved his compression up as high as she could go 
    And he did some reduction and he did some expansion 
    And he sheltered all his numbers with a ceiling and a flo'.
</pre>
</div>
<p>
If you've read the earlier part of this book, this verse doesn't need
annotating. If you haven't, go back and read it.
</p><p>

<div>
<pre>
Now Sussenguth and Falkoff, they thought it would be fine 
To use the new notation to describe the product line. 
They got with Dr. Iverson and went behind the scenes 
And wrote a clear description of a batch of new machines.
Well...
	They wrote down dots and they wrote down squiggles
	And they wrote down symbols that they didn't even know
	And they wrote down questions when they didn't know the answer
	And they made the Systems Journal in nineteen sixty-fo'
</pre>
</div>
</p><p>

Though the scan required that I place Sussenguth's name first, this is 
perhaps misleading. Ed Sussenguth has done a lot of good work for IBM but, except 
for his participation in this paper, I don't know of any other in n which he 
used APL.
</p><p>
Adin Falkoff, on the other hand, was one of those crazy-symbol 
Iverson-language authors whose papers I started requesting from the ASDD Library when I first
joined IBM. I remember one paper in particular. It struck me because it 
seemed to be written by someone who hated jargon as much as I did. One of the data-
processing fads current at that time was





<!-- start page 20   --->




the "associative memory". Adin, like the rest of us, had to use the term
because everybody else was using it. But he rather wistfully (can you 
imagine Adin wistful?) pointed out that a more descriptive term would be "content-
addressable memory".
</p><p>
And, of course, as you all know (or should know, if you don't), Adin 
Falkoff, in both technical and administrative capacities, has been in the forefront 
of APL developments ever since the days of those early, incomprehensible 
reports out of IBM Research.
</p><p>
The paper referred to in the verse is A Formal E. escription of System/360,
by Falkoff, A. D., Iverson, K. E., Sussenguth,	H. IBM Systems Journal,
Vol. 4, No. 4, October, 1964.
</p><p>
About "questions where they didn't know the answers": the paper was indeed, 
to the best of my recollection, the first to use the question mark as an APL
function.
</p><p>
I gave my copy of that issue of the Systems Journal to Larry Breed. (I had
already ordered several more. John Lawrence, editor of the Systems Journal 
at the time, had the APL functions in the article printed separately for more
effective study. I ordered several copies of those, as well.) Larry and Phil
Abrams conducted a seminar on the System/360 paper that extended over 
several weeks. They also produced a list of "cliches", to assist in understanding
regularly recurring patterns, and a list of errata, to remind the authors 
(or the typesetters) that they didn't know it all.
</p><p>
The sessions conducted by Larry and Phil were well attended. When Ken 
Iverson came out to give a talk at Stanford, he drew the biggest crowd the Computer
Science auditorium had seen up to that time. I told my Business Information
Systems class to attend since they would hear something better than 
anything I had to say; this also gave me a chance to attend myself.
</p><p>
<div>
<pre>
Now writing dots and squiggles is a mighty pleasant task 
But it doesn't answer questions that a lot of people ask. 
Ken needed an interpreter for folks who couldn't read 
So he hiked to Californ-i-a to talk to Larry Breed.

   Oh, he got Larry Breed and he got Phil Abrams 
   And they started coding Fortran just as fast as they could go 
   And they punched up cards and ran them through the reader 
   In Stanford, Palo Alto, on the seventy ninety oh.

</pre></div>
</p><p>
Ken Iverson and Larry Breed first met in my office at Polya Hall. Since this
may be my only claim to fame, I'm glad to put this historical fact on the
record.
</p><p>
Larry was about to graduate. Ken had a job to offer him. We now have APL.
</p><p>
I remember a phone call of Ken's, shortly after Larry had joined him and 
Adin at IBM Research in Yorktown, in which he said something like: "This young 
man thinks he can write a translator in a couple of months." He sounded as if he
were wondering whether he'd made a bad bargain. I assured him that if Larry
said he could do something in a couple of months he would probably do it in 
a couple of weeks. He and Roger Moore were legends in their own time during
Stanford's SUBALGOL days.

</p><p>
Stanford has left a mark on APL second only to that of left-handed 
Canadians. For a while, there was a theory that all of APL was being dominated by 
left-handed Canadians. I have been told that when Mike Jenkins, at lunch in the
Yorktown cafeteria, was observed to be left-handed, someone facetiously 
asked him if he happened to be Canadian. He happened.




<!-- start page 21   --->



</p></a><p><a name="A">
I tried to start a similar factoid<sup></sup></a><a href="#SUP">5</a> about right-handed 
Brooklynites,
hoping to get included along with Falkoff and McDonnell. I forget what 
happened to that. I think one of them is lefthanded. I know I'm not.

</p><p>
<div>
<pre>
Well a Fortran batch interpreter's a mighty awesome thing 
But while it hums a pretty tune it doesn't really sing. 
The thing that we all had to have to make our lives sublime 
Was an interactive program that would let us share the time.

Oh, they got Roger Moore and they got Dick Lathwell, 
And they got Gene McDonnell with his carets and his sticks, 
And you should've heard the uproar in the Hudson River valley 
When they saved the first CLEANSPACE in 1966.
</pre></div>
</p><p>
 

APL bigots seem to be characterized by literacy and a feeling for history. 
The first time-sharing APL system was implemented (as IVSYS) on an IBM 7090 at
Mohansic. In those days, there was no )CLEAR command. To get a CLEAR 
workspace, you had to load one. The one that came with the system was called 
CLEANSPACE. Although it was no longer needed when )CLEAR was introduced, CLEANSPACE, 
along with the time and date it was originally stored, has been preserved in 
Library 1 of a continuous sequence of systems ever since: the Yorktown Model 50, the
Philadelphia Scientific Center Model 75, the Palo Alto model 158, the Santa
Teresa model 168 and, as I discovered for the first time just a few hours
before I wrote this, the Santa Teresa Model 3033. At one point, after a
disaster had caused the loss of CLEANSPACE, it was carefully restored with 
the correct date and time. The objective, of course, is to preserve a record of 
the moment when APL first became a time-sharing computer language.
</p><p>
Preserving CLEANSPACE in APL2 presented a problem, since workspace names are
limited to eight characters in CMS, the first "environment" in which APL2 
has been offered. However, as you can see from the following exhibit, which is a
copy of what appeared on the screen in response to a )LOAD 1 CLEANSPACE 
command that I executed on our APL2 system (which operates under CMS) the problem 
has been solved, or, better, circumvented.
</p><p>
<p>
<img src="https://ed-thelen.org/comp-hist/APL-hist-pg21.gif">
</p>

</p><p>
Note that not only is the time given, the time zone of the area in which the
storing was done is also given, indicating that the original workspace was
stored when United States Eastern Standard Time was in effect. Note also 
that the original workspace size was 32K and that the time zone in which 
CLEANSPACE was loaded to produce this example was Santa Teresa Daylight Savings Time.
</p><p>
What hard workers AP L. bigots are' I've checked my handy perpetual calendar
and, as far as I can tell, November 27, 1966 was the Sunday of what




<!-- start page 22   --->




must have been a four-day Thanksgiving weekend. What were those loonies 
doing working such crazy hours during the holiday season?
</p><p>
The !'carets and sticks" reference is to a paper by Gene McDonnell on the
logical and relational functions--the ones whose symbols can be constructed 
out of "carets and sticks".
</p><p>
<div>
<pre>Well, when A1 Rose saw this he took a little ride 
In a big station wagon with a type ball by his side. 
He did a lot of teaching and he had a lot of fun 
With an old, bent, beat-up 2741.

Oh, it typed out stars and it typed out circles 
And it twisted and it wiggled just like a living thing. 
Al fed it a tape when he couldn't get a phone line 
And it purred like a tiger with its trainer in the ring.

</pre>
</div>
</p><p>
A1 Rose was, and I assume still is, one of the most spectacular APL
demonstrators there ever has been. The verse refers to a vacation he took in
which he was accompanied not only by his family but by what was laughingly
called a portable 2741. This was a 2741 that came in two parts which, when
ready to be "ported", looked like two big, black pieces of luggage. 
Wherever Al went, he'd find some likely APL prospects, park the station wagon near an
electrical outlet and a phone, lower the tailgate and start hammering on the
keys.
</p><p>
In those days, getting connected to a working APL system was a chancy 
thing. As a safeguard, A1 recorded, on tape, what went across the acoustic coupler 
during a sample session. When he had problems getting to a real APL system, he`d 
play the tape into the acoustic coupler and produce a simulated computer session
that was an exact copy of the real thing.
</p><p>
I remember that double-black-box 2741 very well myself. I, too, did quite a 
bit of APL demonstrating in those days. At the University of California at 
Davis, the demonstration was given on the second floor and there was no elevator. I
had to haul those two big boxes up a long flight of stairs. I'm glad I 
didn't find out until later how heavy they were. When I sent them Air Express to an
IBM System Engineer in Seattle, I learned for the first time that they 
weighed 120 pounds. Well, I'm not too bright but I'm pretty strong.
</p><p>
<div>
<pre>
Now, there's much more to the story, but I just don't have the time 
(And I doubt you have the patience) for an even longer rhyme. 
So I'm ending this first chapter of the tale I hope to tell 
Of how Iverson's notation blossomed into APL.
So..
    Keep writing nands when you're not writing neithers, 
And point with an arrow to the place you want to be, 
But don't forget to bless those early APL sources 
Who preserved the little seedling that became an APL tree.

Dedicated to the pioneers of APL with respect and
affection by
J. C. L. Guest
</pre>
</div>

</p><p>



J. C. L. Guest is the pseudonym I used for sore light verse I submitted to
Datamation several years back. There were four pieces in all. <u>The Far-flung
Data Base</u>, <u>SYSABEND Dump</u>, <u>Virtual Memory</u> and <u>Decision Making</u>.
</p><p>
If you were offended by the unkind things I said about modern management in
this talk, don't read Decision Making. You won't like it.




<!-- start page 23   --->

<a name="B">


</a></p><hr><a name="B">
<h2>APPENDIX B - TWENTY YEARS AFTER </h2>
<p>
The following four figures show how I applied APL2 to Program 1.9 (Example 
1.1) of <b>A Programming Language</b>, page 19.
</p><p>
The first figure shows the sample bank ledger I used and the calculations I
performed to illustrate the ledger's shape and various facts about its
composition. Note that the name entry for an unassigned account number is a
single blank rather than the "none" used in the original example.
</p><p>
The second figure shows two versions of the four reports (P, Q, R, S) 
required in the example. In the first, the output is unformatted. In the second,
"picture format" is used to format the numeric part of the report.
</p><p>

The	four required reports are:
</p><ol>
<li> 	P - name, account number and balance for each account with a balance less
than two dollars. (Although the original example did not require this, the
illustrated calculations do not include unassigned account numbers in the
report.)

</li><li> 	Q - name, account number and balance for each account with a negative
balance exceeding one hundred dollars.

</li><li> 	R - name and account number of each account with a balance exceeding one
thousand dollars.
</li><li> 	S - all unassigned account numbers
</li></ol>
<p>
The third and fourth figures show the programs for the unformatted and
formatted reports respectively. They could have been written as the four 
one-liners of the original example, except that report P, the one producing a 
list of accounts with balances of less than two dollars would have included
unassigned account numbers. To avoid this, the unassigned account number
report, S, was produced first and an array T, consisting of all assigned
accounts, was used to create the subsequent reports.

</p><p>
The other lines in the report merely introduce spaces to separate the
successive reports.


<!-- start page 24   --->



</p><p>
<p>
<img src="https://ed-thelen.org/comp-hist/APL-hist-pg24.gif">
</p>
</p><p>
<p>
<img src="https://ed-thelen.org/comp-hist/APL-hist-pg25.gif">
</p>
</p><p>
<p>
<img src="https://ed-thelen.org/comp-hist/APL-hist-pg26.gif">

</p>
</p><p>
<p>
<img src="https://ed-thelen.org/comp-hist/APL-hist-pg27.gif">
</p>
</p></a><p><a name="B">

------------------------------------
</a><a name="SUP">
</a></p><ol><a name="SUP">

<li><b>First draft of a report on the EDVAC</b>, J. von Neumann, June 1945,
(report), Moore School of Electrical Engineering, Univerity of
Pennsylvania, Philadelphia, Pa.

</li><li>A Programming Language, Kenneth Iverson, John Wiley, 1962

</li><li>In making this comment here, and not earlier when I was describing the
work I did for the Air Force, I do not mean to make an invidious
comparison of the services. The work I did for the Air Force didn't
require me to know whether either the data we used or the answers we
calculated corresponded to reality; all I had to do was to supply
plugboards or programs. At the Naval Research Laboratory, on the other
hand, it was my responsibility to get good answers from good data. That's
when I found out there wasn't any good data.
<p>
To even things out, let me observe that the Air Force doesn't know what's
going on either. As for the Armor, well, I served in the Army. I can tell
you about the Army.

</p></li><li> Decision Tables, Michael Montalbano, Science Research Associates, 1974
</li></a></ol><a name="SUP">
</a></dd></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The analog computer for the Nike missile system (2001) (106 pts)]]></title>
            <link>https://www.ed-thelen.org/computer.html</link>
            <guid>38504787</guid>
            <pubDate>Sun, 03 Dec 2023 04:14:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ed-thelen.org/computer.html">https://www.ed-thelen.org/computer.html</a>, See on <a href="https://news.ycombinator.com/item?id=38504787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>Appendix 3: <a href="#ServoPots">Precision Servo-driven Potentiometers</a>

<center>

<img src="https://www.ed-thelen.org/functnov.gif" height="478" width="574">
<br>From FM 44-1-2 ADA Reference Handbook, 15 June 1984,
see page 21 <a href="https://www.ed-thelen.org/related.html#rings">"Rings of Supersonic Steel"</a>

</center>
<p>
<table>
<tbody><tr><td> <a href="https://www.ed-thelen.org/ifc_comp.jpg"><img src="https://www.ed-thelen.org/ifc_comp_t.gif"></a>
</td><td> <b>Nike computer </b>- 
	<span size="-1">Installed in class room, not BC van.
	 From <a href="mailto:rolfdieter.goerigk@nwn.de">Rolf Goerigk</a></span>

	<ul>
	<li>Left rack has the power supplies - outputs about 7 different voltages.
		Top panel is switches, meters, voltage warning lights. (Note: in the
		van installation, this rack is on the right side of the computer.)
	</li><li>Middle two racks - operational amplifies, brown square boxes are
		zero set units, back part of both racks have many relays
	</li><li>Right rack has the servo-driven potentiomenters. Top panel has
		tracking radar offsets, 
		test switches (sets test inputs, verify outputs)
	</li></ul>
</td></tr><tr>

<td><a href="https://www.ed-thelen.org/ZeroSetNewOverview-.jpg"><img src="https://www.ed-thelen.org/ZeroSetNewOverview-t.jpg"></a>
</td><td>
So - the <b><u>Nike Analog Computer System</u></b>
<br>  - this is one of four cabinets or racks -

 <br>includes   Zero Set Switches (the brown boxes)
 <br>each can zero set 12 operational amplifiers.



</td></tr><tr>
<td> <a href="https://www.ed-thelen.org/NikeComputerBackSwingOutDoor-.jpg"><img src="https://www.ed-thelen.org/NikeComputerBackSwingOutDoor-t.jpg"></a>
</td><td> Back of a swing out door/rack. Lots of components - Analog computers
	of this complexity, 78 Operational Amplifiers, were expensive and heavy.  Look at all
	that hand wiring and soldering.  Days of work - Your cell phone likely costs less
	than many of the components you are looking at -
</td></tr><tr>
<td> <a href="https://www.ed-thelen.org/NikeComputerRelays-.jpg"><img src="https://www.ed-thelen.org/NikeComputerRelays-t.jpg"></a>
</td><td>The wall behind a swing out door. Note the many relays to set:
    <br> - operational  modes, pre-launch, launch, 7 g dive, 1/2 g cruise
    <br> -  and many test conditions, known inputs to get known outputs




</td></tr></tbody></table>
 
</p><hr>

<p><span size="+2"><a name="History">

<u><b>0) History of the Nike Analog Computer</b></u></a></span>
</p><blockquote>
Now that digital computing logic elements (transistors) are
<dd>-    how many thousands per penny?

</dd><dd>-    and floating point pretty much eliminates scaling,
<br>Digital computing has pretty much taken over from Analog computers for process control.
<p>
Back in the goode olde dayze, 
 </p></dd><dd>-   beginning before the 1930s and 
       Vannavar Bush's differential analyzer at MIT
</dd><dd></dd><dd> <a href="http://web.mit.edu/klund/www/analyzer/">

		http://web.mit.edu/klund/www/analyzer/</a>

</dd><dd>-    until the 1960s

<br>
Analog Computing was the practical process control for the masses.
</dd><dd>-    Not many could afford the ENIAC, 
</dd><dd>-    or the other massive vacuum tube collections.

</dd><dd>- And a few hundred tubes are a lot more reliable than thousands. 
<p>
In the late 1930s, mechanical computing elements
</p></dd><dd>-       with rather awkward  torque amplifiers
</dd><dd></dd><dd>            to handle gain, friction and losses
</dd><dd>-    began to give way to electrical computing elements

</dd><dd></dd><dd>        with vacuum tube amplifiers to
            handle gain,  resistance and losses

<p>
So - at the beginning of WWII, the needs for
    solving dynamic fire-control problems 
 </p></dd><dd>     began to be solved by electronic analog computers.



</dd><dd></dd><dd> <a href="http://www.ed-thelen.org/pre_nike.html#gun_dir">
	http://www.ed-thelen.org/pre_nike.html#gun_dir</a>

</dd><dd></dd><dd> <a href="http://en.wikipedia.org/wiki/Operational_amplifier#1941:_First_.28vacuum_tube.29_op-amp">
	http://en.wikipedia.org/wiki/Operational_amplifier#1941:_First_.28vacuum_tube.29_op-amp</a>
<br>[Note: most artillery people did not have time to reference 
     the printed fire control tables 

</dd><dd>generated by human computers or  by ENIAC.

<br>   The tables were needed to generate 
</dd><dd>  - cam configurations
</dd><dd>  - potentiometer tapers



<br>    for the analog fire control computers. ]
<p>
A few generations later (1950), with improvements
 </p></dd><dd>    (including automatic rather than manual analog amplifier zero setting :-))
<br> the  M-33 analog fire control computer for
      anti aircraft guns was in the field
 </dd><dd>        and working well - 


<p>
So, by the time the Nike missile system was needed, (1950)
 </p></dd><dd>    the computing and display elements of the M-33
      were used for the related missile guidance problem.
<p>

Actually, there was practically no choice,
    digital computing technology
    would not catch up/supercede analog
        for many control functions
     for about 20 another years.

In 1974, when most of the Nike systems in the US
   were being shut down, a digital computer replacement
   (a militarized DEC PDP-11) was replacing
   the Nike analog computer in the rest of the world.

</p></dd></blockquote>

<p><span size="+2"><a name="Mission">
<u><b>1) Mission of the Nike Computer</b></u></a></span>

</p><blockquote>
<p>
The Nike Computer had the following main missions:
</p><ul>

<li>a) Provide Predicted Intercept Point and Predicted Flight Time 
      to Plotting Board - for human viewing

</li><li>b) Provide Predicted Intercept azimuth angle to missile during pre-launch
</li><li>c) Provide Missile Steering commands after launch
</li><li>d) Provide Missile Burst command at correct time after launch
</li><li>e) (The <a href="#About">Nike Hercules Computer</a> had an added Surface-to-Surface function.)
</li><li>f) And of course be easy to test,  highly reliable, accurate, testable and maintainable
</li><li>g) - and be compact enough to  fit into a van with other equipment and functions.
</li></ul>

<p>
There were three main modes:
</p><ol>
<li> Test
</li><li> Pre-Launch - Compute Predicted_Intercept_Point and Time_of_Flight to plotting boards
</li><li> Post-Launch - add Missile_Steering and Burst commands
</li></ol>

<p>
a) The <b>Predicted Intercept Point</b> is the point where the missile
   would intercept the aircraft if:
   </p><ul>
   <li>the aircraft continued in a straight path and at the same speed
   </li><li>the missile was fired right now
   </li></ul>

<dd>

   and the <n>Predicted Flight Time is the time from now for that meeting.<br>

Before launch, this information is useful for the human decision making about 
when to fire a missile.<br>
After launch, this information is continuously updated based upon actual aircraft
flight and missile position and flight characteristics.
<p>
b) The <b>Predicted Intercept Azimuth</b> is the direction from the launcher to
   the current Predicted Intercept Point.  This direction (azimuth) was sent
   to the gyro in the selected missile before launch, and was used to provide the missile
   a sense of "down".  This missile gyro and the missile control system 
   kept the belly of the missile "down" and provided the computer and missile
   a common sense of "down" and left/right.


</p><p>
c) During missile flight, the computer sends <b>Steering Commands</b> to the missile
    (via the missile tracking radar) to guide the missile to the continuously 
     updated Predicted Intercept Point.<br>

</p><p>

d) The <b>Missile Burst Command</b> is generated by the computer since:
     </p><ul>

     <li>A human is much to slow and variable to send the command.  Since the missile 
         is traveling at about 3000 feet per second, a 0.1 second mistake means a
         missile explosion 300 feet from the intended location (a clear miss).
     </li><li>Nike missiles did not "see" the intended target, and could not generate
         their own burst command.  (Although they would automatically burst if they
         did not receive steering commands for 2 seconds.)
      </li></ul>

</n></dd><dd>
The Missile Burst Command is sent via pulse codes through the missile tracking radar.
<p>


e) <b>And of course be  highly reliable, accurate, testable and maintainable.</b>

	<br>In the 1950's, <b>digital computers</b> had <b>tens of thousands of vacuum tubes</b>,
 and because 
the vacuum tubes had a mean time to failure of only a few thousand hours, 
the computers had a mean time to failure of only a few hours.
90 percent "up" time was considered outstanding, and required a round the clock staff of
real experts.  Digital input and output devices were similarly failure prone.
(In the 1970s, when reliable transistors and integrated circuits, 
and cheaper high speed memory became available, some Nike analog computers were replaced by 
digital computers.)


</p><p>
The <b>only alternative that was reliable enough and accurate enough</b> was the 
electronic analog computer, which could
be implemented for the Nike with fewer than 500 vacuum tubes.  There were failures, but the
technology was maturing, the tubes were run in a different (not ON/OFF) manner,
 and the uptime exceeded 99% at most sites. (One failure a month was considered really 
poor.)

<br>

<table>
<tbody><tr><td> These test points are inputs to computing networks, easily accessable. A "Null Voltage Test Set"
	could be plugged into these test points, and was sensitive to 1/400 volt ( 2.5 millivolts )
</td><td><a href="https://www.ed-thelen.org/NikeComputerTestPoints-.jpg"><img src="https://www.ed-thelen.org/NikeComputerTestPoints-t.jpg"></a>

</td><td> Some of the built-in test and trouble shooting aids
</td><td><a href="https://www.ed-thelen.org/NikeComputerMeter-1-.jpg"><img src="https://www.ed-thelen.org/NikeComputerMeter-1-t.jpg"></a>
</td><td><a href="https://www.ed-thelen.org/NikeComputerMeter-2-.jpg"><img src="https://www.ed-thelen.org/NikeComputerMeter-2-t.jpg"></a>
</td></tr></tbody></table>

</p><p>
(<b>In the late 1970s, the analog computer was replaced by a digital computer,</b> a
 PDP-11 W (running the RT-11 operating system. Two of the 4 analog computer cabinets 
	became closets and storage space.)

 
</p></dd></blockquote>
<hr>

<p><span size="+2">

<a name="What"><u><b>
2) What is an Electronic Analog Computer?</b></u></a></span>

</p><blockquote>
<p>

The Nike analog computer was single purpose, a fixed program with a few different modes
set by relays to simplify and automate testing and different modes of operation.
</p><p>

<a href="http://en.wikipedia.org/wiki/Analog_computer"> wikipedia Analog_computer</a>

<br>An interesting <a href="http://www.righto.com/2019/09/reverse-engineering-precision-op-amps.html">
	Analog Computer Web site</a> Reverse-engineering precision op amps from a 1969 analog computer 
	  
<br>Another <a href="http://www.analogmuseum.org/english/">
	Bernd Ulmann's Analog Computer Museum</a>

</p><p>
Schematics and Operation Manual for the Heathkit EC-1 
	<a href="https://www.ed-thelen.org/comp-hist/vs-heathkit-ec-1-analog-computer.html#Architecture">here</a>
</p><p>

  From <b>"The Analog Computer Museum and History Center"</b>  - no longer available

 <div>
<b>Analog computer </b>

 

<i>- A computer that performs mathematical operations in a PARALLEL 
 manner on CONTINUOUS variables. The components of the computer are interconnected to 
 permit the computer to perform as a model, or in a manner ANALOGOUS to some physical 
 system.</i>

<p>

 
<b>Electronic analog computer </b>

 
<i>- An analog computer with input, output and program 
 operations that are usually expressed in terms of direct current voltages. 

</i></p><p>
 

<b>Analog computers </b>

 may seem to be "simple" or "like a toy computer", in fact they are
 powerful tools that were used during the 1950s and 1960s to design and test systems like
 ICBMs, supersonic aircraft and spacecraft. But the analog computer can be used to model any
 physical system that can be described by mathematical formulas, even more mundane ones from
 modeling the effects of pollution on the fish population in a river to fine tuning the 
suspension on
a new car design. Analog computers will not only test a fixed design but also allows 
variables to
be quickly changed to test "what if' conditions. By scaling time as an independent variable,
physical processes that happen quickly can be stretched out, and processes that happen over a
long period can be shortened to make the process easier to study. And it is very easy to study
variables at any point in the program while it is running to find faults in the program design.
</p><p>


<b>Although </b>
 
the analog machine is correctly termed a computer, it does not perform its
computations by numerical calculations as does the calculator or the digital computer. The
analog computer performs mathematical operations on CONTINUOUS variables instead of
counting with digits. Positive numbers are represented by positive voltages and negative
numbers are represented by negative voltages, all scaled to the computer's working range,
usually -100 volts to +100 volts (vacuum tube) or -10 volts to +10 volts (transistorized),
 Thus the
analog computer does not subtract 20 inches from 45 inches to obtain 25 inches but, rather,
 it
subtracts 4 volts from 9 volts to obtain 5 volts. This 5 volts the operator reads as 25 
inches in
accordance with his arbitrarily specified "scale factor' of 1 volt equals (or is ANALOGOUS 
to) 5
inches.

</p><p>


 
<b>The analog computer </b>

is basically a set of building blocks, each able to perform specific
mathematical operations on direct current voltages and capable of being easily interconnected
one to another. Some of the basic operations include addition, subtraction, multiplication,
division, inversion, and integration. By interconnecting these building blocks, mathematical
equations are modeled. BUT an analog computer is a true PARALLEL computer that can solve
one or one thousand equations at the same time. In fact, similar analog computers can be easily
connected together to increase their computing power. When you think about the result of many
equations being solved simultaneously and becoming the input to other equations, and
sometimes these solutions are then fed back or looped back into the original equations with 
all of
the variables changing CONTINUOUSLY with time, then you can get a brief glance into the
incredible power of these computers. Output is usually a voltmeter, oscilloscope, or plotter.

</p><p>


<b>Many universities </b>
today like Massachusetts Institute of Technology, University of Illinois,
University of Notre Dame, and Purdue University offer classes or do research using analog.
computers, because they realize that the last chapter of the history of analog computers 
has not
being written. It's an ANALOG universe and analog computers are a natural way to study and
understand it.
</p><p>



Prepared by:</p><dl>
<dd>
<b>

The Analog Computer Museum and History Center<br>

 http://www.cowardstereoview.com/analog/"&gt;http://www.cowardstereoview.com/analog/ - no longer available 

 <br>
</b>
</dd>
</dl>

We do except donations of your unused analog computing equipment, working or not.
</div>

 
</p></blockquote>

<hr>
<p>
<span size="+2">

<a name="About">
<u><b>3) Nike Hercules Computer</b></u></a></span>

</p><blockquote>
The "Improved Nike Hercules" computer commanded the missile flight in several selectable modes
 (see <a href="https://www.ed-thelen.org/MMS-150-Ch01.pdf">MMS-150 Chapter 1</a>)


<p>

From the deployment of Nike in <b>1954 to the mid 1970's</b>, the Nike Computer was an 
<b>analog computer</b>. 
 That means that distances, times, and other values were not digital bit representing 
numbers (like 12.3)  but were (in this case) voltage values (like 12.3 volts).
</p><p>
The values as stated above were voltages, and simple circuits 
(using 76 "operational amplifiers" of 2.5 tubes each)
could quickly <b>(1 microsecond)</b>:
</p><ul>

<li> add or subtract 2 or more variables 
</li><li> determine rate of change (of distance giving velocity)
</li><li> multiply or divide a variable by a constant 


</li><li> approximate a function to 1 %
</li></ul>

<dd>

but <b>slower motor driven potentiometers</b> were required to:
<ul>
<ul>

<li> multiply or divide a variable by a variable
</li><li> store a variable for a long time (minutes or hours) (not needed in anti-aircraft)
</li><li> generate a precision non-linear function 

</li></ul>

</ul>
Each amplifier had a nominal gain of 20,000

<ul>

<li> most amplifiers used "semi-precision" zero set switches with gains of 200, giving effective gains of 4 million.
</li><li> about 6 amplifiers used "precision" (re-entrant) zero setting, with gains of 3,000.
</li></ul>


<p>
Further details on the operational amplifier are in the Technical Manual
    <a href="https://www.ed-thelen.org/TM9-5000-13-Ch03.pdf">TM9-5000-13-Ch03 DC Amplifier Circuitry</a> 265 KBytes
 

</p><p>
For images of the motor driven potentiometers see 
	<a href="https://www.ed-thelen.org/t_tour.html#3400">Computer (Servo driven potentiometers)</a>

and
	<a href="https://www.ed-thelen.org/t_tour.html#3450">Computer (Details of Time Potentiometer)</a>

 

</p></dd><dd>
The Nike anti-aircraft problem did not require many slow motor driven circuits 
(about 7) and used about 100 of the simple fast circuits. It also used numerous
relays to change between the various modes of operation (test, pre-launch, post-launch).

<p>
An interesting characteristic of analog computers is that the <b>circuits tend to 
run in parallel</b>, The relatively slow circuits all working together easily  keep
up with the anti-aircraft problem in real time.

</p><p>
	An analog computer (distances and times were voltages) used
	analog (voltage) inputs from the Target Tracking and Missile Tracking Radars.<br>

</p><p>
	
	These values (and derived target and missile velocities) were
	used to calculate the remaining flight time and Predicted 
	Intercept point.  The missile was guided to the predicted
	intercept point by the computer generated steering commands 
	sent through the Missile Tracking Radar.  <br></p><p>

For vacuum tube enthusiasts, here are schematics of a
</p></dd><dd>- <a href="https://www.ed-thelen.org/dc_amp.gif"> operational amplifier</a> <span size="-1"> (42 K bytes) </span>

</dd><dd>- <a href="https://www.ed-thelen.org/PowerSupply.gif">power supply</a>
</dd><dd>- <a href="https://www.ed-thelen.org/VoltageReference.gif">voltage reference</a>

</dd><dd>- <a href="https://www.ed-thelen.org/PowerSupply.gif"> + 450 volt 1 amp thyratron power supply</a>

<br>used in the Nike Ajax and Hercules (as well as the earlier M-33 gun laying analog
computer and radar system).

<p>
The Nike analog computer did not use integrators, but did use filtered
differentiators for velocity determination as well as motor driven potentiometers
for multiplying by a variable (including time to intercept) as mentioned above.


</p><p>
Another system of amplifiers and motor driven switches performed as
"<b>Zero Set Amplifiers</b>" to:
</p><ul>
<li> zero the bias of the operational amplifiers 

</li><li> increase the effective gain of the associated operational amplifier(s) (to over 1,000,000)

</li><li> alarm on excessive inputs caused by operational amplifier failure or 
	computer not settled to a valid "answer".
</li></ul>

</dd><dd>
<p>

A number of preset test cases (switch selectable) helped assure that 
the computer was performing correctly.
</p><p>
Manual knobs input the offset between the missile tracking and target tracking radars.
 (For further information, you can jump ahead to
 <a href="#parallax">6) How does the computer know the radar offsets? </a><br>

</p></dd></blockquote>




<!---------------------------------------------------------------------->
<hr>
<p>
<span size="+2">

  <a name="Digital">
 
<u><b>4) Computer Upgrade to Digital</b></u></a></span><a name="Digital">
<br>Click </a><a href="#DigitalComputer">here for the digital computer itself</a>
  </p><blockquote> 
<p>
  <div>
  <b>Nike <u>System</u> upgrade to digital</b>
  <br><a href="mailto:rcarlib@libero.it">Ramiro CARLI BALLOLA</a> 
	wrote  Sept 19, 2015
  <div>
Hello to everybody, I'm starting answer your questions received by your mail dated September 17,
<ol>
<li> No problems with the pictures and message (the pictures I'm sending are mine)
</li><li> To answer to all other questions is preferable that I list a sequence of modification (and what the MWO introduced into the system) implemented on the European Nike Systems after the U.S. phase out in 1974.
</li></ol>
This is the story, first of all in 1959 the first system was deployed in Europe,
 8 Countries were participating under the MAP , in 1961 the Logistic support was 
placed under the control of NAMSA (a NATO maintenance Agency) and the 
first NIKE Support Conference (SC) among 8 Countries plus the Firing Range in Crete (Greece) 
was held and followed by other 17 SC.
<p>
In 1973 MICOM (Missile Command) changed the assistance conditions and a new agreement 
was taken with NAMSA to ensure the technical and supply assistance until 1985 with NAMSA.
</p><p>
In 1977 the Support Conference was changed in WSPC (Weapon System Partner Ship) 
to take control of all aspect (supply, maintenance, overhaul ecc...)
 of the system support in Europe, still under MICOM external assistance.
</p><p>
MICOM assistance for the nuclear parts was directly followed until 1988 
(when the nuclear warheads have been dismissed from the European Systems).
</p><p>
Starting from 1985 all Maintenance aspects was taken directly from NAMSA, 
transfer of know how took place except for the Engineering parts from 
1985 to 1988, after that  also the engineering parts were released and 
the European facilities started the direct assistance in 1989, 
acting to maintain the system capability until 2005 for ITALY-GRECE and TURKEY 
(all other 5 countries were phasing out their systems).
</p><p>




Since 1977 started the studies by AT&amp;T for the main and relevant modification 
to bring the system to be converted in Solid State NIKE Missile System.
</p><p>
As you know the universal Nike System was really universal until the 
SAMCAP mod. in 1972 (implemented in Europe from 1973 to 1977) 

<br>This was a big change because introduced the first solid state circuits into the system. 
(the first change with the transistors addition was made by the LOPAR AJD modification
 in the period 1963-1964).
</p><p>
Starting from the SAMCAP baseline the RAEMOD (Range and angle encoder modification) 
prepared by SIERRA RESEARCH CORP. was implemented into the systems  
and consisted in the following changes:
</p><ol>
<li> For all tracking antennas, Azimuth and Elevation sin-cos old pots modified 
	and converted to digital output by the mean of opto-electrical converters, 
	(no more Bayol D change and spilling and heavy pots to be moved) 

</li><li> Range pot completely taken out and changed with the new box  
	(heavy like the old one) containing 4 mini computers for the TTR:

	<ol type="a">
	 <li> AES Angle Encoder Section  (converting azimuth and elevation info to 
	az/el error signal for the  mechanical tracking and to a digital words for the computer)

	 </li><li> RTS Range tracker section (converting the range info to a signal 
	for tracking the target and to a  digital words for the computer)

	 </li><li> PCS Periferal controller section to transfer all the signals to the 
	appropriate circuits still inside the 	pot. 

	 </li><li> CCS Coordinate Converter Section (to convert az-el-rng from 
		geographical <i>[or polar]</i> to 
	rectangular coordinates) this circuits were working for the MTR too.
	</li></ol>
 
Other  three mini computer for the MTR, the difference was that AES-RTS-PCS had the 
same function of the TTR, but instead of the CCS was only a buffer circuit to transfer 
the data to the TTR CCS which output was composed of 12 digital words 
(representing the radar coordinates) to be sent to the computer.

</li><li> Because at that time the computer was still analog   (except the Zero Set switches 
converted to solid state) a new item was implemented located into the computer power supply section, the CCDA (Coordinate Converter Digital to Analogic) called also (RCU (Radar Conversion Unit) 
to bring the 12 digital words back to analog info to be used by the analog computer.
<p>
This was a very delicate and unstable circuit due to the thermal control of 
the converting networks inside, but was only to cover the gap until the introduction 
of the digital computer in the 80's.
</p></li></ol>
After the implementation of the RAEMOD from 1978 through 1983 took place 
another big modification called NAMSA NIKE Support Plan to bring the hybrid system 
to be completely digital.
<p>
The modification was composed of:
</p><p>
<b><u>Tracking Antennas </u></b>
<br>TTR/MTR antenna to be digitalized changing:
</p><ol>
	 <li> TTR/MTR the old TR Electron Tube with a new TRL (Transmit-Receive and limiter)
	 </li><li> TTR only, adding a new Imageless rejection mixer and new converter with solid state amplifiers.
	 </li><li> TTR/MTR changing the old klystron local oscillator with a new VTO 
		(still oscillator voltage controlled)
	 </li><li> TTR/MTR new solid state  Skin AFC (automatic Frequency control)
	 </li><li> TTR/MTR new Coaxial  Magnetron to have more stability 
	 </li><li> TRR new Power Monitor, new duplexer with a new type ferrite switches, 
		TRL's and solid state amplifiers
	 </li><li> TRR new solid state Tracking data's
</li></ol>

<b><u>Bore Site Mast</u></b>
<ol>
	<li>  R.F.T.S. (Radar Frequency Test Set) completely converted to digital 
		at the same time of the other MWO's to bring the NIKE to digital system.
		Used for test purposes for TTR/MTR/TRR.
	<br> Inside the RC Van we had the remote control of the RFTS.

</li></ol>


<b><u>RC Van</u></b>
<ol>
	 <li> TTR new solid state Synchronizer, Video Time Share Amplifier, Lin-Log circuits, 
	IF Amplifiers, LP and SP filters, Video and AGC amplifier, Beacon AFC, 
	Az/El error converter, Az/El angle amplifier, IF test signal generator, 
	Remote RFTS control, Signal strength meter, B scope amplifiers .

	 </li><li> MTR new digital Hercules Coder, same modification as for the TTR 
	except Synchronizer and LP filters

	 </li><li> Completely new digital Track Data Processor, able to analize the 12 words 
	coming from the TTR CCS and performing local simultaneous test 
	(at that point in time all the radar tests were terminated) other than 
	radar parallax conversion for all three radars.

	 </li><li> TRR new solid state IF test signal generator, IF amplifiers 
	and ancillary circuits
	
	
</li></ol>

<b><u>BC Van</u></b>
<ol>
	 <li> New digital computer DEC PDP 11/34, located in the former old pot's bay) 
	and supply bay, the first two bay have been left empty (used after many years 
	to include the new IFF system) composed of:
	<p><b><u>Former pot's bay</u></b>
	</p><ol type="a">
	    <li>  two boxes containing CPU and Expansion circuits
	    </li><li> Intercept computer controller for the Plotting boards (with another mini computer) 
			and all circuits relevant to the incoming info by the radars and 
			from the computer to the Launching area.
	    </li><li> 2 Floppy disks (8 inches) one to record the Missions and the other 
			one with the Tactical disk containing the computer program, 	
			one controller and one real time clock, 
			there was another disk 	containing the computer diagnostic software.
	<p>
	<b><u>Supply Bay</u></b>

	    </p></li><li>  Digital Display
	    </li><li> Digital keyboard
	    </li><li> Thermal printer
	</li></ol>
	 </li><li> New digital Tactical Control indicator
	 </li><li> New plotting boards arms movements by means of stepping motors and new pen type 
	 </li><li> New complete Digital AJD circuits
	 </li><li> New digital STC amplifier, az/rng amplifier circuits, PI and PPI all circuit at solid state
	 </li><li> Inside the Director Station Group all circuits converted to digital circuits 
		plus a completely new DMTI (Digital Moving Target Indicator)
</li></ol>
 
    Resulting layout of the previous analog computer area ( From Ramiro Carli Ballola, Feb 2022 )
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <i> - for your reference, the previous analog computer bays are depicted <a href="https://www.ed-thelen.org/ifc_bct-LeftSide-.jpg">here</a>. </i>
    <div>
    Starting from BC Van entrance door,
    <ol start="a">
     <li> the first two bays on the left side, has been used to insert the new IFF/Mark XII 
	with Mode 4 system installed years after the computer digital implementation.
	<p>About the IFF MK XII installation:
	</p><ol>
	<li>The equipment was made by HAZELTINE Corp:
	</li><li>the antenna driving circuits (installed inside the first bay) 
	</li><li>the RCVR XMTR made by SIEMENS (installed inside the second bay lower part, 
		together with the Mode 4 equipment in the highest part of the bay)
	</li><li>the Coder Decoder made by Hazeltine corp. including the decoder expansion 
		panel able to indicate the height of the IFF answer read by an optical 
		pen installed on the Horizontal Plotting board chassis
	</li><li>Outside aside the BC Van an highest pole with the pedestal mounted on top 
		and the related antenna 7 dipoles. Of course the antenna rotation was 
		synchronized and aligned with the LOPAR Antenna. 
	</li></ol>

     </li><li> the third  for the Norden digital computer and interfaces
     </li><li> the fourth for display, printer and power supplies (5V 300Amps)
    </li></ol></div>
 
<p>	
<b><u>LOPAR</u></b>
</p><ol>
	 <li>  New digital amplifiers
	 </li><li> New digital converters
	 </li><li> No more power meter and a new coaxial magnetron for the same reason 
		of the tracks magy (stability)
	 </li><li></li><li> New delay circuit inside the antenna relevant to the application 
		of the HV to the Magnetron
	 </li><li> New solid state Local oscillators, and new front panel in the RCVR/XMTR
</li></ol> 

<b><u>Launching Area</u></b>
<blockquote>
	The modification on the missile were relevant to enhance the time reaction to the orders, 
	with a new exchange valve for the elevons and with the manuver increased to 10 G's
</blockquote>
I have many other information for the subsequent modification, but I believe to have depicted the real situation of the European Nike Systems until the end of 1985.
<p>
I'm collecting other pictures and as soon as I have completed my collection I will sent to you, 
about the TM's I have no chance to have them because are still under Government control 
	(despite that they have been declassified) 	but I'm trying to be able to have some of them.
</p><p>
Best regards
</p><p>
Ramiro Carli Ballola (by the way for me is enough if you call me Ramiro)  
</p></div>












<p>
  <a name="DigitalComputer">
  <b>Digital Computer</b>,
  </a><a href="mailto:rcarlib@libero.it">Ramiro CARLI BALLOLA</a> 
	wrote to <a href="mailto:">Greg Brown</a>, Sept 16, 2015
  <div>
First of all  allow me to present my self, my name is Ramiro CARLI BALLOLA. 
I have been in the Italian Air Force as Maintenance Chief for the IFC area 
of the 79th Group  located at ZELO in lower Veneto Region 
(one of the squadron of the 1st Air Brigade).
<p>
I know the Nike System since 1959 for my knowledge and from 1967 for the Air Force.
I followed all the modifications implemented in the system, until 1995 in the Air Force 
and until the end of System Life in 2007 for the NIKE WSPC at NAMSA 
(a NATO Maintenance Agency) 
</p><p>
You asked to Base Tuono site information about the digital computer 
implemented in the system in the eighties. 
I'm following Base Tuono for the technical side
</p><p>
Basically was the DEC PDP 11 ruggedized for military purposes 
by Norden Company. Composed of the following items:
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- Two boxes with the CPU and the Expansion items in another box
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- Floppy disks system (8 inches) with two of them and one controller, 
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- one real time clock
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- Display, printer and keyboard
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- Plotting orizontal and vertical controlled by another single computer
<br> &nbsp;&nbsp;&nbsp;&nbsp;
	- Tactical control indicator modified to digital display
</p></div>
  <table>
  <tbody><tr><td>  <a href="https://www.ed-thelen.org/pics/DecComputer-1-.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-1-t.jpg">
 	</a></td><td>5244 Computer expansion box
  </td><td>  <a href="https://www.ed-thelen.org/pics/DecComputer-2-.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-2-t.jpg">
 	</a></td><td>5245 CPU box
</td></tr><tr>
  <td>  <a href="https://www.ed-thelen.org/pics/DecComputer-3-.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-3-t.jpg">
 	</a></td><td>5246 Intercept computer controller interface
  </td><td>  <a href="https://www.ed-thelen.org/pics/DecComputer-4-.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-4-t.jpg">
 	</a></td><td>10759 Expansion box cover with component list
</td></tr><tr>
  <td>  <a href="https://www.ed-thelen.org/pics/DecComputer-5-.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-5-t.jpg">
 	</a></td><td>10763 CPU box cover with component list
  </td><td>  <a href="https://www.ed-thelen.org/pics/DecComputer-Stitched-1&amp;2.jpg"><img src="https://www.ed-thelen.org/pics/DecComputer-Stitched-1&amp;2-t.jpg">
 	</a></td><td>top two images stitched
	<br>missing image sections made black


</td></tr><tr>
  <td>  <a href="https://www.ed-thelen.org/pics/BC-VanInterceptCompController&amp;FloppyDisks-.jpg">
		<img src="https://www.ed-thelen.org/pics/BC-VanInterceptCompController&amp;FloppyDisks-t.jpg">
 	</a></td><td>BC Van Intercept Comp Controller &amp; Floppy Disks 
  </td><td>  <a href="https://www.ed-thelen.org/pics/BC-VanInterceptCompPowerSupplyBay-.jpg">
		<img src="https://www.ed-thelen.org/pics/BC-VanInterceptCompPowerSupplyBay-t.jpg">
 	</a></td><td>BC Van Intercept Comp Power Supply Bay 
</td></tr><tr>
  <td>  <a href="https://www.ed-thelen.org/pics/BC-VanInterceptComputerBay-.jpg"><img src="https://www.ed-thelen.org/pics/BC-VanInterceptComputerBay-t.jpg">
 	</a></td><td>BC Van Intercept Computer Bay 
  </td><td>  <a href="https://www.ed-thelen.org/pics/ATR-ExpansionUnitExplodedView-.png">
		<img src="https://www.ed-thelen.org/pics/ATR-ExpansionUnitExplodedView-t.png">
 	</a></td><td>ATR Expansion Unit Exploded View 


</td></tr><tr>
  <td>  <a href="https://www.ed-thelen.org/pics/InterceptComputerControlGroupExplodedView-.png">
		<img src="https://www.ed-thelen.org/pics/InterceptComputerControlGroupExplodedView-t.png">
 	</a></td><td>Intercept Computer Control Group Exploded View 
  </td><td>  <a href="https://www.ed-thelen.org/pics/CPU-ChassisExplodedView-.png"><img src="https://www.ed-thelen.org/pics/CPU-ChassisExplodedView-t.png">
 	</a></td><td>CPU Chassis Exploded View 
 



</td></tr></tbody></table>
</p></div>


</p><p>
  <table>
<tbody><tr><td>
  from "Computerworld" December 20, 1976
  <div>
<h3>Militarized Mini From Norden 
  <br>Features PDP-11 Compatibility </h3> 


<b>Norwalk,</b> Conn. - The PDP-11/34M
fron the Norden Division of United Technologies 
Corp. is a militarized digital minicomputer compatible with the 
Digital Equipment Corp. PDP-11, according to the vendor.


<br>&nbsp;&nbsp;&nbsp;&nbsp;The ruggedized mini features an extended
instruction set with more than 400 instructions,
the ability to perform single- and double-operand instructions,
a memory expandable to 128K words, 900 nsec cycle time in core,
byte parity, memory management, hardware multiply and divide and a
floating-point option, the vendor said.


<br>&nbsp;&nbsp;&nbsp;&nbsp;It can operate in environments from -65degrees F
and in altitudes up to 85,000 feet, Norden said.

<br>&nbsp;&nbsp;&nbsp;&nbsp;In addition the unit car withstand vibration, shock 
and humidiity:  it meets the requirements of the MIL-E-5400, 16400
and 4158 specifications, the firm added.


<br>&nbsp;&nbsp;&nbsp;&nbsp;A basic one-half chassis PDP-11M costs $15,200 to $20,200 depending on
configuration; the full-chassis system costs $18,500 tp $24,700.
 

<br>&nbsp;&nbsp;&nbsp;&nbsp;A system with 32K of memory and a communications
interface ranges in price from $28,000 to $37,500.
Norden said from Helen St., Norwalk, Conn. 06856.
  </div>
  </td><td>
  from "Computerworld" September 18,1978
  <div>
<h3>Military Okays Norden PDP-11s</h3>
Norwalk, Conn. - Norden Systems's PDP-11-11M 
  family of minicomputers has been 
given the U.S. military nomenclature designation of 
AN/UYK-42(V).

<br>&nbsp;&nbsp;&nbsp;&nbsp;This designation is used as 
official recognition for all 
armed forces applications and 
was designated by the U.S.Naval Electronic Systems 
Command, Department of the 
Navy.

<br>&nbsp;&nbsp;&nbsp;&nbsp;Norden Systems, a subsidiary of United Technologies 
Corp., militarizes the Digital 
Equipment Corp. family of 
PDP-]7 minicomputers under 
a special license.

<br>&nbsp;&nbsp;&nbsp;&nbsp;Included in Norden's s militarized minicomputers are the 
PDP-11/70M, the PDP-11/-34M and the LSI-11M 
microprocessor. All have complete 
software identical to DEC's 
commercial software.
  </div>

  </td></tr></tbody></table>

  </p><p>

  In the late 1970's a <b>digital computer</b> was made available for the Nike.  These were sent to
  "off-shore" locations as all U.S. sites had been de-activated.  It is quite possible
  that this computer was a Norden PDP-11M.  This was a licensed version of the 
  DEC (Digital Equipment Corporation) PDP-11 that was housed in a tougher case
  and made more vibration resistant and in other ways made more suitable for
  a military environment. 

</p><p>
   It is known that the file system format on the floppy disks was RT-11M.
(I have two floppies reported to be from a Nike site, but cannot figure out the data/program.)  It had
  two 8 inch floppy disk drives, a printer, (and some I/O cards).
As as best I can determine, the tracking antenna potentiometers
       were retained - the analog voltages being converted to
       digital for digital computing. Maybe the same for the range pot??


</p><p>

Any information about a digital Nike much appreciated.

  </p><p> 
  Here is <a href="mailto:rolfdieter.goerigk@nwn.de">Rolf Dieter G�rigk's</a>
  preliminary message - more info to follow:

<div><pre><b>
"  On the right hand side of the computer cabinet under
the computer power control panel, there was a little monitor
about 10 by 6 inches, and a keyboard.
There under a printer. The printer printed out sampled data
every 100 msec. During a sim track, data were sampled
every 100 msec and printed out.
For me it was heaven. I already re-calculated a lot
of the system capabilities and used the computer during
live ECM and T1 ECM exercises.

Finally I determined the radar cross section (RCS) of  targets and
found that the T1 was wrong by/in determining the radar resolution
cell LP/SP and therefor misinterpreted the amount of chaff that
could be fitted in a resolution cell.

Well,  that sounds academic but it was the greatest success
for me and the reason for many unsuccessful ratings of the
crew performances.
I found out what the real RCS was for a specific airplane
but that was secret.
The Airforce told (ordered) me not to talk about it.

Just imagine, a live missile firing and data sampled every
100 msec!!!"   </b></pre><b>
</b></div>
August 2012, Rolf sent the following
<div>
The following web site and pages are no longer available on the Internet.
<br>
Archive.org does not have them archived due to Rolf's "robots.txt" string in each web page.
<br>
If anyone has recent information about Rolf or the contents of his web site, please send the information to me.
Attempts to contact Rolf by several people have failed :-((
<hr>

<pre><b>
you`ll find the digital modifications under:
<a href="http://www.nikesystem.de/Pages/nike_content.html">http://www.nikesystem.de/Pages/nike_content.html</a>

Click on the "BCT &amp; RCT" or "RADAR" button.

Most of the BCT modifications are at:
<a href="http://www.nikesystem.de/Pages/Equipment/nike_equipment_start.htm">http://www.nikesystem.de/Pages/Equipment/nike_equipment_start.htm</a>

Click on "New BCT" or "RCT"
Remember that the system was not modifyed to a full solid state status.
So some "old" parts were left in the system.

To look at the "radar" modifications click on the RADAR button:
<a href="http://www.nikesystem.de/Pages/Antennas/nike_radars.htm">http://www.nikesystem.de/Pages/Antennas/nike_radars.htm</a>

You`ll find digital parts under "LOPAR", "HIPAR" or "TRACKING RADARS".
Often old &amp; new (digital)  Parts are shown on the same page.
(Note the text.)

I`m working on better (Full HD) picture shows but that will take some time.

Hope that`s of some help!

Rolf D. Goerigk</b></pre></div>
</p><p>
In August 2012, wo Enzo Chieregatti &lt; chrnzo @ libero . it &gt; sent the following:
<table>
<tbody><tr><td> 
Hi I'm looking for information of the function of the Panel shown in the
attached photo that was mounted in the nike system.Thank you
<br>
The photo panel was a converter analog-digital data between advancement station
(R.S.P.U.) and the computer before changing years 80 is it possible?
</td><td>
<a href="https://www.ed-thelen.org/NikeDigitalPanel-.jpg"><img src="https://www.ed-thelen.org/NikeDigitalPanel-t.jpg">
</a></td></tr></tbody></table>
<i>Donald Kraus &lt; dkraus12 atsign hotmail dot com &gt;	e-mailed  May 02, 2013  </i>
<div>
Thought I would tell you a story that relates to the panel that one of your contributors asked about

{above}
<p>
When I was getting out of engineering school in 1978, I was working for a company in Buffalo, New York named Sierra Research. 
</p><p>
By the way, this is the same company that built the zero set switches that you have pictures of on the same page. The circuit boards have the Sierra federal company code (12115) and some of the potted transformers actually have the Sierra Research name on them. The way the part numbers worked at Sierra was that the first two digits of the first group of four digits was the year of the contract that the part was for. The second two digits for circuit boards and things that were developed that were contract specific were the contract number for that year. For special part, like the transformers, other codes were used. The circuit cards for the zero set switch all have 6900 as the first four digits - meaning that these were designed for the first contract in 1969. Way before I joined the company. But this should help you place when the motor driven zero set switches were replaced with the electronic version.
</p><p>
Anyhow, the story about the digital to analog converter panel in the picture. The panel was part of a modification to replace the range and angle pots with microprocessors. The RSPUs (Radar Signal Processing Units -one for the MTR and one for the TTR) were mounted in the cabinet where the original range pots lived in the radar van. The original range pots were no longer used, the return video being processed by some fast digital logic coupled to an 8080 microprocessor. The angle pots were modified to remove the sine and cosine potentiometers. These were replace with an 8 pole resolver mounted directly on the 9:1 shaft of the pot. This resolver signal along with an existing 1:1 resolver signal were fed into converters in the RSPUs and another 8080 computed the pointing angles from resolvers along with the sine and cosine of the azimuth and elevation. Another microprocessor in each RSPU (we are up to six now - but they were only operating at 2.0 megahertz) combined the range and angle data to compute the various things that the original analog pots computed - slant range, X and Y along with the velocities of these things. A single microprocessor in one of the RSPUs (that would be number 7) then packaged this all for a data link to the battery control van, via a single coax cable.
</p><p>
The panel that you show was on the other end of the data link. This box contained a temperature controlled compartment (ECU - heater/cooler switch lower right) which contained an 18 bit multiplexed digital to analog converter. The converter also included ramping between the updates by use of the velocity components computed in the RSPU. The output of the converter was fed into the original analog computer. The velocity ramps were needed to help keep the digital sampling noise out of the analog circuits.
</p><p>
These modifications were performed on many of the Nike sites in Germany around the 1979/1980 time frame. 
</p><p>
Anyhow, as a young engineer, I learned a bunch from helping put this equipment together. The documentation on the various signal flows along with the schematics of the radar equipment was top notch from my point of view, the organization of the actual equipment in racks and drawers supported trouble shooting even in a small space. A truly complex piece of equipment that was modularized to be maintainable. Not much that I have worked on since  has come close to this. 
</p><p>
Just thought I would give you some of the story on that panel.
<br>Anyhow, hope this finds you well, and thanks again for the wealth of information  on your site.
</p><p>
Don Kraus
</p></div>
  </p><hr>
 

</blockquote>
<hr>

<p><span size="+2"><a name="Solving">
<u><b>5)
	 Solving the Predicted Intercept problem</b></u></a></span>

</p><blockquote>
<p>


    To <b>keep flight times down</b>, (and increase the effective range) 
    the <b>missile is aimed ahead of the target</b> at a calculated 
    <b>Predicted Intercept Point</b>.  If the aircraft flies a straight
    line, the missile horizontal flight path will also be straight.
    (A dog chasing a target runs directly toward the target,
     involving a longer run if the target runs straight.)


</p><p>

	A person can worry that assuming that airplane flying straight might not
	be a good assumption, but what better can you make?   One can wonder about
	the 10 million year success of dog-like creatures running directly toward the
	present position of their intended prey.  However their prey can change direction and
	percent speed much faster than an aircraft.  Dog chase path succeeds with a slightly
	different problem.
</p><p>
    The computer has built into it average flight times to various ranges
    and altitudes. Here is a chart of

	This information is compared with the speed and direction of the
	target until a valid time of flight to predicted intercept point
	is computed.  This information is presented to the battery commander
	on the <a href="#Plotting"> About the Nike Plotting Boards</a> 
	to assist him in making the firing decision.




</p><p> 
    The computer computes the Predicted Intercept Point by:
</p><ol>
  <li> Assuming the designated, tracked Plane will continue on its present course.
  </li><li> Using a Trial Missile Flight Time, the position of the plane at the 
	end of that time is estimated
  </li><li> Using the same Trial Missile Flight Time, and a trial missile azimuth,
        the postion of the missile at the end of that time is estimated
  </li><li> Based upon differences of estimated tracked plane position and missile
  	position,<br> 
	- the Trial Missile Flight Time is changed, <br>

	- the Trial Missile Azimuth is changed
  </li><li> Go back to step 2, do this continuously.



</li></ol>
<a href="https://www.ed-thelen.org/compute-int-point.gif"> <img src="https://www.ed-thelen.org/compute-int-point-t.gif">
How Predicted Intercept Point is computed</a>.
<p>
Rod Brimhall has a <a href="https://www.ed-thelen.org/NikeRangePot-paint.pdf">more complete discussion</a>, 240 KBytes, .pdf 
     
</p><p>
	At longer ranges (flight times) the <b>Predicted Intercept Point can
	vary greatly</b> due to target aircraft maneuvers.  The battery commander
	must make allowances for many possibilities.
</p><p>

	The <b>predicted time to intercept is also continuously updated</b> during
	the missile flight to update the predicted intercept point to
	assist in making steering command commands.




 

</p></blockquote>
<hr>

<p>	

<span size="+2"><a name="Summary">
<u><b>6) Missile guidance summary</b></u></a></span><a name="Summary"><br>
</a></p><p><a name="Summary">
Please note: for a missile perspective, please see
 	</a><a href="https://www.ed-thelen.org/flight.html">Nike Missile Flight Sequence</a>

</p><blockquote>
    <p>

    The missile is launched   <b>almost straight up</b>,  boosted
    to about mach 1.7 in <b>3.4 seconds</b>.  It then turns its belly 
    toward the calculated Predicted Intercept (1 second), and a 7 g dive command is sent to the missile.
</p><p>
	This is an image of the "Time-to-Intercept vs Altitude" plotting board describing the 
	"Dead Zone" options which are limits of the Nike Flight dynamics. (The Nike 
	is limited to a 7 g turn.) The Nike cannot get into the "Dead Zone" of altitude vs time.
	There are two 	options of systainer motor start depending upon how close the
	 Predicted Intercept Point is to the launcher.
	<table>
        <tbody><tr><td>
	<a href="https://www.ed-thelen.org/PlottingBoard-Time-vs-Altitude-.jpg">
		<img src="https://www.ed-thelen.org/PlottingBoard-Time-vs-Altitude-t.jpg">
	</a></td><td>
	a) If the Predicted Intercept is close, the firing of the systainer motor is delayed,
		the missile goes slower, can turn tighter, with a smaller "Dead Zone"
	<p>
	b) Normally the sustainer is started immediately after the booster falls away, faster flight
		larger turning radius, larger "Dead Zone".
	</p></td></tr></tbody></table>
	</p><p>

	The missile must not fly directly over the Missile Tracking Radar (MTR)
	because of limitions inherent in that type of antenna mount and the pointing system.
	To avoid flying directly over the MTR, special circuits are included in the computer
	to fly the missile in a path skirting around a flight path over the MTR.
	This situation is normally avoided by placing the launching area toward the expected
	direction of enemy aircraft - but the battery can be effective in any case.
	</p><p>
    A full dive command (7 g's) is sent to the missile to dive it 
    from vertical toward horizontal.    When the missile has reached a vertical angle
    that will be a good (1/2 g) flight path to the intercept point, the 
    full dive command is removed and normal steering begins.   

    For a preview of the "<b>good flight path</b>", jump ahead to
    <a href="https://www.ed-thelen.org/flight.html#end_dive"> End of 7 G dive </a>.


</p><p>
   <a href="https://www.ed-thelen.org/Half-G-Lift-page-.png"><img src="https://www.ed-thelen.org/Half-G-Lift-page-t.jpg"></a>
    <a href="https://www.ed-thelen.org/Half-G-Lift-page65-.png"><img src="https://www.ed-thelen.org/Half-G-Lift-page65-t.jpg"></a>
  After the 7 g dive, the computer flies the missile on a
     <a href="https://www.ed-thelen.org/flight.html#end_dive">1/2 g flight path</a> to the predicted
   intercept point.
   For further details of the 1/2 g flight path, see  page 64 of 
   <a href="https://www.ed-thelen.org/tm9-5000-3.pdf">TM9-5000-3</a> (4.5 MBytes).
    </p><p>

 
    The predicted intercept point is constantly being updated by 
    the computer from data from the target tracking radar and 
    the missile tracking radar. Using the missile position from the Missile Tracking Radar,
    missile velocity and attitude generated in the computer, and the Predicted Intercept
    Point, the <b>computer generates analog steering commands in gravity units
	(g's) </b> for the missile.  These
    commands are sent to the Missile Tracking Radar, where the analog commands are
    converted into radar pulse sequences indicating the command to the missile.

</p><p>
    
    About 0.1 seconds before the missile will be closest to the 
    target, a missile burst command is send by a coded pulse 
    sequence to the missile by the missile tracking radar.   
    This burst command is decoded and the missile warhead exploded.
    The goal is to <b>explode the missile just before</b> (10 meters) the missile
    would impact (or be at the closest point with)  the aircraft.
    This way, the expanding blast of fragements goes through the space where
    the target aircraft would be - giving <b>maximum damage even if a near miss</b>.





</p></blockquote>   


<hr>

<span size="+2"><a name="Steering">
<u><b>7) Steering Command Details</b></u></a></span><a name="Steering"><br>
</a><blockquote><a name="Steering">

	The steering commands are basically to climb/dive and 
	turn left/right a given number of earth gravitational acceleration
	 units 	(g forces of fighter plane fame).  As an example,
 	the computer might command the missile to turn right at a
	rate of 1.0 g's.  The missile would adjust its fins to turn
	hard enough so that the left/right accelerometer would indicate
	1.0 g's right.<p>

	Actually the missile fins are 45 degrees from horizontal,
	 and the <b>accelerometers are also 45 degrees from horizontal</b>.
 	 The last stage of the <b>computer rotates the command</b> so that a 
	 1.0 g right command will be sent as 0.707 g up/right and 0.707 g down/right 
	 which will result in 1.0 g turn right. You do remember your high school
	 trig - don't you?  Oh yes, you must be a "rocket scientist".
	</p></a><p><a name="Steering">

	The missile steering commands are sent in analog form to the 
	Missile Tracking Radar electronics where they are converted to
	radar pulse pairs which  are received by the missile.
	For a description of the commands as they are sent by the Missile Tracking
	Radar see </a><a href="https://www.ed-thelen.org/ifc_track.html#mtr">Missile Tracking Radar</a>.
</p><p>
	About 0.1 second before 	intercept, a burst command is sent 
	to explode the missile and hopefully disable the target.
</p></blockquote>

<hr>			

<p><span size="+2"><a name="Plotting">
<u><b>8) About the Nike Plotting Boards</b></u></a></span>

</p><blockquote> 				             
There were 2 plotting boards
<ul>
   <li>Horizontal Plotting Board, with 2 pens<br>

       x,y - scale = +- 200,000 yards<br>     
   <ul>
     <li>one pen always plotted the target<br>

     </li><li>the other pen plotted <br>
     <ul>
     <li>predicted intercept until the missile is launched
     </li><li>missile position after missile is launched
     </li></ul>

     <!--DD-->

   </li></ul>
   </li><li>Altitude Plotting Board, with 2 pens
   <ul>   z,t - scale   0-100,000 feet,  0-160 seconds<br>

   <li>the left pen plotted the target altitude vs. time to intercept
   </li><li>the right pen plotted time to intercept vs.
   <ul>
     <li>predicted intercept altitude until the missile is launched
     </li><li>missile altitude after missile is launched
   </li></ul>

   <!--DD-->

</li></ul>
</li></ul>

<dd>

There were timing marks every 10 seconds. These were quick jogs up and right.<br>
A launch (fire) mark was a quick jog down and left. 

<p>
The horizontal plotting board had lights to identify which pen was plotting what.<br>

</p><p>
For a photo of the plotting boards, go to <a href="https://www.ed-thelen.org/t_tour.html#3200">

	Battery Commander's View of the World</a>.

  

</p></dd></blockquote>


<hr>
<p><span size="+2"><a name="parallax">

	<u><b>9) How does the computer know the radar offsets? </b></u></a></span>

</p><blockquote> 

The <b>Target Tracking Radar (TTR) is considered the center of the world</b>,
well at least as far as the computer and IFC people are concerned.
All distances are measured from the TTR.  Plotting board distances and elevations 
 are relative to the TTR.

<p>
The computer must know where the Missile Tracking Radar (MTR) is 
	relative to the Target Tracking Radar (TTR), 
and also the relative location of the Target Ranging Radar (TRR)
	relative to the Target Tracking Radar (TTR).
This permits the computer to subtract out the positional differences, so that
<b>all three radars are, for computational purposes, located at the same point
is space</b>. 

</p><p>
The offsets of the MTR and the TRR are dialed into potentiomenters located
on the computer.  The coordinates are as North/South, East/West, Up/Down from
the Target Tracking Radar.  Any errors dialed into these potentiometers will cause
errors in flying the missile to the exact position of the target.
</p><p>
The positional differences of the various acquisition radars are not important
because they are always within 50 yards of the TTR and errors in range and
parallax due to this offset do not affect operation (primarily the locking
on to the designated target by the TTR operators).   It is <b>important that 
the acquisition radars and the TTR (and any area supervision radars) have the 
same "North" reference</b> to within about a degree for more exact target designation.
(Which target is it?)


</p><p>

  	The Tracking Radars have the same North very precisely due to their
	alignment procedures.

 

 

</p></blockquote>
<hr>

<p><span size="+2"><a name="Fun">
<u><b>10) Gotta have a little fun</b></u></a></span> - Mechanical computers.
</p><blockquote>

You have been very good students - serious - no sleeping or whispering - taking notes 
<dd>- ready for a quiz?

<p>
I haven't the heart - time for fun.
<br>Tim Robinson makes analog computers for fun - out of Meccano building "blocks".

</p></dd><dd><a href="http://meccano.us/differential_analyzers/robinson_da/index.html">a differential analyzer</a> 
</dd><dd><a href="http://www.meccano.us/difference_engines/rde_2/index.html">a mini-Babbage machine</a> difference engine

</dd></blockquote>
<hr>

<p><span size="+2"><a name="S2S">
<u><b>11) The Surface to Surface mission/mode </b></u></a></span> 
</p><blockquote>
  In July 2013, CW2 Robin E. Smith reminded me that there is not much discussion of the Hercules surface to surface mode.
<br>OK - here goes what I can glean from the manuals ( way after my time ).
<p>
Attack surface targets below the radar horizon. 
	Dive straight down on a stationary target. The burst order causes guidance cutoff
	rather than an explosion.

<div>Image from TM9-1400-250-10-2 
<br>
	<a href="https://www.ed-thelen.org/TM9-1400-250-10-2-S2S-FD-.jpg"><img src="https://www.ed-thelen.org/TM9-1400-250-10-2-S2S-FD-t.jpg"></a>
	 
Text from MMS 150, 1-P7
<p>
(3)	Surface to surface mission. In a surface 
to surface mission (fig 7). the acquisition radars are not 
used because the target position is known. The range. 
azimuth, and elevation coordinates of the target are 
calculated and manually set into the TTR system. 
therefore, the TTR supplies constant target position data 
to the computer. Although the function of the computer 
system is similar to that described far a normal surface 
to air mission (a(1) above), the missile trajectory data 
must be manually set into the computer. This will, in 
turn, cause the missile to be guided toward a point in
space above the desired point of impact. When the 
missile reaches the space reference point, the computer 
system issues a dive order that will cause the missile to 
approach the ground target vertically. As the missile 
approaches the ground, the computer sends a burst order 
by means of the missile tracking system. Due to special 
missile preparation in a surface to surface mission, 
however, the burst order does not cause the missile 
warhead to detonate. Instead, the burst order disables 
the missile fail-safe mechanism and causes guidance cut-off
 by disabling the missile receiver. The burst order also 
arms a preset barometric fuze in the missile warhead and 
rolls the missile 180 degrees to compensate for any 
possible control surface misalignment The missile then 
follows a vertical trajectory until the barometric fuze 
causes the nuclear warhead to detonate at a predetermined 
altitude above the target.

</p></div>
</p><p> 
 
It doesn't take much imagination to figure that setting the TTR to  a particular azimuth, elevation, and range,
and firing a missile will cause the missile to get close to that point, and explode.  Even in the Ajax program
we thought that could be an interesting idea.  If the point is outside the "dead zone", a circle about 10,000 yards from
the launcher area, if you could see it, you could blast it.
</p><p>
The Improved Hercules used a separate "Surface to Surface" mission/mode for both the computer and the missile. 
This enabled Nike to hit what it couldn't see - among other things, the curvature of the earth.
</p><ol>
<li> There were formal instructions how to set up the TTR in azimuth, elevation, range from your map coordinates
	to the map coordinates of the target.

</li><li> To prevent the signal from the MTR being lost or distorted by ground clutter, the elevation angle
      was set to 5 mils above the MTR ground clutter at the TTR azimuth (above).
	 The MTR could track and guide the missile reliably,
	and the burst command (which was not interpreted by the missile as burst but as "command guidance cut-off")
 	would be reliably received by the missile
</li><li> A nomograph (<a href="https://www.ed-thelen.org/pics/rdr-hori-1.pdf">NOT identical to this one</a>) was available to aid calculations. Nomograph from http://www.tscm.com/rdr-hori.pdf
</li><li> <a href="mailto:rsmithcw2@aol.com">CW2 Robin E. Smith</a> was recognized as being expert in the above - 
	I don't have the details of the computations.
	<br>"In preparation for our mobile mission each unit in our battalion had to prepare to calculate a 
	surface to surface problem and set the radars and computer for firing. In the launching area there 
	were also tasks to be completed, but they were fairly simple and the IFC personnel who calculated the 
	fire mission gave them the information that the launcher crew had to set." 
</li><li> The missile was to be computer guided to be going "straight down" at burst signal time   
	<br> - note: "straight down" near the earth 100 miles away is over 1 degree different  
	<br> - CW2 Robin E. Smith said that "straight down" is relative to  the target, not the Nike site.


</li><li> The missile (before launch) was set into a special mode  
	<ul>
	<li> - a command burst was interpreted as command guidance cut-off
	</li><li> - after  command guidance cut-off, ??? missile guided internally along a 0 g path by its accelerometers ???
        </li><li> - burst was to be triggered by altitude (atmospheric pressure) only
		<br>- - In Europe, a nuclear warhead was assumed?
	</li></ul>
</li><li> Available manuals seem very vague about many useful and needed details - ? still classified ??
</li></ol>
<table>
<tbody><tr><td> Some computations assuming the target is 100 miles from the Nike site.
<br> Note that the tangent line from the Nike site is 1.24 miles above the target.
<br><span color="red"> Please note: These calculation needs to be checked by some competent person.
</span></td><td>
<a href="https://www.ed-thelen.org/S2S-computations-.jpg"><img src="https://www.ed-thelen.org/S2S-computations-t.jpg">
</a></td></tr></tbody></table>

</blockquote>
<hr>

<hr>
<a name="Chopper">
</a><p><a name="Chopper"><span size="+2">

<u><b>Appendix 1: Chopper Stabilized Operational Amplifiers (Op Amps)</b></u></span></a> 
<br><b><a href="#A1Background">Background</a></b> 
<br><b><a href="#A1Theory">Operation</a></b> 
<br><b><a href="#A1New">New (transistor) Zero Set Switch</a></b> 
<br><b><a href="#A1Old">Old (mechanical) Zero Set Switch </a></b> 





</p><blockquote> 
<b><a name="A1Background">Background</a></b>
<br><div>
It is very convenient to assume that Operational Amplifiers (Op Amps) for analog computers have
<dd>- infinite gain (with stability)

</dd><dd>- no input "offset" voltages or currents
 
<p>
Fortunately, they can be made very good so that for many problems errors can be held 
to less than say 0.01 percent per stage
</p></dd><dd>- the "offset" current to the grid of a good triode (or FET) in on the order of nano amps.
<p>

Unfortunately, efforts need to be made to reduce off-set <u>voltage</u> errors - An operational amplifier
is expected to have zero volts output when the input is zero volts. 
Failure to do this is called "off-set error".
Unfortunately, in real amplifiers, a large number of causes will cause voltage off-set errors
which must be continuously corrected.

</p><p>
A principle method of correcting voltage off-set error is to use automatic Zero Set equipment which:
  </p></dd><dd>- reduces "offset" voltage
  </dd><dd>- increases amplifier gain without decreasing  stability
<p>

You can <b><u>manually zero set an operational amplifier</u></b> by:


</p></dd><dd>- removing the amplifier output from the circuit (no feed back)

</dd><dd>- connecting the input of the amplifier to analog ground (zero volts)
</dd><dd>- measuring to output voltage
</dd><dd>- adjusting the amplifier zero set to achieve zero volts on the output
<br>then re-connecting the amplifier to the circuit for proper operation
</dd><dd>Unfortunately, temperatures, voltages and other conditions soon change, 
</dd><dd></dd><dd>and you must zero set again, and yet again.
</dd></div>
<p>



<b><a name="A1Theory">Operation</a></b>
<br><div>
Fortunately, a <b><u><a href="http://en.wikipedia.org/wiki/Operational_amplifier#1949:_First_chopper-stabilized_op-amp">
	good automatic method of zero setting operational amplifiers</a></u></b> was discovered - just in time for Nike.

<dd>- (leave the operational amplifier connected in the circuit  :-))
</dd><dd>- measure the voltage at the "summing junction", the input to the Op Amp


</dd><dd>- amplify this voltage by  200 (in the Zero Set Amplifier)
</dd><dd>&nbsp;&nbsp;&nbsp;&nbsp; ** if this voltage is excessive, a separate amplifier tube (in series) fires a warning neon lamp
</dd><dd>- apply this amplified voltage to the  Op Amp zero set input

<br>and do the above over and over again.
<p>
The voltage measurement and correction can be done in the AC world - which makes life easier  :-))
</p><ol>
<li>Connect the input grid of the Zero Set Amplifier to ground
</li><li>Connect the output capacitor of the Zero Set Amplifier to ground

<dd>The above steps, 1 &amp; 2, provide a zero reference on the output capacitor
</dd>
</li><li>Disconnect  the output capacitor of the Zero Set Amplifier from ground
</li><li>Disconnect the input grid of the Zero Set Amplifier from ground
</li><li>Connect the input grid of the Zero Set Amplifier to the summing junction (Op Amp input grid)

</li><li>Connect the output capacitor of the Zero Set Amplifier to the Op Amp zero set capacitor
<dd> The above 4 steps place a corrective charge on the Op Amp zero set capacitor
</dd>

</li><li>Disconnect the output capacitor of the Zero Set Amplifier from the Op Amp zero set capacitor
</li><li>Disconnect the input grid of the Zero Set Amplifier to the summing junction (Op Amp input grid)
<dd>Ready to start step one all over again
</dd>
</li></ol>
<br>With careful design, this switch (and system) can be very reliable, well shielded, with low electrical noise.
<p>
Further details about the Zero Set  
  are in the Technical Manual
   <a href="https://www.ed-thelen.org/TM9-5000-13-Ch04.pdf">TM9-5000-13-Ch04 Automatic Zero Setting Controls</a> 155 KBytes
</p><p>
 from another source
<p>
<img src="https://www.ed-thelen.org/pics3/ZeroSetText.jpg">
</p>
</p></dd></div>

</p><p> 
<b><a name="A1New">
<br>New (transistor) Zero Set Switch</a></b>
<br>

 <a name="A1Old">  
<br><b>Old Style (Mechanical) Zero Set Switch</b>  ? Ajax only ?
 <div>
 <table>
<tbody><tr><td>

This is the old style (rotory) zero set switch, capabable of zero setting twelve operational 
	amplifiers.   The black button on the bottom is a test switch, indicates all 12 failed
	zero set.
</td><td><a href="https://www.ed-thelen.org/ZeroSetOld-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOld-t.jpg">
</a></td><td>With the cover off. You can see the 12 plus 12 contact switches, and the lucite plastic
	that carries the light from the overload neon lamp to the correct window
	to indicate which amplifier is in trouble.
</td><td><a href="https://www.ed-thelen.org/ZeroSetOldCoverOff-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOldCoverOff-t.jpg">
</a></td></tr><tr>
<td>This is the back of the zero set cover, with the neon Overload Error Indicator Lamp. 
	This lamp fires at about 80 volts and is driven by a separate vacuum tube.
     A plastic piece (see previous picture) picks up this light and carries it to the appropriate window.
</td><td><a href="https://www.ed-thelen.org/ZeroSetOldCoverBack-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOldCoverBack-t.jpg">
</a></td><td>Details of the - contact roller, contact switches, plastic to carry the light from
the Overload error lamp to the  appropriate window

</td><td><a href="https://www.ed-thelen.org/ZeroSetOldRotorDetail-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOldRotorDetail-t.jpg">
</a></td></tr><tr>
<td>This 400 cycle motor (and gearing)  drives the rotor in the Zero Set Switch at about
	two revolutions per second. Given the symetry of the switch, each Op Amp is zero set
	about twice per second. Note the co-ax to protect the nulling point from stray voltages.
</td><td><a href="https://www.ed-thelen.org/ZeroSetOldMotor-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOldMotor-t.jpg">
</a></td><td>Zero Set Switch Motor Name Plate
	<br>Note the 2 Phase indication, this can be easily derived from the 3 phase main voltages.
</td><td><a href="https://www.ed-thelen.org/ZeroSetOldMotorNamePlate-.jpg"><img src="https://www.ed-thelen.org/ZeroSetOldMotorNamePlate-.jpg" height="100">

</a></td></tr></tbody></table>
<p>
Norman Paik (a Nike class mate, who served on Rattle Snake Mountain, above Hanford, Washington) reports 
- "With a little bit of wear or corrosion, these switches were prone to sticking which would, in fact, depending on how they stuck, introduce errors into the analog computations.  Great fun."
</p><p>
Could it have been dust?? dry air?? - On the Chicago water front we had no trouble with the
mechanical zero set switches.
</p></div>







 
</a></p><hr><a name="A1Old">

 

 

</a></blockquote><a name="A1Old">
<hr>


</a><a name="Resistors">
</a><p><a name="Resistors"><span size="+2">

<u><b>Appendix 2: Precision Gain Setting Resistors</b></u></span></a>  
</p><blockquote>

<div>

We are familiar with the usual carbon composition and wire wound resistors,
  with the stated tolerances of 10% to 1%.
<p>
These are not nearly accurate enough (nor stable enough) for gain setting resistors in a Nike system
with a system error budget of say 20 feet in 25 miles between  the errors of the two tracking radars 
and the various gain sensitive operational amplifiers in the computer.
</p><p>just for the sake of argument, let us  allow error budgets of:
</p><dd>- 7 feet to the Missile Tracking Radar subsystem
</dd><dd>- 7 feet to the Target Tracking Radar(s subsystem)

</dd><dd>- 7 feet to the computer subsystem
<br>at a range of 25 miles.

<p>
Friends, those are tight tolerances !!  No room for slop anywhere -
The gains of the Missile Tracking and Target Tracking radars in X, Y, and Height must be as identical (and correct) as possible.

</p><p>
An Op Amp gain is determined by the <b><u>RATIO</u></b> of the (feedback resistor)/(input resistor).
 [Assuming of course adequate amplifier gain.]  If the feedback resistor
is 0.1% low, the input resistor must be an identical 0.1% low.
This correct and stable RATIO is attained by several paths:



</p><ol>

<li> Careful precision matching during resistor network manufacture. This is done by selecting and trimming
	precision resistors monitored by a precision resistor bridge.
</li><li> Minimal changes in resistance due to temperature changes. This is attained by using wire wound resistors
	of low temperature coefficient metal - and non-stress packaging.
</li><li> 
	<table>
	<tbody><tr><td> <a href="https://www.ed-thelen.org/NikeComputerNetworks-.jpg"><img src="https://www.ed-thelen.org/NikeComputerNetworks-t.jpg"></a>

	</td><td>Packaging each resistor network so that each resistor is the same temperature as every other resistor
	in the packaged network. This is accomplished by placing the input and feedback resistors  of each
	op amp into a separate aluminum container so that they get warm and cool together. A draft in the
	computer cabinet should affect all the resistors of an op amp "identically".  The RATIO should
	be maintained.
	</td></tr></tbody></table>

</li></ol>
</dd></div>
</blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Senator: What Do Our Cars Know? and Who Do They Share That Information With? (122 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/12/us-senator-what-do-our-cars-know-and-who-do-they-share-information</link>
            <guid>38504686</guid>
            <pubDate>Sun, 03 Dec 2023 03:57:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/12/us-senator-what-do-our-cars-know-and-who-do-they-share-information">https://www.eff.org/deeplinks/2023/12/us-senator-what-do-our-cars-know-and-who-do-they-share-information</a>, See on <a href="https://news.ycombinator.com/item?id=38504686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>U.S. Senator Ed Markey of Massachusetts has sent a much-needed </span><a href="https://www.markey.senate.gov/imo/media/doc/senator_markey_letter_to_automakers_on_privacy.pdf"><span>letter</span></a><span> to car manufacturers asking them to clarify a surprisingly hard question to answer: what data cars collect? Who has the ability to access that data? Private companies can often be a black box of secrecy that obscure basic facts of the consumer electronics we use. This becomes a massive problem when the devices become more technologically sophisticated and capable of collecting audio, video, geolocation data, as well as biometric information. As the letter says, <br></span></p>
<p><span>“</span><span>As cars increasingly become high-tech computers on wheels, they produce vast amounts of data on drivers, passengers, pedestrians, and other motorists, creating the potential for severe privacy violations. This data could reveal sensitive personal information, including location history and driving behavior, and can help data brokers develop detailed data profiles on users.” <br></span></p>
<p><span>Not only does the letter articulate the privacy harms imposed by vehicles (and trust us, cars are some of the </span><a href="https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/"><span>least privacy-oriented devices on the market</span></a><span>), it also asks probing questions of companies regarding what data is collected, who has access, particulars about how and for how long data is stored, whether data is sold, and how consumers and the public can go about requesting the deletion of that data. <br></span></p>
<p><span>Also essential are the questions concerning the relationship between car companies and law enforcement. We know, for instance, that self-driving car companies have also built relationships with police and have </span><a href="https://www.bloomberg.com/news/articles/2023-06-29/self-driving-car-video-from-waymo-cruise-give-police-crime-evidence?in_source=embedded-checkout-banner"><span>given footage, on a number of occasions, to law enforcement to aid in investigations</span></a><span>. Likewise both Tesla </span><a href="https://www.aclu.org/news/privacy-technology/tesla-camera-scandal-is-the-latest-lesson-in-dangers-of-letting-companies-record-you"><span>employees</span></a><span> and </span><a href="https://www.kcra.com/article/tesla-video-break-in-fairfield-police-quickly-id-suspect/28778086"><span>law enforcement</span></a><span> had been given or gained access to footage from the electric vehicles. <br></span></p>
<p><span>A push for public transparency by members of Congress is essential and a necessary first step toward some much needed regulation. </span><a href="https://www.eff.org/deeplinks/2023/08/impending-privacy-threat-self-driving-cars"><span>Self-driving cars, cars with autonomous modes</span></a><span>, or even just cars connected to the internet and equipped with cameras pose a vital threat to privacy, not just to drivers and passengers, but also to other motorists on the road and pedestrians who are forced to walk past these cars every day. We commend Senator Markey for this letter and hope that the companies respond quickly and honestly so we can have a better sense of what needs to change.&nbsp;</span></p>
<p><span>You can read the letter </span><a href="https://www.eff.org/document/markey-car-letter"><span>here</span></a><span>.&nbsp;</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new approach to domain ranking (192 pts)]]></title>
            <link>https://www.marginalia.nu/log/73-new-approach-to-ranking/</link>
            <guid>38504565</guid>
            <pubDate>Sun, 03 Dec 2023 03:34:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marginalia.nu/log/73-new-approach-to-ranking/">https://www.marginalia.nu/log/73-new-approach-to-ranking/</a>, See on <a href="https://news.ycombinator.com/item?id=38504565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>This is a very brief post announcing a fascinating discovery.</p><p>It appears to be possible to use the cosine similarity approach powering explore2.marginalia.nu as a substitute for the link graph in an eigenvector-based ranking algorithm (i.e. PageRank).</p><p>The original PageRank algorithm can be conceptualized as a simulation of where a random visitor would end up if they randomly clicked links on websites. With this model in mind, the modification replaces the link-clicking with using explore2 for navigation.</p><p>The performance of PageRank has been deteriorating for decades and it’s to a point where it barely is applicable for domain ranking anymore in part due to changes in how websites link to each other, but also a battery of well documented techniques for manipulating the algorithm in order to gain an unfair advantage. You may get decent results at the very top especially with personalized pagerank, but you don’t have to scroll particularly far down in the ranking to find spam earning a conspicuously high ranking using a vanilla pagerank approach.</p><p>This new approach seems remarkably resistant to existing pagerank manipulation techniques. Given a preference-vector, it stays “on topic” remarkably well.</p><ul><li><a href="https://www.marginalia.nu/domains/">Explore Sample Data</a></li></ul><h2 id="see-also">See Also</h2><ul><li><a href="https://www.marginalia.nu/log/69-creepy-website-similarity.gmi">/log/69-creepy-website-similarity.gmi</a></li><li><a href="https://www.marginalia.nu/log/20-dot-com-link-farms.gmi">/log/20-dot-com-link-farms.gmi</a></li><li><a href="https://www.marginalia.nu/log/04-link-farms.gmi">/log/04-link-farms.gmi</a></li></ul></div></div>]]></description>
        </item>
    </channel>
</rss>