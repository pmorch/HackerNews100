<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 08 Sep 2024 06:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GPT-fabricated scientific papers on Google Scholar (109 pts)]]></title>
            <link>https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/</link>
            <guid>41477516</guid>
            <pubDate>Sun, 08 Sep 2024 01:15:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/">https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/</a>, See on <a href="https://news.ycombinator.com/item?id=41477516">Hacker News</a></p>
<div id="readability-page-1" class="page">
	<!-- Google Tag Manager (noscript) -->
	
	<!-- End Google Tag Manager (noscript) -->
	<a href="#main-content">Skip to main content</a>
	<header role="banner">
		

		

	</header>
	<section id="main-content" role="main">
	
	<article>

		<div>

			<header>
				
				
				
				
				<p>Peer Reviewed</p>				

			</header>
			
			<div>
				<div><h6>Article Metrics</h6><div><div><p><img src="https://misinforeview.hks.harvard.edu/wp-content/themes/ristretto/img/crossref-logo.png" alt="CrossRef" height="30" width="29"></p><p>0</p></div><p>CrossRef Citations</p></div></div>				
<div><p><em>Academic journals, archives, and repositories are seeing an increasing number of questionable research papers clearly produced using generative AI. They are often created with widely available, general-purpose AI applications, most likely ChatGPT, and mimic scientific writing. Google Scholar easily locates and lists these questionable papers alongside reputable, quality-controlled research. Our analysis of a selection of questionable GPT-fabricated scientific papers found in Google Scholar shows that many are about applied, often controversial topics susceptible to disinformation: the environment, health, and computing. The resulting enhanced potential for malicious manipulation of society’s evidence base, particularly in politically divisive domains, is a growing concern.</em></p></div>




<div id="bylines-block_c6a68959a4398404ccfdd7743d1b0768">
    <div><p><a href="https://misinforeview.hks.harvard.edu/article/author/jutta-haider" title="Posts by Jutta Haider" rel="author">Jutta Haider</a></p><p>Swedish School of Library and Information Science, University of Borås, Sweden</p></div><div><p><a href="https://misinforeview.hks.harvard.edu/article/author/bjorn-ekstrom" title="Posts by Björn Ekström" rel="author">Björn Ekström</a></p><p>Swedish School of Library and Information Science, University of Borås, Sweden</p></div><div><p><a href="https://misinforeview.hks.harvard.edu/article/author/malte-rodl" title="Posts by Malte Rödl" rel="author">Malte Rödl</a></p><p>Division of Environmental Communication, Swedish University of Agricultural Sciences, Sweden</p></div>    </div>



<figure><img fetchpriority="high" decoding="async" width="1080" height="721" src="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/chat-gpt-8282265_1280-copy.png" alt="" srcset="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/chat-gpt-8282265_1280-copy.png 1080w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/chat-gpt-8282265_1280-copy-300x200.png 300w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/chat-gpt-8282265_1280-copy-1024x684.png 1024w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/chat-gpt-8282265_1280-copy-768x513.png 768w" sizes="(max-width: 1080px) 100vw, 1080px"><figcaption>image by&nbsp;<a href="https://pixabay.com/users/viarami-13458823/" title="">viarami</a>&nbsp;on&nbsp;<a href="https://pixabay.com/">pixabay</a></figcaption></figure>



<div>
<h2>Research Questions</h2>



<ul>
<li>Where are questionable publications produced with generative pre-trained transformers (GPTs) that can be found via Google Scholar published or deposited?</li>



<li>What are the main characteristics of these publications in relation to predominant subject categories?</li>



<li>How are these publications spread in the research infrastructure for scholarly communication?</li>



<li>How is the role of the scholarly communication infrastructure challenged in maintaining public trust in science and evidence through inappropriate use of generative AI?</li>
</ul>



<h2>research note Summary</h2>



<ul>
<li>A sample of scientific papers with signs of GPT-use found on Google Scholar was retrieved, downloaded, and analyzed using a combination of qualitative coding and descriptive statistics. All papers contained at least one of two common phrases returned by conversational agents that use large language models (LLM) like OpenAI’s ChatGPT. Google Search was then used to determine the extent to which copies of questionable, GPT-fabricated papers were available in various repositories, archives, citation databases, and social media platforms.</li>



<li>Roughly two-thirds of the retrieved papers were found to have been produced, at least in part, through undisclosed, potentially deceptive use of GPT. The majority (57%) of these questionable papers dealt with policy-relevant subjects (i.e., environment, health, computing), susceptible to influence operations. Most were available in several copies on different domains (e.g., social media, archives, and repositories).</li>



<li>Two main risks arise from the increasingly common use of GPT to (mass-)produce fake, scientific publications. First, the abundance of fabricated “studies” seeping into all areas of the research infrastructure threatens to overwhelm the scholarly communication system and jeopardize the integrity of the scientific record. A second risk lies in the increased possibility that convincingly scientific-looking content was in fact deceitfully created with AI tools and is also optimized to be retrieved by publicly available academic search engines, particularly Google Scholar. However small, this possibility and awareness of it risks undermining the basis for trust in scientific knowledge and poses serious societal risks.</li>
</ul>
</div>



<hr>



<h2>Implications</h2>



<p>The use of ChatGPT to generate text for academic papers has raised concerns about research integrity. Discussion of this phenomenon is ongoing in editorials, commentaries, opinion pieces, and on social media (Bom, 2023; Stokel-Walker, 2024; Thorp, 2023). There are now several lists of papers suspected of GPT misuse, and new papers are constantly being added.<sup data-mfn="1" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">1</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-1" role="tooltip" tabindex="0" data-mfn="1">See for example Academ-AI, <a href="https://www.academ-ai.info/">https://www.academ-ai.info/</a>, and Retraction Watch, <a href="https://retractionwatch.com/papers-and-peer-reviews-with-evidence-of-chatgpt-writing/">https://retractionwatch.com/papers-and-peer-reviews-with-evidence-of-chatgpt-writing/</a>.</span> While many legitimate uses of GPT for research and academic writing exist (Huang &amp; Tan, 2023; Kitamura, 2023; Lund et al., 2023), its undeclared use—beyond proofreading—has potentially far-reaching implications for both science and society, but especially for their relationship. It, therefore, seems important to extend the discussion to one of the most accessible and well-known intermediaries between science, but also certain types of misinformation, and the public, namely Google Scholar, also in response to the legitimate concerns that the discussion of generative AI and misinformation needs to be more nuanced and empirically substantiated&nbsp; (Simon et al., 2023).</p>



<p>Google Scholar, <a href="https://scholar.google.com/">https://scholar.google.com</a>, is an easy-to-use academic search engine. It is available for free, and its index is extensive (Gusenbauer &amp; Haddaway, 2020). It is also often touted as a credible source for academic literature and even recommended in library guides, by media and information literacy initiatives, and fact checkers (Tripodi et al., 2023). However, Google Scholar lacks the transparency and adherence to standards that usually characterize citation databases. Instead, Google Scholar uses automated crawlers, like Google’s web search engine (Martín-Martín et al., 2021), and the inclusion criteria are based on primarily technical standards, allowing any individual author—with or without scientific affiliation—to upload papers to be indexed (Google Scholar Help, n.d.). It has been shown that Google Scholar is susceptible to manipulation through citation exploits (Antkare, 2020) and by providing access to fake scientific papers (Dadkhah et al., 2017). A large part of Google Scholar’s index consists of publications from established scientific journals or other forms of quality-controlled, scholarly literature. However, the index also contains a large amount of gray literature, including student papers, working papers, reports, preprint servers, and academic networking sites, as well as material from so-called “questionable” academic journals, including paper mills. The search interface does not offer the possibility to filter the results meaningfully by material type, publication status, or form of quality control, such as limiting the search to peer-reviewed material.</p>



<p>To understand the occurrence of ChatGPT (co-)authored work in Google Scholar’s index, we scraped it for publications, including one of two common ChatGPT responses (see Appendix A) that we encountered on social media and in media reports (DeGeurin, 2024). The results of our descriptive statistical analyses showed that around 62% did not declare the use of GPTs. Most of these GPT-fabricated papers were found in non-indexed journals and working papers, but some cases included research published in mainstream scientific journals and conference proceedings.<sup data-mfn="2" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">2</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-2" role="tooltip" tabindex="0" data-mfn="2">Indexed journals mean scholarly journals indexed by abstract and citation databases such as Scopus and Web of Science, where the indexation implies journals with high scientific quality. Non-indexed journals are journals that fall outside of this indexation.</span> More than half (57%) of these GPT-fabricated papers concerned policy-relevant subject areas susceptible to influence operations. To avoid increasing the visibility of these publications, we abstained from referencing them in this research note. However, we have made the data available in the Harvard Dataverse repository.</p>



<p>The publications were related to three issue areas—health (14.5%), environment (19.5%) and computing (23%)—with key terms such “healthcare,” “COVID-19,” or “infection”for health-related papers, and “analysis,” “sustainable,” and “global” for environment-related papers. In several cases, the papers had titles that strung together general keywords and buzzwords, thus alluding to very broad and current research. These terms included “biology,” “telehealth,” “climate policy,” “diversity,” and “disrupting,” to name just a few.&nbsp; While the study’s scope and design did not include a detailed analysis of which parts of the articles included fabricated text, our dataset did contain the surrounding sentences for each occurrence of the suspicious phrases that formed the basis for our search and subsequent selection. Based on that, we can say that the phrases occurred in most sections typically found in scientific publications, including the literature review, methods, conceptual and theoretical frameworks, background, motivation or societal relevance, and even discussion. This was confirmed during the joint coding, where we read and discussed all articles. It became clear that not just the text related to the telltale phrases was created by GPT, but that almost all articles in our sample of questionable articles likely contained traces of GPT-fabricated text everywhere.</p>



<p><em>Evidence hacking and backfiring effects</em></p>



<p>Generative pre-trained transformers (GPTs) can be used to produce texts that mimic scientific writing. These texts, when made available online—as we demonstrate—leak into the databases of academic search engines and other parts of the research infrastructure for scholarly communication. This development exacerbates problems that were already present with less sophisticated text generators (Antkare, 2020; Cabanac &amp; Labbé, 2021). Yet, the public release of ChatGPT in 2022, together with the way Google Scholar works, has increased the likelihood of lay people (e.g., media, politicians, patients, students) coming across questionable (or even entirely GPT-fabricated) papers and other problematic research findings. Previous research has emphasized that the ability to determine the value and status of scientific publications for lay people is at stake when misleading articles are passed off as reputable (Haider &amp; Åström, 2017) and that systematic literature reviews risk being compromised (Dadkhah et al., 2017). It has also been highlighted that Google Scholar, in particular, can be and has been exploited for manipulating the evidence base for politically charged issues and to fuel conspiracy narratives (Tripodi et al., 2023). Both concerns are likely to be magnified in the future, increasing the risk of what we suggest calling <em>evidence hacking</em>—the strategic and coordinated malicious manipulation of society’s evidence base.</p>



<p>The authority of quality-controlled research as evidence to support legislation, policy, politics, and other forms of decision-making is undermined by the presence of undeclared GPT-fabricated content in publications professing to be scientific. Due to the large number of archives, repositories, mirror sites, and shadow libraries to which they spread, there is a clear risk that GPT-fabricated, questionable papers will reach audiences even after a possible retraction. There are considerable technical difficulties involved in identifying and tracing computer-fabricated papers (Cabanac &amp; Labbé, 2021; Dadkhah et al., 2023; Jones, 2024), not to mention preventing and curbing their spread and uptake.</p>



<p>However, as the rise of the so-called anti-vaxx movement during the COVID-19 pandemic and the ongoing obstruction and denial of climate change show, retracting erroneous publications often fuels conspiracies and increases the following of these movements rather than stopping them. To illustrate this mechanism, climate deniers frequently question established scientific consensus by pointing to other, supposedly scientific, studies that support their claims. Usually, these are poorly executed, not peer-reviewed, based on obsolete data, or even fraudulent (Dunlap &amp; Brulle, 2020). A similar strategy is successful in the alternative epistemic world of the global anti-vaccination movement (Carrion, 2018) and the persistence of flawed and questionable publications in the scientific record already poses significant problems for health research, policy, and lawmakers, and thus for society as a whole (Littell et al., 2024). Considering that a person’s support for “doing your own research” is associated with increased mistrust in scientific institutions (Chinn &amp; Hasell, 2023), it will be of utmost importance to anticipate and consider such backfiring effects already when designing a technical solution, when suggesting industry or legal regulation, and in the planning of educational measures.</p>



<p><em>Recommendations</em></p>



<p>Solutions should be based on simultaneous considerations of technical, educational, and regulatory approaches, as well as incentives, including social ones, across the entire research infrastructure. Paying attention to how these approaches and incentives relate to each other can help identify points and mechanisms for disruption. Recognizing fraudulent academic papers must happen alongside understanding how they reach their audiences and what reasons there might be for some of these papers successfully “sticking around.” A possible way to mitigate some of the risks associated with GPT-fabricated scholarly texts finding their way into academic search engine results would be to provide filtering options for facets such as indexed journals, gray literature, peer-review, and similar on the interface of publicly available academic search engines. Furthermore, evaluation tools for indexed journals<sup data-mfn="3" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">3</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-3" role="tooltip" tabindex="0" data-mfn="3">Such as LiU Journal CheckUp, <a href="https://ep.liu.se/JournalCheckup/default.aspx?lang=eng">https://ep.liu.se/JournalCheckup/default.aspx?lang=eng</a>.</span> could be integrated into the graphical user interfaces and the crawlers of these academic search engines. To enable accountability, it is important that the index (database) of such a search engine is populated according to criteria that are transparent, open to scrutiny, and appropriate to the workings of &nbsp;science and other forms of academic research. Moreover, considering that Google Scholar has no real competitor, there is a strong case for establishing a freely accessible, non-specialized academic search engine that is not run for commercial reasons but for reasons of public interest. Such measures, together with educational initiatives aimed particularly at policymakers, science communicators, journalists, and other media workers, will be crucial to reducing the possibilities for and effects of malicious manipulation or evidence hacking. It is important not to present this as a technical problem that exists only because of AI text generators but to relate it to the wider concerns in which it is embedded. These range from a largely dysfunctional scholarly publishing system (Haider &amp; Åström, 2017) and academia’s “publish or perish” paradigm to Google’s near-monopoly and ideological battles over the control of information and ultimately knowledge. Any intervention is likely to have systemic effects; these effects need to be considered and assessed in advance and, ideally, followed up on.</p>



<p>Our study focused on a selection of papers that were easily recognizable as fraudulent. We used this relatively small sample as a magnifying glass to examine, delineate, and understand a problem that goes beyond the scope of the sample itself, which however points towards larger concerns that require further investigation. The work of ongoing whistleblowing initiatives<sup data-mfn="4" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">4</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-4" role="tooltip" tabindex="0" data-mfn="4">Such as Academ-AI, <a href="https://www.academ-ai.info/">https://www.academ-ai.info/</a>, and Retraction Watch, <a href="https://retractionwatch.com/papers-and-peer-reviews-with-evidence-of-chatgpt-writing/">https://retractionwatch.com/papers-and-peer-reviews-with-evidence-of-chatgpt-writing/</a>.</span>, recent media reports of journal closures (Subbaraman, 2024), or GPT-related changes in word use and writing style (Cabanac et al., 2021; Stokel-Walker, 2024) suggest that we only see the tip of the iceberg. There are already more sophisticated cases (Dadkhah et al., 2023) as well as cases involving fabricated images (Gu et al., 2022). Our analysis shows that questionable and potentially manipulative GPT-fabricated papers permeate the research infrastructure and are likely to become a widespread phenomenon. Our findings underline that the risk of fake scientific papers being used to maliciously manipulate evidence (see Dadkhah et al., 2017) must be taken seriously. Manipulation may involve undeclared automatic summaries of texts, inclusion in literature reviews, explicit scientific claims, or the concealment of errors in studies so that they are difficult to detect in peer review. However, the mere possibility of these things happening is a significant risk in its own right that can be strategically exploited and will have ramifications for trust in and perception of science. Society’s methods of evaluating sources and the foundations of media and information literacy are under threat and public trust in science is at risk of further erosion, with far-reaching consequences for society in dealing with information disorders. To address this multifaceted problem, we first need to understand why it exists and proliferates.</p>



<h2>Findings</h2>



<p><em>Finding 1: 139 GPT-fabricated, questionable papers were found and listed as regular results on the Google Scholar results page. Non-indexed journals dominate.</em></p>



<p>Most questionable papers we found were in non-indexed journals or were working papers, but we did also find some in established journals, publications, conferences, and repositories. We found a total of 139 papers with a suspected deceptive use of ChatGPT or similar LLM applications (see Table 1). Out of these, 19 were in indexed journals, 89 were in non-indexed journals, 19 were student papers found in university databases, and 12 were working papers (mostly in preprint databases). Table 1 divides these papers into categories. Health and environment papers made up around 34% (47) of the sample. Of these, 66% were present in non-indexed journals.</p>



<figure><table><tbody><tr><td><strong>Paper category</strong></td><td><strong>Computing</strong></td><td><strong>Environment</strong></td><td><strong>Health</strong></td><td><strong>Others</strong></td><td><strong>Total</strong></td></tr><tr><td>Indexed journals*</td><td>5</td><td>3</td><td>4</td><td>7</td><td>19</td></tr><tr><td>Non-indexed journals</td><td>18</td><td>18</td><td>13</td><td>40</td><td>89</td></tr><tr><td>Student papers</td><td>4</td><td>3</td><td>1</td><td>11</td><td>19</td></tr><tr><td>Working papers</td><td>5</td><td>3</td><td>2</td><td>2</td><td>12</td></tr><tr><td>Total</td><td>32</td><td>27</td><td>20</td><td>60</td><td>139</td></tr></tbody></table><figcaption><strong>Table 1.</strong> <em>Number of papers across topics and venues using ChatGPT fraudulently or undeclared.</em> <br><em>* Indexed by Scopus, Norwegian register for scientific journals, series and publishers, WoS and/or DOAJ.</em></figcaption></figure>



<p><em>Finding 2: GPT-fabricated, questionable papers are disseminated online, permeating the research infrastructure for scholarly communication, often in multiple copies. Applied topics with practical implications dominate.</em></p>



<p>The 20 papers concerning health-related issues are distributed across 20 unique domains, accounting for 46 URLs. The 27 papers dealing with environmental issues can be found across 26 unique domains, accounting for 56 URLs.&nbsp; Most of the identified papers exist in multiple copies and have already spread to several archives, repositories, and social media. It would be difficult, or impossible, to remove them from the scientific record.</p>



<p>As apparent from Table 2, GPT-fabricated, questionable papers are seeping into most parts of the online research infrastructure for scholarly communication. Platforms on which identified papers have appeared include ResearchGate, ORCiD, Journal of Population Therapeutics and Clinical Pharmacology (JPTCP), Easychair, Frontiers, the Institute of Electrical and Electronics Engineer (IEEE), and X/Twitter. Thus, even if they are retracted from their original source, it will prove very difficult to track, remove, or even just mark them up on other platforms. Moreover, unless regulated, Google Scholar will enable their continued and most likely unlabeled discoverability.</p>



<figure><table><tbody><tr><td><strong>Subject</strong></td><td><strong>1</strong></td><td><strong>2</strong></td><td><strong>3</strong></td><td><strong>4</strong></td><td><strong>5</strong></td></tr><tr><td>Environment</td><td>researchgate.net (13)</td><td>orcid.org (4)</td><td>easychair.org (3)</td><td>ijope.com* (3)</td><td>publikasiindonesia.id (3)</td></tr><tr><td>Health</td><td>researchgate.net (15)</td><td>ieee.org (4)</td><td>twitter.com (3)</td><td>jptcp.com** (2)</td><td>frontiersin.org<br>(2)</td></tr></tbody></table><figcaption><strong>Table 2. </strong><em>Top domains by subject.</em> <em>* International Journal of Open Publication and Exploration (ISSN: 3006-2853)</em><br><em>** The Journal of Population Therapeutics and Clinical Pharmacology (ISSN 2561-8741)</em><br><em>Note: We removed the original publication URL to avoid double counting.</em></figcaption></figure>



<p>A word rain visualization (Centre for Digital Humanities Uppsala, 2023), which combines word prominences through TF-IDF<sup data-mfn="5" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">5</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-5" role="tooltip" tabindex="0" data-mfn="5"><em>Term frequency–inverse document frequency</em>, a method for measuring the significance of a word in a document compared to its frequency across all documents in a collection.</span> scores with semantic similarity of the full texts of our sample of GPT-generated articles that fall into the “Environment” and “Health” categories, reflects the two categories in question. However, as can be seen in Figure 1, it also reveals overlap and sub-areas. The y-axis shows word prominences through word positions and font sizes, while the x-axis indicates semantic similarity. In addition to a certain amount of overlap, this reveals sub-areas, which are best described as two distinct events within the word rain. The event on the left bundles terms related to the development and management of health and healthcare with “challenges,” “impact,” and “potential of artificial intelligence”emerging as semantically related terms. Terms related to research infrastructures, environmental, epistemic, and technological concepts are arranged further down in the same event (e.g., “system,” “climate,” “understanding,” “knowledge,” “learning,” “education,” “sustainable”). A second distinct event further to the right bundles terms associated with fish farming and aquatic medicinal plants, highlighting the presence of an aquaculture cluster.&nbsp; Here, the prominence of groups of terms such as “used,” “model,” “-based,” and “traditional” suggests the presence of applied research on these topics. The two events making up the word rain visualization, are linked by a less dominant but overlapping cluster of terms related to “energy” and “water.”</p>



<figure><img decoding="async" width="1920" height="1778" src="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1.png" alt="" srcset="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1.png 1920w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1-300x278.png 300w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1-1024x948.png 1024w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1-768x711.png 768w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-1-1536x1422.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption><strong>Figure 1. </strong><em>Word rain of environment- and health-related GPT-fabricated, questionable full-text papers.</em></figcaption></figure>



<p>The bar chart of the terms in the paper subset (see Figure 2) complements the word rain visualization by depicting the most prominent terms in the full texts along the y-axis. Here, word prominences across health and environment papers are arranged descendingly, where values outside parentheses are TF-IDF values (relative frequencies) and values inside parentheses are raw term frequencies (absolute frequencies).</p>



<figure><img decoding="async" width="1920" height="1228" src="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2.png" alt="" srcset="https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2.png 1920w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2-300x192.png 300w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2-1024x655.png 1024w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2-768x491.png 768w, https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/09/figure-2-1536x982.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption><strong>Figure 2.</strong> <em>Most prominent terms in environment- and health-related GPT-fabricated, questionable full-text papers.</em></figcaption></figure>



<p><em>Finding 3: Google Scholar presents results from quality-controlled and non-controlled citation databases on the same interface, providing unfiltered access to GPT-fabricated questionable papers.</em></p>



<p>Google Scholar’s central position in the publicly accessible scholarly communication infrastructure, as well as its lack of standards, transparency, and accountability in terms of inclusion criteria, has potentially serious implications for public trust in science. This is likely to exacerbate the already-known potential to exploit Google Scholar for evidence hacking (Tripodi et al., 2023) and will have implications for any attempts to retract or remove fraudulent papers from their original publication venues. Any solution must consider the entirety of the research infrastructure for scholarly communication and the interplay of different actors, interests, and incentives.</p>



<h2>Methods</h2>



<p>We searched and scraped Google Scholar using the Python library Scholarly (Cholewiak et al., 2023) for papers that included specific phrases known to be common responses from ChatGPT and similar applications with the same underlying model (GPT3.5 or GPT4): “as of my last knowledge update” and/or “I don’t have access to real-time data” (see Appendix A). This facilitated the identification of papers that likely used generative AI to produce text, resulting in 227 retrieved papers. The papers’ bibliographic information was automatically added to a spreadsheet and downloaded into Zotero.<sup data-mfn="6" data-mfn-post-scope="000000005b026c12000000004dba4ff5_13165">6</sup><span id="mfn-content-000000005b026c12000000004dba4ff5_13165-6" role="tooltip" tabindex="0" data-mfn="6">An open-source reference manager, <a href="https://zotero.org/">https://zotero.org</a>.</span> </p>



<p>We employed multiple coding (Barbour, 2001) to classify the papers based on their content. First, we jointly assessed whether the paper was suspected of fraudulent use of ChatGPT (or similar) based on how the text was integrated into the papers and whether the paper was presented as original research output or the AI tool’s role was acknowledged. Second, in analyzing the content of the papers, we continued the multiple coding by classifying the fraudulent papers into four categories identified during an initial round of analysis—health, environment, computing, and others—and then determining which subjects were most affected by this issue (see Table 1). Out of the 227 retrieved papers, 88 papers were written with legitimate and/or declared use of GPTs (i.e., false positives, which were excluded from further analysis), and 139 papers were written with undeclared and/or fraudulent use (i.e., true positives, which were included in further analysis). The multiple coding was conducted jointly by all authors of the present article, who collaboratively coded and cross-checked each other’s interpretation of the data simultaneously in a shared spreadsheet file. This was done to single out coding discrepancies and settle coding disagreements, which in turn ensured methodological thoroughness and analytical consensus (see Barbour, 2001). Redoing the category coding later based on our established coding schedule, we achieved an intercoder reliability (Cohen’s kappa) of 0.806 after eradicating obvious differences.</p>



<p>The ranking algorithm of Google Scholar prioritizes highly cited and older publications (Martín-Martín et al., 2016). Therefore, the position of the articles on the search engine results pages was not particularly informative, considering the relatively small number of results in combination with the recency of the publications. Only the query “as of my last knowledge update” had more than two search engine result pages. On those, questionable articles with undeclared use of GPTs were evenly distributed across all result pages (min: 4, max: 9, mode: 8), with the proportion of undeclared use being slightly higher on average on later search result pages.</p>



<p>To understand how the papers making fraudulent use of generative AI were disseminated online, we programmatically searched for the paper titles (with exact string matching) in Google Search from our local IP address (see Appendix B) using the googlesearch<em>–</em>python library(Vikramaditya, 2020). We manually verified each search result to filter out false positives—results that were not related to the paper—and then compiled the most prominent URLs by field. This enabled the identification of other platforms through which the papers had been spread. We did not, however, investigate whether copies had spread into SciHub or other shadow libraries, or if they were referenced in Wikipedia.</p>



<p>We used descriptive statistics to count the prevalence of the number of GPT-fabricated papers across topics and venues and top domains by subject. The pandas software library for the Python programming language (The pandas development team, 2024) was used for this part of the analysis. Based on the multiple coding, paper occurrences were counted in relation to their categories, divided into indexed journals, non-indexed journals, student papers, and working papers. The schemes, subdomains, and subdirectories of the URL strings were filtered out while top-level domains and second-level domains were kept, which led to normalizing domain names. This, in turn, allowed the counting of domain frequencies in the environment and health categories. To distinguish word prominences and meanings in the environment and health-related GPT-fabricated questionable papers, a semantically-aware word cloud visualization was produced through the use of a word rain (Centre for Digital Humanities Uppsala, 2023) for full-text versions of the papers. Font size and y-axis positions indicate word prominences through TF-IDF scores for the environment and health papers (also visualized in a separate bar chart with raw term frequencies in parentheses), and words are positioned along the x-axis to reflect semantic similarity (Skeppstedt et al., 2024), with an English Word2vec skip gram model space (Fares et al., 2017). An English stop word list was used, along with a manually produced list including terms such as “https,” “volume,” or “years.”</p>
			</div>

							
			
			<div>

					<div>
							<h6>Cite this Essay</h6>
							<p><cite><p>
							Haider, J., Söderström, K. R., Ekström, B., &amp; Rödl, M.  (2024). GPT-fabricated scientific papers on Google Scholar: Key features, spread, and implications for preempting evidence manipulation. <em> Harvard Kennedy School (HKS) Misinformation Review</em>. https://doi.org/10.37016/mr-2020-156							</p></cite>
						</p></div>

					<h4>Bibliography</h4><div><p>Antkare, I. (2020). Ike Antkare, his publications, and those of his disciples. In M. Biagioli &amp; A. Lippman (Eds.), <em>Gaming the metrics</em> (pp. 177–200). The MIT Press. <a href="https://doi.org/10.7551/mitpress/11087.003.0018">https://doi.org/10.7551/mitpress/11087.003.0018</a></p>
<p>Barbour, R. S. (2001). Checklists for improving rigour in qualitative research: A case of the tail wagging the dog? <em>BMJ</em>, <em>322</em>(7294), 1115–1117. <a href="https://doi.org/10.1136/bmj.322.7294.1115">https://doi.org/10.1136/bmj.322.7294.1115</a></p>
<p>Bom, H.-S. H. (2023). Exploring the opportunities and challenges of ChatGPT in academic writing: A roundtable discussion. <em>Nuclear Medicine and Molecular Imaging</em>, <em>57</em>(4), 165–167. <a href="https://doi.org/10.1007/s13139-023-00809-2">https://doi.org/10.1007/s13139-023-00809-2</a></p>
<p>Cabanac, G., &amp; Labbé, C. (2021). Prevalence of nonsensical algorithmically generated papers in the scientific literature. <em>Journal of the Association for Information Science and Technology</em>, <em>72</em>(12), 1461–1476. <a href="https://doi.org/10.1002/asi.24495">https://doi.org/10.1002/asi.24495</a></p>
<p>Cabanac, G., Labbé, C., &amp; Magazinov, A. (2021). <em>Tortured phrases: A dubious writing style emerging in science. Evidence of critical issues affecting established journals</em>. arXiv. <a href="https://doi.org/10.48550/arXiv.2107.06751">https://doi.org/10.48550/arXiv.2107.06751</a></p>
<p>Carrion, M. L. (2018). “You need to do your research”: Vaccines, contestable science, and maternal epistemology. <em>Public Understanding of Science</em>, <em>27</em>(3), 310–324. <a href="https://doi.org/10.1177/0963662517728024">https://doi.org/10.1177/0963662517728024</a></p>
<p>Centre for Digital Humanities Uppsala (2023). CDHUppsala/word-rain [Computer software]. <a href="https://github.com/CDHUppsala/word-rain">https://github.com/CDHUppsala/word-rain</a></p>
<p>Chinn, S., &amp; Hasell, A. (2023). Support for “doing your own research” is associated with COVID-19 misperceptions and scientific mistrust. <em>Harvard Kennedy School (HSK) Misinformation Review, 4</em>(3). <a href="https://doi.org/10.37016/mr-2020-117">https://doi.org/10.37016/mr-2020-117</a></p>
<p>Cholewiak, S. A., Ipeirotis, P., Silva, V., &amp; Kannawadi, A. (2023). SCHOLARLY: Simple access to Google Scholar authors and citation using Python (1.5.0) [Computer software]. <a href="https://doi.org/10.5281/zenodo.5764801">https://doi.org/10.5281/zenodo.5764801</a></p>
<p>Dadkhah, M., Lagzian, M., &amp; Borchardt, G. (2017). Questionable papers in citation databases as an issue for literature review. <em>Journal of Cell Communication and Signaling</em>, <em>11</em>(2), 181–185. <a href="https://doi.org/10.1007/s12079-016-0370-6">https://doi.org/10.1007/s12079-016-0370-6</a></p>
<p>Dadkhah, M., Oermann, M. H., Hegedüs, M., Raman, R., &amp; Dávid, L. D. (2023). Detection of fake papers in the era of artificial intelligence. <em>Diagnosis</em>, <em>10</em>(4), 390–397. <a href="https://doi.org/10.1515/dx-2023-0090">https://doi.org/10.1515/dx-2023-0090</a></p>
<p>DeGeurin, M. (2024, March 19). <em>AI-generated nonsense is leaking into scientific journals.</em> Popular Science. <a href="https://www.popsci.com/technology/ai-generated-text-scientific-journals/">https://www.popsci.com/technology/ai-generated-text-scientific-journals/</a></p>
<p>Dunlap, R. E., &amp; Brulle, R. J. (2020). Sources and amplifiers of climate change denial. In D.C. Holmes &amp; L. M. Richardson (Eds.), <em>Research handbook on communicating climate change</em> (pp. 49–61). Edward Elgar Publishing. <a href="https://doi.org/10.4337/9781789900408.00013">https://doi.org/10.4337/9781789900408.00013</a></p>
<p>Fares, M., Kutuzov, A., Oepen, S., &amp; Velldal, E. (2017). Word vectors, reuse, and replicability: Towards a community repository of large-text resources. In J. Tiedemann &amp; N. Tahmasebi (Eds.), <em>Proceedings of the 21st Nordic Conference on Computational Linguistics </em>(pp. 271–276). Association for Computational Linguistics. <a href="https://aclanthology.org/W17-0237">https://aclanthology.org/W17-0237</a></p>
<p>Google Scholar Help. (n.d.). <em>Inclusion guidelines for webmasters</em>. <a href="https://scholar.google.com/intl/en/scholar/inclusion.html">https://scholar.google.com/intl/en/scholar/inclusion.html</a></p>
<p>Gu, J., Wang, X., Li, C., Zhao, J., Fu, W., Liang, G., &amp; Qiu, J. (2022). AI-enabled image fraud in scientific publications. <em>Patterns</em>, <em>3</em>(7), 100511. <a href="https://doi.org/10.1016/j.patter.2022.100511">https://doi.org/10.1016/j.patter.2022.100511</a></p>
<p>Gusenbauer, M., &amp; Haddaway, N. R. (2020). Which academic search systems are suitable for systematic reviews or meta-analyses? Evaluating retrieval qualities of Google Scholar, PubMed, and 26 other resources. <em>Research Synthesis Methods</em>, <em>11</em>(2), 181–217. &nbsp;<a href="https://doi.org/10.1002/jrsm.1378">https://doi.org/10.1002/jrsm.1378</a></p>
<p>Haider, J., &amp; Åström, F. (2017). Dimensions of trust in scholarly communication: Problematizing peer review in the aftermath of John Bohannon’s “Sting” in science. <em>Journal of the Association for Information Science and Technology</em>, <em>68</em>(2), 450–467. <a href="https://doi.org/10.1002/asi.23669">https://doi.org/10.1002/asi.23669</a></p>
<p>Huang, J., &amp; Tan, M. (2023). The role of ChatGPT in scientific communication: Writing better scientific review articles. <em>American Journal of Cancer Research</em>, <em>13</em>(4), 1148–1154. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10164801/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10164801/</a></p>
<p>Jones, N. (2024). How journals are fighting back against a wave of questionable images. <em>Nature</em>, <em>626</em>(8000), 697–698. <a href="https://doi.org/10.1038/d41586-024-00372-6">https://doi.org/10.1038/d41586-024-00372-6</a></p>
<p>Kitamura, F. C. (2023). ChatGPT is shaping the future of medical writing but still requires human judgment. <em>Radiology</em>, <em>307</em>(2), e230171. <a href="https://doi.org/10.1148/radiol.230171">https://doi.org/10.1148/radiol.230171</a></p>
<p>Littell, J. H., Abel, K. M., Biggs, M. A., Blum, R. W., Foster, D. G., Haddad, L. B., Major, B., Munk-Olsen, T., Polis, C. B., Robinson, G. E., Rocca, C. H., Russo, N. F., Steinberg, J. R., Stewart, D. E., Stotland, N. L., Upadhyay, U. D., &amp; Ditzhuijzen, J. van. (2024). Correcting the scientific record on abortion and mental health outcomes. <em>BMJ</em>, <em>384</em>, e076518. <a href="https://doi.org/10.1136/bmj-2023-076518">https://doi.org/10.1136/bmj-2023-076518</a></p>
<p>Lund, B. D., Wang, T., Mannuru, N. R., Nie, B., Shimray, S., &amp; Wang, Z. (2023). ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing. <em>Journal of the Association for Information Science and Technology, 74</em>(5), 570–581. <a href="https://doi.org/10.1002/asi.24750">https://doi.org/10.1002/asi.24750</a></p>
<p>Martín-Martín, A., Orduna-Malea, E., Ayllón, J. M., &amp; Delgado López-Cózar, E. (2016). Back to the past: On the shoulders of an academic search engine giant. <em>Scientometrics</em>,<em> 107</em>, 1477–1487. <a href="https://doi.org/10.1007/s11192-016-1917-2">https://doi.org/10.1007/s11192-016-1917-2</a></p>
<p>Martín-Martín, A., Thelwall, M., Orduna-Malea, E., &amp; Delgado López-Cózar, E. (2021). Google Scholar, Microsoft Academic, Scopus, Dimensions, Web of Science, and OpenCitations’ COCI: A multidisciplinary comparison of coverage via citations. <em>Scientometrics</em>, <em>126</em>(1), 871–906. <a href="https://doi.org/10.1007/s11192-020-03690-4">https://doi.org/10.1007/s11192-020-03690-4</a></p>
<p>Simon, F. M., Altay, S., &amp; Mercier, H. (2023). Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown. <em>Harvard Kennedy School (HKS) Misinformation Review, 4</em>(5). <a href="https://doi.org/10.37016/mr-2020-127">https://doi.org/10.37016/mr-2020-127</a></p>
<p>Skeppstedt, M., Ahltorp, M., Kucher, K., &amp; Lindström, M. (2024). From word clouds to Word Rain: Revisiting the classic word cloud to visualize climate change texts. <em>Information Visualization</em>, <em>23</em>(3), 217–238. <a href="https://doi.org/10.1177/14738716241236188">https://doi.org/10.1177/14738716241236188</a></p>
<p>Swedish Research Council. (2017). <em>Good research practice.</em> Vetenskapsrådet.</p>
<p>Stokel-Walker, C. (2024, May 1.). <em>AI Chatbots Have Thoroughly Infiltrated Scientific Publishing</em>. Scientific American. <a href="https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/">https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/</a></p>
<p>Subbaraman, N. (2024, May 14). Flood of fake science forces multiple journal closures: Wiley to shutter 19 more journals, some tainted by fraud. <em>The Wall Street Journal</em>. <a href="https://www.wsj.com/science/academic-studies-research-paper-mills-journals-publishing-f5a3d4bc">https://www.wsj.com/science/academic-studies-research-paper-mills-journals-publishing-f5a3d4bc</a></p>
<p>The pandas development team. (2024). pandas-dev/pandas: Pandas (v2.2.2) [Computer software]. <em>Zenodo.</em> <a href="https://doi.org/10.5281/zenodo.10957263">https://doi.org/10.5281/zenodo.10957263</a></p>
<p>Thorp, H. H. (2023). ChatGPT is fun, but not an author. <em>Science</em>, <em>379</em>(6630), 313–313. <a href="https://doi.org/10.1126/science.adg7879">https://doi.org/10.1126/science.adg7879</a></p>
<p>Tripodi, F. B., Garcia, L. C., &amp; Marwick, A. E. (2023). ‘Do your own research’: Affordance activation and disinformation spread. <em>Information, Communication &amp; Society</em>, <em>27</em>(6), 1212–1228. <a href="https://doi.org/10.1080/1369118X.2023.2245869">https://doi.org/10.1080/1369118X.2023.2245869</a></p>
<p>Vikramaditya, N. (2020). Nv7-GitHub/googlesearch [Computer software]. <a href="https://github.com/Nv7-GitHub/googlesearch">https://github.com/Nv7-GitHub/googlesearch</a></p>
</div><h4>Funding</h4><p>This research has been supported by Mistra, the Swedish Foundation for Strategic Environmental Research, through the research program Mistra Environmental Communication (Haider, Ekström, Rödl) and the Marcus and Amalia Wallenberg Foundation [2020.0004] (Söderström).</p><h4>Competing Interests</h4><p>The authors declare no competing interests.</p><h4>Ethics</h4><p>The research described in this article was carried out under Swedish legislation. According to the relevant EU and Swedish legislation (2003:460) on the ethical review of research involving humans (“Ethical Review Act”), the research reported on here is not subject to authorization by the Swedish Ethical Review Authority (“etikprövningsmyndigheten”) (SRC, 2017).</p><h4>Copyright</h4><p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided that the original author and source are properly credited.</p><h4>Data Availability</h4><h4>Acknowledgements</h4><p>The authors wish to thank two anonymous reviewers for their valuable comments on the article manuscript as well as the editorial group of <em>Harvard Kennedy School (HKS) Misinformation Review</em> for their thoughtful feedback and input.</p>
				</div>

		</div>

	</article>

	
	<!-- <nav role="navigation" class="post-nav">
		<div class="previous-post">
			<a href="https://misinforeview.hks.harvard.edu/article/the-algorithmic-knowledge-gap-within-and-between-countries-implications-for-combatting-misinformation/" rel="prev"><span class="fa fa-caret-left"></span> Previous</a>		</div>
		<div class="next-post">
					</div>
	</nav> -->

	
</section> 
	
	

	












	<!-- Go to www.addthis.com/dashboard to customize your tools -->
	



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gnome Files: A detailed UI examination (131 pts)]]></title>
            <link>https://www.datagubbe.se/gnomefiles/</link>
            <guid>41476873</guid>
            <pubDate>Sat, 07 Sep 2024 22:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.datagubbe.se/gnomefiles/">https://www.datagubbe.se/gnomefiles/</a>, See on <a href="https://news.ycombinator.com/item?id=41476873">Hacker News</a></p>
Couldn't get https://www.datagubbe.se/gnomefiles/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[CitizenDJ – Make music using free audio and video from the Library of Congress (105 pts)]]></title>
            <link>https://citizen-dj.labs.loc.gov/</link>
            <guid>41475998</guid>
            <pubDate>Sat, 07 Sep 2024 19:47:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://citizen-dj.labs.loc.gov/">https://citizen-dj.labs.loc.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=41475998">Hacker News</a></p>
Couldn't get https://citizen-dj.labs.loc.gov/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Hallelujah, Leonard Cohen, and a Pulitzer Prize-winning writer's suicide (123 pts)]]></title>
            <link>https://subtledigressions.substack.com/p/hallelujah-leonard-cohen-and-a-pulitzer</link>
            <guid>41475618</guid>
            <pubDate>Sat, 07 Sep 2024 18:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://subtledigressions.substack.com/p/hallelujah-leonard-cohen-and-a-pulitzer">https://subtledigressions.substack.com/p/hallelujah-leonard-cohen-and-a-pulitzer</a>, See on <a href="https://news.ycombinator.com/item?id=41475618">Hacker News</a></p>
Couldn't get https://subtledigressions.substack.com/p/hallelujah-leonard-cohen-and-a-pulitzer: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The "email is authentication" pattern (162 pts)]]></title>
            <link>https://rubenerd.com/the-email-is-authentication-pattern/</link>
            <guid>41475218</guid>
            <pubDate>Sat, 07 Sep 2024 17:48:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubenerd.com/the-email-is-authentication-pattern/">https://rubenerd.com/the-email-is-authentication-pattern/</a>, See on <a href="https://news.ycombinator.com/item?id=41475218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I’m the first to admit that I don’t live in the real (electronic) world. As the late Jim Kloss pointed out during one of his broadcasts, we (and probably you) live in a part of the Web with ad blockers (as the <a href="https://www.ic3.gov/Media/Y2022/PSA221221">FBI recommends</a>), limited JavaScript, password managers, and a (mostly) finely-tuned sense of what is a scam and what is legitimate (that was a lot of brackets).</p>
<p>Most people don’t live like this. I’d posit the <em>vast majority</em> don’t. And it’s worth a reality check sometimes.</p>
<p>Here’s a shockingly-common login process I witness:</p>
<ol>
<li>Get to a login page</li>
<li>Click “I forgot my password”</li>
<li>Go to their email</li>
<li>Click the recovery link</li>
<li>Type a throwaway password they won’t retain</li>
<li>Rinse, and repeat</li>
</ol>
<p>When I ask people why they do this, they either don’t have an answer, or respond with “huh, I never thought about why”. And that’s interesting to me.</p>
<p>Enough has been written (including here) about the need for password managers, the risks of identity theft, two-factor and multi-factor authentication, and whether the entire concept of a username/password is antiquated and in bad need of replacement. If you’re a reader of my silly blog here, you likely already know all this.</p>
<p>What I’m interested in here is the fact people have come up with that above process <em>in the first place</em>. How do you decide that using “I forgot my password” as authentication makes sense to you? Or more specifically, the <em>most</em> sense to you, out of all possible options?</p>
<p>I think people can’t answer why they do this because it’s not a concious decision. They don’t wake up in the morning and decide <em>yes, this is how I’m going to interact with online accounts today!</em> Instead, this is a process that has coalesced over time and become rote. It offers a guaranteed, repeatable, low-effort solution (of sorts) to passphrases they don’t need to think about (there’s those brackets again).</p>
<p>It makes me wonder if we’re looking at a bunch of these issues backwards, and whether we can take advantage of people’s tendencies towards learned behaviour like this. What if we could somehow design systems so that the people who use them evolve to use them in <em>better</em> ways? Because I do empathise with people that often improved security comes with more barriers and friction, not fewer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new rare high-rank elliptic curve, and an orchard of Diophantine equations (152 pts)]]></title>
            <link>https://thehighergeometer.wordpress.com/2024/09/08/two-items-a-new-rare-high-rank-elliptic-curve-and-a-beautifully-organised-orchard-of-diophantine-equations/</link>
            <guid>41475177</guid>
            <pubDate>Sat, 07 Sep 2024 17:43:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehighergeometer.wordpress.com/2024/09/08/two-items-a-new-rare-high-rank-elliptic-curve-and-a-beautifully-organised-orchard-of-diophantine-equations/">https://thehighergeometer.wordpress.com/2024/09/08/two-items-a-new-rare-high-rank-elliptic-curve-and-a-beautifully-organised-orchard-of-diophantine-equations/</a>, See on <a href="https://news.ycombinator.com/item?id=41475177">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-1245">
	<!-- .entry-header -->

	<div>
		
<p>I got an email the other day from mathematician Bogdan Grechuk, whose book <em>Polynomial Diophantine Equations: A Systematic Approach</em> (<a href="https://doi.org/10.1007/978-3-031-62949-5">https://doi.org/10.1007/978-3-031-62949-5</a>) was recently released. This is to my mind a rather remarkable book. The blurb starts: </p>



<blockquote>
<p>This book proposes a novel approach to the study of Diophantine equations: define an appropriate version of the equation’s size, order all polynomial Diophantine equations by size, and then solve the equations <strong>in order.</strong> [emphasis added]</p>
</blockquote>



<p>The book really does do this systematically. The start of the book solves extremely easy examples, but pays close attention to the process, so that it can identify classes of equations that this method will apply to. And as a new method of solution is provided, hence solving a new class of equations, this class of equations is removed from considerations going forward. Grechuk, halfway through the book (&gt;400 pages in!) takes stock and provides an outline of the algorithm built up over the four chapters to that point. It has approximately 21 main cases, of increasing difficulty, spread over pages, referring constantly back through the book to various methods and algorithms for different cases. As the equations keep getting harder, the problem of solution shifts focus: from “describe all solutions parametrically”, to “write down a family of polynomials (or rational functions) that give all solutions”, to “find a recurrence relation to describe solutions”, to “determine if there are finitely or infinitely many solutions”, to “determine if there is any one solution”. The methods start out wholly elementary, and by the end the discussion uses the cutting edge of current techniques for attacking number-theoretic problems of this sort, for instance <a href="https://en.wikipedia.org/wiki/Claude_Chabauty">Chabauty</a> methods. </p>



<p>Long-time readers of the blog may recall the post <a href="https://thehighergeometer.wordpress.com/2021/07/27/diophantine-fruit/">Diophantine fruit</a>. which was inspired by a MathOverflow question of Grechuk on the problem of “the smallest unsolved Diophantine equation”. This blog post led to a <a href="https://arxiv.org/search/?query=%22fruit+diophantine%22&amp;searchtype=title">chain of papers</a> using the phrase “fruit equations” by authors wholly unconnected with me, with the first solving what was at the time an open problem on Grechuk’s list. So it’s worth consulting the companion paper <em>A systematic approach to Diophantine equations: open problems</em> (<a href="https://arxiv.org/abs/2404.08518">https://arxiv.org/abs/2404.08518</a>) if you have any particular hankering to solve an equation (in any of the various ways: from parametrising a family of solutions to just finding one single solution) and have the honour of being the <em>first person ever</em> (modulo the problem of finding some equation equivalent to it buried in the literature) to solve a hard equation. The book ends with a summary that is a line-in-the-sand version of the just-cited arXiv preprint, stating the earliest/smallest/shortest equations that the various types of solutions are not known. And the last open problem is this:</p>



<blockquote>
<p>What is the smallest (in H) equation for which the existence of integer solutions (Problem 7.1) is a problem which is independent from the standard axioms of mathematics (Zermelo–Fraenkel set theory with the axiom of choice)?</p>
</blockquote>



<p>Here “H” refers to the function that gives the “size” of a polynomial Diophantine equation, that allows a systematic ordering. Other natural orderings are given in the book, which end up being more-or-less comparable, if not the same, and the above problem is also posed for these orderings. From the MDRP solution to <a href="https://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem">Hilbert’s Tenth Problem</a> we know that at some point equations whose solvability is unprovable in ZFC will turn up. By work of Zhi-Wei Sun (<a href="https://arxiv.org/abs/1704.03504">https://arxiv.org/abs/1704.03504</a>) we know that the unsolvability result (that is, there is no algorithm that can solve in integers all equations in a given class) is true taking even just Diophantine equations with no more than 11 variables. But identifying an explicit equation, let alone the smallest one, seems very hard. Moreover, trying to optimise to find a small ZFC-undecidable equation, rather than an algorithmically unsolvable one, is another whole kettle of fish; compare how the value BB(745) of the Busy Beaver function is <a href="https://www.ingo-blechschmidt.eu/assets/bachelor-thesis-undecidability-bb748.pdf">not possible to calculate in ZFC</a>, through a line of work whose current endpoint is by Johannes Riebel’s 2023 Bachelor thesis. (ADDED: I just now found that in fact BB(636) is known to uncalculable in ZFC, by <a href="https://github.com/CatsAreFluffy/metamath-turing-machines/commits/master/zf2.nql">very recent work of Rohan Ridenour</a> in the past two months)</p>



<hr>



<p>Just as Grechuk’s book starts small and tries to find the smallest so-far unsolved Diophantine equations, here is an example of one such equation, but one that is far from small:</p>



<pre><code>y^2 + xy = x^3 - 27006183241630922218434652145297453784768054621836357954737385x + 55258058551342376475736699591118191821521067032535079608372404779149413277716173425636721497</code></pre>



<p>(source: <a href="https://web.math.pmf.unizg.hr/~duje/tors/rk29.html">https://web.math.pmf.unizg.hr/~duje/tors/rk29.html</a>). This equation defines an elliptic curve, and it has the largest-known number of solutions in rational numbers of any such equation. By “largest-known” I mean that there is a copy of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BZ%7D%5E%7B29%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BZ%7D%5E%7B29%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb%7BZ%7D%5E%7B29%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\mathbb{Z}^{29}"> in the set of rational solutions (where we are in fact finding solutions in the projective plane, not just in affine coordinates as presented). That is, there are 29 rational solutions (shown at the previous link) that are linearly-idependent (over the integers) under the abelian group operation on the rational points. It is not proved that there are no other linearly independent solutions (this number is known as the <em>rank</em> of the elliptic curve described by the equation). The announcement of the result as well as a summary of how much more is known is given in the email:</p>



<ul>
<li>N. D. Elkies and Z. Klagsbrun, <em><strong>Z</strong><sup>29</sup> in E(<strong>Q</strong>)</em>, Number Theory Listserver, Aug 2024. (<a href="https://listserv.nodak.edu/cgi-bin/wa.exe?A2=NMBRTHRY;b9d018b1.2409&amp;S=">https://listserv.nodak.edu/cgi-bin/wa.exe?A2=NMBRTHRY;b9d018b1.2409&amp;S=</a>)</li>
</ul>



<p>The above elliptic curve has been proved to have rank exactly 29 using the Generalised Riemann Hypothesis  for zeta functions of number fields, which is very far from being known (the usual Riemann Hypothesis is the special case of taking the number field to be the rationals). So the specific two-variable cubic equation above is an example of a polynomial Diophantine equation whose complete solution—and I haven’t even mentioned the possible (finite) torsion subgroup of the elliptic curve—requires knowing a the resolution of a conjecture that is wholly out of reach of current mathematics.</p>



<p>(source for image: Mark Hughes, <em><a href="https://www.allaboutcircuits.com/technical-articles/elliptic-curve-cryptography-in-embedded-systems/">How Elliptic Curve Cryptography Works</a></em>, 2019)</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	</article><!-- #post-## -->

			
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebP: The WebPage Compression Format (360 pts)]]></title>
            <link>https://purplesyringa.moe/blog/webp-the-webpage-compression-format/</link>
            <guid>41475124</guid>
            <pubDate>Sat, 07 Sep 2024 17:32:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://purplesyringa.moe/blog/webp-the-webpage-compression-format/">https://purplesyringa.moe/blog/webp-the-webpage-compression-format/</a>, See on <a href="https://news.ycombinator.com/item?id=41475124">Hacker News</a></p>
Couldn't get https://purplesyringa.moe/blog/webp-the-webpage-compression-format/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Cracking an old ZIP file to help open source the ANC's "Vula" secret crypto code (156 pts)]]></title>
            <link>https://blog.jgc.org/2024/09/cracking-old-zip-file-to-help-open.html</link>
            <guid>41474828</guid>
            <pubDate>Sat, 07 Sep 2024 16:41:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jgc.org/2024/09/cracking-old-zip-file-to-help-open.html">https://blog.jgc.org/2024/09/cracking-old-zip-file-to-help-open.html</a>, See on <a href="https://news.ycombinator.com/item?id=41474828">Hacker News</a></p>
Couldn't get https://blog.jgc.org/2024/09/cracking-old-zip-file-to-help-open.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A Post-Google World (212 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/a-post-google-world</link>
            <guid>41474508</guid>
            <pubDate>Sat, 07 Sep 2024 15:39:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/a-post-google-world">https://www.thebignewsletter.com/p/a-post-google-world</a>, See on <a href="https://news.ycombinator.com/item?id=41474508">Hacker News</a></p>
Couldn't get https://www.thebignewsletter.com/p/a-post-google-world: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ten Things to Know about the Great Wave (210 pts)]]></title>
            <link>https://www.artic.edu/articles/1139/10-things-to-know-about-the-great-wave</link>
            <guid>41474449</guid>
            <pubDate>Sat, 07 Sep 2024 15:31:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.artic.edu/articles/1139/10-things-to-know-about-the-great-wave">https://www.artic.edu/articles/1139/10-things-to-know-about-the-great-wave</a>, See on <a href="https://news.ycombinator.com/item?id=41474449">Hacker News</a></p>
Couldn't get https://www.artic.edu/articles/1139/10-things-to-know-about-the-great-wave: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Hindenburg’s Interior (117 pts)]]></title>
            <link>https://rarehistoricalphotos.com/hindenburg-interior-photos/</link>
            <guid>41474311</guid>
            <pubDate>Sat, 07 Sep 2024 15:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rarehistoricalphotos.com/hindenburg-interior-photos/">https://rarehistoricalphotos.com/hindenburg-interior-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=41474311">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
					<p><img fetchpriority="high" decoding="async" src="https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small.jpg" alt="The Hindenburg’s Interior: Vintage Photos Reveal What Luxury Air Travel Was Like in the 1930s" width="1600" height="1055" srcset="https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small.jpg 1600w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-300x198.jpg 300w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-1024x675.jpg 1024w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-150x99.jpg 150w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-768x506.jpg 768w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-1536x1013.jpg 1536w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-294x194.jpg 294w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-384x253.jpg 384w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-1152x759.jpg 1152w, https://rarehistoricalphotos.com/wp-content/uploads/2023/01/hindenburg-interior-photos-small-1440x950.jpg 1440w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<p>Before modern air travel and first-class suites, the grandest thing in luxury air travel was the German Zeppelin airship.</p>
<p>The Hindenburg was designed to ferry passengers across the Atlantic in serenity, with the dirigible floating smoothly through the clouds. The airship was considered the longest class of flying machine and the largest airship by envelope volume.</p>
<p>During the 1930s, airships like the Hindenburg class were widely considered the future of air travel, and the lead ship of the class, LZ 129 Hindenburg, established a regular transatlantic service. The airship’s destruction in a <span><a href="https://rarehistoricalphotos.com/hindenburg-disaster-pictures/">highly publicized accident</a></span> was the end of these expectations.</p>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-NQBLuOeM1xM/WxiUeOHDIhI/AAAAAAAAQPg/S4Z56tKVGacoO8B71ASkuizCI4MfPct7QCLcBGAs/s1600/Hindenburg_Disaster%2B%252817%2529.jpg" width="1400"></p><p>The Hindenburg floats over Manhattan Island in New York City on May 6, 1937, just hours from disaster in nearby New Jersey.</p></div>
<p>Hindenburg had a duralumin structure, incorporating 15 Ferris wheel-like main ring bulkheads along its length, with 16 cotton gas bags fitted between them.</p>
<p>The bulkheads were braced to each other by longitudinal girders placed around their circumferences. The airship’s outer skin was of cotton doped with a mixture of reflective materials intended to protect the gas bags within from radiation, both ultraviolet (which would damage them) and infrared (which might cause them to overheat).</p>
<p>The gas cells were made by a new method pioneered by Goodyear using multiple layers of gelatinized latex rather than the previous goldbeater’s skins.</p>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-uIkwCDOR4bg/Wgq84zBV6II/AAAAAAAC4uM/_cNdHt2v0YoaOSPrhhQ-vCOBazNoQCDdgCLcBGAs/s1600/hindenburg-interior-0.jpg" alt="" width="1400"></p><p>Dining Room of Airship Hindenburg. (Photo from Airships.net collection).</p></div>
<p>Hindenburg’s interior furnishings were designed by Fritz August Breuhaus, whose design experience included Pullman coaches, ocean liners, and warships of the German Navy.</p>
<p>The upper “A” Deck contained 25 small two-passenger cabins in the middle flanked by large public rooms: a dining room to port and a lounge and writing room to starboard.</p>
<p>The pictures collected in this article reveal what luxury air travel looked like aboard the airship Hindenburg in the mid-1930s. The photos are part of the <span><a href="https://www.airships.net/" rel="nofollow ">Airship.net collection</a></span> by Dan Grossman.&nbsp;</p>
<p>Each cabin had call buttons to summon a steward or stewardess, a small fold-down desk, a wash basin made of lightweight white plastic with taps for hot and cold running water, and a small closet covered with a curtain in which a limited number of suits or dresses could be hung; other clothes had to be kept in their suitcases, which could be stowed under the lower berth.</p>
<p>None of the cabins had toilet facilities; male and female toilets were available on B Deck below, as was a single shower, which provided a weak stream of water “more like that from a seltzer bottle” than a shower, according to Charles Rosendahl.</p>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-rMQmxNF-cwI/Wgq8irSaYlI/AAAAAAAC4uA/EtEvGxzE-tEQp49JK0LZ4XiT53vUINp-ACLcBGAs/s1600/hindenburg-interior-1.jpg" alt="" width="1400"></p><p>Dining Room of Airship Hindenburg. (Photo from Airships.net collection).</p></div>
<p>Paintings on the dining room walls portrayed the Graf Zeppelin’s trips to South America. A stylized world map covered the wall of the lounge.</p>
<p>Long slanted windows ran the length of both decks. The passengers were expected to spend most of their time in the public areas, rather than their cramped cabins.</p>
<p>The lower “B” Deck contained washrooms, a mess hall for the crew, and a smoking lounge. Yes, you heard it right, one of the most surprising areas aboard a hydrogen airship was the smoking room.</p>
<p>However, it was kept at higher than ambient pressure, so in case of a leak, the hydrogen couldn’t enter the room. Furthermore, its associated bar was separated from the rest of the ship by a double-door airlock. There was one electric lighter since no open flames were allowed aboard the ship.</p>
<p>Harold G. Dick, an American representative from the Goodyear Zeppelin Company, recalled<em> “The only entrance to the smoking room, which was pressurized to prevent the admission of any leaking hydrogen, was via the bar, which had a swiveling air lock door, and all departing passengers were scrutinized by the bar steward to make sure they were not carrying out a lit cigarette or pipe.”</em></p>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-B4HuKSb5ymU/Wgq8i6U3VKI/AAAAAAAC4uE/4o7L6KZO57s6IqCIoQCUnyOCbi-oXWFUQCLcBGAs/s1600/hindenburg-interior-2.jpg" alt="" width="1500"></p><p>Dining on the Hindenburg. (Photo from Airships.net collection).</p></div>
<p>The Hindenburg’s bar was a small ante-room between the smoking room and the air-lock door leading to the corridor on B-Deck.</p>
<p>This is where Hindenburg bartender Max Schulze served up LZ-129 Frosted Cocktails (gin and orange juice) and Maybach 12 cocktails (recipe lost to history), but more importantly, it is where Schulze monitored the air-lock to ensure that no one left the smoking room with burning cigarettes, cigars, or pipes.</p>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-xOHsGMqRDoc/Wgq8jNR_6lI/AAAAAAAC4uI/k6xcP-j1kE4-wATJwGwjCtoHUhuUTkelgCLcBGAs/s1600/hindenburg-interior-3.jpg" alt="" width="1400"></p><p>Dining Room of Hindenburg, with Port Promenade. (Photo from Airships.net collection).</p></div>
<p>Hindenburg made 17 round trips across the Atlantic in 1936—its first and only full year of service—with ten trips to the United States and seven to Brazil.</p>
<p>The flights were considered demonstrative rather than routine in schedule. The first passenger trip across the North Atlantic left Frankfurt on 6 May with 56 crew and 50 passengers, arriving in Lakehurst on 9 May.</p>
<p>As the elevation at Rhein-Main’s airfield lies at 111 m (364 ft) above sea level, the airship could lift 6 tonnes (13,000 lb) more at takeoff there than she could from Friedrichshafen, which was situated at 417 m (1,368 ft).</p>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-upkQIXVFZLE/Wgq-lh66laI/AAAAAAAC4uY/2WwMcaRhZlggGdHFt1msIJQsUWWCj2DZwCLcBGAs/s1600/hindenburg-interior-4.jpg" alt="" width="1400" height="992"></p><p>Passenger Lounge. (Photo from Airships.net collection).</p></div>
<p>The airship was said to be so stable a pen or pencil could be balanced on end atop a tablet without falling. Launches were so smooth that passengers often missed them, believing the airship was still docked to the mooring mast.</p>
<p>A one-way fare between Germany and the United States was US$400 (equivalent to $7,811 in 2021); Hindenburg passengers were affluent, usually, entertainers, noted sportsmen, political figures, and leaders of the industry.</p>
<p>Hindenburg was used again for propaganda when it flew over the Olympic Stadium in Berlin on August 1 during the opening ceremonies of the 1936 Summer Olympic Games.</p>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-Xdjib9Yomzg/Wgq-lmpZNPI/AAAAAAAC4uc/2v5OdBGTQx4xbl4AvDOa5C1nC-boH1AQQCLcBGAs/s1600/hindenburg-interior-5.jpg" alt="" width="1400" height="717"></p><p>Two views of the Lounge, showing a portrait of Hitler and the ship’s duralumin piano.</p></div>
<p>In 1936, Hindenburg had a Blüthner aluminium grand piano placed on board in the music salon, though the instrument was removed after the first year to save weight</p>
<p>Over the winter of 1936–37, several alterations were made to the airship’s structures. The greater lift capacity allowed nine passenger cabins to be added, eight with two beds and one with four, increasing passenger capacity to 70.</p>
<p>These windowed cabins were along the starboard side aft of the previously installed accommodations, and it was anticipated for the LZ 130 to also have these cabins. Additionally, the Olympic rings painted on the hull were removed for the 1937 season.</p>
<p>After making the first South American flight of the 1937 season in late March, Hindenburg left Frankfurt for Lakehurst on the evening of 3 May, on its first scheduled round trip between Europe and North America that season.</p>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-yB28yZ1rEaA/Wgq-tmHaGVI/AAAAAAAC4ug/VRfh-GHUY7UjjVBNxK5KSdb8XIG-qGQmACLcBGAs/s1600/hindenburg-interior-6.jpg" alt="" width="1400" height="621"></p><p>Passenger Lounge. (Photo from Airships.net collection).</p></div>
<p>The now known as the <span><a href="https://rarehistoricalphotos.com/hindenburg-disaster-pictures/" rel="nofollow ">Hindenburg disaster</a></span> occurred on May 6, 1937, in Manchester Township, New Jersey, United States. The passenger airship caught fire and was destroyed during its attempt to dock with its mooring mast at Naval Air Station Lakehurst.</p>
<p>The accident caused 35 fatalities (13 passengers and 22 crewmen) from the 97 people on board (36 passengers and 61 crewmen), and an additional fatality on the ground.</p>
<p>The disaster was the subject of newsreel coverage, photographs, and Herbert Morrison’s recorded radio eyewitness reports from the landing field, which were broadcast the next day.</p>
<p>A variety of theories have been put forward for both the cause of ignition and the initial fuel for the ensuing fire. The publicity shattered public confidence in the giant, passenger-carrying rigid airship and marked the abrupt end of the airship era.</p>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-c6oD4OWCPAw/Wgq-t4fN3qI/AAAAAAAC4uo/UcYOK1kGL2cTNZnrHJmJlMqkyvBPpNqzwCLcBGAs/s1600/hindenburg-interior-7.jpg" alt="" width="1400" height="621"></p><p>Passenger Lounge. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-wMNbVZEXJOY/Wgq-t4GkAGI/AAAAAAAC4uk/QbxpWej3Rw8jxLkdk8c0Bt8nlDFmH4XxwCLcBGAs/s1600/hindenburg-interior-8.jpg" alt="" width="1400" height="965"></p><p>Passenger Lounge on the Airship Hindenburg, showing promenade windows. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-KHnb-oX8XD0/Wgq-1hCxYoI/AAAAAAAC4us/IJtuZF-_J6YgTJE9V_oe74CqJvURb2iUACLcBGAs/s1600/hindenburg-interior-9.jpg" alt="" width="1400" height="705"></p><p>Writing Room. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-yoWFDccFrEk/Wgq_QEeRJ6I/AAAAAAAC4u4/NN2RN3fPDPo-LLV5Vjk4DMkA6kwByeoSgCLcBGAs/s1600/hindenburg-interior-10.jpg" alt="" width="1400" height="990"></p><p>Passenger Cabin aboard Hindenburg. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-mOM-IprwKeg/Wgq_UEERFlI/AAAAAAAC4u8/T8UYiNWF5YAGriWepFayRJXfP-v8GkPcACLcBGAs/s1600/hindenburg-interior-11.jpg" alt="" width="1400" height="1000"></p><p>Passenger Cabin aboard Hindenburg. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-zFW5xdtWoUs/Wgq_o8vhN0I/AAAAAAAC4vA/ASLcJNwhg5wlRIV1w9xMPSNkHSYGECRqQCLcBGAs/s1600/hindenburg-interior-12.jpg" alt="" width="1400" height="957"></p><p>Starboard Promenade aboard LZ-129 Hindenburg, next to the Lounge. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-P_d_YMDnk7I/Wgq_-eLAQoI/AAAAAAAC4vM/ifbDhAtkr4I_YkwdkmHIcUNyFoqkLmGHwCLcBGAs/s1600/hindenburg-interior-13.jpg" alt="" width="1400" height="985"></p><p>Smoking Room aboard LZ-129 Hindenburg. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-WQKsCxd5bc4/Wgq_-W6K7gI/AAAAAAAC4vI/ZOs-kK9PEBgjg3XU4k2IzBshEzFpY9XoACLcBGAs/s1600/hindenburg-interior-14.jpg" alt="" width="1400" height="715"></p><p>Smoking Room aboard LZ-129 Hindenburg. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-s9z68LriF-Q/WgrADOXOz6I/AAAAAAAC4vQ/edyPJXeLuDcpDBqNEJdtECAjDpeTz-ragCLcBGAs/s1600/hindenburg-interior-15.jpg" alt="" width="1400" height="951"></p><p>Pressurized Smoking Room aboard LZ-129 Hindenburg, showing the door to the bar, with the airlock doors beyond. (Photo from Airships.net collection).</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-KLY08X3zmfg/WgrWcnSby_I/AAAAAAAC4wg/wpLMopVo5o4cL2B99sEVqYbvYrsFeed-ACLcBGAs/s1600/hindenburg-interior-18.jpg" alt="" width="1400" height="1497"></p><p>Hindenburg Bar.</p></div>
<div><p><img decoding="async" src="https://2.bp.blogspot.com/-7tXAbjuq7EE/WgrWciuZNXI/AAAAAAAC4wc/sKHrEol1VbQoHpFWnMdVpjKM_LBQ8DUMQCLcBGAs/s1600/hindenburg-interior-19.jpg" alt="" width="1400" height="1036"></p><p>Cocktails aboard the Hindenburg.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-pQoY4b9pzbM/WgrAnB3quoI/AAAAAAAC4vg/8OjtptcyfgAutZ8TPWrClLuAcS2iX-3KACLcBGAs/s1600/hindenburg-interior-control-car-1.jpg" alt="" width="1400" height="1037"></p><p>Hindenburg Control Room (Ludwig Felber at helm, possibly Knut Eckener to his right). At far left is ballast board, then rudder station with gyro compass repeater, to right of tall figure is the eyepiece of a drift measuring telesope, and to the right is the engine telegraph, axial corridor speaking tube, altimeter, and engine instruments; to the far right is a variometer.</p></div>
<p><img decoding="async" src="https://3.bp.blogspot.com/-QlH-8Xlfd_w/WgrAm0v-aFI/AAAAAAAC4vY/4BBEsE_BNX0-No6ECNv4jE2pN4OUxpdHgCLcBGAs/s1600/hindenburg-interior-control-car-2.jpg" width="1400"></p>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-vnpVHtGNCx4/WgrAnLYFYqI/AAAAAAAC4vc/KQVNXyXbr6s1NWdsWI1fS3JSQxT_IQGtgCLcBGAs/s1600/hindenburg-interior-control-car-3.jpg" alt="" width="1400" height="1481"></p><p>Elevator Wheel, Elevator Panel, and Ballast Board.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-F1tsQclUo6k/WgrAnsnSP7I/AAAAAAAC4vk/bf2Sihu4bRsPVU2enBMKPpd5kHDVgUDZACLcBGAs/s1600/hindenburg-interior-control-car-4.jpg" alt="" width="1400" height="475"></p><p>Hindenburg’s Elevator Panel.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-jfYAIMUeZ38/WgrAoGC0jbI/AAAAAAAC4vo/tCSvc-XzGy8BYm3Rte21AO84rsiVm-9oQCLcBGAs/s1600/hindenburg-interior-control-car-5.jpg" alt="" width="1400" height="1044"></p><p>Hindenburg’s Navigation Room.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-sYR4wFg-TAo/WgrAoUGbvrI/AAAAAAAC4vs/m9OupCDxcBEfHGtV3LZyg6CodMBIMtPVgCLcBGAs/s1600/hindenburg-interior-control-car-6.jpg" alt="" width="1400" height="1046"></p><p>Ernst Lehmann with Navigation Radios.</p></div>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-3x7hpe1Hsbk/WgrAoRge8BI/AAAAAAAC4vw/eq40bGFTGRoFrACzvk2LzhgR816IH9UggCLcBGAs/s1600/hindenburg-interior-control-car-7.jpg" alt="" width="1400" height="1028"></p><p>Hindenburg’s main telephone station.</p></div>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-a6UQT1Hj05o/WgrA1rsmfQI/AAAAAAAC4v0/LzSQyFPjPIoyehFHyWlSVsr9B1XLFLVmQCLcBGAs/s1600/hindenburg-interior-crew-areas-keel-1.jpg" alt="" width="1400" height="1041"></p><p>Hindenburg Radio Room.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-TUwOOIUinL4/WgrA1k-KA5I/AAAAAAAC4v4/Oi0vWzR1Ul8eye-NhLbZmvO4l6_LQyzxgCLcBGAs/s1600/hindenburg-interior-crew-areas-keel-2.jpg" alt="" width="1400" height="1039"></p><p>Hindenburg Electrical Room.</p></div>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-yvW6S6qw_P8/WgrA1pWgROI/AAAAAAAC4v8/wnV-NqU8F0MzrrKYA_trs-HKNU8DakLMACLcBGAs/s1600/hindenburg-interior-crew-areas-keel-3.jpg" alt="" width="1400" height="698"></p><p>Hindenburg crew bunks, along the keel.</p></div>
<div><p><img decoding="async" src="https://3.bp.blogspot.com/-TPadFVf4Hk0/WgrA2pUq-BI/AAAAAAAC4wA/uEv9YqhbrA0LfGxgPYgm3Rf0us7QKsqyQCLcBGAs/s1600/hindenburg-interior-crew-areas-keel-4.jpg" alt="" width="1400" height="752"></p><p>Cargo storage along Hindenburg’s keel.</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-KwrtcZw4uZk/WgrA25qvp2I/AAAAAAAC4wE/VroT0p_QdwQvOdqTJpbgPpgvHPfZBOBMACLcBGAs/s1600/hindenburg-interior-crew-areas-keel-5.jpg" alt="" width="1400" height="629"></p><p>Hindenburg galley on B Deck.</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-rArnMAer0GA/WgrA3B7mT6I/AAAAAAAC4wI/1IJlk6P2jR0_p_kfxqLQc4qh1XN6UiPRwCLcBGAs/s1600/hindenburg-interior-crew-areas-keel-6.jpg" alt="" width="1400" height="882"></p><p>Hindenburg galley on B Deck.</p></div>
<div><p><img decoding="async" src="https://1.bp.blogspot.com/-4sYt_U2jENo/WgrA3dSlprI/AAAAAAAC4wM/Mmxz-HIQzWktzc5owKrNOSQ-hYEEBjW4ACLcBGAs/s1600/hindenburg-interior-crew-areas-keel-7.jpg" alt="" width="1400" height="675"></p><p>B Deck: Crew mess, with photographs of Hitler and Hindenburg (left); Officers mess (right).</p></div>
<div><p><img decoding="async" src="https://4.bp.blogspot.com/-MbMH9htJrgs/WxiUfyOhG5I/AAAAAAAAQP0/dvCzifgxULIB_HELdxOQdsCqyKUa80w7ACLcBGAs/s1600/Hindenburg_Disaster%2B%252821%2529.jpg" width="1400"></p><p>As the lifting Hydrogen gas burned and escaped from the rear of the Hindenburg, the tail dropped to the ground, sending a burst of flame punching through the nose. Ground crew below scatter to flee the inferno.</p></div>
<p><em>(Photo credit: <span><a href="https://www.airships.net/" rel="nofollow ">airships.net collection by Dan Grossman</a></span> / Wikimedia Commons / Britannica / Bundesarchiv / Archiv der Luftschiffbau Zeppelin GmbH, Friedrichshafen).</em></p>
					</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Right to Repair for Your Body': The Rise of DIY, Pirated Medicine (194 pts)]]></title>
            <link>https://fourthievesvinegar.org/</link>
            <guid>41474080</guid>
            <pubDate>Sat, 07 Sep 2024 14:19:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fourthievesvinegar.org/">https://fourthievesvinegar.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41474080">Hacker News</a></p>
Couldn't get https://fourthievesvinegar.org/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Conservative GC can be faster than precise GC (130 pts)]]></title>
            <link>https://wingolog.org/archives/2024/09/07/conservative-gc-can-be-faster-than-precise-gc</link>
            <guid>41473061</guid>
            <pubDate>Sat, 07 Sep 2024 10:44:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wingolog.org/archives/2024/09/07/conservative-gc-can-be-faster-than-precise-gc">https://wingolog.org/archives/2024/09/07/conservative-gc-can-be-faster-than-precise-gc</a>, See on <a href="https://news.ycombinator.com/item?id=41473061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Should your garbage collector be precise or conservative?  The
prevailing wisdom is that precise is always better.  Conservative GC can
retain more objects than strictly necessary, making GC slow: GC has to
more frequently, and it has to trace a larger heap on each collection.
However the calculus is not as straightforward as most people think, and
indeed there are some reasons to expect that conservative root-finding
can result in faster systems.</p><p>(I have made / relayed some of these arguments before but I feel like a
dedicated article can make a contribution here.)</p><h3>problem precision</h3><p>Let us assume that by <i>conservative GC</i> we mean conservative
root-finding, in which the collector assumes that any integer on the
stack that happens to be a heap address indicates a reference on the
object containing that address.  The address doesn’t have to be at the
start of the object.  Assume that objects on the heap are traced
precisely; contrast to BDW-GC which generally traces both the stack and
the heap conservatively.  Assume a collector that will pin referents of
conservative roots, but in which objects not referred to by a
conservative root can be moved, as in <a href="https://dl.acm.org/doi/10.1145/2660193.2660198">Conservative
Immix</a> or Whippet’s
<a href="https://github.com/wingo/whippet/blob/main/doc/collector-mmc.md#conservative-stack-scanning"><tt>stack-conservative-mmc</tt>
collector</a>.</p><p>With that out of the way, let’s look at some reasons why conservative GC
might be faster than precise GC.</p><h3>smaller lifetimes</h3><p>A compiler that does precise root-finding will typically output a
side-table indicating which slots in a stack frame hold references to
heap objects.  These lifetimes aren’t always precise, in the sense that
although they precisely enumerate heap references, those heap references
might actually not be used in the continuation of the stack frame.  When
GC occurs, it might mark more objects as live than are actually live,
which is the imputed disadvantage of conservative collectors.</p><p>This is most obviously the case when you need to explicitly register
roots with some kind of handle API: the handle will typically be kept
live until the scope ends, but that might be an overapproximation of
lifetime.  A compiler that can assume conservative stack scanning may
well exhibit more precision than it would if it needed to emit stack
maps.</p><h3>no run-time overhead</h3><p>For generated code, stack maps are great.  But if a compiler needs to
call out to C++ or something, it needs to precisely track roots in a
<a href="https://github.com/v8/v8/blob/main/src/handles/handles.h">run-time data
structure</a>.
This is overhead, and conservative collectors avoid it.</p><h3>smaller stack frames</h3><p>A compiler may partition spill space on a stack into a part that
contains pointers to the heap and a part containing numbers or other
unboxed data.  This may lead to larger stack sizes than if you could
just re-use a slot for two purposes, if the lifetimes don’t overlap.  A
similar concern applies for compilers that partition registers.</p><h3>no stack maps</h3><p>The need to emit stack maps is annoying for a compiler and makes
binaries bigger.  Of course it’s necessary for precise roots.  But then
there is additional overhead when tracing the stack: for each frame on
the stack, you need to look up the stack map for the return
continuation, which takes time.  It may be faster to just test if words
on the stack might be pointers to the heap.</p><h3>unconstrained compiler</h3><p>Having to make stack maps is a constraint imposed on the compiler.
Maybe if you don’t need them, the compiler could do a better job, or you
could use a different compiler entirely.  A conservative compiler can sometimes have better codegen, for example by the use of interior pointers.</p><h3>anecdotal evidence</h3><p>The <a href="https://dl.acm.org/doi/10.1145/2660193.2660198">Conservative Immix</a>
paper shows that conservative stack scanning can beat precise scanning
in some cases.  I have reproduced these results with
<a href="https://github.com/wingo/whippet/blob/main/doc/collector-mmc.md#conservative-stack-scanning"><tt>parallel-stack-conservative-mmc</tt> compared to
<tt>parallel-mmc</tt></a>.
It’s small—maybe a percent—but it was a surprising result to me and I
thought others might want to know.</p><p>Also, Apple’s JavaScriptCore uses conservative stack scanning, and <a href="https://wingolog.org/archives/2023/12/07/the-last-5-years-of-v8s-garbage-collector">V8 is looking at switching to it</a>.  Funny, right?</p><h3>conclusion</h3><p>When it comes to designing a system with GC, don’t count out
conservative stack scanning; the tradeoffs don’t obviously go one way or the other, and conservative scanning might be the right engineering choice for your system.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The PERQ Computer (161 pts)]]></title>
            <link>https://graydon2.dreamwidth.org/313862.html</link>
            <guid>41472855</guid>
            <pubDate>Sat, 07 Sep 2024 09:58:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://graydon2.dreamwidth.org/313862.html">https://graydon2.dreamwidth.org/313862.html</a>, See on <a href="https://news.ycombinator.com/item?id=41472855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A note on the PERQ computer.</p><p>Through a sequence of random events (seeing a note about an Alto emulator, listening to a truly atrocious podcast-retelling of the NeXT computer company) I found myself reading about the <a href="https://bitsavers.org/pdf/perq/PERQ_Brochure.pdf">PERQ</a> computer this evening.</p><p>Reader: the modern <a href="https://en.wikipedia.org/wiki/Mac_(computer)">Mac</a> is not "a copy of an <a href="https://en.wikipedia.org/wiki/Xerox_Alto">Alto</a>". I mean it kinda is. But more recently than that, it's really a copy of a <a href="https://en.wikipedia.org/wiki/PERQ">PERQ</a>.</p><p><img src="https://p.dreamwidth.org/20661e79c4f3/684470-313862/venge.net/graydon/perq.png" width="400"><img src="https://p.dreamwidth.org/f695b1792867/684470-313862/venge.net/graydon/perq-guy.png" width="400"></p><p>The PERQ is an early, commercial, and technical-user-focused version of an Alto. Except not quite. It had the same fast CPU, large local memory and bitmapped display with fast microcoded rasterops (a so-called "<a href="https://en.wikipedia.org/wiki/3M_computer">3M machine</a>" -- 1 MIPS CPU, 1 megabyte RAM, 1 megapixel display, "and 1 megapenny of price", about $10,000). It had the same GUI with overlapping windows. It also had Pascal, Fortran, C and Lisp. It also demoed and started taking orders in 1979 and shipped in 1980, before the competition, including before Xerox. The Xerox <a href="https://en.wikipedia.org/wiki/Xerox_Star">Star</a> (Xerox did finally commercialize the Alto) and <a href="https://en.wikipedia.org/wiki/Apollo/Domain">Apollo/Domain</a> each shipped a year later, in 1981.</p><p>The <a href="https://en.wikipedia.org/wiki/Sun-1">Sun-1</a>? Another year out, 1982. The Apple <a href="https://en.wikipedia.org/wiki/Apple_Lisa">Lisa</a>? A third the screen real estate and another year out, 1983. Mac? <a href="https://en.wikipedia.org/wiki/1984_(advertisement)">1984</a> of course. After the Mac (which was not especially successful), Steve Jobs actually wound up in Apple's SuperMicro division trying to make a 3M machine for real, to crack that market -- a market mostly consisting of PERQs, Suns and Apollos at the time. Apple's foray was going to be the <a href="https://en.wikipedia.org/wiki/Big_Mac_(computer)">Big Mac</a>. It never shipped. When he left Apple, that team went with him to <a href="https://en.wikipedia.org/wiki/NeXT">NeXT</a>, where .. they tried again to build a 3M machine. And they did! Just extremely late, in 1989. And still $10k, despite almost a decade of brutal price competition on the low end.</p><p>The PERQ was <em>literally</em> built to be a commercial Alto, a version-you-could-buy. But it was also not from Palo Alto, or Mountain View, or Cupertino, or anywhere in California. It was from the much less flashy but extremely important computer town of <a href="https://en.wikipedia.org/wiki/Pittsburgh">Pittsburgh, PA</a>. It was built by a <a href="https://en.wikipedia.org/wiki/Carnegie_Mellon_University">CMU</a> spinoff: the <a href="https://en.wikipedia.org/wiki/Three_Rivers_Computer_Corporation">Three Rivers Computer Company</a> (Pittsburgh is at the confluence of 3 rivers). One of the company's founders -- Brian Rosen -- actually went to work on the Star at Xerox PARC for two years, from 76 to 78, and then came back to Three Rivers to pitch everything-he-learned as the basis for a new machine, which became the PERQ. (It was briefly even called the "Pascalto", because like all machines in this genre it supported user-written microcode and custom instruction sets, and the PERQ ran Pascal P-code. Through a microcode emulator. Things were wild.)</p><p>Ok so maybe the PERQ is just Alto in commercial clothing? No there's more! The PERQ didn't run <a href="https://en.wikipedia.org/wiki/Pilot_(operating_system)">Xerox Pilot</a> or whatever, it ran either PNX (a straight Unix port done by <a href="https://en.wikipedia.org/wiki/International_Computers_Limited">ICL</a> running on yet another microcoded VM, C-code) or this other operating system called <a href="https://en.wikipedia.org/wiki/Accent_kernel">Accent</a>. What's that? Why, it's the predecessor of <a href="https://en.wikipedia.org/wiki/Mach_(kernel)">Mach</a>! Written by CMU Professor <a href="https://en.wikipedia.org/wiki/Richard_Rashid">Rick Rashid</a> and his grad student <a href="https://en.wikipedia.org/wiki/Avie_Tevanian">Avie Tevanian</a>. Does that name sound familiar? Avie and Mach are what NeXT bet their farm on in 1988. Mach is what Apple bet their farm on when they bought NeXT, and is what all of today's Apple stuff from watches to phones to laptops runs on. And when Steve pitched Avie to join NeXT in 1986 it was because of the <a href="https://eecs582.github.io/readings/mach-usenix86.pdf">Usenix paper Avie just published</a> about Mach, which ran on VAX, <a href="https://en.wikipedia.org/wiki/IBM_RT_PC">IBM RT/PC</a> (the RS/6000 predecessor) and ... PERQ. Because Avie and Rick, like everyone at CMU, were big PERQ fans, had PERQs all over their department as surrogate Altos. PERQs were the Altos you could buy, that CMU had bought a bunch of, that ran Unix and Mach.</p><p>But wait, why did CMU even want surrogate Altos? How did CMU people have any connection to Altos <em>before</em> PERQs, what motivated that connection, and .. how did Xerox wind up connected here? Aha! Through the even less well-thought-of neighboring city of <a href="https://en.wikipedia.org/wiki/Rochester,_New_York">Rochester, NY</a>! Xerox isn't a west coast company at all. <a href="https://en.wikipedia.org/wiki/Xerox#History">It's from Rochester</a>. Because of even older origin-stories involving the <a href="https://en.wikipedia.org/wiki/Institute_of_Optics">optics</a> business, and Kodak, and (long digression here into east-coast tech history). Anyway it's from Rochester. But their chief scientist <a href="https://en.wikipedia.org/wiki/Jack_Goldman">Jack Goldman</a> was former faculty from CMU which is a short drive from Rochester, and he set up a wild unsupervised west-coast lab in Palo Alto, called Xerox PARC, and when PARC made the Alto, Xerox HQ back in Rochester naturally donated a bunch of them to University of Rochester, and Rick Rashid (then a Rochester PhD) and Avie Tevanian (then a Rochester undergrad) spent their days at Rochester hacking video games on the Alto. And dreaming of someday having their own.</p><p>And then they went down the road to CMU: Rick to a professorship, and Avie to be his student. And CMU was Jack Goldman's alma mater, and so Xerox had also donated a bunch of Altos there. And CMU was enjoying their donated Altos so much they had started up a 3M machine joint hardware-software project: <a href="https://bitsavers.org/pdf/cmu/spice/A_Proposal_For_A_Joint_Effort_In_Personal_Scientific_Computing_Aug1979.pdf">SPICE</a>. Which had ARPA money and was going to involve buying 200 machines from their former colleagues down the street at Three Rivers Computer Company -- 200 PERQs. Which was the first of the 3M machines everyone actually bought and used, in the years between the 3M machine becoming a cool idea and the market imploding right as NeXT tried to enter it.</p><p>So anyway, short story long: the path to modern macOS and iOS machines is less than 100% sunny California people; it involves quite a bit of slushy rust belt grad students (fun fact: mach is named after Pittsburgh winter slush, a mishearing of the word "muck".)</p><p>(There's also much more here involving a <a href="https://www.chilton-computing.org.uk/acd/sus/overview.htm">whole joint development situation with ICL</a>, not just a Unix port, which you definitely should fall down the rabbit hole of -- especially if you're not familiar with ICL itself! -- but I think I've talked enough here already.)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keyhole – Forge own Windows Store licenses (516 pts)]]></title>
            <link>https://massgrave.dev/blog/keyhole</link>
            <guid>41472643</guid>
            <pubDate>Sat, 07 Sep 2024 09:13:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://massgrave.dev/blog/keyhole">https://massgrave.dev/blog/keyhole</a>, See on <a href="https://news.ycombinator.com/item?id=41472643">Hacker News</a></p>
Couldn't get https://massgrave.dev/blog/keyhole: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Richard Feynman and the Connection Machine (1989) (153 pts)]]></title>
            <link>https://longnow.org/essays/richard-feynman-and-connection-machine/</link>
            <guid>41472135</guid>
            <pubDate>Sat, 07 Sep 2024 07:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://longnow.org/essays/richard-feynman-and-connection-machine/">https://longnow.org/essays/richard-feynman-and-connection-machine/</a>, See on <a href="https://news.ycombinator.com/item?id=41472135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        





<p>
    Published on Sunday, January 15, 01989 &nbsp;•&nbsp; <span>35&nbsp;years, 7&nbsp;months ago</span><br> 
    Written by <span>Danny Hillis</span> for <span>Physics Today</span>
</p>

        <p><img src="https://media.longnow.org/files/2/Feynman.JPG" alt=""></p>
<p>One day when I was having lunch with Richard Feynman, I mentioned to him that        I was planning to start a company to build a parallel computer with a million        processors. His reaction was unequivocal, "That is positively the dopiest idea        I ever heard." For Richard a crazy idea was an opportunity to either prove it        wrong or prove it right. Either way, he was interested. By the end of lunch        he had agreed to spend the summer working at the company.</p>
<p>Richard's interest in computing went back to his days at Los Alamos, where        he supervised the "computers," that is, the people who operated the mechanical        calculators. There he was instrumental in setting up some of the first plug-programmable        tabulating machines for physical simulation. His interest in the field was heightened        in the late 1970's when his son, Carl, began studying computers at MIT.</p>
<p>I got to know Richard through his son. I was a graduate student at the MIT        Artificial Intelligence Lab and Carl was one of the undergraduates helping me        with my thesis project. I was trying to design a computer fast enough to solve        common sense reasoning problems. The machine, as we envisioned it, would contain        a million tiny computers, all connected by a communications network. We called        it a "Connection Machine." Richard, always interested in his son's activities,        followed the project closely. He was skeptical about the idea, but whenever        we met at a conference or I visited CalTech, we would stay up until the early        hours of the morning discussing details of the planned machine. The first time        he ever seemed to believe that we were really going to try to build it was the        lunchtime meeting.</p>
<p>Richard arrived in Boston the day after the company was incorporated. We had        been busy raising the money, finding a place to rent, issuing stock, etc. We        set up in an old mansion just outside of the city, and when Richard showed up        we were still recovering from the shock of having the first few million dollars        in the bank. No one had thought about anything technical for several months.        We were arguing about what the name of the company should be when Richard walked        in, saluted, and said, "Richard Feynman reporting for duty. OK, boss, what's        my assignment?" The assembled group of not-quite-graduated MIT students was        astounded.</p>
<p>After a hurried private discussion ("I don't know, you hired him..."), we        informed Richard that his assignment would be to advise on the application of        parallel processing to scientific problems.</p>
<p>"That sounds like a bunch of baloney," he said. "Give me something real to        do."</p>
<p>So we sent him out to buy some office supplies. While he was gone, we decided        that the part of the machine that we were most worried about was the router        that delivered messages from one processor to another. We were not sure that        our design was going to work. When Richard returned from buying pencils, we        gave him the assignment of analyzing the router.</p>
<h2>The Machine</h2>
<p>The router of the Connection Machine was the part of the hardware that allowed        the processors to communicate. It was a complicated device; by comparison, the        processors themselves were simple. Connecting a separate communication wire        between each pair of processors was impractical since a million processors would        require $10^{12]$ wires. Instead, we planned to connect the processors in a        20-dimensional hypercube so that each processor would only need to talk to 20        others directly. Because many processors had to communicate simultaneously,        many messages would contend for the same wires. The router's job was to find        a free path through this 20-dimensional traffic jam or, if it couldn't, to hold        onto the message in a buffer until a path became free. Our question to Richard        Feynman was whether we had allowed enough buffers for the router to operate        efficiently.</p>
<p>During those first few months, Richard began studying the router circuit diagrams        as if they were objects of nature. He was willing to listen to explanations        of how and why things worked, but fundamentally he preferred to figure out everything        himself by simulating the action of each of the circuits with pencil and paper.</p>
<p>In the meantime, the rest of us, happy to have found something to keep Richard        occupied, went about the business of ordering the furniture and computers, hiring        the first engineers, and arranging for the Defense Advanced Research Projects        Agency (DARPA) to pay for the development of the first prototype. Richard did        a remarkable job of focusing on his "assignment," stopping only occasionally        to help wire the computer room, set up the machine shop, shake hands with the        investors, install the telephones, and cheerfully remind us of how crazy we        all were. When we finally picked the name of the company, Thinking Machines        Corporation, Richard was delighted. "That's good. Now I don't have to explain        to people that I work with a bunch of loonies. I can just tell them the name        of the company."</p>
<p>The technical side of the project was definitely stretching our capacities.        We had decided to simplify things by starting with only 64,000 processors, but        even then the amount of work to do was overwhelming. We had to design our own        silicon integrated circuits, with processors and a router. We also had to invent        packaging and cooling mechanisms, write compilers and assemblers, devise ways        of testing processors simultaneously, and so on. Even simple problems like wiring        the boards together took on a whole new meaning when working with tens of thousands        of processors. In retrospect, if we had had any understanding of how complicated        the project was going to be, we never would have started.</p>
<h2>'Get These Guys Organized'</h2>
<p>I had never managed a large group before and I was clearly in over my head.        Richard volunteered to help out. "We've got to get these guys organized," he        told me. "Let me tell you how we did it at Los Alamos."</p>
<p>Every great man that I have known has had a certain time and place in their        life that they use as a reference point; a time when things worked as they were        supposed to and great things were accomplished. For Richard, that time was at        Los Alamos during the Manhattan Project. Whenever things got "cockeyed," Richard        would look back and try to understand how now was different than then. Using        this approach, Richard decided we should pick an expert in each area of importance        in the machine, such as software or packaging or electronics, to become the        "group leader" in this area, analogous to the group leaders at Los Alamos.</p>
<p>Part Two of Feynman's "Let's Get Organized" campaign was that we should begin        a regular seminar series of invited speakers who might have interesting things        to do with our machine. Richard's idea was that we should concentrate on people        with new applications, because they would be less conservative about what kind        of computer they would use. For our first seminar he invited John Hopfield,        a friend of his from CalTech, to give us a talk on his scheme for building neural        networks. In 1983, studying neural networks was about as fashionable as studying        ESP, so some people considered John Hopfield a little bit crazy. Richard was        certain he would fit right in at Thinking Machines Corporation.</p>
<p>What Hopfield had invented was a way of constructing an [associative memory],        a device for remembering patterns. To use an associative memory, one trains        it on a series of patterns, such as pictures of the letters of the alphabet.        Later, when the memory is shown a new pattern it is able to recall a similar        pattern that it has seen in the past. A new picture of the letter "A" will "remind"        the memory of another "A" that it has seen previously. Hopfield had figured        out how such a memory could be built from devices that were similar to biological        neurons.</p>
<p>Not only did Hopfield's method seem to work, but it seemed to work well on        the Connection Machine. Feynman figured out the details of how to use one processor        to simulate each of Hopfield's neurons, with the strength of the connections        represented as numbers in the processors' memory. Because of the parallel nature        of Hopfield's algorithm, all of the processors could be used concurrently with        100\% efficiency, so the Connection Machine would be hundreds of times faster        than any conventional computer.</p>
<h2>An Algorithm For Logarithms</h2>
<p>Feynman worked out the program for computing Hopfield's network on the Connection        Machine in some detail. The part that he was proudest of was the subroutine        for computing logarithms. I mention it here not only because it is a clever        algorithm, but also because it is a specific contribution Richard made to the        mainstream of computer science. He invented it at Los Alamos.</p>
<p>Consider the problem of finding the logarithm of a fractional number between        1.0 and 2.0 (the algorithm can be generalized without too much difficulty).        Feynman observed that any such number can be uniquely represented as a product        of numbers of the form $1 + 2^{-k]$, where $k$ is an integer. Testing each of        these factors in a binary number representation is simply a matter of a shift        and a subtraction. Once the factors are determined, the logarithm can be computed        by adding together the precomputed logarithms of the factors. The algorithm        fit especially well on the Connection Machine, since the small table of the        logarithms of $1 + 2^{-k]$ could be shared by all the processors. The entire        computation took less time than division.</p>
<p>Concentrating on the algorithm for a basic arithmetic operation was typical        of Richard's approach. He loved the details. In studying the router, he paid        attention to the action of each individual gate and in writing a program he        insisted on understanding the implementation of every instruction. He distrusted        abstractions that could not be directly related to the facts. When several years        later I wrote a general interest article on the Connection Machine for [Scientific        American], he was disappointed that it left out too many details. He asked,        "How is anyone supposed to know that this isn't just a bunch of crap?"</p>
<p>Feynman's insistence on looking at the details helped us discover the potential        of the machine for numerical computing and physical simulation. We had convinced        ourselves at the time that the Connection Machine would not be efficient at        "number-crunching," because the first prototype had no special hardware for        vectors or floating point arithmetic. Both of these were "known" to be requirements        for number-crunching. Feynman decided to test this assumption on a problem that        he was familiar with in detail: quantum chromodynamics.</p>
<p>Quantum chromodynamics is a theory of the internal workings of atomic particles        such as protons. Using this theory it is possible, in principle, to compute        the values of measurable physical quantities, such as a proton's mass. In practice,        such a computation requires so much arithmetic that it could keep the fastest        computers in the world busy for years. One way to do this calculation is to        use a discrete four-dimensional lattice to model a section of space-time. Finding        the solution involves adding up the contributions of all of the possible configurations        of certain matrices on the links of the lattice, or at least some large representative        sample. (This is essentially a Feynman path integral.) The thing that makes        this so difficult is that calculating the contribution of even a single configuration        involves multiplying the matrices around every little loop in the lattice, and        the number of loops grows as the fourth power of the lattice size. Since all        of these multiplications can take place concurrently, there is plenty of opportunity        to keep all 64,000 processors busy.</p>
<p>To find out how well this would work in practice, Feynman had to write a computer        program for QCD. Since the only computer language Richard was really familiar        with was Basic, he made up a parallel version of Basic in which he wrote the        program and then simulated it by hand to estimate how fast it would run on the        Connection Machine.</p>
<p>He was excited by the results. "Hey Danny, you're not going to believe this,        but that machine of yours can actually do something [useful]!" According to        Feynman's calculations, the Connection Machine, even without any special hardware        for floating point arithmetic, would outperform a machine that CalTech was building        for doing QCD calculations. From that point on, Richard pushed us more and more        toward looking at numerical applications of the machine.</p>
<p>By the end of that summer of 1983, Richard had completed his analysis of the        behavior of the router, and much to our surprise and amusement, he presented        his answer in the form of a set of partial differential equations. To a physicist        this may seem natural, but to a computer designer, treating a set of boolean        circuits as a continuous, differentiable system is a bit strange. Feynman's        router equations were in terms of variables representing continuous quantities        such as "the average number of 1 bits in a message address." I was much more        accustomed to seeing analysis in terms of inductive proof and case analysis        than taking the derivative of "the number of 1's" with respect to time. Our        discrete analysis said we needed seven buffers per chip; Feynman's equations        suggested that we only needed five. We decided to play it safe and ignore Feynman.</p>
<p>The decision to ignore Feynman's analysis was made in September, but by next        spring we were up against a wall. The chips that we had designed were slightly        too big to manufacture and the only way to solve the problem was to cut the        number of buffers per chip back to five. Since Feynman's equations claimed we        could do this safely, his unconventional methods of analysis started looking        better and better to us. We decided to go ahead and make the chips with the        smaller number of buffers.</p>
<p>Fortunately, he was right. When we put together the chips the machine worked.        The first program run on the machine in April of 1985 was Conway's game of Life.</p>
<h2>Cellular Automata</h2>
<p>The game of Life is an example of a class of computations that interested        Feynman called [cellular automata]. Like many physicists who had spent their        lives going to successively lower and lower levels of atomic detail, Feynman        often wondered what was at the bottom. One possible answer was a cellular automaton.        The notion is that the "continuum" might, at its lowest levels, be discrete        in both space and time, and that the laws of physics might simply be a macro-consequence        of the average behavior of tiny cells. Each cell could be a simple automaton        that obeys a small set of rules and communicates only with its nearest neighbors,        like the lattice calculation for QCD. If the universe in fact worked this way,        then it presumably would have testable consequences, such as an upper limit        on the density of information per cubic meter of space.</p>
<p>The notion of cellular automata goes back to von Neumann and Ulam, whom Feynman        had known at Los Alamos. Richard's recent interest in the subject was motivated        by his friends Ed Fredkin and Stephen Wolfram, both of whom were fascinated        by cellular automata models of physics. Feynman was always quick to point out        to them that he considered their specific models "kooky," but like the Connection        Machine, he considered the subject sufficiently crazy to put some energy into.</p>
<p>There are many potential problems with cellular automata as a model of physical        space and time; for example, finding a set of rules that obeys special relativity.        One of the simplest problems is just making the physics so that things look        the same in every direction. The most obvious pattern of cellular automata,        such as a fixed three-dimensional grid, have preferred directions along the        axes of the grid. Is it possible to implement even Newtonian physics on a fixed        lattice of automata?</p>
<p>Feynman had a proposed solution to the anisotropy problem which he attempted        (without success) to work out in detail. His notion was that the underlying        automata, rather than being connected in a regular lattice like a grid or a        pattern of hexagons, might be randomly connected. Waves propagating through        this medium would, on the average, propagate at the same rate in every direction.</p>
<p>Cellular automata started getting attention at Thinking Machines when Stephen        Wolfram, who was also spending time at the company, suggested that we should        use such automata not as a model of physics, but as a practical method of simulating        physical systems. Specifically, we could use one processor to simulate each        cell and rules that were chosen to model something useful, like fluid dynamics.        For two-dimensional problems there was a neat solution to the anisotropy problem        since [Frisch, Hasslacher, Pomeau] had shown that a hexagonal lattice with a        simple set of rules produced isotropic behavior at the macro scale. Wolfram        used this method on the Connection Machine to produce a beautiful movie of a        turbulent fluid flow in two dimensions. Watching the movie got all of us, especially        Feynman, excited about physical simulation. We all started planning additions        to the hardware, such as support of floating point arithmetic that would make        it possible for us to perform and display a variety of simulations in real time.</p>
<h2>Feynman the Explainer</h2>
<p>In the meantime, we were having a lot of trouble explaining to people what        we were doing with cellular automata. Eyes tended to glaze over when we started        talking about state transition diagrams and finite state machines. Finally Feynman        told us to explain it like this,</p>
<p>"We have noticed in nature that the behavior of a fluid depends very little        on the nature of the individual particles in that fluid. For example, the flow        of sand is very similar to the flow of water or the flow of a pile of ball bearings.        We have therefore taken advantage of this fact to invent a type of imaginary        particle that is especially simple for us to simulate. This particle is a perfect        ball bearing that can move at a single speed in one of six directions. The flow        of these particles on a large enough scale is very similar to the flow of natural        fluids."</p>
<p>This was a typical Richard Feynman explanation. On the one hand, it infuriated        the experts who had worked on the problem because it neglected to even mention        all of the clever problems that they had solved. On the other hand, it delighted        the listeners since they could walk away from it with a real understanding of        the phenomenon and how it was connected to physical reality.</p>
<p>We tried to take advantage of Richard's talent for clarity by getting him        to critique the technical presentations that we made in our product introductions.        Before the commercial announcement of the Connection Machine CM-1 and all of        our future products, Richard would give a sentence-by-sentence critique of the        planned presentation. "Don't say `reflected acoustic wave.' Say [echo]." Or,        "Forget all that `local minima' stuff. Just say there's a bubble caught in the        crystal and you have to shake it out." Nothing made him angrier than making        something simple sound complicated.</p>
<p>Getting Richard to give advice like that was sometimes tricky. He pretended        not to like working on any problem that was outside his claimed area of expertise.        Often, at Thinking Machines when he was asked for advice he would gruffly refuse        with "That's not my department." I could never figure out just what his department        was, but it did not matter anyway, since he spent most of his time working on        those "not-my-department" problems. Sometimes he really would give up, but more        often than not he would come back a few days after his refusal and remark, "I've        been thinking about what you asked the other day and it seems to me..." This        worked best if you were careful not to expect it.</p>
<p>I do not mean to imply that Richard was hesitant to do the "dirty work." In        fact, he was always volunteering for it. Many a visitor at Thinking Machines        was shocked to see that we had a Nobel Laureate soldering circuit boards or        painting walls. But what Richard hated, or at least pretended to hate, was being        asked to give advice. So why were people always asking him for it? Because even        when Richard didn't understand, he always seemed to understand better than the        rest of us. And whatever he understood, he could make others understand as well.        Richard made people feel like a child does, when a grown-up first treats him        as an adult. He was never afraid of telling the truth, and however foolish your        question was, he never made you feel like a fool.</p>
<p>The charming side of Richard helped people forgive him for his uncharming        characteristics. For example, in many ways Richard was a sexist. Whenever it        came time for his daily bowl of soup he would look around for the nearest "girl"        and ask if she would fetch it to him. It did not matter if she was the cook,        an engineer, or the president of the company. I once asked a female engineer        who had just been a victim of this if it bothered her. "Yes, it really annoys        me," she said. "On the other hand, he is the only one who ever explained quantum        mechanics to me as if I could understand it." That was the essence of Richard's        charm.</p>
<h2>A Kind Of Game</h2>
<p>Richard worked at the company on and off for the next five years. Floating        point hardware was eventually added to the machine, and as the machine and its        successors went into commercial production, they were being used more and more        for the kind of numerical simulation problems that Richard had pioneered with        his QCD program. Richard's interest shifted from the construction of the machine        to its applications. As it turned out, building a big computer is a good excuse        to talk to people who are working on some of the most exciting problems in science.        We started working with physicists, astronomers, geologists, biologists, chemists        --- everyone of them trying to solve some problem that it had never been possible        to solve before. Figuring out how to do these calculations on a parallel machine        requires understanding of the details of the application, which was exactly        the kind of thing that Richard loved to do.</p>
<p>For Richard, figuring out these problems was a kind of a game. He always started        by asking very basic questions like, "What is the simplest example?" or "How        can you tell if the answer is right?" He asked questions until he reduced the        problem to some essential puzzle that he thought he would be able to solve.        Then he would set to work, scribbling on a pad of paper and staring at the results.        While he was in the middle of this kind of puzzle solving he was impossible        to interrupt. "Don't bug me. I'm busy," he would say without even looking up.        Eventually he would either decide the problem was too hard (in which case he        lost interest), or he would find a solution (in which case he spent the next        day or two explaining it to anyone who listened). In this way he worked on problems        in database searches, geophysical modeling, protein folding, analyzing images,        and reading insurance forms.</p>
<p>The last project that I worked on with Richard was in simulated evolution.        I had written a program that simulated the evolution of populations of sexually        reproducing creatures over hundreds of thousands of generations. The results        were surprising in that the fitness of the population made progress in sudden        leaps rather than by the expected steady improvement. The fossil record shows        some evidence that real biological evolution might also exhibit such "punctuated        equilibrium," so Richard and I decided to look more closely at why it happened.        He was feeling ill by that time, so I went out and spent the week with him in        Pasadena, and we worked out a model of evolution of finite populations based        on the Fokker Planck equations. When I got back to Boston I went to the library        and discovered a book by Kimura on the subject, and much to my disappointment,        all of our "discoveries" were covered in the first few pages. When I called        back and told Richard what I had found, he was elated. "Hey, we got it right!"        he said. "Not bad for amateurs."</p>
<p>In retrospect I realize that in almost everything that we worked on together,        we were both amateurs. In digital physics, neural networks, even parallel computing,        we never really knew what we were doing. But the things that we studied were        so new that no one else knew exactly what they were doing either. It was amateurs        who made the progress.</p>
<h2>Telling The Good Stuff You Know</h2>
<p>Actually, I doubt that it was "progress" that most interested Richard. He        was always searching for patterns, for connections, for a new way of looking        at something, but I suspect his motivation was not so much to understand the        world as it was to find new ideas to explain. The act of discovery was not complete        for him until he had taught it to someone else.</p>
<p>I remember a conversation we had a year or so before his death, walking in        the hills above Pasadena. We were exploring an unfamiliar trail and Richard,        recovering from a major operation for the cancer, was walking more slowly than        usual. He was telling a long and funny story about how he had been reading up        on his disease and surprising his doctors by predicting their diagnosis and        his chances of survival. I was hearing for the first time how far his cancer        had progressed, so the jokes did not seem so funny. He must have noticed my        mood, because he suddenly stopped the story and asked, "Hey, what's the matter?"</p>
<p>I hesitated. "I'm sad because you're going to die."</p>
<p>"Yeah," he sighed, "that bugs me sometimes too. But not so much as you think."        And after a few more steps, "When you get as old as I am, you start to realize        that you've told most of the good stuff you know to other people anyway."</p>
<p>We walked along in silence for a few minutes. Then we came to a place where        another trail crossed and Richard stopped to look around at the surroundings.        Suddenly a grin lit up his face. "Hey," he said, all trace of sadness forgotten,        "I bet I can show you a better way home."</p>
<p>And so he did.</p>
    </div></div>]]></description>
        </item>
    </channel>
</rss>