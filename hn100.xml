<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 06 Aug 2024 14:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[WordStar 7, the last ever DOS version, is re-released for free (130 pts)]]></title>
            <link>https://www.theregister.com/2024/08/06/wordstar_7_the_last_ever/</link>
            <guid>41169195</guid>
            <pubDate>Tue, 06 Aug 2024 09:47:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/08/06/wordstar_7_the_last_ever/">https://www.theregister.com/2024/08/06/wordstar_7_the_last_ever/</a>, See on <a href="https://news.ycombinator.com/item?id=41169195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Before WordPerfect, the most popular work processor was WordStar. Now, the last ever DOS version has been bundled and set free by one of its biggest fans.</p>
<div><p><a href="https://regmedia.co.uk/2024/08/05/wordstar-7-on-macos.png" target="_blank"><img src="https://regmedia.co.uk/2024/08/05/wordstar-7-on-macos.png?x=648&amp;y=375&amp;infer_y=1" alt="wordstar 7 on macos" title="wordstar 7 on macos" height="375" width="648"></a></p><p>Wordstar 7 on macOS - click to enlarge</p>
</div>
<p>WordStar 7.0d was the last-ever DOS release of <em>the</em> classic word processor, and it still has admirers today. A <a href="https://sfwriter.com/wordstar.htm" rel="nofollow">notable enthusiast</a> is Canadian SF writer Robert J Sawyer, who wrote the book that became the <a href="https://www.imdb.com/title/tt1441135/" rel="nofollow">TV series <em>Flashforward</em></a>.</p>
<p>Thanks to his efforts you can now try out this pinnacle of pre-Windows PC programs for professional prose-smiths. Sawyer has taken the final release, packaged it up along with some useful tools — including DOS emulators for modern Windows – and <a href="https://sfwriter.com/blog/?p=5806" rel="nofollow">shared the result</a>. Now you, too, can revel in the sheer unbridled power of this powerful app.</p>
<p>Sawyer says:</p>

<p>The download is 680MB, but as well as the app itself, full documentation, and some tools to help translate WordStar documents to more modern formats, it also includes copies of two FOSS tools that will let you run this MS-DOS application on modern Windows: <a href="https://dosbox-x.com/" rel="nofollow">DOSbox-X</a> and <a href="http://vdosplus.org/" rel="nofollow">vDosPlus</a>. Regular <em>Register</em> readers may recognize both from our story on <a href="https://www.theregister.com/2022/06/28/friday_foss_fest_running_dos/">how to run DOS on a 64-bit OS</a> from last year. Sawyer also offers a <a href="https://www.sfwriter.com/wordstar-command-summary.pdf" rel="nofollow">handy command reference</a> [PDF].</p>
<p>WordStar has a long and exceptionally involved history, as the Wordstar.org fan site <a href="https://web.archive.org/web/20240525080009/https:/www.wordstar.org/index.php/wordstar-history" rel="nofollow">used to chronicle</a>. It started out on CP/M, was ported to DOS, multiple incompatible programs of the same name launched, and later still <a href="https://winworldpc.com/product/wordstar/20-for-windows" rel="nofollow">ported to Windows</a>. The last ever release was part of an <a href="https://winworldpc.com/product/xoom-office-suite/97" rel="nofollow">obscure office suite</a>. Sawyer is correct: the final DOS version really is the true classic.</p>
<p>MicroPro, the company behind WordStar, was repeatedly acquired. At one point it was part of SoftKey, which was acquired and became <a href="https://www.theregister.com/1999/05/04/fears_grow_over_web_perverting/">the Learning Company</a>, which was <a href="https://www.theregister.com/2000/02/08/was_mattel_ceo_pushed/">bought by Mattel</a> in what <a href="https://www.theglobeandmail.com/report-on-business/rob-magazine/kevin-oleary-hes-not-a-billionaire-he-just-plays-one-on-tv/article4564334/?page=all" rel="nofollow">BusinessWeek called</a> "the worst acquisition of all time." As a result, the software business was spun off again and bought by <a href="https://www.theregister.com/2007/10/19/ireland_mergers_acquisitions/">Houghton Mifflin Riverdeep</a>. Sawyer says:</p>

<p>While it certainly has been abandoned since the end of the 20th century, the term "abandonware" isn't a legal one. It's not clear to us who owns the intellectual property. We doubt it's one of the surviving offshoots, today's <a href="https://www.hmhco.com/about-us" rel="nofollow">Houghton Mifflin Harcourt</a>, but it could be another offshoot, <a href="https://www.mackiev.com/" rel="nofollow">Software MacKiev</a>. Either way, it's very unlikely that the owners will care.</p>
<p>If the many changes&nbsp;of ownership weren't enough, the program itself had many offshoots. A rewrite in C became the incompatible <a href="https://winworldpc.com/product/wordstar/2000" rel="nofollow">Wordstar 2000</a>, that abandoned the keyboard-centric UI which was WordStar's hallmark. MicroPro also acquired a student's Modula-2 project and rebadged it WordStar Express, which Amstrad PC 1512 owners may remember: Amstrad got a licence cheaply and bundled it as "WordStar 1512". Even WordStar 7 isn't based on the original code: MicroPro bought a rival clone of the program called NewWord, and made it the official WordStar 4 – as still <a href="https://www.bbc.co.uk/news/technology-27407502" rel="nofollow">used by George R R Martin</a>.</p>
<ul>

<li><a href="https://www.theregister.com/2024/07/03/wordperfect_bruce_bastian/">RIP: WordPerfect co-founder Bruce Bastian dies at 76</a></li>

<li><a href="https://www.theregister.com/2023/10/25/microsoft_word_40/">Word turns 40: From 'new kid on the block' to 'I can't believe it's not bloatware'</a></li>

<li><a href="https://www.theregister.com/2022/03/04/on_call/">Saving a loved one from a document disaster</a></li>

<li><a href="https://www.theregister.com/2021/12/17/tilde_text_editor/">Fans of original gangster editors, look away now: It's Tilde, a text editor that doesn't work like it's 1976</a></li>
</ul>
<p>While many folks in the Unix world have Vi keystrokes engraved in their muscle memory, those for WordStar are the equivalent for CP/M and MS-DOS users&nbsp;of a certain age. <code>Ctrl+S/ E/D/X</code> for navigation, <code>Ctrl+K, B</code> to mark the start of a block, <code>Ctrl+K, K</code> to mark the end, then <code>Ctrl+K, C</code> to copy it or <code>Ctrl+K, V</code> to move it; and <code>Ctrl+K+S</code> to Save. The modern <a href="https://joe-editor.sourceforge.io/" rel="nofollow">Joe text editor</a> still uses them, for instance. It hasn't got all the functionality, but if you don't want to struggle with an emulator to run a DOS app, the FOSS clone <a href="http://wordtsar.ca/" rel="nofollow">WordTsar</a> comes close, and has <a href="https://sourceforge.net/projects/wordtsar/files/Releases/" rel="nofollow">versions for Windows, Linux and macOS</a>.</p>
<p>By modern standards, WordStar doesn't do much, but it does everything many writers want. The <em>Reg</em> FOSS desk is rather fond of Robert Sawyer's novels, as well as George R R Martin's come to that, but those less given to genre fiction may recognize William F Buckley Jr and Ralph Ellison, both&nbsp;keen users. ®</p>

    
                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI co-founder John Schulman says he will leave and join rival Anthropic (317 pts)]]></title>
            <link>https://www.cnbc.com/2024/08/06/openai-co-founder-john-schulman-says-he-will-join-rival-anthropic.html</link>
            <guid>41168904</guid>
            <pubDate>Tue, 06 Aug 2024 08:39:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/08/06/openai-co-founder-john-schulman-says-he-will-join-rival-anthropic.html">https://www.cnbc.com/2024/08/06/openai-co-founder-john-schulman-says-he-will-join-rival-anthropic.html</a>, See on <a href="https://news.ycombinator.com/item?id=41168904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108016585" data-test="InlineImage"><p>The ChatGPT chat screen on a smartphone arranged in the Brooklyn borough of New York, US, on Thursday, March 9, 2023. ChatGPT has made writing computer code and cheating on homework easier. Soon, it could make email scams a cinch. That's the warning from Darktrace Plc, the British cybersecurity firm.</p><p>Gabby Jones | Bloomberg | Getty Images</p></div><div><p>OpenAI co-founder John Schulman said in a Monday X post that he would leave the <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>-backed company and join Anthropic, an artificial intelligence startup with funding from <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>.</p><p>The move comes less than three months after OpenAI <a href="https://www.cnbc.com/2024/05/17/openai-superalignment-sutskever-leike.html">disbanded a superalignment team</a> that focused on trying to ensure that people can control AI systems that exceed human capability at many tasks.</p><p>Schulman had been a co-leader of OpenAI's post-training team that refined AI models for the ChatGPT chatbot and a programming interface for third-party developers, according to a biography on his <a href="http://joschu.net/" target="_blank">website</a>. In June, OpenAI <a href="https://openai.com/index/openai-board-forms-safety-and-security-committee/" target="_blank">said</a> Schulman, as head of alignment science, would join a safety and security committee that would provide advice to the board. Schulman has only worked at OpenAI since receiving a Ph.D. in computer science in 2016 from the University of California, Berkeley.</p><p>"This choice stems from my desire to deepen my focus on AI alignment, and to start a new chapter of my career where I can return to hands-on technical work," Schulman wrote in the <a href="https://x.com/johnschulman2/status/1820610863499509855" target="_blank">social media post</a>.</p><p>He said he wasn't leaving because of a lack of support for new work on the topic at OpenAI.</p><p>"On the contrary, company leaders have been very committed to investing in this area," he said.</p><p>The leaders of the superalignment team, Jan Leike and company co-founder Ilya Sutskever, both left this year. Leike <a href="https://www.cnbc.com/2024/05/28/openai-safety-leader-jan-leike-joins-amazon-backed-anthropic.html">joined Anthropic</a>, while Sutskever said he was <a href="https://www.cnbc.com/2024/06/19/openai-co-founder-ilya-sutskever-announces-safe-superintelligence.html">helping to start</a> a new company, Safe Superintelligence Inc.</p><p>Since OpenAI staff members established Anthropic in 2021, the two young San Francisco-based businesses have been battling to have the most performant generative AI models that can come up with human-like text. Amazon, Google and Meta have also developed large language models.</p><p>"Very excited to be working together again!" Leike wrote <a href="https://x.com/janleike/status/1820613953350959504" target="_blank">in reply</a> to Schulman's message.</p><p>Sam Altman, OpenAI's co-founder and CEO, said in a <a href="https://x.com/sama/status/1820617107354083611" target="_blank">post</a> of his own that Schulman's perspective informed the startup's early strategy.</p><p>Schulman and others chose to leave after the board pushed out Altman as chief last November. Employees protested the decision, prompting Sutskever and two other board members, Tasha McCauley and Helen Toner, to resign. <a href="https://www.cnbc.com/2023/11/22/openai-brings-sam-altman-back-as-ceo-days-after-ouster.html">Altman was reinstated</a> and OpenAI took on additional board members.</p><p>Toner said on a<a href="https://www.thedailybeast.com/former-openai-board-member-helen-toner-dishes-on-reasons-why-they-ousted-sam-altman" target="_blank"> podcast</a> that Altman had given the board incorrect information about the "small number of formal safety processes that the company did have in place."</p><p>The law firm WilmerHale found in an independent <a href="https://openai.com/index/review-completed-altman-brockman-to-continue-to-lead-openai/" target="_blank">review</a> that the board wasn't concerned about product safety when it pushed out Altman.</p><p>Last week, Altman <a href="https://x.com/sama/status/1818867964369928387" target="_blank">said on X</a> that OpenAI "has been working with the US AI Safety Institute on an agreement where we would provide early access to our next foundation model so that we can work together to push forward the science of AI evaluations." Altman said OpenAI is still committed to keeping 20% of its computing resources for safety initiatives.</p><p>Also on Monday, Greg Brockman, another co-founder of OpenAI and its president, announced that he was taking a <a href="https://x.com/gdb/status/1820644694264791459" target="_blank">sabbatical for the rest of the year</a>.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2024/07/25/openai-announces-a-search-engine-called-searchgpt.html">OpenAI announces a search engine called SearchGPT</a></p></div><div id="Placeholder-ArticleBody-Video-108011950" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000346800" aria-labelledby="Placeholder-ArticleBody-Video-108011950"><p><img src="https://image.cnbcfm.com/api/v1/image/108011951-17219321001721932097-35516808318-1080pnbcnews.jpg?v=1721932099&amp;w=750&amp;h=422&amp;vtcrop=y" alt="OpenAI announces a search engine called SearchGPT"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X is closing San Francisco HQ and relocating staffers to San Jose (175 pts)]]></title>
            <link>https://fortune.com/2024/08/05/x-closing-san-francisco-hq-relocating-staffers-san-jose-palo-alto-shared-space-with-x-ai-linda-yaccarino-leaked-email/</link>
            <guid>41168889</guid>
            <pubDate>Tue, 06 Aug 2024 08:37:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2024/08/05/x-closing-san-francisco-hq-relocating-staffers-san-jose-palo-alto-shared-space-with-x-ai-linda-yaccarino-leaked-email/">https://fortune.com/2024/08/05/x-closing-san-francisco-hq-relocating-staffers-san-jose-palo-alto-shared-space-with-x-ai-linda-yaccarino-leaked-email/</a>, See on <a href="https://news.ycombinator.com/item?id=41168889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="article-content" id="article-content"><p>X, the social media company formerly known as <a href="https://fortune.com/company/twitter/" target="_blank" aria-label="Go to https://fortune.com/company/twitter/">Twitter</a>, is set to leave San Francisco in the coming weeks.</p><div>



<p>In a Monday email from Linda Yaccarino, the<a href="https://fortune.com/2023/11/20/inside-elon-musk-twitter-44-billion-takeover-x-oral-history/" target="_self" aria-label="Go to https://fortune.com/2023/11/20/inside-elon-musk-twitter-44-billion-takeover-x-oral-history/"> CEO of X appointed last year by owner Elon Musk</a>, X staffers were briefly informed of the company’s plans to shutter the office that has served as Twitter headquarters for more than a decade.</p>



<p>“After much thought, we have made the decision to close our San Francisco office over the next few weeks,” Yaccarino wrote in the email viewed by <em>Fortune</em>. “This is an important decision that impacts many of you, but it is the right one for our company in the long term.”</p>



<p>Musk abruptly&nbsp;<a href="https://x.com/elonmusk/status/1813295489032622586?lang=en" target="_blank" aria-label="Go to https://x.com/elonmusk/status/1813295489032622586?lang=en" rel="noopener">stated on X</a>&nbsp;about three weeks ago that the company’s headquarters would move to Texas, where his other companies <a href="https://fortune.com/company/spacex/" target="_blank" aria-label="Go to https://fortune.com/company/spacex/">SpaceX</a>, <a href="https://fortune.com/company/tesla/" target="_blank" aria-label="Go to https://fortune.com/company/tesla/">Tesla</a> and The Boring Company, are also located. Musk and X were sued earlier this year by the owner of the Market Street building, for allegedly failing to pay rent after Musk took over Twitter in late 2022. The building owner&nbsp;<a href="https://www.reuters.com/legal/litigation/xs-san-francisco-landlord-dismisses-lawsuit-claiming-unpaid-rent-2024-03-19/" target="_blank" aria-label="Go to https://www.reuters.com/legal/litigation/xs-san-francisco-landlord-dismisses-lawsuit-claiming-unpaid-rent-2024-03-19/" rel="noopener">dismissed</a>&nbsp;the lawsuit in March.&nbsp;&nbsp;</p>



<p>Yaccarino’s note to X staff said nothing of a move to Texas, as Musk claimed last month. Instead, she said that X staff located in San Francisco would be moved to existing office space in San Jose and Palo Alto.&nbsp;</p>



<p>“We will work to transition to our new primary locations in the Bay Area,” she wrote.</p>



<p>The move comes as San Francisco is struggling to revive its downtown district and its commercial real estate market. And it marks a setback to the city’s efforts to turn the gritty mid-Market Street area into a thriving tech hub. </p>



<p><a href="https://www.sfgate.com/business/article/twitter-signs-lease-for-headquarters-in-mid-market-2374112.php" target="_blank" aria-label="Go to https://www.sfgate.com/business/article/twitter-signs-lease-for-headquarters-in-mid-market-2374112.php" rel="noopener">Twitter took over the San Francisco space</a>—an expansive, 1-million square foot Art Deco building that once served as a furniture showroom—and made it its global headquarters in 2012. Soon after Musk became Twitter’s owner, firing thousands of employees, several floors of the building were effectively closed; and when the company was renamed X, the famous <a href="https://fortune.com/2023/07/26/passionate-elon-musk-employees-are-coating-the-twitter-offices-in-black-paint-and-boasting-about-hunting-and-eradicating-remnants-of-the-twitter-bird/" target="_self" aria-label="Go to https://fortune.com/2023/07/26/passionate-elon-musk-employees-are-coating-the-twitter-offices-in-black-paint-and-boasting-about-hunting-and-eradicating-remnants-of-the-twitter-bird/">Twitter sign (along with all other vestiges of the company’s pre-Musk era) were summarily removed</a>. More than a dozen&nbsp;<a href="https://www.businessinsider.com/elon-musk-twitter-layoffs-closing-international-offices-singapore-europe-2023-1#:~:text=Twitter%20is%20leaving%20at%20least,Twitter's%20new%20owner%2C%20Elon%20Musk." target="_blank" aria-label="Go to https://www.businessinsider.com/elon-musk-twitter-layoffs-closing-international-offices-singapore-europe-2023-1#:~:text=Twitter%20is%20leaving%20at%20least,Twitter's%20new%20owner%2C%20Elon%20Musk." rel="noopener">global offices were closed as well.</a>&nbsp;Musk also ended the company’s flexible work from home policy, requiring all employees to work in the office every day.&nbsp;</p>



<p>X representatives did not respond to an email seeking comment. Details of Yaccarino’s email was first <a href="https://www.nytimes.com/2024/08/05/technology/x-twitter-san-francisco-office.html" target="_blank" aria-label="Go to https://www.nytimes.com/2024/08/05/technology/x-twitter-san-francisco-office.html" rel="noopener">reported by the New York Times</a>. </p>



<p>Below is the full note that Yaccarino sent staffers on Monday:</p>



<p>Title:<em>&nbsp;SF Office Closing</em></p>



<p><em>All,</em></p>



<p><em>After much thought, we have made the decision to close our San Francisco office over the next few weeks. This is an important decision that impacts many of you, but it is the right one for our company in the long term.</em></p>



<p><em>We will work to transition to our new primary locations in the Bay Area including the existing office in San Jose and a new engineering focused shared space with XAl in Palo Alto.</em></p>



<p><em>For those based in San Francisco, I know this will impact you all in different ways. Leadership is actively working on plans, including transportation options, for those directly impacted.</em></p>



<p><em>Further information and next steps will be communicated in the coming weeks.</em></p></div><p><strong>Recommended Newsletter:</strong> The Fortune Next to Lead newsletter is a must-read for the next generation of C-suite leaders. Every Monday, the newsletter provides the strategies, resources, and expert insight needed to claim the most coveted positions in business. <a href="https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google" target="_self" aria-label="Go to https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google">Subscribe now</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Soul of Maintaining a New Machine (160 pts)]]></title>
            <link>https://books.worksinprogress.co/book/maintenance-of-everything/communities-of-practice/the-soul-of-maintaining-a-new-machine/1</link>
            <guid>41167615</guid>
            <pubDate>Tue, 06 Aug 2024 03:49:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://books.worksinprogress.co/book/maintenance-of-everything/communities-of-practice/the-soul-of-maintaining-a-new-machine/1">https://books.worksinprogress.co/book/maintenance-of-everything/communities-of-practice/the-soul-of-maintaining-a-new-machine/1</a>, See on <a href="https://news.ycombinator.com/item?id=41167615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><p data-block-index="0"><span>T</span>THEY ATE TOGETHER every chance they could.&nbsp; They had to.&nbsp; The enormous photocopiers they were responsible for maintaining were so complex, temperamental, and variable between models and upgrades that it was difficult to keep the machines functioning without frequent conversations with their peers about the ever-shifting nuances of repair and care.&nbsp; The core of their operational knowledge was social.&nbsp; That’s the subject of this chapter.</p><p data-block-index="1">It was the mid-1980s.&nbsp; They were the technician teams charged with servicing the Xerox machines that suddenly were providing all of America’s offices with vast quantities of photocopies and frustration.&nbsp; The machines were so large, noisy, and busy that most offices kept them in a separate room.&nbsp;&nbsp;</p><p data-block-index="2">An inquisitive anthropologist discovered that what the technicians did all day with those machines was grotesquely different from what Xerox corporation thought they did, and the divergence was hampering the company unnecessarily.&nbsp; The saga that followed his revelation is worth recounting in detail because of what it shows about the ingenuity of professional maintainers at work in a high-ambiguity environment, the harm caused by an institutionalized wrong theory of their work, and the invincible power of an institutionalized wrong theory to resist change.</p><figure><p><img sizes="(max-width: 1050px) 100vw, 800px" loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/wnul3lsbpisc9bau28qa"></p><figcaption><p>The cover of Julian Orr’s influential <em>Talking About Machines </em>shows technicians working on the Xerox 5090 photocopier, introduced in 1990.&nbsp; Though they were doing messy blue-collar work, Xerox required the technicians to act and dress white-collar.&nbsp; They carried their tools in a briefcase.</p></figcaption><figcaption><a href="https://www.amazon.com/Talking-about-Machines-Ethnography-Collection/dp/0801432979/ref=sr_1_1" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="4">The anthropologist was Julian Orr.&nbsp; In 1979, he was hired by Xerox PARC (Palo Alto Research Center) in northern California to provide technical support for two machines being developed there—the Alto computer and a color laser printer.&nbsp; By 1984 he had migrated to studying Xerox service technicians, encouraged by John Seely Brown, then a lab manager, later director of PARC.&nbsp; Orr’s research culminated in <sub><strong>a remarkable book titled </strong></sub><sub><em><strong>Talking About Machines</strong></em></sub><em>: An Ethnography of a Modern Job</em>, published in 1996.&nbsp; His book shows that the most baffling problems the technicians faced in their machines were solved by <em>discussion</em>, and the most instructive element in their conversation was what Orr calls “war stories”—narratives the technicians told each other about how they worked through a bewildering problem in a machine to arrive at a satisfying solution.</p><p data-block-index="5">The stories also establish the teller’s contribution to the local community of technicians.&nbsp; Orr writes:</p><blockquote data-block-index="6">Given that the only status within the community is that of competent practitioner, fame can only be based on a reputation for extraordinarily competent practice, the ability to solve newer and harder problems.&nbsp; Since technicians normally work alone, achievements will only be known if the person responsible tells them.&nbsp; Moreover, technicians want the information to circulate, so that others can address similar problems.&nbsp; A team shares responsibility for its calls, so there is incentive to have all members competent for as many problems as possible.<sup>1</sup></blockquote><p data-block-index="7">Often, the issue was not with the copier but with unintentionally destructive behavior by the users.&nbsp; That, too, was considered fixable.&nbsp; Orr declares that the technicians’</p><blockquote data-block-index="8">practice is a continuous, highly skilled improvisation within a triangular relationship of technician, customer, and machine…. Narrative forms a primary element of this practice.&nbsp; The actual process of diagnosis involves the creation of a coherent account of the troubled state of the machine from available pieces of unintegrated information…. A coherent diagnostic narrative constitutes a technician’s mastery of the problematic situation.</blockquote><blockquote data-block-index="9">Narrative preserves such diagnoses as they are told to colleagues…. The circulation of stories among the community of technicians is the principal means by which the technicians stay informed of the developing subtleties of machine behavior in the field.<sup>2</sup></blockquote><p data-block-index="10">By the mid-1980s, Xerox copiers had reached such a degree of complexity that “individual machines,” Orr writes, “are quite idiosyncratic, new failure modes appear continuously, and rote procedure cannot address unknown problems.”<sup>3</sup></p><figure><p><img sizes="(max-width: 1050px) 100vw, 1000px" loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/doq9sgdspwlb35zxjmum"></p><figcaption><p>A Xerox 9400 with its panel open for technicians to get at the guts of the machine.</p></figcaption><figcaption><a href="https://xeroxnostalgia.com/wp-content/uploads/2013/10/9400_front_cover_open.jpg" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><figure><p><img sizes="(max-width: 1050px) 100vw, 1000px" loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/kbmbbdvwtbbijqkwsluu"></p><figcaption><p>Specifying the exact features for a copying job on the 9400’s control panel was not for the faint of heart.  Users varied in their sophistication.  When the machine had a problem, some customers could communicate helpfully with the repair technicians.  Many could not.  Some were, in fact, the cause of the problem.</p></figcaption><figcaption><a href="https://xeroxnostalgia.com/2013/10/27/xerox-9500/?_gallery=gg-18-134" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><figure><p><img loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/yianyfxrscau6apzn4mz"></p><figcaption><p>Jane Fonda’s first-day-on-the-job character is overwhelmed by a Xerox 9400 belching copies at her in the feminist comedy <em>9 to 5</em>, made in 1980, co-starring Dolly Parton and Lily Tomlin.  Her humiliating defeat by the copy machine was a common experience for office workers in those years.</p></figcaption><figcaption><a href="https://www.youtube.com/watch?v=WxDKgQuehMY&amp;t=178s" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="14">For example,<strong> </strong><sub><strong>the famous Xerox 9400 that was introduced in 1977</strong></sub><sub> </sub><sub><strong>weighed one and a half tons and took up floor space measuring nine by fifteen feet.</strong></sub>&nbsp; It cost $85,000 ($430,000 in 2024).&nbsp; Automatically feeding up to 3,000 sheets of paper, it made copies at a rate of two per second and collated them into 50 separate bins.&nbsp; It could read and write two-sided sheets, and the image size was adjustable.&nbsp; Every stage of the process required extreme precision—from imaging to paper handling to managing the sequence of electric fields that transferred the image-bearing toner onto the paper, then pressing and baking the toner into the paper, and cleaning everything to be ready for the next image a half-second later.&nbsp; A fault anywhere in that sequence or in the control system could cause degraded copies or take down the whole machine.</p><p data-block-index="15">A technician who serviced 9400s in the 1980s recalls:</p><blockquote data-block-index="16">This machine was the main method of information distribution for the entire Federal Government for quite a while… I took service calls on these machines coming from the Pentagon, the CIA, the State Department, the Defense Mapping Agency, the Nuclear Regulatory Agency, Pax River Naval Research Center, the National Institutes of Health, the Uniformed Services University of the Health Sciences, and the National Bureau of Standards…. Xerox must have made an unbelievably enormous amount of money from that product—and spent an almost equally unbelievable amount maintaining them, because I also remember the nearly endless field retrofits we had to perform to keep them running…. Oh, those were the days!<sup>4</sup></blockquote><p data-block-index="17">The technicians were organized into regional teams, servicing all the machines within a geographic area.&nbsp; Each team member had sole responsibility for a group of customer offices and machines.&nbsp; Orr emphasizes that all their attention was focused on the work, with little to spare for the corporation that paid them.&nbsp; Indeed, they “shared few cultural values” with the rest of Xerox and did not seek to rise within it.<sup>5</sup>&nbsp; They relished working within the technician-customer-machine triangle, where their competence was tested and rewarded daily.</p><p data-block-index="18">Since half of the problems they had to fix were caused by misuse of the machines, they had an adage: “Don’t fix the machine, fix the customer.”&nbsp; The copiers were so sensitive that users could screw things up by using toner from a different machine or a cheap knock-off supplier. &nbsp; Or they could mistakenly put paper in the feeder tray curl-side-up instead of curl-side-down (it was vice-versa in other copiers).</p><figure><p><img loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/qv4xtciegyjnxgcpl3dr"></p><figcaption><p>In 1983, PARC intern Lucy Suchman conducted a famously diabolical experiment with the supposedly user-friendly Xerox 8200 copier.&nbsp; She made videos of PARC people using it.&nbsp; Tech historian John Tinnell recounts what happened when PARC director John Seely Brown (who was a long-time motorcycle buddy of Xerox CEO Paul Allaire) took one of the videos to corporate headquarters:&nbsp; “[Brown] played the video for a room of Xerox managers.&nbsp; It featured two men struggling and failing to produce a copy of an article [Ronald] Kaplan had written.&nbsp; Everyone back at PARC knew [that] Kaplan was a world-renowned computational linguist, and [Allan] Newell was revered as a founding father of AI.&nbsp; The video showed Newell peering over Kaplan’s shoulder, oscillating between curiosity and confusion as the pair exhausted the full arsenal of their joint expertise, to no avail, for over an hour and a half.&nbsp; One of the Rochester men slammed his fist on the table and hollered, ‘Goddammit, Brown! What did you do, get those guys off the goddamn loading dock?’&nbsp; Brown looked at him and smiled, ‘Well, actually, let me introduce these two stooges to you,’ He revealed Kaplan’s and Newell’s pedigrees, and the Xerox execs sat speechless.”<sup>9</sup></p><p>Lucy Suchman later became the manager of the “Work Practice and Technology” research group at PARC, which was composed of all the anthropologists at PARC plus a few computer scientists.&nbsp; Julian Orr was a member from the beginning.&nbsp; Suchman’s 1987 book, <em>Plans and Situated Actions: The Problem of Human-Machine Communication</em>, became a classic text.</p></figcaption><figcaption><a href="https://www.youtube.com/watch?v=DUwXN01ARYg" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="20"><sub><strong>The machines were so complex that even sophisticated customers could lose their way</strong></sub>—for example by failing to replace a baffle after clearing a paper jam (which would affect the paper’s temperature and cause further jams) or rashly re-using paper that had been through the machine once and was, therefore, oily (which would make rollers so oily that they could no longer feed properly).</p><p data-block-index="21">Even when the problem was purely mechanical, the customer was a primary source of important diagnostic information about when and how the breakdown had occurred.&nbsp; That meant, says Orr, that “the customer must be initiated into the technicians’ community of discourse,”<sup>6</sup> complete with an understanding of how the machine worked, how to recognize the noises it made at the various stages of copying, and the correct language to describe its many failure modes.&nbsp; Some customers resisted learning any such thing, and the technicians had to find a way to jolly them into learning it anyway.&nbsp; Orr writes that users were</p><blockquote data-block-index="22">taught by the technicians how to talk about the machine. They know what to observe—the state of the originals, where the machine leaves paper when it stops, and where in the cycle trouble occurs—and they know most of the terms to describe these phenomena.<sup>7</sup></blockquote><p data-block-index="23">As a consequence, the technicians became protective of the nuanced social relationship they built with each customer. &nbsp; Orr notes: “Technicians worry more about the social damage another technician can do in their territory than about what might happen with the machine, perhaps because the machine would be easier to repair than the delicate social equilibrium.<sup>8</sup>”</p><p data-block-index="24">Ethnographer Orr had a sharp eye for detail.&nbsp; He noticed when a technician on a call began by examining copies that had been thrown in the trash and deduced from them that the problem with the machine was different from what the customer had reported.&nbsp; “The trashcan is a filter between good copies and bad,” one technician explained&nbsp; “Just go to the trashcan to find the bad copies and then… interpret what connects them all.”<sup>10</sup></p><p data-block-index="25">Another time, Orr observed a technician joking with a customer about the need to keep any engineers in the building away from a machine that needed fixing, because “engineers believe they have a right to fiddle with any machine they encounter, whether they know anything about it or not.”<sup>11</sup> Orr recalls, “Engineers would go in and change adjustments, which offers limitless possibilities for disaster.”<sup>12</sup></p><p data-block-index="26">Orr noted that many of the technicians came from rural backgrounds, and nearly all—women as well as men—grew up as inveterate tinkerers.&nbsp; Half had studied technical subjects at junior colleges.&nbsp; A fifth learned their technical skills in the military, as had Orr.&nbsp; All received training at Xerox Document University in Leesburg, Virginia, and Orr did the same before undertaking his research on their behavior in the field.&nbsp;&nbsp;</p><figure><p><img sizes="(max-width: 1050px) 100vw, 600px" loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/reuywbbacbhrqoamup84"></p><figcaption><p>In 1982, the Xerox 1075 inaugurated the 10 Series, which became known as “the most successful line of copiers in Xerox history and served to restore the company’s finances and morale.”<sup>16</sup>  The technicians Orr studied were primarily responsible for servicing this machine.</p></figcaption><figcaption><a href="https://xeroxnostalgia.com/2018/01/28/xerox-1075/" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="28">The machine he studied for three weeks in Virginia was the then-new Xerox 1075, introduced in 1982 with a $55,000 price tag ($180,000 in 2024 dollars).&nbsp; It was a medium-sized copier that could churn out 70 copies a minute and featured an advanced level of electronics that performed onboard diagnostics and kept error and use logs.&nbsp; Orr writes, “Designed for a monthly volume of less than 40,000 copies, it was placed in situations demanding six and seven times that, which quickly produced unanticipated problems.”<sup>13</sup></p><figure><p><img loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/e5wpzr5tphueo7a2zzaa"></p><figcaption><p>The notorious 1970s Xerox 4000 copier.&nbsp; On the “Xerox Nostalgia” website, technicians remember it as “a dog in terms of reliability,” “a beast,” “an electromechanical monster, and dirty,”&nbsp; “a nightmare to keep it working,” “I hated this product!” “I still suffer from two 4000-induced medical conditions: ‘4000 knees’ and ‘A-transport replacement lower back pain’!” and “I got quite proficient on the 4000/4500 and was once told by a Leesburg trainer that <em>an experienced 4000 rep could fix anything.</em>”&nbsp; This photo of the back of the 4000 was taken by a hobbyist who set about restoring the machine in 2019, showing some of the tips he got from battle-scarred technicians on how to get it going.&nbsp; With their help, he succeeded.</p></figcaption><figcaption><a href="https://xeroxnostalgia.com/2020/11/23/restoration-of-a-xerox-4000-copier/" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="30">Orr notes that<strong> </strong><sub><strong>the technicians</strong></sub><sub> </sub><sub><strong>he studied</strong></sub><sub> </sub><sub><strong>were accustomed to dealing with unanticipated problems because of their years of experience with Xerox’s worst copier, the infamous 4000</strong></sub>, first released in 1970 and kept in use far past its expected lifespan.&nbsp; “Consequently,” Orr writes, “successful 4000 technicians developed considerable resourcefulness and a propensity for pooling their information with their fellows.”<sup>14</sup></p><p data-block-index="31">Thanks to his training, Orr could blend in with the technicians as a colleague and decipher the cryptic technical language of their war stories, which were always told with extreme brevity.&nbsp; “This brevity,” he explains, “is a matter of cultural propriety and competent practice; it would be inappropriate to waste everyone’s time with the superfluous.”<sup>15</sup>&nbsp; Specialists talking to fellow specialists speak in dense jargon, not to exclude outsiders but to honor their listeners’ expertise and engage it.&nbsp; “Story-telling is an interactive practice,” Orr adds.&nbsp; “You tell the story concisely, but if you notice one of your listeners looking confused, you back up and provide as much detail as necessary so they understand.”<sup>17</sup></p><p data-block-index="32">The war stories were never about routine maintenance or standard problems that everyone knew how to fix.&nbsp; Instead, Orr says,</p><blockquote data-block-index="33">Technicians like new manifestations of the extremes of machine behavior or of human behavior with machines.&nbsp; Problems that require consideration of the chains of cause and effect in the machines and that shed new light on those chains are interesting to talk about…. The stranger the sequence of events and interactions producing the machine behavior, the better the story is, and the more fun it is to tell.<sup>18</sup></blockquote><p data-block-index="34">Orr recites the exact wording of one war story told by a senior technician to his peers.&nbsp; (The language is characteristically dense and technical; I’ll explain in a moment what the technician’s peers heard and understood in the story.)&nbsp; The man said:</p><blockquote data-block-index="35">When you have a shorted dicorotron, you can’t even get the machine to run—it’ll cycle about twice and then shut down and give you an E053.&nbsp; First time with the new boards—the new XER board configuration—it wouldn't cook the board if you had an arcing dicorotron.&nbsp; Instead, now it trips the 24-Volt Interlock in the Low Voltage Power Supply, the machine will crash, and when it comes back up, it'll give you an E053.&nbsp; It may or may not give you an F066 that tells you the short is in—you know, check the xerographics. That's exactly what I had down here, at the end of the hall, and Weber and I ran for four hours trying to chase that thing.&nbsp; All it was was a bad dicorotron.&nbsp; We finally got it, ... run it long enough so that we got an E053 with an F066, and the minute we checked the dicorotrons, we had one that was totally dead.&nbsp; Put a new dicorotron in it, and it ran fine.&nbsp; Yeah, that was a fun one.<sup>19</sup></blockquote><p data-block-index="36">His peers understood that this story concerned an upgrade to the 1075 copier that, in the process of solving one problem, created a more difficult new one, which combined a meaningless error code with a maddeningly intermittent correct error code.&nbsp; The upgrade was an improved “XER” circuit board that no longer burned out when there was a short in one of the four “dicorotrons” that managed the electrical fields that did the copying (“the xerographics”).&nbsp; Instead, the machine now shut down and displayed a misleading error code—“E053”—indicating a blown circuit breaker, which could be caused by any number of things.&nbsp; The documentation for that error code advised that the problem would go away if certain specific components were replaced—but it never mentioned dicorotrons.&nbsp; Technicians would spend hours replacing components, and the machine just kept on crashing.&nbsp; It turned out that if you ran the process to failure enough times, every now and then, a seemingly spurious “F066” error code would show up, and the documentation for <em>that</em> error code led straight to the dicorotrons.</p><p data-block-index="37">For anyone to solve that problem in the future, they had to know and remember the whole sequence.&nbsp; That was the point of telling a rousing war story about it.&nbsp; (I prefer to call them detective stories.&nbsp; They are all about teasing out the crucial clues from a confusing excess of potentially relevant information.)&nbsp; Other PARC researchers later wrote that the technicians have a</p><blockquote data-block-index="38">strong preference for building up a story of what might be wrong with a particular machine by gleaning information from many sources, including other people in their work group, artifacts (e.g. the machine itself), and formal and informal documents.<sup>20</sup></blockquote><p data-block-index="39">Clever word, “gleaning.”&nbsp; It means “to frugally accumulate resources from low-yield contexts.”&nbsp; You peruse a mess of ambiguous data points and get some of them to disambiguate each other.</p><p data-block-index="40">Orr notes that tracking down the cause of a problem is often best done jointly with another technician:</p><blockquote data-block-index="41">In most of the hard diagnoses observed, solution was discovered through re-interpretation of known facts and following the new interpretation with new investigations.&nbsp; This is one of the reasons that consultations and joint trouble-shooting are so popular and effective.&nbsp; The presence of another guarantees another perspective and makes it easier to experiment with new interpretations.&nbsp; It also provides someone to whom to tell stories, who will tell stories in return…. The consideration of the present with reference to known diagnoses of the past, is an essential part of diagnosis.<sup>21</sup></blockquote><p data-block-index="42">Orr has a withering critique of the diagnostic “Fault Isolation Procedures” in the documentation—the service manuals—issued to the technicians:</p><blockquote data-block-index="43"><sub><strong>This directive documentation is designed </strong></sub><sub><em><strong>not</strong></em></sub><sub><strong> to provide information for thinking about the machine and its problems but to direct the technician to the solution through a minimal decision tree</strong></sub>…. A system that fixes the machine without either customer or technician knowing how or why is unlikely to be acceptable.&nbsp; Consequently, when the technicians use the directive documentation, they try to determine the <em>purpose</em> of the various tests, to understand what the documentation is testing, to know what they are doing.<sup>22</sup></blockquote><figure><p><img loading="lazy" decoding="async" srcset="https://res.cloudinary.com/books-in-progress/image/upload/w_640,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 640w,
https://res.cloudinary.com/books-in-progress/image/upload/w_750,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 750w,
https://res.cloudinary.com/books-in-progress/image/upload/w_828,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 828w,
https://res.cloudinary.com/books-in-progress/image/upload/w_960,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 960w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1080,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 1080w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1280,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 1280w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1668,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 1668w,
https://res.cloudinary.com/books-in-progress/image/upload/w_1920,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 1920w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2048,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 2048w,
https://res.cloudinary.com/books-in-progress/image/upload/w_2560,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 2560w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3200,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 3200w,
https://res.cloudinary.com/books-in-progress/image/upload/w_3840,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 3840w,
https://res.cloudinary.com/books-in-progress/image/upload/w_4480,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 4480w,
https://res.cloudinary.com/books-in-progress/image/upload/w_5120,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 5120w,
https://res.cloudinary.com/books-in-progress/image/upload/w_6016,c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s 6016w" src="https://res.cloudinary.com/books-in-progress/image/upload/c_lfill,f_auto/v1/bip/lefviwz5qaukanafmk2s"></p><figcaption><p>A typical diagnostic decision tree in the service manual for the Xerox 1075 copier.  It is a “Fault Isolation Prodedure” (FIP) to correct “High Background/High Density” in copies.  The tests mostly lead to other FIPs on other pages of the manual.  They are entirely directive—do this, then do that.  They do not invite understanding or suggest clues to look for outside the decision tree.  They contain nothing learned by technicians in the field.  They can offer nothing about problems that emerged after the manual was written.</p></figcaption><figcaption><a href="https://apps.dtic.mil/sti/tr/pdf/ADA194403.pdf" target="_blank" rel="noopener noreferrer">Source</a></figcaption></figure><p data-block-index="45">“The documentation,” Orr writes, “is designed not to enable deduction.”<sup>23</sup>&nbsp; Sometimes the manual would suggest something insane, such as solving a particular problem by replacing—at vast expense—all the circuit boards in the entire machine.&nbsp; No one would ever do that.&nbsp; John Seely Brown, the Director of PARC from 1990 to 2000, recalls:&nbsp;</p><blockquote data-block-index="46">Xerox had these beautifully produced instruction manuals for the technicians.&nbsp; They were big.&nbsp; There was a sort of social prestige in leaving them behind on a call.&nbsp; I mean: A, they were useless; and B, you looked like a fool walking in to fix a copier carrying a big encyclopedia.<sup>24</sup></blockquote><p data-block-index="47">The field technicians had no part in writing the manuals.&nbsp; They were written by the engineers who had designed the machine and by management, who, Orr says, “[seek] control over their employees, through control of the knowledge necessary to do the job, and can hire cheaper employees, since they do not need skilled labor.”<sup>25</sup>&nbsp;&nbsp;</p><p data-block-index="48">At one point, Orr states explicitly what his entire book proves: “<em>Repair and maintenance are not in any sense unskilled work</em>.”<sup>26</sup>&nbsp; He observed that the technicians operated with far more extensive knowledge than the documentation could provide.&nbsp; (An important exception was the schematics.&nbsp; Because the schematic diagrams showed how the machine’s electrical, electronic, mechanical, and pneumatic systems were connected, the technicians considered them accurate and helpful for tracing possible sequences of cause and effect in a machine’s misbehavior.)</p><p data-block-index="49">The technicians were dismayed when—sometimes encouraged by the documentation, as in the dicorotron war story—they had to resort to “shotgunning,” which meant just swapping new parts into the machine until a problem went away.&nbsp; Evaporating a problem rather than solving it meant that nothing was learned that might be helpful next time.&nbsp; The cause remained a mystery, and so did the remedy, along with any hint of how to prevent the problem from recurring.&nbsp; Orr emphasizes the effort the technicians made to earn and maintain the customer’s confidence:</p><blockquote data-block-index="50">The point of telling the customer what has happened is to establish that the problem was addressed in a professional manner, and this requires being able to tell what the machine is doing and being able to say what was done to fix it.<sup>27</sup></blockquote><p data-block-index="51">&nbsp;Nevertheless, shotgunning was preferable to failing to fix the customer’s machine.&nbsp; That was unacceptable.&nbsp; Service techs felt obliged to live up to what Orr calls their “gun-slinger mystique” of “the lone technician walking into the customer site to cope with whatever troubles lie therein.”<sup>28</sup>&nbsp;</p><p data-block-index="52">To be effective, Orr concludes, the technicians had to “become connoisseurs of the variations in machine misbehavior and of new shades of misunderstanding displayed and practiced by customers.”<sup>29</sup>&nbsp; The enemy of all technicians is chaos, he says.&nbsp; The service techs he studied insisted on carefully tuned reliability in the machines they serviced and valued tidiness at the worksite—no mess of tools, parts, and toner stains all over the place.&nbsp; This was, Orr says, core to “their identity as technicians—defined as those who fix the world and make it right.”<sup>30</sup></p><p data-block-index="53">That might do as a description of maintainers in general: Those who fix the world and make it right.</p><p data-block-index="55"><sub><strong>O</strong></sub>rr’s study quickly became famous and infamous throughout Xerox.&nbsp; A few, mostly Orr’s colleagues at PARC in California, thought it showed a revolutionary path to the future for the company.&nbsp; The many, especially at Xerox headquarters back east in Rochester, New York, thought the study revealed how much time—and company money!—the technicians were wasting just chatting with each other instead of doing what they were paid to do: working with customers.&nbsp; Since customer service was treated primarily as a cost center, some managers suggested the company could save serious money by cutting back on the socializing by the technicians.</p><p data-block-index="56">In April 2000, the <em>Harvard Business Review</em> published a piece by PARC researchers John Seely Brown and Paul Duguid titled “Balancing Act: How to Capture Knowledge Without Killing It.”&nbsp; Referring to the technicians as “reps” (short for “customer service representatives”), the paper summarizes Orr’s research this way:</p><blockquote data-block-index="57">Orr… studied what reps actually did, not what they were assumed to do…. They succeed primarily by departing from formal processes…. Orr found that a quick breakfast can be worth hours of training. While eating, playing cribbage, and gossiping, the reps talked work, and talked it continually. They posed questions, raised problems, offered solutions, constructed answers, laughed at mistakes, and discussed changes in their work, the machines, and customer relations.</blockquote><blockquote data-block-index="58">Orr showed that the reps use one another as their most critical resources. In the course of socializing, the reps develop a collective pool of practical knowledge that any one of them can draw upon. That pool transcends any individual member’s knowledge, and it certainly transcends the corporation’s documentation. Each rep contributes to the pool, drawing from his or her own particular strengths, which the others recognize and rely on. Collectively, the local groups constitute a community of practice.<sup>31</sup></blockquote><p data-block-index="59">Some researchers at PARC noted that many of the technician team’s important insights could be applied throughout Xerox globally but were confined within that team.&nbsp; Since engineers at PARC specialized in computer networks—Ethernet was invented there—Orr’s colleagues imagined a company-wide system linking all of Xerox’s 25,000 technicians via the Internet in a global “network of practice” where, to the edification of all, they could share their best solutions and workarounds.&nbsp; The idea was named the Eureka project.</p><p data-block-index="60">It began with a failure.&nbsp; The culmination of a multi-year PARC project to develop a state-of-the-art, artificial-intelligence-driven expert system to help the technicians diagnose problems was finally shown in 1991 to some technicians for comment.&nbsp; They said the system was ingenious, but it wouldn’t be much use because it covered nothing but common faults that everyone already knew how to detect and correct.&nbsp; Confronted by Orr’s observations, the project’s developers realized they had to focus on</p><blockquote data-block-index="61">the importance of <em>non-</em>canonical knowledge generated and shared within the service community.&nbsp; It suggested to us that we could stand the artificial intelligence approach on its head, so to speak; the work community itself could become the expert system, and ideas could flow up from the people engaged in work on the organization’s frontlines.<sup>32</sup></blockquote><p data-block-index="62">They resolved to replace the expert system with “a system for experts.”&nbsp; The hard-won knowledge that each technician team developed would instantly be available to all the other teams.&nbsp; “The project,” Brown writes, “set out to create a database to preserve resourceful ideas over time and deliver them over space.”<sup>33</sup><br></p><p data-block-index="64"><sub><strong>I</strong></sub>n 1991, a Xerox district manager in Colorado got wind of Orr’s research and invited him to a meeting in Denver to help develop an idea.&nbsp; Orr recalls:</p><blockquote data-block-index="65">The most significant moment of the meeting occurred when the District Service Manager told a story.&nbsp; He had recently had his furnace repaired.&nbsp; The technician doing the repair had been carrying a portable radio, with which he maintained a continuous conversation with his colleagues, other technicians repairing other furnaces elsewhere.&nbsp; This use of the radio for constant communications struck the manager as something which technicians in his organization could use.<sup>34</sup></blockquote><p data-block-index="66">The participants in the meeting noted that Xerox service technicians are “one of the lowest levels of the corporate hierarchy,” and yet they “have more contact with the corporation's customers than any other member of the corporation and so should be valued.”<sup>35</sup>&nbsp; They further noted that customers’ machines were spread so widely all over Colorado that many technicians spent most of their time driving alone, unable to meet very often with other technicians.</p><p data-block-index="67">The first order of business, they decided, was to involve technicians directly in building the scheme, or the whole thing would look like just another unwelcome intervention by management in their work lives.&nbsp; Ethnography to the rescue.&nbsp; Conspicuously non-management Julian Orr was funded to study four teams for three weeks to find out if they wanted portable radios and to pique their interest in helping design the project.&nbsp; The technicians told Orr they would love to have two-way radios that could be used like portable telephones to communicate with their families, co-workers, and customers—but <em>not</em> with their managers, thank you.</p><p data-block-index="68">Accordingly, radios were distributed to five work groups.&nbsp; Orr was invited to study the radio system in use for six months and to work with the technicians on improving the system.&nbsp; (Cell phones were not considered because they couldn’t be group-oriented the way logic-trunked radios could.)&nbsp; The technicians insisted that their communications must be “free from interference or even monitoring,” and the district manager supported them in this.&nbsp; Orr recalls, “On many occasions during the fieldwork, [I] found it necessary to assure other technicians that managers were not <em>allowed</em> to use the radios.”<sup>36</sup>&nbsp; Orr praises the Colorado district for honoring the privacy of the technician teams:</p><blockquote data-block-index="69">This relinquishment underscores a dilemma of modern managers: If they are not controlling, what then is their function?&nbsp; Given these pressures, the managerial decision to let the information remain available only to the technicians is a remarkable event and an achievement for those involved.<sup>37</sup></blockquote><p data-block-index="70">The radio project was a roaring success.&nbsp; Orr observes that the technicians “mostly work alone in other people's offices and rarely spoke to any colleagues; now they spend part of their time on the air supporting each other and often converse while driving home at the end of the day, unwinding and getting the day's events in perspective.”&nbsp; Also they “find it easier to share parts or to coordinate trips to the warehouse when necessary.&nbsp; They exchange information about weather or traffic.”&nbsp; When Orr asked them if a message system wouldn’t work just as well, he was told “that the stress in someone's voice cannot be conveyed in a typed message.”&nbsp; “The workgroups have become real through this tool,” they said.&nbsp; “The groups now are based on real and continuing relationships which could not be achieved with weekly meetings.”<sup>38</sup></p><p data-block-index="71">Outside of the enlightened Colorado district, however, perspective on the radio-empowered technicians shifted.&nbsp; Orr writes:</p><blockquote data-block-index="72">After six months of experience, the technicians were quite clear that the radios helped them with diagnosis, with coordination, with morale, with parts supply problems, and with the training of new technicians, but these were not acceptable benefits from the corporation's perspective, which required demonstrable dollar savings.<sup>39</sup></blockquote><p data-block-index="73">Xerox corporate decided that since radios made the service reps more efficient, the company could save money by employing fewer reps.&nbsp; To lower the cost of the radios, Xerox reduced their power and range and thus their ability to connect all of the technicians in the district.&nbsp; “The original desire to help the technicians enhance their own practice,” Orr writes, “disappeared from managerial discourse.”<sup>40</sup>&nbsp; For Xerox corporate, the issue was simple.&nbsp; The whole point of any improvement in customer service was to reduce its cost, period.</p><p data-block-index="74">Nevertheless, within a few years, all 25,000 Xerox service reps worldwide were furnished with portable radios to enrich the peer-to-peer discourse that made their work go better.</p><p data-block-index="76"><sub><strong>T</strong></sub>he radio breakthrough in Colorado was a relatively quick win.&nbsp; Getting the Eureka project from vision to reality, it became clear, would require a much longer slog because the concept violated Xerox’s deeply embedded views of how to run a company—from the top down.&nbsp; The lowly technicians should be guided solely by their superiors, not by each other.</p><p data-block-index="77">(I can tell this story in some detail thanks to the profusion of papers published about Xerox service practice and Eureka between 1986 and 2011.&nbsp; Julian Orr wrote 11 of them, including his book and the 1990 PhD thesis it was expanded from.&nbsp; Other authors I’ve relied on are John Seely Brown &amp; Paul Duguid, Daniel Bobrow &amp; Jack Whalen, plus Olivier Rainman, David Bell, Mark Shirley, Cindy Gordon, Robert Cheslow, Norman Crowfoot, Steve Barth, Yutaka Yamauchi, and Andrew Cox.)</p><p data-block-index="78">Eureka’s primary designer and champion at PARC was a French national named Olivier Raiman.&nbsp; One of his colleagues, Cindy Gordon, later wrote of him: “Olivier Raiman was visionary, and his passion, energy, and commitment helped create momentum for the Eureka project.”<sup>41</sup>&nbsp; Establishing some kind of momentum was surely needed, because the managers in Worldwide Customer Services who had oversight of the technicians saw no value in the project and took every opportunity to block it.</p><p data-block-index="79">Their view was partly the product of an earlier effort to “de-skill” the technicians.&nbsp; After the Vietnam War ended in 1975, the supply of technicians trained by the military dried up.&nbsp; “Xerox decided,” writes one of the PARC researchers, “to use less skilled, less experienced service people. It moved away from the documentation and training that described the principles of product operation…, and moved toward ‘directive’ repair and adjustment procedures.”<sup>42</sup> &nbsp; These were the simplistic Fault Isolation Procedures that the technicians struggled to penetrate, trying to discern their purpose.&nbsp; The procedures were all “how” and no “why.”&nbsp; The idea of hiring less skilled technicians quickly died, but the documentation-for-dummies remained unchanged.</p><p data-block-index="80">The managers were so adamant that the directive procedures were sufficient that the technicians had to pretend that was so in order to keep their jobs.&nbsp; The formula was: “Quality service meant uniform service, and uniform service meant following the instructions in the manual.”<sup>43</sup>&nbsp; One service rep told a PARC researcher that he never made private annotations in the manual because that might suggest he was giving nonstandard service.&nbsp; Then, the researcher reports,</p><blockquote data-block-index="81">he showed his "cheat sheet" with recent tips for difficult service problems that he used as an augmentation to the manual.&nbsp; In essence, he was keeping two sets of books: one to show quality inspectors, and one to use for a quality job!<sup>44</sup></blockquote><p data-block-index="82">What would have happened if the technicians dutifully never ventured outside the manual?&nbsp; The opinion at PARC was:</p><blockquote data-block-index="83">If the technicians had abandoned diagnosis when the directive documentation did and followed the catch-all rule, which was to replace the machine, they would have drained Xerox of customers.<sup>45</sup>&nbsp;</blockquote><p data-block-index="84">Fortunately for the company, the technicians were more loyal to their customers than to their managers.&nbsp; They would quietly defy Xerox policy to fulfill their professional imperative to fix their customers’ Xerox machines, no matter what.&nbsp; In Julian Orr’s view, “The corporate use of information for leverage and control contrasts with the technicians' attitude of sharing it among those who can use it.”<sup>46</sup>&nbsp; While the managers wanted to suppress improvisation, the technicians celebrated it—and had to keep it secret.&nbsp; Orr adds in disgust:</p><blockquote data-block-index="85">During the 1990s,… the corporation created mandatory structures of meta-work, work about belonging to the organization, which both kept the technicians away from their work with machines and customers and was used to judge them for their performance reviews.<sup>47</sup></blockquote><p data-block-index="86">The result, writes Orr, was that the technicians “do less work now servicing customers and more servicing Xerox.”<sup>48</sup></p><p data-block-index="87">Consequently, while the technicians were intrigued by the idea of Eureka sharing their knowledge globally, they had reason to doubt it would go anywhere.&nbsp; One old-timer among the technicians remembered how</p><blockquote data-block-index="88">decades ago when he started at Xerox, he submitted a suggestion on how to install a machine more efficiently.&nbsp; For six months he did not receive any feedback about the suggestion.&nbsp; Then he saw a published bulletin with his idea, attributed to the person who received the suggestion over the phone.&nbsp; After that, the service engineer did not submit any ideas.<sup>49</sup></blockquote><p data-block-index="89">Furthermore, Orr was told, other technicians might pay no attention to Eureka because it would look like just another lame offering from on high.&nbsp; In their experience,</p><blockquote data-block-index="90">Information which is distributed to the technicians… is often so fragmentary that the technicians do not perceive it to be of any use at all, and information from the corporation is usually regarded as suspect until confirmed through community experience.<sup>50</sup></blockquote><p data-block-index="91">Eureka’s lead champion, Olivier Raiman, describes the resistance this way:</p><blockquote data-block-index="92">Eureka was about a commitment to constant listening and adaptation….&nbsp; In fact, it required an acceptance of what many companies consider a radical concept—the person who does the job is in the best position to know how it can and should be done.&nbsp; This is a scary proposition for middle managers because it fundamentally changes their job description and takes away their role as the residential expert on operational functions.<sup>51</sup></blockquote><p data-block-index="93">Orr concluded that the asymmetry between the managers and the technicians was stark: “Management has most of the money and power.”<sup>52</sup>&nbsp; The heavyweights at Worldwide Customer Service said to the PARC researchers, essentially, “The service representatives work for us, not you.&nbsp; The system we have is working just fine.&nbsp; You are not welcome to screw it up with one of your harebrained academic theories.”</p><p data-block-index="95"><sub><strong>T</strong></sub>he emphatic “No” to Eureka from headquarters made Olivier Raiman search for a fragment of the company that might say “Maybe.”&nbsp; He found one in his native France.&nbsp; With permission to immerse himself in the work-life of French service technicians, he set about designing Eureka around their needs.&nbsp; Xerox corporate refused to provide any money for the work, so PARC and Xerox France funded it.&nbsp; Eureka’s designers remember:</p><blockquote data-block-index="96">In the initial stages, we sometimes had to operate like a guerrilla group because opposition was enough to kill the project…. We conducted our first experiment in France partly because it was out of sight of the central Xerox organization.<sup>53</sup></blockquote><p data-block-index="97">In 1994, France had the world’s first national computerized communication system--French Minitel, with five million terminals in use.&nbsp; It would provide the infrastructure for the technicians to connect with the Eureka database.&nbsp;&nbsp;</p><p data-block-index="98">In their <em>Harvard Business Review </em>paper, Brown and Duguid summarized how the database of tips was assembled:</p><blockquote data-block-index="99">Reps, not the organization, supply the tips.&nbsp; But reps also vet the tips.&nbsp; A rep submits a suggestion first to a local expert on the topic.&nbsp; Together, they refine the tip.&nbsp; It’s then submitted to a centralized review process, organized according to business units.&nbsp; Here reps and engineers again vet the tips, accepting some, rejecting others, eliminating duplicates, and calling in experts on the particular product line to resolve doubts and disputes.&nbsp; If a tip survives this process, it becomes available to reps… who have access to the tips database…. So reps using the system know that the tips… are relevant, reliable, and probably not redundant.</blockquote><blockquote data-block-index="100">[Xerox France] offered to pay for the tips, but the pilot group of reps who helped design the system thought that would be a mistake, worrying… that payment for submissions would lead people to focus on quantity rather than quality in making submissions.&nbsp; Instead, the reps chose to have their names attached to tips.&nbsp; Those who submit good tips earn positive recognition. Because even good tips vary in quality, reps, like scientists, build social capital through the quality of their input.<sup>54</sup></blockquote><p data-block-index="101">The process relied in particular on the most experienced technician specialists known as “tigers.”&nbsp; France’s leading tiger, Eric Delanchy, joined Raiman in championing the idea with technicians nationwide.&nbsp; Because the tigers were “consultants to other technicians with a mandate to teach and share expertise,”<sup>55</sup> they were best equipped to frame the tips in the most helpful way.&nbsp; The researchers from PARC remember: “We worked interactively with the tigers in France to improve the software, often responding overnight; this transformed [Eureka] from our idea to their tool.”<sup>56</sup>&nbsp;</p><p data-block-index="102">Each tip had a three-part structure: Problem, Cause, Solution.&nbsp; That made the tips easy to scan quickly.&nbsp; Here’s an example:</p><blockquote data-block-index="103"><em>Problem</em>: When running Xerox coated stock from Tray 3, customer gets jammed PO8- 19X, and message on copier indicated: ”Paper width is too narrow.”</blockquote><blockquote data-block-index="104"><em>Cause</em>: Xerox coated stock in Tray 3 is too flat or loaded with the curl the wrong way, causing the sheet to be fed skewed. The sheet is still skewed at the registration sensor.&nbsp;</blockquote><blockquote data-block-index="105"><em>Solution</em>: Contrary to what we have been taught, with this stock, load curl <em>down</em> in Tray 3. Instruct customer how to check for curl in paper and flatness. Totally flat stock seems to jam right away. Last resort is to coat the registration transport with antistatic fluid. The fluid will hold up for approximately 10,000 to 15,000 copies. Any question, feel free to contact Employee #930124 — Michael Posus, CST Twin Cities District<sup>57</sup>&nbsp;</blockquote><p data-block-index="106">Eureka was still in rudimentary form in France when the designers first tested it for efficacy.&nbsp; They picked 40 technicians to be trained on Eureka and matched them with 40 similar but Eureka-less technicians to act as the control group.&nbsp; Their work was measured with the standard Xerox metrics, including:</p><blockquote data-block-index="107">cost of parts, service time, number of unscheduled maintenance calls, interrupted calls, and callbacks….&nbsp; The metrics after two months were startling.&nbsp; The experimental group had an approximately 10% lower parts cost and 10% lower average service time than did the control group, without differing significantly in the other service metrics.<sup>58</sup>&nbsp;</blockquote><p data-block-index="108">That convinced the leaders of Xerox France.&nbsp; They rolled out the system to all 1,300 technicians in the country.&nbsp; Within a year, new validated tips were being added at a rate of one a day, coming from 20 percent of the technicians.&nbsp; On average, the technicians were consulting the system more than twice a week.&nbsp; “Xerox France, compared to the rest of Europe,” the PARC researchers report, “went from being an average or below average performer in service to being a benchmark performer.&nbsp; The French service metrics were soon better than the European average by 5-20%, depending on the product.”<sup>59</sup>&nbsp;</p><p data-block-index="109">Back in the US, Xerox corporate was <em>still </em>not persuaded, but a senior manager in Canada named Mark Hill was.&nbsp; In 1996, he invited the Eureka team to build a Canadian version. &nbsp; Once again, a leading tiger was essential to championing the project.&nbsp; There was no Minitel platform to work with, but the tiger, Michel Boucher, said some service technicians were already using a networked bulletin board system accessed via laptop and modem.&nbsp; Why not convert Eureka to work on the bulletin board?&nbsp; The database of tips would now be conveniently searchable thanks to new software developed at Xerox called SeachLite.</p><p data-block-index="110">Boucher trained all the other tigers on how to use the system so they could then train the rest of Canada’s 1,200 technicians.&nbsp; They had to do it all in their spare time because, as the PARC developers recall, “Xerox expected technicians to author tips and validators to provide rapid turnaround and validation of submitted tips without any relief from their current workloads.”<sup>60</sup>&nbsp; Along with expecting the work to be done for free, management required that it be done to schedule.&nbsp; The PARC researchers explain how well that worked:</p><blockquote data-block-index="111">Management had never dealt with a program in which the requirements emerged from experiments with pilot users, iterated until the users felt the program warranted large-scale deployment.&nbsp; Managers would try to set deadlines for us to get things done, independent of our process for rapid prototyping and debugging with extensive community involvement.&nbsp; The clash of these two different design and deployment methods had negative results.&nbsp; Some higher-level managers lost some faith in the ability of the Eureka team to deliver.<sup>61</sup></blockquote><p data-block-index="112">But they did deliver.&nbsp; After six months of intense work, Eureka launched in Canada in early 1997 with support for 20 Xerox products.&nbsp; Soon, there were 1,900 validated tips for 76 products, and the cost savings for product maintenance were 5 to 8 percent, the same as in France.&nbsp; Cindy Gordon, who was responsible for overseeing the project, writes: “Eureka is a great example of what might be called vernacular knowledge sharing — that is harvesting, organizing and passing around insights that come from the grassroots of an organization.”<sup>62</sup>&nbsp; She notes that the Canadian experiment was so successful, “Some technicians in Minneapolis actually stole the software and access to Eureka and started using it on their own.”<sup>63</sup></p><p data-block-index="114"><sub><strong>A</strong></sub>t last, Xerox’s Worldwide Customer Service was compelled to pay attention, although, as one of their officers, Tom Ruddy, recalls,</p><blockquote data-block-index="115">What it really took was testimonial video clips of old-school, hard-nosed, 25-years-of-experience service technicians telling their personal stories of how Eureka made a difference to them.<sup>64</sup></blockquote><p data-block-index="116">The project developers quickly learned that expanding to all 10,000 technicians in the US would meet new hindrances from the “much more bureaucratic and hierarchical” organization in America.&nbsp; They observed that</p><blockquote data-block-index="117">we were constantly trying to balance our belief that simpler was better with corporate managers’ beliefs that if Eureka was the answer, they wanted to be the one to generate the question.<sup>65</sup></blockquote><p data-block-index="118">One manager, for instance, insisted that accessing the whole project through Microsoft’s web browser, Internet Explorer, would simplify everything.&nbsp; In fact it complicated everything, just as the developers had predicted.&nbsp; Cascading versions of the browser, operating systems, and other software often failed to work together and had to be constantly updated on 10,000 laptops, which delayed the project for months.</p><p data-block-index="119">Worse was management’s failure to understand that Eureka only spread successfully through direct contact among technicians, as proven in Canada and France.&nbsp; The developers recall:</p><blockquote data-block-index="120">We had originally suggested to… management an alternative ‘‘participatory deployment’’ strategy in which the pilot champions, technicians, and managers most knowledgeable about Eureka would go to other locations in the US service community and talk about their experiences and ideas.&nbsp; Because these people were peers, the technicians would trust them.&nbsp; During a relatively short time, Eureka would have spread across the entire country.<sup>66</sup></blockquote><p data-block-index="121">Instead, Xerox employed its customary “spray and pray” distribution mode.&nbsp; For the June 1998 launch, the company</p><blockquote data-block-index="122">distributed Eureka CD-ROMs to the field managers, who were then expected to distribute them to technicians in their work groups.&nbsp; The CD included a computer-based training module; no hands-on training or direct engagement with technicians around the program was planned.<sup>67</sup></blockquote><p data-block-index="123">Use of the system spread very slowly.</p><p data-block-index="124">Yet spread it did.&nbsp; The technicians who loved it gradually infected their peers with comments like “In all my years in Xerox, the two best things ever given to us are the radios and Eureka.’’<sup>68</sup> &nbsp;The original plan was to install the system throughout the US before going overseas, but, as the system developers later reported, “demand from technicians in Europe, Latin America, and Asia was so intense that the corporation had to begin distributing Eureka worldwide.”<sup>69</sup>&nbsp; Soon, it reached all 25,000 service reps in the whole company.</p><p data-block-index="125">Eureka was run by PARC, deploying its extensive computer and connectivity resources.&nbsp; When researchers examined how the scaled-up system was being used, they found some surprises.&nbsp; They had assumed that Eureka would be consulted mainly as a last resort, when all routine solutions to a problem had been exhausted.&nbsp; Instead, they discovered that many technicians “use it as a tool of <em>first</em> rather than last resort.”<sup>70</sup>&nbsp; One user reported:</p><blockquote data-block-index="126">I check Eureka before I go to a site, that way when I get there I already know what parts to bring in. The customer is always impressed when you show up and already have an idea on how to fix the machine, and have the part with you. They just love it.<sup>71</sup></blockquote><p data-block-index="127">Another said: “Eureka is almost like having another technician with you because you can bounce your ideas or your thought processes off the Eureka database.”<sup>72</sup>&nbsp; Another said he studied Eureka’s problems and solutions because “attending to how others found workarounds has helped him develop his own skills.”<sup>73</sup>&nbsp;</p><p data-block-index="128">Best of all, Eureka gave the technicians a way to build their reputation for competence and generosity within the global fellowship of their peers—and with the company at large.&nbsp; In their <em>Harvard Business Review</em> paper, Brown and Duguid report, “At a meeting of Xerox reps in Canada, one individual was surprised by a spontaneous standing ovation from coworkers expressing their respect for his tips.”<sup>74</sup></p><p data-block-index="129">The whole of Xerox received accolades.&nbsp; At the time, many corporations were trying to build sophisticated “Knowledge Management Systems,” and Eureka was a rare success story.&nbsp; &nbsp; In 2002, Cindy Gordon reported that</p><blockquote data-block-index="130">funding for Eureka has steadily increased in the range of 60 percent year over year.…Return on investment has been in the range of tenfold, but, most important, management has supported Eureka at all levels in the organization.<sup>75</sup></blockquote><p data-block-index="131">Xerox announced that Eureka was transforming the company and henceforth, “Knowledge Management is our culture.”&nbsp; The company’s Worldwide Customer Service division, which had fought Olivier Raiman for so long, honored him with a plaque praising him for building Eureka “despite resistance from us.”<sup>76</sup>&nbsp;</p><p data-block-index="132">Apparently, Julian Orr’s study really had revealed a revolutionary path to the future for Xerox, just as his colleagues at PARC had hoped and lobbied for a decade earlier.&nbsp; Or had it?&nbsp; How deep did the revolution go?&nbsp; As Cindy Gordon noted in 2002, “The Eureka project also had pockets of resistance, and some remain.&nbsp; Some of the biggest opposition came from company strategists.”<sup>77</sup></p><p data-block-index="133">The company’s 25,000 technicians—comprising a fourth of Xerox’s entire workforce—had their titles elevated to “customer service engineer,” but they were still not paid for the time they spent on generating tips, validating them, and constantly pruning and updating the Eureka database.&nbsp; The system’s developers also noted that the technicians and their lore remained oddly isolated from the rest of the company.&nbsp; They wrote, “No formal process incorporates Eureka’s information back into the documentation.”<sup>78</sup>&nbsp; And:</p><blockquote data-block-index="134">One type of tip content was suggestions for better ways of doing things, including proposing modifications to the machines.&nbsp; Technicians are in a good position to notice when a machine was being overused for its purpose, and to suggest to a sales person that the customer might be ready for an upgrade.&nbsp; Viewing field service as the frontline to your customers dramatically changes the perspective on their role, and could engender new strategies for the service force.<sup>79</sup></blockquote><p data-block-index="135">To my eye, Xerox never got past viewing customer service as a cost center.&nbsp; The dense lore in the Eureka database proved that the company was ignoring a priceless <em>value</em> center.&nbsp; The service technicians were Xerox’s primary interface with its customers.&nbsp; The techs knew everything about the customers’ real use behavior.&nbsp; They knew exactly what made the machines fail and what made customers unhappy—crucial data for any company.&nbsp; They really were engineers: They solved emergent problems in the machines with a high degree of creativity. &nbsp; More thoroughly than the most adept salesperson, they routinely figured out how to shape their customers’ experience toward satisfaction.</p><p data-block-index="136">(“In their frenzy to earn their bonuses,” Orr recalls, “Xerox salespeople would tell the customer that the machine would do whatever the customer wanted.&nbsp; The technician could later explain what it would really do.”)<sup>80</sup></p><p data-block-index="137">If Xerox had deeply reoriented itself toward service, the best technicians—the tigers—might have been considered for promotion paths into sales, design engineering, and manufacturing.&nbsp; Xerox’s salespeople could have been required to go on occasional repair calls to learn the perspective of the actual users of the machines, not just the account managers they sold to.&nbsp; Ditto the company’s design engineers: Let them watch their brilliant machines fail in mysterious ways.&nbsp; Let them study the myriad paths to destructive misuse by the customers and figure out ways to design around them.&nbsp; The company’s mid-level high-fliers slated for senior management could, in preparation for promotion, get trained up on a current machine at Xerox Document University and then go on some service calls for that machine, ideally in the company of a savvy tiger.&nbsp; Take <em>that</em> knowledge to the top of the corporation.</p><p data-block-index="138">None of that happened, of course. Xerox declined after 2000, and the company’s glory years and Xerox PARC faded into history.</p><p data-block-index="140"><sub><strong>A</strong></sub> byproduct of the Eureka success story was popularization of the term “community of practice.”&nbsp; The concept was developed at the PARC-adjacent Institute for Research on Learning in Palo Alto and published as the core idea of a 1991 book on apprenticeship titled <em>Situated Learning: Legitimate Peripheral Participation, </em>by Jean Lave and Etienne Wenger.&nbsp; Their investigation of apprenticeships among butchers, navy quartermasters, tailors in Liberia, and midwives in Yucután showed that potential recruits to a practice were allowed to hover at the edge of the work, observing.&nbsp; Then they were given simple, routine tasks, and if they showed promise, gradually they were granted more complex tasks.&nbsp; It was not a course of study; it was the stepwise joining of a work community, with all of its skills, values, lingo, jokes, friendships, and tricks of the trade.&nbsp; “The community,” Wenger notes, “is the living curriculum for the apprentice.”<sup>81</sup></p><p data-block-index="141">Brown and Duguid draw an important distinction between the communities of practice embodied in the technician teams and the “network of practice” that Eureka became:</p><blockquote data-block-index="142">People in such networks have practice and knowledge in common, [but they] don’t interact with one another directly to any significant degree…. It produces very loosely coupled systems.”<sup>82</sup></blockquote><p data-block-index="143">One thing lost in Eureka was most of the wisdom that the service teams developed about dealing with customer issues, perhaps because, while all 25,000 technicians had the same machines in common, each local team had unique customers.</p><p data-block-index="144">As years went by and social media like Facebook, Reddit, and YouTube proliferated online, all manner of <em>virtual</em> communities of practice emerged that did encourage interaction.&nbsp; You may recall my informant on Twitter who told me about rebuilding his 1996 Toyota guided by Timmy the Toolman YouTube videos and about the “robust community of people that love Toyota 4Runners” he found on Facebook.&nbsp; (He’s @idlebell on Twitter.)&nbsp; When I asked him about the nature of interaction in the group, he wrote:</p><blockquote data-block-index="145">I could post a video or picture of different problems.&nbsp; Or ponder possible solutions and have ten different people debating.&nbsp; Very specific advice.&nbsp; And now I jump in when relevant.&nbsp; For example, I contributed a trick to remove a difficult-to-reach bolt.&nbsp; Imagine.&nbsp; After 26 years discovering a new way to replace a bolt.<sup>83</sup></blockquote><p data-block-index="146">Over the years, a considerable literature has emerged espousing communities of practice.&nbsp; Oddly, nearly all of it leaves out something that Orr emphasized: the importance of honoring skill.&nbsp; Who are the best among us?&nbsp; What will it take for me to become one of them?&nbsp;&nbsp;</p><p data-block-index="147">A major attraction of a community of practice is its role as an arena for recognition and endorsement by one’s peers.&nbsp; Orr showed how amicable competition among Xerox technicians built competence and spurred achieving mastery.&nbsp; That’s how the tigers were made.&nbsp; The communities discover best practices mainly by paying attention to their best practitioners.</p><p data-block-index="148">I like what Wikipedia has to say about the “social capital” aspect of communities of practice.&nbsp; It says the communities create—and operate—through</p><blockquote data-block-index="149">a shared sense of identity, a shared understanding, shared norms, shared values, trust, cooperation, and reciprocity….&nbsp;</blockquote><blockquote data-block-index="150">Unlike financial forms of capital, social capital is not depleted by use; it is depleted by non-use.<sup>84</sup></blockquote><p data-block-index="152">_________________________________</p></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No Salt (405 pts)]]></title>
            <link>https://jakeseliger.com/2024/08/05/no-salt/</link>
            <guid>41167467</guid>
            <pubDate>Tue, 06 Aug 2024 03:03:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakeseliger.com/2024/08/05/no-salt/">https://jakeseliger.com/2024/08/05/no-salt/</a>, See on <a href="https://news.ycombinator.com/item?id=41167467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						
<p><em>This is by my brother, Sam. </em></p>



<p>I arrived to Arizona late Saturday, after learning that my brother <a href="https://jakeseliger.com/2024/08/04/starting-hospice-the-end/">has only a few days left</a> before cancer <a href="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/">ends him</a>. Jake’s wife, <a href="https://bessstillman.substack.com/">Bess</a>, confessed that she had neither the willpower or the energy to take care of the post-death rituals—in this case, cremation, followed by a celebration of life at some point in the future. Likely at <a href="https://jakeseliger.com/2023/08/21/i-know-what-happens-to-me-after-i-die-but-what-about-those-left-behind/">a memorial bench at Stuyvesant Park in New York City</a>, where he and Bess built their life together, met their core group of friends, and made their fondest memories.</p>



<p>I do a lot of research, and finding a funeral home for my brother’s remains was and is quite a bit different than looking for, say, a great sushi restaurant. What should I look for out of a funeral home? Do they have five stars on Yelp? Do they seem “nice?”</p>



<p>Several funeral homes that had good reviews online. The folks on the other end of the line seemed nice. They said the right things, which makes sense because they’ve got a sales funnel. And then they asked for a credit card. I get that funeral homes are businesses that need to make money, just as most of us do. It still feels callous and transactional. Send me an agreement, or something. I’ll DocuSign it. You’ll get your money. I’m barely functional at the moment—sleepwalking through my days as if I will somehow wake from this nightmare, watching my brother and his wonderful wife fall into despair.</p>



<p><strong>Prior to his illness</strong>, Jake and I had been at odds for many years. I didn’t understand him, and neither did he. Both of us lacked the <a href="https://www.amazon.com/Adult-Children-Emotionally-Immature-Parents/dp/1626251703?ie=UTF8&amp;tag=thstsst-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957">emotional maturity</a> to form deep, meaningful relationships with other people. In my case, this manifested in self-destructive behaviors like drinking, partying, womanizing, and things of that nature. For Jake, he withdrew from most of society, finding more comfort from the pages of a novel or the many works he himself has written. He eventually found meaning in teaching, and focused on his relationship with Bess.</p>



<p>In turn, I eventually found a partner and a wife who made me a better person. Somehow, both of us <a href="https://jakeseliger.com/2023/09/25/strange-trip-psychedelics-and-confronting-the-fear-of-death/">found our way to psychedelics</a> as a way of dealing with reality and exploring the deeper, more esoteric corners of the world. Over the last two years, Jake and I have talked extensively about our experiences with these substances. Therapy has never worked for me. <a href="https://www.wired.com/2000/05/mckenna/">As Terrence McKenna once said</a>, “The real truth, that dare not speak itself, is that no one is in control. Absolutely no one.”</p>



<p>This is not meant to disparage therapists, advocates, or grief counselors. Each person must find their own way to deal with the reality that we perceive: what works for one may not work for others. Changing your life is difficult. It requires hard work. But your life may depend on it, so stop procrastinating and find something that works.</p>



<p><strong><a href="https://jakeseliger.com/2023/08/21/i-know-what-happens-to-me-after-i-die-but-what-about-those-left-behind/">Besides psychedelics</a>, Jake</strong> and I have discovered over the past year that we share a love of cooking, particularly using modern gadgets like Instant Pots, sous vide, and interesting spices. Jake loves his <a href="https://www.amazon.com/gp/product/B01G5MZZ5Q?ie=UTF8&amp;tag=thstsst-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957">plug-in induction stovetop</a>, and thinks it worthwhile despite its cost. At one point I was supposed to go to the final auditions for a show called <a href="https://www.imdb.com/title/tt1694423/">MasterChef</a>, which pits amateur cooks against each other behind the gentle coaching of Gordon Ramsay. I foolishly accepted a job offer instead, but perhaps I’ll try again someday in honor of my brother.</p>



<p>Which brings me to the title of this essay. When I arrived at their home yesterday, I observed Jake in the worst condition I’ve ever seen: emaciated, with obvious tumors rampaging throughout his neck and jaw. Bess is seven months pregnant, worrying about the impending death of her soulmate, clinging to what seems like an irrational hope of a miracle turnaround.</p>



<p>I noticed an extremely uncharacteristic lack of food in their home—usually, when I walk in, Jake offers something to eat even when he knows I just ate—so I immediately went to the store to at least ensure that Bess had some food. Jake can scarcely take a sip of water, but says that “normal” food feels more wholesome going through his PEG tube than the brown, yet nutritious, <a href="https://www.functionalformularies.com/product/liquid-hope/">Liquid Hope</a> that gives him most of his daily calories.</p>



<p>Jake still has a larder of dried goods, spices, and gadgets that would be the envy of even a professional chef. Fenugreek sourced directly from Egypt. Fermented locust beans from Nigeria. More forms of masala and curry than most Indian restaurants. I had ambitions to use these spices for what Jake labeled as “possibly his final real meal,”<sup data-fn="f8512c1c-7cae-4665-b5ba-b76a84e5b6e9"><a href="#f8512c1c-7cae-4665-b5ba-b76a84e5b6e9" id="f8512c1c-7cae-4665-b5ba-b76a84e5b6e9-link">1</a></sup> only to realize that antibiotics have ruined his gastrointestinal system to the point that making anything exotic might bug his stomach.</p>



<p>So I opted for something simple: a shakshuka. Tomatoes, vegetables, sauce, and mild flavorings, topped with feta cheese, eggs, and basil. I reached for the salt, and found the bottle empty. I’m not sure why, but I started weeping. No salt. No salt means that he’s not cooking. He’ll never cook again. Salt is the most basic ingredient. <a href="https://jakeseliger.com/2024/02/26/food-and-friends-part-i-food-is-social-life/">Food is (was, I guess) so important to him.</a> He cooked for Bess throughout the summer of 2023, when he couldn’t eat anything except by PEG tube.</p>



<p>I’ll go over to their house again later today, and make sure I cook enough food at least for Bess to be able to eat, and hopefully for Jake to eat via the tube. I’ll stop for more salt on my way.</p>



<p>If the salt is gone, then Jake is too.</p>



<figure><a href="https://jakeseliger.com/wp-content/uploads/2024/08/dsc00635.jpg"><img data-attachment-id="9024" data-permalink="https://jakeseliger.com/2024/08/05/no-salt/dsc00635/" data-orig-file="https://jakeseliger.com/wp-content/uploads/2024/08/dsc00635.jpg" data-orig-size="2048,1365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DSC00635" data-image-description="" data-image-caption="" data-medium-file="https://jakeseliger.com/wp-content/uploads/2024/08/dsc00635.jpg?w=300" data-large-file="https://jakeseliger.com/wp-content/uploads/2024/08/dsc00635.jpg?w=550" tabindex="0" role="button" width="1024" height="682" src="https://jakeseliger.com/wp-content/uploads/2024/08/dsc00635.jpg?w=1024" alt=""></a></figure>


<ol><li id="f8512c1c-7cae-4665-b5ba-b76a84e5b6e9">Jake’s wonderful friend <a href="https://www.yelp.com/biz/tracy-dempsey-originals-tempe">Tracey Dempsey</a> also dropped off a plethora of baked goods. Everything she makes is incredible, but I’m partial to the cheesecake. <a href="#f8512c1c-7cae-4665-b5ba-b76a84e5b6e9-link">↩︎</a></li></ol>					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building rqlite 9.0: Cutting disk usage by half (123 pts)]]></title>
            <link>https://www.philipotoole.com/building-rqlite-9-0-cutting-disk-usage-by-half/</link>
            <guid>41167060</guid>
            <pubDate>Tue, 06 Aug 2024 01:20:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.philipotoole.com/building-rqlite-9-0-cutting-disk-usage-by-half/">https://www.philipotoole.com/building-rqlite-9-0-cutting-disk-usage-by-half/</a>, See on <a href="https://news.ycombinator.com/item?id=41167060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-6737">
	
	<!-- .entry-header -->

		<div>
		<p><a href="https://rqlite.io/" target="_blank" rel="noopener noreferrer"><img src="https://www.philipotoole.com/wp-content/uploads/2016/04/j.png" alt="" width="131" height="126"></a><a href="https://www.rqlite.io/" target="_blank" rel="noopener noreferrer">rqlite</a> is a lightweight, <a href="https://github.com/rqlite/rqlite" target="_blank" rel="noopener noreferrer">open-source</a>, distributed relational database written in <a href="https://golang.org/" target="_blank" rel="noopener noreferrer">Go</a>, that uses <a href="http://sqlite.com/" target="_blank" rel="noopener noreferrer">SQLite</a> as its storage engine.</p>
<p><a href="https://github.com/rqlite/rqlite/tree/referential-snapshot" target="_blank" rel="noopener noreferrer">Development for 9.0 has started</a>, with the main goal of reducing disk usage by approximately 50%. This goal will be achieved through a high-level design overhaul targeting the primary causes of disk consumption in rqlite.</p>

<h2>What drives current disk usage?</h2>
<p>Today, rqlite’s disk space usage is driven by three main factors:</p>
<ol>
<li><strong>Raft Log:</strong> The log of all changes made to the system. This log is at the core of the <a href="https://raft.github.io/" target="_blank" rel="noopener noreferrer">Raft consensus protocol</a>.</li>
<li><strong>Working SQLite Database:</strong> The live database that rqlite uses to serve reads and writes.</li>
<li><strong>A snapshot of the SQLite Database:</strong> <a href="https://support.hashicorp.com/hc/en-us/articles/4408853527059-What-are-the-snapshot-entries-in-the-consul-data-raft-snapshot-directory" target="_blank" rel="noopener noreferrer">Periodically generated by the Raft system</a> as part of the Raft log truncation process. Log truncation prevents the Raft log from growing indefinitely and is a key component of Raft. This <em>snapshotted</em> copy is used by Raft to restore a node when it restarts, or when a second node needs to “catch up” with the state of an existing cluster.</li>
</ol>
<h2>High-Level Design for rqlite 9.0</h2>
<p>The key strategy for reducing disk usage involves removing the need to store the <em>snapshotted</em> copy of the working SQLite database in the Raft system. While the Raft log is periodically truncated and stops growing after a certain point due to snapshotting, the SQLite database does not have this limitation and continues to grow as more data is written to it. Since the snapshot SQLite database is roughly the same size as the working SQLite database, eliminating this duplicate copy can reduce disk usage by about 50%.</p>
<p><img src="https://www.philipotoole.com/wp-content/uploads/2024/08/rqlite-snapshot.png" alt="" width="150" height="140" srcset="https://www.philipotoole.com/wp-content/uploads/2024/08/rqlite-snapshot.png 360w, https://www.philipotoole.com/wp-content/uploads/2024/08/rqlite-snapshot-300x281.png 300w" sizes="(max-width: 150px) 100vw, 150px"></p>
<p>However, an rqlite node still needs a snapshotted copy — this cannot be avoided. So how do we avoid the copy, but still meet the needs of <em>Snapshot and Restore</em>? <strong>The key thing to understand is that the working SQLite database file — ignoring its associated WAL file — and the snapshotted copy in the Raft system are logically the same thing.</strong></p>
<h3>Step-by-step</h3>
<p>Let’s look at how snapshotting will work in 9.0.</p>
<ol>
<li><strong>Snapshot and WAL Checkpointing:</strong> At snapshot time, rqlite will checkpoint the Write-Ahead Log (WAL) of the working SQLite database. All subsequent writes will then be directed to a newly-created WAL file, leaving the main SQLite file unchanged (until the next snapshot is triggered). <strong>It is this key insight</strong> that allows us to use the working SQLite file to serve reads and writes, as well as contain the point-in-time state that the Raft Snapshot store requires.</li>
<li><strong>Write a <em>Reference</em> to Snapshot Store:</strong> Instead of copying the entire SQLite file, rqlite will write a <em>Reference</em>, such as a checksum, to the Snapshot store. This avoids the need to store a duplicate copy of the SQLite data. This reference can be used to validate that the main SQLite file matches what the Snapshot store references, whenever snapshot data is needed. (This check protects against bugs, operational mistakes, or disk corruption but isn’t strictly needed.)</li>
<li><strong>Restoration from Snapshot:</strong> Because all writes after the snapshot process are written to the WAL file, the main SQLite file remains ready for use by the <em>Restore-from-Snapshot</em> process if needed (e.g., during a node restart or when transferring the snapshot to another node). In other words the main SQLite file (again, ignoring its associated WAL file) remains logically the same as that written to the Raft snapshot store.</li>
</ol>
<p>This is why I call this process <em>Referential Snapshotting</em>.</p>
<h3>Bonus Enhancements</h3>
<p>This design change will actually result in a couple of other high-impact improvements.</p>
<ul>
<li><strong>Faster Snapshotting:</strong> By writing minimal data to the Raft Snapshot store, the snapshotting process will be much faster. It should consist of the SQLite WAL checkpointing time (which is usually very short) and the checksum computation time.&nbsp; There will be no need to copy large amounts of SQLite data to the Snapshot store on every snapshot. When one realises that writes to rqlite are blocked during the Snapshot process, the advantages of faster snapshotting are clear.</li>
<li><strong>Improved Node Restart Times:</strong> Nodes, <a href="https://github.com/rqlite/rqlite/issues/1798" target="_blank" rel="noopener noreferrer">even those with multiple gigabytes of SQLite data</a>, will restart much, much faster. Currently, at restart, rqlite has to restore the working SQLite database file from the copy in Raft Snapshot Store. But with this new design, the working SQLite database file will already be in the correct place at start-up. At most, rqlite will only need to compare the checksum in the Snapshot store to the checksum of the working SQLite database. Multi-GB systems should restart within a few seconds.</li>
</ul>
<h3>Next Steps</h3>
<p>The move to rqlite 9.0 should make a significant step forward in optimizing the efficiency of rqlite. By implementing <em>Referential Snapshotting</em>, I expect to achieve significant reductions in disk usage, faster snapshotting, and improved node restart times.</p>
<p>There are many details to get right, including SQLite WAL management, seamless upgrades from earlier releases, and checksum choice. So stay tuned for further updates as we progress towards this major release.</p>
<p><em>If you’re interested in learning more about Raft and how all this works, <a href="https://www.youtube.com/watch?v=8XbxQ1Epi5w" target="_blank" rel="noopener noreferrer">check out my recent talk at GopherCon</a> on building Distributed Systems.<br>
</em></p>
	</div><!-- .entry-content -->
	
	</article><!-- #post-6737 -->
		<!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<div id="secondary">
		<h2>Philip O'Toole</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can we stop the decline of monarch butterflies and other pollinators? (242 pts)]]></title>
            <link>https://www.wisfarmer.com/story/news/2024/08/05/can-we-stop-the-decline-of-monarch-butterflies-and-other-pollinators/74638545007/</link>
            <guid>41165273</guid>
            <pubDate>Mon, 05 Aug 2024 20:30:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wisfarmer.com/story/news/2024/08/05/can-we-stop-the-decline-of-monarch-butterflies-and-other-pollinators/74638545007/">https://www.wisfarmer.com/story/news/2024/08/05/can-we-stop-the-decline-of-monarch-butterflies-and-other-pollinators/74638545007/</a>, See on <a href="https://news.ycombinator.com/item?id=41165273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><article><div id="videoWrap"><media-video video-id="11622236002" title="Not just monarchs. Other butterflies you find around Wisconsin" poster="https://www.gannett-cdn.com/authoring/video-thumbnails/37786da8-df66-4c12-9ef8-4947419f99f7_poster.jpg" util-module-path="elements/media" placement="snow-video-story-priority"><div id="uwVideoPlaceholder" slot="placeholder"><p><img src="https://www.gannett-cdn.com/authoring/video-thumbnails/37786da8-df66-4c12-9ef8-4947419f99f7_poster.jpg"></p><p><img src="https://www.gannett-cdn.com/appservices/universal-web/universal/icons/icon-play-alt-white.svg" alt="play"></p></div></media-video></div><p>If you have noticed fewer monarch butterflies fluttering around the yard this summer, you're not alone. Several butterfly aficionados recently shared their concerns during a Facebook discussion on Monarch Madness in Wisconsin.</p><partner-banner util-module-path="elements/partner" min-height="600" fluid="" outstream="" momentum=""></partner-banner><p>Because just 5% of monarch eggs survive to become butterflies, conservation-minded people like Nina Bottomley of Elkhorn is trying to help. She says the number of monarch butterflies she's raised from eggs and newly hatched caterpillars has plummeted alarmingly.</p><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643656007-three-monarchs-tasting-flowers-kottke.jpg bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643656007-three-monarchs-tasting-flowers-kottke.jpg?crop=1439,1080,x0,y384 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643656007-three-monarchs-tasting-flowers-kottke.jpg?crop=1439,1919,x0,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643656007-three-monarchs-tasting-flowers-kottke.jpg?crop=1439,810,x0,y480 16:9" image-alt="" credit="Colleen Kottke/Wisconsin State Farmer" caption="A trio of monarch butterflies feed on the nectar of this liatris plant in a small pollinator garden. Whether it's a field, roadside area, open area, wet area, or urban garden; milkweed and flowering plants are needed for monarch habitat." orientation="vertical" util-module-path="elements/media"></media-image><p>"I went from 124 down to nearly none!" she posted. "What's going on?"</p><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643655007-monarch-caterpillar-eating-swamp-milkweed.jpg bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643655007-monarch-caterpillar-eating-swamp-milkweed.jpg?crop=1919,1439,x0,y0 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643655007-monarch-caterpillar-eating-swamp-milkweed.jpg?crop=1080,1439,x480,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643655007-monarch-caterpillar-eating-swamp-milkweed.jpg?crop=1919,1081,x0,y179 16:9" image-alt="" credit="Colleen Kottke/Wisconsin State Farmer" caption="A monarch caterpillar eats its fill on a swamp milkweed plant. Even a caterpillar this size can fall prey to predators like paper wasps." orientation="horizontal" util-module-path="elements/media"></media-image><h2>Where are all the pollinators this summer?</h2><p>PJ Liesch, director of the University of Wisconsin-Madison's Insect Diagnostics Lab, says he's heard several reports of general pollinator activity and numbers — including bees — being down this summer. Unfortunately, reasons for the decline are many.</p><p>In early fall, monarchs begin their 2,500-mile migration to the overwintering grounds in central Mexico. The fragile butterflies face ever-changing weather conditions along the way and declining habitat to fuel them for their arduous journey.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>Liesch says the eastern monarch butterfly population in Mexico's oyamel fir forests this past winter was nearly 60% less than the previous year. Because counting individual monarchs is an impossible task, researchers estimate the population by measuring the area they occupy (in hectares, which is approximately 2.47 acres). Scientists estimate there are between 20-30 million monarchs per hectare.</p><p>"In the winter of 2022-23, butterflies occupied just over two hectares. Last winter monarchs occupied under 1 hectare," said Liesch, adding that this is the first time since the 2013-14 overwintering season that the monarchs have occupied less than one hectare. "If you look back farther into the late 1990s, there has been a definite downward trend over time.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><h2>How do extreme weather events impact the success of migration?</h2><p>Liesch says butterflies across the eastern U.S. heading toward their overwintering ground last fall were met with brutal conditions thanks to a drought that left parched vegetation and fewer late-season nectar sources along waterways.</p><p>Monarch butterflies pass through Central Texas on their fall migration south, but this summer’s drought has made the butterflies' journey harder and may change where you'll see them.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="600" outstream="" momentum=""></partner-banner><p>"When they fly from the Midwest to Mexico, it's a marathon for them and they essentially need Gatorade, if you will, a carbohydrate source. If you have a drought and don't have many flowering plants, that can make it pretty hard for them," Liesch said.</p><p>Droughts during fall migration can also affect monarch lipid levels, which are crucial for overwintering survival and subsequent spring breeding, according to a report from the National Institutes of Health.</p><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643657007-baby-cat-kottke.jpg bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643657007-baby-cat-kottke.jpg?crop=844,633,x0,y0 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643657007-baby-cat-kottke.jpg?crop=669,890,x126,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643657007-baby-cat-kottke.jpg?crop=844,475,x0,y0 16:9" image-alt="" credit="Colleen Kottke/Wisconsin State Farmer" caption="In the wild, scientists estimate that 90 percent of monarch eggs and caterpillars fall victim to predators and parasites." orientation="vertical" util-module-path="elements/media"></media-image><h2>Pathogens and predators make life tough for young monarchs</h2><p>The milkweed plant is essential to the monarch's survival. Adult butterflies lay their eggs on the undersides of the leaves, and when the young larvae hatch out, they begin munching on the leaves, ingesting the toxins from the plant that give them some degree of protection from predators.</p><p>Liesch says the black, white and yellow caterpillars, as well as the adult butterflies, are still vulnerable to predation and disease.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>"Predators that feed on monarchs can range from assassin bugs and predatory stink bugs to paper wasps, which is a key predator," Liesch said. "If these wasps find a particular patch that has a high density of caterpillars, they can swoop in and pick them off one by one."</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>The rains during June may have contributed to lush gardens supporting pollinator-friendly plants, but hiding in that vegetation are insect-infecting pathogens, said Liesch.</p><p>"There's plenty of these naturally occurring insect pathogens out there, but this moisture can sometimes encourage that fungi or bacteria to kick in," he said.</p><p>The UW-Madison entomologist says weather patterns impacted by climate change may affect wider populations of pollinators.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>"There are insects associated with specific plants, and if all of a sudden conditions are no longer conducive for those plants to survive, then the insects that rely on them are going to struggle," Liesch said. "Certain plants bloom at different times, and if insects are emerging at a time when the plants aren't at the right stage for them, that could also lead to some complications."</p><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643681007-sprayer-kottke-ww.jpg bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643681007-sprayer-kottke-ww.jpg?crop=1279,959,x0,y0 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643681007-sprayer-kottke-ww.jpg?crop=720,959,x192,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643681007-sprayer-kottke-ww.jpg?crop=1279,721,x0,y119 16:9" image-alt="" credit="Colleen Kottke/Wisconsin State Farmer" caption="A study released by Michigan State University shows a link between the decline of butterflies and the use of agricultural insecticides in the Midwest." orientation="horizontal" util-module-path="elements/media"></media-image><h2>Insecticides are big factor in lower butterfly numbers, study says</h2><p>While climate change and disappearing habitat appear to play a role in declining pollinator numbers, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0304319">a study published</a> by researchers from Michigan State University points to insecticides as the largest contributor.</p><p>According to the 17-year-long study, co-author Scott Swinton said insecticides — rather than herbicides — are the single largest factor contributing to a decline in total butterfly abundance and species diversity in the Midwest.</p><p>“What drives butterfly decline is a hard nut to crack, due to rapid changes in chemical and genetic technologies alongside changes in climate and butterfly habitat,” said Swinton.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>The study, which collected data on land use, climate, multiple classes of pesticides and butterfly survey information, was gathered across 81 counties in five states including Wisconsin. According to the study, six different kinds of pesticides, and two types of herbicides, as well as glyphosate, and finally neonicotinoid seed treatments.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>The major technological shift in weed control since the 1990s has been the rise and continued dominance of glyphosate herbicides, commonly marketed as “Roundup”. Since the introduction of corn and soybean seed genetically engineered to tolerate this broad-spectrum herbicide, farmers have come to rely primarily on glyphosate for weed control in these crops.</p><p>"As a result, farmers increased glyphosate use while reducing the use of other herbicides," Swinton noted. "This became particularly concerning for monarch butterflies since their host plants are strongly associated with row crops and their numbers began a sharp decline during the period of glyphosate adoption."</p><p>Researchers found that shifts in insecticide use toward neonicotinoid-treated seeds are associated with an 8% decline in butterfly species diversity across the Midwest. Swinton told WPR that monarch butterflies were especially impacted, with populations declining over 20%.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>Ecologist Nick Haddad from the MSU&nbsp;<a href="https://www.kbs.msu.edu/">W.K. Kellogg Biological Station</a>&nbsp;and the&nbsp;<a href="https://integrativebiology.natsci.msu.edu/">Department of Integrative Biolog</a>y said the results of the years-long research is particularly impactful as butterflies play an essential role in pollination and serve as key markers of environmental health.</p><p>“As the best-known insect group, butterflies are key indicators of broader insect decline, and the implications of our findings for conservation will extend to the entire insect world,” Haddad said. "Understanding the primary factors contributing to their decline will help researchers working to protect these species, benefiting our environment and the sustainability of food systems."</p><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643654007-kottke-blazing-star.jpg bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643654007-kottke-blazing-star.jpg?crop=1919,1440,x0,y374 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643654007-kottke-blazing-star.jpg?crop=1641,2188,x139,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2024/08/02/PWWF/74643654007-kottke-blazing-star.jpg?crop=1919,1080,x0,y554 16:9" image-alt="" credit="Colleen Kottke/Wisconsin State Farmer" caption="A native bees burrows into a blazing star plant, a favorite of pollinators." orientation="vertical" util-module-path="elements/media"></media-image><h2>How can you help support pollinators?</h2><p>Pollinators are the engine that keeps our ecosystem healthy and our food supply abundant. According to the U.S. Forest Service, over 80% of flowering plants need pollinators to reproduce, and about one-third of the world's food crops depend on them.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>So, how can we help them? Here are some tips from the U.S. Fish and Wildlife Service:</p><ul><li>Everyone can do something to help keep pollinators abundant. From a simple window boxes filled with blooms to a few rows of flowers around the edge of your vegetable garden.</li><li>To attract a variety of pollinators, include a selection of plants native to your region. Pollinators need a variety of nectar and pollen sources.&nbsp;Check field guides to find out which plants attract native pollinators.</li><li>Select a site that is removed from wind, has at least partial sun, and can provide water.</li><li>Aim for early and late blooming plants. Selecting some plants that bloom early and others that keep their flowers late in the season helps ensure food for pollinators when other sources are scarce.</li><li>Make pesticides your last option in battling weeds and crop and garden pests.&nbsp;</li><li>Save the stems. Stems and twigs provide nesting sites for solitary bees and other insects. Hold off on pruning and snipping until late spring or just let stems naturally decompose.&nbsp;</li><li>Make your yard or garden friendly to overwintering pollinators. Some butterflies and native bees overwinter as larvae, seeking shelter in leaf litter or by burrowing deep into the ground.&nbsp;And don't be in a hurry to clean out that garden bed in early spring.</li></ul><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p><em>Contact Colleen Kottke at 920-517-2653 or&nbsp;</em><a href="mailto:ckottke@gannett.com">ckottke@gannett.com</a><em>. Follow her on X (formerly Twitter) at&nbsp;</em><a href="https://twitter.com/DukeBehnke" target="_blank" rel="noreferrer noopener"><em>@ColleenKottke</em></a><em>.</em></p><lit-timestamp slot="timestamp" publishdate="2024-08-05 10:05:15 +0000 UTC" updatedate="2024-08-05 18:27:45 +0000 UTC"></lit-timestamp><p><a alt="Post the article to your Facebook Timeline" data-size="large" onclick="fireNavShareAnalytics('facebook');" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M12.6143832,21 L3.99346182,21 C3.44462725,21 3,20.5550968 3,20.006476 L3,3.99345411 C3,3.44469364 3.44469709,3 3.99346182,3 L20.006608,3 C20.5552331,3 21,3.44469364 21,3.99345411 L21,20.006476 C21,20.5551667 20.5551632,21 20.006608,21 L15.4197395,21 L15.4197395,14.029408 L17.7594454,14.029408 L18.1097832,11.3128446 L15.4197395,11.3128446 L15.4197395,9.57849053 C15.4197395,8.79198274 15.6381418,8.25600363 16.7659836,8.25600363 L18.2044917,8.25537504 L18.2044917,5.82565895 C17.9557072,5.79255313 17.1017938,5.71858885 16.108332,5.71858885 C14.0343128,5.71858885 12.6143832,6.98457234 12.6143832,9.30945332 L12.6143832,11.3128446 L10.2686707,11.3128446 L10.2686707,14.029408 L12.6143832,14.029408 L12.6143832,21 L12.6143832,21 Z"></path>
            </svg><span>Facebook</span></a>
<a alt="Tweet about this article" data-size="large" onclick="fireNavShareAnalytics('twitter')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M21,6.77573131 C20.338616,7.07692308 19.6265188,7.28060672 18.8795563,7.3716143 C19.6423666,6.9035753 20.2276809,6.16143012 20.5034337,5.27735645 C19.7892235,5.71072589 19,6.02600217 18.1568938,6.19501625 C17.4849445,5.45937161 16.5245642,5 15.461701,5 C13.4236661,5 11.770206,6.69555796 11.770206,8.78656555 C11.770206,9.08342362 11.8019017,9.3716143 11.8652932,9.64897075 C8.79609086,9.4907909 6.07554147,7.98483207 4.25303751,5.69122427 C3.93502377,6.2524377 3.75330164,6.9035753 3.75330164,7.59696641 C3.75330164,8.91007584 4.40517697,10.0693391 5.39619651,10.7486457 C4.79186476,10.7302275 4.22134179,10.5579632 3.72266244,10.276273 L3.72266244,10.3228602 C3.72266244,12.1581798 4.9957739,13.6890574 6.68621236,14.035753 C6.37665082,14.1245937 6.05018489,14.1690141 5.71315372,14.1690141 C5.47543582,14.1690141 5.24300053,14.1462622 5.01796091,14.1018418 C5.4881141,15.6056338 6.85103011,16.7009751 8.46751189,16.7302275 C7.20390914,17.7464789 5.61067089,18.3521127 3.88114105,18.3521127 C3.58320127,18.3521127 3.28843106,18.3347779 3,18.3001083 C4.63444268,19.3726977 6.57633386,20 8.66085578,20 C15.4543053,20 19.1679873,14.2307692 19.1679873,9.22643554 C19.1679873,9.06175515 19.1648177,8.89707476 19.1584786,8.73564464 C19.8800845,8.20151679 20.5066033,7.53521127 21,6.77573131"></path>
            </svg><span>Twitter</span></a>
<a alt="Email this article" onclick="fireNavShareAnalytics('email')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
            <path d="M3,5.8757627 C3,5.39209232 3.39269552,5 3.8926228,5 L20.1073772,5 C20.6003592,5 21,5.40389442 21,5.8757627 L21,18.1242373 C21,18.6079077 20.6073045,19 20.1073772,19 L3.8926228,19 C3.39964084,19 3,18.5961056 3,18.1242373 L3,5.8757627 Z M12,11.09375 L3,6.74107143 L3,8.48214286 L12,12.8348214 L21,8.48214286 L21,6.74107143 L12,11.09375 Z"></path>
        </svg><span>Email</span></a></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debugging a rustc segfault on Illumos (196 pts)]]></title>
            <link>https://sunshowers.io/posts/rustc-segfault-illumos/</link>
            <guid>41164885</guid>
            <pubDate>Mon, 05 Aug 2024 19:54:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sunshowers.io/posts/rustc-segfault-illumos/">https://sunshowers.io/posts/rustc-segfault-illumos/</a>, See on <a href="https://news.ycombinator.com/item?id=41164885">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>At <a href="https://oxide.computer/">Oxide</a>, we use <a href="https://github.com/oxidecomputer/helios/">Helios</a> as
the base OS for the cloud computers we sell. Helios is a distribution of
<a href="https://illumos.org/">illumos</a>, a Unix-based operating system descended from Solaris.</p><p>As someone who learned illumos on the job, I’ve been really impressed by the powerful debugging
tools it provides. I had a chance to use some of them recently to track down a <a href="https://en.wikipedia.org/wiki/Segmentation_fault">segmentation
fault</a> in the Rust compiler, with the help of
several of my colleagues. I learned a lot from the process, and I thought I’d write about it!</p><p>I’m writing this post for an audience of curious technologists who aren’t necessarily familiar with
systems work. If you’re an experienced systems developer, parts of it are likely familiar to
you—feel free to skip over them.</p><h2 id="the-crash">The crash<a href="#the-crash" arialabel="Anchor">#</a></h2><p>A couple of weeks ago, I wanted to make a change to the Rust standard library on illumos. I logged
into my illumos box and cloned the <a href="https://github.com/rust-lang/rust">Rust repository</a> (revision
<code>2d5a628</code>). Following the <a href="https://rustc-dev-guide.rust-lang.org/building/how-to-build-and-run.html">setup
instructions</a>, I configured the <code>rustc</code> build system with the <code>library</code> build profile.</p><p>When I went to run <code>./x.py check</code>, I saw an error with the following output:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ ./x.py check
</span></span><span><span>Checking stage0 cranelift (x86_64-unknown-illumos)
</span></span><span><span>    Checking cranelift-codegen v0.109.0
</span></span><span><span>rustc exited with signal: 11 (SIGSEGV) (core dumped)
</span></span><span><span>error: could not compile `cranelift-codegen` (lib)
</span></span><span><span><span>
</span></span></span><span><span><span></span>Caused by:
</span></span><span><span>  process didn't exit successfully: ...
</span></span><span><span>Build completed unsuccessfully in 0:00:03
</span></span></code></pre></div><p>Quite concerning! Like any good technologist I tried running the command again. But the segfault
seemed to be completely deterministic: the program would crash while compiling <code>cranelift-codegen</code>
every time.</p><p>Coincidentally, we had our <abbr title="Every 2 weeks">fortnightly</abbr> “Rust @ Oxide” virtual meetup at around that time. There wasn’t much to discuss there, so we turned that meeting into a debugging session. (I love how my coworkers get excited about debugging strange issues.)</p><h2 id="background-the-bootstrap-process">Background: the bootstrap process<a href="#background-the-bootstrap-process" arialabel="Anchor">#</a></h2><figure><img src="https://sunshowers.io/images/bootstrap-stages.png" alt="A flowchart to indicate stages of compilation. For a full description, see the link for &quot;a series of stages&quot;."><figcaption>Rust compiler build stages.</figcaption></figure><p>Like the compilers for many other languages, the Rust compiler is written in the language it is
intending to compile (in this case, Rust). In other words, the Rust compiler is
<a href="https://en.wikipedia.org/wiki/Self-hosting_(compilers)#Compilers"><em>self-hosting</em></a>.</p><p>Any self-hosting compiler needs to answer the question: how in the world do you compile the compiler
if you don’t already have a working compiler? This is known as the <a href="https://en.wikipedia.org/wiki/Bootstrapping_(compilers)"><em>bootstrapping
problem</em></a>. There are several ways to
address the problem, but the two most common are:</p><ol><li><p><strong>Use the previous version of the compiler.</strong> In other words, use version N-1 of the compiler to
compile version N. For example, use Rust 1.75 to compile Rust 1.76.</p><details><summary>From where do you begin, though?</summary><p>The earliest versions of Rust were written in Ocaml. So if
you’re spinning up Rust on a brand new platform and have an Ocaml compiler available, you can
actually start <a href="https://github.com/rust-lang/rust/tree/ef75860a0a72f79f97216f8aaa5b388d98da6480/src/boot">from
there</a>
and effectively create your own lineage of compilers.</p><p>There are also implementations of Rust in other languages, like <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a> in C++, which can be used to build some (typically pretty old) version of the compiler. Interestingly, these other implementations don’t need to be perfect—for example, since they’re only used to compile code that’s known to be valid, they don’t need to handle errors well. That’s a large chunk of the complexity of a real compiler.</p></details></li><li><p><strong>Cross-compile from another platform.</strong> As a shortcut, if you have a way to cross-compile code
from another platform, you can use that to set up the initial compiler. This is the most common
method for setting up Rust on a new platform. (But note that method 1 must be used on at least
one platform.)</p></li></ol><p>While bootstrapping from the previous version of Rust, the toolchain follows <a href="https://rustc-dev-guide.rust-lang.org/building/bootstrapping/what-bootstrapping-does.html#stages-of-bootstrapping">a series of
stages</a>, ranging from <em>stage 0</em> to <em>stage 2</em>.</p><p>In our case, since we’re working with the standard library we’re only concerned with <em>stage 0</em>: the
standard library compiled with the previous version of <code>rustc</code>. That is the build process that crashed.</p><h2 id="orienting-ourselves">Orienting ourselves<a href="#orienting-ourselves" arialabel="Anchor">#</a></h2><p>The first thing to find is the version of <code>rustc</code> that’s crashing. There are a few ways to find the compiler, but a simple <code>find</code> command works well:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ find . -name rustc
</span></span><span><span>./compiler/rustc
</span></span><span><span>./src/doc/rustc
</span></span><span><span>./build/x86_64-unknown-illumos/stage0/bin/rustc
</span></span></code></pre></div><p>This command finds <code>rustc</code> at <code>./build/x86_64-unknown-illumos/stage0/bin/rustc</code>. Let’s ask it for its version:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ ./build/x86_64-unknown-illumos/stage0/bin/rustc -Vv
</span></span><span><span>rustc 1.80.0-beta.1 (75ac3b633 2024-06-10)
</span></span><span><span>binary: rustc
</span></span><span><span>commit-hash: 75ac3b6331873133c4f7a10f2252afd6f3906c6a
</span></span><span><span>commit-date: 2024-06-10
</span></span><span><span>host: x86_64-unknown-illumos
</span></span><span><span>release: 1.80.0-beta.1
</span></span><span><span>LLVM version: 18.1.7
</span></span></code></pre></div><p>Can the bug be reproduced independently of the Rust toolchain? The toolchain does all sorts of
non-standard things, so it’s worth checking. The output says <code>cranelift-codegen v0.109.0</code>, so let’s try building that separately. Again, there are a few ways to do this, but the easiest is to make a simple Cargo project that depends on the crate.</p><div><pre tabindex="0"><code data-lang="toml"><span><span>[<span>package</span>]
</span></span><span><span><span>name</span> = <span>"cranelift-codegen-test"</span>
</span></span><span><span><span>version</span> = <span>"0.1.0"</span>
</span></span><span><span><span>edition</span> = <span>"2021"</span>
</span></span><span><span>
</span></span><span><span>[<span>dependencies</span>]
</span></span><span><span><span>cranelift-codegen</span> = <span>"=0.109.0"</span>
</span></span></code></pre></div><p>And then run <code>cargo build</code>. I didn’t have rustc 1.80.0 beta 1 on the machine, so I tried with the 1.80.0 release:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ cargo +1.80.0 build
</span></span><span><span>   Compiling cranelift-codegen v0.109.0
</span></span><span><span>error: could not compile `cranelift-codegen` (lib)
</span></span><span><span><span>
</span></span></span><span><span><span></span>Caused by:
</span></span><span><span>  process didn't exit successfully: `/home/rain/.rustup/toolchains/1.80.0-x86_64-unknown-illumos/bin/rustc ...` (signal: 11, SIGSEGV: invalid memory reference)
</span></span></code></pre></div><p>Yep, it crashes in the same spot.</p><p>This is a minimal-enough example, so let’s work with this.</p><h2 id="finding-the-core-file">Finding the core file<a href="#finding-the-core-file" arialabel="Anchor">#</a></h2><figure><img src="https://sunshowers.io/images/dumpster-fire.jpg" alt="A cute cartoon depiction of a dumpster fire with a smiley face."><figcaption>Not this kind of dump! (<a href="https://www.pinterest.com/pin/dumpster-fire-2021-by-bywayanyone--227502218670597019/">Pinterest</a>)</figcaption></figure><p>When a program crashes, systems are typically configured to generate a <a href="https://en.wikipedia.org/wiki/Core_dump">core dump</a>, also known as a core file. The first step while debugging any crash is to ensure that core dumps are generated, and then to find one to examine it.</p><p>On illumos, many of the system-level administration tools are called <code>&lt;something&gt;adm</code>. The tool for managing core files is called <code>coreadm</code>. Let’s run that:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ coreadm
</span></span><span><span>     global core file pattern:
</span></span><span><span>     global core file content: default
</span></span><span><span>       init core file pattern: core
</span></span><span><span>       init core file content: default
</span></span><span><span>            global core dumps: disabled
</span></span><span><span>       per-process core dumps: enabled
</span></span><span><span>      global setid core dumps: disabled
</span></span><span><span> per-process setid core dumps: disabled
</span></span><span><span>     global core dump logging: disabled
</span></span></code></pre></div><p>This suggests that core “per-process core dumps” are enabled. The lack of a pattern indicates that the defaults are used. Generally, on Unix systems the default is to generate a file named <code>core</code> in the current directory of the crashing process.</p><p>A simple <code>ls</code> in our little test project doesn’t show a <code>core</code> file, which means that it might be elsewhere. Let’s just do a global <code>find</code> for it.</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ find / -name core -type f
</span></span></code></pre></div><p>This showed a few files on my system, including: <code>~/.cargo/registry/src/index.crates.io-6f17d22bba15001f/cranelift-codegen-0.109.0/core</code>. Bingo! That looks like a hit. (Why is it in the registry? Because when compiling a crate, Cargo sets the current working directory of the child <code>rustc</code> process to the crate’s directory.)</p><p>The next step is to move the file into another directory<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. After doing that, let’s start examining it.</p><h2 id="examining-the-core-file-registers-and-call-stack">Examining the core file: registers and call stack<a href="#examining-the-core-file-registers-and-call-stack" arialabel="Anchor">#</a></h2><p>The best way to examine a core file on illumos is with the <a href="https://illumos.org/books/mdb/preface.html">Modular Debugger, <code>mdb</code></a>. <code>mdb</code> is a powerful tool that can be used to inspect the state of both live and dead processes, as well as the kernel itself.</p><p>Using <code>mdb</code> with the core file is simple: just run <code>mdb core</code>.</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ mdb core
</span></span><span><span>Loading modules: [ libumem.so.1 libc.so.1 ld.so.1 ]
</span></span><span><span>&gt;
</span></span></code></pre></div><p>The first step is to enable symbol demangling<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The command to do that in <code>mdb</code> is <code>$G</code>, so let’s run that:</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; $G
</span></span><span><span>C++ symbol demangling enabled
</span></span></code></pre></div><p>(The output says “C++”, but illumos’s demangler can handle Rust symbols, too.)</p><p>Let’s look at the <a href="https://en.wikipedia.org/wiki/Processor_register">CPU registers</a> now. A register stores a small amount of data that the CPU can access very quickly. Core files typically have the contents of registers at the time of the crash, which can be very useful for debugging.</p><p>In <code>mdb</code>, the command to print out registers is <code>$r</code> or <code>::regs</code>. Here’s the output:</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; $r
</span></span><span><span>%rax <span>=</span> 0x000000000fb0d460       %r8  <span>=</span> 0x0000000001000000
</span></span><span><span>%rbx <span>=</span> 0x0000000000000000       %r9  <span>=</span> 0x0000000000000000
</span></span><span><span>%rcx <span>=</span> 0x0000000000000000       %r10 <span>=</span> 0x0000000000000010
</span></span><span><span>%rdx <span>=</span> 0x0000000000000001       %r11 <span>=</span> 0x0000000000000286
</span></span><span><span>%rsi <span>=</span> 0x000000000fb0d3d0       %r12 <span>=</span> 0x0000000000000d96
</span></span><span><span>%rdi <span>=</span> 0xfffffc7fed8e5f30       %r13 <span>=</span> 0x0000000000000000
</span></span><span><span>                                %r14 = 0x000000000fb0d3d0
</span></span><span><span>                                %r15 = 0xfffffc7fed8e6200
</span></span><span><span><span>
</span></span></span><span><span><span></span>%cs <span>=</span> 0x0053    %fs <span>=</span> 0x0000    %gs <span>=</span> 0x0000
</span></span><span><span>%ds <span>=</span> 0x004b    %es <span>=</span> 0x004b    %ss <span>=</span> 0x004b
</span></span><span><span><span>
</span></span></span><span><span><span></span>%rip <span>=</span> 0xfffffc7fd1adc4bb librustc_driver-86178b5e8d46877c.so<span>`</span>&lt;rustc_parse::parser::Parser&gt;::parse_path_segment+0x7b
</span></span><span><span>%rbp <span>=</span> 0xfffffc7fed8e6140
</span></span><span><span>%rsp <span>=</span> 0xfffffc7fed8e5c20
</span></span><span><span><span>
</span></span></span><span><span><span></span>%rflags <span>=</span> 0x00010216
</span></span><span><span>  id=0 vip=0 vif=0 ac=0 vm=0 rf=1 nt=0 iopl=0x0
</span></span><span><span>  status=&lt;of,df,IF,tf,sf,zf,AF,PF,cf&gt;
</span></span><span><span><span>
</span></span></span><span><span><span></span>%gsbase <span>=</span> 0x0000000000000000
</span></span><span><span>%fsbase <span>=</span> 0xfffffc7fee830a80
</span></span><span><span>%trapno <span>=</span> 0xe
</span></span><span><span>   %err = 0x6
</span></span></code></pre></div><p>All right, there’s a lot going on here. A full accounting of the registers on x86-64 is beyond the scope of this post, but if you’re interested <a href="https://math.hws.edu/eck/cs220/f22/registers.html">here’s a quick summary</a>. The most important registers here are <code>%rip</code>, <code>%rsp</code>, and <code>%rbp</code>. All three of these are 64-bit addresses.</p><figure><img src="https://sunshowers.io/images/call-stack.png" alt="A visual depiction of a call stack, showing three inactive frames plus an active frame."><figcaption>A visual depiction of a call stack.</figcaption></figure><ul><li><p><code>%rip</code> is the <strong>instruction pointer</strong>, also known as the <strong>program counter</strong>. <code>%rip</code> is a special register that points to the next instruction to be executed. The CPU uses to keep track of where it is in the program.</p></li><li><p><code>%rsp</code> is the <strong>stack pointer</strong>. The call stack is a region of memory that is used to store function call information and local variables. The stack pointer points to the head of the stack.</p><p>Note that on most architectures including x86-64, the stack grows down in memory: when a function is called, a new <em>stack frame</em> is set up and the stack pointer is decremented by however much space the function needs.</p></li><li><p><code>%rbp</code> is the <strong>base pointer</strong>, more commonly known as the <strong>frame pointer</strong>. It points to the base of the current stack frame<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p></li></ul><p>We can also look at the call stack via the <code>$C</code> command. The stack turns out to be enormous (<a href="https://gist.github.com/sunshowers/5edb7207c1e1234b0400bc6517f45b29">full output</a>):</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; $C ! wc -l
</span></span><span><span>1493
</span></span><span><span>&gt; $C
</span></span><span><span>fffffc7fed8e6140 librustc_driver-86178b5e8d46877c.so`&lt;rustc_parse::parser::Parser&gt;::parse_path_segment+0x7b()
</span></span><span><span>&lt;... snipped ...&gt;
</span></span></code></pre></div><p>(The <code>!</code> is used to send the output to a shell command, in this case one that counts the number of lines.)</p><p>It looks like the crash is in the <code>rustc</code> parser. (Notably, the crash is while compiling a crate called <code>cranelift-codegen</code>, which suggests automatic code generation. Generated code often tends to stress the parser in ways that manually written code does not.)</p><p>Based on the call stack, it looks like the <code>rustc</code> parser is recursive in nature. A quick Google
search
<a href="https://users.rust-lang.org/t/what-type-of-parser-does-the-rust-compiler-use/71430">confirms</a> that
the <code>rustc</code> parser is a “simple hand-written recursive descent parser”. This isn’t surprising, since
most production parsers are written this way. (For example, <a href="https://docs.rs/syn"><code>syn</code></a> is also a
recursive descent parser.)</p><p>Turning our attention to the instruction pointer <code>fffffc7fd1adc4bb</code>, we can use the <code>::dis</code> command to disassemble the function at that address. (<a href="https://gist.github.com/sunshowers/959c649926fe4a9d8bc53d967f895cdf#file-gistfile0-txt-L11">Full output</a>; the <code>-a</code> flag ensures that addresses are not converted to very long function names.)</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; fffffc7fd1adc4bb::dis -a
</span></span><span><span>&lt;... snipped ...&gt;
</span></span><span><span>fffffc7fd1adc4b6                movl   $0x1,%edx
</span></span><span><span>fffffc7fd1adc4bb                call   +0x1caf0 &lt;librustc_driver-86178b5e8d46877c.so`&lt;rustc_parse::parser::Parser&gt;::parse_ident_common&gt;
</span></span><span><span>fffffc7fd1adc4c0                cmpl   $0x0,0xfffffffffffffdf0(%rbp)
</span></span><span><span>&lt;... snipped ...&gt;
</span></span></code></pre></div><p>So it looks like the crash is happening in a <code>call</code> instruction to another function,
<code>parse_ident_common</code>.</p><p>(Keep in mind that this information could be completely unreliable! The stack might be corrupted, the registers might be wrong, and so on. But it’s what we have for now.)</p><h2 id="examining-the-address-space">Examining the address space<a href="#examining-the-address-space" arialabel="Anchor">#</a></h2><p>On <a href="https://en.wikipedia.org/wiki/Virtual_memory">virtual memory systems</a>, which includes all modern
desktop and server systems, each process gets the illusion that it has a very large amount of memory
all to itself. This is called the address space of a process. The instructions, the call stack, and
the heap all get their own regions of addresses in that space, called <em>memory mappings</em>. The 64-bit
addresses that we saw earlier are all part of the address space.</p><p><code>mdb</code> has a command called <code>whatis</code> to look up which part of memory an address is at. Let’s look at the stack pointer first:</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; fffffc7fed8e5c20::whatis
</span></span><span><span>fffffc7fed8e5c20 is in [ unknown ] [fffffc7fed8e5000,fffffc7fed8e6000)
</span></span></code></pre></div><p>This tells us that the address is in the range <code>0xfffffc7fed8e5000</code> to <code>0xfffffc7fed8e6000</code>. This is
a small 4 KiB range.</p><p>What about the frame pointer?</p><div><pre tabindex="0"><code data-lang="console"><span><span>&gt; fffffc7fed8e6140::whatis
</span></span><span><span>fffffc7fed8e6140 is in [ unknown ] [fffffc7fed8e6000,fffffc7fed9e7000)
</span></span></code></pre></div><p>This appears to be in a different range.</p><p>In this case, the ending address is <code>fffffc7fed9e7000</code> (note the <code>9e</code>, not the <code>8e</code>!). This address
is <strong><code>0x101000</code></strong> bytes away from the starting address. That is equal to 1028 <abbr title="Kibibyte, or 1024 bytes">KiB</abbr>, or 1 <abbr title="Mebibyte, or 1024 kibibytes">MiB</abbr> + 4 KiB page<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</p><p>Something else that’s relevant here is what permissions each range of addresses has. Like files on Unix, a block of virtual memory can have <em>read</em>, <em>write</em>, or <em>execute</em> permissions. (In this case, <em>execute</em> means that it is valid for the instruction pointer to point here<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.)</p><p>On illumos, a tool called <code>pmap</code> can show these spaces. <code>pmap</code> works on both live processes and core files. Running <code>pmap core</code> shows the permissions for the addresses we’re interested in (<a href="https://gist.github.com/sunshowers/03fdbd76162a838d9b11b3c9beba6a81#file-gistfile0-txt-L27-L28">full output</a>):</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ pmap core
</span></span><span><span>&lt;... snipped ..&gt;
</span></span><span><span>FFFFFC7FED8E5000          4K -----    [ anon ]
</span></span><span><span>FFFFFC7FED8E6000       1028K rw---    [ anon ]
</span></span><span><span>&lt;... snipped ..&gt;
</span></span></code></pre></div><p>The 1028 KiB range is read-write, and the 4 KiB range above that doesn’t have any permissions whatsoever.</p><p><strong>This would explain the segfault</strong>. A segfault is an attempt to operate on a part of memory that the program doesn’t have permissions for. Attempting to read from or write to memory which has no permissions is an example of that.</p><h2 id="formulating-a-theory">Formulating a theory<a href="#formulating-a-theory" arialabel="Anchor">#</a></h2><p>At this point, we have enough information to come up with a theory:</p><ul><li>The thread had a call stack of 1028 KiB available to it, starting at <code>fffffc7fed8e6000</code>.</li><li>The call stack pointer was at <code>fffffc7fed8e6140</code> (only <code>0x140</code> = 320 bytes away), and it tried to create a frame of size <code>0x520</code> (1312) bytes, at <code>fffffc7fed8e5c20</code>.</li><li>This caused the call stack to be <em>exhausted</em>: the thread ran out of space<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</li><li>When the thread ran out of space, it indexed into a 4 KiB section known as a <em>guard page</em>. The thread did not have any permissions to operate on the page, and was in fact designed to cause a segfault if accessed in any way.</li><li>The program then (correctly) segfaulted.</li></ul><p>But there are also other bits of evidence that this theory doesn’t explain, or even cuts against. (This is what makes post-mortem debugging exciting! There are often contradictory-seeming pieces of information that need to be explained.)</p><ol><li><p><strong>The memory is marked <code>anon</code> or <code>unknown</code>.</strong> That’s not how call stacks are supposed to be marked! In the <code>pmap</code> output, there’s a line which says:</p><pre tabindex="0"><code>FFFFFC7FED7B1000        316K rw---    [ stack tid=3 ]
</code></pre><p>So you’d expect call stacks to be marked with <code>[ stack tid=&lt;something&gt; ]</code>, not <code>[ anon ]</code>.</p></li><li><p><strong>Why is the size of the allocation 1028 KiB?</strong> You’d generally expect stack sizes to be a round power of two.</p></li><li><p><strong>Isn’t 1028 KiB kind of small?</strong> The thread is a non-main thread, and <a href="https://doc.rust-lang.org/std/thread/#stack-size">the default stack size for Rust threads is 2 MiB</a>. Why is our thread ~1 MiB and not 2 MiB?</p><details><summary>How are call stack sizes determined?</summary><p>On Unix platforms, for the main thread, the call stack size is determined by <code>ulimit -s</code> (in KiB). On my illumos machine, this printed <code>10240</code>, indicating a 10 MiB call stack.</p><p>For child threads, the call stack size is determined by whatever created them. For Rust, the default is 2 MiB.</p></details></li><li><p><strong>Why doesn’t this crash happen on other platforms?</strong> If this is a crash in the <code>rustc</code> parser, one would ordinarily expect it to arise everywhere. Yet it doesn’t seem to occur on Linux, macOS, or Windows. What’s special about illumos?</p></li><li><p><strong>Setting <code>RUST_MIN_STACK</code> doesn’t help.</strong> Rust-created thread stack sizes can be configured via <a href="https://doc.rust-lang.org/std/thread/#stack-size">the <code>RUST_MIN_STACK</code> environment variable</a>. If we try to use that:</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ RUST_MIN_STACK<span>=</span><span>$((</span><span>4</span> <span>*</span> <span>1024</span> <span>*</span> <span>1024</span><span>))</span> cargo build
</span></span></code></pre></div><p>It turns out that <code>rustc</code> crashes at exactly the same spot. That’s really strange!</p><p>It is possible that the stack size was overridden at thread creation time. The documentation for <code>RUST_MIN_STACK</code> says: “Note that setting <code>Builder::stack_size</code> will override this.” But that seems unlikely.</p></li></ol><h2 id="a-closer-look-at-the-call-stack">A closer look at the call stack<a href="#a-closer-look-at-the-call-stack" arialabel="Anchor">#</a></h2><p>Looking towards the bottom of the call stack, there’s <a href="https://gist.github.com/sunshowers/5edb7207c1e1234b0400bc6517f45b29#file-gistfile0-txt-L1478-L1483">something really strange</a>:</p><pre tabindex="0"><code>fffffc7fed9e5f80 librustc_driver-86178b5e8d46877c.so`rustc_query_system::query::plumbing::try_execute_query...
fffffc7fed9e5fd0 librustc_driver-86178b5e8d46877c.so`stacker::grow::&lt;rustc_middle::query::erase::Erased&lt;[u8; 16]&gt;, ...&gt;
fffffc7fed9e5ff0 librustc_driver-86178b5e8d46877c.so`psm::on_stack::with_on_stack...
fffffc7fed7e4960 librustc_driver-86178b5e8d46877c.so`rust_psm_on_stack+9()
fffffc7fed7e4a20 librustc_driver-86178b5e8d46877c.so`stacker::_grow+0x13e()
fffffc7fed7e4ad0 librustc_driver-86178b5e8d46877c.so`rustc_query_impl::query_impl::resolver_for_lowering_raw::get_query_non_incr...
</code></pre><p>Notice the jump in addresses from <code>fffffc7fed7e4960</code> to <code>fffffc7fed9e5ff0</code>? Normally, stack addresses are decremented as new functions are called: the number goes down. In this case the stack address is <em>incremented</em>. The number went up. Strange.</p><p>Also notice that this coincides with the use of a function called <code>stacker::_grow</code>. Now that’s a real lead!</p><p><strong>What part of memory is <code>fffffc7fed7e4960</code> in?</strong> <code>mdb</code> says:</p><pre tabindex="0"><code>&gt; fffffc7fed7e4960::whatis
fffffc7fed7e4960 is in [ stack tid=3 ]
</code></pre><p>So <em>this</em> address is part of the stack for thread 3. <a href="https://gist.github.com/sunshowers/03fdbd76162a838d9b11b3c9beba6a81#file-gistfile0-txt-L26"><code>pmap</code> agrees</a>:</p><pre tabindex="0"><code>FFFFFC7FED7B1000        316K rw---    [ stack tid=3 ]
</code></pre><p><strong>What is <code>stacker</code>?</strong> Time for some googling! Per <a href="https://docs.rs/stacker">the documentation</a>, <code>stacker</code> is:</p><blockquote><p>A library to help grow the stack when it runs out of space.</p><p>This is an implementation of manually instrumented segmented stacks where
points in a program’s control flow are annotated with “maybe grow the stack
here”. Each point of annotation indicates how far away from the end of the
stack it’s allowed to be, plus the amount of stack to allocate if it does
reach the end.</p></blockquote><p>Because the <code>rustc</code> parser is recursive, it is susceptible to call stack exhaustion. The use of <code>stacker</code> is supposed to prevent, or at least mitigate, that.</p><p><strong>How does <code>stacker</code> work?</strong> The library has <a href="https://docs.rs/stacker/0.1.15/stacker/fn.maybe_grow.html">a pretty simple API</a>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span> <span>fn</span> <span>maybe_grow</span><span>&lt;</span>R, F: FnOnce() -&gt; <span>R</span><span>&gt;</span>(
</span></span><span><span>    red_zone: <span>usize</span>,
</span></span><span><span>    stack_size: <span>usize</span>,
</span></span><span><span>    callback: <span>F</span>,
</span></span><span><span>) -&gt; <span>R</span> { <span>..</span>. }
</span></span></code></pre></div><figure><img src="https://sunshowers.io/images/rust-stack.jpg" alt="An image from YouTube showing Rust the video game, titled &quot;EZ Triple Floor Stack&quot;."><figcaption>Er, wrong Rust.</figcaption></figure><p>The developer is expected to intersperse calls to <code>maybe_grow</code> within their recursive function. If less than <code>red_zone</code> bytes of stack space remain, <code>stacker</code> will allocate a new segment of <code>stack_size</code> bytes, and run <code>callback</code> with the stack pointer pointing to the new segment.</p><p><strong>How does rustc use <code>stacker</code>?</strong> The code is in <a href="https://github.com/rust-lang/rust/blob/dba8e2d2c2890a8b9e88cbf4855ac5711337946c/compiler/rustc_data_structures/src/stack.rs#L17">this file</a>. The code requests an additional 1 MiB stack with a red zone of 100 KiB.</p><p><strong>Why did <code>stacker</code> create a new stack segment?</strong> In our case, the call is at the very bottom of the stack, when plenty of space should be available, so ordinarily <code>stacker</code> should not need to allocate a new segment. Why did it do so here?</p><p>The answer is <a href="https://github.com/rust-lang/stacker/blob/5df2309ccf7b1671909386c2670c7342a4d44142/src/lib.rs#L412-L457">in <code>stacker</code>’s source code</a>. There is code to guess the stack size on many platforms. But it isn’t enabled on illumos: <code>guess_os_stack_limit</code> always returns <code>None</code>.</p><h2 id="putting-it-together">Putting it together<a href="#putting-it-together" arialabel="Anchor">#</a></h2><p>With this information in hand, we can flesh out our call stack exhaustion theory:</p><ul><li><p>Some file in <code>cranelift-codegen</code> was triggering the crash by requiring more than 1 MiB of stack space.</p><ul><li>The <code>rustc</code> parser running against <code>cranelift-codegen</code> needed more than 1 MiB of stack space, but less than 2 MiB.</li></ul></li><li><p>Had this bug occurred on other platforms like Linux, this issue would have been a showstopper. However, it wasn’t visible on those platforms because:</p><ul><li>Threads created by Rust use a 2 MiB stack by default.</li><li><code>rustc</code> requested that <code>stacker</code> create a 1 MiB stack segment, but only if less than 100 KiB of stack space was left.</li><li>On the other platforms, <code>stacker</code> could see that well over 100 KiB of stack space was left, and so it did not allocate a new segment.</li><li>On illumos, <code>stacker</code> could not see how much stack was left, and so it allocated a new 1 MiB segment.</li><li>This 1 MiB stack was simply not enough to parse <code>cranelift-codegen</code>.</li></ul></li><li><p><code>rustc</code> didn’t call <code>stacker::maybe_grow</code> enough! In order for it to work, <code>stacker</code> needs to be interspersed throughout the recursive code. But some recursive parts did not appear to have called it.</p></li></ul><p>(It is somewhat ironic that <code>stacker</code>, a library meant to prevent call stack exhaustion, was actively making life worse here.)</p><p><strong>Where does the 1028 KiB come from?</strong> Looking at the <a href="https://github.com/rust-lang/stacker/blob/5df2309ccf7b1671909386c2670c7342a4d44142/src/lib.rs#L228-L234"><code>stacker</code> source code</a>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span> page_size <span>=</span> page_size();
</span></span><span><span><span>let</span> requested_pages <span>=</span> stack_size
</span></span><span><span>    .checked_add(page_size <span>-</span> <span>1</span>)
</span></span><span><span>    .expect(<span>"unreasonably large stack requested"</span>) <span>/</span> page_size;
</span></span><span><span><span>let</span> stack_pages <span>=</span> std::cmp::max(<span>1</span>, requested_pages) <span>+</span> <span>2</span>;
</span></span><span><span><span>let</span> stack_bytes <span>=</span> stack_pages.checked_mul(page_size)
</span></span><span><span>    .expect(<span>"unreasonably large stack requesteed"</span>);
</span></span></code></pre></div><p>It looks like <code>stacker</code> first computes the number of requested pages by dividing the requested stack size by the page size, rounding up. Then it adds 2 to that. In our case:</p><ul><li>The requested stack size is 1 MiB.</li><li>With 4 KiB pages, this works out to 256 pages.</li><li><code>stacker</code> then requests 256 + 2 = 258 pages, which is 1032 KiB.</li></ul><p>This explains both the 1028 KiB allocation (one guard page after the stack), and the 4 KiB guard page we’re crashing at (one guard page before the stack).</p><h2 id="triggering-the-bug-on-other-platforms">Triggering the bug on other platforms<a href="#triggering-the-bug-on-other-platforms" arialabel="Anchor">#</a></h2><p>If the issue is that a 1 MiB stack isn’t enough, it should be possible to reproduce this on other platforms by setting their stack size to something smaller than the 2 MiB default.</p><p>With a stack size &lt;= 1 MiB, we would expect that:</p><ol><li><code>rustc</code> calls <code>stacker</code> as before.</li><li>There are two possibilities: either <code>stacker</code> decides there is enough stack space and doesn’t create a new segment, or it decides there isn’t enough and does create a new 1 MiB segment.</li><li>In either case, 1 MiB is simply not enough to parse <code>cranelift-codegen</code>, and the program crashes.</li></ol><p>Let’s try to compile <code>cranelift-codegen</code> on Linux with a reduced stack size.</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ cd cranelift-codegen-test
</span></span><span><span>$ RUST_MIN_STACK<span>=</span><span>1048576</span> cargo +1.80.0 build
</span></span><span><span><span>
</span></span></span><span><span><span></span>note: rustc unexpectedly overflowed its stack! this is a bug
</span></span><span><span>note: maximum backtrace depth reached, frames may have been lost
</span></span><span><span>note: we would appreciate a report at https://github.com/rust-lang/rust
</span></span><span><span>help: you can increase rustc's stack size by setting RUST_MIN_STACK=2097152
</span></span><span><span>note: backtrace dumped due to SIGSEGV! resuming signal
</span></span></code></pre></div><p>This does crash as expected. The full output is <a href="https://gist.github.com/sunshowers/3ac000e5a5022acd3f07886a16a39520">here</a>. Some of the symbols are missing, but the crash does seem to be in parser code.</p><p>(At this point, we could have gone further and tried to make <a href="https://github.com/rust-lang/rust/issues/116249#issuecomment-1741572717">a debug-assertions build of <code>rustc</code></a> – but it was already pretty clear why the crash was happening.)</p><h2 id="what-codes-failing-to-parse-anyway">What code’s failing to parse, anyway?<a href="#what-codes-failing-to-parse-anyway" arialabel="Anchor">#</a></h2><p>Call stack exhaustion in the parser suggests that the crash is happening in some kind of large, automatically generated file. But what file is it?</p><figure><img src="https://sunshowers.io/images/strace-mascot.png" alt="A cartoon ostrich with a light orange head, yellow eyes, orange beak and feet, and a coat of black and a couple shades of grey."><figcaption>Der Strauß, the strace mascot. CC BY-SA 4.0, by Vitaly Chaykovsky.</figcaption></figure><p>It’s hard to tell by looking at the core file itself, but we have another dimension of debugging at hand: syscall tracers! These tools print out all the <abbr title="System calls: calls from user programs into the kernel">syscalls</abbr> made by a process. Most OSes have some means to trace syscalls: <a href="https://strace.io/"><code>strace</code></a> on Linux, <a href="https://opensource.apple.com/source/dtrace/dtrace-147/DTTk/dtruss.auto.html"><code>dtruss</code></a> on macOS, <a href="https://en.wikipedia.org/wiki/Process_Monitor">Process Monitor</a> on Windows, and <a href="https://illumos.org/man/1/truss"><code>truss</code></a> on illumos<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>.</p><p>Since we’re interested in file reads, we can try filtering it down to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/">the <code>open</code> and <code>openat</code> syscalls</a>. You need to open a file to read it, after all. (Alternatively, we can also simply not filter out any syscalls, dump the entire trace to a file, and then look at it afterwards.)</p><p>On illumos, we tell <code>truss</code> to run <code>cargo build</code>, filtering syscalls to <code>open</code> and <code>openat</code> (<code>-t</code>), and following child processes (<code>-f</code>):</p><div><pre tabindex="0"><code data-lang="console"><span><span>$ truss -ft open,openat cargo build
</span></span></code></pre></div><p>This prints out every file that the child <code>rustc</code> tries to open (<a href="https://gist.github.com/sunshowers/1d9d67722d10b4b3f80ac2fe42d61e7a#file-gistfile0-txt-L549-L555">full output</a>):</p><pre tabindex="0"><code>20755/3:	open("/home/rain/dev/cranelift-codegen-test/target/debug/build/cranelift-codegen-dad37ce046df129a/out/isle_opt.rs", O_RDONLY|O_CLOEXEC) = 13
20755/3:	    Incurred fault #6, FLTBOUNDS  %pc = 0xFFFFFC7FD9E74361
20755/3:	      siginfo: SIGSEGV SEGV_ACCERR addr=0xFFFFFC7FED22CA58
20755/3:	    Received signal #11, SIGSEGV [default]
20755/3:	      siginfo: SIGSEGV SEGV_ACCERR addr=0xFFFFFC7FED22CA58
20754/3:	    Received signal #18, SIGCLD, in waitid() [default]
20754/3:	      siginfo: SIGCLD CLD_DUMPED pid=20755 status=0x000B
</code></pre><p>It looks like the crash is in a file called <code>isle_opt.rs</code> in the <code>out/</code> directory. With Cargo, a file being in an <code>out/</code> directory is a pretty strong indication that it is generated by a build script.</p><p>On Linux, a similar <code>strace</code> command is:</p><div><pre tabindex="0"><code data-lang="console"><span><span>RUST_MIN_STACK=1048576 strace -fe open,openat cargo build
</span></span></code></pre></div><p>This command also blames the same file, <code>isle_opt.rs</code>.</p><p>What does this file look like, anyway? <a href="https://gist.githubusercontent.com/sunshowers/22b1a612ee1cb88047c456532e0f6877/raw/9403b8b644f25c600d426ee1a39e2459684244dc/gistfile0.txt">Here’s my copy.</a> It’s pretty big and deeply nested! It does look large and complex enough to trigger call stack exhaustion.</p><p>Syscall traces would definitely be somewhat harder to get if the crash weren’t so easily reproducible. Someone smarter than me should write about how to figure this out using just the core file. The file’s fully loaded into memory so it seems like it should be possible.</p><h2 id="unblocking-myself">Unblocking myself<a href="#unblocking-myself" arialabel="Anchor">#</a></h2><p>Going back to the beginning: the reason I went down this adventure was because I wanted to make an unrelated change to the Rust standard library. But the stage 0 compiler being broken meant that it was impossible to get to the point where I could build the standard library as-is, let alone test that change.</p><p>How can we work around this? Well, going back to basics, where did the stage 0 compiler come from? It came from Rust’s CI, and it wasn’t actually built on illumos! (Partly because there’s no publicly-available CI system running illumos.) Instead, it was cross-compiled from Linux to illumos.</p><p>Based on this, my coworker Joshua suggested that I try and do whatever Rust’s CI does to build a stage 0 compiler for illumos.</p><p>Rust’s CI uses <a href="https://github.com/rust-lang/rust/tree/75ac3b633/src/ci/docker">a set of Docker images</a> to build distribution artifacts. In theory, building a patched rustc should be as simple as running these commands on my Linux machine:</p><div><pre tabindex="0"><code data-lang="console"><span><span># Check out the exact version of the stage0 compiler
</span></span><span><span>$ git checkout 75ac3b633
</span></span><span><span><span>
</span></span></span><span><span><span></span># Make changes...
</span></span><span><span><span>
</span></span></span><span><span><span></span># Run Docker build
</span></span><span><span>$ ./src/ci/docker/run.sh dist-x86_64-illumos
</span></span></code></pre></div><p>In reality, there were some Docker permissions issues due to which I had to make a couple of changes to the script. Overall, though, it was quite simple. <a href="https://gist.github.com/sunshowers/2dacc5902ad4aecc50d215f018f55232">Here’s the patch</a> I built the compiler with, including the changes to the CI scripts.</p><p>The result of building the compiler was a set of <code>.tar.xz</code> files, just like <a href="https://github.com/rust-lang/rust/blob/2d5a628a1de1d38318909a710ef37da6251e362e/src/stage0">the ones published by Rust’s CI</a>. After copying the files over to my illumos machine, I wasn’t sure which tarballs to extract. So I made <a href="https://gist.github.com/sunshowers/9b6774edfabbea6985881617302caf34">a small change</a> to the bootstrap script to use my patched tarballs.</p><p>With this patch, I was able to successfully build Rust’s standard library on illumos and test my changes. Hooray! (<a href="https://github.com/rust-lang/rust/pull/128259">Here’s</a> what I was trying to test.)</p><p><em>Update 2024-08-05: After this post was published, jyn pointed out <a href="https://hachyderm.io/deck/@jyn@tech.lgbt/112906410687051157">on Mastodon</a> that <code>cranelift-codegen</code> is actually optional, and that I could have also worked around the issue by disabling it in the <code>rustc</code> build system’s <code>config.toml</code>. Thanks!</em></p><h2 id="what-did-we-learn">What did we learn?<a href="#what-did-we-learn" arialabel="Anchor">#</a></h2><p>The bug occurred due to a combination of several factors. It also revealed a few other issues, such as the lack of an environment variable workaround and some missing error reporting.</p><p>Here are some ways we can make the situation better, and help us have an easier time
debugging similar issues in the future.</p><ol><li><p><strong><code>rustc</code> isn’t using <code>stacker</code> enough.</strong> The basic problem underneath it all is that the part of the <code>rustc</code> parser that triggered the bug wasn’t calling <code>stacker</code> often enough to make new stack segments. <code>rustc</code> should be calling <code>stacker</code> more than it is today.</p><ul><li>Filed as <a href="https://github.com/rust-lang/rust/issues/128422">rust-lang/rust#128422</a>.</li></ul></li><li><p><strong><code>stacker</code> cannot detect the stack size on illumos.</strong> This is something that we should fix in <code>stacker</code>, but this is actually a secondary issue here. On other platforms, <code>stacker</code>’s ability to detect the stack size was masking the <code>rustc</code> bug.</p><p>Fixing this requires two changes:</p><ul><li>A <a href="https://github.com/rust-lang/libc/pull/3788">PR to <code>libc</code></a> to add the <code>pthread_attr_get_np</code> function to it.</li><li>A <a href="https://github.com/rust-lang/stacker/pull/88">PR to <code>stacker</code></a> to use this function to detect the stack size on illumos.</li></ul></li><li><p><strong><code>stacker</code>-created segments don’t print a nice message on stack exhaustion.</strong> This is a bit ironic because <code>stacker</code> is supposed to prevent stack exhaustion. But when it does happen, it would be nice if <code>stacker</code> printed out a message like standard Rust does.</p><ul><li>This is <a href="https://github.com/rust-lang/stacker/issues/59">rust-lang/stacker#59</a>.</li></ul></li><li><p><strong>On illumos, the Rust runtime doesn’t print a message on stack exhaustion.</strong> Separate from the previous point, on illumos the Rust runtime doesn’t print a message on stack exhaustion even when using native stacks.</p><ul><li>Filed as <a href="https://github.com/rust-lang/rust/issues/128568">rust-lang/rust#128568</a>.</li></ul></li><li><p><strong>Rust’s CI doesn’t run on illumos.</strong> At Oxide, we have an existential dependency on Rust targeting illumos. Even a shadow CI that ran on nightly releases would have caught this issue right away.</p><p>We’re discussing the possibilities for this internally; stay tuned!</p></li><li><p><strong><code>stacker</code> segment sizes can’t be controlled via the environment.</strong> Being able to control stack sizes with <code>RUST_MIN_STACK</code> is a great way to work around issues. It doesn’t appear that <code>stacker</code> segment sizes can be controlled in this manner. Maybe that functionality should be added to <code>rustc</code>, or to <code>stacker</code> itself?</p><ul><li>Opened a <a href="https://internals.rust-lang.org/t/allow-controlling-rustc-stacker-segment-sizes-via-the-environment/21292">discussion on internals.rust-lang.org</a>.</li></ul></li><li><p><strong>Maybe a <a href="https://github.com/rust-lang/crater">crater</a> run with a smaller stack size?</strong> It would be interesting to see if there are other parts of the Rust codebase that need to call <code>stacker</code> more as well.</p></li><li><p><strong><code>x.py</code> suggests disabling optional components.</strong> Since <code>cranelift-codegen</code> was an optional component that can be disabled, the <code>x.py</code> tooling
could notice if a build failed in such a component, and recommend disabling that component. <em>Added 2024-08-05, suggested <a href="https://hachyderm.io/deck/@jyn@tech.lgbt/112906451310138312">by jyn</a>.</em></p></li></ol><p>To me, this is the most exciting part of debugging: what kinds of changes can we make, both
specific and systemic ones, to make life easier for our future selves?</p><h2 id="conclusion-and-credits">Conclusion and credits<a href="#conclusion-and-credits" arialabel="Anchor">#</a></h2><p>This was a really fun debugging experience because I got to learn about several illumos debugging
tools, and also because we could synthesize information from several sources to figure out a complex
issue. (Thankfully, the root cause was straightforward, with no memory corruption or other “spooky
action at a distance” involved.)</p><p>Debugging this was a real team effort. I couldn’t have done it without the assistance of several of
my exceptional colleagues. In no particular order:</p><ul><li><a href="https://m.unix.house/@jmc">Joshua M. Clulow</a></li><li><a href="https://mattkeeter.com/">Matt Keeter</a></li><li><a href="https://discuss.systems/@cross">Dan Cross</a></li><li><a href="https://cliffle.com/">Cliff Biffle</a></li><li><a href="https://steveklabnik.com/">Steve Klabnik</a></li><li><a href="https://artemis.sh/">artemis everfree</a></li></ul><p>Thanks to all of you!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Loses DOJ Antitrust Suit Over Search (866 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-08-05/google-loses-doj-antitrust-suit-over-search</link>
            <guid>41164240</guid>
            <pubDate>Mon, 05 Aug 2024 18:58:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-08-05/google-loses-doj-antitrust-suit-over-search">https://www.bloomberg.com/news/articles/2024-08-05/google-loses-doj-antitrust-suit-over-search</a>, See on <a href="https://news.ycombinator.com/item?id=41164240">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Iso20022.js – Create payments in 3 lines of code (245 pts)]]></title>
            <link>https://www.iso20022js.com/</link>
            <guid>41163645</guid>
            <pubDate>Mon, 05 Aug 2024 17:55:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iso20022js.com/">https://www.iso20022js.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41163645">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header></header><main><div><h2><span>Open source</span><br>Enterprise-grade ISO20022 Infrastructure</h2><p><code>iso20022.js</code> is a low-dependency, open-source node library that helps companies communicate with banks using open ISO20022 standards.<!-- --> <a href="https://docs.iso20022js.com/" target="_blank" rel="noopener noreferrer">Try sending a SWIFT payment in three lines of code.</a></p><p><code>npm install iso20022.js</code></p><p><span>Code</span><label><span></span></label><span>XML</span></p><div><pre><code>import { ISO20022 } from 'iso20022.js'

const iso20022 = new ISO20022({
    initiatingParty: {
        name: 'Acme Corporation',
        id: 'ACMECORP',
        account: {
            accountNumber: '123456789012',
        },
        agent: {
            bic: 'CHASUS33',
            bankAddress: {
                country: 'US',
            }
        }
    }
});

const creditPaymentInitiation = iso20022.createSWIFTCreditPaymentInitiation({
    paymentInstructions: [{
        type: 'swift',
        direction: 'credit',
        amount: 1000,
        currency: 'USD',
        creditor: {
            name: 'Jane Smith',
            account: {
                iban: 'DE89370400440532013000'
            },
            agent: {
                bic: 'DEUTDEFF',
            },
            address: {
                streetName: "123 Main St",
                townName: "Funkytown",
                postalCode: "12345",
                country: "DE",
            }
        }
    }]
});

console.log(creditPaymentInitiation.toString());</code></pre></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Airhart Aeronautics (YC S22) – A modern personal airplane (637 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41163382</link>
            <guid>41163382</guid>
            <pubDate>Mon, 05 Aug 2024 17:26:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41163382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="41163382">
      <td><span></span></td>      <td><center><a id="up_41163382" href="https://news.ycombinator.com/vote?id=41163382&amp;how=up&amp;goto=item%3Fid%3D41163382"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=41163382">Launch HN: Airhart Aeronautics (YC S22) – A modern personal airplane</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_41163382">104 points</span> by <a href="https://news.ycombinator.com/user?id=n_ermosh">n_ermosh</a> <span title="2024-08-05T17:26:43"><a href="https://news.ycombinator.com/item?id=41163382">3 hours ago</a></span> <span id="unv_41163382"></span> | <a href="https://news.ycombinator.com/hide?id=41163382&amp;goto=item%3Fid%3D41163382">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Airhart%20Aeronautics%20(YC%20S22)%20%E2%80%93%20A%20modern%20personal%20airplane&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=41163382&amp;auth=31ffb8bc42a23118d4b11c8ab7459e5e28c5f2c6">favorite</a> | <a href="https://news.ycombinator.com/item?id=41163382">117&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hey Hacker News! I’m Nikita, founder of Airhart Aeronautics (<a href="https://www.airhartaero.com/">https://www.airhartaero.com/</a>). We are building an airplane for people who don’t fly airplanes. The goal is to make flying as easy as driving a car—while maintaining a high bar for safety. Here’s a video that shows a bit of our hardware and quite a bit of our software: <a href="https://youtu.be/PGJUGUceu8A" rel="nofollow">https://youtu.be/PGJUGUceu8A</a></p><p>In the US, trips that are 50-300 miles are almost all done by car because that distance is too short for commercial airlines and too far for public transportation. Thanks to the Wright Brothers we've had aerial transport for over 100 years. The US has over 19,000 airports, and large commercial airplane technology has developed to the point that the planes practically fly themselves. If we already have the infrastructure and the technology, why isn't everyone flying planes?</p><p>The problem is that small airplane technology hasn’t innovated and is stuck in the past. Flying a small airplane is complicated, mentally taxing, and dangerous—about 28x more dangerous than driving a car. Outdated airplanes, coupled with outdated flight controls, lead to regular accidents, often due to some form of loss of control. The planes are expensive and margins are small. There is no incentive to innovate within the current market, so we are looking at the new, untapped market of those who don’t think about flying as an option today and making it an option.</p><p>I first came across this when I learned to fly in 2020. I was learning in a “modern” GA airplane but was immediately struck by the fact that an airplane built in 2018 did not have an engine computer and there was a manual level to control the fuel/air mixture ratio. Starting it on a hot day was like starting a stubborn lawn mower. On top of that, my instructor was telling me all the various ways I could kill myself if I’m not running at 100% concentration for hours on end. This just didn’t sit right with me.</p><p>At the time I was working at SpaceX as an avionics engineer, leading the development of the avionics for the fairing recovery program. I also built autonomous aircraft when I was a student at Cornell, where I got a degree in electrical and computer engineering. It was clear to me that the core problem is that airplanes are too unsafe and too complicated to operate which is keeping too many people out of aviation. So, I decided to leave SpaceX and was joined by my long-time friend Brendan (he was a software engineer at Apple at the time; we built autonomous aircraft together at Cornell) to start Airhart to tackle this problem and make flying safer and more accessible.</p><p>We are developing a full hardware and software package to change how people fly airplanes. It’s a fly-by-wire control system, meaning instead of mechanical linkages between the pilot’s control stick and the control surfaces, it’s a joystick that sends digital commands to a computer that then moves the control surfaces accordingly with servo actuators. We’re developing all of the hardware ourselves: the computers, the sensors, the actuators–and all of the software that actually does the control. But it’s not just fly-by-wire. On top of it, we are implementing a simplified control scheme that reduces flying the airplane to just one action to perform one maneuver.</p><p>For readers who aren’t pilots: all flying is basically coordinating the aircraft pitch, roll, yaw, and throttle to coordinate actions. Something as simple as a level turn to the right means you have to 1) roll the airplane, 2) use your feet on the rudder pedals to keep the turn coordinated, 3) pull back to increase your lift since you are now losing lift in a bank, 4) monitor your airspeed (especially if at slow speeds when coming in to land), 5) monitor your altitude as you’re adjusting your lift in (3), 6) monitor your turn coordination as you adjust it in (2). You are now established in a turn. To return to flying straight and level do those in reverse. And while doing all this, you need to be navigating through complex airpaces and talking to air traffic control over 1940s radio technology. All this together makes it very hard to fly and very easy for a pilot (especially a new pilot) to lose control of the airplane, which is still the leading cause of fatalities in general aviation.</p><p>With Airhart Assist (that’s what we call our system), you just push a control stick to the right and the flight computers do all those steps to put you into a coordinated level turn.</p><p>So, how does this actually work?</p><p>The force-feedback joystick in the plane sends its position to a flight controller (actually 3 that work in parallel for safety and redundancy, more on that later). The flight controller interprets the position as a turn rate or climb rate command (for left/right or forward/back). The flight controller also reads a bunch of sensors (gyroscope, accelerometer, magnetometer, air pressure, GPS, etc) to develop an accurate estimate of the airplane’s state: roll, pitch, yaw, velocity, position, etc. Using the current state from the sensor fusion algorithms and the desired state from the joystick, the controller does a bunch of aerodynamics and control theory math to compute the control surface position necessary to bring the aircraft to the desired state. Mixed into this is error checking, envelope protection, and other various safety measures to make sure the aircraft never enters an unsafe state.</p><p>Unlike a traditional airplane, it becomes impossible to command the airplane into a stall, a spin, unsafe attitudes, or other bad states. This is the key to the safety of the system: it prevents the common mistakes that pilots make that lead to disastrous consequences.</p><p>To make sure that this system is always functioning, everything is single-fault tolerant. That means that there are no single points of failure. Any fault that might occur–a broken wire, a fried resistor, a bitflip in a processor, a random hang in a kernel–does not affect the functionality of the system. This is achieved by having three flight controllers that take in information from two different sets of sensors (we call them “strings”), independently compute the desired actions to take, and vote on what to do. Each string has its own power source, backup battery, networking hardware, and set of critical sensors.</p><p>The only real single point of failure is the engine. We only have one, though the engine itself has redundant ignition systems, fuel pumps, controllers, etc. If the engine were to die, the batteries would keep the system running for ~30 minutes, giving you time to make an emergency landing. If the pilot somehow becomes incapacitated, any passenger can initiate an autonomous emergency landing. And if many things go wrong and the system does fail, there’s a full airframe parachute that can be activated to bring the airplane safely to the ground.</p><p>A lot of people will likely wonder: “isn’t removing stick and rudder skills going to make worse pilots”? Short answer: no. The core of what makes a good pilot isn’t stick and rudder skills; it’s good decision making and risk management. For single pilots in GA, it’s even more important. So we are building a system that will give our pilots the tools to focus entirely on decision making and risk management and remove the distraction of stick and rudder that creates so many problems today. We think stick and rudder skills are definitely a necessity for airline pilots flying hundreds of people on board for the extremely rare cases where emergencies do happen and many people's lives are at risk, but not for an average person flying a four seat airplane to go on a weekend trip to the mountains. Our system makes it impossible to lose control of the airplane, potentially solving 80% of today’s fatal accidents in general aviation.</p><p>Fly-by-wire systems typically cost millions of dollars. We intend to build it for much less. How? By leveraging automotive grade components, clever sensor fusion math so that we can use MEMS gyroscopes that cost &lt;$100 instead of laser-ring gyros that cost $1000 if not $10k, and by a first principles approach to the design of our system. This requires that we build a lot of our own hardware. We’ve developed our own control surface actuators, our own display assemblies, we’re developing our own radios and GPS hardware (an aviation grade GPS can cost upwards of $10k, but it’s the same hardware as in a $20 consumer grade GPS).</p><p>To take advantage of this automotive style approach requires scale. Enter the final third of the problem: flying isn’t sexy. Modern airplanes look like they are from the 90s. With our first airplane, the Airhart Sling, we are redesigning the entire UI/UX of the flight deck to make it as easy as possible to use, redesigning the cabin to feel much more like a luxury car than an airplane today, and integrating Airhart Assist to make flying much more accessible and much more inviting. You can see previews of the Airhart Sling on our website, <a href="https://www.airhartaero.com/">https://www.airhartaero.com/</a>. The sexiness of design is extremely important for the economies of scale of an automotive-style approach to work.</p><p>There’s a plethora of other problems that make flying cumbersome: weight and balance worksheets, complicated route planning, talking to ATC, lengthy preflight checks, a fractured system of FBOs, difficult access to instruction, the list goes on. We are working on all of these too, but no amount of extra UI features can solve the fundamental problem that aviating itself is hard. So that’s what we’re solving first.</p><p>We want people who don’t think about airplanes as a mode of transportation to start flying and are hoping that Airhart will pave the way. Whether you fly planes today or not, I’d love to hear your thoughts. This is a very exciting topic with lots to discuss so I’m very much looking forward to the conversation!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new type of neural network is more interpretable (297 pts)]]></title>
            <link>https://spectrum.ieee.org/kan-neural-network</link>
            <guid>41162676</guid>
            <pubDate>Mon, 05 Aug 2024 16:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/kan-neural-network">https://spectrum.ieee.org/kan-neural-network</a>, See on <a href="https://news.ycombinator.com/item?id=41162676">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="A New Type of Neural Network Is More Interpretable"><p><a href="https://spectrum.ieee.org/what-is-deep-learning" target="_blank">Artificial neural networks</a>—algorithms inspired by biological brains—are at the center of modern <a href="https://spectrum.ieee.org/topic/artificial-intelligence/">artificial intelligence</a>, behind both chatbots and image generators. But with their many neurons, they can be <a href="https://www.nature.com/articles/d41586-024-01314-y" rel="noopener noreferrer" target="_blank">black boxes</a>, their inner workings uninterpretable to users. </p><p>Researchers have now created a fundamentally new way to make <a href="https://spectrum.ieee.org/tag/neural-networks">neural networks</a> that in some ways surpasses traditional systems. These new networks are more interpretable and also more accurate, proponents say, even when they’re smaller. Their developers say the way they learn to represent physics data concisely could help scientists uncover new laws of nature. </p><p>“It’s great to see that there is a new architecture on the table.” <strong></strong><strong>—Brice Ménard, Johns Hopkins University</strong><strong></strong></p><p>For the past decade or more, engineers have mostly tweaked neural-network designs through trial and error, says Brice Ménard, a physicist at Johns Hopkins University who studies how neural networks operate but was not involved in the new work, which <a href="https://arxiv.org/abs/2404.19756" rel="noopener noreferrer" target="_blank">was posted on arXiv</a> in April. “It’s great to see that there is a new architecture on the table,” he says, especially one designed from first principles.</p><p>One way to think of neural networks is by analogy with neurons, or nodes, and synapses, or connections between those nodes. In traditional neural networks, called multi-layer perceptrons (MLPs), each synapse learns a weight—a number that determines <em>how strong</em> the connection is between those two neurons. The neurons are arranged in layers, such that a neuron from one layer takes input signals from the neurons in the previous layer, weighted by the strength of their synaptic connection. Each neuron then applies a simple function to the sum total of its inputs, called an activation function.</p><p><img alt="black text on a white background with red and blue lines connecting on the left and black lines connecting on the right " data-rm-shortcode-id="16c6aa72c8d9515c82ff8f3ee8448e30" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-text-on-a-white-background-with-red-and-blue-lines-connecting-on-the-left-and-black-lines-connecting-on-the-right.png?id=53100120&amp;width=980" height="1128" id="e42c9" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-text-on-a-white-background-with-red-and-blue-lines-connecting-on-the-left-and-black-lines-connecting-on-the-right.png?id=53100120&amp;width=980" width="1768"><small placeholder="Add Photo Caption...">In traditional neural networks, sometimes called multi-layer perceptrons [left], each synapse learns a number called a weight, and each neuron applies a simple function to the sum of its inputs. In the new Kolmogorov-Arnold architecture [right], each synapse learns a function, and the neurons sum the outputs of those functions.</small><small placeholder="Add Photo Credit...">The NSF Institute for Artificial Intelligence and Fundamental Interactions</small></p><p>In the new architecture, the synapses play a more complex role. Instead of simply learning <em>how strong</em> the connection between two neurons is, they learn the <em>full nature</em> of that connection—the function that maps input to output. Unlike the activation function used by neurons in the traditional architecture, this function could be more complex—in fact a “spline” or combination of several functions—and is different in each instance. Neurons, on the other hand, become simpler—they just sum the outputs of all their preceding synapses. The new networks are called Kolmogorov-Arnold Networks (KANs), after two mathematicians who studied how functions could be combined. The idea is that KANs would provide greater flexibility when learning to represent data, while using fewer learned parameters. </p><p>“It’s like an alien life that looks at things from a different perspective but is also kind of understandable to humans.” <strong>—Ziming Liu, Massachusetts Institute of Technology</strong></p><p><span></span>The researchers tested their KANs on relatively simple scientific tasks. In some experiments, they took simple physical laws, such as the velocity with which two relativistic-speed objects pass each other. They used these equations to generate input-output data points, then, for each physics function, trained a network on some of the data and tested it on the rest. They found that increasing the size of KANs improves their performance at a faster rate than increasing the size of MLPs did. When solving partial differential equations, a KAN was 100 times as accurate as an MLP that had 100 times as many parameters.</p><p>In another experiment, they trained networks to predict one attribute of topological knots, called their signature, based on other attributes of the knots. An MLP achieved 78 percent test accuracy using about 300,000 parameters, while a KAN achieved 81.6 percent test accuracy using only about 200 parameters.</p><p>What’s more, the researchers could visually map out the KANs and look at the shapes of the activation functions, as well as the importance of each connection. Either manually or automatically they could prune weak connections and replace some activation functions with simpler ones, like sine or exponential functions. Then they could summarize the entire KAN in an intuitive one-line function (including all the component activation functions), in some cases perfectly reconstructing the physics function that created the dataset.</p><p>“In the future, we hope that it can be a <a href="https://spectrum.ieee.org/ai-for-science" target="_self">useful tool for everyday scientific research</a>,” says Ziming Liu, a computer scientist at the Massachusetts Institute of Technology and the paper’s first author. “Given a dataset we don’t know how to interpret, we just throw it to a KAN, and it can <a href="https://www.nature.com/articles/d41586-023-03596-0" target="_blank">generate some hypothesis</a> for you. You just stare at the brain [the KAN diagram] and you can even perform surgery on that if you want.” You might get a tidy function. “It’s like an alien life that looks at things from a different perspective but is also kind of understandable to humans.”</p><p>Dozens of papers have already cited the KAN preprint. “It seemed very exciting the moment that I saw it,” says Alexander Bodner, an undergraduate student of computer science at the University of San Andrés, in Argentina. Within a week, he and three classmates had combined KANs with convolutional neural networks, or CNNs, a popular architecture for processing images. They tested their <a href="https://arxiv.org/abs/2406.13155" target="_blank">Convolutional KANs</a> on their ability to categorize handwritten digits or pieces of clothing. The best one approximately matched the performance of a traditional CNN (99 percent accuracy for both networks on digits, 90 percent for both on clothing) but using about 60 percent fewer parameters. The datasets were simple, but Bodner says other teams with more computing power have begun scaling up the networks. Other people are combining KANs with transformers, an architecture popular in <a href="https://www.nature.com/articles/d41586-021-00530-0" target="_blank">large language models</a>.</p><p>One downside of KANs is that they take longer per parameter to train—in part because they can’t take advantage of <a href="https://spectrum.ieee.org/tag/gpus">GPUs</a>. But they need fewer parameters. Liu notes that even if KANs don’t replace giant CNNs and transformers for processing images and language, training time won’t be an issue at the smaller scale of many physics problems. He’s looking at ways for experts to insert their prior knowledge into KANs—by manually choosing activation functions, say—and to easily extract knowledge from them using a simple interface. Someday, he says, KANs could help physicists discover high-temperature <a href="https://spectrum.ieee.org/tag/superconductors">superconductors</a> or ways to control nuclear fusion.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Visual A* pathfinding and maze generation in Python (123 pts)]]></title>
            <link>https://github.com/Dicklesworthstone/visual_astar_python</link>
            <guid>41162505</guid>
            <pubDate>Mon, 05 Aug 2024 15:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dicklesworthstone/visual_astar_python">https://github.com/Dicklesworthstone/visual_astar_python</a>, See on <a href="https://news.ycombinator.com/item?id=41162505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Visual A* Pathfinding and Maze Generation in Python</h2><a id="user-content-visual-a-pathfinding-and-maze-generation-in-python" aria-label="Permalink: Visual A* Pathfinding and Maze Generation in Python" href="#visual-a-pathfinding-and-maze-generation-in-python"></a></p>
<p dir="auto">This project provides a high-performance implementation of the A* ("A-Star") pathfinding algorithm (based on <a href="https://gitlab.com/lockie/cl-astar" rel="nofollow">this</a> Lisp implementation by Andrew Kravchuck) along with various maze generation techniques to showcase how this algorithm works, as well as an advanced animated visualization of pathfinding in these mazes. The mazes are generated using many diverse approaches, each providing a different visual look and feel and also potential challenges for a pathfinding algorithm. The A* algorithm is designed to efficiently find the shortest path in these mazes, taking into consideration various heuristic functions and neighbor enumerators.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Optimized A* Pathfinding</strong>: Includes custom priority queue and efficient state handling for both integer and float coordinates.</li>
<li><strong>Diverse Maze Generation</strong>: Multiple algorithms for creating complex and varied mazes, including Diffusion-Limited Aggregation (DLA), Game of Life, One-Dimensional Automata, Langton's Ant, Voronoi Diagrams, Fractal Division, Wave Function Collapse, Growing Tree, Terrain-Based, Musicalized, Quantum-Inspired, Artistic, Cellular Automaton, Fourier-Based, and Reaction-Diffusion.</li>
<li><strong>Advanced Visualization</strong>: Detailed visual representation of maze generation and pathfinding, including animation of exploration and path discovery.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=iA6XJRE6CTM" rel="nofollow">
    <img src="https://camo.githubusercontent.com/34b5a01717671ea0f3ec49e4cb6100d9d78b1e37f0a232009407379a3c68afe1/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f694136584a52453643544d2f302e6a7067" alt="Demo of it in Action" data-canonical-src="https://img.youtube.com/vi/iA6XJRE6CTM/0.jpg">
  </a>
  <br>
  <em>Demo of it in Action (click thumbnail for YouTube video!)</em>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pathfinding Implementation</h2><a id="user-content-pathfinding-implementation" aria-label="Permalink: Pathfinding Implementation" href="#pathfinding-implementation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Design Philosophy and Performance</h3><a id="user-content-design-philosophy-and-performance" aria-label="Permalink: Design Philosophy and Performance" href="#design-philosophy-and-performance"></a></p>
<p dir="auto">The A* algorithm implementation focuses on efficiency and scalability. Key aspects include:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Custom Priority Queue</strong>: The priority queue is a fundamental component of the A* algorithm, used to manage the open set (frontier) of nodes to be explored. In this implementation, the priority queue is optimized for fast insertion and extraction of elements based on their priority values, which represent the estimated total cost (distance traveled + heuristic) to reach the goal. This allows the algorithm to quickly focus on the most promising nodes.</p>
</li>
<li>
<p dir="auto"><strong>Coordinate Encoding</strong>: The system supports both integer and float coordinates, which are encoded efficiently to optimize memory usage and computation. This encoding process involves converting floating-point coordinates into a unique integer representation, ensuring precise and quick decoding. The encoding scheme supports a wide range of values, accommodating both fine-grained precision and large-scale maps.</p>
</li>
<li>
<p dir="auto"><strong>Heuristic Functions</strong>: A variety of heuristic functions are available, including Manhattan, Octile, and Euclidean distance heuristics. Each heuristic offers a different way to estimate the cost to reach the goal from a given node, balancing accuracy with computational efficiency. The choice of heuristic can significantly affect the performance of the A* algorithm, with more accurate heuristics generally leading to faster pathfinding at the cost of additional computation.</p>
</li>
<li>
<p dir="auto"><strong>Neighbor Enumeration</strong>: The algorithm provides customizable neighbor enumerators that define how neighboring nodes are considered during the pathfinding process. Options include 4-directional, 8-directional, and more complex movement patterns. This flexibility allows the algorithm to handle various types of terrain and movement costs, such as diagonal movement being more expensive than orthogonal movement.</p>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Exact and Heuristic Cost Functions</h3><a id="user-content-exact-and-heuristic-cost-functions" aria-label="Permalink: Exact and Heuristic Cost Functions" href="#exact-and-heuristic-cost-functions"></a></p>
<ul dir="auto">
<li><strong>Exact Cost</strong>: This function calculates the actual cost of moving from one node to another. It can account for various factors, such as the distance between nodes and any penalties associated with certain types of terrain or movement. For instance, moving diagonally may have a higher cost than moving vertically or horizontally.</li>
<li><strong>Heuristic Cost</strong>: The heuristic cost is an estimate of the cost to reach the goal from a given node. It serves as a guide to the A* algorithm, helping it prioritize nodes that are likely closer to the goal. The accuracy and computational cost of the heuristic can vary; a more accurate heuristic may provide better guidance but require more computation.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maze Generation Methods</h3><a id="user-content-maze-generation-methods" aria-label="Permalink: Maze Generation Methods" href="#maze-generation-methods"></a></p>
<p dir="auto">This project includes a rich variety of maze generation algorithms, each creating unique patterns and challenges. Below is a detailed explanation of each method:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Diffusion-Limited Aggregation (DLA)</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: DLA is a process that simulates the random motion of particles in a medium until they stick to a surface or to each other, forming aggregates. In this algorithm, particles start from random positions and move randomly until they either stick to an existing structure or fall off the boundary of the defined space.</li>
<li><strong>Mechanism</strong>: The algorithm initializes with a few seed particles on the grid. New particles are introduced at random locations and follow a random walk. When a particle encounters an occupied cell (another particle), it sticks to it, thereby growing the aggregate structure. This process results in intricate, tree-like patterns, which can resemble natural formations like snowflakes or mineral deposits.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Game of Life</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Based on Conway's Game of Life, this method uses cellular automata rules to evolve a grid of cells, where each cell can be either alive or dead. The next state of each cell is determined by its current state and the number of alive neighbors it has.</li>
<li><strong>Mechanism</strong>: The grid is initialized with a random configuration of alive (1) and dead (0) cells. The state of each cell in the next generation is determined by counting its alive neighbors. Cells with exactly three alive neighbors become alive, while cells with fewer than two or more than three alive neighbors die. This evolution creates dynamic and unpredictable patterns, often resulting in maze-like structures with complex corridors and dead-ends.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>One-Dimensional Automata</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: This method involves the use of simple rules applied to a single row of cells (1D) which then evolves over time to form a 2D maze pattern. The rule set, often represented as a binary number, dictates the state of a cell based on the states of its neighbors.</li>
<li><strong>Mechanism</strong>: A row of cells is initialized randomly. Each cell's state in the next row is determined by its current state and the states of its immediate neighbors, according to a specific rule set (e.g., Rule 30, Rule 110). This process iteratively generates new rows, creating complex patterns that range from simple to highly chaotic, depending on the rule used.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Langton's Ant</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: A simple Turing machine that moves on a grid of black and white cells, with its movement rules determined by the color of the cell it encounters.</li>
<li><strong>Mechanism</strong>: The ant follows a set of rules: if it encounters a white cell, it turns right, flips the color of the cell to black, and moves forward; if it encounters a black cell, it turns left, flips the color to white, and moves forward. Despite the simplicity, the system exhibits complex behavior, leading to the formation of highways and chaotic regions. Over time, the ant's path can generate intricate and unpredictable patterns.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Voronoi Diagram</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: This method divides space into regions based on the distance to a set of seed points, where each region contains all points closer to one seed point than to any other.</li>
<li><strong>Mechanism</strong>: Random points are placed on the grid, and the Voronoi diagram is computed by determining the nearest seed point for each grid cell. The edges between different regions are treated as walls, resulting in a maze with polygonal cells. The boundaries between the cells are then refined to form passages, often creating a natural, organic feel to the maze structure.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Fractal Division</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: A recursive subdivision method that divides the grid into smaller regions by introducing walls along the division lines.</li>
<li><strong>Mechanism</strong>: The algorithm begins by splitting the grid with a wall either horizontally or vertically and then adds an opening in the wall. The process repeats recursively on the resulting subregions. This method, also known as the recursive division algorithm, can produce highly symmetrical and self-similar patterns, where the layout at smaller scales resembles the overall structure.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Wave Function Collapse</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Inspired by the concept of quantum mechanics, this method uses a constraint-based approach to determine the state of each cell based on its neighbors.</li>
<li><strong>Mechanism</strong>: The algorithm starts with an undecided grid where each cell can potentially take on multiple states. It then collapses each cell's possibilities based on constraints from neighboring cells, ensuring that the pattern remains consistent and non-contradictory. This method produces highly detailed and aesthetically pleasing mazes, where the structure is consistent with the predefined rules and patterns.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Growing Tree</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: A procedural method for creating mazes by expanding paths from a starting point, using a selection strategy to decide which frontier cell to grow from.</li>
<li><strong>Mechanism</strong>: The algorithm begins with a single cell and iteratively adds neighboring cells to the maze. The selection strategy can vary (e.g., random, last-in-first-out, first-in-first-out), affecting the overall structure. The growing tree method is flexible and can generate mazes with a variety of appearances, from long corridors to densely packed networks.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Terrain-Based</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: This approach uses Perlin noise to generate a terrain-like heightmap, which is then converted into a maze by thresholding.</li>
<li><strong>Mechanism</strong>: Perlin noise, a type of gradient noise, is used to create a smooth and continuous terrain heightmap. The grid is then divided into passable and impassable regions based on a threshold value. This method produces mazes that resemble natural landscapes with hills and valleys, offering a different challenge with natural-looking obstacles.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Musicalized</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Inspired by musical compositions, this method generates mazes by interpreting harmonic functions and waves.</li>
<li><strong>Mechanism</strong>: The algorithm generates a grid where the value at each cell is determined by the sum of multiple sine waves with different frequencies and amplitudes. The resulting wave patterns are then thresholded to create walls and paths, resembling rhythmic and wave-like structures. This method provides a unique aesthetic, mirroring the periodic nature of music.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Quantum-Inspired</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Mimics quantum interference patterns by superimposing wave functions, creating complex interference patterns.</li>
<li><strong>Mechanism</strong>: The algorithm uses a combination of wave functions to create a probability density field. By thresholding this field, the maze walls are determined. The resulting patterns are intricate and delicate, often resembling the complex interference patterns seen in quantum physics experiments. This method offers visually stunning mazes with a high degree of symmetry and complexity.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Artistic</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Utilizes artistic techniques such as brush strokes and splatter effects to create abstract maze patterns.</li>
<li><strong>Mechanism</strong>: The algorithm randomly places brush strokes and splatters on a canvas, with each stroke affecting multiple cells on the grid. The placement and orientation of strokes are randomized, creating unique and abstract patterns. This artistic approach results in mazes that mimic various art styles, offering a visually distinct experience.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Cellular Automaton</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Uses custom rules to evolve a grid of cells, with each cell's state influenced by its neighbors.</li>
<li><strong>Mechanism</strong>: The grid is initialized with random states. A set of rules determines the next state of each cell based on the states of its neighbors. This process is iterated multiple times, with the specific rules and number of iterations influencing the final pattern. The method can generate a wide range of structures, from highly ordered to chaotic, depending on the chosen ruleset.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Fourier-Based</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Applies the Fourier transform to a noise field, selectively filtering frequencies to create smooth patterns.</li>
<li><strong>Mechanism</strong>: The algorithm begins with a random noise field and transforms it into the frequency domain using the Fourier transform. Certain frequency components are then filtered out, and the inverse transform is applied to obtain the spatial domain pattern. The result is a maze with smooth, flowing structures, influenced by the selected frequencies and their combinations.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Reaction-Diffusion</strong>:</p>
<ul dir="auto">
<li><strong>Description</strong>: Simulates chemical reaction and diffusion processes to create organic and biomorphic patterns.</li>
<li><strong>Mechanism</strong>: The algorithm models the interaction between two chemical substances that spread out and react with each other. The concentration of these substances evolves over time according to reaction-diffusion equations. The resulting patterns are thresholded to form the maze structure. This method creates mazes with natural, fluid-like structures, similar to those seen in biological organisms and chemical reactions.</li>
</ul>
</li>
</ol>
<p dir="auto">Each method in this collection offers a distinct visual and structural style, making it possible to explore a wide range of maze characteristics and challenges. These mazes are suitable for testing various pathfinding algorithms and for generating visually compelling visualizations.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maze Validation and Adjustment Techniques</h3><a id="user-content-maze-validation-and-adjustment-techniques" aria-label="Permalink: Maze Validation and Adjustment Techniques" href="#maze-validation-and-adjustment-techniques"></a></p>
<p dir="auto">In maze generation, ensuring that the resulting structures are not only visually appealing but also functionally navigable is critical. Various techniques and methods are employed to validate the generated mazes and modify them if they don't meet specific criteria, such as solvability, complexity, or connectivity. This section details the philosophy, theory, and practical implementations behind these techniques, with a focus on ensuring high-quality maze structures.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Overview</h4><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">The approach to maze validation and adjustment involves a multi-step process:</p>
<ol dir="auto">
<li><strong>Validation</strong>: After generating a maze, we assess it against predefined criteria such as connectivity, solvability, and structural diversity.</li>
<li><strong>Modification</strong>: If the maze fails to meet these criteria, specific functions are employed to adjust the structure, such as adding or removing walls, creating pathways, or ensuring connectivity between regions.</li>
<li><strong>Final Verification</strong>: The modified maze is re-evaluated to confirm that it now meets all the desired criteria.</li>
</ol>
<p dir="auto">This process ensures that each maze not only provides a challenging and engaging environment but also maintains a balance between complexity and solvability.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Detailed Function Explanations</h4><a id="user-content-detailed-function-explanations" aria-label="Permalink: Detailed Function Explanations" href="#detailed-function-explanations"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>smart_hole_puncher</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To ensure that a generated maze has a path from the start to the goal by strategically removing walls.</li>
<li><strong>Mechanism</strong>: The function iteratively selects wall cells and removes them, prioritizing areas where the path might be blocked. It stops once a viable path is found, minimizing changes to the maze's overall structure. This method is particularly useful for complex mazes that may have isolated regions.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>ensure_connectivity</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To guarantee that all open regions in a maze are connected, preventing isolated areas.</li>
<li><strong>Mechanism</strong>: This function uses pathfinding algorithms to verify that a continuous path exists between important points (e.g., start and goal). If disconnected regions are found, the function identifies the shortest path between these regions and creates openings to link them, ensuring the maze is fully navigable.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>add_walls</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To increase the complexity of a maze by adding walls, which can create new challenges and alter the maze's navigability.</li>
<li><strong>Mechanism</strong>: Additional walls are placed in the maze in a controlled manner to achieve a target wall density. This function randomly selects open cells to convert into walls, balancing between adding challenge and maintaining solvability.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>remove_walls</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To simplify a maze by removing walls, making it less dense and more navigable.</li>
<li><strong>Mechanism</strong>: The function selects walls for removal based on the need to decrease wall density to a target percentage. It ensures that the removals do not oversimplify the maze, maintaining a level of challenge and complexity.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>add_room_separators</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To divide large open spaces into smaller, distinct areas, thereby adding structure and complexity.</li>
<li><strong>Mechanism</strong>: The function introduces separators or walls within large open areas of the maze. These separators create distinct rooms or sections, which can then be connected or further modified. This technique prevents overly large open areas that can make the maze less challenging.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>break_up_large_room</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To prevent excessively large open spaces that could simplify navigation and reduce the challenge.</li>
<li><strong>Mechanism</strong>: The function identifies large rooms in the maze and introduces additional walls to break them into smaller sections. This process involves a careful analysis of the room sizes and a controlled introduction of walls to maintain the balance between openness and complexity.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>break_up_large_areas</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: Similar to breaking up large rooms, this function targets large contiguous open areas in the maze, ensuring they are partitioned for increased complexity.</li>
<li><strong>Mechanism</strong>: The function identifies large connected areas and introduces walls to create smaller, manageable sections. This helps in preventing navigational ease due to large uninterrupted spaces and ensures a more challenging experience.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>create_simple_maze</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To generate a basic structure or fill in small areas within a larger maze.</li>
<li><strong>Mechanism</strong>: This function uses simple algorithms, such as recursive division or random path generation, to create a basic maze structure. It is often used in conjunction with other techniques to fill specific areas or as a foundation that can be modified further.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>connect_areas</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To ensure that all regions of a maze are accessible and interconnected.</li>
<li><strong>Mechanism</strong>: The function uses a combination of pathfinding and wall removal to connect distinct regions or areas within a maze. This ensures that no area is isolated, facilitating complete navigation from any starting point.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>connect_disconnected_areas</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: Specifically focuses on connecting areas that are entirely isolated from the rest of the maze.</li>
<li><strong>Mechanism</strong>: This function identifies completely disconnected regions and creates paths to integrate them into the main maze. It uses algorithms like breadth-first search (BFS) to find the shortest paths for connection, ensuring efficiency and minimal structural change.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>bresenham_line</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To draw straight lines on a grid, typically used for creating direct connections or walls.</li>
<li><strong>Mechanism</strong>: The Bresenham's line algorithm is employed to draw straight lines between two points on a grid, ensuring the line is as continuous and close to a true line as possible. This is useful for creating corridors or walls that follow a straight path.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>validate_and_adjust_maze</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To perform a comprehensive check of the maze's structural integrity and navigability, followed by necessary adjustments.</li>
<li><strong>Mechanism</strong>: This function validates the maze against criteria such as solvability, wall density, and connectivity. Based on the assessment, it applies various adjustments (like wall addition/removal, area connection) to ensure the maze meets all necessary conditions. It serves as the final quality check before the maze is considered complete.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>generate_and_validate_maze</strong></p>
<ul dir="auto">
<li><strong>Purpose</strong>: To generate a maze using one of the specified algorithms and ensure it meets all criteria for quality and functionality.</li>
<li><strong>Mechanism</strong>: This function integrates the entire process of maze generation, validation, and adjustment. It starts with generating a maze, runs validation checks, and applies modifications as needed. If the maze does not meet the criteria, the function can regenerate or further adjust it until all requirements are satisfied.</li>
</ul>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Visualization</h2><a id="user-content-visualization" aria-label="Permalink: Visualization" href="#visualization"></a></p>
<p dir="auto">The visualization component in this project is designed to provide a comprehensive and interactive display of both the maze generation process and the pathfinding algorithms at work. This component uses the <code>matplotlib</code> library to create detailed visual representations that highlight the complexities and intricacies of maze structures and pathfinding strategies. Key elements of the visualization include:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maze Structure</h3><a id="user-content-maze-structure" aria-label="Permalink: Maze Structure" href="#maze-structure"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Walls and Floors</strong>: The visualization distinctly represents walls and floors using a two-color scheme. Walls are typically rendered in a dark color (e.g., deep blue or gray), while floors are displayed in a contrasting light color (e.g., white or light gray). This clear differentiation helps users easily identify passable and impassable areas within the maze.</p>
</li>
<li>
<p dir="auto"><strong>Color Mapping</strong>: The code allows for the customization of wall and floor colors. This is particularly useful for creating visual themes or adjusting the visualization for different viewing conditions (e.g., color blindness). The <code>LinearSegmentedColormap</code> from <code>matplotlib</code> can be used to define custom gradients for different maze elements.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pathfinding Progress</h3><a id="user-content-pathfinding-progress" aria-label="Permalink: Pathfinding Progress" href="#pathfinding-progress"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Exploration Order</strong>: During the pathfinding process, the visualization dynamically displays the exploration order of the algorithm. This is achieved by coloring explored cells using a gradient that represents the progression of exploration. Lighter shades indicate earlier exploration, while darker shades denote later exploration stages. The use of an exploration colormap helps visualize the pathfinding algorithm's exploration strategy and efficiency.</p>
</li>
<li>
<p dir="auto"><strong>Path Discovery</strong>: As the algorithm discovers the path from the start to the goal, the visualization highlights the path using a distinct color (e.g., blue or green). The path is typically represented as a continuous line, indicating the sequence of cells that constitute the solution. The visualization updates in real-time, allowing viewers to see how the path evolves as the algorithm progresses.</p>
</li>
<li>
<p dir="auto"><strong>Markers for Start and Goal Points</strong>: The start and goal points are clearly marked with distinct symbols (e.g., circles or stars) and colors (e.g., green for the start, red for the goal). These markers remain visible throughout the visualization, providing consistent reference points for the viewer.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Customizable Colors</h3><a id="user-content-customizable-colors" aria-label="Permalink: Customizable Colors" href="#customizable-colors"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Customization Options</strong>: The visualization component offers extensive customization options for colors, allowing users to adjust the appearance of walls, floors, paths, exploration stages, and start/goal markers. This customization is facilitated through parameters passed to the visualization functions, enabling users to tailor the display to their preferences or specific use cases.</p>
</li>
<li>
<p dir="auto"><strong>Colormap Selection</strong>: For the exploration and path colors, users can select from predefined colormaps or create custom ones using <code>LinearSegmentedColormap</code>. This flexibility ensures that the visualization can be adapted to various aesthetic preferences or accessibility needs.</p>
</li>
<li>
<p dir="auto"><strong>Transparency and Layering</strong>: The visualization supports transparency and layering effects, particularly for the exploration map. By adjusting the alpha value, users can overlay the exploration progress on top of the maze structure without obscuring the underlying details. This feature is useful for simultaneously visualizing the explored area and the structural layout of the maze.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Animation and Export</h3><a id="user-content-animation-and-export" aria-label="Permalink: Animation and Export" href="#animation-and-export"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Frame Generation</strong>: The visualization is animated by generating frames that capture the state of the maze and pathfinding process at each time step. The code uses concurrent processing to efficiently generate these frames, leveraging multiple CPU cores for faster rendering. Each frame is created by plotting the maze, exploration progress, and current path status.</p>
</li>
<li>
<p dir="auto"><strong>Animation Playback</strong>: The frames can be compiled into an animation using <code>FuncAnimation</code> from <code>matplotlib.animation</code>. The playback speed can be adjusted by setting the frames per second (FPS), allowing for slower or faster visualization of the pathfinding process. The animation provides a smooth and continuous representation of the algorithm's operation, from initial exploration to final pathfinding.</p>
</li>
<li>
<p dir="auto"><strong>Output Formats</strong>: The frames can be saved individually as images or compiled into a video. Each frame is saved as an individual image in the specified <code>frame_format</code> (e.g., PNG, JPG). This option is useful for creating high-quality image sequences or for detailed post-processing of individual frames. Alternatively, if <code>save_as_frames_only</code> is set to <code>False</code>, the frames are compiled into an animation in formats such as MP4. For MP4 exports, the <code>FFMpegWriter</code> is used, allowing for fine-tuned control over encoding parameters, such as bitrate and codec settings. This ensures high-quality video output suitable for presentations or further analysis.</p>
</li>
<li>
<p dir="auto"><strong>Resource Management</strong>: To manage disk space and avoid clutter, the code includes functionality to delete small or temporary files after the animation or frame sequence is saved. This helps maintain a clean working directory and ensures that only the most relevant files are retained. This feature is particularly useful when saving individual frames, as it can help prevent the accumulation of numerous image files.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Assembling Frames into an MP4 File Using FFmpeg</h3><a id="user-content-assembling-frames-into-an-mp4-file-using-ffmpeg" aria-label="Permalink: Assembling Frames into an MP4 File Using FFmpeg" href="#assembling-frames-into-an-mp4-file-using-ffmpeg"></a></p>
<p dir="auto">If you have saved the frames as individual image files and wish to manually assemble them into an MP4 video, you can use FFmpeg. You can download it from the <a href="https://ffmpeg.org/download.html" rel="nofollow">official FFmpeg website</a> or install it via a package manager. Alternatively, you can download a pre-compiled binary from the most recent version <a href="https://johnvansickle.com/ffmpeg/" rel="nofollow">here</a> (recommended; note that if you do this, you'll have to copy the binary to <code>/usr/bin/</code> and do <code>chmod +x ffmpeg</code> to make it executable. To check which version of FFmpeg you're actually using, try <code>which ffmpeg</code>). Additionally, you may need the <code>bc</code> command for calculations, which can be installed using:</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Command Example</h4><a id="user-content-command-example" aria-label="Permalink: Command Example" href="#command-example"></a></p>
<p dir="auto">Assuming your frames are named sequentially (e.g., <code>frame_0001.png</code>, <code>frame_0002.png</code>, etc.) and stored in the current directory, you can use the following command to generate a 30-second video file using x265:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd /home/ubuntu/visual_astar_python/maze_animations/animation_20240805_114757/ # Change to the directory containing the frames-- this is just an example
ffmpeg -framerate $(echo &quot;($(find . -maxdepth 1 -type f -name 'frame_*.png' | wc -l) + 30 - 1) / 30&quot; | bc) -i frame_%05d.png -vf &quot;pad=ceil(iw/2)*2:ceil(ih/2)*2,scale=3840:2160&quot; -c:v libx265 -preset slow -crf 28 -pix_fmt yuv420p -x265-params &quot;pools=16:bframes=8:ref=4:no-open-gop=1:me=star:rd=4:aq-mode=3:aq-strength=1.0&quot; -movflags +faststart output.mp4"><pre><span>cd</span> /home/ubuntu/visual_astar_python/maze_animations/animation_20240805_114757/ <span><span>#</span> Change to the directory containing the frames-- this is just an example</span>
ffmpeg -framerate <span><span>$(</span>echo <span><span>"</span>(<span><span>$(</span>find <span>.</span> -maxdepth 1 -type f -name <span><span>'</span>frame_*.png<span>'</span></span> <span>|</span> wc -l<span>)</span></span> + 30 - 1) / 30<span>"</span></span> <span>|</span> bc<span>)</span></span> -i frame_%05d.png -vf <span><span>"</span>pad=ceil(iw/2)*2:ceil(ih/2)*2,scale=3840:2160<span>"</span></span> -c:v libx265 -preset slow -crf 28 -pix_fmt yuv420p -x265-params <span><span>"</span>pools=16:bframes=8:ref=4:no-open-gop=1:me=star:rd=4:aq-mode=3:aq-strength=1.0<span>"</span></span> -movflags +faststart output.mp4</pre></div>
<p dir="auto">For encoding using x264, use:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ffmpeg -framerate $(echo &quot;($(find . -maxdepth 1 -type f -name 'frame_*.png' | wc -l) + 30 - 1) / 30&quot; | bc) -i frame_%05d.png -vf &quot;pad=ceil(iw/2)*2:ceil(ih/2)*2&quot; -c:v libx264 -crf 18 -pix_fmt yuv420p -threads 16 -movflags +faststart output_x264.mp4"><pre>ffmpeg -framerate <span><span>$(</span>echo <span><span>"</span>(<span><span>$(</span>find <span>.</span> -maxdepth 1 -type f -name <span><span>'</span>frame_*.png<span>'</span></span> <span>|</span> wc -l<span>)</span></span> + 30 - 1) / 30<span>"</span></span> <span>|</span> bc<span>)</span></span> -i frame_%05d.png -vf <span><span>"</span>pad=ceil(iw/2)*2:ceil(ih/2)*2<span>"</span></span> -c:v libx264 -crf 18 -pix_fmt yuv420p -threads 16 -movflags +faststart output_x264.mp4</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Explanation of Options</h4><a id="user-content-explanation-of-options" aria-label="Permalink: Explanation of Options" href="#explanation-of-options"></a></p>
<ul dir="auto">
<li><strong><code>-framerate $(...)</code></strong>: Calculates the frame rate based on the number of images and desired video duration (30 seconds in this example). This ensures that the video plays for the correct duration regardless of the number of frames.</li>
<li><strong><code>-i frame_%05d.png</code></strong>: Specifies the input file pattern. <code>%05d</code> indicates that the input files are sequentially numbered with four digits (e.g., <code>frame_00001.png</code>, <code>frame_00002.png</code>).</li>
<li><strong><code>-vf "pad=ceil(iw/2)*2:ceil(ih/2)*2,scale=3840:2160"</code></strong>: The <code>pad</code> filter ensures the video dimensions are even, which is required for many codecs. The <code>scale</code> filter resizes the video to 4K resolution (3840x2160). These filters ensure the output video has compatible dimensions and resolution.</li>
<li><strong><code>-c:v libx265</code></strong>: Specifies the use of the x265 codec for encoding, which provides efficient compression. The x264 variant uses <code>-c:v libx264</code> for compatibility and high-quality output.</li>
<li><strong><code>-preset slow</code></strong>: Sets the encoding preset, balancing compression efficiency and encoding time. <code>slow</code> is a good compromise for higher compression at a slower speed.</li>
<li><strong><code>-crf 28</code></strong> (for x265) and <strong><code>-crf 18</code></strong> (for x264): Controls the Constant Rate Factor, affecting the quality and file size. Lower values yield higher quality at the cost of larger file sizes. <code>crf 28</code> is suitable for x265, while <code>crf 18</code> provides nearly lossless quality for x264.</li>
<li><strong><code>-pix_fmt yuv420p</code></strong>: Sets the pixel format to YUV 4:2:0, ensuring compatibility with most media players and devices.</li>
<li><strong><code>-x265-params "pools=16:bframes=8:ref=4:no-open-gop=1:me=star:rd=4:aq-mode=3:aq-strength=1.0"</code></strong>: Specifies advanced x265 settings to fine-tune the encoding process. These parameters set the number of threads (<code>pools</code>), number of B-frames, reference frames, and other encoding settings for optimal quality and compression.</li>
<li><strong><code>-threads 16</code></strong> (for x264): Limits the number of threads used for encoding to 16, balancing performance and resource usage.</li>
<li><strong><code>-movflags +faststart</code></strong>: Enables the <code>faststart</code> option, which moves the metadata to the beginning of the file, allowing the video to start playing before it is fully downloaded. This is useful for streaming scenarios.</li>
</ul>
<p dir="auto">These commands and explanations should help you efficiently create high-quality MP4 videos from a sequence of frames using FFmpeg.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Initial Setup</h3><a id="user-content-initial-setup" aria-label="Permalink: Initial Setup" href="#initial-setup"></a></p>
<p dir="auto">Clone the repo and set up a virtual environment with the required packages using (tested on Python 3.12 and Ubuntu 22):</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Dicklesworthstone/visual_astar_python.git
cd visual_astar_python
python -m venv venv
source venv/bin/activate
python -m pip install --upgrade pip
python -m pip install wheel
python -m pip install --upgrade setuptools wheel
pip install -r requirements.txt"><pre>git clone https://github.com/Dicklesworthstone/visual_astar_python.git
<span>cd</span> visual_astar_python
python -m venv venv
<span>source</span> venv/bin/activate
python -m pip install --upgrade pip
python -m pip install wheel
python -m pip install --upgrade setuptools wheel
pip install -r requirements.txt</pre></div>
<p dir="auto">The code is tested with Python 3.12. If you want to use that version without messing with your system Python version, then on Ubuntu you can install and use PyEnv like so:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if ! command -v pyenv &amp;> /dev/null; then
    sudo apt-get update
    sudo apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev \
    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \
    xz-utils tk-dev libffi-dev liblzma-dev python3-openssl git

    git clone https://github.com/pyenv/pyenv.git ~/.pyenv
    echo 'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;' >> ~/.zshrc
    echo 'export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;' >> ~/.zshrc
    echo 'eval &quot;$(pyenv init --path)&quot;' >> ~/.zshrc
    source ~/.zshrc
fi
cd ~/.pyenv &amp;&amp; git pull &amp;&amp; cd -
pyenv install 3.12
cd visual_astar_python
pyenv local 3.12
python -m venv venv
source venv/bin/activate
python -m pip install --upgrade pip
python -m pip install wheel
python -m pip install --upgrade setuptools wheel
pip install -r requirements.txt
"><pre><span>if</span> <span>!</span> <span>command</span> -v pyenv <span>&amp;</span><span>&gt;</span> /dev/null<span>;</span> <span>then</span>
    sudo apt-get update
    sudo apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev \
    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \
    xz-utils tk-dev libffi-dev liblzma-dev python3-openssl git

    git clone https://github.com/pyenv/pyenv.git <span>~</span>/.pyenv
    <span>echo</span> <span><span>'</span>export PYENV_ROOT="$HOME/.pyenv"<span>'</span></span> <span>&gt;&gt;</span> <span>~</span>/.zshrc
    <span>echo</span> <span><span>'</span>export PATH="$PYENV_ROOT/bin:$PATH"<span>'</span></span> <span>&gt;&gt;</span> <span>~</span>/.zshrc
    <span>echo</span> <span><span>'</span>eval "$(pyenv init --path)"<span>'</span></span> <span>&gt;&gt;</span> <span>~</span>/.zshrc
    <span>source</span> <span>~</span>/.zshrc
<span>fi</span>
<span>cd</span> <span>~</span>/.pyenv <span>&amp;&amp;</span> git pull <span>&amp;&amp;</span> <span>cd</span> -
pyenv install 3.12
<span>cd</span> visual_astar_python
pyenv <span>local</span> 3.12
python -m venv venv
<span>source</span> venv/bin/activate
python -m pip install --upgrade pip
python -m pip install wheel
python -m pip install --upgrade setuptools wheel
pip install -r requirements.txt
</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Generating and Visualizing Mazes</h3><a id="user-content-generating-and-visualizing-mazes" aria-label="Permalink: Generating and Visualizing Mazes" href="#generating-and-visualizing-mazes"></a></p>
<p dir="auto">To generate and visualize a maze, run the main script with the desired parameters:</p>

<p dir="auto">You can see what it looks like running here:</p>
<p dir="auto"><a href="https://asciinema.org/a/BwnzShGe1Py5QZJ2IXru7xGMv" rel="nofollow"><img src="https://camo.githubusercontent.com/74e6e38ae7e914970dc01355b258c90203ec686a1d782dc46bb41bafc68d3711/68747470733a2f2f61736369696e656d612e6f72672f612f42776e7a5368476531507935515a4a32495872753778474d762e737667" alt="asciicast" data-canonical-src="https://asciinema.org/a/BwnzShGe1Py5QZJ2IXru7xGMv.svg"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Customization</h3><a id="user-content-customization" aria-label="Permalink: Customization" href="#customization"></a></p>
<ul dir="auto">
<li><strong>Maze Generation Approach</strong>: Specify the desired maze generation approach (e.g., <code>dla</code>, <code>wave_function_collapse</code>) to customize the type of maze generated.</li>
<li><strong>Grid Size</strong>: Set the <code>GRID_SIZE</code> parameter to adjust the size of the maze.</li>
<li><strong>Visualization Settings</strong>: Modify color schemes and animation settings to suit your preferences.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Parameter Configuration</h2><a id="user-content-parameter-configuration" aria-label="Permalink: Parameter Configuration" href="#parameter-configuration"></a></p>
<p dir="auto">This project includes several parameters that users can configure to customize the output of maze generation and pathfinding visualization. Key parameters include:</p>
<ul dir="auto">
<li><strong>num_animations</strong>: The number of separate animations to generate, each featuring different mazes and pathfinding scenarios.</li>
<li><strong>GRID_SIZE</strong>: The size of the maze grid, determining the number of cells along one dimension. Higher values create more detailed and complex mazes.</li>
<li><strong>num_problems</strong>: The number of mazes to display side by side in each animation, allowing for comparison of different generation methods or pathfinding strategies.</li>
<li><strong>DPI</strong>: The dots per inch for the animation, affecting image resolution and quality. Higher DPI values yield sharper images.</li>
<li><strong>FPS</strong>: Frames per second for animation playback. Higher values create smoother animations but may require more resources.</li>
<li><strong>save_as_frames_only</strong>: A boolean parameter indicating whether to save each frame as an individual image. Set <code>True</code> to save frames, <code>False</code> to compile them into a video.</li>
<li><strong>frame_format</strong>: The format for saving frames when <code>save_as_frames_only</code> is <code>True</code>. Common formats include 'png' and 'jpg'.</li>
<li><strong>dark_mode</strong>: Enables a dark theme for visualizations.</li>
<li><strong>override_maze_approach</strong>: Forces the use of a specific maze generation approach for consistency across all animations.</li>
</ul>
<p dir="auto">These parameters provide users with extensive control over the behavior and appearance of the generated mazes and visualizations, allowing for fine-tuning according to specific requirements or preferences.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A* Algorithm: Theoretical Overview and Advanced Implementation</h2><a id="user-content-a-algorithm-theoretical-overview-and-advanced-implementation" aria-label="Permalink: A* Algorithm: Theoretical Overview and Advanced Implementation" href="#a-algorithm-theoretical-overview-and-advanced-implementation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Big Ideas Behind A*</h3><a id="user-content-the-big-ideas-behind-a" aria-label="Permalink: The Big Ideas Behind A*" href="#the-big-ideas-behind-a"></a></p>
<p dir="auto">The A* algorithm is a sophisticated method for finding the shortest path in various environments, whether it's navigating a complex maze or plotting a course through a dynamically changing landscape. Unlike simpler algorithms, A* intelligently evaluates paths by considering both the journey already taken and the estimated distance to the goal. This dual approach makes A* not only a pathfinder but a path optimizer, ensuring the selected path is the most efficient.</p>
<p dir="auto">Imagine you're in a vast maze; A* doesn't just explore paths blindly. It uses a strategic approach akin to a seasoned traveler who checks their progress and considers the remaining distance to the destination at every decision point. This ability to foresee and plan makes A* particularly adept at avoiding dead ends and minimizing travel time.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Key Components of A*</h3><a id="user-content-key-components-of-a" aria-label="Permalink: Key Components of A*" href="#key-components-of-a"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>The Journey So Far (g-cost)</strong>: This aspect involves calculating the exact cost from the start point to the current position. It's like keeping track of the miles traveled during a road trip. By accumulating these costs, A* can compare different paths to the same point, ensuring it chooses the most efficient one.</p>
</li>
<li>
<p dir="auto"><strong>The Journey Ahead (h-cost)</strong>: Known as the heuristic estimate, this component predicts the cost from the current position to the goal. It's a calculated guess based on the nature of the environment. For example, in a grid, this might be the Euclidean distance (straight-line distance), which provides a quick and reasonably accurate estimate of the remaining journey.</p>
</li>
</ol>
<p dir="auto">The sum of these two values (g-cost + h-cost) forms the <strong>f-cost</strong>, which A* uses to prioritize paths. This combination ensures that A* not only seeks to minimize the total travel cost but also maintains a focus on progressing towards the goal.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why A* Excels Compared to Other Algorithms</h3><a id="user-content-why-a-excels-compared-to-other-algorithms" aria-label="Permalink: Why A* Excels Compared to Other Algorithms" href="#why-a-excels-compared-to-other-algorithms"></a></p>
<p dir="auto">A* stands out for its efficiency and effectiveness, particularly in comparison to simpler algorithms:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Depth-First Search (DFS)</strong> explores as deep as possible along one branch before backtracking. While it may find a path, it often does so inefficiently, sometimes missing the shortest path entirely due to its lack of goal-awareness and tendency to get trapped in deep branches.</p>
</li>
<li>
<p dir="auto"><strong>Breadth-First Search (BFS)</strong> methodically explores all nodes at the present depth before moving on to the next. While BFS guarantees finding the shortest path in an unweighted graph, it is computationally expensive and memory-intensive, especially in large graphs, as it explores all nodes without any consideration of the goal's location.</p>
</li>
<li>
<p dir="auto"><strong>Dijkstra's Algorithm</strong> is a precursor to A* that calculates the shortest path by considering the total cost from the start node to each node. However, it does not incorporate a heuristic, treating all paths equally regardless of their direction relative to the goal. This can lead to unnecessary exploration and inefficiencies, particularly in large graphs with varied edge costs.</p>
</li>
</ul>
<p dir="auto">A* merges the strengths of Dijkstra's thorough cost analysis with an informed heuristic approach, directing its search towards the goal and avoiding unnecessary paths. This combination allows it to find the shortest path efficiently, making it suitable for a wide range of practical applications.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Applications and Advantages</h3><a id="user-content-applications-and-advantages" aria-label="Permalink: Applications and Advantages" href="#applications-and-advantages"></a></p>
<p dir="auto">A* is widely used in various domains due to its reliability and efficiency:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Video Games</strong>: A* is the backbone of many AI pathfinding systems, guiding characters through complex virtual worlds with precision. Its ability to navigate around obstacles and efficiently reach objectives makes it ideal for real-time strategy games and role-playing games.</p>
</li>
<li>
<p dir="auto"><strong>Robotics</strong>: In robotics, A* helps autonomous robots navigate through environments, such as factory floors or outdoor terrains. The algorithm enables robots to avoid obstacles, plan efficient routes, and respond to dynamic changes in their surroundings.</p>
</li>
<li>
<p dir="auto"><strong>Navigation Systems</strong>: A* is used in GPS navigation systems to find the quickest route between two points, considering factors like road distances and traffic conditions.</p>
</li>
<li>
<p dir="auto"><strong>AI and Machine Learning</strong>: A* is used in AI for problem-solving, such as solving puzzles or planning tasks. Its ability to incorporate different heuristics allows it to be adapted to various types of problems.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advanced Implementation Features</h3><a id="user-content-advanced-implementation-features" aria-label="Permalink: Advanced Implementation Features" href="#advanced-implementation-features"></a></p>
<p dir="auto">This project's implementation of A* goes beyond standard features, incorporating advanced techniques to enhance performance and versatility. Most of the credit for these goes to Andrew Kravchuck, who wrote the Lisp implementation this is based on:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Smart Organization</strong>: The algorithm uses a priority queue to manage paths, ensuring that the most promising paths are explored first. This efficient data structure reduces the time spent evaluating less optimal paths.</p>
</li>
<li>
<p dir="auto"><strong>Precision Handling</strong>: The implementation supports both integer and floating-point coordinates, making it adaptable to different scenarios, from simple grid maps to detailed real-world environments.</p>
</li>
<li>
<p dir="auto"><strong>Adaptive Heuristics</strong>: It allows for various heuristic functions, such as Manhattan, Euclidean, or Octile distances, which can be tailored to the specifics of the problem space, optimizing the search process.</p>
</li>
<li>
<p dir="auto"><strong>Complex Terrain Navigation</strong>: The implementation can handle diverse movements, including diagonal and custom paths, enhancing its capability to navigate through varied terrains.</p>
</li>
<li>
<p dir="auto"><strong>Efficient Path Reconstruction</strong>: Upon reaching the goal, the implementation efficiently reconstructs the path, ensuring minimal computational overhead in finalizing the route.</p>
</li>
<li>
<p dir="auto"><strong>Robust Error Handling</strong>: The algorithm gracefully manages exceptional situations, such as encountering impassable regions or unsolvable configurations, providing clear feedback to users.</p>
</li>
<li>
<p dir="auto"><strong>Optimized Data Structures</strong>: The use of bit fields for coordinate encoding enhances memory efficiency and processing speed, crucial for handling large-scale environments or high-resolution grids.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dependencies</h2><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<ul dir="auto">
<li>Python 3.x</li>
<li>NumPy</li>
<li>Matplotlib</li>
<li>SciPy</li>
<li>Scikit-Image</li>
<li>Noise</li>
<li>Pillow</li>
<li>TQDM</li>
<li>Numba (for JIT compilation)</li>
<li>FFmpeg (for video encoding)</li>
<li>Requests (for downloading custom fonts)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License. See the <code>LICENSE</code> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Andy Warhol's lost Amiga art found (474 pts)]]></title>
            <link>https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/</link>
            <guid>41162311</guid>
            <pubDate>Mon, 05 Aug 2024 15:33:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/">https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/</a>, See on <a href="https://news.ycombinator.com/item?id=41162311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After 39 years, Andy Warhol’s lost Amiga art has been found. And it’s for sale. Details of the reemergence help to shed light on an earlier discovery from about a decade ago. And those details come from the very person who taught Andy Warhol how to use a computer. In this blog post, I’ll put these discoveries in context, and offer some thoughts from both an art teacher and a sales engineer.</p><h2>The lost Andy Warhol image of Debbie Harry</h2><figure id="attachment_35575" aria-describedby="caption-attachment-35575"><a href="https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/andy-warhol-debbie-harry-amiga-art/" rel="attachment wp-att-35575"><img fetchpriority="high" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-debbie-harry-amiga-art.jpg?resize=294%2C300&amp;ssl=1" alt="Debbie Harry by Andy Warhol, Amiga art from 1985" width="294" height="300" srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-debbie-harry-amiga-art.jpg?resize=294%2C300&amp;ssl=1 294w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-debbie-harry-amiga-art.jpg?resize=55%2C55&amp;ssl=1 55w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-debbie-harry-amiga-art.jpg?w=490&amp;ssl=1 490w" sizes="(max-width: 294px) 100vw, 294px" data-recalc-dims="1"></a><figcaption id="caption-attachment-35575">The original digital copy of this famous Andy Warhol-created image of Debbie Harry resurfaced in July 2024.</figcaption></figure><p>Commodore famously commissioned Andy Warhol to demonstrate the artistic capabilities of its new <a href="https://dfarq.homeip.net/amiga-1000-ten-years-ahead-of-its-time/">Amiga 1000 computer</a> in 1985. As part of his demonstration, Warhol created some digital art images, including a self-portrait of himself sitting in front of the computer, which in turn was displaying the self portrait. Another image he created was a famous portrait of Debbie Harry, the photogenic lead singer of the New Wave band Blondie.</p><p>In recounting the event, Debbie Harry said in her autobiography that she had a copy of the images from the event, and as far as she knew, only one other person had a copy. She did not identify the other person.</p><h3>The unnamed other person</h3><p>In July 2024, former Commodore engineer <a href="https://www.artnews.com/art-news/news/andy-warhol-lost-portrait-blondie-debbie-harry-resurfaces-1234713192/">Jeff Bruette came forward and said he owns a print of the image Andy Warhol created</a> at the event, and a signed floppy disk containing eight images that Andy Warhol created that day. He said he’s had them on display in his home for about 39 years.</p><p>Some of the accounts of the Warhol art resurfacing describe Bruette as a technician, and although that was essentially the role he was serving at the event, he was much more than a technician. He was a long time Commodore employee, and he programmed two popular early Commodore 64 games that Commodore distributed commercially, Gorf and Wizard of Wor. Bruette also acted as the product manager of the graphics software Warhol used.</p><p>He was more than a technician to Andy Warhol as well. He was the one who taught Andy Warhol how to use an Amiga. For that matter, he probably taught Andy Warhol almost everything he knew about computers in general, not just Amigas.</p><h2>Andy Warhol’s demonstration Amiga art</h2><p>The digital images Andy Warhol created are rudimentary by today’s standards, and in some ways, perhaps less ambitious then some of the thumbnails I create for my blog posts. But this was 39 years ago, and I have much better tools than he did. The maximum resolution he had to work with was 640 pixels in one direction and 400 pixels the other direction. And while he had 4,096 colors to choose from, he could only use 32 of them at a time. He had a digital camera available to him, but it wasn’t a digital camera in any modern sense. It was really best suited to taking monochromatic images.</p><p>To a casual viewer, they look like low resolution images with a very limited number of colors, and it’s not completely unfair to say they bear some resemblance to something my kids would have created in Microsoft Paint when they were little.</p><h3>An art teacher’s impression</h3><p>But when I showed the images to my wife, a former high school art teacher, the first thing she noticed was his choice of colors. He deliberately chose colors that contrasted with each other, and the other colors he used were colors you would get from mixing two or more of the other colors he used. Rule number one of painting, she said, is to never use black or brown, but make your own from the other colors you’re using. Warhol’s images contain odd shades that result from mixing other colors in the image together.</p><p>When you look at Andy Warhol paintings, his style suited these specific tools. He often worked from photographs, creating stark images containing bold flood fills with only a few colors. Sometimes he would cut up photographs, or have someone else cut up the photographs, then he would arrange the pieces and then paint what he saw.</p><p>With the Amiga, he could do all of this digitally. So the choice of Andy Warhol to demonstrate how to use the machine was a brilliant idea. This computer with advanced graphics capabilities for its time, and the ability to multitask and switch between different tools so he could cut up and resize images and then paste the result into the image he was working on couldn’t have suited him any better if he’d designed it himself.</p><p>Problem was, he didn’t know how to use a computer.</p><h3>Andy Warhol’s body language</h3><figure id="attachment_35581" aria-describedby="caption-attachment-35581"><a href="https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/andy-warhol-self-portrait-amiga-art-2/" rel="attachment wp-att-35581"><img decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-self-portrait-amiga-art-2.jpg?resize=195%2C300&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-self-portrait-amiga-art-2.jpg?resize=195%2C300&amp;ssl=1" alt="Andy Warhol self portrait with Amiga computer" width="195" height="300" data-srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-self-portrait-amiga-art-2.jpg?resize=195%2C300&amp;ssl=1 195w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/andy-warhol-self-portrait-amiga-art-2.jpg?w=416&amp;ssl=1 416w" data-sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1"></a><figcaption id="caption-attachment-35581">Note how Warhol is holding the mouse in this self portrait, keeping his fingers clear of the mouse buttons.</figcaption></figure><p>In all of the photographs I have seen of Andy Warhol with an Amiga, I noticed something. He is never, ever holding the mouse the way I would hold it. He has a death grip on the sides with his thumb on one side and his index and pinky finger on the other. And then he has his pointer and middle fingers curled up, as far away from the two mouse buttons and he can possibly get them while still being able to maintain the death grip on the mouse body. It betrays a fear of accidentally clicking either of the mouse buttons and another fear of accidentally dropping the mouse, or perhaps even accidentally moving the mouse.</p><h3>Warhol’s lament</h3><p>I read somewhere that Andy Warhol didn’t think he was very good at demonstrating how to use the computer, and he wished he could get good at it, because it seemed like a really good way to make money. I asked Jeff Bruette about that, and he said that was consistent with his experience with Warhol. “He saw the things that [AmigaWorld magazine’s art director] was able to create and how I could fluidly click the tools, colors, and menus to create things. He was completely inexperienced with computers and struggled with the process,” Bruette said.</p><p>“In fact, we would go through things together in the morning. After breaking for lunch he’d need a refresher on the difference between the right and left mouse buttons. True story,” he added.</p><p>For those unfamiliar with the Amiga, the left mouse button works like the left mouse button in Windows and other operating systems. The right mouse button activated the pull-down menus at the top of the screen. Conceptually, it was similar to context menus in today’s operating systems.</p><h3>A modern sales engineer’s critique</h3><p>Warhol’s results in creating his computer art were inconsistent. The famous image of Debbie Harry was not the result of the live demonstration. It came from a rehearsal earlier in the day. When he tried to recreate the image live with an audience, the result didn’t look like an Andy Warhol painting. Bruette shared the image in a private group, so I don’t feel like I am at liberty to share it, but I’ll share the story.</p><p>The lighting conditions were different during the event than they had been at rehearsal, so the photo he started with had different contrast. The flood fill to the right of Debbie Harry went fine. When he filled her hair, it was fine on the right side of the image, but not so good on the left. And exactly zero of his other flood fills did what he intended. Without the level of undo that modern paint programs have, he didn’t have an easy way to correct even that first mistake. His efforts to correct it just ended up blowing out her face. Instead of looking like an Andy Warhol painting of Debbie Harry, it looked like what you’d get if you told an impressionist to paint a woman with long hair.</p><p>In my day job, one of my responsibilities happens to be giving product demos. I’ve experienced demos where one mistake compounds the next. You learn to roll with it, but it takes practice.</p><p>When Commodore released the video of the event, they spliced in the image from the rehearsal session.</p><h3>What about flood fills?</h3><p>I’ve heard several stories from other Commodore engineers about how the flood fill function in the software they were using would crash the machine. I’m pretty sure those stories have even ended up in books about Commodore. Bruette said the flood fills were working in the versions of the software Warhol had, and that’s pretty clear even from the images in Warhol’s estate.</p><p>To create Warhol-style digital art, you need to be able to capture an image from a camera, resize it, copy and paste it, select your colors, and do flood fills on it. In a pinch you can get by without resizing and copying and pasting, but not having flood fills would be a showstopper.</p><h2>How the earlier discovery relates</h2><figure id="attachment_35582" aria-describedby="caption-attachment-35582"><a href="https://dfarq.homeip.net/andy-warhols-lost-amiga-art-found/warhol-self-portrait-1985/" rel="attachment wp-att-35582"><img decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/warhol-self-portrait-1985.jpg?resize=300%2C225&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/warhol-self-portrait-1985.jpg?resize=300%2C225&amp;ssl=1" alt="A self portrait from Warhol's own collection" width="300" height="225" data-srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/warhol-self-portrait-1985.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/08/warhol-self-portrait-1985.jpg?w=534&amp;ssl=1 534w" data-sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a><figcaption id="caption-attachment-35582">In this portion of an image recovered from Warhol’s estate in 2014, you can see how he was messing around with copying and pasting images and flood fills, two techniques he widely used in his other art.</figcaption></figure><p>In 2014, a series of images was recovered from disks found in Andy Warhol’s estate. His personal effects included two pre-production Amiga computers and a collection of disks containing not just the files he created, but also the software he used to create those images, including a previously undiscovered early version of the operating system. In <a href="https://dfarq.homeip.net/the-warhol-amiga-discovery-in-context/">a blog post I wrote at the time</a>, I speculated that the images were the result of him trying to learn how to use the computer.</p><p>Looking at the images again, I think they were more than that. He was experimenting with techniques. One of the images appears to be a photograph of himself where he clicked around with the fill function. But when you look at the image more closely, you can see where he had three different images of himself of differing sizes, and he superimposed the three, then he started messing around with fills.</p><h3>Insights into how (and what) Warhol learned</h3><p>I can almost see and hear Jeff Bruette explaining the capabilities of the computer to Andy Warhol, and then him walking through what Bruette had just described, trying to create in his own style using what he had just learned.</p><p>That’s because I had to do something similar. The discomfort level in the photographs of Andy Warhol with the computer remind me of something. I was in the odd position of teaching my own teachers about computers from the time I was a teenager into my mid 20s. Many of them had the same level of discomfort with the mouse. I would fire up Solitaire and have them play that to get used to clicking and dragging. Bruette didn’t have that luxury when tutoring Warhol.</p><h2>The lost opportunity</h2><p>I always wished Commodore had <a href="https://dfarq.homeip.net/the-trade-off-of-fidelity-and-convenience-in-marketing-and-how-it-doomed-my-favorite-company/">pursued the Andy Warhol connection further</a>. Now I understand why it didn’t happen. I don’t think Commodore marketing recognized the opportunity, but I also don’t think Andy Warhol was comfortable with it. It wasn’t the same as sitting William Shatner down in front of a VIC-20 with a simulated screen on the TV and showing him how to position his hands so it looked like he was typing and showing him where the cameras were so he could make sure he was looking at the camera while he was smiling. He was trying to do it right, he struggled to do it live, and he gave up.</p><p>He was trying to be a modern day sales engineer, but without the benefit of the professional training that I received. I also had at least five years of professional experience with the product I was demonstrating before gaining the title of sales engineer. I also sometimes had to give product demos at another company, a company whose software was not as far along, and where I had about the same level of experience and as Andy Warhol did, and let’s just say that didn’t go as well.</p><h3>A possible workaround</h3><p>But they had options. They could have done a Shatner-like maneuver in print advertising, having Warhol mime in front of the computer, with a copy of the image on screen but the mouse unplugged, just to make it look like he was producing it live. And then they could have added some text about how this new computer is the first one ever that works the way Andy Warhol does.</p><p>At any rate, I think it’s fantastic that the images Andy Warhol created on that day survive, we now know where the copy is, and the person who preserved them for 39 years will have a chance to get them into the hands of someone who will enjoy them, and use the proceeds to fund his retirement. That sounds like a win all around to me, and it closes the loop on some details of Andy Warhol’s involvement with the Amiga computer.</p><div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p>David Farquhar is a computer security professional, entrepreneur, and author. He started his career as a part-time computer technician in 1994, worked his way up to system administrator by 1997, and has specialized in vulnerability management since 2013. He invests in real estate on the side and his hobbies include O gauge trains, baseball cards, and retro computers and video games. A University of Missouri graduate, he holds CISSP and Security+ certifications. He lives in St. Louis with his family.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebGL visual programming editor cables.gl is now open source (213 pts)]]></title>
            <link>https://cables.gl/standalone</link>
            <guid>41162036</guid>
            <pubDate>Mon, 05 Aug 2024 15:05:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cables.gl/standalone">https://cables.gl/standalone</a>, See on <a href="https://news.ycombinator.com/item?id=41162036">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content"><canvas id="glcanvasmouse"></canvas><section><div><div><p><span>You can now <span>create</span> next generation interaction, motion and 3D online or <span>offline</span>!</span></p></div><div><p>Whether you're a seasoned developer or a creative with little to no coding experience.<br>Create interaction, motion and 3D content with our new open-source, offline version that puts the full power of cables in your hands.</p></div></div><div><div><h2>Open source: peek under the hood</h2><ul><li><b>Licence</b>: MIT licence gives you all the freedom for your work</li><li><b>Transparency</b>: inspect the code, understand the tool, help us improve</li><li><b>Make it yours</b>: customise cables to fit your specific needs</li><li><b>Join the dev community</b>: contribute to cables development</li><li><b>Smooth workflow</b>: integrate easily with your local development setup</li></ul><p><a href="https://cables.gl/docs/6_1_developing_cables/1_setup_dev_env/setup_dev_env">Start developing cables!</a></p></div><div><h2>Standalone: unplug and create</h2><ul><li><b>Work anywhere</b>: even offline - no internet required. </li><li><b>Local asset freedom</b>: use files and assets without restrictions, ensuring privacy</li><li><b>Code your way</b>: use your preferred code editor for development</li><li><b>Fixed version</b>: work with one version for reliability</li><li><b>Security unchained</b>: wave goodbye to browser security headaches</li><li><b>Develop with npm</b>: use npm packages for native functionality</li></ul></div></div><div><br><h2>create</h2><ul><li>Easy to use node based interface</li><li>Real time adjustments allow for rapid prototyping of interaction, motion, 3D, generative and digital environments</li><li>Import and work with many different file formats: image, video, 3d, fonts, audio, json</li></ul></div><div><br><h2>contribute</h2><ul><li>Clone existing or write your own operators</li><li>Embed patches into your website</li><li>Build stunning visual experiences</li><li>Share, explore and learn with the cables community</li></ul></div><div><p><h2>support</h2></p></div></section></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the music industry learned to love piracy (138 pts)]]></title>
            <link>https://www.nytimes.com/2024/07/31/magazine/how-music-got-free-documentary.html</link>
            <guid>41161968</guid>
            <pubDate>Mon, 05 Aug 2024 14:57:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/07/31/magazine/how-music-got-free-documentary.html">https://www.nytimes.com/2024/07/31/magazine/how-music-got-free-documentary.html</a>, See on <a href="https://news.ycombinator.com/item?id=41161968">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/07/31/magazine/how-music-got-free-documentary.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A 20-something dethroned dotcom CEO that went to work the counter at McDonald's (2000) (116 pts)]]></title>
            <link>https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/</link>
            <guid>41161947</guid>
            <pubDate>Mon, 05 Aug 2024 14:55:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/">https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/</a>, See on <a href="https://news.ycombinator.com/item?id=41161947">Hacker News</a></p>
<div id="readability-page-1" class="page">

<br>
<a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/">heiferman.com</a> / <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/">my photo of the day</a><p><span size="5" color="#000000">i was a 20-something dethroned dotcom ceo that
went to work the counter at&nbsp; mcdonald's</span></p>
<p><span color="#000000">by scott heiferman (12/00)</span></p>

<p><span color="#000000"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/fry_guy4.jpg" width="360" height="272"></span></p>

<p><span color="#000000"><span size="5">background:</span>5/94: graduated from the university of iowa<br>
5/94-4/95: <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/sonycard.htm">"interactive marketing frontiersman"
at sony</a><br>
4/95-10/99: founder/ceo <a href="https://web.archive.org/web/20040616091238/http://www.i-traffic.com/">i-traffic</a>
(acquired by agency.com 10/99)<br>
10/99-10/01: chairman, i-traffic (an agency.com company)<br>
10/00-10/00:&nbsp; counterperson, mcdonald's (4th &amp; broadway, nyc)<br>
<a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/scott">more about me</a></span></p>

<p><span color="#000000"><span size="5">why i got a job at mcdonald's:</span> </span></p>
<p><span color="#000000">i spend a lot of time with <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/seth6million.htm">bankers</a>, <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/europeanstyling.htm">lawyers</a>,
<a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/saul.htm">
internet freaks</a>, <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/bubba-drain.htm"> corporate wonks</a>, and other people living
strange lives.&nbsp; as a good marketing guy, that's a bad thing.&nbsp; and as a
practicing anti-consumerist, that's a bad thing.&nbsp; i got a job at mcdonald's
to help get back in touch with the real world.&nbsp; also, after over 6 grueling
years in the internet whirlwind, i wanted to experience a profitable,
well-oiled, multi-billion-dollar machine. and&nbsp; i deserved a break today. </span></p>

<p><span size="5" color="#000000">how i got the job:</span></p>
<p><span color="#000000"><a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/app.jpg"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/app_small.jpg" alt="app.jpg (40139 bytes)" width="250" height="156"></a><p>

i walked in, filled out an application, and was interviewed.&nbsp; i was
truthful.&nbsp; in my interview, the manager (ralph) asked if i can handle a
fast-paced, intense environment.&nbsp; i said yes.&nbsp; he looked at my resume and asked about my current part-time job as chairman at i-traffic.&nbsp; i said,
"it's an internet thing."&nbsp; he said "ok" and then asked
me for my waist size.</p></span></p>

<p><span size="5" color="#000000">a few observations:</span></p>
<p><span color="#000000">1. people like the "dollar menu".&nbsp; the
dollar menu consists of about a dozen items at mcdonald's that sell for a
dollar.&nbsp; not 99 cents, but one dollar.&nbsp; most of these items had had
existed elsewhere on the menu for about a dollar. mcdonald's has done a good job
of keeping their menu relatively simple and short, but people clearly respond to
the ultra-simplicity of the dollar menu.&nbsp; most people weren't primarily
ordering from the dollar menu because they were overwhelmed by the wider menu,
but because they perceived it to be the best value.&nbsp; someone call <a href="https://web.archive.org/web/20040616091238/http://abcnews.go.com/onair/ABCNEWSspecials/JohnStossel.html"> john
stossel</a>... but the dollar menu isn't always the best value. </span>interestingly,
"dollar stores" preceded mcdonald's "dollar menu" ---&nbsp; <span color="#000000">it's
fun to see "blue chip" kellogg-trained marketers from&nbsp;
mcdonald's borrow strategy from sleaze-level marketers.&nbsp; </span></p>
<p><span color="#000000">2. $5.75 ain't much. $5.75/hour X 40 hours/week X 52
weeks/year = $11,960.&nbsp; that's before taxes are taken out.&nbsp; some people said
it was disrespectful for me to take a job at mcdonalds --- i didn't need the
money, and they thought
that i was making fun of people that work there.&nbsp; the opposite is true:&nbsp; i gained a bucket of respect for people
that bust their butt for such low pay.&nbsp; it's one thing to scan past stats
about americans that make $12,000 per year -- or read about them in <a href="https://web.archive.org/web/20040616091238/http://www.nytimes.com/2000/12/12/nyregion/12SHEE.html">the
paper</a>.&nbsp; but, to actually work a tough fry-heaving, mcnugget-wielding
6-hour shift --- and get home smelling like those fries and mcnuggets -- and
realize that you only made about $30 that day... that's a serious
eye-opener.&nbsp; interpret as you see fit.</span></p>
<p><span color="#000000">3.&nbsp; i was never told to treat customers
well.&nbsp; correction:&nbsp; i was never told by management to treat customers
well.&nbsp;&nbsp; before i started the job, i had read on the mcdonald's website
that "<a href="https://web.archive.org/web/20040616091238/http://www.mcdonalds.com/countries/usa/careers/regional/expect/index.html">our
crewmembers make each customer feel like a welcomed guest</a>."&nbsp; i had
even noticed a few months before that mcdonald's even went so far as to change
their <a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/smilogos">logo &amp; tagline to feature
the message "we love to see you smile."</a>  i expected to be
specifically, officially instructed to smile and make customers feel like a
welcomed guest.&nbsp; well, as any patron of a manhattan mcdonald's knows, there
ain't much feel-good from the counter staff.&nbsp; my co-workers were downright
rude to customers.&nbsp; i got funny looks from my co-workers when i was
friendly with customers.&nbsp; they must not have seen the logo or tagline or
website.</span></p>
<p><span color="#000000">4.&nbsp; nobody thanked me.&nbsp; i worked hard.&nbsp;
i got paid peanuts.&nbsp; i even ate mcdonald's food during my break (deducted
from my pay).&nbsp; it was intense:&nbsp; the cash register was complex, people
want their food NOW, the lines get deep, the mcflurry must be made just
right.&nbsp; i was trying hard and i was doing an ok job.&nbsp; now, i've been
the leader/manager for most of my life.&nbsp; i've had plenty of crap jobs, but
i've been the boss for the past few years.&nbsp; i faithfully read my fast
company magazine and my harvard business review.&nbsp; i've been taught
countless times the value of a leader/manager showing appreciation for people's
effort.&nbsp; however, my instinct has often been that showing appreciation
really isn't too necessary for good people.&nbsp; they just take pride in a job
well done --- and, anyway, they can read my mind and see the appreciation.&nbsp;
well, from day 1 at mcdonald's, i was yearning for someone there to say
"thanks".&nbsp; even a "you're doing ok" would
suffice.&nbsp; but, no.&nbsp; neither management experience -- nor reading about
management --- teaches this lesson as well as being an under-appreciated
employee.</span></p>
<p><span color="#000000">5. most of my mcdonald's co-workers did their jobs much
better than i ever could.&nbsp; they just seemed quicker.&nbsp; they had various
talents and intuition that i don't have.&nbsp;&nbsp;&nbsp;</span></p>
<p><span color="#000000">6.&nbsp; the fry basket burns skin.&nbsp;&nbsp;<br>
<img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/DSCF0003.JPG" width="247" height="189"><br>
</span>i got burned.</p>

<p><span size="5">other&nbsp;</span></p>
<p><a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/fry_guy7.jpg"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/fry_guy7_small1.jpg" alt="fry_guy7.jpg (131659 bytes)" width="250" height="187"></a>&nbsp;&nbsp;&nbsp;
<a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/fry_guy2.jpg"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/fry_guy2_small1.jpg" alt="fry_guy2.jpg (123668 bytes)" width="250" height="187"></a></p>

<p><a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/check.jpg"><span color="#000000"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/check_small.jpg" alt="check.jpg (41341 bytes)" width="250" height="203"><br>
</span></a><span color="#000000">i got paid.</span></p>



<p><a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/mcd/crains2.jpg"><span color="#000000"><img src="https://web.archive.org/web/20040616091238im_/http://www.heiferman.com/mcd/crains2_small.jpg" width="250" height="344"><br>
</span></a><span color="#000000">crain's called me a couple days before i started at mcdonalds.&nbsp; they were doing a
story on post-acquisition internet ceo's in new york.&nbsp; i told
them that i was starting a job at mcdonald's and didn't say much else.&nbsp; i let them take my picture
after i got off work one day.&nbsp;they put a strange spin on the piece.&nbsp;
most annoying were the people who thought that this was a publicity stunt.</span></p>

<br>


<p><span size="4"><a href="https://web.archive.org/web/20040616091238/http://www.heiferman.com/">heiferman.com photo of the day</a></span></p><span size="4">









</span></div>]]></description>
        </item>
    </channel>
</rss>