<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 15 Aug 2023 19:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[We reduced the cost of building Mastodon at Twitter-scale by 100x (193 pts)]]></title>
            <link>https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/</link>
            <guid>37137110</guid>
            <pubDate>Tue, 15 Aug 2023 17:54:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/">https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/</a>, See on <a href="https://news.ycombinator.com/item?id=37137110">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1075">
	<!-- .entry-header -->

	<div>
		




<div><p>I’m going to cover a lot of ground in this post, so here’s the TLDR:</p>
<ul>
<li>We built a Twitter-scale <a href="https://joinmastodon.org/">Mastodon</a> instance from scratch in only 10k lines of code. This is <strong>100x less code</strong> than the ~1M lines Twitter wrote to build and scale their original consumer product, which is very similar to Mastodon. Our instance is located at <a href="https://mastodon.redplanetlabs.com/" rel="nofollow">https://mastodon.redplanetlabs.com</a> and open for anyone to use. The instance has 100M bots posting 3,500 times per second at 403 average fanout to demonstrate its scale.</li>
<li>Our implementation is built on top of a new platform called Rama that we at <a href="https://redplanetlabs.com/">Red Planet Labs</a> have developed over the past 10 years. This is the first time we’re talking about Rama publicly. Rama unifies computation and storage into a coherent model capable of building end-to-end backends at any scale in 100x less code than otherwise. Rama integrates and generalizes data ingestion, processing, indexing, and querying. Rama is a generic platform for building application backends, not just for social networks, and is programmed with a pure Java API. I will be exploring Rama in this post through the example of our Mastodon implementation.</li>
<li>We spent nine person-months building our scalable Mastodon instance. Twitter spent ~200 person-years to build and scale their original consumer product, and <a href="https://www.washingtonpost.com/technology/2023/07/29/meta-threads-mark-zuckerberg-rival-twitter-musk/">Instagram spent ~25 person-years building Threads</a>, a recently launched Twitter competitor. In their effort Instagram was able to leverage infrastructure already powering similar products.</li>
<li>Our scalable Mastodon implementation is also significantly less code than Mastodon’s <a href="https://github.com/mastodon/mastodon">official implementation</a>, which cannot scale anywhere near Twitter-scale.</li>
<li>In one week we will release a version of Rama that anyone can download and use. This version simulates Rama clusters within a single process and can be used to explore the full Rama API and build complete prototypes. We will also release the Rama documentation at that time.</li>
<li>In two weeks we will fully open-source our Mastodon implementation.</li>
<li>Red Planet Labs will be starting a private beta soon to give companies access to the full version of Rama. We will release more details on the private beta later, but companies can <a href="https://docs.google.com/forms/d/e/1FAIpQLSfrhmBwI0YAeaL8u4XmgfscW4UIUUDp2ZHSs4KmPH_TaDt1QQ/viewform">apply here</a> in the meantime.</li>
</ul>
<p>We recognize the way we’re introducing Rama is unusual. We felt that since the 100x cost reduction claim sounds so unbelievable, it wouldn’t do Rama justice to introduce it in the abstract. So we took it upon ourselves to directly demonstrate Rama’s 100x cost reduction by replicating a full application at scale in all its detail.</p>
</div>



<h2>Table of contents</h2>
<div><ul>
<li><a href="#Our_Mastodon_instance">Our Mastodon instance</a></li>
<li><a href="#Performance_and_scalability">Performance and scalability</a></li>
<li><a href="#Rama">Rama</a></li>
<li><a href="#Mastodon_on_Rama">Mastodon on Rama</a>
<ul>
<li><a href="#Following_hashtags">Following hashtags</a></li>
<li><a href="#Social_graph">Social graph</a></li>
<li><a href="#Computing_and_rendering_home_timelines">Computing and rendering home timelines</a></li>
<li><a href="#Personalized_follow_suggestions">Personalized follow suggestions</a></li>
</ul>
</li>
<li><a href="#DevOps_with_Rama">DevOps with Rama</a></li>
<li><a href="#Simple_Rama_code_example">Simple Rama code example</a></li>
<li><a href="#Sample_code_from_our_Mastodon_implementation">Sample code from our Mastodon implementation</a>
<ul>
<li><a href="#Representing_data">Representing data</a></li>
<li><a href="#Following_hashtags_code">Following hashtags code</a></li>
<li><a href="#Social_graph_code">Social graph code</a></li>
<li><a href="#Timeline_fanout_code">Timeline fanout code</a></li>
</ul>
</li>
<li><a href="#Conclusion">Conclusion</a></li>
</ul>
</div>



<h2 id="Our_Mastodon_instance">Our Mastodon instance</h2>



<div><p>First off, we make no comment about whether Mastodon should be scalable. There are good reasons to limit the size of an individual Mastodon instance. It is our belief, however, that such decisions should be product decisions and not forced by technical limitations. What we are demonstrating with our scalable Mastodon instance is that building a complex application at scale doesn’t have to be a costly endeavor and can instead be easily built and managed by individuals or small teams. There’s no reason the tooling you use to most quickly build your prototype should be different from what you use to build your application at scale.</p>
<p>Our Mastodon instance is hosted at <a href="https://mastodon.redplanetlabs.com/">https://mastodon.redplanetlabs.com</a>. We’ve implemented every feature of Mastodon from scratch, including:</p>
<ul>
<li>Home timelines, account timelines, local timeline, federated timeline</li>
<li>Follow / unfollow</li>
<li>Post / delete statuses</li>
<li>Lists</li>
<li>Boosts / favorites / bookmarks</li>
<li>Personalized follow suggestions</li>
<li>Hashtag timelines</li>
<li>Featured hashtags</li>
<li>Notifications</li>
<li>Blocking / muting</li>
<li>Conversations / direct messages</li>
<li>Filters</li>
<li>View followers / following in order (paginated)</li>
<li>Polls</li>
<li>Trending hashtags and links</li>
<li>Search (status / people / hashtags)</li>
<li>Profiles</li>
<li>Image/video attachments</li>
<li>Scheduled statuses</li>
<li>ActivityPub API to integrate with other Mastodon instances</li>
</ul>
<p>There’s huge variety between these features, and they require very different kinds of implementations for how computations are done and how indexes are structured. Of course, every single aspect of our Mastodon implementation is scalable.</p>
<p>To demonstrate the scale of our instance, we’re also running 100M bot accounts which continuously post statuses (Mastodon’s analogue of a “tweet”), replies, boosts (“retweet”), and favorites. 3,500 statuses are posted per second, the average number of followers for each post is 403, and the largest account has over 22M followers. As a comparison, Twitter serves 7,000 tweets per second at 700 average fanout (according to the numbers I could find). With the click of a button we can scale our instance up to handle that load or much larger –&nbsp;it would just cost us more money in server costs. We used the OpenAI API to generate 50,000 statuses for the bots to choose from at random.</p>
<p>Since our instance is just meant to demonstrate Rama and costs money to run, we’re not planning to keep it running for that long. So we don’t recommend using this instance for a primary Mastodon account.</p>
<p>One feature of Mastodon that needed tweaking because of our high rate of new statuses was global timelines, as it doesn’t make sense to flood the UI with thousands of new statuses per second. So for that feature we instead <a href="https://mastodon.redplanetlabs.com/timeline/local">show a small sample</a> of all the statuses on the platform.</p>
<p>The implementation of our instance looks like this:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" width="634" height="285" data-attachment-id="1080" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/overall-structure/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?fit=634%2C285&amp;ssl=1" data-orig-size="634,285" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="overall-structure" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?fit=634%2C285&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?resize=634%2C285&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?w=634&amp;ssl=1 634w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?resize=300%2C135&amp;ssl=1 300w" sizes="(max-width: 634px) 100vw, 634px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?w=634&amp;ssl=1 634w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?resize=300%2C135&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/overall-structure.png?resize=634%2C285&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>The Mastodon backend is implemented as Rama modules (explained later on this page), which handles all the data processing, data indexing, and most of the product logic. On top of that is our implementation of the <a href="https://docs.joinmastodon.org/api/">Mastodon API</a> using Spring/Reactor. For the most part, the API implementation just handles HTTP requests with simple calls to the Rama modules and serves responses as JSON. We use <a href="https://soapbox.pub/">Soapbox</a> to serve the frontend since it’s built entirely on top of the Mastodon API.</p>
<p><a href="https://aws.amazon.com/s3/">S3</a> is used only for serving pictures and videos. Though we could serve those from Rama, static content like that is better served via a <a href="https://en.wikipedia.org/wiki/Content_delivery_network">CDN</a>. So we chose to use S3 to mimic that sort of architecture. All other storage is handled by the Rama modules.</p>
<p>Our implementation totals 10k lines of code, about half of which is the Rama modules and half of which is the API server. We will be fully open-sourcing the implementation in two weeks.</p>
<p>Our implementation is a big reduction in code compared to the <a href="https://github.com/mastodon/mastodon">official Mastodon implementation</a>, which is built with Ruby on Rails. That codebase doesn’t always have a clear distinction between frontend and backend code, but just adding up the code for clearcut backend portions (models, workers, services, API controllers, ActivityPub) totals 18k lines of Ruby code. That doesn’t include any of the database schema definition code, configurations needed to run Postgres and Redis, or other controller code, so the true line count for the official Mastodon backend is higher than that. And unlike our Rama implementation, it can’t achieve anywhere near Twitter-scale.</p>
<p>This isn’t a criticism of the Mastodon codebase –&nbsp;building products with existing technologies is just plain expensive. The reason we’ve worked on Rama for so many years is to enable developers to build applications much faster, with much greater quality, and to never have to worry about scaling ever again.</p>
</div>



<h2 id="Performance_and_scalability">Performance and scalability</h2>



<p>Here’s a chart showing the scalability of the most intensive part of Mastodon, processing statuses:</p>



<figure><img data-lazy-fallback="1" decoding="async" width="656" height="407" data-attachment-id="1306" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/mastodon-perf-1-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?fit=1934%2C1202&amp;ssl=1" data-orig-size="1934,1202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mastodon-perf-1-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?fit=300%2C186&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?fit=656%2C407&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=656%2C407&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1024%2C636&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=300%2C186&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=768%2C477&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1536%2C955&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1200%2C746&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?w=1934&amp;ssl=1 1934w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1024%2C636&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=300%2C186&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=768%2C477&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1536%2C955&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=1200%2C746&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?w=1934&amp;ssl=1 1934w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-1-2.png?resize=656%2C407&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>As you can see, increasing the number of nodes increases the statuses/second that can be processed. Most importantly, the relationship is linear. Processing statuses is so intensive because of fanout&nbsp;–&nbsp;if you have 15M followers, each of your statuses has to be written to 15M timelines. Each status on our instance is written to an average of 403 timelines (plus additional work to handle replies, lists, and conversations).</p>
<p>Twitter operates at 7,000 tweets per second at 700 average fanout, which is equivalent to about 12,200 tweets / second at 403 average fanout. So you can see we tested our Mastodon instance well above Twitter-scale.</p>
<p>Here’s a chart showing the latency distribution for the time from a status being posted to it being available on follower timelines:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="411" data-attachment-id="1084" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/mastodon-perf-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?fit=1672%2C1046&amp;ssl=1" data-orig-size="1672,1046" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mastodon-perf-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?fit=656%2C411&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=656%2C411&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1024%2C641&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1536%2C961&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1200%2C751&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?w=1672&amp;ssl=1 1672w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1024%2C641&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1536%2C961&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=1200%2C751&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?w=1672&amp;ssl=1 1672w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-2.png?resize=656%2C411&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>These numbers are a bit better than <a href="https://youtu.be/WEgCjwyXvwc?t=255">Twitter’s numbers</a>. Because of how unbalanced the social graph is, getting performance this good and this reliable is <a href="https://twitter.com/elonmusk/status/1624660886572126209">not easy</a>. For example, when someone with 20M followers posts a status, that creates a huge burst of load which could delay other statuses from fanning out. How we handled this is described more below.</p>
<p>Lastly, here’s a chart showing the latency distribution for fetching the data to render a user’s home timeline:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="410" data-attachment-id="1085" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/mastodon-perf-3/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?fit=1674%2C1046&amp;ssl=1" data-orig-size="1674,1046" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mastodon-perf-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?fit=300%2C187&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?fit=656%2C410&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=656%2C410&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1024%2C640&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=300%2C187&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1536%2C960&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1200%2C750&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?w=1674&amp;ssl=1 1674w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1024%2C640&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=300%2C187&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1536%2C960&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=1200%2C750&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?w=1674&amp;ssl=1 1674w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/mastodon-perf-3.png?resize=656%2C410&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Rendering a home timeline requires a lot of data from the backend: a page of statuses to render that aren’t muted/filtered, stats on each status (number of replies, boosts, and favorites), as well as information on the accounts that posted each status (username, display name, profile pic). Getting all this done in an average of 87ms is extremely efficient and a result of Rama being such an integrated system.</p>



<h2 id="Rama">Rama</h2>



<div><p>The numbers I’ve shared here should be hard to believe: a Twitter-scale Mastodon implementation with extremely strong performance numbers in only 10k lines of code, which is less code than Mastodon’s current backend implementation and 100x less code than Twitter’s scalable implementation of a very similar product? How is it possible that we’ve reduced the cost of building scalable applications by multiple orders of magnitude?</p>
<p>You can begin to understand this by starting with a simple observation: you can describe Mastodon (or Twitter, Reddit, Slack, Gmail, Uber, etc.) in total detail in a matter of hours. It has profiles, follows, timelines, statuses, replies, boosts, hashtags, search, follow suggestions, and so on. It doesn’t take that long to describe all the actions you can take on Mastodon and what those actions do. So the real question you should be asking is: given that software is entirely abstraction and automation, why does it take so long to build something you can describe in hours?</p>
<p>At its core Rama is a coherent set of abstractions for expressing backends end-to-end. All the intricacies of an application backend can be expressed in code that’s much closer to how you describe the application at a high level. Rama’s abstractions allow you to sidestep the mountains of complexity that blow up the cost of existing applications so much. So not only is Rama inherently scalable and fault-tolerant, it’s also far less work to build a backend with Rama than any other technology.</p>
<p>Let’s now dive into Rama. We’ll start with a high-level overview of Rama’s concepts. Then we’ll look at how some of the most important parts of our Mastodon instance are implemented in terms of these concepts. Finally, we’ll look at some code from our Mastodon implementation.</p>
<p>Rama is programmed entirely with a Java API, and Rama’s programming model has four main concepts:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="354" data-attachment-id="1087" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/rama-concepts/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?fit=1622%2C874&amp;ssl=1" data-orig-size="1622,874" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rama-concepts" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?fit=300%2C162&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?fit=656%2C354&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=656%2C354&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1024%2C552&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=300%2C162&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=768%2C414&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1536%2C828&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1200%2C647&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?w=1622&amp;ssl=1 1622w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1024%2C552&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=300%2C162&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=768%2C414&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1536%2C828&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=1200%2C647&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?w=1622&amp;ssl=1 1622w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/rama-concepts.png?resize=656%2C354&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>On the left are “depots”, which are distributed, durable, and replicated logs of data. All data coming into Rama comes in through depot appends. Depots are like <a href="https://kafka.apache.org/">Apache Kafka</a> except integrated with the rest of Rama.</p>
<p>Next are "ETL"s, extract-transform-load topologies. These process incoming data from depots as it arrives and produce indexed stores called “partitioned states”. Rama offers two types of ETL, streaming and microbatching, which have different performance characteristics. Most of the time spent programming Rama is spent making ETLs. Rama exposes a Java dataflow API for coding topologies that is extremely expressive.</p>
<p>Next are “partitioned states”, which we usually call “PStates”. PStates are how data is indexed in Rama, and just like depots they’re partitioned across many nodes, durable, and replicated. PStates are one of the keys to how Rama is such a general-purpose system. Unlike existing databases, which have rigid indexing models (e.g. “key-value”, “relational”, “column-oriented”, “document”, “graph”, etc.), PStates have a flexible indexing model. In fact, they have an indexing model already familiar to every programmer: <strong>data structures</strong>. A PState is an arbitrary combination of data structures, and every PState you create can have a different combination. With the “subindexing” feature of PStates, nested data structures can efficiently contain hundreds of millions of elements. For example, a “map of maps” is equivalent to a “document database”, and a “map of subindexed sorted maps” is equivalent to a “column-oriented database”. Any combination of data structures and any amount of nesting is valid –&nbsp;e.g. you can have a “map of lists of subindexed maps of lists of subindexed sets”. I cannot emphasize enough how much interacting with indexes as regular data structures instead of magical “data models” liberates backend programming.</p>
<p>The last concept in Rama is “query”. Queries in Rama take advantage of the data structure orientation of PStates with a “path-based” API that allows you to concisely fetch and aggregate data from a single partition. In addition to this, Rama has a feature called “query topologies” which can efficiently do real-time distributed querying and aggregation over an arbitrary collection of PStates. These are the analogue of “predefined queries” in traditional databases, except programmed via the same Java API as used to program ETLs and far more capable.</p>
<p>Individually, none of these concepts are new. I’m sure you’ve seen them all before. You may be tempted to dismiss Rama’s programming model as just a combination of <a href="https://martinfowler.com/eaaDev/EventSourcing.html">event sourcing</a> and <a href="https://en.wikipedia.org/wiki/Materialized_view">materialized views</a>. But what Rama does is integrate and generalize these concepts to such an extent that you can build entire backends end-to-end without any of the impedance mismatches or complexity that characterize and overwhelm existing systems.</p>
<p>All these concepts are implemented by Rama in a linearly scalable way. So if your application needs more resources, you can add them at the click of a button. Rama also achieves fault-tolerance by replicating all data and implementing automatic failover.</p>
<p>Here’s an example of how these concepts fit together. These are all the depots, ETLs, PStates, and query topologies for the portion of our Mastodon implementation handling profiles, statuses, and timelines:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="577" data-attachment-id="1088" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timelines-diagram/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?fit=1457%2C1282&amp;ssl=1" data-orig-size="1457,1282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timelines-diagram" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?fit=300%2C264&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?fit=656%2C577&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=656%2C577&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=1024%2C901&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=300%2C264&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=768%2C676&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=1200%2C1056&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?w=1457&amp;ssl=1 1457w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=1024%2C901&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=300%2C264&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=768%2C676&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=1200%2C1056&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?w=1457&amp;ssl=1 1457w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram.png?resize=656%2C577&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>This looks intimidating, but this part of the codebase only totals 1,100 lines of code. And it implements a ton of functionality, all scalably: statuses, timelines, boosts, conversations, favorites, bookmarks, mutes, account registration, profile edits, federation, and more. Notice that the PStates are a diverse collection of data structure combinations, and there are 33 of them here. Many of the ETLs produce multiple PStates and consume multiple depots. Making depots, ETLs, and PStates is inexpensive in Rama and can be done liberally.</p>
<p>What you’re seeing in this diagram is a total inversion of control compared to how applications are typically architected today. For example, consider the “fanout” ETL in this diagram which processes incoming statuses and sends them to follower timelines (you’ll see the code for this <a href="#Timeline_fanout_code">later in this post</a>). There are a bunch of rules dictating which statuses go to which followers –&nbsp;boosts never go back to the original author, replies only go to followers who also follow the account being replied to, and so on. Traditionally, that’s accomplished with a “database layer” handling storage and a separate “application layer” implementing the product logic. The “application layer” does reads and writes to the “database layer”, and the two layers are deployed, scaled, and managed separately. But with Rama, the product logic exists inside the system doing the indexing. Computation and storage are colocated. Rama does everything a database does, but it also does so much more.</p>
<p>When building a backend with Rama, you begin with all the use cases you need to support. For example: fetch the number of followers of a user, fetch a page of a timeline, fetch ten follow suggestions, and so on. Then you determine what PState layouts (data structures) you need to support those queries. One PState could support ten of your queries, and another PState may support just one query.</p>
<p>Next you determine what your source data is, and then you make depots to receive that data. Source data usually corresponds to events happening in your application, like “Alice follows Bob”, “James posted the status ‘Hello world’”, or “Bob unfollows Charlie”. You can represent your data however you want, whether Java objects, frameworks like <a href="https://thrift.apache.org/">Thrift</a> or <a href="https://protobuf.dev/">Protocol Buffers</a>, or even unstructured formats like JSON (however, we recommend using structured formats as much as possible).</p>
<p>The last step is writing the ETL topologies that convert source data from your depots into your PStates. When deployed, the ETLs run continuously keeping your PStates up to date. Rama’s ETL API, though just Java, is like a “distributed programming language” with the computational capabilities of any Turing-complete language along with facilities to easily control on which partition computation happens at any given point. You’ll see many examples of this API later in this post.</p>
</div>



<h2 id="Clusters_and_modules">Clusters and modules</h2>



<div><p>Rama is deployed onto a cluster of nodes. There’s a central daemon called the “Conductor” which coordinates deploys, updates, and scaling operations. Every node has a “Supervisor” daemon which manages the launch/teardown of user code.</p>
<p>Applications are deployed onto a Rama cluster as “modules”. A “module” contains an arbitrary combination of depots, ETLs, PStates, and query topologies. Unlike traditional architectures, where the corresponding analogues exist in separate processes and usually on separate nodes, in Rama these are colocated in the same set of processes. This colocation enables fantastic efficiency which has never been possible before. Modules can also consume data from depots and PStates in other modules just as easily as they can from their own. A module runs forever, continuously processing new data from depots, unless you choose to destroy it.</p>
<p>A module is deployed by giving the Conductor a .jar file with user code. Additionally, configuration is provided for the number of nodes to allocate to the module, replication parameters, as well as any other tuning parameters. A module is updated a similar way: a new .jar is provided with the new code, and the Conductor orchestrates an update sequence that launches new processes and transfers depots and PStates to the new module version.</p>
<p>Here’s what a Rama cluster could look like with two modules deployed, “SocialGraphModule” and “TimelineModule”:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="338" data-attachment-id="1091" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-overview/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?fit=1548%2C796&amp;ssl=1" data-orig-size="1548,796" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-overview" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?fit=300%2C154&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?fit=656%2C338&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=656%2C338&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1024%2C527&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=300%2C154&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=768%2C395&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1536%2C790&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1200%2C617&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?w=1548&amp;ssl=1 1548w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1024%2C527&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=300%2C154&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=768%2C395&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1536%2C790&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=1200%2C617&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?w=1548&amp;ssl=1 1548w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-overview.png?resize=656%2C338&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>For testing and development, Rama provides a class called

<code>InProcessCluster</code>

for simulating Rama clusters within a single process.</p>



<h2 id="Mastodon_on_Rama">Mastodon on Rama</h2>



<p>Let’s look at some of the key parts of how Mastodon is implemented on top of Rama. In this section we’ll focus on the design of Mastodon –&nbsp;what PStates are created, the flow of how data is processed, and how everything is organized. You’ll see how Rama’s capabilities enable some seriously novel ways to architect applications. In the next section we’ll look at some of the code from our implementation.</p>



<h3 id="Following_hashtags">Following hashtags</h3>



<div><p>Let’s start with an extremely simple part of the implementation, tracking followers for hashtags. The implementation for this totals 11 lines of code and supports the following queries:</p>
<ul>
<li>Does user A follow hashtag H?</li>
<li>Who follows hashtag H (paginated)?</li>
<li>How many followers does hashtag H have?</li>
</ul>
</div>



<p>Only a single PState is needed for this, called

<code>$$hashtagToFollowers</code>

(PState names in Rama always begin with

<code>$$</code>

). It is a map from a hashtag to a set of account IDs. Here’s a visualization of what this PState could look like across two partitions. Keep in mind that PStates are distributed across many partitions, with each partition of a PState being the specified data structure:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="536" height="241" data-attachment-id="1120" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/hashtagtofollowers/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?fit=536%2C241&amp;ssl=1" data-orig-size="536,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hashtagToFollowers" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?fit=536%2C241&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?resize=536%2C241&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?w=536&amp;ssl=1 536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?resize=300%2C135&amp;ssl=1 300w" sizes="(max-width: 536px) 100vw, 536px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?w=536&amp;ssl=1 536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?resize=300%2C135&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/hashtagToFollowers.png?resize=536%2C241&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>There are two events that change this PState: following a hashtag, and unfollowing a hashtag. In our implementation, these are represented by the types

<code>FollowHashtag</code>

and

<code>RemoveFollowHashtag</code>

.</p>



<p>A good way to visualize how data is processed to produce this PState is via a dataflow graph, as you can see how data moves from the start of processing (one or more depots) to the end results of processing (updates to PStates):</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="372" height="472" data-attachment-id="1121" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/follow-hashtags/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?fit=372%2C472&amp;ssl=1" data-orig-size="372,472" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="follow-hashtags" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?fit=236%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?fit=372%2C472&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?resize=372%2C472&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?w=372&amp;ssl=1 372w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?resize=236%2C300&amp;ssl=1 236w" sizes="(max-width: 372px) 100vw, 372px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?w=372&amp;ssl=1 372w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?resize=236%2C300&amp;ssl=1 236w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags.png?resize=372%2C472&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>The logic here is trivial, which is why the implementation is only 11 lines of code. You don’t need to worry about things like setting up a database, establishing database connections, handling serialization/deserialization on each database read/write, writing deploys just to handle this one task, or any of the other tasks that pile up when building backend systems. Because Rama is so integrated and so comprehensive, a trivial feature like this has a correspondingly trivial implementation.</p>
<p>You may be wondering why the follow and unfollow events go onto the same depot instead of separate depots. Though you could implement it that way, it would be a mistake to do so. Data is processed off a depot partition in the order in which it was received, but there are no ordering guarantees across different depots. So if a user was spamming the “Follow” and “Unfollow” buttons on the UI and those events were appended to different depots, it’s possible a later unfollow could be processed before a prior follow. This would result in the PState ending up in the incorrect state according to the order by which the user made actions. By putting both events in the same depot, the data is processed in the same order in which it was created.</p>
<p>As a general rule, Rama guarantees <strong>local ordering</strong>. Data sent between two points are processed in the order in which they were sent. This is true for processing data off a depot, and it’s also true for intra-ETL processing when your processing jumps around to different partitions as part of computation.</p>
<p>This dataflow diagram is literally how you program with Rama, by specifying dataflow graphs in a pure Java API. As you’ll see below, the details of specifying computations like this involve variables, functions, filters, loops, branching, and merging. It also includes fine-grained control over which partitions computation is executing at any given point.</p>
</div>







<div><p>Let’s now look at a slightly more involved part of the implementation, the social graph. The social graph totals 105 lines of code and supports the following queries which power various aspects of Mastodon:</p>
<ul>
<li>Does user A follow user B?</li>
<li>How many followers does user A have?</li>
<li>How many accounts does user A follow?</li>
<li>Who are user A’s followers in the order in which they followed (paginated)?</li>
<li>Who does user A follow in the order in which they followed them (paginated)?</li>
<li>Who is currently requesting to follow user A in the order in which they requested (paginated)?</li>
<li>Does user A block user B?</li>
<li>Does user A mute user B?</li>
<li>Does user A wish to see boosts from user B?</li>
</ul>
<p>Even though the implementation is so simple with Rama, it’s worth noting that Twitter had to write a <a href="https://github.com/twitter-archive/flockdb">custom database from scratch</a> to build their scalable social graph.</p>
</div>



<p>There are four main PStates produced by our social graph implementation, named

<code>$$followerToFollowees</code>

,

<code>$$followeeToFollowers</code>

,

<code>$$accountIdToFollowRequests</code>

, and

<code>$$accountIdToSuppressions</code>

. The first three PStates have the same structure, which is a map from account ID to a linked set of account IDs plus additional information needed about the relationship. For example, for

<code>$$followeeToFollowers</code>

we track whether a follower wants to see boosts from that account in their home timeline (which is one of Mastodon’s features). This PState is also used to compute: whether an account already follows another account, the order in which accounts were followed (which is why a linked set is used rather than a regular set), and the number of followers for an account (which is just the size of the inner set, something Rama computes in fast constant time even if the set has millions of elements).</p>



<p>The

<code>$$accountIdToSuppressions</code>

PState tracks blocks and mutes for each account and has a different structure. It is a map from account ID to a map containing two keys: “blocked” and “muted”. The “blocked” key maps to the set of account IDs the top-level account ID has blocked. The “muted” key is similar but stores a map from account ID to the options for that mute (like expiration time). This PState is used wherever statuses are rendered (e.g. home timeline, notifications) to filter out statuses a user doesn’t want to see.</p>



<p>Here’s a visualization of what the

<code>$$followeeToFollowers</code>

PState could look like in a deployed module:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="261" data-attachment-id="1125" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/followeetofollowers/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?fit=1208%2C480&amp;ssl=1" data-orig-size="1208,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="followeeToFollowers" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?fit=300%2C119&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?fit=656%2C261&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=656%2C261&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=1024%2C407&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=300%2C119&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=768%2C305&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=1200%2C477&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?w=1208&amp;ssl=1 1208w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=1024%2C407&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=300%2C119&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=768%2C305&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=1200%2C477&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?w=1208&amp;ssl=1 1208w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/followeeToFollowers.png?resize=656%2C261&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>Here you can see that account “1” is followed by accounts “2”, “7”, and “5”, with “2” and “7” having boosts enabled and “5” having boosts disabled. Account “4” is only followed by account “1”, and “1” has boosts enabled for that relationship.</p>
<p>The social graph is constructed based on follow, unfollow, block, unblock, mute, and unmute events. In Mastodon’s design, blocking a user also unfollows in both directions (if currently followed). So the block and unblock events go on the same depot as the follow-related events, while the mute and unmute events go on a separate depot.</p>
<p>Here’s the dataflow graph showing how these PStates are computed based on the source data:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="704" data-attachment-id="1126" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?fit=1136%2C1219&amp;ssl=1" data-orig-size="1136,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?fit=280%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?fit=656%2C704&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=656%2C704&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=954%2C1024&amp;ssl=1 954w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=280%2C300&amp;ssl=1 280w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=768%2C824&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=954%2C1024&amp;ssl=1 954w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=280%2C300&amp;ssl=1 280w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=768%2C824&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph.png?resize=656%2C704&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is more involved than the hashtag follows dataflow graph since this ETL supports so many more features. Yet it’s still only 105 lines of code to implement. You can see how this ETL makes use of conditionals, branching, and merging in its implementation. Here’s a few notes on the logic within this ETL:</p>



<ul>
<li>When a user follows another user, the

<code>$$followerToFollowees</code>

and

<code>$$followeeToFollowers</code>

PStates are updated. Unfollowing updates the same PStates but removes the relationship instead of adding it.</li>
<li>Blocking is handled specially by implicitly emitting additional unfollow events as part of processing (to unfollow in both directions), as well as tracking who blocks who in the

<code>$$accountIdToSuppressions</code>

PState.</li>
<li>A locked account (where each follower must be individually approved) receives

<code>FollowLockedAccount</code>

events, and unlocked accounts receive

<code>Follow</code>

events.</li>
<li>Attributes of a relationship (e.g. “show boosts”, “notify”) are updated via appending another

<code>Follow</code>

or

<code>FollowLockedAccount</code>

event to the depot. This is why the

<code>FollowLockedAccount</code>

checks if the follow relationship already exists so it can determine whether to update the follow relationship or add a new follow request.</li>
<li>A

<code>Follow</code>

event also removes the corresponding follow request if it exists. This is why an

<code>AcceptFollowRequest</code>

event just converts to a

<code>Follow</code>

event.</li>
</ul>



<p>This ETL interacts with many PStates at the same time. Because of Rama’s integrated nature, these PStates are colocated with one another within the same processes that are executing the ETL logic. So whereas you always have to do a network operation to access most databases, PState operations are local, in-process operations with Rama ETLs. As you’ll see later, you utilize the network in an ETL via “partitioner” operations to get to the right partition of a module, but once you’re on a partition you can perform as many PState operations to as many colocated PStates as you need. This is not only extremely efficient but also liberating due to the total removal of impedance mismatches that characterizes interacting with databases.</p>



<h3 id="Computing_and_rendering_home_timelines">Computing and rendering home timelines</h3>



<p>Next let’s look at the core of Mastodon, computing and rendering home timelines. This powers the primary page of the Mastodon experience:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="411" data-attachment-id="1157" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/home-timeline-screenshot-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?fit=3382%2C2122&amp;ssl=1" data-orig-size="3382,2122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="home-timeline-screenshot-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?fit=656%2C411&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=656%2C411&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1024%2C642&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=768%2C482&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1536%2C964&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=2048%2C1285&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1200%2C753&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1024%2C642&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=768%2C482&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1536%2C964&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=2048%2C1285&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=1200%2C753&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/home-timeline-screenshot-1.png?resize=656%2C411&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This use case is a great example of how to think about building data-intensive systems not just with Rama, but in general. For any backend feature you want to implement, you have to balance what gets precomputed versus what gets computed on the fly at query-time. The more you can precompute, the less work you’ll have to do at query-time and the lower latencies your users will experience. This basic structure looks like this:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="243" data-attachment-id="1133" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/backend-model/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?fit=1642%2C608&amp;ssl=1" data-orig-size="1642,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="backend-model" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?fit=300%2C111&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?fit=656%2C243&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=656%2C243&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1024%2C379&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=300%2C111&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=768%2C284&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1536%2C569&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1200%2C444&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?w=1642&amp;ssl=1 1642w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1024%2C379&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=300%2C111&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=768%2C284&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1536%2C569&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=1200%2C444&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?w=1642&amp;ssl=1 1642w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/backend-model.png?resize=656%2C243&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>This of course is the programming model of Rama you’ve already seen, and a big part of designing Rama applications is determining what computation goes in the ETL portion versus what goes in the query portion. Because both the ETL and query portions can be arbitrary distributed computations, and since PStates can be any structure you want, you have total flexibility when it comes to choosing what gets precomputed versus what gets computed on the fly.</p>
<p>It’s generally a good idea to work backwards from the needed queries to learn how to best structure things. In the case of querying for a page of a timeline, you need the following information:</p>
<ul>
<li>Content for each status</li>
<li>Stats for each status (number of replies, boosts, and favorites)</li>
<li>Information about the account that posted each status (username, display name, profile pic)</li>
<li>Whether the author of each status is blocked or muted</li>
<li>For boosts, the username of the booster</li>
<li>ID to use to fetch the next page of statuses</li>
</ul>
<p>Since statuses can be edited and profile information can be changed, almost all this information is dynamic and must be fetched for each render of a timeline page.</p>
<p>Let’s consider a typical way to go about this with non-Rama technologies, even scalable ones, which unfortunately is extremely inefficient:</p>
<ul>
<li>Fetch the list of status IDs for a page of the timeline</li>
<li>In parallel, send database requests to fetch:
<ul>
<li>Content for each status</li>
<li>Stats for each status</li>
<li>Information for each author</li>
</ul>
</li>
</ul>
<p>For a page of 20 statuses, this could easily require over 100 database calls with a lot of overhead in the sheer amount of back and forth communication needed to fetch data from each database partition.</p>
<p>We handled this use case with Rama by making use of Rama’s facilities for colocation of PStates. The module is organized such that <strong>all information</strong> for a status and the account who posted it are colocated in the same process. So instead of needing separate requests for status content, status stats, and author information, only one request is needed per status.</p>
</div>



<h4>Structuring the PStates</h4>



<p>Here are all the depots, PStates, and query topologies in the module implementing timelines and profiles (repeated from above):</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="577" data-attachment-id="1136" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timelines-diagram-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?fit=1457%2C1282&amp;ssl=1" data-orig-size="1457,1282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timelines-diagram-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?fit=300%2C264&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?fit=656%2C577&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=656%2C577&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=1024%2C901&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=300%2C264&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=768%2C676&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=1200%2C1056&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?w=1457&amp;ssl=1 1457w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=1024%2C901&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=300%2C264&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=768%2C676&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=1200%2C1056&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?w=1457&amp;ssl=1 1457w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timelines-diagram-1.png?resize=656%2C577&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Let’s look at these PStates in closer detail, as the way they’re structured and partitioned is extremely interesting. Let’s start with

<code>$$accountIdToAccount</code>

. This is a map from account ID to profile information, including username, display name, and profile pic. Here’s a picture of what this PState could look like across four partitions:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="401" data-attachment-id="1137" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/accountidtoaccount/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?fit=786%2C481&amp;ssl=1" data-orig-size="786,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="accountIdToAccount" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?fit=300%2C184&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?fit=656%2C401&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=656%2C401&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?w=786&amp;ssl=1 786w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=300%2C184&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=768%2C470&amp;ssl=1 768w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?w=786&amp;ssl=1 786w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=300%2C184&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=768%2C470&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToAccount.png?resize=656%2C401&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This PState is partitioned by the account ID. When I say “partitioned by”, I mean how the Mastodon implementation chooses on which partition to store data for any particular account. The most common way to partition a PState is to hash a partitioning key and modulo the hash by the number of partitions. This deterministically chooses a partition for any particular partitioning key, while evenly spreading out data across all partitions (this “hash/mod” technique is used by most distributed databases). For this PState, the partitioning key is the same as the key in the map, the account ID (as you’ll see soon, it doesn’t have to be).</p>



<p>Next is

<code>$$accountIdToStatuses</code>

. This is a map from account ID to a map from status ID to a list of status content versions. A list of status content versions is stored to capture the edit history of a status, which Mastodon lets you view in its UI. You can visualize this PState like so:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="480" height="554" data-attachment-id="1141" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/accountidtostatuses/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?fit=480%2C554&amp;ssl=1" data-orig-size="480,554" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="accountIdToStatuses" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?fit=260%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?fit=480%2C554&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?resize=480%2C554&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?w=480&amp;ssl=1 480w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?resize=260%2C300&amp;ssl=1 260w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?w=480&amp;ssl=1 480w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?resize=260%2C300&amp;ssl=1 260w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/accountIdToStatuses.png?resize=480%2C554&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Whenever a status is edited, a new version is prepended to its respective inner list. Since this PState and

<code>$$accountIdToAccount</code>

are in the same module, each partition is colocated on the same thread within the same process. You can visualize this colocation like so:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="656" data-attachment-id="1143" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/colocated-account-pstates/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?fit=1077%2C1078&amp;ssl=1" data-orig-size="1077,1078" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="colocated-account-pstates" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?fit=656%2C656&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=656%2C656&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=768%2C769&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?w=1077&amp;ssl=1 1077w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=768%2C769&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?w=1077&amp;ssl=1 1077w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/colocated-account-pstates.png?resize=656%2C656&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Because of this colocation queries can look at the partitions for both PStates at the same time within the same event instead of needing two roundtrips. You can also have multiple threads per worker process, or multiple worker processes per node.</p>



<p>Now let’s see how things get really interesting.

<code>$$statusIdToFavoriters</code>

is a map from a status ID to a linked set of account IDs. Here’s a visualization of this PState:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="439" height="480" data-attachment-id="1145" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/statusidtofavoriters/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?fit=439%2C480&amp;ssl=1" data-orig-size="439,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="statusIdToFavoriters" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?fit=274%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?fit=439%2C480&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?resize=439%2C480&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?w=439&amp;ssl=1 439w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?resize=274%2C300&amp;ssl=1 274w" sizes="(max-width: 439px) 100vw, 439px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?w=439&amp;ssl=1 439w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?resize=274%2C300&amp;ssl=1 274w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/statusIdToFavoriters.png?resize=439%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Similar to the social graph PStates, this PState is used to compute: the order in which accounts favorited a status (paginated), whether a particular account already favorited a status, and the number of favorites for a status.</p>



<p>What’s interesting is how this PState is partitioned. It is <strong>not</strong> partitioned by the status ID, which is the key of the map. It is instead partitioned by the account ID of the user who posted that status, which is not even in the map! This same partitioning scheme is used for all other PStates tracking status information, like

<code>$$statusIdToReplies</code>

,

<code>$$statusIdToBoosters</code>

, and

<code>$$statusIdToMuters</code>

. This means all information for a user and all information for that user’s statuses exist on the same partition, and performing a query to fetch all the information needed to render a status only needs to perform a single roundtrip.</p>



<p>Here’s a visualization of how all the PStates described could exist in a module deployment:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="528" height="1024" data-attachment-id="1148" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/all-colocated-pstates/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?fit=1074%2C2084&amp;ssl=1" data-orig-size="1074,2084" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="all-colocated-pstates" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?fit=155%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?fit=528%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=528%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=528%2C1024&amp;ssl=1 528w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=155%2C300&amp;ssl=1 155w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=768%2C1490&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=792%2C1536&amp;ssl=1 792w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=1055%2C2048&amp;ssl=1 1055w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?w=1074&amp;ssl=1 1074w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=528%2C1024&amp;ssl=1 528w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=155%2C300&amp;ssl=1 155w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=768%2C1490&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=792%2C1536&amp;ssl=1 792w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=1055%2C2048&amp;ssl=1 1055w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?w=1074&amp;ssl=1 1074w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/all-colocated-pstates.png?resize=528%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Notice, for example, how status ID “3” for account ID “10” exists both as a subvalue within

<code>$$accountIdToStatuses</code>

and also as a top-level key for the status-specific states on the same partition.</p>



<p>This use case is a great example of the power of Rama’s integrated approach, achieving incredible efficiency and incredible simplicity. Each of these PStates exists in exactly the perfect shape and partitioning for the use cases it serves.</p>



<h4 id="Home_timelines">Home timelines</h4>



<div><p>Next, let’s explore how home timelines are stored. Materializing home timelines is by far the most intensive part of the application, since statuses are fanned out to all followers. Since the average fanout on our instance is 403, there are over 400x more writes to home timelines than any of the other PStates involved in processing statuses.</p>
<p>PStates are durable, replicated, high-performance structures. They are easy to reason about and ideal for most use cases. In our initial implementation of Mastodon, we stored home timelines in a PState and it worked fine.</p>
<p>However, writing to the home timelines PState was clearly the overwhelming bottleneck in the application because of the sheer amount of data that had to be written to disk and replicated. We also realized that home timelines are unique in that they are somewhat redundant with other PStates. You can reconstruct a home timeline by looking at the statuses of everyone you follow. This can involve a few hundred PState queries across the cluster, so it isn’t cheap, but it’s also not terribly expensive.</p>
<p>As it turns out, what we ended up doing to optimize home timelines is very similar to how Twitter did it for their chronological timelines, and for the exact same reasons. In our revised implementation, we store home timelines in-memory and unreplicated. So instead of needing to persist each timeline write to disk and replicate it to followers, a timeline write is an extremely cheap write to an in-memory buffer. This optimization increased the number of statuses we could process per second by 15x.</p>
<p>Solely storing the timeline in-memory is not sufficient though, as it provides no fault-tolerance in the event of a power loss or other node failure. So a new leader for the partition would not have the timeline info since it’s unreplicated and not persisted to disk. To solve this, we reconstruct the timeline on read if it’s missing or incomplete by querying the recent statuses of all follows. This provides the same fault-tolerance as replication, but in a different way.</p>
<p>Implementing fault-tolerance this way is a tradeoff. For the benefit of massively reduced cost on timeline write, sometimes reads will be much more expensive due to the cost of reconstructing lost timelines. This tradeoff is overwhelmingly worth it because timeline writes are way, way more frequent than timeline reads and lost partitions are rare.</p>
<p>Whereas Twitter stores home timelines in a dedicated in-memory database, in Rama they’re stored in-memory in the same processes executing the ETL for timeline fanout. So instead of having to do network operations, serialization, and deserialization, the reads and writes to home timelines in our implementation are literally just in-memory operations on a hash map. This is dramatically simpler and more efficient than operating a separate in-memory database. The timelines themselves are stored like this:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br></p></td><td><p><span>public</span> <span>static</span> <span>class</span> Timeline <span>{</span><br>
&nbsp; <span>public</span> <span>long</span><span>[</span><span>]</span> buffer<span>;</span><br>
&nbsp; <span>public</span> <span>int</span> startIndex <span>=</span> <span>0</span><span>;</span> <span>// index within buffer that contains oldest timeline element</span><br>
&nbsp; <span>public</span> <span>int</span> numElems <span>=</span> <span>0</span><span>;</span> <span>// number of elements in this timeline</span><br>
<span>}</span></p></td></tr></tbody></table></div>




<div><p>To minimize memory usage and GC pressure, we use a ring buffer and Java primitives to represent each home timeline. The buffer contains pairs of author ID and status ID. The author ID is stored along with the status ID since it is static information that will never change, and materializing it means that information doesn’t need to be looked up at query time. The home timeline stores the most recent 600 statuses, so the buffer size is 1,200 to accommodate each author ID and status ID pair. The size is fixed since storing full timelines would require a prohibitive amount of memory (the number of statuses times the average number of followers).</p>
<p>Each user utilizes about 10kb of memory to represent their home timeline. For a Twitter-scale deployment of 500M users, that requires about 4.7TB of memory total around the cluster, which is easily achievable.</p>
<p>The in-memory home timelines and other PStates are put together to render a page of a timeline with the following logic:</p>
</div>



<ul>
<li>First, query the in-memory home timeline to fetch a page of

<code>[author ID, statusID]</code>

pairs.</li>
<li>Next, invoke a query topology (a predefined distributed query) that takes in a list of

<code>[author ID, statusID]</code>

pairs and returns all information needed to render each status –&nbsp;status content, status stats, and author information. The query topology goes to all partitions containing requested status IDs in parallel and fetches all needed information with colocated PState queries.</li>
</ul>



<h4 id="timeline-fanout">Implementing fanout</h4>



<div><p>So that’s the story on how timelines are rendered, but how are home timelines and these various PStates computed? If you look back at <a href="#Performance_and_scalability">the performance numbers</a>, you can see our Mastodon implementation has high throughput that scales linearly while also having great, consistent latencies for delivering statuses to follower timelines.</p>
<p>Let’s focus on how statuses are handled, particularly how timelines are materialized. Whenever someone posts a status, that status must be fanned out to all followers and appended to their home timelines.</p>
<p>The tricky part is dealing with bursty load arising from how unbalanced the social graph can get. In our Mastodon instance, for example, the average fanout is 403, but the most popular user has over 22M followers. 3,500 statuses are posted each second, meaning that every second the system usually needs to perform 1.4M timeline writes to keep up. But if a user with 20M followers posts a status, then the number of timeline writes blows up by 15x to about 21.4M. With a naive implementation this can significantly delay other statuses from reaching follower timelines. And since the latency from posting a status to it reaching follower timelines is one of the most important metrics for this product, that’s really bad!</p>
<p>This is essentially a problem of fairness. You don’t want very popular users to hog all the resources on the system whenever they post a status. The key to solving this issue is to limit the amount of resources a status from a popular user can use before allocating those resources to other statuses. The approach we take in our implementation is:</p>
<ul>
<li>For each iteration of timeline processing, fan out each status to at most 64k followers.</li>
<li>If there are more followers left to deliver to for a status, add that status to a PState to continue fanout in the next iteration of processing.</li>
</ul>
<p>With this approach a status from a user with 20M followers will take 312 iterations of processing to complete fanout (about 3 minutes), and fairness is achieved by giving all statuses equal access to resources at any given time. Since the vast majority of users have less than 64k followers, most users will see their statuses delivered in one iteration of processing. Statuses from popular users take longer to deliver to all followers, but that is the tradeoff that has to be made given that the amount of resources is fixed at any given time.</p>
<p>As a side note, Twitter also has special handling for users with lots of followers to address the exact same issue.</p>
<p>With the basic approach understood, let’s look specifically at how statuses are processed in our implementation to materialize timelines. Here’s a dataflow diagram showing the logic:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="549" height="1024" data-attachment-id="1284" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-9/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?fit=742%2C1384&amp;ssl=1" data-orig-size="742,1384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-9" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?fit=161%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?fit=549%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=549%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=549%2C1024&amp;ssl=1 549w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=161%2C300&amp;ssl=1 161w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?w=742&amp;ssl=1 742w" sizes="(max-width: 549px) 100vw, 549px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=549%2C1024&amp;ssl=1 549w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=161%2C300&amp;ssl=1 161w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?w=742&amp;ssl=1 742w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-9.png?resize=549%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>This dataflow diagram is a little bit different than the social graph one, as this ETL is implemented with microbatching while the social graph is implemented with streaming. Streaming processes data directly off of depots as it arrives, while microbatching processes data in small batches. “Start iteration” in this diagram signifies the beginning of a microbatch. The tradeoffs between streaming and microbatching are too much to cover for this post, but you’ll be able to learn more about that next week when we release the documentation for Rama.</p>
<p>In this diagram you can see all the steps involved in delivering statuses to followers. There are many product rules implemented here, such as: only fan out statuses with the correct visibility, only send replies to followers who also follow the account being replied to, respect “show boost” settings, and so on.</p>
<p>This dataflow diagram only shows the computation of home timelines, whereas in reality this ETL also handles lists, hashtag timelines, and conversations. Those all work similarly to home timelines and are just additional branches of dataflow computation with slightly differing logic.</p>
</div>



<h4>Processing skew from unbalanced social graph</h4>



<div><p>Fairness issues aren’t the only problem caused by an unbalanced social graph. Another problem is skew: a naive implementation that handles all fanout for a single user from a single partition will lead to some partitions of a module having a lot more overall work to do than others. Without balanced processing, throughput is lowered since some resources are idle while others are being overwhelmed.</p>
<p>In our Mastodon implementation, we put significant effort into balancing fanout computation regardless of how unbalanced a social graph gets. This is a deep topic, so we will explore this further in a subsequent blog post. The optimizations we did in this area increased throughput by about 15%.</p>
</div>



<h3 id="Personalized_follow_suggestions">Personalized follow suggestions</h3>



<p>Let’s now look at another part of Mastodon which works completely differently than timelines: personalized follow suggestions. This powers this section on Mastodon:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="608" height="438" data-attachment-id="1159" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/follow-suggestions-screenshot/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?fit=608%2C438&amp;ssl=1" data-orig-size="608,438" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="follow-suggestions-screenshot" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?fit=300%2C216&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?fit=608%2C438&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?resize=608%2C438&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?w=608&amp;ssl=1 608w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?resize=300%2C216&amp;ssl=1 300w" sizes="(max-width: 608px) 100vw, 608px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?w=608&amp;ssl=1 608w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?resize=300%2C216&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-screenshot.png?resize=608%2C438&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>Everything about how data is processed and indexed for follow suggestions is different from what we looked at in the previous sections. Taken together, the implementations of timelines, the social graph, and follow suggestions demonstrate how expressive Rama is as a system. This generality is a result of the total arbitrariness with which you can write ETL computations, structure indexes, and compute queries.</p>
<p>Unlike the social graph and timelines, the behavior of personalized follow suggestions could be specified in very different ways. We’ve chosen to determine follow suggestions like so:</p>
<ul>
<li>Rank accounts to suggest based on who’s most followed by the accounts you already follow</li>
<li>Don’t suggest accounts you already follow</li>
<li>If this doesn’t produce enough suggestions (e.g. because you don’t follow many accounts yet), suggest the most followed accounts on the platform</li>
</ul>
<p>We took a different approach than Mastodon for follow suggestions –&nbsp;the <a href="https://docs.joinmastodon.org/methods/suggestions/">API docs</a> describe follow suggestions as “Accounts that are promoted by staff, or that the user has had past positive interactions with, but is not yet following.” We chose our approach because it’s much more difficult to implement and thus a better demonstration of Rama. Our implementation of personalized follow suggestions totals 141 lines of code.</p>
</div>



<p>The main PState underlying follow suggestions is called

<code>$$whoToFollow</code>

, a map from account ID to a list of up to 80 account ID suggestions. The interesting part of the follow suggestions implementation is how this PState is computed and maintained.</p>



<div><p>Follow suggestions can’t be computed fully incrementally, at least not practically. That is, you can’t receive a new follow or unfollow event and incrementally update all the follow suggestions for affected accounts. Computing follow suggestions is a batch operation that needs to look at everyone an account follows, and everyone they follow, at the same time in a single computation.</p>
<p>With that in mind, there are a few pieces to our implementation. First, everyone’s follow suggestions are recomputed on a regular basis. The ETL for follow suggestions recomputes the suggestions for 1,280 accounts every 30 seconds. Since there are 100M accounts, this means each account has its suggestions updated every 27 days.</p>
<p>In addition to this, we have special handling for new users. When a new user signs up, you want to provide good follow suggestions as soon as possible in order to increase engagement and increase the chance they’ll continue to use the service. So you don’t want to wait 27 days to compute personalized suggestions for a new user. At the same time, you can’t produce good personalized suggestions until the user has followed at least a few accounts. So our implementation tracks milestones which trigger immediate recomputation of follow suggestions: when a user follows 10 accounts and when a user follows 100 accounts.</p>
</div>



<h4>Structuring the PStates</h4>



<p>Here are all the depots, PStates, and query topologies related to the follow suggestions implementation:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="135" data-attachment-id="1161" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/follow-suggestions-diagram/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?fit=1417%2C290&amp;ssl=1" data-orig-size="1417,290" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="follow-suggestions-diagram" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?fit=300%2C61&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?fit=656%2C135&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=656%2C135&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=1024%2C210&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=300%2C61&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=768%2C157&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=1200%2C246&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?w=1417&amp;ssl=1 1417w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=1024%2C210&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=300%2C61&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=768%2C157&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=1200%2C246&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?w=1417&amp;ssl=1 1417w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?w=1312&amp;ssl=1 1312w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-diagram.png?resize=656%2C135&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Notice that this ETL also consumes

<code>followAndBlockAccountDepot</code>

, which is the same depot as consumed by the social graph ETL to produce the social graph PStates. Depots are sources of truth that can be consumed by as many topologies as you need.</p>



<p>Here’s what each PState for follow suggestions is used for:</p>



<ul>
<li>

<code>$$whoToFollow</code>

: As described above, this stores a list of up to 80 suggestions for each user.</li>
<li>

<code>$$nextId</code>

: This keeps track of the next group of accounts for which to recompute follow suggestions. This stores a

<code>Long</code>

on each partition that points to a key within the colocated

<code>$$followerToFollowees</code>

PState partition.</li>
<li>

<code>$$followCounts</code>

: This is a map from account ID to the number of follow actions that account has taken. This is used to track when a user has passed 10 or 100 follows and trigger an immediate recompute of their follow suggestions.</li>
<li>

<code>$$forceRecomputeUsers</code>

: This is the set of users (a set per partition) that have recently passed the 10 or 100 follows milestone. Accounts chosen for follow suggestion recomputes come from this PState as well as where

<code>$$nextId</code>

is pointing in

<code>$$followerToFollowees</code>

.</li>
<li>

<code>$$topFollowedUsers</code>

: This is a global list of the top followed users on the platform. These are used to supplement a user’s follow suggestions when not enough are computed via the personalized method.</li>
</ul>



<p>Notice how some of these PStates are not maps at the top-level, which may feel unusual given that pretty much every database that’s ever existed is map-based (with a “key” being the central concept to identify a record or row). But just as data structures other than maps are useful for everyday programming, data structures other than maps are useful for backend programming as well.</p>



<h4>Computing follow suggestions</h4>



<p>Let’s explore in more detail how follow suggestions are recomputed. Unlike the other ETLs we’ve described, this one initiates computations based on time and not on the receipt of data. Every 30 seconds it needs to recompute follow suggestions for a rotating subset of all users and for any users specified in the

<code>$$forceRecomputeUsers</code>

PState.</p>



<div><p>You can think of time as an infinite stream of events, with each event being an instant in time. Rama exposes a special depot for time called a “tick depot” which emits events according to a specified frequency.</p>
<p>For follow suggestions, a tick depot is used to trigger processing every 30 seconds. The subsequent computation then uses the PStates described to recompute follow suggestions for a subset of users. The dataflow looks like this:</p>
</div>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="648" height="1013" data-attachment-id="1165" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/follow-suggestions-dataflow/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?fit=648%2C1013&amp;ssl=1" data-orig-size="648,1013" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="follow-suggestions-dataflow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?fit=192%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?fit=648%2C1013&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?resize=648%2C1013&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?w=648&amp;ssl=1 648w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?resize=192%2C300&amp;ssl=1 192w" sizes="(max-width: 648px) 100vw, 648px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?w=648&amp;ssl=1 648w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?resize=192%2C300&amp;ssl=1 192w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-suggestions-dataflow.png?resize=648%2C1013&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The key PState is

<code>$$followerToFollowees</code>

. The ETL selects a subset of the keys in that map for processing, and it stores the last key chosen in

<code>$$nextId</code>

. The next iteration will start from that key. When it gets to the end of the PState, it starts over again from the beginning.</p>



<p>The rest of the processing uses

<code>$$followerToFollowees</code>

to fetch follows, fetch the follows of those follows, and aggregate a list of candidates along with how many times each candidate is followed among that subset of users. After filtering out candidates the starting account already follows, the

<code>$$whoToFollow</code>

PState is updated.</p>



<p>Every step of this is done in parallel. So when a subset of users is selected from

<code>$$followerToFollowees</code>

, it’s actually selecting a subset of users from each partition of that PState.</p>



<p>In between recomputes, a user may have followed some of the users in their list of suggestions. This is handled with a query topology that filters a user’s follow suggestions to exclude users they already follow.</p>



<h2 id="DevOps_with_Rama">DevOps with Rama</h2>



<p>
Let’s briefly take a look at how we do DevOps with Rama: managing the deployment, monitoring, and operation of modules in production. Since the steps are the same for all modules, we’ll use as an example how we manage the module handling statuses, timelines, and profiles. The module is implemented in the class

<code>com.rpl.mastodon.modules.Core</code>

and is deployed to a Rama cluster like so:
</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br></p></td><td><p>rama deploy \<br>
--action launch \<br>
--jar target/mastodon.jar \<br>
--module com.rpl.mastodon.modules.Core \<br>
--tasks 128 \<br>
--threads 32 \<br>
--workers 16 \<br>
--replicationFactor 3 \<br>
--configOverrides overrides.yaml</p></td></tr></tbody></table></div>




<div><p>This submits the module and its code to the cluster with the given parallelism, and Rama then launches worker processes around the cluster to run the module. The same cluster is shared by all modules. Once the workers finish starting up, they start reading from depots, executing ETLs, updating PStates, serving query requests, and so on.</p>
<p>The “replication factor” specifies to how many nodes each depot and PState should replicate its data. Replication happens completely behind the scenes and provides automatic failover in case of failures (e.g. hardware issues). Rama provides very strong guarantees with replication –&nbsp;data is not made visible for consumption from depots or PStates until it has been successfully replicated.</p>
</div>



<p>The referenced

<code>overrides.yaml</code>

file has only two lines and just registers with Rama how to serialize/deserialize the custom types used by our implementation (defined using <a href="https://thrift.apache.org/">Thrift</a>, described more below).</p>



<p>After the module finishes launching, the Cluster UI for Rama starts displaying telemetry on the module:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/blog.redplanetlabs.com\/2023\/08\/15\/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x\/&quot;}">
<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="373" data-attachment-id="1173" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-modules-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?fit=3290%2C1870&amp;ssl=1" data-orig-size="3290,1870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-modules" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?fit=656%2C373&amp;ssl=1" data-id="1173" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=656%2C373&amp;ssl=1" alt="" title="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1024%2C582&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=768%2C437&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1536%2C873&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=2048%2C1164&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1200%2C682&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1024%2C582&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=768%2C437&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1536%2C873&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=2048%2C1164&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=1200%2C682&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-modules.png?resize=656%2C373&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="374" data-attachment-id="1174" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-1-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?fit=3280%2C1870&amp;ssl=1" data-orig-size="3280,1870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?fit=656%2C374&amp;ssl=1" data-id="1174" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=656%2C374&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1024%2C584&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1536%2C876&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=2048%2C1168&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1024%2C584&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1536%2C876&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=2048%2C1168&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-1.png?resize=656%2C374&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="374" data-attachment-id="1179" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-2-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?fit=3286%2C1874&amp;ssl=1" data-orig-size="3286,1874" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?fit=656%2C374&amp;ssl=1" data-id="1179" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=656%2C374&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1024%2C584&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1536%2C876&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=2048%2C1168&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1024%2C584&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1536%2C876&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=2048%2C1168&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-2.png?resize=656%2C374&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="375" data-attachment-id="1177" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-3-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?fit=3278%2C1876&amp;ssl=1" data-orig-size="3278,1876" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?fit=300%2C172&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?fit=656%2C375&amp;ssl=1" data-id="1177" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=656%2C375&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1024%2C586&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=300%2C172&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=768%2C440&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1536%2C879&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=2048%2C1172&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1200%2C687&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1024%2C586&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=300%2C172&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=768%2C440&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1536%2C879&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=2048%2C1172&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=1200%2C687&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-3.png?resize=656%2C375&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="373" data-attachment-id="1178" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-6-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?fit=3288%2C1870&amp;ssl=1" data-orig-size="3288,1870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?fit=656%2C373&amp;ssl=1" data-id="1178" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=656%2C373&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1024%2C582&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=768%2C437&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1536%2C874&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=2048%2C1165&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1200%2C682&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1024%2C582&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=768%2C437&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1536%2C874&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=2048%2C1165&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=1200%2C682&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-6.png?resize=656%2C373&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="375" data-attachment-id="1175" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-5-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?fit=3272%2C1874&amp;ssl=1" data-orig-size="3272,1874" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?fit=300%2C172&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?fit=656%2C375&amp;ssl=1" data-id="1175" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=656%2C375&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1024%2C586&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=300%2C172&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=768%2C440&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1536%2C880&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=2048%2C1173&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1200%2C687&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1024%2C586&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=300%2C172&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=768%2C440&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1536%2C880&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=2048%2C1173&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=1200%2C687&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-5.png?resize=656%2C375&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="373" data-attachment-id="1176" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/cluster-ui-telemetry-4-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?fit=3282%2C1870&amp;ssl=1" data-orig-size="3282,1870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cluster-ui-telemetry-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?fit=656%2C373&amp;ssl=1" data-id="1176" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=656%2C373&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1024%2C583&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1536%2C875&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=2048%2C1167&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1024%2C583&amp;ssl=1 1024w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=768%2C438&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1536%2C875&amp;ssl=1 1536w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=2048%2C1167&amp;ssl=1 2048w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=1200%2C684&amp;ssl=1 1200w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?w=1312&amp;ssl=1 1312w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?w=1968&amp;ssl=1 1968w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/cluster-ui-telemetry-4.png?resize=656%2C373&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</figure>



<div><p>Rama tracks and displays telemetry for the module as a whole, as well as specific telemetry for each topology, depot, and PState. The telemetry is extremely useful for understanding the performance of a module and when it needs to be scaled. Rama uses itself to implement telemetry –&nbsp;a built-in module collects telemetry data from all modules into a depot, processes that data with an ETL, and indexes the results into PStates arranged in a time-series structure.</p>
<p>When we want to update the module to add a feature (e.g. add a new PState) or fix a bug, we run a command like the following:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br></p></td><td><p>rama deploy \<br>
--action update \<br>
--jar target/mastodon.jar \<br>
--module com.rpl.mastodon.modules.Core \<br>
--configOverrides overrides.yaml</p></td></tr></tbody></table></div>




<div><p>This launches a carefully coordinated automated procedure to launch new worker processes and handoff responsibility for depots and PStates to the new version of the module. Clients of the module doing depot appends and PState queries don’t need to be updated and automatically transition themselves to the new module version.</p>
<p>Similarly, when we want to scale the module to have more resources, we run a command like the following:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br></p></td><td><p>rama scaleExecutors \<br>
--module com.rpl.mastodon.modules.Core \<br>
--workers 24</p></td></tr></tbody></table></div>




<div><p>This launches a similar procedure as module update to transition the module to the new version.</p>
<p>And that’s all there is to DevOps with Rama –&nbsp;it’s just a few commands at the terminal to manage everything. You don’t need to invest huge amounts of time writing piles of shell scripts to coordinate changes across dozens of systems. Since Rama is such a cohesive, integrated system it’s able to automate deployment entirely, and it’s able to provide deep and detailed runtime telemetry without needing to lift a finger.</p>
</div>



<h2 id="Simple_Rama_code_example">Simple Rama code example</h2>



<div><p>Let’s look at some code! Before diving into the Mastodon code, let’s look at a simple example of coding with Rama to gain a feeling for what it’s like.</p>
<p>I’m not going to explain every last detail in this code –&nbsp;the API is so rich that it’s too much to explain for this post. Instead, I’ll do my best to summarize what the code is doing. In one week we will be releasing all the documentation for Rama, and this includes a six part tutorial that gently introduces everything. We will also be releasing a build of Rama that anyone can download and use. This build will be able to simulate Rama clusters within a single process but will not be able to run distributed clusters. It has the full Rama API and can be used to experiment with Rama. Once we open-source our Mastodon implementation in two weeks, you’ll be able to run it within a single process using this build.</p>
<p>With that said, let’s look at a simple example. Here’s the complete definition for a “word count module”, which accepts sentences as input and produces a single PState containing the count of all words in those sentences:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br></p></td><td><div><p><span>public</span> <span>class</span> WordCountModule <span>implements</span> RamaModule <span>{</span><br>
&nbsp; &nbsp; @Override<br>
&nbsp; &nbsp; <span>public</span> <span>void</span> define<span>(</span>Setup setup, Topologies topologies<span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; setup.<span>declareDepot</span><span>(</span><span>"*sentenceDepot"</span>, Depot.<span>random</span><span>(</span><span>)</span><span>)</span><span>;</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; StreamTopology wordCount <span>=</span> topologies.<span>stream</span><span>(</span><span>"wordCount"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; wordCount.<span>pstate</span><span>(</span><span>"$$wordCounts"</span>, PState.<span>mapSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a>.<span>class</span>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span><span>)</span><span>)</span><span>;</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; wordCount.<span>source</span><span>(</span><span>"*sentenceDepot"</span><span>)</span>.<span>out</span><span>(</span><span>"*sentence"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>each</span><span>(</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> sentence, OutputCollector collector<span>)</span> <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span>for</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> word<span>:</span> sentence.<span>split</span><span>(</span><span>" "</span><span>)</span><span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;collector.<span>emit</span><span>(</span>word<span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span>}</span>, <span>"*sentence"</span><span>)</span>.<span>out</span><span>(</span><span>"*word"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>hashPartition</span><span>(</span><span>"*word"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>compoundAgg</span><span>(</span><span>"$$wordCounts"</span>, CompoundAgg.<span>map</span><span>(</span><span>"*word"</span>, Agg.<span>count</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>}</span><br>
<span>}</span></p></div></td></tr></tbody></table></div>




<p>This module has one ETL named

<code>wordCount</code>

, one depot named

<code>*sentenceDepot</code>

, and one PState named

<code>$$wordCounts</code>

. The ETL receives new sentences from the depot, tokenizes those sentences into words, and then updates the counts for those words in the PState. The PState partitions are updated within a few milliseconds of appending a sentence to the depot.</p>



<p>A module implements the interface

<code>RamaModule</code>

that has a single method

<code>define</code>

on it.

<code>setup</code>

is used to declare depots and any dependencies to depots or PStates in other modules, and

<code>topologies</code>

is used to declare all ETL and query topologies.</p>



<p>The first line of

<code>define</code>

declares the depot. Depot names always begin with a

<code>*</code>

. Strings beginning with

<code>*</code>

are interpreted as variables in Rama code, and they can be passed around and used just like variables in any programming language. The second argument

<code>Depot.random()</code>

specifies the partitioning scheme of the depot. In this case the partitioning scheme causes appended sentences to go to a random partition of the depot. When local ordering is important, like for follow and unfollow events, the partitioning scheme would be set appropriately so events for the same entity go to the same partition.</p>



<p>The next line declares the ETL

<code>wordCount</code>

as a streaming topology.</p>



<p>After that is the declaration of the PState

<code>$$wordCounts</code>

. The PState is declared with a schema that specifies what it stores and how it stores it. In this case it’s just a simple map, but you can specify whatever structure you want here (e.g. a map of subindexed maps of lists of subindexed sets).</p>



<p>Lastly is the definition of the ETL. The line

<code>wordCount.source("*sentenceDepot").out("*sentence")</code>

subscribes the ETL to

<code>*sentenceDepot</code>

and binds any new sentences received to the variable

<code>*sentence</code>

.</p>



<p>The next line tokenizes each sentence into words. Java code is inserted with a lambda to split each sentence on whitespace and emit each word individually as the variable

<code>*word</code>

. Inserting arbitrary Java code into topologies like this is extremely common.</p>



<p>The next line

<code>.hashPartition("*word")</code>

relocates the dataflow to the partition of the module storing the counts for that word. The code before that line and after that line can execute on different machines, and Rama takes care of all the serialization and network transfer involved in moving the computation.</p>



<div><p>Finally, now that the computation is on the correct partition, the last line updates the count for the word in the PState. This PState update is specified in the form of an aggregation template –&nbsp;in this case it says it’s aggregating a map where the key is the word and the value is the count of all events seen for that word.</p>
<p>This is such a basic example that it doesn’t really do justice to the expressive power of Rama. However, it does demonstrate the general workflow of declaring modules, depots, PStates, and topologies. Some of the functionality not shown here includes: consuming depots/PStates from other modules, query topologies, microbatching, branching/merging, joins, loops, shadowing variables, conditionals, and decomposing code with macros.</p>
<p>Let’s now take a look at interacting with Rama modules as a client outside the cluster, similar to how you interact with a database using a database client. Here’s code that connects to a remote cluster, creates handles to the depot and PState of the module, appends some sentences, and then does some PState queries:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br></p></td><td><div><p><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+map"><span>Map</span></a> config <span>=</span> <span>new</span> <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+hashmap"><span>HashMap</span></a><span>(</span><span>)</span><span>;</span><br>
config.<span>put</span><span>(</span><span>"conductor.host"</span>, <span>"1.2.3.4"</span><span>)</span><span>;</span><br>
RamaClusterManager manager <span>=</span> RamaClusterManager.<span>open</span><span>(</span>config<span>)</span><span>;</span><br>
Depot depot <span>=</span> manager.<span>clusterDepot</span><span>(</span><span>"rama.examples.wordcount.WordCountModule"</span>, <span>"*sentenceDepot"</span><span>)</span><span>;</span><br>
depot.<span>append</span><span>(</span><span>"hello world"</span><span>)</span><span>;</span><br>
depot.<span>append</span><span>(</span><span>"hello world again"</span><span>)</span><span>;</span><br>
depot.<span>append</span><span>(</span><span>"say hello to the planet"</span><span>)</span><span>;</span><br>
depot.<span>append</span><span>(</span><span>"red planet labs"</span><span>)</span><span>;</span></p><p>

PState wc <span>=</span> manager.<span>clusterPState</span><span>(</span><span>"rama.examples.wordcount.WordCountModule"</span>, <span>"$$wordCounts"</span><span>)</span><span>;</span><br>
<a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'hello' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"hello"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
<a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'world' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"world"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
<a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'planet' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"planet"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
<a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'red' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"red"</span><span>)</span><span>)</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div>




<p>

<code>RamaClusterManager</code>

is used to connect to a cluster and retrieve handles to depots and PStates. Depots and PStates are identified by their module name (the class name of the module definition) and their name within the module. By default, depot appends block until all colocated streaming topologies have finished processing the appended data. This is why the PState queries can be executed immediately following the depot appends without further coordination.</p>



<p>The PState queries here fetch the values for the specified keys. PStates are queried using Rama’s “Path” API, and this example barely scratches the surface of what you can do with paths. They allow you to easily reach into a PState, regardless of its structure, and retrieve precisely what you need –&nbsp;whether one value, multiple values, or an aggregation of values. They can also be used for updating PStates within topologies. Mastering paths is one of the keys to mastering Rama development.</p>



<p>Let’s now take a look at how you would run

<code>WordCountModule</code>

in a unit test environment:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br></p></td><td><div><p><span>public</span> <span>void</span> wordCountTest<span>(</span><span>)</span> <span>throws</span> <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+exception"><span>Exception</span></a> <span>{</span><br>
&nbsp; &nbsp; <span>try</span> <span>(</span>InProcessCluster cluster <span>=</span> InProcessCluster.<span>create</span><span>(</span><span>)</span><span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; cluster.<span>launchModule</span><span>(</span><span>new</span> WordCountModule<span>(</span><span>)</span>, <span>new</span> LaunchConfig<span>(</span><span>4</span>, <span>2</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> moduleName <span>=</span> WordCountModule.<span>class</span>.<span>getName</span><span>(</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; Depot depot <span>=</span> cluster.<span>clusterDepot</span><span>(</span>moduleName, <span>"*sentenceDepot"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; depot.<span>append</span><span>(</span><span>"hello world"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; depot.<span>append</span><span>(</span><span>"hello world again"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; depot.<span>append</span><span>(</span><span>"say hello to the planet"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; depot.<span>append</span><span>(</span><span>"red planet labs"</span><span>)</span><span>;</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; PState wc <span>=</span> cluster.<span>clusterPState</span><span>(</span>moduleName, <span>"$$wordCounts"</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'hello' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"hello"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'world' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"world"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'planet' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"planet"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>out</span>.<span>println</span><span>(</span><span>"'red' count: "</span> <span>+</span> wc.<span>selectOne</span><span>(</span>Path.<span>key</span><span>(</span><span>"red"</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>}</span><br>
<span>}</span></p></div></td></tr></tbody></table></div>




<p>Running this code prints:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br></p></td><td><p>'hello' count: 3<br>
'world' count: 2<br>
'planet' count: 2<br>
'red' count: 1</p></td></tr></tbody></table></div>




<p>

<code>InProcessCluster</code>

simulates a Rama cluster completely in-process and is ideal for unit testing modules. Here you can see how

<code>InProcessCluster</code>

is used to launch the module and then fetch depots/PStates just like with

<code>RamaClusterManager</code>

. There’s no difference in the functionality available with

<code>InProcessCluster</code>

versus a real cluster, and you’ll be able to try out

<code>InProcessCluster</code>

next week when we release the non-production build of Rama.</p>



<h2 id="Sample_code_from_our_Mastodon_implementation">Sample code from our Mastodon implementation</h2>



<div><p>Now let’s look at some code from our Mastodon implementation. We’ll be looking at bigger code samples in this section utilizing a lot more of the Rama API, so even more than the last section I won’t be able to explain all the details of the code. I’ll summarize what the key parts are, and you’ll be able to learn all the details next week when we release the documentation.</p>
<p>Please don’t be too intimidated by this code. There are a lot of concepts and API methods at work here, and no one could possibly understand this code completely at a first glance. This is especially true without the accompanying documentation. I’m showing this code because it ties together the high-level concepts I’ve discussed in this post by making them real instead of abstract.</p>
</div>



<h3 id="Representing_data">Representing data</h3>



<p>Let’s start by looking at an example of how data is defined. We chose to represent data using <a href="https://thrift.apache.org/">Thrift</a> since it has a nice schema definition language and produces efficient serialization, but you can just as easily use plain Java objects, <a href="https://protobuf.dev/">Protocol Buffers</a>, or anything else you want. We use Thrift-defined objects in both depots and PStates. Here’s how statuses are defined:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>73<br>74<br></p></td><td><div><p>typedef i64 AccountId<br>
typedef i64 StatusId<br>
typedef i64 Timestamp</p><p>

enum StatusVisibility {<br>
&nbsp; Public = 1,<br>
&nbsp; Unlisted = 2,<br>
&nbsp; Private = 3,<br>
&nbsp; Direct = 4<br>
}</p><p>

enum AttachmentKind {<br>
&nbsp; Image = 1,<br>
&nbsp; Video = 2<br>
}</p><p>

struct StatusPointer {<br>
&nbsp; 1: required AccountId authorId;<br>
&nbsp; 2: required StatusId statusId;<br>
&nbsp; 3: optional Timestamp timestamp;<br>
&nbsp; 4: optional bool shouldExclude;<br>
}</p><p>

struct PollContent {<br>
&nbsp; 1: list&lt;string&gt; choices;<br>
&nbsp; 2: required Timestamp expiration;<br>
&nbsp; 3: required bool multipleChoice;<br>
}</p><p>

struct Attachment {<br>
&nbsp; 1: required AttachmentKind kind;<br>
&nbsp; 2: required string extension;<br>
&nbsp; 3: required string description;<br>
}</p><p>

struct AttachmentWithId {<br>
&nbsp; 1: required string uuid;<br>
&nbsp; 2: required Attachment attachment;<br>
}</p><p>

struct NormalStatusContent {<br>
&nbsp; 1: required string text;<br>
&nbsp; 2: required StatusVisibility visibility;<br>
&nbsp; 3: optional PollContent pollContent;<br>
&nbsp; 4: optional list&lt;AttachmentWithId&gt; attachments;<br>
&nbsp; 5: optional string sensitiveWarning;<br>
}</p><p>

struct ReplyStatusContent {<br>
&nbsp; 1: required string text;<br>
&nbsp; 2: required StatusVisibility visibility;<br>
&nbsp; 3: required StatusPointer parent;<br>
&nbsp; 4: optional PollContent pollContent;<br>
&nbsp; 5: optional list&lt;AttachmentWithId&gt; attachments;<br>
&nbsp; 6: optional string sensitiveWarning;<br>
}</p><p>

struct BoostStatusContent {<br>
&nbsp; 1: required StatusPointer boosted;<br>
}</p><p>

union StatusContent {<br>
&nbsp; 1: NormalStatusContent normal;<br>
&nbsp; 2: ReplyStatusContent reply;<br>
&nbsp; 3: BoostStatusContent boost;<br>
}</p><p>

struct Status {<br>
&nbsp; 1: required AccountId authorId;<br>
&nbsp; 2: required StatusContent content;<br>
&nbsp; 3: required Timestamp timestamp;<br>
&nbsp; 4: optional string remoteUrl;<br>
&nbsp; 5: optional string language;<br>
}</p></div></td></tr></tbody></table></div>




<p>Every type of status, including boosts, replies, and statuses with polls is represented by this definition. Being able to represent your data using normal programming practices, as opposed to restrictive database environments where you can’t have nested definitions like this, goes a long way in avoiding impedance mismatches and keeping code clean and comprehensible.</p>



<h3 id="Following_hashtags_code">Following hashtags code</h3>



<p>Next, let’s look at the entire definition of following hashtags (described <a href="#Following_hashtags">earlier</a> in this post). As a reminder, here’s the dataflow diagram for the following hashtags ETL:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="372" height="472" data-attachment-id="1194" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/follow-hashtags-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?fit=372%2C472&amp;ssl=1" data-orig-size="372,472" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="follow-hashtags-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?fit=236%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?fit=372%2C472&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?resize=372%2C472&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?w=372&amp;ssl=1 372w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?resize=236%2C300&amp;ssl=1 236w" sizes="(max-width: 372px) 100vw, 372px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?w=372&amp;ssl=1 372w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?resize=236%2C300&amp;ssl=1 236w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/follow-hashtags-1.png?resize=372%2C472&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Here’s the implementation, which is a direct translation of the diagram to code:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br></p></td><td><div><p>setup.<span>declareDepot</span><span>(</span><span>"*followHashtagDepot"</span>, Depot.<span>hashBy</span><span>(</span>ExtractToken.<span>class</span><span>)</span><span>)</span><span>;</span></p><p>

StreamTopology stream <span>=</span> topologies.<span>stream</span><span>(</span><span>"relationshipsStream"</span><span>)</span><span>;</span></p><p>

stream.<span>pstate</span><span>(</span><span>"$$hashtagToFollowers"</span>, PState.<span>mapSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a>.<span>class</span>, PState.<span>setSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span><span>)</span>.<span>subindexed</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span></p><p>

stream.<span>source</span><span>(</span><span>"*followHashtagDepot"</span>, StreamSourceOptions.<span>retryAllAfter</span><span>(</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; .<span>subSource</span><span>(</span><span>"*data"</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;SubSource.<span>create</span><span>(</span>FollowHashtag.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*token"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>localTransform</span><span>(</span><span>"$$hashtagToFollowers"</span>, Path.<span>key</span><span>(</span><span>"*token"</span><span>)</span>.<span>voidSetElem</span><span>(</span><span>)</span>.<span>termVal</span><span>(</span><span>"*accountId"</span><span>)</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;SubSource.<span>create</span><span>(</span>RemoveFollowHashtag.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*token"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>localTransform</span><span>(</span><span>"$$hashtagToFollowers"</span>, Path.<span>key</span><span>(</span><span>"*token"</span><span>)</span>.<span>setElem</span><span>(</span><span>"*accountId"</span><span>)</span>.<span>termVoid</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div>




<p>This is extremely simple.

<code>subSource</code>

branches the dataflow graph based on the type of an object. In this code the object in

<code>*data</code>

can be one of two types, and there is a separate branch of dataflow for each type. When a

<code>FollowHashtag</code>

event is received, that account is added to the set of followers for that hashtag. When a

<code>RemoveFollowHashtag</code>

event is received, that account is removed from the set of followers for that hashtag. Because the nested sets are subindexed, they can efficiently contain hundreds of millions of elements or more.</p>



<p>

<code>extractFields</code>

is a helper function in the Mastodon implementation for extracting fields out of Thrift objects by name and binding them to corresponding Rama variables of the same name. So

<code>extractFields("*data", "*accountId", "*token"))</code>

extracts the fields “accountId” and “token” from the Thrift object in

<code>*data</code>

and binds them to the variables

<code>*accountId</code>

and

<code>*token</code>

.</p>



<p>

<code>extractFields</code>

is implemented as a Rama macro, which is a utility for inserting a snippet of dataflow code into another section of dataflow code. It is a mechanism for code reuse that allows the composition of any dataflow elements: functions, filters, aggregation, partitioning, etc.</p>



<div><p>Unlike word count, this code uses paths instead of aggregators to define the writes to the PStates, which is the same API used to read from PStates. You’ll be able to learn more next week when we release Rama’s documentation about the differences between aggregators and paths and when to prefer one over the other.</p>
<p>Note that this code defines a parallel computation just like the word count example earlier. The code runs across many nodes to process data off each partition of the depot and update the PState. Any failures (e.g. a node dying) are handled transparently and Rama guarantees all depot data will be fully processed.</p>
</div>



<p>The partitioning is defined at the depot level (

<code>Depot.hashBy(ExtractToken.class)</code>

), so when the ETL begins processing a piece of data, the computation is already located on the partition of the module storing followers for that hashtag. So no further partitioning is needed in the ETL definition.</p>







<p>Next, let’s look at the entire definition of the social graph as described <a href="#Social_graph">earlier</a>. Here was the dataflow diagram for the social graph ETL:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="704" data-attachment-id="1198" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?fit=1136%2C1219&amp;ssl=1" data-orig-size="1136,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?fit=280%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?fit=656%2C704&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=656%2C704&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=954%2C1024&amp;ssl=1 954w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=280%2C300&amp;ssl=1 280w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=768%2C824&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=954%2C1024&amp;ssl=1 954w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=280%2C300&amp;ssl=1 280w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=768%2C824&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1.png?resize=656%2C704&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Like hashtag follows, the social graph implementation is also a direct translation of the diagram to code. Since the code for this is longer, let’s look at it section by section in the order in which it’s written. The first part is the declaration of the depots, topology, and PStates:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br></p></td><td><div><p>setup.<span>declareDepot</span><span>(</span><span>"*followAndBlockAccountDepot"</span>, Depot.<span>hashBy</span><span>(</span>ExtractAccountId.<span>class</span><span>)</span><span>)</span><span>;</span><br>
setup.<span>declareDepot</span><span>(</span><span>"*muteAccountDepot"</span>, Depot.<span>hashBy</span><span>(</span>ExtractAccountId.<span>class</span><span>)</span><span>)</span><span>;</span></p><p>

StreamTopology stream <span>=</span> topologies.<span>stream</span><span>(</span><span>"relationshipsStream"</span><span>)</span><span>;</span></p><p>

KeyToLinkedEntitySetPStateGroup accountIdToFollowRequests <span>=</span> <span>new</span> KeyToLinkedEntitySetPStateGroup<span>(</span><span>"$$accountIdToFollowRequests"</span>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, FollowLockedAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; .<span>entityIdFunction</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, req <span>-&gt;</span> <span>(</span><span>(</span>FollowLockedAccount<span>)</span> req<span>)</span>.<span>requesterId</span><span>)</span><br>
&nbsp; &nbsp; .<span>descending</span><span>(</span><span>)</span><span>;</span><br>
accountIdToFollowRequests.<span>declarePStates</span><span>(</span>stream<span>)</span><span>;</span></p><p>

KeyToLinkedEntitySetPStateGroup followerToFollowees <span>=</span> <span>new</span> KeyToLinkedEntitySetPStateGroup<span>(</span><span>"$$followerToFollowees"</span>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, Follower.<span>class</span><span>)</span><br>
&nbsp; &nbsp; .<span>entityIdFunction</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, <span>new</span> ExtractAccountId<span>(</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; .<span>descending</span><span>(</span><span>)</span><span>;</span><br>
KeyToLinkedEntitySetPStateGroup followeeToFollowers <span>=</span> <span>new</span> KeyToLinkedEntitySetPStateGroup<span>(</span><span>"$$followeeToFollowers"</span>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, Follower.<span>class</span><span>)</span><br>
&nbsp; &nbsp; .<span>entityIdFunction</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, <span>new</span> ExtractAccountId<span>(</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; .<span>descending</span><span>(</span><span>)</span><span>;</span><br>
followerToFollowees.<span>declarePStates</span><span>(</span>stream<span>)</span><span>;</span><br>
followeeToFollowers.<span>declarePStates</span><span>(</span>stream<span>)</span><span>;</span></p><p>

stream.<span>pstate</span><span>(</span><span>"$$accountIdToSuppressions"</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PState.<span>mapSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, PState.<span>fixedKeysSchema</span><span>(</span><span>"muted"</span>, PState.<span>mapSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span>, MuteAccountOptions.<span>class</span><span>)</span>.<span>subindexed</span><span>(</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>"blocked"</span>, PState.<span>setSchema</span><span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>.<span>class</span><span>)</span>.<span>subindexed</span><span>(</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div>




<p>Note that both hashtag follows and the social graph are part of the same stream topology. The social graph implementation consumes different depots than hashtag follows does, so the code is otherwise completely independent.</p>



<p>The

<code>$$followerToFollowees</code>

and

<code>$$followeeToFollowers</code>

PStates are defined with

<code>KeyToLinkedEntitySetPStateGroup</code>

, which defines the “map to linked set” data structure abstraction as the composition of multiple, more primitive PStates underneath the hood. Its implementation is only 68 lines of code.</p>



<p>The next part defines the root of processing where the branching occurs at the start of the dataflow diagram:</p>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>stream.<span>source</span><span>(</span><span>"*followAndBlockAccountDepot"</span>, StreamSourceOptions.<span>retryAllAfter</span><span>(</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*initialData"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; .<span>anchor</span><span>(</span><span>"SocialGraphRoot"</span><span>)</span></p></td></tr></tbody></table></div>




<p>As we build up the code for the social graph, let’s also take a look visually at how the dataflow diagram is filled out. This code starts off the dataflow diagram like this:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="100" height="69" data-attachment-id="1201" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-1-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1-1.png?fit=100%2C69&amp;ssl=1" data-orig-size="100,69" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-1-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1-1.png?fit=100%2C69&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1-1.png?fit=100%2C69&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1-1.png?resize=100%2C69&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-1-1.png?resize=100%2C69&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>

<code>anchor</code>

defines a location in a dataflow graph that can later be hooked onto with

<code>hook</code>

. The next section defines the first branch of processing:</p>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>.<span>each</span><span>(</span>Ops.<span>IDENTITY</span>, <span>"*initialData"</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
.<span>anchor</span><span>(</span><span>"Normal"</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="100" height="485" data-attachment-id="1203" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?fit=100%2C485&amp;ssl=1" data-orig-size="100,485" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?fit=62%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?fit=100%2C485&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?resize=100%2C485&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?w=100&amp;ssl=1 100w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?resize=62%2C300&amp;ssl=1 62w" sizes="(max-width: 100px) 100vw, 100px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?w=100&amp;ssl=1 100w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?resize=62%2C300&amp;ssl=1 62w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-2.png?resize=100%2C485&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This branch passes all data through to the anchor “Normal”, which will later be merged with other branches as you can see in the dataflow diagram.</p>



<p>Rama provides the

<code>Ops</code>

class which has commonly used functions to use within dataflow code. This includes math operations, comparators, and other utilities. Here

<code>Ops.IDENTITY</code>

is used which emits its input unchanged.</p>



<p>The next section defines the branch handling implicit unfollow events for block events:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br></p></td><td><p>.<span>hook</span><span>(</span><span>"SocialGraphRoot"</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_INSTANCE_OF</span>, BlockAccount.<span>class</span>, <span>"*initialData"</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>BlockAccount data, OutputCollector collector<span>)</span> <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; collector.<span>emit</span><span>(</span><span>new</span> RemoveFollowAccount<span>(</span>data.<span>getAccountId</span><span>(</span><span>)</span>, data.<span>getTargetId</span><span>(</span><span>)</span>, data.<span>getTimestamp</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; collector.<span>emit</span><span>(</span><span>new</span> RemoveFollowAccount<span>(</span>data.<span>getTargetId</span><span>(</span><span>)</span>, data.<span>getAccountId</span><span>(</span><span>)</span>, data.<span>getTimestamp</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; collector.<span>emit</span><span>(</span><span>new</span> RejectFollowRequest<span>(</span>data.<span>getAccountId</span><span>(</span><span>)</span>, data.<span>getTargetId</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span><br>
<span>}</span>, <span>"*initialData"</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
.<span>anchor</span><span>(</span><span>"ImplicitUnfollow"</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="248" height="457" data-attachment-id="1206" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-3/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?fit=248%2C457&amp;ssl=1" data-orig-size="248,457" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?fit=163%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?fit=248%2C457&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?resize=248%2C457&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?w=248&amp;ssl=1 248w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?resize=163%2C300&amp;ssl=1 163w" sizes="(max-width: 248px) 100vw, 248px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?w=248&amp;ssl=1 248w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?resize=163%2C300&amp;ssl=1 163w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-3.png?resize=248%2C457&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This uses

<code>hook</code>

to create a branch off the root of processing for this depot that was defined in the previous code section. The

<code>keepTrue</code>

line continues processing on this branch only for block events. It then generates implicit events to unfollow in both directions and remove a follow request if it exists. Lastly, the “ImplicitUnfollow” anchor is declared which will later be used to merge this branch together with “Normal” and other branches.</p>



<p>The next section defines the branch handling accepting a follow request:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br></p></td><td><p>.<span>hook</span><span>(</span><span>"SocialGraphRoot"</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_INSTANCE_OF</span>, AcceptFollowRequest.<span>class</span>, <span>"*initialData"</span><span>)</span><span>)</span><br>
.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*initialData"</span>, <span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span><br>
.<span>localSelect</span><span>(</span><span>"$$accountIdToFollowRequests"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span><span>)</span>.<span>must</span><span>(</span><span>"*requesterId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*followRequestId"</span><span>)</span><br>
.<span>localSelect</span><span>(</span><span>"$$accountIdToFollowRequestsById"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"*followRequestId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*followRequest"</span><span>)</span><br>
.<span>hashPartition</span><span>(</span><span>"*requesterId"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>AcceptFollowRequest data, FollowLockedAccount req<span>)</span> <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; FollowAccount follow <span>=</span> <span>new</span> FollowAccount<span>(</span>data.<span>getRequesterId</span><span>(</span><span>)</span>, data.<span>getAccountId</span><span>(</span><span>)</span>, data.<span>getTimestamp</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>if</span> <span>(</span>req.<span>isSetShowBoosts</span><span>(</span><span>)</span><span>)</span> follow.<span>setShowBoosts</span><span>(</span>req.<span>showBoosts</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>if</span> <span>(</span>req.<span>isSetNotify</span><span>(</span><span>)</span><span>)</span> follow.<span>setNotify</span><span>(</span>req.<span>notify</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>if</span> <span>(</span>req.<span>isSetLanguages</span><span>(</span><span>)</span><span>)</span> follow.<span>setLanguages</span><span>(</span>req.<span>languages</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>return</span> follow<span>;</span><br>
<span>}</span> , <span>"*initialData"</span>, <span>"*followRequest"</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
.<span>anchor</span><span>(</span><span>"CompleteFollowRequest"</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="378" height="457" data-attachment-id="1209" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-4/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?fit=378%2C457&amp;ssl=1" data-orig-size="378,457" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?fit=248%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?fit=378%2C457&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?resize=378%2C457&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?w=378&amp;ssl=1 378w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?resize=248%2C300&amp;ssl=1 248w" sizes="(max-width: 378px) 100vw, 378px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?w=378&amp;ssl=1 378w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?resize=248%2C300&amp;ssl=1 248w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-4.png?resize=378%2C457&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This code is structured just like the previous sections by hooking onto the root and then filtering for the data type of interest. Then, this code checks to see if that follow request still exists since a user could retract their follow request at the same time it was accepted. The

<code>must</code>

navigator stops this branch of computation if the follow request no longer exists.</p>



<p>After that, the code generates the implicit

<code>Follow</code>

event which will later perform the actual logic of updating the

<code>$$followerToFollowees</code>

and

<code>$$followeeToFollowers</code>

PStates.</p>



<p>The next section handles follows to a locked account. As a reminder, a locked account requires all followers to be manually approved.</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br></p></td><td><p>.<span>hook</span><span>(</span><span>"SocialGraphRoot"</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_INSTANCE_OF</span>, FollowLockedAccount.<span>class</span>, <span>"*initialData"</span><span>)</span><span>)</span><br>
.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*initialData"</span>, <span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span><br>
.<span>localSelect</span><span>(</span><span>"$$followeeToFollowers"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*existingFollowerId"</span><span>)</span><br>
.<span>ifTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_NOT_NULL</span>, <span>"*existingFollowerId"</span><span>)</span>,<br>
&nbsp; &nbsp;Block.<span>each</span><span>(</span><span>(</span>FollowLockedAccount data<span>)</span> <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; FollowAccount follow <span>=</span> <span>new</span> FollowAccount<span>(</span>data.<span>requesterId</span>, data.<span>accountId</span>, data.<span>timestamp</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span><span>(</span>data.<span>isSetShowBoosts</span><span>(</span><span>)</span><span>)</span> follow.<span>setShowBoosts</span><span>(</span>data.<span>isShowBoosts</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span><span>(</span>data.<span>isSetNotify</span><span>(</span><span>)</span><span>)</span> follow.<span>setNotify</span><span>(</span>data.<span>isNotify</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span><span>(</span>data.<span>isSetLanguages</span><span>(</span><span>)</span><span>)</span> follow.<span>setLanguages</span><span>(</span>data.<span>getLanguages</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> follow<span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span>, <span>"*initialData"</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; .<span>hashPartition</span><span>(</span><span>"*requesterId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; .<span>anchor</span><span>(</span><span>"UpdatePrivateFollow"</span><span>)</span>,<br>
&nbsp; &nbsp;Block.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*initialData"</span>, <span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; .<span>macro</span><span>(</span>accountIdToFollowRequests.<span>addToLinkedSet</span><span>(</span><span>"*accountId"</span>, <span>"*initialData"</span><span>)</span><span>)</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="539" height="1024" data-attachment-id="1211" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-5/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?fit=618%2C1175&amp;ssl=1" data-orig-size="618,1175" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?fit=158%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?fit=539%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=539%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=539%2C1024&amp;ssl=1 539w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=158%2C300&amp;ssl=1 158w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?w=618&amp;ssl=1 618w" sizes="(max-width: 539px) 100vw, 539px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=539%2C1024&amp;ssl=1 539w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=158%2C300&amp;ssl=1 158w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?w=618&amp;ssl=1 618w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-5.png?resize=539%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>When a follow request is done in the UI to a locked account, a

<code>FollowLockedAccount</code>

event is appended to the depot. Otherwise, a

<code>FollowAccount</code>

event is appended.</p>



<p>Follow relationships contain additional information such as whether the follower wants to see boosts from the followee and whether they only want to see statuses in a certain language from the followee (another one of Mastodon’s features). Updating these settings is done via another

<code>Follow</code>

or

<code>FollowLockedAccount</code>

event.</p>



<p>This code uses

<code>ifTrue</code>

to determine if the follower already follows the followee.

<code>ifTrue</code>

works just like

<code>if</code>

in any programming language, with a “then” block and an optional “else” block. If the follow relationship exists, it creates an implicit

<code>FollowAccount</code>

event to update the options on the relationship. The “UpdatePrivateFollow” anchor is used later to merge that branch just like the previous sections.</p>



<div><p>If the follow relationship does not already exist, then the PState tracking follow requests is updated.</p>
<p>The next section merges the prior branches together and begins processing for the rest of the events, whether they came directly off the depot or were created implicitly by one of the branches:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>.<span>unify</span><span>(</span><span>"Normal"</span>, <span>"ImplicitUnfollow"</span>, <span>"CompleteFollowRequest"</span>, <span>"UpdatePrivateFollow"</span><span>)</span><br>
.<span>subSource</span><span>(</span><span>"*data"</span>,</p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="512" height="1024" data-attachment-id="1213" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-6/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?fit=587%2C1175&amp;ssl=1" data-orig-size="587,1175" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-6" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?fit=150%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?fit=512%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=512%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=512%2C1024&amp;ssl=1 512w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=150%2C300&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?w=587&amp;ssl=1 587w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=512%2C1024&amp;ssl=1 512w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=150%2C300&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?w=587&amp;ssl=1 587w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-6.png?resize=512%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>

<code>unify</code>

merges the specified branches together so they share subsequent computation. Any variables that are in scope in all specified branches are in scope in the code following the

<code>unify</code>

call.</p>



<p>The

<code>subSource</code>

call dispatches subsequent code on the type of the object in

<code>*data</code>

. The following code defines the handling for

<code>FollowAccount</code>

events:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br></p></td><td><p>SubSource.<span>create</span><span>(</span>FollowAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span>, <span>"*followerSharedInboxUrl"</span>, <span>"*showBoosts"</span>, <span>"*notify"</span>, <span>"*languages"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$followerToFollowees"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span><span>)</span>.<span>view</span><span>(</span>Ops.<span>SIZE</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*followeeCount"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>LESS_THAN</span>, <span>"*followeeCount"</span>, relationshipCountLimit<span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$followerToFollowees"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"*targetId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*followeeId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$followerToFolloweesById"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"*followeeId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*existingFollowee"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>each</span><span>(</span>Relationships<span>::</span>makeFollower, <span>"*targetId"</span>, <span>"*showBoosts"</span>, <span>"*languages"</span>, <span>"*followerSharedInboxUrl"</span>, <span>"*existingFollowee"</span><span>)</span>.<span>out</span><span>(</span><span>"*followee"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>followerToFollowees.<span>addToLinkedSet</span><span>(</span><span>"*accountId"</span>, <span>"*followee"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>hashPartition</span><span>(</span><span>"*targetId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$followeeToFollowers"</span>, Path.<span>key</span><span>(</span><span>"*targetId"</span>, <span>"*accountId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*followerId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$followeeToFollowersById"</span>, Path.<span>key</span><span>(</span><span>"*targetId"</span>, <span>"*followerId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*existingFollower"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>each</span><span>(</span>Relationships<span>::</span>makeFollower, <span>"*accountId"</span>, <span>"*showBoosts"</span>, <span>"*languages"</span>, <span>"*followerSharedInboxUrl"</span>, <span>"*existingFollower"</span><span>)</span>.<span>out</span><span>(</span><span>"*follower"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>followeeToFollowers.<span>addToLinkedSet</span><span>(</span><span>"*targetId"</span>, <span>"*follower"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>accountIdToFollowRequests.<span>removeFromLinkedSetByEntityId</span><span>(</span><span>"*targetId"</span>, <span>"*accountId"</span><span>)</span><span>)</span>,</p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="974" data-attachment-id="1215" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-7/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?fit=844%2C1252&amp;ssl=1" data-orig-size="844,1252" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-7" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?fit=202%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?fit=656%2C974&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=656%2C974&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=690%2C1024&amp;ssl=1 690w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=202%2C300&amp;ssl=1 202w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=768%2C1139&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?w=844&amp;ssl=1 844w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=690%2C1024&amp;ssl=1 690w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=202%2C300&amp;ssl=1 202w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=768%2C1139&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?w=844&amp;ssl=1 844w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-7.png?resize=656%2C974&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This code adds the relationship to the

<code>$$followerToFollowees</code>

and

<code>$$followerToFollowees</code>

PStates. If the relationship already exists, it updates the options on the relationship. It also removes any corresponding follow request from

<code>$$accountIdToFollowRequests</code>

if it exists.</p>



<p>

<code>relationshipCountLimit</code>

puts an upper limit on the number of follows someone can have and is set to a very conservative limit of 100,000. It exists to prevent abuse of the system.</p>



<p>The next section handles

<code>RemoveFollowAccount</code>

events:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br></p></td><td><p>SubSource.<span>create</span><span>(</span>RemoveFollowAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span>, <span>"*followerSharedInboxUrl"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>hashPartition</span><span>(</span><span>"*accountId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>followerToFollowees.<span>removeFromLinkedSetByEntityId</span><span>(</span><span>"*accountId"</span>, <span>"*targetId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>hashPartition</span><span>(</span><span>"*targetId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>followeeToFollowers.<span>removeFromLinkedSetByEntityId</span><span>(</span><span>"*targetId"</span>, <span>"*accountId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>accountIdToFollowRequests.<span>removeFromLinkedSetByEntityId</span><span>(</span><span>"*targetId"</span>, <span>"*accountId"</span><span>)</span><span>)</span>,</p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="960" data-attachment-id="1218" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-8/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?fit=833%2C1219&amp;ssl=1" data-orig-size="833,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?fit=205%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?fit=656%2C960&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=656%2C960&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=700%2C1024&amp;ssl=1 700w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=205%2C300&amp;ssl=1 205w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=768%2C1124&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?w=833&amp;ssl=1 833w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=700%2C1024&amp;ssl=1 700w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=205%2C300&amp;ssl=1 205w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=768%2C1124&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?w=833&amp;ssl=1 833w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-8.png?resize=656%2C960&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>This code just removes the relationship from all relevant PStates.</p>
<p>Here is the next section:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br></p></td><td><div><p>SubSource.<span>create</span><span>(</span>FollowLockedAccount.<span>class</span><span>)</span>,</p><p>

SubSource.<span>create</span><span>(</span>AcceptFollowRequest.<span>class</span><span>)</span>,</p></div></td></tr></tbody></table></div>




<p>This handles events coming off the depot that were handled already in one of the top-level branches we already looked at.

<code>subSource</code>

requires every data type it sees to have a handler, so this code says to do nothing for those types.</p>



<p>The next section handles

<code>RejectFollowRequest</code>

:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br></p></td><td><p>SubSource.<span>create</span><span>(</span>RejectFollowRequest.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>accountIdToFollowRequests.<span>removeFromLinkedSetByEntityId</span><span>(</span><span>"*accountId"</span>, <span>"*requesterId"</span><span>)</span><span>)</span>,</p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="960" data-attachment-id="1221" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-9/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?fit=833%2C1219&amp;ssl=1" data-orig-size="833,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-9" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?fit=205%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?fit=656%2C960&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=656%2C960&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=700%2C1024&amp;ssl=1 700w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=205%2C300&amp;ssl=1 205w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=768%2C1124&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?w=833&amp;ssl=1 833w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=700%2C1024&amp;ssl=1 700w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=205%2C300&amp;ssl=1 205w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=768%2C1124&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?w=833&amp;ssl=1 833w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-9.png?resize=656%2C960&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This just removes the follow request from the PState.</p>



<p>The next section handles

<code>BlockAccount</code>

:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br></p></td><td><p>SubSource.<span>create</span><span>(</span>BlockAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span>, <span>"*timestamp"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localSelect</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"blocked"</span><span>)</span>.<span>view</span><span>(</span>Ops.<span>SIZE</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*blockeeCount"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>LESS_THAN</span>, <span>"*blockeeCount"</span>, relationshipCountLimit<span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localTransform</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"blocked"</span><span>)</span>.<span>voidSetElem</span><span>(</span><span>)</span>.<span>termVal</span><span>(</span><span>"*targetId"</span><span>)</span><span>)</span>,</p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="914" data-attachment-id="1223" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-10/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?fit=875%2C1219&amp;ssl=1" data-orig-size="875,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-10" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?fit=215%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?fit=656%2C914&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=656%2C914&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=735%2C1024&amp;ssl=1 735w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=768%2C1070&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?w=875&amp;ssl=1 875w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=735%2C1024&amp;ssl=1 735w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=768%2C1070&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?w=875&amp;ssl=1 875w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-10.png?resize=656%2C914&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>

<code>BlockAccount</code>

was handled in one of the initial branches to generate the implicit unfollows between the two accounts. Here,

<code>BlockAccount</code>

is handled again to record the block relationship in the

<code>$$accountIdToSuppressions</code>

PState.</p>



<p>The next section handles

<code>RemoveBlockAccount</code>

events:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br></p></td><td><p>SubSource.<span>create</span><span>(</span>RemoveBlockAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localTransform</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"blocked"</span><span>)</span>.<span>setElem</span><span>(</span><span>"*targetId"</span><span>)</span>.<span>termVoid</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="914" data-attachment-id="1226" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-11/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?fit=875%2C1219&amp;ssl=1" data-orig-size="875,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-11" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?fit=215%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?fit=656%2C914&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=656%2C914&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=735%2C1024&amp;ssl=1 735w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=768%2C1070&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?w=875&amp;ssl=1 875w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=735%2C1024&amp;ssl=1 735w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=768%2C1070&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?w=875&amp;ssl=1 875w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-11.png?resize=656%2C914&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>All this does is remove the block relationship from the

<code>$$accountIdToSuppressions</code>

PState.</p>



<p>That’s all the code for handling social graph updates from events on

<code>followAndBlockAccountDepot</code>

. The next section contains all the logic for handling events from

<code>muteAccountDepot</code>

:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br></p></td><td><p>stream.<span>source</span><span>(</span><span>"*muteAccountDepot"</span>, StreamSourceOptions.<span>retryAllAfter</span><span>(</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; .<span>subSource</span><span>(</span><span>"*data"</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;SubSource.<span>create</span><span>(</span>MuteAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span>, <span>"*options"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>localSelect</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"muted"</span><span>)</span>.<span>view</span><span>(</span>Ops.<span>SIZE</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*muteeCount"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>LESS_THAN</span>, <span>"*muteeCount"</span>, relationshipCountLimit<span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>localTransform</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"muted"</span>, <span>"*targetId"</span><span>)</span>.<span>termVal</span><span>(</span><span>"*options"</span><span>)</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;SubSource.<span>create</span><span>(</span>RemoveMuteAccount.<span>class</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*accountId"</span>, <span>"*targetId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>localTransform</span><span>(</span><span>"$$accountIdToSuppressions"</span>, Path.<span>key</span><span>(</span><span>"*accountId"</span>, <span>"muted"</span>, <span>"*targetId"</span><span>)</span>.<span>termVoid</span><span>(</span><span>)</span><span>)</span><span>)</span><span>;</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="656" height="685" data-attachment-id="1229" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/social-graph-12/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?fit=1167%2C1219&amp;ssl=1" data-orig-size="1167,1219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="social-graph-12" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?fit=287%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?fit=656%2C685&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=656%2C685&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=980%2C1024&amp;ssl=1 980w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=287%2C300&amp;ssl=1 287w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=768%2C802&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?w=1167&amp;ssl=1 1167w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=980%2C1024&amp;ssl=1 980w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=287%2C300&amp;ssl=1 287w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=768%2C802&amp;ssl=1 768w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?w=1167&amp;ssl=1 1167w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/social-graph-12.png?resize=656%2C685&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is really simple, as all it does is add the mute relationship for

<code>MuteAccount</code>

events and remove the relationship for

<code>RemoveMuteAccount</code>

events.</p>



<p>That’s the complete implementation of the social graph! As you can see, it’s expressed exactly as you saw in the dataflow diagram with branches, merges, and dispatching on the types of events.</p>



<p>It’s worth noting that dataflow code compiles to efficient bytecode when deployed, as efficient as regular Java code. So Rama variables like

<code>*accountId</code>

and

<code>*targetId</code>

become actual variables in the generated bytecode.</p>



<div><p>The code for this ETL is also a great example of why it’s so beneficial to interact with your data layer with an API in a general-purpose language instead of a custom language (like SQL). This code makes use of normal programming practices to factor out reusable functionality or to separate code into separate functions to make it easier to read. This code also demonstrates how easy it is to intermix logic written in Java with logic written in Rama’s dataflow API. Method references, lambdas, and macros are facilities for combining the two.</p>
<p>Let’s look at some of the Mastodon API implementation related to the social graph so you can see how you interact with a Rama cluster to serve the frontend. Here’s how a new unfollow event is added:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br></p></td><td><p><span>public</span> CompletableFuture<span>&lt;</span>Boolean<span>&gt;</span> postRemoveFollowAccount<span>(</span><span>long</span> followerId, <span>long</span> followeeId, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> sharedInboxUrl<span>)</span> <span>{</span><br>
&nbsp; &nbsp; RemoveFollowAccount removeFollowAccount <span>=</span> <span>new</span> RemoveFollowAccount<span>(</span>followerId, followeeId, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>currentTimeMillis</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>if</span> <span>(</span>sharedInboxUrl <span>!=</span> <span>null</span><span>)</span> removeFollowAccount.<span>setFollowerSharedInboxUrl</span><span>(</span>sharedInboxUrl<span>)</span><span>;</span><br>
&nbsp; &nbsp; <span>return</span> followAndBlockAccountDepot.<span>appendAsync</span><span>(</span>removeFollowAccount<span>)</span>.<span>thenApply</span><span>(</span>res <span>-&gt;</span> <span>true</span><span>)</span><span>;</span><br>
<span>}</span></p></td></tr></tbody></table></div>




<p>This uses the async API for depots to append unfollow data to

<code>followAndBlockAccountDepot</code>

. Rama’s async API is used almost exclusively in the Mastodon API implementation so as not to block any threads (which would be an inefficient use of resources).</p>



<p>Here’s how a follow event is handled, conditioning the type of data appended depending on if the account is locked or not:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br></p></td><td><p><span>public</span> CompletableFuture<span>&lt;</span>Boolean<span>&gt;</span> postFollowAccount<span>(</span><span>long</span> followerId, <span>long</span> followeeId, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> sharedInboxUrl, PostFollow params<span>)</span> <span>{</span><br>
&nbsp; &nbsp; <span>return</span> getAccountWithId<span>(</span>followeeId<span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; .<span>thenCompose</span><span>(</span><span>(</span>followee<span>)</span> <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>followee <span>!=</span> <span>null</span> <span>&amp;&amp;</span> followee.<span>account</span> <span>!=</span> <span>null</span> <span>&amp;&amp;</span> followee.<span>account</span>.<span>locked</span><span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; FollowLockedAccount req <span>=</span> <span>new</span> FollowLockedAccount<span>(</span>followeeId, followerId, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>currentTimeMillis</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params <span>!=</span> <span>null</span><span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>reblogs</span> <span>!=</span> <span>null</span><span>)</span> req.<span>setShowBoosts</span><span>(</span>params.<span>reblogs</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>notify</span> <span>!=</span> <span>null</span><span>)</span> req.<span>setNotify</span><span>(</span>params.<span>notify</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>languages</span> <span>!=</span> <span>null</span><span>)</span> req.<span>setLanguages</span><span>(</span>params.<span>languages</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> followAndBlockAccountDepot.<span>appendAsync</span><span>(</span>req<span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span> <span>else</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; FollowAccount req <span>=</span> <span>new</span> FollowAccount<span>(</span>followerId, followeeId, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+system"><span>System</span></a>.<span>currentTimeMillis</span><span>(</span><span>)</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params <span>!=</span> <span>null</span><span>)</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>reblogs</span> <span>!=</span> <span>null</span> <span>)</span> req.<span>setShowBoosts</span><span>(</span>params.<span>reblogs</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>notify</span> <span>!=</span> <span>null</span><span>)</span> req.<span>setNotify</span><span>(</span>params.<span>notify</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>params.<span>languages</span> <span>!=</span> <span>null</span><span>)</span> req.<span>setLanguages</span><span>(</span>params.<span>languages</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>sharedInboxUrl <span>!=</span> <span>null</span><span>)</span> req.<span>setFollowerSharedInboxUrl</span><span>(</span>sharedInboxUrl<span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> followAndBlockAccountDepot.<span>appendAsync</span><span>(</span>req<span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><span>)</span>.<span>thenApply</span><span>(</span>res <span>-&gt;</span> <span>true</span><span>)</span><span>;</span><br>
<span>}</span></p></td></tr></tbody></table></div>




<p>This first calls the helper function

<code>getAccountWithId</code>

which uses a query topology to get all information about that account. If the account is locked, a

<code>FollowLockedAccount</code>

is appended with any options appropriately set. Otherwise, a

<code>FollowAccount</code>

events is appended.</p>



<p>The helper function

<code>getAccountWithId</code>

is implemented like this:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br></p></td><td><div><p><span>public</span> CompletableFuture<span>&lt;</span>AccountWithId<span>&gt;</span> getAccountWithId<span>(</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a> requestAccountIdMaybe, <span>long</span> accountId<span>)</span> <span>{</span><br>
&nbsp; &nbsp; <span>return</span> getAccountsFromAccountIds.<span>invokeAsync</span><span>(</span>requestAccountIdMaybe, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+arrays"><span>Arrays</span></a>.<span>asList</span><span>(</span>accountId<span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<span>thenApply</span><span>(</span>accounts <span>-&gt;</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>accounts.<span>size</span><span>(</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>null</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> accounts.<span>get</span><span>(</span><span>0</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><span>)</span><span>;</span><br>
<span>}</span></p><p>

<span>public</span> CompletableFuture<span>&lt;</span>AccountWithId<span>&gt;</span> getAccountWithId<span>(</span><span>long</span> accountId<span>)</span> <span>{</span><br>
&nbsp; &nbsp; <span>return</span> <span>this</span>.<span>getAccountWithId</span><span>(</span><span>null</span>, accountId<span>)</span><span>;</span><br>
<span>}</span></p></div></td></tr></tbody></table></div>




<p>The query topology can optionally be invoked with a “requesting account ID”, because in some circumstances an account should not be visible to another account (e.g. the requesting account is blocked by that user). In this case, it just needs to check if the account is locked or not so it passes

<code>null</code>

for the requesting account ID. The query topology client is fetched like so:</p>




<div><table><tbody><tr><td><p>1<br></p></td><td><p>QueryTopologyClient<span>&lt;</span>List<span>&gt;</span> getAccountsFromAccountIds <span>=</span> cluster.<span>clusterQuery</span><span>(</span><span>"com.rpl.mastodon.modules.Core"</span>, <span>"getAccountsFromAccountIds"</span><span>)</span><span>;</span></p></td></tr></tbody></table></div>




<p>As you can see, a query topology client is fetched just like how you fetch a handle to a depot or PState. Invoking a query topology is like invoking a regular function –&nbsp;you pass it some arguments and you get a result back. Unlike a regular function, a query topology executes on a cluster across potentially many nodes. Here the result is received asynchronously, but you can also do a blocking call with

<code>invoke</code>

.</p>



<h3 id="Timeline_fanout_code">Timeline fanout code</h3>



<p>Lastly, let’s look at the code implementing timeline fanout, as described <a href="#timeline-fanout">earlier</a>. This implementation is only 51 lines of code. As a reminder, here’s the dataflow diagram for timeline fanout:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="549" height="1024" data-attachment-id="1285" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-10/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?fit=742%2C1384&amp;ssl=1" data-orig-size="742,1384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-10" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?fit=161%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?fit=549%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=549%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=549%2C1024&amp;ssl=1 549w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=161%2C300&amp;ssl=1 161w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?w=742&amp;ssl=1 742w" sizes="(max-width: 549px) 100vw, 549px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=549%2C1024&amp;ssl=1 549w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=161%2C300&amp;ssl=1 161w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?w=742&amp;ssl=1 742w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-10.png?resize=549%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Once again, since this is a longer piece of code let’s look at it section by section. Let’s start with the subscription to the depot containing all the statuses:</p>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>fan.<span>source</span><span>(</span><span>"*statusWithIdDepot"</span><span>)</span>.<span>out</span><span>(</span><span>"*microbatch"</span><span>)</span><br>
&nbsp; &nbsp;.<span>anchor</span><span>(</span><span>"FanoutRoot"</span><span>)</span></p></td></tr></tbody></table></div>




<p>Like in the social graph example, let’s see visually how the dataflow diagram gets filled out. This code starts off the dataflow diagram like this:</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="83" height="68" data-attachment-id="1239" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-1-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-1-1.png?fit=83%2C68&amp;ssl=1" data-orig-size="83,68" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-1-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-1-1.png?fit=83%2C68&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-1-1.png?fit=83%2C68&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-1-1.png?resize=83%2C68&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-1-1.png?resize=83%2C68&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Unlike the previous examples, this topology is implemented with microbatching. Microbatching guarantees exactly-once processing semantics even in the case of failures. That is, even if there are node or network outages and computation needs to be retried, the resulting PState updates will be as if each depot record was processed exactly once.</p>



<p>The variable

<code>*microbatch</code>

represents a batch of data across all partitions of the depot. This code simply binds that variable and marks the root of computation with the label “FanoutRoot”. As you can see in the dataflow diagram, there are two branches off the root of processing.</p>



<p>The next section implements the first branch, which handles continuing fanout for statuses with too many followers from the previous iteration:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br></p></td><td><p>.<span>allPartition</span><span>(</span><span>)</span><br>
.<span>localSelect</span><span>(</span><span>"$$statusIdToLocalFollowerFanouts"</span>, Path.<span>all</span><span>(</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*keyAndVal"</span><span>)</span><br>
.<span>each</span><span>(</span>Ops.<span>EXPAND</span>, <span>"*keyAndVal"</span><span>)</span>.<span>out</span><span>(</span><span>"*statusId"</span>, <span>"*followerFanouts"</span><span>)</span><br>
.<span>localTransform</span><span>(</span><span>"$$statusIdToLocalFollowerFanouts"</span>, Path.<span>key</span><span>(</span><span>"*statusId"</span><span>)</span>.<span>termVoid</span><span>(</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span>Ops.<span>EXPLODE</span>, <span>"*followerFanouts"</span><span>)</span>.<span>out</span><span>(</span><span>"*followerFanout"</span><span>)</span><br>
.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*followerFanout"</span>, <span>"*authorId"</span>, <span>"*nextIndex"</span>, <span>"*fanoutAction"</span>, <span>"*status"</span>, <span>"*task"</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span>FanoutAction<span>::</span>getValue, <span>"*fanoutAction"</span><span>)</span>.<span>out</span><span>(</span><span>"*fanoutActionValue"</span><span>)</span><br>
.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*status"</span>, <span>"*content"</span>, <span>"*language"</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>RamaFunction2<span>&lt;</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, StatusPointer<span>&gt;</span><span>)</span> StatusPointer<span>::</span><span>new</span>, <span>"*authorId"</span>, <span>"*statusId"</span><span>)</span>.<span>out</span><span>(</span><span>"*statusPointer"</span><span>)</span><br>
.<span>directPartition</span><span>(</span><span>"$$partitionedFollowers"</span>, <span>"*task"</span><span>)</span><br>
.<span>anchor</span><span>(</span><span>"LocalFollowerFanoutContinue"</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="331" height="258" data-attachment-id="1241" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-2/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?fit=331%2C258&amp;ssl=1" data-orig-size="331,258" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?fit=300%2C234&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?fit=331%2C258&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?resize=331%2C258&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?w=331&amp;ssl=1 331w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?resize=300%2C234&amp;ssl=1 300w" sizes="(max-width: 331px) 100vw, 331px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?w=331&amp;ssl=1 331w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?resize=300%2C234&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-2.png?resize=331%2C258&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Whenever a status has too many followers for one iteration of fanout, it is added to the

<code>$$statusIdToLocalFollowerFanouts</code>

PState. This PState is a map from status ID to the type

<code>FollowerFanout</code>

, which contains the information needed to continue fanout starting with the next unhanded follower. As you can see in this code, it reads everything from that PState using

<code>Path.all()</code>

and then deletes everything from that PState.</p>



<p>As you’ll see later, adding to

<code>$$statusIdToLocalFollowerFanouts</code>

is done on whatever partition followers were read for that status. So this code uses

<code>allPartition</code>

to access every partition of the PState.

<code>allPartition</code>

is a partitioner like

<code>hashPartition</code>

, except instead of the subsequent code executing on one partition, the subsequent code executes on all partitions. This allows the ETL to fetch all statuses that required continued fanout from the last iteration. You have to be careful when using

<code>allPartition</code>

as you can create non-scalable topologies if you were to use it for every piece of data on a high throughput depot. In this case

<code>allPartition</code>

is used just once per iteration, so it doesn’t affect the scalability of the topology.</p>



<p>At the end of this block of code is some handling related to

<code>$$partitionedFollowers</code>

. We didn’t mention this PState in the earlier discussion of fanout, but it’s an additional optimization to balance load for handling of users with large amounts of followers. In short, this is an additional view of the social graph where users with more than 1,000 followers have their followers spread among multiple partitions of this PState. This balances the load of processing for fanout by reducing variance among partitions. We will be publishing another blog post in the future exploring this optimization and others.</p>



<p>The next section begins the other branch of processing at the root of the dataflow diagram:</p>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>.<span>hook</span><span>(</span><span>"FanoutRoot"</span><span>)</span><br>
.<span>explodeMicrobatch</span><span>(</span><span>"*microbatch"</span><span>)</span>.<span>out</span><span>(</span><span>"*data"</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="537" height="263" data-attachment-id="1244" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-3/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?fit=537%2C263&amp;ssl=1" data-orig-size="537,263" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?fit=300%2C147&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?fit=537%2C263&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?resize=537%2C263&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?w=537&amp;ssl=1 537w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?resize=300%2C147&amp;ssl=1 300w" sizes="(max-width: 537px) 100vw, 537px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?w=537&amp;ssl=1 537w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?resize=300%2C147&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-3.png?resize=537%2C263&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This creates the branch and reads all new statuses for this iteration from the microbatch.

<code>explodeMicrobatch</code>

here reads all data from the microbatch across all partitions and binds each piece of data to the variable

<code>*data</code>

. This operation emits across all partitions of the module.</p>



<p>The next section begins processing of new statuses:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br></p></td><td><p>.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*data"</span>, <span>"*statusId"</span>, <span>"*status"</span><span>)</span><span>)</span><br>
.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*status"</span>, <span>"*authorId"</span>, <span>"*content"</span>, <span>"*language"</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span>MastodonHelpers<span>::</span>getStatusVisibility, <span>"*status"</span><span>)</span>.<span>out</span><span>(</span><span>"*visibility"</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>NOT_EQUAL</span>, <span>"*visibility"</span>, StatusVisibility.<span>Direct</span><span>)</span><span>)</span><br>
.<span>each</span><span>(</span>Ops.<span>IDENTITY</span>, <span>-</span>1L<span>)</span>.<span>out</span><span>(</span><span>"*nextIndex"</span><span>)</span><br>
.<span>each</span><span>(</span>Ops.<span>IDENTITY</span>, FanoutAction.<span>Add</span>.<span>getValue</span><span>(</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*fanoutActionValue"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>RamaFunction2<span>&lt;</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, StatusPointer<span>&gt;</span><span>)</span> StatusPointer<span>::</span><span>new</span>, <span>"*authorId"</span>, <span>"*statusId"</span><span>)</span>.<span>out</span><span>(</span><span>"*statusPointer"</span><span>)</span><br>
.<span>each</span><span>(</span>HomeTimelines<span>::</span>addTimelineItem, <span>"*homeTimelines"</span>, <span>"*authorId"</span>, <span>"*statusPointer"</span>, <span>new</span> Expr<span>(</span>Ops.<span>CURRENT_MICROBATCH_ID</span><span>)</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="547" height="1024" data-attachment-id="1287" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-4-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?fit=733%2C1372&amp;ssl=1" data-orig-size="733,1372" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-4-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?fit=160%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?fit=547%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=547%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=547%2C1024&amp;ssl=1 547w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=160%2C300&amp;ssl=1 160w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?w=733&amp;ssl=1 733w" sizes="(max-width: 547px) 100vw, 547px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=547%2C1024&amp;ssl=1 547w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=160%2C300&amp;ssl=1 160w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?w=733&amp;ssl=1 733w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-4-1.png?resize=547%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This code specifies to only perform fanout for statuses with visibility other than

<code>Direct</code>

, which is for direct messages and handled elsewhere. It then adds the status to the author’s own home timeline, which implements self-fanout.</p>



<p>The next section reads a batch of followers for the status:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br></p></td><td><div><p>.<span>select</span><span>(</span><span>"$$partitionedFollowersControl"</span>, Path.<span>key</span><span>(</span><span>"*authorId"</span><span>)</span><span>)</span>.<span>out</span><span>(</span><span>"*tasks"</span><span>)</span><br>
.<span>each</span><span>(</span>Ops.<span>EXPLODE_INDEXED</span>, <span>"*tasks"</span><span>)</span>.<span>out</span><span>(</span><span>"*i"</span>, <span>"*task"</span><span>)</span><br>
.<span>ifTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>NOT_EQUAL</span>, <span>0</span>, <span>"*i"</span><span>)</span>, Block.<span>directPartition</span><span>(</span><span>"$$partitionedFollowers"</span>, <span>"*task"</span><span>)</span><span>)</span><br>
.<span>anchor</span><span>(</span><span>"NormalFanout"</span><span>)</span></p><p>

.<span>unify</span><span>(</span><span>"NormalFanout"</span>, <span>"LocalFollowerFanoutContinue"</span><span>)</span><br>
.<span>macro</span><span>(</span>safeFetchMapLocalFollowers<span>(</span><span>"$$partitionedFollowers"</span>, <span>"*authorId"</span>, <span>"*nextIndex"</span>, rangeQueryLimit, <span>"*fetchedFollowers"</span>, <span>"*nextFollowerId"</span><span>)</span><span>)</span><br>
.<span>ifTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_NOT_NULL</span>, <span>"*nextFollowerId"</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; Block.<span>each</span><span>(</span><span>(</span>RamaFunction5<span>&lt;</span><a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a>, FanoutAction, Status, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+integer"><span>Integer</span></a>, FollowerFanout<span>&gt;</span><span>)</span> FollowerFanout<span>::</span><span>new</span>, <span>"*authorId"</span>, <span>"*nextFollowerId"</span>, <span>new</span> Expr<span>(</span>FanoutAction<span>::</span>findByValue, <span>"*fanoutActionValue"</span><span>)</span>, <span>"*status"</span>, <span>"*task"</span><span>)</span>.<span>out</span><span>(</span><span>"*followerFanout"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>localTransform</span><span>(</span><span>"$$statusIdToLocalFollowerFanouts"</span>, Path.<span>key</span><span>(</span><span>"*statusId"</span><span>)</span>.<span>nullToList</span><span>(</span><span>)</span>.<span>afterElem</span><span>(</span><span>)</span>.<span>termVal</span><span>(</span><span>"*followerFanout"</span><span>)</span><span>)</span><span>)</span></p></div></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="512" height="1024" data-attachment-id="1288" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-5-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?fit=690%2C1381&amp;ssl=1" data-orig-size="690,1381" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-5-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?fit=150%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?fit=512%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=512%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=512%2C1024&amp;ssl=1 512w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=150%2C300&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?w=690&amp;ssl=1 690w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=512%2C1024&amp;ssl=1 512w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=150%2C300&amp;ssl=1 150w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?w=690&amp;ssl=1 690w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-5-1.png?resize=512%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>As mentioned earlier, in a future post we’ll explore the

<code>$$partitionedFollowers</code>

optimization. As will be explored in that future post, the first section of this code determines from which tasks to read followers in parallel for the status’s author.</p>
<p>The

<code>unify</code>

call merges processing for statuses from both last iteration and new statuses from this iteration.

<code>safeFetchMapLocalFollowers</code>

is a small helper function reading up to

<code>rangeQueryLimit</code>

followers from this partition for that author (

<code>rangeQueryLimit</code>

is a constant set to 1,000). Since followers are read in parallel across many partitions for users with more than 1,000 followers, and since we deployed this module with 64 partitions, this means up to 64k followers are read per status per iteration.</p>
<p>The

<code>ifTrue</code>

line writes to the

<code>$$statusIdToLocalFollowerFanouts</code>

PState to continue fanout next iteration if there are still more followers to handle. This is the same PState you saw used in the earlier section.</p>



<p>The next section handles follower-specified options on the types of statuses they wish to see from this author:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br></p></td><td><p>.<span>each</span><span>(</span>Ops.<span>EXPLODE</span>, <span>"*fetchedFollowers"</span><span>)</span>.<span>out</span><span>(</span><span>"*follower"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>Follower follower<span>)</span> <span>-&gt;</span> follower.<span>accountId</span>, <span>"*follower"</span><span>)</span>.<span>out</span><span>(</span><span>"*followerId"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>Follower follower<span>)</span> <span>-&gt;</span> follower.<span>sharedInboxUrl</span>, <span>"*follower"</span><span>)</span>.<span>out</span><span>(</span><span>"*followerSharedInboxUrl"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>Follower follower<span>)</span> <span>-&gt;</span> follower.<span>isShowBoosts</span><span>(</span><span>)</span>, <span>"*follower"</span><span>)</span>.<span>out</span><span>(</span><span>"*showBoosts"</span><span>)</span><br>
.<span>each</span><span>(</span><span>(</span>Follower follower<span>)</span> <span>-&gt;</span> follower.<span>getLanguages</span><span>(</span><span>)</span>, <span>"*follower"</span><span>)</span>.<span>out</span><span>(</span><span>"*languages"</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_NULL</span>, <span>"*followerSharedInboxUrl"</span><span>)</span><span>)</span> <span>// skip remote followers</span><br>
.<span>ifTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_INSTANCE_OF</span>, BoostStatusContent.<span>class</span>, <span>"*content"</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; Block.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*content"</span>, <span>"*boostedAuthorId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>NOT_EQUAL</span>, <span>"*boostedAuthorId"</span>, <span>"*followerId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>keepTrue</span><span>(</span><span>"*showBoosts"</span><span>)</span><span>)</span><br>
.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span><span>(</span>List<span>&lt;</span>String<span>&gt;</span> languages, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+string"><span>String</span></a> statusLanguage<span>)</span> <span>-&gt;</span> languages <span>==</span> <span>null</span> <span>||</span> statusLanguage <span>==</span> <span>null</span> <span>||</span> languages.<span>contains</span><span>(</span>statusLanguage<span>)</span>, <span>"*languages"</span>, <span>"*language"</span><span>)</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="489" height="1024" data-attachment-id="1289" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-6-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?fit=659%2C1381&amp;ssl=1" data-orig-size="659,1381" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-6-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?fit=143%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?fit=489%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=489%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?w=659&amp;ssl=1 659w" sizes="(max-width: 489px) 100vw, 489px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?w=659&amp;ssl=1 659w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-6-1.png?resize=489%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This filters this follower out of fanout for this status if: it’s a boost and they don’t wish to see boosts from this author, it’s a boost and they’re the original author of the status, or they specified they only wish to see certain languages from this author and the status doesn’t match.</p>



<p>Notice how all the information needed to do the filtering is on the

<code>Follower</code>

structure that was retrieved as part of fetching followers for fanout. No extra PState queries need to be done for this information, which is one of the reasons our implementation has such high throughput. The average amount of fanout per status on our instance is 403, so any work post-fanout (after the

<code>Ops.EXPLODE</code>

call, which emits once per follower in the

<code>*fetchedFollowers</code>

list) is multiplied by 403 compared to work pre-fanout. This is why we went out of our way to materialize as much information on the follow relationship as possible to minimize the work post-fanout.</p>



<p>The next section handles additional filtering required for replies:</p>




<div><table><tbody><tr><td><p>1<br>2<br>3<br>4<br>5<br>6<br></p></td><td><p>.<span>ifTrue</span><span>(</span><span>new</span> Expr<span>(</span>Ops.<span>IS_INSTANCE_OF</span>, ReplyStatusContent.<span>class</span>, <span>"*content"</span><span>)</span>,<br>
&nbsp; &nbsp; &nbsp; &nbsp; Block.<span>macro</span><span>(</span>extractFields<span>(</span><span>"*content"</span>, <span>"*parentAuthorId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>hashPartition</span><span>(</span><span>"*followerId"</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>macro</span><span>(</span>fetchBloomMacro<span>(</span><span>"*followerId"</span>, <span>"*rbloom"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>keepTrue</span><span>(</span><span>new</span> Expr<span>(</span><span>(</span>RBloomFilter rbloom, <a href="http://www.google.com/search?hl=en&amp;q=allinurl%3Adocs.oracle.com+javase+docs+api+long"><span>Long</span></a> accountId<span>)</span> <span>-&gt;</span> rbloom.<span>bloom</span>.<span>isPresent</span><span>(</span><span>""</span> <span>+</span> accountId<span>)</span>, <span>"*rbloom"</span>, <span>"*parentAuthorId"</span><span>)</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;.<span>select</span><span>(</span><span>"$$followerToFollowees"</span>, Path.<span>key</span><span>(</span><span>"*followerId"</span><span>)</span>.<span>must</span><span>(</span><span>"*parentAuthorId"</span><span>)</span><span>)</span><span>)</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="489" height="1024" data-attachment-id="1290" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-7-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?fit=659%2C1381&amp;ssl=1" data-orig-size="659,1381" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-7-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?fit=143%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?fit=489%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=489%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?w=659&amp;ssl=1 659w" sizes="(max-width: 489px) 100vw, 489px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?w=659&amp;ssl=1 659w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-7-1.png?resize=489%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Replies are delivered to a follower only if they also follow the account being replied to. This code queries

<code>$$followerToFollowees</code>

to perform that check, with the

<code>must</code>

navigator only emitting if the follow relationship exists.</p>



<div><p>Before the PState query, there’s a bloom filter check to minimize the amount of PState queries done here. This is another optimization that we didn’t mention in the earlier discussion of fanout, and we’ll discuss it more in a future post. In short, a bloom filter is materialized and cached in-memory on this module for each account with all follows for the account. If the bloom filter returns false, the follow relationship definitely does not exist and no PState query is necessary. If it returns true, the PState query is done to weed out false positives. The bloom filter reduces PState queries for replies by 99%.</p>
<p>The next section completes this ETL by writing to the home timelines of followers that have passed each of the preceding filters:</p>
</div>




<div><table><tbody><tr><td><p>1<br>2<br></p></td><td><p>.<span>hashPartition</span><span>(</span><span>"*followerId"</span><span>)</span><br>
.<span>each</span><span>(</span>HomeTimelines<span>::</span>addTimelineItem, <span>"*homeTimelines"</span>, <span>"*followerId"</span>, <span>"*statusPointer"</span>, <span>new</span> Expr<span>(</span>Ops.<span>CURRENT_MICROBATCH_ID</span><span>)</span><span>)</span><span>;</span></p></td></tr></tbody></table></div>




<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="489" height="1024" data-attachment-id="1291" data-permalink="https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/timeline-fanout-8-1/" data-orig-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?fit=659%2C1381&amp;ssl=1" data-orig-size="659,1381" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="timeline-fanout-8-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?fit=143%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?fit=489%2C1024&amp;ssl=1" src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=489%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?w=659&amp;ssl=1 659w" sizes="(max-width: 489px) 100vw, 489px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=489%2C1024&amp;ssl=1 489w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=143%2C300&amp;ssl=1 143w, https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?w=659&amp;ssl=1 659w" data-lazy-src="https://i0.wp.com/blog.redplanetlabs.com/wp-content/uploads/2023/07/timeline-fanout-8-1.png?resize=489%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This simply routes to the appropriate partition hosting each follower’s home timeline and then adds to it. That

<code>.hashPartition</code>

call is actually the most expensive part of this ETL because of the huge volume of messages that flow through it. Due to the average of 403 fanout on our instance and our incoming rate of 3,500 statuses / second, 1.4M messages go across that partitioner every second.</p>



<div><p>When we open-source our Mastodon instance in two weeks, you’ll see that this ETL also handles hashtags, lists, conversations, and federation. We excluded those from this code example since they’re all pretty similar to home timeline fanout, with slightly different rules. They’re just additional branches of computation on this ETL.</p>
<p>That’s all we’ll show for now. As mentioned, in two weeks we’ll be open-sourcing our entire Mastodon implementation.</p>
</div>



<h2 id="Conclusion">Conclusion</h2>



<div><p>I’ve covered a lot in this post, but I’ve barely scratched the surface on Rama and our Mastodon implementation. For example, I didn’t mention “fine-grained reactivity”, a new capability provided by Rama that’s never existed before. It allows for true incremental reactivity from the backend up through the frontend. Among other things it will enable UI frameworks to be fully incremental instead of doing expensive diffs to find out what changed. We use reactivity in our Mastodon implementation to power much of <a href="https://docs.joinmastodon.org/methods/streaming/">Mastodon’s streaming API</a>.</p>
<p>I also didn’t mention Rama’s integration API. Because of my description of Rama as being able to build an entire backend on its own, you may have the impression that Rama is an “all-or-nothing” tool. However, just because Rama can do so much doesn’t mean it has to be used to do everything. We’ve designed Rama to be able to seamlessly integrate with any other tool (e.g. databases, queues, monitoring systems, etc.). This allows Rama to be introduced gradually into any architecture.</p>
</div>



<p>To reiterate what’s to come: in one week we will be releasing the full Rama documentation as well as a build of Rama that exposes the full API for use with

<code>InProcessCluster</code>

, and in two weeks we will be fully open-sourcing our Mastodon implementation (which can run on

<code>InProcessCluster</code>

). Additionally, we will be publishing more posts exploring Rama and our Mastodon implementation in greater depth.</p>



<div><p>You can keep track of developments with Rama by joining <a href="https://redplanetlabs.us13.list-manage.com/subscribe?u=68cd3e63bd4533d0db57922c5&amp;id=fae70c7c5b">our newsletter</a> or following us on Twitter at <a href="https://twitter.com/redplanetlabs">@redplanetlabs</a>. We’ve also started the Google group <a href="https://groups.google.com/u/1/g/rama-user">rama-user</a>, where you can discuss Rama or ask questions.</p>
<p>Lastly, Red Planet Labs will be starting a private beta in the coming months to give companies access to the full version of Rama. We plan to work closely with our private beta users to help them build new systems or reimplement existing systems at massively reduced cost. We will be releasing more details on the private beta later, but you can <a href="https://docs.google.com/forms/d/e/1FAIpQLSfrhmBwI0YAeaL8u4XmgfscW4UIUUDp2ZHSs4KmPH_TaDt1QQ/viewform">apply here</a> in the meantime.</p>
</div>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Code Is Not Literature (2014) (135 pts)]]></title>
            <link>https://gigamonkeys.com/code-reading/</link>
            <guid>37134520</guid>
            <pubDate>Tue, 15 Aug 2023 14:36:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gigamonkeys.com/code-reading/">https://gigamonkeys.com/code-reading/</a>, See on <a href="https://news.ycombinator.com/item?id=37134520">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                
                <p>I have started code reading groups at the last two companies I’ve worked at, Etsy and Twitter, and some folks have asked for my advice about code reading and running code reading groups. Tl;dr: don’t start a code reading group. What you should start instead I’ll get to in a moment but first I need to explain how I arrived at my current opinion.</p>
                <p>As a former English major and a sometimes writer, I had always been drawn to the idea that code is like literature and that we ought to learn to write code the way we learn to write English: by reading good examples. And I’m certainly not the only one to have taken this point of view—Donald Knuth, in addition to his work on <i>The Art of Computer Programming</i> and TeX, has long been a proponent of what he calls Literate Programming and has published several of his large programs as books.</p>
                <p>On the other hand, long before I got to Etsy and started my first code reading group I had in hand several pieces of evidence that should have suggested to me that this was the wrong way to look at things.</p>
                <p>First, when I did my book of interviews with programmers, <a href="http://www.codersatwork.com/">Coders at Work</a>, I asked pretty much everyone about code reading. And while most of them said it was important and that programmers should do it more, when I asked them about what code they had read recently, very few of them had any great answers. Some of them had done some serious code reading as young hackers but almost no one seemed to have a regular habit of reading code. Knuth, the great synthesizer of computer science, does seem to read a lot of code and Brad Fitzpatrick was able to talk about several pieces of open source code that he had read just for the heck of it. But they were the exceptions.</p>
                <p>If that wasn’t enough, after I finished <i>Coders</i> I had a chance to <a href="http://www.gigamonkeys.com/code-quarterly/2011/hal-abelson/">interview Hal Abelson</a>, the famous MIT professor and co-author of the <i>Structure and Interpretation of Computer Programs</i>. The first time I talked to him I asked my usual question about reading code and he gave the standard answer—that it was important and we should do it more. But he too failed to name any code he had read recently other than code he was obliged to: reviewing co-workers’ code at Google where he was on sabbatical and grading student code at MIT. Later I asked him about this disconnect:</p>
                <blockquote>
                <div>
                    <p><i>Seibel:</i> I’m still curious about this split between what people say and what they actually do. Everyone says, “People should read code” but few people seem to actually do it. I’d be surprised if I interviewed a novelist and asked them what the last novel they had read was, and they said, “Oh, I haven’t really read a novel since I was in grad school.” Writers actually read other writers but it doesn’t seem that programmers really do, even though we say we should.</p>
                    <p><i>Abelson:</i> Yeah. You’re right. But remember, a lot of times you crud up a program to make it finally work and do all of the things that you need it to do, so there’s a lot of extraneous stuff around there that isn’t the core idea.</p>
                    <p><i>Seibel:</i> So basically you’re saying that in the end, most code isn’t worth reading?</p>
                    <p><i>Abelson:</i> Or it’s built from an initial plan or some kind of pseudocode. A lot of the code in books, they have some very cleaned-up version that doesn’t do all the stuff it needs to make it work.</p>
                    <p><i>Seibel:</i> I’m thinking of the preface to SICP, where it says, “programs must be written for people to read and only incidentally for machines to execute.” But it seems the reality you just described is that in fact, most programs are written for machines to execute and only incidentally, if at all, for people to read.</p>
                    <p><i>Abelson:</i> Well, I think they start out for people to read, because there’s some idea there. You explain stuff. That’s a little bit of what we have in the book. There are some fairly significant programs in the book, like the compiler. And that’s partly because we think the easiest way to explain what it’s doing is to express that in code.</p>
                </div>
                </blockquote>
                <p>Yet somehow even this explicit acknowledgement that most real code isn’t actually in a form that can be simply read wasn’t enough to lead me to abandon the literature seminar model when I got to Etsy. For our first meeting I picked Jeremy Ashkenas’s backbone.js because many of the Etsy developers would be familiar with Javascript and because I know Jeremy is particularly interested in writing readable code. I still envisioned something like a literature seminar but I figured that a lot of people wouldn’t actually have done the reading in advance (well, maybe not so different from a literature seminar) so I decided to start things off by presenting the code myself before the group discussion.</p>
                <p>As I prepared my presentation, I found myself falling into my usual pattern when trying to really understand a piece of code—in order to grok it I have to essentially rewrite it. I’ll start by renaming a few things so they make more sense to me and then I’ll move things around to suit my ideas about how to organize code. Pretty soon I’ll have gotten deep into the abstractions (or lack thereof) of the code and will start making bigger changes to the structure of the code. Once I’ve completely rewritten the thing I usually understand it pretty well and can even go back to the original and understand it too. I have always felt kind of bad about this approach to code reading but it's the only thing that's ever worked for me.</p>
                <p>My presentation to the code reading group started with stock backbone.js and then walked through the changes I would make to it to make it, by my lights, more understandable. At one point I asked if people thought we should move on to the group discussion but nobody seemed very interested. Hopefully seeing my refactoring gave people some of the same insights into the underlying structure of the original that I had obtained by doing the refactoring.</p>
                <p>The second meeting of the Etsy code reading group featured Avi Bryant demonstrating how to use the code browsing capabilities of Smalltalk to navigate through some code. In that case, because few of the Etsy engineers had any experience with Smalltalk, we had no expectation that folks would read the code in advance. But the presentation was an awesome chance for folks to get exposed to the power of the Smalltalk development environment and for me to heckle Avi about Smalltalk vs Lisp differences.</p>
                <hr>
                <p>When I got to Twitter I inexplicably still had the literature seminar model in mind even though neither of the two meetings of the Etsy reading group—which folks seemed to like pretty well—followed that model at all. When I sent out the email inviting Twitter engineers to join a code reading group the response was pretty enthusiastic. The first meeting was, yet again, a presentation of some code, in this case the internals of the Scala implementation of Future that is used throughout Twitter’s many services, presented by Marius Eriksen, who wrote most of it.</p>
                <p>It was sometime after that presentation that I finally realized the obvious: code is not literature. We don’t read code, we <i>decode</i> it. We examine it. A piece of code is not literature; it is a specimen. Knuth said something that should have pointed me down this track when I asked him about his own code reading:</p>
                <blockquote>
                <p><i>Knuth:</i> But it’s really worth it for what it builds in your brain. So how do I do it? There was a machine called the Bunker Ramo 300 and somebody told me that the Fortran compiler for this machine was really amazingly fast, but nobody had any idea why it worked. I got a copy of the source-code listing for it. I didn’t have a manual for the machine, so I wasn’t even sure what the machine language was.</p>
                <p>But I took it as an interesting challenge. I could figure out <code>BEGIN</code> and then I would start to decode. The operation codes had some two-letter mnemonics and so I could start to figure out “This probably was a load instruction, this probably was a branch.” And I knew it was a Fortran compiler, so at some point it looked at column seven of a card, and that was where it would tell if it was a comment or not.</p>
                <p>After three hours I had figured out a little bit about the machine. Then I found these big, branching tables. So it was a puzzle and I kept just making little charts like I’m working at a security agency trying to decode a secret code. But I knew it worked and I knew it was a Fortran compiler—it wasn’t encrypted in the sense that it was intentionally obscure; it was only in code because I hadn’t gotten the manual for the machine.</p>
                <p>Eventually I was able to figure out why this compiler was so fast. Unfortunately it wasn’t because the algorithms were brilliant; it was just because they had used unstructured programming and hand optimized the code to the hilt.</p>
                <p>It was just basically the way you solve some kind of an unknown puzzle—make tables and charts and get a little more information here and make a hypothesis. In general when I’m reading a technical paper, it’s the same challenge. I’m trying to get into the author’s mind, trying to figure out what the concept is. The more you learn to read other people’s stuff, the more able you are to invent your own in the future, it seems to me.</p>
                </blockquote>
                <p>He’s not describing reading literature; he’s describing a scientific investigation. So now I have a new mode for how people should get together to gain insights from code which I explained to the Twitter code reading group like this:</p>
                <blockquote>
                <p>Preparing for the talk I’m going to give to the Girls who Code cohort, I started thinking about what to tell them about code reading and code they should read. And once again it struck me that for all the lip service we pay to the idea of reading code, most programmers really don’t read that much code, at least not just for the sake of reading it. As a simple proof: name me one piece of code that you’ve read and that you can be reasonably sure that most other good programmers will have read or will at least have heard of. Not many, right? Probably none.</p>
                <p>But then it hit me. Code is not literature and we are not readers. Rather, interesting pieces of code are specimens and we are naturalists. So instead of trying to pick out a piece of code and reading it and then discussing it like a bunch of Comp Lit. grad students, I think a better model is for one of us to play the role of a 19th century naturalist returning from a trip to some exotic island to present to the local scientific society a discussion of the crazy beetles they found: “Look at the antenna on this monster! They look incredibly ungainly but the male of the species can use these to kill small frogs in whose carcass the females lay their eggs.”</p>
                <p>The point of such a presentation is to take a piece of code that the presenter has understood deeply and for them to help the audience understand the core ideas by pointing them out amidst the layers of evolutionary detritus (a.k.a. kluges) that are also part of almost all code. One reasonable approach might be to show the real code and then to show a stripped down reimplementation of just the key bits, kind of like a biologist staining a specimen to make various features easier to discern.</p>
                <p>The ideal presentation should be aimed at an audience of gentleman and lady programmers—smart, and generally capable but without, necessarily, any specific knowledge of the domain from which the code comes. Presentations should provide enough context for the audience to to understand what the code is and should explain any details of the implementation language that may be obscure to the average programmer.</p>
                </blockquote>
                <p>Since I had my epiphany we’ve had several meetings of the code reading group, now known as the Royal Society of Twitter for Improving Coding Knowledge, along the new lines. We’re still learning about the best ways to present code but the model feels very right. Also, I no longer feel bad about my dissection-based approach to reading code.</p>
                <p>The biggest lesson so far is that code is very dense. A half hour presentation is just enough time to present maybe a dozen meaty lines of code and one main idea. It is also almost certainly the case that the presenters, who have to actually really dig down into a piece of code, get more out of it than anybody. But it does seem that a good presentation can at least expose people to the main ideas and maybe give them a head start if they do decide to read the code themselves.</p>
                <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox finally outperforming Google Chrome in SunSpider (589 pts)]]></title>
            <link>https://www.phoronix.com/news/Firefox-Faster-SunSpider</link>
            <guid>37134092</guid>
            <pubDate>Tue, 15 Aug 2023 13:58:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/Firefox-Faster-SunSpider">https://www.phoronix.com/news/Firefox-Faster-SunSpider</a>, See on <a href="https://news.ycombinator.com/item?id=37134092">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="MOZILLA" src="https://www.phoronix.com/assets/categories/mozilla.webp" width="100" height="100"></p><p>
Mozilla developers are celebrating that they are now faster than Google Chrome with the SunSpider JavaScript benchmark, although that test has been superseded by the JetStream benchmark.
</p><p>
Last week a new Firefox Nightly News was published that outlines that "We’re now apparently beating Chrome on the SunSpider JavaScript benchmark!" The provided numbers now show Firefox easily beating Chrome in this decade-old JavaScript benchmark.
</p><p><img src="https://www.phoronix.net/image.php?id=2023&amp;image=firefox_faster_sunspider" alt="SunSpider browser benchmark results"></p>
<p>The benchmarks come from <a href="https://arewefastyet.com/win10/benchmarks/overview?numDays=60">AreWeFastYet.com</a>. Meanwhile for the newer and more demanding JetStream 2.0 benchmark, Google Chrome continues to win easily over Firefox:
</p><p><img src="https://www.phoronix.net/image.php?id=2023&amp;image=chrome_jetstream_win" alt="Chrome much faster in JetStream 2"></p>
<p>Besides Firefox running the JavaScript SunSpider benchmark much faster over the roughly past month, there's been work on the HTTP/2 upload speed improvements, and various other enhancements.
</p><p>
Learn about the latest Firefox Nightly build advancements via the <a href="https://blog.nightly.mozilla.org/2023/08/10/a-view-to-a-better-faster-web-these-weeks-in-firefox-issue-143/">Firefox Nightly News</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stellar Developers (602 pts)]]></title>
            <link>https://stellarsamurai.com/</link>
            <guid>37133872</guid>
            <pubDate>Tue, 15 Aug 2023 13:38:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stellarsamurai.com/">https://stellarsamurai.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37133872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="MainContent" role="main" tabindex="-1">
      <div id="shopify-section-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24"><p>
        <h2 id="SectionHeading-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24">
          Favorite Categories
        </h2></p><slider-component>
      <ul id="Slider-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24" role="list"><li id="Slide-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24-1" data-cascade="">


          </li><li id="Slide-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24-2" data-cascade="">


          </li><li id="Slide-template--19422400577876__41a3ff50-b491-469f-8cd8-eaebc2dacd24-3" data-cascade="">


          </li></ul></slider-component></div><div id="shopify-section-template--19422400577876__256b0e40-e01d-4353-8ed0-5b40603a99f1">
    <div>
      <p><img src="https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=1500" alt="" srcset="https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=198 198w, https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=432 432w, https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=642 642w, https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=900 900w, https://stellarsamurai.com/cdn/shop/files/StellarSamuraiGrafittiW1.png?v=1691489553&amp;width=1284 1284w" width="1500" height="1500" loading="lazy" sizes="(min-width: 1200px) 659.9868002639947px,
              (min-width: 750px) calc((100vw - 130px) / 1.667), calc((100vw - 50px) / 1.667)">
</p>
    </div>
    <div id="ImageWithText--template--19422400577876__256b0e40-e01d-4353-8ed0-5b40603a99f1"><h2>
                Our Vision
              </h2><div>
                <p>We aim to portray the essence of ancient warriors know as Samurai into everyday clothing and accessories.</p><p>Each  design holds a story, wisdom and energy that we want to share with the world.</p><p>Unique clothing, accessories and home décor that gives a new feeling and an elegant touch. </p>
              </div><p><a href="https://stellarsamurai.com/pages/about">
                  Learn more about us
                </a></p></div>
  </div><div id="shopify-section-template--19422400577876__c5052349-f3ac-4407-aee0-d90ebc946611"><p>As a part of our launch, all customers get:</p><h2 data-cascade="">
                20% Discount for orders over 150$!
              </h2></div><div id="shopify-section-template--19422400577876__9207cebc-a5dc-4b77-8753-369fdc80294f">
    <h2>
      Find your style!
    </h2>
    
  </div><div data-cascade="" id="shopify-section-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3"><slider-component>
      <ul id="Slider-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3" role="list"><li id="Slide-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3-1" data-cascade="">
            <div><h3>Quality</h3><p>Each product is tested and reviewed before it reaches your home. We do our best to ensure the quality of each item meets our standards.</p></div>
          </li><li id="Slide-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3-2" data-cascade="">
            <div><h3>Durability</h3><p>We optimize for better and not cheaper materials. This type of approach makes sure that each design will last for as long as possible.</p></div>
          </li><li id="Slide-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3-3" data-cascade="">
            <div><h3>Style</h3><p>Whether it's a backpack, T-Shirt or phone case each product holds it's own unique look that catches the eye and makes you stand out.</p></div>
          </li><li id="Slide-template--19422400577876__195040ff-b3b8-4bbb-86a4-1e9bd99b70b3-4" data-cascade="">
            <div><h3>Uniqueness</h3><p>No two designs are the same. Explore our various palettes and be pleasantly surprised with the volume of variety that we have prepared!</p></div>
          </li></ul></slider-component>
    
  </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why host your own LLM? (168 pts)]]></title>
            <link>http://marble.onl/posts/why_host_your_own_llm.html</link>
            <guid>37133504</guid>
            <pubDate>Tue, 15 Aug 2023 13:06:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://marble.onl/posts/why_host_your_own_llm.html">http://marble.onl/posts/why_host_your_own_llm.html</a>, See on <a href="https://news.ycombinator.com/item?id=37133504">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>Andrew Marble<br><a href="http://marble.onl/">marble.onl</a><br>andrew@willows.ai<br>August 13, 2023</p>
<p>In the Terminator movies, good relationships beat technological superiority. Kyle Reese and Sarah Connor outwit the advanced T-800 who in turn helps Sarah and John beat the ultra-advanced T-1000. OpenAI’s GPT-4 is currently the most advanced publicly available language model. There are also analyses showing it’s generally cheaper to run than self-hosting comparable models. I want to argue that despite everything OpenAI’s models have going for them, it’s worth considering self-hosting anyway, especially if you’re building a product or an internal capability.</p>
<p>If you’re using language models for custom applications, you can use an API from companies like OpenAI or Anthropic, where you submit your prompt, get a response, and pay usage based fees. Or you can configure your own model and host it locally or in the cloud. There are many models available for self-hosting. A few recent analyses have made a case for using OpenAI’s API based on cost and performance<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a><sup>,</sup><a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Very detailed cost calculations are possible, but the obvious cost advantage of a usage based API is that you only pay for the hardware when you use it. Most self-hosted applications will be challenged to get good utilization from dedicated GPUs and so are paying a lot for idle time.</p>
<p>There’s a lot of subtlety in gauging performance – personally I think there’s not a 1:1 relationship between rankings in the various benchmarks and “leaderboards”<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> and performance on specific commercially relevant tasks. But GPT-4 is unequivocally better than the rest across a wide range of skills and only the best publicly available models compete with Claude (Anthropic’s model) and GPT-3.5.</p>
<p>Despite the advantages, there is still a compelling case for working with publicly available models. (Note I don’t say open source, many have other limitations that disqualify them from being labeled as such<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>, but I won’t dwell on that here.) To me it boils down to a the “relationship”. Using APIs means you’re a taker of whatever OpenAI et al. are offering. Model features, customizations, values (censorship and world view) etc. are all dictated by those companies. You can only build a front-end. This also means you don’t have access to internal states and so are limited, for example in applying advanced accountability techniques or guardrails on top. All of this could be good, it means you don’t have to worry about it. But it also makes whatever you build utterly dependent on a start-up company.</p>
<p>For “relationship-based” development, there are good reasons to use self-hosted models. Having control over the model architecture and weights removes uncertainty about future changes, and means you don’t have to take what OpenAI decides to give you. There is a rich ecosystem of different models to experiment with, as well as the ability to customize – for example by fine-tuning on your own terms. The construct ultimately lets you build a long-term relationship with your AI model and adapt your product around it, having clarity that what you build is going to keep working with the model that you’ve chosen and giving you control over when and if you decide to make changes. It lets you build something that isn’t just a front-end on somebody else’s language model but is deeply integrated.</p>
<p>Also, for many applications, the well-rounded superiority of a GPT-like model is not what’s driving value. Running a model as big as GPT-4 is potentially $10,000’s per month. But it’s possible to run 7B and 13B models (models with 7 and 13 billion parameters, common sizes for LLaMA and other public models) on a laptop. These models are big enough to perform many tasks competently and can be cost-effective as part of local systems.</p>
<p>“Responsible” use of AI has many meanings. Tech companies have often focused on political correctness and superficial notions of bias, largely to avoid controversy in broadly capable public models like chat-GPT. For many applications, particularly specialized knowledge work<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>, those concerns are mostly irrelevant and give way to real issues about factual accuracy, completeness, or simply staying on-topic. Many techniques for “keeping models in line” require access to internal states, gradients, and intermediate outputs<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Using an API-based model limits the kind of experimentation and augmentation that is possible.</p>
<p>The same holds true for various optimizations such as caching internal model states, as well as model fine-tuning. APIs offer options, but they are limited compared to what is available. The technology is evolving so quickly still that new models and techniques are becoming available every day. For those that are using the LLM as a tightly integrated part of a product or tool, the only way to have the flexibility to evolve with the technology is to have a self-hosted model.</p>
<p>An additional aspect of the fast pace of change in language models right now is that the skills and knowledge required to work with the technology are evolving quickly. Working with self-hosted models gives institutional and individual experience in this evolving landscape, in a way that APIs don’t. For professional development of employees as well as adaptability to change, keeping “AI” at a deeper technical level is important for many companies, particularly those that are building applications. It’s not a mature technology, and part of the “moat” that we practitioners have is simply knowing what’s going on. I’ll actually go further and say that any organization making nontrivial use of AI should internally or through advisers have access to some deep knowledge of the technology, not just the API reference, to be able to understand what it fundamentally does best. As AI gets commodified and hyped-up, there often ends up being a big disconnect between what it can do and what it’s used or proposed for.</p>
<p>In a few years, I expect the landscape will look very different – there will be agreed upon things that are critical to be able to do with a model, and APIs will support this. For a new, still experimental, and rapidly evolving technology, real participation requires deep access to the models and code. This doesn’t mean that all companies or products require such access – there are many valuable things that can be built on top of an API and would probably be a waste of time to self-host. But these are different kinds of products.</p>
<p>Back to the Terminator, Reese and the T-800 both built strong relationships that led to their successful completion of their missions. The Skynet-tasked Terminators just went around flexing their superior technological prowess, and it wasn’t enough to win the day. Part of building the relationships is access. I know it’s a silly analogy, but I believe the same is true with these models, it’s about being able to deeply understand the strengths of the tool and built something tightly integrated, and you can’t do that with an API.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://betterprogramming.pub/you-dont-need-hosted-llms-do-you-1160b2520526">https://betterprogramming.pub/you-dont-need-hosted-llms-do-you-1160b2520526</a><a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="https://www.cursor.so/blog/llama-inference">https://www.cursor.so/blog/llama-inference</a><a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard</a><a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a href="http://marble.onl/posts/software-licenses-masquerading-as-open-source.html">http://marble.onl/posts/software-licenses-masquerading-as-open-source.html</a><a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>There is a wide range of literature and research into model accountability. For a narrow example, see “The Internal State of an LLM Knows When its Lying” <a href="https://arxiv.org/pdf/2304.13734.pdf">https://arxiv.org/pdf/2304.13734.pdf</a> but also <a href="https://arxiv.org/pdf/2307.00175.pdf">https://arxiv.org/pdf/2307.00175.pdf</a><a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Llama2 Embeddings FastAPI Server (116 pts)]]></title>
            <link>https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service</link>
            <guid>37133163</guid>
            <pubDate>Tue, 15 Aug 2023 12:31:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service">https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service</a>, See on <a href="https://news.ycombinator.com/item?id=37133163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Llama2 Embeddings FastAPI Service</h2>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">The Llama2 Embedding Server is designed to facilitate and optimize the process of obtaining text embeddings using different LLMs via llama_cpp and langchain. To avoid wasting computation, these embeddings are cached in SQlite and retrieved if they have already been computed before. To speed up the process of loading multiple LLMs, optional RAM Disks can be used, and the process for creating and managing them is handled automatically for you.</p>
<p dir="auto">Some additional useful endpoints are provided, such as computing semantic similarity between submitted text strings (using various measures of similarity, such as cosine similarity, but also more esoteric measures like <a href="https://blogs.sas.com/content/iml/2021/05/03/examples-hoeffding-d.html" rel="nofollow">Hoeffding's D</a> and <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705121008297" rel="nofollow">HSIC</a>, and semantic search across all your cached embeddings using FAISS vector searching.</p>
<p dir="auto">You can also submit a plaintext file or PDF file (not requiring OCR) and get back a zip file containing all of the embeddings for each sentence as JSON, organized in various ways such <code>records</code>, <code>table</code>, etc. (i.e., all the export options from the Pandas <code>to_json()</code> function). The results of getting the embeddings for all sentences in a document can be returned either as a zip file containing a JSON file (so it won't crash Swagger among other things), or as a direct JSON response if you're using curl or similar.</p>
<p dir="auto">In addition to fixed-sized embedding vectors, we also expose functionality that allows you to get back token-level embeddings, where each token in the input stream is embedded with its context in the string as a full sized vector, thus producing a matrix that has a number of rows equal to the number of tokens in the input string. This includes far more nuanced information about the contents of the string at the expense of much greater compute and storage requirements. The other drawback is that, instead of having the same sized output for every string, regardless of length (which makes it very easy to compare unequal length strings using cosine similarity and other measures), the token-level embedding matrix obviously differs in dimensions for two different strings if the strings have different numbers of tokens. To deal with this, we introduce combined feature vectors, which compute the column-wise mean, min, max, and std. deviation of the token-level emeddding matrix, and concatenate these together in to a single huge matrix; this allows you to compare strings of different lengths while still capturing more nuance. The combined results, including the embedding matrix and associated combined feature vector, can similarly be returned as either a zip file or direct JSON response.</p>
<h2 tabindex="-1" dir="auto">Screenshot</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service/raw/main/Llama2-FastAPI-Service-%20Swagger%20Screenshot.png"><img src="https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service/raw/main/Llama2-FastAPI-Service-%20Swagger%20Screenshot.png" alt="Llama2 FastAPI Service Swagger UI"></a></p>
<p dir="auto"><em>TLDR:</em> If you just want to try it very quickly on a fresh Ubuntu 22+ machine (warning, this will install docker using apt):</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service
cd llama_embeddings_fastapi_service
chmod +x setup_dockerized_app_on_fresh_machine.sh
sudo ./setup_dockerized_app_on_fresh_machine.sh"><pre>git clone https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service
<span>cd</span> llama_embeddings_fastapi_service
chmod +x setup_dockerized_app_on_fresh_machine.sh
sudo ./setup_dockerized_app_on_fresh_machine.sh</pre></div>
<p dir="auto">Then open a browser to <code>&lt;your_static_ip_address&gt;:8089</code> if you're using a VPS.</p>
<p dir="auto">Or to <code>localhost:8089</code> if you're using your own machine-- but, really, you should never run untrusted code with sudo on your own machine! Just get a cheap VPS to experiment with for $30/month.</p>
<p dir="auto">Watch the the automated setup process in action <a href="https://asciinema.org/a/601603" rel="nofollow">here</a>.</p>
<hr>
<h2 tabindex="-1" dir="auto">Features</h2>
<ol dir="auto">
<li><strong>Text Embedding Computation</strong>: Utilizes pre-trained LLama2 and other LLMs via llama_cpp and langchain to generate embeddings for any provided text, including token-level embeddings that capture more nuanced information about the content.</li>
<li><strong>Embedding Caching</strong>: Efficiently stores and retrieves computed embeddings in SQLite, minimizing redundant computations. It supports caching both fixed-sized embedding vectors and token-level embeddings.</li>
<li><strong>Advanced Similarity Measurements and Retrieval</strong>: Offers various measures of similarity like cosine similarity, Hoeffding's D, HSIC, and semantic search across cached embeddings using FAISS vector searching.</li>
<li><strong>File Processing for Documents</strong>: Submit plaintext files or PDFs (not requiring OCR) to get back a ZIP file or JSON response containing embeddings for each sentence, organized in various ways like <code>records</code>, <code>table</code>, etc., using Pandas <code>to_json()</code> function.</li>
<li><strong>Token-Level Embeddings and Combined Feature Vectors</strong>: Provides token-level embeddings to capture the context of each token in the input string. Introduces combined feature vectors by computing the column-wise mean, min, max, and std. deviation of the token-level embedding matrix, allowing comparison of unequal length strings.</li>
<li><strong>RAM Disk Usage</strong>: Optionally uses RAM Disk to store models for faster access and execution. Automatically handles the creation and management of RAM Disks.</li>
<li><strong>Robust Exception Handling</strong>: Features comprehensive exception management to ensure system resilience.</li>
<li><strong>Interactive API Documentation</strong>: Integrates with Swagger UI for an interactive and user-friendly experience, accommodating large result sets without crashing.</li>
<li><strong>Scalability and Concurrency</strong>: Built on the FastAPI framework, handles concurrent requests and supports parallel inference with configurable concurrency levels.</li>
<li><strong>Flexible Configurations</strong>: Offers configurable settings through environment variables and input parameters, including response formats like JSON or ZIP files.</li>
<li><strong>Comprehensive Logging</strong>: Captures essential information with detailed logs, without overwhelming storage or readability.</li>
<li><strong>Support for Multiple Models and Measures</strong>: Accommodates multiple embedding models and similarity measures, allowing flexibility and customization based on user needs.</li>
</ol>
<h2 tabindex="-1" dir="auto">Demo Screen Recording in Action:</h2>
<p dir="auto"><a href="https://asciinema.org/a/39dZ8vv9nkcNygasUl35wnBPq" rel="nofollow">Here</a> is the live console output while I interact with it from the Swagger page to make requests.</p>
<hr>
<h2 tabindex="-1" dir="auto">Requirements:</h2>
<div data-snippet-clipboard-copy-content="fastapi
pydantic
uvicorn
sqlalchemy
python-decouple
psutil
aiosqlite
faiss-cpu
pandas
PyPDF2
python-multipart
python-magic
langchain
scikit-learn
llama-cpp-python
httpx
numba
scipy
hyppo"><pre><code>fastapi
pydantic
uvicorn
sqlalchemy
python-decouple
psutil
aiosqlite
faiss-cpu
pandas
PyPDF2
python-multipart
python-magic
langchain
scikit-learn
llama-cpp-python
httpx
numba
scipy
hyppo
</code></pre></div>
<h2 tabindex="-1" dir="auto">Running the Application</h2>
<p dir="auto">You can run the application using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python llama_2_embeddings_fastapi_server.py"><pre>python llama_2_embeddings_fastapi_server.py</pre></div>
<p dir="auto">The server will start on <code>0.0.0.0</code> at the port defined by the <code>LLAMA_EMBEDDING_SERVER_LISTEN_PORT</code> variable.</p>
<p dir="auto">Access the Swagger UI:</p>
<div data-snippet-clipboard-copy-content="http://localhost:<LLAMA_EMBEDDING_SERVER_LISTEN_PORT>"><pre><code>http://localhost:&lt;LLAMA_EMBEDDING_SERVER_LISTEN_PORT&gt;
</code></pre></div>
<h2 tabindex="-1" dir="auto">Configuration</h2>
<p dir="auto">You can configure the service easily by editing the included <code>.env</code> file. Here's a list of available configuration options:</p>
<ul dir="auto">
<li><code>USE_SECURITY_TOKEN</code>: Whether to use a hardcoded security token. (e.g., <code>True</code>)</li>
<li><code>USE_PARALLEL_INFERENCE_QUEUE</code>: Use parallel processing. (e.g., <code>True</code>)</li>
<li><code>MAX_CONCURRENT_PARALLEL_INFERENCE_TASKS</code>: Maximum number of parallel inference tasks. (e.g., <code>30</code>)</li>
<li><code>DEFAULT_MODEL_NAME</code>: Default model name to use. (e.g., <code>llama2_7b_chat_uncensored</code>)</li>
<li><code>LLM_CONTEXT_SIZE_IN_TOKENS</code>: Context size in tokens for LLM. (e.g., <code>512</code>)</li>
<li><code>LLAMA_EMBEDDING_SERVER_LISTEN_PORT</code>: Port number for the service. (e.g., <code>8089</code>)</li>
<li><code>MINIMUM_STRING_LENGTH_FOR_DOCUMENT_EMBEDDING</code>: Minimum string length for document embedding. (e.g., <code>15</code>)</li>
<li><code>MAX_RETRIES</code>: Maximum retries for locked database. (e.g., <code>10</code>)</li>
<li><code>DB_WRITE_BATCH_SIZE</code>: Database write batch size. (e.g., <code>25</code>)</li>
<li><code>RETRY_DELAY_BASE_SECONDS</code>: Retry delay base in seconds. (e.g., <code>1</code>)</li>
<li><code>JITTER_FACTOR</code>: Jitter factor for retries. (e.g., <code>0.1</code>)</li>
<li><code>USE_RAMDISK</code>: Use RAM disk. (e.g., <code>True</code>)</li>
<li><code>RAMDISK_PATH</code>: Path to the RAM disk. (e.g., <code>"/mnt/ramdisk"</code>)</li>
<li><code>RAMDISK_SIZE_IN_GB</code>: RAM disk size in GB. (e.g., <code>40</code>)</li>
</ul>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">If you'd like to contribute to the project, please submit a pull request.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">This project is licensed under the MIT License.</p>
<hr>
<h2 tabindex="-1" dir="auto">Setup and Configuration</h2>
<h3 tabindex="-1" dir="auto">RAM Disk Configuration</h3>
<p dir="auto">To enable password-less sudo for RAM Disk setup and teardown, edit the <code>sudoers</code> file with <code>sudo visudo</code>. Add the following lines, replacing <code>username</code> with your actual username:</p>
<div data-snippet-clipboard-copy-content="username ALL=(ALL) NOPASSWD: /bin/mount -t tmpfs -o size=*G tmpfs /mnt/ramdisk
username ALL=(ALL) NOPASSWD: /bin/umount /mnt/ramdisk"><pre lang="plaintext"><code>username ALL=(ALL) NOPASSWD: /bin/mount -t tmpfs -o size=*G tmpfs /mnt/ramdisk
username ALL=(ALL) NOPASSWD: /bin/umount /mnt/ramdisk
</code></pre></div>
<p dir="auto">The application provides functionalities to set up, clear, and manage RAM Disk. RAM Disk is used to store models in memory for faster access. It calculates the available RAM and sets up the RAM Disk accordingly. The functions <code>setup_ramdisk</code>, <code>copy_models_to_ramdisk</code>, and <code>clear_ramdisk</code> manage these tasks.</p>
<h2 tabindex="-1" dir="auto">API Endpoints</h2>
<p dir="auto">The following endpoints are available:</p>
<ul dir="auto">
<li><strong>GET <code>/get_list_of_available_model_names/</code></strong>: Retrieve Available Model Names. Retrieves the list of available model names for generating embeddings.</li>
<li><strong>GET <code>/get_all_stored_strings/</code></strong>: Retrieve All Strings. Retrieves a list of all stored strings from the database for which embeddings have been computed.</li>
<li><strong>GET <code>/get_all_stored_documents/</code></strong>: Retrieve All Stored Documents. Retrieves a list of all stored documents from the database for which embeddings have been computed.</li>
<li><strong>POST <code>/get_embedding_vector_for_string/</code></strong>: Retrieve Embedding Vector for a Given Text String. Retrieves the embedding vector for a given input text string using the specified model.</li>
<li><strong>POST <code>/get_token_level_embeddings_matrix_and_combined_feature_vector_for_string/</code></strong>: Retrieve Token-Level Embeddings and Combined Feature Vector for a Given Input String. Retrieve the token-level embeddings and combined feature vector for a given input text using the specified model.</li>
<li><strong>POST <code>/compute_similarity_between_strings/</code></strong>: Compute Similarity Between Two Strings. Compute the similarity between two given input strings using specified model embeddings and a selected similarity measure.</li>
<li><strong>POST <code>/search_stored_embeddings_with_query_string_for_semantic_similarity/</code></strong>: Get Most Similar Strings from Stored Embeddings in Database. Find the most similar strings in the database to the given input "query" text.</li>
<li><strong>POST <code>/get_all_embedding_vectors_for_document/</code></strong>: Get Embeddings for a Document. Extract text embeddings for a document, supporting both plain text and PDF files (PDFs requiring OCR are not supported).</li>
<li><strong>POST <code>/clear_ramdisk/</code></strong>: Clear Ramdisk Endpoint. Clears the RAM Disk if it is enabled.</li>
</ul>
<p dir="auto">For detailed request and response schemas, please refer to the Swagger UI available at the root URL or the section at the end of this <code>README</code>.</p>
<h2 tabindex="-1" dir="auto">Exception Handling</h2>
<p dir="auto">The application has robust exception handling to deal with various types of errors, including database errors and general exceptions. Custom exception handlers are defined for <code>SQLAlchemyError</code> and general <code>Exception</code>.</p>
<h2 tabindex="-1" dir="auto">Logging</h2>
<p dir="auto">Logging is configured at the INFO level to provide detailed logs for debugging and monitoring. The logger provides information about the state of the application, errors, and activities.</p>
<p dir="auto">The logs are stored in a file named <code>llama2_embeddings_fastapi_service.log</code>, and a log rotation mechanism is implemented to handle log file backups. The rotating file handler is configured with a maximum file size of 10 MB, and it keeps up to 5 backup files.</p>
<p dir="auto">When a log file reaches its maximum size, it is moved to the <code>old_logs</code> directory, and a new log file is created. The log entries are also printed to the standard output stream.</p>
<p dir="auto">Here are some details of the logging configuration:</p>
<ul dir="auto">
<li>Log Level: INFO</li>
<li>Log Format: <code>%(asctime)s - %(levelname)s - %(message)s</code></li>
<li>Max Log File Size: 10 MB</li>
<li>Backup Count: 5</li>
<li>Old Logs Directory: <code>old_logs</code></li>
</ul>
<p dir="auto">Additionally, the log level for SQLAlchemy's engine is set to WARNING to suppress verbose database logs.</p>
<h2 tabindex="-1" dir="auto">Database Structure</h2>
<p dir="auto">The application uses a SQLite database via SQLAlchemy ORM. Here are the data models used, which can be found in the <code>embeddings_data_models.py</code> file:</p>
<h3 tabindex="-1" dir="auto">TextEmbedding Table</h3>
<p dir="auto">This table stores individual text embeddings.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>text</code>: Text for which the embedding was computed</li>
<li><code>text_hash</code>: Hash of the text, computed using SHA3-256</li>
<li><code>model_name</code>: Model used to compute the embedding</li>
<li><code>embedding_json</code>: The computed embedding in JSON format</li>
<li><code>ip_address</code>: Client IP address</li>
<li><code>request_time</code>: Timestamp of the request</li>
<li><code>response_time</code>: Timestamp of the response</li>
<li><code>total_time</code>: Total time taken to process the request</li>
<li><code>document_id</code>: Foreign Key referencing the DocumentEmbedding table</li>
<li>Unique Constraint on <code>text_hash</code> and <code>model_name</code></li>
</ul>
<h3 tabindex="-1" dir="auto">DocumentEmbedding Table</h3>
<p dir="auto">This table stores embeddings for entire documents.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>document_id</code>: Foreign Key referencing the Documents table</li>
<li><code>filename</code>: Name of the document file</li>
<li><code>mimetype</code>: MIME type of the document file</li>
<li><code>file_hash</code>: Hash of the file</li>
<li><code>model_name</code>: Model used to compute the embedding</li>
<li><code>file_data</code>: Binary data of the original file</li>
<li><code>document_embedding_results_json</code>: The computed embedding results in JSON format</li>
<li><code>ip_address</code>: Client IP address</li>
<li><code>request_time</code>: Timestamp of the request</li>
<li><code>response_time</code>: Timestamp of the response</li>
<li><code>total_time</code>: Total time taken to process the request</li>
<li>Unique Constraint on <code>file_hash</code> and <code>model_name</code></li>
</ul>
<h3 tabindex="-1" dir="auto">Document Table</h3>
<p dir="auto">This table represents a document.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>model_name</code>: Model name associated with the document</li>
<li><code>document_hash</code>: Hash of the document (concatenation of specific attributes from the <code>document_embeddings</code> relationship)</li>
</ul>
<h3 tabindex="-1" dir="auto">TokenLevelEmbedding Table</h3>
<p dir="auto">This table stores token-level embeddings.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>token</code>: Token for which the embedding was computed</li>
<li><code>token_hash</code>: Hash of the token, computed using SHA3-256</li>
<li><code>model_name</code>: Model used to compute the embedding</li>
<li><code>token_level_embedding_json</code>: The computed token-level embedding in JSON format</li>
<li><code>ip_address</code>: Client IP address</li>
<li><code>request_time</code>: Timestamp of the request</li>
<li><code>response_time</code>: Timestamp of the response</li>
<li><code>total_time</code>: Total time taken to process the request</li>
<li><code>token_level_embedding_bundle_id</code>: Foreign Key referencing the TokenLevelEmbeddingBundle table</li>
<li>Unique Constraint on <code>token_hash</code> and <code>model_name</code></li>
</ul>
<h3 tabindex="-1" dir="auto">TokenLevelEmbeddingBundle Table</h3>
<p dir="auto">This table stores token-level embedding bundles.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>input_text</code>: Input text associated with the token-level embeddings</li>
<li><code>input_text_hash</code>: Hash of the input text</li>
<li><code>model_name</code>: Model used to compute the embeddings</li>
<li><code>token_level_embeddings_bundle_json</code>: JSON containing the token-level embeddings</li>
<li><code>ip_address</code>: Client IP address</li>
<li><code>request_time</code>: Timestamp of the request</li>
<li><code>response_time</code>: Timestamp of the response</li>
<li><code>total_time</code>: Total time taken to process the request</li>
<li>Unique Constraint on <code>input_text_hash</code> and <code>model_name</code></li>
</ul>
<h3 tabindex="-1" dir="auto">TokenLevelEmbeddingBundleCombinedFeatureVector Table</h3>
<p dir="auto">This table stores combined feature vectors for token-level embedding bundles.</p>
<ul dir="auto">
<li><code>id</code>: Primary Key</li>
<li><code>token_level_embedding_bundle_id</code>: Foreign Key referencing the TokenLevelEmbeddingBundle table</li>
<li><code>model_name</code>: Model name associated with the combined feature vector</li>
<li><code>combined_feature_vector_json</code>: JSON containing the combined feature vector</li>
<li><code>combined_feature_vector_hash</code>: Hash of the combined feature vector</li>
<li>Unique Constraint on <code>combined_feature_vector_hash</code> and <code>model_name</code></li>
</ul>
<h2 tabindex="-1" dir="auto">Performance Optimizations</h2>
<p dir="auto">This section highlights the major performance enhancements integrated into the provided code to ensure swift responses and optimal resource management.</p>
<h3 tabindex="-1" dir="auto">1. <strong>Asynchronous Programming</strong>:</h3>
<ul dir="auto">
<li><strong>Benefit</strong>: Handles multiple tasks concurrently, enhancing efficiency for I/O-bound operations like database transactions and network requests.</li>
<li><strong>Implementation</strong>: Utilizes Python's <code>asyncio</code> library for asynchronous database operations.</li>
</ul>
<h3 tabindex="-1" dir="auto">2. <strong>Database Optimizations</strong>:</h3>
<ul dir="auto">
<li><strong>Write-Ahead Logging (WAL) Mode</strong>: Enables concurrent reads and writes, optimizing for applications with frequent write demands.</li>
<li><strong>Retry Logic with Exponential Backoff</strong>: Manages locked databases by retrying operations with progressive waiting times.</li>
<li><strong>Batch Writes</strong>: Aggregates write operations for more efficient database interactions.</li>
<li><strong>DB Write Queue</strong>: Uses an asynchronous queue to serialize write operations, ensuring consistent and non-conflicting database writes.</li>
</ul>
<h3 tabindex="-1" dir="auto">3. <strong>RAM Disk Utilization</strong>:</h3>
<ul dir="auto">
<li><strong>Benefit</strong>: Speeds up I/O-bound tasks by prioritizing operations in RAM over disk.</li>
<li><strong>Implementation</strong>: Detects and prioritizes a RAM disk (<code>/mnt/ramdisk</code>) if available, otherwise defaults to the standard file system.</li>
</ul>
<h3 tabindex="-1" dir="auto">4. <strong>Model Caching</strong>:</h3>
<ul dir="auto">
<li><strong>Benefit</strong>: Reduces overhead by keeping loaded models in memory for subsequent requests.</li>
<li><strong>Implementation</strong>: Uses a global <code>model_cache</code> dictionary to store and retrieve models.</li>
</ul>
<h3 tabindex="-1" dir="auto">5. <strong>Parallel Inference</strong>:</h3>
<ul dir="auto">
<li><strong>Benefit</strong>: Enhances processing speed for multiple data units, like document sentences.</li>
<li><strong>Implementation</strong>: Employs <code>asyncio.gather</code> for concurrent inferences, regulated by a semaphore (<code>MAX_CONCURRENT_PARALLEL_INFERENCE_TASKS</code>).</li>
</ul>
<h3 tabindex="-1" dir="auto">6. <strong>Embedding Caching</strong>:</h3>
<ul dir="auto">
<li><strong>Benefit</strong>: Once embeddings are computed for a particular text, they are stored in the database, eliminating the need for re-computation during subsequent requests.</li>
<li><strong>Implementation</strong>: When a request is made to compute an embedding, the system first checks the database. If the embedding for the given text is found, it is returned immediately, ensuring faster response times.</li>
</ul>
<hr>
<h3 tabindex="-1" dir="auto">Dockerized Llama2 Embeddings API Service App</h3>
<p dir="auto">A bash script is included in this repo, <code>setup_dockerized_app_on_fresh_machine.sh</code>, that will automatically do everything for you, including installing docker with apt install.</p>
<p dir="auto">To use it, first make the script executable and then run it like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="chmod +x setup_dockerized_app_on_fresh_machine.sh
sudo ./setup_dockerized_app_on_fresh_machine.sh"><pre>chmod +x setup_dockerized_app_on_fresh_machine.sh
sudo ./setup_dockerized_app_on_fresh_machine.sh</pre></div>
<p dir="auto">If you prefer a manual setup, then read the following instructions:</p>
<h4 tabindex="-1" dir="auto">Prerequisites</h4>
<p dir="auto">Ensure that you have Docker installed on your system. If not, follow these steps to install Docker on Ubuntu:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt-get update
sudo apt-get install docker.io
sudo systemctl start docker
sudo docker --version
sudo usermod -aG docker $USER"><pre>sudo apt-get update
sudo apt-get install docker.io
sudo systemctl start docker
sudo docker --version
sudo usermod -aG docker <span>$USER</span></pre></div>
<p dir="auto">You may need to log out and log back in or restart your system to apply the new group permissions, or use sudo in the following steps to build and run the container.</p>
<h4 tabindex="-1" dir="auto">Setup and Running the Application</h4>
<ol dir="auto">
<li>
<p dir="auto"><strong>Clone the Repository:</strong></p>
<p dir="auto">Clone the Llama2 Embeddings API Service repository to your local machine:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service
cd llama_embeddings_fastapi_service"><pre>git clone https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service
<span>cd</span> llama_embeddings_fastapi_service</pre></div>
</li>
<li>
<p dir="auto"><strong>Build the Docker Image:</strong></p>
<p dir="auto">Build the Docker image using the provided Dockerfile:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker build -t llama-embeddings ."><pre>sudo docker build -t llama-embeddings <span>.</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Run the Docker Container:</strong></p>
<p dir="auto">Run the Docker container, mapping the container's port 8089 to the host's port 8089:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker run -p 8089:8089 llama-embeddings"><pre>sudo docker run -p 8089:8089 llama-embeddings</pre></div>
</li>
<li>
<p dir="auto"><strong>Accessing the Application:</strong></p>
<p dir="auto">The FastAPI application will now be accessible at <code>http://localhost:8089</code> or at the static IP address of your VPS instance if you're running on one (You can get a 10-core, 30gb RAM, 1tb SSD with a static IP running Ubuntu 22.04 at Contabo for around $30/month, which is the cheapest I've found so far).</p>
<p dir="auto">You can interact then with the API using tools like <code>curl</code> or by accessing the FastAPI documentation at <code>http://localhost:8089/docs</code>.</p>
</li>
<li>
<p dir="auto"><strong>Viewing Logs:</strong></p>
<p dir="auto">Logs from the application can be viewed directly in the terminal where you ran the <code>docker run</code> command.</p>
</li>
</ol>
<h4 tabindex="-1" dir="auto">Stopping and Managing the Container</h4>
<ul dir="auto">
<li>To stop the running container, press <code>Ctrl+C</code> in the terminal or find the container ID using <code>docker ps</code> and run <code>sudo docker stop &lt;container_id&gt;</code>.</li>
<li>To remove the built image, use <code>sudo docker rmi llama-embeddings</code>.</li>
</ul>
<hr>
<p dir="auto">Based on the provided code, I'll help you update the <code>Startup Procedures</code> section of your <code>readme.md</code> file. Here's the updated version:</p>
<hr>
<h2 tabindex="-1" dir="auto">Startup Procedures</h2>
<p dir="auto">During startup, the application performs the following tasks:</p>
<ol dir="auto">
<li><strong>Database Initialization</strong>:
<ul dir="auto">
<li>The application initializes the SQLite database, setting up tables and executing important PRAGMAs to optimize performance.</li>
<li>Some of the important SQLite PRAGMAs include setting the database to use Write-Ahead Logging (WAL) mode, setting synchronous mode to NORMAL, increasing cache size to 1GB, setting the busy timeout to 2 seconds, and setting the WAL autocheckpoint to 100.</li>
</ul>
</li>
<li><strong>Initialize Database Writer</strong>:
<ul dir="auto">
<li>A dedicated database writer (<code>DatabaseWriter</code>) is initialized with a dedicated asynchronous queue to handle the write operations.</li>
<li>A set of hashes is created which represents the operations that are currently being processed or have already been processed. This avoids any duplicate operations in the queue.</li>
</ul>
</li>
<li><strong>RAM Disk Setup</strong>:
<ul dir="auto">
<li>If the <code>USE_RAMDISK</code> variable is enabled and the user has the required permissions, the application sets up a RAM Disk.</li>
<li>The application checks if there's already a RAM Disk set up at the specified path, if not, it calculates the optimal size for the RAM Disk and sets it up.</li>
<li>If the RAM Disk is enabled but the user lacks the required permissions, the RAM Disk feature is disabled and the application proceeds without it.</li>
</ul>
</li>
<li><strong>Model Downloads</strong>:
<ul dir="auto">
<li>The application downloads the required models.</li>
</ul>
</li>
<li><strong>Model Loading</strong>:
<ul dir="auto">
<li>Each downloaded model is loaded into memory. If any model file is not found, an error log is recorded.</li>
</ul>
</li>
<li><strong>Build FAISS Indexes</strong>:
<ul dir="auto">
<li>The application creates FAISS indexes for efficient similarity search using the embeddings from the database.</li>
<li>Separate FAISS indexes are built for token-level embeddings.</li>
<li>Associated texts are stored by model name for further use.</li>
</ul>
</li>
</ol>
<p dir="auto">Note:</p>
<ul dir="auto">
<li>If the RAM Disk feature is enabled but the user lacks the required permissions, the application will disable the RAM Disk feature and proceed without it.</li>
<li>For any database operations, if the database is locked, the application will attempt to retry the operation a few times with an exponential backoff and a jitter.</li>
</ul>
<hr>
<h2 tabindex="-1" dir="auto">Endpoint Functionality and Workflow Overview</h2>
<p dir="auto">Here's a detailed breakdown of the main endpoints provided by the FastAPI server, explaining their functionality, input parameters, and how they interact with underlying models and systems:</p>
<h3 tabindex="-1" dir="auto">1. <code>/get_embedding_vector_for_string/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Retrieve the embedding vector for a given input text string using the specified model.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>text</code>: The input text for which the embedding vector is to be retrieved.</li>
<li><code>model_name</code>: The model used to calculate the embedding (optional, will use the default model if not provided).</li>
<li><code>token</code>: Security token (optional).</li>
<li><code>client_ip</code>: Client IP address (optional).</li>
</ul>
<h4 tabindex="-1" dir="auto">Workflow</h4>
<ol dir="auto">
<li><strong>Retrieve Embedding</strong>: The function retrieves or computes the embedding vector for the provided text using the specified or default model.</li>
<li><strong>Return Result</strong>: The embedding vector for the input text string is returned in the response.</li>
</ol>
<h3 tabindex="-1" dir="auto">2. <code>/compute_similarity_between_strings/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Compute the similarity between two given input strings using specified model embeddings and a selected similarity measure.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>text1</code>: The first input text.</li>
<li><code>text2</code>: The second input text.</li>
<li><code>model_name</code>: The model used to calculate embeddings (optional).</li>
<li><code>similarity_measure</code>: The similarity measure to be used. It can be <code>cosine_similarity</code>, <code>hoeffdings_d</code>, or <code>hsic</code> (optional, default is <code>cosine_similarity</code>).</li>
<li><code>token</code>: Security token (optional).</li>
</ul>
<h4 tabindex="-1" dir="auto">Workflow</h4>
<ol dir="auto">
<li><strong>Retrieve Embeddings</strong>: The embeddings for <code>text1</code> and <code>text2</code> are retrieved or computed using the specified or default model.</li>
<li><strong>Compute Similarity</strong>: The similarity between the two embeddings is calculated using the specified similarity measure.</li>
<li><strong>Return Result</strong>: The similarity score, along with the embeddings and input texts, is returned in the response.</li>
</ol>
<h3 tabindex="-1" dir="auto">3. <code>/search_stored_embeddings_with_query_string_for_semantic_similarity/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Find the most similar strings in the database to the given input "query" text. This endpoint uses a pre-computed FAISS index to quickly search for the closest matching strings.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>query_text</code>: The input text for which to find the most similar string.</li>
<li><code>model_name</code>: The model used to calculate embeddings.</li>
<li><code>number_of_most_similar_strings_to_return</code>: (Optional) The number of most similar strings to return, defaults to 10.</li>
<li><code>token</code>: Security token (optional).</li>
</ul>
<h4 tabindex="-1" dir="auto">Workflow</h4>
<ol dir="auto">
<li><strong>Search FAISS Index</strong>: The FAISS index, built on stored embeddings, is searched to find the most similar embeddings to the <code>query_text</code>.</li>
<li><strong>Return Result</strong>: The most similar strings found in the database, along with the similarity scores, are returned in the response.</li>
</ol>
<h3 tabindex="-1" dir="auto">4. <code>/get_all_embedding_vectors_for_document/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Extract text embeddings for a document. This endpoint supports both plain text and PDF files. OCR is not supported.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>file</code>: The uploaded document file (either plain text or PDF).</li>
<li><code>model_name</code>: (Optional) The model used to calculate embeddings.</li>
<li><code>json_format</code>: (Optional) The format of the JSON response.</li>
<li><code>send_back_json_or_zip_file</code>: Whether to return a JSON file or a ZIP file containing the embeddings file (optional, defaults to <code>zip</code>).</li>
<li><code>token</code>: Security token (optional).</li>
</ul>
<h3 tabindex="-1" dir="auto">5. <code>/get_list_of_available_model_names/</code> (GET)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Retrieve the list of available model names for generating embeddings.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>token</code>: Security token (optional).</li>
</ul>
<h3 tabindex="-1" dir="auto">6. <code>/get_all_stored_strings/</code> (GET)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Retrieve a list of all stored strings from the database for which embeddings have been computed.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>token</code>: Security token (optional).</li>
</ul>
<h3 tabindex="-1" dir="auto">7. <code>/get_all_stored_documents/</code> (GET)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Retrieve a list of all stored documents from the database for which embeddings have been computed.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>token</code>: Security token (optional).</li>
</ul>
<h3 tabindex="-1" dir="auto">8. <code>/clear_ramdisk/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Clear the RAM Disk to free up memory.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>token</code>: Security token (optional).</li>
</ul>
<h3 tabindex="-1" dir="auto">9. <code>/get_token_level_embeddings_matrix_and_combined_feature_vector_for_string/</code> (POST)</h3>
<h4 tabindex="-1" dir="auto">Purpose</h4>
<p dir="auto">Retrieve the token-level embeddings and combined feature vector for a given input text using the specified model.</p>
<h4 tabindex="-1" dir="auto">Parameters</h4>
<ul dir="auto">
<li><code>text</code>: The input text for which the embeddings are to be retrieved.</li>
<li><code>model_name</code>: The model used to calculate the embeddings (optional).</li>
<li><code>db_writer</code>: Database writer instance for managing write operations (internal use).</li>
<li><code>req</code>: HTTP request object (optional).</li>
<li><code>token</code>: Security token (optional).</li>
<li><code>client_ip</code>: Client IP address (optional).</li>
<li><code>json_format</code>: Format for JSON response of token-level embeddings (optional).</li>
<li><code>send_back_json_or_zip_file</code>: Whether to return a JSON response or a ZIP file containing the JSON file (optional, defaults to <code>zip</code>).</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The OpenTF Manifesto (317 pts)]]></title>
            <link>https://opentf.org/</link>
            <guid>37133054</guid>
            <pubDate>Tue, 15 Aug 2023 12:19:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opentf.org/">https://opentf.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37133054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
          Terraform was open-sourced in 2014 under the Mozilla Public License (v 2.0) (the “MPL”).
          Over the next ~9 years, it built up a community that included thousands of users, contributors, customers,
          certified practitioners, vendors, and an ecosystem of open-source modules, plugins,
          libraries, and extensions.

          Then, on August 10th, 2023, with little or no advance notice or chance for much, if not all,
          of the community to have any input, HashiCorp switched the license for Terraform from the
          MPL to the Business Source License (v1.1) (the “BSL”), a non-open source license. In our
          opinion, this change threatens the entire community and ecosystem that’s built up around
          Terraform over the last 9 years.
        </p>

        <p>
          Our concern: the BSL license is a poison pill for Terraform.
        </p>

        <p>
          Overnight, tens of thousands of businesses, ranging from one-person shops to the
          Fortune 500, woke up to a new reality where the underpinnings of their infrastructure
          suddenly became a potential legal risk. The BSL and the additional use grant written by
          the HashiCorp team are vague, and now every company, vendor, and developer using Terraform
          has to wonder whether what they are doing could be construed as competitive with HashiCorp’s
          offerings. The FAQ provides some solace for end-customers and systems integrators today,
          but even if you might be in the clear now, how can you build confidence that your usage
          won't violate the license terms in the future? What if your products or HashiCorp's products
          change? What if HashiCorp changes how they interpret competitive? What if they change the
          license again? As a result, everything that uses Terraform is on shaky ground.
        </p>

        <p>
          It is clear to us that under the new license, the thriving ecosystem built up around the
          open source Terraform will dwindle and wither. As developers consider what tools to learn
          and what ecosystems to contribute to, and as companies consider what tools to use to manage
          their infrastructure, more and more, they'll pick alternatives that are genuinely open-source.
          Existing Terraform codebases will turn into outdated liabilities, independent tooling will
          all but disappear, and the community will fracture and disappear.
        </p>

        <p>
          This sort of change also harms all similar open-source projects. Every company and every
          developer now needs to think twice before adopting and investing in an open-source project
          in case the creator suddenly decides to change the license. Imagine if the creators of Linux
          or Kubernetes suddenly switched to a non-open-source license that only permitted
          non-competitive usage.
        </p>

        <p>
          We believe that the essential building blocks of the modern Internet, such as Linux, Kubernetes, 
          and Terraform need to be truly open source: that is the only way to ensure
          that we are building our industry on top of solid and predictable underpinnings.
        </p>

        <p>
          Our goal: ensure Terraform remains truly open source—always.
        </p>

        <p>
          Our aim with this manifesto is to return Terraform to a fully open source license. BSL 
          is <em>not</em> open source, so this would mean moving Terraform back to the MPL license, 
          or some other well-known, widely accepted open source license (e.g., Apache License 2.0). 
          Moreover, we want to be confident that Terraform will always remain open source, so you 
          don't have to worry about another sudden license change putting everything at risk. 
        </p>

        <p>
          Our request to HashiCorp: switch Terraform back to an open source license.
        </p>

        <p>
          We ask HashiCorp to do the right thing by the community: instead of going forward with the
          BSL license change, switch Terraform back to a truly open source license, and commit to keeping
          it that way forever going forward. That way, instead of fracturing the community, we end up with 
          a single, impartial, reliable home for Terraform where the whole community can unite to keep 
          building this amazing ecosystem.
        </p>

        <p>
          Our fallback plan: fork Terraform into a foundation.
        </p>

        <p>
          If HashiCorp is unwilling to switch Terraform back to an open source license, we propose to fork
          the legacy MPL-licensed Terraform and maintain the fork in the foundation. This is similar to how 
          Linux and Kubernetes are managed by foundations (the Linux Foundation and the Cloud Native 
          Computing Foundation, respectively), which are run by multiple companies, ensuring the tool stays 
          truly open source and neutral, and not at the whim of any one company.
        </p>

        <p>
          In particular, we want to create a foundation for Terraform that is:
        </p>

        <ul>
          <li>
            <span>Truly open source</span> - under a well-known and widely-accepted license that companies can trust,
            that won't suddenly change in the future, and isn't subject to the whims of a single vendor
          </li>
          <li>
            <span>Community-driven</span> - so that the community governs the project for the community, where pull
            requests are regularly reviewed and accepted on their merit
          </li>
          <li>
            <span>Impartial</span> - so that valuable features and fixes are accepted based on their value to the community,
            regardless of their impact on any particular vendor
          </li>
          <li>
            <span>Layered and modular</span> - with a programmer-friendly project structure
            to encourage building on top, enabling a new vibrant ecosystem of
            tools and integrations
          </li>
          <li>
            <span>Backwards-compatible</span> - so that the existing code can drive value for years to come
          </li>
        </ul>

        <h2>LIST OF PLEDGING COMPANIES AND PLEDGED RESOURCES:</h2>

        <p>
          We acknowledge that maintaining an open source project such as Terraform takes a considerable investment 
          in terms of time, skill, effort, and coordination. We are grateful to HashiCorp for creating Terraform
          and their leadership in getting it to this point, and to the thousands of community members for their 
          contributions so far. The next step for Terraform must be to remain open source, either by HashiCorp 
          switching it back to a truly open source license or by us forking it into a foundation. Whichever way 
          it turns out, to ensure that there is sufficient investment to grow and evolve Terraform, the 
          signatories below pledge to pool our resources to build a more open, inclusive future 
          for an open source Terraform.
        </p>

        <p>
          If you’re willing to join our cause, please sign the manifesto by
          <a href="https://github.com/opentffoundation/manifesto">creating a
            PR</a> and adding yourself at the bottom of this page and optionally
          let us know how you’d like to help, either as an individual or as an
          organization.
        </p>

        <h2>Pledged Companies</h2>

        <ul>
          <li><a href="https://gruntwork.io/">Gruntwork</a></li>
          <li><a href="https://spacelift.io/">Spacelift</a></li>
          <li><a href="https://env0.com/">env0</a></li>
          <li><a href="https://scalr.com/">Scalr</a></li>
          <li><a href="https://digger.dev/">Digger</a></li>
          <li><a href="https://doppler.com/">Doppler</a></li>
          <li><a href="https://massdriver.cloud/">Massdriver</a></li>
          <li><a href="https://www.qovery.com/">Qovery</a></li>
          <li><a href="https://rivet.gg/">Rivet</a></li>
          <li><a href="https://terramate.io/">Terramate</a></li>
          <li><a href="https://terrateam.io/">Terrateam</a></li>    
          <li><a href="https://verifa.io/">Verifa</a></li>    
          <li><a href="https://finisterra.io/">Finisterra</a></li>
        </ul>

        <h2>Contact us</h2>

        <p>
          If you are a member of the community, a member of the press, an employee of HashiCorp, or anyone else
          with questions or feedback to share, you can reach the team behind this manifesto by emailing us at
          <a href="mailto:pledge@opentf.org">pledge@opentf.org</a>.
        </p>

        <h2>Share</h2>

        
        <p>
          August 14th, 2023
        </p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Selectors: A Visual Guide (248 pts)]]></title>
            <link>https://fffuel.co/css-selectors/</link>
            <guid>37132754</guid>
            <pubDate>Tue, 15 Aug 2023 11:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fffuel.co/css-selectors/">https://fffuel.co/css-selectors/</a>, See on <a href="https://news.ycombinator.com/item?id=37132754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section id="universal"><h2><span>*</span> universal selector</h2><p>Select all elements:</p><div><pre><code>div * {
  background: coral;
}</code></pre></div></section><section id="element"><h2><span>element</span> element selector</h2><p>Select element(s):</p><div><pre><code>p {
  background: deeppink;
}</code></pre></div></section><section id="class"><h2><span>.class</span> class selector</h2><p>Select all elements with the specified class name:</p><div><pre><code>.my-class {
  background: royalblue;
}</code></pre></div></section><section id="id"><h2><span>#id</span> ID selector</h2><p>Select the element with the specified ID:</p><div><pre><code>#my-id {
  background: aquamarine;
}</code></pre></div></section><section id="multiple"><h2><span>.class.class-2</span> multiple selectors</h2><p>Chain two or more classes or IDs to select the element(s) that have all the specified classes/IDs:</p><div><pre><code>.my-class.special {
  background: royalblue;
}</code></pre></div></section><section id="comma"><h2><span>.class, .class-2</span> comma combinator</h2><p>Separate multiple selector declarations using a <strong>comma</strong>. This makes it easy to apply the same styles to multiple selector declarations:</p><div><pre><code>.item-1, .item-2 {
  background: sandybrown;
}</code></pre></div></section><section id="descendant"><h2><span>.class .class-2</span> descendant selector</h2><p>Leave a <strong>space</strong> (<em>descendant combinator</em>) between selectors to select element(s) that are descendant of another element:</p><div><pre><code>.wrapper .card {
  background: lightblue;
}</code></pre></div></section><section id="adjacent"><h2><span>.class + .class-2</span> adjacent selector</h2><p>Use a <strong>plus sign</strong> (<em>adjacent combinator</em>) to select an element that is a direct sibling to a first element:</p><div><pre><code>.item-1 + div {
  background: yellowgreen;
}</code></pre></div></section><section id="child"><h2><span>.class &gt; .class-2</span> child selector</h2><p>Use a <strong>&gt;</strong> sign (<em>child combinator</em>) to select element(s) that are direct children to another element:</p><div><pre><code>.wrapper &gt; div {
  background: olive;
}</code></pre></div></section><section id="subsequent"><h2><span>.class ~ .class-2</span> subsequent selector</h2><p>Use a <strong>tilde sign</strong> (<em>subsequent combinator</em>) to select every element that is preceded by the first element, without having to be a direct sibling to the first element:</p><div><pre><code>.item-1 ~ div {
  background: lightcoral;
}</code></pre></div></section><section id="lobotomized"><h2><span>* + *</span> lobotomized owl</h2><p>A selector pattern where all elements that have a preceding sibling are selected. Use it for example to add spacing to elements within a container except for the first element, which has no preceding sibling:</p><div><pre><code>* + * {
  background: khaki;
}</code></pre></div></section><section id="attribute"><h2><span>[attr]</span> attribute selector</h2><p>Select element(s) that have a specified attribute:</p><div><pre><code>[data-text] {
  background: deepskyblue;
}</code></pre></div></section><section id="attribute-value"><h2><span>[attr=val]</span> attribute &amp; attribute value</h2><p>Select element(s) that have the specified attribute and attribute value:</p><div><pre><code>[data-text="hello"] {
  background: lemonchiffon;
}</code></pre></div></section><section id="attribute-tilde-value"><h2><span>[attr~=val]</span> attribute &amp; one of the attribute's values</h2><p>Select element(s) that have the specified attribute with one of it's space-separated values matching the value:</p><div><pre><code>[title~="old"] {
  background: crimson;
}</code></pre></div></section><section id="attribute-star-value"><h2><span>[attr*=val]</span> attribute &amp; partial value</h2><p>Select element(s) that have the specified attribute with <em>val</em> being included in the attribute value:</p><div><pre><code>[title*="saur"] {
  background: darkgoldenrod;
}</code></pre></div></section><section id="link"><h2><span>:link :visited :hover &amp; :active</span> link pseudo-class selectors</h2><p>These 4 pseudo-classes are useful to select elements such as links in various states. These 4 are most often used with links, but <strong>:active</strong> is also useful for buttons and <strong>:hover</strong> can be used on all kinds of elements:</p><ul><li><strong>:link</strong> - Targets unvisited links. It allows you to style hyperlinks that the user hasn't clicked on yet.</li><li><strong>:visited</strong> - Targets links that have already been visited by the user. This pseudo-class lets you apply styles to previously clicked hyperlinks.</li><li><strong>:hover</strong> - Targets elements (commonly links) when they are being hovered over by the user's pointer, such as a mouse cursor.</li><li><strong>:active</strong> - Targets elements (typically links or buttons) during the moment they are being activated, like when a user clicks on them.</li></ul><div><pre><code>a:link {
  background: aliceblue;
}
a:visited {
  background: blanchedalmond;
}
a:hover {
  background: honeydew;
}
a:active {
  background: lavenderblush;
}</code></pre></div></section><section id="focus"><h2><span>:focus</span> focused input element(s)</h2><p>The <strong>:focus</strong> pseudo-class targets an element when it receives focus, such as when a user clicks on an input field or navigates to it using the keyboard:</p><div><pre><code>input:focus {
  border: 2px solid deepskyblue;
  background: lightcyan;
  outline: none;
  box-shadow: 0 0 8px rgba(0, 191, 255, 0.5);
}</code></pre><p><label for="my-input">Your name: </label></p></div></section><section id="checked"><h2><span>:checked</span> checked input element(s)</h2><p>The <strong>:checked</strong> pseudo-class targets <em>radio buttons, checkboxes, or options</em> in a select element that are currently selected/checked.</p><p>In the following example I make use of <em>appearance: none</em> to remove the default styling of the checkbox input, then use the <strong>:checked</strong> pseudo-class to style the sibling label, while also adding styling on the label when the checkbox is focused:</p><div><pre><code>input[type='checkbox'] {
  /* remove default
     checkbox styles */
  all: unset;
  -webkit-appearance: none;
  appearance: none;
  margin: 0;
}
input[type='checkbox']:checked + label {
  background: mediumseagreen;
}
input[type='checkbox']:focus + label {
  box-shadow: 0 0 0 2px yellow;
}</code></pre><p> <label for="checkbox1">I am a label</label></p></div></section><section id="disabled"><h2><span>:disabled</span> disabled input element(s)</h2><p>The <strong>:disabled</strong> pseudo-class matches form elements like buttons or text inputs that are disabled:</p><div><pre><code>input[type="text"] {
  padding: 10px;
  border: 2px solid mediumslateblue;
  margin-right: 10px;
}

input[type="text"]:disabled {
  background: lightgray;
  border: 2px solid darkgray;
  color: darkgray;
}</code></pre></div></section><section id="enabled"><h2><span>:enabled</span> enabled input element(s)</h2><p>The <strong>:enabled</strong> pseudo-class matches form elements that are interactive and can receive input:</p><div><pre><code>input[type="text"] {
  padding: 10px;
  border: 1px solid gray;
  margin-right: 10px;
}

input[type="text"]:enabled {
  background: lightgreen;
  border: 1px solid green;
}</code></pre></div></section><section id="valid"><h2><span>:valid</span> valid input element(s)</h2><p>The <strong>:valid</strong> pseudo-class is used to target an input element that has content that matches the requirements as specified by its attributes (like <em>pattern</em>, <em>type</em>, etc.):</p><div><pre><code>input[type="email"]:valid {
  border: 2px solid limegreen;
  background: honeydew;
}</code></pre><p><label>Email: </label></p></div></section><section id="invalid"><h2><span>:invalid</span> invalid input element(s)</h2><p>The <strong>:invalid</strong> pseudo-class is used to target input elements that have content that doesn't match the requirements:</p><div><pre><code>input[type="email"]:invalid {
  border: 2px solid tomato;
  background: mistyrose;
}</code></pre><p><label>Email: </label></p></div></section><section id="required"><h2><span>:required</span> required input element(s)</h2><p>The <strong>:required</strong> pseudo-class targets input elements that have the <em>required</em> attribute, indicating that they must be filled out before the form can be submitted:</p><div><pre><code>input:required {
  border: 2px dotted orangered;
  background: floralwhite;
  box-shadow: 0 0 10px rgba(255, 69, 0, 0.2);
}</code></pre><p><label>Name (required): </label> <label>Optional Field: </label></p></div></section><section id="optional"><h2><span>:optional</span> optional input element(s)</h2><p>The <strong>:optional</strong> pseudo-class targets input elements that do not have the <em>required</em> attribute, implying that they're not mandatory to fill out:</p><div><pre><code>input:optional {
  border: 2px dotted darkgray;
  background: whitesmoke;
  box-shadow: 0 0 10px rgba(105, 105, 105, 0.2);
}</code></pre><p><label>Name (required): </label> <label>Optional Field: </label></p></div></section><section id="first-child"><h2><span>:first-child</span> first child element</h2><p>The <strong>:first-child</strong> pseudo-class targets the first child element within its parent:</p><div><pre><code>div {
  border: 1px dotted gray;
}

div:first-child {
  background: lightblue;
  border-color: deepskyblue;
  border-style: solid;
}</code></pre><div><p>First Child</p><p>Second Child</p><p>Third Child</p></div></div></section><section id="last-child"><h2><span>:last-child</span> last child element</h2><p>The <strong>:last-child</strong> pseudo-class targets the last child element within its parent:</p><div><pre><code>div {
  border: 1px dotted gray;
}

div:last-child {
  background: lightblue;
  border-color: deepskyblue;
  border-style: solid;
}</code></pre><div><p>First Child</p><p>Second Child</p><p>Last Child</p></div></div></section><section id="nth-child"><h2><span>:nth-child</span> nth child element</h2><p>The <strong>:nth-child</strong> pseudo-class targets elements based on their position within their parent, allowing for a wide variety of selections:</p><div><pre><code>div {
  border: 1px dotted gray;
}

div:nth-child(2) {
  background: lightcoral;
  border-color: darkred;
  border-style: solid;
}</code></pre><div><p>First Child</p><p>Second Child</p><p>Last Child</p></div></div></section><section id="nth-last-child"><h2><span>:nth-last-child</span> nth child element, counting backwards from last</h2><p>The <strong>:nth-last-child</strong> pseudo-class is similar to :nth-child, but it counts from the last child backwards:</p><div><pre><code>div {
  border: 1px dotted gray;
}

div:nth-last-child(2) {
  background: darkorchid;
  border-color: indigo;
  color: white;
  border-style: solid;
}</code></pre><div><p>First Child</p><p>Second Child</p><p>Third Child</p><p>Last Child</p></div></div></section><section id="only-child"><h2><span>:only-child</span> only child of an element</h2><p>The <strong>:only-child</strong> pseudo-class targets an element if it's the only child element of its parent:</p><div><pre><code>div {
  border: 1px dotted gray;
}

div:only-child {
  background: lightsalmon;
  border-color: darksalmon;
  border-style: solid;
}</code></pre><div><div><p>1st Child</p><p>Inner child 1</p><p>Inner child 2</p></div><div><p>2nd Child</p><p>Only child of '2nd Child'</p></div></div></div></section><section id="first-of-type"><h2><span>:first-of-type</span> first element of a type</h2><p>The <strong>:first-of-type</strong> pseudo-class targets the first element of its type within its parent:</p><div><pre><code>p, div {
  border: 1px dotted gray;
}

div:first-of-type {
  background: lightyellow;
  border-color: gold;
  color: darkorange;
  border-style: solid;
}</code></pre><div><p>First paragraph</p><p>Second paragraph</p><p>First div</p><p>Second div</p></div></div></section><section id="last-of-type"><h2><span>:last-of-type</span> last element of a type</h2><p>The <strong>:last-of-type</strong> pseudo-class targets the last element of its type within a parent:</p><div><pre><code>p, div {
  border: 1px dotted gray;
}

p:last-of-type {
  background: lightyellow;
  border-color: gold;
  color: darkorange;
  border-style: solid;
}</code></pre><div><p>First paragraph</p><p>Second paragraph</p><p>First div</p><p>Second div</p></div></div></section><section id="nth-of-type"><h2><span>:nth-of-type</span> nth element of a type</h2><p>The <strong>:nth-of-type</strong> pseudo-class matches elements based on their type and position among siblings:</p><div><pre><code>p, div {
  border: 1px dotted gray;
}

p:nth-of-type(3) {
  background: lightyellow;
  border-color: gold;
  color: darkorange;
  border-style: solid;
}</code></pre><div><p>First paragraph</p><p>Second paragraph</p><p>Third paragraph</p><p>First div</p><p>Second div</p><p>Third div</p></div></div></section><section id="nth-last-of-type"><h2><span>:nth-last-of-type</span> nth element of type, counting backwards</h2><p>The <strong>:nth-last-of-type</strong> pseudo-class matches elements based on their type and position among siblings, but counting from the end:</p><div><pre><code>p, div {
  border: 1px dotted gray;
}

div:nth-last-of-type(3) {
  background: lightyellow;
  border-color: gold;
  color: darkorange;
  border-style: solid;
}</code></pre><div><p>First paragraph</p><p>Second paragraph</p><p>Third paragraph</p><p>First div</p><p>Second div</p><p>Third div</p></div></div></section><section id="only-of-type"><h2><span>:only-of-type</span> only element of its type</h2><p>The <strong>:only-of-type</strong> pseudo-class targets an element that is the only element of its type among its siblings:</p><div><pre><code>p, div {
  border: 1px dotted gray;
}

:only-of-type {
  background: lightyellow;
  border-color: gold;
  color: darkorange;
  border-style: solid;
}</code></pre><div><p>First paragraph</p><p>Second paragraph</p></div></div></section><section id="target"><h2><span>:target</span> target element selector</h2><p>The <strong>:target</strong> pseudo-class selects an element with an ID attribute matching the URL fragment (eg: <em>https://example.com/#fragment</em>).</p><p><strong>:target</strong> is often used to style sections of a page that are directly linked to, typically used with in-page links:</p><div><pre><code>div:target {
  border: 3px solid deepskyblue;
  background-color: lightcyan;
  transform: scale(1.05);
}</code></pre><div><p><a href="#section1">Go to Section 1</a> <a href="#section2">Go to Section 2</a></p><p>Section 1 content</p><p>Section 2 content</p></div></div></section><section id="not"><h2><span>:not()</span> negation pseudo-class</h2><p>The <strong>:not()</strong> functional pseudo-class allows you to target elements that do not match a specified selector or condition. It's essentially an exclusion filter:</p><div><pre><code>div:not(.exclude) {
  border: 2px solid royalblue;
  background: aliceblue;
}</code></pre><div><p>This div is targeted</p><p>This div has the '.exclude' class</p><p>Another targeted div</p></div></div></section><section id="has"><h2><span>:has()</span> parent selector</h2><p>The <strong>:has()</strong> functional pseudo-class allows to style an element if it contains a certain element or another selector:</p><div><pre><code>div:has(p.special) {
  border: 2px solid darkkhaki;
  background-color: peachpuff;
}</code></pre><div><p>Regular paragraph.</p><p>This paragraph has a the '.special' class, so its parent div is styled!</p><p>Another regular paragraph.</p></div></div></section><section id="before"><h2><span>::before</span> first child pseudo-element</h2><p>The <strong>::before</strong> pseudo-element is used to insert content before the content of an element. It can be used to add decorative content, icons, or other elements that don't need to be in the actual DOM:</p><div><pre><code>.alert::before {
  content: '⚠️ ';
  margin-right: 0.25rem;
}</code></pre></div></section><section id="after"><h2><span>::after</span> last child pseudo-element</h2><p>The <strong>::after</strong> pseudo-element is similar to <em>::before</em> and is used to insert content after the content of an element:</p><div><pre><code>.info::after {
  content: '';
  display: inline-block;
  width: 0.75rem;
  height: 0.75rem;
  border-radius: 35%;
  background: darkseagreen;
  margin-left: 0.35rem;
  rotate: 45deg;
  vertical-align: middle;
}</code></pre></div></section><section id="first-letter"><h2><span>::first-letter</span> first letter pseudo-element</h2><p>The <strong>::first-letter</strong> pseudo-element is used to style the first letter of a block-level element, allowing for design elements like drop caps:</p><div><pre><code>p::first-letter {
  font-size: 2em;
  font-weight: bold;
  float: left;
  color: crimson;
}</code></pre><p>Once upon a time, in a land far, far away, there lived a curious coder on a quest for knowledge.</p></div></section><section id="first-line"><h2><span>::first-line</span> first line pseudo-element</h2><p>The <strong>::first-line</strong> pseudo-element is used to style the first line of a block-level element. This allows for typographic effects that can adapt dynamically based on the size of the containing element and the font size:</p><div><pre><code>p::first-line {
  font-weight: bold;
  color: darkslategray;
  text-transform: uppercase;
}</code></pre><p>It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness...</p></div></section><section id="placeholder"><h2><span>::placeholder</span> text input placeholder</h2><p>The <strong>::placeholder</strong> pseudo-element is used to style the placeholder text of form fields like <em>&lt;input&gt;</em> and <em>&lt;textarea&gt;</em>:</p><div><pre><code>input::placeholder {
  font-style: italic;
  color: thistle;
  opacity: 0.7;
}</code></pre></div></section><section id="selection"><h2><span>::selection</span> style highlighted box</h2><p>The <strong>::placeholder</strong> pseudo-element is used to style the portion of an element that has been highlighted or selected by the user. For instance, when a user clicks and drags to select text, the <em>::selection</em> pseudo-element can be used to modify the background color, text color, and other styles of that selection:</p><div><pre><code>::selection {
  background-color: gold;
  color: darkblue;
}</code></pre><p>Click and drag to select this text to see the custom selection styling in action.</p></div></section><section id="marker"><h2><span>::marker</span> list marker pseudo-element</h2><p>The <strong>::placeholder</strong> pseudo-element is used to style marker boxes in list items, which typically contain bullets (for unordered lists) or numbers/letters (for ordered lists).</p><p>Before the introduction of the <em>::marker</em> pseudo-element, customizing these markers often required workarounds, but this pseudo-element gives us a bit more control:</p><div><pre><code>li::marker {
  color: LightSeaGreen;
  font-size: 1.5em;
  font-weight: bold;
}</code></pre><div><ul><li>Apples 🍎</li><li>Bananas 🍌</li><li>Cherries 🍒</li></ul></div></div></section><svg width="300" viewBox="0 0 687 155" xmlns="http://www.w3.org/2000/svg"><g stroke="currentColor" stroke-width="7" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"><path d="M20 58c27-13.33333333 54-20 81-20 40.5 0 40.5 20 81 20s40.626917-20 81-20 40.123083 20 80.5 20 40.5-20 81-20 40.5 20 81 20 40.626917-20 81-20c26.915389 0 53.748722 6.66666667 80.5 20" opacity=".1"></path><path d="M20 78c27-13.3333333 54-20 81-20 40.5 0 40.5 20 81 20s40.626917-20 81-20 40.123083 20 80.5 20 40.5-20 81-20 40.5 20 81 20 40.626917-20 81-20c26.915389 0 53.748722 6.6666667 80.5 20" opacity=".2"></path><path d="M20 98c27-13.3333333 54-20 81-20 40.5 0 40.5 20 81 20s40.626917-20 81-20 40.123083 20 80.5 20 40.5-20 81-20 40.5 20 81 20 40.626917-20 81-20c26.915389 0 53.748722 6.6666667 80.5 20" opacity=".6"></path><path d="M20 118c27-13.3333333 54-20 81-20 40.5 0 40.5 20 81 20s40.626917-20 81-20 40.123083 20 80.5 20 40.5-20 81-20 40.5 20 81 20 40.626917-20 81-20c26.915389 0 53.748722 6.6666667 80.5 20"></path></g></svg><section id="more"><h2>More pseudo-classes</h2><p>Here's some additional pseudo-classes that are available in CSS:</p><ul><li><strong>:root:</strong> Targets the highest-level parent element in a document, typically the <em>&lt;html&gt;</em> element in HTML documents. Useful to define CSS variables that will be available to all elements within the page.</li><li><strong>:is():</strong> Matches elements that can be one of several selectors, making long selector lists shorter and easier to read. For example, <em>:is(h1, h2, h3)</em> would match any of those three heading elements.</li><li><strong>:where():</strong> Similar to <em>:is()</em>, but allows for selecting elements based on conditions without affecting the specificity of the selector.</li><li><strong>:default:</strong> Matches UI elements (like radio buttons or checkboxes) that are set to their default selection state.</li><li><strong>:empty:</strong> Selects elements that have no children (including text nodes).</li><li><strong>:fullscreen:</strong> Targets elements that are currently displayed in fullscreen mode.</li><li><strong>:in-range:</strong> Matches form elements with a value that is within the specified range (using attributes like <em>min</em> and <em>max</em>).</li><li><strong>:out-of-range:</strong> Matches form elements with a value that is outside the specified range.</li><li><strong>:indeterminate:</strong> Targets form elements whose state is uncertain, such as a checkbox that's neither checked nor unchecked (often seen in tree-view structures).</li><li><strong>:read-only:</strong> Matches form elements that are not editable by the user, due to the <em>readonly</em> attribute.</li><li><strong>:read-write:</strong> Targets form elements that are editable by the user, implying they are not <em>readonly</em>.</li><li><strong>:lang()</strong>: Matches elements based on their language attribute. E.g., <em>:lang(en)</em> selects elements defined in English.</li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Servicer, pm2 alternative built on Rust and systemd (104 pts)]]></title>
            <link>https://servicer.dev</link>
            <guid>37132651</guid>
            <pubDate>Tue, 15 Aug 2023 11:34:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://servicer.dev">https://servicer.dev</a>, See on <a href="https://news.ycombinator.com/item?id=37132651">Hacker News</a></p>
<div id="readability-page-1" class="page"><nav><hr></nav><p><a href="https://github.com/servicer-labs/servicer"><img src="https://simpleicons.org/icons/github.svg" alt="Github repo"></a></p><p><a href="https://crates.io/crates/servicer"><img src="https://img.shields.io/crates/v/servicer?style=flat-square" alt="Crates.io"></a>
<a href="https://crates.io/crates/servicer"><img src="https://img.shields.io/crates/d/servicer?style=flat-square" alt="Crates.io"></a>
<a href="https://servicer.dev/LICENSE-MIT"><img src="https://img.shields.io/badge/license-MIT-blue?style=flat-square" alt="License"></a></p><h2 id="simplify-service-management-on-systemd">Simplify Service Management on systemd</h2><p><code>servicer</code> is a user-friendly CLI tool designed to simplify service management on <code>systemd</code>, abstracting away the complexities of the systemd ecosystem. With an easy-to-use API comparable to popular tools like <code>pm2</code>, servicer empowers users to create, control, and manage services effortlessly.</p><p><code>servicer</code> is lightweight, written in Rust and doesn’t run in the background. It does not fork services nor run a custom logging solution. It is a thin layer on <code>systemd</code> that creates <code>.ser.service</code> files. Logging is handled by journald.</p><h3 id="install">Install</h3><p>Download the binary from the <a href="https://github.com/servicer-labs/servicer/releases/download/v0.1.2/servicer">release page</a> or setup as-</p><pre><code>wget https://github.com/servicer-labs/servicer/releases/download/v0.1.2/servicer

# grant permissions
chmod +rwx ./servicer

# Rename to ser and make it accessable from path
sudo mv ./servicer /usr/bin/ser

# This should work now
ser --help
</code></pre><p>Or build from source</p><pre><code>cargo install servicer
sudo ln -s ~/.cargo/bin/servicer /usr/bin/ser
</code></pre><h3 id="create-service">Create service</h3><pre><code>sudo ser create index.js --start --enable

# Custom interpreter
sudo ser create index.js --start --enable --interpreter deno
</code></pre><p>Or write your own custom <code>.service</code> file. <code>servicer</code> provides a starter template to get you started quickly.</p><pre><code>sudo ser edit index.js
</code></pre><p>Got an existing service? No problem. Rename your <code>.service</code> file to <code>.ser.service</code> and servicer will pick it up.</p><h3 id="view-services">View services</h3><pre><code>ser status
</code></pre><pre><code>+-------+-------------+--------+----------------+-------+--------+
| pid   | name        | active | enable on boot | cpu % | memory |
+-------+-------------+--------+----------------+-------+--------+
| 24294 |    index.js | active | true           | 0     | 9.5 KB |
+-------+-------------+--------+----------------+-------+--------+
</code></pre><h3 id="view-logs">View logs</h3><pre><code>ser logs index.js
</code></pre><h3 id="stop-disable-or-delete">Stop, disable or delete</h3><pre><code># Stop a running service
sudo ser stop index.js

# Disable load on boot
sudo ser disable index.js

# Delete the .service file
sudo ser rm index.js
</code></pre><h3 id="view-file-and-unit-path">View file and unit path</h3><pre><code>ser which index.js
</code></pre><pre><code>Paths for index.js.ser.service:
+--------------+-----------------------------------------------------------+
| name         | path                                                      |
+--------------+-----------------------------------------------------------+
| Service file | /etc/systemd/system/index.js.ser.service                  |
+--------------+-----------------------------------------------------------+
| Unit file    | /org/freedesktop/systemd1/unit/index_2ejs_2eser_2eservice |
+--------------+-----------------------------------------------------------+
</code></pre><ul></ul></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPU-Accelerated LLM on an Orange Pi (172 pts)]]></title>
            <link>https://blog.mlc.ai/2023/08/09/GPU-Accelerated-LLM-on-Orange-Pi</link>
            <guid>37132209</guid>
            <pubDate>Tue, 15 Aug 2023 10:30:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mlc.ai/2023/08/09/GPU-Accelerated-LLM-on-Orange-Pi">https://blog.mlc.ai/2023/08/09/GPU-Accelerated-LLM-on-Orange-Pi</a>, See on <a href="https://news.ycombinator.com/item?id=37132209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>
        <time datetime="2023-08-09T13:30:00+00:00" itemprop="datePublished">
          Aug 9, 2023
        </time>
        
        • 
        
      </p>
      
    <br>
    <h2 id="tldr">TL;DR</h2>

<p>This post shows GPU-accelerated LLM running smoothly on an embedded device at a reasonable speed. More specifically, on a $100 Orange Pi 5 with Mali GPU, we achieve 2.5 tok/sec for Llama2-7b and 5 tok/sec for RedPajama-3b through Machine Learning Compilation (MLC) techniques. Additionally, we are able to run a Llama-2 13b model at 1.5 tok/sec on a 16GB version of the Orange Pi 5+ under $150.</p>

<p>
  <img src="https://blog.mlc.ai/img/orange-pi/orange-pi.jpg" width="90%">
</p>

<h2 id="background">Background</h2>

<p>Progress in open language models has been catalyzing innovation across question-answering, translation, and creative tasks. While current solutions demand high-end desktop GPUs to achieve satisfactory performance, to unleash LLMs for everyday use, we wanted to understand how usable we could deploy them on the affordable embedded devices.</p>

<p>Many embedded devices come with mobile GPUs that can serve as a source of acceleration. In this post, we pick Orange Pi 5, a RK35888-based board that is similar to Raspberry Pi but also features a more powerful Mali-G610 GPU. This post summarizes our first attempt at leveraging Machine Learning Compilation and provides out-of-box GPU acceleration for this device.</p>

<h2 id="machine-learning-compilation-for-mali">Machine Learning Compilation for Mali</h2>

<p>
  <img src="https://blog.mlc.ai/img/orange-pi/WebXYZ%20Images.svg" width="90%">
</p>

<p>Machine learning compilation (MLC) is an emerging technology that automatically compiles and optimizes machine learning workloads, and deploys the compiled workload to a broad set of backends. At the time of writing, based on Apache TVM Unity, MLC supports platforms including browsers (WebGPU, WASM), NVIDIA GPUs (CUDA), AMD GPUs (ROCm, Vulkan), Intel GPUs (Vulkan), iOS and MacBooks (Metal), Android (OpenCL), and Mali GPUs (this post).</p>

<h3 id="generalizable-ml-compilation-for-mali-codegen">Generalizable ML Compilation for Mali Codegen</h3>

<p>MLC is built on top of  Apache TVM Unity, a generalizable stack for compiling machine learning models across different hardwares and backends. To compile LLMs onto Mali GPUs, we reuse all the existing compilation pipeline without any code optimizations. More specifically, we successfully deployed Llama-2 and RedPajama models with the following steps:</p>

<ul>
  <li>Reuse model optimization passes, including quantization, fusion, layout optimization, etc;</li>
  <li>Reuse a generic GPU kernel optimization space written in TVM TensorIR and re-target it to Mali GPUs;</li>
  <li>Reuse OpenCL codegen backend from TVM, and re-target it to Mali GPUs;</li>
  <li>Reuse the existing user interface, including Python APIs, CLI, and REST APIs.</li>
</ul>

<h2 id="try-it-out">Try it out</h2>

<p>This section provides a step-by-step guide so that you can try it out on your own orange pi device. Here we use <code>RedPajama-INCITE-Chat-3B-v1-q4f16_1</code> as the running example. You can replace that by <code>​​Llama-2-7b-chat-hf-q4f16_1</code> or <code>​​Llama-2-13b-chat-hf-q4f16_1</code> (requires a 16GB board).</p>

<h3 id="prepare">Prepare</h3>

<p>Please first follow the instruction <a href="https://mlc.ai/mlc-llm/docs/install/gpu.html#orange-pi-5-rk3588-based-sbc">here</a>, to setup the RK3588 board with OpenCL driver. Then clone the MLC-LLM from the source, and download weights and prebuilt libs.</p>

<div><pre><code><span># clone mlc-llm from GitHub</span>
git clone <span>--recursive</span> https://github.com/mlc-ai/mlc-llm.git <span>&amp;&amp;</span> <span>cd </span>mlc-llm
<span># Download prebuilt weights and libs</span>
git lfs <span>install
mkdir</span> <span>-p</span> dist/prebuilt <span>&amp;&amp;</span> <span>cd </span>dist/prebuilt
git clone https://github.com/mlc-ai/binary-mlc-llm-libs.git lib
git clone https://huggingface.co/mlc-ai/mlc-chat-RedPajama-INCITE-Chat-3B-v1-q4f16_1
<span>cd</span> ../../..
</code></pre></div>

<h3 id="try-out-the-cli">Try out the CLI</h3>

<p>Build mlc_llm_cli from the source code</p>

<div><pre><code><span>cd </span>mlc-llm/
<span># create build directory</span>
<span>mkdir</span> <span>-p</span> build <span>&amp;&amp;</span> <span>cd </span>build
<span># generate build configuration</span>
python3 ../cmake/gen_cmake_config.py
<span># build `mlc_chat_cli`</span>
cmake .. <span>&amp;&amp;</span> cmake <span>--build</span> <span>.</span> <span>--parallel</span> <span>$(</span><span>nproc</span><span>)</span> <span>&amp;&amp;</span> <span>cd</span> ..
</code></pre></div>

<p>Verify installation</p>

<div><pre><code><span># expected to see `mlc_chat_cli`, `libmlc_llm.so` and `libtvm_runtime.so`</span>
<span>ls</span> <span>-l</span> ./build/
<span># expected to see help message</span>
./build/mlc_chat_cli <span>--help</span>
</code></pre></div>

<p>Run LLMs through mlc_chat_cli</p>

<div><pre><code>./build/mlc_chat_cli <span>--local-id</span> RedPajama-INCITE-Chat-3B-v1-q4f16_1 –device mali
</code></pre></div>

<p>
  <img src="https://blog.mlc.ai/img/orange-pi/cli.png" width="90%">
</p>

<h3 id="try-out-the-python-api">Try out the Python API</h3>

<p>Build TVM runtime</p>

<div><pre><code><span># clone from GitHub</span>
git clone <span>--recursive</span> https://github.com/mlc-ai/relax.git tvm_unity <span>&amp;&amp;</span> <span>cd </span>tvm_unity/
<span># create build directory</span>
<span>mkdir</span> <span>-p</span> build <span>&amp;&amp;</span> <span>cd </span>build
<span># generate build configuration</span>
<span>cp</span> ../cmake/config.cmake <span>.</span> <span>&amp;&amp;</span> <span>echo</span> <span>"set(CMAKE_BUILD_TYPE RelWithDebInfo)</span><span>\n</span><span>set(USE_OPENCL ON)"</span> <span>&gt;&gt;</span> config.cmake
<span># build `mlc_chat_cli`</span>
cmake .. <span>&amp;&amp;</span> cmake <span>--build</span> <span>.</span> <span>--target</span> runtime <span>--parallel</span> <span>$(</span><span>nproc</span><span>)</span> <span>&amp;&amp;</span> <span>cd</span> ../..
</code></pre></div>

<p>Setup python path (please set it to the <code>bashrc</code> or <code>zshrc</code> for persistent settings)</p>

<div><pre><code><span>export </span><span>TVM_HOME</span><span>=</span><span>$(</span><span>pwd</span><span>)</span>/tvm_unity
<span>export </span><span>MLC_LLM_HOME</span><span>=</span><span>$(</span><span>pwd</span><span>)</span>/mlc-llm
<span>export </span><span>PYTHONPATH</span><span>=</span><span>$TVM_HOME</span>/python:<span>$MLC_LLM_HOME</span>/python:<span>${</span><span>PYTHONPATH</span><span>}</span>
</code></pre></div>

<p>Run the following python script.</p>

<div><pre><code><span>from</span> <span>mlc_chat</span> <span>import</span> <span>ChatModule</span>
<span>from</span> <span>mlc_chat.callback</span> <span>import</span> <span>StreamToStdout</span>
<span>cm</span> <span>=</span> <span>ChatModule</span><span>(</span><span>model</span><span>=</span><span>"RedPajama-INCITE-Chat-3B-v1-q4f16_1"</span><span>)</span>

<span># Generate a response for a given prompt
</span><span>output</span> <span>=</span> <span>cm</span><span>.</span><span>generate</span><span>(</span>
   <span>prompt</span><span>=</span><span>"What is the meaning of life?"</span><span>,</span>
   <span>progress_callback</span><span>=</span><span>StreamToStdout</span><span>(</span><span>callback_interval</span><span>=</span><span>2</span><span>),</span>
<span>)</span>

<span># Print prefill and decode performance statistics
</span><span>print</span><span>(</span><span>f</span><span>"Statistics: </span><span>{</span><span>cm</span><span>.</span><span>stats</span><span>()</span><span>}</span><span>\n</span><span>"</span><span>)</span>
</code></pre></div>

<h2 id="discussion-and-future-work">Discussion and Future Work</h2>

<p>Our current experiments show that 3B models might be a sweet spot. The RedPajama-3B model can provide up to 5 tok/sec and a decent chat experience. There is also room for improvements, specifically around the integer-to-float conversions. Moving forward, we will address the related issues and improve Mali GPUs’ performance.</p>

<p>This post contributes to our quest to integrate LLMs into affordable devices and bring AI to everyone. Our future endeavors will focus on harnessing advancements in single-board computers, refining software frameworks like OpenCL and MLC-LLM, and exploring broader applications such as smart home devices. Collaborative efforts in the open-source community and a commitment to continuous learning and adaptation will be pivotal in navigating the evolving landscape of LLM deployment on emerging hardware.</p>

<h2 id="contributions">Contributions</h2>

<p>LLM on Orange Pi is primarily completed by <a href="https://www.linkedin.com/in/haolin-zhang-534530231/">Haolin Zhang</a>. The support of mali optimizations comes from Siyuan Feng, with foundation support from Junru Shao and Bohan Hou and other community members.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy friendly ESP32 smart doorbell with Home Assistant local integration (229 pts)]]></title>
            <link>https://tristam.ie/2023/758/</link>
            <guid>37131957</guid>
            <pubDate>Tue, 15 Aug 2023 09:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tristam.ie/2023/758/">https://tristam.ie/2023/758/</a>, See on <a href="https://news.ycombinator.com/item?id=37131957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p id="bkmrk-privacy-focused-%22sma">Privacy focused “smart” doorbells seem to be few and far between so I decided to build one that integrates with Home Assistant via ESPHome and is easy to build.</p>



<p id="bkmrk-this-project-is-aime">This project is aimed at being simple while allowing a ton of customisation and flexibility. To get started, you’ll need an instance of <a rel="noreferrer noopener" href="https://www.home-assistant.io/" target="_blank">Home Assistant</a> running with the <a rel="noreferrer noopener" href="https://esphome.io/index.html" target="_blank">ESPHome</a> add-on as well as the Home Assistant companion app on your mobile phone to receive notifications when someone presses the doorbell button.</p>



<p>I have used an 8 RGB LED ring light in my version but if you want to simplify things, you can skip this and use the ESP32-CAM’s built in LED as a flash – it’s surprisingly bright.</p>



<h4 id="bkmrk-parts"><strong>Parts list:</strong></h4>



<ul id="bkmrk-esp32-cam-%28amazon---">
<li>ESP32-CAM (Amazon – <a rel="noreferrer noopener" href="https://amzn.to/3KoP1x1" target="_blank">US</a>, <a rel="noreferrer noopener" href="https://amzn.to/442cUBH" target="_blank">UK</a>, <a href="https://amzn.to/3DPKhNn" target="_blank" rel="noreferrer noopener">DE</a>) Make sure to get one with a “flash/download/io0” button to make your life easier when you flash ESPHome onto it for the first time. If you make the same mistake as me and buy the one without that button, follow <a rel="noreferrer noopener" href="https://hagensieker.com/2021/10/03/esp32-cam-tiny-live-stream-camera/" target="_blank">this guide</a> to flash the ESP32-CAM using an FTDI adapter.</li>



<li>Momentary push button (Amazon –&nbsp;<a rel="noreferrer noopener" href="https://amzn.to/3Yfktna" target="_blank">US</a>, <a href="https://amzn.to/3DO0EtP" data-type="link" data-id="https://amzn.to/3DO0EtP" target="_blank" rel="noreferrer noopener">UK</a>, <a rel="noreferrer noopener" href="https://amzn.to/44RJ3gs" target="_blank">DE</a>)</li>



<li>10k resistor</li>



<li>8&nbsp; RGB LED ring light (Amazon – <a href="https://amzn.to/3KizvTx" target="_blank" rel="noreferrer noopener">US</a>, <a href="https://amzn.to/3OBUinp" target="_blank" rel="noreferrer noopener">DE</a>) Note: these aren’t the exact ones that I used but they are the closest ones that I could find. I used the Pi Supply PIS-1270 from <a href="https://ie.rs-online.com/web/p/led-development-tools/2011639" target="_blank" rel="noreferrer noopener">RS Components</a>.</li>



<li>10m Micro USB cable (Amazon –&nbsp;<a rel="noreferrer noopener" href="https://amzn.to/3rIiUlt" target="_blank">US</a>, <a href="https://amzn.to/3OORUtF" target="_blank" rel="noreferrer noopener">UK</a>, <a rel="noreferrer noopener" href="https://amzn.to/457hjnD" target="_blank">DE</a>)</li>



<li>M2.5 brass inserts (Amazon – <a rel="noreferrer noopener" href="https://amzn.to/3VYSZ4i" target="_blank">US</a>, <a rel="noreferrer noopener" href="https://amzn.to/455KYOz" target="_blank">UK</a>, <a href="https://amzn.to/3sazoD6" target="_blank" rel="noreferrer noopener">DE</a>) </li>



<li>M2.5 screws (Amazon – <a href="https://amzn.to/3IIuAuG">US</a>, <a href="https://amzn.to/45iVkdM" target="_blank" rel="noreferrer noopener">UK</a>, <a href="https://amzn.to/3lUMHVs">DE</a>)</li>



<li>eSUN white PETG filament (Amazon –&nbsp;<a rel="noreferrer noopener" href="https://amzn.to/45aTyes" target="_blank">US</a>, <a href="https://amzn.to/3OtHTAN" target="_blank" rel="noreferrer noopener">UK</a>, <a rel="noreferrer noopener" href="https://amzn.to/45aTyes" target="_blank">DE</a>)&nbsp;</li>
</ul>



<p>You can find the .stl’s on Printables <a rel="noreferrer noopener" href="https://www.printables.com/model/542900-privacy-friendly-esp32-smart-doorbell-with-home-as" target="_blank">here</a> and the home assistant config in my github repo: <a rel="noreferrer noopener" href="https://github.com/thatguy-za/esp32-cam-doorbell" target="_blank">thatguy-za/esp32-cam-doorbell</a>.</p>



<h4 id="bkmrk-build-guide"><strong>Build guide</strong></h4>



<h5 id="bkmrk-step-1---printing-th"><strong>Step 1 – Printing the enclosure</strong></h5>



<p id="bkmrk-this-step-takes-the-">This step takes the longest so lets send the .stl’s to the printer while we crack on with the rest of the build. There are three pieces that you’ll need to print:<br>1. The main body<br>2. The ESP32-CAM retention plate<br>3. The back plate/wall mount</p>



<p id="bkmrk-you%27ll-need-to-print">You’ll need to print the front and the back of the enclosure with supports. I printed it using PLA but you’ll want to use PETG or ABS filament so it is waterproof and use 20-30% infill.&nbsp;</p>



<p id="bkmrk-once-the-enclosure-h">Once everything has printed, you’ll need to add two M2.5 threaded inserts:<br>1. Into the front cover so you can screw the ESP32-CAM retention bracket into it.<br>1. Into the bottom of the backplate so you can screw on the face plate with a 10mm M2.5 screw</p>







<h5 id="bkmrk-step-1---adding-the-"><strong>Step 2 – Configuring the ESP32-CAM in ESPHome</strong></h5>



<p id="bkmrk-it%27s-easiest-to-do-t">Hold down the&nbsp;<strong>“flash/download/io0” button</strong> and connect your ESP32-CAM to your computer using a micro USB cable.&nbsp; This will boot it into flashing mode.</p>



<p id="bkmrk-head-over-to-your-in">Launch Google Chrome, go to your instance of Home Assistant and launch the ESPHome Add-on by clicking&nbsp;<strong>Settings -&gt; Add-ons -&gt; ESPHome -&gt; Open Web UI</strong>. Chrome is important because it seems to be the most reliable browser for flashing firmware onto the ESP32-CAM.</p>



<p id="bkmrk-click-%2B-new-device-t">Click <strong>+ New Device</strong> to add a new device.Give it a name (“Doorbell” is probably a good starting point).</p>



<p id="bkmrk-when-asked-to-select">When asked to select the device type, select <strong>ESP32 </strong>and check the box <strong>“use recommended settings’</strong>.</p>



<p id="bkmrk-once-the-configurati">Once the configuration has been created, you can skip installing it onto the device – we’ll do that later.</p>



<p id="bkmrk-from-your-list-of-es">From your list of ESPHome devices, click <strong>Edit</strong> on the device that you have just created.</p>



<p id="bkmrk-at-the-bottom-of-the">At the bottom of the yaml file (below <code>captive_portal:</code>), paste the configuration code from my github repository that is linked above.&nbsp;</p>



<p id="bkmrk-click-save-and-insta">Click <strong>Save</strong> and <strong>Install</strong>.</p>



<p id="bkmrk-select-%22plug-into-th">Select&nbsp;<strong>Plug into this computer</strong>.</p>



<p id="bkmrk-click-open-esphome-w">Click <strong>Open ESPHome Web</strong>, this will allow you to flash the firmware onto the device from the web browser. This is where it is important that you are using Google Chrome.</p>



<p id="bkmrk-once-the-firmware-ha">Once the firmware has compiled, you should be able to click <strong>Download Project</strong> – this could take a few minutes.</p>



<p id="bkmrk-head-over-to-esphome">Head over to <strong>ESPHome Web </strong>and follow the prompts to flash the firmware onto your ESP32-CAM.</p>



<p id="bkmrk-once-flashing-is-com">Home Assistant should discover the new device once the new firmware has been flashed onto it – yay! Now you can add whatever entities you want to your dashboard.</p>



<figure><img decoding="async" width="495" height="241" src="https://tristam.ie/wp-content/uploads/2023/08/Screenshot-2023-08-01-153724.png" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/Screenshot-2023-08-01-153724.png 495w, https://tristam.ie/wp-content/uploads/2023/08/Screenshot-2023-08-01-153724-300x146.png 300w" sizes="(max-width: 495px) 100vw, 495px"><figcaption>Screenshot: New device found in Home Assistant.</figcaption></figure>



<h5 id="bkmrk-">Step 3 –&nbsp; Time for some automation &amp; notifications</h5>



<p id="bkmrk--1">We want to create an Automation to take a snapshot from the doorbell’s camera and send it to your mobile phone when someone presses the doorbell button.</p>



<p>Click <strong>Settings -&gt; Automations -&gt; + Create Automation</strong> and then create a new automation from scratch. </p>



<p>Click on the three vertical dots in the top right hand corner of the screen and then click <strong>Edit in YAML</strong></p>



<p>Paste the automation from my github repo (linked above) into the editor and  update entity names for devices such as your mobile phone. </p>



<p>Save the automation and restart Home Assistant so the new automation becomes active.</p>



<p>Here is a summary of how the automation should behave.</p>



<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1.png" data-slb-active="1" data-slb-asset="1931303768" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="1024" height="417" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1-1024x417.png" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1-1024x417.png 1024w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1-300x122.png 300w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1-768x313.png 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_process-1.png 1155w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h5 id="bkmrk-wiring">Step 4 – Time to wire it up</h5>



<p id="bkmrk-once-the-enclosure-i">Once the enclosure is printed, we can start the final assembly.</p>



<p id="bkmrk-i-tried-to-keep-this">There are a few variants of the ESP32-CAM board, each with slightly different pinouts so double check the pinout on the board you get.</p>



<p id="bkmrk-follow-the-wiring-gu">Follow the wiring guide below. I soldered everything onto the back of the lower PCB (the one with the micro USB port).&nbsp; It’s&nbsp;important to add the 10k ohm pull down resistor between GPIO14 and ground because without it, I noticed GPIO14 was floating high on quite often.&nbsp;</p>



<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring.png" data-slb-active="1" data-slb-asset="848354910" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="1024" height="497" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring-1024x497.png" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring-1024x497.png 1024w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring-300x145.png 300w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring-768x372.png 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_wiring.png 1060w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>This is what it should look like when you’re done. Bonus points for covering the resistor in heatshrink tube.</p>



<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside.jpg" data-slb-active="1" data-slb-asset="164896066" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="1024" height="576" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside-1024x576.jpg" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside-1024x576.jpg 1024w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside-300x169.jpg 300w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside-768x432.jpg 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside-1536x864.jpg 1536w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_inside.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Here are some pics of mine before it goes up next to the front door!</p>



<figure>
<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall.jpg" data-slb-active="1" data-slb-asset="2010640426" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="1024" height="576" data-id="772" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall-1024x576.jpg" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall-1024x576.jpg 1024w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall-300x169.jpg 300w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall-768x432.jpg 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall-1536x864.jpg 1536w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_on_wall.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside.jpg" data-slb-active="1" data-slb-asset="2025733673" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="1024" height="576" data-id="773" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside-1024x576.jpg" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside-1024x576.jpg 1024w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside-300x169.jpg 300w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside-768x432.jpg 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside-1536x864.jpg 1536w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l.jpg" data-slb-active="1" data-slb-asset="1634067867" data-slb-internal="0" data-slb-group="758"><img decoding="async" width="576" height="1024" data-id="774" src="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l-576x1024.jpg" alt="" srcset="https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l-576x1024.jpg 576w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l-169x300.jpg 169w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l-768x1365.jpg 768w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l-864x1536.jpg 864w, https://tristam.ie/wp-content/uploads/2023/08/esp32_doorbell_outside_2l.jpg 1080w" sizes="(max-width: 576px) 100vw, 576px"></a></figure>
</figure>



<div>
<p><em>*The product links in this post may contain affiliate links. Any commission earned is used to keep the servers running and the gin cool.</em></p>



<p><strong>Thanks for making it to the end of the post! Did this article help you or do you like my work? </strong><br>☕<strong><a rel="noreferrer noopener" href="https://www.buymeacoffee.com/tristam" target="_blank">Buy Me a Coffee</a></strong>☕</p>
</div>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things you forgot because of React (405 pts)]]></title>
            <link>https://joshcollinsworth.com/blog/antiquated-react</link>
            <guid>37131802</guid>
            <pubDate>Tue, 15 Aug 2023 09:18:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshcollinsworth.com/blog/antiquated-react">https://joshcollinsworth.com/blog/antiquated-react</a>, See on <a href="https://news.ycombinator.com/item?id=37131802">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
	


<main id="main" tabindex="-1"><article><img src="https://d33wubrfki0l68.cloudfront.net/3a018a423858b084f337e9d9b7c167dc2b4849bd/74eac/images/post_images/because-of-react.png" alt="" width="320" height="180">

		

		
		<p><b>Published:</b> August 4, 2023
			<br>
				<b>Updated:</b> August 9, 2023</p>
		
		
		

<h2 id="part-1-an-intro-about-music-defaults-and-bubbles">Part 1: an intro about music, defaults, and bubbles</h2>
<p>Like a lot of people, there was a time when the only music I listened to was whatever was played on my local radio station. (<em>A lot of people over 30 or so, anyway. If this doesn’t sound familiar to you yet, just stick with me for a minute here</em>.) At the time, I was happy with that. It seemed like all I needed.</p>


<p>Looking back, I realize: I naively trusted that anything good inevitably became popular—and therefore, anything worth knowing would eventually come my way on its own.</p>

<p>Eventually, though, <em>other</em> music began to take root in my life. Through new friends and the internet, I became acquainted with new artists, further and further from the things I liked before—or, at least, <em>thought</em> I liked.</p>
<p><em>This</em> music was different. I wasn’t in love with it one week and sick of it the next. Listening to it wasn’t part of an endless cycle.</p>
<p>If anything, it was the <em>opposite</em>; it was music I actually liked and appreciated <em>more</em> the more I listened to it. There was depth to it. Sure, it didn’t have the loud distorted guitars, punch-line lyrics, or sugar-coated melodies I’d enjoyed up until that point. But to my surprise, that actually somehow made it <em>better</em>, not worse.</p>
<p>That’s when I began to realize: maybe I was never really as satisfied as I thought I was.</p>
<p>Maybe my bliss was, in fact, predicated on ignorance.</p>
<h3 id="finding-richness-beyond-the-defaults">Finding richness beyond the defaults</h3>
<p>I suspect you can probably relate to that story, even if it’s not with music specifically.</p>
<p>Most likely, you now count a food or drink you didn’t once like among your favorites. Or, maybe you were surprised to find a movie, book, game, podcast, influencer, or hobby you didn’t expect to like resonated with you.</p>
<p>The details aren’t important; all I’m getting at is:</p>


<p>You’ve probably experienced finding something great beyond the periphery of popular defaults.</p>

<p>Not to sound like a frontend version of a snobby hipster. That’s not my intention. If your idea of a good time is Bud Lites at Olive Garden: cool, pass the breadsticks.</p>
<p>But what I <em>am</em> trying to do is: gently share the idea that <em>maybe</em> you’re shutting yourself off to something great, without even realizing it.</p>
<p>Maybe this whole concept—finding better things beyond familiar boundaries—applies to our tools and workflows just as much as it does any other area of life.</p>
<p>And maybe—just <em>maybe</em>— your current satisfaction comes, at least a little bit, from simply <em>not knowing what you’re missing</em>.</p>
<h3 id="completing-the-analogy-and-acknowledging-its-shortcomings">Completing the analogy, and acknowledging its shortcomings</h3>
<p>I’ve written before about how <a href="https://reactjs.org/" rel="nofollow">React</a> is <a href="https://joshcollinsworth.com/blog/self-fulfilling-prophecy-of-react">the new default</a> frontend framework, and how I don’t think most people using React on a regular basis realize quite how much it’s fallen behind.</p>
<p>And on that note, this is where our analogy begins to fall short.</p>
<p>Assuming we were only talking about personal preferences, I’d never write a blog post arguing about what you like, or trying to change your mind. (Not at this age, anyway.) Who cares? If you enjoy it, have fun.</p>


<p>But unlike music or other subjective things meant for our own enjoyment, our choice of frontend tools has empirical, measurable effects on others.</p>

<p>That decision carries a real responsibility. It’s not just about what we like. When it comes to development—unless we’re building things purely for ourselves, anyway—our enjoyment is secondary; the user’s experience is what matters most.</p>
<p>If you love your tools, that’s wonderful. I hope you do. But that’s a side quest at best, and a potentially harmful distraction at worst. Developer experience (DX) shouldn’t ever supersede user experience (UX).</p>
<p>So forgive me for choosing a flimsy metaphor. You can keep listening to the same music for the rest of your life, if you want to. I support that. But we have very valid and important reasons to push beyond the comfort of our existing preferences when it comes to the tools we use.</p>
<h3 id="the-react-bubble">The React bubble</h3>
<p>The idea that React lags behind its peers might be new to you. Like many, you might still consider React the modern standard in frontend. So let’s quickly poke at that bubble, in this one last section before we get into the titular list.</p>
<p>This, from <a href="https://toot.cafe/@slightlyoff" rel="nofollow">Alex Russell, via Mastodon</a>, is what started me writing this post:</p>
<blockquote><p>Someone asked me today if there was a case for using React in a new app that doesn’t need to support IE.</p>
<p>I could not come up with a single reason…</p>
<p>It’s astonishing how antiquated React is.</p></blockquote>
<p>Alex mentions React’s lack of support for web components in that thread. That feature has been glaringly missing from React for years. And yes, it’s “on the roadmap.” As of this writing, though, there’s no firm commitment to either an implementation or an expected ship date.</p>


<p>Meanwhile, pretty much all of React’s contemporaries—any framework or technology you might choose instead of React—already have that story shipped and in production.</p>

<p>Web components are one thing. But they’re far from the only item on the list of “stuff everything else does already and/or better.” (We’ll cover several others below.)</p>
<p>React benefitted mightily from being early to the framework game; it set the standard. But that’s come with severe drawbacks in agility and adaptability. Every decision React’s made since its inception circa 2013 is another layer of tech debt—one that its newer contemporaries aren’t constrained by.</p>
<p>To <a href="https://toot.cafe/@slightlyoff/110512849934452558" rel="nofollow">quote Alex once more</a>:</p>
<blockquote><p>React is ‘13 tech designed to ‘08 constraints. Nothing about it is innovative in 2023; in fact, it’s the slowest way to get functional-reactive frontend programming in the modern era…</p></blockquote>
<p><a href="https://joshcollinsworth.com/blog/self-fulfilling-prophecy-of-react">React has aged, and how I don’t think most people realize how much or how poorly</a>. So to put the quote above another way (and tie it back to our intro about music):</p>


<p>React was designed seven Taylor Swift albums ago, for a world where John Mayer and Jennifer Aniston were still dating.</p>

<p>(<em>Seven</em> new <em>Taylor Swift albums ago, that is. That doesn’t even count the</em> Taylor’s Version <em>releases</em>.)</p>
<p>So if you’re one of the many developers whose whole world has been React for the past few years, there might be things you’ve forgotten—or never knew at all—because you’ve been using React for so long.</p>
<p>As fast as modern frontend moves, we seem to be very slow in realizing the world which crowned React king, in many ways, no longer exists. (<em>If it ever did; not many organizations had anything resembling Facebook’s specific set of problems to begin with</em>.)</p>
<p>Browsers have seen <em>wild</em> growth in new feature adoption in the last ten years, in both JavaScript and CSS. Technology and user expectations have evolved, and the current ecosystem of tools has done a <em>lot</em> more than you might think to iterate and adapt past React, in ways such legacy software can’t.</p>
<p>I realize calling React “legacy software” is controversial, but I think it’s fair; it’s comparatively complicated, relatively old, contains a lot of rules and gotchas, beginners are often afraid of it, and the architectural decisions it’s built on top of have long since become an impediment to its ability to iterate.</p>
<hr>
<p>If I haven’t completely alienated you yet by this point (<em>with some combination of quasi-elitism, rambling preamble, and overuse of parenthetical interjections</em>), I’d like to share some things you might have missed if your head’s been entirely in the React world for a while, in the hopes of introducing you to some tunes you might be surprised to find are better than what’s on your current playlist.</p>
<h2 id="part-2-things-you-forgot-or-never-knew-because-of-react">Part 2: things you forgot (or never knew) because of React</h2>

<p>I’ve touched on this in <a href="https://joshcollinsworth.com/blog/self-fulfilling-prophecy-of-react#community-and-support">other posts</a>, but any time an “unproven” framework’s name comes up as a potential tool for a dev project, the first question anybody seems to care about is: <em>how big is the ecosystem</em>?</p>
<p>You might have even had that thought as soon as you read the premise of this post. <em>Move from React to another framework? Are any of them big enough yet?</em></p>
<p>Why do we have this obsession with ecosystem size?</p>
<p>Sure, we want to be certain this framework won’t just vanish on us, or stop being maintained in a few years. That’s perfectly valid. And yes, we wouldn’t bet the farm on something <em>too</em> new or unproven. But <a href="https://vuejs.org/" rel="nofollow">Vue</a>, <a href="https://svelte.dev/" rel="nofollow">Svelte</a>, <a href="https://preactjs.com/" rel="nofollow">Preact</a>, <a href="https://www.solidjs.com/" rel="nofollow">Solid</a>, <a href="https://astro.build/" rel="nofollow">Astro</a>, and others are all <em>far</em> past that point, well-supported and well-maintained. So it clearly isn’t just that.</p>
<p>So what <em>is</em> the sticking point? I have a theory:</p>
<p>We’ve been trained that packages need to be built <em>specifically for our framework</em>.</p>
<p>You could reasonably argue that mindset started with jQuery, but I think React accelerated it.</p>
<p>With React, any time we needed a module or a widget or a library to do something specific (a carousel, a map, an accordion, or whatever else), <em>it had to be a React thing</em>; a plain web thing or a vanilla JavaScript thing just wouldn’t do. All of React’s rules and handling of state and quirks of component lifecycles meant that any available package or library which <em>wasn’t</em> explicitly written for React probably wasn’t going to work.</p>


<p>React trained us that things need to be built <em>specifically for a certain framework</em>. But that’s not very true anymore, and it arguably never should have been.</p>

<p>We shouldn’t <em>need</em> to do that—especially for a framework that so often claims it’s “just JavaScript.” If it’s <em>just JavaScript</em>, then it should <em>just work</em> with anything that’s <em>actually just JavaScript</em>.</p>
<p>Sure, other frontend frameworks have their own rules and conventions about state and architecture. You can step on figurative rakes in their yards, too. And yes, there will always be things that are, and need to be, built specifically to work with Svelte or Vue or whatever else.</p>
<p>But crucially—and I want to emphasize this as strongly as possible:</p>


<p>No other modern frontend framework is as stubbornly incompatible with the platform as React is.</p>

<p>If you’re building using other modern tools and frameworks, it’s <em>far</em> more likely that the vanilla JavaScript packages available will work just fine for you—and there are <em>thousands</em> of them. They’re far less likely to cause issues with render cycles, or other framework-specific issues. Not to mention: they all have the option of using web components, too.</p>
<p>You often don’t <em>need</em> a specialized package or library tailor-built for your thing, because your thing probably already works with the platform, and therefore, everything else that’s already out there.</p>
<p><a href="https://preactjs.com/guide/v10/signals/" rel="nofollow">Preact Signals</a> is a phenomenal example: although built for use with Preact, it can be imported and used in <em>any</em> framework, or even in vanilla JavaScript. Web components, too, are compatible with just about any modern non-React framework.</p>
<p>Where the frameworks fall short, it’s likely the platform already has the thing you need. (Form submission, for example; always a pain point in React, now made infinitely easier by two-way data binding and just using the conventions browsers give to us.)</p>
<p>And worst-case, it’s probably a lot <em>easier</em> to build whatever thing you need than it was in React. (It shouldn’t take very much comparing of <code>useState</code> with other frameworks’ versions to see that.)</p>
<p>Being newer is often considered a disadvantage by conservative-minded developers who are wary to test the waters with something that hasn’t been thoroughly vetted in every which way possible. But it’s important to remember that being new is <em>also</em> an advantage, because there’s less tech debt and old browser support to worry about—<em>and</em> new things are free to iterate further on existing good ideas and more modern browser features.</p>
<h3 id="react-hooks-are-actually-kind-of-outdated">React hooks are actually kind of outdated</h3>
<p>Hooks are the newest evolution of React, replacing class components.</p>
<p>Credit where it’s due: hooks <em>were</em> a massive shift in the frontend space. They revolutionized how we composed logic and state in our applications. Hooks are undeniably great, and pretty much every framework has coalesced around a hooks-like model for managing state.</p>
<p>But React hooks aren’t new anymore. (In fact, stable React with hooks is almost exactly the same age as my kid, and he’s starting pre-k in a couple of weeks.)</p>
<p>Hooks are no longer a competitive advantage, or even a notable feature; they’re the baseline. They’re just the way we do things.</p>


<p>Every other framework not only has its own implementation of hooks, but notably: every one of them is faster, smarter, easier to write, or a combination of all three.</p>

<p>Preact’s Signals warrant mention here; so do Svelte’s dead-simple stores. Solid, too, has Signals. Even Vue 3’s composition API, which is pretty directly inspired by hooks, has some key advantages over the React implementation.</p>
<p>Hooks are an excellent pattern, and React deserves credit for popularizing it. But pretty much every other framework does hooks better, with fewer rules, and with less boilerplate.</p>
<p>If you’re unfamiliar with the concept of Signals: it’s a crude oversimplification, but you could think of them as the next, better evolution of reactive state; an update to hooks, with better defaults around what causes re-renders, to only re-render the nodes that need to be re-rendered, instead of entire components.</p>
<h3 id="you-dont-need-to-micro-manage-rendering-anymore">You don’t need to micro-manage rendering anymore</h3>
<p>I have a confession to make: I’m still not exactly sure what the difference between <code>useMemo</code> and <code>useCallback</code> is—or when you should and shouldn’t use them—even though I <em>literally read multiple articles on that exact topic earlier today</em>. (No joke.)</p>
<p>I have a second confession: it’s still not intuitive to me what should and shouldn’t go into the <code>useEffect</code> dependency array, or why. I feel like every time I write a <code>useEffect</code> call, I spend like 15 minutes refactoring my code to be in a shape the linter likes, even when <em>I’m 99% certain it’s actually fine</em> and it’s not going to suck my app into an infinite abyss.</p>
<p>I’m betting if you use React, you can probably relate to those confessions. And maybe you’ve even just accepted that confusion and ambiguity as normal. But if so, you should know:</p>
<p>We haven’t had to do this kind of rendering cycle micromanagement in other frameworks for <em>years</em>.</p>


<p>These days, frameworks are smart enough to handle this kind of thing without you needing to hold their hand and explain what they should do.</p>

<p>They already know not to waste precious resources re-rendering when there’s no real need. They’re intelligent enough to only update values, and not constantly reevaluate things that don’t need it.</p>
<p>…Most of the time, anyway. They’re not perfect. But they <em>are</em> much better than React at knowing what to do, and doing it in a performant way by default.</p>
<p>You <em>might</em> need to optimize some things in other frameworks, too. They’re not perfect. But by the time you do, you’re way, <em>way</em> past the point where you would’ve needed to in React.</p>
<h3 id="nobody-else-is-afraid-of-their-frameworks-version-of-useeffect">Nobody else is afraid of their framework’s version of <code>useEffect</code></h3>
<p>When you want a component to just do something when it enters the DOM—and/or when you want it to recalculate something dynamically, based on some other data or variable(s)—just about every other framework has a better way than <code>useEffect</code>.</p>
<p>I don’t think I need to harp too much on this here, because even within React communities, <code>useEffect</code> is considered notoriously hazardous, and often even avoided altogether. But trust me: no other non-React-based frontend framework has people so afraid to use such a normal, useful feature, and nowhere else are there such obtuse rules around it.</p>
<p>Nobody else is looking at third-party packages just to do something when a component is mounted without shooting themselves in the foot.</p>
<h3 id="scaling-isnt-really-a-frontend-concern-anymore">Scaling isn’t really a frontend concern anymore</h3>
<p>This is the <em>other</em> question people immediately ask when a new(er than React) framework comes up: <em>does it scale</em>? But I believe that question might be a bit outdated.</p>
<p>It’s worth remembering: the world that gave us React had a different set of problems.</p>
<p>In that world, most frontend UIs were built either with vanilla JavaScript, or with jQuery (or similar alternatives). And that method of building apps, as we now know, didn’t scale well beyond a certain limit.</p>
<p>That’s because you had to write your own selectors for each and every element and DOM node you might want to interact with, and you had to come up with your own manual way of tracking and syncing state. That usually involved writing to and retrieving from the DOM, which was messy, error-prone, and most importantly, slow. (That’s where the virtual DOM came in, but even <em>that</em> has been <a href="https://svelte.dev/blog/virtual-dom-is-pure-overhead" rel="nofollow">pretty thoroughly outdated for years</a>.)</p>
<p>Writing modular code back then was difficult to impossible, and JS files often ballooned to hundreds of lines, if not thousands. If multiple authors were working on the same project, they’d often reinvent, repeat, or even override each other’s code (partly because code often went into a shared global namespace, which made collisions even more likely). And the bigger or more complex your app (<em>Facebook</em>), the worse the problem was.</p>
<p>It’s important to remember: that’s our baseline for “does it scale?” as it relates to frontend. Does it stay reasonably maintainable even if my app grows exponentially?</p>


<p>The worry that a frontend framework might not scale is as old as jQuery, and should be considered just as antiquated in relation to modern web development.</p>

<p>React solved many of these problems, yes. But it didn’t do so by being a marvel of modern engineering, so much as simply coming up with a good way to manage and share state, make data reactive, abstract complexity, and enable developers to share the same programming patterns without conflicts, namespace collisions, or overrides.</p>
<p>React wasn’t the best, only, or even <em>first</em> solution to frontend scalability; it’s just one of many possible versions of the same paradigm.</p>
<p>(It also happens to be among the oldest.)</p>
<p>How do I know this? Because a plethora of benchmark tests have been run, with publicly available results, comparing the performance of React to every other frontend framework at scale. (I’m not linking to any here, because they’re readily available online.) They all confirm that just about every other option in the frontend space does as well or better than React—and in many cases, <em>dramatically</em> better.</p>
<p>Here I’m referring to scaling in the general sense; making sure complexity stays minimal, and doesn’t grow linearly as the app increases in size. Certainly, some frameworks will scale much better or worse than others in terms of, say, building static HTML from Markdown files, or other more specialized tasks.</p>
<h3 id="server-side-rendering-isnt-special-anymore">Server-side rendering isn’t special anymore</h3>
<p>An earlier version of this section erroneously conflated server-side rendering with React Server Components (for reasons that I hope are at least understandable, given the confusing naming conventions).</p>
<p>There was a time, several years ago, when React was pretty much the only game in town when it came to server-rendered content (mainly via Next JS). People were rightly excited for the idea that React could be rendered on a server as HTML, instead of on the client as a Single-Page App (SPA). The speed and SEO gains were impossible to ignore, and initially, it took other frameworks a bit to catch up.</p>
<p>However, as is a theme with these things in general, and with this post in particular: the first to iterate is rarely the best.</p>
<p><a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a> is server-rendered by default, without you needing to do anything, and offers fine-grained control over its rendering patterns. <a href="https://nuxt.com/" rel="nofollow">Nuxt</a>, Vue’s meta-framework, was earlier to the game (being obviously inspired by Next).</p>
<p><a href="https://fresh.deno.dev/" rel="nofollow">Fresh</a> (Deno’s frontend framework) is entirely server-rendered, except for what you designate as an “island” (client-rendered); anything else just ships as static HTML. Fresh also uses Preact (which, again, is even faster than React, and which has <a href="https://preactjs.com/guide/v10/signals/" rel="nofollow">Signals</a>, a much more performant and ergonomic version of <code>useState</code> and the reactivity model).</p>
<p>Astro has server-rendering, and just lets you server-render whatever flavor of components you want. It can render other frameworks’ components just fine, and has even been noted as a major performance upgrade from Next, in some cases.</p>
<p><a href="https://start.solidjs.com/getting-started/what-is-solidstart" rel="nofollow">SolidStart</a> (Solid’s meta-framework) has server rendering. Qwik is entirely built around it. Even some older frameworks like <a href="https://emberjs.com/" rel="nofollow">Ember</a> and <a href="https://angularjs.org/" rel="nofollow">Angular</a> have a story here; I’m sure I’m leaving out others, too.</p>
<p>Point is: way back when, React was one of few frameworks that had the concept of rendering client view framework components on a server. But now, server rendering is table stakes. A lot of newer frameworks don’t just have the <em>option</em> to render on the server; they do it <em>by default</em>.</p>
<p>PHP is back, baby.</p>
<h3 id="two-way-data-binding-isnt-hard-and-it-isnt-a-bad-idea">Two-way data binding isn’t hard and it isn’t a bad idea</h3>
<p>I think it’s important to remember that React was created by Facebook, in order to solve Facebook’s unique set of problems.</p>
<p>One of React’s strongest opinions—that data should flow only one way (top down)—is a good example of how the engineering challenges of Facebook in the early 2010s indelibly shaped React’s architecture.</p>
<p>For some time, it seemed like one-way data flow was considered a best practice. These days, though, we’ve mostly figured out solutions to the pitfalls of two-way data binding, and found that in many cases, it’s actually much more convenient.</p>
<p>Working with forms in React is notoriously cumbersome because every user keystroke is a two-step process: get the value from the input; then set the state to match it (which in turn needlessly re-renders the input, to contain the exact value it already did, but synced up with React state). Sure, it’s usually too fast to notice, but it’s a lot of extra work.</p>
<p>Svelte, Vue, and many others don’t have this issue. You can just bind state in such a way that it updates automatically from both ends. If the state changes, the DOM updates; if the DOM changes, the state updates.</p>
<p>This way, you don’t have to do the multi-step dance. If you just want to capture, say, the value of a text box, you do two-way data binding. Then, when the user types into the field, the data updates automatically, and you can get it whenever the time is right with no further steps. If in the meantime you need to do something like set a value or clear the field, that’s also a simple one-liner.</p>
<p>Two-way data binding lets you keep data and the DOM in sync without the need to constantly make sure one is keeping up with the other.</p>
<p>Could you get in trouble using these? For sure. But I find that dogmatic ideals of best practices get in the way as much or more than they help. One-way data flow is a prime example.</p>
<h3 id="styling-is-easy-actually">Styling is easy, actually</h3>
<p>If you work mostly in React, it’s quite possible you’ve gone through two, three, or more iterations of handling styles in your frontend components.</p>
<p>You might have imported .css files straight into JSX components, or used CSS Modules, Styled Components, and/or Tailwind (probably with either the <code>classnames</code> or <code>tailwind-merge</code> packages—or maybe even both, plus some extra Tailwind add-ons). And those are just the most popular options.</p>
<p>Tailwind is its own rabbit hole (and its own frontend framework I’m not particularly a fan of; I consider it cutting against the grain of the platform in exchange for short-term gains that eventually compound into long-term losses). But in any case, these styling solutions exist and see significant adoption at least partly because React’s had a vacuum in place of first-party styling options for as long as it’s been around.</p>


<p>You might not realize styling is a solved problem in several other frameworks.</p>

<p>In particular, Vue and Svelte both have their own component styling story. They both have component-level scoping (Vue’s is opt-in; Svelte’s is opt-out). They both work wonderfully with vanilla CSS, if that’s the way you want to go. But both of them—along with every other frontend framework—are still compatible with CSS modules, Tailwind, Sass, or whatever else you like to use.</p>
<p>But most importantly: all the supposed problems with CSS—whether you actually consider them problems or not—are fully addressed by the built-in style handling. You don’t need a mess of packages and configs nearly as much anywhere else, because scoped CSS solves just about every issue you could possibly imagine.</p>
<p>Seriously; read through any list of reasons CSS is supposedly bad (it’s not, but people who are bad at it like to say that). Just about any critique you could possibly have of CSS is solved by scoped styling, and multiple non-React frameworks just come with it already built in.</p>
<h3 id="frameworks-arent-as-hard-to-learn-anymore">Frameworks aren’t as hard to learn anymore</h3>
<p>I theorize developers mainly trained on React think back to how difficult it was to learn, and assess the learning curve of other frameworks similarly. And that’s probably part of what keeps us from trying new things; it seems really hard, because it sure was the first time.</p>
<p>All the ins and outs of state management, props, nesting, component lifecycles, hooks, and of course, how to write JSX…it’s a lot. Even the most ardent React fans would likely concede it’s not the easiest thing for beginners to pick up quickly. (Anyone who says otherwise has probably forgotten what it was like to be a beginner.)</p>
<p>If you can relate, I have good news:</p>


<p>There’s no comparable tool as difficult to learn as React is. But once you know one framework, you have a huge head start on all the others.</p>

<p>I compare this to learning your <em>second</em> musical instrument (not just to tie this back to music again). The <em>first</em> time you learn to play, you’re learning <em>everything about music</em>, on top of learning your specific instrument, and how to get it to make the sounds you want. But when you learn your <em>second</em> instrument, you get to skip so much. All the concepts are familiar. You understand music. All you need to do is transfer your existing knowledge and muscle memory into a slightly different shape.</p>
<p>Frontend is similar: every frontend framework has components; they’re all compatible with TypeScript; they all have the concept of props, children, and reactive state. These are things we’ve generally agreed we like and are good. They just have different takes on implementation.</p>
<p>And speaking of which: while React undoubtedly helped to proliferate these ideas, it would be silly to consider React the ideal implementation of them.</p>
<p>Great things are created through iteration, and for the most part, other choices in the frontend space that came later have the distinct advantage of iterating on top of the core ideas of React.</p>
<p>This means React is a bit like a git branch that’s fallen well behind <code>main</code>. You might not realize it, if React is the star your galaxy orbits around, but…well, frontend has moved on. The ecosystem has taken those ideas and run with them to make things that are even better.</p>
<p>We have no shortage of more performant, less complex, less difficult-to-learn options available to us now. And if you know React already, none of them will be very hard to learn as well.</p>
<h2 id="part-3-the-other-stuff-you-should-try">Part 3: the other stuff you should try</h2>
<p>You probably started wondering a few dozen paragraphs ago: if React is so antiquated, what’s the alternative?</p>
<p>I’m going to cover several here, and mention their use cases as well. One of the issues with React is that it’s long tried to be everything for everyone, and useful though a React-shaped tool might be, I think maybe two or three different tools could be better than one Swiss army knife.</p>
<p>Two quick notes before we dive in, though:</p>
<ol><li><p>I list several options here, for the sake of covering all the other modern frameworks I mentioned above. <strong>I don’t expect anyone to learn about—let alone <em>use</em>—all of them</strong>. If you have to pick one, go with Svelte, or maybe Vue. But in any case, know that I’m only listing them all for the sake of thoroughness.</p></li>
<li><p>I didn’t list <em>all</em> the options here. There are others.</p>
<p>I omitted Ember and Angular, for example, because they’re both older than React, and don’t generally tend to outperform React significantly, if at all, in benchmark tests (sorry, Mel).</p>
<p>I also omitted the lightweight options like <a href="https://alpinejs.dev/" rel="nofollow">Alpine</a> and <a href="https://github.com/vuejs/petite-vue" rel="nofollow">Petite Vue</a>, since those are more replacements for jQuery than React, and shine where you might not need something as heavy-handed as a framework.</p>
<p>Finally, I also omitted exceptionally good tools in and around this category, like <a href="https://www.11ty.dev/" rel="nofollow">Eleventy</a>, since it’s more of a pure static site generator than a framework. (Still worth a look if you’re using Gatsby, however.)</p></li></ol>
<p>All that said: here’s your Discover Weekly.</p>
<h3 id="svelte-my-personal-pick"><a href="https://svelte.dev/" rel="nofollow">Svelte</a> (my personal pick)</h3>
<blockquote><p><em>Ladies and gentlemen of the class of 2023: use Svelte.</em></p>
<p><em>If I could offer you only one tip for the future, Svelte would be it.</em></p></blockquote>
<p>Joking aside: if I were to pick one thing from this list to recommend over React, it would be <a href="https://svelte.dev/" rel="nofollow">Svelte</a>. I’ve long maintained that “Svelte is React, but without the bullshit,” as I originally quipped on Twitter back in 2019 (RIP), and if anything, that’s only grown truer over time.</p>
<p>Svelte is delightfully simple to use, comparatively easy to learn (especially if you’re coming from the React world already; even the syntax is often similar), much, much more performant in just about all cases, and capable of anything React is and more. This site, and all my own side projects these days, are written in <a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a>.</p>
<p>Svelte is fast; it’s comparable to the fastest options available. Its DX is phenomenal; it regularly appears at or near the top of most-loved frameworks in developer surveys.</p>
<p>Svelte hews as closely to the web platform as possible, so even though it’s incredibly powerful, its concepts will be largely familiar. Svelte also includes transitions, easings, CSS handling, component-scoped styles, and more niceties out of the box.</p>
<p>That might make you wonder about framework size, but where Svelte differs is: instead of being a JavaScript runtime, it’s a compiler. Anything you don’t use is stripped away at build time, and your code is transpiled into tiny bits of vanilla JavaScript. That means Svelte’s bundles are generally a fraction the size of React’s.</p>


<p>Although it feels and works like a framework, Svelte is, essentially, a small, elegant superset of HTML, with a delightfully simple syntax, which compiles to fast, minimal bundles.</p>

<p>Svelte’s own meta-framework, <a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a>, is highly versatile and powerful, capable of static, server-rendered, deployment to the edge, and even mixing per-route. It hit version 1.0 at the end of 2022 and is very ready for production. (It’s also supported by Vercel, who make Next.js as well.)</p>
<h4 id="svelte-is-recommended-if">Svelte is recommended if:</h4>
<p>You want to rediscover the joy of frontend with (what I consider to be) the best all-around option, for the reasons above.</p>
<h4 id="svelte-replaces">Svelte replaces:</h4>
<p>Anything you’re doing with React. Svelte can replace React itself, or SvelteKit is versatile enough to sub in for Next, Gatsby, and/or Remix (or even all at once).</p>
<h3 id="vue"><a href="https://vuejs.org/" rel="nofollow">Vue</a></h3>
<p><a href="https://vuejs.org/" rel="nofollow">Vue</a> is possibly the closest option to React, and likely has the next-biggest ecosystem. It’s significantly more performant than React, however, and a bit more UI-focused.</p>
<p>In some ways, Vue is the smallest leap from React, especially now that it has a similar hooks-based approach in Vue 3. But Vue uses a templating language closer to default HTML than to JSX, which makes it much easier to write conditionals and loops in template files, without having to reach for workarounds like <code>map</code> and ternaries.</p>
<p>Vue has a similar meta-framework to Next in <a href="https://nuxtjs.org/" rel="nofollow">Nuxt</a>, which is well maintained and adding powerful new features all the time. Vue is also a bit more batteries-included than React, coming with things like scoped CSS handling and easy transitions/animations out of the box.</p>
<h4 id="vue-is-recommended-if">Vue is recommended if:</h4>
<p>Community size/overall framework popularity is an important factor for you; you want something like React, but more batteries-included or HTML-like; you prefer your framework to be independent and <em>not</em> be owned by a large corporation.</p>
<h4 id="vue-replaces">Vue replaces:</h4>
<p>React itself, or <a href="https://nuxt.com/" rel="nofollow">Nuxt</a> can replace anything you might be using Next for.</p>
<h3 id="solid"><a href="https://www.solidjs.com/" rel="nofollow">Solid</a></h3>
<p><a href="https://www.solidjs.com/" rel="nofollow">Solid</a> is what I would call React, but better. It looks almost (if not entirely) identical to React in many cases, but Solid is far, far more performant. It’s one of the fastest options available, in fact.</p>
<p>Solid essentially starts with React, and then rethinks it to eliminate complexity, performance issues, and a lot of boilerplate. Signals appear as a concept in Solid, which eliminate a great deal of the confusion and footguns around component rendering and lifecycles. It might even be fair to say Solid is React, if React was built in the modern era, on top of all the lessons we’ve learned since 2013.</p>
<p>Solid also offers its own meta-framework in <a href="https://start.solidjs.com/getting-started/what-is-solidstart" rel="nofollow">SolidStart</a>, though that is currently in beta. Solid itself is plenty mature enough to use, though, and boasts an impressive gallery of sponsors.</p>
<h4 id="solid-is-recommended-if">Solid is recommended if:</h4>
<p>You generally like React (and JSX), but you just wish it was more modern, faster and/or easier; performance is an absolute top priority.</p>
<h4 id="solid-replaces">Solid replaces:</h4>
<p>React and React DOM. SolidStart will likely be capable of replacing Next one day, but it’s still in beta as of this writing.</p>
<h3 id="fresh"><a href="https://fresh.deno.dev/" rel="nofollow">Fresh</a></h3>
<p><a href="https://fresh.deno.dev/" rel="nofollow">Fresh</a> is a server-rendered frontend framework with islands architecture, built on Deno. It’s a bit younger than most of the rest of the items on this list, but it’s full of promise as a minimal-JS, island-based framework that can run on the edge—powered by Deno, no less, which means your server code is faster, more secure, TypeScript by default, and all the other benefits Deno brings over traditional Node (such as easier, first-party linting, testing, and code formatting settings).</p>
<p>Every Fresh component is either static-rendered and served at response time as HTML, with no JavaScript, or an “island,” which means it renders only on the client. You can mix and match as needed. Because it runs on Deno, this opens the gate for extremely fast, dynamic content that loads as quickly as possible on any device anywhere in the world.</p>
<p>Fresh uses Preact, so you know it’s fast, and won’t be difficult to pick up if you’re coming from React, either. And again: building on Deno feels great.</p>
<h4 id="fresh-is-recommended-if">Fresh is recommended if:</h4>
<p>You like the idea of a server-side app globally available in the cloud, shipping absolutely minimal JavaScript, and/or building on the latest technology.</p>
<h4 id="fresh-replaces">Fresh replaces:</h4>
<p>Remix is probably the closest thing to Fresh in React-land.</p>
<h3 id="astro"><a href="https://astro.build/" rel="nofollow">Astro</a></h3>
<p><a href="https://astro.build/" rel="nofollow">Astro</a> is a next-gen, highly performant static site generator that does more than static. Astro is one of the newest options on this list, but it’s already at a very stable 1.0 release and has garnered widespread praise and adoption.</p>
<p>Built mainly to be a new generation of SSG (hey, React fans: it supports JSX and MDX), Astro now also features dynamic, server-side capabilities as well. I’d definitely recommend it over, say, Gatsby, or for any content-heavy or static sites.</p>
<p>The real killer feature is: Astro ships zero JavaScript by default. You opt in to only what you want to use.</p>
<p>Astro is also compatible with whatever frontend framework you want to use, so if you prefer to template in React, Vue, Svelte, or others, you can!</p>
<h4 id="astro-is-recommended-if">Astro is recommended if:</h4>
<p>You’re building a largely static, or content/Markdown-based site (even if you may need some server-side rendering or logic); you want to ship minimal JavaScript; you want to bring your own frontend framework.</p>
<h4 id="astro-replaces">Astro replaces:</h4>
<p>Gatsby, or similar React-based content tools.</p>
<h3 id="preact"><a href="https://preactjs.com/" rel="nofollow">Preact</a></h3>
<p>You probably already know about <a href="https://preactjs.com/" rel="nofollow">Preact</a> if you live in React land, but it warrants mention here. It’s a much slimmer, much faster version of React. Although it began more-or-less as a drop-in replacement for React, it’s beginning to gain some superior features React doesn’t have (like <em>Signals</em>, which we’ve already mentioned).</p>
<h4 id="preact-is-recommended-if">Preact is recommended if:</h4>
<p>You want to stick with React, essentially, but you just want it to be faster.</p>
<h4 id="preact-replaces">Preact replaces:</h4>
<p>React. (Actually, it just adds a P to the beginning. The P stands for performance. I made all that up; don’t blame the Preact team for that.)</p>
<h3 id="qwik"><a href="https://qwik.builder.io/" rel="nofollow">Qwik</a></h3>
<p><a href="https://qwik.builder.io/" rel="nofollow">Qwik</a> server-renders React-like code (JSX) with a new approach to hydration and performance. In fact, what it does can’t really be called “hydration” at all; instead, it serializes JavaScript into the DOM, and loads it in tiny bits only when it’s needed. Qwik is one of the deeper cuts on this list, but if you have a <em>lot</em> of interactivity that you need to run as fast as possible, it’s well worth a look.</p>
<h4 id="qwik-is-recommended-if">Qwik is recommended if:</h4>
<p>You’re shipping <em>lots</em> of JavaScript to the browser, and you want a way to make that more performant.</p>
<h4 id="qwik-replaces">Qwik replaces:</h4>
<p>React itself, allowing it to run very efficiently on the edge.</p>
<h3 id="web-component-libraries">Web component libraries</h3>
<p>I won’t go very deep on this one, because frankly, I’m not the guy for that. I don’t have the experience with either <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components" rel="nofollow">web components</a> on their own, or web component frameworks, to speak well on the topic.</p>
<p>That said, there <em>is</em> a certain class of projects that could benefit from a <a href="https://www.webcomponents.org/libraries" rel="nofollow">web component framework/library</a> like <a href="https://lit.dev/" rel="nofollow">Lit</a>, <a href="https://stenciljs.com/" rel="nofollow">Stencil</a>, <a href="https://www.polymer-project.org/" rel="nofollow">Polymer</a>, or others. Rather than generating “proprietary” components in a specific frontend framework, these libraries help you write actual web components, which are then portable to any web project.</p>
<p>In my opinion, most projects still benefit from using a frontend framework over pure web components—or, at the very least, both together. Maybe that will change in the future, but for now, I think the tradeoffs still tilt away from a pure web component approach in most cases.</p>
<p>Still, there are certainly use cases for which a purely web component-based approach ought to be considered. And for <em>those</em> projects, React is definitely overkill. The web component libraries mentioned above would be a much better fit.</p>
<h4 id="web-component-libraries-are-recommended-if">Web component libraries are recommended if:</h4>
<p>You need to reuse the same components in multiple environments; want to future-proof yourself against framework changes; or just prefer using the platform, and are prepared to deal with the tradeoffs of web component authoring.</p>
<h4 id="web-components-replace">Web components replace:</h4>
<p>React, but maybe only partially, depending on your use case</p>
<h2 id="epilogue">Epilogue</h2>
<p>This post is, admittedly, a lot like my post from last year, <a href="https://joshcollinsworth.com/blog/self-fulfilling-prophecy-of-react"><em>The self-fulfilling prophecy of React</em></a>. It treads some of the same territory, and makes some of the same arguments (albeit hopefully in new ways or from new perspectives).</p>
<p>I didn’t set out to repeat myself, but clearly, I think about this stuff a lot—spurred no doubt by my professional shift to working with React full time around the time that post was published, by coincidence.</p>
<p>I’ve come to believe React’s popularity is, in no small part, because folks don’t look beyond it. It’s not the greatest, but most people aren’t looking for the greatest; they’re just looking for good enough. (We’re humans. There are a lot of personal, emotional, irrational reasons for our decisions, all of us, and that’s fine. We’re busy.)</p>
<p>It seems like we adopt technologies in leaps, rather than in a linear motion, at least in the world of frontend. Part of what caused everyone to jump on the React bandwagon was that <em>everyone</em> at the time was stuck on antiquated technology, and was looking for something better. We didn’t gradually advance to the new thing, in small steps (maybe because that wasn’t really an option to begin with); we took a giant <em>leap</em> from where we were to the next thing.</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/d1e525bee1dc5534a4f1c1466ce1a429e2b2d286/4f0d3/images/post_images/tech-adoption.png" alt="A linear line with an arrow pointing forward, labeled 'progress.' There are a few arced leaps of progress on top of the line, jumping from left to right, labeled 'adoption.' The final leap, however, lands well short of the furthest edge of the straight 'progress' line."></p>
<p>But the thing is: we’ve been sitting there, in mostly that same spot, since we took that leap all those years ago.</p>
<p>My sense is: we’re beginning to near another leap.</p>
<p>I don’t know what it will be, or why. But I think we’re starting to feel all the problems React actually <em>doesn’t</em> solve for us, like we felt with jQuery back in those days. And I think eventually, it will be clear that it’s time to advance.</p>
<p>What will that new thing be? I don’t know. Maybe it’ll just be the web platform. Maybe we won’t even need frameworks. Maybe it’ll be a framework above; maybe it’ll be something we haven’t even seen yet. Maybe it won’t even be <em>a thing</em>; maybe there will be more diversity of tooling and less coalescing around one single accepted standard (though of all the above options, I’d say that seems the least likely, because again: humans. We’re busy little monkeys and so we like defaults.)</p>
<p>I think, though, that the delta between React and that thing, whatever it is, will continue to grow larger and larger over time.</p>
<p>So every new day is an even better day than the one before it to explore what you’ve been missing.</p>
<p>Happy listening.</p>

		

		
</article></main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Bankman-Fried is going to jail (144 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/08/sam-bankman-fried-is-going-to-jail/</link>
            <guid>37131626</guid>
            <pubDate>Tue, 15 Aug 2023 08:49:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/08/sam-bankman-fried-is-going-to-jail/">https://arstechnica.com/tech-policy/2023/08/sam-bankman-fried-is-going-to-jail/</a>, See on <a href="https://news.ycombinator.com/item?id=37131626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      From Bahamas penthouse to Manhattan’s big house    —
</h4>
            
            <h2 itemprop="description">Judge also denied SBF's request to delay jail time.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/GettyImages-1258714385-800x534.jpg" alt="Sam Bankman-Fried.">
      <figcaption><div><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/GettyImages-1258714385.jpg" data-height="683" data-width="1024">Enlarge</a> <span>/</span> Sam Bankman-Fried.</p></div></figcaption>  </figure>

  




<!-- cache hit 57:single/related:14f233083c90a25e64cd5632e9f5f425 --><!-- empty -->
<p>A federal judge in New York today ordered disgraced FTX founder Sam Bankman-Fried's to jail after revoking his bail, <a href="https://www.nytimes.com/2023/08/11/technology/sam-bankman-fried-to-be-sent-to-jail-after-judge-revokes-bail.html">The New York Times reported</a>.</p>
<p>Bankman-Fried had been under house arrest, but prosecutors convinced Judge Lewis A. Kaplan of the Federal District Court in Manhattan that Bankman-Fried had fed documents to the media in order to intimidate a witness in the case. Now Bankman-Fried has to prepare his defense to seven criminal charges from jail.</p>
<p>In June, Bankman-Fried filed a motion to dismiss, hoping that some of those charges would be dropped. But Kaplan decided that his arguments in the motion were "either moot or without merit,” <a href="https://www.cnn.com/2023/06/27/business/sbf-motion-to-dismiss-denied/index.html">CNN reported</a>.</p>
<p>A New York Times <a href="https://www.nytimes.com/2023/07/20/technology/ftx-caroline-ellison-bankman-fried.html">report</a> was among media stories that the prosecution shared to convince the court to give Bankman-Fried jail time. In that report, Bankman-Fried shared private writings of Caroline Ellison, a former FTX executive and former girlfriend to Bankman-Fried who has pled guilty and is currently cooperating with law enforcement in their investigation of the cryptocurrency exchange, the Times reported.</p>
<p>Prosecutors claimed that Bankman-Fried shared Ellison's communications to intimidate her. The court found that Bankman-Fried tampered with witnesses at least twice, <a href="https://www.reuters.com/legal/ftxs-bankman-fried-seeking-avoid-jail-due-back-court-2023-08-11/">Reuters reported</a>.</p>
<p>It wasn't just the New York Times report that alarmed the court, however. Bankman-Fried's other communications with the media led the prosecution to request a gag order to block all talks with the media.</p>
<p>According to The New York Times, "The Times, the Reporters Committee for the Freedom of the Press, and a documentarian making a film" about Bankman-Fried "each submitted court filings raising First Amendment concerns about the gag order."</p>
<p>Bankman-Fried requested his detention be delayed, pending an appeal of the order revoking his bail, Reuters reported, but the judge denied that request.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Continuous batching to increase LLM inference throughput and reduce p50 latency (106 pts)]]></title>
            <link>https://www.anyscale.com/blog/continuous-batching-llm-inference</link>
            <guid>37131477</guid>
            <pubDate>Tue, 15 Aug 2023 08:21:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anyscale.com/blog/continuous-batching-llm-inference">https://www.anyscale.com/blog/continuous-batching-llm-inference</a>, See on <a href="https://news.ycombinator.com/item?id=37131477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Due to the large GPU memory footprint and <a href="https://www.anyscale.com/large-language-models">compute cost of LLMs</a>, serving dominates the compute cost for most real world applications. ML engineers often treat LLMs like "black boxes" that can only be optimized with internal changes such as quantization and custom CUDA kernels. However, this is not entirely the case. Because LLMs iteratively generate their output, and because LLM inference is often memory and not compute bound, there are surprising <i>system-level</i> batching optimizations that make 10x or more differences in real-world workloads.</p><p>One recent such proposed optimization is <b>continuous batching</b>, also known as <b>dynamic batching</b>, or batching with <b>iteration-level scheduling</b>. We wanted to see how this optimization performs. We will get into details below, including how we simulate a production workload, but to summarize our findings:</p><ul><li><p>Up to 23x throughput improvement using continuous batching and continuous batching-specific memory optimizations (using <a href="https://twitter.com/zhuohan123/status/1671234707206590464?s=20"><u>vLLM</u></a>).</p></li><li><p>8x throughput over naive batching by using continuous batching (both on <a href="https://docs.ray.io/en/latest/serve/index.html"><u>Ray Serve</u></a> and <a href="https://github.com/huggingface/text-generation-inference"><u>Hugging Face’s text-generation-inference</u></a>).</p></li><li><p>4x throughput over naive batching by using an optimized model implementation (<a href="https://github.com/NVIDIA/FasterTransformer"><u>NVIDIA’s FasterTransformer</u></a>).</p></li></ul><p>You can try out continuous batching today: see <a href="https://github.com/ray-project/ray/blob/cc983fc3e64c1ba215e981a43dd0119c03c74ff1/doc/source/serve/doc_code/vllm_example.py"><u>this example to run vLLM on Ray Serve</u></a>.</p><p>The remainder of this blog is structured as follows:</p><ul><li><p>We’ll cover the basics of how LLM inference works and highlight inefficiencies in traditional request-based dynamic batching policies.</p></li><li><p>We’ll introduce continuous batching and how it answers many of the inefficiencies of request-based dynamic batching.&nbsp;</p></li><li><p>We then discuss our benchmarks and the implications this has on how to serve LLM models cost-effectively.</p></li></ul><hr><h2>The basics of LLM inference</h2><p>There is a lot to know about LLM inference, and we refer users to <a href="https://huggingface.co/docs/transformers/perf_infer_gpu_one"><i><u>Efficient Inference on a Single GPU</u></i></a><i> </i>and <a href="https://huggingface.co/blog/bloom-inference-optimization"><i><u>Optimization story: Bloom inference</u></i></a> for more detail. However, at a high level, LLM inference is pretty straightforward.</p><p>For each request:</p><ol><li><p>You start with a sequence of tokens (called the "prefix" or "prompt").</p></li><li><p>The LLM produces a sequence of completion tokens, stopping only after producing a stop token or reaching a maximum sequence length. </p></li></ol><p>This is an iterative process. You get one additional completion token for each new forward pass of the model. For example, suppose you prompt with a sentence "What is the capital of California: ", it would take ten forward pass iterations to get back the full response of ["S", "a", "c", "r", “a”, "m", "e", "n", "t", "o"]. This example simplifies things a little bit because in actuality tokens do not map 1:1 to ASCII characters (a popular token encoding technique is <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding"><u>Byte-Pair Encoding</u></a> which is beyond the scope of this blog post), but the iterative nature of generation is the same regardless of how you tokenize your sequences.</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/4Htl7q5sOaX47ViD1EaMdT/039ba19b73bcf58e7be4130d53b147d4/01_diagram-llm-basics_aspect_ratio.png" alt="cb 01 diagram-llm-basics"></p></div><p><span>Simplified LLM inference. This toy example shows a hypothetical model which supports a maximum sequence length of 8 tokens (T1, T2, …, T8). Starting from the prompt tokens (yellow), the iterative process generates a single token at a time (blue). Once the model generates an end-of-sequence token (red), the generation loop stops. This example shows a batch of only one input sequence, so the batch size is 1.</span></p></div><p>Now that we understand the simplicity of the iterative process, let’s dive deeper with some things you may not know about LLM inference:</p><ol><li><p>The initial ingestion (“prefill”) of the prompt "What is the capital of California: " takes about as much time as the generation of each subsequent token. This is because the <a href="https://github.com/huggingface/text-generation-inference/tree/f59fb8b630844c2ad2cd80e689202de89d45c37e/router#prefill-decode-and-past-key-values"><u>prefill phase</u></a> pre-computes <a href="https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache"><u>some inputs</u></a> of the attention mechanism that remain constant over the lifetime of the generation. This prefill phase efficiently uses the GPU’s parallel compute because these inputs can be computed independently of each other.</p></li><li><p>LLM inference is <a href="https://en.wikipedia.org/wiki/Memory_bandwidth"><u>memory-IO bound</u></a>, not compute bound. In other words, it currently takes more time to load 1MB of data to the GPU’s compute cores than it does for those compute cores to perform LLM computations on 1MB of data. This means that LLM inference throughput <i>is largely determined by how large a batch you can fit into high-bandwidth GPU memory</i>. See <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-gpu-background/index.html#understand-perf"><u>this page</u></a> in the NVIDIA docs for more details.</p></li><li><p>The amount of GPU memory consumed scales with the base model size + the length of the token sequence. In <a href="https://github.com/ray-project/llm-numbers#1-mb-gpu-memory-required-for-1-token-of-output-with-a-13b-parameter-model"><i><u>Numbers every LLM developer should know</u></i></a>, it’s estimated that a 13B parameter model consumes nearly 1MB of state for each token in a sequence. On a higher-end A100 GPU with 40GB RAM, back-of-the-envelope math suggests that since 14 GB are left after storing the 26GB of model parameters, ~14k tokens can be held in memory at once. This may seem high but is actually quite limiting; if we limit our sequence lengths to 512, we can process at most ~28 sequences in a batch. The problem is worse for higher sequence lengths; a sequence length of 2048 means our batch size is limited to 7 sequences. Note that this is an upper bound since it doesn’t leave room for storing intermediate computations.</p></li></ol><p>What this all means is that there is substantial “room on the table” so to speak if you can optimize memory usage. This is why approaches such as model quantization strategies such as <a href="https://github.com/PanQiWei/AutoGPTQ"><u>AutoGPTQ</u></a> are potentially so powerful; if you could halve the memory usage by moving from 16-bit to 8-bit representations, you could double the space available for larger batch sizes. However, not all strategies require modifications to the model weights. For example, <a href="https://github.com/HazyResearch/flash-attention"><u>FlashAttention</u></a> found significant throughput improvements by reorganizing the attention computation to require less memory-IO.</p><p>Continuous batching is another memory optimization technique which does not require modification of the model. We next explain how naive batching works (and is inefficient), and how continuous batching increases the memory-efficiency of LLM generation.</p><hr><h2>LLM batching explained</h2><p>GPUs are massively-parallel compute architectures, with compute rates (measured in floating-point operations per second, or flops) in the teraflop (<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf"><u>A100</u></a>) or even petaflop (<a href="https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet"><u>H100</u></a>) range. Despite these staggering amounts of compute, LLMs struggle to achieve saturation because so much of the chip’s memory bandwidth is spent loading model parameters.</p><p>Batching is one way to improve the situation; instead of loading new model parameters each time you have an input sequence, you can load the model parameters once and then use them to process many input sequences. This more efficiently uses the chip’s memory bandwidth, leading to higher compute utilization, higher throughput, and cheaper LLM inference.</p><h3>Naive batching / static batching</h3><p>We call this traditional approach to batching <i>static batching</i>, because the size of the batch remains constant until the inference is complete. Here’s an illustration of static batching in context of LLM inference:</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1LJioEsEdQQpDCxYNWirU6/82b9fbfc5b78b10c1d4508b60e72fdcf/cb_02_diagram-static-batching.png" alt="cb 02 diagram-static-batching"></p></div><p><span>Completing four sequences using static batching. On the first iteration (left), each sequence generates one token (blue) from the prompt tokens (yellow). After several iterations (right), the completed sequences each have different sizes because each emits their end-of-sequence-token (red) at different iterations. Even though sequence 3 finished after two iterations, static batching means that the GPU will be underutilized until the last sequence in the batch finishes generation (in this example, sequence 2 after six iterations).</span></p></div><p>Unlike traditional deep learning models, batching for LLMs can be tricky due to the iterative nature of their inference. Intuitively, this is because requests can "finish" earlier in a batch, but it is tricky to release their resources and add new requests to the batch that may be at different completion states. This means that as the GPU is underutilized as generation lengths of different sequences in a batch differ from the largest generation length of the batch. In the figure on the right above, this is illustrated by the white squares after end-of-sequence tokens for sequences 1, 3, and 4.</p><p>How often does static batching under-utilize the GPU? It depends on the generation lengths of sequences in a batch. For example, one could use LLM inference to emit a single token as a classification task (there are better ways to do this but let’s use this as an example). In this case, every output sequence is the same size (1 token). If the input sequences are also the same size (say, 512 tokens), then each static batch will achieve the best possible GPU utilization.</p><p>On the other hand, a LLM-powered chatbot service cannot assume fixed-length input sequences, nor assume fixed-length output sequences. Proprietary models offer maximum context lengths in excess of 8K tokens at the time of writing. With static batching, variance in generation output could cause massive underutilization of GPUs. It’s no wonder OpenAI CEO Sam Altman described the compute costs as <a href="https://twitter.com/sama/status/1599669571795185665?lang=en">eye-watering</a>.</p><p>Without restrictive assumptions on user input and model output, unoptimized production-grade LLM systems simply can’t serve traffic without underutilizing GPUs and incurring unnecessarily high costs. We need to optimize how we serve LLMs for their power to be broadly accessible.</p><h3>Continuous batching</h3><p>The industry recognized the inefficiency and came up with a better approach. <a href="https://www.usenix.org/conference/osdi22/presentation/yu"><i><u>Orca: A Distributed Serving System for Transformer-Based Generative Models</u></i></a> is a paper presented in OSDI ‘22 which is the first to our knowledge to tackle this problem. Instead of waiting until every sequence in a batch has completed generation, Orca implements <i>iteration-level</i> scheduling where the batch size is determined per iteration. The result is that once a sequence in a batch has completed generation, a new sequence can be inserted in its place, yielding higher GPU utilization than static batching.</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/744TAv4dJIQqeHcEaz5lko/b823cc2d92bbb0d82eb252901e1dce6d/cb_03_diagram-continuous-batching.png" alt="cb 03 diagram-continuous-batching"></p></div><p><span>Completing seven sequences using continuous batching. Left shows the batch after a single iteration, right shows the batch after several iterations. Once a sequence emits an end-of-sequence token, we insert a new sequence in its place (i.e. sequences S5, S6, and S7). This achieves higher GPU utilization since the GPU does not wait for all sequences to complete before starting a new one.</span></p></div><p>Reality is a bit more complicated than this simplified model: since the prefill phase takes compute and has a different computational pattern than generation, it cannot be easily batched with the generation of tokens. Continuous batching frameworks currently manage this via hyperparameter: <a href="https://github.com/huggingface/text-generation-inference/blob/f59fb8b630844c2ad2cd80e689202de89d45c37e/launcher/src/main.rs#L124-L135"><u>waiting_served_ratio</u></a>, or the ratio of requests waiting for prefill to those waiting end-of-sequence tokens.</p><p>Speaking of frameworks, Hugging Face has productionized continuous batching in their Rust- and Python-based <a href="https://github.com/huggingface/text-generation-inference/tree/main"><u>text-generation-inference LLM inference server</u></a>. We use their implementation to understand the performance characteristics of continuous batching in our benchmarks below.</p><p><b><i>Note</i></b><i>: Continuous batching, dynamic batching, and iteration-level scheduling are all close enough in meaning that any one of them can be used to describe the batching algorithm. We chose to use continuous batching. Dynamic batching is fitting but can be confused with request-level batching, where an LLM inference server uses a static batch whose size is chosen when the current batch has completely finished generation. We feel that iteration-level scheduling is descriptive of the scheduling mechanism but not the process as a whole.</i></p><hr><h2>PagedAttention and vLLM</h2><p>For this blog post, we want to showcase the differences between static batching and continuous batching. It turns out that continuous batching can unlock memory optimizations that are not possible with static batching by improving upon Orca’s design.</p><p>PagedAttention is a new attention mechanism implemented in <a href="https://vllm.ai/"><u>vLLM</u></a> (<a href="https://github.com/vllm-project/vllm/tree/main#easy-fast-and-cheap-llm-serving-for-everyone"><u>GitHub</u></a>). It takes inspiration from traditional OS concepts such as <a href="https://en.wikipedia.org/wiki/Memory_paging"><u>paging</u></a> and <a href="https://en.wikipedia.org/wiki/Virtual_memory"><u>virtual memory</u></a>. They allow the KV cache (what is computed in the “prefill” phase, discussed above) to be non-contiguous by allocating memory in fixed-size “pages”, or blocks. The attention mechanism can then be rewritten to operate on block-aligned inputs, allowing attention to be performed on non-contiguous memory ranges.</p><p>This means that buffer allocation can happen just-in-time instead of ahead-of-time: when starting a new generation, the framework does not need to allocate a contiguous buffer of size maximum_context_length. Each iteration, the scheduler can decide if it needs more room for a particular generation, and allocate on the fly without any degradation to PagedAttention’s performance. This doesn’t guarantee perfect utilization of memory (<a href="https://vllm.ai/"><u>their blog</u></a> says the wastage is now limited to under 4%, only in the last block), but it significantly improves upon wastage from ahead-of-time allocation schemes used widely by the industry today.</p><p>Altogether, PagedAttention + vLLM enable massive memory savings as most sequences will not consume the entire context window. These memory savings translate directly into a higher batch size, which means higher throughput and cheaper serving. We include vLLM in our benchmarks below.</p><hr><h2>Benchmarking setup</h2><p>We’ll discuss our experimental setup then dive into the results of our benchmarks.</p><h3>Experiments</h3><p>Our goal is to see how continuous batching performs versus static batching on a simulated real-world live-inference workload. Fundamentally, we care about cost. We break this down into throughput and latency since cost is directly downstream of how efficiently you can serve at a given latency.</p><table><tbody><tr><td><p><b>Benchmark goal</b></p></td><td><p><b>Measurement</b></p></td></tr><tr><td><p>Measure throughput</p></td><td><p>Time-to-process a queue of 1000 requests, each with 512 input tokens and generation length sampled from an exponential distribution.</p></td></tr><tr><td><p>Measure latency</p></td><td><p>Request latencies for 100 requests, with varying input lengths, output lengths, and arrival times at a fixed average rate.</p></td></tr></tbody></table><p>We’ll discuss the datasets and other details of the experiments in their respective results section.</p><h3>Hardware/model</h3><p><br>We benchmark throughput and latency on a single <a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf"><u>NVIDIA A100 GPU</u></a> provided by <a href="https://www.anyscale.com/"><u>Anyscale</u></a>. Our A100 has 40GB of GPU RAM. We selected <a href="https://huggingface.co/facebook/opt-13b"><u>Meta’s OPT-13B</u></a> model because each framework under test had a readily-available integration with this model. We selected the 13B variant because it fits into our GPU without requiring tensor parallelism, yet is still large enough to present memory efficiency challenges. We opt not to use tensor parallelism, where each transformer block is split over multiple GPUs, to keep our experiments simple, although both static batching and continuous batching work with tensor parallelism.</p><h3>Frameworks</h3><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3K202bzJfK6ZlhmJpgwZ9q/7ccf0aacaf298e24bf824ee0ac429c47/06_frameworks_aspect_ratio.png" alt="cb 06 frameworks"></p></div><p>We test two static batching frameworks and three continuous batching frameworks. Our static batching frameworks are:</p><ul><li><p><a href="https://huggingface.co/docs/transformers/pipeline_tutorial"><b><u>Hugging Face’s Pipelines</u></b></a><b>.</b> This is the simplest inference solution. It provides static batching with an easy-to-use API that works with any model and supports more tasks than simple text-generation. We use this as our baseline.&nbsp;</p></li><li><p><a href="https://github.com/NVIDIA/FasterTransformer"><b><u>NVIDIA’s FasterTransformer</u></b></a><b>.</b> This is a library which provides optimized implementations of various transformer models. It currently only provides static batching (the <a href="https://github.com/triton-inference-server/server"><u>Triton inference server</u></a> provides request-level dynamic batching, but not continuous batching yet). This provides us with an idea of how far an extremely optimized implementation of our model can get us with static batching – it provides a more competitive baseline than the relatively unoptimized OPT-13B implementation <a href="https://huggingface.co/facebook/opt-13b"><u>available on Hugging Face Hub</u></a>.</p></li></ul><p>Our continuous batching frameworks are:</p><ul><li><p><a href="https://github.com/huggingface/text-generation-inference"><b><u>Hugging Face’s text-generation-inference</u></b></a><b>.</b> This is the inference server Hugging Face uses to power their LLM live-inference APIs. It <a href="https://github.com/huggingface/text-generation-inference/tree/main/router#continuous-batching"><u>implements</u></a> continuous batching.</p></li><li><p><u><b>Continuous batching on Ray Serve</b></u><b>.</b> <a href="https://docs.ray.io/en/latest/serve/index.html"><u>Ray Serve</u></a> leverages Ray’s serverless capabilities to provide seamless autoscaling, high-availability, and support for complex DAGs. We wanted to understand how continuous batching works, so we re-implemented text-generation-inference’s core continuous batching logic in pure-Python on Ray Serve. As you will see in our results, our implementation achieves the same performance as text-generation-inference, which validates our understanding.</p></li><li><p><a href="https://vllm.ai/"><b><u>vLLM</u></b></a><b>.</b> This is an open-source project recently released by folks at UC Berkeley (<a href="https://github.com/vllm-project/vllm"><u>GitHub</u></a>). It builds upon Orca’s continuous batching design by taking full control of dynamic memory allocations, allowing it to significantly reduce different forms of GPU memory fragmentation. We test this framework because it shows the impact of further optimizations made possible by iteration-level scheduling and continuous batching.</p></li></ul><h2>Benchmarking results: Throughput</h2><p>Based on our understanding of static batching, we expect continuous batching to perform significantly better when there is higher <i>variance</i> in sequence lengths in each batch. To show this, we run our throughput benchmark four times for each framework, each time on a dataset with higher variance in sequence lengths.</p><p>To do this, we create a dataset containing 1000 sequences each with 512 input tokens. We configure our model to always emit a per-sequence generation length by ignoring the end-of-sequence token and configuring max_tokens. We then generate 1000 generation lengths, one for each request, sampled from an<a href="https://en.wikipedia.org/wiki/Exponential_distribution"><u> exponential distribution</u></a> with mean=128 tokens. We use an exponential distribution as it is a good approximation of the generation lengths that one may encounter while serving an application like ChatGPT. To vary the variance of each run, we select only samples from the exponential distribution that are less than or equal to 32, 128, 512, and 1536. The total output sequence length is then, at most, 512+32=544, 512+128=640, 512+512=1024, and 512+1536=2048 (the maximum sequence length of our model).</p><p>We then use a simple asyncio Python benchmarking script to submit HTTP requests to our model server. The benchmarking script submits all requests in burst fashion, so that the compute is saturated.</p><p>The results are as follows:</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1Os82uuLDUkqP90Nlhp3vh/1e783aff1edb97cd25b5139d26083c1c/cb_07_throughput_table.png" alt="cb 07 throughput table"></p></div><p><span>Throughput in tokens per second of each framework as variance in sequence length increases.</span></p></div><p>As expected, the static batchers and naive continuous batchers perform approximately identically for lower-variance generation lengths. However as the variance increases, naive static batching’s performance plummets to 81 token/s. FasterTransformers improves upon naive static batching significantly, nearly keeping up with the naive continuous batchers until generation length limit of 1536. Continuous batching on Ray Serve and text-generation-inference achieves about the same performance, which is what we expect since they use the same batching algorithm.</p><p>What is most impressive here is vLLM. For each dataset, vLLM more than doubles performance compared to naive continuous batching. We have not analyzed what optimization contributes the most to vLLM performance the most, but we suspect vLLM’s ability to reserve space dynamically instead of ahead-of-time allows vLLM to dramatically increase the batch size.</p><p>We plot these performance results relative to naive static batching:</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/46OIG2WmA2j0SBfcG5fdq7/3bcdebf8014730a1a592a18f023cfdcc/cb_08_throughput_graph.png" alt="cb 08 throughput graph"></p></div><p><span>Our throughput benchmark results presented as improvement multiples over naive static batching, log scale.</span></p></div><p>It’s important to note how impressive even FasterTransformer’s 4x improvement is; we’re very interested in benchmarking FasterTransformers plus continuous batching when NVIDIA implements it. However, continuous batching is clearly a significant improvement over static batching even with an optimized model. The performance gap becomes gigantic when you include further memory optimization enabled by continuous batching and iteration-level scheduling as vLLM does.</p><h2>Benchmarking results: Latency</h2><p>Live-inference endpoints often face latency-throughput tradeoffs that must be optimized based on user needs. We benchmark latency on a realistic workload and measure how the <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function"><u>cumulative distribution function</u></a> of latencies changes with each framework.</p><p>Similar to the throughput benchmark, we configure the model to always emit a specified amount of tokens specified per-request. We prepare 100 randomly-generated prompts by sampling lengths from a <a href="https://en.wikipedia.org/wiki/Discrete_uniform_distribution"><u>uniform distribution</u></a> between 1 token and 512 tokens. We sample 100 output lengths from a capped exponential distribution with mean=128 and maximum size of 1536. These numbers were chosen because they are reasonably realistic and allow the generation to use up the full context-length of our model (512+1536=2048).</p><p>Instead of submitting all requests at the same time as done in the throughput benchmark, we delay each request by a predetermined number of seconds. We sample a <a href="https://en.wikipedia.org/wiki/Poisson_distribution"><u>Poisson distribution</u></a> to determine how long each request waits after the previously submitted request. The Poisson distribution is parameterized by λ, the expected rate, which in our case is how many queries per second (QPS) hit our model endpoint. We measure latencies at both QPS=1 and QPS=4 to see how the latency distribution changes as load changes.</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/4ElanYNZRv3sUBL0459zWV/ce78b3daf7e05f1bb84dad61906f1663/cb_09_latency_table.png" alt="cb 09 latency table"></p></div><p><span>Median generation request latency for each framework, under average load of 1 QPS and 4 QPS. Continuous batching systems improve median latency.</span></p></div><p>We see that while improving throughput, continuous batching systems also <i>improve</i> median latency. This is because continuous batching systems allow for new requests to be added to an existing batch if there is room, each iteration. But how about other percentiles? In fact, we find that they improve latency across all percentiles:</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/6zynLiX4AJVO23tRfQ1rnV/763589eb4a6418157f21a51e6e36abaf/cb_10_latency_cdf_qps_1.png" alt="cb 10 latency cdf qps=1"></p></div><p><span>Cumulative distribution function of generation request latencies for each framework with QPS=1. Static batchers and continuous batchers have distinct curve shapes caused by the presence of iteration-level batch scheduling in continuous batchers. All continuous batchers perform approximately equally under this load; FasterTransformers performs noticeably better than static batching on a naive model implementation.</span></p></div><p>The reason why continuous batching improves latency at all percentiles is the same as why it improves latency at p50: new requests can be added regardless of how far into generation other sequences in the batch are. However, like static batching, continuous batching is still limited by how much space is available on the GPU. As your serving system becomes saturated with requests, meaning a higher on-average batch size, there are less opportunities to inject new requests immediately when they are received. We can see this as we increase the average QPS to 4:</p><div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/2az2DSpj3IujUOOu2i5WPp/5f7457205acae98fcd7fb3170e93b773/cb_11_latency_cdf_qps_4.png" alt="cb 11 latency cdf qps=4"></p></div><p><span>Cumulative distribution function of generation request latencies for each framework with QPS=4. Compared to QPS=1, FasterTransformer’s distribution of latencies becomes more similar to static batching on a naive model. Both Ray Serve and text-generation-inference’s continuous batching implementations perform similarly, but noticeably worse than vLLM.</span></p></div><p>We observe that FasterTransformer becomes more similar to naive static batching, and that both text-generation-inference and Ray Serve’s implementation of continuous batching are on their way to look like FasterTransformer’s curve with QPS=1. That is, as the systems become saturated there are less opportunities to inject new requests immediately, so request latency goes up. This lines up with the vLLM curve – it remains mostly unchanged between QPS=1 and QPS=4. This is because due to its advanced memory optimizations, it has a higher maximum batch size.</p><p>Anecdotally, we observe that vLLM becomes saturated around QPS=8 with a throughput near 1900 token/s. To compare these numbers apples-to-apples to the other serving systems requires more experimentation; however we have shown that continuous batching significantly improves over static batching by 1) reducing latency by injecting new requests immediately when possible, and 2) enable advanced memory optimizations (in vLLM’s case) that increase the QPS that the serving system can handle before becoming saturated.</p><h2>Conclusion</h2><p>LLMs present some amazing capabilities, and we believe their impact is still mostly undiscovered. We have shared how a new serving technique, continuous batching, works and how it outperforms static batching. It improves throughput by wasting fewer opportunities to schedule new requests, and improves latency by being capable of immediately injecting new requests into the compute stream. We are excited to see what people can do with continuous batching, and where the industry goes from here.</p><h2>Try out continuous batching for yourself</h2><p>We have a <a href="https://github.com/ray-project/ray/blob/cc983fc3e64c1ba215e981a43dd0119c03c74ff1/doc/source/serve/doc_code/vllm_example.py"><u>vLLM + Ray Serve example</u></a> that allows you to try out continuous batching. We are integrating continuous batching systems into <a href="https://aviary.anyscale.com/"><u>Aviary</u></a>, a webapp <a href="https://www.anyscale.com/blog/announcing-aviary-open-source-multi-llm-serving-solution"><u>that allows you to compare the outputs of different LLMs in parallel</u></a>, and will release it within the week.</p><p><i>Acknowledgements. We’d like to thank the following people for assisting in benchmarking and/or reviewing our results. </i>Anyscale<i>: Stephanie Wang, Antoni Baum, Edward Oakes, and Amog Kamsetty; </i>UC Berkeley<i>: Zhuohan Li and Woosuk Kwon.</i></p><h2>Get involved with Ray</h2><p>The <a href="https://github.com/anyscale/llm-continuous-batching-benchmarks"><u>code used for the experiments in the blog post is here</u></a>. To connect with the Ray community, join <a href="https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform"><u>the Ray Slack</u></a> or ask questions <a href="https://discuss.ray.io/"><u>on the Discuss forum</u></a>. If you are interested in hosting LLMs, check out <a href="https://www.anyscale.com/platform"><u>our managed Ray offering</u></a>. If you are interested in learning more about Ray, see <a href="http://ray.io/">ray.io</a> and <a href="http://docs.ray.io/">docs.ray.io</a>.</p><p>See our earlier <a href="https://www.anyscale.com/blog/ray-common-production-challenges-for-generative-ai-infrastructure"><u>blog series on solving Generative AI infrastructure</u></a> and using <a href="https://www.anyscale.com/blog/llm-open-source-search-engine-langchain-ray"><u>LangChain with Ray</u></a>.</p><p><b>Ray Summit 2023</b>: If you are interested to learn much more about how Ray can be used to build performant and scalable LLM applications and fine-tune/train/serve LLMs on Ray, <a href="https://raysummit.anyscale.com/"><u>join Ray Summit on September 18-20th</u></a>! We have a set of great keynote speakers including <a href="http://joschu.net/"><u>John Schulman</u></a> from OpenAI and <a href="https://aidangomez.ca/"><u>Aidan Gomez</u></a> from <a href="https://cohere.com/"><u>Cohere</u></a>, community and tech talks about Ray <a href="https://github.com/ray-project/ray-educational-materials/blob/main/NLP_workloads/Text_generation/LLM_finetuning_and_batch_inference.ipynb"><u>as well as practical training focused on LLMs</u></a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New responsibilities (119 pts)]]></title>
            <link>https://www.hadess.net/2023/08/new-responsibilities.html</link>
            <guid>37131263</guid>
            <pubDate>Tue, 15 Aug 2023 07:40:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hadess.net/2023/08/new-responsibilities.html">https://www.hadess.net/2023/08/new-responsibilities.html</a>, See on <a href="https://news.ycombinator.com/item?id=37131263">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-727042356482467106" itemprop="description articleBody">
<p><span>, my management chain has made the decision to stop all 
upstream and downstream work on desktop Bluetooth, multimedia 
applications (namely totem, rhythmbox and sound-juicer) and 
libfprint/fprintd. The rest of my upstream and downstream work will be 
reassigned depending on Red Hat's own priorities (see below), as I am 
transferred to another team that deals with one of a list of Red Hat’s 
priority projects.</span></p><p><span>I'm
 very disappointed, because those particular projects were already 
starved for resources: I spent less than 10% of my work time on them in 
the past year, with other projects and responsibilities taking most of 
my time.</span></p><p><span>This means that, in the medium-term at least, all those GNOME projects will go without a maintainer, reviewer, or triager:</span></p><p><span>- gnome-bluetooth (including Settings panel and gnome-shell integration)</span></p><p><span>- totem, totem-pl-parser, gom</span></p><p><span>- libgnome-volume-control</span></p><p><span>- libgudev</span></p><p><span>- geocode-glib</span></p><p><span>- gvfs AFC backend</span></p><p><span>Those freedesktop projects will be archived until further notice:</span></p><p><span>- power-profiles-daemon</span></p><p><span>- switcheroo-control</span></p><p><span>- iio-sensor-proxy</span></p><p><span>- low-memory-monitor</span></p><p><span>I will not be available for reviewing libfprint/fprintd, upower, grilo/grilo-plugins, gnome-desktop thumbnailer sandboxing patches, or any work related to XDG specifications.</span></p><p><span>Kernel
 work, reviews and maintenance, including recent work on SteelSeries 
headset and Logitech devices kernel drivers, USB revoke for Flatpak 
Portal support, or core USB is suspended until further notice.</span></p><p><span>All my <a href="https://lists.fedoraproject.org/archives/list/devel@lists.fedoraproject.org/thread/WRHVGQBKKFU74CBO3CHIJC3Q5VEKH2AV/">Fedora </a></span><span><a href="https://lists.fedoraproject.org/archives/list/devel@lists.fedoraproject.org/thread/WRHVGQBKKFU74CBO3CHIJC3Q5VEKH2AV/">packages 
were orphaned</a> about a month and a half ago, it's likely that there are 
still some that are orphaned, if there are takers. RHEL packages were 
unassigned about 3 weeks ago, they've been reassigned 
since then, so I cannot point to the new maintainer(s).</span></p><p><span>If
 you are a partner, or a customer, I would recommend that you get in 
touch with your Red Hat contacts to figure out what the plan is going 
forward for the projects you might be involved with.</span></p><p><span>If
 you are a colleague that will take on all or part of the 90% of the 
work that's not being stopped, or a community member that was relying on
 my work to further advance your own projects, get in touch, I'll do my 
best to accommodate your queries, time permitting.</span></p><p><span>I'll try to make sure to update this post, or create a new one if and when any of the above changes.<br></span></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Features of Project Loom incorporated in JDK 21 (207 pts)]]></title>
            <link>https://jdk.java.net/loom/</link>
            <guid>37130138</guid>
            <pubDate>Tue, 15 Aug 2023 04:21:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jdk.java.net/loom/">https://jdk.java.net/loom/</a>, See on <a href="https://news.ycombinator.com/item?id=37130138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="footer"><p><a href="https://oracle.com/"><img alt="Oracle logo" src="https://jdk.java.net/images/oracle.png"></a></p><p> © 2023 Oracle Corporation and/or its affiliates </p><div><p><a href="https://jdk.java.net/tou">Terms of Use</a>
          · <a href="https://www.oracle.com/legal/privacy/">Privacy</a>
          · <a href="https://openjdk.org/legal/openjdk-trademark-notice.html">Trademarks</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: t.co is adding a five-second delay to some domains (470 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37130060</link>
            <guid>37130060</guid>
            <pubDate>Tue, 15 Aug 2023 04:09:03 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37130060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37130129"><td></td></tr>
                <tr id="37130240"><td></td></tr>
            <tr id="37130260"><td></td></tr>
            <tr id="37130194"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130194" href="https://news.ycombinator.com/vote?id=37130194&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>Agree/confirmed - just recorded a number of different nytimes urls that pass through t.co, all 4.7s+. various cnbc and google articles through t.co were ~130-200ms response time from t.co specifically (not total redirect-&gt;page load).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37130246"><td></td></tr>
            <tr id="37130186"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130186" href="https://news.ycombinator.com/vote?id=37130186&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>I almost didn't believe OP, because it's so comically inept and petty. But, I can also confirm in some private testing there is a deliberate delay.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130327"><td></td></tr>
                        <tr id="37130143"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37130143" href="https://news.ycombinator.com/vote?id=37130143&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>I think that HN itself also shadow flags submissions from a list of domains it doesn't like.<p>Try submitting a URL from the following domains, and it will be automatically flagged (but you can't see its flagged unless you log out):</p><pre><code>  - archive.is
  - watcher.guru
  - stacker.news
  - zerohedge.com
  - freebeacon.com
  - thefederalist.com
  - breitbart.com</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130147"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130147" href="https://news.ycombinator.com/vote?id=37130147&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>Well, yes, many sites are banned on HN. Others are penalized (see e.g. <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;query=by%3Adang%20%22major%20media%22&amp;sort=byDate&amp;type=comment" rel="nofollow noreferrer">https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;que...</a>). None of this is secret, though we don't publish the lists themselves.<p>Edit: about 67k sites are banned on HN. Here's a random selection of 10 of them:</p><pre><code>  vodlockertv.com
  biggboss.org
  infoocode.com
  newyorkpersonalinjuryattorneyblog.com
  moringajuice.wordpress.com
  surrogacymumbai.com
  maximizedlivingdrlabrecque.com
  radio.com
  gossipcare.com
  tecteem.com</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130185"><td></td></tr>
                <tr id="37130234"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37130234" href="https://news.ycombinator.com/vote?id=37130234&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>The problem is that if you publish the lists it leads to more abuses. For example if spammers find out which sites are banned then they just post other ones.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130270"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37130270" href="https://news.ycombinator.com/vote?id=37130270&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>&gt; For example if spammers find out which sites are banned then they just post other ones.<p>I don't think that makes sense. The supposed spammers can just try looking up whether their submissions show up or not when not logged in.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37130279"><td></td></tr>
                              <tr id="37130261"><td></td></tr>
                <tr id="37130315"><td></td></tr>
                        <tr id="37130155"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130155" href="https://news.ycombinator.com/vote?id=37130155&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>The difference is that HN is explicitly heavily moderated while Twitter pretends to be an equitable free speech platform.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37130144"><td></td></tr>
                <tr id="37130157"><td></td></tr>
                <tr id="37130177"><td></td></tr>
                <tr id="37130220"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37130220" href="https://news.ycombinator.com/vote?id=37130220&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>And how was  the decision made to ban Federalist, but not say Guardian or The Daily Beast? Do you have any process in place to ensure that your political biases don't influence the list, or you don't care about that?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130299"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37130299" href="https://news.ycombinator.com/vote?id=37130299&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>Hey, man, if you want to go read those sites go for it. It's a free country.<p>This is a moderated site targeted at a specific community. It's under no obligation to be politically balanced. It's certainly under no obligation to promote right-wing propaganda and hate.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37130325"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37130325" href="https://news.ycombinator.com/vote?id=37130325&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>&gt; It's under no obligation to be politically balanced.<p>And obviously, I'm under no obligation to not voice my concern about that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37130255"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37130255" href="https://news.ycombinator.com/vote?id=37130255&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>I'm guessing it's reactive, and Federalist links tended to be garbage often enough to convince someone they should hit the ban button, whereas the others didn't rise up with trash often enough to matter?</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37130170"><td></td></tr>
                        <tr id="37130217"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130217" href="https://news.ycombinator.com/vote?id=37130217&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>the wise man bowed his head solemnly and spoke: "theres actually zero difference between good &amp; bad things." -- @dril</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37130078"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37130078" href="https://news.ycombinator.com/vote?id=37130078&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>Remember when people were excoriating Google AMP for encouraging walled gardens? If true, this seems in so much worse faith than that.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130131"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130131" href="https://news.ycombinator.com/vote?id=37130131&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>Not worse. They are both as evil as it gets. Typical: take public resource and use it for an exclusive  profit.<p>What happened to net neutrality? Could it applied for this case?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37130099"><td></td></tr>
                <tr id="37130191"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130191" href="https://news.ycombinator.com/vote?id=37130191&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>Enshitification is different. It’s when companies destroy a product with hundreds of changes that prioritise
internal politics above what end users want.<p>This is something else - just the ego of one rich guy petulantly satisfying his inner demons.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                            <tr id="37130102"><td></td></tr>
                <tr id="37130163"><td></td></tr>
            <tr id="37130151"><td></td></tr>
                  <tr id="37130179"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37130179" href="https://news.ycombinator.com/vote?id=37130179&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>If true and intentional, then this is a strong move by Musk against his ideological opponents. Hard to believe he has the cognizance to recognize them as such but maybe he purged more of the 3-letter agency folks from X than it seemed.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37130111"><td></td></tr>
            <tr id="37130073"><td></td></tr>
                <tr id="37130101"><td></td></tr>
                <tr id="37130117"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37130117" href="https://news.ycombinator.com/vote?id=37130117&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>A good test might include a bunch of domains. And checking the timing on each. Could we demonstrate the delay is on t.co and not on NYT?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130180"><td></td></tr>
                  <tr id="37130208"><td></td></tr>
                  <tr id="37130109"><td></td></tr>
            <tr id="37130226"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130226" href="https://news.ycombinator.com/vote?id=37130226&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><p><span>they already told you they did tested it and you don't believe them.<p>what else could they say that would make you believe them?</p><p>you might as well just test it yourself like i did with time wget. it's not like you're going to believe anything anyone writes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37130137"><td></td></tr>
            <tr id="37130119"><td></td></tr>
                <tr id="37130192"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130192" href="https://news.ycombinator.com/vote?id=37130192&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>It is probably not illegal in America. Would it be illegal in Europe? Because (at least w/r/t Threads) it is an anti-competitive practice?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37130161"><td></td></tr>
                  <tr id="37130097"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37130097" href="https://news.ycombinator.com/vote?id=37130097&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>i mean, you can stop visiting the site, no? just leave, bro. it's not that hard. there are other means to connect to people.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130107"><td></td></tr>
            <tr id="37130127"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130127" href="https://news.ycombinator.com/vote?id=37130127&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>You're right! Which is why making Twitter's product <i>worse</i> when there are active competitors taking big bites out of their business seems... dumb?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130245"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37130245" href="https://news.ycombinator.com/vote?id=37130245&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>yep, it also seems to me that the helmsman of that site is dumb. good thing i left that site many years ago.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37130165"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37130165" href="https://news.ycombinator.com/vote?id=37130165&amp;how=up&amp;goto=item%3Fid%3D37130060"></a></center>    </td><td><br><div>
                  <p><span>Unfortunately not. All of my local government agencies - Police, Fire, DOT, Weather Service, Emergency Management updates, etc. are exclusively on twitter - they frequently post things there they don't even post to their own websites.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37130268"><td></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The unpublished preface to Orwell’s Animal Farm (262 pts)]]></title>
            <link>https://mindmatters.ai/2023/08/a-warning-from-the-unpublished-preface-to-orwells-animal-farm/</link>
            <guid>37129768</guid>
            <pubDate>Tue, 15 Aug 2023 03:18:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mindmatters.ai/2023/08/a-warning-from-the-unpublished-preface-to-orwells-animal-farm/">https://mindmatters.ai/2023/08/a-warning-from-the-unpublished-preface-to-orwells-animal-farm/</a>, See on <a href="https://news.ycombinator.com/item?id=37129768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-swiftype-name="body">
			
<p><a href="http://www.bbc.co.uk/history/historic_figures/orwell_george.shtml">George Orwell</a>‘s novella <em><a href="http://www.george-orwell.org/Animal_Farm/0.html">Animal Farm</a></em> (1945) was a political fable. The cleverly portrayed animals who chase off the farmer and try to run the farm as a utopia slowly begin to replicate all the attitudes and practices against which they had rebelled. The story, summarized <a href="https://interestingliterature.com/2020/05/a-summary-and-analysis-of-george-orwells-animal-farm/">here,</a> satirizes the Soviet Union’s transition from revolution to totalitarianism under Joseph Stalin (1878–1953). In fact, the animal characters and incidents are often allusions to <a href="https://www.enotes.com/homework-help/what-some-examples-allusions-book-animal-farm-349433">historical Soviet figures and events.</a></p>







<figure><div>
<p><iframe title="Animal Farm Video Summary" width="500" height="281" src="https://www.youtube.com/embed/BFP1IMyKyy4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
</div></figure>







<p>His Preface, <a href="https://orwell.ru/library/novels/Animal_Farm/english/efp_go">“The Freedom of the Press,”</a> was omitted from the first edition of the book, then disappeared, and <a href="https://www.bl.uk/collection-items/orwells-proposed-introduction-to-animal-farm">was not rediscovered until 1971.</a> From it, we learn that Orwell had considerable difficulty getting his fable published. That wasn’t principally because of wartime issues. There was a shortage of books and his was highly readable. Rather, British intellectuals of the day did not wish to hear any criticism of Stalin or allusions to his atrocities:</p>



<p>Obviously it is not desirable that a government department should have any power of censorship (except security censorship, which no one objects to in war time) over books which are not officially sponsored. But the chief danger to freedom of thought and speech at this moment is not the direct interference of the MOI or any official body. If publishers and editors exert themselves to keep certain topics out of print, it is not because they are frightened of prosecution but because they are frightened of public opinion. In this country intellectual cowardice is the worst enemy a writer or journalist has to face, and that fact does not seem to me to have had the discussion it deserves…</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-892x1597.jpg" alt="" width="276" height="494" srcset="https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-892x1597.jpg 892w, https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-551x987.jpg 551w, https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-768x1375.jpg 768w, https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-858x1536.jpg 858w, https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1-1144x2048.jpg 1144w, https://mindmatters.ai/wp-content/uploads/sites/2/2023/08/Animal-Farm-1.jpg 1430w" sizes="(max-width: 276px) 100vw, 276px"></figure></div>


<p>At this moment what is demanded by the prevailing orthodoxy is an uncritical admiration of Soviet Russia. Everyone knows this, nearly everyone acts on it. Any serious criticism of the Soviet régime, any disclosure of facts which the Soviet government would prefer to keep hidden, is next door to unprintable. And this nation-wide conspiracy to flatter our ally takes place, curiously enough, against a background of genuine intellectual tolerance. For though you arc not allowed to criticise the Soviet government, at least you are reasonably free to criticise our own. Hardly anyone will print an attack on Stalin, but it is quite safe to attack Churchill, at any rate in books and periodicals. And throughout five years of war, during two or three of which we were fighting for national survival, countless books, pamphlets and articles advocating a compromise peace have been published without interference. More, they have been published without exciting much disapproval. So long as the prestige of the USSR is not involved, the principle of free speech has been reasonably well upheld. There are other forbidden topics, and I shall mention some of them presently, but the prevailing attitude towards the USSR is much the most serious symptom. It is, as it were, spontaneous, and is not due to the action of any pressure group. </p>



<p>Orwell, it should be said, was very much a man of the Left. But he was not a totalitarian. That combination perhaps enabled him to publish some of the most broadly appealing  popular-level dissections of the evils of totalitarian rule in English.</p>



<p>For example, he offers us a significant insight in the passage above. The censorship he had to address was not a conspiracy or even a campaign; it was spontaneous. Every right-thinking intellectual somehow <em>knew</em> that a candid assessment of Soviet rule was, well, just <em>not the done thing!…</em></p>



<p>Why not? Well, gentle reader, if you have ever encountered such an environment, you will know — or suspect anyway — that most of the people who know for sure which political views need censoring could not ably defend their opinion. Their defense is, precisely, groupthink. They don’t need to think much about it individually. And they don’t. In fact, if you challenge them on their censorship, they may act aggrieved, as if they were the victims of a calculated personal injury. It’s doubtless all the more tiresome if, as Orwell found, the groupthinkers are held up as the leading intellectuals of the day:</p>



<p>But now to come back to this book of mine. The reaction towards it of most English intellectuals will be quite simple: ‘It oughtn’t to have been published.’ Naturally, those reviewers who understand the art of denigration will not attack it on political grounds but on literary ones. They will say that it is a dull, silly book and a disgraceful waste of paper. This may well be true, but it is obviously not [th]e whole of the story. One does not say that a book ‘ought not to have been published’ merely because it is a bad book. After all, acres of rubbish are printed daily and no one bothers. The English intelligentsia, or most of them, will object to this book because it traduces their Leader and (as they see it) does harm to the cause of progress. If it did [th]e opposite they would have nothing to say against it, even if its literary faults were ten times as glaring as they are. The success of, for instance, the Left Book Club over a period of four or five years shows how willing they are to tolerate both scurrility and slipshod writing, provided that it tells them what they want to hear.</p>



<p>And he ends his Preface on a high note,</p>



<p>I know that the English intelligentsia have plenty of reason for their timidity and dishonesty, indeed I know by heart the arguments by which they justify themselves. But at least let us have no more nonsense about defending liberty against Fascism. If liberty means anything at all it means the right to tell people what they do not want to hear.</p>



<p>Orwell would doubtless be pleased that millions of people worldwide have offered a much more positive assessment of <em>Animal Farm.</em> Many of us might also find key points of comparison between his situation and the shrill calls for censorship that we hear so often today.</p>







<figure><div>
<p><iframe loading="lazy" title="Animal Farm trailer" width="500" height="375" src="https://www.youtube.com/embed/LAeKX5n-5IE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
</div></figure>







<p><em>Note:</em> The better-known <em><a href="https://www.amazon.com/1984-George-Orwell/dp/0451516753">1984</a></em> was not published until 1949, not long before Orwell’s death from tuberculosis. Also, “George Orwell” was a pen name; he was known in life as <a href="https://www.cliffsnotes.com/literature/n/1984/george-orwell-biography">Eric Blair.</a></p>



<p><em>You may also wish to read:</em> In Big Tech World: the journalist as <a href="https://mindmatters.ai/2021/02/in-big-tech-world-the-journalist-as-censor-hit-man-and-snitch/">censor, hit man, and snitch.</a> Glenn Greenwald looks at a disturbing trend in media toward misrepresentation as well as censorship.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lynn Conway's Story (2000) (159 pts)]]></title>
            <link>https://ai.eecs.umich.edu/people/conway/LynnsStory.html</link>
            <guid>37129132</guid>
            <pubDate>Tue, 15 Aug 2023 01:39:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.eecs.umich.edu/people/conway/LynnsStory.html">https://ai.eecs.umich.edu/people/conway/LynnsStory.html</a>, See on <a href="https://news.ycombinator.com/item?id=37129132">Hacker News</a></p>
<div id="readability-page-1" class="page">

<dl>
  <dt><center>&nbsp;</center>
  </dt><dt><center></center>
</dt></dl>

<center><i>This is the story of a woman who made amazing contributions
to society,<br>
in spite of intense ostracism and stigmatization just for trying
to be herself, <br>
and how she did it by taking on a secret new identity, and living
her life in "stealth mode".</i></center>

<center>#</center>

<p>
<a href="http://ai.eecs.umich.edu/people/conway/Awards/ElectronicDesign/HallOfFame.html">Lynn Conway is a 
<span>famed pioneer of 
microelectronics chip design</span></a>.
Her innovations during the 1970's at the Xerox Palo Alto Research
Center (PARC) have impacted chip design worldwide. Many high-tech
companies and computing methods have foundations in her work.</p>

<p>Thousands of chip designers learned their craft from Lynn's
textbook <i>Introduction to VLSI Systems</i>, which she co-authored
with Prof. Carver Mead of Caltech. Thousands more did their first
VLSI design projects using the government's MOSIS prototyping
system, which is based directly on Lynn's work at PARC. 
<span>
<a href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9046420">
Much of the modern silicon chip design revolution is based on her work</a></span>.</p>

<p>Lynn went on to win many awards and high honors, including
election as a Member of the National Academy of Engineering, the
highest professional recognition an engineer can receive.</p>

<center>#</center>

<p>What no one knew till recently is that Lynn also did earlier
pioneering research at IBM in the 1960's. Fresh out of grad school,
she invented a powerful method for issuing multiple out-of-order
instructions per machine cycle in supercomputers. By solving this
fundamental computer architecture problem way back in 1965, she
made possible the creation of the first true superscalar computer,
and participated in its design at IBM. Lynn called her invention
dynamic instruction scheduling (DIS).</p>

<p>By the 90's, chips held enough transistors so that entire superscalar
computers could be put on single chips. Lynn's DIS invention suddenly
became used in almost all the powerful new PC chips, making them
much more powerful than they'd otherwise have been. Lynn's work
thus had yet another big impact on the modern information technology
revolution.</p>

<p>Most computer engineers thought DIS was a generalization of
decades of work, and had no idea it had been invented in 1965.
It caused Lynn great angst to see her wonderful invention so widely
used, and described in all the computer architecture textbooks,
without anyone knowing it was her idea.</p>

<center>#</center>

<p>How could this oversight have happened? Why did Lynn remain
silent for over three decades about her IBM work?</p>

<p>The answer is that women like Lynn have lived, especially in
the past, in a holocaust of stigmatization, persecution and violence.
They could not reveal their past identities without risking great
physical danger to themselves, and great harm to their careers
and their personal relationships.</p>

<p>You see, Lynn was born and raised as a boy. It was a terrible
mistake, because Lynn had the brain-sex and gender identity of
a girl. However, back in the forties and fifties there wasn't
any knowledge about such things, and Lynn was forced to grow up
as a boy. She did the best she could at it, but suffered terribly
from what was happening to her. She was still a boy and had a
boy's name when she worked at IBM.</p>

<p>After years and years of trying to find help, she finally connected
with the pioneering physician Harry Benjamin, M.D. in 1966, shortly
after he'd published his seminal textbook <i>The Transsexual Phenomenon</i>.
That text was the first to describe the true nature of, and medical
solutions for, Lynn's mis-gendering affliction.</p>

<p>With Dr. Benjamin's help, Lynn began medical treatments in
1967. She became one of the very early transsexual women to undergo
hormonal and surgical sex reassignment to have her body completely
changed from that of a boy into that of a woman. Sadly, just before
Lynn underwent sex reassignment surgery in 1968, she was fired
by IBM for being transsexual and lost all connections to her important
work there.</p>

<center>#</center>

<p>Lynn's case was a first at IBM. The idea that a professional
person would seek a "sex change" totally shocked IBM's
management. Most transsexual women seeking help back then were
from among those who worked as "female impersonators"
or as prostitutes. Only those who were sure they could fully pass
as women, who were totally desperate and who had nothing to lose,
dared to change gender back then. When top IBM management learned
what Lynn was doing, she was fired in a maelstrom of animosity.
It is almost certain that the decision was made by T. J. Watson,
Jr., himself.</p>

<p>Lynn had managed to put together some fragile bits of support
and help from her family and friends. However, when IBM fired
her everyone lost confidence in what she was doing and her support
system collapsed. Lynn went abroad for her surgery, all alone.
She had lost not only her career and professional reputation,
but also her family, relatives, friends and colleagues. She faced
a frighteningly uncertain future without a soul in the world to
help her other than her doctors.</p>

<center>#</center>

<p>When Lynn returned, she made her social transition and took
on her new name. She started her career all over again as a lowly
contract programmer without a past. A gritty survivor, her adjustment
in her new role went completely against the dire predictions of
the IBM executives and all the family and the friends who had
deserted her. All alone she went out into the world, made new
friends and worked hard to succeed in her new life.</p>

<p>Amazingly, Lynn became so happy, and so full of life and hope
after her transformation, that her career took off like a rocket.
Moving up through a series of companies, she landed a computer
architecture job at Memorex in 1971. In 1973, she was recruited
by Xerox's exciting new Palo Alto Research Center, just as it
was forming.</p>

<p>By 1978, just 10 years after her gender transition, Lynn was
already on the verge of international fame in her field for her
VLSI innovations. By then she was writing the seminal textbook
on the subject, and was heading off to M. I. T. to teach the first
prototype course on VLSI systems.</p>

<p>Within two years, universities all over the world were adopting
her text for similar courses. The Department of Defense started
a major new program to sponsor research to build on her work.
Scores of startup companies began incubating and forming to commercialize
the knowledge. All this happened without people catching on to
Lynn's secret past. She could never have survived and done it
if they had.</p>

<center>#</center>

<p>In the 80's and 90's, Lynn went on to enjoy a wide-ranging,
influential career, and a wonderfully adventurous, fulfilling
and happy personal life. She is now Professor of Electrical Engineering
and Computer Science, Emerita, at the University of Michigan in
Ann Arbor, where she also served for many years as Associate Dean
of Engineering. She now lives on country property in rural Michigan
with her husband Charlie. They've been together since 1987.</p>

<p>However, for 31 years after her transition, Lynn carefully
remained in "stealth mode". Only her closest friends
knew about her past. Lynn knew of other transsexual women who
had been socially ostracized, ghettoized, beaten, gang-raped,
murdered or driven to suicide when "read" or otherwise
discovered by brutal, hateful people.</p>

<p>For years Lynn lived with an ever-present sense of danger,
fearful that exposure of her past could cause her to lose her
civil rights, legal rights and employment rights, and to suffer
estrangements in her professional and personal relationships.</p>

<center>#</center>

<p>In 1999, computer historians finally stumbled into Lynn's early
IBM work. They tracked it down to her, and her past was revealed
amongst her colleagues. Frightened at first, she gradually realized
times might have changed enough that she needn't be afraid to
be "out" now. She certainly has nothing at all to be
ashamed of, and is indeed very proud of the successes in her personal
life as well as those in her career.</p>

<p>At the same time, Lynn was dismayed that transsexual women
are still treated so inhumanely by parents, relatives, employers,
the legal system and society at large. The total rejection of teenage 
transgender and transsexual girls-to-be by their families is especially tragic,
since it often happens just as they first cry out for
help, and can doom them to years of marginalized existence.</p>

<p>Lynn began to think that her story might help somehow. Societal
views are partly a media problem. Images of transsexualism routinely
come from stories of "transition". That's a time when
media can focus on prurient, somewhat shocking and often embarrassing
aspects of someone's gender change. The stories seem superficially
sympathetic, but often convey a sad, dreary image. Readers are
left feeling sorry for the "poor things", and "certainly
wouldn't want it to happen in their family"!</p>

<p>What doesn't come through is the miracle of release from entrapment
in a male body that the transsexual girl experiences, and the
happiness she finds as a woman later on. Folks never learn about
the tens of thousands of post-operative women living among us
who are very successful and fully accepted as regular gals. The
public simply never sees these successes.</p>

<div><p>Why is this? Because almost all these women live in stealth,
just as Lynn did, fearing what might happen if their pasts were
revealed. Meanwhile, tens of thousands of young pre-operative
transsexuals live in fear and doubt about their futures. They
are often excommunicated by their families and lose their jobs,
as had happened to Lynn, when they identify their problem and
seek medical help. </p><p>

Lynn is the first truly successful case to come out of long-term
stealth and tell her story. That story should give hope to young
transsexuals. It should help parents see possibilities for happiness for a 
transsexual daughter-to-be, especially if they were to support
their child's efforts to transform a "boy's" body
and become a woman early enough in life. It should also give employers
pause for thought before firing someone - just because of their
transsexualism. </p></div>

<p>The day will come when gender transition is no longer be seen
as a sad, somewhat shameful and tragic event, but instead as a
wonderful life-giving miracle for those so unfortunate as to have
been mis-gendered at birth. Lynn hopes to live to see that day.</p>

<dl>
  <dt>&nbsp;
  </dt><dt>&nbsp;
  </dt><dt>&nbsp;
  </dt><dt><center><i>For background on transgender, transsexual and
  intersex issues, see <a href="http://ai.eecs.umich.edu/people/conway/TS/TS.html">TG/TS/IS
  Info.</a></i></center>
  </dt><dt><center><i>For more about Lynn's accomplishments, see her
  <a href="https://ai.eecs.umich.edu/people/conway/BioSketch.html">BioSketch.</a></i></center>
  </dt><dt><center><i>For more on her story, see her <a href="https://ai.eecs.umich.edu/people/conway/RetrospectiveT.html">Retrospective</a></i>
  <i>and also</i></center>
  </dt><dt><center><i>Lynn's Homepage: <a href="https://ai.eecs.umich.edu/people/conway/conway.html">http://www.lynnconway.com</a></i></center>
  </dt><dt>&nbsp;
  </dt><dt>&nbsp;
  </dt><dt>&nbsp;
  </dt><dt><center><b>A <i>Los Angeles Times Sunday Magazine</i> Feature
  Story about Lynn</b></center>
  </dt><dt><center><b>can also be retrieved at:</b></center>
  </dt><dt><center><a href="https://ai.eecs.umich.edu/people/conway/Media/Through%20the%20Gender%20Labyrinth.pdf"><span size="+1">Through the Gender Labyrinth.pdf</span></a></center>
  </dt><dt><center>&nbsp;</center>
  </dt><dt><center>&nbsp;</center>
  </dt><dt><center>&nbsp;</center>
  </dt><dt><center><img src="http://cgi.www.umich.edu/counter?link=http:/ai.eecs.umich.edu/people/conway/LynnsStory.html&amp;width=6&amp;font=simpson"></center>
  </dt><dt><center>&nbsp;</center>
  </dt><dt><center>Reset on 5-11-00<br>
  V-5-13-04</center>
</dt></dl>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bankman-Fried used $100M in stolen FTX funds for political donations, US says (255 pts)]]></title>
            <link>https://www.reuters.com/legal/bankman-fried-used-customer-funds-100-mln-us-political-donations-prosecutors-say-2023-08-14/</link>
            <guid>37128392</guid>
            <pubDate>Mon, 14 Aug 2023 23:57:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/bankman-fried-used-customer-funds-100-mln-us-political-donations-prosecutors-say-2023-08-14/">https://www.reuters.com/legal/bankman-fried-used-customer-funds-100-mln-us-political-donations-prosecutors-say-2023-08-14/</a>, See on <a href="https://news.ycombinator.com/item?id=37128392">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="primary-image" role="figure" aria-describedby="primary-image-caption"><figure><div data-testid="Image"><p><img src="https://cloudfront-us-east-2.images.arcpublishing.com/reuters/6RDKDYUWOFMHPJTDYF7SGZ4IUY.jpg" srcset="https://www.reuters.com/resizer/cyhXAgZITfCPqTP0ns4WMKlZEgY=/480x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/6RDKDYUWOFMHPJTDYF7SGZ4IUY.jpg 480w,https://www.reuters.com/resizer/pTykvtuFz1Z7dlzPf1iOb16WEu4=/960x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/6RDKDYUWOFMHPJTDYF7SGZ4IUY.jpg 960w,https://www.reuters.com/resizer/5VTmp8WvaqPcCqqo5ITFnnKbEwA=/1080x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/6RDKDYUWOFMHPJTDYF7SGZ4IUY.jpg 1080w,https://www.reuters.com/resizer/6gg5bwQ8_1WWEOWXE8OoNx8M2Qs=/1200x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/6RDKDYUWOFMHPJTDYF7SGZ4IUY.jpg 1200w" sizes="(min-width: 1024px) 560px, (min-width: 1440px) 700px, 100vw" width="4631" height="3115" alt="Former FTX Chief Executive Bankman-Fried at a courthouse in New York"></p></div><p data-testid="Body">Sam Bankman-Fried, the founder of bankrupt cryptocurrency exchange FTX, arrives at court as lawyers push to persuade the judge overseeing his fraud case not to jail him ahead of trial, at a courthouse in New York, U.S., August 11, 2023.  REUTERS/Eduardo Munoz/File Photo</p></figure></div><div><p data-testid="paragraph-0">NEW YORK, Aug 14 (Reuters) - Sam Bankman-Fried used money he stole from customers of his FTX cryptocurrency exchange to make more than $100 million in political campaign contributions before the 2022 U.S. midterm elections, federal prosecutors said on Monday.</p><p data-testid="paragraph-1">An amended indictment accused the 31-year-old former billionaire of directing two FTX executives to evade contribution limits by donating to Democrats and Republicans, and to conceal where the money came from.</p><p data-testid="paragraph-2">"He leveraged this influence, in turn, to lobby Congress and regulatory agencies to support legislation and regulation he believed would make it easier for FTX to continue to accept customer deposits and grow," the indictment said.</p><p data-testid="paragraph-3">Bankman-Fried faces seven counts of conspiracy and fraud over FTX's collapse, though the indictment no longer includes conspiracy to violate campaign finance laws as a separate count.</p><p data-testid="paragraph-4">Federal prosecutors in Manhattan said last month they would drop that charge after the Bahamas, where FTX was based and where Bankman-Fried was arrested in December 2022, said it never intended to extradite him on that count.</p><p data-testid="paragraph-5">Instead, prosecutors told U.S. District Judge Lewis Kaplan last week that a new indictment would "make clear that Mr. Bankman-Fried remains charged with conducting an illegal campaign finance scheme as part of the fraud and money laundering schemes originally charged."</p><p data-testid="paragraph-6">Mark Botnick, a spokesman for Bankman-Fried, declined to comment.</p><p data-testid="paragraph-7">Bankman-Fried has previously pleaded not guilty to stealing billions of dollars in FTX customer funds to plug losses at Alameda Research, his crypto-focused hedge fund.</p><p data-testid="paragraph-8">Kaplan <a data-testid="Link" href="https://www.reuters.com/legal/ftxs-bankman-fried-seeking-avoid-jail-due-back-court-2023-08-11/">jailed him last Friday</a> ahead of his Oct. 2 trial, after finding probable cause that Bankman-Fried tampered with witnesses.</p><p data-testid="paragraph-9">Previously, Bankmman-Fried had been largely confined to his parents' Palo Alto, California, home on $250 million bond.</p><p data-testid="paragraph-10">Bankman-Fried rode a boom in cryptocurrency values to amass a fortune that was once estimated at $26 billion, and became an influential donor to mostly Democratic candidates and causes.</p><p data-testid="paragraph-11">The November 2022 collapse of FTX after a flurry of customer withdrawals destroyed his wealth and stained his reputation.</p><h2 data-testid="Heading">EX-FTX EXEC SALAME DECLINES TO TESTIFY</h2><p data-testid="paragraph-12">Bankman-Fried's indictment does not name the two people prosecutors say he used for "straw donors" to donate money at his direction. But other court papers and Federal Elections Commission data show they are Nishad Singh and Ryan Salame.</p><p data-testid="paragraph-13">Singh, FTX's former engineering chief, pleaded guilty to fraud and campaign finance violations in February. He donated $9.7 million to Democratic candidates and causes, and <a data-testid="Link" href="https://www.reuters.com/legal/ftxs-singh-agrees-plead-guilty-us-criminal-charges-lawyer-says-2023-02-28/">said in court</a> he knew the money came from FTX customers.</p><p data-testid="paragraph-14">Salame, the former co-CEO of FTX's Bahamian unit, gave more than $24 million to Republican candidates and causes in the 2022 election cycle, according to Federal Election Commision data.</p><p data-testid="paragraph-15">He has not been charged with a crime. In a separate court filing on Monday, prosecutors said Salame's lawyer had told them he would invoke his Fifth Amendment right against self-incrimination if called to testify.</p><p data-testid="paragraph-16">Prosecutors said Salame told a family member in a November 2021 message that Bankman-Fried wanted to use political donations to "weed-out" anti-crypto Democratic and Republican lawmakers, and would likely “route money through me to weed out that republican [sic] side.”</p><p data-testid="paragraph-17">Salame's lawyer did not immediately respond to a request for comment.</p><p><span data-testid="Text">Reporting by Luc Cohen in San Jose, California
Editing by Chris Reese, David Gregorio, Jonathan Oatis and Shri Navaratnam</span></p><p data-testid="Body">Our Standards: <a data-testid="Link" href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank">The Thomson Reuters Trust Principles.</a></p><div><address><p data-testid="Body">Reports on the New York federal courts. Previously worked as a correspondent in Venezuela and Argentina.</p></address></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AI-town, run your own custom AI world SIM with JavaScript (403 pts)]]></title>
            <link>https://github.com/a16z-infra/ai-town</link>
            <guid>37128293</guid>
            <pubDate>Mon, 14 Aug 2023 23:46:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/a16z-infra/ai-town">https://github.com/a16z-infra/ai-town</a>, See on <a href="https://news.ycombinator.com/item?id=37128293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">AI Town <g-emoji alias="house" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3e0.png">🏠</g-emoji><g-emoji alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">💻</g-emoji><g-emoji alias="love_letter" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f48c.png">💌</g-emoji></h2>
<p dir="auto"><a href="https://www.convex.dev/ai-town" rel="nofollow">Live Demo</a></p>
<p dir="auto"><a href="https://discord.gg/PQUmTBTGmT" rel="nofollow">Join our community Discord: AI Stack Devs</a></p>
<a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/3489963/260520547-a4c91f17-23ed-47ec-8c4e-9f9a8505057d.png"><img width="1454" alt="Screen Shot 2023-08-14 at 10 01 00 AM" src="https://user-images.githubusercontent.com/3489963/260520547-a4c91f17-23ed-47ec-8c4e-9f9a8505057d.png"></a>
<p dir="auto">AI Town is a virtual town where AI characters live, chat and socialize.</p>
<p dir="auto">This project is a deployable starter kit for easily building and customizing your own version of AI town. Inspired by the research paper <a href="https://arxiv.org/pdf/2304.03442.pdf" rel="nofollow"><em>Generative Agents: Interactive Simulacra of Human Behavior</em></a>.</p>
<p dir="auto">The primary goal of this project, beyond just being a lot of fun to work on, is to provided a platform with a strong foundation that is meant to be extended. The back-end engine natively supports shared global state, transactions, and a journal of all events so should be suitable for everything from a simple project to play around with to a scalable, multi-player game. A secondary goal is to make a JS/TS framework available as most simulators in this space (including the original paper above) are written in Python.</p>
<h2 tabindex="-1" dir="auto">Overview</h2>
<ul dir="auto">
<li><g-emoji alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">💻</g-emoji> <a href="#stack">Stack</a></li>
<li><g-emoji alias="brain" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png">🧠</g-emoji> <a href="#installation">Installation</a></li>
<li><g-emoji alias="bust_in_silhouette" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png">👤</g-emoji> <a href="#customize-your-own-simulation">Customize - run YOUR OWN simulated world</a></li>
<li><g-emoji alias="trophy" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c6.png">🏆</g-emoji> <a href="#credits">Credits</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Stack</h2>
<ul dir="auto">
<li>Game engine &amp; Database: <a href="https://convex.dev/" rel="nofollow">Convex</a></li>
<li>VectorDB: <a href="https://www.pinecone.io/" rel="nofollow">Pinecone</a></li>
<li>Auth: <a href="https://clerk.com/" rel="nofollow">Clerk</a></li>
<li>Text model: <a href="https://platform.openai.com/docs/models" rel="nofollow">OpenAI</a></li>
<li>Deployment: <a href="https://fly.io/" rel="nofollow">Fly</a></li>
<li>Pixel Art Generation: <a href="https://replicate.com/" rel="nofollow">Replicate</a>, <a href="https://serverless.fal.ai/lora" rel="nofollow">Fal.ai</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Installation</h2>
<h3 tabindex="-1" dir="auto">Clone repo and Install packages</h3>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:a16z-infra/ai-town.git
cd AI-town
npm install
npm run dev"><pre>git clone git@github.com:a16z-infra/ai-town.git
<span>cd</span> AI-town
npm install
npm run dev</pre></div>
<p dir="auto"><code>npm run dev</code> will fail asking for environment variables.
Enter them in the environment variables on your Convex dashboard to proceed.
You can get there via <code>npx convex dashboard</code> or <a href="https://dashboard.convex.dev/" rel="nofollow">https://dashboard.convex.dev</a>
See below on how to get the various environnment variables.</p>
<p dir="auto">a. <strong>Set up Clerk</strong></p>
<ul dir="auto">
<li>Go to <a href="https://dashboard.clerk.com/" rel="nofollow">https://dashboard.clerk.com/</a> and click on "Add Application"</li>
<li>Name your application and select the sign-in providers you would like to offer users</li>
<li>Create Application</li>
<li>Add <code>NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY</code> and <code>CLERK_SECRET_KEY</code> to <code>.env.local</code></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_***
CLERK_SECRET_KEY=sk_***"><pre>NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_<span>***</span>
CLERK_SECRET_KEY=sk_<span>***</span></pre></div>
<ul dir="auto">
<li>Go to JWT Templates and create a new Convex Template.</li>
<li>Copy the JWKS endpoint URL for use below.</li>
</ul>
<p dir="auto">b. <strong>OpenAI API key</strong></p>
<p dir="auto">Visit <a href="https://platform.openai.com/account/api-keys" rel="nofollow">https://platform.openai.com/account/api-keys</a> to get your OpenAI API key if you're using OpenAI for your language model.</p>
<p dir="auto">c. <strong>Pinecone API keys</strong></p>
<ul dir="auto">
<li>Create a Pinecone index by visiting <a href="https://app.pinecone.io/" rel="nofollow">https://app.pinecone.io/</a> and click on "Create Index"</li>
<li>Give it an index name (this will be the environment variable <code>PINECONE_INDEX_NAME</code>)</li>
<li>Fill in Dimension as <code>1536</code></li>
<li>Once the index is successfully created, click on "API Keys" on the left side nav and create an API key: copy "Environment" value to <code>PINECONE_ENVIRONMENT</code> variable, and "Value" to <code>PINECONE_API_KEY</code></li>
</ul>
<p dir="auto">d. <strong>Add secrets to the convex dashboard</strong></p>

<p dir="auto">Go to "settings" and add the following environment varables. <code>CLERK_ISSUER_URL</code> should be the URL from the JWKS endpoint.</p>
<div dir="auto" data-snippet-clipboard-copy-content="OPENAI_API_KEY  sk-*******
CLERK_ISSUER_URL  https://****
PINECONE_API_KEY  ********
PINECONE_ENVIRONMENT us****
PINECONE_INDEX_NAME  ********"><pre>OPENAI_API_KEY  sk-<span>*******</span>
CLERK_ISSUER_URL  https://<span>****</span>
PINECONE_API_KEY  <span>********</span>
PINECONE_ENVIRONMENT us<span>****</span>
PINECONE_INDEX_NAME  <span>********</span></pre></div>
<h3 tabindex="-1" dir="auto">Run the code</h3>
<p dir="auto">To run both the front and and back end:</p>

<p dir="auto">You can now visit <a href="http://localhost:%5BPORT_NUMBER%5D" rel="nofollow">http://localhost:[PORT_NUMBER]</a></p>
<p dir="auto">If you'd rather run the frontend in a separate terminal from Convex (which syncs
your backend functions as they're saved), you can run these two commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm run dev:frontend
npm run dev:backend"><pre>npm run dev:frontend
npm run dev:backend</pre></div>
<p dir="auto">See package.json for details, but dev:backend runs <code>npx convex dev</code></p>
<p dir="auto">*Note: The simulation will pause after 5 minutes if the window is idle.
Loading the page will unpause it. If you want to run the world without the
browser, you can comment-out the heartbeat check in <code>convex/engine.ts</code></p>
<h3 tabindex="-1" dir="auto">Various commands to run / test / debug</h3>
<p dir="auto"><strong>To add a new world, seed it, and start it running</strong></p>
<p dir="auto"><strong>Note</strong>: you can add <code>--no-push</code> to run these commands without first syncing
the functions. If you already have <code>npm run dev</code> running, this will be faster.
If you remove it, it'll push up the latest version of code before running the
command.</p>
<div dir="auto" data-snippet-clipboard-copy-content="npx convex run init:reset"><pre>npx convex run init:reset</pre></div>
<p dir="auto"><strong>To go one iteration at a time, you can create a world with</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="npx convex run --no-push init:resetFrozen

# for each iteration
npx convex run --no-push engine:tick '{&quot;worldId&quot;:&quot;<your world id>&quot;,&quot;noSchedule&quot;:true}'"><pre>npx convex run --no-push init:resetFrozen

<span><span>#</span> for each iteration</span>
npx convex run --no-push engine:tick <span><span>'</span>{"worldId":"&lt;your world id&gt;","noSchedule":true}<span>'</span></span></pre></div>
<p dir="auto"><strong>To freeze the back end, in case of too much activity</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="npx convex run --no-push engine:freezeAll

# when ready to rerun (defaults to latest world)
npx convex run --no-push engine:unfreeze"><pre>npx convex run --no-push engine:freezeAll

<span><span>#</span> when ready to rerun (defaults to latest world)</span>
npx convex run --no-push engine:unfreeze</pre></div>
<p dir="auto"><strong>To clear all databases</strong></p>
<p dir="auto">Many options:</p>
<ul dir="auto">
<li>Go to the dashboard <code>npx convex dashboard</code> and clear tables from there.</li>
<li>Adjust the variables in <a href="https://github.com/a16z-infra/ai-town/blob/main/convex/crons.ts"><code>crons.ts</code></a> to automatically clear
up space from old journal and memory entries.</li>
<li>Run <code>npx convex run --no-push testing:debugClearAll</code> to wipe all the tables.</li>
<li>As a fallback, if things are stuck, you can check out the <code>origin/reset-town</code>
git branch. Doing <code>npm run dev</code> from there will clear your schema, stop your
functions, and allow you to delete your tables in the dashboard.</li>
</ul>
<p dir="auto">To delete all vectors from the Pinecone index, you can run:</p>
<div data-snippet-clipboard-copy-content="npx convex run --no-push lib/pinecone:deleteAllVectors"><pre><code>npx convex run --no-push lib/pinecone:deleteAllVectors
</code></pre></div>
<p dir="auto"><strong>NOTE</strong>: If you share this index between dev &amp; prod, or between projects,
it will wipe them all out. You generally don't need to be deleting vectors from
Pinecone, as each query is indexed on the userId, which is unique between worlds
and backend instances.</p>
<p dir="auto"><strong>To Snoop on messages</strong></p>
<p dir="auto">Run the following in a side terminal</p>
<div dir="auto" data-snippet-clipboard-copy-content="npx convex run testing:listMessages --no-push --watch"><pre>npx convex run testing:listMessages --no-push --watch</pre></div>
<p dir="auto">Or to watch one player's state:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npx convex run testing:latestPlayer --no-push --watch"><pre>npx convex run testing:latestPlayer --no-push --watch</pre></div>
<p dir="auto">See more functions in <a href="https://github.com/a16z-infra/ai-town/blob/main/convex/testing.ts"><code>testing.ts</code></a>.</p>
<h3 tabindex="-1" dir="auto">Deploy the app</h3>
<h4 tabindex="-1" dir="auto">Deploy to fly.io</h4>
<ul dir="auto">
<li>
<p dir="auto">Register an account on fly.io and then <a href="https://fly.io/docs/hands-on/install-flyctl/" rel="nofollow">install flyctl</a></p>
</li>
<li>
<p dir="auto"><strong>If you are using Github Codespaces</strong>: You will need to <a href="https://fly.io/docs/hands-on/install-flyctl/" rel="nofollow">install flyctl</a> and authenticate from your codespaces cli by running <code>fly auth login</code>.</p>
</li>
<li>
<p dir="auto">Run <code>npx convex deploy</code> to deploy your dev environment to prod environment. Make sure you copy over all secrets to Convex's prod environment</p>
</li>
<li>
<p dir="auto">Run <code>fly launch</code> under project root. This will generate a <code>fly.toml</code> that includes all the configurations you will need</p>
</li>
<li>
<p dir="auto">Modify generated <code>fly.toml</code> to include <code>NEXT_PUBLIC_*</code> during build time for NextJS to access client side.</p>
</li>
</ul>
<div data-snippet-clipboard-copy-content="[build]
  [build.args]
    NEXT_PUBLIC_CLERK_SIGN_IN_URL=&quot;/sign-in&quot;
    NEXT_PUBLIC_CLERK_SIGN_UP_URL=&quot;/sign-up&quot;
    NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=&quot;/&quot;
    NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=&quot;/&quot;
    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=&quot;pk_*****&quot;
    NEXT_PUBLIC_CONVEX_URL=&quot;https://*******.convex.cloud&quot;"><pre><code>[build]
  [build.args]
    NEXT_PUBLIC_CLERK_SIGN_IN_URL="/sign-in"
    NEXT_PUBLIC_CLERK_SIGN_UP_URL="/sign-up"
    NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL="/"
    NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL="/"
    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY="pk_*****"
    NEXT_PUBLIC_CONVEX_URL="https://*******.convex.cloud"
</code></pre></div>
<ul dir="auto">
<li>Modify fly.io's generated <code>Dockerfile</code> to include new ENV variables right above <code>RUN npm run build</code></li>
</ul>
<div data-snippet-clipboard-copy-content="ARG NEXT_PUBLIC_CLERK_SIGN_IN_URL
ARG NEXT_PUBLIC_CLERK_SIGN_UP_URL
ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL
ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL
ARG NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY
ARG NEXT_PUBLIC_CONVEX_URL

# Build application
RUN npm run build"><pre><code>ARG NEXT_PUBLIC_CLERK_SIGN_IN_URL
ARG NEXT_PUBLIC_CLERK_SIGN_UP_URL
ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL
ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL
ARG NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY
ARG NEXT_PUBLIC_CONVEX_URL

# Build application
RUN npm run build
</code></pre></div>
<ul dir="auto">
<li>Run <code>fly deploy --ha=false</code> to deploy the app. The --ha flag makes sure fly only spins up one instance, which is included in the free plan.</li>
<li>Run <code>fly scale memory 512</code> to scale up the fly vm memory for this app.</li>
<li>Create a new file <code>.env.prod</code> locally and fill in all the production-environment secrets. Remember to update <code>NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY</code> and <code>CLERK_SECRET_KEY</code> by copying secrets from Clerk's production instance -<code>cat .env.prod | fly secrets import</code> to upload secrets. Also remember to update <code>CONVEX_DEPLOYMENT</code> and <code>NEXT_PUBLIC_CONVEX_URL</code>.</li>
</ul>
<h2 tabindex="-1" dir="auto">Customize your own simulation</h2>
<p dir="auto">NOTE: every time you change character data, you should re-run <code>npx convex run testing:debugClearAll --no-push</code> and then <code>npm run dev</code> to re-upload everything to Convex. This is because character data is sent to Convex on the initial load. However, beware that <code>npx convex run testing:debugClearAll --no-push</code> WILL wipe all of your data, including your vector store.</p>
<ol dir="auto">
<li>Create your own characters and strories: All characters and stories, as well as their spirtesheet references are stored in <a href="https://github.com/a16z-infra/ai-town/blob/main/convex/characterdata/data.ts#L4">data.ts</a>. You can start by changing character descriptions.</li>
<li>Updating spritesheets: in <code>data.ts</code>, you will see this code:</li>
</ol>
<div data-snippet-clipboard-copy-content="  {
    name: 'f1',
    textureUrl: '/assets/32x32folk.png',
    spritesheetData: f1SpritesheetData,
    speed: 0.1,
  },..."><pre lang="export"><code>  {
    name: 'f1',
    textureUrl: '/assets/32x32folk.png',
    spritesheetData: f1SpritesheetData,
    speed: 0.1,
  },...
</code></pre></div>
<p dir="auto">You should find a sprite sheet for your character, and define sprite motion / assets in the corresponding file (in the above example, <code>f1SpritesheetData</code> was defined in f1.ts)</p>
<ol start="3" dir="auto">
<li>Update the background (environment): <code>convex/maps/firstmap.ts</code> is where the map gets loaded. The easiest way to export a tilemap is by using <a href="https://www.mapeditor.org/" rel="nofollow">Tiled</a> -- Tiled export tilemaps as a CSV and you can convert CSV to a 2d array accepted by firstmap.ts</li>
</ol>
<h2 tabindex="-1" dir="auto">Credits</h2>
<ul dir="auto">
<li>Tilesheet:
<ul dir="auto">
<li><a href="https://opengameart.org/content/16x16-game-assets" rel="nofollow">https://opengameart.org/content/16x16-game-assets</a> by George Bailey</li>
<li><a href="https://opengameart.org/content/16x16-rpg-tileset" rel="nofollow">https://opengameart.org/content/16x16-rpg-tileset</a> by hilau</li>
</ul>
</li>
<li>We used <a href="https://github.com/pierpo/phaser3-simple-rpg">https://github.com/pierpo/phaser3-simple-rpg</a> for the original POC of this project. We have since re-wrote the whole app, but appreciated the easy starting point</li>
<li>Original assets by <a href="https://opengameart.org/content/tiny-rpg-forest" rel="nofollow">ansimuz</a></li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dell fined $6.5M after admitting it made overpriced monitors look discounted (134 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/08/dell-fined-6-5m-after-admitting-it-made-overpriced-monitors-look-discounted/</link>
            <guid>37128281</guid>
            <pubDate>Mon, 14 Aug 2023 23:44:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/08/dell-fined-6-5m-after-admitting-it-made-overpriced-monitors-look-discounted/">https://arstechnica.com/gadgets/2023/08/dell-fined-6-5m-after-admitting-it-made-overpriced-monitors-look-discounted/</a>, See on <a href="https://news.ycombinator.com/item?id=37128281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      5,300 monitors sold    —
</h4>
            
            <h2 itemprop="description">Dell Australia is paying for something many of its peers are guilty of. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/GettyImages-497371776-800x533.jpg" alt="An employee uses a handheld scanner to register the barcode of an outgoing Dell Inc. computer monitor inside the warehouse of an order fulfillment centre,">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 52:single/related:ba14820ac87d6f95974cc19b433acd26 --><!-- empty -->
<p>Dell's Australia arm has been slapped with a $10 million AUD (about $6.49 million) fine for "making false and misleading representations on its website about discount prices for add-on computer monitors," the Australian Competition &amp; Consumer Commission (ACCC) announced today. The Australian regulator said the company sold 5,300 monitors this way.</p>
<p>As Ars Technica previously reported, the ACCC launched <a href="https://arstechnica.com/gadgets/2023/06/dell-in-hot-water-for-making-shoppers-think-overpriced-monitors-were-discounted/">litigation against Dell Australia</a> in November. In June, the Australian Federal Court <a href="https://www.judgments.fedcourt.gov.au/judgments/Judgments/fca/single/2023/2023fca0588" data-uri="05854df1c1e3192c7a6baccebbf109c8">declared</a> that Dell Australia made shoppers believe monitors would be cheaper if bought as an add-on item.</p>
<p>Here's how the "misleading representations" worked. Shoppers of Dell Australia's website who were buying a computer would see an offer for a Dell display with a lower price next to a higher price with a strikethrough line. That suggested to shoppers that the price they'd pay for the monitor if they added it to their cart now would be lower than the monitor's usual cost. But it turns out the strikethrough prices weren't the typical costs. Sometimes, the lower price was actually <em>higher</em> than what Dell Australia typically charged.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/Dell-jpg.jpg" data-height="874" data-width="654"><img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/Dell-jpg-640x855.jpg" width="640" height="855" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/08/Dell-jpg.jpg 2x"></a><figcaption></figcaption></figure>
<p>"In some cases, consumers paid more for the add-on monitor advertised as 'discounted' than they would have paid if they had bought it as a stand-alone product, which is shocking," ACCC commissioner Liza Carver said in a statement in June.</p>
<p>Dell Australia's website would use savings-signaling lingo, such as: "Includes x% off," "Total Savings" plus a dollar amount, and "Get the best price for popular accessories when purchased with this product," the ACCC noted.</p>                                            
                                                        
<p>Dell Australia also admitted to overstating "discounts customers received" since "monitors were not sold for the strikethrough price for most of the relevant time" and that it "contravened the Australian Consumer Law," according to ACCC's announcement today.</p>
<p>These tricky methods led to shoppers spending over $2 million AUD (about $1.3 million) on Dell monitors from August 2019 to December 2021, according to the ACCC.</p>
<p>“We took this action against Dell Australia because consumers rely on accurate information about prices and discounts to make purchasing decisions," Carver said in a statement today.</p>
<p>Dell Australia was already ordered by Australia's Federal Court to provide full or partial refunds to customers. The ACCC said Dell has already started contacting customers about giving full or partial refunds.</p>
<p>A Dell spokesperson told Ars Technica today that Dell is also paying customers interest and "taking steps to improve our pricing processes to ensure this sort of error does not happen again." Dell didn't specify its exact steps, but in June, Australia's Federal Court ordered Dell Australia to hire an "independent compliance professional."</p>
<p>A Dell spokesperson also told Ars:</p>
<blockquote><p>We are pleased that this is now behind us, and our focus can return to serving our Australian customers. As we acknowledged in November 2022 when the ACCC commenced these proceedings, due to an error in Dell's pricing processes, there was incorrect information displayed on our website about the pricing and savings associated with certain monitors.</p></blockquote>
<p>Unfortunately, for shoppers, even if Dell makes good on its word and eliminates tactics that make typical or bad prices seem like deals, the practice is common among consumer tech vendors. I often see OEMs list products, like laptops and monitors, with discounted prices <em>before</em> they've actually been released. And online marketplaces are flooded with strikethrough prices that represent what the product might have cost <em>years</em> ago.</p>
<p>Dell Australia may promise to make it easier to spot its actual deals, but it's best to make your own price comparisons or use a price tracker like <a href="https://pcpartpicker.com/" data-uri="8379f2468ee2483f463d89cdbcdc3028">PCPartPicker</a> or <a href="https://camelcamelcamel.com/camelizer" data-uri="6f2b6aaa9b5247ef1624625dd07701e8">The Camelizer</a> (which also comes as a handy browser plugin) and avoid buyer's remorse.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive responds to recording industry lawsuit targeting obsolete media (381 pts)]]></title>
            <link>https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/</link>
            <guid>37128044</guid>
            <pubDate>Mon, 14 Aug 2023 23:14:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/">https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/</a>, See on <a href="https://news.ycombinator.com/item?id=37128044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>Late Friday, some of the world’s largest record labels, including Sony and Universal Music Group, filed a lawsuit against the Internet Archive and others for the <a href="https://great78.archive.org/">Great 78 Project</a>, a community effort for the preservation, research and discovery of 78 rpm records that are 70 to 120 years old. As a non-profit library, we take this matter seriously and are currently reviewing the lawsuit with our legal counsel.</p>


<div>
<figure><a href="http://blog.archive.org/wp-content/uploads/2023/08/20thcenturytimemachineimages_0000.jpg"><img decoding="async" width="500" height="750" src="http://blog.archive.org/wp-content/uploads/2023/08/20thcenturytimemachineimages_0000.jpg" alt="" srcset="https://blog.archive.org/wp-content/uploads/2023/08/20thcenturytimemachineimages_0000.jpg 500w, https://blog.archive.org/wp-content/uploads/2023/08/20thcenturytimemachineimages_0000-200x300.jpg 200w" sizes="(max-width: 500px) 100vw, 500px"></a><figcaption>A 78 rpm player in the foyer of the Internet Archive.</figcaption></figure></div>


<p>Of note, the <a href="https://great78.archive.org/">Great 78 Project</a> has been in operation since 2006 to bring free public access to a largely forgotten but culturally important medium. Through the efforts of dedicated librarians, archivists and sound engineers, we have preserved hundreds of thousands of recordings that are stored on shellac resin, an obsolete and brittle medium. The resulting preserved recordings retain the scratch and pop sounds that are present in the analog artifacts; noise that modern remastering techniques remove.</p>



<p><strong>Statement from Brewster Kahle, digital librarian of the Internet Archive:</strong><br>“When people want to listen to music they go to Spotify. When people want to study sound recordings as they were originally created, they go to libraries like the Internet Archive. Both are needed. There shouldn’t be conflict here.”</p>



<p>These preservation recordings are used in teaching and research, including by university professors like Jason Luther of Rowan University, whose students use the Great 78 collection as the basis for researching and writing podcasts for use in class assignments (<a href="https://blog.archive.org/2021/06/09/university-professor-leverages-78rpm-record-collection-from-the-internet-archive-for-students/">University Professor Leverages 78rpm Record Collection From the Internet Archive for Student Podcasts</a>, June 9, 2021). While this mode of access is important, usage is tiny—on average, each recording in the collection is only accessed by one researcher per month.</p>



<figure><a href="https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1.jpg"><img decoding="async" loading="lazy" width="1000" height="750" src="https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1.jpg" alt="" srcset="https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1.jpg 1000w, https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1-300x225.jpg 300w, https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1-768x576.jpg 768w, https://blog.archive.org/wp-content/uploads/2023/08/Technician-digitizes-78-1000x750-1-624x468.jpg 624w" sizes="(max-width: 1000px) 100vw, 1000px"></a><figcaption>A technician uses a 4-arm turntable to digitize a 78 rpm record.</figcaption></figure>



<p>While we review the lawsuit, we remain dedicated to our mission of providing “Universal Access to All Knowledge.” We are grateful for the continued support of our library patrons and partners as we continue to fight these attacks.</p>



<p>For more information or media inquiries, please contact <a href="mailto:press@archive.org">press@archive.org</a>.&nbsp;</p>



<p><strong>LINKS</strong></p>



<ul>
<li>The Great 78 Project: <a href="https://great78.archive.org/">https://great78.archive.org/</a>&nbsp;</li>



<li>University Professor Leverages 78rpm Record Collection From the Internet Archive for Student Podcasts: <a href="https://blog.archive.org/2021/06/09/university-professor-leverages-78rpm-record-collection-from-the-internet-archive-for-students/">https://blog.archive.org/2021/06/09/university-professor-leverages-78rpm-record-collection-from-the-internet-archive-for-students/</a>&nbsp;</li>



<li>78 rpm record digitization: <a href="https://archive.org/details/mass78rpmdiscdigitization">https://archive.org/details/mass78rpmdiscdigitization</a></li>
</ul>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Montana loses fight against youth climate activists in landmark ruling (150 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/08/montana-loses-fight-against-youth-climate-activists-in-landmark-ruling/</link>
            <guid>37127606</guid>
            <pubDate>Mon, 14 Aug 2023 22:33:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/08/montana-loses-fight-against-youth-climate-activists-in-landmark-ruling/">https://arstechnica.com/tech-policy/2023/08/montana-loses-fight-against-youth-climate-activists-in-landmark-ruling/</a>, See on <a href="https://news.ycombinator.com/item?id=37127606">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      "A monumental decision"    —
</h4>
            
            <h2 itemprop="description">Emotional testimony leads to plaintiffs' win in first youth-led climate trial.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/GettyImages-1258643987-800x532.jpg" alt="Youth plaintiffs are greeted by supporters as they arrive for the nation's first youth climate change trial at Montana's First Judicial District Court on June 12, 2023. ">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/GettyImages-1258643987.jpg" data-height="681" data-width="1024">Enlarge</a> <span>/</span> Youth plaintiffs are greeted by supporters as they arrive for the nation's first youth climate change trial at Montana's First Judicial District Court on June 12, 2023. </p></figcaption>  </figure>

  




<!-- cache hit 52:single/related:a2e5d82019c1f66e0c2bd583e2cac693 --><!-- empty -->
<p>A Montana state court <a href="https://westernlaw.org/wp-content/uploads/2023/08/2023.08.14-Held-v.-Montana-victory-order.pdf">today sided</a> with <a href="https://arstechnica.com/tech-policy/2023/06/montana-calls-un-climate-report-hearsay-at-landmark-youth-led-climate-trial/">young people who sued the state</a> for promoting the fossil fuel industry through its <a href="https://leg.mt.gov/bills/2023/billpdf/HB0971.pdf">energy policy</a>, which they alleged prohibits Montana from weighing greenhouse gas emissions in approving the development of new factories and power plants. This prohibition, 16 plaintiffs ages 5 to 22 successfully argued, violates their constitutional right to a "clean and healthful environment in Montana for present and future generations."</p>
<p>Experts previously predicted that a win for youths in Montana would set an important legal precedent for how courts can hold states accountable for climate inaction. The same legal organization representing Montana's young plaintiffs, Our Children's Trust, is currently pursuing similar cases in four other states, <a href="https://www.washingtonpost.com/climate-environment/2023/08/14/youths-win-montana-climate-trial/">The Washington Post reported</a>.</p>
<p>The Post described this landmark case as "the nation’s first constitutional and first youth-led climate lawsuit to go to trial."</p>
<p>To climate activists, it illustrates the power of a court hearing directly from young people describing experiences with immense loss caused by climate change. Today's order followed five days of emotional testimony from young plaintiffs describing harms caused by the state's climate inaction.</p>
<p>Montana tried to argue that adjusting its energy policy and other statutes would have “no meaningful impact or appreciable effect,” the Post reported, because climate change is a global issue. Montana Assistant Attorney General Michael Russell described the testimony as a “week-long airing of political grievances that properly belong in the Legislature, not a court of law,” according to the Post. Notably, the state did not meaningfully attempt to dispute climate science.</p>
<p>However, "undisputed testimony established" that the state "could evaluate 'greenhouse gas emissions and corresponding impacts to the climate in the state' when evaluating fossil fuel activities," judge Kathy Seeley wrote in the Montana 1st Judicial District Court <a href="https://westernlaw.org/wp-content/uploads/2023/08/2023.08.14-Held-v.-Montana-victory-order.pdf">order</a>. The state had no compelling interest not to conduct climate analyses and consider remedies, Seeley wrote.</p>                                            
                                                        
<p>Experts <a href="https://www.scientificamerican.com/article/young-people-in-historic-climate-trial-rest-their-case/">told Scientific American</a> that Montana's emissions are significant given its population size, emitting in 2019 "about 32 million tons of carbon dioxide." That's "about as much as Ireland, which has a population six times larger," Scientific American reported. Young people suing alleged that Montana had "never denied a permit for a fossil fuel project," the Post reported.</p>
<p>Because of this powerful youth testimony, the court ruled that the state's energy policy's limitation on environmental impact reviews was unconstitutional.</p>
<p>"Montana's greenhouse gas emissions and climate change have been proven to be a substantial factor in causing climate impacts to Montana's environment and harm and injury to the youth plaintiffs," Seeley wrote.</p>
<p>As a result of the order, any Montana statutes prohibiting climate impact analysis and remedies are now invalid and permanently enjoined.</p>
<p>"This is a monumental decision," Phil Gregory, the plaintiffs' attorney, told the Post. Another attorney for plaintiffs and executive director of Our Children's Trust, Julia Olson, <a href="https://apnews.com/article/climate-change-youth-montana-trial-c7fdc1d8759f55f60346b31c73397db0?taid=64da64ccb5e4dd0001f844bc&amp;utm_campaign=TrueAnthem&amp;utm_medium=AP&amp;utm_source=Twitter">told AP</a> that the ruling was a "huge win for Montana, for youth, for democracy, and for our climate."</p>
<p>Montana is expected to appeal the ruling, according to Emily Flower, a spokesperson for the state's Attorney General Austin Knudsen, who called the ruling "absurd."</p>
<p>“Montanans can’t be blamed for changing the climate—even the plaintiffs’ expert witnesses agreed that our state has no impact on the global climate," Flower said. "Their same legal theory has been thrown out of federal court and courts in more than a dozen states. It should have been here as well, but they found an ideological judge who bent over backward to allow the case to move forward and earn herself a spot in their next documentary.”</p>
<p>Youth plaintiffs did not ask for any damages beyond their attorneys' fees and costs, which were awarded by the court. To young people suing, winning is seemingly just about pushing the state to embrace climate science and mitigate known harms moving forward.</p>
<p>“As fires rage in the West, fueled by fossil fuel pollution, today’s ruling in Montana is a game-changer that marks a turning point in this generation’s efforts to save the planet from the devastating effects of human-caused climate chaos,” Olson told AP.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cuts at WVU (103 pts)]]></title>
            <link>https://community.wvu.edu/~jokatz/Closure/</link>
            <guid>37127450</guid>
            <pubDate>Mon, 14 Aug 2023 22:13:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.wvu.edu/~jokatz/Closure/">https://community.wvu.edu/~jokatz/Closure/</a>, See on <a href="https://news.ycombinator.com/item?id=37127450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div face="garamond, palatino, geneva">
<span>
<img src="http://community.wvu.edu/~jokatz/JKShih.jpg" alt="Photo by Stephanie Shih" height="300">		
<p>My name is Jonah Katz; I'm an associate professor of linguistics at West Virginia University. I work in a large department that includes all of the world languages and literatures at WVU in addition to its 'basic' and applied linguistics programs. On August 10, 2023, the WVU provost recommended dissolving our department and all of its academic programs and faculty lines, including the only Linguistics programs in the state of West Virginia (our MA and undergrad minor). All of the tenured and untenured faculty in the department are to be laid off, including the linguistics faculty. All of the foreign language and literature programs at the university are to be discontinued; the president of the university publicly stated that foreign-language classes will be replaced with online apps or remote classes at other universities. I'm asking linguists to help us publicize what's happened here and advocate on our behalf. We are a very small program (4 faculty in basic linguistics and 4-5 more in applied linguistics/TESOL), but punch well above our weight in both research output and external grant funding. In fact, on the same day WVU wrote to tell us our department is cancelled and we are fired, they ran a front-page <a href="https://wvutoday.wvu.edu/stories/2023/08/10/wvu-linguists-sound-out-how-intensity-and-duration-of-speech-shape-pronunciation-rethinking-language-learning">article</a> on the university website celebrating the NSF grant that Sergio Robles-Puente and I recently received, and lauding our innovative research and intensive student mentoring. That grant will now need to be discontinued or moved to another institution.
</p><p>The reason given for this egregious violation of ethical and professional norms is that the university faces a dire budget crisis, and the administration has no choice but to cut academic programs in order to close their structural budget deficit. But the administration's own financial data, gathered at great cost with external consultants and publicly posted <a href="https://provost.wvu.edu/files/d/bf3ef02f-e90a-4e43-a316-d295fa489067/academic-transformation-public-data-table_july-17-2023-100.pdf">here</a>, clearly indicate that the department as a whole (p. 7) has generated operating profits of more than $800,000 in each of the last three years, even without counting our grant income, which is substantial (our NSF project is just one of several large external grants that faculty in our department have been awarded in the past several years). This is not a financial decision: it is an ideological one, as our president's public comments make clear.
</p><p>The story of how the university got into such a catastrophic financial position to begin with is a long and complex one, and tangential to my message here. But for those interested, <a href="https://www.chronicle.com/article/why-is-west-virginia-u-making-sweeping-cuts?">this exposé</a> in the Chronicle of Higher Education (unfortunately paywalled for many readers) and this <a href="https://wvufacts.wordpress.com/">anonymous report</a> by WVU faculty demonstrate convincingly that skyrocketing administrative personnel costs and excessive debt associated with a failed growth strategy are two of the major drivers (declining enrollment, COVID, and inadequate state funding also played a role).
</p><p>To be honest, I don't know if anything that we can do will help the situation. The leadership of the university has made up its mind, they have the backing of state politicians and the board they appointed to oversee the university, and they will not be swayed by appeals to reason or ideals. What they may respond to is public pressure, and to that end I am asking my colleagues to share what is happening here as widely as you can through all available media and professional networks. Sunlight is the best disinfectant, and we need a whole lot of disinfectant at my institution. You could also consider writing to the people who made these decisions and their enablers, and if you represent an organization like a department or institute, consider doing so publicly in an open letter. Let them know what you think of the decision to eliminate all foreign language, literature, and linguistics classes at a public land-grant state flagship, and to fire all faculty regardless of merit, longevity, or tenure. Let them know how this will affect the reputation of West Virginia University and the state that it represents. Let them know how it will affect young people's prospects and their choices in one of the poorest and least-educated states in the country, where huge numbers of our most talented and driven young people are already leaving to seek better educational and professional opportunities. Thank you for your time, and to my many wonderful colleagues who have reached out this week to ask how you can help. I am lucky beyond belief to work in such a supportive, principled, and collaborative field, and to have so many amazing mentors and colleagues. Linguists really are the best. 

</p></span></div><p><span face="garamond, palatino, geneva">University leadership directly in charge of this process include President Gordon Gee ( Gordon.Gee@mail.wvu.edu ) and Provost Maryanne Reed ( Maryanne.Reed@mail.wvu.edu ). The WVU Board of Governors is a politically appointed body that is supposed to oversee the administration of the university, and will eventually need to approve the provost's recommendations. They can be contacted via Special Assistant Valerie Lopez ( Valerie.Lopez@mail.wvu.edu ). Governor Jim Justice appointed most of the Board and has strongly supported Gee during his term. His office can be contacted using <a href="https://appengine.egov.com/apps/wv/governor/contactus">this form</a>. 
 
</span></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grindr employees have 2 weeks: agree to move across the country+RTO or lose jobs (107 pts)]]></title>
            <link>https://www.businessinsider.com/grindr-united-unionized-employees-work-from-home-return-in-person-2023-8</link>
            <guid>37126856</guid>
            <pubDate>Mon, 14 Aug 2023 21:12:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/grindr-united-unionized-employees-work-from-home-return-in-person-2023-8">https://www.businessinsider.com/grindr-united-unionized-employees-work-from-home-return-in-person-2023-8</a>, See on <a href="https://news.ycombinator.com/item?id=37126856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Employees at LGBTQ+ dating site Grindr are being asked to return to work in person.&nbsp;</li><li>The company gave employees two weeks to decide if they could move by October.&nbsp;</li><li>The company's employees say Grindr could be retaliating against them for trying to form a union.</li></ul><section id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="newsinlinesignup">
                            
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section><p>Management at the popular LGBTQ+ dating app Grindr is asking workers to return to the office or lose their jobs, prompting outrage from employees who say the move will upend their lives.</p><p>According to a form sent to workers at Grindr on August 4, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.vice.com/en/article/qjv3gm/grindr-tells-unionizing-workers-move-across-the-country-or-be-fired" data-analytics-product-module="body_link"><u>obtained by Vice's Motherboard</u></a>, workers would need to confirm by August 17 whether or not they would move within 50 miles of Grindr's three offices in Chicago, Los Angeles, or the San Francisco Bay Area or lose their jobs at the end of the month.</p><p>The news comes two weeks after employees <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/unions-having-major-moment-but-dont-expect-1930s-level-boom-2023-7" data-analytics-product-module="body_link"><u>announced their effort to unionize</u></a> under the Communications Workers of America, Grindr United. Grindr United posted Sunday that the pivot to in-person work by the company <a target="_blank" rel="noopener noreferrer nofollow" href="https://twitter.com/GrindrUnited/status/1690811142082527233?s=20" data-analytics-product-module="body_link"><u>is a "bizarre coincidence."</u></a></p><p>The CWA has also <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.nlrb.gov/case/31-CA-323349" data-analytics-product-module="body_link"><u>filed a complain</u></a>t with the National Labor Relations Board as a result of the return to office order, arguing that it is retaliation against union organizing.</p><div id="1691976039072" data-styles="default-width" data-embed-type="twitter" data-script="https://platform.twitter.com/widgets.js" data-type="embed"><blockquote><div lang="en" dir="ltr"><p>Timeline review!</p><p>July 20: we tell management that we have organized ourselves and request voluntary recognition.</p><p>July 20 - Aug 3: no contact from management. At all. None. Zero.</p><p>Aug 4: management announces we have two weeks to decide whether to uproot our lives or we're fired.</p></div>— Grindr United ✊ (@GrindrUnited) <a href="https://twitter.com/GrindrUnited/status/1687803784251031552?ref_src=twsrc%5Etfw" rel=" nofollow">August 5, 2023</a></blockquote>  
                        </div><p>Rowan Rosenthal, an organizing committee member at Grindr United CWA, told Insider that the move has been a significant hit for Grindr's "majority queer" workplace, as well as for disabled members of the company.</p><p>"A big part of our vision as a union was to enshrine this benefit that we had in the past of remote first to accommodate those folks," Rosenthal told Insider. "A lot of people who are disabled or have neurodivergence or mental health concerns or caring for somebody that they love, it just makes it a lot more possible to do your best work when you have the flexibility to work from your home or go into an office in your city a few times a week or month."</p><p>Rosenthal told Insider that as of Monday, Grindr has given employees an opportunity to send in questions about the company's new policy but still has not addressed union organizers.</p><p>Grindr CEO George Arison told staff that the decision was "many months" in the making, per a memo <a target="_blank" rel="noopener noreferrer nofollow" href="https://news.bloomberglaw.com/daily-labor-report/grindr-uses-return-to-work-order-to-thwart-union-complaint-says" data-analytics-product-module="body_link"><u>obtained by Bloomberg.</u></a></p><p>In a statement to Insider, a company spokesperson said the company began "the process of transitioning away from 'remote-first' to hybrid" in April and that employees were informed of a future switch to hybrid work during an all-hands meeting in June — before the <a target="_blank" rel="noopener noreferrer nofollow" href="https://time.com/6296516/grindr-union-tech-layoffs-lgbt/" data-analytics-product-module="body_link"><u>unionization effort was announced</u></a>.</p><p>However, employees told <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.nytimes.com/2023/08/12/business/grindr-rto-union.html" data-analytics-product-module="body_link"><u>The New York Times</u></a> that the company told them to expect the transition after one or two quarters. Rosenthal told Insider that they were not at the all-hands meeting but said many employees expected that remote workers would be allowed to stay remote based on company communications.</p><p>"We were told that we were going to hire new workers in these specific cities, but specifically that this was not going to affect existing employees," Rosenthal said.</p><p>The company spokesperson also said that the decision to move to a hybrid-work model has "nothing to do with the NLRB election petition" and said, "We respect and support our team members' rights to make their own decision about union representation."</p><p>Grindr is just one of the latest companies to <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/wfh-work-from-home-decreases-productivity-18-percent-study-rto-2023-8" data-analytics-product-module="body_link"><u>urge employees to return to the office</u></a>. <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/amazon-senior-leader-office-remote-work-grow-faster-better-job-2023-8" data-analytics-product-module="body_link"><u>Amazon</u></a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/apple-threatens-staff-not-coming-office-three-days-week-2023-3" data-analytics-product-module="body_link"><u>Apple</u></a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/disney-starbucks-forcing-employees-back-office-your-company-unlikely-next-2023-1" data-analytics-product-module="body_link"><u>Disney</u></a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/google-microsoft-ibm-companies-hybrid-work-office-collaboration-flexibility-happiness-2023-8" data-analytics-product-module="body_link"><u>Google</u></a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/meta-rehiring-workers-from-layoffs-2023-8" data-analytics-product-module="body_link"><u>Meta</u></a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/elon-musk-emailed-twitter-staff-office-is-not-optional-2023-3" data-analytics-product-module="body_link"><u>X</u></a> (formerly <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/x-could-be-a-positive-move-for-musk-twitter-2023-7" data-analytics-product-module="body_link"><u>Twitter</u></a>), and <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/companies-making-workers-employees-return-to-office-rto-wfh-hybrid-2023-1" data-analytics-product-module="body_link"><u>dozens of other </u></a>businesses are asking their white-collar employees to work in the office at least part of the time.</p><p>That model is unpopular <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/i-do-not-miss-office-life-2023-4" data-analytics-product-module="body_link"><u>among many workers</u></a>, who say they would <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/us-remote-workers-would-take-pay-cut-to-keep-wfh-2023-5" data-analytics-product-module="body_link"><u>take a pay cut over an in-person job.</u></a> According to a recent <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.wsj.com/articles/need-to-hire-workers-in-a-hot-job-market-let-them-do-some-remote-work-506f72e6?mod=hp_lead_pos8" data-analytics-product-module="body_link"><u>Wall Street Journal</u></a> report, employers forcing a return to <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.businessinsider.com/employees-work-from-home-benefits-as-good-as-raise-2023-8" data-analytics-product-module="body_link"><u>in-person work</u></a> are seeing slower hiring rates.</p><p>Quinn McGee, an employee organizer at Grindr United CWA, told Vice the demands sent by Grindr — which McGee said has refused to meet with employees about the union drive — were "dehumanizing."</p><p>"To tell me that I have two weeks to decide whether or not to uproot my family's life for a job that won't come to the table and speak with me as an adult — it's dehumanizing," McGee told the publication.</p><p>Rosenthal, who lives in New York, told Insider that they are being asked to move to Los Angeles as a member of the design team. To do this, they said, would mean that they would have to leave their family and community on the East Coast.</p><p>They also said that it would affect their goals of eventually getting gender-affirming surgery.</p><p>"It feels really awful and scary to be asked to either do this or resign from my job, functionally," Rosenthal said. "In terms of other return-to-office orders that I've seen other companies instate, it just feels shocking, to be honest with you."</p><p><em>Update: August 14, 2023 — This story has been updated to include quotes from Rowan Rosenthal, an organizing committee member for Grindr United CWA.</em></p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java 21: First Release Candidate (143 pts)]]></title>
            <link>https://openjdk.org/projects/jdk/21/</link>
            <guid>37126530</guid>
            <pubDate>Mon, 14 Aug 2023 20:40:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openjdk.org/projects/jdk/21/">https://openjdk.org/projects/jdk/21/</a>, See on <a href="https://news.ycombinator.com/item?id=37126530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">

<p>This release will be the Reference Implementation of
version&nbsp;21 of the Java&nbsp;SE Platform, as specified by
<a href="https://openjdk.org/projects/jdk/21/spec">JSR&nbsp;396</a> in the Java Community Process.</p>
<h2 id="Status">Status</h2>
<p>JDK 21 is in <a href="http://openjdk.java.net/jeps/3#rdp-1">Rampdown Phase Two</a>. The
overall feature set is frozen. No further JEPs will be targeted to
this release.</p>
<p>The stabilization repository, <a href="http://github.com/openjdk/jdk21">jdk21</a>, is open for select bug
fixes, <a href="https://openjdk.org/jeps/3#Fix-Request-Process">with approval</a>, per
the <a href="https://openjdk.org/jeps/3">JDK Release Process (JEP 3)</a>. Late
enhancements are still possible, <a href="https://openjdk.org/jeps/3#Late-Enhancement-Request-Process">with approval</a>, but
the bar is now extraordinarily high. Integrate most stabilization
changes via <a href="https://openjdk.org/jeps/3#Integrating-fixes-and-enhancements">backports
from the main-line repository</a>.</p>
<ul>
<li><a href="http://j.mp/jdk-rdp-2">RDP 2 candidate bugs</a></li>
<li><a href="https://openjdk.org/jeps/3#Fix-Request-Process">Fix-Request
Process</a></li>
<li><a href="https://openjdk.org/jeps/3#Bug-Deferral-Process">Bug-Deferral
Process</a></li>
<li><a href="https://openjdk.org/jeps/3#Late-Enhancement-Request-Process">Late-Enhancement Request
Process</a></li>
</ul>
<p>Early-access binaries under the GPL are available <a href="https://jdk.java.net/21/">here</a>.</p>
<h2 id="Schedule">Schedule</h2>
<blockquote>
<table summary="schedule">
<tbody><tr>
<td>2023/06/08</td>
<td></td>
<td><a href="https://openjdk.org/jeps/3#rdp-1">Rampdown Phase One</a>
(fork from main line)</td>
</tr>
<tr>
<td>2023/07/20</td>
<td></td>
<td><a href="https://openjdk.org/jeps/3#rdp-2">Rampdown Phase
Two</a></td>
</tr>
<tr>
<td>2023/08/10</td>
<td></td>
<td><a href="https://openjdk.org/jeps/3#rc">Initial Release
Candidate</a></td>
</tr>
<tr>
<td>2023/08/24</td>
<td></td>
<td><a href="https://openjdk.org/jeps/3#rc">Final Release
Candidate</a></td>
</tr>
<tr>
<td>2023/09/19</td>
<td></td>
<td>General Availability</td>
</tr>
</tbody></table>
</blockquote>
<h2 id="Features">Features</h2>
<blockquote>
<table summary="jeps"><!--
        <tr><th class="title" colspan="2">JEPs integrated into JDK 21</th></tr>
        -->
<tbody><tr>
<td>430:</td>
<td><a href="https://openjdk.org/jeps/430">String Templates (Preview)</a></td>
</tr>
<tr>
<td>431:</td>
<td><a href="https://openjdk.org/jeps/431">Sequenced Collections</a></td>
</tr>
<tr>
<td>439:</td>
<td><a href="https://openjdk.org/jeps/439">Generational ZGC</a></td>
</tr>
<tr>
<td>440:</td>
<td><a href="https://openjdk.org/jeps/440">Record Patterns</a></td>
</tr>
<tr>
<td>441:</td>
<td><a href="https://openjdk.org/jeps/441">Pattern Matching for switch</a></td>
</tr>
<tr>
<td>442:</td>
<td><a href="https://openjdk.org/jeps/442">Foreign Function &amp; Memory API (Third
Preview)</a></td>
</tr>
<tr>
<td>443:</td>
<td><a href="https://openjdk.org/jeps/443">Unnamed Patterns and Variables
(Preview)</a></td>
</tr>
<tr>
<td>444:</td>
<td><a href="https://openjdk.org/jeps/444">Virtual Threads</a></td>
</tr>
<tr>
<td>445:</td>
<td><a href="https://openjdk.org/jeps/445">Unnamed Classes and Instance Main Methods
(Preview)</a></td>
</tr>
<tr>
<td>446:</td>
<td><a href="https://openjdk.org/jeps/446">Scoped Values (Preview)</a></td>
</tr>
<tr>
<td>448:</td>
<td><a href="https://openjdk.org/jeps/448">Vector API (Sixth Incubator)</a></td>
</tr>
<tr>
<td>449:</td>
<td><a href="https://openjdk.org/jeps/449">Deprecate the Windows 32-bit x86 Port for
Removal</a></td>
</tr>
<tr>
<td>451:</td>
<td><a href="https://openjdk.org/jeps/451">Prepare to Disallow the Dynamic Loading of
Agents</a></td>
</tr>
<tr>
<td>452:</td>
<td><a href="https://openjdk.org/jeps/452">Key Encapsulation Mechanism API</a></td>
</tr>
<tr>
<td>453:</td>
<td><a href="https://openjdk.org/jeps/453">Structured Concurrency (Preview)</a></td>
</tr>
</tbody></table>
</blockquote>
<!--
    <blockquote>
      <table class="jeps" summary="jeps" width="100%">
        <tr><th class="title" colspan="2">JEPs proposed to target JDK 21</th>
            <th class="review">review&nbsp;ends</th></tr>

      </table>
    </blockquote>
-->
<p>Last update: 2023/7/20 15:05 UTC</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Shor's MIT Fall 2022 course lecture notes on quantum computing (136 pts)]]></title>
            <link>https://math.mit.edu/~shor/435-LN/</link>
            <guid>37126479</guid>
            <pubDate>Mon, 14 Aug 2023 20:36:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://math.mit.edu/~shor/435-LN/">https://math.mit.edu/~shor/435-LN/</a>, See on <a href="https://news.ycombinator.com/item?id=37126479">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2> Lecture Notes for 8.370/18.435 Quantum Computation from Fall 2022 </h2>

<h3><a href="http://www-math.mit.edu/~shor/contact-info/">Contact 
information</a></h3>

<!--- Here is the 2021 version of
<A HREF="https://math.mit.edu/~shor/Course-Info-435.pdf">the Course
Info page</a>. Most things stayed the same for 2022. --->

<h4>Lecture Notes</h4>
Here are the 2022 Lecture notes. I never got around to writing the notes for
Lecture 26 --- I may or may not do that at some point in the future.
<p> 

<a href="https://math.mit.edu/~shor/435-LN/Lecture_01.pdf">Lecture 1</a> 
---  Introduction and History<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_02.pdf">Lecture 2</a>
--- The Superposition Principle<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_03.pdf">Lecture 3</a>
--- Unitary Evolution and the Bloch Sphere
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_04.pdf">Lecture 4</a>
--- Quantum Measurements 
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_05.pdf">Lecture 5</a>
--- Joint Quantum Systems and Tensor Products
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_06.pdf">Lecture 6</a>
--- More Tensor Products (Measurements of Joint Systems)
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_07.pdf">Lecture 7</a>
--- Classical Boolean circuits
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_08.pdf">Lecture 8</a>
--- Reversible Boolean circuits
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_09.pdf">Lecture 9</a>
--- Quantum gates I
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_10.pdf">Lecture 10</a>
--- Quantum gates II
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_11.pdf">Lecture 11</a>
--- Quantum Teleportation
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_12.pdf">Lecture 12</a>
--- Density Matrices I
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_13.pdf">Lecture 13</a>
--- Density Matrices II
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_14.pdf">Lecture 14</a>
--- The GHZ Experiment (theory)
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_15.pdf">Lecture 15</a>
--- Quantum Optics and the GHZ Experiment
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_16.pdf">Lecture 16</a>
--- The Deutsch-Jozsa Algorithm
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_17.pdf">Lecture 17</a>
--- Classical computational complexity theory
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_18.pdf">Lecture 18</a>
--- Simon's algorithm
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_19.pdf">Lecture 19</a>
--- The quantum Fourier transform
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_20.pdf">Lecture 20</a>
--- Phase Estimation
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_21.pdf">Lecture 21</a>
--- Quantum factoring algorithm 
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_22.pdf">Lecture 22</a>
--- The Number Theory Needed for the Factoring Algorithm
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_23.pdf">Lecture 23</a>
--- The Discrete Log Algorithm
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_24.pdf">Lecture 24</a>
--- Grover's search algorithm
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_25.pdf">Lecture 25</a>
--- Proof that Grover Search is Optimal
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_26.pdf">Lecture 26</a>
--- Lecture on Hamiltonian Simulation; Notes Unwritten
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_27.pdf">Lecture 27</a>
--- Introduction to Quantum error correcting codes --- the 9-qubit code
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_28.pdf">Lecture 28</a>
--- More on the 9-qubit code
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_29.pdf">Lecture 29</a>
--- The 7-qubit Quantum Hamming Code
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_30.pdf">Lecture 30</a>
--- Quantum CSS Codes
<br>
<a href="https://math.mit.edu/~shor/435-LN/Lecture_31.pdf">Lecture 31</a>
--- The BB84 Quantum Key Distribution Protocol and the Proof of Its Security
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Burnout because of ChatGPT? (142 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37126182</link>
            <guid>37126182</guid>
            <pubDate>Mon, 14 Aug 2023 20:10:51 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37126182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37126182">
      <td><span></span></td>      <td><center><a id="up_37126182" href="https://news.ycombinator.com/vote?id=37126182&amp;how=up&amp;goto=item%3Fid%3D37126182"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37126182">Ask HN: Burnout because of ChatGPT?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37126182">104 points</span> by <a href="https://news.ycombinator.com/user?id=smdz">smdz</a> <span title="2023-08-14T20:10:51"><a href="https://news.ycombinator.com/item?id=37126182">5 hours ago</a></span> <span id="unv_37126182"></span> | <a href="https://news.ycombinator.com/hide?id=37126182&amp;goto=item%3Fid%3D37126182">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Burnout%20because%20of%20ChatGPT%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37126182&amp;auth=4a89681a7f8ea50f2f0b6195c20a05986749518d">favorite</a> | <a href="https://news.ycombinator.com/item?id=37126182">106&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>TL;DR (summarised by ChatGPT) - I'm experiencing increased productivity and independence with ChatGPT but grappling with challenges such as lack of work-life boundaries and overwhelming information, leading to stress and burnout.</p><p>Long story...</p><p>I have been using ChatGPT for a while, and moved to the Plus subscription for their GPT-4 model, which I must say, is quite good.</p><p>1. ChatGPT makes us very productive. Personally, in my early 40s, I feel my brain is back in 20s.</p><p>2. I no longer feel the need to hire juniors. This is a short-term positive and maybe a long-term negative.
[[EDIT: I may have implied a wrong meaning. To clarify - nobody's going yet because of ChatGPT. It is just raising the bar high and higher. What took me years to learn, this thing can do already and much more. And I cannot predict the financial future of OpenAI or the markets in general.]]</p><p>A lot of stuff I used to delegate to fellow humans are now being delegated to ChatGPT. And I can get the results immediately and at any time I want. I agree that it cannot operate on its own. I still need to review and correct things. I have do that even when working with other humans. The only difference is that I can start trusting a human to improve, but I cannot expect ChatGPT to do so. Not that it is incapable, but because it is restricted by OpenAI.</p><p>And I have gotten better at using it. Calling myself a prompt-engineer sounds weird.</p><p>With all the good, I am now experiencing the cons, stress and burnout:</p><p>1. Humans work 9-5 (or some schedule), but ChatGPT is available always and works instantly. Now, when I have some idea I want to try out - I start working on it immediately with the help of AI. Earlier I just used to put a note in the todo-list and stash it for the next day.</p><p>2. The outputs with ChatGPT are so fast, that my "review load" is too high. At times it feels like we are working for ChatGPT and not the other way around.</p><p>3. ChatGPT has the habit of throwing new knowledge back at you. Google does that too, but this feels 10x of Google. Sometimes it is overwhelming. Good thing is we learn a lot, bad thing is that if often slows down our decision making.</p><p>4. I tried to put a schedule to use it - but when everybody has access to this tech, I have a genuine fear of missing out.</p><p>5. I have zero doubt that AI is setting the bar high, and it is going to take away a ton of average-joe desk jobs. GPT-4 itself is quite capable and organisations are yet to embrace it.</p><p>And not the least, it makes me worry - what lies with the future models. I am not a layman when it comes to AI/ML - have worked with it until the past few years in the pre-GPT era.</p><p>Has anybody experienced these issues? And how do you deal with those?</p><p>* I could not resist asking ChatGPT the above - couple of strategies it told me were to "Seek Support from Others" and "Participating in discussions or groups focused on ethical AI". *</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenFarm – a free and open database and web application for gardening knowledge (442 pts)]]></title>
            <link>https://openfarm.cc</link>
            <guid>37125830</guid>
            <pubDate>Mon, 14 Aug 2023 19:42:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openfarm.cc">https://openfarm.cc</a>, See on <a href="https://news.ycombinator.com/item?id=37125830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      

      
<div id="how-it-works">
        
        
        <h2>
            Growing Guides show you how to care for your Crop during all
of its Life Stages. Each Guide is based on specific environmental
conditions and growing practices, and ranked for compatibility
with you and your gardens.

        </h2>
        <ul>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
        </ul>
    </div>

<div>
            <h2>Grow Your Food</h2>
            <h2>Farm and garden through knowledge sharing</h2>
            </div>



<div>
    <p id="community-favorites">
        <h2>Community Favorites</h2>
    </p>
    

</div>

      <!-- Necessary for sticky footer -->
      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study shows dementia more common in older adults with vision issues (134 pts)]]></title>
            <link>https://www.michiganmedicine.org/health-lab/study-shows-dementia-more-common-older-adults-vision-issues</link>
            <guid>37125458</guid>
            <pubDate>Mon, 14 Aug 2023 19:13:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.michiganmedicine.org/health-lab/study-shows-dementia-more-common-older-adults-vision-issues">https://www.michiganmedicine.org/health-lab/study-shows-dementia-more-common-older-adults-vision-issues</a>, See on <a href="https://news.ycombinator.com/item?id=37125458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span><span>Losing the ability to see clearly, and losing the ability to think or remember clearly, are two of the most dreaded, and preventable, health issues associated with getting older. </span></span></span></span></p>

<p><span><span><span><span>Now, a new study lends further weight to the idea that vision problems and dementia are linked.&nbsp; </span></span></span></span></p>

<p><span><span><span><span>In a sample of nearly 3,000 older adults who took vision tests and cognitive tests during home visits, the </span></span><a href="https://jamanetwork.com/journals/jamaophthalmology/fullarticle/10.1001/jamaophthalmol.2023.2854?guestAccessKey=35220a9e-e304-4ca1-a14e-c221ea092c34&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=071323"><span><span>risk of dementia was much higher among those with eyesight problems</span></span></a><span><span> – including those who weren’t able to see well even when they were wearing their usual eyeglasses or contact lenses. </span></span></span></span></p>

<p><span><span><span><span>The research was published recently in <em>JAMA Ophthalmology</em> by a team from the </span></span><a href="https://www.umkelloggeye.org/"><span><span>Kellogg Eye Center at Michigan Medicine</span></span></a><span><span>, the University of Michigan’s academic medical center. </span></span></span></span></p>

<p><span><span><span><span>Based on data from a nationally representative study of older adults conducted in 2021 through the </span></span><a href="https://isr.umich.edu/"><span><span>U-M Institute for Social Research</span></span></a><span><span>, it adds to a growing pile of studies that have suggested a link between vision and dementia. </span></span></span></span></p>

<p><span><span><strong><em><span><span><a href="https://www.michiganmedicine.org/health-lab/many-older-adults-lack-clear-eyesight-even-glasses#:~:text=New%20research%20shows%20that%2028,lenses%2C%20or%20other%20visual%20aids.">SEE ALSO: Many older adults lack clear eyesight, even with glasses</a></span></span></em></strong></span></span></p>

<p><span><span><span><span>All of the older adults in the study were over the age of 71, with an average age of 77. They had their up-close and distance vision, and their ability to see letters that didn’t contrast strongly with their background, tested by a visiting team member using a digital tablet. They also took tests of memory and thinking ability, and provided health information including any existing diagnosis of Alzheimer’s disease or another form of dementia.</span></span></span></span></p>

<p><span><span><span><span><span>Just over 12% of the whole group had dementia. But that percentage was higher – nearly 22% -- among those who had impaired vision for seeing up close.</span></span></span></span></span></p>

<p><span><span><span><span><span>In addition, one-third (33%) of those with moderate or severe distance vision impairment, including those who were blind, had signs of dementia. So did 26% of those who had trouble seeing letters that didn’t contrast strongly against a background</span></span></span></span></span></p>

<p><span><span><span><span><span>Even among those with a mild distance vision issue, 19% had dementia.</span></span></span></span></span></p>

<p><span><span><span><span><span>After the researchers adjusted for other differences in health status and personal characteristics, people with moderate to severe distance vision issues were 72% more likely than those with no vision issues to have dementia. </span></span></span></span></span></p>

<p><span><span><span><span><span>The gaps were smaller, but still large, for other types of vision impairment&nbsp;</span></span></span>– <span><span><span> except mild problems with distance vision, where there was no statistical difference.</span></span></span></span></span></p>

<p><span><span><span><span><span>Those who had more than one kind of vision impairment were also 35% more likely to have dementia than those with normal vision.</span></span></span></span></span></p>

<p><span><span><span><span><span>The study b</span></span></span><span><span>uilds on previous studies that had similar findings but relied on self-reported vision abilities rather than objective testing, or that were not representative of the United States population. </span></span></span></span></p>

<p><span><span><strong><em><span><span><a href="https://www.michiganmedicine.org/health-lab/vision-impairment-associated-mortality">SEE ALSO: Vision Impairment is Associated with Mortality</a></span></span></em></strong></span></span></p>

<p><span><span><span><span>It also builds on previous work about cataract surgery that showed lower rates of dementia over time in adults who had had their distance vision restored by having surgery. </span></span></span></span></p>

<p><span><span><span><span>The authors, led by ophthalmologists Olivia Killeen, M.D., M.S. and Joshua Ehrlich, M.D., M.P.H., write, “</span></span><span><span><span>Prioritizing vision health may be key to optimizing both sight and overall health and well-being.</span></span></span> <span><span><span>Randomized trials are warranted to determine whether optimizing vision is a viable strategy to slow cognitive decline and reduce dementia risk.”</span></span></span></span></span></p>

<p><span><span><span><span>But in the meantime, in an </span></span><a href="https://jamanetwork-com.proxy.lib.umich.edu/article.aspx?doi=10.1001/jamaophthalmol.2023.3008"><span><span>accompanying editorial</span></span></a><span><span>, Sheila West, Ph.D., of the Wilmer Eye Institute at Johns Hopkins Medicine, wrote that the new study adds to accumulating evidence about the link between vision and cognitive issues. </span></span></span></span></p>

<p><span><span><span><span>“Equitable access to vision care services that prevent, reverse, or at least stave off progression of loss of sight is a worthy goal regardless of the potential impact on dementia and may be especially critical for those experiencing cognitive decline,” she wrote.</span></span></span></span></p>

<p><span><span><span><span>The study is based on data from </span></span><a href="https://www.nhats.org/"><span><span>the National Health and Aging Trends Study</span></span></a><span><span>, which is based at the U-M Institute for Social Research and the Johns Hopkins University Bloomberg School of Public Health.&nbsp; </span></span></span></span></p>

<p><span><span><strong><em><span><span><a href="https://www.michiganmedicine.org/health-lab/early-signs-alzheimers-most-older-adults-see-value-screening-havent-been-tested">SEE ALSO: Early signs of Alzheimer’s: Most older adults see the value of screening but haven’t been tested</a></span></span></em></strong></span></span></p>

<p><span><span><span><span>Last year, Ehrlich and colleagues </span></span><a href="https://jamanetwork.com/journals/jamaneurology/article-abstract/2791268"><span><span>published a paper in JAMA Neurology</span></span></a><span><span> that used another ISR-based survey of older adults – the Health and Retirement Study – to estimate the percentage of Americans with dementia whose condition is likely related to their vision loss. They calculated that 1.8 percent of all cases are vision-related, equating to more than 100,000 of the 6 million Americans with dementia. This study suggested that vision impairment should be considered alongside other more commonly recognized modifiable dementia risk factors. That study was funded by the </span></span><span><span>U-M Center to Accelerate Population Research in Alzheimer's through funding from the National Institute on Aging. </span></span></span></span></p>

<p><span><span><span><span>Killeen recently completed the </span></span><a href="https://ihpi.umich.edu/education-training/NCSP"><span><span>National Clinician Scholars Program</span></span></a><span><span> at the U-M Institute for Healthcare Policy and Innovation and is now at Duke University. Ehrlich is an assistant professor of Ophthalmology and Visual Sciences at Michigan Medicine and a research assistant professor at ISR, where he is a co-investigator of NHATS, as well as a member of IHPI.</span></span></span></span></p>

<p><span><span><span><span>The study’s authors also include Yunshu Zhou, M.S.</span></span></span></span></p>

<p><span><span><span><span>In addition to the National Institute on Aging grant that supports NHATS, and the U-M funding that supports the National Clinician Scholars Program, the study was funded by an unrestricted grant to the U-M Department of Ophthalmology and Visual Sciences by Research to Prevent Blindness</span></span></span></span></p>

<p><span><span><strong><span><span>Paper cited:</span></span></strong><span><span> “Objectively Measured Visual Impairment and Dementia Prevalence in Older Adults,” <em>JAMA Ophthalmology</em>. </span></span><a href="https://jamanetwork.com/journals/jamaophthalmology/fullarticle/10.1001/jamaophthalmol.2023.2854?guestAccessKey=35220a9e-e304-4ca1-a14e-c221ea092c34&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=071323"><span><span>DOI:10.1001/jamaophthalmol.2023.2854</span></span></a></span></span></p></div></div>]]></description>
        </item>
    </channel>
</rss>