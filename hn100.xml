<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 02 Jan 2024 18:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A Canadian payroll dependency chart (150 pts)]]></title>
            <link>https://www.daemonology.net/blog/2023-12-31-Canadian-payroll-dependency-chart.html</link>
            <guid>38843388</guid>
            <pubDate>Tue, 02 Jan 2024 16:26:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.daemonology.net/blog/2023-12-31-Canadian-payroll-dependency-chart.html">https://www.daemonology.net/blog/2023-12-31-Canadian-payroll-dependency-chart.html</a>, See on <a href="https://news.ycombinator.com/item?id=38843388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>
The Canada Revenue Agency publishes, on a regular basis (they're now up to
the 119th edition), a document entitled
<a href="https://www.canada.ca/en/revenue-agency/services/forms-publications/payroll/t4127-payroll-deductions-formulas/t4127-jan/t4127-jan-payroll-deductions-formulas-computer-programs.html">"Payroll
Deductions Formulas"</a>.  This document contains all of the formulas needed
to calculate payroll deductions collected by the CRA: Canada Pension Plan,
Employment Insurance, and Income Tax.  As someone running a
<a href="https://www.tarsnap.com/">small business in Canada</a> and not wanting
to use an external payroll provider, I implement these formulas myself in a
spreadsheet.
</p><p>
Unfortunately, like most aspects of the tax system, this steadily increases
in complexity, and this year with the Canada Pension Plan including not just
"base" premiums and "additional" premiums but also "second additional
premiums", I needed to rewrite my spreadsheet from scratch; and also very
unfortunately, the authors of the document have failed to grasp an essential
detail of software: You have to calculate values before you use them.  This
results in a document requiring constant jumping back and forth to find
where each value is calculated — before <i>or after</i> it is used.
</p><p>
To help myself keep everything straight, I decided to draw a dependency chart
using GraphViz.  There are 79 nodes in the graph, starting with values like
"Year's Annual Maximum Pensionable Earnings" ($73200 in the 2024 tax year),
and ending up with "Total payroll deductions".  Note that I did not write the
formulas onto the chart — I simply recorded which other values they
depend upon, so someone (aka myself) looking at the chart can figure out
what to calculate first without going around in circles.
</p><p>
Oh, and to keep things simple, I assumed I wasn't dealing with commissioned
employees, employees entering or exiting the Canada Pension Plan, or anyone
resident in Quebec, Nova Scotia, Yukon, or Ontario (each of which has their
own special tax complications).
</p><p>
Here's what it looks like; click for a full size version (warning, 5627x2033
image):
<br>
<a href="https://www.daemonology.net/blog/payroll.png"><img src="https://www.daemonology.net/blog/payroll-small.png"></a> 
</p>



<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan Goes All In: Copyright Doesn't Apply to AI Training (155 pts)]]></title>
            <link>https://www.biia.com/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/</link>
            <guid>38842788</guid>
            <pubDate>Tue, 02 Jan 2024 15:47:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biia.com/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/">https://www.biia.com/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/</a>, See on <a href="https://news.ycombinator.com/item?id=38842788">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-106014">
														
							
														
							
														
							<div>
									<p><span>In a surprising move, Japan’s government recently reaffirmed that it will not enforce copyrights on data used in AI training. The policy allows AI to use any data <a href="https://www.biia.com/wp-content/uploads/2023/06/Keiko_Nagaoka_20151102_cropped-600x800-1-e1687193572247.jpg"><img decoding="async" src="https://www.biia.com/wp-content/uploads/2023/06/Keiko_Nagaoka_20151102_cropped-600x800-1-225x300.jpg" alt="" width="165" height="220" data-src="https://www.biia.com/wp-content/uploads/2023/06/Keiko_Nagaoka_20151102_cropped-600x800-1-225x300.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>“regardless of whether it is for non-profit or commercial purposes, whether it is an act other than reproduction, or whether it is content obtained from illegal sites or otherwise.” <strong>Keiko Nagaoka, Japanese Minister of Education, Culture, Sports, Science, and Technology</strong>,&nbsp;<a href="https://go2senkyo.com/seijika/122181/posts/685617" target="_blank" rel="noreferrer noopener">confirmed</a>&nbsp;the bold stance to local meeting, saying that Japan’s laws won’t protect copyrighted materials used in AI datasets.</span></p>

<p><span>English language coverage of the situation is sparse. It seems the Japanese government believes copyright worries, particularly those linked to anime and other visual media, have held back the nation’s progress in AI technology. In response, Japan is going all-in, opting for a no-copyright approach to remain competitive.</span></p>
<p><span>This news is part of Japan’s ambitious plan to become a leader in AI technology. Rapidus, a local tech firm known for its advanced 2nm chip technology, is stepping into the spotlight as a serious contender in the world of AI chips. With Taiwan’s political situation looking unstable, Japanese chip manufacturing could be a safer bet. Japan is also stepping up to help shape the global rules for AI systems within the G-7.</span></p>
<h2><span>Artists vs. Business (Artists Lost)</span></h2>
<p><span>Not everyone in Japan is on board with this decision. Many anime and graphic art creators are concerned that AI could lower the value of their work. But in contrast, the academic and business sectors are pressing the government to use the nation’s relaxed data laws to propel Japan to global AI dominance.</span></p>
<p><span>Despite having the world’s third-largest economy, Japan’s economic growth has been sluggish since the 1990s. Japan has the lowest per-capita income in the G-7. With the effective implementation of AI, it could potentially boost the nation’s GDP by 50% or more in a short time. For Japan, which has been experiencing years of low growth, this is an exciting prospect.</span></p>
<h2><span>It’s All About The Data</span></h2>
<p><span>Western data access is also key to Japan’s AI ambitions. The more high-quality training data available, the better the AI model. While Japan boasts a long-standing literary tradition, the amount of Japanese language training data is significantly less than the English language resources available in the West. However, Japan is home to a wealth of anime content, which is popular globally. It seems Japan’s stance is clear – if the West uses Japanese culture for AI training, Western literary resources should also be available for Japanese AI.</span></p>
<h2><span>What This Means For The World</span></h2>
<p><span><strong>On a global scale, Japan’s move adds a twist to the regulation debate</strong>. Current discussions have focused on a “rogue nation” scenario where a less developed country might disregard a global framework to gain an advantage. But with Japan, we see a different dynamic. <strong>The world’s third-largest economy is saying it won’t hinder AI research and development. Plus, it’s prepared to leverage this new technology to compete directly with the West</strong>.</span></p>
<p><em><strong><span>Source: <a href="https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/">Technomancers.ai</a></span></strong></em></p>
																	</div>
														

																				</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A New Blog for 2024 (105 pts)]]></title>
            <link>https://chrisnicholas.dev/blog/a-new-blog-for-2024</link>
            <guid>38842116</guid>
            <pubDate>Tue, 02 Jan 2024 14:46:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrisnicholas.dev/blog/a-new-blog-for-2024">https://chrisnicholas.dev/blog/a-new-blog-for-2024</a>, See on <a href="https://news.ycombinator.com/item?id=38842116">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>It’s been a <em>long time</em> since I’ve published a blog post, two whole years. Part of the reason is that it took too much effort to create posts for my previous blog. I needed better DX. A few nights ago, feeling inspired after reading articles by <a target="_blank" rel="noreferrer nofollow noopener" href="https://ped.ro/writing/website-refresh-2023" data-headlessui-state="">Pedro Duarte</a>, <a target="_blank" rel="noreferrer nofollow noopener" href="https://rauno.me/craft/vercel" data-headlessui-state="">Rauno Freiberg</a>, and <a target="_blank" rel="noreferrer nofollow noopener" href="https://leerob.io/blog/2023" data-headlessui-state="">Lee Robinson</a>, I decided it was time to start over.</p>

<p>So here’s the score—I want a blog with great DX that makes it as easy as possible to create posts. I also want to go <em>minimal</em>, so I can get away with a single design on mobile and desktop. No faffing around; I want this blog built and published in 5 days! And lastly, I’m looking to try some new libraries and technologies. Right, let’s dive in.</p>

<p>At work I spend most of my time <a data-headlessui-state="" href="https://chrisnicholas.dev/work">writing and programming</a>, so dipping my toes into design was a nice change. Here’s a couple of details.</p>

<p>For the header, I was aiming for an animated background that combined an <em>aurora</em>, <em>light beams</em>, and a <em>rainbow</em>. I’m quite pleased with the result, and it's actually pure CSS—try changing <code><span><span>hue</span><span>-</span><span>rotate</span></span></code> below to emulate the animation.</p>
<figure><figcaption>An interactive demo showing the header background</figcaption><pre><code>.aurora <!-- -->{<br>  <!-- -->filter:<!-- --> <span>hue-rotate(<!-- -->0<!-- -->deg)</span> <span>saturate(<!-- -->7.0<!-- -->)</span> <span>blur(<!-- -->30<!-- -->px)</span>;<br>}</code></pre><div><p><label for="change-aurora-hue"><code>hue-rotate</code></label><label for="change-aurora-saturate"><code>saturate</code></label><label for="change-aurora-blur"><code>blur</code></label></p></div></figure>
<h3 id="saturated-text"><a href="#saturated-text">Saturated text</a></h3>
<p>All text that overlays the aurora is saturated with its underlying colours—a tiny touch that really unifies the design. You can do this by simply applying a <code><span><span>luminosity</span></span></code> <a target="_blank" rel="noreferrer nofollow noopener" href="https://www.ctnicholas.dev/articles/which-blend-mode" data-headlessui-state="">blend mode</a> to the text.</p>
<figure><div><p>My name’s Chris Nicholas</p></div><div data-slot="field" data-headlessui-state=""><p><span data-slot="control" id="headlessui-control-:R8lmuuuela:" role="checkbox" aria-checked="true" tabindex="0" data-headlessui-state="checked" data-checked=""><span><svg viewBox="0 0 14 14" fill="none"><path d="M3 8L6 11L11 3.5" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 7H11" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></span><label data-slot="label" id="headlessui-label-:R9olmuuuela:" for="headlessui-control-:R8lmuuuela:" data-headlessui-state=""><code>mix-blend-mode: luminosity;</code></label></p></div></figure>
<h3 id="noise"><a href="#noise">Noise</a></h3>
<p>I’m applying a tiny amount of film grain to the <code><span><span>body</span></span></code>. To me, this makes the page feel like one consistent piece; as you scroll down, the noise sticks to the content, somewhat similar to seeing texture on paper.</p>
<figure><figcaption>An interactive demo allowing you to change the noise level on the page</figcaption><pre><code>.noise <!-- -->{<br>  <!-- -->opacity:<!-- --> <span>0.018</span>;<br>}</code></pre><p><label for="change-noise-opacity"><code>opacity</code></label></p></figure>
<p>I wouldn’t recommend noise for most websites, and it’s very easy to overdo it, but I enjoy the subtle filmic effect on my blog.</p>
<h3 id="catalyst"><a href="#catalyst">Catalyst</a></h3>
<p>I’m using <a target="_blank" rel="noreferrer nofollow noopener" href="https://tailwindcss.com/blog/introducing-catalyst" data-headlessui-state="">Catalyst</a>, a new UI kit by the Tailwind team. It’s clear that a tonne of thought has gone into making these components accessible, and pixel perfect, on both light and dark modes.</p>
<figure><figcaption>Tailwind UI Catalyst demo</figcaption><div><p><span>badge</span><span data-slot="control" aria-label="Example checkbox" id="headlessui-checkbox-:R2p3muuuela:" role="checkbox" aria-checked="true" tabindex="0" data-headlessui-state="checked" data-checked=""><span><svg viewBox="0 0 14 14" fill="none"><path d="M3 8L6 11L11 3.5" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 7H11" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></span></p></div></figure>
<p>Catalyst provides you with a set of files to download into your project, and you can export your components from these. <a target="_blank" rel="noreferrer nofollow noopener" href="https://heroicons.com/" data-headlessui-state="">Heroicons</a> has also been updated with new icons that fit neatly into Catalyst.</p>

<pre><code><span><span>import</span><span> </span><span>{</span><span> </span><span>Button</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>../components/Button</span><span>"</span><span>;</span><span></span></span>
<span><span>import</span><span> </span><span>{</span><span> </span><span>PaperAirplaneIcon</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@heroicons/react/16/solid</span><span>"</span><span>;</span><span></span></span>
<span><span>	</span><span></span></span>
<span><span>function</span><span> </span><span>Component</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></span>
<span><span>  </span><span>return</span><span> </span><span>(</span><span></span></span>
<span><span>    </span><span>&lt;</span><span>Button</span><span> </span><span>type</span><span>=</span><span>"</span><span>submit</span><span>"</span><span> </span><span>color</span><span>=</span><span>"</span><span>rose</span><span>"</span><span>&gt;</span><span></span></span>
<span><span></span><span>      </span><span>&lt;</span><span>PaperAirplaneIcon</span><span> </span><span>/&gt;</span><span></span></span>
<span><span></span><span>      Send message</span><span></span></span>
<span><span></span><span>    </span><span>&lt;/</span><span>Button</span><span>&gt;</span><span></span></span>
<span><span>  </span><span>)</span><span>;</span><span></span></span>
<span><span>}</span></span></code></pre>
<p>If you’d like to customise your components further, you can edit the downloaded files directly. Each file contains <a target="_blank" rel="noreferrer nofollow noopener" href="https://headlessui.com/" data-headlessui-state="">Headless UI</a> components with lists of carefully annotated classes dispersed throughout.</p>
<pre><code><span><span>&lt;</span><span>HeadlessListBoxButton</span><span></span></span>
<span><span>  </span><span>className</span><span>=</span><span>{</span><span>clsx</span><span>(</span><span></span></span>
<span><span>    </span><span>// Basic layout</span></span>
<span><span></span><span>    </span><span>"</span><span>group relative block w-full</span><span>"</span><span>,</span><span></span></span>
<span><span></span></span>
<span><span>    </span><span>// Focus ring</span></span>
<span><span></span><span>    </span><span>"</span><span>after:pointer-events-none after:absolute ...</span><span>"</span><span>,</span><span></span></span>
<span><span></span></span>
<span><span>    </span><span>// Disabled state</span></span>
<span><span></span><span>    </span><span>"</span><span>data-[disabled]:opacity-50 before:data-[d... </span><span>"</span><span></span></span>
<span><span>  </span><span>)</span><span>}</span><span></span></span>
<span><span>  </span><span>.</span><span>.</span><span>.</span><span></span></span>
<span><span>/&gt;</span><span></span></span></code></pre>
<p>Catalyst is still in alpha, so be warned, breaking changes will most likely be ahead!</p>
<h3 id="twc"><a href="#twc">TWC</a></h3>
<p>While we’re talking about Tailwind, I’ve used a new library called <a target="_blank" rel="noreferrer nofollow noopener" href="https://react-twc.vercel.app/" data-headlessui-state="">TWC</a> to save time building reusable components. It takes boilerplate code you've written countless times (forwarding refs, adding <code><span><span>clsx</span></span></code>, etc.), and makes it a one-liner.</p>
<pre><code><span><span>const</span><span> </span><span>Card</span><span> </span><span>=</span><span> </span><span>twc</span><span>.</span><span>div</span><span>`</span><span>rounded-lg border bg-slate-100 text-white shadow-sm</span><span>`</span><span>;</span><span></span></span>
<span><span></span></span>
<span><span>&lt;</span><span>Card</span><span> </span><span>ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span> </span><span>className</span><span>=</span><span>{</span><span>[</span><span>"</span><span>my-6</span><span>"</span><span>,</span><span> </span><span>hidden</span><span> </span><span>&amp;</span><span>&amp;</span><span> </span><span>"</span><span>hidden</span><span>"</span><span>]</span><span>}</span><span> </span><span>{</span><span>.</span><span>.</span><span>.</span><span>props</span><span>}</span><span> </span><span>/&gt;</span><span>;</span><span></span></span></code></pre>

<h3 id="nextjs"><a href="#nextjs">Next.js</a></h3>
<p>I’ve used <a target="_blank" rel="noreferrer nofollow noopener" href="https://nextjs.org/" data-headlessui-state="">Next.js</a> to build my new blog, and virtually every component is a server component. It feels pretty snappy, I like it.</p>
<h4>Layout files</h4>
<p>Did you notice that the header animation continues running when you change pages? That’s because it’s placed in a Next.js <a target="_blank" rel="noreferrer nofollow noopener" href="https://nextjs.org/docs/pages/building-your-application/routing/pages-and-layouts#layout-pattern" data-headlessui-state="">layout file</a>, meaning it doesn’t get refreshed on route changes.</p>
<figure><video src="https://chrisnicholas.dev/blog/a-new-blog-for-2024/header-animation.mp4" muted="" autoplay="" loop="" playsinline=""></video><figcaption>Header animation when changing pages</figcaption></figure>
<pre><code><span><span>// layout.tsx</span></span>
<span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>function</span><span> </span><span>Layout</span><span>(</span><span>{</span><span> </span><span>children</span><span> </span><span>}</span><span>)</span><span> </span><span>{</span><span></span></span>
<span><span>  </span><span>return</span><span> </span><span>(</span><span></span></span>
<span><span>    </span><span>&lt;</span><span>&gt;</span><span></span></span>
<span><span>      </span><span>&lt;</span><span>HeaderAnimation</span><span> </span><span>/&gt;</span><span></span></span>
<span><span>      </span><span>&lt;</span><span>main</span><span>&gt;</span><span>{</span><span>children</span><span>}</span><span>&lt;/</span><span>main</span><span>&gt;</span><span></span></span>
<span><span>    </span><span>&lt;/</span><span>&gt;</span><span></span></span>
<span><span>  </span><span>)</span><span>;</span><span></span></span>
<span><span>}</span></span></code></pre>
<h4>OG image generation</h4>
<p>A major pain point on my previous blog was manually creating each social media image. Nowadays, you can <a target="_blank" rel="noreferrer nofollow noopener" href="https://nextjs.org/docs/app/api-reference/file-conventions/metadata/opengraph-image" data-headlessui-state="">generate OpenGraph images dynamically</a> in Next.js, and it’s very little effort to get started.</p>
<p><img alt="Open graph image for this article" loading="lazy" width="628" height="330" decoding="async" data-nimg="1" srcset="https://chrisnicholas.dev/_next/image?url=%2Fblog%2Fa-new-blog-for-2024%2Fopengraph-image&amp;w=640&amp;q=75 1x, https://chrisnicholas.dev/_next/image?url=%2Fblog%2Fa-new-blog-for-2024%2Fopengraph-image&amp;w=1920&amp;q=75 2x" src="https://chrisnicholas.dev/_next/image?url=%2Fblog%2Fa-new-blog-for-2024%2Fopengraph-image&amp;w=1920&amp;q=75"></p>
<pre><code><span><span>// /blog/[slug]/opengraph-image.tsx</span></span>
<span><span></span><span>export</span><span> </span><span>const</span><span> </span><span>runtime</span><span> </span><span>=</span><span> </span><span>"</span><span>edge</span><span>"</span><span>;</span><span></span></span>
<span><span>export</span><span> </span><span>const</span><span> </span><span>alt</span><span> </span><span>=</span><span> </span><span>"</span><span>...</span><span>"</span><span>;</span><span></span></span>
<span><span>export</span><span> </span><span>const</span><span> </span><span>size</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>width</span><span>:</span><span> </span><span>1200</span><span>,</span><span> </span><span>height</span><span>:</span><span> </span><span>630</span><span> </span><span>}</span><span>;</span><span></span></span>
<span><span>	</span><span></span></span>
<span><span>export</span><span> </span><span>default</span><span> </span><span>async</span><span> </span><span>function</span><span> </span><span>Image</span><span>(</span><span>{</span><span> </span><span>params</span><span> </span><span>}</span><span>)</span><span> </span><span>{</span><span></span></span>
<span><span>  </span><span>return</span><span> </span><span>new</span><span> </span><span>ImageResponse</span><span>(</span><span>(</span><span></span></span>
<span><span>    </span><span>&lt;</span><span>div</span><span> </span><span>style</span><span>=</span><span>{</span><span>{</span><span> </span><span>display</span><span>:</span><span> </span><span>"</span><span>flex</span><span>"</span><span>,</span><span> </span><span>color</span><span>:</span><span> </span><span>"</span><span>#000</span><span>"</span><span> </span><span>}</span><span>}</span><span>&gt;</span><span></span></span>
<span><span></span><span>      </span><span>&lt;</span><span>div</span><span>&gt;</span><span>A new blog for 2024</span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></span>
<span><span>      </span><span>.</span><span>.</span><span>.</span><span></span></span>
<span><span>    </span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></span>
<span><span>  </span><span>)</span><span>,</span><span> </span><span>{</span><span> </span><span>.</span><span>.</span><span>.</span><span>size</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></span>
<span><span>}</span></span></code></pre>
<h3 id="contentlayer"><a href="#contentlayer">Contentlayer</a></h3>
<p>My blog uses <code><span><span>.</span><span>mdx</span></span></code> files with custom React components interspersed throughout. I’d heard a lot of good things about <a target="_blank" rel="noreferrer nofollow noopener" href="https://contentlayer.dev/" data-headlessui-state="">Contentlayer</a>, so I gave it a try—it’s been a breeze to use, and has really sped up my development time. It’s so easy to make changes to your schema, and the type-safe setup is excellent.</p>
<h4>How it works</h4>
<p>You can generate a <code><span><span>Post</span></span></code> schema, for example with a <code><span><span>title</span></span></code> and <code><span><span>date</span></span></code>, and then ask it to load files from the <code><span><span>/</span><span>posts</span></span></code> folder.</p>
<pre><code><span><span>export</span><span> </span><span>const</span><span> </span><span>Post</span><span> </span><span>=</span><span> </span><span>defineDocumentType</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>(</span><span>{</span><span></span></span>
<span><span>  </span><span>name</span><span>:</span><span> </span><span>"</span><span>Post</span><span>"</span><span>,</span><span></span></span>
<span><span>  </span><span>filePathPattern</span><span>:</span><span> </span><span>`</span><span>/posts/**/*.mdx</span><span>`</span><span>,</span><span></span></span>
<span><span>  </span><span>contentType</span><span>:</span><span> </span><span>"</span><span>mdx</span><span>"</span><span>,</span><span></span></span>
<span><span>  </span><span>fields</span><span>:</span><span> </span><span>{</span><span></span></span>
<span><span>    </span><span>title</span><span>:</span><span> </span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>"</span><span>string</span><span>"</span><span>,</span><span> </span><span>required</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>,</span><span></span></span>
<span><span>    </span><span>date</span><span>:</span><span> </span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>"</span><span>date</span><span>"</span><span>,</span><span> </span><span>required</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>,</span><span></span></span>
<span><span>  </span><span>}</span><span>,</span><span></span></span>
<span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></span></code></pre>
<p>Next, create your <code><span><span>.</span><span>mdx</span></span></code> file in <code><span><span>/</span><span>posts</span></span></code>.</p>
<pre><code>---
title: A new blog for 2024
date: 2024-01-02
---

It’s been a _long_ time since I’ve publis…</code></pre>
<p>Then simply import your posts, with full type-safety, and render your <code><span><span>mdx</span></span></code> content.</p>
<pre><code><span><span>import</span><span> </span><span>{</span><span> </span><span>allPosts</span><span>,</span><span> </span><span>Post</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>contentlayer/generated</span><span>"</span><span>;</span><span></span></span>
<span><span>import</span><span> </span><span>{</span><span> </span><span>useMDXComponent</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>next-contentlayer/hooks</span><span>"</span><span>;</span><span></span></span>
<span><span></span></span>
<span><span>// { title: "A new blog for 2024", ... }</span></span>
<span><span></span><span>const</span><span> </span><span>post</span><span>:</span><span> </span><span>Post</span><span> </span><span>=</span><span> </span><span>allPosts</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></span>
<span><span></span></span>
<span><span>// &lt;p&gt;It’s been a &lt;em&gt;long time&lt;/em&gt; since I’ve publis…</span></span>
<span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>function</span><span> </span><span>Page</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></span>
<span><span>  </span><span>const</span><span> </span><span>MDXContent</span><span> </span><span>=</span><span> </span><span>useMDXComponent</span><span>(</span><span>post</span><span>.</span><span>body</span><span>.</span><span>code</span><span>)</span><span>;</span><span></span></span>
<span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>MDXContent</span><span> </span><span>/&gt;</span><span>;</span><span></span></span>
<span><span>}</span><span></span></span></code></pre>
<h2 id="archived-posts"><a href="#archived-posts">Archived posts</a></h2>
<p>I’ve archived all the posts from my previous blog, <em>ctnicholas.dev</em>, as it’d take too long to transfer them to the new site, though they’re all still <a data-headlessui-state="" href="https://chrisnicholas.dev/blog">available to read</a>.</p>
<p><img alt="A screenshot of my bold blog" loading="lazy" width="628" height="327" decoding="async" data-nimg="1" srcset="https://chrisnicholas.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fold-articles.69315554.png&amp;w=640&amp;q=75 1x, https://chrisnicholas.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fold-articles.69315554.png&amp;w=1920&amp;q=75 2x" src="https://chrisnicholas.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fold-articles.69315554.png&amp;w=1920&amp;q=75"></p>

<p>My blog’s a work in progress, and there's so much more I’d like to add, for example:</p>
<ul>
<li>Code snippets with more features, languages, and <a target="_blank" rel="noreferrer nofollow noopener" href="https://www.ctnicholas.dev/articles/how-to-use-sandpack-for-code-demos" data-headlessui-state="">interactivity</a>.</li>
<li><a target="_blank" rel="noreferrer nofollow noopener" href="https://liveblocks.io/comments" data-headlessui-state="">Real-time comments</a> and <a target="_blank" rel="noreferrer nofollow noopener" href="https://liveblocks.io/presence" data-headlessui-state="">multiplayer presence</a>.</li>
<li>Dynamic content that streams in with <a target="_blank" rel="noreferrer nofollow noopener" href="https://vercel.com/blog/partial-prerendering-with-next-js-creating-a-new-default-rendering-model" data-headlessui-state="">partial prerendering</a>.</li>
</ul>
<p>But it’s all too easy to get stuck in the “just one more feature…” loop, when the most important thing is to get shipping! So here it is—thanks for reading.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After 34 Years, Someone Beat Tetris [video] (149 pts)]]></title>
            <link>https://www.youtube.com/watch?v=GuJ5UuknsHU</link>
            <guid>38841080</guid>
            <pubDate>Tue, 02 Jan 2024 12:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=GuJ5UuknsHU">https://www.youtube.com/watch?v=GuJ5UuknsHU</a>, See on <a href="https://news.ycombinator.com/item?id=38841080">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs and Programming in the first days of 2024 (343 pts)]]></title>
            <link>http://antirez.com/news/140</link>
            <guid>38840626</guid>
            <pubDate>Tue, 02 Jan 2024 11:43:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://antirez.com/news/140">http://antirez.com/news/140</a>, See on <a href="https://news.ycombinator.com/item?id=38840626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="140-" id="140-"><span><span><a href="http://antirez.com/user/antirez">antirez</a></span> 3 hours ago. 20882 views.  </span><pre>I'll start by saying that this article is not meant to be a retrospective on LLMs. It's clear that 2023 was a special year for artificial intelligence: to reiterate that seems rather pointless. Instead, this post aims to be a testimony from an individual programmer. Since the advent of ChatGPT, and later by using LLMs that operate locally, I have made extensive use of this new technology. The goal is to accelerate my ability to write code, but that's not the only purpose. There's also the intent to not waste mental energy on aspects of programming that are not worth the effort. Countless hours spent searching for documentation on peculiar, intellectually uninteresting aspects; the efforts to learn an overly complicated API, often without good reason; writing immediately usable programs that I would discard after a few hours. These are all things I do not want to do, especially now, with Google having become a sea of spam in which to hunt for a few useful things.

Meanwhile, I am certainly not a novice in programming. I am capable of writing code without any aid, and indeed, I do so quite often. Over time, I have increasingly used LLMs to write high-level code, especially in Python, and much less so in C. What strikes me about my personal experience with LLMs is that I have learned precisely when to use them and when their use would only slow me down. I have also learned that LLMs are a bit like Wikipedia and all the video courses scattered on YouTube: they help those with the will, ability, and discipline, but they are of marginal benefit to those who have fallen behind. I fear that at least initially, they will only benefit those who already have an advantage.

But let's take it step by step.

# Omniscient or Parrots?

One of the most concerning phenomena of this new wave of novelty and progress in machine learning is the limited ability of AI experts to accept their limited knowledge. Homo sapiens invented neural networks, and then, even more crucially, an algorithm to automatically optimize the parameters of a neural network. Hardware has become capable of training increasingly larger models, and using statistical knowledge about the data to be processed (the priors) and through a lot of trial and error for successive approximations, architectures have been discovered that work better than others. But all in all, neural networks remain quite opaque.

In the face of this inability to explain certain emerging capabilities of LLMs, one would have expected more caution from scientists. Instead, many have deeply underestimated LLMs, saying that after all they were nothing more than somewhat advanced Markov chains, capable, at most, of regurgitating extremely limited variations of what they had seen in the training set. Then this notion of the parrot, in the face of evidence, was almost universally retracted.

At the same time, much of the enthusiastic masses attributed to LLMs supernatural powers that do not exist in reality. Unfortunately, LLMs can, at most, interpolate in the space represented by the data they have seen during training: and this would already be a lot. In reality, their ability to interpolate is limited (but still astonishing, and also unexpected). Oh, if only the largest LLMs of today could interpolate continuously in the space bounded by all the code they have seen! Even if they would not be able to produce true novelties, they would be able to replace 99% of programmers. The reality is more modest, as it almost always is. An LLM is certainly capable of writing programs that it has not seen in that exact form, showing a certain ability to blend different ideas that appeared in the training set with a certain frequency. It is also clear that this ability has, at the moment, deep limits, and whenever subtle reasoning is required, LLMs fail disastrously. Yet they represent the greatest achievement of AI, from its dawn to today. This seems undeniable.

# Stupid but All-Knowing

It's true: LLMs are capable, at most, of rudimentary reasoning, often inaccurate, many times peppered with hallucinations about non-existent facts. But they have a vast knowledge. In the field of programming, as well as in other fields for which quality data are available, LLMs are like stupid savants who know a lot of things. It would be terrible to do pair programming with such a partner (for me, pair programming is terrible even in the most general terms): they would have nonsensical ideas and we would have to continuously fight to impose our own. But if this erudite fool is at our disposal and answers all the questions asked of them, things change. Current LLMs will not take us beyond the paths of knowledge, but if we want to tackle a topic we do not know well, they can often lift us from our absolute ignorance to the point where we know enough to move forward on our own.

In the field of programming, perhaps their ability would have been of very little interest up to twenty or thirty years ago. Back then you had to know a couple of programming languages, the classic algorithms, and those ten fundamental libraries. The rest you had to add yourself, your own intelligence, expertise, design skills. If you had these ingredients you were an expert programmer, able to do more or less everything. Over time, we have witnessed an explosion of frameworks, programming languages, libraries of all kinds. An explosion of complexity often completely unnecessary and unjustified, but the truth is that things are what they are. And in such a context, an idiot who knows everything is a precious ally.

Let me give you an example: my experiments on machine learning were carried forward for at least a year using Keras. Then for various reasons, I switched to PyTorch. I already knew what an embedding or a residual network was, but I didn't feel like studying PyTorch's documentation step by step (as I had done with Keras, which I learned when ChatGPT did not yet exist). With LLMs, it was very easy to write Python code that used Torch. I just needed to have clear ideas about the model I wanted to put together and ask the right questions.

# Time for Examples

I'm not talking about easy things like: "Hey, what's the method of class X to do Y"? If it were just for that, one might be tempted to agree with those who are skeptical about LLMs. What the more complex models are capable of is much more elaborate. Until a few years ago, it would have been pure magic. I can tell GPT4: look, this is the neural network model I have implemented in PyTorch. These are my batches. I would like to resize the tensors so that the function that emits the batches is compatible with the input of the neural network, and I would like to represent things in this particular way. Can you show me the code needed to do the reshaping? GPT4 writes the code, and all I had to do was test in the Python CLI if the tensors really have the dimensions that are useful to me and if the data layout is correct.

Here's another example. Some time ago I had to implement a BLE client for certain ESP32-based devices. After some research, I realized that multi-platform Bluetooth programming bindings are more or less all unusable. The solution was simple, write the code in Objective C using macOS's native API. So, I found myself having to deal with two problems at the same time: learning the cumbersome BLE API of Objective C, full of patterns that I consider nonsensical (I'm a minimalist, that kind of API is at the opposite end of the spectrum of what I consider "good design") and at the same time remembering how to program in Objective C. The last time I had written a program in Objective C was ten years ago: I didn't remember the details of the event loop, memory management, and much more.

The final result is this code here, not exactly beautiful, but it does what it has to do. I wrote it in an extremely short time. It would have been impossible otherwise.

<a rel="nofollow" href="https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m">https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m</a>

The code was written mostly by doing cut &amp; paste on ChatGPT of the things I wanted to do and didn't quite know how to do, so they didn't work properly. Having the LLM explain to me what the problem was and how to solve it. It's true that the LLM didn't write much of that code, but it's also true that it significantly accelerated the writing. Would I have been able to do it without ChatGPT? Certainly yes, but the most interesting thing is not the fact that it would have taken me longer: the truth is that I wouldn't even have tried, because it wouldn't have been worth it. This fact is crucial. The ratio between the effort and the benefit of writing such a program, secondary to my project, would have been inconvenient. Moreover, this had a much more useful secondary collateral effect than the program itself: for that project I modified linenoise (one of my libraries for line editing) so that it works in multiplexing.

Another example, this time less about code writing and more about data interpretation. I wanted to set up a Python script using a convolutional neural network I found online, but it was quite lacking in documentation. The network had the advantage of being in ONNX format, so I could easily extract a list of inputs and outputs, and their assigned names. I only knew one thing about this convnet: it detected certain features within an image. I didn't know the input image format and size, and especially, the network's output was far more complicated than I imagined (I thought it was a binary classifier: is the observed image okay or does it have problems? Two outputs, but there were hundreds). I began by copy-pasting the ONNX network metadata output into ChatGPT. I explain to the assistant what little I know about the network. ChatGPT hypothesizes how the inputs are organized, and that the outputs are probably normalized boxes indicating parts of the images corresponding to potential defects, and other outputs indicating the likelihood of these defects. After a few minutes of back-and-forth, I had a Python script capable of network inference, plus the necessary code to transform the starting image into the tensor suitable for input, and so on. What struck me about that session was ChatGPT finally “understood” how the network functioned once it observed the raw output values (the logits, basically) on a test image: a series of floating-point numbers provided the context to identify the exact output details, the normalization, if the boxes where centred or if the left-top corner was specified, and so forth.

# Disposable Programs

I could document dozens of such cases I've narrated above. It would be pointless, as it's the same story repeating itself in more or less the same way. I have a problem, I need to quickly know something that *I can verify* if the LLM is feeding me nonsense. Well, in such cases, I use the LLM to speed up my need for knowledge.

However, there are different cases where I let the LLM write all the code. For example, whenever I need to write a more or less disposable program. Like this one:

<a rel="nofollow" href="https://github.com/antirez/simple-language-model/blob/main/plot.py">https://github.com/antirez/simple-language-model/blob/main/plot.py</a>

I needed to visualize the loss curve during the learning of a small neural network. I showed GPT4 the format of the CSV file produced by the PyTorch program during learning, and then I requested that if I specified multiple CSV files on the command line, I didn’t want the training and validation loss curves of the same experiment anymore, but a comparison of the validation loss curves of different experiments. The above is the result, as generated by GPT4. Thirty seconds in total.

Similarly, I needed a program that read the AirBnB CSV report and grouped my apartments by month and year. Then, considering the cleaning costs, and the number of nights per booking, it would do statistics on the average rental price for different months of the year. This program is extremely useful for me. At the same time, writing it is deadly boring: there's nothing interesting. So I took a nice piece of the CSV file and did copy-paste on GPT4. I wrote to the LLM what the problem was to be solved: the program worked on the first try. I show it to you in full below.

```python
import pandas as pd
pd.set_option('display.max_rows', None)
df = pd.read_csv('listings.csv')
reservations = df[df['Type'] == 'Reservation']
reservations['Start Date'] = pd.to_datetime(reservations['Start Date'])
reservations['Year'] = reservations['Start Date'].dt.year
reservations['Month'] = reservations['Start Date'].dt.month
reservations['Nightly Rate'] = (reservations['Amount'] - reservations['Cleaning Fee']) / reservations['Nights']
all_listings = reservations['Listing'].unique()
all_years = reservations['Year'].unique()
all_months = range(1, 13)
index = pd.MultiIndex.from_product([all_listings, all_years, all_months], names=['Listing', 'Year', 'Month'])
all_data = pd.DataFrame(index=index).reset_index()
merged_data = pd.merge(all_data, reservations, on=['Listing', 'Year', 'Month'], how='left')
average_nightly_rates = merged_data.groupby(['Listing', 'Year', 'Month'])['Nightly Rate'].mean().fillna(0)
print(average_nightly_rates)
```

To understand exactly how to group the data, which were otherwise quite scattered and disordered, requires some simple reasoning: it’s not a problem that an LLM could solve simply by regurgitating something that approximates the language it has seen. GPT4 has certainly observed similar programs during its training, but almost certainly has not seen a program that had to group things in the exact way I asked for and in a CSV file with that specific format. This shows (in my opinion) that LLMs can interpolate to some extent within the space outlined by the different programs in the training set.

Writing this type of program would be, in my opinion, an imprudent use of my time. The fact that an LLM can do it for me certainly speeds up my ability to produce code in a rather direct way: I can focus on the things that matter.

# When things don't go as they should: System Programming

Despite my success with LLMs and programming, when I write a program in C, I almost always end up using LLMs only as a more convenient form of documentation. I am an expert in system programming, and in that context, LLMs would be useful to me only if they were capable of complex reasoning: in this scenario, they almost always fail.

Let's start with the prompt of this experiment:

Outline the requirements of a nice, small but working C implementation of a bloom filter. Focus on the important aspects of the hashing function. Then write it, in good quality C.

Also consider that your example implementation should be sized to store 100,000 elements, with a false positive probability of at most 5%. The elements added are null-terminated strings.

Here’s the output:

```c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;math.h&gt;

#define N 100000  // Number of elements
#define P 0.05    // False positive probability
#define M (int)(-(N * log(P)) / (log(2) * log(2)))  // Size of bit array
#define K (int)(M / N * log(2))  // Number of hash functions

unsigned char bitArray[M / 8 + 1];

void setBit(int n) {
    bitArray[n / 8] |= 1 &lt;&lt; (n % 8);
}

int getBit(int n) {
    return bitArray[n / 8] &amp; (1 &lt;&lt; (n % 8));
}

// Basic hash functions (for demonstration purposes)
int hash1(char *str) {
    int hash = 5381;
    int c;
    while ((c = *str++))
        hash = ((hash &lt;&lt; 5) + hash) + c;
    return abs(hash % M);
}

int hash2(char *str) {
    unsigned long hash = 0;
    int c;
    while ((c = *str++))
        hash = c + (hash &lt;&lt; 6) + (hash &lt;&lt; 16) - hash;
    return abs(hash % M);
}

void add(char *str) {
    setBit(hash1(str));
    setBit(hash2(str));
    // Add more hash functions if needed
}

int is_in(char *str) {
    return getBit(hash1(str)) &amp;&amp; getBit(hash2(str));
    // Check more hash functions if used
}

int main() {
    char *testStr = "testString";
    add(testStr);

    if (is_in(testStr)) {
        printf("%s is probably in the set.\n", testStr);
    } else {
        printf("%s is definitely not in the set.\n", testStr);
    }

    return 0;
}
```

The implementation produced by GPT4 is not exactly brilliant. Bloom filters are quite widespread. It’s not such an exotic data structure. However, it’s clear that writing a decent bloom filter requires a greater capacity for abstraction: for example, there’s the problem of finding an effective way to hash the same string N times, and being certain that the hashes are sufficiently decorrelated.

Yet if you explicitly ask GPT4 to modify the hashing function so that it produces N decorrelated outputs, its proposed solution is significantly more acceptable:

```c
unsigned int hash(const char* str, unsigned int hash_id) {
    unsigned int hash = 5381;
    int c;
    while ((c = *str++)) {
        hash = ((hash &lt;&lt; 5) + hash) + c + hash_id;
    }
    return hash % BF_SIZE;
}
```

If it had come up with this idea on its own, it would have written the bloom filter differently, setting K bits at a time using a single hashing function.

GPT4 was able to perform, in isolation, the task of writing an appropriate and more generic hashing function. But in the larger project of writing a bloom filter, it failed to show sufficient reasoning ability, and instead spat out two different but similar hashing functions: this is what one would expect from a poorly written article example on bloom filters.

The current weak reasoning abilities of Large Language Models, combined with a possible scarcity of sources on the subject, and even worse, potentially many low-quality sources, collectively result in this meager outcome. Yet, this is not an isolated case. The few times I attempt to use LLMs in the realm of algorithmic or system programming, the results are extremely poor, even when the expected reasoning abilities are not greater than what LLMs seem to possess in contexts like Python programming.

At the same time, GPT-4 is capable of decompiling the function it produced (in a separate session), and also precisely understand its purpose:

<a rel="nofollow" href="https://chat.openai.com/share/f54b64d7-d19a-4be4-8f10-08553aa812f1">https://chat.openai.com/share/f54b64d7-d19a-4be4-8f10-08553aa812f1</a>

Therefore, stating that there are no uses in system programming contexts is certainly inaccurate.

One interesting and pretty much expected thing is that, in these cases, the difference between smaller and larger models is indeed significant. Let’s see how two local models fare.

For instance, Mixtral, the MoE of Mistral, responded to the same question as follows:

```c
unsigned int hash(const char* str, unsigned int hash_id) {
    unsigned int hash = 5381;
    int c;
    while ((c = *str++)) {
        hash = ((hash &lt;&lt; 5) + hash) + c;
    }
    return hash + hash_id;
}
```

Clearly, adding `hash_id` only at the end is an extremely poor solution. Mixtral is an excellent model for many uses, but as for the already weak reasoning capabilities of LLMs, the rule so far is certainly: larger is better.

This is a chat with the local LLM deepseek-coder, quantized to 4 bits as I don’t have enough RAM to use the model at higher precision. Yet, being 34 billion parameters large, its reasoning capabilities on this matter seem quite advanced. Here’s the log of the chat (conducted with llama.cpp):

&gt; I have a hash function that should output N distinct hashes for the same data. However, I'm seeing a very poor distribution of the produced hashes as I change the value of hash_id:

unsigned int hash(const char* str, unsigned int hash_id) {
    unsigned int hash = 5381;
    int c;
    while ((c = *str++)) {
        hash = ((hash &lt;&lt; 5) + hash) + c;
    }
    return hash + hash_id;
}

Maybe the salting strategy I'm using is poor? How could I change it?

[Deep-seek coder reply]

A possible issue with your implementation is that you're simply adding `hash_id` to the end of the hash. This can potentially lead to a poor distribution, especially if `hash_id` is too large or is not evenly distributed.

Consider using bitwise operations for mixing the `hash_id` in. Here is an example with XOR:

```c
unsigned int hash(const char* str, unsigned int hash_id) {
    unsigned int hash = 5381;
    int c;
    while ((c = *str++)) {
        hash = ((hash &lt;&lt; 5) + hash) ^ c + hash_id; // Using XOR to mix in the hash_id
     }
    return (hash ^ hash_id); // Mixing the hash_id one more time at the end
}
```

This will spread `hash_id` throughout your hashes better than simply adding it, which can lead to less uniform distribution. [Snipped… the actual reply contained more informative stuff]

Not bad for a model running on my MacBook M1 Max. It also mixed the sums with XORs. In this case, the model was certainly helped by the fact that I provided clues about the problem to solve, but it was the model that identified what the real source of the trouble was, and the proposed alternative is valid. Something like the above is not within the reach of any book, documentation, or Google search. And as primitive, a result of interpolation, or however you want to perceive it, the model has performed some form of reasoning, if by reasoning, in this specific case, we accept the identification of the origin of a problem and its potential solution. However one wants to think about LLMs, stating that they are not helpful for programmers is extremely rash.

At the same time, however, my experience over the past few months suggests that for system programming, LLMs almost never provide acceptable solutions if you are already an experienced programmer. Let me show you another real world example. My current project, ggufflib, involves writing a library that reads and writes GGUF format files, which is the format in which llama.cpp loads quantized models. Initially, to understand how the quantization encodings worked (for speed reasons the bits of each quant are stored in fancy ways), I tried using ChatGPT, but then I resolved to reverse engineer llama.cpp's code: it was much faster. An LLM that can decently assist a system programmer, if it sees the data encoding “struct” declaration and the decoding function, should be able to reconstruct the data format documentation. The functions of llama.cpp were small enough to fit entirely in the context of GPT4, yet the output was completely useless. In these cases, things are done as in the past: paper and pen, reading the code, and seeing where the bits that the decoder extracts are registered.

Let me explain better the above use case so that you can try it yourself, if you wish. We have this structure from llama.cpp implementation.

// 6-bit quantization
// weight is represented as x = a * q
// 16 blocks of 16 elements each
// Effectively 6.5625 bits per weight
typedef struct {
    uint8_t ql[QK_K/2];      // quants, lower 4 bits
    uint8_t qh[QK_K/4];      // quants, upper 2 bits
    int8_t  scales[QK_K/16]; // scales, quantized with 8 bits
    ggml_fp16_t d;           // super-block scale
} block_q6_K;

Then there is this function that is used to perform the dequantization:

void dequantize_row_q6_K(const block_q6_K * restrict x, float * restrict y, int k) {
    assert(k % QK_K == 0);
    const int nb = k / QK_K;

    for (int i = 0; i &lt; nb; i++) {

        const float d = GGML_FP16_TO_FP32(x[i].d);

        const uint8_t * restrict ql = x[i].ql;
        const uint8_t * restrict qh = x[i].qh;
        const int8_t  * restrict sc = x[i].scales;
        for (int n = 0; n &lt; QK_K; n += 128) {
            for (int l = 0; l &lt; 32; ++l) {
                int is = l/16;
                const int8_t q1 = (int8_t)((ql[l +  0] &amp; 0xF) | (((qh[l] &gt;&gt; 0) &amp; 3) &lt;&lt; 4)) - 32;
                const int8_t q2 = (int8_t)((ql[l + 32] &amp; 0xF) | (((qh[l] &gt;&gt; 2) &amp; 3) &lt;&lt; 4)) - 32;
                const int8_t q3 = (int8_t)((ql[l +  0]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 4) &amp; 3) &lt;&lt; 4)) - 32;
                const int8_t q4 = (int8_t)((ql[l + 32]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 6) &amp; 3) &lt;&lt; 4)) - 32;
                y[l +  0] = d * sc[is + 0] * q1;
                y[l + 32] = d * sc[is + 2] * q2;
                y[l + 64] = d * sc[is + 4] * q3;
                y[l + 96] = d * sc[is + 6] * q4;
            }
            y  += 128;
            ql += 64;
            qh += 32;
            sc += 8;
        }
    }
}

If I ask GPT4 to write an outline of the format used, it struggles to provide a clear explanation of how the blocks are stored on the lower / upper 4 bits of “ql” depending on the weight position. For this blog post, I also tried asking it to write a simpler function that shows how data is stored (maybe it can’t explain it with words, but can with code). The produced function is broken in many ways, the indexes are wrong, the 6-bit -&gt; 8-bit sign extension is wrong (it just casts to uint8_t), and so forth.

Btw, this is the code that I ended writing myself:

    } else if (tensor-&gt;type == GGUF_TYPE_Q6_K) {
        uint8_t *block = (uint8_t*)tensor-&gt;weights_data;
        uint64_t i = 0; // i-th weight to dequantize.
        while(i &lt; tensor-&gt;num_weights) {
            float super_scale = from_half(*((uint16_t*)(block+128+64+16)));
            uint8_t *L = block;
            uint8_t *H = block+128;
            int8_t *scales = (int8_t*)block+128+64;
            for (int cluster = 0; cluster &lt; 2; cluster++) {
                for (uint64_t j = 0; j &lt; 128; j++) {
                    f[i] = (super_scale * scales[j/16]) *
                           ((int8_t)
                            ((((L[j%64] &gt;&gt; (j/64*4)) &amp; 0xF) |
                             (((H[j%32] &gt;&gt; (j/32*2)) &amp; 3) &lt;&lt; 4)))-32);
                    i++;
                    if (i == tensor-&gt;num_weights) return f;
                }
                L += 64;
                H += 32;
                scales += 8;
            }
            block += 128+64+16+2; // Go to the next block.
        }
   }

From the function above, I removed what was the actual contribution of this code: the long comments documenting the exact format used by llama.cpp Q6_K encoding. Now, it would be immensely useful if GPT could do this for me, and I bet it’s just a matter of months, because these kind of tasks are within what can be reached without any breakthrough, just with a bit of scaling.

# Putting Things in Perspective

I regret to say it, but it's true: most of today's programming consists of regurgitating the same things in slightly different forms. High levels of reasoning are not required. LLMs are quite good at doing this, although they remain strongly limited by the maximum size of their context. This should really make programmers think. Is it worth writing programs of this kind? Sure, you get paid, and quite handsomely, but if an LLM can do part of it, maybe it's not the best place to be in five or ten years.

And then, do LLMs have some reasoning abilities, or is it all a bluff? Perhaps at times, they seem to reason only because, as semioticians would say, the "signifier" gives the impression of a meaning that actually does not exist. Those who have worked enough with LLMs, while accepting their limits, know for sure that it cannot be so: their ability to blend what they have seen before goes well beyond randomly regurgitating words. As much as their training was mostly carried out during pre-training, in predicting the next token, this goal forces the model to create some form of abstract model. This model is weak, patchy, and imperfect, but it must exist if we observe what we observe. If our mathematical certainties are doubtful and the greatest experts are often on opposing positions, believing what one sees with their own eyes seems a wise approach.

Finally, what sense does it make today not to use LLMs for programming? Asking LLMs the right questions is a fundamental skill. The less it is practiced, the less one will be able to improve their work thanks to AI. And then, developing a descriptive ability of problems is also useful when talking to other human beings. LLMs are not the only ones who sometimes don't understand what we want to say. Communicating poorly is a great limitation, and many programmers communicate very poorly despite being very capable in their specific field. And now Google is unusable: using LLMs even just as a compressed form of documentation is a good idea. For my part, I will continue to make extensive use of them. I have never loved learning the details of an obscure communication protocol or the convoluted methods of a library written by someone who wants to show how good they are. It seems like "junk knowledge" to me. LLMs save me from all this more and more every day.</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elizabeth line testing ways of banishing its "ghosts in the walls" (120 pts)]]></title>
            <link>https://www.ianvisits.co.uk/articles/elizabeth-line-testing-ways-of-banishing-its-ghosts-in-the-walls-68642/</link>
            <guid>38840339</guid>
            <pubDate>Tue, 02 Jan 2024 10:59:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ianvisits.co.uk/articles/elizabeth-line-testing-ways-of-banishing-its-ghosts-in-the-walls-68642/">https://www.ianvisits.co.uk/articles/elizabeth-line-testing-ways-of-banishing-its-ghosts-in-the-walls-68642/</a>, See on <a href="https://news.ycombinator.com/item?id=38840339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-68642">
								
				

				<div>
<!-- Article Start -->
					
<p>The appearance of shadowy ghosts has plagued some of the <a href="https://www.ianvisits.co.uk/articles/tag/crossrail-elizabeth-line/">Elizabeth line’s</a> central London stations, and now TfL is trying to banish them.</p>
<p><a href="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03.jpg"><img fetchpriority="high" decoding="async" src="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-1024x569.jpg" alt="" width="605" height="336" loading="none" srcset="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-1024x569.jpg 1024w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-600x333.jpg 600w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-768x427.jpg 768w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-1536x853.jpg 1536w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-100x56.jpg 100w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-150x83.jpg 150w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-200x111.jpg 200w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-300x167.jpg 300w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-450x250.jpg 450w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03-900x500.jpg 900w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-03.jpg 1800w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>The shadows are appearing behind the seats on the platforms where people are leaning up against the walls and thanks to their appearance, have been nicknamed by some as ghosts.</p>
<p>They are starting to look shabby though, so TfL is trying out an idea to see if it can help reduce the effect or even eradicate it entirely.</p>
<p>One would be to replace all the seats with new designs with backs to lean on, but that would be expensive, so an alternative is to put large decorative stickers on the walls to mask the shadows.</p>
<p><a href="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05.jpg"><img decoding="async" src="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-1024x569.jpg" alt="" width="605" height="336" srcset="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-1024x569.jpg 1024w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-600x333.jpg 600w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-768x427.jpg 768w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-1536x853.jpg 1536w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-100x56.jpg 100w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-150x83.jpg 150w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-200x111.jpg 200w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-300x167.jpg 300w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-450x250.jpg 450w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05-900x500.jpg 900w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-05.jpg 1800w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>Several designs are being tested at <a href="https://www.ianvisits.co.uk/articles/tag/liverpool-street-station/">Liverpool Street station</a>, ranging from large sheets to “pawns” that sit behind each seat.</p>
<p>The plain pawns are primarily black, but a blue pawn highlights the accessible seats on the ends of the rows. The other pawns and the solid blocks of sheeting are coloured to match the design of the Elizabeth line seating moquette.</p>
<p><a href="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01.jpg"><img decoding="async" src="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-1024x569.jpg" alt="" width="605" height="336" srcset="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-1024x569.jpg 1024w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-600x333.jpg 600w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-768x427.jpg 768w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-1536x853.jpg 1536w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-100x56.jpg 100w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-150x83.jpg 150w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-200x111.jpg 200w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-300x167.jpg 300w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-450x250.jpg 450w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01-900x500.jpg 900w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-01.jpg 1800w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A TfL spokesperson said: “The Elizabeth line has had a transformational effect, providing new journey options for customers, including at new central London stations. At some of our underground Elizabeth line stations we have been exploring new ways to clean the walls behind seating to remove any marks and better protect the walls in future to improve the customer experience.”</p>
<p><a href="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04.jpg"><img decoding="async" src="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-1024x569.jpg" alt="" width="605" height="336" srcset="https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-1024x569.jpg 1024w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-600x333.jpg 600w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-768x427.jpg 768w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-1536x853.jpg 1536w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-100x56.jpg 100w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-150x83.jpg 150w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-200x111.jpg 200w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-300x167.jpg 300w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-450x250.jpg 450w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04-900x500.jpg 900w, https://www.ianvisits.co.uk/articles/wp-content/uploads/2023/12/elizabeth-line-wall-stickers-04.jpg 1800w" sizes="(max-width: 605px) 100vw, 605px"></a></p>



										


								
					



					

									</div><!-- end of .post-entry -->
				
				
	
				





				

				
				

				<!-- end of .navigation -->

				
		<!-- end of .post-data -->


						
								
				
				

				
<div>
<p>SUPPORT THIS WEBSITE</p>

<div>

<p>This website has been running now for over a decade, and while advertising revenue contributes to funding the website, it doesn't cover the costs. That is why I have set up a facility with <a href="https://donorbox.org/support-ianvisits-reporting-and-events-guide">DonorBox</a> where you can contribute to the costs of the website and time invested in writing and research for the news articles.</p>

<p>It's very similar to the way The Guardian and many smaller websites are now seeking to generate an income in the face of rising costs and declining advertising.</p>

<p>Whether it's a one-off donation or a regular giver, every additional support goes a long way to covering the running costs of this website, and keeping you regularly topped up doses of Londony news and facts.</p>

<p>If you like what you read on here, then please support the website <a href="https://donorbox.org/support-ianvisits-reporting-and-events-guide"><strong>here</strong></a>.</p>

<p>Thank you</p>

</div>

</div>




			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JAL A359 at Tokyo collided with Coast Guard DH8C on runway and burst into flames (168 pts)]]></title>
            <link>http://avherald.com/h?article=5132b9fe&amp;opt=0</link>
            <guid>38839885</guid>
            <pubDate>Tue, 02 Jan 2024 09:44:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://avherald.com/h?article=5132b9fe&#x26;opt=0">http://avherald.com/h?article=5132b9fe&#x26;opt=0</a>, See on <a href="https://news.ycombinator.com/item?id=38839885">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>A JAL Japan Airlines Airbus A350-900, registration JA13XJ performing flight JL-516 from Sapporo to Tokyo Haneda (Japan) with 367 passengers and 12 crew, landed on Haneda's runway 34R at 17:47L (08:47Z) in night time conditions but collided with a Japanese Coast Guard Dash 8-300 registration JA722A (Coast Guard code MA722) on the runway shortly after touchdown and burst into flames. The A350 came to a stop off the right hand edge of the runway about 1680 meters/5510 feet down the runway and was evacuated. All occupants were able to evacuate. The other aircraft carrying 6 people also burst into flames, 5 of the six occupants are confirmed dead. Both aircraft burned down. 14 occupants of the A359 received injuries, the captain of the Dash 8 received serious injuries.<p>The airline reported their A350 was carrying 367 passengers (including 8 children) and 12 crew, all of them evacuated from the aircraft.</p><p>Japan's Coast Guard reported their Dash 8-300 registration JA722A (Code MA722) was carrying 6 people, the captain was able to evacuate, the other 5 are currently missing. The aircraft was carrying supplies to their Niigata based where the New Year's Earthquake struck.</p><p>Tokyo's Metropolitan Police reported 5 of the occupants of the Dash 8 are confirmed dead. </p><p>Tokyo's fire department reported, the captain of the DH8C received serious injuries, 17 occupants of the A359 received injuries. Later the Fire Department corrected the number to 14 injuries amongst the occupants of the A359.</p><p>Passengers of the A359 reported the landing appeared normal at first, after touchdown there was a thud and the outside lit up in orange. A first announcement was made "please calm down" followed by "do not take your luggage and do not stand up". There was no clear announcement to evacuate, however, when other passengers stood up they also stood up and thus escaped.</p><p>Japan's Ministry of Transport stated Haneda Airport was closed, the flights cancelled, there is no prediction when the airport will open again.</p><p>A number of arriving flights are being diverted to Narita Airport where the flights are being accepted one by one.</p><p>Related NOTAMs:<br>E5877/23 NOTAMN<br>Q) RJJJ/QMXLC/IV/M/A/000/999/3533N13947E005<br>A) RJTT B) 2401021530 C) 2401302130<br>D) 02 05 09 12 16 19 23 26 30 1530/2130<br>E) TWY C1 THRU C14-CLSD DUE TO MAINT</p><p>E0023/24 NOTAMN<br>Q) RJJJ/QMXLC/IV/M/A/000/999/3533N13947E005<br>A) RJTT B) 2401020930 C) 2401021500 EST<br>E) TWY C1 THRU C14-CLSD DUE TO TRBL</p><p>J0011/24 NOTAMR J0010/24<br>Q) RJJJ/QMRLC/IV/NBO/A/000/999/3533N13947E005<br>A) RJTT B) 2401021136 C) 2401021300 EST<br>E) ALL RWY-CLSD DUE TO DISABLED ACFT</p><p>E0025/24 NOTAMN<br>Q) RJJJ/QMXLC/IV/M/A/000/999/3533N13947E005<br>A) RJTT B) 2401021144 C) 2401021300 EST<br>E) TWY C(FM C1 TO C14)-CLSD DUE TO TRBL</p><p>E0026/24 NOTAMR E0024/24<br>Q) RJJJ/QMXLC/IV/M/A/000/999/3533N13947E005<br>A) RJTT B) 2401021154 C) 2401031200<br>E) TWY G(BTN C AND H2),G(INT OF H2)-CLSD DUE TO RESCUE OPR</p><p>E0024/24 NOTAMN<br>Q) RJJJ/QMXLC/IV/M/A/000/999/3533N13947E005<br>A) RJTT B) 2401020953 C) 2401021200<br>E) TWY G(BTN C AND H2),G(INT OF H2)-CLSD DUE TO RESCUE OPR</p><p>Metars:<br>RJTT 021000Z 32003KT 9999 R34L/P2000N R22/P2000N R34R/P2000N R05/P2000N FU BKN015 08/04 Q1016 NOSIG RMK 7SC015 A3002 1000E FU ON RWYC-MID=<br>RJTT 020930Z 31007KT 9999 R34L/P2000N R22/P2000N R34R/0900VP2000U R05/P2000N FU BKN015 08/04 Q1016 NOSIG=<br><b>RJTT 020900Z 33008KT 9999 FEW020 07/04 Q1016 NOSIG=</b><br><b>RJTT 020830Z VRB03KT 9999 FEW020 SCT090 08/04 Q1016 BECMG TL0900 30006KT=</b><br>RJTT 020800Z 13003KT 090V150 9999 FEW020 BKN090 09/05 Q1016 BECMG TL0930 30006KT RMK 1CU020 6AC090 A3000=<br>RJTT 020730Z 16007KT 130V190 9999 FEW020 BKN100 08/05 Q1016 NOSIG=<br>RJTT 020700Z 12007KT 9999 FEW030 BKN100 09/04 Q1016 NOSIG=<br>RJTT 020630Z 13010KT 9999 -RA FEW030 BKN070 09/04 Q1016 NOSIG=<br>RJTT 020600Z 14005KT 120V180 9999 -RA FEW030 SCT060 BKN080 08/03 Q1017 NOSIG=<br>RJTT 020530Z 12005KT 9999 -RA FEW025 SCT060 BKN080 08/02 Q1017 NOSIG=<br>RJTT 020500Z 09003KT 050V120 9999 -RA FEW040 BKN060 08/02 Q1017 NOSIG=<br>RJTT 020430Z VRB01KT 9999 -RA FEW030 BKN050 09/01 Q1018 NOSIG=<br>RJTT 020400Z 01003KT 310V060 9999 -RA FEW030 BKN045 09/00 Q1018 NOSIG=</p><p>The A350 skidding to a halt on the runway:<br><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_1.jpg" width="750" height="447" alt="The A350 skidding to a halt on the runway"></p><p>The aircraft after coming to a halt:<br><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_2.jpg" width="750" height="336" alt="The aircraft after coming to a halt"></p><p><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_4.jpg" width="750" height="532" alt="The aircraft after coming to a halt"></p><p>Still out CCTV recording showing the A359 shortly after touchdown, just before and at the moment of collision:<br><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_3_1.jpg" width="750" height="422" alt="Still out CCTV recording showing the A359 shortly after touchdown"></p><p><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_3_2.jpg" width="750" height="422" alt="Still out CCTV recording showing the A359 just before collision"></p><p><img src="http://avherald.com/img/jal_a359_ja13xj_tokyo_240102_3_3.jpg" width="750" height="422" alt="Still out CCTV recording showing the A359 just at collision"></p></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The funny rules of SpamAssassin in 2023 (115 pts)]]></title>
            <link>https://updown.io/blog/the-funny-rules-of-spamassassin-in-2023</link>
            <guid>38839763</guid>
            <pubDate>Tue, 02 Jan 2024 09:27:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://updown.io/blog/the-funny-rules-of-spamassassin-in-2023">https://updown.io/blog/the-funny-rules-of-spamassassin-in-2023</a>, See on <a href="https://news.ycombinator.com/item?id=38839763">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="articles">
    <h2>
      <a href="https://updown.io/blog">Blog</a> <em>&nbsp;〉</em>The funny rules of SpamAssassin in 2023 (deep dive)
    </h2><p>This investigation was surprising to me so I thought it would be interesting to share my findings and I hope you'll like it.</p>

<p>Some of my clients occasionally reported that the updown confirmation email (used to confirm a new email address, provided by <a href="https://github.com/heartcombo/devise/blob/main/app/views/devise/mailer/confirmation_instructions.html.erb">Devise</a>) had been classified as spam, we're talking about this one:</p>

<p><img src="https://updown.io/files/655b30f9893e4ad2c794f3c4.png" alt="confirmation email screenshot"></p>

<p>Doesn't look too spammy so far but sometimes mails servers running <a href="https://spamassassin.apache.org/">SpamAssassin</a> were indeed reporting a rating above 5 on its "Spam-Score". 5 being the default threshold from SpamAssassin to consider an email as spam. If we have access to the raw email with headers, this is something we can often see easily (real example provided by one client):</p>
<div><pre><code><span>X-Spam-Report</span><span>:</span><span> 
    *  0.0 HTML_MESSAGE BODY: Nachricht =?UTF-8?Q?enth=E4lt?= HTML
    *  2.8 HTML_IMAGE_ONLY_28 BODY: HTML: images with 2400-2800 bytes of words
    * -0.0 T_SCC_BODY_TEXT_LINE No description available.
    *  4.0 URI_PHISH Phishing using web form</span>
<span>X-Spam-Score</span><span>:</span><span> 6.8</span>
</code></pre></div>
<p>So I started investigating why SpamAssassin was applying these rules to this email and oh boy I wasn't ready for what I found 😅</p>

<p>I first tried reproducing the problem locally by installing SpamAssassin and running some checks on the exact same email from that client (example instructions used on Ubuntu 22.04):</p>
<div><pre><code><span>&gt;</span><span> </span><span>sudo </span>apt <span>install </span>spamassassin
<span>
</span><span>&gt;</span><span> </span>spamassassin <span>-V</span>
<span>SpamAssassin version 3.4.6
  running on Perl version 5.34.0

</span><span>&gt;</span><span> </span>spamassassin <span>-t</span> &lt; confirmation-instructions.eml
<span># ...
</span><span>Content analysis details:   (0.6 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
-1.0 RCVD_IN_MSPIKE_H5      RBL: Excellent reputation (+5)
                            [104.245.209.212 listed in wl.mailspike.net]
-0.0 SPF_HELO_PASS          SPF: HELO matches SPF record
 0.7 HTML_IMAGE_ONLY_28     BODY: HTML: images with 2400-2800 bytes of
                            words
 0.0 HTML_MESSAGE           BODY: HTML included in message
-0.1 DKIM_VALID             Message has at least one valid DKIM or DK signature
-0.1 DKIM_VALID_AU          Message has a valid DKIM or DK signature from
                            author's domain
 0.1 DKIM_SIGNED            Message has a DKIM or DK signature, not necessarily
                            valid
-0.0 RCVD_IN_MSPIKE_WL      Mailspike good senders
 1.0 URI_PHISH              Phishing using web form
</span></code></pre></div>
<p>Dissapointingly the result was very different and the score very low. We could still see the same impacting rules though (<code>HTML_IMAGE_ONLY_28</code> and <code>URI_PHISH</code>) but with lower scores.</p>

<p>I also tried with the <code>-Lt</code> options which means "local-only test" (no calls to remote servers, online blacklists, etc.) and in that case there's fewer tests as expected but it <strong>increases</strong> the score of others:</p>
<div><pre><code><span>&gt;</span><span> </span>spamassassin <span>-Lt</span> &lt; confirmation-instructions.eml
<span># ...
</span><span>Content analysis details:   (3.8 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 0.0 HTML_MESSAGE           BODY: HTML included in message
 2.8 HTML_IMAGE_ONLY_28     BODY: HTML: images with 2400-2800 bytes of
                            words
 1.0 URI_PHISH              Phishing using web form
</span></code></pre></div>
<p>This is likely to make up for the fact that there's less signal to be used so they need to amplify the only available signals in order to reach the spam score threshold of 5 earlier, I guess.</p>

<blockquote>
<p>If you do/can have a local DNS resolver, I would recommend making sure you enable <a href="https://cwiki.apache.org/confluence/display/spamassassin/UsingNetworkTests">network rules</a> for more reliable results. If using <code>spampd</code>, this is configured with <code>LOCALONLY=0</code>  in <code>/etc/default/spampd</code> </p>
</blockquote>

<p>So even though the scores were lower, I knew they could be multiplied for some reasons and also by configuration so better see if I can avoid the email being flagged as <code>HTML_IMAGE_ONLY_28</code> and <code>URI_PHISH</code> entirely to eliminate the problem.</p>

<p>I first wrote a quick way to test these emails spam scores in my specs (using <code>spamd</code> the daemon version of SpamAssassin, and <code>spamc</code> the command-line client). In order to be able to iterate and test changes quickly, but also to <strong>avoid regressions in the future</strong>. Future changes of my emails or future versions of SpamAssassin:</p>
<div><pre><code><span>def</span> <span>spam_check</span> <span>email</span>
  <span># Using spamc/spamd (daemon) if available, much faster</span>
  <span>cmd</span> <span>=</span> <span>"spamc --full --connect-retries=1"</span>
  <span># Using spamassassin (standalone cmd), slower but supports local-only option</span>
  <span># cmd = "spamassassin -Lt"</span>
  <span># Inject Received header to trigger more rules like __VIA_ML (return-path contains "bounces@")</span>
  <span>stdin</span> <span>=</span> <span>"Received: by mta212a-ord.mtasv.net id h6qj0s27tk4a for &lt;</span><span>#{</span><span>email</span><span>.</span><span>to</span><span>.</span><span>first</span><span>}</span><span>&gt;; </span><span>#{</span><span>email</span><span>.</span><span>date</span><span>.</span><span>rfc2822</span><span>}</span><span> (envelope-from &lt;pm_bounces@bounce.updown.io&gt;)</span><span>\n</span><span>"</span> <span>+</span> <span>email</span><span>.</span><span>to_s</span>
  <span>out</span><span>,</span> <span>err</span><span>,</span> <span>status</span> <span>=</span> <span>Open3</span><span>.</span><span>capture3</span><span>(</span><span>cmd</span><span>,</span> <span>stdin_data: </span><span>stdin</span><span>)</span>
  <span>if</span> <span>out</span> <span>==</span> <span>"0/0</span><span>\n</span><span>"</span>
    <span>skip</span> <span>"spamd is not running: `sudo systemctl start spamassassin.service`"</span>
  <span>elsif</span> <span>status</span><span>.</span><span>success?</span>
    <span># minor processing to have stable rules orders and remove width limit</span>
    <span>headers</span><span>,</span> <span>rules</span> <span>=</span> <span>out</span><span>.</span><span>chomp</span><span>.</span><span>split</span><span>(</span><span>"--</span><span>\n</span><span>"</span><span>)</span>
    <span>rules</span><span>.</span><span>gsub!</span><span>(</span><span>/\n\s{5,}/m</span><span>,</span> <span>" "</span><span>)</span>
    <span>return</span> <span>headers</span> <span>+</span> <span>"</span><span>\n</span><span>"</span> <span>+</span> <span>rules</span><span>.</span><span>lines</span><span>.</span><span>sort</span><span>.</span><span>join</span>
  <span>else</span>
    <span>raise</span> <span>Error</span><span>.</span><span>new</span><span>(</span><span>"Command `</span><span>#{</span><span>cmd</span><span>}</span><span>` exited with status </span><span>#{</span><span>status</span><span>.</span><span>to_i</span><span>}</span><span>: </span><span>#{</span><span>err</span><span>}</span><span>"</span><span>)</span>
  <span>end</span>
<span>rescue</span> <span>Errno</span><span>::</span><span>ENOENT</span> <span>=&gt;</span> <span>e</span>
  <span>skip</span> <span>"SpamAssassin not installed: </span><span>#{</span><span>e</span><span>.</span><span>to_s</span><span>}</span><span>"</span>
<span>end</span>
</code></pre></div><div><pre><code><span>require</span> <span>"rails_helper"</span>

<span>describe</span> <span>UserMailer</span> <span>do</span> <span># Devise inherited mailer</span>
  <span>let</span><span>(</span><span>:user</span><span>)</span> <span>{</span> <span>create</span> <span>:user</span> <span>}</span>
  <span>let</span><span>(</span><span>:email</span><span>)</span> <span>{</span> <span>ActionMailer</span><span>::</span><span>Base</span><span>.</span><span>deliveries</span><span>.</span><span>last</span> <span>}</span>

  <span>describe</span> <span>'#confirmation_instructions'</span> <span>do</span>
    <span>subject</span> <span>{</span> <span>user</span> <span>}</span>

    <span>it</span> <span>"passes spam check"</span> <span>do</span>
      <span>subject</span>
      <span>expect</span><span>(</span><span>spam_check</span><span>(</span><span>email</span><span>)).</span><span>to</span> <span>include</span><span>(</span><span>&lt;&lt;~</span><span>REPORT</span><span>)</span><span>
        Content analysis details:   (0.0 points, 5.0 required)

         pts rule name              description
        ---- ---------------------- ------------------------------------------------
         0.0 HTML_IMAGE_ONLY_32     BODY: HTML: images with 2800-3200 bytes of words
         0.0 HTML_MESSAGE           BODY: HTML included in message
        -0.0 NO_RELAYS              Informational: message was not relayed via SMTP
</span><span>      REPORT</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<p>Now let's have a look at these two rules. It's hard to find clear definitions sometimes but fortunately SpamAssassin is <a href="https://github.com/apache/spamassassin">open source</a> so where there is a will there's a way.</p>

<h3>HTML_IMAGE_ONLY_24</h3>

<p>This  one is the easiest and the most self-explanatory, it simply checks if the email contains an image (it does, the updown.io logo) and if the content is between 2000 and 2400 bytes. So basically if the email is short and has an image, it's more likely to be spam (this is because of spam email which hide text as images to avoid filters). Only two options here:<br>
1. Remove the image<br>
2. Increase the content length</p>

<p>I choose the later to keep a consistent look and also because of the second rule. In the end I only increased it a bit and now it matches the <code>HTML_IMAGE_ONLY_32</code> rule, this rule scores <strong>2.2</strong> in local-only testing but <strong>0</strong> (surprisingly) when network test are enabled. (If we follow the same logic as <code>HTML_IMAGE_ONLY_24</code>, it should have been 2.2/4 ≃ 0.55)</p>

<p>Getting rid of this rule would require much more text bloat or cheating (invisible text, etc..) and it matches more of my emails, so for the moment I decided to leave it like that and wait for the next problem. 2.2 is not enough on it's own to trip the spam threshold (5) and hopefully spamassassin will improve this part before I need to hack around it.  </p>

<h3>URI_PHISH</h3>

<p>Now for the most interesting part, after some online search I first <a href="https://spamassassin.apache.org/full/3.4.x/doc/Mail_SpamAssassin_Plugin_Phishing.txt">found this</a> which seems to be a plugin checking for URL against a blacklist, but it gives the <code>URI_PHISHING</code>  rule (not exactly the same) and I didn't install any plugin, so this is not the one.</p>

<p>I then found this <a href="https://bz.apache.org/SpamAssassin/show_bug.cgi?id=7940">very interesting report</a> in 2021 about a similar confirmation email receiving a "false positive" classification as <code>URI_PHISH</code>, and the official answer was:</p>

<blockquote>
<p><em>It's not based on "phishing URLs" or the specific link, it's based on having body text that looks like account phishing and having a URL.  The body text that looks suspiciously like phishing is, unsurprisingly, "confirm your account".</em></p>

<p><em>As Loren said, this is not a FP, as the total score for the message did not exceed the spam threshold. This is a single-rule hit on spammy-looking content without other signs to support it. That happens.</em></p>

<p><em>It is not a bug that a given rule will hit some ham. The only suggestion I can offer is that you reword your message to make it look less like phishing.</em></p>
</blockquote>

<p>So let's skip over the fact that it is now very sad that anti-spam filters have to block any simple confirmation email just because scamers are successfully abusing people with them...</p>

<p>That piqued my curiousity: what are they looking for in the email exactly? how can I make sure that the change I make won't be matched by another rule or in the future? (yes we unfortunately have to think like scammers now in order to get our regular email accepted...)</p>

<p>So by searching for <code>URI_PHISH</code> into the code I ended up in this <a href="https://github.com/apache/spamassassin/blob/773338709e3a4e53380ec9b7ef530af5f115d5ed/rulesrc/sandbox/jhardin/20_misc_testing.cf#L1340">big rules file</a> which does contain this (extract slightly simplified):</p>
<div><pre><code>meta        __URI_PHISH    __HAS_ANY_URI <span>&amp;&amp;</span> <span>!</span>__URI_GOOGLE_DOC <span>&amp;&amp;</span> <span>!</span>__URI_GOOG_STO_HTML <span>&amp;&amp;</span> <span>(</span>__EMAIL_PHISH <span>||</span> __ACCT_PHISH<span>)</span>
meta        URI_PHISH      __URI_PHISH <span>&amp;&amp;</span> <span>!</span>ALL_TRUSTED <span>&amp;&amp;</span> <span>!</span>__UNSUB_LINK <span>&amp;&amp;</span> <span>!</span>__TAG_EXISTS_CENTER <span>&amp;&amp;</span> <span>!</span>__HAS_SENDER <span>&amp;&amp;</span> <span>!</span>__CAN_HELP <span>&amp;&amp;</span> <span>!</span>__VIA_ML <span>&amp;&amp;</span> <span>!</span>__UPPERCASE_URI <span>&amp;&amp;</span> <span>!</span>__HAS_CC <span>&amp;&amp;</span> <span>!</span>__NUMBERS_IN_SUBJ <span>&amp;&amp;</span> <span>!</span>__PCT_FOR_YOU <span>&amp;&amp;</span> <span>!</span>__MOZILLA_MSGID <span>&amp;&amp;</span> <span>!</span>__FB_COST <span>&amp;&amp;</span> <span>!</span>__hk_bigmoney <span>&amp;&amp;</span> <span>!</span>__REMOTE_IMAGE <span>&amp;&amp;</span> <span>!</span>__HELO_HIGHPROFILE <span>&amp;&amp;</span> <span>!</span>__RCD_RDNS_SMTP_MESSY <span>&amp;&amp;</span> <span>!</span>__BUGGED_IMG <span>&amp;&amp;</span> <span>!</span>__FB_TOUR <span>&amp;&amp;</span> <span>!</span>__RCVD_DOTGOV_EXT 
describe    URI_PHISH            Phishing using web form
score       URI_PHISH            4.00   <span># limit</span>
</code></pre></div>
<p>Ok so we now have an entry point which contains <strong>MANY</strong> other rules of course (some of which also contains other rules). I checked <strong>ALL</strong> of them for you ^^ and here are my most interesting findings:</p>

<h4>First in the positive rules, which needs to be true:</h4>

<ul>
<li><code>__HAS_ANY_URI</code> → simple regexp on <code>/^\w+:\/\//</code></li>
<li><code>__EMAIL_PHISH || __ACCT_PHISH</code> → these the sub rules where the main "phishing" heuristics happens<br>

<ul>
<li><code>__WEBMAIL_ACCT</code>, <code>__MAILBOX_FULL</code>, <code>__MAILBOX_FULL_SE</code>, <code>__CLEAN_MAILBOX</code>, <code>__VALIDATE_MAILBOX</code>, <code>__VALIDATE_MBOX_SE</code>, <code>__UPGR_MAILBOX</code>, <code>__LOCK_MAILBOX</code>, <code>__SYSADMIN</code>, <code>__ATTN_MAIL_USER</code>, <code>__MAIL_ACCT_ACCESS1</code>, <code>__MAIL_ACCT_ACCESS2</code>, <code>__ACCESS_REVOKE</code>, <code>__PASSWORD_UPGRADE</code>, <code>__PENDING_MESSAGES</code>, <code>__RELEASE_MESSAGES</code>, <code>__PASSWORD_EXP_CLUMSY</code> → these are all regexps for typical email scams (mailbox full, click here to regain access to your account, etc...), nothing matching in my email.</li>
<li><code>__PDS_FROM_NAME_TO_DOMAIN</code> ⚠️ this one is interesting, it triggers if the <strong>From name</strong>  is equal to the <strong>To domain</strong> (for example if the emails is From “example.com” To "<a href="mailto:adrien@example.com">adrien@example.com</a>"). → this is because many scam use that to make it look like the email comes from your "domain administrator". It wasn't the case for me here, but make sure you don't do that.</li>
<li><code>__VERIFY_ACCOUNT</code> → ✅ this is the one matching our email so I had to change the wording to avoid it. The regexp is: <code>/(?:confirm|updated?|verif(?:y|ied)) (?:your|the) (?:(?:account|current|billing|personal|online)? ?(?:records?|information|account|identity|access|data|login)|"?[^\@\s]+\@\S+"? (?:account|mail ?box)|confirm verification|verify k?now|Ihre Angaben .berpr.ft und best.tigt)/i</code></li>
<li><code>__FAILED_LOGINS</code>, <code>__ACCOUNT_REACTIV</code>, <code>__SECURITY_DEPT</code>, <code>__ACCOUNT_ERROR</code>, <code>__ACCOUNT_DISRUPT</code>, <code>__ACCOUNT_UPGRADE</code>, <code>__ACCOUNT_SECURE</code>, <code>__SUSPICION_LOGIN</code>, <code>__ACCESS_SUSPENDED</code>, <code>__ACCESS_RESTORE</code>, <code>__ACCESS_REVOKE</code> → another set of regexp for classic account scams based on fear, I made sure my "account locked" email does not match any of those.</li>
</ul></li>
</ul>

<h4>Now let's look at all the negative rules here (starting with a <code>!</code>) which are meant to exclude content (if this rule is true, then the <code>URI_PHISH</code> rule will NOT apply):</h4>

<ul>
<li><code>!__URI_GOOGLE_DOC</code> and  <code>!__URI_GOOG_STO_HTML</code> → regexp on <code>docs\.google\.com</code> and <code>storage\.googleapis\.com</code>, they got their own special rule so are excluded here.</li>
<li><code>!ALL_TRUSTED</code> → this is for when you configure some internal email servers as "trusted", not applicable here</li>
<li><code>!__UNSUB_LINK</code> → ⚠️ Also interesting, this one tries to match unsubscribe links with <code>/\b(?:(?:un)?subscri(?:ber?|ptions?)|abuses?|opt(?:ing)?.?out)\b/i</code>. This is good to know that simply having an unsubscribe link could prevent <code>URI_PHISH</code>, but unfortunately for an account confirmation email you can't really "unsubscribe" people, this is not a mailing list or on-boarding email. Otherwise this would have a been a good option to improve both the spam score and the user experience.</li>
<li><code>!__VIA_ML</code> → this rule checks if the envelope-from/return-path contains "bounces@" to declare this is a "Mailing List". In my case using <a href="https://postmarkapp.com/">Postmark</a> this is the case and cannot be customized unfortunately (only the domain: <code>pm_bounces@bounce.updown.io</code>). So I guess you should avoid using "bounces@" in your return path addresses for transactional emails if you can... </li>
</ul>

<h4>And now let's have a look at my favorites: the totally WTF rules 😱:</h4>

<ul>
<li><code>!__TAG_EXISTS_CENTER</code> → this rule just checks for the presence of a <code>&lt;center&gt;</code> tag. So if you add one, magically your email is no longer <code>URI_PHISH</code>... WAIT, WHAT? Surely if your email is centered the old way, then it's not phishing (tested locally).</li>
<li><code>!__HAS_SENDER</code> → if you add ANY <code>Sender</code> header, the <code>URI_PHISH</code> rule is skipped… The goal of the Sender header is for services sending emails on behalf of other users, it helps for authentication validations. But anybody can put anything in here, so there's no reason to consider an email "less phishing" because it contains this header. (tested locally)</li>
<li><code>!__CAN_HELP</code> →  even simpler, this will skip the rule if the email contains "can help"... (tested locally)</li>
<li><code>!__UPPERCASE_URI</code> → pretty self-explanatory</li>
<li><code>!__HAS_CC</code> → what? why?</li>
<li><code>!__NUMBERS_IN_SUBJ</code> → OK so more than 3 digits in subject line also helps...  <code>/\d{3}/</code></li>
<li><code>!__FB_COST</code> → this is one checks for  the word... "cost". Yep, just that. Put it in an email and suddenly it's not phishing... (tested locally) </li>
<li><code>!__FB_TOUR</code> → similarly this one checks for the word "tour"...</li>
</ul>

<p>It's likely that some of these rules are only here to replace <code>URI_PHISH</code> by another one more specific maybe (like we saw the case with Google Doc URLs), but still in this state it's pretty easy to exploit them and in my testing locally, using those words to trigger those rules didn't cause other spam rules to appear...</p>

<p>Which means that in the end we have a spam filter which is very easy to fool, yet easily tripped by honest emails...</p>

<h3>What I changed in the end</h3>

<ol>
<li>I tried changing the <strong>return-path</strong> to avoid "bounces@" but couldn't do it with Postmark unfortunately.</li>
<li>I did not want to ~use~ <strong>exploit</strong> any of the stupid hacks like "cost" or "&lt;center&gt;".</li>
<li>I changed the <strong>wording</strong> of the email to make it longer and avoid the common word combinations matched in the regexp (see screenshot below for the new version)</li>
<li>I also added a <code>Sender</code> header (only for some emails and with the same value as <code>From</code>) in order to please the rules because this one doesn't look too hackish, but I still don't feel great about this 🙃.</li>
</ol>

<h4>New email</h4>

<p><img src="https://updown.io/files/655b50e2893e4ad2c7951554.png" alt="new email screenshot"></p>
<p id="like" rel="tooltip" title="Connected users only"><a disabled="disabled" data-remote="true" rel="nofollow" data-method="post" href="https://updown.io/articles/655b3104893e4ad2c794f3f0/like"><svg height="24" viewBox="-1 -1 26 26" fill="none" stroke="currentColor" stroke-width="2.2" stroke-linejoin="round"><path d="M20.84 5.11a5.5 5.5 0 0 0-7.78 0L12 6.17l-1.06-1.06a5.5 5.5 0 0 0-7.78 7.78l1.06 1.06L12 21.73l7.78-7.78 1.06-1.06a5.5 5.5 0 0 0 0-7.78z"></path></svg>8 Like</a></p><p><small>Created on December 04, 2023 · <a target="_blank" href="mailto:support@updown.io?subject=%F0%9F%93%9D%20Suggest%20changes%20to%20%C2%AB%20Blog%20%C2%A0%E3%80%89The%20funny%20rules%20of%20SpamAssassin%20in%202023%20%28deep%20dive%29%20%C2%BB">Suggest&nbsp;changes&nbsp;to&nbsp;this&nbsp;page</a></small>
  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Salim Kara stole $2M in coins with a magnet and a car antenna (352 pts)]]></title>
            <link>https://www.nofreelunch.co.uk/blog/salim-kara-lrt-scam/</link>
            <guid>38839652</guid>
            <pubDate>Tue, 02 Jan 2024 09:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nofreelunch.co.uk/blog/salim-kara-lrt-scam/">https://www.nofreelunch.co.uk/blog/salim-kara-lrt-scam/</a>, See on <a href="https://news.ycombinator.com/item?id=38839652">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-774">

	<!-- .entry-header -->

	<div>
		
<h2>Over 13 years, one man stole $2.3 million in fares from Edmonton LTR one coin at a time using a car antenna and magnet. </h2>



<figure><img decoding="async" width="1024" height="512" src="https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_coin_scam_edmonton_lrt.jpg" alt="Salim Kara Edmonton coin scam" srcset="https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_coin_scam_edmonton_lrt.jpg 1024w, https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_coin_scam_edmonton_lrt-300x150.jpg 300w, https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_coin_scam_edmonton_lrt-768x384.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>Maintaining public transit ticket machines is crucial to keeping cities moving but not a job that would normally generate headlines. That is unless you’re Salim Kara, who for 13 years used a car antenna and magnet to pilfer $ 2.3 million of fares from Edmonton’s LTR, one coin at a time. Finally caught in 1994, Salim’s <a href="https://www.nofreelunch.co.uk/blog/what-is-salami-slicing-scam/">salami-slicing style scam</a> had netted him 37 tonnes of small change and minor celebrity status. Here’s the fascinating story of Salim Kara’s coin scam in full.</p>



<p>Originally from Uganda but of East Indian descent, Salim Kara fled Idi Amin’s regime in 1972 for England, eventually migrating to Canada and settling in Edmonton, the capital of the province of Alberta. </p>



<h2>Magnet fishing for coins</h2>



<p>In 1981, Kara was hired on a $ 38k-a-year salary to maintain and fix the 68 ticket machines of Edmonton’s LRT – light rail transit system. From the get-go, it seems Salim wasn’t satisfied with being paid $17.66 per hour, so began supplementing his pay by pilfering a portion of the fares.</p>



<p>As Kara only maintained the machine function, he didn’t have direct access to the cash box where the coins were collected after customers had fed them to purchase LRT tickets.&nbsp;</p>



<p>Working alone and at night, he developed a simple yet ingenious method for fishing those coins out.&nbsp;</p>



<p>He removed the face plate from the ticket machines, which as a repairman would raise no suspicion, then rigged a car antenna with a magnetic tip, like a make-shift fishing rod. Coin-by-coin, Kara hooked his catch out of the ticketing machine cash box into a shaving bag, which acted as his keep net.</p>



<p><strong>Banking his heavy booty</strong></p>



<p><a href="https://www.nofreelunch.co.uk/blog/what-is-salami-slicing-scam/">Salami-slicing scams</a> focus on stealing tiny amounts of money in the hope that the size of the theft makes it unnoticeable. <a href="https://www.nofreelunch.co.uk/blog/what-was-coin-clipping/">Coin clipping</a>, the removal of small slithers of silver or gold coins, is the original salami-slicing scam, dating back to Roman times, but ended around the 17th century as coin designs became more sophisticated and eventually of no intrinsic value.&nbsp;</p>



<p>The digital age opened up a new era of salami-slicing opportunities, the best of which we’ve summarised in a separate article on computer crimes, but it is unusual for modern salami-slicing type scams to focus on coins.&nbsp;</p>



<p><a href="https://www.nofreelunch.co.uk/blog/why-cash-is-more-anonymous-than-crypto/">Cash is king where organised criminals are concerned</a>, given its untraceable nature, but their preference is for high-value bank notes. </p>



<p>Salim Kara was no King Pin; just a petty criminal with a unique gift and the patience to play the long game, quietly siphoning coins day by day over more than a decade and creating a convincing cover story to enable him to launder the proceeds.</p>



<p>Kara told his bank that he ran a successful machine-vending business. News reports estimated that he stole an average of $3k a week over 13 years, but Kara’s scheme received a boost in 1987 when Canada introduced the $1 loonie, almost doubling his weekly take.</p>



<p>Like an urban pirate, soon Kara was lugging $900 home daily in loot and around $5k a week. </p>



<blockquote>
<p>Such was the scale of coins that Kara accumulated that his bank allowed him to drag his booty through the back door and even considered expanding their vault to accommodate the volume of coinage Kara was regularly hauling in.</p>
<cite>Edmonton Journal, December 2010</cite></blockquote>



<h2><strong>Kara’s coin-powered property empire</strong></h2>



<p>Over time the proceeds from Salim Kara’s scam began to pile up, so he began investing, including a house in Victoria and two other houses in Edmonton. He also sunk $ 1 million into a term deposit but could crucially keep his distance from these visible signs of wealth.</p>



<p>Perhaps one of the main reasons why Kara could maintain his grift so long was being smart enough to keep a low profile locally, helped by the image he presented driving a dilapidated 1977 Chevrolet Malibu.</p>



<p>Sooner or later, the temptation to spend became too much and maybe thinking he would never get caught in 1992, Kara decided to trade up from his modest $136,000 home to something much more fitting of a vending-machine millionaire.</p>



<p>His mountain of coins financed the building of a $ 1 million house in an exclusive area of Edmonton with five bedrooms, five bathrooms, an indoor jacuzzi, a steam room, an indoor fountain and a garage for four cars with a built-in car wash.</p>



<p>If asked about the source of his funds, Kara claimed to have sold properties in England and made various claims to be employed in investment banking or owning a computer repair business.&nbsp;</p>



<div>
<p><strong>Salim Kara’s Coin Scam in numbers</strong></p>



<ul>
<li><strong>$2,327,890 </strong>– total amount stolen&nbsp;</li>



<li><strong>13 years</strong> – how long he maintained the salami-slicing scam</li>



<li><strong>37 tonnes</strong> – estimated total weight of stolen coins</li>



<li><strong>2 million </strong>– the number of passenger fares Kara’s crime equated to</li>



<li><strong>150km</strong> – the approximate length of Kara’s haul laid end-to-end; six times the length of the entire Edmonton LTR network</li>



<li><strong>$2,959</strong> – the average amount stolen per week</li>
</ul>
</div>



<h2><strong>All good things come to an end</strong></h2>



<p>Kara was effectively stealing 20% of LRT fares over the 13-year period; one in five coins that were fed into the machines by the paying public ended up in his shaving bag, amounting to around 2 million customer journeys. It seems inconceivable that he wasn’t caught sooner.</p>



<p>The failure to catch him, despite discrepancies between fares and cash raised in two audits, was put down to a belief that the errors were software glitches and, after his arrest, led to a significant amount of internal finger-pointing.</p>



<p>There were suspicions and even video-taped evidence of Kara acting very strangely a year before he was finally caught, but inadequate processes for whistleblowing meant that it took another year for the alarm to be finally raised.&nbsp;</p>



<p>In 1993, with the red flags mounting up, the city authorities hired private investigators to observe Kara, which finally caught him in the act. In March 1994, he sliced off the final piece of this very lucrative salami.</p>



<div>
<div>
<p>Two years later, aged 44, Kara was sentenced to four years in jail. Given the unique nature of his crime, the trial attracted plenty of public attention packing out the courthouse, but Kara’s infamy spread further when his attempts to avoid attention outside the courts backfired. </p>



<p>He was rumbled dressing up in disguise worthy of Inspector Clouseau – complete with dark glasses, woolly beanie and trenchcoat – which only heightened interest in him.</p>
</div>



<div>
<figure><img decoding="async" width="460" height="588" src="https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_edmonton_coin_scam.png" alt="Salim Kara Edmonton coin scam" srcset="https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_edmonton_coin_scam.png 460w, https://www.nofreelunch.co.uk/wp-content/uploads/2022/12/salim_kara_edmonton_coin_scam-235x300.png 235w" sizes="(max-width: 460px) 100vw, 460px"><figcaption>Salim Kara outside court doing his Inspector Clouseau impression</figcaption></figure></div>
</div>



<p>‘There are about 600,000 people living in the city. You have stolen from every citizen, man, woman and child approximately $4 each.’ Associate Chief Justice, A.H. Wachowich commented ahead of passing down the sentence.</p>



<p>As Kara repaid the proceeds of his scam to cover the city’s insurers, he was released after 16 months.&nbsp;</p>



<p>Given the fascinating nature of the crime, the length of time it was maintained and the lifestyle it financed, there were rumours of a book deal, but to date, that hasn’t materialised.&nbsp;</p>



<p>Before his sentencing in March 1996, Kara made an enigmatic statement in court, promising at some point to share his side of this fascinating tale “<em>Remember, every coin has two sides</em>”</p>



<hr>



<p>Sources</p>



<p><a href="https://apnews.com/article/a91839cb5c0c140915f9e5436dc5dffc">Associated Press, March 26th, 1996</a></p>



<p><em>The Edmonton Journal ,</em>Sep 28, 1994; March 26, 1996; June 4, 1996; December 27th, 2010</p>



<div>
<h3><strong>No Free Lunch</strong></h3>



<div><p><a href="https://www.nofreelunch.co.uk/">There is&nbsp;no such thing as a free lunch</a>, but if you’re hungry to find out why, we’re here to help.</p><p>You can learn the <a href="https://www.nofreelunch.co.uk/meaning-no-such-thing-free-lunch/">meaning</a> and <a href="https://www.nofreelunch.co.uk/origin-of-phrase-no-such-thing-as-free-lunch/">origin</a> of the no free lunch concept, as well as the broader philosophy behind the idea that nothing can ever be regarded as free.</p><p>We look at our <a href="https://www.nofreelunch.co.uk/blog/what-is-money/">relationship with money</a> and truth, examining all of the supposed shortcuts, life hacks and get-rich-quick schemes.</p></div>
</div>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What I've learned about flow fields so far (203 pts)]]></title>
            <link>https://damoonrashidi.me/articles/flow-field-methods</link>
            <guid>38839506</guid>
            <pubDate>Tue, 02 Jan 2024 08:42:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://damoonrashidi.me/articles/flow-field-methods">https://damoonrashidi.me/articles/flow-field-methods</a>, See on <a href="https://news.ycombinator.com/item?id=38839506">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><section data-fresh-key="flow-field-methods"><p>June 15, 2021, updated December 27, 2023.</p></section><blockquote>If you feel that this article is too wordy skip all the text and play with the illustrations, they get more and more fun as the articles rambles on!<figcaption>-- Me</figcaption></blockquote><section><span>Table of contents</span><ol><li><a href="#intro">Brief introduction</a></li><li><a href="#noise-functions">Noise functions</a></li><li><a href="#drawing-lines">Drawing lines</a></li><li><a href="#noise-function-alternatives">Alternatives to noise functions</a></li><li><a href="#collision-detection">Collision detection</a><ol><li><a href="#optimizing-collision-detection">Optimizing collision detection</a></li></ol></li><li><a href="#colors">colors</a></li><li><a href="#conclusion">Conclusion</a></li></ol></section><h2 id="intro">Brief introduction.</h2><p>This article will describe the methods and concepts I used to create the series of generated artworks pictured below. I've tried to visualize the algorithms and provide some code samples. The code samples are written in a Typescript with some simplifications so that the code is readable on mobile and to make them more concise and easy to follow. The general algorithms can easily be ported to any language though, I have for instance done some <a href="https://github.com/damoonrashidi/generative-art">implementations using Rust</a>.</p><p>As a note, far more talented people than me have written <a href="https://tylerxhobbs.com/essays/2020/flow-fields">articles on the subject</a> upon which my work is very obviously based. I recommend reading that one too!</p><p><img src="https://damoonrashidi.me/articles/flow-field-methods/example-1.webp?__frsh_c=35d83479d7e5b288d9b64df7753f8a599aa80b3d" alt="Flow field example one" width="300" height="475"><img src="https://damoonrashidi.me/articles/flow-field-methods/example-2.webp?__frsh_c=35d83479d7e5b288d9b64df7753f8a599aa80b3d" alt="Flow field example two" width="300" height="475"><img src="https://damoonrashidi.me/articles/flow-field-methods/example-3.webp?__frsh_c=35d83479d7e5b288d9b64df7753f8a599aa80b3d" alt="Flow field example three" width="300" height="475"></p><h2 id="noise-functions">Noise functions</h2><p>The main driving force behind these flow field images is usually a noise function. Without regurgitating the <a href="https://en.wikipedia.org/wiki/Perlin_noise">wikipedia article</a>, a noise function is a function that takes a coordinate in 2d space (higher dimension noise-functions also exist, but are irrelevant for the purpose of this article) and returns a value in the range <code>-1..=1</code> such as points close together return similar, but slightly different, values.</p><p>The interactive illustration below shows how this works by uniformly sampling points in a grid and calling the noise function for that point. Note that the values have been rounded to one decimal for legibility, the actual values have far more precision. Click <code>Regenerate</code> to run the noise function again with a new seed to get new noise values.</p><!--frsh-articles_flow_fields_noise_noiseillustration:0:--><!--/frsh-articles_flow_fields_noise_noiseillustration:0:--><p>And here is the code that generated the image above, abbreviated for clarity.</p><!--frsh-articles_code_code:1:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:1:--><p>To make it a bit easier to digest, we can visualize this in a more effective manner by translating the noise values into degrees and draw lines from a starting position and a few pixels following the degree of the noise value.</p><!--frsh-articles_flow_fields_noise_angles_noiseangleillustration:2:--><!--/frsh-articles_flow_fields_noise_angles_noiseangleillustration:2:--><!--frsh-articles_code_code:3:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:3:--><p>This doesn't look like much currently. It would appear that lines are fairly disjointed and go off in seemingly random directions. Not at all the smooth effect we're going for.</p><p>It turns out that noise functions are pretty sensitive. You'd think that the points<code>(1.0, 1.0)</code> and <code>(1.0, 2.0)</code> would produce somewhat similar noise values, following the rule that points in close proximity yield fairly similar noise values, but they're not close enough to each other.</p><p>To combat this we can force our points to be closer together by just dividing our x and y coordinates by some smoothness constant. For example, the distance between our two example points was previously <code>1.0</code> for the y-axis, and <code>0.0</code> for the x-axis, for a total distance of <code>1.0</code>.</p><p>If we divide all our x and y values by the constant <code>smoothness = 100</code>  we'd end up with: <code>p1 = (0.01, 0.01), p2 = (0.01, 0.02)</code>, making the distance only <code>0.01</code>, but keeping the relation between the points the same.</p><p>The only change we need to make to our code is the following:</p><!--frsh-articles_code_code:4:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:4:--><p>You can think of it as shrinking our domain to better fit the noise values. Or zooming in on the noise function if that helps.</p><!--frsh-articles_flow_fields_noise_angles_noiseangleillustration:5:--><!--/frsh-articles_flow_fields_noise_angles_noiseangleillustration:5:--><p>As we can see by dragging the smoothness value up, closer to 100 in this case, the lines start to smooth out and patterns start to emerge.</p><h2 id="drawing-lines">Drawing lines.</h2><p>At this point we know how to navigate the flow field. Pick any point <code>P</code>, read the noise value <code>n</code> for that point and increment <code>P.x</code> by <code>cos(n)</code> and <code>P.y</code> by <code>sin(n)</code> as well as some extra pixels that represents the distance we want to travel in the direction of the field.</p><p>We did this in the previous examples by sampling points in a grid and and having a fixed line length. To approximate the effect illustrated in the images at the beginning of this article a bit better another implementation is necessary. First we need to pick a random point on the canvas and then ride the flow field until we get out of bounds.</p><!--frsh-articles_code_code:6:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:6:--><!--frsh-articles_flow_fields_building_line_buildingaline:7:--><!--/frsh-articles_flow_fields_building_line_buildingaline:7:--><p>Going from the above example to drawing an actual line should now be trivial. Start at any given point on the canvas an instantiate your line, move through the field just as before, but instead of drawing a new point at the given position add it to the points for the line. Stop the loop when the line has reached the end of the canvas and finally draw the line.</p><!--frsh-articles_code_code:8:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:8:--><p>Mouse over the illustration below to create new lines from your mouse position.</p><!--frsh-articles_flow_fields_noise_line_noiselineillustration:9:--><!--/frsh-articles_flow_fields_noise_line_noiselineillustration:9:--><h2 id="experimenting-with-lines">Experimenting with lines.</h2><p>So far not a lot of variance has been achieved. All results, no matter what the seed of the noise function is, will yield somewhat similar images. There are a few ways to combat this, one way is by warping the noise value a bit, resulting in lines exaggerating their turns, this is done by simply multiplying the noise value by some constant before applying the <code>cos()</code> and <code>sin()</code> functions.</p><!--frsh-articles_code_code:10:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:10:--><p>Another way is by varying the length of the steps each line takes between each step as it progresses through the field. Shorter steps yield much smoother curves while longer steps will make the lines a lot more jagged.</p><!--frsh-articles_code_code:11:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:11:--><!--frsh-articles_flow_fields_line_variation_linevariationillustration:12:--><div><canvas></canvas><div><p><label for="smoothness_variation">Smoothness</label><span>100</span></p><p><label for="warp_variation">Warp</label><span>1</span></p><p><label for="max_length_variation">Max length</label><span>10</span></p><p><label for="step_size_variation">Step size</label><span>2</span></p></div></div><!--/frsh-articles_flow_fields_line_variation_linevariationillustration:12:--><h2 id="noise-function-alternatives">Alternatives to noise functions</h2><p>So far we've been using a noise function called OpenSimplex.</p><blockquote>OpenSimplex noise is an n-dimensional gradient noise function that was developed in order to overcome the patent-related issues surrounding Simplex noise, while continuing to also avoid the visually-significant directional artifacts characteristic of Perlin noise.<figcaption>- Kurt Spencer</figcaption></blockquote><p>As alluded to in the quote, there are few different noise functions. A proper noise function is a bit complicated and out of scope for this article, but nothing is stopping us from writing a function that returns similar values for a given coordinate, that part can be done pretty easily.</p><p>These home grown functions won't yield as random seeming results as a noise function but they will let us control the final output much more. They will also let us be much more creative in trying new things out now that we can draw lines that reliably follow a path.</p><p>An easy first test we can do is simply taking a coordinate and return it's distance to another point that we'll call the <code>focalPoint</code>, just to see what would happen. This function would satisfy the rule that points close together yield similar values, making our lines nice and smooth.</p><!--frsh-articles_code_code:13:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:13:--><p>Mouse over the illustration below to set a new focal point</p><!--frsh-articles_flow_fields_distance_to_point_distancetopointillustration:14:--><!--/frsh-articles_flow_fields_distance_to_point_distancetopointillustration:14:--><p>If we instead of returning the distance to <code>focalPoint</code> we can return the angle the line has from our point to  and offset our point along the radius (with a slight distortion to the y-axis) we can get a nice swirl-like effect.</p><!--frsh-articles_code_code:15:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:15:--><!--frsh-articles_code_code:16:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:16:--><!--frsh-articles_flow_fields_angle_to_point_anglebetweenillustration:17:--><!--/frsh-articles_flow_fields_angle_to_point_anglebetweenillustration:17:--><h2 id="collision-detection">Collision Detection</h2><p>In my opinion, the real fun doesn't really begin until we start looking at having the lines interact with each other. Instead of stopping when we reach the end of the canvas or we've reached the max line length we can instead stop when this line would collide with another line.</p><p>Hover the illustration (or slide your finger over it) to add lines of varying width.</p><!--frsh-articles_flow_fields_collision_detection_collisiondetectionillustration:18:--><!--/frsh-articles_flow_fields_collision_detection_collisiondetectionillustration:18:--><p>Now, a lot can be said about collision detection and how to make it performant. I'll show only one method and a small optimization to keep the solution somewhat performant.</p><p>Checking the <a href="https://en.wikipedia.org/wiki/Line%E2%80%93line_intersection">intersection of two straight lines</a> isn't too bad and can be done in O(1) time. Our lines aren't straight however so we'll have to be a bit more clever. If we go back to the beginning of how we drew the line, it started with stepping through the noise field and adding a point for each step. If we made that point into a circle by giving it same radius as the line and kept track of each circle, not just in the line but in all lines it's a lot easier to check if the circle we are about to draw overlaps any other circle.</p><p>Checking if two circles overlap is only a matter of checking if the sum of their radii is smaller than the distance between their origo.</p><!--frsh-articles_code_code:19:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:19:--><p>Here is another illustration that highlights when two non-linear lines meet using this method. Play with the illustration to move the colliding line.</p><!--frsh-articles_flow_fields_collision_example_collisionexampleillustration:20:--><!--/frsh-articles_flow_fields_collision_example_collisionexampleillustration:20:--><!--frsh-articles_code_code:21:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:21:--><h3 id="optimizing-collision-detection">Optimizing it slightly.</h3><p>These example illustrations are fairly small so we haven't ran into any performance issues when checking if our line collides with any other line... yet. When trying to make a larger image however, in a print-friendly size for instance, we'd end up with a lot of lines with a lot of points that we could potentially collide with, meaning that for every new point we add we must check collisions against all other points. This stacks up fast and will make your render times a lot longer than desired. A way to mitigate this is to only check against points that are close enough for us to collide with.</p><p>The simplest way of doing that is by dividing our canvas up into a grid of boxes and whenever we are about to add a new point check which box it would go in, and then only check against collisions with points in that box.</p><p>Time for another illustration. This time, move your finger or mouse cursor around to see which points belong to the same box.</p><!--frsh-articles_flow_fields_pointmap_pointmapillustration:22:--><!--/frsh-articles_flow_fields_pointmap_pointmapillustration:22:--><p>Now, with 100 boxes (10 across, 10 down) and if the points are distributed uniformly on the canvas, we end up doing 1/100<sup>th</sup> as many checks that we did previously, increasing rendering performance by quite a bit! One thing to note however, is that if our boxes would be too small to reliably hold points with the radius of our lines then we'd start to get overlapping lines at the edges. This would also happen if a points origo was at the very edge of a box, causing its body to spill outside the boxes area. We could fix that by checking surrounding boxes for collisions as well, but that would mean we'd check another eight boxes besides the current one, increasing the search space a bit, but the result would be more exact.</p><p>A final optimisation we can do with this technique is that if our step size (the distance between each point in each line) is sufficiently small we could skip checking a few points in the box, since if our circle overlaps with one of the circles there's a high chance that it overlaps with some other circles as well. Now this might yield a less accurate result, but accuracy is not necessarly the end goal. Some small overlaps for a few lines might introduce some visually pleasing artifacts. Usually those kinds of details are <em>happy little accidents</em>.</p><!--frsh-articles_code_code:23:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:23:--><p>Here we check against every 7<sup>th</sup> circle in a box hoping to get a hit if there is one. The constant <code>7</code> might be too high in some cases, or could be increased even more, it all depends on the step size for the lines and can be tweaked to get a good balance between render times and correctness.</p><h2 id="colors">Finally, Colors.</h2><p>The theme for this article is converging to <em>"you can achieve a lot of variation with some tweaks"</em>. That's true for applying colors to these images as well. So far things in this article have been pretty monochrome to focus on the underlying techniques of how to achieve the overarching look.</p><p>The easiest way to get some color in there is to create a palette with a few different colors and picking at random when creating a new line.</p><!--frsh-articles_code_code:24:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:24:--><!--frsh-articles_flow_fields_color_colorillustration:25:--><!--/frsh-articles_flow_fields_color_colorillustration:25:--><p>Another coloring method is by coloring each line by the angle of the noise function where the line started. This will yield a gradient like coloring across larger images.</p><!--frsh-articles_code_code:26:--><pre>[<span>object</span> <span>Object</span>]</pre><!--/frsh-articles_code_code:26:--><!--frsh-articles_flow_fields_color_colorillustration:27:--><!--/frsh-articles_flow_fields_color_colorillustration:27:--><p>Finally, my favorite method is by subdividing the canvas into a set of regions, either by some <a href="https://en.wikipedia.org/wiki/Composition_with_Red_Blue_and_Yellow">Piet Mondrian Composition style</a>, or recursively splitting the canvas into more and more refined polygons. After the canvas has been divided I assign each region a color and whenever a line spawns assign it the color of the region it spawned in.</p><p>This method creates a nice effect where things don't look as disjointed and more like streams of paint flowing into other buckets of paint.</p><!--frsh-articles_flow_fields_color_colorillustration:28:--><!--/frsh-articles_flow_fields_color_colorillustration:28:--><h2 id="conclusion">Conclusion</h2><p>Even though this article got quite long, it only scratches the surface of all the variants that can be achieved using the fundamental techniques described. I highly recommend trying things out and experimenting, swapping a <code>cos()</code> for a <code>sin()</code> somewhere, or maybe even a <code>tan()</code> if you're crazy.</p><p>Try subdividing the canvas into subregions who all have their own rules, or maybe dive deeper into noise functions. Or have a small border around the canvas and let some small percent of the lines escape it. Why use lines at all? Why not circles or squares or blobs?</p><p>Thanks for sticking in there this long, hope it was helpful.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blueprint health protocol (119 pts)]]></title>
            <link>https://protocol.bryanjohnson.com/</link>
            <guid>38839436</guid>
            <pubDate>Tue, 02 Jan 2024 08:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://protocol.bryanjohnson.com/">https://protocol.bryanjohnson.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38839436">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

			
			
			<div data-container="set" data-id="0" data-view="Content" data-set="Scaffolding">

	<div data-container="page" data-id="25025057" local-style="25025057">
			<bodycopy>
				
				<div data-elementresizer="" data-resize-parent="">
					<projectcontent><p><h2><span>DON’T DIE</span></h2></p><div><br>
<h2>BLUEPRINT STARTER KIT coming soon<br></h2>
<br>

<blockquote>
<p>Join the waitlist</p>

</blockquote>

 <div grid-row="" grid-pad="0.75" grid-gutter="1.5" grid-responsive="">
	
	<p>Two years and millions were spent developing Blueprint, an algorithm that takes better care of me than I can myself. Now, you can build your Autonomous Self as well.</p>
	
</div></div><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="7" grid-pad="2.5"><h2>MY RESULTS FROM 2 yrs of Blueprint:</h2><p>+ Slowed pace of aging by equivalent 31 years<br>+ Now accumulating aging damage slower than 88% of 18 year olds<br>
+ Body inflammation is 85% below the average 18 year old (hsCRP 0.15)&nbsp;<br>+ VO2 max: 58.7 mL/(kg·min), top 1.5% of 18 year olds<br>
+ Total Bone Mineral Density top .2% of 30 year olds<br>
<span></span>+ Perfect liver fat (1.36%, top 10%.), iron &amp; stiffness (MRI)&nbsp; <br>
+&nbsp; top 99.5% highest muscle volume<br>+ bottom 0.5% visceral fat, muscle fat, and subcutaneous fat volume <br>
+ Top 1% sleep performance &amp; recovery (whoop)<br>
+&nbsp;Possibly increased thymocyte volume to 7 yrs younger, pending further testing<br>
+ Ideal whole body muscle &amp; fat (MRI)<br>+ 50+ optimal clinical outcome biomarkers<br>+ 100+ markers &lt; chronological age<br>+ Perfect liver markers: ALT+AST+GGT = 49<br>
+ Leg press single rep max: 800 lbs. Top 1-2% of 18 yr olds.&nbsp;<br>+ Bench press single rep max: 240 lbs. Top 10% of 18 yr olds.<br>
+ 12 year age reversal in 500 day average HRV <br>
+&nbsp;Reduced Alpha Klotho biological age by 21 yrs in 5 months, from 42 to 21.<br>
+ 31 year age reversal in grey hair age (80% reduction in grey hair)<br>+&nbsp;Identified and corrected (w/o surgery) ticking time bomb: bilateral internal jugular vein (IJV) stenosis<br>
+ Brain white matter hyperintensities (WMHs) reduced by 50% (MRI)<br>
+ 30+ organ ages quantified<br>
+ Free testosterone index (FTI) biological age reduced 20 years
<br>
<span></span>+ Improved homocysteine (hcy) by 49% (5.9 umol/L).&nbsp;</p><p>

<b>“The Most Measured Man in Human History”&nbsp;</b>

<br>
<img width="370" height="134" width_o="370" height_o="134" data-src="https://freight.cargo.site/t/original/i/8802d6e65b838968a7d50b1f8131caf3328b8337812afa20f2c912015c542d3b/VICE.png" data-mid="175130292" data-scale="2" data-icon-mode="" src="https://freight.cargo.site/t/original/i/8802d6e65b838968a7d50b1f8131caf3328b8337812afa20f2c912015c542d3b/VICE.png"></p><h2>THE PHILOSOPHY POWERING THIS ENDEAVOR:&nbsp;<br></h2>&nbsp;<p><img width="1170" height="1432" width_o="1170" height_o="1432" data-src="https://freight.cargo.site/t/original/i/9b90a99ca52404cc1df9d7bd64739b57c7816bf7b9fe687133e9967fe6306620/Screen-Shot-2023-09-28-at-8.54.11-AM.png" data-mid="192152069" data-scale="27" src="https://freight.cargo.site/t/original/i/9b90a99ca52404cc1df9d7bd64739b57c7816bf7b9fe687133e9967fe6306620/Screen-Shot-2023-09-28-at-8.54.11-AM.png">
<br><b><a href="https://protocol.bryanjohnson.com/DONT-DIE-by-Zero" rel="history">READ&nbsp;→</a>&nbsp;</b>(yes, it’s free)&nbsp;</p><h2>FUN FICTION NOVEL:<br></h2>&nbsp;<p><img width="1172" height="1474" width_o="1172" height_o="1474" data-src="https://freight.cargo.site/t/original/i/7772b2410c645902af39578b8946d1d6b4ae75c3b9fe50f869b3bd50f53dd7f5/We-The-People.png" data-mid="198882833" data-scale="27" src="https://freight.cargo.site/t/original/i/7772b2410c645902af39578b8946d1d6b4ae75c3b9fe50f869b3bd50f53dd7f5/We-The-People.png">
<br><b><a href="https://protocol.bryanjohnson.com/We-the-People-by-Zero" rel="history">READ →</a> </b>(yes, it’s free) <br>
</p></div>
	<div grid-col="5" grid-pad="2.5"><p><img width="3018" height="2160" width_o="3018" height_o="2160" data-src="https://freight.cargo.site/t/original/i/0128a596fea8b3a19e55a4e16dc6deb4a4d73ff09e5550c17da7c1124b0c0b7a/Bryan-2-years-of-blueprint-with-shirt.jpg" data-mid="194940392" src="https://freight.cargo.site/t/original/i/0128a596fea8b3a19e55a4e16dc6deb4a4d73ff09e5550c17da7c1124b0c0b7a/Bryan-2-years-of-blueprint-with-shirt.jpg"><img width="3022" height="2271" width_o="3022" height_o="2271" data-src="https://freight.cargo.site/t/original/i/60d021b12d6ec7fc2b89d29f0ca5e5126765b6baf441266b5d8ff04361017121/IMG_6928.jpg" data-mid="184978714" data-scale="100" src="https://freight.cargo.site/t/original/i/60d021b12d6ec7fc2b89d29f0ca5e5126765b6baf441266b5d8ff04361017121/IMG_6928.jpg"></p></div>
</div><span></span>
<div>
<p data-gallery="%7B%22mode_id%22%3A3%2C%22gallery_instance_id%22%3A17%2C%22name%22%3A%22Justify%22%2C%22path%22%3A%22justify%22%2C%22data%22%3A%7B%22image_padding%22%3A%220.75%22%2C%22row_height%22%3A%2217%22%2C%22variation_index%22%3A%221%22%2C%22variation%22%3A50%2C%22variation_mode%22%3A1%2C%22variation_seed%22%3A2%2C%22responsive%22%3Atrue%2C%22meta_data%22%3A%7B%7D%2C%22mobile_data%22%3A%7B%22image_padding%22%3A1%2C%22row_height%22%3A60%2C%22separate_mobile_view%22%3Afalse%7D%2C%22captions%22%3Atrue%7D%7D">
<iframe frameborder="0" width="560" height="315" src="https://www.youtube.com/embed/aXdEPiFlqH8" allowfullscreen="" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" title="YouTube video player"></iframe>
<iframe frameborder="0" width="1020" height="630" src="https://www.youtube.com/embed/F_3p81GmHEg" allowfullscreen="" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" title="YouTube video player"></iframe>
</p></div><br>This website is provided for educational and informational purposes only and does not constitute providing medical advice or professional services. The information provided should not be used for diagnosing or treating a health problem or disease, and those seeking personal medical advice should consult with a licensed physician.<p><img width="2048" height="1536" width_o="2048" height_o="1536" data-src="https://freight.cargo.site/t/original/i/ccb950f44ecfceb2572a83d9ccdb7221feca4ced582754a9df68deac0372c47d/dt_gym.jpg" data-mid="159785801" src="https://freight.cargo.site/t/original/i/ccb950f44ecfceb2572a83d9ccdb7221feca4ced582754a9df68deac0372c47d/dt_gym.jpg">
<img width="800" height="640" width_o="800" height_o="640" data-src="https://freight.cargo.site/t/original/i/b4d7d275d8c02762d254ebf8ed2054bdff2c7f856af5005353bb1a5725803c1d/Damien-Maloney-2.jpeg" data-mid="166479135" src="https://freight.cargo.site/t/original/i/b4d7d275d8c02762d254ebf8ed2054bdff2c7f856af5005353bb1a5725803c1d/Damien-Maloney-2.jpeg">
<img width="1500" height="2262" width_o="1500" height_o="2262" data-src="https://freight.cargo.site/t/original/i/6f7f64b4aaa49ba322d35036571d9af017d9ecf5c1006a50859c8772d4c77a00/Bryan-Johnson_Blueprint_3.jpg" data-mid="161785916" src="https://freight.cargo.site/t/original/i/6f7f64b4aaa49ba322d35036571d9af017d9ecf5c1006a50859c8772d4c77a00/Bryan-Johnson_Blueprint_3.jpg">
<img width="1500" height="2262" width_o="1500" height_o="2262" data-src="https://freight.cargo.site/t/original/i/637ed5c885793a6d4a4758a650e5880c853fea20bcba13cecfd99ab0b2dbd635/Photo-Credit_Dustin-Giallanza_5.jpg" data-mid="166479151" src="https://freight.cargo.site/t/original/i/637ed5c885793a6d4a4758a650e5880c853fea20bcba13cecfd99ab0b2dbd635/Photo-Credit_Dustin-Giallanza_5.jpg">
</p><h2><b>Blueprint Philosophy: Zeroism</b> </h2><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="8" grid-pad="2.5"><p>20th century: Live Fast and Die Young <br>2023: don’t die because we don’t know how long and well we can live&nbsp;</p><p>

Humans used storytelling to build society: where we came from; why we’re here; what exists after death; what creates meaning; what’s right and what’s wrong. Daily health related decisions have historically been influenced by story. For example, ideological lists of what one can and cannot eat. Social norms signaling what’s fashionable. Meaning-making to inform what is desirable and laudable. </p><p>

STEM (Science, Technology, Engineering &amp; Math) offered up a new way to approach health. </p><p>

Blueprint is STEM for health. My team and I had endeavored to do what no one had ever done: enable a body to run itself. Practically, I do this by routinely taking hundreds of measurements of my body’s biological processes, enabling my heart, liver, lungs and kidneys to speak for themselves what they need to be in their ideal state. My mind - a story telling creature - is <i><b>unauthorized </b></i>to grocery shop, peruse the pantry, spontaneously order pizza, eat a dessert - to basically make any food related decision. This is my Autonomous Self. </p><p>

My practical and immediate objective is <a href="https://medium.com/future-literacy/my-goal-alignment-problem-d90e0c14b717" target="_blank">Goal Aligning</a> the 35+ trillion cells that make me who I am. Aligning, as best I can, for optimal health and youth.&nbsp;</p><p><b>wtf does any of that even mean? </b><br>This time, our time, right now - the early 21st century - will be defined by the radical evolution of intelligence: human, AI and biology. Our opportunity is to <i><b>be</b></i> this exciting future.&nbsp;</p><p>

Aspire to look and feel your very best? Opt into a system where your body + science and data do the work. It’s akin to saying yes to the internet, computers and AI to improve our lives in ways that exceed our natural abilities.&nbsp;</p><p>This Automation - and the elimination of self destructive behaviors - allows us to improve at the rate at which you can automate important functions without thinking about them - in this case, your health. Improve at the speed of compounded gains, opening up a future of possibilities more expansive than our imaginations are capable of grasping, a <a href="https://medium.com/future-literacy/zeroth-principles-thinking-9376d0b7e7f5" target="_blank">Zeroth Principle Future</a>. </p><p>Talent hits the target that no one else can (First Principles); Genius hits the target no one can see (Zeroth Principles). </p><p>Lucky us we exist; let’s play an infinite game together. </p></div>
	<div grid-col="4" grid-pad="2.5"><p><img width="964" height="736" width_o="964" height_o="736" data-src="https://freight.cargo.site/t/original/i/12e5ba90518d18efba95c70678a32e7dbd04c9bec0a80962cbab77ef1fbc4b17/Talent-and-Genius.png" data-mid="166466617" data-scale="100" src="https://freight.cargo.site/t/original/i/12e5ba90518d18efba95c70678a32e7dbd04c9bec0a80962cbab77ef1fbc4b17/Talent-and-Genius.png"><br>
“Talent hits a target no one else can hit; Genius hits a target no one else can see.” -&nbsp;Arthur Schopenhauer<br></p>
</div>
</div><hr>
<br>
<div grid-row="" grid-pad="2" grid-gutter="4" grid-responsive="">
	<div grid-col="x11" grid-pad="2"><p><b>Embrace ♥️:</b></p><ul><li>systems over willpower </li><li>data over human opinion </li><li>harmony over addiction </li><li>compounded rates of self improvement </li></ul></div>
	<div grid-col="x11" grid-pad="2"><p><b>Rebel 👿 against:</b></p><ul><li>addictive algorithms </li><li>corporate profiteering at your detriment </li><li>social norms encouraging bad behavior</li><li>self aided destruction (SAD)</li></ul></div>
</div>
<br><hr>

<br>
<h2>What WOULD The 25th Century respect?&nbsp;<br></h2>
<br><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="8" grid-pad="2.5"><p>This thought experiment cleared the fog overlaying my mind. It was 2013 and I’d just sold Braintree Venmo for $800 million in cash, achieving my goal to become independently wealthy by age 30 (I was four years late). A blazing fire had ignited within me when, from ages 19 to 21, I lived among extreme poverty in Ecuador. </p><p>

From that point on, contemplations on how to improve the future of intelligent life were constantly simmering in my mind.Flush with cash, what do I do? And more importantly, what do I not do? 99% of what happens today will be forgotten to history. The future is distant, barely audible. The present is overbearingly loud. Focus on what the 25th century would value.</p><p>

This month is my ten year anniversary check-in (the first 10 years are always the hardest):</p><p>

<b>2013 decision</b>: invest in deep tech companies making the physical world programmable. Humanity being able to program atoms, molecules, organisms, and genes as easily as computer software will open unimaginable frontiers of possibility. Essential to a sustainable biosphere and shattering the limitations of health and lifespan. Example investments <a href="https://twitter.com/Ginkgo">@Ginkgo</a> <a href="https://twitter.com/numattech">@numattech</a> <a href="https://twitter.com/justegg">@justegg</a>, <a href="https://twitter.com/VergeGenomics">@VergeGenomics</a> and <a href="https://osfund.co/portfolio-companies/" target="_blank">others.</a>&nbsp; <a href="https://t.co/N3KOhWxXgo" rel="noopener noreferrer nofollow" target="_blank"></a></p><p>

<b>2016 decision</b>: founded <a href="http://kernel.com/">@KernelCo</a> Our mental health and wellness, and the evolution of our minds, will determine whether we survive ourselves. Seven years in, we’ve built the first non-invasive neuroimaging system capable of planetary scale. What gets measured improves. Currently in clinical trials for depression and dementia.</p><p>

<b>2020 decision</b>: Founded Blueprint to explore a defining question of our time: is death inevitable? Created, and made free for all, potentially the most powerful health protocol in history?</p><p>

<b>2023 decision</b>: DON’T DIE, the rallying cry of the 21st century. <br>Don’t:
<br>
… die;
<br>
… kill each other;<br>
… destroy our biosphere;
<br>
… underestimate the importance of aligning with AI.</p><p>

After billions of years of evolutionary advance, we are on the cusp of what could be the most extraordinary existence in the galaxy.&nbsp; May we have the courage and wisdom to believe that now is the very beginning.</p></div>
	<p><img width="2000" height="1500" width_o="2000" height_o="1500" data-src="https://freight.cargo.site/t/original/i/af154581486ad6e13ea91f3ef4060ae718274fb30bc0e17b4559d8ec172718d2/20230912BryanJohnson6351.JPG" data-mid="194939498" data-scale="100"></p>
	
</div><hr><br>
<h2>Does Blueprint work? Here is my data after 18 months of adherence</h2><br>
<b>OPTIMAL CLINICAL OUTCOME RANGE</b><br>
<div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5"> <table><tbody><tr><td>BIOMARKER&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>&nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>RESULT&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>AGE EQUIVALENT&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>OPTIMAL CLINICAL OUTCOMES&nbsp; RANGE (OCOR)</td></tr><tr><td>ALT</td><td><span>OPTIMAL</span></td><td>18</td><td> </td><td>&lt;15</td></tr><tr><td>BMI</td><td><span>OPTIMAL</span></td><td>22.8</td><td> </td><td>&lt;22.5</td></tr><tr><td>Fasting plasma glucose</td><td><span>OPTIMAL</span></td><td>82</td><td>28 (max reduction)</td><td>&lt;95</td></tr><tr><td>Body Fat</td><td><span>OPTIMAL</span></td><td>6.9</td><td>16 (max reduction)</td><td>&lt;10%</td></tr><tr><td>Cholesterol (total)</td><td><span>OPTIMAL</span></td><td>158</td><td> </td><td> </td></tr><tr><td>DHEA</td><td><span>OPTIMAL</span></td><td>310</td><td>25 (max reduction)</td><td>&lt; age 50</td></tr><tr><td>Free Testosterone Index </td><td><span>OPTIMAL</span></td><td>0.4</td><td>41</td><td>&lt; age 50</td></tr><tr><td>GGT</td><td><span>OPTIMAL</span></td><td>10</td><td> </td><td>&lt;14</td></tr><tr><td>Glutathione </td><td><span>OPTIMAL</span></td><td>227</td><td>29</td><td>&lt; age 30</td></tr><tr><td>Grip Strength Dominant</td><td><span>OPTIMAL</span></td><td>134</td><td>33 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>Grip Strength Non-dominant</td><td><span>OPTIMAL</span></td><td>124</td><td>43 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>HbA1C</td><td><span>OPTIMAL</span></td><td>4.5</td><td>28 (max reduction)</td><td>4.5-5.6</td></tr><tr><td>HDL</td><td><span>OPTIMAL</span></td><td>73</td><td> </td><td>50 - 60</td></tr><tr><td>hsCRP</td><td><span>OPTIMAL</span></td><td>0.20</td><td>10 (max reduction)</td><td>&lt;0.55</td></tr><tr><td>IGF-1</td><td><span>OPTIMAL</span></td><td>151</td><td> </td><td>75 - 150</td></tr><tr><td>LDL</td><td><span>OPTIMAL</span></td><td>74</td><td> </td><td>&lt; 100</td></tr><tr><td>NAD</td><td><span>OPTIMAL</span></td><td>52.6</td><td>16 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>PSA</td><td><span>OPTIMAL</span></td><td>0.68</td><td>22 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>RDW</td><td><span>OPTIMAL</span></td><td>11.3</td><td>18 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>SHBG</td><td><span>OPTIMAL</span></td><td>68</td><td> </td><td> </td></tr><tr><td>TSH</td><td><span>OPTIMAL</span></td><td>1.94</td><td> </td><td>1 - 2.1</td></tr><tr><td>Triglycerides </td><td><span>OPTIMAL</span></td><td>55</td><td> </td><td>27 - 89</td></tr><tr><td>Testosterone </td><td><span>OPTIMAL</span></td><td>769</td><td>33 (max reduction)</td><td> </td></tr><tr><td>VO2 max treadmill</td><td><span>OPTIMAL</span></td><td>53.6</td><td>18 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>WBC</td><td><span>OPTIMAL</span></td><td>4.5</td><td> </td><td>3.5 - 6</td></tr><tr><td>20th percentile telomeres PBMC</td><td><span>OPTIMAL</span></td><td>7</td><td>28 (max reduction)</td><td>&lt; age 30</td></tr></tbody></table></div><hr>
<br><hr><br>
<h2>Blueprint Principles</h2><p>
For thousands of years, the human experience has been roughly the same. &nbsp;Things are about to change, and radically. Blueprint is about riding the torrid waves of technological and scientific progress into the future.&nbsp;</p><p>Principle 1: Self destructive behavior is kinda insane<br>
Principle 2: Empower your body to speak for itself&nbsp;<br>
Principle 3: The aspirations we need are beyond our imagination&nbsp;<br>
Principle 4: Look in the darkness to avoid being blinded by the light</p><h2>Principle 1: self destructive behavior is kinda insane&nbsp;<br></h2>
<br><div grid-col="8" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><p>Isn’t it weird that we commit the same self destructive behaviors hundreds or even thousands of times in a lifetime? Even when we know they shorten our life, accelerate disease and aging, cloud our judgement and make us feel miserable.&nbsp;</p><p>

Maybe this behavior is a little embarrassing as the self proclaimed most intelligent species on this planet? &nbsp;</p><p>

What if we didn’t commit self harm? What if it wasn’t normalized and gleefully blessed and encouraged by society?&nbsp;</p><p>

If you’d like to stop this insanity...:identify the worst version of yourself. For me, it was 7pm Bryan who would eat everything in sight to try and momentarily escape life pain. He is a monster, overpowering, and indifferent about all other Bryans needs. A sweet talker and expert rationalizer.&nbsp; 7pm Bryan ruins life quality for all other Bryans: </p><ul><li>awful sleep</li><li>overweight</li><li>poor health</li><li>accelerated aging &amp; disease </li><li>turbulent emotions</li><li>depressing life outlook</li></ul><p>The solution: revoking 7pm Bryan’s authority to eat food.</p><p>Now your turn: </p><ul><li>Step 1: identify your 20% rascal.. <br></li><li>Step 2: list what decisions they are and are not authorized to make<br></li><li>Step 3: wait for them to appear <br></li><li>Step 4: approve or deny their requests using step 2 list&nbsp; <br></li><li>Step 5: celebrate happy you for stopping self harm.<br></li></ul>
<p>Believe it or not, this is your most consequential and powerful life intervention.&nbsp;<br>
</p></div>
<h2>Principle #2: Empower your body to speak for itself</h2>What and when I eat is decided by asking my heart, liver, lungs and my other 70+ organs what they need to be optimal. This is done by doing hundreds of organ measurements on a regular basis and then carefully analyzing gold standard scientific evidence. <p>
My mind is demoted, Self is elevated. </p><p>

Allowing our minds to do whatever it wants, whenever it wants, and offering any explanation it wants is a bedrock of our reality. So firmly rooted that it’s beyond most of our imaginations that it would be checked by any other system of decision making.&nbsp;</p><p>

Blueprint takes better care of me than I was ever able. It will for you too.&nbsp;</p><h2>Principle #3: The aspirations we need are beyond our imaginations&nbsp;</h2><br>
It would have been hard to predict the books that would be written with the introduction of the printing press; or what the internet would enable. The same principle applies to what the human race can become when paired with the torrid wave of technological and scientific progress. We can take baby steps as we work on stretching our imaginations:&nbsp;<ul><li> Week 1: drink the Green Giant (GG) daily. <br></li><li>
Week 2: GG + Super Veggie (SV) daily.<br></li><li>
Week 3: GG + SV + Nutty Pudding (NP) daily. <br></li><li>
Week 4: GG + SV + NP + supplements daily.<br></li></ul>
 [<a href="https://protocol.bryanjohnson.com/Step-1-Step-2-Step-3" rel="history">Recipes</a>]<h2>Principle 4: Look in the Darkness to avoid being blinded by the light&nbsp;</h2><br>
A person is looking for their keys under a street light. Someone walks by and inquires, “Are you certain you lost your keys here?”<p>

“No” they reply, “I lost them across the street.”</p><p>

Confused, the stranger says, “Then why are you looking here?”</p><p>

They responded, “The light is much brighter here!”
</p><p>

#</p><p>
Common reactions to Blueprint: </p><ul><li>Bryan, you are surely miserable</li><li>It would be hilarious if Bryan got hit by a bus, lol&nbsp; </li><li>I’d rather die than eat veggies, berries and nuts </li><li>This is dystopic </li><li>I wish u knew my joy of pizza + donuts</li></ul><br>
Or, maybe is it? <br>
<ul><li>I have no control over myself&nbsp;</li><li>Change is hard for me</li><li>I am scared of being left behind</li><li>I’m addicted to self sabotage</li><li>Without unlimited choice to do whatever I want, existence doesn’t make sense to me </li></ul><br>
I hear you. I’ve been there. Felt and thought all these things. <p>

We all know this: no one wants to be sick, diseased and sad. We all want exceptional health and vibrancy.&nbsp;</p></projectcontent>
				</div>

				<svg width="1" height="1" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg">
 <!-- Created with SVG-edit - https://github.com/SVG-Edit/svgedit-->
 <g transform="translate(26.16015625, 117.83869171142578)">
  <title></title>
 </g>
</svg>
			</bodycopy>
		</div>

			
	<div data-container="page" data-id="25025058" local-style="25025058">
			<bodycopy>
				
				<div data-elementresizer="" data-resize-parent="">
					<projectcontent><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<p grid-col="x12" grid-pad="2.5"><h2 id="blueprint-starter-guide">Blueprint Protocol Starter Guide</h2></p>
</div><br>
<div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><p><sup>This web site is provided for educational and informational purposes only and does not constitute providing medical advice or professional services. The information provided should not be used for diagnosing or treating a health problem or disease, and those seeking personal medical advice should consult with a licensed physician.</sup></p><h2>Contents</h2><blockquote><a href="#by-the-numbers">Blueprint by the numbers &nbsp;</a></blockquote><blockquote><a href="#step-1-meal-prep"><b>Step 1</b>: Meal preparation </a><br></blockquote>
<blockquote><ul><li><a href="#the-green-giant">The Green Giant</a></li><li><a href="#super-veggie">Super Veggie</a></li><li><a href="#nutty-pudding">Nutty Pudding</a></li><li><a href="#example-third-meals">Example third meals</a></li><li><a href="#extra-virgin-olive-oil">Extra Virgin Olive Oil&nbsp;</a></li><li><a href="#extra-virgin-olive-oil"></a><a href="https://www.santabarbarachocolate.com/?ref=vysHWo_Vh7aJ_L" target="_blank">Dark Chocolate&nbsp;</a></li></ul><a href="https://protocol.bryanjohnson.com/#step-2-supplements"><b>Step 2:</b> Supplements</a></blockquote><blockquote><b>Step 3</b>: Starter Items (stuff I use, not endorsements)&nbsp;</blockquote><ul><ul><li><a href="https://amzn.to/3pMs2VI" target="_blank">Withings scale</a></li><li><span><a href="https://talktoadam.com/adam-sensor-blueprint" target="_blank">Measure night time erections</a></span></li><li><span><a href="https://talktoadam.com/adam-sensor-blueprint" target="_blank"></a></span><a href="https://bit.ly/gr7_blueprint" target="_blank">Grey hair reversal</a><span> (7% discount “BLUEPRINT”)</span></li><li><a href="https://trudiagnostic.com/discount/BryanJohnson?redirect=%2Fproducts%2Ftruage-complete-epigenetic-collection" target="_blank">Pace of Aging Test</a><span> (includes 12% discount)&nbsp;</span></li><li><a href="https://www.jinfiniti.com/product/intracellular-nad-test/" target="_blank">NAD test</a> (5% discount&nbsp;“blueprint”)</li><li><a href="http://join.whoop.com/blueprint" target="_blank">
Whoop</a> Track fitness &amp; sleep. First month free.&nbsp;<br></li><li><a href="https://amzn.to/40yxcAY" target="_blank">
Grip Strength Trainer</a></li><li><a href="https://recharge.health/product/the-flexbeam?ref=chV07PDvFPVb26&amp;utm_source=go_aff_pro" target="_blank">
Flex Beam</a> - red light therapy&nbsp;</li><li><a href="https://eight-sleep.ioym.net/DKyNrq" target="_blank">
EightSleep Mattress</a>&nbsp; ($100 discount “BLUEPRINT“)</li><li><a href="https://amzn.to/3Mt8LB5" target="_blank">Pillow&nbsp;</a></li><li><a href="https://amzn.to/41S9P5U" target="_blank">Grounding bed sheets</a></li><li><a href="https://amzn.to/41S9P5U" target="_blank"></a><span>(HRV) </span><a href="https://www.getsensate.com/blueprint" target="_blank">Sensate</a><span> (10% discount “Blueprint”)</span></li><li>(HRV)&nbsp;<a href="https://nurosym.com/discount/BLUEPRINT?redirect=%2Fproducts%2Fnurosym" target="_blank">Nurosym</a>&nbsp;(10% discount “Blueprint”)</li><li>(HRV)&nbsp;<a href="https://pulsetto.tech/ref/Bryan10/" target="_blank">Pulsetto</a>&nbsp;(10% discount “Blueprint”)&nbsp;</li><li><a href="https://foodmarble.com/shop/?discount_code=BRYANJ" target="_blank">Food intolerance testing</a> (15% discount)</li><li><a href="https://amzn.to/3IFnVkl" target="_blank">Pill tins</a></li><li><a href="https://www.levelshealth.com/join?partner=BRYAN&amp;campaignid=36303&amp;utm_source=partner&amp;utm_medium=all-channels&amp;utm_campaign=bryan-johnson" target="_blank">Blood glucose measurement</a></li><li>Bedroom blackout <a href="https://amzn.to/3Pgi7lp" target="_blank">film</a>&nbsp;</li><li><a href="https://amzn.to/42ZGy9Y" target="_blank">Light therapy</a> first thing in the am&nbsp;</li></ul></ul><br>
<blockquote><a href="#step-4-measurements"><b>Step 4:</b> Track progress with measurement<br></a></blockquote><h2 id="by-the-numbers">BY THE NUMBERS</h2><p>Monthly Blueprint cost = $1,684.50&nbsp;<br>
Daily Calories = 2250</p></div><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x8" grid-pad="2.5"><p><b>Food Costs</b> <br>$44.91 / day (vary by geography) </p><ul><li>The Green Giant: $9.91</li><li>Super Veggie: $11</li><li>Nutty Pudding: $11</li><li>Third meal: $11</li><li>Other: $2 (i.e. <a href="https://blueprint.bryanjohnson.co/" target="_blank">extra virgin olive oil</a>, brazil nuts)<br></li></ul></div>
	<div grid-col="x8" grid-pad="2.5"><p><b>Supplements Costs</b> <br>
$11.24 / day </p><ul><li>Morning: $5.76</li><li>Dinner: $5.48</li></ul></div>
	<div grid-col="x8" grid-pad="2.5"><p><b>Kitchen Readiness Costs</b><br>(one time cost)<br>Total approx ~$500</p><ul><li>High speed blender </li><li>Food scale </li><li>Storage/Transport&nbsp; </li><ul><li>Glass (<a href="https://amzn.to/3zSAzYJ" target="_blank">small</a>, <a href="https://amzn.to/3MKpdxo" target="_blank">large</a>), $100</li><li><a href="https://amzn.to/41kZLT6" target="_blank">Stainless steel</a>, $200</li></ul></ul></div>
	<div grid-col="x8" grid-pad="2.5"><p><b>Initial Test Costs</b><br>(every 3 to 6 mths)<br>
<span>Total: ~$350</span></p><ul><li>Blood panel</li></ul></div>
	
</div><br></projectcontent>
				</div>

				
			</bodycopy>
		</div>

			
	<div data-container="page" data-id="25026880" local-style="25026880">
			<bodycopy>
				
				<div data-elementresizer="" data-resize-parent="">
					<projectcontent><span id="step-1-meal-prep"></span>
<br><div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2>Step 1: Meal Prep</h2><p>

Three meals daily: Super Veggie and Nutty Pudding, and a third that varies and consists of vegetables, nuts, seeds, and berries. Each has been methodically crafted based on gold standard scientific evidence for optimal nutrition. They continue to be modified at the introduction of new evidence.</p></div><span id="blueprint-recipe-guide"></span><br><h2><span><b><a href="https://protocol.bryanjohnson.com/Recipe-Guide-by-Zero" rel="history">Blueprint Recipe GUIDE&nbsp;→</a></b></span></h2>(yes, it’s free)<h2><b>A DAY’S WORTH OF FOOD:</b><br></h2>
<br><img width="6480" height="4320" width_o="6480" height_o="4320" data-src="https://freight.cargo.site/t/original/i/1a97d4d1cf5b9bd35773f6cfe82f30749f899374072dca4cb86d061bcfe1b59e/Photo-Credit_Bryan-Johnson_All_Blueprint_Food_5.jpg" data-mid="166716432" data-scale="98" src="https://freight.cargo.site/t/original/i/1a97d4d1cf5b9bd35773f6cfe82f30749f899374072dca4cb86d061bcfe1b59e/Photo-Credit_Bryan-Johnson_All_Blueprint_Food_5.jpg"><div grid-col="7" grid-pad="2" id="the-green-giant" grid-row="" grid-gutter="4" grid-responsive=""><h2><b>Note: discontinued Green Giant 10/23</b></h2><ul><li>More of a reorganization of what goes where.&nbsp;</li><li>Amino acids are discontinued. Protein intake is adequate.&nbsp;</li><li>Added spermidine (that was in the chlorella powder) to pills.</li><li><a href="https://amzn.to/475i69G" target="_blank">Cocoa flavanols</a> are in Nutty Pudding<br>
</li><li>I continue to take 25 g of <a href="https://amzn.to/3S8gyaR" target="_blank">collagen peptides</a> and 2.5 g of <a href="https://amzn.to/3QuQFkh" target="_blank">creatine</a> daily. Can add the collagen peptides to Nutty Pudding as is tasteless and adds a fun texture.&nbsp;</li><li>We’ve dramatically simplified the Blueprint stack so you don’t have to chase around all of details. Launch ETA is January 2024.&nbsp;</li></ul></div><hr><br>
<div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="7" grid-pad="2.5" id="super-veggie"><h2><b>Super Veggie</b></h2>
 

<ul><li><a href="https://amzn.to/45EX8hG" target="_blank">Black lentils,</a> 45 grams dry, ~150 grams cooked<br></li><li>Broccoli (head+stalk), 250 grams&nbsp;<br></li><li>Cauliflower. 150 grams&nbsp;</li><li>Shiitake or Maitake Mushrooms, 50 grams&nbsp;<br></li><li>Garlic, 1 clove (a piece)<br></li><li>Ginger Root, 3 grams&nbsp;<br></li><li>
Lime, 1 <br></li><li>Cumin, 1 Tbsp</li><li>Apple Cider Vinegar, 1 Tbsp<br></li><li>Hemp Seeds, 1 Tbsp
</li><li>After prep, drizzle 1 Tbsp of <a href="https://blueprint.bryanjohnson.co/" target="_blank">Extra Virgin Olive Oil&nbsp;</a></li></ul><p>Recently been sprinkling 1 Tbsp of <a href="https://www.santabarbarachocolate.com/?ref=vysHWo_Vh7aJ_L" target="_blank">100% dark chocolate</a> to dish<br>
(All organic)</p><p>
<b>Super Veggie Preparation instructions</b></p><ul><li>Weigh vegetables. Place broccoli, cauliflower, mushrooms (maitake or shiitake), ginger and garlic in boiling water*. Boil until tender (7-9 min). Steaming is also acceptable. </li><li>Lentils: bring the water to boil in a medium saucepan. Add lentils. Reduce heat to low and cook uncovered for 18-20 or minutes until "al dente". Place in a colander to drain and rinse under cold water<br></li><li>You can choose to blend or keep whole pieces. </li><li>Blend in a high-speed blender place 1 Tbsp of dried cumin, 1 Tbsp of apple cider vinegar, 1 fresh Lime, cooked black lentils, the strained cooked vegetables, and blend until it becomes thick soup. Can also serve as the picture above. </li><li>If needed add some of the vegetable water (or steaming water) to thin out the texture. </li><li>Top with hemp seeds.</li></ul><p>Prepared correctly, taste should be an easy and smooth tasting veggie hummus. No smell/taste of garlic. </p><p>I season it with <a href="https://amzn.to/3KVhqM2" target="_blank">NuSalt</a> (potassium chloride).&nbsp; </p><p>
*Cooked via low temperature, high humidity, high acidity, high antioxidant cooking methods to minimize formation of Advanced Glycation End-products (AGEs) and Advanced Lipid Peroxidation End-products (ALEs).</p><p><i>A note on Super Veggie taste. The food I eat is delicious to me; one of the most exciting moments of my day. Both my teenage boys, mother, father, and brother eat the same foods daily and they love them too. When starting, sometimes there is a period of adaptation and some want to play with the recipe and texture. </i></p><p>
 Blueprint breaks all kinds of social norms which predictably triggers human responses that draw those lines. My favorite: my 16 yr old eats Super Veggie for school lunch. His friend offering his observations 😂
</p></div>
	<div grid-col="5" grid-pad="2.5"><p>Super Veggie ready to serve&nbsp;<br>
<img width="4320" height="4320" width_o="4320" height_o="4320" data-src="https://freight.cargo.site/t/original/i/6dda6f6bfcd638f6ac15906a7390bf93ffd51096fd39b9e9256819887657e8f7/Photo-Credit_Bryan-Johnson_Super-Veggie_Blueprint_Food_Non-Blended.jpg" data-mid="166716671" src="https://freight.cargo.site/t/original/i/6dda6f6bfcd638f6ac15906a7390bf93ffd51096fd39b9e9256819887657e8f7/Photo-Credit_Bryan-Johnson_Super-Veggie_Blueprint_Food_Non-Blended.jpg"><br>
Super Veggie hummus w/ olive oil &amp; chocolate...</p><p>

<img width="1462" height="1462" width_o="1462" height_o="1462" data-src="https://freight.cargo.site/t/original/i/cab747ece8aaa309332d4d2c96fa21462a92b0a1de5e6dd751a2651661a37127/Screen-Shot-2023-01-30-at-8.39.17-PM.png" data-mid="166716534" src="https://freight.cargo.site/t/original/i/cab747ece8aaa309332d4d2c96fa21462a92b0a1de5e6dd751a2651661a37127/Screen-Shot-2023-01-30-at-8.39.17-PM.png"></p><p>

<img width="973" height="975" width_o="973" height_o="975" data-src="https://freight.cargo.site/t/original/i/34cd9f12bec54b4def8b8faa7587034e67b42b40e1cae62e835cded0bb47a6b5/super-veggie-with-chicken.jpg" data-mid="185750060" src="https://freight.cargo.site/t/original/i/34cd9f12bec54b4def8b8faa7587034e67b42b40e1cae62e835cded0bb47a6b5/super-veggie-with-chicken.jpg"><br>
<img width="596" height="866" width_o="596" height_o="866" data-src="https://freight.cargo.site/t/original/i/5d38517f649570f95f61b05aa5106274b37ef898e8771fdf56614fe152e8c27b/Super-Veggie_Nutrition.png" data-mid="172755506" data-scale="55" src="https://freight.cargo.site/t/original/i/5d38517f649570f95f61b05aa5106274b37ef898e8771fdf56614fe152e8c27b/Super-Veggie_Nutrition.png"></p></div>
</div><hr><br>
<div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	
	<p><img width="4320" height="4320" width_o="4320" height_o="4320" data-src="https://freight.cargo.site/t/original/i/e28582a4963f320e39d7364ad77b24623be189fd7041d9720ac10f0d62fcb864/Photo-Credit_Bryan-Johnson_Nutty-Pudding_Blueprint_Food.jpg" data-mid="166716802" src="https://freight.cargo.site/t/original/i/e28582a4963f320e39d7364ad77b24623be189fd7041d9720ac10f0d62fcb864/Photo-Credit_Bryan-Johnson_Nutty-Pudding_Blueprint_Food.jpg"></p>
</div><br><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="7" grid-pad="2.5"><p><b>Nutty Pudding Preparation instructions</b></p><ul><li>Add 50-100 mL milk nut based upon desired consistency. </li><li>Add walnuts, macadamia nuts, ground flax seeds (highest nutritional value to buy seeds and grind)&nbsp; </li><li>Add cocoa, sunflower lecithin, cinnamon</li><li>Add 3 cherries, 1/2 cup of berries (save half for topping) &amp; pomegranate juice&nbsp;</li><li>Mix on high for 3 or 4 minutes</li><li>Pour into a dish. </li><li>Add the rest of the berries</li><li>Typically will also add 30-60 grams of pea protein</li></ul><p>If you want to go wild, you can add a Tbsp of sweetener Trehalose and a Tbsp of Manuka honey.<br></p></div>
	<p><img width="604" height="1134" width_o="604" height_o="1134" data-src="https://freight.cargo.site/t/original/i/00d523f48c6bab2da6eece423b503b075d947938bbfe9dd5192523f12d946870/Nutty-Pudding-7.24.23.png" data-mid="185951633" data-scale="74" src="https://freight.cargo.site/t/original/i/00d523f48c6bab2da6eece423b503b075d947938bbfe9dd5192523f12d946870/Nutty-Pudding-7.24.23.png"></p>
</div>
<br><hr>
<br><h2><b>Example Third Meals</b><br></h2>
<br><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	
	<p><b>Asparagus Almond Beet Salad, 500 cal <br></b>Beets				500 grams cooked<br>Asparagus 			300 grams cooked<br>Almonds Slivers 		21 grams<br>Arugula			1 cup<br>Shallot				1 large<br>Balsamic			3 Tablespoons<br>Dijon				3 Tablespoons<br>Mustard Seeds		1 Tablespoons<br><b></b><br></p>
	<div grid-col="7" grid-pad="2.5"><p><b>Asparagus Almond Beet Salad Preparation Instructions</b><br>Trim and clean beets. Boil in water till the beets can be easily pierced with a fork. Drain and while still warm, the skin will rub off easily underwater. Set aside the skinless beets in a bowl.</p><p>
Blanch Asparagus - Set aside a bowl of ice water. Heat a large saucepan of water till boiling. Add Asparagus to the boiling water for 4 minutes. It may be shorter or larger boiling times depending on the size of the stalks. Once asparagus is firm but not crisp, remove it from boiling water and dump it into the ice bath. Once asparagus is cool. Drain and take a paper towel to blot any excess water away.</p><p>
In another heated pan, add the mustard seeds to a dry pan for one minute. After one minute add sliced shallots and one-fourth cup of water. Cook shallots and mustard seeds down until the shallots are transparent. Add more water if needed.</p><p>
In a small bowl add the balsamic and the dijon and blend well.</p><p>
Once everything is assembled and cooled to room temperature. Chop the beets and asparagus into small bite-sized pieces. Add the cooled shallots mixture. Add in chopped arugula and toss lightly. Once lightly tossed pour dressing over and toss lightly again. Top the salad with slivered almond</p></div>
</div>
<div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	
	 <p><b>Orange Fennel Salad, 500 calories</b> <br>Cara Cara Orange		1 segmented orange<br>Fennel				¼ cup shredded<br>Goji Berries			30 grams<br>Pecans			30 grams<br>Grape Tomatoes		14 <br>Spring Mix			3 cups<br>Arugula Leaf or Sprouts	1 cup<br>Fresh Mint			¼ cup<br>Fig Balsamic Vinegar		2 Tablespoon</p>
	<p><b>Orange Fennel Salad Preparation Instructions</b><br>Gather ingredients. Segment the orange. Shred the fennel on a grater. Toss in greens, torn mint leaves, fennel, grape tomatoes, top with chopped pecans, and goji berries. Right before serving add fig balsamic dressing.</p>
</div>
<div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	
	<p><b>Stuffed Sweet Potato, 500 calories</b><br>Sweet Potato			300 grams cooked<br>Chickpeas			45 grams cooked<br>Grape Tomatoes		12 <br>Avocado			½ <br>Radishes			4<br>Cilantro			¼ cup<br>Jalapeno Pepper		1 large<br>Limes				2 whole<br>Lemon				1 whole<br>Chile Powder			1 Teaspoon</p>
	<div grid-col="7" grid-pad="2.5"><p><b>Stuffed Sweet Potato Preparation Instructions</b><br>Roast the sweet potato until you can puncture it with a fork. While the potato is roasting, place chickpeas in a bowl. Add the juice of half of a lemon and the chile powder and set aside to marinate. </p><p>
On a sheet pan, roast the grape tomatoes until they have popped and have a bit of color.<br>Add to a small bowl the avocado mash with the juice of one lime and half of a lemon. Stir until creamy.<br>Thinly slice the radishes and the jalapeno pepper. </p><p>
Once everything is roasted. Build your dish. Start with the potato, slice open. Remove skin if preferred. Pour the chickpea mixture over the sweet potato, next add roasted grape tomatoes and some jalapenos. Top with avocado mixture, chopped fresh cilantro, radishes, and the remainder of jalapeno peppers. Serve with sliced lime on the side.</p></div>
</div>
<h2><b>Extra Virgin Olive Oil</b></h2>


<p>

<b>Fun fact: </b>on Blueprint, you’ll eat over 70+ lbs of veggies, berries and nuts per month</p><p>
<img width="1262" height="634" width_o="1262" height_o="634" data-src="https://freight.cargo.site/t/original/i/77097bca9a37a63d68d0cc23f8645ea5dad71d2fab4494d33e64b6b08a947feb/Screen-Shot-2022-04-01-at-4.34.50-AM.png" data-mid="138278159" data-scale="61" src="https://freight.cargo.site/t/original/i/77097bca9a37a63d68d0cc23f8645ea5dad71d2fab4494d33e64b6b08a947feb/Screen-Shot-2022-04-01-at-4.34.50-AM.png"></p><p><img width="4320" height="4320" width_o="4320" height_o="4320" data-src="https://freight.cargo.site/t/original/i/459fda3bfb4be536cd1fa954930987e1eee67a3a7bd22591d18969cfd4dd1312/Photo-Credit_Bryan-Johnson_Varied-Meal-Example_Blueprint_Food.jpg" data-mid="166716956" src="https://freight.cargo.site/t/original/i/459fda3bfb4be536cd1fa954930987e1eee67a3a7bd22591d18969cfd4dd1312/Photo-Credit_Bryan-Johnson_Varied-Meal-Example_Blueprint_Food.jpg">
<img width="4320" height="4320" width_o="4320" height_o="4320" data-src="https://freight.cargo.site/t/original/i/75560daa0d2844b0d914af2a41c088f73384d1db4bdbd33e1e7656edf3973aff/Photo-Credit_Bryan-Johnson_Super-Veggie_Blueprint_Food_Blended.jpg" data-mid="166716957" src="https://freight.cargo.site/t/original/i/75560daa0d2844b0d914af2a41c088f73384d1db4bdbd33e1e7656edf3973aff/Photo-Credit_Bryan-Johnson_Super-Veggie_Blueprint_Food_Blended.jpg">
<img width="1150" height="1428" width_o="1150" height_o="1428" data-src="https://freight.cargo.site/t/original/i/9d13feccc5aa99a9f85b166101ec9e3b01b18e00d2f37fb8e7a26425c0b6016b/Screen-Shot-2023-01-30-at-8.47.24-PM.png" data-mid="166716978" src="https://freight.cargo.site/t/original/i/9d13feccc5aa99a9f85b166101ec9e3b01b18e00d2f37fb8e7a26425c0b6016b/Screen-Shot-2023-01-30-at-8.47.24-PM.png">
<img width="1872" height="1234" width_o="1872" height_o="1234" data-src="https://freight.cargo.site/t/original/i/7fb3e488096a0874e568d0a76899c06e85f9507b183ddf85194d54e9dfd58c53/Screen-Shot-2023-01-30-at-8.47.54-PM.png" data-mid="166716977" src="https://freight.cargo.site/t/original/i/7fb3e488096a0874e568d0a76899c06e85f9507b183ddf85194d54e9dfd58c53/Screen-Shot-2023-01-30-at-8.47.54-PM.png">
<img width="4320" height="6000" width_o="4320" height_o="6000" data-src="https://freight.cargo.site/t/original/i/042d50e127ea8526e0f83cca84d2c7e8e2e461ef3a4de44419fd166c90bb3e0d/Photo-Credit_Bryan-Johnson_Green-Giant_Blueprint_Food_4.jpg" data-mid="166716958" src="https://freight.cargo.site/t/original/i/042d50e127ea8526e0f83cca84d2c7e8e2e461ef3a4de44419fd166c90bb3e0d/Photo-Credit_Bryan-Johnson_Green-Giant_Blueprint_Food_4.jpg">
<img width="1150" height="1724" width_o="1150" height_o="1724" data-src="https://freight.cargo.site/t/original/i/bcb76d5f4af8017f84c7eaf98281fcff882aa616dceb47c9983ed938b4519693/Screen-Shot-2023-01-30-at-8.47.15-PM.png" data-mid="166716976" src="https://freight.cargo.site/t/original/i/bcb76d5f4af8017f84c7eaf98281fcff882aa616dceb47c9983ed938b4519693/Screen-Shot-2023-01-30-at-8.47.15-PM.png">
</p><hr><h2>Step 2: Supplements</h2>
<br>
<div grid-col="6" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><br>
<div><p>
Note: this protocol is based upon regular measurements. Optimal protocol for you may differ. <a href="https://youtu.be/F_3p81GmHEg?t=375" target="_blank">How I organize them</a>.<br>
</p></div></div><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x9" grid-pad="2.5"><p><b>Upon waking</b></p><ul><li>Acarbose 200 mg (Rx)</li><li><a href="https://amzn.to/3XbnJzv" target="_blank">Ashwagandha</a> 600 mg</li><li><a href="https://amzn.to/477qYfD" target="_blank">Astaxanthin</a> 12 mg</li><li><a href="https://amzn.to/3MJUssr" target="_blank">B Complex</a> .50 pill Mon &amp; Thus (1/2 pill, twice a wk)</li><li><a href="https://amzn.to/45jdkVp" target="_blank">Boron</a> 2 mg</li><li><a href="https://amzn.to/3oa4ybQ" target="_blank">BroccoMax</a> 17.5mg<br>
</li><li><a href="https://amzn.to/46i2Lmz" target="_blank">C</a> 500mg</li><li><a href="https://vitality-pro.com/?ref=projectblueprint" target="_blank">Ca-AKG</a> 1 gram</li><li><a href="https://amzn.to/3RoMGXw" target="_blank">Cocoa Flavanols</a> 500 mg</li><li><a href="https://amzn.to/44oMGdk" target="_blank">CoQ10</a> 100 mg</li><li><a href="https://amzn.to/41nrVwW" target="_blank">D-3</a> 2,000 IU</li><li><a href="https://amzn.to/3Pg8GCz" target="_blank">DHEA</a> 25 mg</li><li><a href="https://amzn.to/43JXcvv" target="_blank">E </a>67 mg</li><li><a href="https://amzn.to/3mq7Wz3" target="_blank">EPA</a> 500mg&nbsp;</li><li><a href="https://timehealth.co.uk/product/fisetin/" target="_blank">Fisetin</a> 200 mg</li><li><a href="https://amzn.to/3ogmf9y" target="_blank">Garlic</a> 2.4 g equivalent</li><li><a href="https://amzn.to/3GGs6vf" target="_blank">Garlic</a> 1.2 g (kyolic) </li><li><a href="https://amzn.to/3YhL0QO" target="_blank">Genistein</a> 125 mg</li><li><a href="https://amzn.to/3UBJYgw" target="_blank">Ginger Root</a> 2.2 g</li><li><a href="https://amzn.to/3MGtrWH" target="_blank">Glucosamine Sulphate 2KCL</a> 1500 mg</li><li><a href="https://amzn.to/40XM1Ox" target="_blank">Iodine as potassium iodide</a> 125 mcg&nbsp;</li><li><a href="https://amzn.to/439rUgx" target="_blank">K2-MK4,</a> 5 mg</li><li><a href="https://amzn.to/43dZaTO" target="_blank">K1,</a> 1.5 mg</li><li><a href="https://amzn.to/3XLzQUb" target="_blank">K2 MK-7 &nbsp;600 mcg</a></li><li><a href="https://amzn.to/3mrGFw7" target="_blank">Lithium</a> 1 mg</li><li><a href="https://amzn.to/3UD2gOz" target="_blank">Lycopene</a> 10 mg</li><li><a href="https://amzn.to/43xTEwE" target="_blank">Lysine</a> 1 g</li><li>Metformin ER 1,500 mg (Rx)</li><li><a href="https://amzn.to/3zSBGYp" target="_blank">Nicotinamide Riboside</a> 375 mg (6 x wk)<br>
</li><li><a href="https://amzn.to/3UyP9hk" target="_blank">N-Acetyl-L-Cysteine</a> (NAC) 1,800 mg<br></li><li><a href="https://amzn.to/3UQdijG" target="_blank">Proferrin</a> 10 mg</li><li>Spermidine 10 mg</li><li><a href="https://amzn.to/3KXHztt" target="_blank">Turmeric</a>&nbsp;1 g</li><li><a href="https://amzn.to/3UGht1y" target="_blank">Taurine</a> 2 g<br>
</li><li>Viviscal (<a href="https://amzn.to/3Kzhu3v" target="_blank">male</a>) (<a href="https://amzn.to/446YiAN" target="_blank">female</a>) 1 pill</li><li><a href="https://amzn.to/4410L06" target="_blank">Zeaxanthin</a> (20 mg Lutein, 4 mg Zeaxanthin) 3x/wk</li><li><a href="https://amzn.to/3qkvir6" target="_blank">Zinc</a> 15 mg</li></ul></div>
	<div grid-col="x9" grid-pad="2.5"><p><b>w/Dinner at 11 am</b></p><ul><li>Acarbose 200 mg (Rx)</li><li><a href="https://amzn.to/3oa4ybQ" target="_blank">BroccoMax</a> 17.5mg</li><li><a href="https://vitality-pro.com/?ref=projectblueprint" target="_blank">Ca-AKG </a>1 G</li><li><a href="https://amzn.to/3RoMGXw" target="_blank">Cocoa Flavanols</a> 500 mg (contains caffeine)</li><li><a href="https://amzn.to/43JXcvv" target="_blank">E </a>67 mg<br></li><li><a href="https://amzn.to/404UNZN" target="_blank">EPA</a> 500 mg&nbsp;</li><li><a href="https://amzn.to/3ogmf9y" target="_blank">Garlic</a> 2.4 g equivalent&nbsp;</li><li>
<a href="https://amzn.to/3GGs6vf" target="_blank">Garlic</a> 1.2 g (kyolic)</li><li><a href="https://amzn.to/3Pi0Us1" target="_blank">Ginger Root</a> 2.2 g</li><li><a href="https://amzn.to/3MGtrWH" target="_blank">Glucosamine Sulphate</a> 2KCL 1,500 mg</li><li><a href="https://amzn.to/406clVm" target="_blank">Hyaluronic Acid</a> 300 mg<span>&nbsp;</span></li><li>L-<a href="https://amzn.to/43xTEwE" target="_blank">Lysine</a> 1g<br>
</li><li><a href="https://amzn.to/3pczPf5" target="_blank">L-Tyrosine</a> 500 mg</li><li>Metformin ER 500 mg (Rx)</li><li><a href="https://amzn.to/3UyP9hk" target="_blank">N-Acetyl-L-Cysteine</a> (NAC) 1,800 mg<br></li><li><a href="https://amzn.to/3zSBGYp" target="_blank">NR</a> 375 mg OR <a href="https://www.jinfiniti.com/product/accuri-vitality-boost-60g/" target="_blank">NMN</a> 500 mg, (6x wk)&nbsp;</li><li><a href="https://amzn.to/3UGht1y" target="_blank">Taurine</a> 1 g<br></li><li><a href="https://amzn.to/3MDqXbR" target="_blank">Turmeric</a> 1 g</li><li>Viviscal (<a href="https://amzn.to/3Kzhu3v" target="_blank">men</a>) (<a href="https://amzn.to/446YiAN" target="_blank">women</a>) 1 pill<br></li></ul></div>
	
	<div grid-col="x9" grid-pad="2.5"><p><b>Other</b></p><ul><li>Extra Virgin Olive Oil, 30 mL daily&nbsp;</li><li><a href="https://amzn.to/3XoXJ3J" target="_blank">Pea Protein</a>, 29 grams daily</li><li>Dark Chocolate, 15 grams</li><li>Rapamycin (Rx)<br>
wk 1: 13 mg<br>
wk 2: 6 mg<br>
wk 3: 13 mg<br>
wk 4: 6 mg&nbsp;</li><li>17α-E2, 8 mg wk transdermal</li><li><a href="https://amzn.to/43nAh9A" target="_blank">B12 methylcobalamin</a> 1x/wk</li><li><a href="https://amzn.to/3qz5N5C" target="_blank">Aspirin</a> 81 mg 3x wk</li><li>112 mcg Levothyroxine, 60 mg Armour Thyroid (diagnosed with hypothyroidism at age 21)</li></ul><br></div></div>


<h2>Step 3: Track progress<br></h2><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="3" grid-pad="2.5">
<p><b>Basic blood panel</b> <br>Cystatin C<br>Complete blood count with differential, RDW, WBC, MCV<br>BUN<br>Creatinine<br>HbA1c<br>IGF-1<br>venous glucose<br>lipid panel <br>total protein <br>albumin<br>liver panel<br>thyroid panel</p><p>hsCRP</p><br></div>
    
	<div grid-col="5" grid-pad="2.5"><p>Vitamin A serum, B1 serum, B2 serum, B3 serum, B6 serum, B7 serum, B9 serum, B12 serum, C serum, D serum, alpha tocopherol serum, PIVKA-II/a.k.a. DCP (vitamin K deficiency) serum, CoQ10 serum</p><p>Calcium serum, chloride serum, chromium serum, copper plasma, magnesium serum, manganese plasma, phosphate serum, potassium RBC, selenium plasma/serum, zinc serum/plasma</p></div>
	<div grid-col="4" grid-pad="2.5"><p>DHEA-S<br>Testosterone<br>Estrogen<br>SHBG</p><p>
Urine<br>Iodine<br>Iodine to creatinine ratio<br>albumin to creatinine ratio</p></div></div><a href="https://rejuvenationolympics.com/" target="_blank"><img width="1407" height="661" width_o="1407" height_o="661" data-src="https://freight.cargo.site/t/original/i/c549ce725a692d663f8bf77f3abae55352161766f71adf4cb329b441d3f020b3/Rejuvenation-Olympics.png" data-mid="166466940" data-scale="47" src="https://freight.cargo.site/t/original/i/c549ce725a692d663f8bf77f3abae55352161766f71adf4cb329b441d3f020b3/Rejuvenation-Olympics.png"></a><br>
&nbsp;<a href="https://rejuvenationolympics.com/" target="_blank">https://rejuvenationolympics.com/</a>
</projectcontent>
				</div>

				
			</bodycopy>
		</div>

						<div data-container="set" data-id="25267815">

	<div data-container="page" data-id="25025060" local-style="25025060">
			<bodycopy>
				
				<div data-elementresizer="" data-resize-parent="">
					<projectcontent><div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="bryan-johnsons-blueprint">Bryan Johnson’s Blueprint Protocol<br></h2><h2>PROFESSIONAL REJUVENATION ATHLETE</h2>
<p><b>Objective</b>: I am trying to maximally slow the speed of my biological aging. My goal: one year of chronological time passes and my biological age stays the same. &nbsp;There is no magic pill for this.&nbsp;<br>
+ 78 organ biological age rejuvenation<br>
+ 200+ science backed protocols<br>
+ 1,000 Peer-reviewed References<br>
</p></div><p>
<img width="1966" height="750" width_o="1966" height_o="750" data-src="https://freight.cargo.site/t/original/i/01dd33b30d06810bee0a195040b877fd3f2005afea9be3d3c8759590f9a789c3/Screen-Shot-2022-12-15-at-12.58.16-PM.png" data-mid="162065682" src="https://freight.cargo.site/t/original/i/01dd33b30d06810bee0a195040b877fd3f2005afea9be3d3c8759590f9a789c3/Screen-Shot-2022-12-15-at-12.58.16-PM.png"></p><h2>Philosophical Principles &nbsp;</h2>
<br>
<ol><li>My path here, <a href="https://medium.com/future-literacy/hi-i-am-bryan-johnson-5d833d49e70e" target="_blank">Hi, I am Bryan Johnson</a></li><li>How I approach problems <a href="https://medium.com/future-literacy/zeroth-principles-thinking-9376d0b7e7f5" target="_blank">Zeroth Principle Thinking</a> &amp; solve them <a href="https://medium.com/future-literacy/my-goal-alignment-problem-d90e0c14b717" target="_blank">My Goal Alignment Problem </a></li><li>Building systems to solve things systematically: <a href="https://medium.com/future-literacy/autonomous-self-fe2dfa755b74" target="_blank">My Autonomous Self</a> and <a href="https://www.bryanjohnson.com/articles/i-fired-myself" target="_blank">I fired myself</a></li><li>Blueprint is born: <a href="https://www.bryanjohnson.com/articles/project-blueprint" target="_blank">Project Blueprint </a></li><li>Blueprint + Kernel: <a href="https://medium.com/future-literacy/sleep-and-impulse-control-87e844218ff2" target="_blank">Sleep &amp; Impulse Control</a></li><li>Contemplations: <a href="https://medium.com/future-literacy/a-plan-for-humanity-2bc04088e3d4" target="_blank">A Plan for Humanity</a> </li></ol>All together: Ashlee Vance: <a href="https://www.bloomberg.com/news/features/2023-01-25/anti-aging-techniques-taken-to-extreme-by-bryan-johnson" target="_blank">How to Be 18 Years Old Again for Only $2 Million a Year</a><h2>Blueprint at a glance</h2><br>
<h2>BASICS....</h2><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive=""><div grid-col="6" grid-pad="2.5"><ul><li>Chronological age: 45</li><li>Measured muti-epi clock biological age: 42.5</li><li><a href="https://medium.com/future-literacy/how-fast-are-you-aging-e845830d8a3c" target="_blank">Pace of aging: .69</a></li><li>160.7 lbs (88.7% lean mass)</li><li>7.1% body fat </li><li>4.3% bone mass </li><li>60.2% body water </li><li>21.9 BMI</li></ul><br></div>

	<div grid-col="6" grid-pad="2.5"><ul><li>2250 &nbsp;daily caloric intake </li><li>Vegan (except for collagen peptides)</li><li>16-18 hr daily fast </li><li>70+ lbs of veggies/mthly</li><li>19% protein, 33% carbs, 48% fat</li></ul><br>
</div></div>
<h2>WHAT IS HEALTHY CHOCOLATE? (<a href="https://www.santabarbarachocolate.com/?ref=vysHWo_Vh7aJ_L" target="_blank">what i use</a>)<br></h2><ul><li>LEVEL 1: Chocolate is good for you. A snickers bar isn’t that bad!</li><li>LEVEL 2: Any brand advertising “dark chocolate”&nbsp;</li><li>LEVEL 3: Un-dutched dark chocolate&nbsp;</li><li>LEVEL 4: Un-dutched dark chocolate, tested for heavy metals&nbsp;</li><li>LEVEL 5: Un-dutched dark chocolate, tested for heavy metals and from specific regions of the world with the highest polyphenol density<br></li></ul>
<br>
<b>BLUEPRINT IS LEVEL 5 ONLY</b><p>
<i>Decision algorithm* <br><ul><li>
What studies have been done on chocolate?<br></li><li>
Do the chocolate studies meet our statistical thresholds? <br></li><li>
Should I take chocolate of a certain type and dose based on 1 and 2?<br></li><li>
How do I personally check that chocolate is safe and effective for me?</li></ul>*See appendix for more detailed description of decision algorithm <br>
</i></p></projectcontent>
				</div>

				
			</bodycopy>
		</div>

			
	<div data-container="page" data-id="25025061" local-style="25025061">
			<bodycopy>
				
				<div data-elementresizer="" data-resize-parent="">
					<projectcontent><h2 id="current-results">Current Results</h2><br>Science and engineering begin with counting. Health is no different. During this past year, I’ve had hundreds of measurements taken. Some are standard, such as biofluids and fitness scores. Some are advanced, such as MRI and ultrasound. And some uncommon, such as my lungs, nerves, hearing, and intestinal tract. Below is a sampling of these measurements. <br>
<br>
<h2><b>Results: Optimal Clinical Outcome Range </b><br></h2>
<br>
<div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5"> <table><tbody><tr><td>BIOMARKER&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>&nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>RESULT&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>AGE EQUIVALENT&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td><td>OPTIMAL CLINICAL OUTCOMES&nbsp; RANGE (OCOR)</td></tr><tr><td>ALT</td><td><span>OPTIMAL</span></td><td>18</td><td> </td><td>&lt;15</td></tr><tr><td>BMI</td><td><span>OPTIMAL</span></td><td>22.8</td><td> </td><td>&lt;22.5</td></tr><tr><td>Fasting plasma glucose</td><td><span>OPTIMAL</span></td><td>82</td><td>28 (max reduction)</td><td>&lt;95</td></tr><tr><td>Body Fat</td><td><span>OPTIMAL</span></td><td>6.9</td><td>16 (max reduction)</td><td>&lt;10%</td></tr><tr><td>Cholesterol (total)</td><td><span>OPTIMAL</span></td><td>158</td><td> </td><td> </td></tr><tr><td>DHEA</td><td><span>OPTIMAL</span></td><td>149</td><td>25 (max reduction)</td><td>&lt; age 50</td></tr><tr><td>Free Testosterone Index </td><td><span>OPTIMAL</span></td><td>0.39</td><td>41</td><td>&lt; age 50</td></tr><tr><td>GGT</td><td><span>OPTIMAL</span></td><td>13</td><td> </td><td>&lt;14</td></tr><tr><td>Glutathione </td><td><span>OPTIMAL</span></td><td>227</td><td>29</td><td>&lt; age 30</td></tr><tr><td>Grip Strength Dominant</td><td><span>OPTIMAL</span></td><td>134</td><td>33 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>Grip Strength Non-dominant</td><td><span>OPTIMAL</span></td><td>124</td><td>43 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>HbA1C</td><td><span>OPTIMAL</span></td><td>4.5</td><td>28 (max reduction)</td><td>4.5-5.6</td></tr><tr><td>HDL</td><td><span>OPTIMAL</span></td><td>73</td><td> </td><td>50 - 60</td></tr><tr><td>hsCRP</td><td><span>OPTIMAL</span></td><td>0.46</td><td>10 (max reduction)</td><td>&lt;0.55</td></tr><tr><td>IGF-1</td><td><span>OPTIMAL</span></td><td>125</td><td> </td><td>75 - 150</td></tr><tr><td>LDL</td><td><span>OPTIMAL</span></td><td>74</td><td> </td><td>&lt; 100</td></tr><tr><td>NAD</td><td><span>OPTIMAL</span></td><td>52.6</td><td>16 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>PSA</td><td><span>OPTIMAL</span></td><td>0.68</td><td>22 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>RDW</td><td><span>OPTIMAL</span></td><td>11.3</td><td>18 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>SHBG</td><td><span>OPTIMAL</span></td><td>68</td><td> </td><td> </td></tr><tr><td>TSH</td><td><span>OPTIMAL</span></td><td>1.94</td><td> </td><td>1 - 2.1</td></tr><tr><td>Triglycerides </td><td><span>OPTIMAL</span></td><td>55</td><td> </td><td>27 - 89</td></tr><tr><td>Testosterone </td><td><span>OPTIMAL</span></td><td>769</td><td>33 (max reduction)</td><td> </td></tr><tr><td>VO2 max treadmill</td><td><span>OPTIMAL</span></td><td>53.6</td><td>18 (max reduction)</td><td>&lt; age 30</td></tr><tr><td>WBC</td><td><span>OPTIMAL</span></td><td>4.5</td><td> </td><td>3.5 - 6</td></tr><tr><td>20th percentile telomeres PBMC</td><td><span>OPTIMAL</span></td><td>7</td><td>28 (max reduction)</td><td>&lt; age 30</td></tr></tbody></table></div><br>
<hr><br>
<h2><b>Results: Younger than Chronological Age</b><br></h2>
<br><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x9" grid-pad="2.5"><p>REJUVENATION POINTS </p><ul><li>hsCRP</li><li>DunedinPoAm</li><li>NAD</li><li>Frailty index</li><li>Total glutathione</li><li>VO2 max</li><li>12 min run distance</li><li>Whole brain volume</li><li>White matter volume</li><li>Cerebral volume</li><li>Total sleep time</li><li>Wake after sleep onset</li><li>Sleep efficiency</li><li>Digit comparison score</li><li>Digit symbol score</li><li>ETS score</li><li>RAVENS score</li><li>Letter number sequencing score</li><li>Ventricular volumes</li><li>Subcortical grey matter</li><li>Pituitary brightness</li><li>Cerebellar volume</li><li>Stand on 1 leg </li><li>5 min deep sleep RMSSD</li><li>MaxHR</li></ul><ul><li>BNP</li><li>LVEDV</li><li>LV E</li><li>LV A</li><li>LV E/A</li><li>LV E’m</li><li>LV IVRT</li><li>LV PWT</li><li>LA A’ lat</li><li>LA SRE</li><li>LA SRA</li><li>LA SRE/SRA</li><li>cfPWV</li></ul><br></div>
	<div grid-col="x9" grid-pad="2.5"><p>REJUVENATION POINTS</p><ul><li>RCCA PSEM</li></ul><ul><li>LCCA PSEM</li><li>RCCA CIMT</li><li>LCCA CIMT</li></ul><ul><li>RICA CIMT</li><li>LICA&nbsp; CIMT</li><li>TPA</li><li>Systolic blood pressure </li><li>Brachial blood pressure</li><li>Non-map C2 CSBP </li><li>Non-map C2 CDBP</li><li>PPA ratio</li><li>AI</li></ul>
<ul><li>AP</li><li>FEV1</li><li>FVC</li><li>PEFT</li><li>DLCOc</li><li>A line quant</li><li>MIP </li><li>MEP</li><li>RDW</li><li>EpiTOC2.tnsc</li><li>PC telo length methylation pred</li><li>QFISH median PBMC telo</li><li>QFISH 20th cent PBMC teloRRI left</li><li>RRI right</li><li>Cystatin C</li><li>eGFR CKD EPI</li><li>EHF Hz Right</li><li>14-16k Hz Left</li><li>Calculus index</li><li>Recession gingival</li><li>Index gingival</li><li>HbA1c</li><li>FPG</li><li>CGM</li></ul><ul><li>Albumin</li></ul><br>
</div>
	<div grid-col="x9" grid-pad="2.5"><p>REJUVENATION POINTS</p><ul><li>QT</li></ul><ul><li>VISIA Tru L</li><li>VISIA Tru R</li></ul><ul><li>ZM-Facial age</li><li>ZM Neck age</li><li>ZM Decollete age</li><li>ZM Gluteal age</li><li>ZM Lower limb age</li></ul><ul><li>Facial left spots</li><li>Facial right spots</li><li>Facial left texture</li><li>Facial right texture</li><li>Facial left brown</li><li>Facial right brown</li><li>Facial left wrinkles</li><li>Facial right wrinkles</li><li>Facial central spots</li><li>Facial central texture</li><li>Facial central browns</li><li>Modified HN hair</li><li>DHEA-S</li><li>Thyroid volumetrics</li><li>Push up continuity</li><li>Bench press 1 rep max </li><li>Leg press 1 rep max</li></ul>
<ul><li>Grip strength L</li><li>Grip strength R</li><li>WC</li><li>BF%</li><li>DEXA L1-4</li><li>DEXA Femur</li><li>DEXA Hip</li><li>Osteocalcin</li><li>Spinal flexibility</li><li>Prostatic volume</li><li>PSA total </li><li>Total testosterone</li><li>Free testosterone index</li></ul></div>
	<div grid-col="x9" grid-pad="2.5"><p>IDEAL MARKERS FOR</p><ul><li>Vit A</li><li>Alpha carotene</li><li>Beta Carotene</li><li>Lycopene</li><li>Vit C</li><li>B1</li><li>B2</li><li>B3</li><li>B5</li><li>B6</li></ul>
<ul><li>B7</li><li>B12</li><li>Vit E (Alpha + Gamma) </li><li>Vit D</li><li>Vit K</li><li>CoQ10</li><li>Bicarbonate</li><li>Calcium</li><li>Chloride</li><li>Chromium</li><li>Copper</li><li>Iodine</li><li>Magnesium</li><li>Phosphate</li><li>Potassium</li><li>Selenium</li><li>Sodium</li><li>Zinc</li><li>ALT</li><li>AST</li><li>ALP</li><li>GGT</li><li>TG</li><li>LDL</li><li>HDL</li><li>IGF-1</li></ul></div>
</div><hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="routine-measurement">Routine Measurement</h2><br><ul><li>Weight, body fat, muscle mass, body water, BMI </li><li>Sleep: HR, HRV, Deep, REM, Respiration Rate, Body Temp </li><li>Waking body temp (ear) </li><li>SpO2 while sleeping </li><li>Blood Glucose </li><li>MRI - whole body </li><li>Ultrasound - whole body </li><li>Biofluids (blood, stool, urine, saliva) </li><li>Physical fitness - whoop + Polar </li><li>VO2Max</li><li>Hearing</li><li>Eyes </li><li>Air quality </li></ul><p><b>Vein health for blood draws (via ultrasound)</b><br>- Using ultrasound to evaluate potential vein damage from serial blood draws. No damage found. &nbsp;Bilateral antecubitcal fossae (ACF) venous ultrasound was performed to identify potential venous wall or valve pathology related to serial blood draws of the ACF veins, <i>with no pathology identified</i>, suggesting further draws at this site are safe.</p><p>

<b>Whole body MRI cancer screening </b><br>Nothing suspicious was identified. Head to lower sacral non-contrast 3T T1, T2 and DWI were performed (with some regions missed for DWI), with additional FLAIR on the head region, HASTE on abdominal region and sagittal STIR on C1 to S2 were performed for cancer screening with no suspicious, potentially suspicious or likert ⅗ or greater lesions identified</p><p>

<b>Sensory nervous system measurements</b><br>- Right plantar 2 point discrimination of 1.5 cm coming in at age 30 equivalent</p><p>

<b>Kidneys</b></p><ul><li>Zero cysts, zero parenchymal thickness abnormalities (i.e. irregular or thinning) present in the kidneys&nbsp; </li><li>Renal interlobar arteries resistive index (RRI) coming in at 0.46 (right kidney) and 0.49 (left kidney), equal to age 25 of a newly diagnosed essential hypertensive, but otherwise average, western population (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>) (non-hypertensive population data currently not available)</li></ul><p><b>Thyroid</b></p><ul><li>Thyroid volume (increases with age) coming in at age 23 equivalent at 20.9 milliliters (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>)</li></ul>
<p><b>Prostate</b></p><ul><li>Prostate volume (increases with age) coming in at age 30 equivalent for a Westerner at 19.14 milliliters (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>)</li></ul><p><b>Blood Glucose levels</b> are perfect. Resting steadily around 90 mg/dL over 24hrs/7 days.</p><p>
<b>New maxHR of 183 bpm</b>, = to age 37, 5% improvement in 90 days. 8% increase (from 169 bpm) in 12 months (originally age 60). 23 year age reduction to date. Exciting because we couldn’t get maxHR to budge for over 12 months. Neither could we find any research showing&nbsp; maxHR increase was possible. Measured w/ <a href="https://www.amazon.com/gp/product/B07PM54P4N/" target="_blank">Polar H10</a></p><p>

<b>Waist circumference</b> measurement 82.8 cm, average for a 25 year old (maximum age reduction)</p><p>

<b>BIA scale body fat%</b> 21-23 ave BMI, = to age 16 (max reduction) </p><p>

<b>My Pulse Wave Velocity of 5.7</b>, ranks in 10% &lt;30, top 5% of 45+. </p><p>

<b>Blood urea nitrogen</b>, a measure of protein intake and kidney function, was lowered to 13 mg/dL, deeper into the optimal range for all cause mortality and scoring age 21 equivalent.
</p></div><img width="1446" height="1526" width_o="1446" height_o="1526" data-src="https://freight.cargo.site/t/original/i/5b7f71ab8300fd3d9920c7db8f5667abf6da42d80b78f96bc378e10231027185/2022.9-whole-body-MRI.jpg" data-mid="165223780" src="https://freight.cargo.site/t/original/i/5b7f71ab8300fd3d9920c7db8f5667abf6da42d80b78f96bc378e10231027185/2022.9-whole-body-MRI.jpg"><hr>
<div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="heart-health">Heart Health</h2><p>MEASUREMENT PROTOCOL </p><ul><li>MRI</li><li>Ultrasound </li><li>RHR, HRV, VO2Max </li></ul><p>
N=1 HIGH ACCURACY METHOD MARKERS </p><ul><li>Resting Heart Rate: 44 bpm</li><li>HRV 54, age 40</li><li>VO2Max 58.7 mL/(kg·min), age 18</li><li>LV septal A’ mitral: age 70+</li><li>Aortic root diameter age 70+ </li><li>LA E’ latbasal: age 70+ </li><li>RVSP: age 70 </li><li>LV sepal E/E’: age 55</li><li>RV E/A: age 52 </li><li>MaxHR: age 37</li><li>LV E/A: age 28</li></ul>
<p>[Heart] Carotid arteries</p><ul><li>Pressure strain elastic modulus (PSEM) of the right and left common carotid arteries (RCCA and LCCA) elasticity scoring at 4.51 Pascal units age 26 equivalent and 2.82 Pascal units age 18 equivalent respectively (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>)</li><li>Common carotid average intima media thicknesses age 32 equivalent, at 0.47 mm thickness, although there is little change between age 18 and age 32 (only 0.03 mm) (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>)</li><li>No plaque or atherosclerosis. Details: total plaque area across 6 carotid artery branches of 0 cm^2, showing no significant atherosclerosis; with plaque being defined as any thickening of the intima media beyond 1 mm. </li><li>Internal carotid artery maximum intima media thicknesses age 25 equivalent, as low as is possible to score, at 0.51 and 0.45 mm (<a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a>)</li></ul><p>[Heart] Left ventricle</p><ul><li><span>Intraventricular relaxation time (IVRT) of 50.6 ms scored at age 19 average (</span><a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a><span>)</span><br></li><li>
<span>E/A pulsed wave doppler in the mitral valve of 1.67 score (dimensionless) coming in at age 28, with the E component at 0.96 m/s of age 15 average for healthy caucasian men (This is a measure of how well blood is flowing through the mitral valve) (</span><a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a><span>)</span><br></li><li>
<span>Tissue doppler showed septal LV E’ (e prime) mitral annulus speed of 11.12 cm/s at age 24 average (</span><a href="https://protocol.bryanjohnson.com/Bam-Criteria" rel="history">ref</a><span>) (This is a measure of how well the left ventricle septum is contracting back and forth)</span></li></ul><p><span></span><br>Mitral valve pulsed wave doppler still taken during echocardiogram. Clearly shows the four chambers of the heart and the blood flow toward and away from the transducer, red and blue colors respectively.
<br>
</p></div><br>
<hr><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="brain-health">Brain Health</h2><p>
MEASUREMENT PROTOCOL </p><ul><li>Complex small voxel non-contrast 3D T1, T2, T2 FLAIR, mag, phase, minIP, SWI, 2/3D MRA, 2/3D MRV, 3D DTI, triple 2D DWI, ASL, CSF, SPACE, ultrasound, cognitive testing, EEG, peripheral blood markers etc.</li></ul><p>
MARKERS </p><ul><li>White Matter Hyperintensities: age 48</li><li>Pineal calcification: &gt;40 TBC</li><li>Ventricular volume: age 48</li><li>Cortical grey vol: age 45</li><li>AI T1 brain age: age 44</li><li>RAVENS PM: age 41 </li><li>Total Cerebral WMV: age 37 </li><li>WASO: age 37</li></ul><p>
NOTES </p><ul><li>Bi-lateral, congenital IJV&nbsp;</li></ul><br>
</div><hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="lung-health">Lung Health</h2><p>MEASUREMENT PROTOCOL </p><ul><li>Ultrasound </li><li>Functional markers</li></ul><p>
MARKERS </p><ul><li>FEV1 age 22</li><li>FVC age 26</li><li>PEFR age 33</li><li>A lines age 33</li><li>B lines age 70+</li></ul><br><ul><li>DLCOc, 32.8 ml/min/mmHg, age 38.5 equivalent, a measure of the ability of the lungs air sacs, alveoli, to pass oxygen into the red blood cells in the lung capillaries</li><li>KCOc, 4.32 1/min, age 54</li><li>MIP &amp; MEP are diaphragm measurements - maximum inspiratory (MIP) and expiratory (MEP) pressure scored at 155 and 117 cmH2O respectively, = to age 20 (maximum possible reduction) for both markers. These measure the strength of the double-domed diaphragm muscle below the lungs, with my Diaphragm showing no signs of weakening with chronological age. </li></ul><br>
</div><br>
<hr><br>
<div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x11" grid-pad="2.5"><h2 id="gastrointestinal-health">Gastrointestinal Health</h2><p>
MEASUREMENT PROTOCOL </p><ul><li>Small bowel capsule camera (large bowel capsule camera TBC)</li><li>Acquired 33,537 images </li><li>Looking for lymphoma, Crohn’s ulcerations, small bowel cancer, diverticula, and polyps. Nothing found. </li><li>Microbiome, GI Effects, other. </li><li>Stool </li></ul><p>
MARKERS </p><ul><li>SCFAs &amp; elastase: age 70+ (8/21, since have started intervention)</li><li>Polyps negative</li><li>Bleeds negative</li><li>Serial FIT FOBT, Cologuard Gen 1 negative</li></ul><p><b>Intestinal Tract - </b>I swallowed this pill, the size of a baby carrot, after fasting for 24 hours. Then took laxatives for 6 hours. It reemerged 10 hours and 38 minutes later, having taken 33,537 images of my intestinal tract. Main things we were looking for: lymphoma, Crohn’s ulcerations, small bowel cancer, diverticula, and polyps. Nothing found. Most common small bowel changes with age are motility, peristalsis reduction, dysphagia and enteric neuropathy. Advantages of small bowel pillcams include screening and baseline results for n=1 study. Here are some of the pictures. 
</p></div>
	<div grid-col="x11" grid-pad="2.5"><p><img width="480" height="352" width_o="480" height_o="352" data-src="https://freight.cargo.site/t/original/i/297b37ce5a27754a03acfa372b5680db8f38100f36171e4b19e56578022689c1/Bryan-Johnson_Blueprint_GI_GIF.gif" data-mid="140951878">
<img width="2100" height="1100" width_o="2100" height_o="1100" data-src="https://freight.cargo.site/t/original/i/a756e583f31350f6506b8a28caf2c8c87a9e737e5ea5a77e506c0e6e026fadc0/Bryan-Johnson-CapsoCam.png" data-mid="140952355" src="https://freight.cargo.site/t/original/i/a756e583f31350f6506b8a28caf2c8c87a9e737e5ea5a77e506c0e6e026fadc0/Bryan-Johnson-CapsoCam.png">
</p></div>
</div>
<hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="hair-health">Hair Health&nbsp;<br>
</h2><p>Based upon my genetics, I should be bald by now. I started greying and losing my hair in my late 20s. Been a lot of work to try and keep it.</p><p>
PROTOCOL </p><ul><li><b>Custom hair formulation. Recipe:</b></li></ul><p><span>Caffeine USP 1%</span><br>
<span>Finasteride USP 0.25%</span><br>
<span>Minoxidil USP 5%<br>Azelaic Acid 1.5%<br>Diclofenac 0.5%<br>Tea Tree Oil 5%<br>Rosemary Oil 0.37%<br>Ginko Biloba 0.05%<br>Biotin 0.01%<br>Melatonin USP 0.0033%</span></p><ul><li><span><a href="https://bit.ly/gr7_blueprint" target="_blank">Grey hair reversal</a> (BLUEPRINT discount) &nbsp;</span></li><li><span>If you want to <a href="https://hairmayraki.com/anti-grey-hair-color-restoring-treatment/" target="_blank">double up on treatment</a> (use gloves, stains hands)</span></li></ul><ul><li><b>PRP 1x 60-90 days. Recipe:</b></li><li>10x PRP concentration from 120 ccs</li><li>.3 ml of 0.1% dutasteride</li><li>Autologous exosomes via <a href="https://supershotprp.com/" target="_blank">SuperShot</a></li><li><a href="https://supershotprp.com/pages/for-physicians" target="_blank"></a><span>A Cell</span></li></ul><ul><li><a href="https://www.capillus.com/products/capillus-pro-s1" target="_blank">Laser cap</a> (I have the 304 laser diodes)&nbsp;</li></ul><p>
MARKERS </p><ul><li>Grey+white: measuring age 41&nbsp;</li><li>Quant Hamilton-Norwood: measuring age 26
</li></ul>
</div>
<hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="skin-health">Skin Health</h2><p>MEASUREMENT PROTOCOL </p><ul><li>Multi Spectral Imaging </li><li>Autofluorescence&nbsp; </li><li>Merz </li></ul><p>
MARKERS </p><ul><li>Spots: Age 10</li><li>Wrinkles: Age 10</li><li>Texture: Age 14</li><li>Pores: Age 50</li><li>UV Spots: Age 62</li><li>Brown spots: Age 11</li><li>Red areas: Age 70<span>&nbsp;</span></li><li>Autofluorescence: age 32<br>
</li><li>Multispectral imaging face age: 41</li></ul><p>DAILY PROTOCOL </p><ul><li><a href="https://amzn.to/3MIzfh2" target="_blank">Face wash </a></li><li>Other active creams </li><li>Vit C, E, ferulic, B3, azelaic etc</li><li><a href="https://amzn.to/43tbvF8" target="_blank">Cerave am face </a></li><li><a href="https://amzn.to/3KLG41x" target="_blank">Cerave body </a></li><li><a href="https://amzn.to/3zSiucY" target="_blank">Cerave pm face</a></li><li>Tretinoin .1%</li><li><a href="https://amzn.to/45y2fk1" target="_blank">UVA+B mineral sunscreen</a></li><li>UV environmental filters </li></ul><p>
Things we’re trialing:&nbsp;</p><ul><li>Non-bleeding microneedling with HA serum</li><li><span>Cutera Excel V coolview &amp; genesis</span><br></li><li>Fotona Dynamis Pro 4D and other protocols</li><li>Microbotox injections for pore shrinkage</li><li>Sculptra&nbsp;</li><li>PRF</li><li>Renuva (autologous fat transfer)</li><li>Whole body LED -&nbsp;<span>630 nm (red) and 830 nm (infra red)
Continuous wave or pulsed up to 40 Hz 
Up to 200 mw/cm^2 irradiance at 6 inches 
60 J/cm^2 dose at 6 inch distance. &nbsp;</span></li><li><span>Be careful not to burn yourself by standing too close. Protocol (mine, is device dependent): 12 min, 3x weekly.&nbsp;</span></li><li><span>Objectives:&nbsp;</span></li><li><span>. accelerated healing</span></li><li><span>. skin health&nbsp;</span></li><li><span>. possible helper w/ anxiety + depression (only if applied to forehead)&nbsp;</span></li><li><span>. sleep</span></li><li><span>bought mine from <a href="https://t.co/2YDKqYdrQR" rel="noopener noreferrer nofollow" target="_blank">http://reddotled.com</a></span></li></ul><br>
</div>
<br>
<hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="eye-health">Eye Health</h2><p>MEASUREMENT PROTOCOL &nbsp;</p><ul><li>Drusen volume 0</li><li>Enhanced depth imaging optical coherence tomography subfoveal choroidal thickness high n=1 accuracy read left age 51, right age 70, prior to axial length/refractive error regression adjustment</li><li>IOP 13 mmHg, age 38</li><li>Accommodative distance high n=1 accuracy read TBC</li><li>Eyelash length age 70+ (genetically short)
</li></ul><p>EYE MEASUREMENTS</p><ul><li>Sub-foveal choroidal thickness on enhanced depth imaging spectral domain optical coherence tomography (sfCT EDI-SD-OCT) was acquired showing 332 microns and 400 microns respectively; however, future 3D choroidal quantification methods we will perform will have lower standard deviation and higher biological age resolution</li></ul>
<br>
</div><hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="ear-health">Ear Health</h2><p>MEASUREMENT PROTOCOL &nbsp;</p><ul><li>Research grade digital audiometric setup with high n=1 accuracy reads</li><li>RESULTS: Left (me), Right (my 17 yr old)</li></ul><p>
MARKERS </p><ul><li>Right ear normal freq: age 61</li><li>Left ear normal freq: age 51 </li><li>Right ear EHF: age 60</li><li>Left ear EHF: age 32</li><li>Typmpanometric, OAE, cochlear magnetic resonance markers, waxome TBC</li><li>Pinna age 30</li></ul>
<br>
</div><br>
<hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="oral-health">Oral Health</h2><p>MEASUREMENT PROTOCOL &nbsp;</p><ul><li>Plaque index, recession, attachment loss &nbsp; </li></ul><p>
MARKERS </p><ul><li>Most recent plaque index was 24.4% which is ideal </li><li>Reduced attachment loss by 41% via specially designed procedures </li></ul><p>
DAILY PROTOCOL </p><ul><li>Brush 2 min (am/pm) </li><li>Water pik (am/pm) </li><li>Floss&nbsp; (am/pm) </li><li>Tongue scraper </li><li><a href="https://amzn.to/3RD81Mi" target="_blank">Tea tree oil rinse </a></li><li>CoQ10 gel</li></ul><p>RESULTS</p><ul><li>My dentist reports<i> “you have the gums of a healthy teenager” </i></li><li>Improved plaque index to 63.6% (<a href="https://amzn.to/3MCLoWp" target="_blank">tracked plaque in mouth</a> post brushing to assess how to improving brushing technique) </li><li>Filled the one remaining 4 mm pocket on #11.</li></ul>
<p><b>Gingival index and calculus index</b> scoring 0, the lowest possible; having the same level of calculus and gum inflammation as a 17 year old.
</p></div><br>
<hr><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="sleep-health">Sleep Health<br></h2>
<h2>Sleep Is A Lighthouse<br></h2><p>
Perhaps the most important health/wellness practice, I’ve been working on achieving consistent, high quality sleep for years (<a href="https://www.bryanjohnson.com/articles/sleep-is-the-new-coffee" target="_blank">Sleep is the new coffee</a>). These are the things that work for me.&nbsp;</p><p>
PROTOCOL &nbsp;</p><ul><li>Blacked out room </li><li>Same bedtime daily </li><li>Sleep alone </li><li>Blue light blocking glasses </li><li>1 hr downtime before bed </li><li>Temp controlled mattress</li></ul><p>
8/2023 - completed 6 months of achieving 100% sleep score performance via Whoop. Also, my one month recovery score is in the top 1.4% of all male whoop users.&nbsp;</p><p>
<img width="1170" height="2153" width_o="1170" height_o="2153" data-src="https://freight.cargo.site/t/original/i/4e9f929e9a482920553c2cb2288b025c6c0e3cdd1d4d2f21f8283d0d1134edb6/IMG_7524.jpg" data-mid="188982834" data-scale="70" src="https://freight.cargo.site/t/original/i/4e9f929e9a482920553c2cb2288b025c6c0e3cdd1d4d2f21f8283d0d1134edb6/IMG_7524.jpg"></p></div><hr><br><h2 id="other-measurements">Other Measurements</h2><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x10" grid-pad="2.5"><p>RED BONE MARROW </p><ul><li>PBMC LIfelength QFISH median telomere length: 42&nbsp;</li></ul><p>
PANCREAS</p><ul><li>Pancreatic elastase: 70+</li></ul><p>
MSK</p><ul><li>Tendons enthuses US: 51</li><li>[other]</li></ul><p>
PROSTATE </p><ul><li>Volume (Bolivia tribe): 59</li><li>Volume (westerner): 30 </li></ul><p>
ARTERIES</p><ul><li>Abdo aorta IMT: age 46</li><li>CCA IMT: age 32</li></ul>
<br>
</div>
	<div grid-col="x10" grid-pad="2.5"><p>ORGANS TO COMPLETE MEASUREMENT FOR</p><ul><li>Thymus </li><li>Liver &amp; GB</li><li>Pancreas</li><li>Bone marrow</li><li>Retina</li><li>Stomach, esophagus, large Bowel/small bowel</li><li>Mesentery</li><li>Trachea</li><li>Larynx</li><li>Pharynx</li><li>Lips</li><li>Bronchi/oles</li><li>Glymphatics</li><li>Lymphatics</li><li>Spleen</li><li>Ureters, bladder, urethra</li><li>Middle ear</li><li>Nose, tongue</li><li>Peno-scrotal</li><li>Cartilage, ligaments</li><li>Motor &amp; sensory nerves, spinal cord</li></ul></div>
	<div grid-col="x10" grid-pad="2.5"><p>SEXUAL HEALTH </p><ul><li>Urine Chlamydia</li><li>Urine Gonorrhea</li><li>Hepatitis B [blood]<ul><li>HepB core antibody, surface antibody, and surface antigen</li></ul></li><li>Hepatitis C [blood]</li><li>Herpes Simplex Virus I (Typically Oral Herpes)</li><li>Herpes Simplex Virus II (Typically Genital Herpes)</li><li><a href="https://oraldna.com/test/ohpv-complete/" target="_blank">Oral Human Papilloma Virus (HPV)</a><ul><li>PCR HPV 20 subtypes</li></ul></li><li>HIV 1 [blood]</li><li>HIV 2 [blood]</li><li>RPR Syphilis [blood]</li><li>Also have the <a href="https://www.gardasil9.com/adults/" target="_blank">Gardasil 9 HPV vaccine</a></li></ul>
<br></div>
</div>
<br>
<hr><div grid-col="x12" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="diet-and-supplements">Diet and Supplements</h2><p><b>&nbsp;<br></b><a href="https://protocol.bryanjohnson.com/#step-1-meal-prep">Diet</a> recipes &amp; <a href="https://protocol.bryanjohnson.com/#step-2-supplements">Supplements</a> lists are located in the Blueprint Starter Guide.&nbsp;<br>
</p></div><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><p>BY THE NUMBERS</p><ul><li>2,250 calories daily </li><li>~10% Caloric Restriction </li><li>Vegan (preference, not necessity)</li><li>70+lbs of veggies monthly </li><li>100+ pills daily </li></ul><p>
MEASUREMENTS </p><ul><li>biofluids, devices, imaging, fitness tests&nbsp; </li></ul><p>ROUTINE </p><ul><li>Green Giant + 54 pills </li><li>One hour workout</li><li>Super Veggie </li><li>Skin/oral/hair/eye care</li><li>Travel to work </li><li>Nutty Pudding</li><li>Third dish + 34 pills&nbsp;</li></ul><br></div>
<br>
<hr><br>

<span> </span><br><div grid-col="x11" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive=""><h2 id="fitness">Fitness</h2><p><b>Daily routine <br>
</b><b> </b><a href="https://www.youtube.com/watch?v=HNywRJgCRaQ" target="_blank">Having fun workout (Oct 21</a>)</p><p>


PROTOCOL (here’s a&nbsp;<a href="https://www.youtube.com/watch?v=sYyVi-H-ozI" target="_blank">video showing it</a>)</p><ul><li>1 hr day </li><li>~25 exercises </li><li>7 hrs wkly&nbsp;</li><li>88-105 bpm ~1 hr</li><li>106-159 bpm -4hr 30 min</li><li>159+ bpm 90 minutes&nbsp;</li></ul>&nbsp; &nbsp; <p>
ROUTINE</p><ul><li>Backwards Sled, 2 min</li><li>Posture exercises (<a href="https://www.youtube.com/watch?v=in9ubCilsT8" target="_blank">video</a>)</li><li>Tricep extensions 1x25<br></li><li>Face pulls 1x15<br></li><li>Butterfly, 1x15<br></li><li>Band pull apart (back muscles), 1x15<br></li><li>Back extensions (on a hyperextension), 1x25<br></li><li>Obliques (each side, on a hyperextension), 1x25<br></li><li>Stretches</li><ul><li>Kneeling shin</li><li>Hip flexor</li><li>Couch</li></ul><li><span>Leg raises (for abdomen), 1x50</span></li><li><span>Seated calf raises, 1x25</span></li><li>Poliquin step ups, 3x10, each leg</li><li>Slant board squats, 3x15</li><li>ATG Split squats, 3x10</li></ul><ul><li>Nordics, 1x10</li><li>Reverse Nordics, 1x10</li><li>Tibialis raises, 1x25</li><li>IsoTib ankle rotations (each), 1x15</li><li>Pull ups, 1x15</li><li>Chin ups, 1x15</li><li>10 min HIIT (M,W,F)</li><li>Hiking on weekends, basketball, tennis</li></ul><p>FITNESS SCORES (ref: <a href="https://www.acsm.org/read-research/books/acsms-guidelines-for-exercise-testing-and-prescription" target="_blank">ACSM</a>)<br>Scoring equal to top 10% of 18 year olds in the following:</p><ul><li>Bench press single rep max, 240lbs, top 10% of 18 year olds<br></li><li>VO2 max&nbsp; 58.7 mL/(kg·min), top 1.5% of 18 year olds<br></li><li>Leg press, single rep max. 800 lbs<br></li><li>Push ups, continuous, 60<br></li><li>YMCA sit and reach, 26.5 inches. &nbsp;<br></li><li>Grip strength (dominant hand) 60 kg, above the age related peak that occurs in men at age 32.5 (Jamar Dynamometer Corporation reference data</li></ul>
</div>


<br><hr><br>
<h2 id="notable-challenges">Notable Challenges</h2><div grid-row="" grid-pad="2.5" grid-gutter="5" grid-responsive="">
	<div grid-col="x10" grid-pad="2.5"><h2>CONGENITAL BILATERAL IJV STENOSIS<br></h2><p>
CASE NOTES DECEMBER 2021</p><ul><li>44yo male</li><li>RIJV: 70-80% stenosis</li><li>LIJV: 100% stenosis </li><li>Below reference range flow in all positions on duplex bilateral IJV doppler </li><li>Missing left transverse sinus on MRV; cerebral venous thrombosis?</li><li>Severe headache symptoms causing to wake in the night, on acetazolamide 250 mg since 25th Jan 2022</li><li>Likely cause: bilateral styloid + atlatl transverse process compression of the IJVs both sides; multiple signs of raised ICP on serial MRIs</li><li>Possible TOS (thoracic outlet syndrome seen on subclavian MRA) </li><li>20 years history of nocturnal bruxism untreated until 2021</li><li>No previous stroke, TIA, aphasia, blurred vision or other medical conditions. </li><li>Deciding next steps RE tests and surgical intervention.</li></ul>
<br>
</div>
	<div grid-col="x10" grid-pad="2.5"><h2>LUNG B LINES<br></h2>
<ul><li>9 when I should have 2</li><li>Possible pathological confirmation via hyperpolarized MRI </li><li>Possible elimination via multi-component nebulised protocol </li></ul><br><h2>GRAY HAIR<br></h2>
<ul><li>Excessive stress, chronic depression from age 20-40 whitened my hair</li><li>Struggling to reverse it (8/23 update 8/23 - we’ve made some meaningful progress with<a href="https://bit.ly/gr7_blueprint" target="_blank"> this formulation</a> “Blueprint for 7% off”)</li></ul>
<br></div>
	<div grid-col="x10" grid-pad="2.5"><h2>HEART REJUVENATION</h2> <br>
<ul><li>Several heart markers including LV septal A’ mitral, Aortic root diameter, LA E’ latbasal and RVSP are all coming in decades older than my chrono age. No symptoms.&nbsp; </li><li>Need to formulate a plan </li></ul><br><h2>MAX HR<br></h2>
<ul><li>In twelve months, improved from 169 bpm to 183 bpm</li><li>Struggling to make further gains </li></ul>
<br></div>
</div></projectcontent>
				</div>

				
			</bodycopy>
		</div>

			
			</div>
			
			</div>

			<div data-container="content" data-id="25025077" local-style="25025077" data-view="pinned_bottom" data-set="Scaffolding" data-position="bottom">
		<bodycopy>

			
			<div data-elementresizer="" data-resize-parent="">
				<projectcontent><div grid-col="12" grid-pad="2.5" grid-row="" grid-gutter="5" grid-responsive="" id="end"><p><span>This work is licensed under a </span><a target="_blank" href="http://creativecommons.org/licenses/by-nc/4.0/" rel="noopener noreferrer">Attribution-NonCommercial 4.0 International</a> | Consult your doctor for what’s right for you.</p><p>

<b>Medical disclaimer</b><br>This website, including any experimental results presented, is for informational purposes only and does not constitute medical advice or professional services. The information provided should not be used for diagnosing or treating a health problem or disease. Individuals seeking medical advice should consult with a licensed physician. </p><p>
<b>Biological age measurements and claims</b><br>Any claims regarding the measurement or reversal of biological age are preliminary and can be influenced by various biostatistical errors, including statistical variation, reference range relevancy, and clinical outcome significance. Ongoing, formal peer-reviewed studies are essential for validating these biological age tests for FDA approval (or its international equivalent) and confirming any clinically relevant changes in biological age. The data presented reflect our team's rigorous efforts to adhere to current scientific and biostatistical standards, while formal peer-reviewed validation studies are underway. Please note: These tests are experimental and intended solely for research purposes. They should not replace or supplement any clinical tests recommended by licensed medical professionals."</p><p>
<b>Context</b><br>The protocol presented on this website is based on scientific research, ranging from mouse studies to meta-analyses of randomized controlled trials and international clinical practice guidelines. These have been carefully reviewed for their unique relevance to my personal situation. The protocol encompasses a mix of on-label, off-label, and unlicensed therapies, as well as research-use-only tests. Some of these tests and therapies are still under scientific investigation and have not yet received on-label licensing for specific health conditions. All tests and therapies, regardless of their licensing status, carry risks. These risks have been assessed for my personal use by a specialized team of clinicians and scientists. This protocol represents an experimental clinical research project. Results will be periodically published in peer-reviewed journals, adhering to international quality standards relevant to various types of clinical studies, including case reports, randomised controlled trials, and systematic reviews. Case reports, case series, and systematic reviews are important components of evidence-based medicine, helping inform the design of gold-standard randomised controlled trials and guiding clinical practice.</p><p>
<b>Rx</b><br>
The use of Prescription only Medicines (PoMs) such as HGH, acarbose, rapamycin, metformin, thyroxine, testosterone, statins, phenylbutyric acid, tadalafil and others discussed in this protocol should not be considered an endorsement or promotion of these products. PoMs should only be prescribed by a licensed doctor who has assessed that the benefits and risks are acceptable for the individual and acquired through licensed pharmacies in a jurisdictionally legal manner. The prescribing doctor should be made aware of all other PoMs being taken and other relevant interventions such as foods, supplements and medical history to enable accurate assessment for safe prescribing and monitoring of combination interventions.</p><p><sub>This web site is provided for educational and informational purposes only and does not constitute providing medical advice or professional services. The information provided should not be used for diagnosing or treating a health problem or disease, and those seeking personal medical advice should consult with a licensed physician.</sub></p></div></projectcontent>
			</div>

			
		</bodycopy>
	</div>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eating fewer calories can ward off ageing (169 pts)]]></title>
            <link>https://www.economist.com/technology-quarterly/2023/09/25/eating-fewer-calories-can-ward-off-ageing</link>
            <guid>38839088</guid>
            <pubDate>Tue, 02 Jan 2024 07:30:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/technology-quarterly/2023/09/25/eating-fewer-calories-can-ward-off-ageing">https://www.economist.com/technology-quarterly/2023/09/25/eating-fewer-calories-can-ward-off-ageing</a>, See on <a href="https://news.ycombinator.com/item?id=38839088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-body-id="cp2"><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/061%20Technology%20Quarterly%20-%20Calorie%20restriction-bd3e98a3a6834cf47481f462db7325f7.mp3" title="Eating fewer calories can ward off ageing" controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p data-component="paragraph"><span data-caps="initial">I</span><small>n 1991 eight</small> volunteers sealed themselves into a huge greenhouse in the desert near Tucson, Arizona. They were part of an experiment seeking to discover whether a carefully curated selection of plants and animals could develop into a self-sustaining ecosystem: a “Biosphere 2” independent of “Biosphere 1”, aka the outside world.</p><p data-component="paragraph">In terms of proving grand ecological truths the Biosphere 2 experiments were something of a bust. As an illustration of what can happen when somewhat fringe-y science meets extreme wealth they were fascinating. There were fierce fallings-out on both sides of the glass. In 1994 Ed Bass, an oil dynast who had paid for the facility, threw out the management team and handed the reins to Steve Bannon, later a key adviser to Donald Trump. At the same time, though, there was what some took to be a breakthrough in the science of human ageing.</p><p data-component="paragraph">One of the eight biospherians was Roy Walford, a professor of pathology at the University of California, Los Angeles (<small>ucla</small>). Research by Walford and others had shown that restricting what animals ate could significantly lengthen their lives. The lifespans of nematode worms, fruit flies, rodents and dogs could be extended as much as 50% by laboratory protocols which gave them a diet with all the nutrients they needed in terms of minerals, vitamins and the like but fewer calories than were seen as normal.</p><p data-component="paragraph">Biosphere 2 allowed him to test the theory on humans in no position to sneak off for snacks. With a daily intake of 1,750-2,100 calories (7,320-8,790 kilojoules) the biospherians, trim to begin with, all slimmed down. But after eight months their weight stabilised. Gaunt as they were, their energy levels remained high. Blood tests showed physiological responses which matched those of calorie-restricted rodents with extended lifespans.</p><p data-component="paragraph">Some people have taken this as a reason to incorporate calorie restriction into their lives, as Walford did. But such diets, which go well beyond the sort of weight-restricting efforts to which any sensible person might aspire, are hard to maintain. That has provoked an interest in finding ways to get the benefits of calorie restriction without having to engage in it.</p><h2>The garden of forking paths </h2><p data-component="paragraph">Calories are a measure of the amount of energy that cells can get from breaking food into its component chemical parts. The precise nature of that breaking down, and what happens with all the parts, is under the control of a range of signalling pathways which have the job of matching what the cell is doing with how much energy the organism needs and has available. Dysfunction in these nutrient-signalling pathways is one of the 12 hallmarks of ageing listed by Dr López-Otín and his colleagues.</p><p data-component="paragraph">If there is a general truth behind the success of calorie restriction, it is that when energy is on the scarce side, the nutrient signalling pathways in cells pay greater attention to what is going on and keep the cell in better shape. What is necessary if the same pathways are to be recruited without the calorie reduction is an understanding of what other cues can have the same effect.</p><p data-component="paragraph">The research would be both easier to do and easier to understand if these pathways all had distinct, clearly understood functions. Alas, this is not the case. Pathways frequently regulate more than one function, functions are frequently regulated by more than one pathway and the farthest-flung parts of pathways are often obscure. To make things yet less comprehensible, the proteins involved in the pathways have incredibly opaque names.</p><p data-component="paragraph">Take the <small>MTORC1 </small>pathway. The complex of proteins which gives it its name first came to attention because an immune suppressant called rapamycin has a strong effect on it: hence “mechanistic target of rapamycin complex 1”. That gives no real clue, however, to the fact that the signalling pathway in which <small>MTORC1 </small>sits is a complex set of controls and feedbacks designed to regulate metabolism in response both to the availability of nutrients (for example, glucose, which provides energy, and amino acids, from which proteins are made) and impediments to their use (for example, low oxygen levels).</p><p data-component="paragraph">The ambit of this regulatory power is broad; it influences the rate at which cells break down damaged internal structures (“autophagy”), the balance of their protein content (“proteostasis”) and the reproduction of their mitochondria, components responsible for turning the calories it receives into a form of energy its proteins can use. Autophagy, proteostasis and mitochondrial reproduction are three more of the 12 hallmarks of ageing.</p><h2>Rap of ages</h2><p data-component="paragraph">What is more, rapamycin, the effects of which give <small>MTORC1</small> its name, turns out to lengthen the lives of lab animals even though it curbs their immune responses. This has led some longevity enthusiasts to seek off-label prescriptions for it. But its side-effects, including anaemia and an insensitivity to insulin, make rapamycin ill-suited for widespread use. There is thus a search for “rapalogs” which provide the benefits of a tuned-up<small> MTORC1</small> pathway without so many costs.</p><p data-component="paragraph">Another pathway which calorie-restriction studies have marked out as promising is named after a protein called <small>AMPK</small> (don’t ask). This regulates the production of <small>ATP</small>, a small energy-carrying molecule produced in mitochondria. When <small>ATP</small> levels fall, the <small>AMPK</small> pathway increases a cell’s sensitivity to insulin.</p><p data-component="paragraph">Metformin, a drug used to treat type-<small>2</small> diabetes, does so by activating the <small>AMPK</small> pathway. Like rapamycin, it extends the lifespans of healthy mice. It does the same for diabetic humans. A study published in 2014 showed that diabetes patients treated with metformin enjoyed a decreased mortality rate, not just compared with patients who were not treated with it, but also with healthy controls who were not given the drug.</p><p data-component="paragraph">Not surprisingly, metformin is also used off-label, probably more widely than rapamycin. The American Federation for Ageing Research, a not-for-profit organisation, hopes soon to start a six-year, 3,000-person clinical trial to measure its effects in people from 65- to 79-years-old. The Targeting Ageing with Metformin (<small>TAME</small>) trial will see if metformin helps prevent cardiovascular disease, cancer and cognitive decline; it will also test the hypothesis that it reduces all-cause mortality.</p><p data-component="paragraph">A further set of medicines developed to treat diabetes but now used more widely are the <small>GLP-1 </small>receptor agonists. The best known, semaglutide (sold as Wegovy), has been specifically licensed in various places for use in people without diabetes who nevertheless need to lose weight. Whether they might live longer than someone of the same final weight who does not take one of the drugs is an open question. There are no published studies that show the drugs to have an effect on the lifespans of laboratory animals.</p><p data-component="paragraph">One thing that does do the job for lab animals is taurine, an amino acid widely used as a dietary supplement. According to a recent paper by Parminder Singh of the Buck Institute for Research on Ageing in Novato, California, and colleagues, in mice taurine increases lifespan by 10%; some of this seems to be due to nutrient signalling. But there are effects on four or five other hallmarks of ageing, too. Taurine levels drop with age in humans but, in those who live to be over 100, levels stay significantly higher. </p><p data-component="paragraph">Nutrient sensitivity may also be enhanced by a molecule called <small>NAD+</small>. Some enzymes—proteins which catalyse chemical reactions—require the presence of a small extra molecule to do their thing. <small>NAD+</small> is such a “co-enzyme”. More than 300 enzymes need it to be present if they are to do their bit for the cell. And if you give mice more of it, they live longer.</p><p data-component="paragraph">Considering that <small>NAD+</small> is so generous with its favours it is difficult to know exactly which of the enzymes it helps are responsible for delivering this effect. But one connection which looks particularly interesting is that with a set of proteins called sirtuins.</p><h2>La vie en vin rouge</h2><p data-component="paragraph">Sirtuins came to prominence two decades ago when David Sinclair, who is now co-director of the Centre for Biology of Ageing Research at Harvard University, showed that stimulating their production prolongs life in a variety of laboratory animals. One form of stimulation is calorie restriction. But Dr Sinclair discovered a chemical alternative: resveratrol, a molecule found, among other places, in the skins of red grapes.</p><p data-component="paragraph">Dr Sinclair is by no means publicity-shy; his discovery saw a great deal of brouhaha. He founded a company, Sirtris, to produce resveratrol derivatives suited to the human body. The work did not amount to much. Sirtris, having been bought by GlaxoSmithKline, ceased to exist as a separate entity in 2013.</p><p data-component="paragraph">That might seem a cautionary tale. But it can also be seen as grounds for hope. Sirtuins got a lot of attention because there had been no similarly credible claims about longevity for some time. Their story set out a blueprint for looking into such things: a mechanism looked interesting, a molecule seemed promising, investigations were carried out, conclusions were drawn. Many more mechanisms and drugs are now being scrutinised in the same way. Some scepticism is warranted. But there is no reason to believe that none of them will get results just because the few looked at so far have not. <span>■</span></p></div><p>This article appeared in the Technology Quarterly section of the print edition under the headline "Don’t be greedy"</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Why the EU must get bigger" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20230930_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20230930_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20230930_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20230930_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20230930_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20230930_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20230930_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20230930_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20230930_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20230930_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20230930_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20230930_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20230930_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20230930_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20230930_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230930_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230930_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the September 30th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-09-30" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an open source web calendar inspired by the Google calendar (181 pts)]]></title>
            <link>https://schedule-x.dev/demos/calendar</link>
            <guid>38838946</guid>
            <pubDate>Tue, 02 Jan 2024 06:58:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://schedule-x.dev/demos/calendar">https://schedule-x.dev/demos/calendar</a>, See on <a href="https://news.ycombinator.com/item?id=38838946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Code</h2><p>The demo above is based on the code below.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Ultra Fast Lossless Audio Codec (HALAC) (191 pts)]]></title>
            <link>https://hydrogenaud.io/index.php/topic,125248.0.html?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0</link>
            <guid>38838531</guid>
            <pubDate>Tue, 02 Jan 2024 05:43:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hydrogenaud.io/index.php/topic,125248.0.html?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0">https://hydrogenaud.io/index.php/topic,125248.0.html?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0</a>, See on <a href="https://news.ycombinator.com/item?id=38838531">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="sp_main">
			
			<nav>
				
				
							
			</nav>
		<main id="forumposts">
			
			<section>
			<p><span id="whoisviewing">0 Members and 132 Guests are viewing this topic.
				</span>
			</p>
			<form id="quickModForm" action="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;action=quickmod2;topic=125248.0" method="post" accept-charset="UTF-8" name="quickModForm" onsubmit="return oQuickModify.bInEditMode ? oQuickModify.modifySave('MszKjLVdk9bUQzThRd0O48Wlt3N1z5nD', 'YQpNJni') : false">
				<article>
					
					<div>
						<header>
						
							
							<span id="messageicon_1037197">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037197">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037197#msg1037197" rel="nofollow"></a><time title="Last post" datetime="2023-12-31 21:12" data-timestamp="1704057143">2023-12-31 21:12:23</time>
							</h5>
							
						</header>
						<section id="msg_1037197">I'm new in this forum. I am glad it was such a special forum on Audio. I am the writer of the lossless image codec called <a href="https://encode.su/threads/4025-HALIC-(High-Availability-Lossless-Image-Compression)" target="_blank" rel="noopener noreferrer">HALIC(High Availability Lossless Image Compression)</a>. It is a work that can offer a good compression ratio quite quickly. This time I would like to introduce my work called HALAC(High Availability Lossless Audio Compression).<p>In the past(2018-2019), I had been working on the lossless audio compression. However, I could not bring together the work I did. Now I have a little time and I think I developed a fast codec. I worked on 16 bit, 2 channel audio data (.wav). Higher bit and channel options can be added if necessary. As a result, the approach is the same.</p><p>HALAC, like the HALIC, focuses on a reasonable compression ratio and high processing speed. The compression rate for audio data is usually limited. So I wanted a solution that can work faster with a few percent concessions.</p><p>I used a quick estimation with ANS(FSE). I don't know if there are other codecs using ANS, but the majority uses "Rice Coding". However, in my tests, Rice Coding(my own implementation) is a bit behind in terms of speed(0.6x - 0.7x), but it gives better results as compression rate(1% - 2%). The loss of speed in the Rice Coding is due to the calculation of adaptive parameter. I am really happy with ANS right now because speed is more important to me. In addition, I do not think that I use ANS fully efficiently.</p><p>GPU or SIMD was not used. Also now in the single-thread version. In the next version, I can add the Multithread option. I couldn't compile the Linux version because my Linux machine collapsed. I tried to find the middle way by working with different music genres.<br>Below are the comparisons (from original wav, 16 bit, 2 channel, 44100 bps) with FLAC, ALAC and WAVPACK (Pazera_Free_Audio_Extractor ver. 2.11).</p><p><strong>Test Machine (2012):</strong> i7 3770k, 3.9 ghz, 16 gb ram, 256 gb ssd<br><strong>Encode Usage:</strong> halac_encode.exe input.wav out.halac<br><strong>Decode Usage: </strong>halac_decode.exe out.halac original.wav</p><p><img src="https://encode.su/attachment.php?attachmentid=10971&amp;d=1704053753" alt=""></p><p><img src="https://encode.su/attachment.php?attachmentid=10972&amp;d=1704053768" alt=""></p><p><img src="https://encode.su/attachment.php?attachmentid=10973&amp;d=1704053780" alt=""></p></section>
							
					<nav>
						<ul id="buttons_1037197">
							<li id="modified_1037197">
								<span>Last Edit</span>: 2023-12-31 21:17:50 by Hakan Abbas
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037204"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037204">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037204">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037204">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037204#msg1037204" rel="nofollow">Reply #1</a> – <time title="Last post" datetime="2024-01-01 08:18" data-timestamp="1704097089">2024-01-01 08:18:09</time>
							</h5>
							
						</header>
						<section id="msg_1037204">Speed wise your codec is quite impressive. I ran some simple tests here and it seems to compress a tiny bit worse than FLAC 1.4.3 in mode -4 but clearly better than FLAC in mode -3.<br>But in compression speed it beats even FLAC mode -0 and TAK -p0. And seems to beat them all in decoding speed too.
						</section>
					<nav>
						<ul id="buttons_1037204">
							<li id="modified_1037204">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037210"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037210">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037210">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037210">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037210#msg1037210" rel="nofollow">Reply #2</a> – <time title="Last post" datetime="2024-01-01 11:31" data-timestamp="1704108695">2024-01-01 11:31:35</time>
							</h5>
							
						</header>
						<section id="msg_1037210">Very nice. tl;dr is it essentially LPC with ANS for the residual? If you could release source or compile for Linux that would be great, I have trouble running .NET mono crap through wine.
						</section>
					<nav>
						<ul id="buttons_1037210">
							<li id="modified_1037210">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037211"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037211">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037211">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037211">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037211#msg1037211" rel="nofollow">Reply #3</a> – <time title="Last post" datetime="2024-01-01 11:39" data-timestamp="1704109192">2024-01-01 11:39:52</time>
							</h5>
							
						</header>
						<section id="msg_1037211">I wonder how much of the speed benefit comes from the codec seemingly lacking any safety checks.<p>I compressed a WAV with metadata and the decoded file seems to have copied the header from the original file but is missing the metadata chunks, so it's a bit invalid length wise.</p><p>And I randomly altered bits in the encoded binary data as a test, decoder didn't notice any issues but of course the decoded file is no longer bit-identical to the original.
						</p></section>
					<nav>
						<ul id="buttons_1037211">
							<li id="modified_1037211">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037213"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037213">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037213">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037213">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037213#msg1037213" rel="nofollow">Reply #4</a> – <time title="Last post" datetime="2024-01-01 12:14" data-timestamp="1704111257">2024-01-01 12:14:17</time>
							</h5>
							
						</header>
						<section id="msg_1037213"><blockquote>Very nice. tl;dr is it essentially LPC with ANS for the residual? If you could release source or compile for Linux that would be great, I have trouble running .NET mono crap through wine.<br></blockquote>Yes, a linear prediction and then 2 pieces FSE are used to encode residues. After the installation of my Linux machine is completed, I add execuable files. It is not open source at the moment, but can be evaluated according to the situation in the future. Right now, it's very new and I have things to improve.<p>There are also different predictors I don't use. Some are good in high entropy and some low entropy. As I said, we are at the beginning yet.
						</p></section>
					<nav>
						<ul id="buttons_1037213">
							<li id="modified_1037213">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037215"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037215">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037215">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037215">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037215#msg1037215" rel="nofollow">Reply #5</a> – <time title="Last post" datetime="2024-01-01 12:22" data-timestamp="1704111724">2024-01-01 12:22:04</time>
							</h5>
							
						</header>
						<section id="msg_1037215"><blockquote>I wonder how much of the speed benefit comes from the codec seemingly lacking any safety checks.<p>I compressed a WAV with metadata and the decoded file seems to have copied the header from the original file but is missing the metadata chunks, so it's a bit invalid length wise.</p><p>And I randomly altered bits in the encoded binary data as a test, decoder didn't notice any issues but of course the decoded file is no longer bit-identical to the original.</p></blockquote><br>What you are talking about, ie data integrity control, can be achieved with a rapid Hash functions(wyhash, xxhash...). This will not have much effect on speed. Because they work extremely fast. However, no one had made such a request in my previous studies. If this is necessary, I will add it in the next version, no problem. Thanks a lot...<p>In addition, dealing with Metadata is the next simple details. We usually do not compress them (a few kilobytes).
						</p></section>
					<nav>
						<ul id="buttons_1037215">
							<li id="modified_1037215">
								<span>Last Edit</span>: 2024-01-01 12:25:08 by Hakan Abbas
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037217"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037217">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037217">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037217">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037217#msg1037217" rel="nofollow">Reply #6</a> – <time title="Last post" datetime="2024-01-01 12:34" data-timestamp="1704112488">2024-01-01 12:34:48</time>
							</h5>
							
						</header>
						<section id="msg_1037217">The numbers posted suggest 3x to 5x faster than FLAC, and I get nothing of that kind. Though it is fast indeed! The decoding speeds are outright impressive given how FLAC is the fastest thing we ever saw ... yet. (Only recently did the -0 encoding speeds improve.)<p>I ran it on the corpus in my signature, and it is on par with fastest FLAC --no-md5. On a RAM disk (I use Passmark OSFmount because it is mounting software too) I had to restrict myself down to 4 albums (all classical music, this is just a brief test). After a few runs, I can report figures like these: </p><p>Encoding: <br>10.1 sec for flac -0r0 --no-md5 --totally-silent<br>10.4 sec for HALAC<br>11.0 sec for flac -1 --no-md5<br>14.4 sec for flac -0 <br>16.1 sec for TAK -p0</p><p>Decoding:<br>13.8 for HALAC<br>16.6 for flac on the "-0r0 --no-md5" files<br>18.5 for TAK -p0</p><p>Sizes are impressive at the speed! File sizes for the full "signature" corpus, all FLAC and ALAC figures have had tags and padding removed<br>13 360 205 283 for FLAC -0r0<br>12 772 828 991 for FLAC -1<br>12 393 304 500 for HALAC &lt;---------- that's between ffmpeg's ALAC and refalac<br>12 032 168 423 for FLAC -5 </p><p>FLAC 1.4.3 win32, i5-1135-G7
						</p></section>
					<nav>
						<ul id="buttons_1037217">
							<li id="modified_1037217">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037218"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037218">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037218">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037218">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037218#msg1037218" rel="nofollow">Reply #7</a> – <time title="Last post" datetime="2024-01-01 13:13" data-timestamp="1704114826">2024-01-01 13:13:46</time>
							</h5>
							
						</header>
						<section id="msg_1037218"><span><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;action=profile;u=38207">@Porcus</a></span>;<br>Thank you very much for the test.<br>The results I have obtained with different Converters are almost the same (Pazera, Human, fre:ac). I don't know your results when MD5 is active. As I mentioned in my previous answers, I have just started this work. Although the my data compression history is long, I worked for a certain time for audio compression and took a long break. We can probably put forward better things with your valuable ideas.
						</section>
					<nav>
						<ul id="buttons_1037218">
							<li id="modified_1037218">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037222"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037222">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037222">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037222">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037222#msg1037222" rel="nofollow">Reply #8</a> – <time title="Last post" datetime="2024-01-01 16:53" data-timestamp="1704128001">2024-01-01 16:53:21</time>
							</h5>
							
						</header>
						<section id="msg_1037222">flac.exe will write MD5 unless you invoke that "undocumented" option, so all the <em>presets</em> are with MD5. The "14.4" seconds enoding time using using "-0" was <em>with</em> MD5 - and also with the -r3 that tries to partition into 8/4/2/1, and which matters like 0.1 to 0.2 seconds. <p>Actually,&nbsp; --totally-silent switches off the console output and helps 0.2 to 0.3 on those numbers. <br>Also I can speed up flac.exe slightly by using a larger block size. flac.exe uses 1152 samples per block for the fixed-predictors presets, I doubt that would have been selected today.&nbsp; So some more timings on the RAM disk:<br>9.5 seconds encoding <span>-0fr0 -b3072 --totally-silent --no-md5</span> (that switches off MD5) - and the --totally-silent actually helps a few tenths too.<br>14.6 seconds decoding the same, also with --totally-silent <br>13.1 encoding <span>-0fr0 -b3072 --totally-silent</span> (that is with MD5)<br>18.2 decoding the ones with MD5.</p><p>All times are medians of "a few". So MD5 takes another three and a half seconds. Quite significant in percentage terms. </p><p>Now, switching corpus to four metal albums instead, still on the RAM disk:<br>8.9 &amp; 12.4 encoding &amp; decoding HALAC<br>12.3 &amp; 16.8 encoding flac at <span>-0fr0 -b3072 --totally-silent --no-md5</span><br>15.3 &amp; 18.3 encoding &amp; decoding TAK at -p0</p><p>So material does matter. Impressive. 
						</p></section>
					<nav>
						<ul id="buttons_1037222">
							<li id="modified_1037222">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037225"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037225">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037225">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037225">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037225#msg1037225" rel="nofollow">Reply #9</a> – <time title="Last post" datetime="2024-01-01 17:28" data-timestamp="1704130089">2024-01-01 17:28:09</time>
							</h5>
							
						</header>
						<section id="msg_1037225">Interesting, and what about MLAC ?<br><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;/topic,125201.0.html" target="_blank" rel="noopener noreferrer">https://hydrogenaud.io/index.php/topic,125201.0.html</a>
						</section>
					<nav>
						<ul id="buttons_1037225">
							<li id="modified_1037225">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
				<article>
					<a id="msg1037231"></a>
					
					<div>
						<header>
						
							<h2 id="post_subject_1037231">Re: HALAC (High Availability Lossless Audio Compression)</h2>
							<span id="messageicon_1037231">
								<img src="https://hydrogenaud.io/themes/default/images/post/xx.png" alt="">
							</span>
							<h5 id="info_1037231">
								<a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.msg1037231#msg1037231" rel="nofollow">Reply #10</a> – <time title="Last post" datetime="2024-01-01 20:00" data-timestamp="1704139208">2024-01-01 20:00:08</time>
							</h5>
							
						</header>
						<section id="msg_1037231"><blockquote>Interesting, and what about MLAC ?<br><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;/topic,125201.0.html" target="_blank" rel="noopener noreferrer">https://hydrogenaud.io/index.php/topic,125201.0.html</a><br></blockquote>In fact, instead of writing this, you can offer us files that we can run to test(under your own topic). Or you can share some of your results from there. You shouldn't expect others to do this. Then, those who are interested in the subject can perform different tests and give you feedback.
						</section>
					<nav>
						<ul id="buttons_1037231">
							<li id="modified_1037231">
								
							</li>
						</ul>
					</nav>
					
					</div>
				</article>
				<hr>
			</form>
			</section>
		</main>
			<nav>
				
				
							
			</nav>
			<nav>
				<ul>
					<li>
						<span><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;action=forum"><i><s>Home</s></i></a>
						</span>
					</li>
					<li>
						<span><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;action=forum;?action=forum#c69">Lossless Audio Compression</a>
						</span>
					</li>
					<li>
						<span><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;board=19.0">Lossless / Other Codecs</a>
						</span>
					</li>
					<li>
						<span><a href="https://hydrogenaud.io/index.php?PHPSESSID=su12fvq4ar7cordpr8p1uoa7p0&amp;topic=125248.0">HALAC (High Availability Lossless Audio Compression)</a>
						</span>
					</li>
				</ul>
			</nav>
			
			
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running 9front on an emulated SGI Indy via MAME (111 pts)]]></title>
            <link>https://posixcafe.org/blogs/2024/01/01/0/</link>
            <guid>38838369</guid>
            <pubDate>Tue, 02 Jan 2024 05:16:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://posixcafe.org/blogs/2024/01/01/0/">https://posixcafe.org/blogs/2024/01/01/0/</a>, See on <a href="https://news.ycombinator.com/item?id=38838369">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<p>I recently found that MAME supports running the SGI Indy while looking for ways to test some modifications I was making to the mips code in 9front. After a fair bit of elbow grease cinap and I (but mostly cinap) were able to get the old 9front indy kernel booting and running within mame. I thought I might as well document how we set things up here. As a word of warning this will require some decent 9front infrastructure setup already and some familiarity with things like ndb, additionally this system is barely usable from a modern standard so its usefulness is limited.</p>
<h2>Baseline MAME Indy</h2>
<p>The mainline MAME only gives the Indy 16MB of ram, which is a little tight. Thanks to some clever folks on the irixnet forums I found a patch for bumping this limit to the theoretical maximum (256MB), you can grab a prepatched repo <a href="https://github.com/majiru/mame">here</a> or if you are using a system with nix flakes available you can use <code>nix run github:majiru/9front-in-a-box#mame</code>.</p>
<p>Next you'll need to grab the required firmware files, of which I used <a href="https://sgi.neocities.org/">this</a> guide to get going, some links may be dead but some google searching of the required file names should get you some archive.org files.</p>
<p>Next you'll need to configure networking, MAME is a bit unique here and expects a tap named <code>tap-mess-$UID-0</code>, additionally after running once you'll need to modify the <code>$MAMEROOT/cfg/indy_4610.cfg</code> to make the <code>edlc</code> device line like so:</p>
<p><code>&lt;device tag=":edlc" interface="0" mac="08:00:69:12:34:56" /&gt;</code></p>
<p>Then you'll also likely need to modify the network from the in-emulation menu in MAME, which can be found by booting up the emulator, hitting ScrlLk followed by Tab, then clicking network settings and arrowing over to TAP/TUN network. This should only need to be done once as it will change the <code>interface=</code> line for the <code>edlc</code> device, unfortunately this specific index seems to be OS specific (was 0 for me on linux, was 2 for cinap on Windows) so its a bit difficult to modify without the in-emulation menu. At this point you <em>should</em> have a working Indy with networking, I suggest perhaps booting in to IRIX (as documented in the neocities guide) and double checking if you get stuck further on.</p>
<p>(editor's note: a real tap-mess indeed)</p>
<h2>9front bits</h2>
<p>Now for the fun bits, lets setup our 9front grid for bootp'ing this device. Let's first build the userspace and kernel:</p>
<p><code>cd /sys/src/</code></p>
<p><code>objtype=mips mk install</code></p>
<p><code>cd /sys/src/9/sgi</code></p>
<p><code>mk install</code></p>
<p>Next we need to configure the network booting, first add a <code>/lib/ndb/local</code> line to the tune of:</p>
<p><code>ip=192.168.168.214 ether=080069123456 sys=indy dom=indy.genso fs=myfs auth=myauth bootf=/mips/9indy</code></p>
<p>Then assuming you have your <code>ip/tftpd</code> running and MAME setup correctly you can boot up the Indy, click the button for maintenance mode, enter the PROM shell, then type <code>BOOTP();</code> which should grab your kernel and boot right up.</p>
<h2>Profit?</h2>
<p><img height="576" src="https://files.catbox.moe/wgp8an.png"></p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to forget what you read (106 pts)]]></title>
            <link>https://ckarchive.com/b/68ueh8hk25687hkq88gqmtzope0kk</link>
            <guid>38838198</guid>
            <pubDate>Tue, 02 Jan 2024 04:42:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ckarchive.com/b/68ueh8hk25687hkq88gqmtzope0kk">https://ckarchive.com/b/68ueh8hk25687hkq88gqmtzope0kk</a>, See on <a href="https://news.ycombinator.com/item?id=38838198">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[We Could Fix Everything, We Just Don't (266 pts)]]></title>
            <link>https://erikmcclure.com/blog/we-could-fix-everything-we-just-dont/</link>
            <guid>38837888</guid>
            <pubDate>Tue, 02 Jan 2024 03:51:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikmcclure.com/blog/we-could-fix-everything-we-just-dont/">https://erikmcclure.com/blog/we-could-fix-everything-we-just-dont/</a>, See on <a href="https://news.ycombinator.com/item?id=38837888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><blockquote><div lang="en" dir="ltr"><p>[programmers frantically pulling cables out of the wall]</p><p>AI: "Nuclear power. Double teachers' salaries. Build more houses. Distribute food more fairly. TRAINS—"</p></div>— qntmyrrh (@qntm) <a href="https://twitter.com/qntm/status/1728178227355763063?ref_src=twsrc%5Etfw">November 24, 2023</a></blockquote><p>I remember growing up with that same old adage of how you could be the next scientist to invent a cure for cancer, or a solution to climate change, or whatever. What they don’t tell you is that we already have solutions for a <strong>lot</strong> of problems, we just don’t use them. Sometimes this is because the solution is too expensive, but usually it’s because competing interests create a tragedy of the commons. Most problems in the modern age aren’t complicated engineering problems, they’re the same problem: coordination failure.</p><p>It was recently unveiled that basically every single UEFI SecureBoot implementation ever made <a href="https://binarly.io/posts/finding_logofail_the_dangers_of_image_parsing_during_system_boot/index.html">can be bypassed with a <em><strong>malicious image file</strong></em></a>. This means that any manufacturer that allows the user to customize the boot image is now vulnerable to a complete bypass of SecureBoot <em>and</em> Intel Boot Guard. Luckily, the fix for this is pretty simple: don’t make the logo customizable. But how did something this absurd happen in the first place?</p><blockquote>The results from our fuzzing and subsequent bug triaging unequivocally say that none of these image parsers were ever tested by IBVs or OEMs. We can confidently say this because we found crashes in almost every parser we tested. Moreover, the fuzzer was able to find the first crashes after running just for a few seconds and, even worse, certain parsers were crashing on valid images found on the Internet. — <a href="https://binarly.io/posts/finding_logofail_the_dangers_of_image_parsing_during_system_boot/index.html">binarly.io</a></blockquote><p>It’s pretty obvious what happened, actually. The image parsers were written with the assumption they’d only ever need to load an image file provided by the manufacturer. When this assumption was violated, all hell broke loose, because <a href="https://davidkcaudill.medium.com/maybe-getting-rid-of-your-qa-team-was-bad-actually-52c408bd048b">we don’t test software anymore</a>. None of this happened because engineering is hard. None of this happened because of some tricky, subtle bug. It happened because the people writing the image parsers made an incredibly stupid mistake and then didn’t bother testing it, because the software industry doesn’t bother with QA anymore. Thus, there was no <a href="https://en.wikipedia.org/wiki/Swiss_cheese_model">swiss cheese</a>. There was just one slice of cheese with a gaping hole in it, because it turns out that some manufacturers decided to let users customize their boot image, thinking it would be harmless, and that by itself was enough to wreak havoc.</p><p>Every layer of this problem is a different flavor of coordination failure. No one on the team who implemented this either thought that there might need to be a warning about untrusted images, or whoever did bring it up was ignored because it was supposed to be handled by another team. Except whoever was supposed to put in a warning about this either wasn’t told, or buried it inside a technical document nobody ever reads. The vendors who decided to implement user-customizable boot logos didn’t ask whether this would be a problem, or weren’t told about it.</p><p>And <em>nobody</em>, not a single layer in this clown train, <a href="https://davidkcaudill.medium.com/maybe-getting-rid-of-your-qa-team-was-bad-actually-52c408bd048b#5a65">implemented a proper QA or pentesting process</a> that could have caught this bug, because we just don’t bother testing anything anymore. Our economic incentives have somehow managed to incentivize building the worst possible piece of shit that still technically works. We know how to avoid this situation. We have decades of experience building in-depth QA processes that we are simply ignoring. <strong>We could fix this, we just don’t</strong>.</p><p>This is not exclusive to software, as this <a href="https://www.youtube.com/watch?v=Limpr1L8Pss">fantastic video about the popcorn button</a> explains. Our economic race to the bottom has been sabotaging almost every aspect of engineering in our society. To save a few cents per microwave, the cheap microwaves don’t include a humidity sensor and then lie about having a popcorn button when it can’t actually work properly, which leads to everyone saying “don’t use the popcorn button” and now nobody uses the popcorn buttons <em>even on microwaves that actually have a humidity sensor and a working popcorn button</em>. The cheapskates control the supply chain now. They have pissed in the proverbial pool, and if this sounds familiar, that’s because it’s a classic example of the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">Tragedy of the Commons</a>.</p><p>Except, that’s not an excuse. What’s truly absurd is that the tragedy of the commons <em>isn’t inevitable</em>. We <em>know</em> this because ancient human tribes managed to navigate responsible utilization of common resources <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons#Non-governmental_solution">all the time</a>. It has no historical basis whatsoever. The tragedy of the commons only happens when you have a total failure of collective action. It is the original symptom of societal enshittification.</p><blockquote>[...] many nomadic pastoralist societies of Africa and the Middle East in fact "balanced local stocking ratios against seasonal rangeland conditions in ways that were ecologically sound", reflecting a desire for lower risk rather than higher profit...</blockquote><p>We actually have a cure for blood cancer now, by the way. Like, <a href="https://www.pennmedicine.org/news/news-releases/2023/august/an-immunotherapy-strategy-against-all-blood-cancers">we’ve done it</a>. It’s likely that a similar form of immunotherapy will generalize to most forms of cancer. Unfortunately, the only approved gene therapy we have is for sickle-cell disease and <a href="https://www.nature.com/articles/d41586-023-03590-6">costs $2 million per patient</a>, so most people in America simply assume they will never be able to afford any of these treatments, even if they were dying of cancer, because insurance will never cover it. This is actually really bad, because if nobody can afford the treatment, then biotech companies won’t bother investing into it, because it’s not profitable! We have built a society that <em>can’t properly incentivize</em> <em><strong>CURING CANCER</strong></em>. This is despite the fact that socialized healthcare is a proven effective strategy (as long as the government <a href="https://www.independent.co.uk/voices/nhs-crisis-covid-privatisation-funding-b2255741.html">doesn’t sabotage it</a>). <strong>We could fix this, we just don’t</strong>.</p><p>Some people try to complain that this happens because democracy is hard, or whatever, and they’re also wrong. <em>We know exactly what’s wrong with our current voting systems</em> and CGP Grey even put out a video on it <a href="https://www.youtube.com/watch?v=s7tWHJfhiyo">13 fucking years ago</a>. It <em>inevitably</em> results in a two-party system, because strategic voting is rational behavior, and you can’t break out of this two-party system because of the spoiler effect, and the solution is <a href="https://www.youtube.com/watch?v=3Y3jE3B8HsE">Ranked Choice Voting</a> (or the Alternative Vote). If you want to go further and address gerrymandering you can use the <a href="https://www.youtube.com/watch?v=l8XOZJkozfI">Single Transferable Vote</a>. All of these better systems were proposed decades ago. We have implemented exactly none of them for the presidential election (<a href="https://en.wikipedia.org/wiki/Ranked-choice_voting_in_the_United_States">except for Maine and Alaska</a>). In fact, America still uses the electoral vote system, which is strictly worse than the popular vote, we all know it’s worse, and we even <a href="https://www.youtube.com/watch?v=tUX-frlNBJY">have a potential solution</a> but we still can’t get rid of it due to counterproductive societal interests.</p><p>We <em>HAVE</em> solutions for these problems. We just don’t use them. We <em>could</em> be running fiber-optic cable to every house in America, and we even know how much it would cost. We just don’t because we gave the money to corporations who then <a href="https://www.reddit.com/r/explainlikeimfive/comments/6c5e97/comment/dhsxq6k/">used none of it and instead paid themselves huge bonuses</a>. We <em>know</em> that automation is chipping away at low-skill jobs, which means our workforce needs to be better educated, and that providing free college to everyone would be a good idea, we just don’t. We know how to build interstate high-speed commuter rail, we just don’t (although <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/12/08/fact-sheet-president-biden-announces-billions-to-deliver-world-class-high-speed-rail-and-launch-new-passenger-rail-corridors-across-the-country/">Biden is trying</a>). <strong>We could fix everything, we just don’t</strong>.</p><p>We have no excuses anymore. None of these are novel or difficult problems, not even the tragedy of the commons. We can do better. We don’t need AI to fix things. We don’t need new technology to solve these problems. We <em>already know how to do better</em>. Our society is bad at cooperation simply because it’s run by people who are incentivized to sabotage cooperation in the name of profits. That’s it.</p><p>It’s January 1st of the new year, and with all these people wishing each other a “better year”, I am here to remind you that <strong>it will only get worse</strong> unless we <em>do something</em>. Society getting worse is <a href="https://www.youtube.com/watch?v=q118B_QdP2k">not something you are hallucinating</a>. It cannot be fixed by you biking to work, or winning the lottery. We are running on the fumes of our wild technological progress of the past 100 years, and our inability to build social systems that can cooperate will destroy civilization as we know it, unless we <strong>do something about it</strong>.</p><p>We live in what is perhaps the most critical turning point in all of human history, and we’re on a ship that has drifted far off course. The rapid current of technology means that we are swept along faster and faster, making it exponentially harder to steer away from the icebergs ahead of us. We <em><strong>must</strong></em> address our coordination failures. We <em><strong>must</strong></em> build systems that foster better cooperation, or this century won’t be a turning point for humanity, it will be the end of humanity.</p><blockquote>"All that would remain of us would be a thin layer in some future rock face. This is the future we must avoid at all costs." — <a href="https://www.youtube.com/watch?v=o48X3_XQ9to&amp;t=725s">John D. Boswell (melodysheep)</a></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Build your startup or side project faster with these SaaS templates (115 pts)]]></title>
            <link>https://hackerstartup.com</link>
            <guid>38837885</guid>
            <pubDate>Tue, 02 Jan 2024 03:50:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerstartup.com">https://hackerstartup.com</a>, See on <a href="https://news.ycombinator.com/item?id=38837885">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-svelte-h="svelte-tye7e1"><h2>Useful SaaS Kits and Starter Templates for developers to build your next project faster</h2> <p>Why start from scratch when there are helpful starter templates available? <br> Save time and
			effort to bring your next idea to life faster.</p></div> <div><div><div><h5>ShipFast - Nextjs Boilerplate </h5> <p>The NextJS boilerplate with all you need to build your SaaS, AI tool, or any other web app and make your first $ online fast.</p> <p>Supabase </p>   <a href="https://shipfa.st/?via=hackerstartup" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/shipfast.JPG" alt="ShipFast - Nextjs Boilerplate"></p></div>  <div><div><h5>Divjoy </h5> <p>Build SaaS products and landing pages 10x faster with our advanced codebase generator</p> <p>Firebase </p>  <p>Supabase </p>   <a href="https://divjoy.com/?via=hackerstartup" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/divjoy.JPG" alt="Divjoy"></p></div>  <div><div><h5>Nextjs SaaS boilerplate </h5> <p>Build an unlimited number of SaaS products with any SaaS Boilerplate. Save months of work and focus on building a profitable business.</p> <p>Supabase </p>  <p>Firebase </p>   <a href="https://makerkit.dev/nextjs-saas-boilerplate" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/nextjs-makerkit.webp" alt="Nextjs SaaS boilerplate"></p></div>  <div><div><h5>Next.js 14 SaaS starter kit </h5> <p>Production-ready SaaS boilerplate, includes authentication, multi-tenancy, i18n, billing, a landing page and much more!</p> <p>Prisma </p>   <a href="https://supastarter.dev/products/starter-kits/nextjs" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/nextjs-starter-kit.1.svg" alt="Next.js 14 SaaS starter kit"></p></div>  <div><div><h5>Nuxt 3 SaaS starter kit </h5> <p>Production-ready SaaS boilerplate, includes authentication, multi-tenancy, i18n, billing, a landing page and much more!</p> <p>Prisma </p>   <a href="https://supastarter.dev/products/starter-kits/nuxt" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/nuxt-starter-kit.1.svg" alt="Nuxt 3 SaaS starter kit"></p></div>  <div><div><h5>👋 Wave <p>Free </p>  </h5> <p>Wave is the ultimate Software as a Service Starter Kit packed with awesome features like authentication, subscriptions, invoices, announcements, user profiles, and so much more!</p>  <a href="https://devdojo.com/wave" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/wave-screen.png" alt="👋 Wave"></p></div>  <div><div><h5>Bullet Train - Ruby on Rails SaaS Framework <p>Free </p>  </h5> <p>Saves you months of development by starting you off with all the features that are the same in every product, so you can focus on what makes your app unique.</p>  <a href="https://bullettrain.co/" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/bullettrain.png" alt="Bullet Train - Ruby on Rails SaaS Framework"></p></div>  <div><div><h5>SaaS Pegasus - The Django SaaS boilerplate </h5> <p>You want to get your project off the ground, but you are stuck on all the boring parts. Pegasus handles the foundation of your application for you. Get a head start and launch faster than you dreamed possible.</p>  <a href="https://www.saaspegasus.com/?via=hackerstartup" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/bullettrain.png" alt="SaaS Pegasus - The Django SaaS boilerplate"></p></div>  <div><div><h5>JumpStart Rails </h5> <p>Jumpstart Pro is the best Ruby on Rails SaaS template out there. Focus on your business, not on the boilerplate.</p>  <a href="https://jumpstartrails.com/" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/jumpstart.png" alt="JumpStart Rails"></p></div>  <div><div><h5>Nodewood </h5> <p>A JavaScript SaaS Starter Kit that provides an application scaffold, user authentication, subscription management, and more</p>  <a href="https://nodewood.com/" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/nodewood.JPG" alt="Nodewood"></p></div>  <div><div><h5>SaaSKit Deno <p>Free </p>  </h5> <p>An open source, modern SaaS template built with Fresh and Deno.</p>  <a href="https://deno.com/saaskit" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/deno-saas.JPG" alt="SaaSKit Deno"></p></div>  <div><div><h5>SaaS Starter Kit <p>Free </p>  </h5> <p>Build React &amp; Node.js Saas apps at Lightning Speed</p> <p>Firebase </p>   <a href="https://supastarter.dev/products/starter-kits/nextjs" role="button"><svg xmlns="http://www.w3.org/2000/svg" fill="none" role="img" aria-label="arrow up right from square outline" viewBox="0 0 18 18"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 11v4.833A1.166 1.166 0 0 1 13.833 17H2.167A1.167 1.167 0 0 1 1 15.833V4.167A1.166 1.166 0 0 1 2.167 3h4.618m4.447-2H17v5.768M9.111 8.889l7.778-7.778"></path></svg> </a> </div> <p><img src="https://hackerstartup.com/images/saasstarterkit.png" alt="SaaS Starter Kit"></p></div>  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zig cookbook: collection of simple Zig programs that demonstrate good practices (103 pts)]]></title>
            <link>https://github.com/zigcc/zig-cookbook</link>
            <guid>38837807</guid>
            <pubDate>Tue, 02 Jan 2024 03:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zigcc/zig-cookbook">https://github.com/zigcc/zig-cookbook</a>, See on <a href="https://news.ycombinator.com/item?id=38837807">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Zig Cookbook</h2>
<p dir="auto"><a href="https://discord.gg/bAehMGPb2R" rel="nofollow"><img src="https://camo.githubusercontent.com/bc807225eb83a719258c0dfa16dfafbfc8be154c77476a0d28b60a4b293c8a34/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313135353436393730333834363833343138373f6c6162656c3d436861742532306f6e253230446973636f7264" alt="" data-canonical-src="https://img.shields.io/discord/1155469703846834187?label=Chat%20on%20Discord"></a>
<a href="https://github.com/zigcc/zig-cookbook/stargazers"><img src="https://camo.githubusercontent.com/68dd8fd5159bd87c86c0f1cf4f3aa4bcedf45c8c70d62affc863e8a8fb2af127/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a696763632f7a69672d636f6f6b626f6f6b3f7374796c653d73717561726526636f6c6f723d23333061313465" alt="" data-canonical-src="https://img.shields.io/github/stars/zigcc/zig-cookbook?style=square&amp;color=#30a14e"></a>
<a href="https://github.com/zigcc/zig-cookbook/actions/workflows/ci.yml"><img src="https://github.com/zigcc/zig-cookbook/actions/workflows/ci.yml/badge.svg" alt=""></a>
<a href="https://github.com/zigcc/zig-cookbook/actions/workflows/pages.yml"><img src="https://github.com/zigcc/zig-cookbook/actions/workflows/pages.yml/badge.svg" alt=""></a></p>
<p dir="auto"><a href="https://github.com/zigcc/zig-cookbook">Zig cookbook</a> is a collection of simple Zig programs that demonstrate good practices to accomplish common programming tasks.</p>
<h2 tabindex="-1" dir="auto">How to use</h2>
<p dir="auto"><a href="https://zigcc.github.io/zig-cookbook/" rel="nofollow">The website</a> is generated by <a href="https://rust-lang.github.io/mdBook/" rel="nofollow">mdbook</a>, <code>mdbook serve</code> will start a server at <code>http://localhost:3000</code> for preview.</p>
<p dir="auto">Each recipe is accompanied by an illustrative example named after its corresponding sequence number. These examples can be executed using the command <code>zig build run-{chapter-num}-{sequence-num}</code>, or <code>zig build run-all</code> to execute all.</p>
<blockquote>
<ul dir="auto">
<li>Support Zig 0.11.0 and master, and they are tested on Linux and macOS via GitHub actions.</li>
<li>Some recipes may depend on system libraries, use <code>make install-deps</code> to install them.</li>
</ul>
</blockquote>
<blockquote>
<p dir="auto">Note: Some recipes can't compile in 0.11.0, so they are skipped in CI.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">This cookbook is a work in progress, and we welcome contributions from the community. If you have a favorite recipe that you'd like to share, please submit a <a href="https://github.com/zigcc/zig-cookbook/pulls">pull request</a>.</p>
<h2 tabindex="-1" dir="auto">Acknowledgment</h2>
<p dir="auto">When working on zig-cookbook, we benefit a lot from several similar projects, thanks for their awesome work.</p>
<ul dir="auto">
<li><a href="https://github.com/rust-lang-nursery/rust-cookbook">Rust Cookbook</a></li>
</ul>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">The markdown files are licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" rel="nofollow">CC BY-NC-ND 4.0 DEED</a>, and zig files are under MIT.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$450 for a School Bag? (114 pts)]]></title>
            <link>https://one-from-nippon.ghost.io/randoseru/</link>
            <guid>38837314</guid>
            <pubDate>Tue, 02 Jan 2024 02:17:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://one-from-nippon.ghost.io/randoseru/">https://one-from-nippon.ghost.io/randoseru/</a>, See on <a href="https://news.ycombinator.com/item?id=38837314">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Every year, around March, a curious social custom occurs in Japanese families.</p><p>Parents of kids entering elementary school visit the grandparents and gingerly tread the topic of buying the kids a very expensive item: a <em>randoseru</em>.</p><p>And gingerly they must tread. The <em>randoseru</em>, a Japanese school bag, costs a whopping 60,000 yen ($450) on average.</p><p>It is customary for grandparents to pay for these expensive bags and they are usually more than happy to.</p><h2 id="history">History</h2><p>During the Meiji Reforms of the late 1800s, Japan aimed to modernize and demonstrate to the world that it was as advanced a country as any other.</p><p>One tiny part of these reforms was the introduction of the rucksack (<em>ransel</em> in Dutch) for soldiers to carry their baggage.</p><p>After a few rounds of bastardization, <em>ransel</em>&nbsp;became “randoseru” in Japanese.</p><p>Now, another part of the reforms was revamping the education system. Several modern schools were established to this end. Most of the initial students were children of the affluent and aristocrats, who could afford such luxuries (and would then go on to occupy top posts, but I digress).</p><p>Gakushuin was one such school in Tokyo.</p><p>Despite being a private school for the nobility, Gakushuin had a few slots for commoners. It also had very egalitarian principles.</p><p>The school recognized that education was the great leveler and that students from different walks of life would attend. They wanted all students feel equal in school.</p><p>Japanese students, for the longest time, took their books to school in a <em>furoshiki</em>. A <em>furoshiki</em> is a … versatile, rectangular piece of cloth. There simply wasn’t a concept of a school bag.</p><figure><img src="https://one-from-nippon.ghost.io/content/images/2024/01/5892619045_3c48cd0f03_k.jpg" alt="" loading="lazy" width="2000" height="1333" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2024/01/5892619045_3c48cd0f03_k.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2024/01/5892619045_3c48cd0f03_k.jpg 1000w, https://one-from-nippon.ghost.io/content/images/size/w1600/2024/01/5892619045_3c48cd0f03_k.jpg 1600w, https://one-from-nippon.ghost.io/content/images/2024/01/5892619045_3c48cd0f03_k.jpg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>Furoshiki&nbsp;– Simple but elegant. </span><i><em>Source: </em></i><a href="https://flic.kr/p/9YHdm6?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>weekend knitter</em></i></a></figcaption></figure><p>The children of the affluent would carry their books in, lol, no they didn't carry shite. They had their servants carry their books to school.</p><p>Gakushuin did not like this one bit. They wanted students to learn responsibility and imposed two rules: 1) No commuting by car, rickshaw, or horse and 2) Students had to carry their own books and notebooks in a <em>randoseru</em>.</p><p>At this point, the <em>randoseru</em> still looked like your old-school military satchel. The first box-shaped <em>randoseru</em> was presented by Prime Minister Hirobumi Ito to the Crown Prince Taisho as a gift for entering elementary school. This is the shape that has endured to this day.</p><p>Despite the crown prince’s endorsement, the <em>randoseru</em> was too expensive for most. Since it was made of leather, only the wealthy could afford one. It was only when artificial leather was introduced in the 1950s, that <em>randoseru</em> became affordable for most of the population and popular.</p><h3 id="ran-katsu"><em>Ran</em>-<em>katsu</em></h3><p>Choosing a <em>randoseru</em> is no simple decision. It is a serious, time-consuming affair, involving three generations of the family. </p><p>Japanese even has a word for it: “<em>ran-katsu”</em> (ラン活): <em>ran-</em> for <em>randoseru</em> and <em>katsu</em> for 活動 (activity).&nbsp;</p><blockquote>Note: &lt;something something&gt;-<em>katsu</em> is a common Japanese thing. 就活 (‘shuu-katsu’) is the activity of looking for a job, 婚活 (kon-katsu) is trying to find a partner, 妊活 (‘nin-katsu’) is trying to conceive, and パパ活 (‘papa-katsu’) is … can you guess? Sugar daddying.</blockquote><p>Given how expensive it is, a <em>randoseru</em> is used throughout the six years of elementary school.</p><p>Parents and elementary school-goers-to-be first request paper catalogs from <em>randoseru</em> makers and visit <em>randoseru </em>exhibitions to find out what the next year's fashion is going to be.</p><p>They then visit multiple <em>randoseru</em> showrooms to find which colors and designs they like and which sizes fit well. They then place their orders (which are non-cancellable) and wait with bated breath for 6+ months as the bags are crafted. (There are also <em>randoseru</em> you can buy off the shelf but you don't get to customize these.)</p><p>The general advice is to start <em>ran-katsu</em> at least 18 months ahead of school.</p><figure><img src="https://one-from-nippon.ghost.io/content/images/2024/01/Schoolkids_wearing_hats_and_randoseru_in_Kugayama-_Japan-_January_2010.jpg" alt="" loading="lazy" width="1600" height="1200" srcset="https://one-from-nippon.ghost.io/content/images/size/w600/2024/01/Schoolkids_wearing_hats_and_randoseru_in_Kugayama-_Japan-_January_2010.jpg 600w, https://one-from-nippon.ghost.io/content/images/size/w1000/2024/01/Schoolkids_wearing_hats_and_randoseru_in_Kugayama-_Japan-_January_2010.jpg 1000w, https://one-from-nippon.ghost.io/content/images/2024/01/Schoolkids_wearing_hats_and_randoseru_in_Kugayama-_Japan-_January_2010.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Children carrying their </span><i><em>randoseru</em></i><span> to school in Tokyo </span><i><em>Source: </em></i><a href="https://commons.wikimedia.org/wiki/File:Schoolkids_wearing_hats_and_randoseru_in_Kugayama,_Japan;_January_2010.jpg?ref=one-from-nippon.ghost.io" rel="noreferrer"><i><em>Wikimedia</em></i></a></figcaption></figure><h3 id="but-why-is-it-so-expensive">But why is it so expensive?</h3><p>It’s valid to ask “What’s in a kid’s school bag for it to cost $400?!<em>”</em>.&nbsp;</p><p>In answering this question I realized just how much of our worldview is informed by everything we touch being mass produced. When we think of things like school bags, we imagine large machines in some factory in China spitting out pieces by the hundreds.</p><p>The <em>randoseru</em> is a little different.</p><p>A <em>randoseru</em> can have up to 200 die cut parts and polyurethane back plates, and are mostly assembled by hand, making it an expensive item to produce.</p><p>Every part is built and assembled with the utmost focus on quality and durability. After all, the bag needs to last throughout the six years of school, through rough and tumble, in the rain, in the humid summer, and in the snow. Take a look at how one of these manufacturers crafts one ↓</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/lSochjb6ovI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Tsuchiya Kaban | How we make Randoseru in our Japan studio"></iframe></figure><h3 id="the-user-the-buyer-and-the-sponsor">The User, the Buyer, and the Sponsor</h3><p>In a brilliant exposition of the difference between the user, the buyer, and the sponsor, the <em>randoseru</em> is used by the grandchildren, bought by the parents, and paid for by the grandparents.&nbsp;</p><p>A recent survey uncovered that about 60% of <em>randoseru</em> purchases in 2022 were paid for by grandparents.</p><p>This brings interesting challenges. Grandparents, who went to school many decades ago, have their own ideas on what to buy. In their days, there existed only two types of <em>randoseru</em> (red for girls and black for boys) and customization was limited.</p><p>This sometimes creates friction between the generations, with kids not liking what their grandparents want for them.</p><p>Watch this video from a <em>randoseru</em> manufacturer encouraging children to choose what <em>they</em> want. The kids are first asked to choose what they think their parents would like them to buy. They are then asked to choose what <em>they</em> want to buy. The difference is telling.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/r1Bic3Go2dY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="【セイバン公式】ランドセル選びドキュメンタリー篇"></iframe><figcaption><p><span>(Tip: Turn on Auto-translate inside ⚙️ for subtitles)</span></p></figcaption></figure><h3 id="but-is-a-randoseru-really-necessary">But is a <em>randoseru</em> really necessary?</h3><p>Curiously, there is <em>absolutely</em> no law, regulation, or rule that requires students to use a <em>randoseru</em>. It is one of those decades-old Japanese traditions has become the <em>de facto</em> choice.</p><p>No choice in life is devoid of downsides and there are a few with <em>randoseru</em> too.</p><p>Doctors are identifying a new class of problems as “<em>randoseru</em> symptoms”: a set of physical and mental issues caused by heavy and badly fitting <em>randoseru</em>.</p><p>In a survey by the Japanese Ministry of Education, today’s average <em>randoseru, </em>when fully loaded, weighs in at 6 kilograms (13.2 lbs.). That is a lot for a child to carry, especially since many children walk to school in Japan.</p><p>The priciness of <em>randoseru</em> also has many questioning the value. Why invest hundreds of dollars in a bag that is heavy and locks your child into a choice for six years? Worse, the cost of the <em>randoseru</em> also brings problems that it was originally meant to solve: it creates divisions between the richer and poorer children, paving the way for other issues.</p><p>A handful of Japanese towns have moved to cheaper, lighter alternatives. Some schools in Shimane prefecture have moved to city-provided lightweight nylon backpacks called <em>ran-bag</em>s (yeah, don’t ask me how they name things in Japan). Unlike the <em>randoseru</em>, these cost a much more affordable 8,000 yen (57 USD), are lighter, and just as durable.</p><h3 id="the-future">The Future?</h3><p>I don’t expect that the <em>randoseru</em> will completely disappear, but look forward to how it evolves as more schoolwork moves to digital devices. Perhaps there will come a day when children simply walk empty-handed to school. </p><p>But seeing how Japan is doing with eliminating fax machines I am not holding my breath…</p>
<!--kg-card-begin: html-->
<p>

We hope you enjoyed this article! If you haven't already, we would love it if you subscribed to our newsletter. It would encourage us <b>greatly</b> to create more interesting posts like this. Sign up from <a href="https://one-from-nippon.ghost.io/">here</a>.</p>
<!--kg-card-end: html-->
<hr>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<hr>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E621, Pornhub, and others block North Carolina residents (126 pts)]]></title>
            <link>https://www.foxcarolina.com/2023/12/29/major-pornographic-blocks-users-nc-response-new-law/</link>
            <guid>38836550</guid>
            <pubDate>Tue, 02 Jan 2024 00:09:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.foxcarolina.com/2023/12/29/major-pornographic-blocks-users-nc-response-new-law/">https://www.foxcarolina.com/2023/12/29/major-pornographic-blocks-users-nc-response-new-law/</a>, See on <a href="https://news.ycombinator.com/item?id=38836550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>RALEIGH, N.C. (FOX Carolina) - Pornography site Pornhub announced that they will be blocking their site to users in North Carolina just days before a new law in the state takes effect.</p><p>Under the new law, websites that publish material considered harmful to minors will be required to verify that users are 18 years or older.</p><p>Aylo, the parent company of Pornhub, released the following statement regarding the decision:</p><p>Officials explained that companies will be able to use commercially available databases to verify that users are old enough to access their content. The new law will take effect starting January 1st.</p><p>Stay with us as we work to learn more.</p><p><i>Copyright 2023 WHNS. All rights reserved.</i></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fireworks likely caused water contamination at Mount Rushmore (2016) (127 pts)]]></title>
            <link>https://www.usgs.gov/news/national-news-release/fireworks-likely-caused-water-contamination-mount-rushmore</link>
            <guid>38835845</guid>
            <pubDate>Mon, 01 Jan 2024 22:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usgs.gov/news/national-news-release/fireworks-likely-caused-water-contamination-mount-rushmore">https://www.usgs.gov/news/national-news-release/fireworks-likely-caused-water-contamination-mount-rushmore</a>, See on <a href="https://news.ycombinator.com/item?id=38835845">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure role="group">

  

<figcaption>USGS scientists&nbsp;collect composite soil samples at&nbsp;Mount Rushmore National Memorial.&nbsp;(Credit: Barbara Rowe, USGS)</figcaption>
</figure>
<p>Perchlorate is a compound used as an <a href="https://www.usgs.gov/mission-areas/water-resources/science/oxidationreduction-redox?qt-science_center_objects=0#qt-science_center_objects">oxidizing</a> agent in fireworks, and is a common component in rocket fuels, explosives and certain nitrogen fertilizers. At high levels in drinking water, perchlorate can interfere with the function of the human thyroid gland. However, the drinking water at Mount Rushmore meets current regulations and is safe for public consumption.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>Aerial fireworks displays took place at the memorial around the 1998-2009 Independence Days. The USGS and National Park Service studied perchlorate and metals associated with fireworks in 106 water and 11 soil samples taken from Mount Rushmore during 2011-2015. Perchlorate concentrations were greatest in samples collected from the northeast side of the memorial, and the scientists found perchlorate in soil where the fireworks were launched and where the debris landed.</p>
<p>“The lack of alternative perchlorate sources in the area, such as a military site or agricultural land with applied fertilizers, and the presence of firework debris suggest that past fireworks are the perchlorate source,” said Galen Hoogestraat, a USGS scientist and the lead author of the report. “Our results can help park managers protect water quality at this iconic national landmark.”</p>
<figure role="group">

  

<figcaption>This map shows the major drainage basins and sampling locations within the Mount Rushmore National Memorial&nbsp;study area. (Credit: USGS)</figcaption>
</figure>
<p>The main findings include:</p>
<ul>
<li>A maximum perchlorate concentration of 54 micrograms per liter (µg/L) measured in a stream sample, and 38 µg/L measured from a groundwater well. In contrast, all groundwater and stream samples collected from sites outside the memorial boundary had perchlorate concentrations less than 0.2 µg/L.</li>
<li>Concentrations of metals in water samples were similar at sites within and outside the memorial, indicating little evidence of metal contamination due to human-made factors.</li>
<li>Dynamite that was used to blast the memorial in the 1930s is not a likely source of the perchlorate because perchlorate is not a component of dynamite formulations.</li>
</ul>
<p>Drinking water is provided to about 3 million visitors to the memorial every year and to year-round park personnel. Perchlorate in drinking water is not currently regulated by the U.S. Environmental Protection Agency, but the park has planned for additional voluntary monitoring and treatment.</p>
<p>“The park will continue to strive to provide safe drinking water that meets and exceeds current standards,” said Cheryl Schreier, the Mount Rushmore National Memorial superintendent. “The USGS was an excellent partner committed to sound science throughout the process of sampling, analyzing, reviewing and finalizing the report and findings. The park is committed to ensuring the safety of the public and all of our employees, and preserving and protecting the natural and cultural resources with which we are entrusted.”</p>
<p>More information about this study is available on the <a href="http://sd.water.usgs.gov/">USGS South Dakota Water Science Center website</a>.</p>
<figure role="group">

  

<figcaption>Author interview:&nbsp;Galen Hoogestraat, USGS</figcaption>
</figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NERV Disaster Prevention (184 pts)]]></title>
            <link>https://nerv.app/en/</link>
            <guid>38835419</guid>
            <pubDate>Mon, 01 Jan 2024 21:16:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nerv.app/en/">https://nerv.app/en/</a>, See on <a href="https://news.ycombinator.com/item?id=38835419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="message-top"><p>
      In the aftermath of the Great East Japan Earthquake, when everything came to a standstill, the availability of information was the difference between life and death for many people. While some lives were saved by the information they had beforehand, others may have lost their lives because of it.</p><p>
      There must have been many lives that could have been saved if the information had been available immediately afterwards.<br>
      We, modern people, trust our lives to information.<br>
      Without information, action is delayed.</p><p>
      But when a disaster of that magnitude strikes, you have to use your intuition and act on your own before waiting for information.</p><p>
      <span>Excerpt from the description of the permanent exhibition at Rias Ark Museum</span><br>
      </p></div><div id="mainContainer">
    <div id="mainvisual">
      <header>
        
        <p><a href="https://nerv.app/en/"><img src="https://nerv.app/img/logo.png" alt="Image of the NERV Logo"></a></p>
        
      </header>

      
    </div>

    <div id="kmoni">
        <h2>
          <span>Release 2023.09.01</span><br>
          Strong-Motion Monitor Layer
        </h2>
        <div>
          <div><p>
            The Strong-Motion Monitor layer is a feature that displays the real-time shaking situation throughout Japan, as observed by the Strong-Motion Observation Network (a network of seismometers for recording strong shaking), operated by the National Research Institute for Earth Science and Disaster Resilience (NIED). When an Earthquake Early Warning (Forecast) is issued, the Strong-Motion Monitor layer automatically integrates and displays the information from the EEW, including the forecasted Seismic Intensity distribution, and estimated propagation of the P and S waves along side the Strong-Motion data.</p><p>
            If you enable Shaking Detection Notifications, you can receive Push Notifications when shaking from an earthquake is believed to have been detected. In some cases, it is possible to detect and be notified about earthquakes for which no Earthquake Early Warning has been issued. Please note that the detection method is not perfect, and notifications may be sent due to false positives.
          </p></div>
          <p><img src="https://nerv.app/img/kmoni-en.png" alt="kmoni images"></p>
          <p><img src="https://nerv.app/img/logo-3.png" alt="NEWSDIG NEID NERV"></p>
          <p>
            The Strong-Motion Monitor layer has been experimentally worked on since February 2023 based on the "Joint Research Implementation Plan for the Utilisation of Strong-Motion Monitor Data" which was established by four parties: the National Research Institute for Earth Science and Disaster Resilience (NIED), Gehirn Inc., TBS Television Inc., and TBS / JNN NEWS DIG LLC. This service has been made available to the general public through the "Mutual Cooperation Agreement for the Utilisation of Strong-Motion Monitor Data". Gehirn Inc. processes and distributes the information received from a dedicated communications line installed at NIED. This dedicated line uses a redundant configuration to ensure a fast and reliable service for the NERV Disaster Prevention app. Please note that this is a separate service from the "Strong-Motion Monitor" web service provided by NIED.
          </p>
        </div>
      </div>

    <div id="update">
          <div>
            <h2>
              <span>Towards Universal Design</span><br>
              Accessibility for all
            </h2>
            <p>
              Tailor the app’s interface to your own preference.<br>
              Choose a colour scheme that’s optimised for colour vision deficiency/colour blindness<sup>(※1)</sup>, change the contrast to suit visual sensitivity<sup>(※2)</sup> and low vision, adjust the text size and thickness, or even make use of VoiceOver, throughout the app.<br>
              Learn more on the <a href="https://nerv.app/en/about.html">Accessibility Features</a> page.
            </p>
            <p>
              ※ 1.  Colour vision deficiency can be a group of eye conditions in which the photoreceptor cells (cone cells) that identify colours, recognise and discriminate differently from the majority. There are three types: Standard colour vision, Deuteranopia/Protanopia (red/green colour deficiency), Tritanopia (blue/yellow colour deficiency), and Monochromacy (achromatopsia/complete colour deficiency).<br>
              ※ 2.  Visual hypersensitivity is a sensory sensitivity of the eyes to brightness and colour. Symptoms include difficulty keeping the eyes open due to glare from the sun, and inability to look directly at certain colours or combinations of colours, such as primary colours.
            </p>
            
          </div>
          <div>
            
            <p><img id="display" src="https://nerv.app/img/bg-update-en.png" alt="Light Theme Images">
            <img id="display-sp" src="https://nerv.app/img/bg-update-sp.png" alt="Light Theme Images">
          </p></div>
        </div>

    <div id="introduction-top"><p>
            The NERV Disaster Prevention app is a smartphone service that delivers optimised disaster prevention and weather information, such as earthquake, tsunami and volcanic eruption bulletins, as well as landslide, flooding and inundation risk information based on the user’s current and registered locations. The app has been developed to assist residents and visitors to areas where damage is expected to occur to accurately recognise the situation and make quick decisions to be able to take action.</p><p>
            The provided disaster prevention and weather information is received directly through a dedicated line connected to the Meteorological Service Support Centre (in both the main building of the Japan Meteorological Agency and the Osaka District Meteorological Observatory) to ensure the reliability of the information, and our independently developed technology enables the fastest level of information distribution in Japan.
          </p></div>

    <div id="about">
        <h2>Various Disaster Information<span>All in One Place</span></h2>
        <p>
            Receive a wide range of disaster prevention information - real-time earthquake early warnings (with expected seismic intensity at your current location and a countdown until the arrival of shaking), earthquake, tsunami, and volcanic eruption early warnings, weather warnings and advisories, landslide, flooding and inundation risk distribution, rain cloud radar, real-time weather observations, typhoon information, ashfall forecasts, snow depth, and even J-Alert (Civil Protection Information) - in just one app. By touching the map displayed on the screen, you can view rain cloud conditions and local seismic intensity at any scale.
          </p>
      </div>

    <div id="information">
          <div>
            <h2>Providing Users With the Most Appropriate Disaster Information</h2>
            <div><p>
              The home screen displays the information you need at the time and place you need it. When there’s an earthquake, the home screen will show you the latest information. If another type of warning or alert is issued while the earthquake is active, the app will sort them depending on the type, elapsed time and urgency, so you’ll always have the most important information at your fingertips.</p><p>
              The timeline screen shows you information related to your current location (or your registered areas) for the past three days. Before a flood or landslide caused by heavy rain, a lot of relevant information will be available, so you can confirm and react to the immediate situation at a glance.</p></div>
          </div>
          <p><img src="https://nerv.app/img/feature01-en.png" alt="Home window, Timeline window, and Earthquake window">
          </p>
        </div>

    <div id="features">
        <div>
          <div>
            <p><span>FEATURE 01</span></p><h2>At-a-glance design</h2>
            <p>
              Disaster prevention and weather information are integrated with an easy-to-understand map interface, so you can find the information you need at a glance. On the home screen, information is automatically sorted according to importance.
            </p>
          </div>
          <div>
            <p><span>FEATURE 02</span></p><h2>Useful for daily activities</h2>
            <p>
              Check the rain cloud radar and weather forecasts, as well as other useful daily information such as current temperature, wind speed and direction and volcanic ashfall forecasts.
            </p>
          </div>
        </div>
        <div>
          <div>
            <p><span>FEATURE 03</span></p><h2>Unobtrusive by nature</h2>
            <p>
              We don’t send unnecessary push notifications such as advertisements or announcements. There are no advertisements or pop-ups in the app that interfere with operation. We only provide you with the information you need for disaster prevention.
            </p>
          </div>
          <div>
            <p><span>FEATURE 04</span></p><h2>Real-time updates</h2>
            <p>
              Real-time earthquake alerts that display the expected seismic intensity at your current location and the number of seconds until arrival, seismic intensity and tsunami information that is automatically updated while the screen is open, and lightning strike information* that is updated every minute. Other frequently updated information is also immediately reflected.<br>
              <span>* Lightning strike information is currently only available through Early Access to Supporters’ Club members.</span>
            </p>
          </div>
        </div>
      </div>

    <div id="notification-top">
          <div>
            <h2>Push Notifications for Important Information</h2>
            <p>
              We send out different types of notifications depending on the device’s location, the type of information and level of urgency. If the information is not urgent, we send a silent notification as not to disturb the user. For more urgent situations where a disaster is time-sensitive, a ‘Critical Alert’ alerts the user to an imminent danger. Notifications like Earthquake Early Warnings (Alert level) and Tsunami Warnings will be forced to sound, even if the device is in Silent or Do Not Disturb modes.
            </p>
            <p>
              ※ If you prefer not to have critical alerts, you can disable them at any time from; [iOS] Settings &gt; Notifications &gt; Critical Alerts, or [Android] Settings &gt; Notifications &gt; Silent Mode Exception (Android 9.0 or later). When disabled, critical alerts will be treated as normal notifications.
            </p>
          </div>
          <p><img src="https://nerv.app/img/feature02-en.png" alt="A Critical Alert is shown on the lock screen"></p>
        </div>

    <div id="intro-supporters">
        <h2>Supporters' Club</h2>
        <div><p>
          The "NERV Disaster Prevention App Supporters Club" is a fan club where users can choose to support the NERV Disaster Prevention App through a monthly subscription. You'll get access to exclusive perks, like "early access" to new/unreleased features, an increased number of registered locations, and access to members-only content on higher plans.</p><p>
          In order to continue to provide a stable service and to strengthen our research and development efforts, we decided to establish the Supporters' Club. For more information, take a look at the Supporters' Club homepage.
        </p></div>
        <h3>Plans</h3>
        <dl>
          <dt>E Plan<span>¥250/m*</span></dt>
          <dd>
            
          </dd>
        </dl>
        <dl>
          <dt>EE Plan<span>¥480/m*</span></dt>
          <dd>
            
            
          </dd>
        </dl>
        <p>* Please note that the subscription price is determined by the App Store/Google Play Store based on the country/region your Apple ID/Google Play account is associated with, and may be different from the price displayed above.</p>
        </div>

    <div id="cm">
      <h2>Disaster Awareness Series</h2>
      <p>We created this series of commercials as a message of 'self-discipline' to ourselves. Japan is a country that experiences frequent natural disasters, so it's important that the message we wish to convey with this series, is that "so long as you're here, be prepared".</p>
      <ul>
        <li>
          <p><span>
              <img src="https://nerv.app/img/cm01.png" alt="Natural Disaster Monument">
            </span>
          </p>
          <p>"Natural Disaster Monument"<br>Released 2020.12.11</p>
        </li>
        <li>
          <p><span>
              <img src="https://nerv.app/img/cm02.png" alt="The History of Tsunamis">
            </span>
          </p>
          <p>"The History of Tsunamis"<br>Released 2021.01.11</p>
        </li>
        <li>
          <p><span>
              <img src="https://nerv.app/img/cm03.png" alt="As Quickly As Possible">
            </span>
          </p>
          <p>"As Quickly As Possible"<br>Released 2021.02.11</p>
        </li>
        <li>
          <p><span>
              <img src="https://nerv.app/img/cm04.png" alt="Our Duty">
            </span>
          </p>
          <p>"Our Duty" <br>Released 2021.03.12</p>
        </li>
      </ul>
      
      <p>Voice Actor: Koichi Yamadera / Planning and Production: Gehirn Inc. / Video Production: mimoid inc. and Shunsuke Sugiyama / Music Production: PASOCOM MUSIC CLUB / Cooperation: Geospatial Information Authority of Japan</p>
    </div>

    <div id="cm-phev">
        <h2>
          <span>NERV Disaster Response Vehicle Introduction Video</span><br>
          Reflection is about thinking about the future
        </h2>
        <div>
          <p>
            The NERV Disaster Response Vehicle is a PHEV, a hybrid vehicle with power generation capabilities, that can be deployed to ensure that our information dissemination activities can continue in the event of an accident or disaster that results in a prolonged power outage.
          </p>
          <p>
            When we imagined what would happen if a blackout like the one caused by the 2018 Hokkaido Eastern Iburi earthquake were to occur in the Tokyo metropolitan area, we could see ourselves helplessly regretting our lack of preparedness. As long as such events are possible, we want to be as prepared as possible.
          </p>
          <p>
            Voice Actor: Tetsuya Iwanaga (portrayed Kensuke Aida in the Neon Genesis: Evangelion series) / Planning and Production: Gehirn Inc. / Video Production: mimoid inc. and Shunsuke Sugiyama / Music Production: PASOCOM MUSIC CLUB / Audio Production: Takaki Kato (TREE Digital Studio) / Assistants: Ayuko Kuwata, Kanta Doki, Yutaro Nakamura / Cooperation: Mitsubishi Motors Corporation
          </p>
        </div>
        <div>
          <p><span>
              <img src="https://nerv.app/img/cm05.png" alt="Preparing for power outages">
            </span>
          </p>
        </div>
      </div>

    <div id="message"><p>
        In the aftermath of the Great East Japan Earthquake, when everything came to a standstill, the availability of information was the difference between life and death for many people. While some lives were saved by the information they had beforehand, others may have lost their lives because of it.</p><p>
        There must have been many lives that could have been saved if the information had been available immediately afterwards.<br>
        We, modern people, trust our lives to information.<br>
        Without information, action is delayed.</p><p>
        But when a disaster of that magnitude strikes, you have to use your intuition and act on your own before waiting for information.</p><p>
        <span>Excerpt from the description of the permanent exhibition at Rias Ark Museum</span></p></div>

    <div id="reliability">
          <h2>Reliability</h2>
          <div>
            <h3>Privacy</h3>
            <p>
              The NERV Disaster Prevention app puts user privacy and security first. The app does not acquire any information about the user or their device that are not required to help the app to function. The user’s detailed location information (precise position) is only used for disaster prevention purposes and is calculated and processed entirely on-device, and is never transmitted externally. Location information required for push notifications of disaster prevention information is stored on the device only after having been converted to an area code (similar to that of a postcode). No location history is stored either on your device or the server, so your movements cannot be tracked.
            </p>
          </div>
          <div>
            <h3>Credibility</h3>
            <p>
              The Earthquake Early Warning service of the NERV Disaster Prevention app has been reviewed for operational systems, equipment and technical suitability, and is distributed under a licence from the Director General of the Japan Meteorological Agency to forecast earthquake ground motion. The <a href="https://www.jma.go.jp/jma/kishou/know/bosai/ame_push.html" target="_blank" rel="noopener">Risk Distribution notification service</a> was jointly developed with the JMA as a cooperating operator. Other disaster prevention and weather information that’s displayed in the app is processed independently based on JMA data. The maps are independently created based on the Geographical Survey Institute’s map data.
            </p>
          </div>
          <div>
            <h3>System Reliability</h3>
            <p>
              The NERV Disaster Prevention app’s information processing system is connected by a dedicated line to the Japan Meteorological Agency’s main office in Tokyo, and the Meteorological Service Support Centre at the Osaka District Meteorological Observatory. The system is geographically redundant with multiple data centres based in Tokyo and Osaka, and is designed to be able to continue working in the event of a major disaster.
            </p>
          </div>
        </div>

    <div id="support-info">
      <h2>Support Information</h2>
      <div>
        <div>
          <p><img src="https://nerv.app/img/icon-q.svg" alt="question mark"></p><h3>Check the FAQ first!</h3>
          <p>The FAQ page answers questions we frequently receive, as well as includes additional information on how to manage your Supporters’ Club subscription.</p>
          </div>
        <div>
          <p><img src="https://nerv.app/img/icon-mail.svg" alt="E-mail icon"></p><h3>If the problem persists...</h3>
          <p>If your question was not answered on the FAQ page, please contact us via the Contact Us form. <span>※ Please note that our responses may be delayed as we’re only a small team of developers.</span></p>
          </div>
      </div>
      <div>
        <div>
          <h3>Privacy <sup>※3</sup></h3>
          <p>Acquired location information and registered area information is used only for displaying disaster prevention information and sending push notifications. Location information sent from the application to the server is converted into an area code or mesh code in advance, within the application (client side), and only those codes are sent over the internet. In other words, the user’s detailed location coordinates never leave your device.</p>
        </div>
        <div>
          <h3>Battery Consumption <sup>※4</sup></h3>
          <p>If the app's location setting is set to "Always Allow," the app will periodically retrieve your location in the background. This should have very little impact on your battery life. Also, when "Low Power Mode" is enabled, the app will not update your location in order to reduce power consumption.</p>
        </div>
        <div>
          <h3>Requests and Feedback</h3>
          <p>Please use the review function on the App Store or Google Play Store for any requests or feedback regarding additional features or quality improvements. ※ Please note that we may not respond to requests submitted via the Contact Us form.</p>
        </div>
      </div>
    </div>

    <div id="mention">
        <div><p>
          The NERV Disaster Prevention App is a smartphone service that delivers earthquake, tsunami, volcanic eruption and emergency warnings, as well as provides weather-related disaster prevention information for flooding and landslides, optimised based on the user's current and registered locations. It was developed to help people living in or visiting an area where damage is expected to occur, to accurately assess the situation and make quick decisions and actions.</p><p>
          With information received directly through a leased line connected to the Japan Meteorological Agency, our proprietary technology enables the fastest information distribution in Japan.
        </p></div>
        
        <div><p>
          ※3 Gehirn Inc. is first and foremost an information security company. The security and privacy of our users is our highest priority. We take great care not to collect excessive amounts of information about our users through this application.</p><p>
          Acquired location and registered location information is used only for displaying disaster prevention information, and for sending push notifications. The location information that's sent from the app to the server is first converted to an area code. An area code is roughly equivalent to a zip code. Only that code is sent to the server, meaning the user's exact location is never sent to the server.</p><p>For example, if you were located in "Chiyoda-ku, Tokyo", it will be converted to a code that is used by everyone in Chiyoda-ku, so no one will ever be able to trace your exact location back to you. Additionally, the server doesn't store past area codes, so your movements cannot be tracked.</p><p>
          All data sent over the internet is first encrypted, and all data stored in the server's database is encrypted before being stored. If you ever set your location permissions to "Do Not Allow" or "Allow Only While Using", the registration information will be deleted from the server. Additionally, if the user ever uninstalls the app, the registration information will automatically be deleted from the server roughly one month after the app last tried to communicate with the server.
        </p></div>
        <div><p>
          ※4. In order to receive notifications about disasters related to your current location; [iOS] Set Location permissions to "Always Allow" and enable "Background App Refresh". [Android] Set Location permissions to "Always Allow".</p><p>
          When you set the app's location permissions to "Always Allow", the app will periodically retrieve your location in the background. This doesn't happen often, so the battery usage impact is negligible. Additionally, if "Low Power Mode" is enabled, the app will not update your location in the background in order to save power.
        </p></div>
        
        <ul>
          <li>The name and logo of "NERV" are used with the explicit permission of khara Inc., the copyright holder of the "Evangelion" series, and Groundworks Corporation, which manages the rights to the series.</li>
          <li>The fonts "AXIS" and "DIN 2014" are used under the paid license terms set by each respective type foundry. The "Inter" font is graciously used as part of the SIL Open Font License 1.1.</li>
          <li>The explanatory text for the permanent exhibition of "Rias Ark Museum" on this website is taken from the keyword "Information" panel of the permanent exhibition "History and Records of the Great East Japan Earthquake and Tsunami Disaster", and is used under the permission of Rias Ark Museum.</li>
        </ul>
      </div>

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[uBlacklist: Blocks specific sites from appearing in Google search results (219 pts)]]></title>
            <link>https://github.com/iorate/ublacklist</link>
            <guid>38835345</guid>
            <pubDate>Mon, 01 Jan 2024 21:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/iorate/ublacklist">https://github.com/iorate/ublacklist</a>, See on <a href="https://news.ycombinator.com/item?id=38835345">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">uBlacklist</h2>
<p dir="auto"><a href="https://github.com/iorate/ublacklist/blob/master/README.zh-CN.md">简体中文</a></p>
<p dir="auto">Blocks specific sites from appearing in Google search results</p>
<p dir="auto"><a href="https://chrome.google.com/webstore/detail/ublacklist/pncfbmialoiaghdehhbnbhkkgmjanfhe" rel="nofollow">Chrome Web Store</a> / <a href="https://addons.mozilla.org/en-US/firefox/addon/ublacklist/" rel="nofollow">Firefox Add-ons</a> / <a href="https://apps.apple.com/us/app/ublacklist-for-safari/id1547912640" rel="nofollow">App Store</a> (for macOS and iOS, thanks to <a href="https://github.com/HoneyLuka/uBlacklist/tree/safari-port/safari-project">Group-Leafy</a>)</p>
<h2 tabindex="-1" dir="auto">Description</h2>
<p dir="auto">This extension prevents the sites you specify from appearing in Google search results.</p>
<p dir="auto">You can add rules on search result pages, or on sites to be blocked by clicking the toolbar icon. Rules can be specified either by <a href="https://developer.mozilla.org/en-us/docs/mozilla/add-ons/webextensions/match_patterns" rel="nofollow">match patterns</a> (e.g. <code>*://*.example.com/*</code>) or by <a href="https://developer.mozilla.org/en-us/docs/web/javascript/guide/regular_expressions" rel="nofollow">regular expressions</a> (e.g. <code>/example\.(net|org)/</code>).</p>
<p dir="auto">You can synchronize rulesets across devices via cloud storage. At the moment, Google Drive and Dropbox are supported.</p>
<p dir="auto">You can also subscribe to public rulesets. Some subscriptions are listed on the website:
<a href="https://iorate.github.io/ublacklist/subscriptions" rel="nofollow">https://iorate.github.io/ublacklist/subscriptions</a></p>
<h2 tabindex="-1" dir="auto">Supported search engines</h2>
<p dir="auto">This extension is available in the below search engines.</p>
<table>
<thead>
<tr>
<th></th>
<th>Web</th>
<th>Images</th>
<th>Videos</th>
<th>News</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Bing</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Brave *3</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Ecosia</td>
<td>✔️</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Qwant</td>
<td>✔️</td>
<td>✔️</td>
<td>*1</td>
<td>✔️</td>
</tr>
<tr>
<td>SearX *2</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Startpage</td>
<td>✔️</td>
<td></td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Yahoo! JAPAN</td>
<td>✔️</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Yandex</td>
<td>✔️</td>
<td></td>
<td></td>
<td>✔️</td>
</tr>
</tbody>
</table>
<p dir="auto">*1 Only if "Always play videos on Qwant.com" is turned off<br>
*2 Only certain public instances are supported. If you want to add support for your own SearX/SearXNG search engine, edit <code>src/common/search-engines.ts</code> and build the extension manually<br>
*3 Due to the difficulty in obtaining the full URLs of image links, this extension does not support per-subdomain blocking in Brave Image Search. (For example, if the link is to "<a href="http://www.example.com/" rel="nofollow">www.example.com</a>", it will block the entire "example.com").</p>
<h2 tabindex="-1" dir="auto">For subscription providers</h2>
<p dir="auto">To publish a ruleset as a subscription, place a ruleset file encoded in UTF-8 on a suitable HTTP(S) server, and publish the URL. Here is an example hosted on GitHub:<br>
<a href="https://raw.githubusercontent.com/iorate/ublacklist-example-subscription/master/uBlacklist.txt" rel="nofollow">https://raw.githubusercontent.com/iorate/ublacklist-example-subscription/master/uBlacklist.txt</a></p>
<p dir="auto">In uBlacklist &gt;=6.6.0 for <em>Chrome</em>, subscription links are available. To add a subscription with <code>name</code> and <code>url</code>, the following URL can be used as a shortcut to the options page:</p>
<div data-snippet-clipboard-copy-content="https://iorate.github.io/ublacklist/subscribe?name={urlEncode(name)}&amp;url={urlEncode(url)}"><pre><code>https://iorate.github.io/ublacklist/subscribe?name={urlEncode(name)}&amp;url={urlEncode(url)}
</code></pre></div>
<p dir="auto">For the above example:<br>
<a href="https://iorate.github.io/ublacklist/subscribe?name=Example&amp;url=https%3A%2F%2Fraw.githubusercontent.com%2Fiorate%2Fublacklist-example-subscription%2Fmaster%2FuBlacklist.txt" rel="nofollow">https://iorate.github.io/ublacklist/subscribe?name=Example&amp;url=https%3A%2F%2Fraw.githubusercontent.com%2Fiorate%2Fublacklist-example-subscription%2Fmaster%2FuBlacklist.txt</a></p>
<h2 tabindex="-1" dir="auto">For developers</h2>
<h3 tabindex="-1" dir="auto">Build</h3>
<p dir="auto">To build this extension, <a href="https://nodejs.org/en/" rel="nofollow">Node.js</a>&gt;=16 and <a href="https://yarnpkg.com/" rel="nofollow">Yarn</a> are required.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/iorate/ublacklist.git

cd ublacklist

yarn

# yarn build <browser:=chrome-mv3> <mode:=development>
yarn build firefox production"><pre>git clone https://github.com/iorate/ublacklist.git

<span>cd</span> ublacklist

yarn

<span><span>#</span> yarn build &lt;browser:=chrome-mv3&gt; &lt;mode:=development&gt;</span>
yarn build firefox production</pre></div>
<p dir="auto">Before opening a pull request, you should make sure that <code>yarn lint</code>, <code>yarn test</code>, and <code>yarn build-all</code> pass.</p>
<div dir="auto" data-snippet-clipboard-copy-content="yarn lint
# Some lint errors can be fixed automatically
# yarn fix

yarn test

yarn build-all"><pre>yarn lint
<span><span>#</span> Some lint errors can be fixed automatically</span>
<span><span>#</span> yarn fix</span>

yarn <span>test</span>

yarn build-all</pre></div>
<p dir="auto"><strong>NOTE:</strong> The API keys and secrets for the sync feature are not included in this repository. To develop the sync feature, set your own API keys and secrets in the <code>.env</code> file.</p>
<div data-snippet-clipboard-copy-content="DROPBOX_API_KEY=...
DROPBOX_API_SECRET=...
GOOGLE_DRIVE_API_KEY=...
GOOGLE_DRIVE_API_SECRET=..."><pre><code>DROPBOX_API_KEY=...
DROPBOX_API_SECRET=...
GOOGLE_DRIVE_API_KEY=...
GOOGLE_DRIVE_API_SECRET=...
</code></pre></div>
<h3 tabindex="-1" dir="auto">Locale</h3>
<p dir="auto">To add a locale,</p>
<ol dir="auto">
<li>Determine an ISO language code such as <code>en</code> referring to <a href="https://src.chromium.org/viewvc/chrome/trunk/src/third_party/cld/languages/internal/languages.cc" rel="nofollow">kLanguageInfoTable</a>.</li>
<li>Copy <code>src/locales/en.json.ts</code> to <code>src/locales/${languageCode}.json.ts</code> and translate entries.</li>
<li>Open <code>src/scripts/dayjs-locales.ts</code> and import the dayjs locale.</li>
<li>To localize description and screenshots on web stores, create <code>web-store-assets/${languageCode}/</code> and add files.
<ul dir="auto">
<li>Screenshot localization is available only on Chrome Web Store.</li>
<li>Screenshots should be 1280x800.</li>
</ul>
</li>
</ol>
<h2 tabindex="-1" dir="auto">Author</h2>
<p dir="auto"><a href="https://github.com/iorate">iorate</a> (<a href="https://twitter.com/iorate" rel="nofollow">Twitter</a>)</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">uBlacklist is licensed under <a href="https://github.com/iorate/ublacklist/blob/master/LICENSE.txt">MIT License</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyPy has moved to Git, GitHub (162 pts)]]></title>
            <link>https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html</link>
            <guid>38834895</guid>
            <pubDate>Mon, 01 Jan 2024 20:06:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html">https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html</a>, See on <a href="https://news.ycombinator.com/item?id=38834895">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody text">
      <p>PyPy has moved its canonical repo and issue tracker from
<a href="https://foss.heptapod.net/pypy/pypy">https://foss.heptapod.net/pypy/pypy</a> to <a href="https://github.com/pypy/pypy">https://github.com/pypy/pypy</a>. Obviously,
this means development will now be tracked in Git rather than Mercurial.</p>
<h3 id="motivation">Motivation<a href="#motivation" title="Permalink to this heading">¶</a></h3>
<p>We still feel Mercurial is a better version control system. The named branch
model and user interface are superior. But</p>
<ul>
<li>
<p>foss.heptapod.net is not well indexed in google/bing/duckduckgo
  search, so people find it harder to search for issues in the project.</p>
</li>
<li>
<p>Since Heptapod has tightened its spam control, we get reports that
  users create issues only to have them flagged as spam.</p>
</li>
<li>
<p>Open Source has become synonymous with GitHub, and we are too small to
  change that.</p>
</li>
<li>
<p>Much of the current development comes as a reaction to fixing issues.
  Tracking interlocking issues is easier if all the code is on the same
  platform.</p>
</li>
<li>
<p>The <a href="https://doc.pypy.org/en/latest/faq.html#why-doesn-t-pypy-use-git-and-move-to-github">FAQ</a>
  presents two arguments against the move. <a href="https://git-scm.com/docs/git-notes">Github notes</a>
  solves much of point (1): the difficulty of discovering provenance of
  commits, although not entirely. But the main problem is point (2), it turns
  out that <strong>not</strong> moving to GitHub is an impediment to contribution and issue
  reporting.</p>
</li>
<li>
<p>People who wish to continue to use Mercurial can use the same method below to
  push to GitHub.</p>
</li>
<li>
<p>GitHub is more resource rich than foss.heptapod.net. We could add CI
  jobs to replace some of our aging <a href="https://buildbot.pypy.org/">buildbot
  infrastructure</a>.</p>
</li>
</ul>
<h3 id="method">Method<a href="#method" title="Permalink to this heading">¶</a></h3>
<p>The migration required two parts: migrating the code and then migrating the
issues and merge requests.</p>
<h4 id="code-migration-1-code-and-notes">Code migration 1: code and notes<a href="#code-migration-1-code-and-notes" title="Permalink to this heading">¶</a></h4>
<p>I used a <a href="https://github.com/mnauw/git-remote-hg">fork of git-remote-hg</a> to
create a local Git repo with all the changesets. Then I wanted to add a Git
note to each commit with the branch it came from. So I prepared a file with two
columns: the Git commit hash, and the corresponding branch from Mercurial.
Mercurial can describe each commit in two ways: either the commit hash or by a
number index. I used <code>hg log</code> to convert an index <code>i</code> to the Mercurial hash,
and then <code>git-hg-helper</code> from <code>git-remote-hg</code> to convert the Mercurial hash to
a Git hash:</p>
<div><pre>$(cd pypy-git; git-hg-helper git-rev $(cd ../pypy-hg; hg log -r $i -T"{node}\n"))
</pre></div>

<p>Then I used <code>hg log</code> again to print the Mercurial branch for the index <code>i</code>:</p>
<div><pre>$(cd pypy-hg; hg log -r $i -T'{branch}\n')
</pre></div>

<p>Putting these two together, I could loop over all the commits by their
numerical index to prepare the file. Then I iterated over each line in the
file, and added the Git note. Since the <code>git note add</code> command works on the
current HEAD, I needed to checkout each commit in turn and then add the note:</p>
<div><pre>git checkout -q &lt;hash&gt; &amp;&amp; git notes --ref refs/notes/branch add -m branch:&lt;branch&gt;
</pre></div>

<p>I could then use <code>git push --all</code> to push to GitHub.</p>
<h4 id="code-migration-2-prepare-the-branches">Code migration 2: prepare the branches<a href="#code-migration-2-prepare-the-branches" title="Permalink to this heading">¶</a></h4>
<p>PyPy has almost 500 open branches. The code migration created all the branch
HEADs, but <code>git push --all</code> did not push them. I needed to check them out and
push each one. So I created a file with all the branch names</p>
<div><pre>cd pypy-hg; hg branches | cut -f1 -d" " &gt; branches.txt
</pre></div>

<p>and then push each one to the GitHub repo</p>
<div><pre><span>while</span><span> </span><span>read</span><span> </span><span>branch</span><span>; do git checkout branches/$branch &amp;&amp; git push origin branches/$branch; done &lt; branches.txt</span>
</pre></div>

<p>Note that the branches were named <code>branches/XXX</code> by the migration, not <code>branch/XXX</code>. This confuses the merge request migration, more about that later.</p>
<h4 id="issue-and-merge-request-migration">Issue and merge request migration<a href="#issue-and-merge-request-migration" title="Permalink to this heading">¶</a></h4>
<p>I used the solution from
<a href="https://github.com/piceaTech/node-gitlab-2-github">node-gitlab-2-github</a> which
worked almost perfectly. It is important to do the conversion on a <strong>private
repo</strong> otherwise every mention of a sucessfully mapped user name notifies
the user about the transfer. This can be quite annoying for a repo the size of
PyPy with 600 merge requests and over 4000 issues. Issues transfered without a
problem: the script properly retained the issue numbers. However the script
does not convert the Mercurial hashes to Git hashes, so the bare hashes in
comments show up without a link to the commit. Merge requests are more of a problem:</p>
<ul>
<li>The Mercurial named branch "disappears" once it is merged, so a merge request
  to a merged branch does not find the target branch name in Git. The
  conversion creates an issue instead with the label <code>gitlab merge request</code>.</li>
<li>For some reason, the branches created by <code>git-remote-hg</code> are called
  <code>branches/XXX</code> and not <code>branch/XXX</code> as expected by GitLab. This messes up the
  merge request/PR conversion. For some of the branches (open PRs and main
  target branches) I manually created additional branches without the <code>es</code>. The
  net result is that open merge requests became open PRs, merged merge requests
  became issues, and closed-not-merged merge requests were not migrated.</li>
</ul>
<h4 id="layered-conversions">Layered conversions<a href="#layered-conversions" title="Permalink to this heading">¶</a></h4>
<p>PyPy already migrated once from Bitbucket to Heptapod. Many of the issues
reflect the multiple transitions: they have lines like "Created originally on
Bitbucket by XXX" from the first transition, and an additional line "In
Heptapod" from this transition.</p>
<h3 id="credits">Credits<a href="#credits" title="Permalink to this heading">¶</a></h3>
<p>We would like to express our gratitude to the <a href="https://octobus.net/">Octobus</a>
team who support Heptapod. The transition from Bitbucket was quite an effort,
and they have generously hosted our developement since then. We wish them all
the best, and still believe that Mercurial should have "won".</p>
<h3 id="next-steps">Next steps<a href="#next-steps" title="Permalink to this heading">¶</a></h3>
<p>While the repo at GitHub is live, there are still a few more things we need to
do:</p>
<ul>
<li>Documentation needs an update for the new repo and the build automation from
  readthedocs must be adjusted.</li>
<li>The wiki should be copied from Heptapod.</li>
<li>buildbot.pypy.org should also look at the new repo. I hope the code is up to
  the task of interacting with a Git repo.</li>
<li>speed.pypy.org tracks changes, it too needs to reference the new location</li>
<li>To keep tracking branches with Git notes on new commits, I activated a
  <a href="https://github.com/Julian/named-branch-action">github action</a> by Julian to
  add a Git branch note to each commit. Please see the README there for
  directions on using Git notes.</li>
<li>Some of the merge requests were not migrated. If someone wants to, they could
  migrate those once they figure out the branch naming problems.</li>
</ul>
<p>Additionally, now is the time for all of you to prove the move is worthwhile:</p>
<ul>
<li>Star the repo, let others know how to find it,</li>
<li>Help fix some of the open issues or file new ones,</li>
<li>Take advantage of the more familiar workflow to get involved in the project,</li>
<li>Suggest ways to improve the migration: are there things I missed or could
  have done better?</li>
</ul>
<h3 id="how-will-development-change">How will development change?<a href="#how-will-development-change" title="Permalink to this heading">¶</a></h3>
<p>Heptapod did not allow personal forks, so we were generous with a commit bit to
the main repo. Additionally, we (well, me) have been using a
commit-directly-to-main workflow. We will now be adopting a more structured
workflow. Please fork the repo and submit a pull request for any changes. We
can now add some pre-merge CI to check that the PR at least passes the first
stage of translation. The live and active branches will be:</p>
<ul>
<li>
<code>main</code>: what was "default" in Mercurial, it is the Python2.7 interpreter and
  the base of the RPython interpreter,</li>
<li>
<code>py3.9</code>: the Python3.9 interpreter, which also includes all RPython changes
  from <code>main</code>. This is exactly like on Mercurial, and</li>
<li>
<code>py3.10</code>: the Python3.10 interpreter, which also includes all RPython changes
  from <code>main</code> and all bugfixes from <code>py3.9</code>. This is exactly like on Mercurial.</li>
</ul>
<h4 id="working-between-the-repos">Working between the repos<a href="#working-between-the-repos" title="Permalink to this heading">¶</a></h4>
<h5 id="finding-commits">Finding commits<a href="#finding-commits" title="Permalink to this heading">¶</a></h5>
<p>If you want to figure out how a Mercurial commit relates to a Git commit, you
can use <code>git-hg-helper</code>. You run it in the Git repo. It takes the full long
hash from one repo and gives you the corresponding hash of the other repo:</p>
<div><pre>$<span> </span>git-hg-helper<span> </span>git-rev<span> </span>d64027c4c2b903403ceeef2c301f5132454491df
4527e62ad94b0e940a5b0f9f20d29428672f93f7
$<span> </span>git-hg-helper<span> </span>hg-rev<span> </span>4527e62ad94b0e940a5b0f9f20d29428672f93f7
d64027c4c2b903403ceeef2c301f5132454491df
</pre></div>

<h5 id="finding-branches">Finding branches<a href="#finding-branches" title="Permalink to this heading">¶</a></h5>
<p>Branches migrated from Mercurial will have a <code>branches</code> prefix, not <code>branch</code>.
While GitLab uses <code>branch</code> for its prefix, the <code>git-remote-hg</code> script uses
<code>branches</code>. New work should be in a PR targeting <code>main</code>, <code>py3.9</code> or <code>py3.10</code>.</p>
<p>Thanks for helping to make PyPy better.</p>
<p>Matti</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory (413 pts)]]></title>
            <link>https://arxiv.org/abs/2310.20360</link>
            <guid>38834244</guid>
            <pubDate>Mon, 01 Jan 2024 18:46:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.20360">https://arxiv.org/abs/2310.20360</a>, See on <a href="https://news.ycombinator.com/item?id=38834244">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.20360.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-Łojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Benno Kuckuck [<a href="https://arxiv.org/show-email/87e3788f/2310.20360">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 31 Oct 2023 11:01:23 UTC (2,327 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2024's public domain is a banger (122 pts)]]></title>
            <link>https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/</link>
            <guid>38833881</guid>
            <pubDate>Mon, 01 Jan 2024 18:13:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/">https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/</a>, See on <a href="https://news.ycombinator.com/item?id=38833881">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7686">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
public domain, copyfight, old school, jennifer jenkins, music, books, movies, sex, bertold brecht, web dubois, tigger, marx brothers, cthulhu,

Summary:
2024's public domain is a banger; Hey look at this

URL:
https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/

Title:
Pluralistic: 2024's public domain is a banger (20 Dec 2023) em-oh-you-ess-ee

Bullet:
👩🏼‍🚒

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
None

--><br>
<a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/"><img decoding="async" src="https://i0.wp.com/craphound.com/images/20Dec2023.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#sexytimes">2024's public domain is a banger</a>: How he got in my pajamas, I don't know.
</li>
<li><a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#retro">This day in history</a>: 2013, 2018, 2022
</li>
<li><a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="sexytimes"></a><br>
<img decoding="async" alt="A collage of works entering the public domain on January 1, 2024." src="https://i0.wp.com/craphound.com/images/PDDmontageRS.png?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>2024's public domain is a banger (<a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#sexytimes">permalink</a>)</h2>
<p>They stole something from you. For decades, they stole it. That thing they stole? Your entire culture. For all of human history, works created in living memory entered the public domain every year. 40 years ago, that stopped.</p>
<p>First in 1976, and then again in 1998, Congress retroactively extended copyright's duration by 20 years, for all works, including works whose authors were unknown and long dead, whose proper successors could not be located. Many of these authors were permanently erased from history as every known copy of their works disappeared before they could be brought back into our culture through reproduction, adaptation and re-use (copyright is "strict liability," meaning that even if you pay to clear the rights to a work from someone who has good reason to believe they control those rights, if they're wrong, you are on the hook as an infringer, and the statutory damages run to six figures).</p>
<p>Works that are still in our cultural currents 50 or 70 or 90 years after their creation are an infinitesimal fraction of all the works we create as a species. But these works are – by definition – extraordinarily important to our culture. The creators who made these works were able to plunder a rich public domain of still-current works as inputs to their own enduring creations. The slow-motion arson attack on the public domain meant that two generations of creators were denied the public domain that every other creator in the history of the human race had enjoyed.</p>
<p>As 2019 drew nearer, the copyright resistance who had fought over this grew nervous, then…elated. Was Congress actually going to heed the evidence of a decades-long failed experiment and decline to extend copyright again?</p>
<p><a href="https://archive.org/details/MarybethPetersFormerUsRegisterOfCopyrightsOnTermsBeingTooLong">https://archive.org/details/MarybethPetersFormerUsRegisterOfCopyrightsOnTermsBeingTooLong</a></p>
<p>I had pitched email debates with comrades over this. Michael S Hart, visionary founder of the Project Gutenberg, was <em>certain</em> it wouldn't happen (he didn't live to see it). But then, miraculously, astoundingly, 2019 rolled around and <em>we got new works in the public domain</em>!</p>
<p><a href="https://web.law.duke.edu/cspd/publicdomainday/2019/">https://web.law.duke.edu/cspd/publicdomainday/2019/</a></p>
<p>For decades, Jennifer Jenkins from the Duke Center for the Study of the Public Domain published an annual lament for the public domain works we <em>weren't</em> getting that year. Jenkins painstakingly catalogued the materials that the public would be denied, though their creators had been only too happy to release them with the belief that the copyright would be 40 years shorter than it turned out.</p>
<p>Starting in 2019, those laments turned into celebrations, starter pistols for a generation of creators discovering a living public domain for the first time since the <em>Carter administration</em>. The 1923 works that entered the public domain in 2019 were mostly curiosities, but with each successive year, the public domain's new arrivals get ever more vibrant.</p>
<p>The public domain shipment that arrived on January 1, 2023 was a <em>banger</em>: we got some Virginia Woolf, some Hemingway, some Kafka, some Faulkner, some Agatha Christie and Edith Wharton, as well as Proust and Hesse:</p>
<p><a href="https://pluralistic.net/2022/12/20/free-for-2023/#oy-canada">https://pluralistic.net/2022/12/20/free-for-2023/#oy-canada</a></p>
<p>All of Sherlock Holmes came home to the public domain last year. We also got "Ol' Man River," "Puttin' On the Ritz" and "Mississippi Mud."</p>
<p>What we didn't get 2023? Sound recordings. The Music Modernization Act froze all sound recordings in copyright until 2024 – that is, until 11 days hence.</p>
<p>Those old 78RPM recordings exist in an odd superposition. On the one hand, they have real cultural value and bring great joy to many listeners. On the other hand, they produce either zero (in the case of out-of-print recordings) or very little revenue for labels.</p>
<p>The Internet Archive, a public library, has preserved over 400,000 of these recordings through its Great 78 Project. Like every library with a sound recording collection, the Archive lends out access to these recordings to people with library cards:</p>
<p><a href="https://great78.archive.org/">https://great78.archive.org/</a></p>
<p>But the record industry has decided to attack the library and its founder. In a lawsuit that could shut down the Internet Archive and bankrupt its founder, they claim that internet-based libraries can't do what their physical counterparts have done since literal time immemorial:</p>
<p><a href="https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/">https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/</a></p>
<p>The Big Three labels (Universal, Sony and Warner) who bought out all their rivals until three companies ended up owning <em>70%</em> of all in-copyright sound recordings do not take seriously their responsibility to preserve the recording history they bought and now would exercise eternal dominance over. Even as they attack independent efforts to preserve our culture, they fail grotesquely to preserve it on their own:</p>
<p><a href="https://www.nytimes.com/2019/06/11/magazine/universal-fire-master-recordings.html">https://www.nytimes.com/2019/06/11/magazine/universal-fire-master-recordings.html</a></p>
<p>January 1 won't change any of that: come this year's public domain day, the record labels will still own the vast majority of all the music in the world, and they'll still be indifferently preserving it, and they'll still be trying to kill the Internet Archive and the Wayback Machine, and they'll still be trying to eviscerate Brewster Kahle.</p>
<p>But at least we'll get some music in the public domain again this year. Indeed, this year's public domain is shaping up to be an even bigger banger than 2023:</p>
<p><a href="https://web.law.duke.edu/cspd/publicdomainday/2024/">https://web.law.duke.edu/cspd/publicdomainday/2024/</a></p>
<p>The majority of works entering the public domain this year are from 1928, six years before the Hays Code – a regime of self-censorship overseen by the motion picture cartel that banned sex, radical politics, queerness, and everything else good in this world for generations – came into effect. 1928 was the year that the "Magna Charta" of the movie cartel was adopted – a set of voluntary guidelines that were roundly ignored by the studios:</p>
<p><a href="https://en.wikipedia.org/wiki/Hays_Code#Pre-Code:_%22Don'ts%22_and_%22Be_Carefuls%22,_as_proposed_in_1927">https://en.wikipedia.org/wiki/Hays_Code#Pre-Code:_%22Don'ts%22_and_%22Be_Carefuls%22,_as_proposed_in_1927</a></p>
<p>The late 1920s were <em>super horny</em>. This year's public domain time-capsule from 1928 includes DH Lawrence's <em>Lady Chatterley's Lover</em>, Cole Porter's <em>Let's Do It</em>, Virginia Woolf's <em>Orlando</em>, Khan and Donaldson's <em>Makin' Whoopee</em>, and, horniest of all, Milne's <em>House at Pooh Corner</em>, featuring the first appearance of literature's greatest perennial sex-pest: Tigger.</p>
<p>Getting all this sexy stuff from 1928 in 2024 – when panicked bigots are waging war on sex in popular culture – is <em>quite</em> timely. These pietist prigs keep acting like sex in popular culture, "where the children can see it," was invented five years ago by Scholastic editors with purple hair, neopronouns and septum piercings. Earth to Moms For Liberty: the "good old days," free from sex in culture, ended 2 billion years ago when horny eukaryotes invented fucking.</p>
<p>But 1928 wasn't <em>all</em> flappers doing the horizontal Charleston with college men in the backs of jalopies. Our newly liberated cultural forebears found time to create the Marx Brothers' <em>Animal Crackers</em>, Brecht's <em>Threepenny Opera</em> (including <em>Mack the Knife</em>), and Agatha Christie's <em>The Mystery of the Blue Train</em>.</p>
<p>WEB Dubois's <em>Dark Princess</em> comes home to the public domain on Jan 1. So do Robert Frost's <em>West-Running Brook</em> and Buster Keaton's <em>The Cameraman</em>. We're getting Charlie Chaplin's <em>The Circus</em> and Leni's <em>The Man Who Laughs</em>, which Bob Kane plundered to create The Joker. You can record <em>Sonny Boy</em>, <em>I Can't Give You Anything But Love</em> or <em>I Wanna Be Loved By You</em>.</p>
<p>In addition to all the compositions entering the public domain in a few days, there's the first shipment of recordings in two years: the Charleston, <em>Yes, We Have No Bananas</em>, and Satchmo singing with King Oliver’s Creole Jazz Band on <em>Dipper Mouth Blues</em> and <em>Froggie More</em>.</p>
<p>Also noteworthy: the works of MC Escher are starting to enter the public domain. The records are fragmentary, but <em>Tower Of Babel</em> is yours for the taking on Jan 1 (this is especially satisfying given that the estate is a noteworthy bully that has sent me baseless threats).</p>
<p>There's a lot of other visual art that may be entering the public domain in 2024, but because the registration records are so poorly organized, it's hard to tell. A lot of that art may not have been registered or renewed, and already be in the public domain. 80% of the books published between 1924 and 1963 are in the public domain on this basis!</p>
<p><a href="https://www.crummy.com/2019/07/22/0">https://www.crummy.com/2019/07/22/0</a></p>
<p>Among those works that are Secretly Public Domain? HP Lovecraft's <em>Call of Cthulhu</em>, which has been public domain since <em>1956</em> (the Lovecraft estate is another one of those bullying monsters who will be put out of business soon, thanks to the reawakened public domain).</p>
<p>The main event, of course, is Mickey Mouse, who enters the public domain along with his first two short cartoon appearances: <em>Plane Crazy</em> and <em>Steamboat Willie</em>. Though there's been a lot of FUD about trademark keeping Mickey out of the public domain, it's a lie. He's all yours (mostly):</p>
<p><a href="https://pluralistic.net/2023/12/15/mouse-liberation-front/#free-mickey">https://pluralistic.net/2023/12/15/mouse-liberation-front/#free-mickey</a></p>
<p>It's wonderful to see the public domain growing again, but spare a thought for the orphan works whose copyright caging outlasted the works themselves. This year saw several silent films entering the public domain – but some of those films no longer exist in their entirety, or at all. They were set afire in the slow-motion arson attack on our culture the monopolistic entertainment industry began 40+ years ago.</p>
<p>Today, the world's worst people remain in charge of that culture, and they're still destroying it. David Zaslav, the loathsome villain of this year's writers' strike and actors' strike, has pioneered the permanent erasure of beloved movies and TV shows as a cheap way of getting tax credits for the bloated post-merger behemoth of that is Discovery-Warner:</p>
<p><a href="https://insidethemagic.net/2023/04/warner-bros-under-fire-for-destroying-history-af1/">https://insidethemagic.net/2023/04/warner-bros-under-fire-for-destroying-history-af1/</a></p>
<p>The purpose of a system is what it does. It's not that the media execs who demanded copyright extensions in the seventies and nineties failed to foresee that this was a mass cultural extinction event. It's that they didn't care. David Zaslav burning down his own company's vault is part of a multigenerational tradition in his industry. Those media execs know <em>exactly</em> what they're doing. They just don't care.</p>
<hr>

<h2>Hey look at this (<a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#linkdump">permalink</a>)</h2>
<p><img decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<ul>
<li>Search Tweaks <a href="http://searchtweaks.com/">http://searchtweaks.com/</a>
</li>
<li>
<p>Reversing Reagan: Is Wall Street Giving Up on Consolidation? <a href="https://www.thebignewsletter.com/p/reversing-reagan-is-wall-street-giving">https://www.thebignewsletter.com/p/reversing-reagan-is-wall-street-giving</a></p>
</li>
<li>
<p>Command Line Interface Guidelines <a href="https://clig.dev/">https://clig.dev</a></p>
</li>
<li>
<p>Volkswagen will reintroduce buttons to dashboards because everyone hates the touch controls <a href="https://boingboing.net/2023/12/19/volkswagen-will-reintroduce-buttons-to-dashboards-because-everyone-hates-the-touch-controls.html">https://boingboing.net/2023/12/19/volkswagen-will-reintroduce-buttons-to-dashboards-because-everyone-hates-the-touch-controls.html</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img decoding="async" alt="A Wayback Machine banner." src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1"></p>
<h2>This day in history (<a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#retro">permalink</a>)</h2>
<p>#10yrsago Kansas Universities can fire faculty for tweets that are “contrary to best interest of the University” <a href="https://www.washingtonpost.com/news/monkey-cage/wp/2013/12/19/kansas-board-of-regents-restricts-free-speech-for-academics/">https://www.washingtonpost.com/news/monkey-cage/wp/2013/12/19/kansas-board-of-regents-restricts-free-speech-for-academics/</a></p>
<p>#10yrsago Judge throws out Libyan rendered by UK spooks &amp; CIA to Gaddafi for torture, because “it might embarrass America” <a href="https://www.theguardian.com/world/2013/dec/20/libyan-rendition-claim-uk-interests">https://www.theguardian.com/world/2013/dec/20/libyan-rendition-claim-uk-interests</a></p>
<p>#10yrsago NSA and GCHQ targeted NGOs, charities, EU chief, Israeli defense minister for deep surveillance <a href="https://www.theguardian.com/uk-news/2013/dec/20/gchq-targeted-aid-agencies-german-government-eu-commissioner">https://www.theguardian.com/uk-news/2013/dec/20/gchq-targeted-aid-agencies-german-government-eu-commissioner</a></p>
<p>#10yrsago Oklahoma City cops charge Keystone XL protesters with “terrorism hoax” because their banner shed some glitter <a href="https://www.vice.com/en/article/xd5dxa/two-environmentalists-were-charged-with-terrorism-hoax-for-too-much-glitter-on-their-banner">https://www.vice.com/en/article/xd5dxa/two-environmentalists-were-charged-with-terrorism-hoax-for-too-much-glitter-on-their-banner</a></p>
<p>#10yrsago Mother of three boys’ funny review for Kleenex multipacks <a href="https://www.amazon.com/review/RFWM0CFO0UMWY/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;linkCode=ur2&amp;tag=downandoutint-20#RFWM0CFO0UMWY">https://www.amazon.com/review/RFWM0CFO0UMWY/?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;linkCode=ur2&amp;tag=downandoutint-20#RFWM0CFO0UMWY</a></p>
<p>#10yrsago Deriving cryptographic keys by listening to CPUs’ “coil whine” <a href="https://arstechnica.com/information-technology/2013/12/new-attack-steals-e-mail-decryption-keys-by-capturing-computer-sounds/">https://arstechnica.com/information-technology/2013/12/new-attack-steals-e-mail-decryption-keys-by-capturing-computer-sounds/</a></p>
<p>#10yrsago Chief cable lobbyist: data caps were never about network congestion, always about profit <a href="https://www.dslreports.com/shownews/Cable-Industry-Finally-Admits-Caps-Not-About-Congestion-122791">https://www.dslreports.com/shownews/Cable-Industry-Finally-Admits-Caps-Not-About-Congestion-122791</a></p>
<p>#5yrsago The audiophile MQA format really doesn’t have DRM, but that doesn’t mean it’s not on the toxic rainbow of locked tech <a href="https://www.eff.org/deeplinks/2018/12/closed-proprietary-felonious-toxic-rainbow-locked-technology">https://www.eff.org/deeplinks/2018/12/closed-proprietary-felonious-toxic-rainbow-locked-technology</a></p>
<p>#5yrsago The latest Facebook scandal might explain why Amazon wrongfully banned book-reviewers <a href="https://gizmodo.com/amazon-and-facebook-reportedly-had-a-secret-data-sharin-1831192148">https://gizmodo.com/amazon-and-facebook-reportedly-had-a-secret-data-sharin-1831192148</a></p>
<p>#5yrsago Inside the funny accounting that lets the money-losing fracking industry claim to be profitable <a href="https://www.desmog.com/2018/12/18/fracking-finances-record-oil-production-fuzzy-math/">https://www.desmog.com/2018/12/18/fracking-finances-record-oil-production-fuzzy-math/</a></p>
<p>#5yrsago Regulating Airbnb drives down local rents (as well as house prices) <a href="https://cepr.org/voxeu/columns/short-term-rentals-and-housing-market-quasi-experimental-evidence-airbnb-los-angeles">https://cepr.org/voxeu/columns/short-term-rentals-and-housing-market-quasi-experimental-evidence-airbnb-los-angeles</a></p>
<p>#5yrsago How Amazon’s crackdown on dirty sellers has made it easier for dirty sellers to kill good sellers’ accounts <a href="https://www.theverge.com/2018/12/19/18140799/amazon-marketplace-scams-seller-court-appeal-reinstatement">https://www.theverge.com/2018/12/19/18140799/amazon-marketplace-scams-seller-court-appeal-reinstatement</a></p>
<p>#5yrsago Not all “screen time” is created equal <a href="https://www.wired.com/story/year-in-review-tech-addiction-debate-all-wrong/">https://www.wired.com/story/year-in-review-tech-addiction-debate-all-wrong/</a></p>
<p>#5yrsago Master list of Facebook’s 2018 scandals <a href="https://www.wired.com/story/facebook-scandals-2018/">https://www.wired.com/story/facebook-scandals-2018/</a></p>
<p>#5yrsago 760 flights diverted from Gatwick airport after drone scare, affecting 110,000 passengers <a href="https://www.bbc.com/news/uk-england-sussex-46623754">https://www.bbc.com/news/uk-england-sussex-46623754</a></p>
<p>#1yrago 2023's public domain is a banger <a href="https://pluralistic.net/2022/12/20/free-for-2023/#oy-canada">https://pluralistic.net/2022/12/20/free-for-2023/#oy-canada</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img decoding="async" src="https://i0.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Colophon (<a href="https://pluralistic.net/2023/12/20/em-oh-you-ess-ee/#bragsheet">permalink</a>)</h2>
<p>Today's top sources:</p>
<p>Currently writing:</p>
<ul>
<li>A Little Brother short story about DIY insulin PLANNING
</li>
<li>
<p>Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. FORTHCOMING TOR BOOKS JAN 2025</p>
</li>
<li>
<p>The Bezzle, a Martin Hench noir thriller novel about the prison-tech industry. FORTHCOMING TOR BOOKS FEB 2024</p>
</li>
<li>
<p>Vigilant, Little Brother short story about remote invigilation. FORTHCOMING ON TOR.COM</p>
</li>
<li>
<p>Spill, a Little Brother short story about pipeline protests. FORTHCOMING ON TOR.COM</p>
</li>
</ul>
<p>Latest podcast: The Internet’s Original Sin <a href="https://craphound.com/news/2023/12/17/the-internets-original-sin/">https://craphound.com/news/2023/12/17/the-internets-original-sin/</a>)</p>
<p>Upcoming appearances:</p>
<ul>
<li>Internet Con (Peculiar Book Club), Jan 11<br>
<a href="https://www.youtube.com/watch?v=s5UvzuJ1R4I">https://www.youtube.com/watch?v=s5UvzuJ1R4I</a></li>
</ul>
<p>Recent appearances:</p>
<ul>
<li>Enshittification: A Monopoly Story (Macro n Cheese)<br>
<a href="https://realprogressives.org/podcast_episode/episode-255-enshittification-a-monopoly-story-with-cory-doctorow">https://realprogressives.org/podcast_episode/episode-255-enshittification-a-monopoly-story-with-cory-doctorow</a>
</li>
<li>
<p>Science Fiction and the Future of Science<br>
<a href="https://council.science/podcast/science-fiction/">https://council.science/podcast/science-fiction/</a></p>
</li>
<li>
<p>AI needs to work with humans — not replace us (CBC IDEAS)<br>
<a href="https://www.cbc.ca/radio/ideas/artificial-intelligence-provocation-ideas-festival-1.7046841">https://www.cbc.ca/radio/ideas/artificial-intelligence-provocation-ideas-festival-1.7046841</a></p>
</li>
</ul>
<p>Latest books:</p>
<ul>
<li>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>). Signed, personalized copies at Dark Delicacies (<a href="https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/">https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/</a>)
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>. Signed copies at Dark Delicacies (US): <a href="https://www.darkdel.com/store/p2873/Wed%2C_Apr_26th_6pm%3A_Red_Team_Blues%3A_A_Martin_Hench_Novel_HB.html#/"> and Forbidden Planet (UK): </a><a href="https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/">https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
<li>
<p>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html</a></p>
</li>
<li>
<p>"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. <a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b</a>) (signed copies: <a href="https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html">https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html</a>)</p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, and kicking ass. Order here: <a href="https://us.macmillan.com/books/9781626723627">https://us.macmillan.com/books/9781626723627</a>. Get a personalized, signed copy here: <a href="https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/">https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/</a>.</p>
</li>
</ul>
<p>Upcoming books:</p>
<ul>
<li>The Bezzle: a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books, February 2024
</li>
<li>
<p>Picks and Shovels: a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books, February 2025</p>
</li>
<li>
<p>Unauthorized Bread: a graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2025</p>
</li>
</ul>
<hr>
<p><img decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a TrueType font renderer (291 pts)]]></title>
            <link>https://axleos.com/writing-a-truetype-font-renderer/</link>
            <guid>38833747</guid>
            <pubDate>Mon, 01 Jan 2024 18:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://axleos.com/writing-a-truetype-font-renderer/">https://axleos.com/writing-a-truetype-font-renderer/</a>, See on <a href="https://news.ycombinator.com/item?id=38833747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-blog-post-content-container">
<content>
<p>Text is <em>the</em> medium of digital interaction, and text rendering has an outsized impact on the overall fit and finish of any system. It therefore
pains me that axle has for years relied on a low-resolution 8x8 bitmap font. Let’s fix it!</p>
<p>Take a look at the characters composing this sentence. Note the curves, the negative space, the use of size and distance.</p>
<p>If you’ve got a magnifying glass handy, you can even see how ‘black-on-white’ text uses many shades of gray to make the text smoother on the eyes. I’ll show you:</p>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/shades2.png" width="100%">
</figure>
<p>Font rendering comes down to telling the computer which pixels should be on or off, which should be darkened slightly for effect and which should let the background shine through.</p>
<p>The challenge comes from describing this to the computer in a way that’s <em>efficient</em> and <em>resizable</em>. Fonts shouldn’t take up too much storage, and we should be able to scale a font to any size the user requests while preserving the character✱ of the font design. Perhaps most importantly, we’ll want to satisfy these constraints while also making the text pleasant to read.</p>

<h2 id="minimalist-text-renderer">Minimalist Text Renderer</h2>
<p>Let’s do away with all of these requirements for now, and start off with the simplest viable approach to rendering characters. How might we go about coloring pixels into text?</p>
<p>Firstly, we’ll select a fixed size for each character. We’ll agree that every character will be exactly 8 pixels wide and 8 pixels high. That gives us a grid of 64 pixels per character to work with.</p>
<p>We can use a simple data format that describes whether each pixel in our 8x8 grid should be on (colored with the font color) or off (retain the background color). We can draw out our character grid like so:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _
</span></span><span><span>_ _ _ _ _ _ _ _</span></span></code></pre></div>
<p>Since we’ve got 8 pixels in each row, and each pixel has two states, it’s natural to store each row in our grid as one byte. For example, we could represent a capital <code>A</code> using a representation like the following:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Byte 1: 0 0 1 1 0 0 0 0
</span></span><span><span>Byte 2: 0 1 1 1 1 0 0 0
</span></span><span><span>Byte 3: 1 1 0 0 1 1 0 0
</span></span><span><span>Byte 4: 1 1 0 0 1 1 0 0
</span></span><span><span>Byte 5: 1 1 1 1 1 1 0 0
</span></span><span><span>Byte 6: 1 1 0 0 1 1 0 0
</span></span><span><span>Byte 7: 1 1 0 0 1 1 0 0
</span></span><span><span>Byte 8: 0 0 0 0 0 0 0 0</span></span></code></pre></div>
<div>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/highlighted_bitmap3.png" width="30%">
</figure>
</div>
<p>This is equivalent to the following hexadecimal representation:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Byte 1: 0x0c
</span></span><span><span>Byte 2: 0x1e
</span></span><span><span>Byte 3: 0x33
</span></span><span><span>Byte 4: 0x33
</span></span><span><span>Byte 5: 0x3f
</span></span><span><span>Byte 6: 0x33
</span></span><span><span>Byte 7: 0x33
</span></span><span><span>Byte 8: 0x00</span></span></code></pre></div>
<p>… and allows us to very efficiently store render maps for ASCII:</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>uint8_t</span> <span>ascii_map</span><span>[</span><span>256</span><span>][</span><span>8</span><span>]</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>// 64 previous entries...
</span></span></span><span><span><span></span>    <span>{</span> <span>0x0C</span><span>,</span> <span>0x1E</span><span>,</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x3F</span><span>,</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0041 (A)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x3F</span><span>,</span> <span>0x66</span><span>,</span> <span>0x66</span><span>,</span> <span>0x3E</span><span>,</span> <span>0x66</span><span>,</span> <span>0x66</span><span>,</span> <span>0x3F</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0042 (B)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x3C</span><span>,</span> <span>0x66</span><span>,</span> <span>0x03</span><span>,</span> <span>0x03</span><span>,</span> <span>0x03</span><span>,</span> <span>0x66</span><span>,</span> <span>0x3C</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0043 (C)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x1F</span><span>,</span> <span>0x36</span><span>,</span> <span>0x66</span><span>,</span> <span>0x66</span><span>,</span> <span>0x66</span><span>,</span> <span>0x36</span><span>,</span> <span>0x1F</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0044 (D)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x7F</span><span>,</span> <span>0x46</span><span>,</span> <span>0x16</span><span>,</span> <span>0x1E</span><span>,</span> <span>0x16</span><span>,</span> <span>0x46</span><span>,</span> <span>0x7F</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0045 (E)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x7F</span><span>,</span> <span>0x46</span><span>,</span> <span>0x16</span><span>,</span> <span>0x1E</span><span>,</span> <span>0x16</span><span>,</span> <span>0x06</span><span>,</span> <span>0x0F</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0046 (F)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x3C</span><span>,</span> <span>0x66</span><span>,</span> <span>0x03</span><span>,</span> <span>0x03</span><span>,</span> <span>0x73</span><span>,</span> <span>0x66</span><span>,</span> <span>0x7C</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0047 (G)
</span></span></span><span><span><span></span>    <span>{</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x3F</span><span>,</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x33</span><span>,</span> <span>0x00</span><span>},</span> <span>// U+0048 (H)
</span></span></span><span><span><span></span>    <span>// ...
</span></span></span><span><span><span></span><span>];</span></span></span></code></pre></div>
<p>This is quite a tidy encoding! To render a character, we can directly look up its render map using its ASCII representation:</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>fn</span> <span>render</span><span>(</span><span>ch</span><span>:</span> <span>char</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>let</span> <span>ch_render_map</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>8</span><span>]</span> <span>=</span> <span>ascii_bitmaps</span><span>[</span><span>ch</span> <span>as</span> <span>u8</span><span>];</span> <span>// Neat!
</span></span></span><span><span><span></span>    <span>for</span> <span>row</span> <span>in</span> <span>ch_render_map</span><span>.</span><span>iter</span><span>()</span> <span>{</span>
</span></span><span><span>        <span>for</span> <span>col</span> <span>in</span> <span>row</span><span>.</span><span>bits</span><span>().</span><span>iter</span><span>()</span> <span>{</span>
</span></span><span><span>            <span>if</span> <span>col</span> <span>==</span> <span>1</span> <span>{</span>
</span></span><span><span>                <span>// This pixel belongs to the character
</span></span></span><span><span><span></span>            <span>}</span>
</span></span><span><span>            <span>else</span> <span>{</span>
</span></span><span><span>                <span>// This pixel should display the background
</span></span></span><span><span><span></span>            <span>}</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span></span></span></code></pre></div>
<p>Believe it or not, that’s it. axle has been using the above font rendering technique for the better part of a decade.</p>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/old_desktop.png" width="100%">
</figure>
<p>Although the font above only natively provides 8px bitmaps, it’s pretty easy to scale it to any size we like. However, the font will always appear jagged and low-resolution.</p>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/old_desktop_closeup.png" width="100%">
</figure>
<p>While the 8x8 bitmap font <em>works</em>, it sure isn’t pretty, and it’s quite limited: we can only use whatever font we’re willing to encode into this little 8x8 grid, and
we’re unable to use any of the many fonts available online and in the public domain. Additionally, our 8x8 grid doesn’t give us much of a good way to describe curves, which are essential in some fonts (check out this <code>a</code>!).</p>
<p>Most importantly, writing a new font renderer sounds like fun.</p>
<h2 id="truetype">TrueType</h2>
<p>For the next leap in our text rendering journey, we turn to TrueType: the de facto standard for encoding and distributing fonts. Unlike our humble 8x8 bitmaps, TrueType fonts are distributed as structured binary files (<code>.ttf</code>). We’ll need to parse these files and render their data into pixels.</p>
<p>There’s few things in this world I love more than taking an opaque binary and gradually uncovering the organization that was present all along. Dissecting the underlying and general structure of a binary is as gratifying as anything I can imagine.</p>
<p>The <a href="https://developer.apple.com/fonts/TrueType-Reference-Manual/">TrueType specification</a> gives a great introduction to the problem space (I highly recommend the overviews in <code>Digitizing Letterforms</code> and especially <code>Instructing Fonts</code>), but it doesn’t give much in the way of signposting “start parsing here”. I’ll save you the trouble.</p>
<p>TTFs are structured somewhat similarly to Mach-Os. This is quite a nice surprise, because I’ve spent <a href="https://github.com/datatheorem/strongarm/">a lot of time parsing Mach-Os</a>! Both file formats were developed at Apple✱ around the same time, so I suppose they had some design points in the air.</p>
<div>

<p>
I don’t know all the history here. Please feel welcome to correct me if I’ve got this wrong!
</p>
</div>
<p>TTFs and Mach-Os are both largely structured around a flat series of sections, each of which is described by a table of contents at the beginning of the file. In the case of TTFs, each of these sections will contain some metadata or other that we’ll need over the course of rendering the font.</p>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/macho_ttf_comparison.png" width="100%">
</figure>
<p>Before taking a look at these sections becomes fruitful, though, we need to know the fundamental process for describing fonts used by TrueType. The specification does a great job, so I’ll keep myself brief.</p>
<p>The collection of lines and curves used to visually represent a particular letter is referred to as a <em>glyph</em>. As an example, the glyph for <code>b</code> consists of a vertical line and a semicircle.</p>
<p>Without further information, though, our renderer won’t know <em>which</em> glyph represents each character. We’ll need some additional metadata to convert from a character within a <em>character map</em> (such as ASCII or Unicode) to the <em>glyph</em> that a particular font is using to visually represent that character. The job of the TTF is dually to describe how to draw all the glyphs represented by the font, and to describe the correspondence between the character map and these glyphs.</p>
<p>TrueType describes how to draw each glyph by listing a series of points, which collectively compose the <em>outline</em> of each glyph. It’s up to the renderer to connect these points into lines, to turn these lines into curves, and to ‘color inside the lines’ as appropriate. There’s more nuance here, but that’s the bare bones.</p>
<p><img src="https://axleos.com/writing-a-truetype-font-renderer/points.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log3.png"><br>
<i>Rendering points without connecting them into lines</i>
</p>
<p>Things start to look a lot more comprehensible once you connect the dots.</p>
<p><img src="https://axleos.com/writing-a-truetype-font-renderer/log1.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log2.png">
</p>
<p>Coloring inside the lines turns out to be more difficult than you might imagine✱.</p>
<table>
<tbody><tr>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/log4.png">
</th>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/log6.png">
</th>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/log7.png">
</th>
</tr>
</tbody></table>
<div>

<p>
Describing and filling closed polygons was missing from axle’s Rust-based graphics stack until the TrueType renderer gave me a reason. It’s implemented <a href="https://github.com/codyd51/axle/blob/paging-demo/rust_programs/agx_definitions/src/lib.rs#L1554-L1723">here</a>.
</p>
</div>
<p>My first implementation of this renderer didn’t draw any curves, but instead directly connected the points with straight lines. My colleague Amos <a href="https://github.com/codyd51/axle/pull/47">implemented</a> the ability for the renderer to interpolate the glyph outline along the curves described in the font, which really improved the look of things. Thanks, Amos!</p>
<div>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/bezier_curves.png" width="60%">
</figure>
<p><i>Before and after Amos's work to interpolate along curves</i>
</p></div>
<h2 id="tangled-text-tables">Tangled Text Tables</h2>
<p>Each section in the TTF is identified by a 4-character ASCII name. Different sections in the TTF contain different important metadata, such as:</p>
<ul>
<li><code>glyf</code>: The set of points for each glyph outline in the font (most important!)</li>
<li><code>hmtx</code>:✱ Spacing information, i.e. how far to advance the cursor after drawing each glyph</li>
<li><code>cmap</code>: The correspondence of Unicode✱ codepoints to glyph indexes</li>
</ul>
<div>

<p>
<code>hmtx</code> just gives the <em>horizontal metrics</em>. <code>vmtx</code> gives the metrics for the vertical direction as well.
</p>
</div>
<div>

<p>
I’m simplifying here. TTFs can contain several ‘character maps’ covering many encoding schemes, including several versions of Unicode (such as Unicode v1, Unicode v2, Unicode v2 with <em>just</em> the <a href="https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane">basic multilingual plane</a>, etc.). The data within the <code>cmap</code> section will specify which character maps are available, and it’s up to the parser to select whichever character map is convenient.
</p>
</div>
<p>Each of these sections contains a bunch of structured data describing their contents. Here, our first mini challenge presents itself. TTF was designed in an era in which neither RAM nor core cycles were cheap. Therefore, the designers of the format made sure it’d be as easy as possible for the renderer to complete its work. To this end, they offloaded two responsibilities to the font file itself:</p>
<ul>
<li>Efficient data structures that the renderer can walk to retrieve info (for example, lookup tables to map a character code to a glyph index)</li>
<li>Pre-computation of some values used during lookup (for example, scaling parameters for binary searching a character map)</li>
</ul>
<p>These optimizations aren’t so relevant today, but we’ll need to work with them nonetheless. The first one is particularly important: TTF is designed to be <em>loaded directly into memory</em> and read by the renderer <em>in-place</em>, without the renderer populating its own intermediary data structures. Inexplicably, though, the TTF stores all fields in big endian, so we’ll definitely have to do some work on our end before we can read any sane values out of font structures.</p>
<p>To be able to define and read from these font structures with minimal boilerplate and repetition, I set things up such that I could wrap any font structure fields in <code>BigEndianValue</code>. After I call <code>.into()</code>, everything is done and dusted and I can move on with my day. A little bit of structure definition upfront for some easy breezy parsing code down the line!</p>
<div onclick="window.open(&quot;https://github.com/codyd51/axle/blob/9d83c62eaad9dd0850bb7fe3641bd2821e5b84b0/rust_programs/ttf_renderer/src/parser.rs#L35-L66&quot;, '_blank');">
<p><code>rust_programs/ttf_renderer/src/parser.rs</code></p>

<div><pre tabindex="0"><code data-lang="rust"><span><span><span>/// Here, we're modelling a structure that's defined by the TTF specification
</span></span></span><span><span><span></span><span>#[repr(C, packed)]</span><span>
</span></span></span><span><span><span></span><span>#[derive(Debug, Copy, Clone)]</span><span>
</span></span></span><span><span><span></span><span>struct</span> <span>OffsetSubtableRaw</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>/// Note each field is wrapped in BigEndianValue
</span></span></span><span><span><span></span><span>    </span><span>scalar_type</span>: <span>BigEndianValue</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>num_tables</span>: <span>BigEndianValue</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>search_range</span>: <span>BigEndianValue</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>entry_selector</span>: <span>BigEndianValue</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>range_shift</span>: <span>BigEndianValue</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>/// This marker trait indicates that this structure sits directly in TTF memory
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>TransmuteFontBufInPlace</span><span> </span><span>for</span><span> </span><span>OffsetSubtableRaw</span><span> </span><span>{}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>/// This is our 'high-level' parsed representation
</span></span></span><span><span><span></span><span>#[derive(Debug, Copy, Clone)]</span><span>
</span></span></span><span><span><span></span><span>struct</span> <span>OffsetSubtable</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>scalar_type</span>: <span>u32</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>num_tables</span>: <span>u16</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>search_range</span>: <span>u16</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>entry_selector</span>: <span>u16</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>range_shift</span>: <span>u16</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>/// Convert the 'raw' TTF memory representation into our high-level representation with native byte order
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>FromFontBufInPlace</span><span>&lt;</span><span>OffsetSubtableRaw</span><span>&gt;</span><span> </span><span>for</span><span> </span><span>OffsetSubtable</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>from_in_place_buf</span><span>(</span><span>raw</span>: <span>&amp;</span><span>OffsetSubtableRaw</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>scalar_type</span>: <span>raw</span><span>.</span><span>scalar_type</span><span>.</span><span>into_value</span><span>(),</span><span>
</span></span></span><span><span><span>            </span><span>num_tables</span>: <span>raw</span><span>.</span><span>num_tables</span><span>.</span><span>into_value</span><span>(),</span><span>
</span></span></span><span><span><span>            </span><span>search_range</span>: <span>raw</span><span>.</span><span>search_range</span><span>.</span><span>into_value</span><span>(),</span><span>
</span></span></span><span><span><span>            </span><span>entry_selector</span>: <span>raw</span><span>.</span><span>entry_selector</span><span>.</span><span>into_value</span><span>(),</span><span>
</span></span></span><span><span><span>            </span><span>range_shift</span>: <span>raw</span><span>.</span><span>range_shift</span><span>.</span><span>into_value</span><span>(),</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div>
</div>
<p>Ready for the payoff?</p>
<div onclick="window.open(&quot;https://github.com/codyd51/axle/blob/9d83c62eaad9dd0850bb7fe3641bd2821e5b84b0/rust_programs/ttf_renderer/src/parser.rs#L336&quot;, '_blank');">
<p><code><code><span>pub</span><span> </span><span>fn</span> <span>parse</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span>-&gt; <span>Font</span></code></code>
</p>
<p><code>rust_programs/ttf_renderer/src/parser.rs</code></p>

<div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>offset_table</span><span> </span><span>=</span><span> </span><span>OffsetSubtable</span>::<span>from_in_place_buf</span><span>(</span><span>self</span><span>.</span><span>read_with_cursor</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>cursor</span><span>));</span></span></span></code></pre></div>
</div>
<p>Oh yeah! We can parse our high-level, byte-order-corrected representation directly from the TTF memory without even needing to <em>mention</em> the raw TTF representation at the call-site. I’ll call that a win.</p>
<h2 id="parser">Parser</h2>
<p>Handy APIs in hand, we’ll parse all the section descriptions at the start of the file.</p>
<p>The <code>head</code> section (or <em>table</em>, as TTF prefers) stores some important metadata about the font as a whole. We know that TTF describes glyph outlines via a series of connected points. But if we see a point like <code>(371, 205)</code>, without further information we don’t have a reference point for understanding where this sits visually. The <code>head</code> table gives us such a reference point, by describing the <code>glyph_bounding_box</code> that all points sit within.</p>
<p>Next up, we’ll want to <a href="https://github.com/codyd51/axle/blob/paging-demo/rust_programs/ttf_renderer/src/character_map.rs#L224">parse a character map</a> to find out how we’ll correspond encoded characters to glyph indexes. Each character map will also be described in an <a href="https://github.com/codyd51/axle/blob/paging-demo/rust_programs/ttf_renderer/src/character_map.rs#L340-L357">extremely gnarly format</a> that the parser will need to know how to read.</p>
<p>And now the exciting bit: parsing glyphs! The <code>maxp</code> table will give us some metadata on how many glyphs the font contains, while the glyph data itself is stored in <code>glyf</code>.</p>
<p>Before we can parse each <code>glyf</code> entry, we’ll need to know where each entry begins. The <code>loca</code> table will give us these offsets. However, nowhere is the <em>size</em> of each glyph’s data given explicitly in the font. Instead, the size of each glyph’s data is implicitly given by the difference with the starting offset of the <em>next</em> glyph.</p>
<p>The intrepid font parser will quickly notice that some glyph descriptions appear to have <em>no</em> size. This is intentional: some glyphs, such as the one corresponding to the space character, have no visible manifestation aside from the negative space they occupy. When the renderer tries to draw one of these zero-sized glyphs, we’ll just advance the cursor based on the corresponding <code>htmx</code> size for this glyph.</p>
<p>We’ve actually got three distinct types of glyphs:</p>
<ul>
<li><em>Polygon</em> glyphs
<ul>
<li>These glyphs are the classic case, an ordered connection of edge points and control points that should be connected in a series of curves.</li>
</ul>
</li>
<li><em>Blank</em> glyphs
<ul>
<li>Special case for glyphs such as those corresponding to the space character.</li>
</ul>
</li>
<li><em>Compound</em> glyphs
<ul>
<li>Glyphs manufactured by combining and scaling other glyphs.</li>
</ul>
</li>
</ul>
<p>The third category is really interesting! The glyphs for <code>i</code> and <code>j</code> both share an identical dot on top, and there’s no need to duplicate its description in the draw instructions. Instead, we can just say that <code>i</code> and <code>j</code> are each composed of a couple of glyph fragments laid out on the canvas at specific scales and positions.</p>
<figure><img src="https://axleos.com/writing-a-truetype-font-renderer/compound_glyphs.png" width="100%">
</figure>
<p>There are all sorts of counterintuitive edge cases with compound glyphs. As an example, we know that traditional polygon glyphs specify how far the cursor should advance after drawing them via corresponding entries in the <code>hmtx</code> and <code>vmtx</code> tables. However, how far should the cursor advance for a compound glyph? Sometimes the compound glyph has its own metrics table entries, and sometimes the compound glyph is annotated with a special flag indicating that it should take its cursor advance metrics from a specific child glyph.</p>
<div onclick="window.open(&quot;https://github.com/codyd51/axle/blob/paging-demo/rust_programs/ttf_renderer/src/glyphs.rs#L218-L229&quot;, '_blank');">
<p><code>rust_programs/ttf_renderer/src/glyph.rs</code></p>

<div><pre tabindex="0"><code data-lang="rust"><span><span><span>enum</span> <span>CompoundGlyphComponentFlag</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>HeaderValuesAreWords</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>HeaderValuesAreCoordinates</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>RoundCoordinatesToGrid</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>CustomScale</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>MoreComponentsFollow</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>HasDifferentScalesForXAndY</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>HasTwoByTwoTransformation</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>HasInstructions</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>UseMetricsFromThisComponent</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>ComponentsOverlap</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div>
</div>
<p>Compound glyphs don’t always directly contain polygon glyphs. Instead, a compound glyph can be composed of a tree of other compound glyphs, all stretched and scaled and repositioned across the bounding box.</p>
<h2 id="hinting">Hinting</h2>
<p>TrueType famously defines a hinting VM that’s intended to help retain the essence of a font when rendering at low resolutions to a limited pixel grid. The job of the program running under this VM is to nudge the glyph’s control points into a specific layout on low-resolution bitmaps✱.</p>
<div>

<p>
There’s an interesting inversion here. The job of this hinting program is to <em>keep</em> the visual appeal of the font, but it accomplishes this by <em>intentionally distorting</em> the proportions of each glyph.
</p>
</div>
<p>Let’s say you’re trying to scale down a glyph’s points to fit on a small grid. If the render resolution isn’t exactly divisible by the glyph’s point spacing, you’re going to get scaling artifacts when you round each glyph point to a pixel.</p>
<table>
<tbody><tr>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/e_points.png">
</th>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/e_snapped.png">
</th>
</tr>
</tbody></table>
<p>The font can embed a little program that, when executed, nudges the glyph’s layout points to better represent the glyph within the available grid.</p>
<table>
<tbody><tr>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/e_nudges2.png">
</th>
<th>
<img src="https://axleos.com/writing-a-truetype-font-renderer/e_final_result.png">
</th>
</tr>
</tbody></table>
<p>Our renderer will need to implement this VM, which is always a fun endeavor.</p>
<p>The hinting VM is built around a standard (and incredibly satisfying) interpreter loop that modifies a virtual machine state based on the operations indicated by the byte stream:</p>
<div onclick="window.open(&quot;https://github.com/codyd51/axle/blob/paging-demo/rust_programs/ttf_renderer/src/hints.rs#L470-L497&quot;, '_blank');">
<p><code>rust_programs/ttf_renderer/src/hints.rs</code></p>

<div><pre tabindex="0"><code data-lang="rust"><span><span><span>0x4b</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// Measure pixels per em in the projection vector's axis
</span></span></span><span><span><span></span><span>    </span><span>if</span><span> </span><span>operations</span><span>.</span><span>should_print</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>println!</span><span>(</span><span>
</span></span></span><span><span><span>            </span><span>"MPPEM</span><span>\t</span><span>Measure pixels per em in </span><span>{:?}</span><span>"</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>graphics_state</span><span>.</span><span>projection_vector</span><span>
</span></span></span><span><span><span>        </span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>if</span><span> </span><span>operations</span><span>.</span><span>should_execute</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>val</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>graphics_state</span><span>.</span><span>projection_vector</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>Axis</span>::<span>X</span><span> </span><span>=&gt;</span><span> </span><span>graphics_state</span><span>.</span><span>font_size</span><span>.</span><span>width</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>Axis</span>::<span>Y</span><span> </span><span>=&gt;</span><span> </span><span>graphics_state</span><span>.</span><span>font_size</span><span>.</span><span>height</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>};</span><span>
</span></span></span><span><span><span>        </span><span>graphics_state</span><span>.</span><span>push</span><span>(</span><span>val</span><span> </span><span>as</span><span> </span><span>u32</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span></span><span>0x50</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// Less than
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>e2</span><span> </span><span>=</span><span> </span><span>graphics_state</span><span>.</span><span>pop</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>e1</span><span> </span><span>=</span><span> </span><span>graphics_state</span><span>.</span><span>pop</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>e1</span><span> </span><span>&lt;</span><span> </span><span>e2</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>if</span><span> </span><span>operations</span><span>.</span><span>should_print</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>println!</span><span>(</span><span>"LT</span><span>\t</span><span>Less than? </span><span>{e1}</span><span> &lt; </span><span>{e2}</span><span> = </span><span>{result}</span><span>"</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>if</span><span> </span><span>operations</span><span>.</span><span>should_execute</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>graphics_state</span><span>.</span><span>push</span><span>(</span><span>if</span><span> </span><span>result</span><span> </span><span>{</span><span> </span><span>1</span><span> </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span> </span><span>0</span><span> </span><span>});</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div>
</div>
<p>There a slew of hilarious little engineering challenges that come up when trying to execute functions targeting a font’s operating environment.</p>
<div onclick="window.open(&quot;https://github.com/codyd51/axle/blob/paging-demo/rust_programs/ttf_renderer/src/hints.rs#L303-L310&quot;, '_blank');">
<p><code>rust_programs/ttf_renderer/src/hints.rs</code></p>

<div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span>(</span><span>crate</span><span>)</span><span> </span><span>fn</span> <span>identify_functions</span><span>(</span><span>instructions</span>: <span>&amp;</span><span>[</span><span>u8</span><span>])</span><span> </span>-&gt; <span>Vec</span><span>&lt;</span><span>FunctionDefinition</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// We have a bootstrapping problem: Functions can't be run to 
</span></span></span><span><span><span></span><span>    </span><span>// completion without the context (arguments, etc.) from the caller, but we need to 
</span></span></span><span><span><span></span><span>    </span><span>// parse function boundaries before we can run callers since callers address functions via 
</span></span></span><span><span><span></span><span>    </span><span>// identifiers that get created when the fpgm table is executed.
</span></span></span><span><span><span></span><span>    </span><span>// To resolve this circular dependency, we use a simple heuristic to identify function 
</span></span></span><span><span><span></span><span>    </span><span>// definitions, rather than doing a full interpreter pass. 
</span></span></span><span><span><span></span><span>    </span><span>// This has the downside that our heuristic can't tell the
</span></span></span><span><span><span></span><span>    </span><span>// difference between code and data. 
</span></span></span><span><span><span></span><span>    </span><span>// If some data is pushed to the stack with the same value as the
</span></span></span><span><span><span></span><span>    </span><span>// function definition opcode, we may interpret it as a function definition.
</span></span></span><span><span><span></span><span>    </span><span>//
</span></span></span><span><span><span></span><span>    </span><span>// ...
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div>
</div>
<h2 id="truetype-quirks">TrueType Quirks</h2>
<h3 id="occult-memorabilia">Occult Memorabilia</h3>
<p>The hinting VM is all about nudging the glyph’s outline points so that they look better on a small pixel grid. All of these points that actually compose a part of the glyph outline are in the ‘Glyph Zone’.</p>
<p>However, the VM designers realized that it was sometimes useful to have a point that wasn’t really part of the outline, but was just used as a reference when doing distance calculations. These points don’t belong in the Glyph Zone, so instead TrueType places them in a different space called… the <a href="https://developer.apple.com/fonts/TrueType-Reference-Manual/RM05/Chap5.html#SZP0">Twilight Zone</a>.</p>
<p>The TrueType designers were clearly fans of the paranormal. TrueType provides convenient support for describing emboldened and italicized versions of fonts by embedding offsets to apply to each point in a glyph outline. A font variation might need the entire bounding box of a glyph to be modified too, so there are <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/tt_instructing_glyphs#phantom-points">‘phantom points’</a> corresponding to the corners of the bounding box that can be stretched and squeezed.</p>
<h3 id="implied-control-points">Implied Control Points</h3>
<p>The TrueType specification suggests to the reader, hey! Maybe it’d be possible to save space by letting the renderer deduce missing control points?</p>
<img src="https://axleos.com/writing-a-truetype-font-renderer/implied_on_curve_points.png">
<p>Despite the casual tone of observation, renderers are actually required to support this. Fonts rely on this all the time! This is the only mention of it in the whole spec! Everyone needs to detect and insert implied control points, all on the back of one introductory diagram.</p>
<h3 id="hint-assume-nothing">Hint: Assume Nothing</h3>
<p>Like we’ve seen, TrueType has sophisticated support for manipulating the rendering process in constrained font sizes. But like any good programming environment, it also provides lots of escape hatches. One such escape hatch is the <code>bloc</code> table, which essentially says “if the font size is too small, ignore the glyph curves and hinting programs and just render these tiny bitmaps instead.”</p>
<h2 id="firming-up-a-renderer">Firming Up a Renderer</h2>
<p>There’s still work to do to integrate this font renderer neatly in all the stacks that wind up displaying text on axle’s desktop, but the foundations are ready. Here’s what things looked like the last time I worked on propagating TrueType throughout the desktop.</p>
<p><img src="https://axleos.com/writing-a-truetype-font-renderer/log23.png">
</p>
<p>The source code for this renderer is <a href="https://github.com/codyd51/axle/tree/9d83c62eaad9dd0850bb7fe3641bd2821e5b84b0/rust_programs/ttf_renderer/src">here</a>. Below are some screenshots from the course of this renderer’s development.</p>
<p><img src="https://axleos.com/writing-a-truetype-font-renderer/log5.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log8.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log9.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log10.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log11.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log12.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log13.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log14.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log15.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log16.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log17.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log18.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log19.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log20.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log21.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log22.png">
<img src="https://axleos.com/writing-a-truetype-font-renderer/log24.png">
</p>
</content>
</div></div>]]></description>
        </item>
    </channel>
</rss>