<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 21 Oct 2024 05:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Today is Ubuntu's 20th Anniversary (189 pts)]]></title>
            <link>https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html</link>
            <guid>41898736</guid>
            <pubDate>Sun, 20 Oct 2024 21:44:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html">https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html</a>, See on <a href="https://news.ycombinator.com/item?id=41898736">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Mark Shuttleworth</b> 
    <a href="mailto:ubuntu-announce%40lists.ubuntu.com?Subject=Announcing%20Ubuntu%204.10%20%22The%20Warty%20Warthog%20Release%22&amp;In-Reply-To=" title="Announcing Ubuntu 4.10 &quot;The Warty Warthog Release&quot;">mark at hbd.com
       </a><br>
    <i>Wed Oct 20 11:06:23 CDT 2004</i>
    <ul>
        <li>Previous message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000002.html">Announcing Ubuntu 4.10 (Release Candidate)
</a></li>
        <li>Next message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000004.html">Warty Live CD Released
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/date.html#3">[ date ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/thread.html#3">[ thread ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/subject.html#3">[ subject ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/author.html#3">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>=== Announcing Ubuntu 4.10 "The Warty Warthog Release" ===

The warm-hearted Warthogs of the Warty Team are proud to present the
very first release of Ubuntu!

Ubuntu is a new Linux distribution that brings together the extraordinary
breadth of Debian with a fast and easy install, regular releases (every
six months), a tight selection of excellent packages installed by default
and a commitment to security updates with 18 months of security and
technical support for every release.

You get a distribution that is:

  * absolutely committed to free software,  every end-user application 
on the
    CD is free software

  * 100% free of charge, and the Ubuntu team is committed to keeping
    Ubuntu free of charge

  * security updates for the distribution at no charge for 18 months
    for any release

  * updated to the latest desktop and kernel and infrastructure every
    six months with a new release

  * supports x86, amd64 and ppc processors, with additional ports under
    way

If you've heard all about Ubuntu and just want to get the install CD or
test the Release Candidate Live CD, you can download it here immediately:

  <a href="http://www.ubuntulinux.org/download/">http://www.ubuntulinux.org/download/</a>

If you want a shrinkwrapped CD we will gladly ship it to you at no cost.
To receive a complimentary copy of the Warty Warthog CD -- or a handful
to give to your friends, your school or LUG, register online at:

  <a href="http://shipit.ubuntulinux.org/">http://shipit.ubuntulinux.org/</a>

For more information, you can turn to any of the following resources:

Ubuntu Website: <a href="http://www.ubuntulinux.org/">http://www.ubuntulinux.org</a>

  The website contains some basic background on Ubuntu, an
  overview of the project, information on how to get it, and
  some documentation for the software.

Ubuntu Wiki: <a href="http://wiki.ubuntulinux.org/">http://wiki.ubuntulinux.org</a>

  The wiki is a shared web space used by the Ubuntu community to
  develop new ideas for Ubuntu. Anybody is welcome to edit and
  add to the wiki.

Ubuntu IRC Channel: #ubuntu and on irc.freenode.net

  The Ubuntu IRC channel is your best place to start for help and
  discussion about Ubuntu and the Warty Warthog release. We aim
  to keep the signal-to-noise ratio as high as possible on that
  channel, and on all community forums.

Ubuntu Mailing Lists:

  Ubuntu mailing lists are the heart of our community. In addition to the
  announcement list, and lists for users and developers of Ubuntu,
  there are now Ubuntu mailing lists in German, French, Spanish as well
  as lists devoted to Ubuntu security, news, translators, and the
  inevitable lighthearted chitchat list ("the Sounder"). To get more
  information or subscribe, visit:

    <a href="http://lists.ubuntu.com/">http://lists.ubuntu.com</a>


Warty Warthog Features

 * Simple and fast Installation

   Ubuntu comes on one single CD, with thousands of extra packages
   available online. The install is optimised for speed and
   simplicity. Ubuntu has excellent support for laptops (both
   x86 based and Powerbook / iBook PPC based), and can also be
   setup in a minimalist server configuration.

 * GNOME 2.8

   Ubuntu was the first distribution to ship Gnome 2.8, on the day
   of the 2.8 release. Ubuntu is a great way to try out Gnome 2.8 if
   you have not already experienced its speed and simplicity.

 * Firefox 0.9 (with security patches)

 * First class productivity software

   Evolution 2.0 and OpenOffice.org 1.1.2

 * XFree86 4.3 with improved hardware support

   We also worked hard to detect as much hardware as possible,
   simplifying the X install considerably.

Warty can be installed in a minimalist mode for servers, or in full
desktop mode. It works well on laptops and desktops. Warty is secure
by design - a key goal was to ensure that Warty was as safe from attack
over the internet as possible after a default install.

Thanks to the team of professional and volunteer maintainers who have
worked so hard to bring the Warthog to life, and also to our rapidly
growing community, who have provided excellent testing and ideas for
the future of Ubuntu!

"Ubuntu" is an ancient African word for "humanity towards others", and
we think it's a perfect name for an open source community project. In
that spirit we invite you to join, to contribute and to share Ubuntu
with your own community. Our next release, the Hoary Hedgehog, is due
in six months time. You can help to shape it by joining the team
and contributing your own expertise. See you at #ubuntu on
irc.freenode.net.


</pre>


<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000002.html">Announcing Ubuntu 4.10 (Release Candidate)
</a></li>
	<li>Next message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000004.html">Warty Live CD Released
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/date.html#3">[ date ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/thread.html#3">[ thread ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/subject.html#3">[ subject ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/author.html#3">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="http://lists.ubuntu.com/mailman/listinfo/ubuntu-announce">More information about the ubuntu-announce
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Create mind maps to learn new things using AI (104 pts)]]></title>
            <link>https://github.com/aotakeda/learn-thing</link>
            <guid>41898076</guid>
            <pubDate>Sun, 20 Oct 2024 20:01:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/aotakeda/learn-thing">https://github.com/aotakeda/learn-thing</a>, See on <a href="https://news.ycombinator.com/item?id=41898076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Mind Map Visualization Project</h2><a id="user-content-mind-map-visualization-project" aria-label="Permalink: Mind Map Visualization Project" href="#mind-map-visualization-project"></a></p>
<p dir="auto">This is a simple <a href="https://nextjs.org/" rel="nofollow">Next.js</a> project that implements a mind map visualization tool using <a href="https://reactflow.dev/" rel="nofollow">React Flow</a>.</p>
<p dir="auto">Watch a demo of it in action <a href="https://www.youtube.com/watch?v=Y-9He-tG3aM" rel="nofollow">here</a> or check out the gif below.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/aotakeda/learn-thing/blob/main/public/demo.gif"><img src="https://github.com/aotakeda/learn-thing/raw/main/public/demo.gif" alt="Demo gif" data-animated-image=""></a></p>
<p dir="auto">The UI is built using <a href="https://ui.shadcn.com/" rel="nofollow">shadcn</a> and some components from <a href="https://magicui.design/" rel="nofollow">Magic UI</a>.</p>
<p dir="auto">It allows users to view and interact with mind maps, and download the mind map data as a markdown file.</p>
<p dir="auto">The mind map data is generated using either local models from <a href="https://ollama.com/" rel="nofollow">Ollama</a> or external models like <a href="https://openai.com/" rel="nofollow">OpenAI</a> and leveraging <a href="https://sdk.vercel.ai/docs/introduction" rel="nofollow">AI SDK</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Interactive mind map visualization</li>
<li>Node details view in a side sheet</li>
<li>Markdown export functionality</li>
<li>Save mind map data to a local JSON file</li>
<li>Switch between local and external models</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Install all dependencies:</p>

<p dir="auto">Copy the <code>.env.template</code> file to <code>.env.local</code> and specify which model (local or external) you want to use by setting the <code>NEXT_PUBLIC_USE_LOCAL_MODELS</code> environment variable to <code>true</code> or <code>false</code>.</p>
<p dir="auto">When running an OpenAI model, you must specify your OpenAI API key in the <code>.env.local</code> file.</p>
<p dir="auto">Inside the <code>route.ts</code> file, you must specify the model you are running using Ollama, by default it will use the <code>llama3.1</code> model for local models and for external models it will use the <code>gpt-3.5-turbo</code> model.</p>
<p dir="auto">Bear in mind that external models tend to be much faster serving than local models.</p>
<p dir="auto">If you want to learn how to run a model locally, check out the <a href="https://github.com/ollama/ollama/blob/main/README.md#quickstart">Ollama documentation</a>.</p>
<p dir="auto">Now you're ready to run the development server:</p>

<p dir="auto">Open <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> with your browser and then start creating your own learning mind maps.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prompts</h2><a id="user-content-prompts" aria-label="Permalink: Prompts" href="#prompts"></a></p>
<p dir="auto">The prompts used to generate the mind map data is defined in the <code>defaultLocalPrompt</code> and <code>defaultExternalPrompt</code> variables in the <code>prompts.ts</code> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebGPU-Based WiFi Simulator (201 pts)]]></title>
            <link>https://wifi-solver.com</link>
            <guid>41897214</guid>
            <pubDate>Sun, 20 Oct 2024 18:01:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wifi-solver.com">https://wifi-solver.com</a>, See on <a href="https://news.ycombinator.com/item?id=41897214">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Kurt Vonnegut's lost board game published (202 pts)]]></title>
            <link>https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview</link>
            <guid>41896636</guid>
            <pubDate>Sun, 20 Oct 2024 16:44:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview">https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview</a>, See on <a href="https://news.ycombinator.com/item?id=41896636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Fans of literature most likely know Kurt Vonnegut for the novel <em><a rel="sponsored" href="https://www.amazon.com/Slaughterhouse-Five-Kurt-Vonnegut-audiobook/dp/B015EKZX2U/?tag=polygon05-20">Slaughterhouse-Five</a></em>. The staunchly anti-war book first resonated with readers during the Vietnam War era, later becoming a staple in high school curricula the world over. When Vonnegut died in 2007 at the age of 84, he was widely recognized as one of the greatest American novelists of all time. But would you believe that he was also an accomplished game designer?</p><p>In 1956, following the lukewarm reception of his first novel, <em>Player Piano</em>, Vonnegut was one of the 16 million other World War II veterans struggling to put food on the table. His moneymaking solution at the time was a board game called <em>GHQ</em>, which leveraged his understanding of modern combined arms warfare and distilled it into a simple game played on an eight-by-eight grid. Vonnegut pitched the game relentlessly to publishers all year long according to game designer and NYU faculty member <a href="https://gamecenter.nyu.edu/faculty/geoff-engelstein/">Geoff Engelstein</a>, who recently found those letters sitting in the archives at <a href="https://libraries.indiana.edu/lilly-library/kurt-vonnegut">Indiana University</a>. But the real treasure was an original set of typewritten rules, complete with Vonnegut’s own notes in the margins. </p><p>With the permission of the Vonnegut estate, Engelstein tells Polygon that he cleaned the original rules up just a little bit, buffed out the dents in <em>GHQ</em>’s endgame, and spun up some decent art and graphic design. Now you can purchase the final product, titled <em>Kurt Vonnegut’s GHQ: The Lost Board Game</em>, at your local Barnes &amp; Noble — nearly 70 years after it was created.</p><div><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="445" data-pswp-width="600" target="_blank" rel="noreferrer"><img alt="A render of GHQ set up on a table for play. The markers are large and colorful, shaped like arrows and blocks. " data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><cite>Image: Mars International</cite></p></div><p>In a recent interview with Polygon, Engelstein still seemed stunned to have stumbled over the game in the first place through his research. But what’s truly fascinating to him is how diametrically opposed to Vonnegut’s later work <em>GHQ </em>truly is.</p><p>“<em>Sirens of Titan</em> was written at the same time as he was working on this game,” Engelstein told Polygon. “In <em>Sirens of Titan</em>, there’s this army of Mars which is really a joke. No one in the army, [not] even the officers, are really in charge of what’s going on. They’re all mind controlled. Nobody has any real free will. They’re just set up as a pawn to be sacrificed, to make Earth come together, kind of <em>Watchmen</em>-style.” </p><div id=":R3irarr6:"><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div></div><p>While <em><a rel="sponsored" href="https://www.amazon.com/The-Sirens-of-Titan-Kurt-Vonnegut-audiobook/dp/B001D1ILCO/?tag=polygon05-20">The Sirens of Titan</a></em> was a deeply cynical view of war, <em>GHQ </em>is deeply <em>un</em>cynical. In fact, his own pitch letters note that Vonnegut thought <em>GHQ</em> would be an excellent training aid for future military leaders, including cadets at West Point. How are modern audiences to reconcile those words from the same man who wrote <em><a rel="sponsored" href="https://www.amazon.com/Cats-Cradle-Kurt-Vonnegut-audiobook/dp/B000Z7FH9M/?tag=polygon05-20">Cat’s Cradle</a></em>?</p><p>“There’s no definitive answers [to those questions],” Engelstein said. “He didn’t write about it. Nobody asked him about it while he was alive, so we will never know.”</p><p>For fans of board gaming, the questions go in a slightly different direction: What if Vonnegut’s pitches from the 1950s had been successful? </p><p>Engelstein reasons that if Vonnegut was pitching the game in ’56, then it would have taken at least a few years for the game to be produced and finally published. That 1958-1959 window would have placed <em>GHQ</em> in rare company — 1958 was the year <em>Tactics 2</em> was published, a game that would go on to inspire the <a href="https://www.polygon.com/features/2013/1/29/3916154/turn-by-turn-battlefront-combat-mission">Squad Leader</a> series of map-and-token tactical wargames and, ultimately, video game genres like turn-based and real-time strategy. Just a year later and the industry would see the release of <em>Risk</em> and <em>Diplomacy</em>, the precursors of the modern 4X genre and, in and of themselves, two successful franchises that are popular to this day. </p><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="A letter pitching GHQ to the Sallfield Publishing Company in Ohio. Also a rejection letter from the same organization." data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p>“Three games that had tremendous influence, all war-related, coming out in that one-year, two-year period,” Engelstein mused. “So if <em>GHQ</em> also came out at the time period? There’s something in the air at that point, obviously.”</p><p>Of course, we’ll never know how those counterfactuals would have played out, but at least <em>GHQ</em> is finally available to the public. That’s great news for one of its original playtesters, Kurt Vonnegut’s son, Mark Vonnegut, who’s now 77. Engelstein said his input was invaluable in bringing the game to life.</p><p>“The success of <em>Slaughterhouse-Five</em> and the other novels is nice enough,” Vonnegut’s son recently wrote Engelstein in an email, “but I truly believe he’s watching somehow, someway, from somewhere and that the success of <em>GHQ</em> will be a greater and purely unadulterated pleasure. [...] He was discouraged about his writing at the time, but had unshakable faith that <em>GHQ</em> would succeed.”</p><p>You can find <em>Kurt Vonnegut’s GHQ: The Lost Board Game</em>, along with a special forward by <a href="https://www.polygon.com/24164196/expanse-james-s-a-corey-new-book-mercy-gods">author James S.A. Corey</a>, exclusively at Barnes &amp; Noble.</p><div data-product-filter=""><p><a href="https://go.skimresources.com/?id=1025X1701642&amp;xs=1&amp;url=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fkurt-vonneguts-ghq-the-lost-board-game-mars-international%2F1146300521" rel="nofollow noopener noreferrer" target="_blank"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 768px) 100vw, 300px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2400"></a><a href="https://go.skimresources.com/?id=1025X1701642&amp;xs=1&amp;url=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fkurt-vonneguts-ghq-the-lost-board-game-mars-international%2F1146300521" rel="nofollow noopener noreferrer" target="_blank"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 768px) 100vw, 600px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2400"></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drasi: Microsoft's open source data processing platform for event-driven systems (211 pts)]]></title>
            <link>https://github.com/drasi-project/drasi-platform</link>
            <guid>41896297</guid>
            <pubDate>Sun, 20 Oct 2024 16:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/drasi-project/drasi-platform">https://github.com/drasi-project/drasi-platform</a>, See on <a href="https://news.ycombinator.com/item?id=41896297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Drasi</h2><a id="user-content-drasi" aria-label="Permalink: Drasi" href="#drasi"></a></p>
<p dir="auto">Drasi is a data processing platform that simplifies detecting changes in data and taking immediate action. It is a comprehensive solution that provides built-in capabilities to track system logs and change feeds for specific events, evaluate them for relevance, and automatically initiate appropriate reactions. Visit our documentation site at <a href="https://drasi.io/" rel="nofollow">https://drasi.io</a> for detailed information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Drasi provides real-time actionable insights without the overhead of traditional data processing methods. It tracks system changes and events without the need to copy data to a central data lake or repeatedly query data sources. Drasi uses queries to continuously evaluate incoming data changes. When the changes match the criteria and conditions specified in these queries the result sets of these queries are updated. These updates then trigger context-aware reactions defined tuned to your specific requirements.</p>
<p dir="auto">Drasi operates through three components:</p>
<ul dir="auto">
<li><strong>Sources</strong> connect to data repositories within software systems to monitor logs and feeds to track changing data.</li>
<li><strong>Continuous Queries</strong> interpret monitored changes by applying criteria and conditions to identify significant changes. In Drasi, these Continuous Queries are written using the Cypher Query Language.</li>
<li><strong>Reactions</strong> trigger meaningful responses based on updates to the result sets of the Continuous Queries.<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/drasi-project/community/blob/main/images/drasi_components.png"><img src="https://github.com/drasi-project/community/raw/main/images/drasi_components.png" alt="Alt text" width="800" height="300"></a></p>
<p dir="auto"><br>To illustrate how Drasi interprets events and triggers appropriate responses, consider a delivery system for an online ordering service. Orders are processed through an order management system, and delivery drivers need real-time notifications when orders are ready for pickup. Drasi automates this process by:<br></p>
<ul dir="auto">
<li>Configuring a Source to monitor the order management system for changes in order statuses and a second Source to detect when a driver becomes available for a delivery run.</li>
<li>Creating a Continuous Query that combines data from both Sources to match orders ready for pickup with available drivers.</li>
<li>Defining a Reaction to send alerts to drivers, notifying them to proceed to the pickup area.
This streamlined setup ensures drivers are promptly informed, optimizing the delivery process through real-time data integration and automated responses.<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/drasi-project/community/blob/main/images/curbside_pickup_drasi.png"><img src="https://github.com/drasi-project/community/raw/main/images/curbside_pickup_drasi.png" alt="Alt text" width="800" height="300"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Follow the <a href="https://drasi.io/getting-started/" rel="nofollow">Getting Started tutorial</a> and try out Drasi. The tutorial will lead you through:</p>
<ol dir="auto">
<li>Applying a Source representing the data source whose changes you want to observe.</li>
<li>Creating Continuous Queries to define the data to observe, conditions to assess changes, and the structure of the output.</li>
<li>Applying a Debug Reaction to view the output generated by one or more Continuous Queries.</li>
</ol>
<p dir="auto">Head over to our <a href="https://drasi.io/" rel="nofollow">documentation site</a> and visit the <a href="https://drasi.io/tutorials/" rel="nofollow">Tutorial</a> and <a href="https://drasi.io/how-to-guides/" rel="nofollow">How To</a> guides to learn more about Drasi.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Release Status</h2><a id="user-content-release-status" aria-label="Permalink: Release Status" href="#release-status"></a></p>
<p dir="auto">This is an early release of Drasi for the community learn about the platform and experiment with in Proofs Of Concept. Please share your thoughts on Drasi and create GitHub issues for any bugs you may find or if you have feature requests that will help improve Drasi.</p>
<p dir="auto">This repo contains everything you require to build a Drasi-based solution with Sources, Reactions, and tooling for development and testing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">We hope you will join us and contribute to Drasi! Some of the ways to get started with contributing are participating in Issue discussions or joining us on our <a href="https://aka.ms/drasidiscord" rel="nofollow">Discord server</a>. Check out our <a href="https://github.com/drasi-project/community">Community repo</a> for more information on the community, and guidance on contributing and development.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing To Drasi</h2><a id="user-content-contributing-to-drasi" aria-label="Permalink: Contributing To Drasi" href="#contributing-to-drasi"></a></p>
<p dir="auto">Please see the <a href="https://github.com/drasi-project/drasi-platform/blob/main/CONTRIBUTING.md">Contribution guide</a> for information on contributing to Drasi.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Please refer to our guide on <a href="https://github.com/drasi-project/drasi-platform/blob/main/SECURITY.md#reporting-security-issues">reporting security vulnerabilities</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code of Conduct</h2><a id="user-content-code-of-conduct" aria-label="Permalink: Code of Conduct" href="#code-of-conduct"></a></p>
<p dir="auto">Please refer to Drasi's <a href="https://github.com/drasi-project/community/blob/main/CODE_OF_CONDUCT.md">Code of Conduct</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <strong>Apache 2.0 license</strong>. Please see the <a href="https://github.com/drasi-project/community/blob/main/LICENSE">LICENSE</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact the Drasi Authors</h2><a id="user-content-contact-the-drasi-authors" aria-label="Permalink: Contact the Drasi Authors" href="#contact-the-drasi-authors"></a></p>
<p dir="auto">Please join us on Discord to contact us and we will get back to you as soon as possible. You can also email us at <a href="mailto:info@drasi.io">info@drasi.io</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Part of PostgreSQL We Hate the Most (2023) (237 pts)]]></title>
            <link>https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html</link>
            <guid>41895951</guid>
            <pubDate>Sun, 20 Oct 2024 15:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html">https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html</a>, See on <a href="https://news.ycombinator.com/item?id=41895951">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>There are a lot of choices in databases (<a onclick="javascript:pageTracker._trackPageview('/outgoing/dbdb.io');" href="https://dbdb.io/" target="_blank">897</a> as of April 2023). With so many systems, it’s hard to know what to pick! But there is an interesting phenomenon where the Internet collectively decides on the default choice for new applications. In the 2000s, the conventional wisdom selected MySQL because rising tech stars like Google and Facebook were using it. Then in the 2010s, it was MongoDB because <a onclick="javascript:pageTracker._trackPageview('/outgoing/stackoverflow.com');" href="https://stackoverflow.com/a/3737121" target="_blank">non-durable writes</a> made it “<a onclick="javascript:pageTracker._trackPageview('/outgoing/youtu.be');" href="https://youtu.be/b2F-DItXtZs" target="_blank">webscale</a>“. In the last five years, PostgreSQL has become the Internet’s darling DBMS. And for good reasons! It’s dependable, feature-rich, extensible, and well-suited for most operational workloads.</p>
<p>But as much as we <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://twitter.com/andy_pavlo/status/1534225032179814403" target="_blank">love PostgreSQL at OtterTune</a>, certain aspects of it are not great. So instead of writing yet another blog article like everyone else touting the awesomeness of everyone’s favorite elephant-themed DBMS, we want to discuss the one major thing that sucks: how PostgreSQL implements <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control" target="_blank">multi-version concurrency control</a> (MVCC). Our <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://db.cs.cmu.edu/papers/2017/p781-wu.pdf" target="_blank">research</a> at Carnegie Mellon University and experience optimizing PostgreSQL database instances on Amazon RDS have shown that its MVCC implementation is the <u><b>worst</b></u> among the other widely used relational DBMSs, including MySQL, Oracle, and Microsoft SQL Server. And yes, Amazon’s PostgreSQL Aurora still has these problems.</p>
<p>In this article, we’ll dive into MVCC: what it is, how PostgreSQL does it, and why it is terrible. Our goal at OtterTune is to give you <i>fewer</i> things to worry about with your databases, so we’ve thought a lot about dealing with this problem. We’ll cover OtterTune’s solution for managing PostgreSQL’s MVCC issues automatically for RDS and Aurora databases in a follow-up article next week.</p>
<h2 id="what-is-mvcc">What is Multi-Version Concurrency Control?</h2>
<p>The goal of MVCC in a DBMS is to allow multiple queries to read and write to the database simultaneously without interfering with each other when possible. The basic idea of MVCC is that the DBMS never overwrites existing rows. Instead, for each (logical) row, the DBMS maintains multiple (physical) versions. When the application executes a query, the DBMS determines which version to retrieve to satisfy the request according to some version ordering (e.g., creation timestamp). The benefit of this approach is that multiple queries can read older versions of rows without getting blocked by another query updating it. Queries observe a snapshot of the database as it existed when the DBMS started that query’s transaction (snapshot isolation). This approach eliminates the need for explicit <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/explicit-locking.html" target="_blank">record locks</a> that block readers from accessing data while writers modify the same item.</p>
<p>David Reed’s 1978 MIT Ph.D. dissertation, “<a onclick="javascript:pageTracker._trackPageview('/outgoing/dspace.mit.edu');" href="https://dspace.mit.edu/handle/1721.1/16279" target="_blank">Concurrency Control in Distributed Database Systems</a>,” was, we believe, the first publication to describe MVCC. The first commercial DBMS implementation of MVCC was <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/InterBase#History" target="_blank">InterBase</a> in the 1980s. Since then, nearly every new DBMS created in the last two decades that supports transactions implements MVCC.</p>
<p>A systems engineer has to make several design decisions when building a DBMS that supports MVCC. At a high level, it comes down to the following:</p>
<ol>
  <li aria-level="1">How to store updates to existing rows.</li>
  <li aria-level="1">How to find the correct version of a row for a query at runtime.</li>
  <li aria-level="1">How to remove expired versions that are no longer visible.</li>
</ol>

<p>These decisions are not mutually exclusive. In the case of PostgreSQL, it’s how they decided to handle the first question in the 1980s that caused problems with the other two that we still have to deal with today.</p>
<p>For our discussion, we will use the following example of a table containing movie information. Each row in the table includes the movie name, release year, director, and a unique ID serving as the primary key, with secondary indexes on the movie name and director. Here is the DDL command to create this table:</p>
<pre><code>CREATE TABLE movies (
  id INTEGER PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
  name VARCHAR(256) NOT NULL,
  year SMALLINT NOT NULL,
  director VARCHAR(128)
);
CREATE INDEX idx_name ON movies (name);
CREATE INDEX idx_director ON movies (director);</code></pre>

<p>The table contains a primary index (<code>movies_pkey</code>) and two secondary B+Tree indexes (<code>idx_name</code>, <code>idx_director</code>).</p>
<h2 id="postgresql-mvcc">PostgreSQL’s Multi-Version Concurrency Control</h2>

<p>As discussed in Stonebraker’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/apps.dtic.mil');" href="https://apps.dtic.mil/sti/citations/ADA187244" target="_blank">system design document from 1987</a>, PostgreSQL was designed from the beginning to support multi-versioning. The core idea of PostgreSQL’s MVCC scheme is seemingly straightforward: when a query updates an existing row in a table, the DBMS makes a copy of that row and applies the changes to this new version instead of overwriting the original row. We refer to this approach as the <b>append-only</b> version storage scheme. But as we now describe, this approach has several non-trivial implications in the rest of the system.</p>
<h3>Multi-Versioned Storage</h3>
<p>PostgreSQL stores all row versions in a table in the same storage space. To update an existing tuple, the DBMS first acquires an empty slot from the table for the new row version. It then copies the row content of the current version to the new version, and applies the modifications to the row in the newly allocated version slot. You can see this process in the example below when an application executes an update query on the movies database to change the release year of “<a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Shaolin_and_Wu_Tang" target="_blank">Shaolin and Wu Tang</a>” from 1985 to 1983:</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example1.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example1.svg"></a>
  <figcaption>When an UPDATE query changes a tuple in the table, PostgreSQL copies the original version of the tuple and then applies the change to the new version. In this example, there is no more space in Table Page #1, so PostgreSQL creates the new version in Table Page #2.</figcaption>
</figure>

<p>Now with two physical versions representing the same logical row, the DBMS needs to record the lineage of these versions so that it knows how to find them in the future. MVCC DBMSs achieve this by creating a <b>version chain</b> via a singly linked-list. The version chain only goes in one direction to reduce storage and maintenance overhead. This means that the DBMS has to decide what order to use: <i>newest-to-oldest</i> (N2O) order or <i>oldest-to-newest</i> (O2N). For the N2O order, each tuple version points to its previous version and the version chain’s head is always the latest version. For the O2N order, each tuple version points to its new version, and the head is the oldest tuple version. The O2N approach avoids the need for the DBMS to update indexes to point to a newer version of the tuple each time it’s modified. However, it may take longer for the DBMS to find the latest version during query processing, potentially traversing a long version chain. Most DBMSs, including Oracle and MySQL, implement N2O. But PostgreSQL stands alone in using O2N (except for Microsoft’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/learn.microsoft.com');" href="https://learn.microsoft.com/en-us/sql/relational-databases/in-memory-oltp/introduction-to-memory-optimized-tables?view=sql-server-ver16" target="_blank">In-Memory OLTP engine</a> for SQL Server).</p>
<p>The next issue is how PostgreSQL determines what to record for these version pointers. The header for each row in PostgreSQL contains a tuple id field ( <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/storage-page-layout.html#STORAGE-TUPLE-LAYOUT" target="_blank">t_tcid</a>) of the next version (or its own tuple id if it is the latest version). Thus, as shown in this next example, when a query requests the latest version of a row, the DBMS traverses the index, lands on the oldest version, and then follows the pointer until it finds a version that it needs.</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example3.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example3.svg"> </a>
  <figcaption>The SELECT query traverses the index to find tuple with requested movie name. The index entry points to the oldest version of the tuple, which means PostgreSQL follows the version chain embedded in the original version to find the new version.</figcaption>
</figure>

<p>PostgreSQL developers realized early on that there are two problems with its MVCC scheme. First, making a new copy of an entire tuple every time it is updated is expensive. And second, traversing the entire version chain just to find the latest version (which is what most queries want) is wasteful. Of course there is also the problem of cleaning up old versions, but we’ll cover that below.</p>
<p>To avoid traversing the entire version chain, PostgreSQL adds an entry to a table’s indexes for each physical version of a row. That means if there are five physical versions of a logical row, there will be (at most) five entries for that tuple in the index! In the example below, we see that the <code>idx_name</code> index contains entries for each of the “Shaolin and Wu Tang” rows that are on separate pages. This enables direct access to the latest version of the tuple, without the need to traverse the long version chain.</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example4.svg">
    <img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example4.svg">
    </a>
    <figcaption>In this example, the index contains multiple entries for the “Shaolin and Wu Tang” tuple (one for each version). Now PostgreSQL uses the index to find the latest version and then immediately retrieves it from Table Page #2 without having to traverse the version chain starting at Table Page #1.</figcaption>
</figure>

<p>PostgreSQL tries to avoid having to install multiple index entries and storing related versions over multiple pages by creating a new copy in the same disk page (block) as the old version to reduce disk I/O. This optimization is known as <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/storage-hot.html" target="_blank">heap-only tuple (HOT)</a> updates. The DBMS uses the HOT approach if an update does not modify any columns referenced by a table’s indexes and the new version is stored on the same data page as the old version (if there is space in that page). Now in our example, after the update the index still points to the old version and queries retrieve the latest version by traversing the version chain. During normal operation, PostgreSQL further optimizes this process by removing old versions to prune the version chain.</p>
<h3>Version Vacuum</h3>
<p>We’ve established that PostgreSQL makes a copy of rows whenever an application updates them. The next question is how the system removes older versions (called “dead tuples”). The original version of PostgreSQL from the 1980s did not remove dead tuples. The idea was that keeping all the older versions allowed applications to execute “time-travel” queries to examine the database at a particular point in time (e.g., run a <code>SELECT</code> query on the state of the database as it existed at the end of last week). But never removing dead tuples means tables never shrink in size if the application deletes tuples. It also means long version chains for frequently updated tuples, which would slow down queries, except that PostgreSQL adds index entries that allow queries to quickly jump to the correct version instead of traversing the chain. But now, this means the indexes are larger, making them slower and adding additional memory pressure. Hopefully, you can understand now why all these issues are interconnected.</p>
<p>To overcome these problems, PostgreSQL uses a vacuum procedure to clean up dead tuples from tables. The vacuum performs a sequential scan on table pages modified since its last run and find expired versions. The DBMS considers a version “<b>expired</b>” if it is not visible to any active transaction. This means no current transaction is accessing that version, and future transactions will use the latest “<b>live</b>” version instead. Thus, removing the expired version and reclaiming the space for reuse is safe.</p>
<p>PostgreSQL automatically executes this vacuum procedure (autovacuum) at regular intervals based on its configuration settings. In addition to the global settings that affect the vacuum frequency for all tables, PostgreSQL provides the flexibility to configure autovacuum at the table level to fine-tune the process for specific tables. Users can also trigger the vacuum manually to optimize database performance via the <code>VACUUM</code> SQL command.</p>
<h2 id="why-postgresqls-mvcc-is-the-worst">Why PostgreSQL’s MVCC is the Worst</h2>
<p>We will be blunt: if someone is going to build a new MVCC DBMS today, they should <u> <b>not</b> </u> do it the way PostgreSQL does (e.g., append-only storage with autovacuum). In our <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://db.cs.cmu.edu/papers/2017/p781-wu.pdf" target="_blank">2018 VLDB paper</a> (aka “ <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/andy_pavlo/status/902863242774634496" target="_blank">the best paper ever on MVCC</a>“), we did not find another DBMS doing MVCC the way PostgreSQL does it. Its design is a relic of the 1980s and before the proliferation of <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Log-structured_merge-tree" target="_blank">log-structured</a> system patterns from the 1990s.</p>
<p>Let’s talk about four problems that arise with PostgreSQL’s MVCC. We will also talk about why other MVCC DBMSs like Oracle and MySQL avoid these problems.</p>
<h3>Problem #1: Version Copying</h3>
<p>With the append-only storage scheme in MVCC, if a query updates a tuple, the DBMS copies all its columns into the new version. This copying occurs no matter if the query updates a single or all of its columns. As you can imagine, append-only MVCC results in massive data duplication and increased storage requirements. This approach means that PostgreSQL requires more memory and disk storage to store a database than other DBMS, which means slower queries and higher cloud costs. Instead of copying an entire tuple for a new version, MySQL and Oracle store a compact delta between the new and current versions (think of it like a git diff). Using deltas means that if a query only updates a single column in a tuple for a table with 1000 columns, then the DBMS only stores a delta record with the change to that one column. On the other hand, PostgreSQL creates a new version with the one column that the query changed and the 999 other untouched columns. We will ignore TOAST attributes because PostgreSQL <a onclick="javascript:pageTracker._trackPageview('/outgoing/dba.stackexchange.com');" href="https://dba.stackexchange.com/a/308779" target="_blank">handles them differently</a>.</p>
<p>There was an attempt to modernize PostgreSQL’s version storage implementation. EnterpriseDB started the <a onclick="javascript:pageTracker._trackPageview('/outgoing/wiki.postgresql.org');" href="https://wiki.postgresql.org/wiki/Zheap" target="_blank">zheap project</a> in 2013 to replace the append-only storage engine to use delta versions. Unfortunately the <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.cybertec-postgresql.com');" href="https://www.cybertec-postgresql.com/en/postgresql-zheap-current-status/" target="_blank">last official update was in 2021</a>, and to the best of our knowledge the effort has fizzled out.</p>
<h3>Problem #2: Table Bloat</h3>
<p>Expired versions in PostgreSQL (i.e., dead tuples) also occupy more space than delta versions. Although PostgreSQL’s autovacuum will eventually remove these dead tuples, write-heavy workloads can cause them to accumulate faster than the vacuum can catch up, resulting in continuous database growth. The DBMS has to load dead tuples into memory during query execution since the system intermingles dead tuples with live tuples in pages. Unfettered bloat slows query performance by causing the DBMS to incur more IOPS and consume more memory than necessary during table scans. Additionally, inaccurate optimizer statistics caused by dead tuples can lead to poor query plans.</p>
<p>Suppose our movies table has 10 million live and 40 million dead tuples, making 80% of the table obsolete data. Assume also that the table also has many more columns than what we are showing and that the average size of each tuple is 1KB. With this scenario, the live tuples occupy 10GB of storage space while the dead tuples occupy ~40GB of storage; the total size of the table is 50GB. When a query performs a full table scan on this table, PostgreSQL has to retrieve all 50GB from the disk and store it in memory, even if most of it is obsolete. Although Postgres has a <a onclick="javascript:pageTracker._trackPageview('/outgoing/madusudanan.com');" href="https://madusudanan.com/blog/understanding-postgres-caching-in-depth/#SeqScans" target="_blank">protection mechanism</a> to avoid polluting its buffer pool cache from sequential scans, it does not help prevent IO costs.</p>
<p>Even if you make sure that PostgreSQL’s autovacuum is running at regular intervals and able to keep up with your workload (which is not always easy to do, see below), the autovacuum cannot reclaim storage space. The autovacuum only removes dead tuples and relocates live tuples within each page, but it does not reclaim empty pages from the disk.</p>
<p>When the DBMS truncates the last page due to the absence of any tuple, other pages remain on disk. In our example above, even if PostgreSQL removed the 40GB of dead tuples from the movies table, it still retains the 50GB of allocated storage space from the operating system (or, in the case of RDS, from Amazon). To reclaim and return such unused space, one must use <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/sql-vacuum.html#:~:text=VACUUM%20FULL%20rewrites%20the%20entire,while%20it%20is%20being%20processed." target="_blank"><code>VACUUM FULL</code></a> or the <a onclick="javascript:pageTracker._trackPageview('/outgoing/reorg.github.io');" href="https://reorg.github.io/pg_repack/" target="_blank">pg_repack</a> extension to rewrite the entire table to a new space with no wasted storage. Running either of these operations is not an easy endeavor that one should take without considering the performance implications for production databases; they are resource-intensive and time-consuming operations that will crush query performance. The following figure shows how <code>VACUUM</code> and <code>VACUUM FULL</code> work.</p>
<figure>
    <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-vacuum.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-vacuum.svg"> </a>
    <figcaption>With PostgreSQL’s regular VACUUM operation, the DBMS only removes dead tuples from each table page and reorganizes it to put all the live tuples at the end of the page. With VACUUM FULL, PostgreSQL removes the dead tuples from each page, coalesces and compacts the remaining live tuples to a new page (Table Page #3), and then deletes the unneeded pages (Table Pages #1 / #2).</figcaption>
</figure>

<h3>Problem #3: Secondary Index Maintenance</h3>
<p>A single update to a tuple requires PostgreSQL to update all the indexes for that table. Updating all the indexes is necessary because PostgreSQL uses the exact physical locations of a version in both primary and secondary indexes. Unless the DBMS stores the new version in the same page as the previous version (HOT update), the system does this for every update.</p>
<p>Returning to our <code>UPDATE</code> query example, PostgreSQL creates a new version by copying the original version into a new page just like before. But it also inserts entries pointing to the new version in table’s primary key index ( <code>movies_pkey</code>) and the two secondary indexes ( <code>idx_director</code>, <code>idx_name</code>).</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example5.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example5.svg"> </a>
  <figcaption>Example of PostgreSQL index maintenance operations with a non-HOT update. The DBMS creates the new version of the tuple in Table Page #2, and then inserts new entries that point to that version in all the table’s indexes.</figcaption>
</figure>

<p>The need for PostgreSQL to modify all of a table’s indexes for each update has several performance implications. Obviously, this makes update queries slower because the system has to do more work. The DBMS incurs additional I/O to traverse each index and insert the new entries. Accessing an index introduces lock/latch contention in both the index and the DBMS’s internal data structures (e.g., buffer pool’s page table). Again, PostgreSQL does this maintenance work for all a table’s indexes, even if queries are never going to use them (by the way, OtterTune <a onclick="javascript:pageTracker._trackPageview('/outgoing/docs.ottertune.com');" href="https://docs.ottertune.com/documentation/database-instance-dashboard-and-recommendations/recommendations/index-recommendations">automatically finds unused indexes in your database</a>). These extra reads and writes are problematic in DBMSs that charge users based on IOPS, like Amazon Aurora.</p>
<p>As described above, PostgreSQL avoids updating indexes each time if it can perform a HOT write where the new version is on the same page as the current version. Our analysis of OtterTune customers’ PostgreSQL databases shows that roughly 46% of updates use the HOT optimization on average. Although that’s an impressive number, it still means more than 50% of the updates are paying this penalty.</p>
<p>There are many examples of users struggling with this aspect of PostgreSQL’s MVCC implementation. The most famous testament of this is Uber’s 2016 blog article about why they <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.uber.com');" href="https://www.uber.com/blog/postgres-to-mysql-migration/" target="_blank">switched from Postgres to MySQL</a>. Their write-heavy workload was experiencing significant performance problems on tables with many secondary indexes.</p>
<p>Oracle and MySQL do not have this problem in their MVCC implementation because their secondary indexes do not store the physical addresses of new versions. Instead, they store a logical identifier (e.g., tuple id, primary key) that the DBMS then uses to look up the current version’s physical address. Now this may make secondary index reads slower since the DBMS has to resolve a logical identifier, but these DBMS have other advantages in their MVCC implementation to reduce overhead.</p>


<h3>Problem #4: Vacuum Management</h3>
<p>PostgreSQL’s performance relies heavily on the effectiveness of the autovacuum to remove obsolete data and reclaim space (this is why OtterTune immediately checks the health status of the autovacuum when you first connect your database). It does not matter if you are running RDS, Aurora, or Aurora Serverless; all variants of PostgreSQL have the same autovacuum issues. But making sure that PostgreSQL’s autovacuum is running as best as possible is difficult due to its complexity. PostgreSQL’s default settings for tuning the autovacuum are not ideal for all tables, particularly for large ones. For example, the default setting for the configuration knob that controls what percentage of a table PostgreSQL has to update before the autovacuum kicks in (<a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/15/runtime-config-autovacuum.html#GUC-AUTOVACUUM-VACUUM-SCALE-FACTOR" target="_blank">autovacuum_vacuum_scale_factor</a>) is 20%. This threshold means that if a table has 100 million tuples, the DBMS does not trigger the autovacuum until queries update at least 20 million tuples. As such, PostgreSQL may unnecessarily keep around a lot of dead tuples in a table (thereby incurring IO and memory costs) for a long time.</p>
<p>Another problem with the autovacuum in PostgreSQL is that it may get blocked by long-running transactions, which can result in the accumulation of more dead tuples and stale statistics. Failing to clean expired versions in a timely manner leads to numerous performance problems, causing more long-running transactions that block the autovacuum process. It becomes a vicious cycle, requiring humans to intervene manually by killing long-running transactions. Consider the graph below that shows the number of dead tuples in an OtterTune customer’s database over two weeks:</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-deadtuples.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-deadtuples.svg"></a>
  <figcaption>The number of dead tuples over time in a PostgreSQL Amazon RDS database.</figcaption>
</figure>

<p>The sawtooth pattern in the chart shows that the autovacuum performs a major clean-up about once every day. For example, on February 14th, the DBMS cleaned up 3.2 million dead tuples. This graph is actually an example of an unhealthy PostgreSQL database. The chart clearly shows an upward trend in the number of dead tuples because the autovacuum cannot keep up.</p>
<p>At OtterTune, we see this problem often in our customers’ databases. One PostgreSQL RDS instance had a long-running query caused by stale statistics after bulk insertions. This query blocked the autovacuum from updating the statistics, resulting in more long-running queries. OtterTune’s automated health checks identified the problem, but the administrator still had to kill the query manually and run <a onclick="javascript:pageTracker._trackPageview('/outgoing/ottertune.com');" href="https://ottertune.com/blog/run-postgresql-analyze-to-fix-a-slowdow-in-db/">ANALYZE after bulk insertions</a>. The good news is that the long query’s execution time went from 52 minutes to just 34 seconds.</p>

<p>There are always hard design decisions one has to make when building a DBMS. And these decisions will cause any DBMS to perform differently on varying workloads. For Uber’s specific write-intensive workload, PostgreSQL’s index write amplification due to MVCC is why they switched to MySQL. But please don’t misunderstand our diatribe to mean that we don’t think you should ever use PostgreSQL. Although its MVCC implementation is the wrong way to do it, PostgreSQL is still our favorite DBMS. To love something is to be willing to work with its flaws (see Dan Savage’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/youtu.be');" href="https://youtu.be/r1tCAXVsClw" target="_blank">“The Price of Admission”</a>).</p>
<p>So how does one work around PostgreSQL’s quirks? Well, you can spend an enormous amount of time and effort tuning it yourself. <a onclick="javascript:pageTracker._trackPageview('/outgoing/philbooth.me');" href="https://philbooth.me/blog/nine-ways-to-shoot-yourself-in-the-foot-with-postgresql" target="_blank">Good luck with that</a>.</p>
<p>We’ll cover more about what we can do in our next article.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive breached again through stolen access tokens (372 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/</link>
            <guid>41895764</guid>
            <pubDate>Sun, 20 Oct 2024 15:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/">https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/</a>, See on <a href="https://news.ycombinator.com/item?id=41895764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="The Internet Archive" height="900" src="https://www.bleepstatic.com/content/hl-images/2024/10/09/internet-archive.jpg" width="1600"></p>
<p>The Internet Archive was breached again, this time on their Zendesk email support platform after repeated warnings that threat actors stole exposed GitLab authentication tokens.</p>
<p>Since last night, BleepingComputer has received numerous messages from people who received replies to their old Internet Archive removal requests, warning that the organization has been breached as they did not correctly rotate their stolen authentication tokens.</p>
<p>"It's dispiriting to see that even after being made aware of the breach weeks ago, IA has still not done the due diligence of rotating many of the API keys that were exposed in their gitlab secrets," reads an email from the threat actor.</p>
<p>"As demonstrated by this message, this includes a Zendesk token with perms to access 800K+ support tickets sent to info@archive.org since 2018."</p>
<p>"Whether you were trying to ask a general question, or requesting the removal of your site from the Wayback Machine your data is now in the hands of some random guy. If not me, it'd be someone else."</p>
<div>
<figure><img alt="Internet Archive Zendesk emails sent by the threat actor" height="600" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/zendesk-emails.jpg" width="937"><figcaption><strong>Internet Archive Zendesk emails sent by the threat actor</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The email headers in these emails also pass all DKIM, DMARC, and SPF authentication checks, proving they were sent by an authorized Zendesk server at&nbsp;192.161.151.10.</p>
<div>
<figure><img alt="Internet Archive Zendesk email headers" height="200" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/mail-headers.jpg" width="909"><figcaption><strong>Internet Archive Zendesk email headers</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>After publishing this story, BleepingComputer was told by a recipient of these emails that they had to upload personal identification when requesting a removal of a page from the Wayback Machine.</p>
<p>The threat actor may now also have access to these attachments depending on the API access they had to Zendesk and if they used it to <a href="https://developer.zendesk.com/api-reference/ticketing/tickets/ticket-attachments/#show-attachment" target="_blank" rel="nofollow noopener">download support tickets</a>.</p>
<p>These emails come after BleepingComputer repeatedly tried to warn the Internet Archive that their source code was stolen through a&nbsp;GitLab authentication token that was exposed online for almost two years.</p>
<h2>Exposed GitLab authentication tokens</h2>
<p>On October 9th, BleepingComputer reported that Internet&nbsp;Archive was <a href="https://www.bleepingcomputer.com/news/security/internet-archive-hacked-data-breach-impacts-31-million-users/" target="_blank">hit by two different attacks at once last week</a>—a data breach where the site's user data for 33 million users was stolen and a DDoS attack by a pro-Palestinian group named SN_BlackMeta.</p>
<p>While both attacks occurred over the same period, they were conducted by different threat actors. However, many outlets incorrectly reported that SN_BlackMeta was behind the breach rather than just the DDoS attacks.</p>
<div>
<figure><img alt="JavaScript alert on Internet Archive warning about the breach" height="300" width="665" data-src="https://www.bleepstatic.com/images/news/security/d/data-breaches/w/wayback-machine/js-alert.jpg" src="https://www.bleepstatic.com/images/news/security/d/data-breaches/w/wayback-machine/js-alert.jpg"><figcaption><strong>JavaScript alert on Internet Archive warning about the breach</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>This misreporting frustrated the threat actor behind the actual data breach, who contacted BleepingComputer through an intermediary to claim credit for the attack and explain how they breached the Internet Archive.</p>
<p>The threat actor told BleepingComputer that the initial breach of Internet Archive started with them finding an exposed GitLab configuration file on one of the organization's development servers, <em>services-hls.dev.archive.org</em>.</p>
<p>BleepingComputer was able to confirm that this token has been exposed since at least December 2022, with it rotating multiple times since then.</p>
<div>
<figure><img alt="Exposed Internet Archive GitLab authentication token" height="600" width="860" data-src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/gitlab-token.jpg" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/gitlab-token.jpg"><figcaption><strong>Exposed Internet Archive GitLab authentication token</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The threat actor says this GitLab configuration file contained an authentication token allowing them to download the Internet Archive source code.</p>
<p>The hacker say that this source code contained additional credentials and authentication tokens, including the credentials to Internet Archive's database management system. This allowed the threat actor to download the organization's user database, further source code, and modify the site.</p>
<p>The threat actor claimed to have stolen 7TB of data from the Internet Archive but would not share any samples as proof.</p>
<p>However, now we know that the stolen data also included the API access tokens for Internet Archive's Zendesk support system.</p>
<p>BleepingComputer attempted contact the Internet Archive numerous times, as recently as on Friday, offering to share what we knew about how the breach occurred and why it was done, but we never received a response.</p>
<h2>Breached for cyber street cred</h2>
<p>After the Internet Archive was breached, conspiracy theories abounded about why they were attacked.</p>
<p>Some said&nbsp;Israel did it,&nbsp;the United States government, or corporations in their ongoing battle with the Internet Archive over copyright infringement.</p>
<p>However, the Internet Archive was not breached for political or monetary reasons but simply because the threat actor could.</p>
<p>There is a large community of people who traffic in stolen data, whether they do it for money by extorting the victim, selling it to other threat actors, or simply because they are collectors of data breaches.</p>
<p>This data is often released for free to gain <em>cyber street cred</em><strong>,&nbsp;</strong>increasing their reputation among other threat actors in this community&nbsp;as they all compete for who has the most significant and most publicized attacks.</p>
<p>In the case of the Internet Archive, there was no money to be made by trying to extort the organization. However, as a well-known and extremely popular website, it definitely boosted a person's reputation amongst this community.</p>
<p>While no one has publicly claimed this breach, BleepingComputer was told it was done&nbsp;while the threat actor was in a group chat with others, with many receiving some of the stolen data.</p>
<p>This database is now likely being traded amongst other people in the data breach community, and we will likely see it leaked for free in the future on hacking forums like Breached.</p>
<p><em>Update 10/20/24: Added information about how some people had to upload personal IDs when requesting removal from Internet Archive.</em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The AI Investment Boom (168 pts)]]></title>
            <link>https://www.apricitas.io/p/the-ai-investment-boom</link>
            <guid>41895746</guid>
            <pubDate>Sun, 20 Oct 2024 14:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apricitas.io/p/the-ai-investment-boom">https://www.apricitas.io/p/the-ai-investment-boom</a>, See on <a href="https://news.ycombinator.com/item?id=41895746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><strong>Thanks for reading! If you haven’t subscribed, please click the button below:</strong></p><p><strong>By subscribing you’ll join over 45,000 people who read Apricitas!</strong></p><p><span>Last month, Microsoft made a high-profile announcement that it is paying to </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=63304" rel="">reopen reactor one at the Three Mile Island nuclear plant to meet the company’s growing data center power demand, joining Amazon</a><span> as the second major US tech company to turn to legacy nuclear facilities for their increasing energy needs. Microsoft is the primary investor and computing provider for OpenAI, who kicked off a revolution in AI development with its release of ChatGPT less than two years ago—and the Three Mile Island reopening underscored the frenzied growth in physical investment currently going on to meet the demands of these new AI systems.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:215863,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Today, AI products are used ubiquitously to generate code, text, and images, analyze data, automate tasks, enhance online platforms, and much, much, much more—with usage expected only to increase going forward. Yet these cutting-edge models require enormous computing resources for their training and inference, that computing requires massive arrays of advanced hardware housed at industrial-scale facilities, and those facilities require access to vast quantities of power, water, broadband, and other infrastructure for their operations.</p><p><span>Thus, the downstream result of the AI boom has been a rapid increase in US fixed investment to meet the growth in computing demand, with hundreds of billions of dollars going to high-end computers, data center facilities, power plants, and more. Right now, US data center construction is at a record-high rate of $28.6B a year, up 57% from last year and 114% from only two years ago. For context, that’s roughly as much as America spends on </span><a href="https://www.census.gov/construction/c30/historical_data.html" rel="">restaurant, bar, and retail store construction combined.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:353767,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>However, that construction figure is only for the physical buildings themselves—it excludes the massive racks of high-powered computers that form the brains of data centers plus the vast quantities of cables, fans, and other parts necessary to make that brain work. In August, net US imports of large computers (like those used for AI training) rose to a new record high, and net imports of computer parts, accessories, and other components had set a record high just the month before—in total, the US has brought in more than $65B across the two categories over the last year </span><a href="https://fred.stlouisfed.org/series/A34SVS" rel="">on top of rising domestic production.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:257436,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The majority of these new data centers, computers, and equipment are being bought by companies in the information technology space—that includes computing infrastructure providers like Amazon, web search firms like Google, and software publishers like Microsoft. Those companies have increased their net holdings of property, plant, and equipment by more than $95B over the last year, a record high, as they each compete to rapidly scale up and deploy their AI systems.</p><p><span>It’s a stark change from a little over a decade ago, when Facebook bought up Instagram for only $1.2B, following it up by paying $15B for WhatsApp two years later. At the time, these acquisitions were some of the largest in tech history and marked the beginning of an era where lightweight software publishers were considered the industry’s future—in total, Instagram had only 13 employees at the time it was purchased, Whatsapp had only 55, and neither company had much of a physical presence beyond some office space and programmers’ workstations. Today, </span><a href="https://s21.q4cdn.com/399680738/files/doc_financials/2024/q2/META-Q2-2024-Earnings-Call-Transcript.pdf" rel="">Facebook (now Meta) has spent $15.2B on capital expenditures in the first half of 2024 alone</a><span>, much of it on massive arrays of computing infrastructure to support the company’s Llama brand of AI models. So far, the AI boom has been more hardware-intensive than any tech boom in history, and that is rapidly boosting construction and investment within the United States.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/be130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:212869,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>American businesses’ investment in computers and related equipment has skyrocketed to a new record high amidst the AI boom, </span><a href="https://fred.stlouisfed.org/graph/?g=1wxmt" rel="">jumping 16.6% over the last year even after adjusting for inflation.</a><span> That’s in stark contrast to the nearly-decade-long relative stagnation in investment seen throughout the 2010s, which was only really shattered by the digital demands of the pandemic-era remote work boom. Computer investment retracted a bit in 2022 as work-from-home levels and internet usage stabilized, but it then came roaring back with the AI boom starting in late 2023.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:249266,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Yet not all computers are created equal—total computer investment may be at record levels, but the growth in the highest-end computer systems has been even faster. Taiwan’s TSMC is the world’s leading manufacturer of cutting-edge semiconductors, and the ravenous demand for AI compute is visible in the growing amount of chips, computers, and related components that the US now imports from Taiwan. Those imports have totaled more than $38B over the last year, rising more than 140% over the previous year, with little sign of stopping. All three categories have seen rapid growth, but direct US imports of logic chips have seen the largest relative increase, rising from relatively minimal levels to nearly $5B a year. Computer parts and components remain the largest import item—a reminder that data centers require more than just computers for their day-to-day operation and even when operational require further supplies for their maintenance and repair.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223124,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://apps.bea.gov/iTable/?ReqID=10&amp;step=2&amp;_gl=1*gocdd0*_ga*NzU5NjY0MDc1LjE3MTgwMDA3NzE.*_ga_J4698JNNFT*MTcyOTQyNDU4OC44NC4wLjE3Mjk0MjQ1ODguNjAuMC4w#eyJhcHBpZCI6MTAsInN0ZXBzIjpbMiwzXSwiZGF0YSI6W1siVGFibGVfTGlzdCIsIjU3Il1dfQ==" rel="">Breaking down the detailed sector-level investment data available through 2023</a><span> shows that </span><a href="https://imgur.com/ECaAd3r" rel="">although data processors and web search firms like Amazon/Google continued to have the largest investment levels in the tech space</a><span>, it was software developers who saw the fastest investment growth. Software publishers’ real investment in intellectual property—which encompasses many of the AI models themselves plus related research and development—grew by 40% since 2021, while real investment in equipment like computers grew by an astonishing 96%. The era of leading software developers being hardware-light companies has been replaced by an era where developers are racing each other to see who can build out hardware capabilities the fastest.</span></p><p><span>All of this hardware investment is not, however, evenly spread throughout the country. While data centers have to be spread out to some extent in order to serve networking needs and avoid binding infrastructure constraints, it’s often beneficial to concentrate them in large clusters to multiply their effectiveness and reduce costs/latency. That’s especially true for AI, which is why firms are pushing the limits of data center size </span><a href="https://www.semianalysis.com/p/multi-datacenter-training-openais" rel="">and networking</a><span> to throw as much computing power at model development as possible.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:455992,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>While we do not have granular data center construction data—official construction numbers only break down data center spending at the regional level—we can still see some interesting underlying patterns. The US data center buildout has remained strongest in its historical clusters within the American South, but growth has been much faster in markets throughout the Midwest and West Coast, while the Northeast has been functionally unaffected.</p><p><span>That buildout can have large implications for local power demand—over the last few months, the Energy Information Administration has </span><a href="https://www.eia.gov/outlooks/steo/pdf/steo_full.pdf" rel="">repeatedly raised its projections for load growth based on data center demand</a><span>, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=62409" rel="">now predicting that total commercial-sector electricity consumption will rise 3% this year and another 1% next year.</a><span> While those projections still leave commercial users as </span><a href="https://www.eia.gov/outlooks/steo/data/browser/#/?v=19&amp;f=A&amp;s=0&amp;start=2024&amp;end=2025&amp;chartindexed=2&amp;map=&amp;linechart=~ELCCTWH~ELRCTWH~ELICTWH&amp;id=&amp;ctype=linechart&amp;maptype=0" rel="">a smaller driver of rising power consumption than residential electrification and industrial reshoring</a><span>, they represent the sector’s fastest demand growth in years—for context, </span><a href="https://www.eia.gov/electricity/data/browser/#/topic/5?agg=0,1&amp;geo=g&amp;endsec=vg&amp;linechart=~~ELEC.SALES.US-COM.A~&amp;columnchart=ELEC.SALES.US-ALL.A~ELEC.SALES.US-RES.A~ELEC.SALES.US-COM.A~ELEC.SALES.US-IND.A&amp;map=ELEC.SALES.US-ALL.A&amp;freq=A&amp;ctype=linechart&amp;ltype=pin&amp;rtype=s&amp;maptype=0&amp;rse=0&amp;pin=" rel="">commercial power consumption rose only 5% in total between 2007 and 2023</a><span> and the </span><a href="https://www.eia.gov/energyexplained/electricity/use-of-electricity.php" rel="">pre-AI-boom official estimates put computers &amp; office equipment at only 11.4% of total commercial power consumption.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:318101,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Yet in some parts of the country, data center power consumption has been a major driver of electricity load growth—to use an illustrative example, North Dakota’s commercial power consumption has risen by more than 45% after the </span><a href="https://www.governor.nd.gov/news/burgum-one-worlds-largest-data-centers-locate-williston-area-industry-targets-growth-nd" rel="">opening of several key data centers in 2022.</a><span> However, North Dakota is a relatively tiny power and computing market, so the most significant increases in raw power demand have instead come from larger data center clusters in larger states like Virginia and Texas.</span></p><p><span>The </span><a href="https://x.com/JosephPolitano/status/1846265551611707500" rel="">byteway</a><span> in the Northern Virginia suburbs of DC is the largest cluster of computing power in the world, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=62409" rel="">and it’s caused the state to see a 30% increase in commercial energy consumption since 2019 and the largest raw increase in commercial power demand in the nation.</a><span> Texas, which has explicitly worked to attract data centers and crypto miners as part of its energy load management program, has also seen a 10% increase in commercial power consumption since 2019, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=63344" rel="">with much larger growth expected in the coming years.</a></p><p><span>That data center load growth has been a contributor to </span><a href="https://www.apricitas.io/p/the-regional-impacts-of-americas" rel="">the Lone Star State’s notable overperformance in renewable investment, where it leads the rest of the country significantly.</a><span> Indeed, ERCOT (Texas’ power grid) and PJM (which serves Virginia) are both currently </span><a href="https://www.eia.gov/outlooks/steo/data/browser/#/?v=22&amp;f=A&amp;s=0&amp;start=2023&amp;end=2025&amp;chartindexed=1&amp;map=&amp;linechart=RTEPGEN_US~RNEPGEN_TX~RNEPGEN_PJ~&amp;maptype=0&amp;ctype=linechart&amp;id=" rel="">projected to outpace the nation in renewables growth through this year and 2025.</a><span> The agglomeration benefits of data centers mean that AI firms are increasingly looking to concentrate near large power resources, hence the renewed focus on nuclear energy and the growing desire for tech companies to directly invest in power generation infrastructure as they build computing capabilities.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:428185,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Amidst the AI boom, revenue in the information technology space has rebounded from the slowdown of 2022 and 2023—software publishers, web search portals, and computing infrastructure providers have all seen their incomes rise by 12-15% over the last year. It’s a far cry from the halcyon days of 2021, but still puts revenue growth on the strong side of pre-COVID norms.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:312405,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Yet despite the tech sector’s recent rebound in revenues and boom in physical investment, employment growth has remained remarkably weak. The US has added only 32k tech jobs over the last year, lower than at any point in 2021, 2022, or the 9 years preceding the pandemic. Even the software publishers and computing infrastructure industries at the forefront of this AI boom have seen functionally zero net employment growth over the last year—the dismal job market that has beleaguered recent computer science graduates simply has not improved much.</p><p><span>That’s not to say there’s been no labor market impact of the AI investment boom, but rather that they’ve been primarily outside of traditional information tech sectors. </span><a href="https://imgur.com/b4lxZ7h" rel="">Total compensation in semiconductor manufacturing increased 25% from Q1 2023 to Q1 2024</a><span> as workers in companies like NVIDIA got much more valuable stock options. Some of the </span><a href="https://data.bls.gov/dataViewer/view/timeseries/CEU2023622001" rel="">30k increase in commercial construction jobs over the last year</a><span> is certainly downstream of data center demand—</span><a href="https://www.apricitas.io/p/the-regional-impacts-of-americas" rel="">that’s in addition to the ongoing job boom in industrial construction for chip fabs and other manufacturing sectors, plus the employment gains as part of the electricity power and broader infrastructure buildout.</a><span> Yet so far, the job dynamics of the AI boom have been radically different than the past decade of tech labor markets as growth focuses more on hardware investments, manufacturing/design firms, and infrastructure builders more than traditional programmers.</span></p><p>Right now, AI developers are competing intensely and each banking that continued product improvements and greater commercialization will more than validate the historical scale of current investments. In the near term, investment is only expected to increase as more advanced models are developed and AI usage is expanded into more real-world applications (like self-driving vehicles). Policymakers also view AI as a key part of the future US economy—AI development and data center capacity are cutting-edge industries where America has built a significant lead by virtue of the dominance of Silicon Valley and large US tech conglomerates, and thus the AI boom has benefitted US investment more than perhaps any other country.</p><p><span>Yet that makes it more likely geopolitical competition will intensify around hardware capacity—the CHIPS Act that is driving so much of current US electronics industrial policy was a pre-ChatGPT creation, and some industry heads already complain that it’s showing its age in terms of priorities and scale. The significant increase in demand for high-end semiconductors has boosted US reliance on Taiwanese imports, which the CHIPS Act was supposed to help ameliorate, and there are any number of components where the US remains dependent on China to meet data-center-scale supply. Plus, the US will likely continue restricting Chinese access to the highest-end chips in hopes of holding back their AI development, while China continues to build out its chipmaking capacity in hopes of reducing import dependence. As this AI investment boom continues, </span><a href="https://www.apricitas.io/p/america-and-chinas-chip-race" rel="">expect it to only move further into the forefront of the ongoing Chip War.</a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Syncthing Android App Discontinued (349 pts)]]></title>
            <link>https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/</link>
            <guid>41895718</guid>
            <pubDate>Sun, 20 Oct 2024 14:51:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/">https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/</a>, See on <a href="https://news.ycombinator.com/item?id=41895718">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Energy-based model explains how chronic stress transforms into disease over time (144 pts)]]></title>
            <link>https://www.sciencedirect.com/science/article/pii/S030645302200292X</link>
            <guid>41895609</guid>
            <pubDate>Sun, 20 Oct 2024 14:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedirect.com/science/article/pii/S030645302200292X">https://www.sciencedirect.com/science/article/pii/S030645302200292X</a>, See on <a href="https://news.ycombinator.com/item?id=41895609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root" data-aa-name="root"><header id="gh-cnt"></header><div id="mathjax-container" role="main"><div role="region" aria-label="Download options and search"><ul aria-label="PDF Options"><li><a target="_blank" aria-label="View PDF. Opens in a new window."><svg focusable="false" viewBox="0 0 35 32" height="20"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span><span><span>View&nbsp;<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article lang="en"><div id="publication"><p><a href="https://www.sciencedirect.com/journal/psychoneuroendocrinology" title="Go to Psychoneuroendocrinology on ScienceDirect"><span><span><img src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/17220c80f4e09945173d394db9fa2f4c6a17b614/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></p><p><a href="https://www.sciencedirect.com/journal/psychoneuroendocrinology/vol/146/suppl/C"><span><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306453022X00103-cov150h.gif" alt="Psychoneuroendocrinology"></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noreferrer noopener"><span><span>license</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></p><p><span></span>open access</p></div><div id="abstracts"><div id="ab0015"><h2>Highlights</h2><div id="abs0015"><ul><li><span>•</span><span><p>Allostasis and allostatic load cost energy</p></span></li><li><span>•</span><span><p>The organism’s energy consumption capacity is biologically limited</p></span></li><li><span>•</span><span><p>The transition from allostasis to allostatic load is defined by an energetic tradeoff where allostasis and stress-related energy costs compete with growth, maintenance, and repair</p></span></li><li><span>•</span><span><p>The energetic model of allostatic load (EMAL) makes testable predictions requiring further research</p></span></li></ul></div></div><div id="ab0010"><h2>Abstract</h2><div id="abs0010"><p>Chronic psychosocial stress increases disease risk and mortality, but the underlying mechanisms remain largely unclear. Here we outline an energy-based model for the transduction of chronic stress into disease over time. The energetic model of allostatic load (EMAL) emphasizes the energetic cost of allostasis and allostatic load, where the “load” is the additional energetic burden required to support allostasis and stress-induced energy needs. Living organisms have a limited capacity to consume energy. Overconsumption of energy by allostatic brain-body processes leads to <em>hypermetabolism</em>, defined as excess energy expenditure above the organism’s optimum. In turn, hypermetabolism accelerates physiological decline in cells, laboratory animals, and humans, and may drive biological aging. Therefore, we propose that the transition from adaptive allostasis to maladaptive allostatic states, allostatic load, and allostatic overload arises when the added energetic cost of stress competes with longevity-promoting growth, maintenance, and repair. Mechanistically, the energetic restriction of growth, maintenance and repair processes leads to the progressive wear-and-tear of molecular and organ systems. The proposed model makes testable predictions around the physiological, cellular, and sub-cellular energetic mechanisms that transduce chronic stress into disease risk and mortality. We also highlight new avenues to quantify allostatic load and its link to health across the lifespan, via the integration of systemic and cellular energy expenditure measurements together with classic allostatic load biomarkers.</p></div></div></div><ul id="issue-navigation"><li></li><li></li></ul><div id="keys0005"><h2>Keywords</h2><p><span>Allostatic load</span></p><p><span>Energy</span></p><p><span>Hypermetabolism</span></p><p><span>Coping resources</span></p><p><span>Energetic model of allostatic load (EMAL)</span></p><p><span>Allostasis and stress-induced energy expenditure (ASEE)</span></p><p><span>Brain</span></p><p><span>Mitochondria</span></p></div><section aria-label="Cited by" id="section-cited-by"><header id="citing-articles-header"><h2>Cited by (0)</h2></header></section><p><span>© 2022 The Author(s). Published by Elsevier Ltd.</span></p></article></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VersaTiles – a complete FLOSS map stack (116 pts)]]></title>
            <link>https://versatiles.org/</link>
            <guid>41895356</guid>
            <pubDate>Sun, 20 Oct 2024 13:51:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://versatiles.org/">https://versatiles.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41895356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div id="heroblock">
	<p><img src="https://versatiles.org/assets/logo/versatiles.svg"></p><div id="heroline">
		
		<p>
			<span>a</span>
			<span>complete</span>
			<span><abbr title="Free, Libre and Open Source Software">FLOSS</abbr></span>
			<span>map</span>
			<span>stack</span>
		</p>
	</div>
</div>
<p><hero>VersaTiles is a completely <a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" title="Free, Libre and Open Source Software">FLOSS</a> stack for generating, distributing, and using map tiles based on OpenStreetMap data, free of any commercial interests.</hero></p>
<h2>Try it out</h2>





<h2>If you want to know more</h2>
<p>we explain here:</p>
<ul>
<li><a href="https://versatiles.org/intro.html">how to use it</a>,</li>
<li><a href="https://versatiles.org/overview.html">how it works</a> and</li>
<li><a href="https://versatiles.org/contribute.html">how you can help.</a></li>
</ul>
<h2>powered by</h2>
<p><a href="https://www.miz-babelsberg.de/foerderung/foerderprojekte-alumni/details/versatiles-editorial-tools.html"><img src="https://versatiles.org/assets/logo/miz-logo.png" width="281"></a></p>
<p><small>MIZ-Babelsberg is funding the development of the "VersaTiles Editorial Tools", which are specifically designed for the use of maps in journalistic newsrooms.</small></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to do distributed locking (2016) (198 pts)]]></title>
            <link>https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</link>
            <guid>41894451</guid>
            <pubDate>Sun, 20 Oct 2024 10:38:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a>, See on <a href="https://news.ycombinator.com/item?id=41894451">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
                

                
                <p>Published by Martin Kleppmann on 08 Feb 2016.</p>
                

                <p>As part of the research for <a href="http://dataintensive.net/">my book</a>, I came across an algorithm called <a href="http://redis.io/topics/distlock">Redlock</a> on the
<a href="http://redis.io/">Redis</a> website. The algorithm claims to implement fault-tolerant distributed locks (or rather,
<a href="https://pdfs.semanticscholar.org/a25e/ee836dbd2a5ae680f835309a484c9f39ae4e.pdf" title="Cary G Gray and David R Cheriton. Leases: An Efficient Fault-Tolerant Mechanism for Distributed File Cache Consistency. SOSP 1989">leases</a>&nbsp;[1]) on top of Redis, and the page asks for feedback from people who are into
distributed systems. The algorithm instinctively set off some alarm bells in the back of my mind, so
I spent a bit of time thinking about it and writing up these notes.</p>

<p>Since there are already <a href="http://redis.io/topics/distlock">over 10 independent implementations of Redlock</a> and we don’t know
who is already relying on this algorithm, I thought it would be worth sharing my notes publicly.
I won’t go into other aspects of Redis, some of which have already been critiqued
<a href="https://aphyr.com/tags/Redis">elsewhere</a>.</p>

<p>Before I go into the details of Redlock, let me say that I quite like Redis, and I have successfully
used it in production in the past. I think it’s a good fit in situations where you want to share
some transient, approximate, fast-changing data between servers, and where it’s not a big deal if
you occasionally lose that data for whatever reason. For example, a good use case is maintaining
request counters per IP address (for rate limiting purposes) and sets of distinct IP addresses per
user ID (for abuse detection).</p>

<p>However, Redis has been gradually making inroads into areas of data management where there are
stronger consistency and durability expectations – which worries me, because this is not what Redis
is designed for. Arguably, distributed locking is one of those areas. Let’s examine it in some more
detail.</p>

<h2 id="what-are-you-using-that-lock-for">What are you using that lock for?</h2>

<p>The purpose of a lock is to ensure that among several nodes that might try to do the same piece of
work, only one actually does it (at least only one at a time). That work might be to write some data
to a shared storage system, to perform some computation, to call some external API, or suchlike. At
a high level, there are two reasons why you might want a lock in a distributed application:
<a href="https://research.google.com/archive/chubby.html" title="Mike Burrows. The Chubby lock service for loosely-coupled distributed systems. OSDI 2006">for efficiency or for correctness</a>&nbsp;[2]. To distinguish these cases, you can ask what
would happen if the lock failed:</p>

<ul>
  <li><strong>Efficiency:</strong> Taking a lock saves you from unnecessarily doing the same work twice (e.g. some
expensive computation). If the lock fails and two nodes end up doing the same piece of work, the
result is a minor increase in cost (you end up paying 5 cents more to AWS than you otherwise would
have) or a minor inconvenience (e.g. a user ends up getting the same email notification twice).</li>
  <li><strong>Correctness:</strong> Taking a lock prevents concurrent processes from stepping on each others’ toes
and messing up the state of your system. If the lock fails and two nodes concurrently work on the
same piece of data, the result is a corrupted file, data loss, permanent inconsistency, the wrong
dose of a drug administered to a patient, or some other serious problem.</li>
</ul>

<p>Both are valid cases for wanting a lock, but you need to be very clear about which one of the two
you are dealing with.</p>

<p>I will argue that if you are using locks merely for efficiency purposes, it is unnecessary to incur
the cost and complexity of Redlock, running 5 Redis servers and checking for a majority to acquire
your lock. You are better off just using a single Redis instance, perhaps with asynchronous
replication to a secondary instance in case the primary crashes.</p>

<p>If you use a single Redis instance, of course you will drop some locks if the power suddenly goes
out on your Redis node, or something else goes wrong. But if you’re only using the locks as an
efficiency optimization, and the crashes don’t happen too often, that’s no big deal. This “no big
deal” scenario is where Redis shines. At least if you’re relying on a single Redis instance, it is
clear to everyone who looks at the system that the locks are approximate, and only to be used for
non-critical purposes.</p>

<p>On the other hand, the Redlock algorithm, with its 5 replicas and majority voting, looks at first
glance as though it is suitable for situations in which your locking is important for <em>correctness</em>.
I will argue in the following sections that it is <em>not</em> suitable for that purpose. For the rest of
this article we will assume that your locks are important for correctness, and that it is a serious
bug if two different nodes concurrently believe that they are holding the same lock.</p>

<h2 id="protecting-a-resource-with-a-lock">Protecting a resource with a lock</h2>

<p>Let’s leave the particulars of Redlock aside for a moment, and discuss how a distributed lock is
used in general (independent of the particular locking algorithm used). It’s important to remember
that a lock in a distributed system is not like a mutex in a multi-threaded application. It’s a more
complicated beast, due to the problem that different nodes and the network can all fail
independently in various ways.</p>

<p>For example, say you have an application in which a client needs to update a file in shared storage
(e.g. HDFS or S3). A client first acquires the lock, then reads the file, makes some changes, writes
the modified file back, and finally releases the lock. The lock prevents two clients from performing
this read-modify-write cycle concurrently, which would result in lost updates. The code might look
something like this:</p>

<figure><pre><code data-lang="js"><span>// THIS CODE IS BROKEN</span>
<span>function</span> <span>writeData</span><span>(</span><span>filename</span><span>,</span> <span>data</span><span>)</span> <span>{</span>
    <span>var</span> <span>lock</span> <span>=</span> <span>lockService</span><span>.</span><span>acquireLock</span><span>(</span><span>filename</span><span>);</span>
    <span>if</span> <span>(</span><span>!</span><span>lock</span><span>)</span> <span>{</span>
        <span>throw</span> <span>'</span><span>Failed to acquire lock</span><span>'</span><span>;</span>
    <span>}</span>

    <span>try</span> <span>{</span>
        <span>var</span> <span>file</span> <span>=</span> <span>storage</span><span>.</span><span>readFile</span><span>(</span><span>filename</span><span>);</span>
        <span>var</span> <span>updated</span> <span>=</span> <span>updateContents</span><span>(</span><span>file</span><span>,</span> <span>data</span><span>);</span>
        <span>storage</span><span>.</span><span>writeFile</span><span>(</span><span>filename</span><span>,</span> <span>updated</span><span>);</span>
    <span>}</span> <span>finally</span> <span>{</span>
        <span>lock</span><span>.</span><span>release</span><span>();</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Unfortunately, even if you have a perfect lock service, the code above is broken. The following
diagram shows how you can end up with corrupted data:</p>

<p><img src="https://martin.kleppmann.com/2016/02/unsafe-lock.png" width="550" height="200" alt="Unsafe access to a resource protected by a distributed lock"></p>

<p>In this example, the client that acquired the lock is paused for an extended period of time while
holding the lock – for example because the garbage collector (GC) kicked in. The lock has a timeout
(i.e. it is a lease), which is always a good idea (otherwise a crashed client could end up holding
a lock forever and never releasing it). However, if the GC pause lasts longer than the lease expiry
period, and the client doesn’t realise that it has expired, it may go ahead and make some unsafe
change.</p>

<p>This bug is not theoretical: HBase used to <a href="http://www.slideshare.net/enissoz/hbase-and-hdfs-understanding-filesystem-usage" title="Enis Söztutar. HBase and HDFS: Understanding filesystem usage in HBase. HBaseCon 2013">have this problem</a>&nbsp;[3,4]. Normally,
GC pauses are quite short, but “stop-the-world” GC pauses have sometimes been known to last for
<a href="https://blog.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/" title="Todd Lipcon. Avoiding Full GCs in Apache HBase with MemStore-Local Allocation Buffers: Part 1. 2011">several minutes</a>&nbsp;[5] – certainly long enough for a lease to expire. Even so-called
“concurrent” garbage collectors like the HotSpot JVM’s CMS cannot fully run in parallel with the
application code – even they <a href="http://mechanical-sympathy.blogspot.co.uk/2013/07/java-garbage-collection-distilled.html" title="Martin Thompson. Java Garbage Collection Distilled. 2013">need to stop the world</a> from time to time&nbsp;[6].</p>

<p>You cannot fix this problem by inserting a check on the lock expiry just before writing back to
storage. Remember that GC can pause a running thread at <em>any point</em>, including the point that is
maximally inconvenient for you (between the last check and the write operation).</p>

<p>And if you’re feeling smug because your programming language runtime doesn’t have long GC pauses,
there are many other reasons why your process might get paused. Maybe your process tried to read an
address that is not yet loaded into memory, so it gets a page fault and is paused until the page is
loaded from disk. Maybe your disk is actually EBS, and so reading a variable unwittingly turned into
a synchronous network request over Amazon’s congested network. Maybe there are many other processes
contending for CPU, and you hit a <a href="https://twitter.com/aphyr/status/682077908953792512">black node in your scheduler tree</a>. Maybe someone
accidentally sent SIGSTOP to the process. Whatever. Your processes will get paused.</p>

<p>If you still don’t believe me about process pauses, then consider instead that the file-writing
request may get delayed in the network before reaching the storage service. Packet networks such as
Ethernet and IP may delay packets <em>arbitrarily</em>, and <a href="https://queue.acm.org/detail.cfm?id=2655736" title="P Bailis and K Kingsbury. The Network is Reliable. ACM Queue 12(7), 2014.">they do</a>&nbsp;[7]: in a famous
<a href="https://github.com/blog/1364-downtime-last-saturday" title="Mark Imbriaco. Downtime last Saturday. 2012">incident at GitHub</a>, packets were delayed in the network for approximately 90
seconds&nbsp;[8]. This means that an application process may send a write request, and it may reach
the storage server a minute later when the lease has already expired.</p>

<p>Even in well-managed networks, this kind of thing can happen. You simply cannot make any assumptions
about timing, which is why the code above is fundamentally unsafe, no matter what lock service you
use.</p>

<h2 id="making-the-lock-safe-with-fencing">Making the lock safe with fencing</h2>

<p>The fix for this problem is actually pretty simple: you need to include a <em>fencing token</em> with every
write request to the storage service. In this context, a fencing token is simply a number that
increases (e.g. incremented by the lock service) every time a client acquires the lock. This is
illustrated in the following diagram:</p>

<p><img src="https://martin.kleppmann.com/2016/02/fencing-tokens.png" width="550" height="200" alt="Using fencing tokens to make resource access safe"></p>

<p>Client 1 acquires the lease and gets a token of 33, but then it goes into a long pause and the lease
expires. Client 2 acquires the lease, gets a token of 34 (the number always increases), and then
sends its write to the storage service, including the token of 34. Later, client 1 comes back to
life and sends its write to the storage service, including its token value 33. However, the storage
server remembers that it has already processed a write with a higher token number (34), and so it
rejects the request with token 33.</p>

<p>Note this requires the storage server to take an active role in checking tokens, and rejecting any
writes on which the token has gone backwards. But this is not particularly hard, once you know the
trick. And provided that the lock service generates strictly monotonically increasing tokens, this
makes the lock safe. For example, if you are using ZooKeeper as lock service, you can use the <code>zxid</code>
or the znode version number as fencing token, and you’re in good shape&nbsp;[3].</p>

<p>However, this leads us to the first big problem with Redlock: <em>it does not have any facility for
generating fencing tokens</em>. The algorithm does not produce any number that is guaranteed to increase
every time a client acquires a lock. This means that even if the algorithm were otherwise perfect,
it would not be safe to use, because you cannot prevent the race condition between clients in the
case where one client is paused or its packets are delayed.</p>

<p>And it’s not obvious to me how one would change the Redlock algorithm to start generating fencing
tokens. The unique random value it uses does not provide the required monotonicity. Simply keeping
a counter on one Redis node would not be sufficient, because that node may fail. Keeping counters on
several nodes would mean they would go out of sync. It’s likely that you would need a consensus
algorithm just to generate the fencing tokens. (If only <a href="https://twitter.com/lindsey/status/575006945213485056">incrementing a counter</a> was
simple.)</p>

<h2 id="using-time-to-solve-consensus">Using time to solve consensus</h2>

<p>The fact that Redlock fails to generate fencing tokens should already be sufficient reason not to
use it in situations where correctness depends on the lock. But there are some further problems that
are worth discussing.</p>

<p>In the academic literature, the most practical system model for this kind of algorithm is the
<a href="http://courses.csail.mit.edu/6.852/08/papers/CT96-JACM.pdf" title="TD Chandra and S Toueg. Unreliable Failure Detectors for Reliable Distributed Systems. JACM 43(2):225–267, 1996">asynchronous model with unreliable failure detectors</a>&nbsp;[9]. In plain English,
this means that the algorithms make no assumptions about timing: processes may pause for arbitrary
lengths of time, packets may be arbitrarily delayed in the network, and clocks may be arbitrarily
wrong – and the algorithm is nevertheless expected to do the right thing. Given what we discussed
above, these are very reasonable assumptions.</p>

<p>The only purpose for which algorithms may use clocks is to generate timeouts, to avoid waiting
forever if a node is down. But timeouts do not have to be accurate: just because a request times
out, that doesn’t mean that the other node is definitely down – it could just as well be that there
is a large delay in the network, or that your local clock is wrong. When used as a failure detector,
timeouts are just a guess that something is wrong. (If they could, distributed algorithms would do
without clocks entirely, but then <a href="http://www.cs.princeton.edu/courses/archive/fall07/cos518/papers/flp.pdf" title="MJ Fischer, N Lynch, and MS Paterson. Impossibility of Distributed Consensus with One Faulty Process. JACM 32(2):374–382, 1985">consensus becomes impossible</a>&nbsp;[10]. Acquiring a lock is
like a compare-and-set operation, which <a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf" title="Maurice Herlihy. Wait-Free Synchronization. TOPLAS 13(1):124–149, 1991">requires consensus</a>&nbsp;[11].)</p>

<p>Note that Redis <a href="https://github.com/antirez/redis/blob/edd4d555df57dc84265fdfb4ef59a4678832f6da/src/server.c#L390-L404">uses <code>gettimeofday</code></a>, not a <a href="http://linux.die.net/man/2/clock_gettime">monotonic clock</a>, to
determine the <a href="https://github.com/antirez/redis/blob/f0b168e8944af41c4161249040f01ece227cfc0c/src/db.c#L933-L959">expiry of keys</a>. The man page for <code>gettimeofday</code> <a href="http://linux.die.net/man/2/gettimeofday">explicitly
says</a> that the time it returns is subject to discontinuous jumps in system time –
that is, it might suddenly jump forwards by a few minutes, or even jump back in time (e.g. if the
clock is <a href="https://www.eecis.udel.edu/~mills/ntp/html/clock.html">stepped by NTP</a> because it differs from a NTP server by too much, or if the
clock is manually adjusted by an administrator). Thus, if the system clock is doing weird things, it
could easily happen that the expiry of a key in Redis is much faster or much slower than expected.</p>

<p>For algorithms in the asynchronous model this is not a big problem: these algorithms generally
ensure that their <em>safety</em> properties always hold, <a href="http://www.net.t-labs.tu-berlin.de/~petr/ADC-07/papers/DLS88.pdf" title="C Dwork, N Lynch, and L Stockmeyer. Consensus in the Presence of Partial Synchrony. JACM 35(2):288–323, 1988">without making any timing
assumptions</a>&nbsp;[12]. Only <em>liveness</em> properties depend on timeouts or some other failure
detector. In plain English, this means that even if the timings in the system are all over the place
(processes pausing, networks delaying, clocks jumping forwards and backwards), the performance of an
algorithm might go to hell, but the algorithm will never make an incorrect decision.</p>

<p>However, Redlock is not like this. Its safety depends on a lot of timing assumptions: it assumes
that all Redis nodes hold keys for approximately the right length of time before expiring; that the
network delay is small compared to the expiry duration; and that process pauses are much shorter
than the expiry duration.</p>

<h2 id="breaking-redlock-with-bad-timings">Breaking Redlock with bad timings</h2>

<p>Let’s look at some examples to demonstrate Redlock’s reliance on timing assumptions. Say the system
has five Redis nodes (A, B, C, D and E), and two clients (1 and 2). What happens if a clock on one
of the Redis nodes jumps forward?</p>

<ol>
  <li>Client 1 acquires lock on nodes A, B, C. Due to a network issue, D and E cannot be reached.</li>
  <li>The clock on node C jumps forward, causing the lock to expire.</li>
  <li>Client 2 acquires lock on nodes C, D, E. Due to a network issue, A and B cannot be reached.</li>
  <li>Clients 1 and 2 now both believe they hold the lock.</li>
</ol>

<p>A similar issue could happen if C crashes before persisting the lock to disk, and immediately
restarts. For this reason, the Redlock documentation <a href="http://redis.io/topics/distlock#performance-crash-recovery-and-fsync">recommends delaying restarts</a> of
crashed nodes for at least the time-to-live of the longest-lived lock. But this restart delay again
relies on a reasonably accurate measurement of time, and would fail if the clock jumps.</p>

<p>Okay, so maybe you think that a clock jump is unrealistic, because you’re very confident in having
correctly configured NTP to only ever slew the clock. In that case, let’s look at an example of how
a process pause may cause the algorithm to fail:</p>

<ol>
  <li>Client 1 requests lock on nodes A, B, C, D, E.</li>
  <li>While the responses to client 1 are in flight, client 1 goes into stop-the-world GC.</li>
  <li>Locks expire on all Redis nodes.</li>
  <li>Client 2 acquires lock on nodes A, B, C, D, E.</li>
  <li>Client 1 finishes GC, and receives the responses from Redis nodes indicating that it successfully
acquired the lock (they were held in client 1’s kernel network buffers while the process was
paused).</li>
  <li>Clients 1 and 2 now both believe they hold the lock.</li>
</ol>

<p>Note that even though Redis is written in C, and thus doesn’t have GC, that doesn’t help us here:
any system in which the <em>clients</em> may experience a GC pause has this problem. You can only make this
safe by preventing client 1 from performing any operations under the lock after client 2 has
acquired the lock, for example using the fencing approach above.</p>

<p>A long network delay can produce the same effect as the process pause. It perhaps depends on your
TCP user timeout – if you make the timeout significantly shorter than the Redis TTL, perhaps the
delayed network packets would be ignored, but we’d have to look in detail at the TCP implementation
to be sure. Also, with the timeout we’re back down to accuracy of time measurement again!</p>

<h2 id="the-synchrony-assumptions-of-redlock">The synchrony assumptions of Redlock</h2>

<p>These examples show that Redlock works correctly only if you assume a <em>synchronous</em> system model –
that is, a system with the following properties:</p>

<ul>
  <li>bounded network delay (you can guarantee that packets always arrive within some guaranteed maximum
delay),</li>
  <li>bounded process pauses (in other words, hard real-time constraints, which you typically only
find in car airbag systems and suchlike), and</li>
  <li>bounded clock error (cross your fingers that you don’t get your time from a <a href="http://xenia.media.mit.edu/~nelson/research/ntp-survey99/">bad NTP
server</a>).</li>
</ul>

<p>Note that a synchronous model does not mean exactly synchronised clocks: it means you are assuming
a <a href="http://www.net.t-labs.tu-berlin.de/~petr/ADC-07/papers/DLS88.pdf" title="C Dwork, N Lynch, and L Stockmeyer. Consensus in the Presence of Partial Synchrony. JACM 35(2):288–323, 1988"><em>known, fixed upper bound</em></a> on network delay, pauses and clock drift&nbsp;[12]. Redlock
assumes that delays, pauses and drift are all small relative to the time-to-live of a lock; if the
timing issues become as large as the time-to-live, the algorithm fails.</p>

<p>In a reasonably well-behaved datacenter environment, the timing assumptions will be satisfied <em>most</em>
of the time – this is known as a <a href="http://www.net.t-labs.tu-berlin.de/~petr/ADC-07/papers/DLS88.pdf" title="C Dwork, N Lynch, and L Stockmeyer. Consensus in the Presence of Partial Synchrony. JACM 35(2):288–323, 1988">partially synchronous system</a>&nbsp;[12]. But is that good
enough? As soon as those timing assumptions are broken, Redlock may violate its safety properties,
e.g. granting a lease to one client before another has expired. If you’re depending on your lock for
correctness, “most of the time” is not enough – you need it to <em>always</em> be correct.</p>

<p>There is plenty of evidence that it is not safe to assume a synchronous system model for most
practical system environments&nbsp;[7,8]. Keep reminding yourself of the GitHub incident with the
<a href="https://github.com/blog/1364-downtime-last-saturday" title="Mark Imbriaco. Downtime last Saturday. 2012">90-second packet delay</a>. It is unlikely that Redlock would survive a <a href="https://aphyr.com/tags/jepsen">Jepsen</a> test.</p>

<p>On the other hand, a consensus algorithm designed for a partially synchronous system model (or
asynchronous model with failure detector) actually has a chance of working. Raft, Viewstamped
Replication, Zab and Paxos all fall in this category. Such an algorithm must let go of all timing
assumptions. That’s hard: it’s so tempting to assume networks, processes and clocks are more
reliable than they really are. But in the messy reality of distributed systems, you have to be very
careful with your assumptions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I think the Redlock algorithm is a poor choice because it is “neither fish nor fowl”: it is
unnecessarily heavyweight and expensive for efficiency-optimization locks, but it is not
sufficiently safe for situations in which correctness depends on the lock.</p>

<p>In particular, the algorithm makes dangerous assumptions about timing and system clocks (essentially
assuming a synchronous system with bounded network delay and bounded execution time for operations),
and it violates safety properties if those assumptions are not met. Moreover, it lacks a facility
for generating fencing tokens (which protect a system against long delays in the network or in
paused processes).</p>

<p>If you need locks only on a best-effort basis (as an efficiency optimization, not for correctness),
I would recommend sticking with the <a href="http://redis.io/commands/set">straightforward single-node locking algorithm</a> for
Redis (conditional set-if-not-exists to obtain a lock, atomic delete-if-value-matches to release
a lock), and documenting very clearly in your code that the locks are only approximate and may
occasionally fail. Don’t bother with setting up a cluster of five Redis nodes.</p>

<p>On the other hand, if you need locks for correctness, please don’t use Redlock. Instead, please use
a proper consensus system such as <a href="https://zookeeper.apache.org/">ZooKeeper</a>, probably via one of the <a href="http://curator.apache.org/curator-recipes/index.html">Curator recipes</a>
that implements a lock. (At the very least, use a <a href="http://www.postgresql.org/">database with reasonable transactional
guarantees</a>.) And please enforce use of fencing tokens on all resource accesses under the
lock.</p>

<p>As I said at the beginning, Redis is an excellent tool if you use it correctly. None of the above
diminishes the usefulness of Redis for its intended purposes. <a href="http://antirez.com/">Salvatore</a> has been very
dedicated to the project for years, and its success is well deserved. But every tool has
limitations, and it is important to know them and to plan accordingly.</p>

<p>If you want to learn more, I explain this topic in greater detail in <a href="http://dataintensive.net/">chapters 8 and 9 of my
book</a>, now available in Early Release from O’Reilly. (The diagrams above are taken from my
book.) For learning how to use ZooKeeper, I recommend <a href="http://shop.oreilly.com/product/0636920028901.do" title="FP Junqueira and B Reed. ZooKeeper: Distributed Process Coordination. O'Reilly, 2013">Junqueira and Reed’s book</a>&nbsp;[3].
For a good introduction to the theory of distributed systems, I recommend <a href="http://www.distributedprogramming.net/" title="C Cachin, R Guerraoui, and L Rodrigues. Introduction to Reliable and Secure Distributed Programming, 2nd ed. Springer, 2011">Cachin, Guerraoui and
Rodrigues’ textbook</a>&nbsp;[13].</p>

<p><em>Thank you to <a href="https://aphyr.com/">Kyle Kingsbury</a>, <a href="https://twitter.com/skamille">Camille Fournier</a>, <a href="https://twitter.com/fpjunqueira">Flavio Junqueira</a>, and
<a href="http://antirez.com/">Salvatore Sanfilippo</a> for reviewing a draft of this article. Any errors are mine, of
course.</em></p>

<p><strong>Update 9 Feb 2016:</strong> <a href="http://antirez.com/">Salvatore</a>, the original author of Redlock, has
<a href="http://antirez.com/news/101">posted a rebuttal</a> to this article (see also
<a href="https://news.ycombinator.com/item?id=11065933">HN discussion</a>). He makes some good points, but
I stand by my conclusions. I may elaborate in a follow-up post if I have time, but please form your
own opinions – and please consult the references below, many of which have received rigorous
academic peer review (unlike either of our blog posts).</p>

<h2 id="references">References</h2>

<p>[1] Cary G Gray and David R Cheriton:
“<a href="https://pdfs.semanticscholar.org/a25e/ee836dbd2a5ae680f835309a484c9f39ae4e.pdf" title="Cary G Gray and David R Cheriton. Leases: An Efficient Fault-Tolerant Mechanism for Distributed File Cache Consistency. SOSP 1989">Leases: An Efficient Fault-Tolerant Mechanism for Distributed File Cache Consistency</a>,”
at <em>12th ACM Symposium on Operating Systems Principles</em> (SOSP), December 1989.
<a href="https://dx.doi.org/10.1145/74850.74870">doi:10.1145/74850.74870</a></p>

<p>[2] Mike Burrows:
“<a href="https://research.google.com/archive/chubby.html" title="Mike Burrows. The Chubby lock service for loosely-coupled distributed systems. OSDI 2006">The Chubby lock service for loosely-coupled distributed systems</a>,”
at <em>7th USENIX Symposium on Operating System Design and Implementation</em> (OSDI), November 2006.</p>

<p>[3] Flavio P Junqueira and Benjamin Reed:
<a href="http://shop.oreilly.com/product/0636920028901.do" title="FP Junqueira and B Reed. ZooKeeper: Distributed Process Coordination. O'Reilly, 2013"><em>ZooKeeper: Distributed Process Coordination</em></a>. O’Reilly Media, November 2013.
ISBN: 978-1-4493-6130-3</p>

<p>[4] Enis Söztutar:
“<a href="http://www.slideshare.net/enissoz/hbase-and-hdfs-understanding-filesystem-usage" title="Enis Söztutar. HBase and HDFS: Understanding filesystem usage in HBase. HBaseCon 2013">HBase and HDFS: Understanding filesystem usage in HBase</a>,” at <em>HBaseCon</em>, June 2013.</p>

<p>[5] Todd Lipcon:
“<a href="https://blog.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/" title="Todd Lipcon. Avoiding Full GCs in Apache HBase with MemStore-Local Allocation Buffers: Part 1. 2011">Avoiding Full GCs in Apache HBase with MemStore-Local Allocation Buffers: Part 1</a>,”
blog.cloudera.com, 24 February 2011.</p>

<p>[6] Martin Thompson: “<a href="http://mechanical-sympathy.blogspot.co.uk/2013/07/java-garbage-collection-distilled.html" title="Martin Thompson. Java Garbage Collection Distilled. 2013">Java Garbage Collection Distilled</a>,”
mechanical-sympathy.blogspot.co.uk, 16 July 2013.</p>

<p>[7] Peter Bailis and Kyle Kingsbury: “<a href="https://queue.acm.org/detail.cfm?id=2655736" title="P Bailis and K Kingsbury. The Network is Reliable. ACM Queue 12(7), 2014.">The Network is Reliable</a>,”
<em>ACM Queue</em>, volume 12, number 7, July 2014.
<a href="https://dx.doi.org/10.1145/2639988.2639988">doi:10.1145/2639988.2639988</a></p>

<p>[8] Mark Imbriaco: “<a href="https://github.com/blog/1364-downtime-last-saturday" title="Mark Imbriaco. Downtime last Saturday. 2012">Downtime last Saturday</a>,” github.com, 26 December 2012.</p>

<p>[9] Tushar Deepak Chandra and Sam Toueg:
“<a href="http://courses.csail.mit.edu/6.852/08/papers/CT96-JACM.pdf" title="TD Chandra and S Toueg. Unreliable Failure Detectors for Reliable Distributed Systems. JACM 43(2):225–267, 1996">Unreliable Failure Detectors for Reliable Distributed Systems</a>,”
<em>Journal of the ACM</em>, volume 43, number 2, pages 225–267, March 1996.
<a href="https://dx.doi.org/10.1145/226643.226647">doi:10.1145/226643.226647</a></p>

<p>[10] Michael J Fischer, Nancy Lynch, and Michael S Paterson:
“<a href="http://www.cs.princeton.edu/courses/archive/fall07/cos518/papers/flp.pdf" title="MJ Fischer, N Lynch, and MS Paterson. Impossibility of Distributed Consensus with One Faulty Process. JACM 32(2):374–382, 1985">Impossibility of Distributed Consensus with One Faulty Process</a>,”
<em>Journal of the ACM</em>, volume 32, number 2, pages 374–382, April 1985.
<a href="https://dx.doi.org/10.1145/3149.214121">doi:10.1145/3149.214121</a></p>

<p>[11] Maurice P Herlihy: “<a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf" title="Maurice Herlihy. Wait-Free Synchronization. TOPLAS 13(1):124–149, 1991">Wait-Free Synchronization</a>,”
<em>ACM Transactions on Programming Languages and Systems</em>, volume 13, number 1, pages 124–149, January 1991.
<a href="https://dx.doi.org/10.1145/114005.102808">doi:10.1145/114005.102808</a></p>

<p>[12] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer:
“<a href="http://www.net.t-labs.tu-berlin.de/~petr/ADC-07/papers/DLS88.pdf" title="C Dwork, N Lynch, and L Stockmeyer. Consensus in the Presence of Partial Synchrony. JACM 35(2):288–323, 1988">Consensus in the Presence of Partial Synchrony</a>,”
<em>Journal of the ACM</em>, volume 35, number 2, pages 288–323, April 1988.
<a href="https://dx.doi.org/10.1145/42282.42283">doi:10.1145/42282.42283</a></p>

<p>[13] Christian Cachin, Rachid Guerraoui, and Luís Rodrigues:
<a href="http://www.distributedprogramming.net/" title="C Cachin, R Guerraoui, and L Rodrigues. Introduction to Reliable and Secure Distributed Programming, 2nd ed. Springer, 2011"><em>Introduction to Reliable and Secure Distributed Programming</em></a>,
Second Edition. Springer, February 2011. ISBN: 978-3-642-15259-7,
<a href="https://dx.doi.org/10.1007/978-3-642-15260-3">doi:10.1007/978-3-642-15260-3</a></p>



                <div>
                    <p>If you found this post useful, please
                    <a href="https://www.patreon.com/martinkl">support me on Patreon</a>
                    so that I can write more like it!</p>
                    <p>
                    To get notified when I write something new,
                    <a href="https://bsky.app/profile/martin.kleppmann.com">follow me on Bluesky</a> or
                    <a href="https://nondeterministic.computer/@martin">Mastodon</a>,
                    or enter your email address:
                    </p>

                    

                    <p>
                    I won't give your address to anyone else, won't send you any spam, and you can unsubscribe at any time.
                    </p>
                </div>

                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Euro coins as weights (2004) (151 pts)]]></title>
            <link>https://www.rubinghscience.org/surv/euroweights1.html</link>
            <guid>41894359</guid>
            <pubDate>Sun, 20 Oct 2024 10:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rubinghscience.org/surv/euroweights1.html">https://www.rubinghscience.org/surv/euroweights1.html</a>, See on <a href="https://news.ycombinator.com/item?id=41894359">Hacker News</a></p>
<div id="readability-page-1" class="page">
http://www.rubinghscience.org/surv/euroweights1.html<br>
Sep 2004
<br><hr><p><span size="5"><b>
Using Euro coins as standard weights
</b></span>
</p>


<p>
Here is a cheap way to obtain a set of standard weights, for measuring
weights up to about 100 gram, to an accuracy of about 0.5 gram :  Use
the coins of the currency of your country.  Thus one can make use of the
fact that these coins are fabricated in mass production, and because of
that have not only a constant shape and size, but also a constant and
accurately fixed weight.
</p><p>
Weights composed of these coins can be used to measure the weight of
small objects (e.g. letters).  The accuracy of the weight of the (Euro)
coins is good enough so that in measuring the weight of objects an
accuracy 0.5 gram is easily obtained in a cheap and quick way.(*)
</p><blockquote><span size="-1">
   (*) One cheap and quick way to construct things for weighing to 
   up to 0.5 gram accuracy with the Euro coins is as follows:<br> 
   &nbsp; &nbsp; &nbsp; 
   1. Use a very simple home-made scales, i.e. a balance, simply
   consisting of a straight rod suspended exactly in the middle, with
   hanging from each end a 'plate' (or 'pan') on which to place the
   object to be weighed and the standard weights.  A straight length of
   e.g. aluminium, two small identical pieces of board, and a small amount
   of supple thread suffice to construct a very serviceable scales.<br>
   &nbsp; &nbsp; &nbsp; 
   2. Create the weights by holding the combinations of Euro coins
   together with narrow paper bands glued around them.  The weight of the
   paper bands and the glue is much smaller than 0.5 g and is therefore
   negligible.  (A sheet of A4 copying paper weighs about 5 gram.)
</span></blockquote> 
<p>
In the rest of this text, I'll use the Euro coins, to illustrate the idea.
Also, I'll use the gram (abbreviated: 'g') as the unit of weight; that
is, I'll assume that the weight of the objects to be measured should be
determined in gram units.  The weight of the Euro coins is as follows:
</p><center>
<tt>
<table>
<tbody><tr>
	<td>Monetary<br>value of coin<br>[Euro]
	</td><td>Weight<br>[g]
</td></tr><tr>
	<td>0.01
	</td><td>2.30
</td></tr><tr>
	<td>0.02
	</td><td>3.06
</td></tr><tr>
	<td>0.05
	</td><td>3.92
</td></tr><tr>
	<td>0.10
	</td><td>4.10
</td></tr><tr>
	<td>0.20
	</td><td>5.74
</td></tr><tr>
	<td>0.50
	</td><td>7.80
</td></tr><tr>
	<td>1.00
	</td><td>7.50
</td></tr><tr>
	<td>2.00
	</td><td>8.50
</td></tr></tbody></table>
</tt>
<span size="-1"><b>
Table 1: Weights of the Euro coins<br>
<span size="-1">(Data obtained from: 
               http://www.euroswapper.com/euro_coins.html)</span>
</b></span>
</center>
<p>
Remarkably, the 1 Euro coin has a nice round weight of exactly 7.5 g;
but in general, the makers of the coins have obviously not used it as
a design criterion to give the coins a weight of a nice round number
of grams... &nbsp; These awkward numerical values of the weights of
the individual coins seems the biggest hurdle to easy use of coins as
standard weights (for weighing things cheaply and with a resolution of
better than 7.5 g).
</p><p>
However, it is easy (with the Euro coins at least) to combine small
numbers of coins together into combinations weighing a round number of
grams.  For example, the combination consisting of one 0.02 Euro coin
(3.06 g), two 0.05 Euro coins (3.92 g each), and one 0.10 Euro coin
(4,10 g), adds up to the round weight of exactly 15.00 g.  
</p><p>
It is possible (with the Euro coins) to compose in this way a
very satisfactory set of "standard weights", each consisting of a
combination of a small number of coins.  The following are the most
useful combinations:
</p><center>
<tt>
<table>
<tbody><tr>
	<td rowspan="2">Weight of<br>combination<br>[g]
	</td><td> 
	</td><td colspan="6">Number of coins of type
	</td><td> 
	</td><td rowspan="2">Cost of<br>combination<br>[Euro]
</td></tr><tr>
	<td>
	</td><td>0.01
	</td><td>0.02
	</td><td>0.05
	</td><td>0.10
	</td><td>0.20
	</td><td>0.50
	</td><td>
	</td><td>
</td></tr><tr>
	<td><p>9.96</p>
	</td><td>
	</td><td>3
	</td><td>1
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>
	</td><td>0.05
</td></tr><tr>
	<td><p>10.04</p>
	</td><td>
	</td><td>  &nbsp;
	</td><td>2
	</td><td>1
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>
	</td><td>0.09
</td></tr><tr>
	<td><p><b>15.00</b></p>
	</td><td>
	</td><td>  &nbsp;
	</td><td><b>1</b>
	</td><td><b>2</b>
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>
	</td><td><b>0.22</b>
</td></tr><tr>
	<td><p>15.50</p>
	</td><td>
	</td><td>2
	</td><td>1
	</td><td>2
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>
	</td><td>0.14
</td></tr><tr>
	<td><p>16.00</p>
	</td><td>
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>2
	</td><td>  &nbsp;
	</td><td>1
	</td><td>
	</td><td>0.70
</td></tr><tr>
	<td><p>16.50</p>
	</td><td>
	</td><td>2
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>1
	</td><td>  &nbsp;
	</td><td>1
	</td><td>
	</td><td>0.62
</td></tr><tr>
	<td><p>17.00</p>
	</td><td>
	</td><td>  &nbsp;
	</td><td>1
	</td><td>  &nbsp;
	</td><td>2
	</td><td>1
	</td><td>  &nbsp;
	</td><td>
	</td><td>0.42
</td></tr><tr>
	<td><p><b>17.50</b></p>
	</td><td>
	</td><td><b>2</b>
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td><b>1</b>
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td>
	</td><td><b>0.34</b>
</td></tr><tr>
	<td><p><b>17.50</b></p>
	</td><td>
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td><b>3</b>
	</td><td>  &nbsp;
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td>
	</td><td><b>0.35</b>
</td></tr><tr>
	<td><p>18.00</p>
	</td><td>
	</td><td>4
	</td><td>1
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>1
	</td><td>  &nbsp;
	</td><td>
	</td><td>0.26
</td></tr><tr>
	<td><p><b>20.00</b></p>
	</td><td>
	</td><td><b>3</b>
	</td><td><b>3</b>
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>  &nbsp;
	</td><td>
	</td><td><b>0.14</b>
</td></tr><tr>
	<td><p><b>25.00</b></p>
	</td><td>
	</td><td>  &nbsp;
	</td><td><b>3</b>
	</td><td><b>1</b>
	</td><td><b>1</b>
	</td><td>  &nbsp;
	</td><td><b>1</b>
	</td><td>
	</td><td><b>0.71</b>
</td></tr></tbody></table>
</tt>
<span size="-1"><b>
Table 2: The most useful combinations of Euro coins<br>
to obtain weights of a round number of grams.<br>
An empty cell means that the coin is not used in the combination.
</b></span>
</center>
<p>
The combinations of 9.96 g and 10.04 g included in Table 2 above are the
closest it is possible to get to a weight of 10.00 g.  
</p><p>
In Table 2, the 15 g and 20 g weights are the mainstay of the weight set.
With them, by placing them both at the left and at the right side in
the scales, one can measure to a resolution of 5 g.  The, relatively
expensive, 25 g weight is not really strictly necessary, but I've added
it for convenience.
</p><p>
By adding the 17.5 g weight to one's set of weights, the resolution is
improved to 2.5 g.  (The two possible coin combinations for the 17.5
g weight, both shown in the table, differ in cost only by 0.01 Euro.)
</p><p>
The remaining weights in Table 2 are included for those who want to 
improve their weight measuring resolution to 1.0 or 0.5 g.
</p><p>
In general, the larger the (desired) weight of the combination, the
larger is the number of ways in which the coins can be put together to
yield that given total weight.  Small weights (made up of only a few
coins) can only be composed in one or a very few ways; for large weights
(made up of larger numbers of coins) of any given desired weight,
in general a larger number of coin combinations exists that sum to
that weight.
</p><p>
For desired weights of &nbsp; <i>n</i> * 0.5 g (where <i>n</i>
= whole number) <br>
&nbsp; -- that is, weights of a whole number
of grams or a whole number of grams plus 0.5 g --<br>
it is, with the Euro coins, not possible to find combinations under a
total weight of 10.50 g.  The smallest possible combinations summing
to &nbsp; <i>n</i> * 0.5 g are:
</p><blockquote>
	10.50<br>
	11.00<br>
	11.50<br>
&nbsp; &nbsp;	15.00<br>
&nbsp; &nbsp;	15.50<br>
&nbsp; &nbsp;	16.00<br>
&nbsp; &nbsp;	16.50<br>
&nbsp; &nbsp;	17.00<br>
&nbsp; &nbsp;	17.50<br>
&nbsp; &nbsp;	18.00<br>
&nbsp; &nbsp; &nbsp; &nbsp;	20.00<br>
</blockquote>
From 20.00 g upwards, all combinations with a weight of &nbsp; <i>n</i>
* 0.5 g are possible.
<p>
To obtain weights of 30 g or larger with a weight of &nbsp; <i>n</i>
* 5 gram (<i>n</i> = whole number), that is, 30 g, 35 g, 40 g, 45 g,
50 g and so on, just put them together out of the combinations for 15
gram and for 20 gram (from Table 2).  For example,
</p><blockquote><pre> 50 g  =  (2 * 15 g) +      20 g        [ = 0.58 Euro ]
 75 g  =       15 g  + (3 * 20 g)       [ = 0.64 Euro ]
100 g  =                5 * 20 g        [ = 0.70 Euro ]
</pre></blockquote>
... and so on. 
<p>
Note (from Table 1), that the ratio of weight to monetary value of the
Euro coins drops uniformly with increasing monetary value of the coin.
That is, the smaller the coin, the more weight it gives you for the
smallest cost.  In order to keep things as cheap as possible, I have in
the above therefore preferably composed my weights from from the smaller
coins, as far as possible.  For the same reason, I've used none of the
coins of 1 Euro or more in my combinations.
</p><p>
When composing the larger &nbsp; <i>n</i> * 5 gram weights from the 15
g and 20 g combinations, note that the 20 g combination, composed in
relatively larger part from lower-value coins, is cheaper than the
15 g combination.  (The 20 g costing 0.14 Euro, and the 15 g costing
0.22 Euro.)
<!--
<div align=center>---</div>
-->
</p><hr>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bitwarden is no longer free software (190 pts)]]></title>
            <link>https://github.com/bitwarden/clients/issues/11611</link>
            <guid>41893994</guid>
            <pubDate>Sun, 20 Oct 2024 08:51:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bitwarden/clients/issues/11611">https://github.com/bitwarden/clients/issues/11611</a>, See on <a href="https://news.ycombinator.com/item?id=41893994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="">
      <div data-gid="I_kwDOAzDwU86atq_U" data-url="/bitwarden/clients/issues/11611/partials/body?issue=11611" data-channel="eyJjIjoiaXNzdWU6MjU5NTY2MzgyOCIsInQiOjE3Mjk0MzQ2MDF9--8d9c313d951f36b6eb23f09ad2280c2f047d08e528fe1835f7127776a825c69b">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/brjsp/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/brjsp"><img src="https://avatars.githubusercontent.com/u/25533179?s=80&amp;v=4" width="40" height="40" alt="@brjsp"></a>

</p>

  <div data-body-version="18f6c3df4a3359182c7ac598b6d414e875b6248912d5d6b9e2fc6f16547e525d" id="issue-2595663828">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Pull request <a data-error-text="Failed to load title" data-id="2516713871" data-permission-text="Title is private" data-url="https://github.com/bitwarden/clients/issues/10974" data-hovercard-type="pull_request" data-hovercard-url="/bitwarden/clients/pull/10974/hovercard" href="https://github.com/bitwarden/clients/pull/10974">#10974</a> introduces the <code>@bitwarden/sdk-internal</code> dependency which is needed to build the desktop client. The dependency contains a licence statement which contains the following clause:</p>
<div data-snippet-clipboard-copy-content="You may not use this SDK to develop applications for use with software other
than Bitwarden (including non-compatible implementations of Bitwarden) or to
develop another SDK."><pre><code>You may not use this SDK to develop applications for use with software other
than Bitwarden (including non-compatible implementations of Bitwarden) or to
develop another SDK.
</code></pre></div>
<p dir="auto">This violates <a href="https://www.gnu.org/philosophy/free-sw.en.html" rel="nofollow">freedom 0</a>.</p>
<p dir="auto">It is not possible to build desktop-v2024.10.0 (or, likely, current master) without removing this dependency.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-dd32c9b5-3bb9-4281-ab66-7c25324afb7d" for="reactions--reaction_button_component-330bdb" popover="manual" data-direction="n" data-type="description" data-view-component="true">Sporesirius, littleblack111, NineKain, lcheylus, Christophe999s, martabal, diogopjesus, mlec1, cbaconnier, pestanko, and 65 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-4a698f39-fbee-4355-aab8-aff447d941af" for="reactions--reaction_button_component-bd4580" popover="manual" data-direction="n" data-type="description" data-view-component="true">mikelward, rmens, NameLessGO, neiios, itayporezky, connorhsm, PKizzle, LucaTheHacker, hserranome, pbering, and 4 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div>
    


      

      <div data-gid="IC_kwDOAzDwU86QRZSh" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QRZSh/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/bitwarden-bot/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/bitwarden-bot"><img src="https://avatars.githubusercontent.com/u/65035528?s=80&amp;u=dcb290eaf0b2928ab41f8c11117b786f684ecfad&amp;v=4" width="40" height="40" alt="@bitwarden-bot"></a>

</p>


  <div data-body-version="f20cf788c93350c330f9ffbeeb5fd6a5ddb3725c9abad5c6ee823e42038ac853" id="issuecomment-2420479137">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Thank you for reporting this issue! We've added this to our internal tracking system.<br>
ID: PM-13815</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QRfgq" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QRfgq/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/brjsp/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/brjsp"><img src="https://avatars.githubusercontent.com/u/25533179?s=80&amp;v=4" width="40" height="40" alt="@brjsp"></a>

</p>


  <div data-body-version="503b673220f7ab2a78f661eead6135d6b99e22555a2755da2f506c5b0927f3ac" id="issuecomment-2420504618">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Namely trying to build with <code>bitwarden_license</code> directory removed (like we have been always doing) and sanitized node_modules results in the following:</p>
<div data-snippet-clipboard-copy-content="[Prel] assets by status 30.6 KiB [cached] 1 asset
[Prel] orphan modules 28.2 KiB [orphan] 25 modules
[Prel] ./src/preload.ts + 25 modules 28.4 KiB [not cacheable] [built] [code generated]
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk.service.ts
[Prel] 3:32-57
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk.service.ts(3,33)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk-client-factory.ts
[Prel] 1:37-62
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk-client-factory.ts(1,38)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk.service.ts
[Prel] 3:54-79
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk.service.ts(3,55)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts
[Prel] 1:21-46
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts(1,22)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts
[Prel] 2:24-81
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts(2,25)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal/bitwarden_wasm_internal_bg.wasm' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/noop-sdk-client-factory.ts
[Prel] 1:37-62
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/noop-sdk-client-factory.ts(1,38)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] 6 errors have detailed information that is not shown.
[Prel] Use 'stats.errorDetails: true' resp. '--stats-error-details' to show it.
[Prel]
[Prel] webpack 5.94.0 compiled with 6 errors in 14233 ms
[Prel] npm error Lifecycle script `build:preload` failed with error:
[Prel] npm error code 1
[Prel] npm error path /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/apps/desktop
[Prel] npm error workspace @bitwarden/desktop@2024.10.0
[Prel] npm error location /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/apps/desktop
[Prel] npm error command failed
[Prel] npm error command sh -c cross-env NODE_ENV=production webpack --config webpack.preload.js
[Prel] npm run build:preload exited with code 1"><pre><code>[Prel] assets by status 30.6 KiB [cached] 1 asset
[Prel] orphan modules 28.2 KiB [orphan] 25 modules
[Prel] ./src/preload.ts + 25 modules 28.4 KiB [not cacheable] [built] [code generated]
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk.service.ts
[Prel] 3:32-57
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk.service.ts(3,33)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk-client-factory.ts
[Prel] 1:37-62
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/abstractions/sdk/sdk-client-factory.ts(1,38)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk.service.ts
[Prel] 3:54-79
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk.service.ts(3,55)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts
[Prel] 1:21-46
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts(1,22)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts
[Prel] 2:24-81
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/default-sdk-client-factory.ts(2,25)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal/bitwarden_wasm_internal_bg.wasm' or its corresponding type declarations.
[Prel]
[Prel] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/noop-sdk-client-factory.ts
[Prel] 1:37-62
[Prel] [tsl] ERROR in /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/libs/common/src/platform/services/sdk/noop-sdk-client-factory.ts(1,38)
[Prel]       TS2307: Cannot find module '@bitwarden/sdk-internal' or its corresponding type declarations.
[Prel]
[Prel] 6 errors have detailed information that is not shown.
[Prel] Use 'stats.errorDetails: true' resp. '--stats-error-details' to show it.
[Prel]
[Prel] webpack 5.94.0 compiled with 6 errors in 14233 ms
[Prel] npm error Lifecycle script `build:preload` failed with error:
[Prel] npm error code 1
[Prel] npm error path /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/apps/desktop
[Prel] npm error workspace @bitwarden/desktop@2024.10.0
[Prel] npm error location /home/abuild/rpmbuild/BUILD/bitwarden-2024.10.0/apps/desktop
[Prel] npm error command failed
[Prel] npm error command sh -c cross-env NODE_ENV=production webpack --config webpack.preload.js
[Prel] npm run build:preload exited with code 1
</code></pre></div>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="CRE_kwDOAmn6As5eMFss">
    <p><a data-hovercard-type="user" data-hovercard-url="/users/ulm/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ulm"><img src="https://avatars.githubusercontent.com/u/206311?s=40&amp;v=4" width="20" height="20" alt="@ulm"></a>
<a data-hovercard-type="user" data-hovercard-url="/users/ulm/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ulm">ulm</a>



    mentioned this issue
    </p><a href="#ref-pullrequest-2597404269">
      <relative-time datetime="2024-10-18T13:24:24Z">Oct 18, 2024</relative-time>
    </a>
</div>

      <div data-gid="IC_kwDOAzDwU86QeJja" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QeJja/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/xndc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/xndc"><img src="https://avatars.githubusercontent.com/u/11667279?s=80&amp;v=4" width="40" height="40" alt="@xndc"></a>

</p>


  <div data-body-version="bfc2242a0e48109dae7556d92a1cf6df60c8edfb21a2d8f25cee89e7c0d9f6ea" id="issuecomment-2423822554">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Also see <a data-error-text="Failed to load title" data-id="2403231331" data-permission-text="Title is private" data-url="https://github.com/bitwarden/sdk/issues/898" data-hovercard-type="issue" data-hovercard-url="/bitwarden/sdk/issues/898/hovercard" href="https://github.com/bitwarden/sdk/issues/898">bitwarden/sdk#898</a>. It looks like this is part of a deliberate campaign by Bitwarden, Inc. to fully transition Bitwarden to proprietary software, despite consistently advertising it as open source, without informing customers about this change.</p>
<p dir="auto">For whatever the opinion of one user is worth, I've switched away from Bitwarden due to this.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-df23cbff-5040-4727-b6b8-e7d6daca4e1b" for="reactions--reaction_button_component-7507ca" popover="manual" data-direction="n" data-type="description" data-view-component="true">drjagan, impredicative, Sporesirius, NineKain, cbaconnier, mamgodev, KnudH, Malix-Labs, zjeffer, AMufInABox, and 31 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QhH_-" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QhH_-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/aphedges/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/aphedges"><img src="https://avatars.githubusercontent.com/u/14283972?s=80&amp;u=a5d1cb3a27a324084bae51cf88e9302f2c84215b&amp;v=4" width="40" height="40" alt="@aphedges"></a>

</p>


  <div data-body-version="43b7c1adbffaf598edd33a757eaec36ace20cb851e6c5a9cdf486c5389fa33d0" id="issuecomment-2424602622">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">I noticed and reported a similar problem with the NPM releases of the CLI client (<a data-error-text="Failed to load title" data-id="2476985390" data-permission-text="Title is private" data-url="https://github.com/bitwarden/clients/issues/10648" data-hovercard-type="issue" data-hovercard-url="/bitwarden/clients/issues/10648/hovercard" href="https://github.com/bitwarden/clients/issues/10648">#10648</a>) two months ago, and I have yet to receive a response. Bitwarden definitely seems to be moving away from being open-source software without making any sort of announcement about it.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e2156ec1-6e90-4549-bd8e-08d66268901f" for="reactions--reaction_button_component-eae635" popover="manual" data-direction="n" data-type="description" data-view-component="true">drjagan, Sporesirius, NineKain, Zireael07, cbaconnier, mamgodev, KnudH, andaag, tesfabpel, NameLessGO, and 10 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QhsED" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QhsED/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/rafntor/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/rafntor"><img src="https://avatars.githubusercontent.com/u/44544090?s=80&amp;v=4" width="40" height="40" alt="@rafntor"></a>

</p>


  <div data-body-version="f4e847117fd1be65939875e1fb8360225775fecaac889aecd195e1d197f595d9" id="issuecomment-2424750339">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">what alternatives do you guys recommend?</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e3ac0f13-c017-4118-bfbe-417b9ac69102" for="reactions--reaction_button_component-b1c430" popover="manual" data-direction="n" data-type="description" data-view-component="true">Malix-Labs, starvald, NameLessGO, servaasvdc, eenturk, xFELAx, rymiel, aronwk-aaron, reddec, 0verEngineer, and 2 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh6VE" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh6VE/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/iHarryPotter178/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/iHarryPotter178"><img src="https://avatars.githubusercontent.com/u/78410114?s=80&amp;u=f23bf8b3c1cb162e8dc83c3f6513ec640868965e&amp;v=4" width="40" height="40" alt="@iHarryPotter178"></a>

</p>


  <div data-body-version="b21cd5bd92f93d100ecf1f6e5dfb8957a89bd12213f392fd949801b799202a27" id="issuecomment-2424808772">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Bitwarden was good to me.. Now it's time to switch to alternatives...</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh-dP" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh-dP/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/adrian-afl/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/adrian-afl"><img src="https://avatars.githubusercontent.com/u/4716150?s=80&amp;u=87fa5e32313db29b578343f8b72457ee698e8bd2&amp;v=4" width="40" height="40" alt="@adrian-afl"></a>

</p>


  <div data-body-version="717b6d66a9a54fe5aa6c5c1ea8bbd7c97e791bded87cc6404b9eeb2a160cea81" id="issuecomment-2424825679">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Best alternative is to fork the version before this change!</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_BU" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_BU/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LalOpen/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LalOpen"><img src="https://avatars.githubusercontent.com/u/92826217?s=80&amp;v=4" width="40" height="40" alt="@LalOpen"></a>

</p>


  <div data-body-version="52db329b5dbbb35e78d0d1e4c0481c2d685b6061596f1610534d9d4ccc9d40a5" id="issuecomment-2424827988">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Ohhh noooo... That's a shame. You're right: i'll go to a fork or to any alternative!</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_Sz" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_Sz/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/impredicative/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/impredicative"><img src="https://avatars.githubusercontent.com/u/566650?s=80&amp;u=ea5dc361b05a0fc8f7b7ec3bb4ab5b996ca800c5&amp;v=4" width="40" height="40" alt="@impredicative"></a>

</p>


  <div data-body-version="d7774ef98f0085ca91fe1bb28410c83e1548967f3ecb9caefe59536d62ef7c70" id="issuecomment-2424829107">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">i'll go to a fork or to any alternative!</p>
</blockquote>
<p dir="auto">I would be careful going to "any alternative". It's your passwords you're talking about.</p>
<p dir="auto">Also, a fork of the client still leaves the open issue of relying on the server service or software.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_Zt" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_Zt/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Gallocon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Gallocon"><img src="https://avatars.githubusercontent.com/u/65094462?s=80&amp;v=4" width="40" height="40" alt="@Gallocon"></a>

</p>


  <div data-body-version="9924d1962e7b5debc574ef08d9fe91482b1b266b627417037c565fba170105c5" id="issuecomment-2424829549">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">This is... concerning to say the least. I'm a long term paid Bitwarden user, and it's making me reconsider that decision.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-191c5c59-5236-42a8-90ba-df7506d757cd" for="reactions--reaction_button_component-b9536f" popover="manual" data-direction="n" data-type="description" data-view-component="true">Pavuucek, TECHNOFAB11, moonlitpath, vHanda, itayporezky, connorhsm, eenturk, xFELAx, aronwk-aaron, JordyEGNL, and 8 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_sr" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_sr/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/cat-pat/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cat-pat"><img src="https://avatars.githubusercontent.com/u/178615483?s=80&amp;u=ea41c50e8f0945f782a45ba81cce0552ab581b85&amp;v=4" width="40" height="40" alt="@cat-pat"></a>

</p>


  <div data-body-version="4b5ff39c88f99c8174f1a21d9c736ad5f4eccdd0c736dc8c9716830cedb78398" id="issuecomment-2424830763">

        <task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/bitwarden/clients/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-91e9ca5e-d9ad-4882-b3ee-10b6e384e9b5" for="reactions--reaction_button_component-f5ab91" popover="manual" data-direction="n" data-type="description" data-view-component="true">impredicative, OdinGitDat, gazben, drobson03, xFELAx, dpurnam, JeanneD4RK, luolong, ctp-tCG, lostb1t, and 5 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_yc" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_yc/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ludouzi/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ludouzi"><img src="https://avatars.githubusercontent.com/u/45490980?s=80&amp;u=4d3c08f4735c2713e440397aa5034f259f5c2086&amp;v=4" width="40" height="40" alt="@ludouzi"></a>

</p>


  <div data-body-version="c1bd23072e8b4308740cdb073b429156693ac611759b2c6f08e7bc407a8b8874" id="issuecomment-2424831132">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">I'll be looking for an alternative after hearing this. Quietly moving away from open source raises serious concerns.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_y5" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_y5/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zarlo/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zarlo"><img src="https://avatars.githubusercontent.com/u/2957727?s=80&amp;u=7a8a0fca51693afbc5ef221f169e43c69c004f21&amp;v=4" width="40" height="40" alt="@zarlo"></a>

</p>


  <div data-body-version="8f2ee76ff0e04b1bd2f78cb2a0c8d03980294f33e9c69a480be80f3ad3e81deb" id="issuecomment-2424831161">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">7.3 The Company may at any time, terminate the License Agreement with you if:<br>
........<br>
d) the Company decides to no longer provide the SDK or certain parts of the SDK<br>
to users in the country in which you are resident or from which you use the<br>
service, or the provision of the SDK or certain SDK services to you by the<br>
Company is, in the Company’'s sole discretion, no longer commercially viable or<br>
technically practicable.</p>
</blockquote>
<p dir="auto">well so it can be striped from us at any time?</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86Qh_0v" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86Qh_0v/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/impredicative/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/impredicative"><img src="https://avatars.githubusercontent.com/u/566650?s=80&amp;u=ea5dc361b05a0fc8f7b7ec3bb4ab5b996ca800c5&amp;v=4" width="40" height="40" alt="@impredicative"></a>

</p>


  

</div>


      <div data-gid="IC_kwDOAzDwU86QiBG5" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiBG5/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/stukinnear/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stukinnear"><img src="https://avatars.githubusercontent.com/u/32877477?s=80&amp;v=4" width="40" height="40" alt="@stukinnear"></a>

</p>


  <div data-body-version="256084458503aed1932053ee4e70f5ccc93f9fe706c6176c4b8638ee7b51b123" id="issuecomment-2424836537">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">what alternatives do you guys recommend?</p>
</blockquote>
<p dir="auto">If it's for the home Vaultwarden.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiBnu" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiBnu/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/NikunjKhangwal/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/NikunjKhangwal"><img src="https://avatars.githubusercontent.com/u/99175083?s=80&amp;v=4" width="40" height="40" alt="@NikunjKhangwal"></a>

</p>


  <div data-body-version="8fb937ad87cc2f4ccd0468677af497841e964fba5d42bff35d7138c70d1e075e" id="issuecomment-2424838638">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">No no no, not Bitwarden please. A service i dearly loved and was satisfied with :(</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiEgp" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiEgp/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/JeanneD4RK/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/JeanneD4RK"><img src="https://avatars.githubusercontent.com/u/61759320?s=80&amp;u=b6c470c8e0b04c73aa7e7eb19936039de8c98d8c&amp;v=4" width="40" height="40" alt="@JeanneD4RK"></a>

</p>


  <div data-body-version="067de635164970c0fe9f47d60355f46f9d067a7aa500ef542680b3a507fcefb0" id="issuecomment-2424850473">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<blockquote>
<p dir="auto">what alternatives do you guys recommend?</p>
</blockquote>
<p dir="auto">If it's for the home Vaultwarden.</p>
</blockquote>
<p dir="auto">Why home use only ?</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiFAG" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiFAG/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Ollie1101/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Ollie1101"><img src="https://avatars.githubusercontent.com/u/46160541?s=80&amp;v=4" width="40" height="40" alt="@Ollie1101"></a>

</p>


  <div data-body-version="dc26d1b1e401afe7bfc43d0dd87573274988daf4115183db95ff80409f93a1ac" id="issuecomment-2424852486">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">enshitification is inevitable with these god forsaken companies</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiFDr" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiFDr/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/GauthierPLM/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/GauthierPLM"><img src="https://avatars.githubusercontent.com/u/2579741?s=80&amp;u=1571f383289037384a7a68dca1e5f8fc9df9d49a&amp;v=4" width="40" height="40" alt="@GauthierPLM"></a>

</p>


  <div data-body-version="c74607a4a083982e7874882f8a7af64b019ca907d5a5538d6771f2dfdff149b3" id="issuecomment-2424852715">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Note that the SDK is used (and enabled as a feature flag) not only in the release of desktop app, but also in the browser, CLI and web clients.</p>
<p dir="auto"><strong>This mean that all versions of BitWarden 2024.10.0 are using the SDK.</strong></p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiFse" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiFse/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Foosec/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Foosec"><img src="https://avatars.githubusercontent.com/u/31885466?s=80&amp;u=f74a1db15ae843f9d9727f0eca8f70a3148b2fdd&amp;v=4" width="40" height="40" alt="@Foosec"></a>

</p>


  <div data-body-version="e308542e22e315a176c7c5e234ebb8dce620f7ec2e3d291820101efb4db6b1ac" id="issuecomment-2424855326">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">How many times do we have to teach companies that try to rug pull this lesson, you want to end up like redis? This is how you end up like redis.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiFug" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiFug/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Yaikava/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Yaikava"><img src="https://avatars.githubusercontent.com/u/83710104?s=80&amp;u=ee4cc2d6145b0d221b032df00402454660ffbedb&amp;v=4" width="40" height="40" alt="@Yaikava"></a>

</p>


  

</div>


      <div data-gid="IC_kwDOAzDwU86QiF50" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiF50/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/impredicative/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/impredicative"><img src="https://avatars.githubusercontent.com/u/566650?s=80&amp;u=ea5dc361b05a0fc8f7b7ec3bb4ab5b996ca800c5&amp;v=4" width="40" height="40" alt="@impredicative"></a>

</p>


  <div data-body-version="7ef333adf24594f5371f3400c1b89555810d65ee10061efc5b0e5a3079115f7b" id="issuecomment-2424856180">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">enshitification is inevitable with these god forsaken companies</p>
</blockquote>
<p dir="auto">It's practically a given with almost any VC (venture capital) or PE (private equity) backed company with worth between 10 million and 1 trillion USD. When outside of this range, they can do what they want.</p>
<p dir="auto">People keep getting surprised every time this happens, but it's so common as to be inevitable indeed.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiGXQ" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiGXQ/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ssddanbrown/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ssddanbrown"><img src="https://avatars.githubusercontent.com/u/8343178?s=80&amp;u=0827017afd8f54d126d84a9dfea02e9f00d81934&amp;v=4" width="40" height="40" alt="@ssddanbrown"></a>

</p>


  <div data-body-version="91a9c60dc0a2835a1c0d6fcb96c991b9d0f17f67be80bfbb2131920ce66140a2" id="issuecomment-2424858064">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Bitwarden has before released projects advertised as "open source" while not under a non-open restrictive license <a href="https://github.com/ssddanbrown/Open-Source-Confusion-Cases/blob/main/cases/bitwarden-passwordless.md">details</a>, <a href="https://github.com/bitwarden/passwordless-server/issues/37" data-hovercard-type="issue" data-hovercard-url="/bitwarden/passwordless-server/issues/37/hovercard">discussion</a>. This may now indicate a pattern or direction.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiGlp" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiGlp/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ninjadev64/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ninjadev64"><img src="https://avatars.githubusercontent.com/u/63245705?s=80&amp;u=5501346037a284432bcc0ddce5fc7070f179ad86&amp;v=4" width="40" height="40" alt="@ninjadev64"></a>

</p>


  <div data-body-version="d7c882897bd4963cfa9e93d773cd4d77f539275ce8c992a9810d8e42293c9253" id="issuecomment-2424858985">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">This sucks. I am going to develop an alternative desktop app which wraps Vaultwarden's web interface using Tauri, if anyone is interested.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiHDK" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiHDK/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Paddy-NI/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Paddy-NI"><img src="https://avatars.githubusercontent.com/u/716404?s=80&amp;v=4" width="40" height="40" alt="@Paddy-NI"></a>

</p>


  <div data-body-version="8bfc0cab636031698a7b518d2d7a03d6c8a76f293779e60cd3918002aeb08b59" id="issuecomment-2424860874">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">So I guess all my customers and myself of course will be moving to an alternative.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiHQr" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiHQr/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ercoppa/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ercoppa"><img src="https://avatars.githubusercontent.com/u/6653252?s=80&amp;v=4" width="40" height="40" alt="@ercoppa"></a>

</p>


  <div data-body-version="cbcdcf137056b86de1a1db14e10e82729d3b2dc1fb4a4f26848927eabcce0d2d" id="issuecomment-2424861739">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Removed the annual subscription (never used the extra features, I had it only to support the project) and moving away very soon to a truly free software solution. Very disappointed since I have pushed a lot of people toward Bitwarden.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOAzDwU86QiH-X" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiH-X/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LalOpen/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LalOpen"><img src="https://avatars.githubusercontent.com/u/92826217?s=80&amp;v=4" width="40" height="40" alt="@LalOpen"></a>

</p>


  <div data-body-version="d0afd84e1676eab8bd8c3b4c37488b151bb27cd022d29d34546ff86650621df2" id="issuecomment-2424864663">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">Very disappointed since I have pushed a lot of people toward Bitwarden.</p>
</blockquote>
<p dir="auto">Same to me. And I quite regret it now...</p>
      </div>
</task-lists>


        
      </div>

</div>




        <div data-gid="IC_kwDOAzDwU86QiIAO" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiIAO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/russeg/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/russeg"><img src="https://avatars.githubusercontent.com/u/55029299?s=80&amp;v=4" width="40" height="40" alt="@russeg"></a>

</p>


  <div data-body-version="a72334f6203b8fdb2a026e47ed01a443a09bbe1de923761dbb2dcb992858ce62" id="issuecomment-2424864782">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Spirit of open source died long time ago. Open source is now a business model.</p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOAzDwU86QiIHJ" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiIHJ/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/kspearrin/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/kspearrin"><img src="https://avatars.githubusercontent.com/u/1190944?s=80&amp;v=4" width="40" height="40" alt="@kspearrin"></a>

</p>


  <div data-body-version="ac58934bc7532099177bc2d06a6487d3d39c4732cb298fb56bc8c2506f6b5ad3" id="issuecomment-2424865225">

        <task-lists disabled="" sortable="">
<div>
          <p dir="auto">Hi <a data-hovercard-type="user" data-hovercard-url="/users/brjsp/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/brjsp">@brjsp</a>,<br>
Thanks for sharing your concerns here.&nbsp;We have been progressing use of our SDK in more use cases for our clients. However, our goal is to make sure that the SDK is used in a way that maintains GPL compatibility.<br>
&nbsp;</p>
<ol dir="auto">
<li>the SDK and the client are two separate programs</li>
<li>code for each program is in separate repositories</li>
<li>the fact that the two programs communicate using standard protocols does not mean they are one program for purposes of GPLv3</li>
</ol>
<p dir="auto">Being able to build the app as you are trying to do here is an issue we plan to resolve and is merely a bug.</p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOAzDwU86QiII0" data-url="/bitwarden/clients/comments/IC_kwDOAzDwU86QiII0/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LalOpen/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LalOpen"><img src="https://avatars.githubusercontent.com/u/92826217?s=80&amp;v=4" width="40" height="40" alt="@LalOpen"></a>

</p>


  <div data-body-version="8ff1cf8a4d042e10f4a2bb32aa5fcc5741b58848710f487597a0dfe0bf89618d" id="issuecomment-2424865332">

        <task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">Spirit of open source died long time ago. Open source is now a business model.</p>
</blockquote>
<p dir="auto">According to me, the spirit of open source still lives in free software philosophy.</p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-team-hovercards-enabled="" id="event-14749734051" data-gid="LOE_lADOAzDwU86atq_UzwAAAANvJxSj">

      

          <p><a data-hovercard-type="organization" data-hovercard-url="/orgs/bitwarden/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/bitwarden"><img src="https://avatars.githubusercontent.com/u/15990069?s=40&amp;v=4" width="20" height="20" alt="@bitwarden"></a>
<a data-hovercard-type="organization" data-hovercard-url="/orgs/bitwarden/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/bitwarden">bitwarden</a>




        locked and limited conversation to collaborators


      </p><a href="#event-14749734051"><relative-time datetime="2024-10-20T11:30:40Z">Oct 20, 2024</relative-time></a>

    </div>



  <!-- Rendered timeline since 2024-10-20 04:30:40 -->
  
</div>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Best Darn Grid Shader (Yet) (2023) (154 pts)]]></title>
            <link>https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f9278b9d8</link>
            <guid>41893987</guid>
            <pubDate>Sun, 20 Oct 2024 08:50:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f9278b9d8">https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f9278b9d8</a>, See on <a href="https://news.ycombinator.com/item?id=41893987">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="93b2">The Competition</h2><h2 id="fce6">Con-text-ure (Texture Based Grid)</h2><figure></figure><p id="8e79">This is using Rotated Grid Super Sampling from<a rel="noopener" href="https://bgolus.medium.com/sharper-mipmapping-using-shader-based-supersampling-ed7aadb47bec"> my article on Sharper Mipmapping</a>, along with 16x Anisotropic filtering. This is basically as good as a simple texture based grid can look while still being reasonably performant.</p><p id="8f1c">And it seems simple enough to write a grid shader. Making grid lines in a shader is one of those early things you see in shader tutorials. So why have I been obsessed with this for so long? Because it’s harder than it might look to get right, and I <em>know </em>a shader based solution could look even better. Really that’s it. I just wanted to understand the problem space better.</p><p id="e3d1">Lets look a little closer at the above texture based grid to see some of the problem areas that still show up.</p><figure></figure><p id="8d35">As you can see some of the thin lines still end up aliasing, in the far mid range there’s some aliasing and Moiré patterns, and in the far distance the lines end up getting fatter and then cutting off early as the anisotropic filtering runs out of steam. They’re also only stay sharp close up if you have a large enough texture, otherwise they start to get a little blurry.</p><figure><figcaption>RGSS Texture Grid blurring on extreme closeup</figcaption></figure><h2 id="2311">MyFirstGrid.shader (Common Grid Shaders)</h2><p id="3bff">So what about one of those tutorial grid shaders? Start with a repeating UV. Draw some lines using a <code>smoothstep()</code> and <code>fwidth()</code>. And we’re done!</p><p id="fac1">Right? <em>(Don’t worry, I’ll show the code later.)</em></p><figure></figure><p id="adfb">But there’s a catch. Most example grid shaders, like this one, use screen space width lines. That can be preferred over a texture based grid in a lot of use cases, and honestly probably what most people want. But it’s not what I’m trying to achieve. As the lines of that kind of grid go into the distance, eventually the each grid cell is less than a pixel wide, and thus the lines converge into a solid color that’s the same color as the lines.</p><p id="99e8">That’s not what happens with a texture based grid. With a texture based grid, the lines themselves have perspective and get thinner the further away they are. Eventually fading out once below pixel wide.</p><figure></figure><p id="3a6c">They both converge solid color, but the texture based grid converges to a color that’s relative to the line coverage of the grid cell area.</p><figure></figure><p id="4bc3">Not to mention the obvious Moiré patterns once the grid gets smaller than a pixel across.</p><p id="2ad9">Most of the example shaders I’ve seen in the past that do try to do lines that are constant world space or UV space width don’t really handle this properly. They usually use a UV space faded edge or no line anti-aliasing at all, both of which end up aliasing horribly in the distance. Or they cheat and fade out the lines at some arbitrary distance to hide the artifacts. And the ones that <em>don’t</em> fade the lines out just end up looking similar to constant pixel width line grids in the distance. Only with worse aliasing and more pronounced Moiré patterns.</p><figure></figure><p id="bc32">None of this matches what a texture based grid looks like. Though it does at least mostly match the perspective on the individual lines themselves.</p><figure></figure><h2 id="24f7">Choo Choo! (Filtered Pulsetrain)</h2><p id="2315">But there are some existing examples that look to solve it properly. One was pointed out to me recently, but has been around for far longer than I’ve been writing shaders. This technique was published in <a href="https://books.google.com/books?id=6_4VaJiOx7EC&amp;q=Pulsetrain#v=onepage&amp;q&amp;f=false" rel="noopener ugc nofollow" target="_blank">Apodaca, Anthony A., and Larry Gritz, eds. 1999. Advanced RenderMan: Creating CGI for Motion Pictures</a>. And later in <a href="https://web.archive.org/web/20220629212902/http://weber.itn.liu.se/~stegu/TNM084-2016/RenderMan_20/basicAntialiasing.html" rel="noopener ugc nofollow" target="_blank">RenderMan’s documentation</a>. The filtered pulsetrain.</p><figure></figure><p id="6909">This technique is intended to solve the exact issue I’ve been trying to. They analytically solved the integral for a convolved pulsetrain. Which, if you’re like me and didn’t finish their college level math courses, means absolutely nothing. I dropped out of art school, so it’s mostly over my head.</p><p id="bfa9">The short version is the function returns the ratio of line to not line within an arbitrary range. And it works <em>incredibly </em>well. Compared to the texture based grid it’s nearly a perfect match in terms of how it handles fading into the distance.</p><figure></figure><p id="f30b">At least at first glance. Closer inspection shows some issues.</p><figure></figure><p id="bebc">While it matches the perceptual brightness of a texture based grid, and there’s no aliasing in the foreground, the aliasing and Moiré in the mid to far distances are significantly worse. Essentially all visible line anti-aliasing disappears. It’s better than no anti-aliasing at all, and the Moiré patterns are less apparent than the pixel and UV width line grids. But this is still not as clean as I was expecting it to be.</p><p id="a8bd">Interestingly there’s this note in the book:</p><figure></figure><blockquote><p id="3c59">… the most egregious aliasing is gone.</p></blockquote><p id="6051">The most <em>egregious</em>, but not <em>all</em>. I have to assume the original authors knew it didn’t remove all aliasing, but were happy enough with the results to not go further with it. And subsequent people using it also didn’t care, or just didn’t look close enough to notice?</p><h2 id="0ae8">Hi IQ (Box Filtered Grid)</h2><p id="636c">There’s also the example from Inigo Quilez in his article on <a href="https://iquilezles.org/articles/filterableprocedurals/" rel="noopener ugc nofollow" target="_blank">filterable procedurals</a>, the box filtered grid.</p><figure></figure><p id="ebec">The box filtered grid function <em>does </em>solve some issues with the filtered pulsetrain, mainly the fact it is highly sensitive to precision and thus starts showing noise artifacts not far away from the origin. But they otherwise behave roughly the same. That includes the same aliasing problems in the mid to far distance.</p><figure></figure><p id="d44a">Though they are <em>slightly </em>different in the aliasing and Moiré patterns each show.</p><figure></figure><p id="a19a">Now while I understand from a high level how both shaders work, I’m simply not smart enough at mathing to understand how to modify them to get what I wanted.</p><h2 id="0b25">The Contender</h2><p id="fc1e">Actually, what <em>do </em>I want from a grid shader? I want:</p><ul><li id="e063">User configurable line widths.</li><li id="54b1">Lines that have perspective thickness, not just a constant pixel width.</li><li id="1d3f">No aliasing at all, at any distance or view orientation.</li><li id="346e">A line width of 0.0 or 1.0 should show completely hidden or filled.</li><li id="fe86">Limited Moiré interference patterns.</li><li id="16a0">Blends to the same value in the distance that texture based grids do.</li><li id="9184">Usable for real time rendering in place of alternative techniques.</li></ul><p id="d150">So, I went back to the shaders I <em>do </em>know well, the pixel and UV width line grids. And then decided to start poking at those to see what I could change to make it work how I wanted. Or rather, start with a single line and build up from there.</p><p id="9419">Lets do a very quick overview of what makes for a basic grid shader with user configurable line widths.</p><p id="9617">First we need to draw a single line.</p><h2 id="3e73">Line One, Begin(ner Line Shader)</h2><p id="aa09">The way I like to draw lines is using the <code>smoothstep()</code> function.</p><pre><span id="1054">float lineUV = abs(uv.x * 2.0);<br>float line = smoothstep(lineWidth + lineAA, lineWidth - lineAA, lineUV);</span></pre><p id="bd39">The UV is used as a gradient. I then use an <code>abs()</code> on the UV so the gradient is positive on both sides of 0.0, and thus the <code>smoothstep()</code> is applied to both sides and we get a line instead of just an edge. Why do I multiply the UV by 2? This is so the <code>lineWidth</code> and <code>lineAA</code> can be specified in total width instead of half widths, or needing to divide them by 2.</p><p id="7d3d">For now lets use the world position as the UV, and some arbitrary values for lineWidth and lineAA. And that gets us this:</p><figure><figcaption>basic line</figcaption></figure><p id="1b51">The problem with this is the anti-aliasing fails in the distance, and gets blurry in the foreground. Why? Because the width of the edge gradient needs to change depending on the angle and distance from the camera. To do that we can use one of my favorite tools, screen space partial derivatives. Something I’ve written about a <a rel="noopener" href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">few</a> <a rel="noopener" href="https://bgolus.medium.com/normal-mapping-for-a-triplanar-shader-10bf39dca05a">times</a> <a rel="noopener" href="https://bgolus.medium.com/sharper-mipmapping-using-shader-based-supersampling-ed7aadb47bec">in</a> <a rel="noopener" href="https://bgolus.medium.com/progressing-in-circles-13452434fdb9">my</a> <a rel="noopener" href="https://bgolus.medium.com/rendering-a-sphere-on-a-quad-13c92025570c">previous</a> <a rel="noopener" href="https://bgolus.medium.com/distinctive-derivative-differences-cce38d36797b">articles</a>. The short explanation is you can get how much a value changes between one pixel and the one next to it, either vertically or horizontally. And by getting the partial derivatives of the starting UV, we can know how wide the <code>smoothstep()</code> needs to be in UV space to appear 1 pixel wide.</p><pre><span id="268d">float lineAA = fwidth(uv.x); //<br>float lineUV = abs(uv.x * 2.0);<br>float line = smoothstep(lineWidth + lineAA, lineWidth - lineAA, lineUV); //</span></pre><figure><figcaption>anti-aliased line</figcaption></figure><p id="07ee">And now the line’s edges are nice and sharp. Note, I’m getting the derivatives of the UV <em>before</em> doing any modifications to them. This keeps them in the “full width” scale, and also avoids some issues in the next step.</p><p id="89cd">Lets make this a repeating line instead of just a single line.</p><pre><span id="018e">float lineAA = fwidth(uv.x);<br>float lineUV = 1.0 - abs(frac(uv.x) * 2.0 - 1.0); //<br>float line = smoothstep(lineWidth + lineAA, lineWidth - lineAA, lineUV);</span></pre><figure><figcaption>anti-aliased repeating line</figcaption></figure><p id="67d0">To explain that funky bit of code I’m doing to the UV, this is transforming a sawtooth wave into a triangle wave, and then making sure the zero points align with where they were before.</p><p id="b1f5">We’re starting with a <code>lineUV</code> like this:</p><figure><figcaption>abs(uv.x * 2.0)</figcaption></figure><p id="3529">Using <code>frac(uv.x)</code> instead gets you this:</p><figure><figcaption>frac(uv.x)</figcaption></figure><p id="81f3">Then the <code>abs(frac(uv.x) * 2.0 - 1.0)</code> gets you this:</p><figure><figcaption>abs(frac(uv.x) * 2.0–1.0)</figcaption></figure><p id="3185">But that has the “0.0" position starting at 1.0 instead of 0.0, so when we draw the lines they’ll be offset by half a period. So we add that <code>1.0 -</code> at the start to get this:</p><figure><figcaption>1.0-abs(frac(uv.x) * 2.0–1.0)</figcaption></figure><p id="55aa">And now when we draw the lines the “first” line’s position matches that single line we had before.</p><p id="8d78">Now, lets make it into a full grid. To do that we just need to do these steps to both axis of the UV, and combine the results.</p><pre><span id="1041">float2 lineAA = fwidth(uv);<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(lineWidth + lineAA, lineWidth - lineAA, gridUV);<br>float grid = lerp(grid2.x, 1.0, grid2.y); //</span></pre><p id="04cc">And that gets us a basic UV width line grid shader!</p><p id="5c3b">That <code>lerp(grid2.x, 1.0, grid2.y)</code> should probably get a little explaining. How to combine the two axis of repeating lines for a grid shader has something I was long confused about. I’d use <code>max(x, y)</code>, or <code>saturate(x + y)</code>, or a few other ways to combine them and they never quite felt right to me. It took me quite a while before I thought about it in terms of “how would I overlap two transparent things normally?” I’d use an alpha blend. In this case, that <code>lerp()</code> is equivalent to a premulitplied alpha blend, which you could also write like this:</p><pre><span id="0a53">float grid = grid2.x * (1.0 - grid2.y) + grid2.y;</span></pre><p id="b732">Alternatively, if you write the shader such that you have black lines on a white background, multiplying the axis together <em>also </em>produces the equivalent of a premultiplied blend. Note the + and - in the <code>smoothstep()</code> are swapped in the below example compared to the first one.</p><pre><span id="752a">float2 lineAA = fwidth(uv);<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(lineWidth - lineAA, lineWidth + lineAA, gridUV); //<br>float grid = 1.0 - grid2.x * grid2.y; //</span></pre><p id="fb0c">However I’ll be continuing to use the original code sample as they end up exactly the same in the end.</p><p id="5747">In retrospect using a premultiplied blend felt incredibly obvious, but it took over a decade for it to click for some reason. This is after I’ve written countless shaders that have done exactly this for other use cases. I even wrote an <a rel="noopener" href="https://bgolus.medium.com/the-team-color-problem-b70ec69d109f">entire article</a> on this exact topic.</p><p id="aadd">Anyhoo, with that bit of code, we get this:</p><figure><figcaption>anti-aliased grid</figcaption></figure><p id="1181">Looks pretty good, apart from the Moiré patterns. But we were expecting that. Now lets reduce the line widths down a bit to something closer to what one might actually use.</p><figure><figcaption>“anti-aliased” grid</figcaption></figure><p id="a79c">Uh oh. It looks good when the lines are close to the camera. But the lines start to alias pretty quickly. We saw these issues earlier in this article when I showed the constant UV width line grid before, but this looks <em>slightly</em> darker and more aliased than that original example. Why?</p><figure><figcaption>latest vs previous examples</figcaption></figure><p id="5092">Well, because there’s one minor difference between the code used between the two. I use a 1.5 pixel wide AA when using <code>smoothstep()</code>. The reason for this is is because <code>smoothstep()</code> sharpens the edge gradient being used for anti-aliasing such that a 1.5 pixel wide smoothstep has a roughly similar slope to a 1 pixel wide linear gradient.</p><figure><figcaption>linear slope vs 1.5 unit wide smoothstep</figcaption></figure><p id="1c60">A 1 pixel wide smoothstep can then be <em>too</em> sharp. The reason for using a smoothstep at all is because when using a 1.5 pixel wide smoothstep adds just a small bit of extra anti-aliasing without affecting the perceived sharpness of the line vs a 1 pixel wide linear gradient.</p><figure></figure><p id="0869">To be fair, this is an <em>increadibly </em>small difference. But HLSL’s<code>smoothstep()</code> is still nice because it additionally acts as an inverse lerp (aka remap) and clamping the value between 0.0 and 1.0. So it helps with simplifying the code. It also doesn’t entirely remove the perceived aliasing still, but we’ll come back to that.</p><p id="af72">In the end we have this shader code for our constant UV width grid:</p><pre><span id="2bbf">float2 uvDeriv = fwidth(uv); //<br>float2 lineAA = uvDeriv * 1.5; //<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(lineWidth + lineAA, lineWidth - lineAA, gridUV);<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><p id="3df8">What about a constant <em>pixel</em> width line grid? Well, that’s a trivial change. Multiply the line width by the derivatives! (Just remember,<code>lineWidth</code> is now the number of pixels wide the line is and not a value between 0.0 and 1.0.)</p><pre><span id="b6b3">float2 uvDeriv = fwidth(uv);<br>float2 drawWidth = uvDeriv * lineWidth; //<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV); //<br>float grid = lerp(grid2.x, 1.0, grid2.y)</span></pre><figure></figure><p id="dba0">Now we’re back to where we were earlier in the article. And have two shaders that fulfil at least two of my requirements. But we haven’t solved any of the problems we didn’t already know how to solve and one only has the perspective lines and the other solves most of the aliasing.</p><p id="d572">So lets focus on a single line for the moment instead of a whole grid. How can we make a single line have both the perspective thickness and no aliasing?</p><h2 id="e8a6">Phoning It In (Phone-wire AA)</h2><p id="5aa2">One of my favorite tricks for anti-aliasing lines comes from Emil Persson. Specifically his Phone-wire AA example.</p><p id="0929">The basic idea behind this technique is don’t let something get thinner than one pixel. Instead clamp the size of the thing so it stays at least one pixel wide and then fade it out. This ends up looking much better than just letting a line get thinner than one pixel as if you do that it will always end up aliasing. The two bits of magic are how you keep things one pixel wide, and more importantly how <em>much</em> you fade them out by.</p><p id="c634">In Emil Persson’s example, he uses knowledge about how wide the wire geometry is, the distance from the camera each vertex is, and camera’s projection matrix to keep the wires one pixel thick. But for this shader, we can use those partial derivatives again! We just need to limit how thin line gets in screen space. Basically, we combine the two shaders we already have, and take the max of the UV line width and UV derivatives.</p><pre><span id="3985">float uvDeriv = fwidth(uv.x);<br>float drawWidth = max(lineWidth, uvDeriv); //<br>float lineAA = uvDeriv * 1.5;<br>float lineUV = abs(uv.x * 2.0);<br>float line = smoothstep(drawWidth + lineAA, drawWidth - lineAA, lineUV);</span></pre><figure><figcaption>Pixel Width Limited Line</figcaption></figure><p id="01e5">That’s the first trick. But the second one is the big one. We fade out the line based on how thick we <em>wanted</em> them divided by how thick we’re <em>drawing</em> them.</p><pre><span id="b915">float uvDeriv = fwidth(uv.x);<br>float drawWidth = max(lineWidth, uvDeriv);<br>float lineAA = uvDeriv * 1.5;<br>float lineUV = abs(uv.x * 2.0);<br>float line = smoothstep(drawWidth + lineAA, drawWidth - lineAA, lineUV);<br>line *= saturate(lineWidth / drawWidth); //</span></pre><figure><figcaption>Phone-wire AA Line</figcaption></figure><p id="0e64">Looking good! You can actually see the perspective of that line even when it’s thin. And there’s no aliasing in the distance!</p><figure><figcaption>Phone-wire AA Line</figcaption></figure><p id="e121">Of note, this <em>also</em> solves the issue of having the line not fully disappear when the intended line width is zero! It’ll gracefully fade the line out the thinner and thinner it gets, just like it does as it recedes into the distance, eventually fading out entirely when it gets to zero.</p><p id="a61e">With that working, lets go back to a full grid again.</p><pre><span id="243e">float2 uvDeriv = fwidth(uv);<br>float2 drawWidth = max(lineWidth, uvDeriv); //<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);<br>grid2 *= saturate(lineWidth / drawWidth); //<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><p id="0de2">Much better! … sort of. That doesn’t look quite right. It’s fading to black at the horizon! As a reminder, the texture based grid fades to a grey, <em>not </em>black.</p><figure></figure><p id="c072">The problem is in a grid a single line can only get so wide before it’s wider than an entire grid cell width. When it’s a single line by itself, this isn’t an issue. But when it’s drawn as a grid, in the areas it’s going black a single pixel is wider than multiple overlapping grid widths. But we’re still only drawing a single set of lines in each pixel, not multiple grid cells worth.</p><p id="1a60">Where I got stuck for a long time in writing these shaders is what to do next. And I focused far too long on trying to figure out how to properly calculate the value to fade the line by, but nothing really seemed to fix it properly. I’m sure this is solvable, but remember how I said I was an art school drop out? Yeah, I’m not the one who’s going to figure that out. I’m going down this path because I’m not mathy enough to do it the “right” way.</p><p id="36a1">The closest I got going down that path was trying to clamp the value I was dividing the line width by to a max of 1.0. My theory being if the line can’t be wider than one pixel, don’t divide by more than 1. And while this is <em>better</em>, it’s still not correct.</p><pre><span id="b4a9">grid2 *= saturate(lineWidth / max(1.0, drawWidth));</span></pre><figure></figure><p id="a15c">It’s very subtle, but this results in there being a bit of a dark “gutter” at the transition between the individually distinguishable lines and the mostly solid color at the horizon.</p><figure></figure><p id="b9a2">As shown before, the filtered pulsetrain and box filtered grid <em>do </em>solve this problem. Not by fading lines exactly, but by always calculating the total coverage of all possible lines within the current pixel’s coverage. But as I’ve shown, neither properly handle <em>anti-aliasing</em> of those lines! And again, art school drop out here. I don’t have the knowledge to do it the way they did.</p><p id="9941">So now what?</p><h2 id="31a7">Right At The Wrong Place</h2><p id="9fdf">After a few years of getting about this far and not really getting any further, I recently sat down and tried to think through it more. Why didn’t that code work? It <em>feels</em> like it should, so what was I missing?</p><p id="857d">Well, it turns out I was doing the right thing. I just in the wrong place in the code. If I limited the <em>actual</em> <code>drawWidth</code>, it works!</p><pre><span id="65f6">float2 uvDeriv = fwidth(uv);<br>float2 drawWidth = clamp(lineWidth, uvDeriv, 0.5); //<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);<br>grid2 *= saturate(lineWidth / drawWidth);<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><p id="b067">Yes, the Moiré is a bit more pronounced, but the overall brightness is finally correct!</p><p id="b90e">A curious thing is I’m clamping the draw width to 0.5, <em>not</em> 1.0. If I use 1.0 it’s too dark on the horizon again.</p><pre><span id="8f7f">float2 drawWidth = clamp(lineWidth, uvDeriv, 1.0);</span></pre><figure></figure><p id="8c8c">If your thought is “well, maybe you just needed to use 0.5 in the previous attempt?” Nope, that’s too bright!</p><pre><span id="dd2c">grid2 *= saturate(lineWidth / max(0.5, drawWidth));</span></pre><figure></figure><p id="e387">Why is 0.5 the correct value to clamp the draw width? Well, it has to do with the way the line anti-aliasing works.</p><p id="2e5e">If we look at some width limited lines without any fading code. If the we manually override the <code>uvDeriv</code> used, we can see how the lines expand and smooth out as they would getting further from the camera.</p><figure></figure><p id="d4a6">When limited to a width of 0.5, like above, it means there’s an equal amount of area that’s above and below 0.5 (the red line). Meaning the average value across the whole vertical is 0.5 beyond a <code>uvDeriv</code> of 0.5.</p><p id="d7c1">This average of 0.5 means when we fade the line out, and also dividing by 0.5, that’s dividing by the same (average) intensity we know those pixels will be.</p><p id="3ac3">If limited to a width of 1.0, we get this instead.</p><figure></figure><p id="3039">Now anywhere past a <code>uvDeriv</code> of 1.0 is <em>above</em> an average of 0.5, with how much above depending on how large the <code>uvDeriv</code> is. But it’s also <em>not </em>an average of 1.0! This is important because the math fading it out assumes it is, resulting in it getting too dark, which is what we saw in the failed example 2.</p><p id="a855">If we <em>don’t </em>limit the line width, and only limit the value we divide by, the “0.5” point disappears entirely as it’s being cut off by the edge of the grid cell, meaning the average brightness is even <em>more</em> above 0.5, but also still not 1.0! And that means if we clamp only the value we divide by in the fade calculation to 0.5 it stays too bright, which is what we saw in the failed example 3.</p><p id="44e3">This is probably the hardest aspect of this whole thing to explain, so I apologize if it’s still confusing.</p><h2 id="1d80">It’s A Moiré (Interference Pattern Suppression)</h2><p id="490f">However we’re still left with those more pronounced Moiré patterns. This is because we still don’t handle when the grid cells are smaller than a single pixel. It correctly averages to the appropriate value, but that’s not really the only issue. And this is where I decided to cheat a little. Remember how one of my main goals is to limit Moiré patterns as much as possible? Well, this is one place where I want to diverge heavily from how a texture based grid, or even ground truth, would look. Those will always have some Moiré artifacts because that’s really what happens when viewing a fine grid.</p><p id="38f4">So instead of figuring out how to do all the math to calculate it the correctly, why not fade to a solid color? Yes, I know it was one of the things I lambasted about a lot of other implementations, but I’m not going to fade just based on some arbitrary distance. I’m going to fade out based on when I know those Moiré patterns are going to appear. And how do you do that? Easy! Using the same UV derivatives we’re already using for anti-aliasing!</p><pre><span id="8634">float2 uvDeriv = fwidth(uv);<br>float2 drawWidth = clamp(lineWidth, uvDeriv, 0.5);<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = 1.0 - abs(frac(uv) * 2.0 - 1.0);<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);<br>grid2 *= saturate(lineWidth / drawWidth);<br>grid2 = lerp(grid2, lineWidth, saturate(uvDeriv * 2.0 - 1.0)); //<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><p id="8a89">The idea here is once the derivatives are greater than 1.0, the grid cells are smaller than a pixel, which is when the Moiré patterns start to appear more noticeably. So this starts to fade to a solid color when the derivatives are 0.5, which is when the anti-aliased lines start to merge. And finishes fading when the derivatives are 1.0.</p><p id="6501">And that’s it! All six of the items on my list for a “perfect” grid shader are satisfied! So we’re done, right?</p><h2 id="ee31">Flipping Out (Line Inversion)</h2><p id="752f">Well, sort of. What happens when you try to make the grid lines wider than 0.5? Nothing, because we clamped the line width to 0.5. This is obviously for a very niche use case, but technically I’ve only succeeded in half of the requirement of “0.0 or 1.0 should show completely hidden or filled”. A line width of 0.0 will hide that axis entirely, but a 1.0 will cap out at a width of 0.5. But if we let lines get wider than that, things go wonky with the above math.</p><p id="637e">The final trick is we never actually draw lines more than half a grid width wide. Instead if the line width is over 0.5, we flip a few things around and effectively draw black lines on white offset by half a grid width. This means most of the math doesn’t have to change.</p><pre><span id="ebba">float2 uvDeriv = fwidth(uv);<br>bool2 invertLine = lineWidth &gt; 0.5; //<br>float2 targetWidth = invertLine ? 1.0 - lineWidth : lineWidth; //<br>float2 drawWidth = clamp(targetWidth, uvDeriv, 0.5); //<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = abs(frac(uv) * 2.0 - 1.0);<br>gridUV = invertLine ? gridUV : 1.0 - gridUV; //<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);<br>grid2 *= saturate(targetWidth / drawWidth);<br>grid2 = lerp(grid2, targetWidth, saturate(uvDeriv * 2.0 - 1.0));<br>grid2 = invertLine ? 1.0 - grid2 : grid2; //<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><h2 id="bba3">One More Thing (Partial Derivative Length)</h2><p id="b538">There’s one last very small tweak to this shader that I make use of. That is that I don’t use <code>fwidth()</code>. The <code>fwidth()</code> function is an approximation for getting the length of the derivatives. That function looks something like this:</p><pre><span id="7d9e">float fwidth(float a)<br>{<br>  return abs(ddx(a)) + abs(ddy(a));<br>}</span></pre><p id="8d52">That’s <em>not</em> how you calculate the length of something. It’s accurate enough when things align to the screen axis, but on diagonals they’re always going to be too wide. The <em>correct</em> way to calculate the length of the derivatives is like this:</p><pre><span id="0683">float ddLength(float a)<br>{<br>  return length(float2(ddx(a), ddy(a)));<br>}</span></pre><p id="d806">Or is it? Inigo Quilez’s article on <a href="https://iquilezles.org/articles/checkerfiltering/" rel="noopener ugc nofollow" target="_blank">checkerboard filtering</a> contends the correct way to do it is to get the absolute max of the derivatives.</p><pre><span id="bfff">float ddMax(float a)<br>{<br>  return max(abs(ddx(a), abs(ddy(a)));<br>}</span></pre><p id="2a7f">Well, lets compare them and see which one looks better. This is going to require zooming in real close because the differences are minimal.</p><figure><figcaption>comparison of the derivative length calculations</figcaption></figure><p id="902f">And here I would say the <code>length()</code> option is the correct one. It strikes the right balance of sharpness without aliasing compared to the other two. It should be noted that <code>fwidth()</code> was never meant to be correct, just a fast approximation. And it <em>is</em> faster, but for modern GPUs the difference is negligible. And the <code>max()</code> method isn’t “wrong” either, just wrong for this use case. The way Inigo Quilez’s filtered procedurals work is different than this shader, so it’s likely correct for <em>that</em> use case. Though his Shader Toy examples all use a slightly different calculation with an arbitrary fudge factor added, so maybe it’s not correct for that use case either?</p><p id="51f7">Ultimately, it’s mostly subjective as to which looks best, and the <code>max()</code> method is just as cheap as <code>fwidth()</code> while being a potentially slightly better approximation. And it’s always good to check your assumptions on things like this by actually trying them out and doing direct comparisons.</p><p id="afe8">But, with that last tweak, the code looks like this:</p><pre><span id="1de1"><br>float4 uvDDXY = float4(ddx(uv), ddy(uv)); //<br>float2 uvDeriv = float2(length(uvDDXY.xz), length(uvDDXY.yw)); //<br>bool2 invertLine = lineWidth &gt; 0.5;<br>float2 targetWidth = invertLine ? 1.0 - lineWidth : lineWidth;<br>float2 drawWidth = clamp(targetWidth, uvDeriv, 0.5);<br>float2 lineAA = uvDeriv * 1.5;<br>float2 gridUV = abs(frac(uv) * 2.0 - 1.0);<br>gridUV = invertLine ? gridUV : 1.0 - gridUV;<br>float2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);<br>grid2 *= saturate(targetWidth / drawWidth);<br>grid2 = lerp(grid2, targetWidth, saturate(uvDeriv * 2.0 - 1.0));<br>grid2 = invertLine ? 1.0 - grid2 : grid2;<br>float grid = lerp(grid2.x, 1.0, grid2.y);</span></pre><figure></figure><p id="c190">And lets compare this to to the other best looking options, the texture based grid and box filtered grid.</p><figure></figure><figure></figure><figure></figure><h2 id="5ef5">Conclusion</h2><p id="0289">I hope you’ll agree that we finally have the smoothest, most alias free, least Moiré patterned, most <em>pristine</em> gird shader you could possibly have. And one that in my eyes visually beats both texture based grids, and the previously best in class options.</p></div><div><p id="1cfa">At least until Mr. Quilez writes a shader that beats this one.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HN Update – Hourly News Broadcast of Top HN Stories (241 pts)]]></title>
            <link>https://hnup.date/</link>
            <guid>41893524</guid>
            <pubDate>Sun, 20 Oct 2024 07:10:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hnup.date/">https://hnup.date/</a>, See on <a href="https://news.ycombinator.com/item?id=41893524">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
      
      <h2>Hourly News Broadcast</h2>
      
      <p>
        <label> Speed: <span id="rate">1.0</span>x </label>
        <label>
          
        </label>
      </p>
    </div>
    <p>AI generated, not affiliated with Hacker News or Y Combinator.</p>

    
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scratches in 2001: A Space Osyssey (2018) (103 pts)]]></title>
            <link>https://aphelis.net/scratches-kubrick-2001-space-odyssey/</link>
            <guid>41893377</guid>
            <pubDate>Sun, 20 Oct 2024 06:33:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aphelis.net/scratches-kubrick-2001-space-odyssey/">https://aphelis.net/scratches-kubrick-2001-space-odyssey/</a>, See on <a href="https://news.ycombinator.com/item?id=41893377">Hacker News</a></p>
Couldn't get https://aphelis.net/scratches-kubrick-2001-space-odyssey/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The IPv6 Transition (131 pts)]]></title>
            <link>https://www.potaroo.net/ispcol/2024-10/ipv6-transition.html</link>
            <guid>41893200</guid>
            <pubDate>Sun, 20 Oct 2024 05:54:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.potaroo.net/ispcol/2024-10/ipv6-transition.html">https://www.potaroo.net/ispcol/2024-10/ipv6-transition.html</a>, See on <a href="https://news.ycombinator.com/item?id=41893200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">
<table>
<tbody><tr>
<td colspan="2">

<p><span face="Arial,Helvetica,Geneva,Swiss,SunSans-Regular">
<i>A column on things Internet</i></span></p>
</td>
</tr>
<tr>
<td></td>
<td>
<div><p>
Other Formats:
</p><!-- InstanceBeginEditable name="pdffile" -->
<p><a href="https://www.potaroo.net/ispcol/2024-10/ipv6-transition.pdf"><img src="https://www.potaroo.net/images/pdf.png" width="18" height="18" alt="PDF"></a></p><!-- InstanceEndEditable -->
&nbsp;
<!-- InstanceBeginEditable name="txtfile" -->
<p><a href="https://www.potaroo.net/ispcol/2024-10/ipv6-transition.txt"><img src="https://www.potaroo.net/images/txt.png" width="18" height="18" alt="TXT"></a></p><!-- InstanceEndEditable -->
&nbsp;

</div>
</td>
</tr>
<tr>
<td colspan="2">
<hr>
<br>
</td>
</tr>
</tbody></table>
<p><span color="#CC6633" size="+2" face="Verdana,Times,Times New Roman">
<b>
<!-- InstanceBeginEditable name="title" -->The IPv6 Transition<!-- InstanceEndEditable -->
</b>
</span>
<br>
<span color="#666666" face="Verdana,Times,Times New Roman">
<!-- InstanceBeginEditable name="month-year" -->October 2024<!-- InstanceEndEditable -->
</span>
</p>

<!-- InstanceBeginEditable name="bodytext" -->
<p>I wrote an article in May 2022, asking “Are we there yet?” about the transition to IPv6. At the time I concluded the article on an optimistic note, observing that we may not be ending the transition just yet, but we are closing in. I thought at the time that we won’t reach the end of this transition to IPv6 with a bang, but with a whimper. A couple of years later, I’d like to revise these conclusions with some different thoughts about where we are heading and why.</p>
<p>The state of the transition to IPv6 within the public Internet continues to confound us. <a href="https://www.rfc-editor.org/rfc/rfc2460.txt">RFC 2460</a>, the first complete effort at a specification of the IPv6 protocol was published in December 1998, more than twenty-five years ago. The entire point of IPv6 was to specify a successor protocol to IPv4 due to the prospect of running out of IPv4 addresses. Yet we ran out of IPv4 addresses more than a decade ago while the Internet is largely sustained through the use of IPv4.  This transition to IPv6 has been going on for 25 years now, and if there was any urgency to be instilled in the transition effort by the prospect and then the reality of IPv4 address exhaustion, then we’ve been living with exhaustion a very long time now, and we’re inured to it. It's probably time to ask the question again: How much longer is this transition to IPv6 going to take?</p>
<p>At APNIC Labs we’ve been measuring the uptake of IPv6 for more than a decade now. We use a measurement approach that looks at the network from the perspective of the Internet’s user base. What we measure is the proportion of users who can reach a published service when the only means to do so is by using IPv6. The date is gathered using a measurement script embedded in an online ad, and the ad placements are configured to sample a diverse collection of end users on an ongoing basis.</p>
<p>The IPv6 adoption report, showing our measurements of IPv6 adoption across the Internet’s user base from 2014 to the present is shown in Figure 1.</p>
<p>On the one hand, Figure 1 is one of those classic “up and to the right” Internet curves which show continual growth in the adoption of IPv6. The problem is in the values in the Y-axis scale. The issue here that in 2024 we are only at a level where slightly more than one third of the Internet’s user base can access an IPv6-only service. Everyone else is still in an IPv4-only Internet.</p>
<p>This seems to be a completely anomalous situation. It’s been over a decade since the supply of “new” IPv4 addresses has been exhausted, and the Internet has not only been running on empty, but also being tasked to span an ever-increasing collection of connected devices without collapsing. In late 2024 its variously estimated that some 20 billion devices use the Internet, yet the Internet’s IPv4 routing table only encompasses some 3.03 billion unique IPv4 addresses. The original “end-to-end” architecture of the Internet assumed that every device was uniquely addressed with its own IP address, yet the Internet is now sharing each individual IPv4 address across an average of 7 devices, and apparently it all seems to be working! If “end-to-end” was the sustaining principle of the Internet architecture then as far as the users of IPv4-based access and services are concerned, then it’s all over!</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig1.png" width="90%"><br>Figure 1 – IPv6 Adoption - 2014 to Now, APNIC Labs Data</p>
<p>IPv6 was meant to address these issues, and the 128-bit wide address fields in the protocol has sufficient address space to allow every connected device to use its own unique address. The design of IPv6 was intentionally very conservative. To a first level of approximation IPv6 is simply “IPv4 with bigger addresses”. There are also some changes to fragmentation controls, changes to the address acquisition protocols (ARP vs Neighbour Discovery), and changes to the IP Options fields, but the upper-level transport protocols are unchanged. IPv6 was intended to be a largely invisible change to a single level in the protocol stack, and definitely not intended to be a massive shift to an entirely novel networking paradigm.</p>
<p>In the sense of representing a very modest incremental change to IPv4, the IPv6 design achieved its objective, but in so doing it necessarily provided little in the way of any marginal improvement in protocol use and performance. IPv6 was no faster, no more versatile, no more secure than IPv4. The major benefit of IPv6 was to mitigate the future risk of IPv4 address exhaustion. In terms of conventional market operations, many markets, including that of the Internet, apply a hefty discount factor to future risk. The result is that the level of motivation to undertake this transition is highly variable given that the expenditure to deploy this second protocol does not realise tangible benefits in terms of lower cost, greater revenue or greater market share. In a networking context where market-based coordination of individual actions is essential, this level of diversity of views of the value of running a dual stack network leads to reluctance on the part of individual actors and sluggish progress of the common outcome of the transition. As a result, there is no common sense of urgency. </p>
<p>To illustrate this, we can look at the time series shown in Figure 1 and ask the question: “If the growth trend of IPv6 adoption continues at its current rate, how long will it take for every device to be IPv6 capable?” This is the same as looking at a linear trend line placed over the data series used in Figure 1, looking for the date when this trend line reaches 100%. Using a least-squares best fit for this data set from January 2020 to the present day, and using a linear trend line, we can come up with Figure 2. </p>
<p>This exercise predicts that we’ll see completion of this transition in late 2045, or some 20 years into the future. It must be noted that there is no deep modelling of the actions of various service providers, consumers, and network entities behind this prediction. The only assumption that drives this prediction is that the forces that shaped the immediate recent past are unaltered when looking into the future. In other words, this exercise simply assumes that “tomorrow is going to be a lot like today.”</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig2.png" width="90%"><br>Figure 2 – IPv6 Adoption - Projection, APNIC Labs Data</p>
<p>The projected date in Figure 2 is less of a concern than the observation that this model predicts a continuation of this transition for a further two decades. If the entire concept of IPv6 was to restore a coherent address plan across the collection of Internet-connected devices, then having this model of coherent unique device addressing be placed in abeyance for a total of some 30 years, from around 2015 through to 2045, leads to question the role and value of such a unique device addressing framework in the first place! If we can operate a fully functional Internet without such a coherent end device address architecture for three decades, then why would we feel the need to restore address coherence at some point in the future? What’s the point of IPv6 if it’s not address coherence? </p>
<p>Something has gone very wrong with this IPv6 transition, and that’s what I’d like to examine in this article.</p>
<h3>A Little Bit of History</h3>
<p>By 1990 it was clear that IP had a problem. It was still a tiny Internet at the time, but the growth patterns were exponential, doubling in size every 12 months. We were stressing out the pool of Class B IPv4 addresses and in the absence of any corrective measures this address pool would be fully depleted in 1994 (Figure 3).
</p><p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig3.png" width="90%"><br>Figure 3 – IPv4 Depletion Predictions, Frank Solensky, 18th IETF Proceedings, August 1990 </p>
<p>We were also placing pressure on the routing system at the time. The deployed routers in 1992 only had enough memory to support a further 12 to 18 months of routing growth. The combination of these routing and addressing pressures was collectively addressed in the IETF at the time under the umbrella of the ROAD effort (<a href="https://www.rfc-editor.org/rfc/rfc1380.txt">RFC 1380</a>).</p>
<p>There was a collection of short-, medium- and longer-term responses that were adopted in the IETF to address the problem.  In the short term, the IETF dispensed with the class-based IPv4 address plan and instead adopted a variably-sized address prefix model. Routing protocols, including BGP, were quickly modified to support these classless address prefixes. Variably-sized address prefixes added additional burdens to the address allocation process, and in the medium term the Internet community adopted the organisational measure of the Regional Internet Registry structure to allow each region to resource the increasingly detailed operation of address allocation and registry functions for their region. These measures increased the specificity of address allocations and provided the allocation process with a more exact alignment to determine adequate resource allocations that permitted a more diligent application of relatively conservative address allocation practices. These measures realized a significant increase in address utilization efficiency. The concept of “address sharing” using Network Address Translation (NATs) also gained some traction in the ISP word. Not only did this dramatically simplify the address administration processes in ISPs, NATs also played a major role in reducing the pressures on overall address consumption.</p>
<p>The adoption of these measures across the early 1990’s pushed a two-year imminent crisis into a more manageable decade-long scenario of depletion. However, they were not considered to be a stable long-term response. It was thought at the time that an effective long-term response really needed to extend the 32-bt address field used in IPv4. At the time the transition from mainframe to laptop was well underway in the computing work and the prospect of further reductions in size and expansion of deployment in smaller embedded devices was clear at the time. An address space of 4 billion was just not large enough for what was likely to occur in the coming years in the computing world.</p>
<p>But in looking at a new network protocol with a vastly increased address space, there was no way that any such change would be backward compatible with the installed base of IPv4 systems. As a result, there were a few divergent schools of thought as to what to do. One approach was to jump streams and switch over to use the Connectionless Transport profile of the OSI protocol suite and adopt OSI NSAP addresses along the way. Another was to change as little as possible in IP except the size of the address fields. And there were a number of ideas being thrown about in the area of proposing significant changes to the IP model.</p>
<p>By 1994 the IETF had managed to settle on the minimal change approach, which was IPv6. The address field was expanded to 128 bits, a Flow ID field was introduced, fragmentation behaviour was altered and pushed into an optional header and ARP was replaced with multicast.</p>
<p>The bottom line was that IPv6 did not offer any new functionality that was not already present in IPv4. It did not introduce any significant changes to the operation of IP. It was just IP, with larger addresses.</p>
<h3>Transition</h3>
<p>While the design of IPv6 consumed a lot of attention at the time, the concept of transition of the network from IPv4 to IPv6 did not. </p>
<p>Given the runaway adoption of IPv4, there was a naive expectation that IPv6 would similarly just take off, and there was no need to give the transition much thought. In the first phase, we would expect to see applications, hosts and networks adding support for IPv6 in addition to IPv4, transforming the internet into a dual stack environment. In the second phase we could then phase out support for IPv4.</p>
<p>There were a number of problems with this plan. Perhaps the most serious of these was a resource allocation problem. The Internet was growing extremely quickly, and most of our effort was devoted to keeping pace with demand. More users, more capacity, larger servers, more content and services, more responsive services, more security, better defence. All of these shared a common theme: scale. We could either concentrate our resources on meeting the incessant demands of scaling, or we could work on IPv6 deployment. The short and medium-term measures that we had already taken had addressed the immediacy of the problems of address depletion, so in terms of priority, scaling was a for more important priority for the industry than IPv6 transition Through the decade from 1995 to 2005 the case for IPv6 quietly slumbered in terms of mainstream industry attention. IPv4 addresses were still available, and the use of classless addressing (CIDR) and far more conservative address allocation practices had pushed the prospect of IPv4 address depletion out by more than a couple of decades. There were many more pressing operational and policy issues for the Internet that absorbed the industry’s collection attention on the day.</p>
<p>However, this was merely a brief period of respite. The scaling problem accelerated by a whole new order of magnitude in the mid 2000’s with the introduction of the iPhone and its brethren. All of a sudden this was not just a scale problem of the order of tens or even hundreds of millions of households and enterprises, but it transformed to a scale problem of billions of individuals and their personal devices and added mobility into the mix. As a taste of a near term future, the production scale of these “smart” devices quickly ramped up into annual volumes of hundreds of millions of units. The entire reason why IPv6 was a necessity was coming into fruition. But at this stage we were just not ready to deploy IPv6 in response. Instead, we rapidly increased our consumption of the remaining pools of IPv4 addresses and we supported the first wave of large-scale mobile services with IPv4.  Dual stack was not even an option in the mobile world at the time. The rather bizarre economics of financing 3G infrastructure meant that dual stack infrastructure in a 3G platform was impractical, so IPv4 was used to support the first wave of mobile services. This quickly turned to IPv4 and NATs as the uptake of mobile services gathered momentum.</p>
<p>At the same time the decentralised nature of the Internet was hampering IPv6 transition efforts. What point was there in developing application support for IPv6 services if no host had integrated IPv6 into its network stack? What point was there in adding IPv6 to a host networking stack if no ISP was providing IPv6 support? And what point was there in an ISP in deploying IPv6 if no hosts and no applications would make use of it? In terms of IPv6 at this time, nothing happened.</p>
<p>The first efforts to try and break this impasse of mutual dependence was the operating system folk, and fully functional IPv6 stacks were added to the various flavours of Linux, Windows and MAC OS, as well as in the mobile host stacks of iOS and Android.</p>
<p>But even this was not enough to allow a transition to achieve critical momentum. It could be argued that this situation made the IPv6 situation worse and set back the transition by some years. The problem was that with IPv6-enabled hosts there was some desire to use IPv6. However, these hosts were isolated “islands” of IPv6 sitting in an ocean of IPv4. The concentration of the transition effort then fixated on various tunnelling methods to tunnel IPv6 packets through the IPv4 networks (Figure 4). While this can be performed in a manual manner when you have control over both tunnel endpoints, this was not that useful an approach. What we wanted was an automated tunnelling mechanism that took care of all these details.</p> 
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig4.png" width="70%"><br>Figure 4 – Phase 1 of the IPv6 Transition</p>
<p>The first such approach that gathered some momentum was 6to4. The first problem with 6to4 was that is required public IPv4 addresses, so it could not provide services to IPv6 hosts that were behind a NAT. The more critical problem was that firewalls had no idea how to handle these 6to4 packets, and the default action when in doubt is to deny access. So 6to4 connections encountered an average of a 20% - 30% failure rate in the public Internet, which made it all but unusable as a mainstream service. The NAT traversal issue was also a problem, so a second auto-tunnel mechanism was devised that performed NAT sensing and traversal.  This mechanism, Teredo, was even worse in terms of failure rates, and some 40% of Teredo connection attempts were observed to fail.</p>
<p>Not only were these Phase 1 IPv6 transition tools extremely poor performers, as they were so unreliable, but even when they worked the connection was both fragile and slower than IPv4. The result was perhaps predictable, even if unfair. It was not just the transition mechanisms that were viewed with disfavour, but IPv6 itself also attracted some opprobrium.</p>
<p>Up until around 2011 IPv6 was largely ignored as a result in the mainstream of the public Internet. A small number of service providers tried to deploy IPv6, but in each case they found themselves with a unique set of challenges that they and their vendors had to solve, and without a rich set of content and services on IPv6, then the value of the entire exercise was highly dubious! So, nothing much happened.</p>
<h3>Movement at last!</h3>
<p>It wasn’t until the central IPv4 address pool managed by the IANA was depleted at the start of 2011, and the first RIR, APNIC, ran down on its general allocation pool in April of that year, that the ISP industry started to pay some more focussed attention to this IPv6 transition.</p>
<p>At around the same time the mobile industry commenced their transition into 4G services. The essential difference between 3G and 4G was the removal of the PPP tunnel through the radio access network from the gateway to the device and its replacement by an IP environment. This allowed a 4G mobile operator to support a dual stack environment without an additional cost component, and this was a major enabler for IPv6. Mapping IPv4 into IPv6 (or the reverse) is fragile and inefficient for service providers as compared to native dual stack. In the six-year period, from 2012 to the start of 2018 the level of IPv6 deployment rose from 0.5% to 17.4%. At this stage IPv6 was no longer predominately tunnelled, as many networks supported IPv6 in native node (Figure 5).</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig5.png" width="70%"><br>Figure 5 – Phase 2 of the IPv6 Transition</p>
<p>The problem here was that we were late with this phase of the transition. The intention of this transition was to complete the work and equip every network and host with IPv6 before we ran out of IPv4 addresses (Figure 6).</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig6.png" width="70%"><br>Figure 6 – The IPv6 Transition Plan</p>
<p>Where we had got to by 2012 was a far more challenging position. The pools of available IPv4 address space were rapidly depleting and the regional address policy communities were introducing highly conservative address allocation practices to eke out the remaining address pools. At the same time the amount of IPv6 uptake was minimal. The transition plan for IPv6 was largely broken (Figure 7).</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig7.png" width="70%"><br>Figure 7 – The IPv6 Transition Plan in 2012</p>
<h3>NATs and Address Scarcity Pressures</h3>
<p>At this point there was no choice for the Internet, and to sustain growth in the IPv4 network while we were waiting for IPv6 to gather momentum we turned to NATs. NATs were a challenging subject for the IETF. The entire concept of coherent end-to-end communications was to eschew active middleware in the network, such as NATs. NATs created a point of disruption in this model, creating a critical dependency upon network elements. They removed elements of network flexibility from the network and at the same time reduced the set of transport options to TCP and UDP.</p>
<p>The IETF resisted any efforts to standardise the behaviour of NATs, fearing perhaps that standard specifications of NAT behaviour would bestow a legitimacy on the use of NATs, an outcome that that a number of IETF participants were very keen to avoid. This aversion did not reduce the level of impetus behind NAT deployment. We had run out of IPv4 addresses and IPv6 was still a distant prospect, so NATs were the most convenient solution. What this action did achieve was to create a large variance of NAT behaviours in various implementations, particularly with respect to UDP behaviours. This has exacted a cost in software complexity where an application needs to dynamically discover the type of NAT (or NATs) in the network path if it wants to perform anything more complex than a simple two-party TCP connection.</p>
<p>Despite these issues NATs were a low friction response to IPv4 address depletion where individual deployment could be undertaken without incurring external dependencies. On the other hand, deployment of IPv6 was dependant on other networks and servers also deploying IPv6. NATs made highly efficient use of address space for clients, as not only could a NAT use the 16-bit source port field, but by time-sharing the NAT binding, NATs achieved an even greater level of address efficiency. A major reason why we’ve been able to sustain an Internet with 10’s of billions of connected devices is through the widespread use of NATs. </p>
<p>Server architectures were also changing. The introduction of TLS (Transport Layer Security) into the web server world included a point in TLS session establishment where the client informs the server platform the name of the service that it intended to connect to. Not only did this allow TLS to validate the authenticity of the service point, but this also allowed a server platform to host an extremely large collection of services from a single platform (and a single platform IP address) and perform individual service selection via this TLS Server Name Indication (SNI). The result is that server platforms perform service selection by name-based distinguishers (DNS names) in the session handshake, allowing a single server platform to serve large numbers of individual servers. The implications of the widespread use of NATs and the use of server sharing in service platforms has taken the pressure off the entire IPv4 address environment. </p>
<p>One of the best ways to illustrate the changing picture of address scarcity pressure in IPv4 is to look at the market price of address transfers over the past decade. Scarcity pressure is reflected in the market price. A time series of the price of traded IPv4 addresses is shown in Figure 8.</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig8.png" width="90%"><br>Figure 8 – Market Prices of IPv4 Address Transfers (Data from Hilco Streambank)</p>
<p>The period of the Covid outbreak coincided with a rapid price escalation over 2021, but the price has since declined to between $30 to $40 per address, and this price, admittedly over a $16 range from $26 to $42 per address, has been stable across 2024. This price data indicates that IPv4 addresses are still in demand in 2024, but the level of demand appears to have equilibrated against available levels of supply, implying that there is no scarcity premium in evidence in the address market in 2024. This data points to the combination of the efficacy of NATs in extending the efficiency of IPv4 addresses by making use of the 16 bits of port address space plus the additional benefits of using shared address pools. </p>
<p>However, it’s not just IPv4 that has alleviated the scarcity pressure for IPv4 addresses. Figure 1 indicates that over the past decade the level of IPv6 adoption has risen to encompass some 40% of the user base of the Internet. Most applications, including browsers, support <a href="https://www.rfc-editor.org/rfc/rfc6555">Happy Eyeballs</a>, which is a shorthand notation for preferring to use IPv6 over IPv4 if both protocols are available for use in support of a service transaction. As network providers roll out IPv6 support, the pressure on their IPv4 address pools for NAT use is relieved due to the applications’ preference to use IPv6 where available.</p>
<h3>How much longer?</h3>
<p>Now that we are somewhere in the middle of this transition, then the question is: How much longer is this transition is going to take?</p>
<p>This seems like a simple question, but it does need a little more elucidation. What is the “end point” when we can declare the transition to be over? When will this transition be “complete”? Is it the time when there is no more IPv4-based traffic on the internet? Or is it the time when there is no requirement for IPv4 in public services on the Internet? Or do we mean the point when IPv6-only services are viable? Or perhaps we should look at the market for IPv4 addresses and define the endpoint of this transition at the time when the price of IPv4 addresses completely collapses? Perhaps we can take a more pragmatic position here and rather than looking for completion as the point when the Internet is completely bereft of all use of IPv4 addresses and their use, we could define “completion” as the point when use of IPv4 is no longer necessary. This would imply that when a service provider can operate a viable Internet service using only IPv6 and having no supported IPv4 access mechanisms at all, then we would’ve completed this transition.</p>
<p>What does this imply? Certainly, the ISP needs to provide IPv6. But as well all the connected edge networks and the hosts in these networks need to support IPv6. After all, the ISP has no IPv4 services at this point of completion of the transition. It also implies that all the services used by the clients of this ISP must be accessible over IPv6. Yes, this includes all the popular cloud services and cloud platforms, all the content streamers and all the content distribution platforms. It also includes specialised platforms such as Slack, Xero, Atlassian and similar. The data published at Internet Society’s Pulse page reports that only some 47% of the top 1000 web sites are reachable over IPv6, and clearly a lot of service platforms have work to do, and this will take more time.</p>
<p>When we look at the IPv6 adoption data for the United States there is another somewhat curious anomaly (Figure 9).</p> 
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig9.png" width="90%"><br>Figure 9 – IPv6 Adoption in the US - 2014 to Now, APNIC Labs Data</p>
<p>The data shows that the level of IPv6 use in the US has remained constant since mid-2019. Why is there no further momentum to continue with the transition to IPv6 in this part of the Internet? I would offer the explanation that the root cause is a fundamental change in the architecture of the Internet.</p>
<h3>Changes to the Internet Architecture</h3>
<p>The major change to the Internet’s architecture is a shift away from a strict address-based architecture. Clients no longer need the use of a persistent unique public IP address in order to communicate with servers and services. And servers no longer need to use a persistent unique public IP address to provide clients with access to the service or content. Address scarcity takes on an entirely different dimension  when unique public addresses are not required to number every client and every distinct service.</p>
<p>Some of the clues that show the implications of this architectural shift are evident when you look at the changes in the internal economy of the Internet. The original model of IP was a network protocol that allowed attached devices to communicate with each other. The network providers supplied the critical resource to allow clients to consume content and access services. At the time the costs of the network service dominated the entire cost of the operation of the Internet, and in the network domain distance was the dominant cost factor. Network providers who provided distance services (so-called “transit providers”) were the dominant providers. Little wonder that we spent a lot of our time working through the issues of interconnection of network service providers, customer/provider relationships and various forms of peering and exchanges. The Internet Service Providers were in effect brokers in the rationing of the scarce resource of distance capacity. This was a classic network economy (Figure 10).
</p><p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig10.png" width="30%"><br>Figure 10 – The Classic Network Economy</p>
<p>For many years the demand for communications services outstripped available inventory, and price was used as a distribution function to moderate demand against available capacity. However, all of this changed due to the effects of Moore’s Law consistently changing the cost of computing and communications.</p>
<p>The most obvious change has been in the count of transistors in a single integrated circuit. Figure 11 shows the transistor count over time since 1970.</p> 
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig11.png" width="90%"><br>Figure 11 – Transistor count over time – from https://assets.ourworldindata.org/uploads/2020/11/Transistor-Count-over-time.png</p>
<p>The latest production chips in 2024 are the Apple M3, a 3nm chip with up to 92 billion transistors. With perhaps the possible exception of powering AI infrastructure, these days processing capability is an abundant and cheap resource.</p>
<p>This continual refinement of integrated circuit production techniques has an impact on the size and unit cost of storage (Figure 12). While the speed of memory has been relatively constant for more than a decade, the unit cost of storage has been dropping exponentially for many decades. Storage is also an abundant resource.
</p><p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig12.png" width="90%"><br>Figure 12 – Computer Memory and Storage unit costs over time – from http://aiimpacts.org/wp-content/uploads/2015/07/storage_memory_prices_large-_hblok.net_.png</p>
<p>These changes in the capabilities of processing have also had a profound impact on communications costs and capacities. The constraining factor in fibre communications systems is the capabilities of the digital signal processors and the modulators. As silicon capabilities improve, it’s possible to improve the signal processing capabilities of transmitters and receivers, which allows for a greater capacity per wavelength on a fibre circuit (Figure 13).</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig13.png" width="90%"><br>Figure 13 – Fibre Capacity over time - from https://www.ncbi.nlm.nih.gov/</p>
<p>This change from scarcity to abundance in processing, storage and transmission capacity has had a profound impact on the service model of the Internet. The model has changed from an on-demand pull to a just in case model of pre-provisioning. These days we load replicas of content and services close to the edge of the network where the users are located and attempt to deliver as much of the content and service as possible from these edge points of presence to the users in the adjacent access networks. These changes in the underlying costs of processing and storage have provided the impetus for the expansion of various forms of content distribution networks (CDNs) which now serve almost the entirety of Internet content and services. In so doing, we’ve been able to eliminate the factor of distance from the network and most network transactions occur over short spans.</p>
<p>The overall result of these changes is the elimination of distance in pushing content and services to clients. We are able to exploit the potential capacity in 5G mobile networks without the inefficiencies of operating the transport protocol over a high delay connection. Today’s access networks operate with greater aggregate capacity, and the close proximity of service delivery platform and client allow transport protocols to make use of this capacity, as transport sessions that operate over a low latency connection are also far more efficient. Service interactions across shorter distances using higher capacity circuitry results in a much faster Internet!</p>
<p>As well as “bigger” and “faster” this environment of abundant communications, processing and storage capacity is operating in an industry when there are significant economies of scale. And much of this environment is funded by capitalising a collective asset that is infeasible to capitalise individually, namely the advertisement market. The of these changes is that a former luxury service accessible to just a few has been transformed into an affordable mass-market commodity service available to all.</p>
<p>However, its more than just bigger, faster and cheaper. This shift into abundance of basic inputs for the digital environment has shifted the economics of the Internet as well. Then role of the network as the arbiter of the scarce resource of communication capability has dissipated. In response, the economic focus of the Internet economy has shifted up the protocol stack to the level of applications and services (Figure 14).</p>
<p><img src="https://www.potaroo.net/ispcol/2024-10/ipv6-fig14.png" width="70%"><br>Figure 14 – The Transformation of the Network Economy</p>
<p>Now let’s return to the situation of the transition to IPv6. It is left to networks and network operators to make the investments to switch to a dual stack platform initially (and then ultimately to remove support for IPv4). But this change is really not visible, or even crucial, to the content or service world. If IPv4 and NATs perform the carriage function adequately, then there is no motivation for the content and service operators to pay a network a premium to have a dual stack platform.  </p>
<p>It's domain names that operate as service identifiers, and its domain names that underpin the users’ tests of authenticity of the online service, and it’s the DNS that increasingly is used to steer users to the “besty” service delivery point for content or service. From this perspective addresses, IPv4 or IPv6, are not the critical resource for a service and its users. The “currency” of this form of CDN network is names.</p>
<p>So where are we in 2024? Today’s public Internet is largely a service delivery network using CDNs to push content and service as close to the user as possible. The multiplexing of multiple services onto underlying service platforms is an application-level function tied largely to TLS and service selection using SNI field of the TLSD handshake. We use the DNS to perform “closest match” service platform selection. It’s the objective of a CDN to directly attach to the access networks where its users are located, and the result is a BGP routing table inside the CDN with an average AS Path Length that is intended to converge to 1! From this respect the DNS has supplanted the role of routing! We may not route “names” in today’s Internet, but it is certainly operating in a way that is largely isomorphic to such a named data network.</p>
<p>There are a few additional implications of this architectural change for the Internet. TLS, like it or not (and there is much to criticise about the robustness of TLS) is the sole underpinning of authenticity in the Internet. DNSSEC has not gathered much momentum to date. DNSSEC is too complex, too fragile and just too slow to use for the majority of services and their users. Some value its benefits highly enough that they are prepared to live with its shortcomings, but that’s not the case for most name holders and most users, and no amount of passionate exhortations about DNSSEC will change this! It supports the view that its not the mapping of a name to an IP address that’s critical. What is critical is that the named service is able to demonstrate that it operated by the owner of the name. Secondly, RPKI, the framework for securing information being passed in the BGP routing protocol, is really not all that useful in a service network where there is no routing!</p>
<p>The implication of these observations is that the transition to IPv6 is progressing very slowly not because this industry is chronically stupid or short-sighted. There is something else going on here. IPv6 alone is not critical to a large set of end user service delivery environments. We’ve been able to take a 1980’s address-based architecture and scale it more than a billion-fold by altering the core reliance on distinguisher tokens from addresses to names. There was no real lasting benefit in trying to leap across to just another 1980’s address-based architecture (with only a few annoyingly stupid differences, apart from longer addresses!).</p>
<p>Where is this heading in the longer term? We are pushing everything out of the network and over to applications. Transmission infrastructure is becoming an abundant commodity. Network sharing technology (multiplexing) is decreasingly relevant. We have so much network and computing resources that we no longer have to bring consumers to service delivery points. Instead, we are bringing services towards consumers and using the content frameworks to replicate servers and services With so much computing and storage the application is becoming the service, rather than just a window to a remotely operated service.</p>
<p>If that’s the case, then will networks matter any more? The last couple of decades have seen us stripping out network-centric functionality and replacing this will an undistinguished commodity packet transport medium. Its fast and cheap, but it’s up to applications to overlay this common basic service with its own requirements. As we push these additional functions out to the edge and ultimately off the network altogether, we are left with simple dumb pipes! </p>
<p>At this point it’s useful to ask: What “defines” the Internet? Is the classic response, namely: “A common shared transmission fabric, a common suite of protocols and a common protocol address pool.” still relevant these days? Or is today’s network more like: “A disparate collection of services that share common referential mechanisms using a common name space?”</p>
<p>When we think about what’s important to the Internet these days is the choice of endpoint protocol addressing really important? Is universal unique end-point addressing a 1980’s concept whose time has come and gone? If network transactions are localised, then what is the residual role of unique global end point addressing for clients or services? And if we cannot find a role for unique end point addressing, then why should we bother? Who decides when to drop this concept? Is this a market function, so that a network that uses local addressing can operate from an even lower cost base gains a competitive market edge? Or are carriage services so cheap already that the relative benefit in discarding the last vestiges of unique global addresses so small that it’s just not worth bothering about? </p>
<p>And while we are pondering such questions, what is the role of referential frameworks in networks? Without a common referential space then how do we usefully communicate? What do we mean by “common” when we think about referential frameworks? How can we join the ‘fuzzy’ human language spaces with the tightly constrained deterministic computer-based symbol spaces?</p>
<p>Certainly, there is much to think about here!</p>
<p>And where does this leave the transition to IPv6? I suspect that the dual stack world we’re in is a world we will be stuck in for quite some time. There seems to be no appetite to resolve this situation by completing the transition any time soon, and absolutely no desire to back out and revert to a IPv4-only network. This is where we are, caught in a partial state of transition to IPv6 that is taking on an unfortunate air of permanence!</p>
<pre>































</pre>
<!-- InstanceEndEditable -->
<p><img src="https://www.potaroo.net/images/border.png" width="600" height="10"></p>
<h3>Disclaimer</h3>
<!-- InstanceBeginEditable name="disclaimer" -->
<p>The above views do not necessarily represent the views of the Asia Pacific Network Information Centre.</p>
<!-- InstanceEndEditable -->
<p><img src="https://www.potaroo.net/images/border.png" width="600" height="10"></p>
<h3>About the Author</h3>
<p>
&nbsp;
GEOFF HUSTON AM B.Sc., M.Sc., is the Chief Scientist at APNIC, the Regional Internet Registry serving the Asia Pacific region.
</p>
<p><a href="https://www.potaroo.net/">www.potaroo.net</a><br>
<!-- InstanceEndEditable -->
</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>