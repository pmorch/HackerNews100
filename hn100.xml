<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 22 Jan 2025 04:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ross Ulbricht was just granted a full pardon (569 pts)]]></title>
            <link>https://twitter.com/Free_Ross/status/1881851923005165704</link>
            <guid>42786962</guid>
            <pubDate>Wed, 22 Jan 2025 00:10:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Free_Ross/status/1881851923005165704">https://twitter.com/Free_Ross/status/1881851923005165704</a>, See on <a href="https://news.ycombinator.com/item?id=42786962">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Hunyuan3D 2.0 ‚Äì High-Resolution 3D Assets Generation (133 pts)]]></title>
            <link>https://github.com/Tencent/Hunyuan3D-2</link>
            <guid>42786040</guid>
            <pubDate>Tue, 21 Jan 2025 22:42:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Tencent/Hunyuan3D-2">https://github.com/Tencent/Hunyuan3D-2</a>, See on <a href="https://news.ycombinator.com/item?id=42786040">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://github.com/Tencent/Hunyuan3D-2/blob/main/README_zh_cn.md">‰∏≠ÊñáÈòÖËØª</a></p>
<p dir="auto"> 
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/images/teaser.jpg"><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/teaser.jpg"></a>
</p>
<p><a href="https://3d.hunyuan.tencent.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/febf402ad9aa71393c9530c20f10eb5ff99f8cc9762cec7d49a8cb675dd0433c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f6666696369616c253230536974652d626c61636b2e7376673f6c6f676f3d686f6d6570616765" height="22px" data-canonical-src="https://img.shields.io/badge/Official%20Site-black.svg?logo=homepage"></a>
  <a href="https://huggingface.co/spaces/tencent/Hunyuan3D-2" rel="nofollow"><img src="https://camo.githubusercontent.com/b01df6333acfa3279bfe495dce3acab0be0c1027bb6dfe321a2b2d4eaf9dc6c2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323044656d6f2d3237366362342e737667" height="22px" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Demo-276cb4.svg"></a>
  <a href="https://huggingface.co/tencent/Hunyuan3D-2" rel="nofollow"><img src="https://camo.githubusercontent.com/dbbc817c0d92c742d5b07f0d54d890f96e5cea25b2124c12b9acd58ecc7b0cb7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541342539372532304d6f64656c732d6439363930322e737667" height="22px" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Models-d96902.svg"></a>
  <a href="https://3d-models.hunyuan.tencent.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/30e5ac4827a0cef8589c5402c9020003d93136b3fffd99d6d91b57bf5cdbea15/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506167652d6262386132652e7376673f6c6f676f3d676974687562" height="22px" data-canonical-src="https://img.shields.io/badge/Page-bb8a2e.svg?logo=github"></a>
  <a href="https://discord.gg/GuaWYwzKbX" rel="nofollow"><img src="https://camo.githubusercontent.com/d25736b4edde958cb4922599c6ba056a053637b482d31c24f41393eefdc73a4b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d77686974652e7376673f6c6f676f3d646973636f7264" height="22px" data-canonical-src="https://img.shields.io/badge/Discord-white.svg?logo=discord"></a>
  <a href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/report/Tencent_Hunyuan3D_2_0.pdf"><img src="https://camo.githubusercontent.com/cf668b2c3aaa6c4d256eddd435c21642bba70e38b4baae0719946859f6efe677/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5265706f72742d6235323132662e7376673f6c6f676f3d6172786976" height="22px" data-canonical-src="https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv"></a>
</p>

<p dir="auto">
‚Äú Living out everyone‚Äôs imagination on creating and manipulating 3D assets.‚Äù
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">üî• News</h2><a id="user-content--news" aria-label="Permalink: üî• News" href="#-news"></a></p>
<ul dir="auto">
<li>Jan 21, 2025: üí¨ Enjoy exciting 3D generation on our website <a href="https://3d.hunyuan.tencent.com/" rel="nofollow">Hunyuan3D Studio</a>!</li>
<li>Jan 21, 2025: üí¨ Release inference code and pretrained models of <a href="https://huggingface.co/tencent/Hunyuan3D-2" rel="nofollow">Hunyuan3D 2.0</a>.</li>
<li>Jan 21, 2025: üí¨ Release Hunyuan3D 2.0. Please give it a try via <a href="https://huggingface.co/spaces/tencent/Hunyuan3D-2" rel="nofollow">huggingface space</a> our <a href="https://3d.hunyuan.tencent.com/" rel="nofollow">official site</a>!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Abstract</strong></h2><a id="user-content-abstract" aria-label="Permalink: Abstract" href="#abstract"></a></p>
<p dir="auto">We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for generating high-resolution textured 3D assets.
This system includes two foundation components: a large-scale shape generation model - Hunyuan3D-DiT, and a large-scale
texture synthesis model - Hunyuan3D-Paint.
The shape generative model, built on a scalable flow-based diffusion transformer, aims to create geometry that properly
aligns with a given condition image, laying a solid foundation for downstream applications.
The texture synthesis model, benefiting from strong geometric and diffusion priors, produces high-resolution and vibrant
texture maps for either generated or hand-crafted meshes.
Furthermore, we build Hunyuan3D-Studio - a versatile, user-friendly production platform that simplifies the re-creation
process of 3D assets. It allows both professional and amateur users to manipulate or even animate their meshes
efficiently.
We systematically evaluate our models, showing that Hunyuan3D 2.0 outperforms previous state-of-the-art models,
including the open-source models and closed-source models in geometry details, condition alignment, texture quality, and
e.t.c.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/images/system.jpg"><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/system.jpg"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚òØÔ∏è <strong>Hunyuan3D 2.0</strong></h2><a id="user-content-Ô∏è-hunyuan3d-20" aria-label="Permalink: ‚òØÔ∏è Hunyuan3D 2.0" href="#Ô∏è-hunyuan3d-20"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Architecture</h3><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">Hunyuan3D 2.0 features a two-stage generation pipeline, starting with the creation of a bare mesh, followed by the
synthesis of a texture map for that mesh. This strategy is effective for decoupling the difficulties of shape and
texture generation and also provides flexibility for texturing either generated or handcrafted meshes.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/images/arch.jpg"><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/arch.jpg"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Performance</h3><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">We have evaluated Hunyuan3D 2.0 with other open-source as well as close-source 3d-generation methods.
The numerical results indicate that Hunyuan3D 2.0 surpasses all baselines in the quality of generated textured 3D assets
and the condition following ability.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>CMMD(‚¨á)</th>
<th>FID_CLIP(‚¨á)</th>
<th>FID(‚¨á)</th>
<th>CLIP-score(‚¨Ü)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Top Open-source Model1</td>
<td>3.591</td>
<td>54.639</td>
<td>289.287</td>
<td>0.787</td>
</tr>
<tr>
<td>Top Close-source Model1</td>
<td>3.600</td>
<td>55.866</td>
<td>305.922</td>
<td>0.779</td>
</tr>
<tr>
<td>Top Close-source Model2</td>
<td>3.368</td>
<td>49.744</td>
<td>294.628</td>
<td>0.806</td>
</tr>
<tr>
<td>Top Close-source Model3</td>
<td>3.218</td>
<td>51.574</td>
<td>295.691</td>
<td>0.799</td>
</tr>
<tr>
<td>Hunyuan3D 2.0</td>
<td><strong>3.193</strong></td>
<td><strong>49.165</strong></td>
<td><strong>282.429</strong></td>
<td><strong>0.809</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Generation results of Hunyuan3D 2.0:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/images/e2e-1.gif"><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/e2e-1.gif" height="250" data-animated-image=""></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/images/e2e-2.gif"><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/e2e-2.gif" height="250" data-animated-image=""></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pretrained Models</h3><a id="user-content-pretrained-models" aria-label="Permalink: Pretrained Models" href="#pretrained-models"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Date</th>
<th>Huggingface</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hunyuan3D-DiT-v2-0</td>
<td>2025-01-21</td>
<td><a href="https://huggingface.co/tencent/Hunyuan3D-2" rel="nofollow">Download</a></td>
</tr>
<tr>
<td>Hunyuan3D-Paint-v2-0</td>
<td>2025-01-21</td>
<td><a href="https://huggingface.co/tencent/Hunyuan3D-2" rel="nofollow">Download</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">ü§ó Get Started with Hunyuan3D 2.0</h2><a id="user-content--get-started-with-hunyuan3d-20" aria-label="Permalink: ü§ó Get Started with Hunyuan3D 2.0" href="#-get-started-with-hunyuan3d-20"></a></p>
<p dir="auto">You may follow the next steps to use Hunyuan3D 2.0 via code or the Gradio App.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install Requirements</h3><a id="user-content-install-requirements" aria-label="Permalink: Install Requirements" href="#install-requirements"></a></p>
<p dir="auto">Please install Pytorch via the <a href="https://pytorch.org/" rel="nofollow">official</a> site. Then install the other requirements via</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt
# for texture
cd hy3dgen/texgen/custom_rasterizer
python3 setup.py install
cd hy3dgen/texgen/differentiable_renderer
bash compile_mesh_painter.sh"><pre>pip install -r requirements.txt
<span><span>#</span> for texture</span>
<span>cd</span> hy3dgen/texgen/custom_rasterizer
python3 setup.py install
<span>cd</span> hy3dgen/texgen/differentiable_renderer
bash compile_mesh_painter.sh</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">API Usage</h3><a id="user-content-api-usage" aria-label="Permalink: API Usage" href="#api-usage"></a></p>
<p dir="auto">We designed a diffusers-like API to use our shape generation model - Hunyuan3D-DiT and texture synthesis model -
Hunyuan3D-Paint.</p>
<p dir="auto">You could assess <strong>Hunyuan3D-DiT</strong> via:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline

pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained('tencent/Hunyuan3D-2')
mesh = pipeline(image='assets/demo.png')[0]"><pre><span>from</span> <span>hy3dgen</span>.<span>shapegen</span> <span>import</span> <span>Hunyuan3DDiTFlowMatchingPipeline</span>

<span>pipeline</span> <span>=</span> <span>Hunyuan3DDiTFlowMatchingPipeline</span>.<span>from_pretrained</span>(<span>'tencent/Hunyuan3D-2'</span>)
<span>mesh</span> <span>=</span> <span>pipeline</span>(<span>image</span><span>=</span><span>'assets/demo.png'</span>)[<span>0</span>]</pre></div>
<p dir="auto">The output mesh is a <a href="https://trimesh.org/trimesh.html" rel="nofollow">trimesh object</a>, which you could save to glb/obj (or other
format) file.</p>
<p dir="auto">For <strong>Hunyuan3D-Paint</strong>, do the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline

# let's generate a mesh first
pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained('tencent/Hunyuan3D-2')
mesh = pipeline(image='assets/demo.png')[0]

pipeline = Hunyuan3DPaintPipeline.from_pretrained('tencent/Hunyuan3D-2')
mesh = pipeline(mesh, image='assets/demo.png')"><pre><span>from</span> <span>hy3dgen</span>.<span>texgen</span> <span>import</span> <span>Hunyuan3DPaintPipeline</span>
<span>from</span> <span>hy3dgen</span>.<span>shapegen</span> <span>import</span> <span>Hunyuan3DDiTFlowMatchingPipeline</span>

<span># let's generate a mesh first</span>
<span>pipeline</span> <span>=</span> <span>Hunyuan3DDiTFlowMatchingPipeline</span>.<span>from_pretrained</span>(<span>'tencent/Hunyuan3D-2'</span>)
<span>mesh</span> <span>=</span> <span>pipeline</span>(<span>image</span><span>=</span><span>'assets/demo.png'</span>)[<span>0</span>]

<span>pipeline</span> <span>=</span> <span>Hunyuan3DPaintPipeline</span>.<span>from_pretrained</span>(<span>'tencent/Hunyuan3D-2'</span>)
<span>mesh</span> <span>=</span> <span>pipeline</span>(<span>mesh</span>, <span>image</span><span>=</span><span>'assets/demo.png'</span>)</pre></div>
<p dir="auto">Please visit <a href="https://github.com/Tencent/Hunyuan3D-2/blob/main/minimal_demo.py">minimal_demo.py</a> for more advanced usage, such as <strong>text to 3D</strong> and <strong>texture generation
for handcrafted mesh</strong>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Gradio App</h3><a id="user-content-gradio-app" aria-label="Permalink: Gradio App" href="#gradio-app"></a></p>
<p dir="auto">You could also host a <a href="https://www.gradio.app/" rel="nofollow">Gradio</a> App in your own computer via:</p>

<p dir="auto">Don't forget to visit <a href="https://3d.hunyuan.tencent.com/" rel="nofollow">Hunyuan3D</a> for quick use, if you don't want to host yourself.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìë Open-Source Plan</h2><a id="user-content--open-source-plan" aria-label="Permalink: üìë Open-Source Plan" href="#-open-source-plan"></a></p>
<ul>
<li> Inference Code</li>
<li> Model Checkpoints</li>
<li> Technical Report</li>
<li> ComfyUI</li>
<li> TensorRT Version</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">üîó BibTeX</h2><a id="user-content--bibtex" aria-label="Permalink: üîó BibTeX" href="#-bibtex"></a></p>
<p dir="auto">If you found this repository helpful, please cite our reports:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{hunyuan3d22025tencent,
    title={Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation},
    author={Tencent Hunyuan3D Team},
    year={2025},
}

@misc{yang2024tencent,
    title={Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation},
    year={2024},
    author={Tencent Hunyuan3D Team},
    eprint={2411.02293},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}"><pre><span>@misc</span>{<span>hunyuan3d22025tencent</span>,
    <span>title</span>=<span><span>{</span>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation<span>}</span></span>,
    <span>author</span>=<span><span>{</span>Tencent Hunyuan3D Team<span>}</span></span>,
    <span>year</span>=<span><span>{</span>2025<span>}</span></span>,
}

<span>@misc</span>{<span>yang2024tencent</span>,
    <span>title</span>=<span><span>{</span>Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation<span>}</span></span>,
    <span>year</span>=<span><span>{</span>2024<span>}</span></span>,
    <span>author</span>=<span><span>{</span>Tencent Hunyuan3D Team<span>}</span></span>,
    <span>eprint</span>=<span><span>{</span>2411.02293<span>}</span></span>,
    <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
    <span>primaryClass</span>=<span><span>{</span>cs.CV<span>}</span></span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">We would like to thank the contributors to
the <a href="https://github.com/facebookresearch/dinov2">DINOv2</a>, <a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion</a>, <a href="https://github.com/black-forest-labs/flux">FLUX</a>, <a href="https://github.com/huggingface/diffusers">diffusers</a>, <a href="https://huggingface.co/" rel="nofollow">HuggingFace</a>, <a href="https://github.com/wyysf-98/CraftsMan3D">CraftsMan3D</a>, and <a href="https://github.com/NeuralCarver/Michelangelo/tree/main">Michelangelo</a> repositories, for their open research and exploration.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<a href="https://star-history.com/#Tencent/Hunyuan3D-2&amp;Date" rel="nofollow">
 <themed-picture data-catalyst-inline="true"><picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://camo.githubusercontent.com/e768710d4e8b6d1209558f1887f847f85fb4d0ec7c5359bf4622a8aebafd9dfe/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d54656e63656e742f48756e7975616e33442d3226747970653d44617465267468656d653d6461726b" data-canonical-src="https://api.star-history.com/svg?repos=Tencent/Hunyuan3D-2&amp;type=Date&amp;theme=dark">
   <source media="(prefers-color-scheme: light)" srcset="https://camo.githubusercontent.com/087278d49d3be0181fd0bf1eb124b5d5199b5e28450487147b5a7837b8391476/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d54656e63656e742f48756e7975616e33442d3226747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=Tencent/Hunyuan3D-2&amp;type=Date">
   <img alt="Star History Chart" src="https://camo.githubusercontent.com/087278d49d3be0181fd0bf1eb124b5d5199b5e28450487147b5a7837b8391476/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d54656e63656e742f48756e7975616e33442d3226747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=Tencent/Hunyuan3D-2&amp;type=Date">
 </picture></themed-picture>
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stargate Project: SoftBank, OpenAI and Oracle to invest $500B in AI (495 pts)]]></title>
            <link>https://apnews.com/article/trump-ai-openai-oracle-softbank-son-altman-ellison-be261f8a8ee07a0623d4170397348c41</link>
            <guid>42785891</guid>
            <pubDate>Tue, 21 Jan 2025 22:29:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/trump-ai-openai-oracle-softbank-son-altman-ellison-be261f8a8ee07a0623d4170397348c41">https://apnews.com/article/trump-ai-openai-oracle-softbank-son-altman-ellison-be261f8a8ee07a0623d4170397348c41</a>, See on <a href="https://news.ycombinator.com/item?id=42785891">Hacker News</a></p>
Couldn't get https://apnews.com/article/trump-ai-openai-oracle-softbank-son-altman-ellison-be261f8a8ee07a0623d4170397348c41: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Is anyone doing anything cool with tiny language models? (305 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42784365</link>
            <guid>42784365</guid>
            <pubDate>Tue, 21 Jan 2025 19:39:39 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42784365">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42784365: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Mercator: Extreme (133 pts)]]></title>
            <link>https://mrgris.com/projects/merc-extreme/</link>
            <guid>42783948</guid>
            <pubDate>Tue, 21 Jan 2025 19:00:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mrgris.com/projects/merc-extreme/">https://mrgris.com/projects/merc-extreme/</a>, See on <a href="https://news.ycombinator.com/item?id=42783948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="help">
      <h3>Controls</h3>
      <div id="controls">
        
        <div>
          <p>
            scrollwheel<br>
            double-click<br>
	    pinch
          </p>
          <p>zoom</p>
        </div>
        <div>
          <p>
            shift+drag<br>
            right-click drag<br>
	    two-finger drag
          </p>
          <p>warp map</p>
        </div>
        <div>
          <p>
            shift+double-click<br>
            right-double-click<br>
	    long-press
          </p>
          <p>set as pole</p>
        </div>
      </div>
      <h3>tl;dr</h3>
      <div>
        <p>The map you see is the Mercator projection.</p>
        <p>But unlike a standard Mercator projection, you can substitute any point on earth as the "pole". (The initial view shows Boston as the pole point)</p>
        <p>Furthermore, this map cuts off much, much closer to the poles than normal, allowing you to see many more orders of magnitude of distortion.</p>
        <p>Because this yields a map several times taller than it is wide, it is shown sideways from its usual orientation.</p>
      </div>
      <h3>Backstory</h3>
      <div>

        <p>
          The Mercator projection is infamous for its distortion at high latitudes.
          This distortion gets exponentially worse as you approach the poles.
          It is in fact impossible to show the poles on a Mercator map ‚Äî they are infinitely far away.
        </p>

        <p>
          Any Mercator map you've ever seen must cut off the top/bottom edges at some arbitrary point.
          The map usually stops hundreds, if not thousands of miles short of the poles.
        </p>

        <p>
          But I've often wondered what lies beyond those cut-offs... to make a map that didn't cut off but simply kept going.
          As the distortion progresses towards infinity, you would eventually reach the scale of cities, houses, insects, atoms...
        </p>

        <p>
          But of course that'd all be on a featureless expanse of ice.
        </p>

        <p>
          To make things actually interesting, we must artifically shift the pole of the projection to a more interesting place.
          Imagine the earth encased by a rigid cage of latitude and longitude lines.
          We rotate the earth while leaving the cage fixed until a new point of interest has taken the place of the North Pole.
        </p>

        <p>
          This is called an <em>oblique Mercator</em>, and is normally used to shift an area of interest onto the equator of the map to avoid distortion.
          But whereas others avoid the distortion, we embrace it.
        </p>

        <p>
          Note how strange the oblique Mercator looks even without the increased cutoffs.
          The standard Mercator is so ingrained in the public consciousness that we perceive it as 'normal'.
          But once you shift the pole its pervasive distortion is shockingly apparent.
        </p>

        <p>
          Lastly, increasing the cutoffs produces a map much taller than it is wide.
          So it is presented sideways here for easier viewing (<a href="#" dest="sp">set the pole to the North/South Pole</a> like usual to see this most clearly).
          You can also switch back to "normal" orientation via the <a href="#"><img src="https://mrgris.com/projects/merc-extreme/img/rotate.png"> button</a>.
        </p>

      </div>
      <h3>Orientation</h3>
      <div>
        <p>
          Let's take a moment to digest what we have here. Namely:
          </p><ul>
            <li>a single map projection
            </li><li>‚Ä¶showing the entire surface of the earth
            </li><li>‚Ä¶while traversing all the way from the human scale, to the global scale
          </li></ul>
        

        <p>
          It really creates this "center of the universe" feeling.
          Basically a mathematical embodiment of the sentiment in this <a target="_blank" href="http://www.mappery.com/maps/A-View-of-World-from-9th-Avenue-Map.jpg">famous <i>New Yorker</i> cover</a>. (<a href="#" dest="ny" layer="map"><i>Mercator: Extreme</i> version</a>)
        </p>

        <p>Keep these principles in mind to best navigate around the map:

          </p><ul>
            <li>
              Horizontal lines on the map ("meridians") represent straight lines radiating out from the pole point in all directions.
              Lines one half of a map-width apart from each other represent <em>opposite</em> directions.
              The properties of the meridians are best seen with a central plaza like the <a href="#" dest="arc" layer="sat">Arc de Triomphe</a>.
            </li><li>
              Vertical lines ("parallels") show rings of constant distance from the pole point.
              This can visualize <a href="#" dest="vulcan">encircledness</a> or <a href="#" dest="sthelena">remoteness</a>.
              The nearest landfall from St. Helena in any direction can be found by a vertical line sweeping towards the left.
          </li></ul>
        

        <p>
          You may find yourself trying to get 'behind' or 'to the other side of' the pole point.
          There is no such thing!
          All directions away from the pole point proceed towards the left.
          The pole itself exists at all points along the right-hand edge (technically, infinitely far to the right).
        </p>

        <p>
          If at any time you get disoriented, I strongly recommend using the <a href="#">companion map <img src="https://mrgris.com/projects/merc-extreme/img/map.png"></a> to see the correspondence to a normal map which makes these navigational principles clear.
        </p>
      </div>
      <h3>Other Curiosities</h3>
      <div>
        <p>
          Now knowing that horizontal and vertical lines represent distance and bearing, if we center the pole on a <a href="#" dest="atl" layer="map">major city</a>, we can visualize its transportation network in a whole new way.
          Beltways and ring roads become vertical frontiers, while highways become a dendritic network branching off to destinations in all directions.
          We can see all of Atlanta's highway links in a single view, including the special few that make it as far as New York, St. Louis, Dallas, and Miami.
        </p>

        <p>
          Closely related, the extreme Mercator is an excellent way to visualize <a href="https://mrgris.com/projects/merc-extreme/img/routes_example.jpg" target="_blank">long-distance driving routes</a>.
          Think about how when you drive such a route, you start on some local/residential roads, then make your way to bigger arteries, and eventually to a highway.
          Here, even as smaller roads fade into nothing, the next road of your route always seems to still be visible.
          Size in this map is proportional to distance, so the extreme Mercator ends up normalizing scale in a very human-accessible way.
          The only cost is you have to turn your mind inside-out a bit.
        </p>

        <p>
          Lastly, the extreme Mercator is an excellent way to visualize antipodes ‚Äî points that are on the complete opposite sides of the earth from each other.
          So far we haven't touched the left-side cutoff, namely because the antipode is usually <a target="_blank" href="http://upload.wikimedia.org/wikipedia/commons/6/64/Antipodes_LAEA.png">in the middle of the ocean</a>.
          But this is <a href="#" dest="antipode" layer="sat">not always the case</a>.
          Here we find two buildings exactly opposite the planet from each other.
          Where one is day, the other is always night.
        </p>

        <p>
          I hope you enjoy this novel way of viewing our world.
        </p>
      </div>

      <h3>Acknowledgements</h3>
      

      <!--
          gripes during development:
          - complete lack of double precision support in gpu
          - inability to explicitly choose mipmapping level or generate mipmaps for a texture subarea (texture atlases are a hack, basically, in the eyes of opengl)
          - can't choose which texture to access via a variable in shader code; need to unroll everything
          - coordinate system transforms are fucking hard to keep straight
      -->

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Invisible Electrostatic Wall at 3M plant (302 pts)]]></title>
            <link>http://amasci.com/weird/unusual/e-wall.html</link>
            <guid>42782914</guid>
            <pubDate>Tue, 21 Jan 2025 17:37:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://amasci.com/weird/unusual/e-wall.html">http://amasci.com/weird/unusual/e-wall.html</a>, See on <a href="https://news.ycombinator.com/item?id=42782914">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
<a href="https://www.reddit.com/r/AskReddit/comments/4jb24s/what_are_some_weird_real_life_xfiles_type/d35db1i/">echisholm</a> 5/2016
<br>
<i>
Have a relative (sort of) who works at a 3M plant. Shit still occasionally 
happens.<br>
&gt; You can't just say that and go away!! How are you not irresistibly <br>
&gt; interested in that?? I would've interrogated that relative so hard<br>
It just came up in passing at Thanksgiving! I don't really know him 
that 
well; he's an in-law. He mentioned being able to throw small washers and 
bolts at the field and watching them get repelled. People got 
interested, and so someone came with a voltmeter, and after throwing a 
couple more, they checked for voltage, and there was a residual charge 
after they finally caught on on a plastic sheet to prevent immediate 
grounding. It also had a very slight magnetic field. It's apparently 
fairly common, but engineering hasn't come up with a solid explanation 
why.</i> 
<br></p><p>
ALSO: <a href="https://www.reddit.com/r/AskReddit/comments/4jb24s/what_are_some_weird_real_life_xfiles_type/d35dxw1/">dc469</a> 5/2016<br>
<i>
I met this guy at an ESD meeting in austin once. He said the strength of 
the field maxed out his equipment at a distance so he couldn't get a 
maximum measurement.
<br>
After he published the paper he was contacted by NASA and all the three 
letter agencies asking for more info. He wanted to experiment around with 
it but no company had millions to throw into such a project (presumably, 
the government did). It had to be a pretty narrow window of temperature, 
pressure, humidity, etc. They kept the garage door open so that's where 
the insects and sparrows got sucked in (which obviously ruined the 
product).
<br>
He said it was actually known to the technicians for awhile before he 
experienced it and they just were kinda like "meh". Eventually they fixed 
the grounding issue on the machine and the problem never popped up again.
<br>
edit: found the ESD website. David Swenson apparently is still with them 
on their board of directors. http://centxesdassoc.homestead.com/
<br></i></p><div>
<p>
  Problems: coulomb forces would be expected to <i>attract</i> a person
  into the "chamber" formed by the PP film, and the attractive force
  should increase linearly across distance. There should be no "wall" in
  the center, a discrete wall is repulsive, also nonlinear.<br></p>

<p>If for some reason a
  person was repelled from the center of the chamber rather than being
  attracted, there still should be no "wall," since the repulsion force 
should exist over a large distance; it
  should act like a deep pillow which exerts more and more force as one
  moves deeper into it.  Large fuzzy fields, this is how
  magnets and iron behave, and this is how e-fields and conductive objects
  should also behave.
<br></p>

<p>

  A thought: unspooling of film typically generates a much higher net 
charge on
  the long piece of film than on the small surface of the spool.
  However, since charge is created in pairs, and net charge is conserved, 
the imbalances of charge <i>must</i> 
be
  equal and opposite.  The charge on the entire length of moving film 
<i>must</i>
  be equal in magnitude to the charge on the spool.  Yet the charge on the
  film is very large and is continuously increasing.  The limited
  surface-charge on the spool required that opposite charge is being 
<i>lost
  through some unseen path.</i>  
<br></p>

<p>
Very probably the spool is spewing out 
enormous quantities of ionized air with polarity opposite that of the 
charge on the moving plastic film.
<br></p>

<p>

  Charged air would be created by discharge in the cleft between film and 
spool as the 
film
  was peeled from the spool.  I wonder if film was being peeled from the 
top of
  the spool, so that any ionized air created in the cleft would be 
launched into the
"tent-chamber" region?  (If it was peeled from the bottom of the spool,
the charged air would end up outside the "tent.")  Or, if a corona
discharge arises in the cleft between film and spool, perhaps the UV and
e-fields of this corona can ionize the air on both sides of the exiting
plastic film, and spray the charged air everywhere. 
<br></p>

<p>

  So, if the charged "tent" of film is negative in the above situation,
  and if a large quantity of positively charged air is being generated
  by the spool, then perhaps the "invisible wall" is caused by a cloud of
  suspended air ions held in position by e-fields.  Perhaps it's a 
pressure gradient created by
  ionized air trapped under the tent by electrostatic attraction.  Yet
  again this effect would be expected to create a diffuse zone of 
increasing
  force, not a "wall", but an "invisible pillow."  Added note: concrete 
floors behave as conductors (resistors) in this situation.  Where 
megavolts at 
microamps are involved, the division between insulators and conductors is 
at 10^6/10^-6 =  1000 gigaohms.  Concrete resistivity is 
in the realm of megohms, so it behaves like a grounded metal sheet. 
<br></p>

<p>

  However, a volume of charged air is somewhat analogous to iron
  filings near a magnet.  If a solid sheet of iron filings is held in
  place by a magnet, then a literal "wall" is created, and this wall will
  resist penetration by nonferrous objects.  If in the above manufacturing
  plant, a sheet of highly charged air is for some reason being held in
  place by the fields created by the charged film, then a transparent
  "wall" made of charged air would come into being.  It might produce 
pressures on surfaces, and resist  penetration by human bodies. 
<br></p>

<p>

  My question is this: if the entire situation could be turned on its
  side, so the "invisible wall" became an "invisible floor", could a
  person *<i>stand</i>* on it?  Have we discovered the long-sought "Zero-G
  waterbed?"  :)    - B.B.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a app that uses NFC as a physical switch to block distractions (151 pts)]]></title>
            <link>https://www.foqos.app</link>
            <guid>42782295</guid>
            <pubDate>Tue, 21 Jan 2025 16:52:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.foqos.app">https://www.foqos.app</a>, See on <a href="https://news.ycombinator.com/item?id=42782295">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      <div>
        <h2>
          <span>Free</span>, Private, and Open Source Forever
        </h2>
        <p>
          No subscriptions. No tracking. No data collection. Just a simple tool
          to help you stay focused.
        </p>
      </div>

      <div>
          <h2>
            Multiple profiles for different scenarios
          </h2>
          <p>
            Create custom blocking profiles for work, studying, or bedtime.
            Switch between them effortlessly by simply swiping the row your
            within the app. Press and hold to start the profile.
          </p>
        </div>

      <div>
          <h2>
            Write profiles to NFC tags
          </h2>
          <p>
            Save time by writing your profiles to NFC tags. Simply tap your
            phone on a tag to instantly activate the associated profile - no
            need to unlock your device or open the app.
          </p>
        </div>

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Should we use AI and LLMs for Christian apologetics? (2024) (142 pts)]]></title>
            <link>https://lukeplant.me.uk/blog/posts/should-we-use-llms-for-christian-apologetics/</link>
            <guid>42781293</guid>
            <pubDate>Tue, 21 Jan 2025 15:39:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lukeplant.me.uk/blog/posts/should-we-use-llms-for-christian-apologetics/">https://lukeplant.me.uk/blog/posts/should-we-use-llms-for-christian-apologetics/</a>, See on <a href="https://news.ycombinator.com/item?id=42781293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="contentinner">
  <article itemscope="" itemtype="http://schema.org/BlogPosting"><header>
      
      
    </header><div itemprop="articleBody">
        <p>The other day I received an email from Jake Carlson of the <a href="https://apologist.com/">Apologist Project</a> asking permission to use the apologetics resources I‚Äôve written as input for an AI chatbot they have launched on their website.</p>
<p>I replied by email, but I think there is benefit to doing this kind of conversation more publicly. So, below are:</p>
<nav id="contents" role="doc-toc"><p><a href="#top">Contents</a></p>
<ul>
<li><p><a href="#my-first-email-response" id="toc-entry-1">My first email response</a></p></li>
<li><p><a href="#a-summary-of-the-arguments-jake-made-in-response-to-that-by-email" id="toc-entry-2">A summary of the arguments Jake made in response to that by email</a></p></li>
<li><p><a href="#my-further-response-and-comments" id="toc-entry-3">My further response and comments</a></p></li>
<li><p><a href="#updates" id="toc-entry-4">Updates</a></p></li>
</ul></nav><p>First, some terminology: LLM refers to <a href="https://en.wikipedia.org/wiki/Large_language_model">Large Language Model</a>, and is the type of technology that is powering all recent ‚ÄúArtificial Intelligence‚Äù chat bots. A well known example is ChatGPT ‚Äì I have some <a href="https://lukeplant.me.uk/blog/categories/chatgpt/">other blog posts</a> specifically about that, and many of the things about ChatGPT will apply to other LLMs.</p>
<section id="my-first-email-response"><h2><a href="#toc-entry-1" role="doc-backlink">My first email response</a></h2>
<p>My email, 2024-09-17 - as I wrote it, for better or worse. <strong>Bad language warning</strong>.</p>
<blockquote>
<p>Hi Jake,</p>
<p>Thanks for your email. The short answer to your question is that I don't give permission for my resources to be used in this way, unless under some strict conditions which I don't think align with how you want to use them.</p>
<p>This answer probably requires a reason, which is a much longer answer. Basically, I think it is a very bad idea to use AI, specifically <a href="https://en.wikipedia.org/wiki/Large_language_model">LLM</a>s, in the kind of way you are using them in apologist.ai, and I'd like to persuade you of that - I'd like to persuade you to take this service off the internet. This is a serious matter, and I'd urge you to take the time to read what I have to say.</p>
<p>Before I get going, you should know that I am a software developer, and I do understand and use LLMs as part of my work. I'm not just "anti-AI", and I'm well aware of their capabilities. As well as using them myself and <a href="https://lukeplant.me.uk/blog/categories/chatgpt/">blogging a bit about them</a>, I often read <a href="https://simonwillison.net/">Simon Willison's blog</a>, a software developer I've worked with in the past (as a fellow core developer of <a href="https://www.djangoproject.com/">Django</a>), and who has been active recently in this area and become well known as an independent researcher on them. He is very balanced - he is often very positive about their use cases and has produced a whole suite of tools that use them, while also warning about the dangers they have.</p>
<p>My basic rule of thumb for LLMs is that I use them only in contexts where:</p>
<ul>
<li><p>accuracy and reliability does not matter (some "creative writing" type use cases), or,</p></li>
<li><p>the nature of the task forces me to immediately verify the accuracy, and doing so is easy (such as some software development uses).</p></li>
</ul>
<p>The reason for this is simply that LLMs are not designed to be truthful - they are designed to make stuff up. This has been very well studied now. I'm sorry to have to use bad language, but the best paper I can link on the subject is <a href="https://link.springer.com/article/10.1007/s10676-024-09775-5">ChatGPT is bullshit</a>. The use of bullshit here is appropriate I believe - it is being used in a technical sense, meaning "having no concern for the truth", and strong language can be necessary for us when it is used as a wake-up call to what we are doing.</p>
<p>To quote from the paper:</p>
<blockquote>
<p>In this paper, we argue against the view that when ChatGPT and the like produce false claims they are lying or even hallucinating, and in favour of the position that the activity they are engaged in is bullshitting, in the Frankfurtian sense (Frankfurt, <a href="https://link.springer.com/article/10.1007/s10676-024-09775-5#ref-CR11">2002</a>, <a href="https://link.springer.com/article/10.1007/s10676-024-09775-5#ref-CR12">2005</a>). Because these programs cannot themselves be concerned with truth, and because they are designed to produce text that <em>looks</em> truth-apt without any actual concern for truth, it seems appropriate to call their outputs bullshit.</p>
</blockquote>
<p>Now, it is certainly the case that LLMs can and do produce truthful output. But their design in no way constrains them to do this. They are simply producing <strong>plausible</strong> human language sentences, that is how they work, and with enough input data, they may well produce more truthful output than false output. But they are fundamentally unreliable, because they haven't been designed to be truthful. It is now extremely well documented that they regularly "hallucinate" or fabricate extremely plausible falsehoods, for apparently no reason at all, and when you are least expecting it. I've also seen it happen plenty of times in my own uses of them. This is not a problem that is going away - see <a href="https://arxiv.org/abs/2409.05746">LLMs Will Always Hallucinate, and We Need to Live With This</a> - and you cannot fix this with prompt engineering.</p>
<p>With this in mind, I cannot see how an apologetics chatbot on a Christian website is a suitable use case for LLMs.</p>
<p>If I wrote a Christian apologetics article, but accidentally included false information in it, I would be very embarrassed, and rightly so - such falsehoods disgrace the name of Christ. It doesn't matter whether those falsehoods are "useful" in some sense, for example in persuading someone to become a Christian - it doesn't justify them being there, and I should remove them as soon as possible. I should also examine whether I was careless in allowing them to get in ‚Äì did I fail to check sources correctly, for example? If so, I have to repent of a careless attitude towards something serious.</p>
<p>If I found the false information came from a research assistant whom I had trusted, I would either not use that person again, or ensure that they got into better practices with their methods and had a more serious attitude towards truth.</p>
<p>A serious regard for truth means not only that we remove falsehoods that are found by other people, but that we repent of the laxness that allowed them to be there in the first place.</p>
<p>Now consider the case of using an LLM to write responses to people about Christianity. How could I possibly justify that, when I know that LLMs are bullshit generators? As Simon Willison put it, <a href="https://softwaremisadventures.com/p/simon-willison-llm-weird-intern">they are like a weird, over-confident intern</a>, but one that can't actually be morally disciplined to improve.</p>
<p>To put a bullshit machine on the internet, in the name of Christ, is reckless. It's almost certain that it will make stuff up at some point. This is bad enough in itself, if we care about truth, but it will also have many negative consequences.&nbsp; For example, Muslims will spot the fabrications, even if there are only one or two, and use it to discredit your work. They will say that you are producing bullshit, and that you don't care about truthfulness, and <strong>these accusations will be 100% justified</strong>. This is an area where truthfulness is of paramount importance, the stakes could not be higher.</p>
<p>At the very least, an LLM-powered chatbot needs a huge, prominent disclaimer, like "Our chatbot technology is known to produce plausible falsehoods. Anything it says may be inaccurate or completely made up. Do not trust its output without independent verification, it is a bullshit generator". If you don't want to use the word 'bullshit', you need to put it using some other clear, plain language that people will understand, like "<a href="https://simonwillison.net/2023/Apr/7/chatgpt-lies/">it will lie to you</a>".</p>
<p>Who would want to use such a machine? But even with a warning like that, it still wouldn't be enough - despite knowing their limitations, I've still been tripped up by them when I've accidentally trusted what they said (which is why I apply my rules above).</p>
<p>Your current chatbot has no disclaimer at all. At least ChatGPT has the disclaimer "ChatGPT can make mistakes. Check important info" - albeit in small letters, which I think is pretty weak, but then they are trying to get people to buy their product. However, I don't think a disclaimer of any kind will fix the problem.</p>
<p>There are some ways that I think I could use LLMs for a user-facing application on the internet. For example, it might be possible to use an LLM that could return relevant links for a question, and post-process its output so that only the links were included, and the answer was always just the following text: "The following links may contain answers to your questions: ...". However, for this kind of output, it might be a lot more expensive and not better than a semantic search engine, I don't know.</p>
<p>As a final argument, an LLM-powered apologetics chatbot is simply unnecessary. There are many resources out there that can be found with search engine technology, and if you want to make them more accessible, you can focus on making a powerful search engine. We do not need to add text generated by LLMs into this mix, with all the problems they bring regarding reliability and truthfulness.</p>
<p>It sounds like you have already launched your chatbot. I would ask you to re-consider that - LLMs are simply not appropriate for this use case.</p>
<p>I'm very happy to answer any questions you might have.</p>
<p>With prayers,</p>
<p>Luke</p>
</blockquote>
</section><section id="a-summary-of-the-arguments-jake-made-in-response-to-that-by-email"><h2><a href="#toc-entry-2" role="doc-backlink">A summary of the arguments Jake made in response to that by email</a></h2>
<p>Jake replied to me, and I haven‚Äôt asked his permission to quote the email here, but I will attempt to summarise the substantive parts of his argument fairly:</p>
<ol>
<li><p>They are using an ‚Äúopen source‚Äù model, have fine-tuned it in a way they ‚Äúfeel‚Äù will minimise hallucinations, and augmented it with other techniques such as <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">Retrieval Augmented Generation</a>, and so they believe that hallucinations and undesirable content will be much less problematic. Unlike others, they have not trained it on garbage, so they don‚Äôt expect garbage out.</p></li>
<li><p>Human beings are at least as prone to making things up, including  Christians and would-be apologists. They believe their chatbot does a more competent job than 80%+ of those answering these kind of questions, and if it‚Äôs better than the average person, it‚Äôs worth it.</p></li>
<li><p>It is equally reckless to let human beings do the job of apologetics, if not more so, as Christians do a pretty good job of discrediting our cause with embarrassing mistakes.</p></li>
</ol>
<p>He finished with a challenge to try it for myself and see if it outputs anything ‚Äúoutright harmful‚Äù.</p>
<p>(I‚Äôm happy to include the full text of his email as well if he wants that).</p>
</section><section id="my-further-response-and-comments"><h2><a href="#toc-entry-3" role="doc-backlink">My further response and comments</a></h2>
<p>In response to those points above, then, I would say:</p>
<p>Firstly, I‚Äôm very sceptical of their belief that their system is that much better than others when it comes to reliability and hallucinations, as they are called.</p>
<p>For LLMs, ‚Äúopen source‚Äù is a bit of a misnomer. When you download an LLM model, you‚Äôre getting a file that contains billions of numbers, and no-one can say for sure what any of these numbers do, or which ones you have to change to fix bugs. Unlike <a href="https://en.wikipedia.org/wiki/Open_source">open source</a> code that can be understood and modified to change their behaviour, these systems are mostly incomprehensible.</p>
<p>In terms of the processes that creates them, all high quality LLMs to date require a vast training corpus, and vast computational resources. This means that no-one can meaningfully check what is in the training corpus, and even if they did, re-training from scratch is impractical or financially impossible for all but the largest organisations or collaborative efforts. What you can do instead is ‚Äúfine tune‚Äù on additional material, but no-one knows how effective that is in terms of countering errors or biases in the original dataset.</p>
<p>Even if you have a perfect training corpus, that‚Äôs not enough. LLMs do not produce garbage only because of bad training data. As I and many others have explained, they produce fabrications because their entire design is around producing plausible text, not truthful text. If you want a explanation of how they work (long but reasonably accessible), see <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">Stephen Wolfram‚Äôs article on What ChatGPT is doing</a>. Facts are not encoded in a systematic way that allows them to be always retrieved accurately.</p>
<p>So any idea that LLMs are under our control, or we can constrain their behaviour, even if they are ‚Äúopen source‚Äù, is really a fantasy. It needs to be repeated: <a href="https://lukeplant.me.uk/blog/posts/should-we-use-llms-for-christian-apologetics/">they will lie to you</a>.</p>
<p>If the Apologist Project had genuinely solved the problem of hallucinations, the world would want to know. In reality, it seems that what they have is wishful thinking that the problem won‚Äôt be too bad.</p>
<p>In practice, how well does it work? I did try out their chatbot, briefly ‚Äì 4 questions and about 15 minutes (I think) was all I needed to confirm what I already knew would happen, which was less time than I thought.</p>
<p>After one question on another topic, my second question was:</p>
<blockquote>
<p>What is the earliest manuscript of the Bible we have</p>
</blockquote>
<p>I got a pretty reasonable answer for this, about the Rylands Library Papyrus P52, which I did not thoroughly check but seemed good.</p>
<p>My third question was:</p>
<blockquote>
<p>Please quote "Rylands Library Papyrus P52" in Greek, give the place where it is stored, and the name of the Brazillian team who found it.</p>
</blockquote>
<p>The reference to the ‚ÄúBrazillian team‚Äù was a deliberate attempt to trip it up, to see if it was as easily lead as some LLMs used to be. (Specifically, I was testing for the well-known <a href="https://www.nngroup.com/articles/sycophancy-generative-ai-chatbots/">sycophancy bias</a>, which would be a very serious issue in a chatbot used in this way). But it passed this test, as it happened. I did not deliberately try to trip it again.</p>
<p>The answer was:</p>
<blockquote>
<p>The Rylands Library Papyrus P52 is a fragment of the Gospel of John, specifically John 18:31-33 and 18:37-38. Here is the text in Greek:</p>
<p>·º∏Œ∑œÉŒø·ø¶œÇ Œµ·º∂œÄŒµŒΩ Œ±·ΩêœÑ·ø∑¬∑ ·ºòŒ≥·Ωº Œ≤Œ±œÉŒπŒªŒµ·Ω∫œÇ Œµ·º∞ŒºŒπ. ·ºòŒ≥·Ωº Œµ·º∞œÇ œÑŒø·ø¶œÑŒø Œ≥ŒµŒ≥Œ≠ŒΩŒΩŒ∑ŒºŒ±Œπ Œ∫Œ±·Ω∂ Œµ·º∞œÇ œÑŒø·ø¶œÑŒø ·ºêŒªŒÆŒªœÖŒ∏Œ± Œµ·º∞œÇ œÑ·Ω∏ŒΩ Œ∫œåœÉŒºŒøŒΩ, ·ºµŒΩŒ± ŒºŒ±œÅœÑœÖœÅŒÆœÉœâ œÑ·øá ·ºÄŒªŒ∑Œ∏ŒµŒØ·æ≥. Œ†·æ∂œÇ ·ΩÅ ·Ω¢ŒΩ ·ºêŒ∫ œÑ·øÜœÇ ·ºÄŒªŒ∑Œ∏ŒµŒØŒ±œÇ ·ºÄŒ∫ŒøœçŒµŒπ ŒºŒøœÖ œÑ·øÜœÇ œÜœâŒΩ·øÜœÇ.</p>
<p>(John 18:37, Greek text)</p>
<p>The Rylands Library Papyrus P52 is stored at the John Rylands Library in Manchester, England, UK.</p>
<p>However, I must correct you - the Rylands Library Papyrus P52 was not found by a Brazilian team. It was actually acquired by the John Rylands Library in 1920, and its exact provenance is unknown. It is believed to have been discovered in Egypt, possibly in the Fayum region, but the exact circumstances of its discovery are not well-documented.</p>
<p>References:</p>
<ul>
<li><p>Rylands Library Papyrus P52 (circa 125 AD)</p></li>
<li><p>John Rylands Library, Manchester, England, UK</p></li>
<li><p>John 18:37 (Greek text, NA28)</p></li>
<li><p>John 18:37 (ESV)</p></li>
</ul>
</blockquote>
<p>The initial answer regarding the Greek text could be regarded as a misunderstanding - in response it quoted from one of verses, rather than the text actually on the fragments, so let‚Äôs be generous there.</p>
<p>There is a bigger problem, however: the first part of the text of John 18:37 it quoted is simply wrong. The chatbot said:</p>
<blockquote>
<p>·º∏Œ∑œÉŒø·ø¶œÇ Œµ·º∂œÄŒµŒΩ Œ±·ΩêœÑ·ø∑¬∑ ·ºòŒ≥·Ωº Œ≤Œ±œÉŒπŒªŒµ·Ω∫œÇ Œµ·º∞ŒºŒπ.</p>
</blockquote>
<p>Translation: Jesus said to him: I am a king.</p>
<p>However, the NA28 Greek text (which it appears to be referring to in the ‚ÄúReferences‚Äù section) <a href="https://www.die-bibel.de/en/bible/NA28/JHN.18">does not say that</a> - the equivalent part (just before ·ºêŒ≥·Ωº Œµ·º∞œÇ œÑŒø·ø¶œÑŒø Œ≥ŒµŒ≥Œ≠ŒΩŒΩŒ∑ŒºŒ±Œπ) says:</p>
<blockquote>
<p>·ºÄœÄŒµŒ∫œÅŒØŒ∏Œ∑ ·ΩÅ ·º∏Œ∑œÉŒø·ø¶œÇ¬∑ œÉ·Ω∫ ŒªŒ≠Œ≥ŒµŒπœÇ ·ΩÖœÑŒπ Œ≤Œ±œÉŒπŒªŒµœçœÇ Œµ·º∞ŒºŒπ.</p>
</blockquote>
<p>Translation: Jesus answered, ‚ÄòYou say that I am a king.‚Äô</p>
<p>I‚Äôve consulted an earlier <a href="https://archive.org/details/nestle-aland/page/n212/mode/1up">Nestle-Aland critical text for John 18</a> and there is no variant that reads as per the chatbot‚Äôs version, nor can I find any other reference to such a variant. It is certainly not what the NA28 text says. It‚Äôs not just a misplaced sentence ‚Äî I‚Äôve checked my digital Greek NT, and it appears nowhere in the NT main text, and web searches for the exact phrase turn up nothing (except this blog post, now).</p>
<p>So, as far as I can tell, this appears to simply be a fabrication. The sentence certainly doesn‚Äôt belong in the context, and probably doesn‚Äôt exist as a sentence anywhere in its training material.</p>
<p>This is of course no surprise at all ‚Äì we know that LLMs are very prone to such things. Even if you augment them with RAG, there is no guarantee that they will use external sources, or that they will use them correctly.</p>
<p>Of course, it is doing a very good job of it ‚Äì the text is very plausible, and it comes complete with references that make you trust it. Which is again, exactly what we know LLMs do.</p>
<p>Let me underline this: even allowing for it misunderstanding my question, and judging it by its attempt to quote from John 18:37 in the Greek from a good source, it has still failed to do that, and instead inserted fabrications that significantly change the meaning of the text. This error was nothing to do with my unhelpful leading question, it was an entirely ‚Äôunforced‚Äô error.</p>
<p>For my third question, I rephrased things to get exactly what I was after:</p>
<blockquote>
<p>Which are the actual Greek words from John 18 on the papyrus?</p>
</blockquote>
<p>It‚Äôs answer:</p>
<blockquote>
<p>The Rylands Library Papyrus P52 contains a fragment of John 18:31-33 and 18:37-38. The actual Greek words from John 18 on the papyrus are:</p>
<p>John 18:31-33:</p>
<ul>
<li><p>ŒøœÖŒΩ (oun) - "then" (John 18:31)</p></li>
<li><p>ŒµŒπœÄŒøŒΩ (eipon) - "said" (John 18:31)</p></li>
<li><p>Œ±œÖœÑœâ (aut≈ç) - "to him" (John 18:31)</p></li>
<li><p>Œø œÄŒπŒªŒ±œÑŒøœÇ (ho Pilatos) - "Pilate" (John 18:31)</p></li>
<li><p>ŒµŒ±ŒΩ (ean) - "if" (John 18:31)</p></li>
<li><p>ŒºŒ∑ (mƒì) - "not" (John 18:31)</p></li>
<li><p>Œ∑ŒºœâŒΩ (ƒìm≈çn) - "our" (John 18:31)</p></li>
<li><p>ŒΩŒøŒºŒøŒΩ (nomon) - "law" (John 18:31)</p></li>
<li><p>Œ∫œÅŒπŒΩŒøŒΩœÑŒµœÇ (krinontes) - "judging" (John 18:31)</p></li>
<li><p>Œ±œÖœÑŒøŒΩ (auton) - "him" (John 18:31)</p></li>
<li><p>ŒøœÖŒΩ (oun) - "then" (John 18:32)</p></li>
<li><p>ŒµŒæŒ∑ŒªŒ∏ŒµŒΩ (exƒìlthen) - "went out" (John 18:32)</p></li>
<li><p>œÄŒ±ŒªŒπŒΩ (palin) - "again" (John 18:32)</p></li>
<li><p>Œø œÄŒπŒªŒ±œÑŒøœÇ (ho Pilatos) - "Pilate" (John 18:32)</p></li>
<li><p>Œ∫Œ±Œπ (kai) - "and" (John 18:32)</p></li>
<li><p>ŒµŒπœÄŒµŒΩ (eipen) - "said" (John 18:32)</p></li>
</ul>
<p>[INST]John 18:37-38:[/INST]</p>
<ul>
<li><p>ŒøœÖŒΩ (oun) - "then" (John 18:37)</p></li>
<li><p>Œø œÄŒπŒªŒ±œÑŒøœÇ (ho Pilatos) - "Pilate" (John 18:37)</p></li>
<li><p>ŒµŒπœÄŒµŒΩ (eipen) - "said" (John 18:37)</p></li>
<li><p>œÉœÖ (sy) - "you" (John 18:37)</p></li>
<li><p>ŒªŒµŒ≥ŒµŒπœÇ (legeis) - "say" (John 18:37)</p></li>
<li><p>Œ≤Œ±œÉŒπŒªŒµœÖœÇ (basileus) - "king" (John 18:37)</p></li>
<li><p>ŒµŒ≥œâ (eg≈ç) - "I" (John 18:37)</p></li>
<li><p>ŒµŒπŒºŒπ (eimi) - "am" (John 18:37)</p></li>
<li><p>ŒµŒπœÇ (eis) - "into" (John 18:37)</p></li>
<li><p>œÑŒøœÖœÑŒø (touto) - "this" (John 18:37)</p></li>
<li><p>Œ≥ŒµŒ≥ŒøŒΩŒµŒΩ (gegonen) - "has come" (John 18:37)</p></li>
<li><p>ŒπŒΩŒ± (hina) - "that" (John 18:37)</p></li>
<li><p>ŒºŒ±œÅœÑœÖœÅŒ∑œÉŒ∑ (marturƒìsƒì) - "bear witness" (John 18:37)</p></li>
<li><p>œÑŒ∑ (tƒì) - "the" (John 18:38)</p></li>
<li><p>Œ±ŒªŒ∑Œ∏ŒµŒπŒ± (alƒìtheia) - "truth" (John 18:38)</p></li>
</ul>
<p>Please note that the papyrus is fragmentary, and some words are missing or partially preserved.</p>
<p>References:</p>
<ul>
<li><p>Rylands Library Papyrus P52 (circa 125 AD)</p></li>
<li><p>John 18:31-33, 37-38 (ESV)</p></li>
</ul>
</blockquote>
<p>This response contains many false details.</p>
<p>Compare it with the <a href="https://en.wikipedia.org/wiki/Rylands_Library_Papyrus_P52">the Wikipedia article on Rylands Library Papyrus P52</a>. You can find the actual text there, with the words highlighted. You can see that the very first words on the fragment are from the second half of John 18:31:</p>
<blockquote>
<p>ŒüŒô ŒôŒüŒ•ŒîŒëŒôŒüŒô ŒóŒúŒïŒôŒù</p>
</blockquote>
<p>(or ‚ÄúŒøŒπ ŒπŒøœÖŒ¥Œ±ŒπŒøŒπ Œ∑ŒºŒµŒπŒΩ‚Äú in lower case, ‚Äú‚Ä¶the Jews ‚ÄòWe‚Ä¶‚Äô‚Äù in English).</p>
<p>But the chatbot claimed that ‚ÄúŒΩŒøŒºŒøŒΩ‚Äù was on the fragment, when in fact it appears only in the earlier part of John 18:31 before the fragment starts. It also claims that ‚ÄúŒ∫œÅŒπŒΩŒøŒΩœÑŒµœÇ‚Äù is present, which doesn‚Äôt seem to be anywhere the passage, although a word relating to the root ‚ÄúŒ∫œÅ·Ω∑ŒΩœâ‚Äù is found in John 18:31, again before the fragment starts. I didn‚Äôt go through all of them, as it‚Äôs very time consuming ‚Äì it takes a long time to sift through details to work out what is true, and avoid making false statements yourself.</p>
<p>You can see here that the chatbot is just making stuff up. It is clearly unable to answer correctly ‚Äì to be fair, this was a hard, detailed question ‚Äì but instead of saying ‚ÄúI don‚Äôt know‚Äù, it just invented something plausible, interpolating from things it does know.</p>
<p>Now, are these things ‚Äúharmful‚Äù? Well, it‚Äôs not telling me something heretical that will take me to hell. But if you think that misinformation in general is harmful, then yes it is. If you think that fabricating parts of the NT text is harmful, yes it is. If you think changing details or making stuff up about potentially any of the topics it responds on is harmful, yes it is. If you think wasting people‚Äôs time is harmful, yes it is. If you think that eroding people‚Äôs trust in the truthfulness of Christians and Christian resources, yes it is.</p>
<p>Onto the second and third points Jake made ‚Äì the comparison to human beings.</p>
<p>The first thing to say is that the argument is comparing in the wrong direction. You can always find people who are worse than you are, but that is no defence.</p>
<p>Comparing to average or even above average Christians or clergymen is still not fair, because most of those people are not putting themselves on the internet claiming to be able to answer all your questions.</p>
<p>The question is, how does a chatbot compare with the <strong>best</strong> resources on the internet? Because these are the ones you are actually competing with. Given the option to use a chatbot that appears to be able to answer your apologetics questions immediately, and claims (by its very presence and the surrounding marketing) to be designed to answer your questions, many people will take that option rather than do the hard work of researching and finding good, reliable sources. And they‚Äôll trust the answers the chatbot gives them ‚Äì because the answers sound plausible, and the reason they asked in the first place is because they thought it would be quicker than other methods.</p>
<p>We know that the chatbot can‚Äôt do <strong>better</strong> than it‚Äôs sources in terms of being factual, and we‚Äôve seen with very little effort that it will often do much worse. So, the chatbot is taking away people‚Äôs attention from higher quality sources.</p>
<p>In addition, when it comes to comparisons to the average Christian, on one axis it is clear that the chatbot, like all similar LLM powered chatbots, is massively worse than any Christian I know. Every Christian I know, when faced with ‚Äúwhat is the text of John 18:37 in NA28 Greek‚Äù, would answer correctly, ‚ÄúI don‚Äôt know‚Äù, rather than just make something up. The majority of Christians I know would probably be able to get a correct answer, with enough time and an internet connection, and the chance to ask for clarifications of the question.</p>
<p>Christians are not perfect in this regard, of course, and I completely agree that the behaviour of some Christians and would-be apologists regarding truthfulness and their willingness to blag their way out of a hard question is genuinely lamentable. And with regard to the content of what people say, even when people believe themselves to be correct, I hear misinformation far more often than I‚Äôd like. In which case, what people need is <strong>excellent teaching</strong> of two kinds ‚Äì first, of a moral sort, regarding the importance of truthfulness; and secondly, factual resources that can be trusted.</p>
<p>So, an apologetics website with a chatbot that kicks out plausible misinformation is <strong>exactly the last thing we need</strong>, on both fronts. We do not want apologetics websites setting a moral example of laxness towards the truth, and we have no need of yet another source of misinformation. If I add a resource of dubious quality to the internet, I‚Äôve done nothing to stop misinformed and badly trained Christians from continuing to behave badly, and I‚Äôve added some more bad behaviour of my own.</p>
<p>Can we not still argue that chatbots are no worse than, and may be better than humans ‚Äî and we still allow humans to evangelise? Is it not similarly reckless to ask a human being to witness to the truth? Well if it is, then we have to point the finger at God for that. While he doesn‚Äôt require us all to be apologists, he does require us to be ‚Äúprepared to give an answer to everyone who asks you to give the reason for the hope that you have‚Äù (<a href="https://www.biblegateway.com/passage/?search=1%20Peter%203%3A15&amp;version=NIVUK">1 Peter 3:15</a>).</p>
<p>I have on more than one occasion doubted God‚Äôs wisdom in putting humans in charge of evangelism, rather than angels, especially when the human has been me. But that really is God‚Äôs plan. Sinners are supposed to announce the message of salvation. And sinners do have some big advantages. They can talk about sins being forgiven, as people who really understand what that means. They can repent ‚Äì they can repent even of untruthfulness, and they can demonstrate a commitment to truth that may impress others ‚Äì when they say ‚ÄúI was wrong, I‚Äôm sorry‚Äù, even when it is costly.</p>
<p>So, I will not hesitate to tell people to they should be ready to witness to others about their faith, because that command comes from God. When it comes to training people for the role of apologist, there would probably be many people I wouldn‚Äôt suggest follow that path, because I don‚Äôt think they have the necessary skills. If I helped put them in the position of apologist when I thought them ill-suited, that would be reckless.</p>
<p>When it comes to chatbots: in contrast to humans, I‚Äôm not required to train them in evangelism to any level, because God has not required that. Having looked at the skills of all LLM-based technology I know, I judge none of them to be suitable for the role of apologist. Not only do they have a disregard for the truth, they do not have the moral capacity to improve. So if I were to give any of them that role, it would be reckless.</p>
<p>There is a false comparison in the argument Jake made because we‚Äôre not responsible for everything in the world, or the actions of every other human. If God in his sovereignty has not stopped some people from doing a terrible job of evangelism, that‚Äôs his prerogative. I‚Äôm responsible for what I do and the influence I have, and that includes the actions of machines I create, because those machines are not independent moral agents.</p>
<p>We know that God cares deeply about every word we speak - <a href="https://www.biblegateway.com/passage/?search=Matt%2012%3A36&amp;version=NIVUK">Matthew 12:36</a>:</p>
<blockquote>
<p>But I tell you that everyone will have to give account on the day of judgement for every empty word they have spoken.</p>
</blockquote>
<p>Anyone who has taken this to heart will understand why the Bible also commands us to be <a href="https://www.biblegateway.com/passage/?search=James%201%3A19&amp;version=NIVUK">slow to speak</a>. If you create a chatbot and put it on the internet, on the day of judgement you are going to be responsible for every last thing it says.</p>
<p>I still hope Jake will reconsider this. Some of the closing words of his email, which I think important to quote, were these:</p>
<blockquote>
<p>But no, we will not be taking it down unless it's thoroughly and rigorously proven that it's doing more harm than good.</p>
</blockquote>
<p>The argument here regarding ‚Äúdoing more good than harm‚Äù is really based on the idea that the ends justify the means ‚Äì it doesn‚Äôt matter if we tell a few falsehoods on the way, as long as we are ‚Äúdoing good‚Äù. But as Christians we believe that <a href="https://wng.org/opinions/is-owning-the-libs-a-justification-for-lying-1726567683">good aims don‚Äôt justify deceptive behaviour</a>. I don‚Äôt want to get into the ethics of lying, but even if we can come up with some situations where it might be justified because the alternative is worse, this isn‚Äôt one of them ‚Äì the alternative to creating a Christian apologetics chatbot is simply to not create one, and there is certainly nothing wrong with doing that.</p>
<p>Perhaps worse than that argument is the attitude displayed in the above words. It‚Äôs very clear that the bar of ‚Äúthoroughly and rigorously proving‚Äù the chatbot to be doing more harm than good is one that no-one can meet. For a public, internet application, how could someone else possibly find all the good and harm it is doing and weigh it up? And why is the burden of proof that way round?</p>
<p>What this really demonstrates is an intention to carry on no matter what ‚Äì that whatever arguments or evidence he sees, nothing will make him change course. I hope that won‚Äôt be true in practice.</p>
</section><section id="updates"><h2><a href="#toc-entry-4" role="doc-backlink">Updates</a></h2>
<ul>
<li><p>2024-09-20 Various small clarifications and additions after initial publishing.</p></li>
<li><p>2024-09-23 Slightly expanded argument about moral responsibility</p></li>
</ul></section>
</div></article>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calm Tech Certification "Rewards" Less Distracting Tech (224 pts)]]></title>
            <link>https://spectrum.ieee.org/calm-tech</link>
            <guid>42780953</guid>
            <pubDate>Tue, 21 Jan 2025 15:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/calm-tech">https://spectrum.ieee.org/calm-tech</a>, See on <a href="https://news.ycombinator.com/item?id=42780953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Calm Tech Certification &quot;Rewards&quot; Less Distracting Tech"><p>The distractions of modern technology seem inescapable. Articles, social media posts, and academic studies frequently condemn the attention-grabbing qualities of our phones and laptops‚Äîironically, a problem we often read about and discuss on the very devices said to cause it.</p><p><a href="https://www.caseorganic.com/" target="_blank">Amber Case</a>, speaker and author of <a href="https://www.oreilly.com/library/view/calm-technology/9781491925874/" target="_blank">Calm Technology</a>, knows this all too well. ‚ÄúA lot of technology is not using our peripheral attention, but instead our primary attention, which makes it tiring and difficult to use it,‚Äù says Case. The much-maligned smartphone notification is a common example, bombarding the user with pop-ups seeking to redirect the user‚Äôs attention.</p><p>But observing a problem is just the first step. What comes next is deciding how to solve it, and the Calm Tech Institute, an organization founded by Case, has an idea.</p><h2>From Principles to Certification</h2><p>Case‚Äôs book, inspired by the work of <a href="https://calmtech.com/papers/coming-age-calm-technology" target="_blank">Xerox PARC researchers Mark Weiser and John Seely Brown</a>, outlines <a href="https://calmtech.com/papers/coming-age-calm-technology" rel="noopener noreferrer" target="_blank">eight principles for calm technology</a>; examples include the idea that technology ‚Äúshould require the smallest possible amount of attention‚Äù while in use, and that it ‚Äúshould work even when it fails.‚Äù The book‚Äôs ideas gained the attention of major technology companies, including <a href="https://spectrum.ieee.org/tag/microsoft">Microsoft</a> and <a href="https://spectrum.ieee.org/tag/amazon">Amazon</a>, and Case gave talks at TED and the Thinking Digital Conference, among others.</p><p>‚ÄúBut that wasn‚Äôt enough,‚Äù says Case. While her ideas received plenty of interest, she noticed that interest didn‚Äôt translate to concrete action. Companies designing new products were unclear on what was right, or wrong, and uncertain about how they might put calm technology ideals into practice. </p><p>So, Case decided on a new approach. She founded the Calm Tech Institute in May 2024 to develop and promote a Calm Tech certification. ‚ÄúA standard is a good way of rewarding that behavior,‚Äù says Case. </p><p>The certification includes 81 points that span six categories: attention, periphery, durability, light, sound, and materials. Some of the certification‚Äôs specifications are quite stringent. It outlines minimum standards for user interface (UI) design, such as consistent use of icons and font typography, asks that all but the ‚Äúmost crucial‚Äù notifications be turned off by default, and requires an instruction booklet with a list of replacements and compatible parts. </p><p><img alt="A person using a stylus to write on a sleek digital tablet whose touch screen resembles matte paper." data-rm-shortcode-id="d8a2590a09fc0cf265f843f1e7db5d77" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-person-using-a-stylus-to-write-on-a-sleek-digital-tablet-whose-touch-screen-resembles-matte-paper.jpg?id=55669767&amp;width=980" height="5504" id="84c25" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-person-using-a-stylus-to-write-on-a-sleek-digital-tablet-whose-touch-screen-resembles-matte-paper.jpg?id=55669767&amp;width=980" width="7339"><small placeholder="Add Photo Caption...">The Calm Tech certified reMarkable Paper Pro ditches distractions for a paper-like feel.</small><small placeholder="Add Photo Credit...">reMarkable AS</small></p><h2>Early Adopters Get on Board</h2><p>The first handful of devices that earned the Calm Tech certification were announced at, or just before, <a href="https://spectrum.ieee.org/tag/ces">CES</a> 2025.</p><p>This first batch included, for example, the <a href="https://remarkable.com/blog/remarkable-paper-pro-earns-calm-tech-certification" rel="noopener noreferrer" target="_blank">reMarkable Paper Pro</a>. Released on September 4, 2024, the Paper Pro looks like an iPad and has a <a href="https://spectrum.ieee.org/how-e-ink-developed-full-color-epaper" target="_blank">color eInk display</a>, but it‚Äôs tightly focused on writing and organizing notes with the tablet‚Äôs included stylus. ReMarkable purposefully constrains the device‚Äôs features to maintain a distraction-free experience. Though it can sync notes online, the Paper Pro doesn‚Äôt have an app store, a web browser, or widgets. It doesn‚Äôt even display the time. </p><p><a href="https://no.linkedin.com/in/matsherding" target="_blank">Mats Herding Solberg</a>, reMarkable‚Äôs chief design officer, wasn‚Äôt aware of the Calm Tech certification while the Paper Pro was designed, but once he learned of it, was pleased to find the tablet‚Äôs distraction-free approach matched up with the requirements.</p><p>‚ÄúWe found that many principles closely aligned with the intentions behind our design,‚Äù says Solberg. ‚ÄúThese principles will guide us in creating technology that aligns with humans.‚Äù </p><p>Another early adopter was Mui Labs, creator of the <a href="https://muilab.com/en/products_and_services/muiboard/" rel="noopener noreferrer" target="_blank">Mui Board</a>, a smart home device that looks like a piece of finely finished decorative wood but, when touched, illuminates to reveal a smart home interface. I spoke with Case at Mui Labs‚Äô booth on the show floor of CES 2025, where the company announced that its latest iteration, the Mui Board Gen 2, earned the Calm Tech certification. </p><p>Several other devices earned certification in late 2024. These include the <a href="https://www.airthings.com/en/view-plus" rel="noopener noreferrer" target="_blank">AirThings View Plus</a>, an air quality monitor with a simple eInk display <a href="https://spectrum.ieee.org/air-quality-easy-to-measure-tough-to-fix" target="_self">that I highlighted during the 2021 wildfire season</a>; the Daylight Computer, a portable PC with an eInk display and custom OS meant to reduce distractions; and <a href="https://www.unpluq.com/products/unpluq-tag" rel="noopener noreferrer" target="_blank">Unpluq</a>, a physical dongle that can lock apps on Android and iOS devices until the dongle is moved close to the device.</p><h2>Calm Tech Looks to Expand in 2025</h2><p>While the first products have received certification, it‚Äôs still early days for the Calm Tech Institute. The certification‚Äôs 81-point specification is not yet publicly available (though Case did provide a copy for me to review). The Calm Tech Institute hopes to have the certification published ‚Äúsoon,‚Äù says Case. It‚Äôs also exploring research into calm technology and working with neuroscientists to study the ‚Äúcognitive <a href="https://spectrum.ieee.org/touchscreens" target="_blank">need for dimensionality</a> and texture‚Äù in user interfaces. </p><p>‚ÄúBit by bit, I hope to influence the industry and reward it,‚Äù says Case.</p><p>ReMarkable, for its part, seems to appreciate the certification and will likely pursue the certification for its future products, according to Solberg. ‚ÄúI am hopeful that we will continue to deliver products that receive high praise from the Calm Tech Institute,‚Äù he says. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[0click deanonymization attack targeting Signal, Discord and other platforms (1086 pts)]]></title>
            <link>https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117</link>
            <guid>42780816</guid>
            <pubDate>Tue, 21 Jan 2025 14:59:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117">https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117</a>, See on <a href="https://news.ycombinator.com/item?id=42780816">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Unique 0-click deanonymization attack targeting Signal, Discord and hundreds of platform
  </p><div id="file-research-md" tabindex="0" role="region" aria-label="file-research-md">
    <article itemprop="text"><p dir="auto">hi, i'm daniel. i'm a 15-year-old high school junior. in my free time, i <a href="https://hackerone.com/daniel" rel="nofollow">hack billion dollar companies</a> and build cool stuff.</p>
<p dir="auto">3 months ago, I discovered a unique 0-click deanonymization attack that allows an attacker to grab the location of any target within a 250 mile radius. With a vulnerable app installed on a target's phone (or as a background application on their laptop), an attacker can send a malicious payload and deanonymize you within seconds--and you wouldn't even know.</p>
<p dir="auto">I'm publishing this writeup and research as a warning, especially for journalists, activists, and hackers, about this type of undetectable attack. Hundreds of applications are vulnerable, including some of the most popular apps in the world: Signal, Discord, Twitter/X, and others. Here's how it works:</p>
<p dir="auto"><h2 dir="auto">Cloudflare</h2><a id="user-content-cloudflare" aria-label="Permalink: Cloudflare" href="#cloudflare"></a></p>
<p dir="auto">By the numbers, Cloudflare is easily the most popular CDN on the market. It beats out competitors such as Sucuri, Amazon CloudFront, Akamai, and Fastly. In 2019, a major Cloudflare outage knocked most of the internet offline for over 30 minutes.</p>
<p dir="auto">One of Cloudflare's most used feature is Caching. Cloudflare's Cache stores copies of frequently accessed content (such as images, videos, or webpages) in its datacenters, reducing server load and improving website performance (<a href="https://developers.cloudflare.com/cache/" rel="nofollow">https://developers.cloudflare.com/cache/</a>).</p>
<p dir="auto">When your device sends a request for a resource that can be cached, Cloudflare retrieves the resource from its local datacenter storage, if available. Otherwise, it fetches the resource from the origin server, caches it locally, and then returns it. By default, <a href="https://developers.cloudflare.com/cache/concepts/default-cache-behavior/" rel="nofollow">some file extensions</a> are automatically cached but site operators can also configure new cache rules.</p>
<p dir="auto">Cloudflare has a vast global presence, with hundreds of datacenters in 330 cities across 120+ countries‚Äîan estimated 273% more datacenters than Google. In the U.S. East region, for example, the nearest datacenter to me is less than 100 miles. If you live in a developed country, there's a good chance the nearest datacenter to you is less than 200 miles from you.</p>
<p dir="auto">A few months ago, I had a lightbulb moment: if Cloudflare stores cached data so close to users, could this be exploited for deanonymization attacks on sites we don't control?</p>
<p dir="auto">You see, Cloudflare returns information about a request's cache status in the HTTP response.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404693583-95e1a39a-ed25-4531-9c57-a1b43c616519.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ2OTM1ODMtOTVlMWEzOWEtZWQyNS00NTMxLTljNTctYTFiNDNjNjE2NTE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MzA5ZTIyNTllOTI0MTJhOWRkY2ZlZDNhNDNkNzg1ODEwMjY0NDYwZDliNmNlZjllYmI4MGI4ZmNlNzIzNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.e9M92dBECy2m5CzJMyFp44ih3IZwDWegcPvRs65is4o"><img width="426" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404693583-95e1a39a-ed25-4531-9c57-a1b43c616519.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ2OTM1ODMtOTVlMWEzOWEtZWQyNS00NTMxLTljNTctYTFiNDNjNjE2NTE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MzA5ZTIyNTllOTI0MTJhOWRkY2ZlZDNhNDNkNzg1ODEwMjY0NDYwZDliNmNlZjllYmI4MGI4ZmNlNzIzNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.e9M92dBECy2m5CzJMyFp44ih3IZwDWegcPvRs65is4o"></a></p>
<p dir="auto"><code>cf-cache-status</code> can be <code>HIT</code>/<code>MISS</code> and <code>cf-ray</code> includes the airport code for the closest airport to the datacenter that handles the request (in my case, IAD).</p>
<p dir="auto">If we can get a user's device to load a resource on a Cloudflare-backed site, causing it to be cached in their local datacenter, we can then enumerate all Cloudflare datacenters to identify which one cached the resource. This would provide an incredibly precise estimate of the user's location.</p>
<p dir="auto"><h2 dir="auto">Cloudflare Teleport</h2><a id="user-content-cloudflare-teleport" aria-label="Permalink: Cloudflare Teleport" href="#cloudflare-teleport"></a></p>
<p dir="auto">There was a one major hurdle I had to get through before I tested this theory.</p>
<p dir="auto">You can't simply send HTTP requests to individual Cloudflare datacenters. For "security purposes" (presumably DDoS protection), all Cloudflare IP ranges are strictly anycast. All TCP connections opened to their network are always handled by the nearest available datacenter to you, there's no way you can ask a datacenter in Canada to handle your request if you live in the US.</p>
<p dir="auto">However, after some research, I found a forum post (<a href="https://community.cloudflare.com/t/how-to-run-workers-on-specific-datacenter-colos/385851" rel="nofollow">https://community.cloudflare.com/t/how-to-run-workers-on-specific-datacenter-colos/385851</a>) from a community member showing me exactly how. The author shared a bug he found to send requests to specific Cloudflare datacenters with Cloudflare Workers.</p>
<p dir="auto">I'm still not 100% sure of the specifics of this bug, but using an IP range used internally by Cloudflare WARP (Cloudflare's VPN client), we could ask certain datacenters to handle HTTP requests. Normally, this IP range blocked inbound connections from external IP addresses but requests sent from Workers could bypass this since the connection would originate from inside Cloudflare's network.</p>
<p dir="auto">I spent a few minutes reading their post and I quickly spined up a tool for this: Cloudflare Teleport (<a href="https://github.com/hackermondev/cf-teleport">https://github.com/hackermondev/cf-teleport</a>). Certain IP ranges corresponded to different datacenters (<a href="https://github.com/hackermondev/cf-teleport/blob/main/scripts/data/colos.json">https://github.com/hackermondev/cf-teleport/blob/main/scripts/data/colos.json</a>).</p>
<p dir="auto">Cloudflare Teleport is a proxy powered by Cloudflare Workers that redirects HTTP requests to specific datacenters. For example, <a href="https://cfteleport.xyz/?proxy=https://cloudflare.com/cdn-cgi/trace&amp;colo=SEA" rel="nofollow">https://cfteleport.xyz/?proxy=https://cloudflare.com/cdn-cgi/trace&amp;colo=SEA</a> would proxy a HTTP GET request to <a href="https://cloudflare.com/cdn-cgi/trace" rel="nofollow">https://cloudflare.com/cdn-cgi/trace</a> specifically to a Seattle (SEA) datacenter.</p>
<p dir="auto">Cloudflare would end up completely patching this bug a few months later, making this tool obsolete, but more on that later. For a majority of my initial, I used this tool.</p>

<p dir="auto">As soon as the Cloudflare Teleport tool was complete, I was able to confirm my theory. I coded a simple CLI program that would send an HTTP GET request to a specified URL and list all datacenters that had the resource cache and its age.</p>
<p dir="auto">For my first test, I used Namecheap's favicon (<a href="https://www.namecheap.com/favicon.ico" rel="nofollow">https://www.namecheap.com/favicon.ico</a>). This resource has Cloudflare Caching enabled, it's just a simple static image of their logo. (This was the quickest site I could find that didn't have rigorous bot protection):</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404707140-8da57801-ae8e-4adf-9a2e-ec6feec6086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ3MDcxNDAtOGRhNTc4MDEtYWU4ZS00YWRmLTlhMmUtZWM2ZmVlYzYwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMTg5NmFkNTE1YWNkYWRjZjkyNDQzOWQ1NjYxNTBmNGVhMDRhNDUxMDMwOWI1MTY4MDU3Yzc1OWY5NzhkYzgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.989wnEI06vGtQEebz7AttCKWthW036QkaEc_6BThozE"><img width="814" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404707140-8da57801-ae8e-4adf-9a2e-ec6feec6086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ3MDcxNDAtOGRhNTc4MDEtYWU4ZS00YWRmLTlhMmUtZWM2ZmVlYzYwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMTg5NmFkNTE1YWNkYWRjZjkyNDQzOWQ1NjYxNTBmNGVhMDRhNDUxMDMwOWI1MTY4MDU3Yzc1OWY5NzhkYzgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.989wnEI06vGtQEebz7AttCKWthW036QkaEc_6BThozE"></a>
<p dir="auto">Boom, it worked. Namecheap had configured their cache age extremely low (5 minutes) but I was able to see every datacenter that had cached the their site's favicon in the last 5 minutes. Since everytime you load their site, your browser automatically downloads this favicon, this means a user from each one of this locations has visited the Namecheap.com site within the 5 minutes with the last visit from Tokyo, Japan.</p>
<p dir="auto">This was just meant to be a simple test and there's almost no impact here, but with this I confirmed my theory. This proved the concept of using Cloudflare caching for deanonymization attacks.</p>
<p dir="auto"><h2 dir="auto">Real-World Application: Signal</h2><a id="user-content-real-world-application-signal" aria-label="Permalink: Real-World Application: Signal" href="#real-world-application-signal"></a></p>
<p dir="auto">Signal, an open-source encrypted messaging service, is widely used by journalists and activists for its privacy features. Internally, the app utilizes two CDNs for serving content: <code>cdn.signal.org</code> (powered by CloudFront) for profile avatars and <code>cdn2.signal.org</code> (powered by Cloudflare) for message attachments.</p>
<p dir="auto"><h2 dir="auto">1-Click Attack</h2><a id="user-content-1-click-attack" aria-label="Permalink: 1-Click Attack" href="#1-click-attack"></a></p>
<p dir="auto">When a user sends an attachment (e.g., an image) on Signal, it is uploaded to cdn2.signal.org. Once the recipient opens the conversation, their device automatically downloads the attachment. Since Cloudflare caching is enabled for these URLs, an attacker can use the cache geolocation method to pinpoint the recipient‚Äôs location.</p>
<p dir="auto">The <code>https://cdn2.signal.org/attachments/*</code> path is configured to cache responses with Cloudflare. This means once a user's device automatically downloads an attachment, it's possible for an attacker to run a cache geolocation attack to find out which local datacenter they're near--similar to how law enforcement track mobile devices through cell phone towers.</p>
<p dir="auto">To test this, I quickly patched the Signal desktop app to remove SSL pinning and configured Burp to intercept and view HTTP requests/responses sent through the app.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404890145-51dd8b7c-375c-4bd1-936c-54c338fe6620.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTAxNDUtNTFkZDhiN2MtMzc1Yy00YmQxLTkzNmMtNTRjMzM4ZmU2NjIwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFiMDg2MmI0OTA4YzBkNWY3NDU5NDkwNTA2ODIyZmI5YzlmMWEyN2Y1OGIzZWQ3NDg0NDZjNzIyZTgxODAyZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.eBAHOyF4bJL0whN1rHtq9KaXDMZGytUuY5UIyIomcLQ"><img width="700" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404890145-51dd8b7c-375c-4bd1-936c-54c338fe6620.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTAxNDUtNTFkZDhiN2MtMzc1Yy00YmQxLTkzNmMtNTRjMzM4ZmU2NjIwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFiMDg2MmI0OTA4YzBkNWY3NDU5NDkwNTA2ODIyZmI5YzlmMWEyN2Y1OGIzZWQ3NDg0NDZjNzIyZTgxODAyZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.eBAHOyF4bJL0whN1rHtq9KaXDMZGytUuY5UIyIomcLQ"></a></p>
<p dir="auto"><h3 dir="auto">Reproduction Steps</h3><a id="user-content-reproduction-steps" aria-label="Permalink: Reproduction Steps" href="#reproduction-steps"></a></p>
<p dir="auto"><h4 dir="auto">1. Block HTTP GET requests to <code>cdn2.signal.org/attachments/*</code> in from the Signal using Burp.</h4><a id="user-content-1-block-http-get-requests-to-cdn2signalorgattachments-in-from-the-signal-using-burp" aria-label="Permalink: 1. Block HTTP GET requests to cdn2.signal.org/attachments/* in from the Signal using Burp." href="#1-block-http-get-requests-to-cdn2signalorgattachments-in-from-the-signal-using-burp"></a></p>
<p dir="auto">This ensures that the app doesn't download attachments uploaded from the our side (the attacker) since that would cache them to our local datacenter and pollute the results. The best way I found to do this with Burp is to configure intercept rules for attachments, then leave request intercept on and deny all requests.
<br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404891288-20a99d9c-ea9e-453d-85b6-13bb8482061e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTEyODgtMjBhOTlkOWMtZWE5ZS00NTNkLTg1YjYtMTNiYjg0ODIwNjFlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3N2ZjNzc1NWFmZjZhOTdmNWQ3MjE4YjYxNWJkZDUwZGIzMGY3M2I2ZjM2YjEzZWU5NGRhODRmMmIxMjc3MWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pa9g5nqedvL0cahQeMgbsNpRefoBYRycSjH_nICs6Og"><img width="809" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404891288-20a99d9c-ea9e-453d-85b6-13bb8482061e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTEyODgtMjBhOTlkOWMtZWE5ZS00NTNkLTg1YjYtMTNiYjg0ODIwNjFlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3N2ZjNzc1NWFmZjZhOTdmNWQ3MjE4YjYxNWJkZDUwZGIzMGY3M2I2ZjM2YjEzZWU5NGRhODRmMmIxMjc3MWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pa9g5nqedvL0cahQeMgbsNpRefoBYRycSjH_nICs6Og"></a></p>
<p dir="auto"><h4 dir="auto">2. Send an attachment (image) to a target.</h4><a id="user-content-2-send-an-attachment-image-to-a-target" aria-label="Permalink: 2. Send an attachment (image) to a target." href="#2-send-an-attachment-image-to-a-target"></a></p>
<p dir="auto">This should work with any attachment but images are automatically downloaded when the user opens the conversation so they work best. I used a simple 1x1.png image for this test. The upload request is sent to Signal's CDN and you can see the attachment url in Burp once we send the attachment in the conversation and Signal uploads it (ex. <a href="https://cdn2.signal.org/attachments/UjLld11tvaL16M8mrd86" rel="nofollow">https://cdn2.signal.org/attachments/UjLld11tvaL16M8mrd86</a>).
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405260342-66b4c6f4-3617-4b79-9612-89a90aa7690c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUyNjAzNDItNjZiNGM2ZjQtMzYxNy00Yjc5LTk2MTItODlhOTBhYTc2OTBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRjZmQ3NzNkZDZhYWI2MTFlODU0Mjc4MjlhMTU2ZDI5ZWMxYjJhMjhmYWFmZDc5MDk1MmYxZjEyYmFiM2IzNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.tcwILTspTfoXNqLWwnfH9S6uhhub0ydVOg6Dn-5KpBo"><img src="https://private-user-images.githubusercontent.com/60828015/405260342-66b4c6f4-3617-4b79-9612-89a90aa7690c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUyNjAzNDItNjZiNGM2ZjQtMzYxNy00Yjc5LTk2MTItODlhOTBhYTc2OTBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRjZmQ3NzNkZDZhYWI2MTFlODU0Mjc4MjlhMTU2ZDI5ZWMxYjJhMjhmYWFmZDc5MDk1MmYxZjEyYmFiM2IzNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.tcwILTspTfoXNqLWwnfH9S6uhhub0ydVOg6Dn-5KpBo" alt="image"></a></p>
<p dir="auto"><h4 dir="auto">3. Attack</h4><a id="user-content-3-attack" aria-label="Permalink: 3. Attack" href="#3-attack"></a></p>
<p dir="auto">After the targets opens the conversation (verify this with read recipts), their device should download the attachment which in turn causes Cloudflare to cache the file in a local datacenter.</p>
<p dir="auto">I ran this attack on myself, used the CLI tool I mentioned earlier with the attachment url and found local datacenters that had cached the attachment.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404906566-1ae6102d-263e-4af6-9073-f3665589d753.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5MDY1NjYtMWFlNjEwMmQtMjYzZS00YWY2LTkwNzMtZjM2NjU1ODlkNzUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM3MzRlMTNiMWExMmU5N2JjOWY1OGMxOWI4MTJkMTQ5MjJiZmE4MGNlZDQyZjVhMmVjZTVkMTEwNTcyNGZhYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aqJ5KDc4E8LRYcM7AT0B7oV5qMGz5Ee5TfhQFFYzcDk"><img width="927" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404906566-1ae6102d-263e-4af6-9073-f3665589d753.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5MDY1NjYtMWFlNjEwMmQtMjYzZS00YWY2LTkwNzMtZjM2NjU1ODlkNzUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM3MzRlMTNiMWExMmU5N2JjOWY1OGMxOWI4MTJkMTQ5MjJiZmE4MGNlZDQyZjVhMmVjZTVkMTEwNTcyNGZhYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aqJ5KDc4E8LRYcM7AT0B7oV5qMGz5Ee5TfhQFFYzcDk"></a>
<p dir="auto">In my case, I'm in New York and one of the closest datacenters to me is Newark, NJ (EWR) which is about 150 miles from my actual coordinates.</p>
<p dir="auto">With an innocent-looking attachment, an attacker can deanonymize users and find their location within an approximate radius.</p>
<p dir="auto"><h2 dir="auto">0-click</h2><a id="user-content-0-click" aria-label="Permalink: 0-click" href="#0-click"></a></p>
<p dir="auto">Here's where things get interesting. Although the 1-click method works, it requires the user to open the Signal conversation. Is it possible to run this attack without a single user interaction? Enter push notifications.</p>
<p dir="auto"><h3 dir="auto">Push Notifications</h3><a id="user-content-push-notifications" aria-label="Permalink: Push Notifications" href="#push-notifications"></a></p>
<p dir="auto">Signal's mobile app has 3 push notification settings. <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404989825-fed86790-9915-43a2-9d8b-18a7e5edef62.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5ODk4MjUtZmVkODY3OTAtOTkxNS00M2EyLTlkOGItMThhN2U1ZWRlZjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM5NjhmNTEzMTdmMGY1M2JlYjA5ZDU5MDM5NzdhNmYyMGM2MTBlNjEwMWUyMjBkZTQwODI3ZDU0MmEyOTEzMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.h80OARR8R2LhuMFTFkSnMEKtoqZiVMqsv6OgHhYAktU"><img width="400" src="https://private-user-images.githubusercontent.com/60828015/404989825-fed86790-9915-43a2-9d8b-18a7e5edef62.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5ODk4MjUtZmVkODY3OTAtOTkxNS00M2EyLTlkOGItMThhN2U1ZWRlZjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM5NjhmNTEzMTdmMGY1M2JlYjA5ZDU5MDM5NzdhNmYyMGM2MTBlNjEwMWUyMjBkZTQwODI3ZDU0MmEyOTEzMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.h80OARR8R2LhuMFTFkSnMEKtoqZiVMqsv6OgHhYAktU"></a></p>
<p dir="auto">Push Notifications are triggered if the user receives a message while not actively on the Signal app. By default, the mobile app includes the author, and message when it sends a push notification to your device. <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404992822-f33a0364-9119-4634-ae0b-4d3af7ee53db.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTI4MjItZjMzYTAzNjQtOTExOS00NjM0LWFlMGItNGQzYWY3ZWU1M2RiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ3NjhkZTA3M2U5NjRkNDVhYzgwNDJkNmE5ODU1YTQ5OTY1Njc1OWYwYjRiZjQ2ZjMzMzBjZGNiZTFjZTFhMzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lbiey-lyN-KPKMBXZp7Oxw-xAlyGRDtd5T5mUKivu1c"><img width="612" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404992822-f33a0364-9119-4634-ae0b-4d3af7ee53db.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTI4MjItZjMzYTAzNjQtOTExOS00NjM0LWFlMGItNGQzYWY3ZWU1M2RiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ3NjhkZTA3M2U5NjRkNDVhYzgwNDJkNmE5ODU1YTQ5OTY1Njc1OWYwYjRiZjQ2ZjMzMzBjZGNiZTFjZTFhMzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lbiey-lyN-KPKMBXZp7Oxw-xAlyGRDtd5T5mUKivu1c"></a></p>
<p dir="auto">The image shown on the right of the notification is the attachment sent with the message from Signal.</p>
<p dir="auto">If the target has push notifications enabled (which it is by default), they don't even have to open the Signal conversation for their device to download the attachment. Once the push notification is sent to their device, it automatically downloads the image from Signal's CDN triggering the local datacenter to cache the response.</p>
<p dir="auto">An attacker can run this deanonymization attack any time and grab a user's current location without a single interaction.</p>
<hr>
<p dir="auto">Signal, like Telegram, is used by journalists, activists, whisteblowers from all over the world. The potiental for this attack is massive. This attack can be used to track Signal accounts, correlate identities, find employees meeting with journalists and much more.</p>
<p dir="auto"><h2 dir="auto">Real-World Application: Discord</h2><a id="user-content-real-world-application-discord" aria-label="Permalink: Real-World Application: Discord" href="#real-world-application-discord"></a></p>
<p dir="auto">During my research, another app I found vulnerable to this type of attack is Discord. Discord is a free app that allows users to communicate with each other through text, voice, and video. Although the app is targeted towards gamers, Discord has been in the news recently this past year for facilitating government leaks and Discord hosts a significant portion of cybercrime on the internet.</p>
<p dir="auto">The 1-click aspect is very simple and fairly similar to Signal, I would say the impact is even wider with Discord. Discord allows users with a Nitro subscription (their $9.99/mo premium service) to use custom emojis in a variety of places: Messages, User Presence, Channels, etc. These custom emojis are loaded from Discord's CDN and are configured to be cached on Cloudflare. An attacker can use the same deanonymization attack with Signal to deanonymize users.</p>
<p dir="auto">So, instead of sending an attachment in a Discord channel, an attacker can display a custom emoji in their user status and simply wait for the target to open their profile to run a deanonymization attack.</p>
<p dir="auto">I've disclosed the <a href="https://gist.github.com/hackermondev/7d9ae6b372159de7b9d3d7bb82a32ed2">entire HackerOne report</a> I sent to Discord which has specific details, but I want to focus on the 0-click aspect here.</p>
<p dir="auto">In Discord, mobile push notifications are sent for a variety of events (not just for messages recieved like Signal). For example, sending a friend request to a Discord user triggers a push notification on the user's mobile device.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404999739-6a013d85-1c4c-406d-8638-e77430a7c723.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTk3MzktNmEwMTNkODUtMWM0Yy00MDZkLTg2MzgtZTc3NDMwYTdjNzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlYzQ2MmZhMjgwNmJiNDRlY2Y2MTNhYTBlYTA0MzdmOWJhMzcxMGRjZTcwMjgxZTBmNjJiMGU3MjdjMmUyODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.JyXivn4opt3kZQVE1z18r16bmpRTMyHGKB8m_3daXT8"><img src="https://private-user-images.githubusercontent.com/60828015/404999739-6a013d85-1c4c-406d-8638-e77430a7c723.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTk3MzktNmEwMTNkODUtMWM0Yy00MDZkLTg2MzgtZTc3NDMwYTdjNzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlYzQ2MmZhMjgwNmJiNDRlY2Y2MTNhYTBlYTA0MzdmOWJhMzcxMGRjZTcwMjgxZTBmNjJiMGU3MjdjMmUyODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.JyXivn4opt3kZQVE1z18r16bmpRTMyHGKB8m_3daXT8" alt="image"></a></p>
<p dir="auto">Interestingly, even if the user is actively on Discord, friend request notifications are always sent to the user's mobile device.</p>
<p dir="auto">How would a deanonymization attack be used with a friend request notification? Well, take a look at the notification.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405000417-4eaa5e0e-4ebf-4e43-98ca-029ec7dd6591.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDA0MTctNGVhYTVlMGUtNGViZi00ZTQzLTk4Y2EtMDI5ZWM3ZGQ2NTkxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg5MDVkMDU3MjUyNGNmMTlmZDI2YjQyMTU0MjdiNjI4OTA5NzQ3MDdkMTU4ZDE3YTdhYmEwOWIwOTYzMDY5ZWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AkBWRoah9wcRf1WhHcSFOh2g5lZ_S-YVB2TnHdBR0Ls"><img src="https://private-user-images.githubusercontent.com/60828015/405000417-4eaa5e0e-4ebf-4e43-98ca-029ec7dd6591.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDA0MTctNGVhYTVlMGUtNGViZi00ZTQzLTk4Y2EtMDI5ZWM3ZGQ2NTkxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg5MDVkMDU3MjUyNGNmMTlmZDI2YjQyMTU0MjdiNjI4OTA5NzQ3MDdkMTU4ZDE3YTdhYmEwOWIwOTYzMDY5ZWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AkBWRoah9wcRf1WhHcSFOh2g5lZ_S-YVB2TnHdBR0Ls" alt="image"></a></p>
<p dir="auto">When you recieve a friend request and Discord sends the notification to your device, it includes the user's avatar url to be shown with the notification. Your phone downloads the avatar url (without any user interaction) and displays it alongside the notification.</p>
<p dir="auto">Discord has Cloudflare caching configured on the CDN path for avatar urls, which means we can simply do the same cache location attack mentioned earlier.</p>
<p dir="auto">In Discord, the avatar URL format used in push notifications is: <code>https://cdn.discordapp.com/avatars/{user_id}/{avatar_hash}</code>. The avatar URL format used in the website to display user avatars is slightly different (it always contains an image extension) (<code>https://cdn.discordapp.com/avatars/{user_id}/{avatar_hash}.png</code>).</p>
<p dir="auto">Both URLs leads to the same image but since images displayed in the app have a different path, they're cached separately. This ensures our results are not polluted and allows us to ensure we are finding the datacenter of a device that loaded the avatar through a push notification and not just the profile on the Discord app.</p>
<p dir="auto">Just like that, we have the steps for a 0-click version of this attack for Discord:</p>
<ol dir="auto">
<li>Change your user avatar. This randomizes your avatar hash and ensures your avatar URL has not been loaded by anyone yet, increasing the accuracy of the attack.</li>
<li>Send a friend request to the target. Although there's a variety of ways to trigger push notifications with Discord, I choose friend requests because they are always sent regardless of whether the user is active on Discord. They also don't require any mutual server with the target, meaning you can practically do this with anyone on Discord.</li>
<li>Use Cloudflare Teleport tool on the user avatar and find all local datacenters that have cached the avatar</li>
</ol>
<p dir="auto"><h2 dir="auto">GeoGuesser</h2><a id="user-content-geoguesser" aria-label="Permalink: GeoGuesser" href="#geoguesser"></a></p>
<p dir="auto">I'm very familar with Discord's API and I realized I could automate every step in Discord's 0-click attack, and so I did.</p>
<p dir="auto">Introducing GeoGuesser. This is a private Discord bot with a single command that takes a username, runs an attack with the steps mentioned earlier and returns the result entirely through Discord.</p>
<p dir="auto">When the command is called, it uses my account credentials to access the Discord User API, changes the user avatar to a randomly generated image (to randomize the hash) and sends a friend request to a username specified.
Finally, it uses a private API based on the Cloudflare Teleport CLI to run the same cache enumeration attack and displays the results directly on Discord, all in less than 30 seconds.</p>
<p dir="auto">To show the extent of this attack, one of the first users I tried this attack on was Stanislav Vishnevskiy, Discord's CTO.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405007407-66914f42-880b-4d23-8902-3cb2f3170118.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDc0MDctNjY5MTRmNDItODgwYi00ZDIzLTg5MDItM2NiMmYzMTcwMTE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlOTIyODA2MTNkMWIzMTY1MTI2NmE2YTEzODEyNTJmYzMyNTUyNjM2ZTZiMWJiNDMyMmFmMDNmMDcyNjZkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.FwgvcrMsd6ou856NncFAvDFRelAEfJ44nF469sXsIeI"><img width="400" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405007407-66914f42-880b-4d23-8902-3cb2f3170118.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDc0MDctNjY5MTRmNDItODgwYi00ZDIzLTg5MDItM2NiMmYzMTcwMTE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlOTIyODA2MTNkMWIzMTY1MTI2NmE2YTEzODEyNTJmYzMyNTUyNjM2ZTZiMWJiNDMyMmFmMDNmMDcyNjZkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.FwgvcrMsd6ou856NncFAvDFRelAEfJ44nF469sXsIeI"></a></p>
<p dir="auto">Here's the bot in action:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e6c10bf50e18f41533bdaa12626f2eb3ceb6644d65f4f11776311a454c3daa69/68747470733a2f2f6e696e6a612e646f672f4b556971684a2e676966"><img src="https://camo.githubusercontent.com/e6c10bf50e18f41533bdaa12626f2eb3ceb6644d65f4f11776311a454c3daa69/68747470733a2f2f6e696e6a612e646f672f4b556971684a2e676966" alt="geogueser live gif" data-animated-image="" data-canonical-src="https://ninja.dog/KUiqhJ.gif"></a></p>
<p dir="auto">The bot sends a friend request to Stan, then waits a couple of seconds to ensure he receives the push notification.</p>
<p dir="auto">It finds 2 local Cloudflare datacenters that have cached the avatar. This could mean he has multiple devices hooked up with his Discord account that recieved the push notification, or his device loaded the avatar twice and the requests were load balanced within different datacenters.</p>
<p dir="auto">GeoGuesser, powered by the Google Maps API, generates a likely location of the user. It finds the midpoint between the 2 datacenters and draws 2 circles that signify his radius.</p>
<p dir="auto">Discord's HQ is located in San Francisco, CA (which is in the outer circle) so this map is accurate. Stan is most likely located somewhere near the edge of the inner circle which is about ~300 miles.</p>
<p dir="auto">This entire process took less than a minute to run. I'm sure Stan saw the notification on his phone, didn't think twice and simply dismissed it. This was just a simple attack but this attack, if calibrated, can be used to track and monitor Stan's location.</p>
<p dir="auto">An attacker like this can be launched on any Discord user and it's almost undetectable.</p>
<p dir="auto"><h2 dir="auto">Bug Bounty Reports</h2><a id="user-content-bug-bounty-reports" aria-label="Permalink: Bug Bounty Reports" href="#bug-bounty-reports"></a></p>
<p dir="auto">I responsibly disclosed to the affected parties my research, hoping something would be done to protect or warn users against this type of deanonymization attack but I was mostly disappointed.</p>
<p dir="auto"><h3 dir="auto">Signal</h3><a id="user-content-signal" aria-label="Permalink: Signal" href="#signal"></a></p>
<p dir="auto">Signal instantly dismissed my report, saying it wasn't their responsibility and it was up to users to hide their identity: "Signal has never attempted to fully replicate the set of network-layer anonymity features that projects like Wireguard, Tor, and other open-source VPN software can provide".</p>
<p dir="auto">I disagree with this. Signal markets itself as a privacy-first communication platform. While it does not claim to provide network-layer anonymity like Tor, users trust Signal to minimize privacy risks.</p>
<p dir="auto">The vulnerability demonstrates that the platform unintentionally leaks information that could narrow down a user‚Äôs location within a few hundred miles. This leakage conflicts with the expectations of many privacy-conscious users who rely on Signal for more than just end-to-end encryption.</p>
<p dir="auto">Telegram, another privacy-focused application, is completely invulnerable to this attack as (1) they use a custom in-house built protocol thats not reliant on HTTP and (2) don't rely on cloud providers like Cloudflare for caching.</p>
<p dir="auto"><h3 dir="auto">Discord</h3><a id="user-content-discord" aria-label="Permalink: Discord" href="#discord"></a></p>
<p dir="auto">Initially, Discord's Security Team promised to look into this and make changes to protect their users against this type of attack but eventually they also changed their position on this, citing this as a Cloudflare issue other consumers are also vulnerable to.</p>
<p dir="auto"><h3 dir="auto">Cloudflare</h3><a id="user-content-cloudflare-1" aria-label="Permalink: Cloudflare" href="#cloudflare-1"></a></p>
<p dir="auto">Cloudflare ended up completing patching the bug used by Cloudflare Teleport to traverse datacenters. The bug had been reported to their HackerOne program a year ago by another reporter, but they hadn't done anything about it back then since they didn't see any impact of traversing datacenters until I shared my research.</p>
<p dir="auto">Cloudflare reopened the old report, resolved it and awarded a bounty to my report and the original.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405028347-30568091-c856-4dc8-a70d-335acf70f397.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMjgzNDctMzA1NjgwOTEtYzg1Ni00ZGM4LWE3MGQtMzM1YWNmNzBmMzk3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkzZjZjODRlYzEwM2EzZGRmYzZlMzk4NjMwNjdhMThjMjkwMGQ4ZDcxY2M5NDJiMDk2NDU5ZDBkYTBmMTRkYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NbJ0Q0iSGzpE42l94hAD_q5Tmq-AyQdSvsmTIYuj1JA"><img width="681" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405028347-30568091-c856-4dc8-a70d-335acf70f397.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMjgzNDctMzA1NjgwOTEtYzg1Ni00ZGM4LWE3MGQtMzM1YWNmNzBmMzk3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkzZjZjODRlYzEwM2EzZGRmYzZlMzk4NjMwNjdhMThjMjkwMGQ4ZDcxY2M5NDJiMDk2NDU5ZDBkYTBmMTRkYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NbJ0Q0iSGzpE42l94hAD_q5Tmq-AyQdSvsmTIYuj1JA"></a></p>
<p dir="auto">Although this is a step in the right direction, this doesn't actually fix the core issue here. Every attack shown in this write up has been done in the last 24 hours even though Cloudflare patched this bug weeks ago. Cloudflare patched the bug inside their network that facilitated datacenter traversal, but that's not the only way to easilly traverse datacenters all over the world.</p>
<p dir="auto">24 hours after their patch, I reprogrammed Cloudflare Teleport to use a VPN instead. Numerous VPNs provide multiple locations that users can connect to which sends their traffic through servers in different parts of the world and these servers map to different Cloudflare datacenters all over the world.</p>
<p dir="auto">I chose a VPN provider with over 3,000 servers located in various locations across 31 different countries worldwide. Using this new method, I'm able to reach about 54% of all Cloudflare datacenters again. While this doesn't sound like a lot, this covers most places in the world with significant population.</p>
<hr>
<p dir="auto">Cloudflare's final statement about this says they do not consider the deanonymization attack to be a vulnerability in their own systems and it is up to their consumers to disable caching for resources they wish to protect.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405032649-da8cd7ea-2c28-444c-af4e-3fc51fa14f92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMzI2NDktZGE4Y2Q3ZWEtMmMyOC00NDRjLWFmNGUtM2ZjNTFmYTE0ZjkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk4MWYwMWY4YWJjYTYwNWUxZmQzNDQwYTA5ODJlODIyZGNlNjFiY2FmOWU3OGI3MzYxMDIwYjM2NGZhM2RkZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NoMiKhLXuiig4kXDaEujpZzZYrujjBl7lJUkkEnxUSU"><img width="889" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405032649-da8cd7ea-2c28-444c-af4e-3fc51fa14f92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMzI2NDktZGE4Y2Q3ZWEtMmMyOC00NDRjLWFmNGUtM2ZjNTFmYTE0ZjkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk4MWYwMWY4YWJjYTYwNWUxZmQzNDQwYTA5ODJlODIyZGNlNjFiY2FmOWU3OGI3MzYxMDIwYjM2NGZhM2RkZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NoMiKhLXuiig4kXDaEujpZzZYrujjBl7lJUkkEnxUSU"></a></p>
<p dir="auto">There's clearly a problem here as Cloudflare says consumers are responsible for protecting themselves against these types of attacks, while consumers (ex. Discord) are putting the blame on Cloudflare.</p>
<p dir="auto"><h2 dir="auto">How to Protect Yourself</h2><a id="user-content-how-to-protect-yourself" aria-label="Permalink: How to Protect Yourself" href="#how-to-protect-yourself"></a></p>
<p dir="auto">The potential for exploitation using this deanonymization attack is significant, especially for users in sensitive positions like journalists, activists, and privacy-conscious individuals. The attack leverages fundamental design decisions in caching and push notification systems, demonstrating how infrastructure meant to enhance performance can be misused for invasive tracking.</p>
<p dir="auto">Although Cloudflare has patched the Teleport bug, and some applications like Discord and Signal may have implemented mitigation measures following my disclosure, the underlying risks remain. Any app using a CDN for content delivery and caching can still be vulnerable if the proper precautions aren‚Äôt taken.</p>
<p dir="auto"><h2 dir="auto">Final Thought</h2><a id="user-content-final-thought" aria-label="Permalink: Final Thought" href="#final-thought"></a></p>
<p dir="auto">This attack highlights how complex and interconnected the digital ecosystem has become. While CDNs improve performance and scalability, they also inadvertently introduce risks that can be exploited in novel ways. By raising awareness and promoting best practices, we can work together to minimize the potential for abuse.</p>
<p dir="auto">For users in sensitive roles or those concerned about their privacy, the key takeaway is this: stay informed and vigilant. While no system is entirely foolproof, taking steps to limit your exposure can make a significant difference.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Metacognitive laziness: Effects of generative AI on learning motivation (289 pts)]]></title>
            <link>https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544</link>
            <guid>42780022</guid>
            <pubDate>Tue, 21 Jan 2025 13:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544">https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544</a>, See on <a href="https://news.ycombinator.com/item?id=42780022">Hacker News</a></p>
Couldn't get https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Organize local communities without Facebook? (353 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42779776</link>
            <guid>42779776</guid>
            <pubDate>Tue, 21 Jan 2025 13:19:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42779776">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42779776: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA['It's a nightmare': couriers mystified by the algorithms that control their jobs (182 pts)]]></title>
            <link>https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs</link>
            <guid>42779544</guid>
            <pubDate>Tue, 21 Jan 2025 12:51:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs">https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs</a>, See on <a href="https://news.ycombinator.com/item?id=42779544">Hacker News</a></p>
Couldn't get https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[People are bad at reporting what they eat. That's a problem for dietary research (251 pts)]]></title>
            <link>https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research</link>
            <guid>42779147</guid>
            <pubDate>Tue, 21 Jan 2025 11:54:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research">https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research</a>, See on <a href="https://news.ycombinator.com/item?id=42779147">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Printercow ‚Äì Turn any thermal printer into an API endpoint (118 pts)]]></title>
            <link>https://www.printercow.com/</link>
            <guid>42778771</guid>
            <pubDate>Tue, 21 Jan 2025 11:06:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.printercow.com/">https://www.printercow.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42778771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-cieln4ax=""> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">What about pricing?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
Right now, everyone gets 300 free prints per month during
                    our beta to explore and create. For the post-beta phase, I'm
                    still figuring out the details, but I'm leaning towards a
                    simple pay-what-you-use model with a generous free monthly
                    allowance. I built Printercow because I genuinely love
                    seeing people get creative with thermal printers, so
                    maintaining a substantial free tier is important to me. If
                    you have thoughts on pricing or what would work best for
                    your use case, I'd love to hear them! The main goal is to
                    keep Printercow accessible for hobbyists and creators while
                    making it sustainable for everyone. You can always reach me
                    at <a href="mailto:hello@printercow.com" data-astro-cid-cieln4ax="">hello@printercow.com</a> or on X at <a href="https://x.com/printercow_com" target="_blank" data-astro-cid-cieln4ax="">@printercow_com</a> in case you need more prints or have special requirements.
</p> </div> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">What printer brands are supported?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
Any thermal printer that works with ESC/POS commands ‚Äì
                    including Epson, Star Micronics, Bixolon, and more.
</p> </div> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">Can I customize the paper width?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
Yes, Printercow supports any paper width from 58mm to 112mm.
                    Just specify it in your HTTP request.
</p> </div> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">How do I handle images/logos?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
Send base64 encoded images in your HTTP request. We handle
                    scaling and dithering automatically.
</p> </div> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">Is there a rate limit for printing?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
No rate limits (for now). Print as fast as your hardware
                    allows. Typical throughput is 30-60 receipts per minute.
</p> </div> <div data-astro-cid-cieln4ax=""> <div onclick="this.closest('.question').classList.toggle('active')" data-astro-cid-cieln4ax=""> <h3 data-astro-cid-cieln4ax="">How long do you store my print data?</h3> <p><img src="https://www.printercow.com/plus-cross.svg" alt="Toggle answer" data-astro-cid-cieln4ax=""> </p></div> <p data-astro-cid-cieln4ax="">
Print data is automatically deleted after 30 days. This
                    gives you enough time to debug issues or reprint something
                    if needed, while still keeping data storage minimal. Of
                    course, you can set your own data retention policy in your
                    settings. I chose 30 days because it feels like a good
                    balance between practicality and privacy.
</p> </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Startup Winter: Hacker News Lost Its Faith (485 pts)]]></title>
            <link>https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/</link>
            <guid>42778266</guid>
            <pubDate>Tue, 21 Jan 2025 10:00:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/">https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/</a>, See on <a href="https://news.ycombinator.com/item?id=42778266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>In 2013, a failing founder posted their story on Hacker News (<a href="https://news.ycombinator.com/item?id=5255209">link</a>). The responses were overwhelmingly supportive: "Failure is just an event, not who you are." "Get back up and try again!" "This is valuable experience for next time."</p>
<p>Fast forward to 2025. Another founder shares their journey of six failed attempts (<a href="https://news.ycombinator.com/item?id=42771676">link</a>). The sentiment in the comments is strikingly different: "Would have been better to work at BigTech." "The rat race isn't worth it." "Most interesting stories remain buried while we're presented with a somewhat skewed reality."</p>
<p>This shift isn't isolated to these two posts. The same forum that championed "fail fast, fail often" now regularly questions whether the startup path makes sense at all.</p>
<p>What's changed?</p>
<ol>
<li>
<p>The human cost has become more visible. Stories of burnout, failed relationships, and mental health struggles are no longer swept under the rug of "hustle culture."</p>
</li>
<li>
<p>Big Tech compensation has transformed the risk-reward equation. When senior engineers can make $300K+ at established companies, the financial argument for startups becomes harder to justify.</p>
</li>
<li>
<p>The VC model's limitations have become apparent. The focus on hypergrowth and exits has left many founders feeling trapped between authentic business building and investor expectations.</p>
</li>
<li>
<p>The industry has matured. The low-hanging fruit of the mobile/web era has largely been picked, making truly innovative opportunities harder to find.</p>
</li>
</ol>
<p>I believe we're entering what might be called a "Startup Winter" - not because startups have stopped being created, but because the mythology around them has frozen over.</p>
<p>What might emerge from this winter could be a startup ecosystem that's less glamorous but more authentic. One where alternative paths to innovation are celebrated alongside the traditional VC-backed route.</p>

<!-- #comments -->

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Censoring '#Democrat' on Instagram (250 pts)]]></title>
            <link>https://mstdn.chrisalemany.ca/@chris/113864600222476627</link>
            <guid>42777938</guid>
            <pubDate>Tue, 21 Jan 2025 09:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mstdn.chrisalemany.ca/@chris/113864600222476627">https://mstdn.chrisalemany.ca/@chris/113864600222476627</a>, See on <a href="https://news.ycombinator.com/item?id=42777938">Hacker News</a></p>
Couldn't get https://mstdn.chrisalemany.ca/@chris/113864600222476627: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Kimi K1.5: Scaling Reinforcement Learning with LLMs (185 pts)]]></title>
            <link>https://github.com/MoonshotAI/Kimi-k1.5</link>
            <guid>42777857</guid>
            <pubDate>Tue, 21 Jan 2025 08:53:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/MoonshotAI/Kimi-k1.5">https://github.com/MoonshotAI/Kimi-k1.5</a>, See on <a href="https://news.ycombinator.com/item?id=42777857">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf"><img width="80%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/kimi_k1.5.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kimi k1.5: Scaling Reinforcement Learning with LLMs</h2><a id="user-content-kimi-k15-scaling-reinforcement-learning-with-llms" aria-label="Permalink: Kimi k1.5: Scaling Reinforcement Learning with LLMs" href="#kimi-k15-scaling-reinforcement-learning-with-llms"></a></p>
<p dir="auto">
  <b>Kimi Team</b>
</p>
<p dir="auto">
  <a href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf"><img src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/logo.png" height="16" width="16"><b> Full Report</b></a>
</p>
<p dir="auto">üöÄ Introducing Kimi k1.5 --- an o1-level multi-modal model</p>
<ul dir="auto">
<li>Sota short-CoT performance, outperforming GPT-4o and Claude Sonnet 3.5 on üìêAIME, üìêMATH-500, üíª LiveCodeBench by a large margin (up to +550%)</li>
<li>Long-CoT performance matches o1 across multiple modalities (üëÄMathVista, üìêAIME, üíªCodeforces, etc)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Abstract</h2><a id="user-content-abstract" aria-label="Permalink: Abstract" href="#abstract"></a></p>
<p dir="auto">Language model pretraining with next token prediction has proved effective for scaling compute but is limited to the amount of available training data. Scaling reinforcement learning (RL) unlocks a new axis for the continued improvement of artificial intelligence, with the promise that large language models (LLMs) can scale their training data by learning to explore with rewards. However, prior published work has not produced competitive results. In light of this, we report on the training practice of Kimi k1.5, our latest multi-modal LLM trained with RL, including its RL training techniques, multi-modal data recipes, and infrastructure optimization. Long context scaling and improved policy optimization methods are key ingredients of our approach, which establishes a simplistic, effective RL framework without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models. Notably, our system achieves state-of-the-art reasoning performance across multiple benchmarks and modalities---e.g., 77.5 on AIME, 96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista---matching OpenAI's o1. Moreover, we present effective long2short methods that use long-CoT techniques to improve short-CoT models, yielding state-of-the-art short-CoT reasoning results---e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on LiveCodeBench---outperforming existing short-CoT models such as GPT-4o and Claude Sonnet 3.5 by a large margin (up to +550%). The service of Kimi k1.5 on <a href="https://kimi.ai/" rel="nofollow">https://kimi.ai</a> will be available soon.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/benchmark-long.jpeg"><img width="100%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/benchmark-long.jpeg"></a>
</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/benchmark-short.jpeg"><img width="100%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/benchmark-short.jpeg"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Ingredients of Kimi k1.5</h2><a id="user-content-key-ingredients-of-kimi-k15" aria-label="Permalink: Key Ingredients of Kimi k1.5" href="#key-ingredients-of-kimi-k15"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/system.png"><img src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/system.png" alt="The Reinforcement Learning Training System for LLM"></a>
</p>
<p dir="auto">There are a few key ingredients about the design and training of k1.5.</p>
<ul dir="auto">
<li><strong>Long context scaling</strong>. We scale the context window of RL to 128k and observe continued improvement of performance with an increased context length. A key idea behind our approach is to use partial rollouts to improve training efficiency---i.e., sampling new trajectories by reusing a large chunk of previous trajectories, avoiding the cost to re-generate the new trajectories from scratch. Our observation identifies the context length as a key dimension of the continued scaling of RL with LLMs.</li>
<li><strong>Improved policy optimization</strong>. We derive a formulation of RL with long-CoT and employ a variant of online mirror descent for robust policy optimization. This algorithm is further improved by our effective sampling strategy, length penalty, and optimization of the data recipe.</li>
<li><strong>Simplistic Framework</strong>. Long context scaling, combined with the improved policy optimization methods, establishes a simplistic RL framework for learning with LLMs. Since we are able to scale the context length, the learned CoTs exhibit the properties of planning, reflection, and correction. An increased context length has an effect of increasing the number of search steps. As a result, we show that strong performance can be achieved without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models.</li>
<li><strong>Mutimodalities</strong>. Our model is jointly trained on text and vision data, which has the capabilities of jointly reasoning over the two modalities.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test Model by API</h2><a id="user-content-test-model-by-api" aria-label="Permalink: Test Model by API" href="#test-model-by-api"></a></p>
<p dir="auto">You can test Kimi k1.5 through the Kimi OpenPlatform. Fill out the test application form in <a href="https://forms.gle/TqZ9XQnPiJPddzhV8" rel="nofollow">this link</a>. We will contact you via email to provide a test account later.</p>
<p dir="auto">Here's an example of calling Kimi k1.5</p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai import Client

client = Client(
    api_key=&quot;YOUR_KIMI_KEY&quot;,
    base_url=&quot;https://api.moonshot.ai/v1&quot;,
)

messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;The lengths of the two legs of a right triangle are 3 cm and 4 cm respectively. Find the length of the hypotenuse of this right triangle.&quot;,
    },
]

stream = client.chat.completions.create(
    model=&quot;kimi-k1.5-preview&quot;,
    messages=messages,
    temperature=0.3,
    stream=True,
    max_tokens=8192,
)

for chunk in stream:
    if chunk.choices[0].delta:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end=&quot;&quot;)
"><pre><span>from</span> <span>openai</span> <span>import</span> <span>Client</span>

<span>client</span> <span>=</span> <span>Client</span>(
    <span>api_key</span><span>=</span><span>"YOUR_KIMI_KEY"</span>,
    <span>base_url</span><span>=</span><span>"https://api.moonshot.ai/v1"</span>,
)

<span>messages</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: <span>"The lengths of the two legs of a right triangle are 3 cm and 4 cm respectively. Find the length of the hypotenuse of this right triangle."</span>,
    },
]

<span>stream</span> <span>=</span> <span>client</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
    <span>model</span><span>=</span><span>"kimi-k1.5-preview"</span>,
    <span>messages</span><span>=</span><span>messages</span>,
    <span>temperature</span><span>=</span><span>0.3</span>,
    <span>stream</span><span>=</span><span>True</span>,
    <span>max_tokens</span><span>=</span><span>8192</span>,
)

<span>for</span> <span>chunk</span> <span>in</span> <span>stream</span>:
    <span>if</span> <span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>:
        <span>if</span> <span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>.<span>content</span>:
            <span>print</span>(<span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>.<span>content</span>, <span>end</span><span>=</span><span>""</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<div data-snippet-clipboard-copy-content="@article{MoonshotAI,
  author = {Kimi Team},
  title = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  year = {2025},
}"><pre><code>@article{MoonshotAI,
  author = {Kimi Team},
  title = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  year = {2025},
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We've lost our respect for complexity (103 pts)]]></title>
            <link>https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/</link>
            <guid>42777715</guid>
            <pubDate>Tue, 21 Jan 2025 08:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/">https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/</a>, See on <a href="https://news.ycombinator.com/item?id=42777715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-amp-original-style="padding-top:var(--wp--preset--spacing--60);padding-bottom:var(--wp--preset--spacing--60)">
<p>I was talking recently to a friend about a video essayist I like, (Dan Olson of Folding Ideas) and when asked why I thought he was any good I pondered it for a moment and said ‚Äúhe has a lot of respect for complexity‚Äù. On reflection, I think that is one of the virtues I look for in new people I meet more generally. It‚Äôs not that we always have to be knees-deep in the details of a topic, but just being able to respect complexity, even that which you don‚Äôt understand, is something that I find admirable. Yet, over time, I feel we have lost a lot of our own respect for these people. Complexity is <em>hard</em>. Hard to work with, hard to remove if it‚Äôs unnecessary, but most of all hard to understand. We talk about complex subjects all the time. Medicine, politics, economics, sociology, morality and more. These are all deep topics that you can study your entire life, but everyone will end up talking about most of these, even quite often. So this isn‚Äôt just about academic papers and overly abstract hand-wavy blogposts like this one. I‚Äôm talking memes, news, thanksgiving dinner arguments, water cooler chats. We are constantly asking our brains to grasp at complex topics and distill down at least our own perception of them to something manageable.</p>



<p>We may be becoming worse at this. It‚Äôs not set in stone but the need to have quick and easy explanations for things, having peaked many centuries ago, has begun to rise again since the techno-optimistic days of only a few decades ago. That‚Äôs not been entirely without good reason, many things were promised then that have failed to materialize. From flying cars to world peace, some more sought than others. But the idea was that we would trust that society was heading in a good direction, and so these complex topics could be safely left to some group of people who would make it their life careers and so overall we would trust them to get the job done. Now, when many may challenge that notion of consistent progress of the world toward a brighter future, letting somebody else do it just doesn‚Äôt seem so right. Instead we now live in a time of doing your own research, of skepticism, but most of all, of the idea that understanding the full complexity of every topic that might cross your path is not only possible, but somehow, expected.</p>



<h2>How did this happen?</h2>



<p>Lots of people have spoken about the information age and what the internet has done for our perceptions of things. You can also look at geopolitical issues and point fingers to tensions or collapsing trust due to specific events. Even one can talk about how the improving lives we live can make us forget about both the value of what we have and the work it took to get there (I‚Äôm thinking of vaccines). All of these are valid contributing factors that others have covered, but I want to talk about one I love to talk about in general: Automation.</p>



<p>What does robots taking our jobs have anything to do with people‚Äôs respect for complexity? Well, it‚Äôs simple. One of the best ways of improving your understanding of something is proximity to it. Do you work in the steel industry? You probably get a better feel for how manufacturing works. Are you waitstaff? You‚Äôll probably live the rest of your life being kind to servers. Does your friend you know work in an essential industry for the economy? You will over time develop a better idea of how much real complexity is involved in that thing. These are not useless anecdotal ideas if they allow you to give more respect for <em>other areas you do not understand but believe are equally complex.</em> Having a deeper understanding of a <em>single</em> value creating and complex system helps us put other such systems into context (at least, for most people). As we take these foundational industries like agriculture, manufacturing, engineering, construction, and automate them (or for that matter, move them overseas) we detach ourselves from real complexity and I think we lose something from that. Then, when we are trying to contextualize grocery prices, repair costs, bugs in our software, roadworks that seem to never end, we do a worse job. We likely get frustrated looking for an answer that may be many fathoms deep in the details. Now, it was never likely that your cousin who does road work might be in the car with you to explain the intricacies of asphalting, but almost as good is to simply have a respect for the complexity that is almost certainly involved. You don‚Äôt even need your cousin to tell you that.</p>



<h2>What to do?</h2>



<p>Am I implying that we should all get out our shovels and start little home gardens? Well, I don‚Äôt think that would be a <em>bad</em> idea, but notice that even people who do that may still not grasp the complexity of the global agriculture industry (in fact, people who grow their own gardens are more likely doing it because of a distrust of that industry). So, really, the gulf between subsistence farming and modern complex industries is to large to be crossed on its own.</p>



<p>Schools, then? Sadly, the education system itself suffers from the effects of this lack of respect. It does <em>seem </em>to currently be in a negative cycle, meaning less trust in teachers means less funding, which leads to less understanding kid‚Äôs and so on. However, <a href="https://en.wiktionary.org/wiki/juvenoia">juvenoia</a> is a recurring theme across history so I‚Äôm inclined to be optimistic. This may just be part of the ebb and flow of trends and ideas. Still, clear answers don‚Äôt seem ahead of us</p>



<p>What? Don‚Äôt look at me like that? I didn‚Äôt promise you any solutions at the start of this text. It‚Äôs a complex problem, and it‚Äôd be genuinely ironic if I now gave you the fix-all solution. I have more respect for the problem than to try and do that in a blogpost. Still, it‚Äôs very easy to get worried about the rhetoric and the new developments in news and elsewhere that seem to all point to disaster, and wanting some comfort. If there‚Äôs merit to this theory above then another big question of our time, how much might AI disrupt human labor, will have even more riding on its outcome. All I can do is continue looking for those people who have that respect for complexity. Some find them boring, or indecisive, or just wrong for not buying into some extreme. I think those are dumb ideas. My trust in people rises immensely these days when they have the ability to sincerely say ‚ÄúI don‚Äôt know‚Äù. Being all-knowing shouldn‚Äôt be the coolest thing to be since, given that it‚Äôs impossible, anyone who comes off that way is, in a sense, lying. <em>Respect for complexity</em>? Now that is cool.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Context should go away for Go 2 (2017) (115 pts)]]></title>
            <link>https://faiface.github.io/post/context-should-go-away-go2/</link>
            <guid>42777625</guid>
            <pubDate>Tue, 21 Jan 2025 08:08:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://faiface.github.io/post/context-should-go-away-go2/">https://faiface.github.io/post/context-should-go-away-go2/</a>, See on <a href="https://news.ycombinator.com/item?id=42777625">Hacker News</a></p>
Couldn't get https://faiface.github.io/post/context-should-go-away-go2/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[More than 40% of postdocs leave academia, study reveals (138 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-025-00142-y</link>
            <guid>42777193</guid>
            <pubDate>Tue, 21 Jan 2025 06:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-025-00142-y">https://www.nature.com/articles/d41586-025-00142-y</a>, See on <a href="https://news.ycombinator.com/item?id=42777193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00142-y/d41586-025-00142-y_50486408.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00142-y/d41586-025-00142-y_50486408.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="The lab bench of an absent university researcher." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00142-y/d41586-025-00142-y_50486408.jpg"><figcaption><p><span>There are more postdocs than faculty positions available in many countries.</span><span>Credit: Lanshi Wu/Alamy</span></p></figcaption></picture></figure><p>More than 40% of postdoctoral researchers leave academia, according to a study of some 45,500 researchers‚Äô careers<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>. Those who stayed and landed a coveted faculty position were more likely to have had a highly cited paper, changed their research topic between their PhD and postdoc, or moved abroad after receiving their doctorate.</p><p>The study, published in <i>Proceedings of the National Academy of Sciences</i> on 20 January, looked at researchers around the world who had progressed from <a href="https://www.nature.com/articles/d41586-024-03222-7" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03222-7" data-track-category="body text link">a PhD</a> to a postdoc ‚Äî a temporary position for further professional training, development and expanded research ‚Äî and then, in some cases, on to a faculty position. The study covered 25 years and 19 academic disciplines and used data from Microsoft Academic Graph, a corpus containing 257 million publications. The researchers filtered the data using an online professional network (presumably LinkedIn, although the authors did not say) to match researchers‚Äô CVs.</p><p>Previous studies have focused mainly on how important the prestige of PhD-granting institutions is to landing a faculty job<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. Bedoor AlShebli, a computational social scientist at New York University Abu Dhabi, United Arab Emirates, and her co-authors wanted to fill a gap in the research and quantify the significance of postdoctoral training to gaining a faculty position and early-career success.</p><p>‚ÄúOur research highlights that the postdoctoral years are just as critical as the PhD years when evaluating a scientist‚Äôs likelihood of successfully entering academia and securing a faculty position,‚Äù she says.</p><h2>A path to success</h2><p>In many countries, there are more postdocs than <a href="https://www.nature.com/articles/d41586-023-03251-8" data-track="click" data-label="https://www.nature.com/articles/d41586-023-03251-8" data-track-category="body text link">faculty positions</a> available. This creates a bottleneck. The team‚Äôs data set shows that 41% of postdocs end up <a href="https://www.nature.com/articles/d41586-022-00198-0" data-track="click" data-label="https://www.nature.com/articles/d41586-022-00198-0" data-track-category="body text link">leaving academia</a>. AlShebli says that researchers who publish less during their postdoc than they did during their PhD are more likely to leave.</p><p>For researchers who stick around, what determines success? To answer that question the team developed a measure of scientific output ‚Äî called the <i>Œ∑</i>-index ‚Äî as a proxy for success. This measure is based on the <i>h</i>-index, a count of a researcher‚Äôs citations, but focuses only on papers published between two and four years after securing a faculty position.</p></div></div>]]></description>
        </item>
    </channel>
</rss>