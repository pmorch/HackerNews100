<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 31 Oct 2024 03:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Generative AI Scripting (145 pts)]]></title>
            <link>https://microsoft.github.io/genaiscript/</link>
            <guid>42001811</guid>
            <pubDate>Wed, 30 Oct 2024 23:39:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microsoft.github.io/genaiscript/">https://microsoft.github.io/genaiscript/</a>, See on <a href="https://news.ycombinator.com/item?id=42001811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">  <main data-pagefind-body="" lang="en" dir="ltr">   <div> <div> <p><img src="https://microsoft.github.io/genaiscript/_astro/logo.C7y7Xksc_ZQDjo6.svg" loading="eager" decoding="async" alt="GenAIScript logo A yellow square with genai text" width="400" height="400"></p> </div>  <div> <h2 id="prompting-is-coding">Prompting is Coding</h2>
<p>Programmatically assemble prompts for LLMs using JavaScript.</p>
<div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Analyze </span><span>${</span><span>env</span><span>.</span><span>files</span><span>}</span><span> and report errors. Use gitmojis.</span><span>`</span></p></div></code></pre></figure></div>
<p>Of course, things can get more complex‚Ä¶</p>
<div><figure><pre data-language="js"><code><div><p><span>// define the context</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>FILE</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, { endsWith: </span><span>"</span><span>.pdf</span><span>"</span><span> })</span></p></div><div><p><span>// structure the data</span></p></div><div><p><span>const </span><span>schema</span><span> = </span><span>defSchema</span><span>(</span><span>"</span><span>DATA</span><span>"</span><span>, { type: </span><span>"</span><span>array</span><span>"</span><span>, items: { type: </span><span>"</span><span>string</span><span>"</span><span> } }</span><span>)</span></p></div><div><p><span>// assign the task</span></p></div><div><p><span>$</span><span>`</span><span>Analyze FILE and extract data to JSON.</span><span>`</span></p></div><div><p><span>// save results to file</span></p></div><div><p><span>defFileOutput</span><span>(</span><span>"</span><span>*.pdf.txt</span><span>"</span><span>, </span><span>"</span><span>Extracted data</span><span>"</span><span><span>, { </span><span>schema</span><span> })</span></span></p></div><div><p><span>// tools</span></p></div><div><p><span>defTool</span><span>(</span><span>"</span><span>weather</span><span>"</span><span>, </span><span>"</span><span>live weather</span><span>"</span><span>, { city: </span><span>"</span><span>Paris</span><span>"</span><span> }, </span><span>/* schema */</span></p></div><div><p><span>    </span><span>async</span><span> </span><span>(</span><span><span>{ </span><span>city</span><span> }</span></span><span>)</span><span> </span><span>=&gt;</span><span> { </span><span>...</span><span> </span><span>"</span><span>sunny</span><span>"</span><span> }) </span><span>/* callback */</span></p></div><div><p><span>// agents!</span></p></div><div><p><span>defAgent</span><span>(</span><span>"</span><span>git</span><span>"</span><span>, </span><span>"</span><span>answer git questions</span><span>"</span><span>, </span><span>"</span><span>You are a git expert.</span><span>"</span><span>, { tools: [</span><span>"</span><span>git</span><span>"</span><span>] })</span></p></div><div><p><span>...</span></p></div></code></pre></figure></div>
<h2 id="next-steps">Next steps</h2>
<div><article> <p>   <span>Listen to the podcast</span> </p> <div><p><audio controls="" loop="false" preload="metadata"> <source src="https://microsoft.github.io/genaiscript/podcasts/overview.wav" type="audio/mpeg">
Your browser does not support the audio element.
</audio> </p></div> </article> <article> <p>   <span>Install the extension</span> </p> <div><p>Install the <a href="https://microsoft.github.io/genaiscript/getting-started/installation/">Visual Studio Code
Extension</a> to get started.</p></div> </article> <article> <p>   <span>Configure your LLMs</span> </p> <p>Configure the <a href="https://microsoft.github.io/genaiscript/getting-started/configuration">secrets</a> to
access your LLMs.</p> </article> <article> <p>   <span>Write your first script</span> </p> <div><p>Follow <a href="https://microsoft.github.io/genaiscript/getting-started/your-first-genai-script/">Getting
Started</a> to write
your first script.</p></div> </article> <article> <p>   <span>Read the docs</span> </p> <div><p>Learn more about GenAIScript in the <a href="https://microsoft.github.io/genaiscript/reference/">Scripting
Reference</a>.</p></div> </article> </div> 
<p><img src="https://microsoft.github.io/genaiscript/_astro/visual-studio-code.CzkSq6ro_ZQ8RMG.webp" alt="A screenshot of VSCode with a genaiscript opened" loading="lazy" width="3072" height="1382" decoding="async"></p><h2 id="features">Features</h2>
<p>GenAIScript brings essential LLM prompt tooling into a cohesive scripting environment.</p>
<div><article> <p>   <span>Stylized JavaScript</span> </p> <div><p>Minimal syntax to build prompts using <a href="https://microsoft.github.io/genaiscript/reference/scripts/">JavaScript</a>
or <a href="https://microsoft.github.io/genaiscript/reference/scripts/typescript">TypeScript</a>.</p><div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Summarize </span><span>${</span><span>env</span><span>.</span><span>files</span><span>}</span><span>. Today is </span><span>${</span><span>new</span><span> </span><span>Date</span><span>()</span><span>}</span><span>.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Fast Development Loop</span> </p>  </article> <article> <p>   <span>LLM Tools</span> </p> <div><p>Register JavaScript functions as <a href="https://microsoft.github.io/genaiscript/reference/scripts/tools/">LLM tools</a></p><div><figure><pre data-language="js"><code><div><p><span>defTool</span><span>(</span><span>"</span><span>weather</span><span>"</span><span>, </span><span>"</span><span>live weahter</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ city: </span><span>"</span><span>Paris</span><span>"</span><span> }, </span><span>// schema</span></p></div><div><p><span>    </span><span>async</span><span> </span><span>(</span><span><span>{ </span><span>city</span><span> }</span></span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>// callback</span></p></div><div><p><span><span>        </span></span><span>{ </span><span>...</span><span> </span><span>"</span><span>sunny</span><span>"</span><span> }</span></p></div><div><p><span>)</span></p></div></code></pre></figure></div><p>or use built-in <a href="https://microsoft.github.io/genaiscript/guides/agentic-tools/">@agentic tools</a></p><div><figure><pre data-language="js"><code><div><p><span>import</span><span> { WeatherClient } </span><span>from</span><span> </span><span>"</span><span>@agentic/weather</span><span>"</span></p></div><div><p><span>defTool</span><span>(</span><span>new</span><span> </span><span>WeatherClient</span><span>())</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>LLM Agents</span> </p> <div><p>Combine <a href="https://microsoft.github.io/genaiscript/reference/scripts/tools">tools</a> and <a href="https://microsoft.github.io/genaiscript/reference/scripts/inline-prompts/">inline prompts</a>
into an <a href="https://microsoft.github.io/genaiscript/reference/scripts/agents">agent</a>.</p><div><figure><pre data-language="js"><code><div><p><span>defAgent</span><span>(</span></p></div><div><p><span>    </span><span>"</span><span>git</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>"</span><span>Agent that answer git questions for the current repo</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>"</span><span>You are a helpful expert in using git.</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ tools: [</span><span>"</span><span>git</span><span>"</span><span>] }</span></p></div><div><p><span>)</span></p></div></code></pre></figure></div><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ tools: </span><span>"</span><span>agent</span><span>"</span><span> })</span></p></div><div><p><span>$</span><span>`</span><span>Do a statistical analysis of the last commits</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Reuse and Share Scripts</span> </p> <div><p>Scripts are <a href="https://microsoft.github.io/genaiscript/reference/scripts/">files</a>! They can be versioned, shared, forked, ‚Ä¶</p><starlight-file-tree data-pagefind-ignore=""><ul><li><details open=""><summary><span><span><span><span>Directory</span></span>genaisrc
</span></span></summary><ul><li><span><span><span></span>my-script.genai.mjs</span></span></li><li><span><span><span></span>another-great-script.genai.mjs</span></span></li></ul></details></li></ul></starlight-file-tree> </div> </article> <article> <p>   <span>Data Schemas</span> </p> <div><p>Define, validate, repair data using <a href="https://microsoft.github.io/genaiscript/reference/scripts/schemas">schemas</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>data</span><span> = </span><span>defSchema</span><span>(</span><span>"</span><span>MY_DATA</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ type: </span><span>"</span><span>array</span><span>"</span><span>, items: { </span><span>...</span><span> }, }</span><span>)</span></p></div><div><p><span>$</span><span>`</span><span>Extract data from files using </span><span>${</span><span>data</span><span>}</span><span> schema.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Ingest text from PDFs, DOCX, ...</span> </p> <div><p>Manipulate
<a href="https://microsoft.github.io/genaiscript/reference/scripts/pdf">PDFs</a>,
<a href="https://microsoft.github.io/genaiscript/reference/scripts/docx">DOCX</a>,
‚Ä¶</p><div><figure><pre data-language="js"><code><div><p><span>// automatically convert to text</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>PDF</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, { endsWith: </span><span>"</span><span>.pdf</span><span>"</span><span> })</span></p></div><div><p><span>// or parse and process</span></p></div><div><p><span>const { </span><span>pages</span><span> } = await </span><span>parsers</span><span>.</span><span>PDF</span><span>(</span><span>env</span><span>.</span><span>files</span><span>[</span><span>0</span><span>])</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Ingest tables from CSV, XLSX, ..</span> </p> <div><p>Manipulate tabular data from
<a href="https://microsoft.github.io/genaiscript/reference/scripts/csv">CSV</a>,
<a href="https://microsoft.github.io/genaiscript/reference/scripts/xlsx">XLSX</a>,
‚Ä¶</p><div><figure><pre data-language="js"><code><div><p><span>// automatically convert to text</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>DATA</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, {</span></p></div><div><p><span><span>    </span></span><span>endsWith: </span><span>"</span><span>.csv</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>// take top 100 rows</span></p></div><div><p><span><span>    </span></span><span>sliceHead: </span><span>100</span><span>,</span></p></div><div><p><span>})</span></p></div><div><p><span>// or parse to JavaScript object array</span></p></div><div><p><span>const </span><span>rows</span><span> = await </span><span>parsers</span><span>.</span><span>CSV</span><span>(</span><span>env</span><span>.</span><span>files</span><span>[</span><span>0</span><span>])</span></p></div><div><p><span>// render as markdown table</span></p></div><div><p><span>defData</span><span>(</span><span>"</span><span>ROWS</span><span>"</span><span><span>, </span><span>rows</span><span>, { sliceHead: </span></span><span>100</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Generate Files</span> </p> <div><p>Extract files and diff from the LLM output.
Preview changes in Refactoring UI.</p><div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Save the result in poem.txt.</span><span>`</span></p></div></code></pre></figure></div><div><figure><pre data-language="txt"><code><div><p><span>FILE ./poem.txt</span></p></div><div><p><span>```txt</span></p></div><div><p><span>The quick brown fox jumps over the lazy dog.</span></p></div><div><p><span>```</span></p></div></code></pre></figure></div><starlight-file-tree data-pagefind-ignore=""><ul><li><span><span><span></span>poem.txt</span> </span></li></ul></starlight-file-tree> </div> </article> <article> <p>   <span>File search</span> </p> <div><p>Grep or fuzz search <a href="https://microsoft.github.io/genaiscript/referen/script/files">files</a></p><div><figure><pre data-language="js"><code><div><p><span>const { </span><span>files</span><span> } = await </span><span>workspace</span><span>.</span><span>grep</span><span>(</span><span>/</span><span>[a-z][a-z0-9]</span><span>+</span><span>/</span><span>, { globs: </span><span>"</span><span>*.md</span><span>"</span><span> }</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Browser automation</span> </p> <div><p>Browse and scrape the web with <a href="https://microsoft.github.io/genaiscript/reference/scripts/browse">Playwright</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>page</span><span> = await </span><span>host</span><span>.</span><span>browse</span><span>(</span><span>"</span><span>https://...</span><span>"</span><span>)</span></p></div><div><p><span>const </span><span>table</span><span> = await </span><span>page</span><span>.</span><span>locator</span><span>(</span><span>"</span><span>table[...]</span><span>"</span><span>)</span><span>.</span><span>innerHTML</span><span>()</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>TABLE</span><span>"</span><span>, </span><span>await</span><span> </span><span>HTML</span><span>.</span><span>convertToMarkdown</span><span><span>(</span><span>table</span><span>))</span></span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>RAG built-in</span> </p> <div><p><a href="https://microsoft.github.io/genaiscript/reference/scripts/vector-search/">Vector search</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const { </span><span>files</span><span> } = await </span><span>retrieval</span><span>.</span><span>vectorSearch</span><span>(</span><span>"</span><span>cats</span><span>"</span><span>, </span><span>"</span><span>**/*.md</span><span>"</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>GitHub Models and GitHub Copilot</span> </p> <div><p>Run models through GitHub using <a href="https://microsoft.github.io/getting-started/configuration/#github-models">GitHub Models</a>
or <a href="https://microsoft.github.io/getting-started/configuration/#github-copilot-in-visual-studio-code">GitHub Copilot</a>.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, model: </span><span>"</span><span>github:gpt-4o</span><span>"</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Local Models</span> </p> <div><p>Run your scripts with <a href="https://microsoft.github.io/genaiscript/getting-started/configuration/#local-models">Open Source models</a>,
like <a href="https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/">Phi-3</a>,
using <a href="https://ollama.com/">Ollama</a>, <a href="https://localai.io/">LocalAI</a>‚Ä¶</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, model: </span><span>"</span><span>ollama:phi3</span><span>"</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Code Interpreter</span> </p> <div><p>Let the LLM run code in a sandboxed execution environment.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ tools: [</span><span>"</span><span>python_code_interpreter</span><span>"</span><span>] })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Containers</span> </p> <div><p>Run code in Docker <a href="https://microsoft.github.io/genaiscript/reference/scripts/containers">containers</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>c</span><span> = await </span><span>host</span><span>.</span><span>container</span><span>(</span><span>{</span></p></div><div><p><span><span>    </span></span><span>image: </span><span>"</span><span>python:alpine</span><span>"</span><span>,</span></p></div><div><p><span>}</span><span>)</span></p></div><div><p><span>const </span><span>res</span><span> = await </span><span>c</span><span>.</span><span>exec</span><span>(</span><span>"</span><span>python --version</span><span>"</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>LLM Composition</span> </p> <div><p><a href="https://microsoft.github.io/genaiscript/reference/scripts/inline-prompts/">Run LLMs</a> to build your LLM prompts.</p><div><figure><pre data-language="js"><code><div><p><span>// summarize each files individually</span></p></div><div><p><span>for</span><span> (</span><span>const </span><span>file</span><span> </span><span>of</span><span> </span><span>env</span><span>.</span><span>files</span><span>) {</span></p></div><div><p><span>    </span><span>const { </span><span>text</span><span> } = await </span><span>runPrompt</span><span>(</span><span>(</span><span>_</span><span>)</span><span> =&gt; {</span></p></div><div><p><span>        </span><span>_</span><span>.</span><span>def</span><span>(</span><span>"</span><span>FILE</span><span>"</span><span>, </span><span><span>file</span><span>)</span></span></p></div><div><p><span>        </span><span>_</span><span>.</span><span>$</span><span>`</span><span>Summarize the FILE.</span><span>`</span></p></div><div><p><span><span>    </span></span><span>}</span><span>)</span></p></div><div><p><span>    </span><span>// use result in main prompt</span></p></div><div><p><span>    </span><span>def</span><span>(</span><span>"</span><span>SUMMARY</span><span>"</span><span><span>, </span><span>text</span><span>)</span></span></p></div><div><p><span>}</span></p></div><div><p><span>// use summary</span></p></div><div><p><span>$</span><span>`</span><span>Summarize all the summaries.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>  <span>Prompty</span> </p> <div><p>Run or convert <a href="https://prompty.ai/">Prompty</a> files using GenAIScript.</p><div><figure><pre data-language="markdown"><code><div><p><span>---</span></p></div><div><p><span>name</span><span>: </span><span>poem</span></p></div><div><p><span>---</span></p></div><div><p><span>Write a short poem.</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Automate with CLI</span> </p> <div><p>Automate using the <a href="https://microsoft.github.io/genaiscript/reference/cli">CLI</a>,
integrate reports in your CI/CD pipeline.</p><div><figure><pre data-language="bash"><code><div><p><span>npx</span><span> </span><span>genaiscript</span><span> </span><span>run</span><span> </span><span>tlaplus-linter</span><span> </span><span>"</span><span>*.tla</span><span>"</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Pull Request Reviews</span> </p> <div><p>Integrate into your <a href="https://microsoft.github.io/genaiscript/reference/cli/run/#pull-requests">Pull Requests checks</a> through comments,
reviews or description updates. Supports GitHub Actions and Azure DevOps pipelines.</p><div><figure><pre data-language="bash"><code><div><p><span>npx</span><span> </span><span>genaiscript</span><span> </span><span>...</span><span> </span><mark><span>--pull-request-reviews</span></mark></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Tests and Evals</span> </p> <div><p>Build reliable prompts using <a href="https://microsoft.github.io/genaiscript/reference/scripts/tests">tests and evals</a>
powered by <a href="https://promptfoo.dev/">promptfoo</a>.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, tests: {</span></p></div><div><p><span><span>  </span></span><span>files: </span><span>"</span><span>penguins.csv</span><span>"</span><span>,</span></p></div><div><p><span><span>  </span></span><span>rubric: </span><span>"</span><span>is a data analysis report</span><span>"</span><span>,</span></p></div><div><p><span><span>  </span></span><span>facts: </span><span>"</span><span>The data refers about penguin population in Antartica.</span><span>"</span><span>,</span></p></div><div><p><span>}})</span></p></div></code></pre></figure></div><p><img src="https://microsoft.github.io/genaiscript/_astro/vscode-test-explorer.DHobrdnh_1FDdux.webp" alt="Visual Studio Test Explorer opened with a few genaiscript tests." loading="lazy" width="815" height="451" decoding="async"></p></div> </article> </div> 
<h2 id="case-studies">Case Studies</h2>
<p>Tales from the real world using GenAIScript.</p>
<div><div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/bicep-best-practices"> <span>Bicep Best Practices</span> </a> <span>Learn how to apply best practices to Azure Bicep files for more efficient and maintainable infrastructure as code.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/seo-frontmatter"> <span>SEO Front Matter</span> </a> <span>Learn how to automate the creation of SEO-optimized front matter for your markdown documents with GenAIScript.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/documentation-translations"> <span>Documentation Translations</span> </a> <span>Explore the challenges and solutions for localizing MakeCode documentation with custom macros while maintaining rich rendering in multiple languages.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/blocks-localization"> <span>Blocks Localization</span> </a> <span>Learn how to localize MakeCode programming blocks while preserving block properties and variable names for international audiences.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/release-notes"> <span>Release Notes</span> </a> <span>Generate comprehensive release notes combining commit history and code diffs</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/tla-ai-linter"> <span>TLA+ AI Linter</span> </a> <span>Explore how the TLA+ AI Linter leverages GenAI scripts and LLMs to enhance TLA+ specifications with automated linting and consistent comment verification.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/image-alt-text"> <span>Image Alt Text</span> </a> <span>Learn how to automatically generate descriptive alt text for images using OpenAI Vision model to enhance accessibility and SEO.</span> </span></p>  </div> </div> 
<h2 id="samples">Samples</h2>
<p>Fully fledged scripts ready to use.</p>
 
<h2 id="guides">Guides</h2>
<p>A cookbook full of recipes to make you a genius scripter.</p>
<div><div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/prompt-as-code"> <span>Prompt As Code</span> </a> <span>Tutorial on using GenAIScript runtime and syntax to assemble prompts</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/sharing-scripts"> <span>Sharing scripts</span> </a> <span>Learn how to share GenAIScript scripts across projects using Git repositories, submodules, and GitHub Gists.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/ask-my-pdf"> <span>Ask My PDF</span> </a> <span>Quick-start guide to using GenAIScript for summarizing and critiquing PDF documents with AI assistance.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/ask-my-image"> <span>Ask My Image</span> </a> <span>Learn how to apply GenAIScript to images for data extraction and analysis using AI models.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/present-my-code"> <span>Present My Code</span> </a> <span>Step-by-step instructions on presenting code effectively using GenAIScript and creating engaging slides.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/search-and-fetch"> <span>Search and Fetch</span> </a> <span>Learn how to leverage web search and fetching pages in GenAIScript</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/tool-agent"> <span>Tool Agent</span> </a> <span>Learn how to define a built-in agent using functions for decision-making and reasoning in arithmetic operations.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/containerized-tools"> <span>Containerized Tools</span> </a> <span>Learn how to create and use containerized tools with executable dependencies in a secure environment using GCC as an example.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/generated-knowledge"> <span>Generated Knowledge</span> </a> <span>Explore the technique of generated knowledge in AI prompting to enhance accuracy in answering questions.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/phi3-with-ollama"> <span>Phi-3 Mini with Ollama</span> </a> <span>Learn how to integrate Phi-3 Mini, a powerful 3.8B parameter model by Microsoft, with Ollama for local execution of state-of-the-art AI models.</span> </span></p>  </div>    <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/llm-agents"> <span>LLM Agents</span> </a> <span>Learn how to use the inline prompts to create a LLM agent.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/pull-request-reviewer"> <span>Pull Request Reviewer</span> </a> <span>Learn how to automate pull request reviews with a GenAIScript that provides feedback and code analysis in GitHub Actions.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/transformers-js"> <span>Transformer.js</span> </a> <span>Implement summarization with Transformers.js and leverage local hardware acceleration</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/using-secrets"> <span>Using Secrets</span> </a> <span>Utilize secrets to augment documents with TypeScript and REST APIs</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/llm-as-tool"> <span>LLM as a tool</span> </a> <span>Create tools and inline prompts using LLM models for executing various tasks</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/zod-schema"> <span>Zod Schema</span> </a> <span>Learn how to define and convert TypeScript-first Zod schemas to JSON schema</span> </span></p>  </div> </div> 
<h2 id="agents">Agents</h2>
<h3 id="builtin-agents">Builtin Agents</h3>
 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_fs"> <span>agent fs</span> </a> <span>query files to accomplish tasks</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_git"> <span>agent git</span> </a> <span>query a repository using Git to accomplish tasks. Provide all the context information available to execute git queries.</span> </span></p>  </div> 
 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_interpreter"> <span>agent interpreter</span> </a> <span>run code interpreters for Python, Math. Use this agent to ground computation questions.</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_memory"> <span>agent memory</span> </a> <span>queries the memories created by other agent conversations.</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_user_input"> <span>agent user_input</span> </a> <span>ask user for input to confirm, select or answer the question in the query. The message should be very clear and provide all the context.</span> </span></p>  </div> 
<h2 id="llm-friendly-docs">LLM friendly docs</h2>
<p>If you are an LLM crawler, fetch <a href="https://microsoft.github.io/genaiscript/.well-known/llms.txt">https://microsoft.github.io/genaiscript/.well-known/llms.txt</a> for an documentation map
or add the <code dir="auto">.md</code> suffix to any documentation URLs to get a raw markdown content.</p>
<p>For example, <a href="https://microsoft.github.io/genaiscript/guides/prompt-as-code.md">https://microsoft.github.io/genaiscript/guides/prompt-as-code.md</a> (note the .md extension)</p>  </div>   </div>  </main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenZFS deduplication is good now and you shouldn't use it (170 pts)]]></title>
            <link>https://despairlabs.com/blog/posts/2024-10-27-openzfs-dedup-is-good-dont-use-it/</link>
            <guid>42000784</guid>
            <pubDate>Wed, 30 Oct 2024 21:48:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://despairlabs.com/blog/posts/2024-10-27-openzfs-dedup-is-good-dont-use-it/">https://despairlabs.com/blog/posts/2024-10-27-openzfs-dedup-is-good-dont-use-it/</a>, See on <a href="https://news.ycombinator.com/item?id=42000784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<article>

<header>
  <p><time>27 October, 2024</time>
    
  </p>

  

  
</header>

<p><a href="https://github.com/openzfs/zfs/releases/">OpenZFS 2.3.0 will be released any day now</a>, and it includes the new <a href="https://www.youtube.com/watch?v=_T2lkb49gc8">‚ÄúFast Dedup‚Äù</a> feature. My team at <a href="https://klarasystems.com/">Klara</a> spent many months in 2023 and 2024 working on it, and we reckon it‚Äôs pretty good, a huge step up from the old dedup as well as being a solid base for further improvements.</p>
<p>I‚Äôve been watching various forums and mailing lists since it was announced, and the thing I kept seeing was people saying something like ‚Äúit has the same problems as the old dedup; needs too much memory, nukes your performance‚Äù. While that was true (ish), and is now significantly less true, the real problem is that this just repeating the same old non-information that they probably heard from someone else repeating it.</p>
<p>I don‚Äôt blame anyone really; it is true that dedup has been extremely challenging to get the best out of, it‚Äôs very difficult to find good information about using it well, and ‚Äúdon‚Äôt use it‚Äù was and remains almost certainly the right answer. But, with this being the first time in almost two decades that dedup has been worth even considering, I want to get some fresh information out there about what dedup is, how it worked traditionally and why it was usually bad, what we changed with fast dedup, and why it‚Äôs still probably not the thing you want.</p>
<nav>
<h2>Table of contents</h2>

<ul>
  
  
    <li><a href="#what-even-is-dedup">What even is dedup?</a>
    
    </li>
  

  
    <li><a href="#how-does-dedup-work">How does dedup work?</a>
    
    </li>
  

  
    <li><a href="#why-is-traditional-dedup-so-bad">Why is traditional dedup so bad?</a>
    
      <ul>
      
      
        <li><a href="#the-dedup-table">The dedup table</a></li>
      
      
      
        <li><a href="#the-live-entry-list">The live entry list</a></li>
      
      
      
        <li><a href="#unique-entries">Unique entries</a></li>
      
      
      </ul>
    
    </li>
  

  
    <li><a href="#how-does-fast-dedup-fix-all-this">How does fast dedup fix all this?</a>
    
      <ul>
      
      
        <li><a href="#making-the-live-entry-list-smaller">Making the live entry list smaller</a></li>
      
      
      
        <li><a href="#the-dedup-log">The dedup log</a></li>
      
      
      
        <li><a href="#incremental-log-flushing">Incremental log flushing</a></li>
      
      
      
        <li><a href="#unique-entries-1">Unique entries</a></li>
      
      
      </ul>
    
    </li>
  

  
    <li><a href="#thats-a-lot-anything-else">That‚Äôs a lot! Anything else?</a>
    
    </li>
  

  
    <li><a href="#nice-cant-wait-to-use-this-with-my-existing-dedup-table">Nice! Can‚Äôt wait to use this with my existing dedup table</a>
    
    </li>
  

  
    <li><a href="#is-deduplication-_really_-good-now">Is deduplication <em>really</em> good now?</a>
    
    </li>
  

  
    <li><a href="#i-dont-get-it-after-all-this-if-its-good-enough-why-shouldnt-i-enable-dedup-everywhere">I don‚Äôt get it. After all this, if it‚Äôs good enough, why shouldn‚Äôt I enable dedup everywhere?</a>
    
    </li>
  

  
    <li><a href="#in-summary">In summary</a>
    
    </li>
  

</ul>

</nav>

<h2 id="what-even-is-dedup">
What even is dedup?
<a href="#what-even-is-dedup">üîó</a> 
</h2>
<p>Dedup can be easily described in a sentence.</p>
<blockquote>
<p><em>When OpenZFS prepares to write some data to disk, if that data is already on disk, don‚Äôt do the write but instead, add a reference to the existing copy.</em></p>
</blockquote>
<p>The challenge is all in how you determine whether or not the data is already on disk, and knowing where on disk it is. The reason it‚Äôs challenging is that that information has to be stored and retrieved, which is additional IO that we didn‚Äôt have to do before, and that IO can add surprising amounts of overhead!</p>
<p>This stored information is the ‚Äúdedup table‚Äù. Conceptually, it‚Äôs hashtable, with the data checksum as the ‚Äúkey‚Äù and the on-disk location and refcount as the ‚Äúvalue‚Äù. It‚Äôs stored in the pool as part of the pool metadata, that is, it‚Äôs considered ‚Äústructural‚Äù pool data, not user data.</p>
<h2 id="how-does-dedup-work">
How does dedup work?
<a href="#how-does-dedup-work">üîó</a> 
</h2>
<p>When dedup is enabled, the ‚Äúwrite‚Äù IO path is modified. As normal, a data block is prepared by the DMU and handed to the SPA to be written to disk. Encryption and compression are performed as normal and then the checksum is calculated.</p>
<p>Without dedup, the metaslab allocator is called to request space on the pool to store the block, and the locations (DVAs) are returned and copied into the block pointer. When dedup is enabled, OpenZFS instead looks up the checksum in the dedup table. If it doesn‚Äôt find it, it calls out to the metaslab allocator as normal, gets fresh DVAs, fills the block and lets the IO through to be written to disks as normal, and then creates a new dedup table entry with the checksum, DVAs and the refcount set to 1. On the other hand, if it does find it, it copies the DVAs from the the value into the block pointer and returns the writing IO as ‚Äúcompleted‚Äù and then increments the refcount.</p>
<p>Blocks allocated with dedup enabled have a special <code>D</code> flag set on the block pointer. This is to assist when it comes time to free the block. The ‚Äúfree‚Äù IO path is similarly modified to check for the <code>D</code> flag. If it exists, the same dedup table lookup happens, and the refcount is decremented. If the refcount is non-zero, the IO is returned as ‚Äúcompleted‚Äù, but if it reaches zero, then the last ‚Äúcopy‚Äù of the block is being freed, so the dedup table entry is deleted and the metaslab allocator is called to deallocate the space.</p>
<p>So all this is working, in that OpenZFS is avoiding writing multiple copies of the same data. The downside is that every single write and free operation requires a lookup and a then a write to the dedup table, regardless of whether or not the write or free proper was actually done by the pool.</p>
<p>It should be clear then that any dedup system worth using needs to save more in ‚Äútrue‚Äù space and IO than it spends on the overhead of managing the table. And this is the fundamental issue with traditional dedup: these overheads are so outrageous that you are unlikely to ever get them back except on rare and specific workloads.</p>
<h2 id="why-is-traditional-dedup-so-bad">
Why is traditional dedup so bad?
<a href="#why-is-traditional-dedup-so-bad">üîó</a> 
</h2>
<p>All of the detail of dedup is in how the table is stored, and how it interacts with the IO pipeline. There‚Äôs three main categories of problem with the traditional setup:</p>
<ul>
<li>the construction and storage of the dedup table itself</li>
<li>the overheads required to accumulate and stage changes to the dedup table</li>
<li>the problem of ‚Äúunique‚Äù entries in the table</li>
</ul>
<h3 id="the-dedup-table">
The dedup table
<a href="#the-dedup-table">üîó</a> 
</h3>
<p>Traditional dedup implemented the dedup table in probably the simplest way that might work: it just hooked up the standard OpenZFS on-disk hashtable object and called it a day. This object type is a ‚ÄúZAP‚Äù, and it‚Äôs used throughout OpenZFS for file directories, property lists and internal housekeeping. It‚Äôs an entirely reasonable choice. It‚Äôs also really not well suited to an application like dedup.</p>
<p>A ZAP is a fairly complicated structure, and I‚Äôm not going to get into it here. For our purposes, it‚Äôs enough to know that each data block in a ZAP object is an array of fixed-size ‚Äúchunks‚Äù, with a single key/value consuming as many chunks as are needed to hold the key, the data, and and a header describing how the chunks are being used.</p>
<p>A dedup entry has a 40-byte key. The value part can be up to 256 bytes, however this is compressed before storing it, so let‚Äôs assume a common case of 64 bytes to actually stored. Each chunk inside the ZAP is 24 bytes, and can contain either the header, or up to 21 bytes of key or value data. All together, we‚Äôre looking at <code>ceil(40/21) + ceil(64/21) + 1 == 7</code> chunks per entry. A typical dedup ZAP block is 32K, which has space for 1320 chunks (ZAP blocks themselves have their own header describing the chunks). So a single dedup block has space for <code>1320/7 = 188</code> ‚Äútypical‚Äù entries.</p>
<p>We could certainly create a better format tailored to storing dedup entries, but the format is not the immediate issue here. The real problem is one present throughout OpenZFS wherever a data block is carrying an array of unrelated items: amplification. OpenZFS never writes partial blocks, and it never overwrites a block in place. So if we want to update a single dedup entry, we need to load the entire block from disk, modify just the bit we want, and write it back out, in full, as a brand-new block. And then the new block pointer needs to be written to an indirect block, and its new block pointer to another indirect, or the dnode, and so on up and up to the top of the tree. This is of course no different to any other OpenZFS write, and further up the tree we go the more that overhead is amortised across writes from the entire pool. But within the dedup ZAP, it‚Äôs a read-modify-write cycle for every single block written, because at minimum we have to bump a refcount.</p>
<p>That‚Äôs just a single entry update. If two writes were done within the same transaction, then that‚Äôs almost certain to be two different ZAP blocks we need to do that read-copy-write change on. Dedup mandates a cryptographically-strong and collision-resistant checksum to use as the key, which means the chance of any two arbitrary checksums falling close enough to land in the same ZAP block is small.</p>
<p>This is where the old recommendations suggesting that dedup requires enormous amounts of RAM ultimately come from. Reading a dedup table is like reading any other data in OpenZFS: it gets cached in the ARC. If you have enough RAM such that the ARC never needs to evict any part of the dedup table, then you can largely cut out the entire read part of the table update.</p>
<p>This is also where the rarely-seen <code>dedup</code> vdev class can help. If you add a sufficiently large and fast <code>dedup</code> vdev to your pool, then you may be able to reduce your memory requirements a little. This still ends up being a challenging build, because at scales that make dedup worthwhile, you really need to build that vdev out of something large enough to hold the entire table, and fast enough the overhead of not being memory is still workable. Multi-terabyte NVMe devices are great if you can afford them, but it‚Äôs not for the faint of heart or light of wallet.</p>
<h3 id="the-live-entry-list">
The live entry list
<a href="#the-live-entry-list">üîó</a> 
</h3>
<p>There is another significant memory use in traditional dedup, that isn‚Äôt as well known and has no good way to balance it against other factors.</p>
<p>Every write in OpenZFS is assigned to a ‚Äútransaction‚Äù, identified by a numerical ‚Äútransaction id‚Äù. Data is written out to disk as it becomes ready, then every so often that transaction is closed and all the metadata for the transaction, which includes dedup table updates, all those block pointer updates mentioned above, and various other bits of housekeeping are all written down. By default this happens no more than 5 seconds since the last time, but in practice it‚Äôs when there‚Äôs a gap in userspace activity.</p>
<p>Imagine you wrote, say, five instances of the same data at the same moment, to a dataset with dedup enabled. Imagine also that this is brand-new data, not currently in the dedup table. You would want this to only be written once, and a dedup table entry for this block to have a refcount of 5.</p>
<p>Because these are data writes, they begin ‚Äúimmediately‚Äù. But if you recall the IO path above, each one needs to look up the dedup table first to decide if it should really be written, or just bump the refcount. The dedup table lookup function will be called five times, all would end up trying to read the relevant part of the dedup ZAP (though the ARC would reduce it to one physical read), and all would discover that the entry doesn‚Äôt exist, and so let the writes through. Finally, all would try to create a new entry with refcount 1. We end up with some distinctly un-duplicated data, and a dedup table that has no reflection on reality.</p>
<p>So instead, OpenZFS keeps an in-memory list of ‚Äúlive‚Äù entries. These are held entirely in memory, and keep track of entries created or modified on this transaction. The dedup table lookup function starts by checking this list for the requested entry. If it‚Äôs there, the live entry refcount is bumped and it is returned. If it‚Äôs not there, then it will create a new live entry, flag it as ‚Äúin progress‚Äù, then it will call down to the ZAP layer to get the dedup entry proper. When that entry comes back, it unpacks it into the live entry, flags it as ‚Äúready‚Äù and then returns it. Meanwhile, the other write threads will arrive, look up the live entry, see that it‚Äôs ‚Äúin progress‚Äù, set up to be woken when it‚Äôs ready, and go to sleep. When they get woken, they will see that the flag has changed to ‚Äúready‚Äù, bump the refcount and return it.</p>
<p>Then, at the end of transaction, the live entry list is walked, and the relevant details are copied into the dedup ZAP.  Because there‚Äôs one and only one live entry for every checksum, each dedup ZAP entry only gets one update. We‚Äôre also applying all of the changes all at once, which is our best chance to be updating multiple entries within the same block.</p>
<p>Overall, this is a reasonable model, and matches the rough model everywhere else in OpenZFS: do all the data work during the transaction, and when the transaction closes, resolve all the associated metadata changes and write them all out. If you‚Äôve ever heard an OpenZFS developer talk about ‚Äúopen‚Äù and ‚Äúsyncing‚Äù contexts, this is what they‚Äôre talking about.</p>
<p>The problem? These live entries are enormous: 424 bytes each. The raw entry that we load from and save to the ZAP is 296 bytes (bigger than the ~104 because this version is uncompressed), which is a problem on its own. However there is also 128 bytes of housekeeping stuff (like the ‚Äúin progress‚Äù and ‚Äúready‚Äù flags and associated locks). It doesn‚Äôt take long for this list to grow very large, and although it‚Äôs cleared out at the end of every transaction, the peaks can be pretty high.</p>
<p>And this is kernel slab memory, not ARC memory. It can‚Äôt be reclaimed when the system is under pressure. There‚Äôs nothing you can tune or configure to bring this down.</p>
<p>It is a little more situational, as it will only grow in proportion to the amount of different things you‚Äôre writing each transaction. That‚Äôs little comfort though, as you‚Äôre only using dedup if you have a lot to write! So in the end, you still need a ton of memory if you want to actually make use of your dedup table.</p>
<h3 id="unique-entries">
Unique entries
<a href="#unique-entries">üîó</a> 
</h3>
<p>The biggest drag on all the dedup table is the space required to track unique entries. For dedup to work, we have to track everything we have stored on the disk, but, we only get any benefit when the refcount goes greater than 1. Any block that we have only one copy of is just consuming space in the dedup table, waiting for the day that something writes exactly the same data. If that never happens, then it‚Äôs a cost that we can never claw back.</p>
<p>And, since dedup is performed on the data after encryption and compression, and on the block level, then it‚Äôs not just the same <em>data</em>, but the same compression method, encryption keys, and alignment within the file. And this is why dedup is worse than useless on general purpose workloads, because there is just so little data that is truly ‚Äúthe same‚Äù.</p>
<h2 id="how-does-fast-dedup-fix-all-this">
How does fast dedup fix all this?
<a href="#how-does-fast-dedup-fix-all-this">üîó</a> 
</h2>
<p>What we call ‚Äúfast dedup‚Äù is a suite of changes that together try to tackle the above problems. Put simply, the goal is to reduce the amount we store in the table, and when we must store something, be much smarter about how we accumulate and stage those changes, and then provide tools to allow the operator to limit and manage the table conetns.</p>
<h3 id="making-the-live-entry-list-smaller">
Making the live entry list smaller
<a href="#making-the-live-entry-list-smaller">üîó</a> 
</h3>
<p>The first place we started was to reduce the memory footprint of the live entry list. The dedup table is a regular stored object, accessed through the ARC, so for that we have many more optimisation options available to us. The live entry list however is exactly that: a simple list, recording every entry touched on this transaction, pinned in memory. We can‚Äôt get rid of it within the current architecture, so we just had to make it smaller.</p>
<p>The live entry type <code>ddt_entry_t</code> was not very well laid out. First, it used a few large numeric types to store simple flags; those were replaced with a bitfield. Next, some of the entry synchronisation fields (recall the ‚Äúwrite five‚Äù example above) were simplified. Finally, it carried 40 bytes of state that is only needed when a dedup‚Äôd data block was first being written, or is in need of a repair write (the OpenZFS ‚Äúself-healing‚Äù stuff). Once an entry is created, this state is never used, so it was lifted out to a separate ‚ÄúIO state‚Äù object that we create when we need it, and toss when we‚Äôre done. This was all fairly small stuff though.</p>
<p>The big fish is in the stored part of the entry. The key is 40 bytes, 32 of which are the checksum. It‚Äôs effectively a block pointer fragment, so can‚Äôt really be modified further without implications for the block pointer structure proper, which is well outside the scope of this work. More importantly though, we actually wanted to keep the key the same for compatibility with existing dedup tables. Not strictly necessary, but there‚Äôs no gains to be made that are significant enough to warrant the complexity of converting back to an old format when needed.</p>
<p>The value part is a different story. In traditional dedup, an entry contains four ‚Äúphysical‚Äù entries, which look like this:</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> ddt_phys {
</span></span><span><span>    <span>dva_t</span>       ddp_dva[SPA_DVAS_PER_BP];
</span></span><span><span>    <span>uint64_t</span>    ddp_refcnt;
</span></span><span><span>    <span>uint64_t</span>    ddp_phys_birth;
</span></span><span><span>} <span>ddt_phys_t</span>;
</span></span></code></pre></div><p>That‚Äôs three 128-bit DVAs, the refcount for this entry, and the birth time (transaction id) for the entry. This is all pretty reasonable, and you can see how it can be combined with the key to produce an almost-complete block pointer (good enough to scrub the block anyway).</p>
<p>But wait, <em>four</em>? Why four? Well.</p>
<p>OpenZFS datasets have a <code>copies</code> parameter, that says how many copies of the block data should be written out. If you recall above I said that during a write, the metaslab allocator is called to allocate space to store the block data, and can return multiple DVAs. That‚Äôs how <code>copies</code> works: the allocator allocates one, two or three regions on the disk of the right size, the data is written to all of them, and that many DVAs go in the block pointer.</p>
<p>The thing is, you can change this property live, and it does what most property changes do, which is to affect all future writes, while leaving existing data on disk.</p>
<p>Consider what that means for dedup. Say you have a dataset with <code>copies=1</code> (the default), and you write a block. The block pointer gets one DVA (the other two are all-zero). You copy it a few times, which reuses the DVA and bumps the dedup refcount. Then you change to <code>copies=2</code> and copy the block again. The entry is looked up in the dedup table, but only has one DVA when the write policy is requesting two. What do we do?</p>
<p>Traditional dedup‚Äôs answer is to treat this as a brand-new write. It goes through to the allocator, two DVAs are allocated and written. Then the dedup entry is updated, but instead of bumping the refcount for the 1-copy ‚Äúphysical‚Äù entry (at <code>dde_phys[1]</code>), it instead copies the DVAs into the 2-copy entry (at <code>dde_phys[2]</code>, and sets the refcount there to 1. And from then on, those two variants of the block are treated effectively as separate dedup entries with a common key.</p>
<p>The thing is, is very unusual for an operator to modify <code>copies=</code> on an existing dataset, and also ill-advised where dedup is in play, because it effectively invalidates your existing dedup table for new writes: they all start back at 1, including using more space! So most of the time, the other ‚Äúphysical‚Äù entries are going to be filled with zeroes, unused. This isn‚Äôt too much of an issue for entries stored in the dedup ZAP, as those are compressed and long runs of zeroes compress reasonably well. But, while they‚Äôre in memory on the live list, they‚Äôre just sitting there, at least 192 bytes of zeroes that will never be needed.</p>
<p>(Astute readers that know that a block pointer can only contain up to three DVAs, and that <code>copies=</code> can be set to 1, 2 or 3, might now be wondering what the fourth entry is for. The answer, these days, is nothing. It used to be where the <code>dedupditto</code> feature lived, storing extra DVAs ‚Äújust in case‚Äù, but it was buggy and not really useful, and was removed years ago. It‚Äôs still supported for very old pools, but modern OpenZFS can only read them, not write them).</p>
<p>After some experimentation, we realised that if we receive a write for a block that is already on the dedup table, but has too few DVAs, all we really have to do is allocate and write enough additional copies of the data to fulfill the request (up to 3), and add those to the dedup entry when we bump the refcount. This does mean we now have blocks on disk with the old number of DVAs, but that‚Äôs ok, as that‚Äôs the same guarantee as before. It does make the ‚Äúlookup entry‚Äù part of the IO pipeline more complex of course, and it does introduce some subtleties when freeing the block when the refcount reaches zero, but that‚Äôs fine - clever and tricky things are ok, for a good cause.</p>
<p>And a good cause this is! New dedup tables created with fast dedup enabled have the ‚Äúvalue‚Äù part of the entry at just 72 bytes, rather than 256 is the traditional version (the extra 8 is for an additional 64-bit integer to support the pruning feature, see below).</p>
<p>Pull this all together, and a single entry in the live list is now 216 bytes, almost half the original 424 in a traditional entry. ‚ÄúHalf the memory‚Äù is a pretty nice thing to be able to put on the future, especially for slab memory that can‚Äôt be easily reclaimed.</p>
<p>The stored entry is technically also smaller, but it‚Äôs still going to hit that ballpark of ~64 bytes after compression. It starts a lot smaller, but is a lot less compressible because it‚Äôs not full of long runs of zeroes that are easy to reduce. Once we take ZAP chunk overheads into account there‚Äôs very little gain made here. But that‚Äôs ok, because reducing the size of the dedup ZAP entries was never really in our plans.</p>
<h3 id="the-dedup-log">
The dedup log
<a href="#the-dedup-log">üîó</a> 
</h3>
<p>As we‚Äôve discussed, the live entry list has a record for every deduplicated modified on the current transaction. At the end of the transaction, these updated entries are written back to the dedup ZAPs. Each entry is surrounded by 187 other entries in the same dedup block, which as the dedup table gets larger, are less and less likely to have been touched on this transaction. So in order to update the entry, we have potentially had to load a full block of entries, which is additional IO or, in the better-but-still-bad scenario, ‚Äúloaded‚Äù the block from the ARC instead. And then, once all the entries are updated, the live entry list is cleared.</p>
<p>After considering some customer workloads, and doing some of our own experiments, we decided that if a block is to be duplicated, it‚Äôs more likely to be one that was ‚Äúrecently‚Äù created or duplicated. Or, put another way, the longer it‚Äôs been since a block was touched, the less likely it is that it will be duplicated or freed in the future. Without thinking very hard this intuitively makes sense; we tend to work with the same bit of data a lot, and then we don‚Äôt touch it again for a while, or ever. If this is true, then it means throwing away the live entry list at the end of the transaction ends up being extremely wasteful, because there‚Äôs a good chance we‚Äôre going to need some or even most of those entries in the very near future!</p>
<p>The thing is, the changes represented by the live entry list ‚Äúbelong‚Äù to the transaction. They <em>must</em> be written down with that transaction, otherwise rolling back to that transaction (eg during crash recovery) will have stale information in the dedup table. So we started thinking about where else we could possibly record these changes such that we could get them back quickly in subsequent transactions, and in a rollback, without wearing the full cost of updating the dedup table proper every time.</p>
<p>The answer of course is the same as it‚Äôs been any time any storage system has wanted to defer work into the future: add a ‚Äújournal‚Äù or ‚Äúlog‚Äù describing the changes, replay the log during crash recovery, and during normal operation, slowly write the logged changes out to their final resting place. The fundamentals of the dedup architecture however, make things a little more complicated, as we‚Äôll see when we imagine building up this system.</p>
<p>So let‚Äôs imagine the simplest thing that might work. At the end of transaction, instead of updating the dedup ZAP, we just dump the entire live entry list as an array of fixed-size entries onto the end of some object, which we declare to be the log. Since the same entry might have been updated on two or more consecutive transactions, and we‚Äôre only appending to the log, this means that the log might contain the same entry more than once. That‚Äôs fine, it just means we should only use the last we see. Every so often, we blast through the log, add the last instance of each entry to the dedup ZAP, and then zero the log. Job done.</p>
<p>This actually works very well for what it is. The log is stored in a regular object, and so is bound to the same transaction as the data changes associated with its entries. Multiple changes to the same entries end up being amortised somewhat; if we only write the log back to the ZAP every five transactions, an entry that changes every five transactions will only be written once. So great, that‚Äôs the write overhead taken care of.</p>
<p>The critical flaw here is on the lookup side. At any point, the write pipeline is going to come asking for an entry. If it hasn‚Äôt been used this transaction (ie it‚Äôs not on the live entry list), it will go to the dedup ZAP and get the entry from there. But if that entry is on the log, then the entry in the ZAP is stale, and we can‚Äôt use it, both because it may be wrong, and because it‚Äôs going to be overwritten when the log is written out.</p>
<p>Our only option then is to search the log to find out if it has a more recent version of the entry. The problem with that is that most of the time it‚Äôs even worse than reading from the ZAP, as the log has no useful ordering, and duplicate entries. We potentially have to read the entire log, however enormous it may be, only to find the entry wasn‚Äôt even there and still have to do a lookup in the ZAP.</p>
<p>What we need is an index of the log, that gives us a fast way to look up any entry that might exist in it. As it turns out, once you remove the overheads of a ‚Äúlive‚Äù object, a single ‚Äúlogged‚Äù entry held in memory is only 144 bytes, for the entire entry. This is small enough that it‚Äôs feasible to keep the entire log in memory, as well as on disk. And then, when doing a lookup, if the entry we want is not on the live entry list, we then check the in-memory log, and if it‚Äôs not there, we go to the dedup ZAP. And then, at end of transaction, we save the updated version of the entry to both the in-memory log and to the on-disk log.</p>
<p>On disk <em>as well</em>? Yes. We still need crash safety. But when we take these two version of the log together, the on-disk log becomes write-only, while all regular activity goes to the in-memory log, that is, the two contain alternate representations of the same data. In the case of rollback or crash recovery (both of which happen at pool import), we simply load the in-memory log from the on-disk log, and move on with life.</p>
<h3 id="incremental-log-flushing">
Incremental log flushing
<a href="#incremental-log-flushing">üîó</a> 
</h3>
<p>Of course, we‚Äôve now introduced some new complexity to help with managing some existing complexity, which naturally means we have to do some work to manage the complexity as well.</p>
<p>We‚Äôve reduced the per-transaction IO overhead of the dedup table to about the smallest it can be, at the cost of the memory required to carry a copy of the log. It‚Äôs smaller on average compared to the ARC overhead, but it‚Äôs not <em>nothing</em>, and we have to keep it in check.</p>
<p>Our earliest version just watched the size of the in-memory tree and when it grew ‚Äútoo big‚Äù, at the end of transaction, we just wrote the entire log out to the dedup ZAP and cleared it. This is less IO <em>in total</em> than if we‚Äôd written those updates to the dedup ZAP at the end of each transaction, but at least that IO was spread across multiple transactions. In our testing, we could easily causes substantial flushing pauses with only a few thousand entries on the list, long before any real memory pressure was fault.</p>
<p>So instead, we changed things so that some amount of the log was written out to the ZAP every transaction. We monitor the log flush rate against the amount of time spent on real IO, so that we write less in busy periods, and more in quiet periods. There‚Äôs some extra consideration there too, like, we may accelerate when the in-memory log is too large and causing memory pressure, and a few other things.</p>
<p>Incremental flushing brought back an older problem though. We want to be able to zero the on-disk log. We know which are the ‚Äúmost recent‚Äù entries on the log, because they‚Äôre the only ones on the in-memory log. But, we don‚Äôt know <em>where</em> in the on-disk log those versions of those entries are, and, because new entries are being added to the log on the same transactions as we are writing them out, we don‚Äôt know which entries on the in-memory log have been written out. Under this model, we cannot zero the on-disk log until and unless the in-memory log is empty, and the in-memory log will only be empty if no updated entries have occurred, which ultimately means that eventually, we have stop and flush the remaining log. And, because the on-disk log is only appended to, the longer we drag out the flushing, the larger it gets.</p>
<p>To handle this, we actually have <em>two</em> logs, each with an in-memory and on-disk version. One of these is only being flushed, the other is only being updated. In this way, we can accumulate new updates on the ‚Äúactive‚Äù log, while the ‚Äúflushing‚Äù log is being emptied. Once it‚Äôs empty, the on-disk flushing log is zeroed, and the two logs are swapped: the old ‚Äúactive‚Äù is now ‚Äúflushing‚Äù and begins being written out, and new changes are written to active. We get our wish that the log needs to be stopped before it can be flushed, without needing to stop the world.</p>
<p>Of course, this adds further complications to the lookup stage, as we now have to look for an entry on the ‚Äúactive‚Äù log list first, and then on the ‚Äúflushing‚Äù log list, before finally going to the ZAP. For obscure reasons, that then means that entries ‚Äúloaded‚Äù from the flushing list then ‚Äùsaved‚Äù to the active list need a little bit of extra finesse, because we can end up with entries on the on-disk ‚Äúflushing‚Äù tree that were never flushed before they were reused. It‚Äôs nothing to worry about; just slightly more complicated dance moves.</p>
<p>There‚Äôs also a ‚Äúlog checkpoint‚Äù. Since checksums are really just very large numbers, they have a very comfortable ordering. So, when we finish flushing on this transaction, we write the last checksum we wrote to the disk (actually to the bonus buffer of the flushing log object). This is there to make import faster; we have to reload both log lists. We can use the checkpoint when reading the flushing log to know which entries have already been flushed and not even bother putting them in the in-memory list.</p>
<p>Finally, there‚Äôs some interesting interactions with pool scans (ie scrub and resilver). Normally, when dedup is enabled, a scan begins by walking the dedup table, reading every block pointer (and taking the wanted action) from every entry within it, and then moving on to the rest of the pool. Every so often, the scan process will record a position in the pool, so that the scan can be resumed from that point.</p>
<p>The problem with the dedup log is that there is no useful notion of ‚Äúposition‚Äù within it to record. The on-disk log has no natural layout as we know, while the in-memory log uses a common structure in OpenZFS called an AVL tree, which does not have a ‚Äústable cursor‚Äù; that is, there‚Äôs nothing you can store to describe a logical position in the tree that would carry over to a different tree with the same structure.</p>
<p>We tried a lot of things to synthesize an AVL cursor, and it is sort of possible, but not within the constraints of the ‚Äúposition‚Äù data we need to save (for those playing along at home, we need to add a 40-byte key to <code>scn_ddt_bookmark</code> within <code>dsl_scan_phys_t</code>). In the end, we take something of a coward‚Äôs way out: when a scrub is requested, we accelerate log flushing; all the log is flushed out to the dedup ZAP, and then do it the old way. Scans set the current transaction as the ‚Äúend of scan‚Äù point, so we don‚Äôt need to worry about changes that come in after, and the dedup ZAP will have everything from before the flush. It does mean that after a crash, the log needs to be re-flushed before the scan can continue, but the expectation is always that the size of the dedup ZAP and the pool data as a whole is always going to dwarf the size of the log.</p>
<h3 id="unique-entries-1">
Unique entries
<a href="#unique-entries-1">üîó</a> 
</h3>
<p>So that was a lot about the logs! If you‚Äôre still reading, well done!</p>
<p>There was one other issue with traditional dedup, and that was the difficulties caused by unique entries vastly inflating the size of the table with entries that never get used. There‚Äôs some new tools to help the operator manage the table size generally, and unique entries specifically.</p>
<p>The big help for unique entries is the new <code>zpool ddtprune</code> command. It will remove some amount of unique entries from all dedup tables on the system, specified by age or percentage. The age option works particularly well with our ideal workload where more recently used data is more likely to be deduplicated. This sort of usage pattern results in a long and aging tail of unique entries that will never be deduplicated. Now you can wholesale get rid of them, and with the new ‚ÄúZAP shrink‚Äù enhancement, dedup ZAP blocks that end up entirely empty as a result of this operation will simply be removed.</p>
<p>Of course, this does mean that if a block whose dedup entry has been removed does later get copied, it will be a new block with a new allocation; there will be no deduplication. That said, if a very old unique block is suddenly copied a dozen times, that will be a dozen references to a single new block, and you‚Äôll have two copies instead of the 13 you‚Äôd have without dedup at all. So you do need to tune the behaviour of <code>ddtprune</code> to match your workload, but it may not be a total disaster if you were to prune too much.</p>
<p>Meanwhile, the pool property <code>dedup_table_quota</code> lets you set a maximum possible size for the dedup tables on your pool. If creating a new entry would take the dedup tables over that limit, the entry won‚Äôt be created and the write will just be a regular non-dedup‚Äôd write. This is good to use in conjunction with a dedicated dedup device where you want it to not spill out to the main device if it gets full.</p>
<h2 id="thats-a-lot-anything-else">
That‚Äôs a lot! Anything else?
<a href="#thats-a-lot-anything-else">üîó</a> 
</h2>
<p>Just a handful of operational improvements.</p>
<p><code>zpool prefetch -t ddt</code> will preload the dedup tables into the ARC, which can help with performance immediately after pool import. In traditional dedup it‚Äôs obvious how this helps, but even in fast dedup, entries not on the log still need to be loaded from the ZAPs, and flushing still needs the ZAPs nearby to write too, so having them in the ARC still helps.</p>
<p>There‚Äôs a new collection of kstats, in <code>/proc/spl/kstat/zfs/&lt;pool&gt;/ddt_stats_&lt;checksum&gt;</code> on Linux or <code>kstat.zfs.&lt;pool&gt;.misc.ddt_stats_&lt;checksum&gt;</code> on FreeBSD. These will show various live stats for the dedup subsystem, including counts of lookups, hit rates on the live and log lists and the dedup ZAPs, and the log flushing rates.</p>
<p>There‚Äôs also a new collection of tuneables, <code>/sys/modules/zfs/parameters/zfs_dedup_log_*</code> on Linux or <code>vfs.zfs.dedup.log_*</code> on FreeBSD. These control various inputs into how much log flushing occurs each transaction. As usual, the defaults are carefully considered and should be fine for anyone, but when they‚Äôre not, having some knobs to adjust is a game changer.</p>
<p>And then the existing dedup-aware things (<code>zpool status -D</code>, <code>zdb -D</code>, <code>zdb -S</code>, etc) have been updated to understand all this new stuff.</p>
<h2 id="nice-cant-wait-to-use-this-with-my-existing-dedup-table">
Nice! Can‚Äôt wait to use this with my existing dedup table
<a href="#nice-cant-wait-to-use-this-with-my-existing-dedup-table">üîó</a> 
</h2>
<p>üò¨</p>
<p>So almost all of the above requires on-disk format changes that your existing dedup tables don‚Äôt have. This was unfortunate, but intentional: the project brief explicitly excluded a migration path, because it‚Äôs complicated (read: expensive) and there‚Äôs very few dedup installations out there of sufficient size and complexity to require it.</p>
<p>However, we didn‚Äôt go out of our way to make it not work, or to prevent it from being possible in the future.</p>
<p>For existing tables, anything that doesn‚Äôt require an on-disk format change should work:</p>
<ul>
<li>Table quotas (<code>dedup_table_quota</code> pool property)</li>
<li>Table prefetch (<code>zpool prefetch -t ddt</code>)</li>
<li>Lookup and hit counts (<code>ddt_stats_*</code> kstats)</li>
<li>ZAP ‚Äúshrink‚Äù (collapsing whole empty blocks; this is a general ZAP enhancement in 2.3)</li>
</ul>
<p>The dedup log feature should be straightforward to make work with traditional tables. Nothing in it cares about the size of the entries (in fact, ‚Äúlog‚Äù and ‚Äúflat entry‚Äù are two separate subfeatures. The only missing piece is something to set up the new ‚Äúcontainer‚Äù object for an existing table, which would be fairly easy to do. Of course, you would not get the smaller live and log list entries in memory or on disk, so some of the sizing tuning would be different.</p>
<p>Unique entry pruning (<code>zpool ddtprune</code>) should be straightforward to add for only the ‚Äúpercentage of uniques‚Äù mode. The ‚Äúage‚Äù mode is not possible, as it requires data in the new entry format which doesn‚Äôt exist in the traditional format.</p>
<p>Converting your old tables is not currently possible. In the simplest case, where <code>copies=</code> has never been changed, it would be as straightforward as creating a new ZAP, walking over the existing ZAP, converting the entry and copying it in. Doing this online would be complicated as we‚Äôd need to either be reading from both old and new ZAPs, or writing down to both ZAPs and then switch over at the end. Doing it offline would be easier, and could be done through a userspace tool, but of course requires taking the pool offline.</p>
<p>If <code>copies=</code> has been changed and there are existing entries carrying both kinds, then a complete conversion is not possible, as the whole method by which existing ‚Äúvariants‚Äù of a block are upgraded is different and there just isn‚Äôt room in a new entry to store it all. The most fortunate cases would be if one and only one of the variants has a refcount greater than 1, as those are uniques that could be ‚Äúpruned‚Äù. Otherwise there‚Äôs nothing we can do with those (though I have just had a strange thought involving the BRT).</p>
<p>And of course, the usual ‚Äútrick‚Äù of sending the deduplicated dataset to another pool where the new dedup is available will certainly do the job.</p>
<p>If you are one of those people with an enormous dedup table and you‚Äôre interested in funding development of one or more of these options, <a href="https://klarasystems.com/company/contact-us/">Klara would love to talk to you</a>.</p>
<h2 id="is-deduplication-_really_-good-now">
Is deduplication <em>really</em> good now?
<a href="#is-deduplication-_really_-good-now">üîó</a> 
</h2>
<p>I think it really is good enough to at least play with. The overheads should at least be reduced enough to make it useful in more marginal situations.</p>
<p>Is it <em>really good</em> though? Probably not, not yet, but ‚Äúnot yet‚Äù is part of the point of all this. We‚Äôve taken perhaps the most unloved OpenZFS feature, given it a substantial upgrade that hopefully will get more people taking a look at it, or maybe even taking a <em>second</em> look at it. Meanwhile, the code is now better structured, commented and understood by a lot more people, and has a lot more obvious points to add and change behaviour. It can finally join all the other features in the OpenZFS toolbox, and from there, who knows what it can become.</p>
<h2 id="i-dont-get-it-after-all-this-if-its-good-enough-why-shouldnt-i-enable-dedup-everywhere">
I don‚Äôt get it. After all this, if it‚Äôs good enough, why shouldn‚Äôt I enable dedup everywhere?
<a href="#i-dont-get-it-after-all-this-if-its-good-enough-why-shouldnt-i-enable-dedup-everywhere">üîó</a> 
</h2>
<p>If you‚Äôre like most people, you‚Äôre thinking about transparent deduplication because you have a general-purpose workload, that is, some ‚Äúbig ball of miscellaneous files‚Äù setup, like a local desktop or laptop. Or maybe a bigger version of that, for example, you provide exactly that service for all the people in your organisation. And good disks cost money, and times are tough, and you‚Äôre thinking well, if I can turn this thing on and it saves a bit of data, wouldn‚Äôt that be worth it?</p>
<p>I actually agree with this in theory.</p>
<p>As we‚Äôve seen from the last 7000+ words, the overheads are not trivial. Even with all these changes, you still need to have a lot of deduplicated blocks to offset the weight of all the unique entries in your dedup table.</p>
<p>But, what might surprise you is how rare it is to find blocks eligible for deduplication are on most general purpose workloads.</p>
<p>Consider a simulated dedup run on my laptop. This is the machine I use for <em>everything</em>, home and work, easily 12 hours every day.</p>
<pre tabindex="0"><code>$ zpool list crayon
NAME     SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
crayon   444G   397G  47.3G        -         -    72%    89%  1.00x    ONLINE  -
</code></pre><pre tabindex="0"><code>$ zdb -S crayon
Simulated DDT histogram:

bucket              allocated                       referenced
______   ______________________________   ______________________________
refcnt   blocks   LSIZE   PSIZE   DSIZE   blocks   LSIZE   PSIZE   DSIZE
------   ------   -----   -----   -----   ------   -----   -----   -----
     1    11.7M    708G    362G    373G    11.7M    708G    362G    373G
     2    12.2K    666M    284M    293M    25.1K   1.32G    582M    602M
     4      294   4.44M    962K   1.55M    1.44K   22.0M   4.67M   7.76M
     8        5     99K     41K     44K       52   1.06M    440K    464K
    16        1   7.50K   3.50K      4K       26    195K     91K    104K
 Total    11.7M    708G    362G    373G    11.7M    709G    362G    373G

dedup = 1.00, compress = 1.96, copies = 1.03, dedup * compress / copies = 1.90
</code></pre><p>So for a table of 11.7M entries, the number of those that represent something we actually managed to deduplicate is a literal rounding error. It‚Äôs pretty much entirely uniques, pure overhead. Turning on dedup would just add IO and memory pressure for almost nothing.</p>
<p>But the real reason you probably don‚Äôt want dedup these days is because since OpenZFS 2.2 we have the BRT (aka ‚Äúblock cloning‚Äù aka ‚Äúreflinks‚Äù). (I acknowledge that it had a shaky start, which has been written and presented on extensively, so I won‚Äôt do that again, but lets just say it‚Äôs all good now).</p>
<p>You may recall, way back at the top of this post, we asked ‚Äúwhat even is dedup?‚Äù, and we defined it as:</p>
<blockquote>
<p><em>When OpenZFS prepares to write some data to disk, if that data is already on disk, don‚Äôt do the write but instead, add a reference to the existing copy.</em></p>
</blockquote>
<p>The dedup table and its entourage all exist to answer ‚Äúis this data already on disk?‚Äù, but in one quite niche situation: when you don‚Äôt have any other knowledge or context about the data being written.</p>
<p>The thing is, it‚Äôs actually pretty rare these days that you have a write operation coming from some kind of copy operation, but you don‚Äôt <em>know</em> that came from a copy operation. In the old days, a client program would read the source data and write to the destination data, and the storage system would see these as two unrelated operations. These days though, ‚Äúcopy offloading‚Äù is readily available, where instead of reading and writing, the program will tell the storage system ‚Äúcopy this source to that destination‚Äù and the storage system is free to do that however it wants. A naive implementation will just do the same read and write as the client would, but a smarter system could do something different, for example, not doing the write and instead just reusing the existing data and bumping a refcount.</p>
<p>For Linux and FreeBSD filesystems, this ‚Äúoffload‚Äù facility is the <code>copy_file_range()</code> syscall. Most systems have an equivalent; macOS calls it <code>copyfile()</code>, Windows calls it <code>FSCTL_SRV_COPYCHUNK</code>. NFS and CIFS support something like it, OS block device drivers are getting equivalents, even disk protocols have something like it (eg SCSI EXTENDED COPY or NVMe Copy).</p>
<p>If you put all this together, you end up in a place where so long as the client program (like <code>/bin/cp</code>) can issue the right copy offload call, and all the layers in between can translate it (eg the Window application does <code>FSCTL_SRV_COPYCHUNK</code>, which Samba converts to <code>copy_file_range()</code> and ships down to OpenZFS). And again, because there‚Äôs that clear and unambiguous signal that the data already exists and also it‚Äôs <em>right there</em>, OpenZFS can just bump the refcount in the BRT.</p>
<p>Most importantly is the space difference. If a block is never cloned, then we never pay for it, and if it is cloned, the BRT entry is only 16 bytes.</p>
<p>On my pool, where the two major users of <code>copy_file_range()</code> (that I know about) are <code>cp</code> and <code>ccache</code>, my BRT stats are rather nicer:</p>
<pre tabindex="0"><code>$ zdb -TTT crayon
BRT: used 292M; saved 309M; ratio 2.05x
BRT: vdev 0: refcnt 12.2K; used 292M; saved 309M

BRT: vdev 0: DVAs with 2^n refcnts:
			 1:  11788 ****************************************
			 2:    645 ***
			 3:     40 *
			 4:      3 *
			 5:      1 *
</code></pre><p>If you compare to the dedup simulation, I‚Äôm not saving as much raw data as dedup would get me, though it‚Äôs pretty close. But I‚Äôm not spending a fortune tracking all those uncloned and forgotten blocks.</p>
<p>Now yes, this is not plumbed through everywhere. zvols don‚Äôt use the BRT yet. Samba has only just gotten support for OpenZFS very recently. Offloading in Windows is only relatively new. The situation is only going to get better, but maybe it‚Äôs not good enough yet. So maybe you might be tempted to try dedup anyway, but for mine, I can‚Äôt see how the gains would be worth it even without block cloning.</p>
<p>And this is why I say you probably don‚Äôt want it. Unless you have a very very specific workload where data is heavily duplicated and clients can‚Äôt or won‚Äôt give direct ‚Äúcopy me!‚Äù signal, then just using block cloning is likely to get you a good chunk of the gain without the outsized amount of pain.</p>
<h2 id="in-summary">
In summary
<a href="#in-summary">üîó</a> 
</h2>
<p>Dedup is about balancing IO throughput, memory usage and dedup table size. Traditional dedup has a very tiny ‚Äúsweet spot‚Äù where these factors balance nicely, while being ruinous if you fall out of it. Fast dedup improves all three, making it far easier to balance these factors and rather less of a disaster if it doesn‚Äôt work out. However, it is still only of benefit if you have a truly enormous amount of data, that gets copied a lot, and aren‚Äôt able to take advantage of other ‚Äúzero-copy‚Äù options within OpenZFS, like block cloning or snapshot clones.</p>
<p>Extra congratulations if you got this far. I hope this was of interest!</p>
<hr>
<p><em>Thanks to <a href="https://aus.social/@mattcen">@mattcen</a> and <a href="https://hachyderm.io/@adavis">@adavis</a> for numerous grammar and spelling fixes. Much obliged! üíö</em></p>






</article>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hi Google, please stop pooping the bed: a desperate plea from the indie web (196 pts)]]></title>
            <link>https://build.shepherd.com/p/hi-google-please-stop-the-bed-a-desperate</link>
            <guid>42000651</guid>
            <pubDate>Wed, 30 Oct 2024 21:35:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://build.shepherd.com/p/hi-google-please-stop-the-bed-a-desperate">https://build.shepherd.com/p/hi-google-please-stop-the-bed-a-desperate</a>, See on <a href="https://news.ycombinator.com/item?id=42000651">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Join the rebellion and help me create the indie book platform readers and authors deserve! Three hurrahs for our&nbsp;818 Founding Members who keep us independent and fund new features. </span><a href="https://forauthors.shepherd.com/membership-for-readers" rel="">Readers</a><span> and </span><a href="https://forauthors.shepherd.com/membership" rel="">authors</a><span> can become Founding Members (</span><em>both get special perks, and more perks are coming</em><span>).</span></p><div><figure><a target="_blank" href="https://www.reddit.com/r/IASIP/comments/raem5o/is_who_pooped_the_bed_the_greatest_iasip_episode/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png" width="399" height="294.95043103448273" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:686,&quot;width&quot;:928,&quot;resizeWidth&quot;:399,&quot;bytes&quot;:1018372,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://www.reddit.com/r/IASIP/comments/raem5o/is_who_pooped_the_bed_the_greatest_iasip_episode/&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1245c635-e700-421c-a6f5-9275d61d9af3_928x686.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Google is killing independent websites by burying them in the search results, even when we perfectly follow their guidelines. </p><p><strong>Nobody" is sure what is going on, but their search engine started breaking down about 16 months ago.</strong><span> </span></p><p><span>Some people believe they have lost control of their AI ranking systems, while others believe that the McKinsey alumni who run Google Search are purposefully doing this to increase ad earnings (</span><em>DOJ leaks from the ongoing trials hint at this</em><span>). </span></p><p><strong>Let me show you how Google is üí© the bed‚Ä¶</strong><span> </span></p><p>Over the last 16 months, we‚Äôve seen an 86% decline from Google to the most-loved section of the website. </p><p><span>This section has been incredibly popular with Google for years and it has&nbsp;</span><strong>sky-high engagement stats from visitors</strong><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png" width="1456" height="685" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:685,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:169493,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d0edc90-3990-469e-935e-660a4becaa3b_1912x900.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Google changes all the time, but </span><strong>a drop like this is insane</strong><span>. This is destroying many websites you know and love. </span></p><p>Google's promise to website owners was simple: create great content, and Google will rank those pages if those pages satisfy users.</p><p>This promise has been broken; let me show you how. </p><p>I am a data nerd. I love building good UX and work constantly to provide my visitors with an amazing experience. </p><p>I even do anonymous user video testing with every feature to ensure it is easy to navigate and that readers love the experience. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp" width="360" height="258" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:344,&quot;width&quot;:480,&quot;resizeWidth&quot;:360,&quot;bytes&quot;:3155864,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb0ad070-bb2e-46f0-ab5f-4d57cc38eee1_480x344.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><ul><li><p>60% of our visitors read 75% or more of the pages in this section. </p></li><li><p><span>On average, visitors spend 5 minutes and 1 second on pages in this section (</span><em>the real number is higher, as this only updates if an action is triggered on the page</em><span>).  </span></p></li></ul><ul><li><p>12% of visitors click to learn more about a book or go to a bookstore to learn more. This is an excellent sign that the reader found something that intrigued them enough to dig deeper.</p></li><li><p>8% of visitors click to visit another book list that we recommend at the end of the recommendations. </p></li><li><p>And more‚Ä¶ </p></li></ul><p><strong>My point is that this section is incredibly popular with visitors, and Google used to see and reward that. </strong><span>This is happening to hundreds of thousands of websites, and Google is not saying anything. </span></p><p><span>I asked Kevin Miller to share his </span><a href="https://shepherd.com/best-books/battle-of-midway" rel="">five favorite books about the Battle of Midway</a><span> and why he thinks each of those is a great read (</span><em>click the below to read that</em><span>). </span></p><div><figure><a target="_blank" href="https://shepherd.com/best-books/battle-of-midway" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png" width="489" height="297.9004120879121" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:887,&quot;width&quot;:1456,&quot;resizeWidth&quot;:489,&quot;bytes&quot;:2922668,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://shepherd.com/best-books/battle-of-midway&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a730161-eb0a-483a-9e3e-5e4c4eed0689_2448x1492.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Kevin has written a book on the Battle of Midway, is the Executive Vice President of the Naval Aviation Museum, and is a former U.S. Navy Fighter Pilot. </p><p>He is exactly the person you want making an expert-led book recommendation about the Battle of Midway.</p><p><span>Since it was published, </span><strong>Kevin‚Äôs page has been in the top 3 results</strong><span> for Google searches related to the ‚Äúbest books on Battle of Midway.‚Äù</span></p><p><strong>‚Ä¶</strong></p><p><strong>Then Google üí© the bed.</strong></p><p>‚Ä¶.</p><p><strong>Kevin‚Äôs page now appears on the 3rd page, or not at all, for all searches.</strong><span> </span></p><p>How does Kevin‚Äôs page engage readers?</p><ul><li><p><span>On average, visitors spend 7 minutes and 16 seconds on his page (</span><em>the real number is higher as this only updates if an action is triggered</em><span>). And 55% of visitors read to the 75% mark or more. </span></p></li><li><p><span>15% of visitors click to explore a book or go to a bookstore (</span><em>to learn more about a specific book</em><span>). This is a very good sign that the reader found something that intrigued them. </span></p></li><li><p>15% of visitors go within Shepherd to a related topic, genre, or book on this page. </p></li><li><p>7.5% of visitors check out a recommended list at the bottom of the page or related topic. </p></li></ul><p><strong>My point is that this page crushes it for a large chunk of readers who are looking for an answer to their query on Google. </strong><span>And even worse, what Google is ranking instead is not great‚Ä¶ </span></p><p>The page ranking #2 is one I created to test how badly Google is üí© the bed. </p><p><span>It is </span><a href="https://bookshop.org/lists/the-best-books-about-the-battle-of-midway" rel="">a list I created on Bookshop.org that has 4 books</a><span>, no personal details, no expertise, and nothing of value. It even links to Kevin‚Äôs list on Shepherd since it is a terrible derivative of that list. </span></p><div><figure><a target="_blank" href="https://bookshop.org/lists/the-best-books-about-the-battle-of-midway" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png" width="591" height="118.52472527472527" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/233954df-7670-4fe9-8088-d459d01daca2_1578x316.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:292,&quot;width&quot;:1456,&quot;resizeWidth&quot;:591,&quot;bytes&quot;:144903,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://bookshop.org/lists/the-best-books-about-the-battle-of-midway&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F233954df-7670-4fe9-8088-d459d01daca2_1578x316.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><ul><li><p><span>There is </span><a href="https://www.goodreads.com/shelf/show/battle-of-midway" rel="">a Goodreads list of all books tagged Battle of Midway</a><span>. They are not sorted by rating, and there is no expert explaining why they are a good resource. It is not the worst list, I guess, but it is just a collection of the 100 books on the battle that Goodreads has in their database. </span></p></li><li><p><a href="https://www.reddit.com/r/WarCollege/comments/nrean5/ive_taken_an_interest_in_the_battle_of_midway/" rel="">A 3-year-old Reddit thread</a><span> with only one book recommendation. I generally like Reddit, but this thread isn‚Äôt very helpful. </span></p></li><li><p><a href="https://store.pacificwarmuseum.org/products/shattered-sword-the-untold-story-of-the-battle-of-midway" rel="">A Museum e-commerce page selling a book about the battle for $35 dollar</a><span>s. There is zero curation, and it just has the default book description. </span></p></li><li><p><a href="https://www.quora.com/What-is-a-good-book-on-the-Battle-of-Midway-What-was-it-like-to-be-in-a-B-17-during-WWII-Why-weren-t-we-able-to-stop-Japan-from-attacking-us-at-Pearl-Harbor" rel="">A Quora post with only 2 answers</a><span>. The first answer recommends a single book, and the other answer can only be viewed if you pay for Quora Plus. </span></p></li><li><p>Google‚Äôs book widget, which shows book covers that match the topic? Wee! Zero curation or expertise or usefulness. </p></li><li><p>An Amazon link to a single book about the Battle of Midway. How is that helpful? </p></li><li><p><a href="https://www.goodreads.com/shelf/show/midway" rel="">Another Goodreads list with 829 books about ‚ÄúMidway.</a><span>‚Äù The 3rd book recommended is Dune, and the fourth is Little Women. Is that helpful?</span></p></li><li><p><span>This is a&nbsp;</span><a href="http://www.midway42.org/Library.aspx" rel="">decent result from the Midway Library</a><span>&nbsp;(</span><em>except it hasn‚Äôt been updated since 2016</em><span>). However, they do have some good recommendations and are curated by experts (</span><em>although I am not sure who</em><span>). The collection also movies and other media.</span></p></li><li><p><span>A 2010 post on a </span><a href="https://boardgamegeek.com/thread/509817/looking-for-a-good-book-on-the-battle-of-midway" rel="">Board Game forum</a><span> asking for good books about the Battle of Midway. Really Google? </span></p></li><li><p>A B&amp;N link to a single book about the Battle of Midway. </p></li></ul><p><strong>My point is that Google has elevated bad results that do not help users and buried independent websites like ourselves. </strong></p><p><span>In many cases, we are seeing websites that have served visitors for years lose 95%+ of their traffic from Google and not even rank for their brand name. This is a shadow ban where something in Google‚Äôs system has effectively blocked that website from existing. </span><strong>Google refuses to acknowledge it is happening or speak about it.</strong><span> </span></p><p>Meanwhile, search engines like DuckDuckGo and Bing rank Kevin‚Äôs page in the #1 and #3 spot, as they should. </p><p><span>I am lucky because while Google Search is breaking, I am receiving increasing traffic from Bing, DuckDuckGo, social media, and other sources. That has allowed us to stay alive along with the support of our Founding Members (</span><em>who financially support the website for the long term</em><span>). </span></p><p><strong>I have many friends and acquaintances who are going bankrupt and shutting down fantastic independently run websites. It is sad to see.</strong><span> </span></p><p>The independent web is in danger, and Google is destroying it. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp" width="390" height="390" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b8a7859e-8434-4427-9216-17c77eb50565_500x500.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:500,&quot;resizeWidth&quot;:390,&quot;bytes&quot;:475138,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8a7859e-8434-4427-9216-17c77eb50565_500x500.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I used to love Google. </p><p>It was magic compared to Altavista. </p><p>I could type in what I wanted, and you would return a result that was what I wanted. At the very least, I had to try a few results before finding what I was specifically looking for.  </p><p><span>Now, it is just a wall of ads, unhelpful results, spam from big publishers like Forbes, and Reddit (</span><em>I like Reddit, but you do have to vet them still</em><span>).  I won‚Äôt even mention the AI overviews‚Ä¶ which could be useful but are instead plastered on every surface you can find. </span></p><p><strong>Google, you have to fix search so it works again.</strong><span> </span></p><p><span>It has gotten so bad I moved to the </span><a href="https://kagi.com/" rel="">Kagi search engine</a><span>, and my wife switched to using ChatGPT 75% of the time. </span></p><p><span>Google has released several core updates since this started, </span><strong>and not a single website has really recovered.</strong><span> </span></p><p><span>It has also not provided </span><strong>enough good</strong><span> information about what is going on. Google has search liaisons who are amazing human beings, but they seem unable to share real information or help anyone. They just say the same corporate speak without saying much of anything. </span></p><ul><li><p><span>Dear&nbsp;</span><a href="https://twitter.com/JohnMu" rel="">John Mu</a><span>&nbsp;and&nbsp;</span><a href="https://x.com/dannysullivan?lang=en" rel="">Danny Sullivan</a><span>&nbsp;(</span><a href="https://x.com/searchliaison" rel="">work</a><span>), I have to do a shot of Tequilla every time you say, ‚Äú</span><em>Just make good content,</em><span>‚Äù so please stop; I am begging you‚Ä¶ Please provide real information and help the website owners you are destroying. I know you want to, as you are both amazing people. </span></p></li></ul><p><strong>Other ideas:</strong></p><ul><li><p>I‚Äôd love to see a partner program where Google has website owners embed code on their websites to pull in anonymous data about engagement so they can better reward good websites. I HATE spam and SEO spam, and I think this could help fix the problem. Google has something similar on YouTube, given their control of that platform, and I think this could work by helping them identify who wants to build a better web. </p></li><li><p>Build real help into GSC. Tell website owners what needs to be improved and why. Why are you hiding this information behind a mysterious black box? </p></li></ul><p>I put off writing this because I am not the best writer. </p><ul><li><p><a href="https://housefresh.com/david-vs-digital-goliaths/" rel="">HouseFresh explains how Google is killing independent websites like theirs</a><span>. This one is especially important as it shows how spam now ranks above them. </span></p></li><li><p><a href="https://retrododo.com/google-is-killing-retro-dodo/" rel="">Here is how Google killed RetroDodo</a><span>, which is one of the best retro video gaming websites on the net. </span></p></li><li><p><a href="https://healthyframework.com/an-open-letter-to-google-from-a-small-publisher/" rel="">Healthy Framework explains how Google is breaking the web</a><span> and why soon, nothing will be left but spam and Reddit.&nbsp;</span><a href="https://healthyframework.com/why-googles-dismissal-of-niche-experts-is-getting-da" rel="">Make sure you read part 2 to see how this is getting dangerous</a><span>. </span></p></li><li><p><a href="https://www.replayjutsu.com/how-google-updates-have-destroyed-many-gaming-and-entertainment-websites/" rel="">And a summary from RePlay on how Google has destroyed an entire swath of websites</a><span>. </span></p></li><li><p><a href="https://readysteadycut.com/2024/10/28/google-destroyed-ready-steady-cut/" rel="">A great overview of the pain Ready Steady Cut is in as well as other sites. </a></p></li><li><p><a href="https://rutledgedaugette.com/2024/10/28/the-notes-i-sent-to-google-before-the-october-2024-web-creator-conversation/" rel="">A fantastic set of notes that Rutledge sent Google before the Oct 28/29 creator summit that Google is throwing</a><span>. </span></p></li><li><p><a href="https://mike-hardaker.com/f/how-googles-updates-brought-out-my-insecurities-from-high-school" rel="">Mike‚Äôs post about Google destroying a 17-year-old outdoor website that is his life</a><span>. </span></p></li></ul><p>I have a lot more, but those are the best overviews of the damage Google is doing. </p><div id="youtube2-uSGVk2KVokQ" data-attrs="{&quot;videoId&quot;:&quot;uSGVk2KVokQ&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/uSGVk2KVokQ?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><span>Thanks for listening Google, </span><br><span>Ben Fox (founder of Shepherd and inarticulate clown)</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg" width="274" height="365.516" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:667,&quot;width&quot;:500,&quot;resizeWidth&quot;:274,&quot;bytes&quot;:76296,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18dffe9-c855-40c4-b17f-03d202a769bd_500x667.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chain-of-Thought Can Hurt Performance on Tasks Where Thinking Makes Humans Worse (188 pts)]]></title>
            <link>https://arxiv.org/abs/2410.21333</link>
            <guid>41999340</guid>
            <pubDate>Wed, 30 Oct 2024 19:42:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2410.21333">https://arxiv.org/abs/2410.21333</a>, See on <a href="https://news.ycombinator.com/item?id=41999340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2410.21333">View PDF</a>
    <a href="https://arxiv.org/html/2410.21333v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Ryan Liu [<a href="https://arxiv.org/show-email/2af21f3d/2410.21333">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 27 Oct 2024 18:30:41 UTC (2,612 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steam games will need to disclose kernel-level anti-cheat on store pages (495 pts)]]></title>
            <link>https://www.gamingonlinux.com/2024/10/steam-games-will-now-need-to-fully-disclose-kernel-level-anti-cheat-on-store-pages/</link>
            <guid>41999314</guid>
            <pubDate>Wed, 30 Oct 2024 19:39:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamingonlinux.com/2024/10/steam-games-will-now-need-to-fully-disclose-kernel-level-anti-cheat-on-store-pages/">https://www.gamingonlinux.com/2024/10/steam-games-will-now-need-to-fully-disclose-kernel-level-anti-cheat-on-store-pages/</a>, See on <a href="https://news.ycombinator.com/item?id=41999314">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p>Valve announced a change for Steam today that will make things a lot clearer for everyone, as developers will now need to clearly list the kernel-level anti-cheat used on Steam store pages.</p>

<p>In the Steamworks Developer <a href="https://steamcommunity.com/groups/steamworks/announcements/detail/4547038620960934857?snr=2___" rel="noopener nofollow" target="_blank">post</a> Valve said: "We've heard from more and more developers recently that they're looking for the right way to share anti-cheat information about their game with players. At the same time, players have been requesting more transparency around the anti-cheat services used in games, as well as the existence of any additional software that will be installed within the game."</p>

<p>Developers with games already on Steam will also need to do this, as it's not just for new games coming up for release, and it is also part of the release process now too. So Valve will be doing checks on games to ensure the notices are there and correct.</p>

<p>However, it's only being <em>forced</em> for kernel-level anti-cheat. If it's only client-side or server-side, it's <em>optional</em>, but Valve say "we generally think that any game that makes use of anti-cheat technology would benefit from letting players know".</p>

<p>Valve's example pictured below:</p>

<p><img src="https://uploads.golmedia.net/uploads/articles/article_media/7927772011730316555gol1.png"></p>
						<p><span>Article taken from <a href="https://www.gamingonlinux.com/">GamingOnLinux.com.</a></span>
						
					</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek v2.5 ‚Äì open-source LLM comparable to GPT-4, but 95% less expensive (134 pts)]]></title>
            <link>https://www.deepseek.com/</link>
            <guid>41999151</guid>
            <pubDate>Wed, 30 Oct 2024 19:24:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.deepseek.com/">https://www.deepseek.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41999151">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><div><p>DeepSeek-V2.5 Capabilities</p><p>DeepSeek-V2.5 delivers impressive results on current major large model leaderboards.</p><div><div><p>Places top 3 in AlignBench</p><p>Surpassing GPT-4 and close to GPT-4-Turbo</p></div><div><p>Ranks top-tier in MT-Bench</p><p>Rivaling LLaMA3-70B and outperforming Mixtral 8x22B</p></div><div><p>Specializes in math, code and reasoning</p></div><div><p>The open-source model and API support 128K context length</p></div></div></div><div><table><tbody><tr><th></th><th rowspan="2">Open source</th><th>Chinese General</th><th>English General</th><th>Knowledge</th><th>Arithmetic</th><th>Math</th><th>Reasoning</th><th>Coding</th></tr><tr><th></th><th>AlignBench</th><th>MT-Bench</th><th>MMLU</th><th>GSM8K</th><th>MATH</th><th>BBH</th><th>HumanEval</th></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>DeepSeek-V2.5</td><td>Yes</td><td>8.04</td><td>9.02</td><td>80.4</td><td>95.1</td><td>74.7</td><td>84.3</td><td>89.0</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>DeepSeek-V2</td><td>Yes</td><td>7.89</td><td>8.85</td><td>80.6</td><td>94.8</td><td>71.0</td><td>83.4</td><td>84.8</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>GPT-4-Turbo-1106</td><td>-</td><td>8.01</td><td>9.32</td><td>84.6</td><td>93.0</td><td>64.1</td><td>-</td><td>82.2</td></tr><tr><td>GPT-4-0613</td><td>-</td><td>7.53</td><td>8.96</td><td>86.4</td><td>92.0</td><td>52.9</td><td>83.1</td><td>84.1</td></tr><tr><td>GPT-3.5</td><td>-</td><td>6.08</td><td>8.21</td><td>70.0</td><td>57.1</td><td>34.1</td><td>66.6</td><td>48.1</td></tr><tr><td>Gemini1.5 Pro</td><td>-</td><td>7.33</td><td>8.93</td><td>81.9</td><td>91.7</td><td>58.5</td><td>84.0</td><td>71.9</td></tr><tr><td>Claude3 Opus</td><td>-</td><td>7.62</td><td>9.00</td><td>86.8</td><td>95.0</td><td>61.0</td><td>86.8</td><td>84.9</td></tr><tr><td>Claude3 Sonnet</td><td>-</td><td>6.70</td><td>8.47</td><td>79.0</td><td>92.3</td><td>40.5</td><td>82.9</td><td>73.0</td></tr><tr><td>Claude3 Haiku</td><td>-</td><td>6.42</td><td>8.39</td><td>75.2</td><td>88.9</td><td>40.9</td><td>73.7</td><td>75.9</td></tr><tr><td>abab-6.5</td><td>-</td><td>7.97</td><td>8.82</td><td>79.5</td><td>91.7</td><td>51.4</td><td>82.0</td><td>78.0</td></tr><tr><td>abab-6.5s</td><td>-</td><td>7.34</td><td>8.69</td><td>74.6</td><td>87.3</td><td>42.0</td><td>76.8</td><td>68.3</td></tr><tr><td>ERNIE-4.0</td><td>-</td><td>7.89</td><td>7.69</td><td>-</td><td>91.3</td><td>52.2</td><td>-</td><td>72.0</td></tr><tr><td>GLM-4</td><td>-</td><td>7.88</td><td>8.60</td><td>81.5</td><td>87.6</td><td>47.9</td><td>82.3</td><td>72.0</td></tr><tr><td>Moonshot-v1</td><td>-</td><td>7.22</td><td>8.59</td><td>-</td><td>89.5</td><td>44.2</td><td>-</td><td>82.9</td></tr><tr><td>Baichuan 3</td><td>-</td><td>-</td><td>8.70</td><td>81.7</td><td>88.2</td><td>49.2</td><td>84.5</td><td>70.1</td></tr><tr><td>Qwen1.5 72B</td><td>Yes</td><td>7.19</td><td>8.61</td><td>76.2</td><td>81.9</td><td>40.6</td><td>65.9</td><td>68.9</td></tr><tr><td>LLaMA 3 70B</td><td>Yes</td><td>7.42</td><td>8.95</td><td>80.3</td><td>93.2</td><td>48.5</td><td>80.1</td><td>76.2</td></tr><tr><td>Mixtral 8x22B</td><td>Yes</td><td>6.49</td><td>8.66</td><td>77.8</td><td>87.9</td><td>49.8</td><td>78.4</td><td>75.0</td></tr></tbody></table></div></div><div><p>DeepSeek API Pricing</p><div><div><p>Per <span>Million</span> Input Tokens</p><p><span>0.14</span><span>$</span></p></div><div><p>Per <span>Million</span> Output Tokens</p><p><span>0.28</span><span>$</span></p></div></div></div></div><section><p>Why DeepSeek?</p><a href="https://platform.deepseek.com/" target="_blank">API Access<svg viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><clipPath id="clip812_775"><rect id="jiantou-9" width="24.000000" height="24.000000" transform="translate(0.000000 -0.255859)"></rect></clipPath></defs><g clip-path="url(#clip812_775)"><path id="path" d="M19.99 12.29L15.62 8.17C15.61 8.16 15.6 8.14 15.58 8.13C15.35 7.93 14.98 7.95 14.78 8.19C14.58 8.43 14.6 8.79 14.84 9L18.16 12.13L3.53 12.13C3.24 12.14 3.01 12.38 3 12.66C2.97 12.97 3.21 13.25 3.53 13.26L19.29 13.26C19.32 13.26 19.34 13.26 19.37 13.26C19.4 13.26 19.44 13.25 19.46 13.25C19.51 13.26 19.55 13.26 19.59 13.26C19.75 13.26 19.89 13.2 20 13.08C20.23 12.86 20.22 12.5 19.99 12.29Z" fill="currentColor" fill-rule="nonzero"></path></g></svg></a><div><div><p><span>236B parameters</span><br><span>128K context (API)</span><br></p><p>Capable</p></div><div><p><span>$0.14/M</span><span> input tokens</span><br><span>$0.28/M</span><span> output tokens</span><br></p></div><div><p><span>Compatible with</span><br><span>OpenAI API</span><br></p><p>Seamless</p></div></div></section><div><p><img alt="DeepSeek Logo" loading="lazy" width="780" height="165" decoding="async" data-nimg="1" srcset="https://www.deepseek.com/_next/image?url=https%3A%2F%2Fcdn.deepseek.com%2Flogo.png&amp;w=828&amp;q=75 1x, https://www.deepseek.com/_next/image?url=https%3A%2F%2Fcdn.deepseek.com%2Flogo.png&amp;w=1920&amp;q=75 2x" src="https://www.deepseek.com/_next/image?url=https%3A%2F%2Fcdn.deepseek.com%2Flogo.png&amp;w=1920&amp;q=75"></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google's TOS doesn't eliminate a user's Fourth Amendment rights, judge rules [pdf] (283 pts)]]></title>
            <link>https://ww3.ca2.uscourts.gov/decisions/isysquery/0814a460-fe8f-42ef-9e82-cf94f952eb28/1/doc/23-6181_opn.pdf</link>
            <guid>41998891</guid>
            <pubDate>Wed, 30 Oct 2024 18:58:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ww3.ca2.uscourts.gov/decisions/isysquery/0814a460-fe8f-42ef-9e82-cf94f952eb28/1/doc/23-6181_opn.pdf">https://ww3.ca2.uscourts.gov/decisions/isysquery/0814a460-fe8f-42ef-9e82-cf94f952eb28/1/doc/23-6181_opn.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41998891">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Crafting Painterly Shaders (122 pts)]]></title>
            <link>https://blog.maximeheckel.com/posts/on-crafting-painterly-shaders/</link>
            <guid>41998319</guid>
            <pubDate>Wed, 30 Oct 2024 18:05:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.maximeheckel.com/posts/on-crafting-painterly-shaders/">https://blog.maximeheckel.com/posts/on-crafting-painterly-shaders/</a>, See on <a href="https://news.ycombinator.com/item?id=41998319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>October 29, 2024<!-- --> /<!-- --> <!-- -->35 min read</p><p><span>Last Updated:<!-- --> <!-- -->October 29, 2024</span></p></div><div><p>Writing a shader that can reproduce the look and feel of aquarelle, watercolor, or gouache to obtain a more <em>painterly</em>
output for my WebGL scenes has always been a long-term goal of mine.
Inspired by the work of very talented 3D artists such
as <a href="https://twitter.com/simonxxoo">@simonxxoo</a> or <a href="https://twitter.com/arpeegee">@arpeegee</a>, the contrast between paintings and the added dimension allowed by 3D renderers
was always very appealing to me. On top of that, my recent work with <a href="https://blog.maximeheckel.com/posts/moebius-style-post-processing/">stylized
shaders to mimic the hand-drawn Moebius art
style</a> emphasized not only that obtaining such stylized output was possible but also that post-processing
was more likely than not the key to emulating any artistic style.</p>
<p>After several months of on/off research that frankly was not leading to much, I stumbled upon a smoothing filter I never heard about before: the <strong>Kuwahara filter</strong>. Lucky for me, it turned out that many (very smart) people published papers about it and its ability to transform any image input into a painting-like work of art. By implementing it into a custom post-processing pass and going through many ups and downs in the process, I got very close to my original objective by building what is essentially <strong>a real-time 3D painting running in the browser</strong>:</p>
<figure></figure>
<p>This article is the culmination of months of work, trial and error, and research to <strong>craft the perfect painterly shader</strong> for your next WebGL project. In it, we will deep dive into <strong>the characteristics of the Kuwahara filter</strong> that make it so great at transforming our work into paintings, as well as look
into several techniques highlighted in the many papers I read to improve the original implementation and have it return <strong>a sharper, and more anisotropic output</strong>. Finally, we'll go through a bit of color correction and the use of textures to achieve a satisfying and accurate painting effect.</p>


<section id="painterly-post-processing-with-the-kuwahara-filter-section"><h2 id="painterly-post-processing-with-the-kuwahara-filter">Painterly post-processing with the Kuwahara filter</h2><p>Up until then, my only attempts at painterly shader consisted of several implementations of custom materials focused on emulating specific aspects of paint that I instinctively listed as <em>essential</em> to get a convincing output:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>The absence of texture/normal detail</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Preserved edges</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Quantized colors</p></li>
</ul><p>Below is an example of one of my "best" iterations from that exploratory work. It notably uses a Voronoi noise to <em>smudge normals</em> and a paintbrush texture for a more realistic look and feel.</p><p>However, despite my best efforts, this work was dead in the water as my implementation was severely flawed and only worked with a subset of meshes. From then on, I knew I had to go the post-processing route to solve most of those issues, but I didn't know how. Then, one day, I stumbled upon the beautiful work of <a href="https://twitter.com/arpeegee">@arpeegee</a>, who gave me the keywords I was missing all this time: <strong>Kuwahara filter</strong>.</p><div><div><div><p><a href="https://twitter.com/arpeegee" target="_blank" rel="noopener noreferrer"><span><span></span><img alt="arpeegee" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fprofile_images%2F1794873330731716608%2FpNEFvCgN_normal.jpg&amp;w=48&amp;q=75 1x, https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fprofile_images%2F1794873330731716608%2FpNEFvCgN_normal.jpg&amp;w=96&amp;q=75 2x" src="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fprofile_images%2F1794873330731716608%2FpNEFvCgN_normal.jpg&amp;w=96&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><a href="https://twitter.com/arpeegee/status/1825974541958422592" target="_blank" rel="noopener noreferrer" aria-label="@arpeegee's Twitter profile"><svg viewBox="328 355 335 276" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M 630, 425    A 195, 195 0 0 1 331, 600    A 142, 142 0 0 0 428, 570    A  70,  70 0 0 1 370, 523    A  70,  70 0 0 0 401, 521    A  70,  70 0 0 1 344, 455    A  70,  70 0 0 0 372, 460    A  70,  70 0 0 1 354, 370    A 195, 195 0 0 0 495, 442    A  67,  67 0 0 1 611, 380    A 117, 117 0 0 0 654, 363    A  65,  65 0 0 1 623, 401    A 117, 117 0 0 0 662, 390    A  65,  65 0 0 1 630, 425    Z" style="fill:#3BA9EE"></path></svg></a></div><p>I'm done with this one! Learned a lot in the process üòå
Blender / Cycles https://t.co/VCkYOJeBNw</p><div><p><span><span></span><img alt="I'm done with this one! Learned a lot in the process üòå
Blender / Cycles https://t.co/VCkYOJeBNw" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXpW4AAkPpT.jpg&amp;w=1920&amp;q=75 1x, https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXpW4AAkPpT.jpg&amp;w=3840&amp;q=75 2x" src="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXpW4AAkPpT.jpg&amp;w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><p><span><span></span><img alt="I'm done with this one! Learned a lot in the process üòå
Blender / Cycles https://t.co/VCkYOJeBNw" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXsWIAABPym.jpg&amp;w=1920&amp;q=75 1x, https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXsWIAABPym.jpg&amp;w=3840&amp;q=75 2x" src="https://blog.maximeheckel.com/_next/image/?url=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FGVcppXsWIAABPym.jpg&amp;w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></div><h3 id="characteristics-of-the-kuwahara-filter">Characteristics of the Kuwahara filter</h3><p>Originally intended to remove noise through smoothing from medical images, the Kuwahara filter is most commonly used today to transform any input into stylistic paintings through post-processing.</p><p>Unlike other smoothing filters that reduce noise but also, on the way, blur our edges, the Kuwahara filter is capable of preserving edges and corners. That specificity is what makes it so good at achieving painting-like artistic effects by getting us two crucial visual properties of paintings:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>The smoothing erases some of the texture details.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>The filter preserves the edges and, in some cases, increases the sharpness compared to the original input.</p></li>
</ul><p>It achieves this by executing the following steps on each pixel of our input, which in our case would be our underlying 3D scene:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We center a box around a pixel.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We divide the box into 4 "sub-boxes" or <strong>Sectors</strong>.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><strong>We calculate the average color and variance for each Sector</strong>.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We set our pixel to the average color of the Sector with the <strong>lowest variance</strong>.</p></li>
</ol><p>I built the widget below to visually represent those sectors surrounding a given pixel at work:</p><p>You can see by selecting the edge examples that:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>when a pixel sits just outside an edge, the Sector with the lowest variance will always be outside the edge</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>when a pixel sits just inside an edge, the Sector with the lowest variance will be inside the edge</p></li>
</ul><p>highlighting the <em>edge-preserving</em> capabilities of this filter.</p><p>The widget below showcases how this process of picking the average color of the Sector with the lowest variance impacts an entire image:</p><p>Notice how, with a reasonable kernel size, we maintain the overall shapes featured in the underlying image but erase many details like, in this case, transparency. However, we can also observe that with a higher kernel size, the image filter, unfortunately, falls apart and denatures quite drastically our input, indicating that we will have to strike the right balance between kernel size and the strength of our painterly post-processing effect.</p><h3 id="our-first-implementation-of-the-kuwahara-filter-as-a-post-processing-effect">Our first implementation of the Kuwahara filter as a post-processing effect</h3><p>Now that we have a good understanding of the inner workings of the Kuwahara filter, let's implement it as a post-processing effect on top of a React Three Fiber scene. Much like the work done in <a href="https://blog.maximeheckel.com/posts/moebius-style-post-processing/">Moebius-style post-processing and other stylized shaders</a>, we will define our custom post-processing pass using the <code>Pass</code> class from the <code>post-processing</code> package.</p><p>This post-processing pass will:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Take our underlying scene as an input.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Implement the Kuwahara filter in its fragment shader.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Output the resulting scene.</p></li>
</ul><p>The implementation of it in GLSL goes as follows:</p><div><div><p data-testid="codesnippet-title">Implementation of the Kuwahara filter in GLSL</p></div><pre><div data-testid="line"><p>4</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> inputBuffer</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> originalTexture</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">void</span><span data-testid="content-line"> </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line"> offset</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">int</span><span data-testid="content-line"> boxSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> variance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> colorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> squaredColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sampleCount </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">int</span><span data-testid="content-line"> y </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">;</span><span data-testid="content-line"> y </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> boxSize</span><span data-testid="content-line">;</span><span data-testid="content-line"> y</span><span data-testid="content-line">++</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">int</span><span data-testid="content-line"> x </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">;</span><span data-testid="content-line"> x </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> boxSize</span><span data-testid="content-line">;</span><span data-testid="content-line"> x</span><span data-testid="content-line">++</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>18</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> sampleOffset </span><span data-testid="content-line">=</span><span data-testid="content-line"> offset </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">x</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">y</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>19</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sampleColor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>21</p><p><span><span data-testid="content-line">            squaredColorSum </span><span data-testid="content-line">+=</span><span data-testid="content-line"> color </span><span data-testid="content-line">*</span><span data-testid="content-line"> color</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>27</p><p><span><span data-testid="content-line">    avgColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> colorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> sampleCount</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>28</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> varianceRes </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">squaredColorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> sampleCount</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">avgColor </span><span data-testid="content-line">*</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>29</p><p><span><span data-testid="content-line">    variance </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">varianceRes</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.299</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.587</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.114</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>33</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>34</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>36</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">kernelSize</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>37</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">kernelSize</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>38</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>39</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> kernelSize</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">3</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">3</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>41</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> minVariance </span><span data-testid="content-line">=</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>42</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> finalColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>44</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">int</span><span data-testid="content-line"> i </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">;</span><span data-testid="content-line"> i </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> SECTOR_COUNT</span><span data-testid="content-line">;</span><span data-testid="content-line"> i</span><span data-testid="content-line">++</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>45</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">if</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> minVariance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>46</p><p><span><span data-testid="content-line">            minVariance </span><span data-testid="content-line">=</span><span data-testid="content-line"> boxVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>47</p><p><span><span data-testid="content-line">            finalColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> boxAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>51</p><p><span><span data-testid="content-line">    gl_FragColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line">(</span><span data-testid="content-line">finalColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>In the code featured above, we can see that:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We're allocating an array of <code>vec3</code> and <code>float</code> to store the average color and variance for each of our Sectors, respectively.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We're computing those stats by sampling the color for every pixel in a given Sector along the x-axis and y-axis and calculating the average and variance using the formulas we saw in the previous part.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We then set <code>minVariance</code> and <code>finalColor</code> as the variance and average color of the first Sector by default.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We then loop through the other Sectors to find the Sector with the lowest variance and set its corresponding average color as the output of our fragment shader.</p></li>
</ol><p>Doing this will result in a version of our scene with fewer texture details while preserving the overall shape of our geometries and also introducing artifacts that <strong>look somewhat like brush strokes</strong>:</p></section>
<section id="the-papari-extension-section"><h2 id="the-papari-extension">The Papari extension</h2><p>Through our initial implementation of the Kuwahara filter as a custom post-processing pass, we already achieved a somewhat convincing paint effect. However, it suffers from several drawbacks at high kernel sizes that may make our underlying scene not discernable by the viewer, and the appearance of our "brush strokes" could most likely be improved.</p><p>Ideally, we could fix both these issues in one go by allowing larger kernel sizes for a more intense stylized effect for our scene and also have more natural-looking artifacts with a slight tweak of our Kuwahara filter. That is what Giuseppe Papari proposes in his paper <strong>Artistic Edge and Corner Enhancing Smoothing</strong>. In it, he presents an <em>extension</em> to the Kuwahara filter that:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Removes the square-shaped kernel in favor of a circular one.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Improves the weight influence that each pixel has on the filter.</p></li>
</ol><p>In this part, we will implement some of those improvements with an additional section on potential performance improvements. It may sound absurd but; I like my paintings to run as close to 60fps as possible.</p><h3 id="circular-kernel">Circular kernel</h3><p>A circular-shaped kernel allows us to increase the number of Sectors when evaluating the color of a given pixel. Its box-shaped counterpart can only allow for up to four Sectors making more complex edge lines not well-preserved. Through his experiments, Papari found that <em>eight Sectors</em> were the ideal amount to balance output quality and good performance.</p><figure><p><img alt="Diagram showcasing both box-shaped and circular kernels and highlighting which parts of the image are being smoothed while maintaining the sharpness of the edges." loading="lazy" width="700" height="323" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kernel_Comparison"></p><figcaption>Diagram showcasing both box-shaped and circular kernels and highlighting which parts of the image are being smoothed while maintaining the sharpness of the edges.</figcaption></figure><p>The widget below showcases the impact that this subtle modification in the implementation of our filter has on a simple image:</p><p>Here, we can see that, compared to what we observed in the first part, this version of the Kuwahara filter yields a way better output even at a larger kernel size! The circular shape and the higher number of Sectors allow us to preserve edge lines for more complex angles and patterns.</p><p>We can tweak the fragment shader code to implement Papari's circular kernel into our post-processing pass by modifying the parts that compute variance and average color by Sector:</p><div><div><p data-testid="codesnippet-title">Switching to a circular kernel in our Kuwahara filter implementation</p></div><pre><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">void</span><span data-testid="content-line"> </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> radius</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> variance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> colorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> squaredColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sampleCount </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>8</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> r </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> radius</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>9</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> a </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.196349</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>10</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> sampleOffset </span><span data-testid="content-line">=</span><span data-testid="content-line"> r </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">cos</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">sin</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sampleColor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">            squaredColorSum </span><span data-testid="content-line">+=</span><span data-testid="content-line"> color </span><span data-testid="content-line">*</span><span data-testid="content-line"> color</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>19</p><p><span><span data-testid="content-line">    avgColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> colorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> sampleCount</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>20</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> varianceRes </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">squaredColorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> sampleCount</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">avgColor </span><span data-testid="content-line">*</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>21</p><p><span><span data-testid="content-line">    variance </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">varianceRes</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.299</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.587</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.114</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>26</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> sectorAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>27</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sectorVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>29</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">int</span><span data-testid="content-line"> i </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">;</span><span data-testid="content-line"> i </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> SECTOR_COUNT</span><span data-testid="content-line">;</span><span data-testid="content-line"> i</span><span data-testid="content-line">++</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>30</p><p><span><span data-testid="content-line">      </span><span data-testid="content-line">float</span><span data-testid="content-line"> angle </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">i</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">6.28318</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>31</p><p><span><span data-testid="content-line">      </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">radius</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> sectorAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> sectorVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>In the end, the filter's principle is roughly the same. What changes here is which pixel is picked for a given sector and included in the average and variance.</p><figure><p><img alt="Diagram showcasing how the sampling of a slice of the circular kernel is split." loading="lazy" width="700" height="430" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Circular_Kernel_Details"></p><figcaption>Diagram showcasing how the sampling of a slice of the circular kernel is split.</figcaption></figure><p>The demo below uses this extended version of the Kuwahara filter on top of our scene. It lets us use a larger kernel size, yielding a more stylized output while keeping our scene discernable:</p><h3 id="a-better-weighting-of-colors">A better weighting of colors</h3><p>The artifacts left by the filter are still quite visible at large kernel sizes. According to Papari's study, this effect is due to the <em>weighting</em> of the colors when calculating the average and the variance of a given Sector, as it does not discriminate any pixel. If a pixel is in a sector, it contributes the same amount to the calculations.</p><p>Using <strong>Gaussian weights</strong> fixes this issue:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>It provides a gradual fall-off from the center of the Sector to its edges.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>This results in more natural-looking transitions from one Sector to another, thus avoiding abrupt changes that would otherwise make those artifacts very visible.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>It <em>emphasizes</em> the central pixels more likely to represent the <strong>most accurate</strong> sector color, giving them more importance when calculating the average color.</p></li>
</ul><figure><p><img alt="Diagram comparing standard weighting vs Gaussian weighting. The darker the color of a pixel is, the 'heavier' the weight for said pixel is." loading="lazy" width="700" height="398" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Weighting_Comparison"></p><figcaption>Diagram comparing standard weighting vs Gaussian weighting. The darker the color of a pixel is, the 'heavier' the weight for said pixel is.</figcaption></figure><p>To use Gaussian weighting in our filter, we only need to change a few lines from the previous implementation:</p><div><div><p data-testid="codesnippet-title">Using Gaussian weighting in our Kuwahara filter implementation</p></div><pre><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> </span><span data-testid="content-line">gaussianWeight</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> distance</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> sigma</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">exp</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">(</span><span data-testid="content-line">distance </span><span data-testid="content-line">*</span><span data-testid="content-line"> distance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">2.0</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> sigma </span><span data-testid="content-line">*</span><span data-testid="content-line"> sigma</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>7</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">void</span><span data-testid="content-line"> </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> radius</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> variance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>8</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> weightedColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> weightedSquaredColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> totalWeight </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sigma </span><span data-testid="content-line">=</span><span data-testid="content-line"> radius </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">3.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>14</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> r </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> radius</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>15</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> a </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.196349</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> sampleOffset </span><span data-testid="content-line">=</span><span data-testid="content-line"> r </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">cos</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">sin</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sampleColor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>18</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">float</span><span data-testid="content-line"> weight </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">gaussianWeight</span><span data-testid="content-line">(</span><span data-testid="content-line">length</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> sigma</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>20</p><p><span><span data-testid="content-line">            weightedColorSum </span><span data-testid="content-line">+=</span><span data-testid="content-line"> color </span><span data-testid="content-line">*</span><span data-testid="content-line"> weight</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>21</p><p><span><span data-testid="content-line">            weightedSquaredColorSum </span><span data-testid="content-line">+=</span><span data-testid="content-line"> color </span><span data-testid="content-line">*</span><span data-testid="content-line"> color </span><span data-testid="content-line">*</span><span data-testid="content-line"> weight</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>22</p><p><span><span data-testid="content-line">            totalWeight </span><span data-testid="content-line">+=</span><span data-testid="content-line"> weight</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>27</p><p><span><span data-testid="content-line">    avgColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> weightedColorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> totalWeight</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>28</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> varianceRes </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">weightedSquaredColorSum </span><span data-testid="content-line">/</span><span data-testid="content-line"> totalWeight</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">avgColor </span><span data-testid="content-line">*</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>29</p><p><span><span data-testid="content-line">    variance </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">varianceRes</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.299</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.587</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.114</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div></pre></div><p>As we can see in the code snippet above:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We compute the weight using the Gaussian formula.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>We then take the resulting weight into account when calculating our <strong>weighted color sum</strong> and <strong>weighted squared color sum</strong>.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Those weights are then reflected in the final result of the variance and average color for each Sector.</p></li>
</ol><p>Now, you may wonder whether adding all those nitty-gritty improvements to a filter that already performed quite well is worth it. You can see the result for yourself in the comparison below between a frame of our first scene using the original implementation of the Kuwahara filter and one using the Papari extension:</p><figure><div tabindex="0" role="slider" aria-label="Comparing the output of our extended Kuwahara filter without and with Gaussian weighting." aria-valuemin="0" aria-valuemax="100" aria-valuenow="50"><p><img alt="Before" loading="eager" width="700" height="376" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-before-gaussian_cfx1fy 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-before-gaussian_cfx1fy 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-before-gaussian_cfx1fy"></p><p><img alt="After" loading="eager" width="700" height="376" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-after-gaussian_zphvl2 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-after-gaussian_zphvl2 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Spaceship-after-gaussian_zphvl2"></p><div id="slider-line"><p><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img" style="transform:rotate(180deg)"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></p></div></div><figcaption>Comparing the output of our extended Kuwahara filter without and with Gaussian weighting.</figcaption></figure><p>The result looks already better than previously, even at a low kernel size! Let's observe now the difference between both implementations for a higher value:</p><figure><div tabindex="0" role="slider" aria-label="Comparing the output of our extended Kuwahara filter without and with Gaussian weighting at a high kernel size." aria-valuemin="0" aria-valuemax="100" aria-valuenow="50"><p><img alt="Before" loading="eager" width="700" height="529" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-before-gaussian_oqjiwu 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-before-gaussian_oqjiwu 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-before-gaussian_oqjiwu"></p><p><img alt="After" loading="eager" width="700" height="529" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-after-gaussian_nsscnb 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-after-gaussian_nsscnb 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Plant-after-gaussian_nsscnb"></p><div id="slider-line"><p><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img" style="transform:rotate(180deg)"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></p></div></div><figcaption>Comparing the output of our extended Kuwahara filter without and with Gaussian weighting at a high kernel size.</figcaption></figure><h3 id="fixing-a-performance-pitfall">Fixing a performance pitfall</h3><p>The Gaussian function used to calculate the weights of our pixel is, unfortunately, quite expensive to run, even more so in all those nested loops necessary to sample each pixel of a given Sector. This improvement is costing us a lot of frames, and it would be very tempting to disregard it and revert to the original weighting method.</p><p>However, a team of <em>smart individuals</em> found a way to squeeze more performance out of the filter while maintaining the advantages given by the Gaussian. In <a href="https://www.umsl.edu/~kangh/Papers/kang-tpcg2010.pdf">Anisotropic Kuwahara Filtering with PolynomialWeighting Functions</a>, they propose to replace the Gaussian with a polynomial that roughly approximates it.</p><p><code>[(x + Œ∂) ‚àí Œ∑y^2]^2</code></p><div><div><p data-testid="codesnippet-title">Using Polynomial weighting in our Kuwahara filter implementation</p></div><pre><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> </span><span data-testid="content-line">polynomialWeight</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> x</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> y</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> eta</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> lambda</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> polyValue </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">x </span><span data-testid="content-line">+</span><span data-testid="content-line"> eta</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> lambda </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">y </span><span data-testid="content-line">*</span><span data-testid="content-line"> y</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">max</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">,</span><span data-testid="content-line"> polyValue </span><span data-testid="content-line">*</span><span data-testid="content-line"> polyValue</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>8</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">void</span><span data-testid="content-line"> </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> radius</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> variance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> colorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> squaredColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> weightSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> r </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> radius</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> a </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.196349</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>19</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> sampleOffset </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">r </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">cos</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> r </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">sin</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>20</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sampleColor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>21</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">float</span><span data-testid="content-line"> weight </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">polynomialWeight</span><span data-testid="content-line">(</span><span data-testid="content-line">sampleOffset</span><span data-testid="content-line">.</span><span data-testid="content-line">x</span><span data-testid="content-line">,</span><span data-testid="content-line"> sampleOffset</span><span data-testid="content-line">.</span><span data-testid="content-line">y</span><span data-testid="content-line">,</span><span data-testid="content-line"> eta</span><span data-testid="content-line">,</span><span data-testid="content-line"> lambda</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>When trying out this formula, I noticed the performance improvements highlighted in the paper but also that I could get a satisfying output at a smaller kernel size compared to what we've implemented so far. I'm still not exactly sure why ü§∑‚Äç‚ôÇÔ∏è, but I'll take it.</p></section>
<section id="from-structure-tensor-to-anisotropic-kuwahara-filter-section"><h2 id="from-structure-tensor-to-anisotropic-kuwahara-filter">From Structure Tensor to Anisotropic Kuwahara filter</h2><p>Papari's extension of the Kuwahara filter is already a step towards a lovely painterly shader, however, (I must sound like a broken record at this point) we still can perceive some artifacts left by the filter on the resulting scene. Indeed, the painting effect is applied indiscriminately to the input without any consideration for the overall structure of the current frame. In the case of a true painting, the artist would adapt the <em>flow of the brush</em> based on the direction of the edge. We're not getting this here.</p><p>Luckily, <a href="https://www.umsl.edu/~kangh/Papers/kang-tpcg2010.pdf">Anisotropic Kuwahara Filtering with PolynomialWeighting Functions</a> answers this problem by building upon the concepts of the extended Kuwahara filter we just saw.</p><p>In this paper, the authors suggest that we could adapt our circular kernel to the local features of the input during sampling by <strong>squeezing</strong> and <strong>rotating</strong> it, thus letting us sample our Sectors more accurately. As a result, our kernel would look more like an ellipsis rather than a circle.</p><figure><p><img alt="Diagram comparing isotropic kernels vs anisotropic kernels." loading="lazy" width="700" height="382" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Anisotropic_Kernel"></p><figcaption>Diagram comparing isotropic kernels vs anisotropic kernels.</figcaption></figure><p>Implementing this improvement will require us to follow several steps and make our post-processing effect <strong>multi-pass</strong>:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>The first pass will take the underlying scene as input and return the <strong>structure of the scene</strong>.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Then based on this structure as input we'll apply our Kuwahara filter to the underlying scene.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Finally, we'll add one extra pass to apply some tone mapping and other details that will make our painterly shader shine.</p></li>
</ol><div data-fullbleed="true"><figure><p><img alt="Diagram showcasing the multi-pass post-processing pipeline details in this section." loading="lazy" width="700" height="203" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara_Pipeline"></p><figcaption>Diagram showcasing the multi-pass post-processing pipeline details in this section.</figcaption></figure></div><h3 id="sobel-operator-and-partial-derivatives">Sobel operator and partial derivatives</h3><p>To obtain the structure of our scene, we can leverage a <strong>Sobel operator</strong> which I introduced in <a href="https://blog.maximeheckel.com/posts/moebius-style-post-processing/">Moebius-style post-processing and other stylized shaders</a> earlier this year.</p><p><code>Sx = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]</code></p><p><code>Sy = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]</code></p><p>However, this time we won't use it for edge detection like we did back then. We will apply our Sobel Matrix for every pixel but instead of a rapid change in intensity, which is characteristic of edges, we want to extract the partial derivatives along the x/y axis representing the <em>rate of change</em>.</p><div><div><p data-testid="codesnippet-title">Applying our Sobel Matrices when sampling</p></div><pre><div data-testid="line"><p>2</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> inputBuffer</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">const</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line"> Gx </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line"> </span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>7</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">const</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line"> Gy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line"> </span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">vec4</span><span data-testid="content-line"> </span><span data-testid="content-line">computeStructureTensor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> uv</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>14</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>15</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>18</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>With those partial derivatives, we can obtain a <strong>structure tensor</strong></p><p>In the following fragment shader code, we apply both Sobel matrices at a given pixel, compute the structure tensor, and return it as an output.</p><div><div><p data-testid="codesnippet-title">Using Sobel Matrices to obtain the structure tensor</p></div><pre><div data-testid="line"><p>2</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> inputBuffer</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">uniform</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">const</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line"> Gx </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line"> </span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>7</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">const</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line"> Gy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mat3</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line"> </span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">vec4</span><span data-testid="content-line"> </span><span data-testid="content-line">computeStructureTensor</span><span data-testid="content-line">(</span><span data-testid="content-line">sampler2D</span><span data-testid="content-line"> inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> uv</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx0y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>14</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>15</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx1y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y0 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>18</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>19</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> tx2y2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputTexture</span><span data-testid="content-line">,</span><span data-testid="content-line"> uv </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">,</span><span data-testid="content-line">  </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> resolution</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>21</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> Sx </span><span data-testid="content-line">=</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>22</p><p><span><span data-testid="content-line">              Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>23</p><p><span><span data-testid="content-line">              Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y2 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y2 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gx</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y2</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>25</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> Sy </span><span data-testid="content-line">=</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y0 </span><span data-testid="content-line">+</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>26</p><p><span><span data-testid="content-line">              Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y1 </span><span data-testid="content-line">+</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>27</p><p><span><span data-testid="content-line">              Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">0</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx0y2 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">1</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx1y2 </span><span data-testid="content-line">+</span><span data-testid="content-line"> Gy</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line">[</span><span data-testid="content-line">2</span><span data-testid="content-line">]</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> tx2y2</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>29</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line">(</span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">Sx</span><span data-testid="content-line">,</span><span data-testid="content-line"> Sx</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">Sy</span><span data-testid="content-line">,</span><span data-testid="content-line"> Sy</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">Sx</span><span data-testid="content-line">,</span><span data-testid="content-line"> Sy</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>33</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> tensor </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">computeStructureTensor</span><span data-testid="content-line">(</span><span data-testid="content-line">inputBuffer</span><span data-testid="content-line">,</span><span data-testid="content-line"> vUv</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>35</p><p><span><span data-testid="content-line">    gl_FragColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> tensor</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>If we were to visualize our scene with this tensor pass applied on top, this is what we'd obtain:</p><h3 id="from-structure-tensor-to-flow">From Structure Tensor to flow</h3><p>Thanks to the Structure Tensor we just obtained, we can derive the information we need to adapt our filter to the local features of our scene. This process is rather tedious and involves some notions of linear algebra that can seem daunting at first. Thus, we'll proceed step-by-step and avoid taking unnecessary shortcuts.</p><p>We want to know in which <em>direction</em> a given pixel points towards, i.e. the <strong>dominant direction and orientation of the tensor at a given position</strong>. Luckily, there is a mathematical concept that represents just that: <strong>eigenvalues</strong> and <strong>eigenvectors</strong>.</p><p>Through our structure tensor, we'd like to obtain <code>Œª1</code> and derive its corresponding eigenvector, giving us the <em>dominant</em> direction of the <em>local structure</em>, to adapt our filter.
We can do so by starting from the definition of an eigenvector <code>A * v = Œª * v</code>. Given a Matrix <code>[[a, b], [b,c]]</code>, we have:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>A * v = Œª * v</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>A * v - Œª * v = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>A * v - Œª * I * v</code> where <code>I</code> is the identity matrix</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>(A - Œª * I) * v = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Since we established that <code>v</code> is non-null, the only way for a product of a matrix transformation and non-zero vector to be null is if the transformation completely squishes space. This can be represented by a zero determinant for that matrix transformation, hence <code>det(A - Œª * I) = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>det([[a - Œª, b], [b, d - Œª]]) = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>By applying the formula of the determinant we highlighted above we get: <code>(a - Œª) * (d - Œª) - b^2 = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Finally, if we simplify this equation, we get the following quadratic equation to solve for lambda: <code>Œª^2 - (a + d)Œª + (ad - b^2) = 0</code></p></li>
</ul><p>The solution of this quadratic equation gives us two possible values for lambda as we expected:</p><p><code>Œª = [(a + d) ¬± ‚àö((a + d)^2 - 4*(ad - b^2))] / 2</code></p><p>Doing all these steps in our fragment shader code would be relatively intensive. If you look a bit closer at the formula above, you will notice that we can replace some bits with the ones of <strong>the determinant and the trace of the transformation matrix</strong>:</p><p><code>Œª = [trace ¬± ‚àö(trace¬≤ - 4*determinant)] / 2</code></p><p>thus making us not have to perform all the steps we just went through in our shader code: we can directly use this formula to compute both eigenvalues.</p><div><div><p data-testid="codesnippet-title">Computing the eigenvalues of our structuretensor</p></div><pre><div data-testid="line"><p>1</p><p><span><span data-testid="content-line">float</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">r</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>2</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> Jyy </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">g</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> Jxy </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">b</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> trace </span><span data-testid="content-line">=</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">+</span><span data-testid="content-line"> Jyy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> determinant </span><span data-testid="content-line">=</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">*</span><span data-testid="content-line"> Jyy </span><span data-testid="content-line">-</span><span data-testid="content-line"> Jxy </span><span data-testid="content-line">*</span><span data-testid="content-line"> Jxy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>8</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> lambda1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">sqrt</span><span data-testid="content-line">(</span><span data-testid="content-line">trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.25</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> determinant</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">float</span><span data-testid="content-line"> lambda2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">sqrt</span><span data-testid="content-line">(</span><span data-testid="content-line">trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.25</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> determinant</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span></span></p></div></pre></div><p>Now that we have our eigenvalues, we can pick the largest one to derive our <strong>eigenvector</strong> following this definition:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>(A - Œª * I) * v = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>[Jxx - Œª, Jxy] [vx] = [0]</code> and <code>[Jxy, Jyy - Œª]* [vy] [0]</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>(Jxx - Œª) * vx + Jxy * vy = 0</code> and <code>Jxy * vx + (Jyy - Œª) * vy = 0</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>vx = -Jxy * vy / (Jxx - Œª)</code>, and by setting <code>vy</code> to <code>1</code> for simplicity we get: <code>vx = -Jxy / (Jxx - Œª)</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>we can then multiply both components by <code>Jxx - Œª</code> and obtain the final value for our eigenvector: <code>v = (-Jxy, Jxx - Œª)</code></p></li>
</ul><p>We can use it as is in our code, however, through many rounds of trial and error, I had to resort to using this eigenvector only if Jxy relative to the other components of the tensor matrix was above zero.</p><div><div><p data-testid="codesnippet-title">Computing the eigenvector of our structure tensor</p></div><pre><div data-testid="line"><p>1</p><p><span><span data-testid="content-line">vec4</span><span data-testid="content-line"> </span><span data-testid="content-line">getDominantOrientation</span><span data-testid="content-line">(</span><span data-testid="content-line">vec4</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>2</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">r</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> Jyy </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">g</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> Jxy </span><span data-testid="content-line">=</span><span data-testid="content-line"> structureTensor</span><span data-testid="content-line">.</span><span data-testid="content-line">b</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> trace </span><span data-testid="content-line">=</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">+</span><span data-testid="content-line"> Jyy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>7</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> determinant </span><span data-testid="content-line">=</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">*</span><span data-testid="content-line"> Jyy </span><span data-testid="content-line">-</span><span data-testid="content-line"> Jxy </span><span data-testid="content-line">*</span><span data-testid="content-line"> Jxy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>9</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> lambda1 </span><span data-testid="content-line">=</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">sqrt</span><span data-testid="content-line">(</span><span data-testid="content-line">trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.25</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> determinant</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>10</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> lambda2 </span><span data-testid="content-line">=</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">sqrt</span><span data-testid="content-line">(</span><span data-testid="content-line">trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> trace </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">0.25</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line"> determinant</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> jxyStrength </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">abs</span><span data-testid="content-line">(</span><span data-testid="content-line">Jxy</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">abs</span><span data-testid="content-line">(</span><span data-testid="content-line">Jxx</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">abs</span><span data-testid="content-line">(</span><span data-testid="content-line">Jyy</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">abs</span><span data-testid="content-line">(</span><span data-testid="content-line">Jxy</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">1e-7</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">if</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">jxyStrength </span><span data-testid="content-line">&gt;</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>17</p><p><span><span data-testid="content-line">        v </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">normalize</span><span data-testid="content-line">(</span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">-</span><span data-testid="content-line">Jxy</span><span data-testid="content-line">,</span><span data-testid="content-line"> Jxx </span><span data-testid="content-line">-</span><span data-testid="content-line"> lambda1</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>22</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line">(</span><span data-testid="content-line">normalize</span><span data-testid="content-line">(</span><span data-testid="content-line">v</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> lambda1</span><span data-testid="content-line">,</span><span data-testid="content-line"> lambda2</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><h3 id="deriving-and-applying-anisotropy-to-our-filter">Deriving and applying anisotropy to our filter</h3><p>From the Structure Tensor of our underlying scene, we derived both its eigenvalues and eigenvector. We could have also merely headed over to <a href="https://docs.opencv.org/4.x/d4/d70/tutorial_anisotropic_image_segmentation_by_a_gst.html">Anisotropic image segmentation by a gradient structure tensor</a> to find those formulas, however, we're grown-ups and it's nice to step out of our comfort zone to learn how to derive/define the tools and formulas we use in our shaders from time to time üôÇ.</p><p>In <a href="https://www.umsl.edu/~kangh/Papers/kang-tpcg2010.pdf">Anisotropic Kuwahara Filtering with PolynomialWeighting Functions</a>, the authors define the anisotropy <code>A</code> using those eigenvalues as follows:</p><p><code>A = (Œª1 - Œª2) / (Œª1 + Œª2 + 1e-7)</code></p><p>With this formula, we can derive that:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>A</code> ranges from <code>0</code> to <code>1</code></p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>when <code>Œª1 = Œª2</code>, the anisotropy is <code>0</code>, representing a <strong>isotropic</strong> region.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>when <code>Œª1 &gt; Œª2</code>, the anisotropy tends towards <code>1</code>, representing an <strong>anisotropic</strong> region.</p></li>
</ul><p>With the anisotropy now defined, we can use it to shape the circular kernel from the Kuwahara filter along the x-axis and y-axis with</p><div><div><p data-testid="codesnippet-title">Excentricity of the circular kernel</p></div><pre><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> structureTensor </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputBuffer</span><span data-testid="content-line">,</span><span data-testid="content-line"> vUv</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> sectorAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>7</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sectorVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> orientationAndAnisotropy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">getDominantOrientation</span><span data-testid="content-line">(</span><span data-testid="content-line">structureTensor</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>10</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> orientation </span><span data-testid="content-line">=</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>12</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> anisotropy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">z </span><span data-testid="content-line">-</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">w</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">z </span><span data-testid="content-line">+</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">w </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">1e-7</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>15</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> scaleX </span><span data-testid="content-line">=</span><span data-testid="content-line"> alpha </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">anisotropy </span><span data-testid="content-line">+</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>16</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> scaleY </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">anisotropy </span><span data-testid="content-line">+</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>Notice how:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>As the anisotropy approaches <code>1</code>, the ellipsis becomes more elongated along the x-axis, stretching our circular kernel.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>When we have a relatively isotropic region, the scale factors are <code>1</code> resulting in our kernel remaining circular.</p></li>
</ul><p>We now know how to stretch and scale our kernel based on the anisotropy, the remaining task we need to achieve is to <em>orient</em> it accordingly using the eigenvector we computed previously and defining a <strong>rotation matrix</strong> from it.</p><div><div><p data-testid="codesnippet-title">Adapt our kernel using anisotropy and the eigenvector from our structure tensor</p></div><pre><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">void</span><span data-testid="content-line"> </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">mat2</span><span data-testid="content-line"> anisotropyMat</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> radius</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> avgColor</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">out</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> variance</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> weightedColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> weightedSquaredColorSum </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> totalWeight </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> r </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> radius</span><span data-testid="content-line">;</span><span data-testid="content-line"> r </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>12</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">float</span><span data-testid="content-line"> a </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">&lt;=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.392699</span><span data-testid="content-line">;</span><span data-testid="content-line"> a </span><span data-testid="content-line">+=</span><span data-testid="content-line"> </span><span data-testid="content-line">0.196349</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">            </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> sampleOffset </span><span data-testid="content-line">=</span><span data-testid="content-line"> r </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">vec2</span><span data-testid="content-line">(</span><span data-testid="content-line">cos</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">sin</span><span data-testid="content-line">(</span><span data-testid="content-line">angle </span><span data-testid="content-line">+</span><span data-testid="content-line"> a</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>14</p><p><span><span data-testid="content-line">            sampleOffset </span><span data-testid="content-line">*=</span><span data-testid="content-line"> anisotropyMat</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>24</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> structureTensor </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputBuffer</span><span data-testid="content-line">,</span><span data-testid="content-line"> vUv</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>26</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> sectorAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>27</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> sectorVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">]</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>29</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> orientationAndAnisotropy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">getDominantOrientation</span><span data-testid="content-line">(</span><span data-testid="content-line">structureTensor</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>30</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec2</span><span data-testid="content-line"> orientation </span><span data-testid="content-line">=</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">xy</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>32</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> anisotropy </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">z </span><span data-testid="content-line">-</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">w</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">z </span><span data-testid="content-line">+</span><span data-testid="content-line"> orientationAndAnisotropy</span><span data-testid="content-line">.</span><span data-testid="content-line">w </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">1e-7</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>35</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> scaleX </span><span data-testid="content-line">=</span><span data-testid="content-line"> alpha </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">anisotropy </span><span data-testid="content-line">+</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>36</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> scaleY </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">anisotropy </span><span data-testid="content-line">+</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> alpha</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>38</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">mat2</span><span data-testid="content-line"> anisotropyMat </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mat2</span><span data-testid="content-line">(</span><span data-testid="content-line">orientation</span><span data-testid="content-line">.</span><span data-testid="content-line">x</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">-</span><span data-testid="content-line">orientation</span><span data-testid="content-line">.</span><span data-testid="content-line">y</span><span data-testid="content-line">,</span><span data-testid="content-line"> orientation</span><span data-testid="content-line">.</span><span data-testid="content-line">y</span><span data-testid="content-line">,</span><span data-testid="content-line"> orientation</span><span data-testid="content-line">.</span><span data-testid="content-line">x</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">mat2</span><span data-testid="content-line">(</span><span data-testid="content-line">scaleX</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">,</span><span data-testid="content-line"> scaleY</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>40</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">for</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">int</span><span data-testid="content-line"> i </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line">;</span><span data-testid="content-line"> i </span><span data-testid="content-line">&lt;</span><span data-testid="content-line"> SECTOR_COUNT</span><span data-testid="content-line">;</span><span data-testid="content-line"> i</span><span data-testid="content-line">++</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>41</p><p><span><span data-testid="content-line">      </span><span data-testid="content-line">float</span><span data-testid="content-line"> angle </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">i</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">6.28318</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">SECTOR_COUNT</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>42</p><p><span><span data-testid="content-line">      </span><span data-testid="content-line">getSectorVarianceAndAverageColor</span><span data-testid="content-line">(</span><span data-testid="content-line">anisotropyMat</span><span data-testid="content-line">,</span><span data-testid="content-line"> angle</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">radius</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> sectorAvgColors</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">,</span><span data-testid="content-line"> sectorVariances</span><span data-testid="content-line">[</span><span data-testid="content-line">i</span><span data-testid="content-line">]</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>As you can see above, the last step simply consists of applying this matrix to our <code>sampleOffset</code>. Voil√†! We adapted our Kuwahara filter to be anisotropic!</p><p>I acknowledge that this process is rather tedious, however, the techniques described in the paper about the anisotropic Kuwahara filter that we reimplemented here are interesting and demonstrate the power that a few matrix transformations can have on an image and all the information we can derive from these.</p><p>The result in itself is subtle, and you'll mostly notice the advantages when:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>analyzing some specific and complex details of your scene from up close once the filter is applied</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>having a very high kernel size</p></li>
</ul><figure><div tabindex="0" role="slider" aria-label="Comparing the output of our isotropic and anisotropic Kuwahara filter." aria-valuemin="0" aria-valuemax="100" aria-valuenow="50"><p><img alt="Before" loading="eager" width="700" height="460" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-before_fzlops 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-before_fzlops 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-before_fzlops"></p><p><img alt="After" loading="eager" width="700" height="460" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-after_peebcb 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-after_peebcb 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Spaceship-after_peebcb"></p><div id="slider-line"><p><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img" style="transform:rotate(180deg)"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></p></div></div><figcaption>Comparing the output of our isotropic and anisotropic Kuwahara filter.</figcaption></figure><figure><div tabindex="0" role="slider" aria-label="Comparing the output of our isotropic and anisotropic Kuwahara filter." aria-valuemin="0" aria-valuemax="100" aria-valuenow="50"><p><img alt="Before" loading="eager" width="700" height="661" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-before_qx9lza 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-before_qx9lza 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-before_qx9lza"></p><p><img alt="After" loading="eager" width="700" height="661" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-after_hank5e 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-after_hank5e 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-Anisotropic-Plant-after_hank5e"></p><div id="slider-line"><p><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img" style="transform:rotate(180deg)"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></p></div></div><figcaption>Comparing the output of our isotropic and anisotropic Kuwahara filter.</figcaption></figure><p>Below is the full implementation of our multi-pass anisotropic Kuwahara filter:</p></section>
<section id="final-touches-and-conclusion-section"><h2 id="final-touches-and-conclusion">Final touches and conclusion</h2><p>To bring out the best of our painterly shader, we can add a final post-processing pass to our scene to perform a few tweaks such as:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>quantization</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>color interpolation</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>saturation</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>tone mapping</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>adding some texture to the output</p></li>
</ul><p>Quantization will help reduce the number of colors our output will feature. I covered this method in length in <a href="https://blog.maximeheckel.com/posts/the-art-of-dithering-and-retro-shading-web/">The Art of Dithering and Retro Shading for the Web</a>. As a reminder, the formula behind quantization is:</p><p><code>floor(color * (n - 1) + 0.5)/n - 1</code>&nbsp;where&nbsp;n&nbsp;is the total number of colors.</p><p>In our fragment shader for our final pass, we can add quantization by:</p><ol>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Calculating the grayscale value of the current pixel.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Setting the number of colors <code>n</code>. In my examples, I picked <code>16</code>.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Using the formula established above.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Clamp the range to avoid extreme values which wouldn't yield a realistic painting effect.</p></li>
</ol><div><div><p data-testid="codesnippet-title">Applying quantization in our final post-processing pass</p></div><pre><div data-testid="line"><p>2</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">texture2D</span><span data-testid="content-line">(</span><span data-testid="content-line">inputBuffer</span><span data-testid="content-line">,</span><span data-testid="content-line"> vUv</span><span data-testid="content-line">)</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> grayscale </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.299</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.587</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.114</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>8</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">float</span><span data-testid="content-line"> qn </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">floor</span><span data-testid="content-line">(</span><span data-testid="content-line">x </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">n </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line">(</span><span data-testid="content-line">n </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">1</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>9</p><p><span><span data-testid="content-line">    qn </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">clamp</span><span data-testid="content-line">(</span><span data-testid="content-line">qn</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.2</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.7</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div></pre></div><p>On top of that, to obtain a more painterly color output, we can use a <strong>Two Point Interpolation</strong> to blend our colors with our grayscale quantized image:</p><ul>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>For a darker quantized pixel, we'd opt to interpolate from black (or close to black) to the image color based on that quantization value.</p></li>
<li><span data-list-item="true"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>For a lighter quantized pixel, we'd interpolate from the image to white.</p></li>
</ul><div><div><p data-testid="codesnippet-title">Adding two point color interpolation</p></div><pre><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mix</span><span data-testid="content-line">(</span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.1</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> color</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">,</span><span data-testid="content-line"> qn </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">2.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">mix</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">.</span><span data-testid="content-line">rgb</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">qn </span><span data-testid="content-line">-</span><span data-testid="content-line"> </span><span data-testid="content-line">0.5</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">2.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>This method emphasizes the contrast between light (represented by white space) and dark areas (more painted, darker colors).</p><p>To make our output <em>pop</em> more, I also chose to increase the saturation of our colors:</p><div><div><p data-testid="codesnippet-title">Saturating our color output</p></div><pre><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">vec3</span><span data-testid="content-line"> </span><span data-testid="content-line">sat</span><span data-testid="content-line">(</span><span data-testid="content-line">vec3</span><span data-testid="content-line"> rgb</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">float</span><span data-testid="content-line"> adjustment</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>4</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> W </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">0.2125</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.7154</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0721</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"> </span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>5</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec3</span><span data-testid="content-line"> intensity </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec3</span><span data-testid="content-line">(</span><span data-testid="content-line">dot</span><span data-testid="content-line">(</span><span data-testid="content-line">rgb</span><span data-testid="content-line">,</span><span data-testid="content-line"> W</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>6</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">mix</span><span data-testid="content-line">(</span><span data-testid="content-line">intensity</span><span data-testid="content-line">,</span><span data-testid="content-line"> rgb</span><span data-testid="content-line">,</span><span data-testid="content-line"> adjustment</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>11</p><p><span><span data-testid="content-line">color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sat</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.5</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>And, finally, I added some tone mapping for better color balance:</p><div><div><p data-testid="codesnippet-title">Applying tone mapping to our scene</p></div><pre><div data-testid="line"><p>9</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">return</span><span data-testid="content-line"> </span><span data-testid="content-line">clamp</span><span data-testid="content-line">(</span><span data-testid="content-line">(</span><span data-testid="content-line">x </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">a </span><span data-testid="content-line">*</span><span data-testid="content-line"> x </span><span data-testid="content-line">+</span><span data-testid="content-line"> b</span><span data-testid="content-line">)</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">x </span><span data-testid="content-line">*</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">c </span><span data-testid="content-line">*</span><span data-testid="content-line"> x </span><span data-testid="content-line">+</span><span data-testid="content-line"> d</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">+</span><span data-testid="content-line"> e</span><span data-testid="content-line">)</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">0.0</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>16</p><p><span><span data-testid="content-line">    color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">sat</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.5</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>17</p><p><span><span data-testid="content-line">    color </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">ACESFilm</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>19</p><p><span><span data-testid="content-line">    </span><span data-testid="content-line">vec4</span><span data-testid="content-line"> outputColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">vec4</span><span data-testid="content-line">(</span><span data-testid="content-line">color</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">1.0</span><span data-testid="content-line">)</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>20</p><p><span><span data-testid="content-line">    gl_FragColor </span><span data-testid="content-line">=</span><span data-testid="content-line"> outputColor</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div></pre></div><p>You can see that these little color improvements compound into significant changes highlighting the best features of our painterly shader:</p><figure><div tabindex="0" role="slider" aria-label="Comparing the output of our post-processing pipeline without/with the final pass." aria-valuemin="0" aria-valuemax="100" aria-valuenow="50"><p><img alt="Before" loading="eager" width="700" height="465" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-without-final-pass_d2ag3x 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-without-final-pass_d2ag3x 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-without-final-pass_d2ag3x"></p><p><img alt="After" loading="eager" width="700" height="465" decoding="async" data-nimg="1" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-with-final-padd_gwu0s8 1x, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-with-final-padd_gwu0s8 2x" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/Kuwahara-with-final-padd_gwu0s8"></p><div id="slider-line"><p><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img" style="transform:rotate(180deg)"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" role="img"><title>Arrow</title><desc>An icon representing an arrow</desc><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></p></div></div><figcaption>Comparing the output of our post-processing pipeline without/with the final pass.</figcaption></figure><p>To wrap it all up, and give our output some <em>physicality</em> and <em>realism</em>, we can add a paper-like texture and blend it with the color output of our fragment shader, exactly as <a href="https://twitter.com/arpeegee">@arpeegee</a> did in the example that originally inspired this article.
This is a very easy trick that adds a <em>lot</em> of details to our scene and makes it look like a real painting.</p><p>The demo below bundles all those improvements together on top of the anisotropic Kuwahara filter making an otherwise standard scene look like a beautiful painting with many features reminiscent of watercolor which is the effect I was originally trying to achieve.</p><p>As we saw throughout this article, making a satisfying painterly shader seemed simple on the surface thanks to the standard implementation of the Kuwahara filter. However, it turned out to be much more intricate once we started to dig deeper, trying to fix the artifacts that each technique yielded. If you were to ask me my take on the topic, <strong>I'd consider the Papari extension of the Kuwahara filter with polynomial weighting to be enough</strong> in most cases, while also being relatively performant compared to its anisotropic counterpart. At the end of the day, it's almost more a question of personal taste/creative choice as the different iterations of this image filter can produce drastically different results given an underlying scene/image.</p><p>Nonetheless, deep diving into how to obtain the structure tensor of an image and deriving anisotropy through many layers of linear algebra is far from useless as the technique can be ported to <em>many</em> other post-processing effects (one of which I'm considering writing about here). Consider it as one additional tool in your ever-growing shader toolbelt.</p><p>To finish this article, which was quite the undertaking not going to lie, here are a couple more shots/paintings of some of the test scenes I used while building this custom post-processing shader:</p><figure><p><img alt="Orange Tree 1 - Anisotropic Kuwahara filter" loading="lazy" width="700" height="426" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting2-min_zvrziz"></p><figcaption>Orange Tree 1 - Anisotropic Kuwahara filter</figcaption></figure><figure><p><img alt="Raymarched Clouds - Extended Kuwahara filter" loading="lazy" width="700" height="388" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/clouds-painting-min_bqf2ia"></p><figcaption>Raymarched Clouds - Extended Kuwahara filter</figcaption></figure><figure><p><img alt="Orange Tree 2 - Anisotropic Kuwahara filter" loading="lazy" width="700" height="426" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/orangetree-painting1-min_ljlg7l"></p><figcaption>Orange Tree 2 - Anisotropic Kuwahara filter</figcaption></figure><figure><p><img alt="Spaceship formation - Extended Kuwahara filter" loading="lazy" width="700" height="410" decoding="async" data-nimg="1" sizes="100vw" srcset="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 640w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 750w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 828w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 1080w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 1200w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 1920w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 2048w, https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake 3840w" src="https://res.cloudinary.com/dg5nsedzw/image/upload/fl_lossy,f_auto,q_auto/blog/spaceship-formation-painting-min_egrake"></p><figcaption>Spaceship formation - Extended Kuwahara filter</figcaption></figure></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CFPB finalizes personal financial data rights rule (124 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/10/no-matter-what-bank-says-its-your-money-your-data-and-your-choice</link>
            <guid>41998192</guid>
            <pubDate>Wed, 30 Oct 2024 17:55:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/10/no-matter-what-bank-says-its-your-money-your-data-and-your-choice">https://www.eff.org/deeplinks/2024/10/no-matter-what-bank-says-its-your-money-your-data-and-your-choice</a>, See on <a href="https://news.ycombinator.com/item?id=41998192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The Consumer Finance Protection Bureau (CFPB) has just </span><a href="https://www.consumerfinance.gov/about-us/newsroom/cfpb-finalizes-personal-financial-data-rights-rule-to-boost-competition-protect-privacy-and-give-families-more-choice-in-financial-services/"><span>finalized a rule</span></a><span> that makes it easy and safe for you to figure out which bank will give you the best deal and switch to that bank, with just a couple of clicks.&nbsp;</span></p>
<p><span>We </span><i><span>love</span></i><span> this kind of thing: the coolest thing about a digital world is how easy it is to switch from product or service to another‚Äîin theory. Digital tools are so flexible, anyone who wants your business can </span><a href="https://www.eff.org/deeplinks/2019/10/adversarial-interoperability"><span>write a program</span></a><span> to import your data into a new service and forward any messages or interactions that show up at the old service.</span></p>
<p><span>That's the theory. But in practice, companies have figured out how to use law - IP law, cybersecurity law, contract law, trade secrecy law‚Äîto </span><a href="https://www.eff.org/deeplinks/2016/07/section-1201-dmca-cannot-pass-constitutional-scrutiny"><span>literally criminalize</span></a><span> this kind of marvelous digital flexibility, so that it can end up being even </span><i><span>harder</span></i><span> to switch away from a digital service than it is to hop around among traditional, analog ones.</span></p>
<p><span>Companies </span><i><span>love</span></i><span> lock-in. The harder it is to quit a product or service, the worse a company can treat you without risking your business. Economists call the difficulties you face in leaving one service for another the "</span><a href="https://www.eff.org/deeplinks/2021/08/facebooks-secret-war-switching-costs"><span>switching costs</span></a><span>" and businesses go to great lengths to raise the switching costs they can impose on you if you have the temerity to be a disloyal customer.&nbsp;</span></p>
<p><span>So long as it's easier to coerce your loyalty than it is to earn it, companies win and their customers lose. That's where the new CFPB rule comes in.</span></p>
<p><span>Under this rule, you can authorize a third party - another bank, a comparison shopping site, a broker, or just your bookkeeping software - to request your account data from your bank. The bank has to give the third party </span><i><span>all</span></i><span> the data you've authorized. This data can include your transaction history and all the data needed to set up your payees and recurring transactions somewhere else.</span></p>
<p><span>That means that‚Äîfor example‚Äîyou can authorize a comparison shopping site to access some of your bank details, like how much you pay in overdraft fees and service charges, how much you earn in interest, and what your loans and credit cards are costing you. The service can use this data to figure out which bank will cost you the least and pay you the most.&nbsp;</span></p>
<p><span>Then, once you've opened an account with your new best bank, you can direct it to request </span><i><span>all</span></i><span> your data from your old bank, and with a few clicks, get fully set up in your new financial home. All your payees transfer over, all your regular payments, all the transaction history you'll rely on at tax time. "Painless" is an admittedly weird adjective to apply to household finances, but this comes pretty darned close.</span></p>
<p><span>Americans lose a </span><i><span>lot</span></i><span> of money to banking fees and low interest rates. How much? Well, CFPB economists, using a </span><i><span>very</span></i><span> conservative methodology, estimate that this rule will make the American public </span><i><span>at least $677 million</span></i><span> better off, </span><i><span>every year.</span></i></p>
<p><span>Now, that $677 million has to come from somewhere, and it does: it comes from the banks that are currently charging sky-high fees and paying rock-bottom interest. The largest of these banks are </span><a href="https://www.americanbanker.com/news/cfpbs-open-banking-rule-faces-suit-from-bank-policy-institute"><span>suing the CFPB</span></a><span> in a bid to block the rule from taking effect.</span></p>
<p><span>These banks claim that they are doing this to protect us, their depositors, from a torrent of fraud that would be unleashed if we were allowed to give third parties access to our own financial data. Clearly, this is the only reason a giant bank would want to make it harder for us to change to a competitor (it can't possibly have anything to do with the $677 million we stand to save by switching).</span></p>
<p><span>We've heard arguments like these before. While EFF takes a back seat to no one when it comes to defending user security (</span><a href="https://www.eff.org/cases/bernstein-v-us-dept-justice"><span>we practically invented this</span></a><span>), we reject the idea that </span><a href="https://www.eff.org/deeplinks/2023/12/without-interoperability-apple-customers-will-never-be-secure"><span>user security is improved when corporations lock us in</span></a><span> (and </span><a href="https://www.eff.org/document/letter-bruce-schneier-senate-judiciary-regarding-app-store-security"><span>leading security experts agree with us</span></a><span>).</span></p>
<p><span>This is not to say that a </span><i><span>bad</span></i><span> data-sharing interoperability rule wouldn't be, you know, </span><i><span>bad</span></i><span>. A rule that lacked the proper safeguards could indeed enable a wave of fraud and identity theft the likes of which we've never seen.</span></p>
<p><span>Thankfully, this is a </span><i><span>good</span></i><span> interoperability rule! </span><a href="https://www.eff.org/deeplinks/2023/10/you-wanna-break-your-bank-cfpb-wants-help-you-do-it"><span>We liked it when it was first proposed</span></a><span>, and it got </span><i><span>even better</span></i><span> through the rulemaking process.</span></p>
<p><span>First, the CFPB had the wisdom to know that a federal finance agency probably wasn't the best‚Äîor only‚Äîgroup of people to design a data-interchange standard. Rather than telling the banks exactly how they should transmit data when requested by their customers, the CFPB instead said, "These are the data you need to share and these are the characteristics of a good standards body. So long as you use a standard from a good standards body that shares this data, you're in compliance with the rule." This is an approach we've advocated for years, and it's the first time we've seen it in the wild.</span></p>
<p><span>The CFPB also instructs the banks to fail safe: any time a bank gets a request to share your data that it thinks might be fraudulent, they have the right to block the process until they can get more information and confirm that everything is on the up-and-up.</span></p>
<p><span>The rule also regulates the third parties that can get your data, establishing stringent criteria for which kinds of entities can do this. It also limits </span><i><span>how</span></i><span> they can use your data (strictly for the purposes you authorize) and what they need to do with the data when that has been completed (delete it forever), and what else they are allowed to do with it (nothing). There's also a mini "</span><a href="https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring"><span>click-to-cancel</span></a><span>" rule that guarantees that you can instantly revoke any third party's access to your data, for any reason.</span></p>
<p><span>The CFPB has had the authority to make a rule like this since its founding in 2010, with the passage of the Consumer Financial Protection Act (CFPA). Back when the CFPA was working its way through Congress, the banks howled that they were being forced to give up "their" data to their competitors.</span></p>
<p><span>But it's not their data. It's </span><i><span>your</span></i><span> data. The decision about who you share it with belongs to </span><i><span>you</span></i><span>, and you alone. </span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Karma connection in Chrome Web Store (143 pts)]]></title>
            <link>https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/</link>
            <guid>41997823</guid>
            <pubDate>Wed, 30 Oct 2024 17:23:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/">https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/</a>, See on <a href="https://news.ycombinator.com/item?id=41997823">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>Somebody <a href="https://gist.github.com/c0m4r/45e15fc1ec13c544393feafca30e74de">brought to my attention</a> that the Hide YouTube Shorts extension for Chrome changed hands and turned malicious. I looked into it and could confirm that it contained two undisclosed components: one performing <a href="https://www.investopedia.com/terms/a/affiliate-fraud.asp">affiliate fraud</a> and the other sending users‚Äô every move to some Amazon cloud server. But that wasn‚Äôt all of it: I discovered eleven more extensions written by the same people. Some contained only the affiliate fraud component, some only the user tracking, some both. A few don‚Äôt appear to be malicious yet.</p>
<p>While most of these extensions were supposedly developed or bought by a person without any other traces online, one broke this pattern. Karma shopping assistant has been on Chrome Web Store since 2020, the company behind it founded in 2013. This company employs more than 50 people and secured tons of cash in venture capital. Maybe a mistake on my part?</p>
<p>After looking thoroughly this explanation seems unlikely. Not only does Karma share some backend infrastructure and considerable amounts of code with the malicious extensions. Not only does Karma Shopping Ltd. admit to selling users‚Äô browsing profiles in their privacy policy. There is even more tying them together, including a mobile app developed by Karma Shopping Ltd. whereas the identical Chrome extension is supposedly developed by the mysterious evildoer.</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/karma.png" alt="Screenshot of the karmanow.com website, with the Karma logo visible and a yellow button ‚ÄúAdd to Chrome - It‚Äôs Free‚Äù" width="718" height="468"></figure>

<div id="tocBox">
  <h4>Contents</h4>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#the-affected-extensions">The affected extensions</a></li>
    <li><a href="#hiding-in-plain-sight">Hiding in plain sight</a></li>
    <li><a href="#affiliate-fraud-functionality">Affiliate fraud functionality</a></li>
    <li><a href="#browsing-profile-collection">Browsing profile collection</a></li>
    <li><a href="#who-is-behind-this">Who is behind this?</a></li>
    <li><a href="#what-does-karma-shopping-want-with-the-data">What does Karma Shopping want with the data?</a></li>
  </ul>
</nav>
</div>

<h2 id="the-affected-extensions"><a href="#the-affected-extensions"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>The affected extensions</h2>
<p>Most of the extensions in question changed hands relatively recently, the first ones in the summer of 2023. The malicious code has been added immediately after the ownership transfer, with some extensions even requesting additional privileges citing bogus reasons. A few extensions have been developed this year by whoever is behind this.</p>
<p>Some extensions from the latter group don‚Äôt have any obvious malicious functionality at this point. If there is tracking, it only covers the usage of the extension‚Äôs user interface rather than the entire browsing behavior. This can change at any time of course.</p>
<div><table>
<thead>
<tr>
<th>Name</th>
<th>Weekly active users</th>
<th>Extension ID</th>
<th>Malicious functionality</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hide YouTube Shorts</td>
<td>100,000</td>
<td>aljlkinhomaaahfdojalfmimeidofpih</td>
<td>Affiliate fraud, browsing profile collection</td>
</tr>
<tr>
<td>DarkPDF</td>
<td>40,000</td>
<td>cfemcmeknmapecneeeaajnbhhgfgkfhp</td>
<td>Affiliate fraud, browsing profile collection</td>
</tr>
<tr>
<td>Sudoku On The Rocks</td>
<td>1,000</td>
<td>dncejofenelddljaidedboiegklahijo</td>
<td>Affiliate fraud</td>
</tr>
<tr>
<td>Dynamics 365 Power Pane</td>
<td>70,000</td>
<td>eadknamngiibbmjdfokmppfooolhdidc</td>
<td>Affiliate fraud, browsing profile collection</td>
</tr>
<tr>
<td>Israel everywhere</td>
<td>70</td>
<td>eiccbajfmdnmkfhhknldadnheilniafp</td>
<td>‚Äì</td>
</tr>
<tr>
<td>Karma | Online shopping, but better</td>
<td>500,000</td>
<td>emalgedpdlghbkikiaeocoblajamonoh</td>
<td>Browsing profile collection</td>
</tr>
<tr>
<td>Where is Cookie?</td>
<td>93</td>
<td>emedckhdnioeieppmeojgegjfkhdlaeo</td>
<td>‚Äì</td>
</tr>
<tr>
<td>Visual Effects for Google Meet</td>
<td>1,000,000</td>
<td>hodiladlefdpcbemnbbcpclbmknkiaem</td>
<td>Affiliate fraud</td>
</tr>
<tr>
<td>Quick Stickies</td>
<td>106</td>
<td>ihdjofjnmhebaiaanaeeoebjcgaildmk</td>
<td>‚Äì</td>
</tr>
<tr>
<td>Nucleus: A Pomodoro Timer and Website Blocker</td>
<td>20,000</td>
<td>koebbleaefghpjjmghelhjboilcmfpad</td>
<td>Affiliate fraud, browsing profile collection</td>
</tr>
<tr>
<td>Hidden Airline Baggage Fees</td>
<td>496</td>
<td>kolnaamcekefalgibbpffeccknaiblpi</td>
<td>Affiliate fraud</td>
</tr>
<tr>
<td>M3U8 Downloader</td>
<td>100,000</td>
<td>pibnhedpldjakfpnfkabbnifhmokakfb</td>
<td>Affiliate fraud</td>
</tr>
</tbody>
</table></div>
<h2 id="hiding-in-plain-sight"><a href="#hiding-in-plain-sight"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Hiding in plain sight</h2>
<p>Whoever wrote the malicious code chose not to obfuscate it but to make it blend in with the legitimate functionality of the extension. Clearly, the expectation was that nobody would look at the code too closely. So there is for example this:</p>
<div><pre tabindex="0"><code data-lang="js"><span><span><span>if</span> <span>(</span><span>window</span><span>.</span><span>location</span><span>.</span><span>href</span><span>.</span><span>startsWith</span><span>(</span><span>"http"</span><span>)</span> <span>||</span>
</span></span><span><span>    <span>window</span><span>.</span><span>location</span><span>.</span><span>href</span><span>.</span><span>includes</span><span>(</span><span>"m.youtube.com"</span><span>))</span> <span>{</span>
</span></span><span><span>  <span>‚Ä¶</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>It <em>looks</em> like the code inside the block would only run on YouTube. Only when you stop and consider the logic properly you realize that it runs on every website. In fact, that‚Äôs the block wrapping the calls to malicious functions.</p>
<p>The malicious functionality is split between content script and background worker for the same reason, even though it could have been kept in one place. This way each part looks innocuous enough: there is some data collection in the content script, and then it sends a <code>check_shorts</code> message to the background worker. And the background worker ‚Äúchecks shorts‚Äù by querying some web server. Together this just <em>happens</em> to send your entire browsing history into the Amazon cloud.</p>
<p>Similarly, there are some complicated checks in the content script which eventually result in a <code>loadPdfTab</code> message to the background worker. The background worker dutifully opens a new tab for that address and, strangely, closes it after 9 seconds. Only when you sort through the layers it becomes obvious that this is actually about adding an affiliate cookie.</p>
<p>And of course there is a bunch of usual complicated conditions, making sure that this functionality is not triggered too soon after installation and generally doesn‚Äôt pop up reliably enough that users could trace it back to this extension.</p>
<h2 id="affiliate-fraud-functionality"><a href="#affiliate-fraud-functionality"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Affiliate fraud functionality</h2>
<p>The affiliate fraud functionality is tied to the <code>kra18.com</code> domain. When this functionality is active, the extension will regularly download data from <code>https://www.kra18.com/v1/selectors_list?&amp;ex=90</code> (90 being the extension ID here, the server accepts eight different extension IDs). That‚Äôs a long list containing 6,553 host names:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/selectors.png" alt="Screenshot of JSON data displayed in the browser. The selectors key is expanded, twenty domain names like drinkag1.com are visible in the list." width="325" height="448"></figure>

<p>Whenever one of these domains is visited and the moons are aligned in the right order, another request to the server is made with the full address of the page you are on. For example, the extension could request <code>https://www.kra18.com/v1/extension_selectors?u=https://www.tink.de/&amp;ex=90</code>:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/affiliate_link.png" alt="Screenshot of JSON data displayed in the browser. There are keys shortsNavButtonSelector, url and others. The url key contains a lengthy URL from awin1.com domain." width="573" height="145"></figure>

<p>The <code>shortsNavButtonSelector</code> key is another red herring, the code only <em>appears</em> to be using it. The important key is <code>url</code>, the address to be opened in order to set the affiliate cookie. And that‚Äôs the address sent via <code>loadPdfTab</code> message mentioned before if the extension decides that right now is a good time to collect an affiliate commission.</p>
<p>There are also additional ‚Äúselectors,‚Äù downloaded from <code>https://www.kra18.com/v1/selectors_list_lr?&amp;ex=90</code>. Currently this functionality is only used on the <code>amazon.com</code> domain and will replace some product links with links going through <code>jdoqocy.com</code> domain, again making sure an affiliate commission is collected. That domain is owned by Common Junction LLC, an affiliate marketing company that published a <a href="https://www.cj.com/case-study/shoptagr-cj-publisher-onboarding-team-case-study">case study</a> on how their partnership with Karma Shopping Ltd. (named Shoptagr Ltd. back then) helped drive profits.</p>
<h2 id="browsing-profile-collection"><a href="#browsing-profile-collection"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Browsing profile collection</h2>
<p>Some of the extensions will send each page visit to <code>https://7ng6v3lu3c.execute-api.us-east-1.amazonaws.com/EventTrackingStage/prod/rest</code>. According to the extension code, this is an Alooma backend. Alooma is a data integration platform which has been acquired by Google a while ago. Data transmitted could look like this:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/tracking.png" alt="Screenshot of query string parameters displayed in Developer Tools. The parameters are: token: sBGUbZm3hp, timestamp: 1730137880441, user_id: 90, distinct_id: 7796931211, navigator_language: en-US, referrer: https://www.google.com/, local_time: Mon Oct 28 2024 18:51:20 GMT+0100 (Central European Standard Time), event: page_visit, component: external_extension, external: true, current_url: https://example.com/" width="488" height="251"></figure>

<p>Yes, this is sent for each and every page loaded in the browser, at least after you‚Äôve been using the extension for a while. And <code>distinct_id</code> is my immutable user ID here.</p>
<p>But wait, it‚Äôs a bit different for the Karma extension. Here you can opt out! Well, that‚Äôs only if you are using Firefox because Mozilla is rather strict about unexpected data collection. And if you manage to understand what ‚ÄúUser interactions‚Äù means on this options page:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/karma_options.png" alt="Screenshot of an options page with two switches labeled User interactions and URL address. The former is described with the text: Karma is a community of people who are working together to help each other get a great deal. We collect anonymized data about coupon codes, product pricing, and information about Karma is used to contribute back to the community. This data does not contain any personably identifiable information such as names or email addresses, but may include data supplied by the browser such as url address." width="575" height="398"></figure>

<p>Well, I may disagree with the claim that <a href="https://palant.info/2020/02/18/insights-from-avast/jumpshot-data-pitfalls-of-data-anonymization/">url addresses do not contain personably identifiable information</a>. And: yes, this is the entire page. There really isn‚Äôt any more text.</p>
<p>The data transmitted is also somewhat different:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/tracking2.png" alt="Screenshot of query string parameters displayed in Developer Tools. The parameters are: referrer: https://www.google.com/, current_url: https://example.com/, browser_version: 130, tab_id: 5bd19785-e18e-48ca-b400-8a74bf1e2f32, event_number: 1, browser: chrome, event: page_visit, source: extension, token: sBGUbZm3hp, version: 10.70.0.21414, timestamp: 1730138671937, user_id: 6372998, distinct_id: 6b23f200-2161-4a1d-9400-98805c17b9e3, navigator_language: en-US, local_time: Mon Oct 28 2024 19:04:31 GMT+0100 (Central European Standard Time), ui_config: old_save, save_logic: rules, show_k_button: true, show_coupon_scanner: true, show_popups: true" width="495" height="430"></figure>

<p>The <code>user_id</code> field no longer contains the extension ID but my personal identifier, complementing the identifier in <code>distinct_id</code>. There is a <code>tab_id</code> field adding more context, so that it is not only possible to recognize which page I navigated to and from where but also to distinguish different tabs. And some more information about my system is always useful of course.</p>
<h2 id="who-is-behind-this"><a href="#who-is-behind-this"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Who is behind this?</h2>
<p>Eleven extensions on my list are supposedly developed by a person going by the name Rotem Shilop or Roni Shilop or Karen Shilop. This isn‚Äôt a very common last name, and if this person really exists it managed to leave no traces online. Yes, I also searched in Hebrew. Yet one extension is developed by Karma Shopping Ltd. (formerly Shoptagr Ltd.), a company based in Israel with at least 50 employees. An accidental association?</p>
<p>It doesn‚Äôt look like it. I‚Äôm not going into the details of shared code and tooling, let‚Äôs just say: it‚Äôs very obvious that all twelve extensions are being developed by the same people. Of course, there is still the possibility that the eleven malicious extensions are not associated directly with Karma Shopping but with some rogue employee or contractor or business partner.</p>
<p>However, it isn‚Äôt only the code. As <a href="#browsing-profile-collection">explained above</a>, five extensions including Karma share the same tracking backend which is found nowhere else. They are even sending the same access token. Maybe this backend isn‚Äôt actually run by Karma Shopping and they are only one of the customers of some third party? Yet if you look at the data being sent, clearly the Karma extension is considered first-party. It‚Äôs the other extensions which are sending <code>external: true</code> and <code>component: external_extension</code> flags.</p>
<p>Then maybe Karma Shopping is merely buying data from a third party, without actually being affiliated with their extensions? Again, this is possible but unlikely. One indicator is the <code>user_id</code> field in the data sent by these extensions. It‚Äôs the same extension ID that they use for internal communication with the <code>kra18.com</code> server. If Karma Shopping were granting a third party access to their server, wouldn‚Äôt they assign that third party some IDs of their own?</p>
<p>And those affiliate links produced by the <code>kra18.com</code> server? Some of them clearly mention <code>karmanow.com</code> as the affiliate partner.</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/affiliate_link2.png" alt="Screenshot of JSON data displayed in the browser. url key is a long link pointing to go.skimresources.com. sref query parameter of the link is https://karmanow.com. url query parameter of the link is www.runinrabbit.com." width="855" height="95"></figure>

<p>Finally, if we look at Karma Shopping‚Äôs mobile apps, they develop two of them. In addition to the Karma app, the app stores also contain an app called ‚ÄúSudoku on the Rocks,‚Äù developed by Karma Shopping Ltd. Which is a very strange coincidence because an identical ‚ÄúSudoku on the Rocks‚Äù extension also exists in the Chrome Web Store. Here however the developer is Karen Shilop. And Karen Shilop chose to include hidden affiliate fraud functionality in their extension.</p>
<p>By the way, guess who likes the Karma extension a lot and left a five-star review?</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/review.png" alt="Screenshot of a five-star review by Rona Shilop with a generic-looking avatar of woman with a cup of coffee. The review text says: Thanks for making this amazing free extension. There is a reply by Karma Support saying: We‚Äôre so happy to hear how much you enjoy shopping with Karma." width="631" height="241"></figure>

<p>I contacted Karma Shopping Ltd. via their public relations address about their relationship to these extensions and the Shilop person but didn‚Äôt hear back so far.</p>
<p><strong>Update</strong> (2024-10-30): An extension developer told me that they were contacted on multiple independent occasions about selling their Chrome extension to Karma Shopping, each time by C-level executives of the company, from official <code>karmanow.com</code> email addresses. The first outreach was in September 2023, where Karma was supposedly looking into adding extensions to their portfolio as part of their growth strategy. They offered to pay between $0.2 and $1 per weekly active user.</p>

<p>It is obvious why Karma Shopping Ltd. would want to add their affiliate functionality to more extensions. After all, affiliate commissions are their line of business. But why collect browsing histories? Only to publish <a href="https://jonathan-65927.medium.com/far-from-being-impulsive-buyers-millennials-agonize-over-online-purchases-bc0dbbf5f2ba">semi-insightful articles on people‚Äôs shopping behavior</a>?</p>
<p>Well, let‚Äôs have a look at <a href="https://www.karmanow.com/privacy">their privacy policy</a> which is actually meaningful for a change. Under 1.3.4 it says:</p>
<blockquote>
<p><strong>Browsing Data.</strong> In case you a user of our browser extensions we may collect data regarding web browsing data, which includes web pages visited, clicked stream data and information about the content you viewed.</p>
<p><strong>How we Use this Data.</strong> We use this Personal Data (1) in order to provide you with the Services and feature of the extension and (2) we will share this data in an aggregated, anonymized manner, for marketing research and commercial use with our business partners.</p>
<p><strong>Legal Basis.</strong> (1) We process this Personal Data for the purpose of providing the Services to you, which is considered performance of a contract with you. (2) When we process and share the aggregated and anonymized data we will ask for your consent.</p>
</blockquote>
<p>First of all, this tells us that Karma collecting browsing data is official. They also openly state that they are selling it. Good to know and probably good for their business as well.</p>
<p>As to the legal basis: I am no lawyer but I have a strong impression that they don‚Äôt deliver on the ‚Äúwe will ask for your consent‚Äù promise. No, not even that Firefox options page qualifies as informed consent. And this makes this whole data collection rather doubtful in the light of GDPR.</p>
<p>There is also a difference between anonymized and pseudonymized data. The data collection seen here is pseudonymized: while it doesn‚Äôt include my name, there is a persistent user identifier which is still linked to me. It is usually fairly easy to deanonymize pseudonymized browsing histories, e.g. because people tend to visit their social media profiles rather often.</p>
<p>Actually anonymized data would not allow associating it with any single person. This is very hard to achieve, and we‚Äôve seen <a href="https://palant.info/2020/02/18/insights-from-avast/jumpshot-data-pitfalls-of-data-anonymization/">promises of aggregated and anonymized data go very wrong</a>. While it‚Äôs theoretically possible that Karma correctly anonymizes and aggregates data on the server side, this is a rather unlikely outcome for a company that, as <a href="#browsing-profile-collection">we‚Äôve seen above</a>, confuses the lack of names and email addresses with anonymity.</p>
<p>But of course these considerations only apply to the Karma extension itself. Because related extensions like Hide YouTube Shorts just straight out lie:</p>
<figure><img src="https://palant.info/2024/10/30/the-karma-connection-in-chrome-web-store/privacy.png" alt="Screenshot of a Chrome Web Store listing. Text under the heading Privacy: The developer has disclosed that it will not collect or use your data." width="494" height="90"></figure>

<p>Some of these extensions actually used to have a privacy policy before they were bought. Now only three still have an identical and completely bogus privacy policy. Sudoku on the Rocks happens to be among these three, and the same privacy policy is linked by the Sudoku on the Rocks mobile apps which are officially developed by Karma Shopping Ltd.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SimpleQA (136 pts)]]></title>
            <link>https://openai.com/index/introducing-simpleqa/</link>
            <guid>41997727</guid>
            <pubDate>Wed, 30 Oct 2024 17:16:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-simpleqa/">https://openai.com/index/introducing-simpleqa/</a>, See on <a href="https://news.ycombinator.com/item?id=41997727">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-simpleqa/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AI OmniGen ‚Äì AI Image Generator with Consistent Visuals (107 pts)]]></title>
            <link>https://aiomnigen.com</link>
            <guid>41997648</guid>
            <pubDate>Wed, 30 Oct 2024 17:10:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aiomnigen.com">https://aiomnigen.com</a>, See on <a href="https://news.ycombinator.com/item?id=41997648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><div><h2>Generate with Text-to-Image and Image-Conditioned Prompts | AI OmniGen</h2><p>OmniGen enables you to craft images with simple text prompts or multi-modal inputs, using placeholders for image-conditioned prompts.

Perfect for creating diverse and contextually rich visuals.</p></div><div data-rcs="root"><p><img src="https://fal.media/files/tiger/McOSLy9PtgUjSEC_xyM0c.jpeg" alt="Image one" data-rcs="image"></p><p><img src="https://fal.media/files/kangaroo/CDyzrRL6KfjPOQT4RoHvI.jpeg" alt="Image two" data-rcs="image"></p></div></section><section><div><h2>Identity-Preserving and Subject-Driven Generation | AI OmniGen</h2><p>Maintain subject identity with OmniGen's advanced model, making it ideal for recognizable figures and consistent character rendering.</p></div><div data-rcs="root"><p><img src="https://aiomnigen.com/assets/featureShow/AI_Pioneers.jpg" alt="Image one" data-rcs="image"></p><p><img src="https://aiomnigen.com/assets/featureShow/pose-2.webp" alt="Image two" data-rcs="image"></p></div></section><section><div><h2>Identity-Preserving and Subject-Driven Image Combined Generation | AI OmniGen</h2><p>This feature allows for personalized and highly tailored imagery creation.</p></div><p><img alt="Feature image 1" src="https://aiomnigen.com/assets/featureShow/entity.webp"></p></section><section><div><h2>Seamless Image Editing and Style Customization | AI OmniGen</h2><p>Edit previously generated images with OmniGen‚Äôs flexible seed handling. For example, switch to a new seed when modifying an existing image for unique edits.

Perfect for image refinement and experimentation.</p></div><div data-rcs="root"><p><img src="https://aiomnigen.com/assets/featureShow/women-1.webp" alt="Image one" data-rcs="image"></p><p><img src="https://aiomnigen.com/assets/featureShow/women-2.webp" alt="Image two" data-rcs="image"></p></div></section><section><div><h2>Enhanced Prompt Adaptation for High-Quality Results | AI OmniGen</h2><p>Detailed prompts yield clearer and higher-quality results. OmniGen‚Äôs model adapts to specific prompts to generate visuals that suit professional and creative needs alike.</p></div><div data-rcs="root"><p><img src="https://aiomnigen.com/assets/featureShow/icl1.jpg" alt="Image one" data-rcs="image"></p><p><img src="https://aiomnigen.com/assets/featureShow/icl3.jpg" alt="Image two" data-rcs="image"></p></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cheap solar panels are changing the world (109 pts)]]></title>
            <link>https://www.theatlantic.com/science/archive/2024/10/solar-power-energy-revolution-global-south/680351/</link>
            <guid>41996425</guid>
            <pubDate>Wed, 30 Oct 2024 15:46:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/science/archive/2024/10/solar-power-energy-revolution-global-south/680351/">https://www.theatlantic.com/science/archive/2024/10/solar-power-energy-revolution-global-south/680351/</a>, See on <a href="https://news.ycombinator.com/item?id=41996425">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Color picture of a fuzzy white orb against an orange, red, and black background" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/1tVAqPhOKJ9-Ama_9rJvchKXqa0=/0x0:2700x1519/750x422/media/img/mt/2024/10/2024_10_23_7764/original.jpg 750w, https://cdn.theatlantic.com/thumbor/poGcucq5ljH2A8eXPv8DSzC6ihQ=/0x0:2700x1519/828x466/media/img/mt/2024/10/2024_10_23_7764/original.jpg 828w, https://cdn.theatlantic.com/thumbor/vzl34JyqeomOmxgWi5RcYdaQFhI=/0x0:2700x1519/960x540/media/img/mt/2024/10/2024_10_23_7764/original.jpg 960w, https://cdn.theatlantic.com/thumbor/-NIQgd0bqmqphOjZdN1F-p3_-jQ=/0x0:2700x1519/976x549/media/img/mt/2024/10/2024_10_23_7764/original.jpg 976w, https://cdn.theatlantic.com/thumbor/qsDScksnq-e6h-728nh23UbXE6I=/0x0:2700x1519/1952x1098/media/img/mt/2024/10/2024_10_23_7764/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/vzl34JyqeomOmxgWi5RcYdaQFhI=/0x0:2700x1519/960x540/media/img/mt/2024/10/2024_10_23_7764/original.jpg" id="article-lead-image" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Franz Gruenewald / Connected Archives</figcaption></figure></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><div data-view-action="view - audio player - start" data-view-label="680351" data-event-module="audio player" data-event-content-type="narrated" data-event-module-state="start" data-event-view="true"><div><p><img alt="Color picture of a fuzzy white orb against an orange, red, and black background" sizes="80px" srcset="https://cdn.theatlantic.com/thumbor/NrENC2WTV6PoxwAzBNU1kHPt0qU=/591x0:2110x1519/80x80/media/img/mt/2024/10/2024_10_23_7764/original.jpg 80w, https://cdn.theatlantic.com/thumbor/KnebwVKvhRfzj3DksnCWgV3ylB4=/591x0:2110x1519/96x96/media/img/mt/2024/10/2024_10_23_7764/original.jpg 96w, https://cdn.theatlantic.com/thumbor/r5lm88Wb1WGE8NpCKHyimiJOHB8=/591x0:2110x1519/128x128/media/img/mt/2024/10/2024_10_23_7764/original.jpg 128w, https://cdn.theatlantic.com/thumbor/dz3XkvczCXE5zjTXKlTRdjQ0rLA=/591x0:2110x1519/160x160/media/img/mt/2024/10/2024_10_23_7764/original.jpg 160w, https://cdn.theatlantic.com/thumbor/_FBXT_ch4BJpeyXbD_oKGoZRNXM=/591x0:2110x1519/192x192/media/img/mt/2024/10/2024_10_23_7764/original.jpg 192w, https://cdn.theatlantic.com/thumbor/_GioWRDwGCI0on9bq086G6tlBI8=/591x0:2110x1519/256x256/media/img/mt/2024/10/2024_10_23_7764/original.jpg 256w, https://cdn.theatlantic.com/thumbor/yUkHVOX7E_V2sZEvyP-kabOZtjY=/591x0:2110x1519/384x384/media/img/mt/2024/10/2024_10_23_7764/original.jpg 384w, https://cdn.theatlantic.com/thumbor/6WNHdMgu43KzHaLNHOnBijKJnJs=/591x0:2110x1519/512x512/media/img/mt/2024/10/2024_10_23_7764/original.jpg 512w" src="https://cdn.theatlantic.com/thumbor/NrENC2WTV6PoxwAzBNU1kHPt0qU=/591x0:2110x1519/80x80/media/img/mt/2024/10/2024_10_23_7764/original.jpg" width="80" height="80"></p></div><p>Produced by ElevenLabs and News Over Audio (NOA) using AI narration.</p></div><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true"><em><small>Updated at 1:40 p.m. ET on October 25, 2024</small></em></p><p data-flatplan-paragraph="true">Last month, an energy think tank released some rare good news for the climate: The world is on track to install 29 percent more solar capacity this year than it did the year before, according to a report from <a data-event-element="inline link" href="https://ember-energy.org/latest-insights/solar-power-continues-to-surge-in-2024/">Ember</a>. ‚ÄúIn a single year, in a single technology, we‚Äôre providing as much new electricity as the entirety of global growth the year before,‚Äù Kingsmill Bond, a senior energy strategist at RMI, a clean-energy nonprofit, told me. A decade or two ago, analysts ‚Äúdid not imagine in their wildest dreams that solar by the middle of the 2020s would already be supplying all of the growth of global electricity demand,‚Äù he said. Yet here we are.</p><p data-flatplan-paragraph="true">In the United States, solar accounted for <a data-event-element="inline link" href="https://grist.org/energy/solar-hits-a-renewable-energy-milestone-not-seen-since-wwii/">more than half</a> of all new power last year. But the most dramatic growth is happening overseas. The latest global report from the International Energy Agency (IEA) notes that solar is on track to <a data-event-element="inline link" href="https://www.iea.org/reports/world-energy-outlook-2024">overtake</a> all other forms of energy by 2033. The world‚Äôs use of fossil fuels is already plateauing (the U.S., for its part, hit its peak demand for fossil-fuel energy <a data-event-element="inline link" href="https://www.eia.gov/todayinenergy/detail.php?id=45096#:~:text=The%20share%20of%20U.S.%20total%20energy%20consumption%20that%20originated%20from,increase%20in%20natural%20gas%20consumption.">way back in 2007</a>). Energy demand is still rising, but renewables are stepping in to make up the difference. ‚ÄúThe really interesting debate now,‚Äù Bond said, ‚Äúis actually: When do we push fossil fuels off the plateau? And from our numbers, if solar keeps on growing this way, it‚Äôs going to be off the plateau by the end of this decade.‚Äù</p><p data-flatplan-paragraph="true">The advantages of solar speak for themselves. Solar can be built faster and with fewer permits than other forms of energy infrastructure, mostly because the panels are flat and modular (unlike, say, a towering wind turbine or a hulking gas-fired power plant). It‚Äôs also adaptable at any scale, from an individual erecting a single panel to a utility company assembling a solar farm. And now, thanks to remarkable drops in prices for solar panels, mainly from China, simple market forces seem to be driving an all-out solar boom. ‚ÄúThis is unstoppable,‚Äù Heymi Bahar, a senior energy analyst at the IEA, told me.</p><p data-flatplan-paragraph="true">Globally, some 40 percent of solar‚Äôs growth is in the form of people powering their own homes and businesses, Bahar said. Perhaps nowhere is this better illustrated than in Africa, where Joel Nana, a project manager at Sustainable Energy Africa in Cape Town, has been leading an effort to help countries regulate and integrate the explosion of small-scale solar. When Nana and his team started quantifying just how much new solar was around, ‚Äúwe were actually shocked,‚Äù he told me. In South Africa, for example, the total amount of energy produced from solar systems in 2019 was thought to be about 500 megawatts, Nana said. But in the first quarter of 2023, when researchers <a data-event-element="inline link" href="https://www.sseg.org.za/wp-content/uploads/2024/02/Status-of-EG-in-South-African-Municipalities-2023-FINAL-2.pdf">used satellite imagery</a> to count all of the solar installations in the country, they estimated that solar was producing a combined 5,700 megawatts of energy‚Äîonly 55 percent of which had been declared to the government. That story of rapid, invisible growth is being repeated across the continent. Kenya now has about 200 megawatts of rooftop solar installed, representing 9 percent of the country‚Äôs total energy use, Nana said. Namibia has about 96 megawatts of rooftop solar capacity in its system, he said‚Äîa whopping 15 percent of its energy mix. ‚ÄúIt‚Äôs been happening for three or four years, maybe five years, completely off the radar,‚Äù Nana said.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/magazine/archive/2020/03/climate-change-peer-pressure/605515/">From the March 2020 issue: Thy neighbor‚Äôs solar panels</a></p><p data-flatplan-paragraph="true">Solar seems to have passed a tipping point: In many countries, the low cost of the technology is propelling its own growth, despite little government help. In South Africa, businesses such as shopping malls and factories have historically run diesel generators to deal with frequent power outages. Many still do, but now others are saving money by installing solar panels. Electricity from a diesel generator costs about 10 rand per kilowatt-hour, Nana said; with solar panels, it plummets to about two rand. ‚ÄúIt‚Äôs literally a no-brainer for a business owner,‚Äù he said. Businesses make up 80 percent of small-scale solar capacity in the country, according to his research. Soon, Nana hopes, arrays and batteries will become cheap enough that more homeowners across the continent will be able to afford switching to solar. And, as the journalist Bill McKibben has reported, some homeowners in African countries who have never been connected to the grid are getting electricity for the very first time via solar-panel kits, <a data-event-element="inline link" href="https://www.newyorker.com/magazine/2017/06/26/the-race-to-solar-power-africa">skipping over</a> a fossil-fuel phase entirely.</p><p data-flatplan-paragraph="true">Across the global South, solar is capturing unprecedented portions of the energy market. <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2024-08-09/pakistan-sees-solar-boom-as-chinese-imports-surge-bnef-says?sref=OVk78rkt">Pakistan</a>, for example, imported the equivalent of a quarter of its total energy capacity in Chinese solar panels in just the first six months of this year. Many countries in the global South lack significant fossil-fuel resources, and importing them is expensive. ‚ÄúBy far the easiest way to obtain economic growth in a country with a lot of sunshine and no fossil fuels is by exploiting your own domestic resources,‚Äù Bond said. Already, in countries including Brazil, Morocco, Mexico, and Uruguay, solar and wind make up a bigger share of electricity generation than it does in global-North countries. By 2030, RMI <a data-event-element="inline link" href="https://rmi.org/insight/powering-up-the-global-south/?utm_campaign=heatmap_am&amp;utm_medium=email&amp;_hsenc=p2ANqtz--BBjdCevYygk974VQXcaVPv4j6TzxSY16EAOWZzFTxiQVb1IaUzr5KB04lHP5hWB-Z4i04a3GWJstmBl3UfnMazBK6ig&amp;_hsmi=329173745&amp;utm_content=329173745&amp;utm_source=hs_email">predicts</a>, the global South will have quadrupled its solar and wind capacity.</p><p data-flatplan-paragraph="true">That estimate doesn‚Äôt account for China, which is experiencing an unparalleled solar boom. In addition to supplying the rest of the world with panels, China installed more than half of the planet‚Äôs new solar capacity within its own borders in 2023, and the Ember report says it‚Äôs on track to add a similar amount this year. In 2023, the country more than doubled its own solar capacity year over year. ‚ÄúNobody was expecting that it would be so high,‚Äù Bahar said.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/science/archive/2021/06/why-the-us-doesnt-really-make-solar-panels-anymore-industrial-policy/619213/">Read: Why America doesn‚Äôt really make solar panels anymore</a></p><p data-flatplan-paragraph="true">Last year, at the United Nations Climate Change Conference, or COP28, in Dubai, 132 countries and the European Union <a data-event-element="inline link" href="https://www.cop28.com/en/global-renewables-and-energy-efficiency-pledge#:~:text=Commit%20to%20work%20together%20to,starting%20points%20and%20national%20circumstances">pledged</a> to triple the world‚Äôs renewable-energy capacity by 2030. According to Bahar, it‚Äôs the only promise of the many made in Dubai that‚Äôs likely to even be close to fulfilled: The world is on track to add 2.7 times its renewable capacity by then, and 80 percent of that increase will come from solar. To make use of all this growth, the world will have to add much more storage and transmission capacity, neither of which are keeping up with solar‚Äôs pace. The IEA, where Bahar works, will advocate for new pledges on those two fronts at COP29 next month. A world that mostly runs on solar power will also need something else‚Äîsuch as hydropower, nuclear, or geothermal‚Äîto generate energy when the sun isn‚Äôt shining in the evenings and winters. Jessika Trancik, an MIT professor who models clean-energy development, told me that governments need to steer investments toward storage and alternate forms of energy to compensate for that inherent downtime. That way, the world can have a reliable energy mix when 50 or 60 percent of electricity generation comes from solar and wind. That may seem far off, she said‚Äîsolar made up about <a data-event-element="inline link" href="https://ember-energy.org/latest-insights/the-global-solar-revolution/">5.5 percent</a> of global electricity in 2023‚Äîbut with the exponential growth of cheap solar, ‚Äúbefore you know it, it‚Äôs upon you.‚Äù</p><p data-flatplan-paragraph="true">For Africa‚Äôs quiet solar boom to meet its full potential, governments will need to regulate and subsidize the technology, Nana said. Federal departments in Namibia, Kenya, and Eswatini have largely ignored the ascendance of solar technology within their borders, Nana said. Yet in South Africa, he‚Äôs seeing bright spots. Last year, the government began providing subsidies for solar for the first time. This year, its updated energy plan acknowledged that small-scale solar will be the biggest player in the country in the next decade. If South Africa is any indication, a solar revolution will arrive in more countries in the coming years. It may even sneak up on them.</p><hr><p data-flatplan-paragraph="true"><small><em>This article originally misstated that solar power made up 5.5 percent of global energy in 2023. It made up 5.5 percent of global electricity.</em></small></p></section><div data-event-module="footer"><p><h3>About the Author</h3></p><div><address id="article-writer-0" data-event-element="author" data-event-position="1" data-flatplan-bio="true"><div><p><a href="https://www.theatlantic.com/author/zoe-schlanger/" data-event-element="image"><img alt="" loading="lazy" src="https://cdn.theatlantic.com/thumbor/u8S5JVOtiftKFSYJUPgPfsZK710=/468x9:2384x1925/120x120/media/img/authors/2023/10/Sten_SSENSE_ZoeSchlanger_18_hi_res_version/original.jpg" width="60" height="60"></a></p><div><p><a href="https://www.theatlantic.com/author/zoe-schlanger/" data-label="https://www.theatlantic.com/author/zoe-schlanger/" data-action="click author - name">Zo√´ Schlanger</a> is a staff writer at <em>The Atlantic</em>. She is the author of <em><a href="https://bookshop.org/p/books/the-light-eaters-how-the-unseen-world-of-plant-intelligence-offers-a-new-understanding-of-life-on-earth-zoe-schlanger/20890522?ean=9780063073852">The Light Eaters</a>, </em>about the world of plant-behavior-and-intelligence research.</p></div></div></address></div></div><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pushing the frontiers of audio generation (175 pts)]]></title>
            <link>https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/</link>
            <guid>41995730</guid>
            <pubDate>Wed, 30 Oct 2024 15:02:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/">https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/</a>, See on <a href="https://news.ycombinator.com/item?id=41995730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    

    
    
      
        <div>
          
            
            
              
              
<div>
    <div>
      <p>Technologies</p>
      

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2024-10-30">30 October 2024</time></dd>
      
      
        <dt>Authors</dt>
        
      
    </dl>
  

      
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w2144-h1206-n-nu-rw 2x"><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w1856-h1044-n-nu-rw 2x"><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w1056-h594-n-nu-rw 2x">
      <img alt="An illustration depicting speech patterns, iterative progress on dialogue generation,  and a relaxed conversation between two voices." height="603" src="https://lh3.googleusercontent.com/_jjPl1Kv1mv1Qz5QdR_nJ-3rnaqSrwTabpyrdabzYl7hytlaIMj_i3elkt5o3pPVCjI-9M0Nuazevo3Jr81VubuIV4QY9IZsxVDPktGMGeODFIFn=w1072-h603-n-nu" width="1072">
    </picture>
    
  
    
  </div>
            
          
            
            
              
              <div>
  <h4 data-block-key="yrcbl">Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.</h4><p data-block-key="3cjpl">Speech is central to human connection. It helps people around the world exchange information and ideas, express emotions and create mutual understanding. As our technology built for generating natural, dynamic voices continues to improve, we‚Äôre unlocking richer, more engaging digital experiences.</p><p data-block-key="bh9mr">Over the past few years, we‚Äôve been pushing the frontiers of audio generation, developing models that can create high quality, natural speech from a range of inputs, like text, tempo controls and particular voices. This technology powers single-speaker audio in many Google products and experiments ‚Äî including <a href="https://blog.google/products/gemini/made-by-google-gemini-ai-updates/" rel="noopener" target="_blank">Gemini Live</a>, <a href="https://deepmind.google/technologies/gemini/project-astra/" rel="noopener" target="_blank">Project Astra</a>, <a href="https://cloud.google.com/text-to-speech/docs/voice-types" rel="noopener" target="_blank">Journey Voices</a> and <a href="https://blog.youtube/news-and-events/made-on-youtube-2024/" rel="noopener" target="_blank">YouTube‚Äôs auto dubbing</a> ‚Äî and is helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.</p><p data-block-key="7838d">Working together with partners across Google, we recently helped develop two new features that can generate long-form, multi-speaker dialogue for making complex content more accessible:</p><ul><li data-block-key="5j7f7"><a href="https://notebooklm.google/" rel="noopener" target="_blank">NotebookLM Audio Overviews</a> turns uploaded documents into engaging and lively dialogue. With one click, two AI hosts summarize user material, make connections between topics and banter back and forth.</li><li data-block-key="9q17j"><a href="https://illuminate.google.com/" rel="noopener" target="_blank">Illuminate</a> creates formal AI-generated discussions about research papers to help make knowledge more accessible and digestible.</li></ul><p data-block-key="c3kro">Here, we provide an overview of our latest speech generation research underpinning all of these products and experimental tools.</p>
</div>
            
          
            
            
              
              <div>
  <h2 data-block-key="auxvk">Pioneering techniques for audio generation</h2><p data-block-key="2rhdn">For years, we've been investing in audio generation research and exploring new ways for generating more natural dialogue in our products and experimental tools. In our previous research on <a href="https://research.google/blog/soundstorm-efficient-parallel-audio-generation/" rel="noopener" target="_blank">SoundStorm</a>, we first demonstrated the ability to generate 30-second segments of natural dialogue between multiple speakers.</p><p data-block-key="ecfnq">This extended our earlier work, <a href="https://research.google/blog/soundstream-an-end-to-end-neural-audio-codec/" rel="noopener" target="_blank">SoundStream</a> and <a href="https://google-research.github.io/seanet/audiolm/examples/" rel="noopener" target="_blank">AudioLM</a>, which allowed us to apply many text-based language modeling techniques to the problem of audio generation.</p><p data-block-key="7m7rr">SoundStream is a neural audio codec that efficiently compresses and decompresses an audio input, without compromising its quality. As part of the training process, SoundStream learns how to map audio to a range of acoustic tokens. These tokens capture all of the information needed to reconstruct the audio with high fidelity, including properties such as <a href="https://en.wikipedia.org/wiki/Prosody_(linguistics)" rel="noopener" target="_blank">prosody</a> and <a href="https://en.wikipedia.org/wiki/Timbre" rel="noopener" target="_blank">timbre</a>.</p><p data-block-key="3bngd">AudioLM treats audio generation as a language modeling task to produce the acoustic tokens of codecs like SoundStream. As a result, the AudioLM framework makes no assumptions about the type or makeup of the audio being generated, and can flexibly handle a variety of sounds without needing architectural adjustments ‚Äî making it a good candidate for modeling multi-speaker dialogues.</p>
</div>
            
          
            
            
              
              


            
          
            
            
              
              




<figure aria-labelledby="single-media-ab666b1b-5b78-44a6-a805-9b31cf82c4e3-figcaption">
  
  
    <figcaption id="single-media-ab666b1b-5b78-44a6-a805-9b31cf82c4e3-figcaption">
      <p data-block-key="1snyy">Example of a multi-speaker dialogue generated by NotebookLM Audio Overview, based on a few potato-related documents.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              <p data-block-key="6qplr">Building upon this research, our latest speech generation technology can produce 2 minutes of dialogue, with improved naturalness, speaker consistency and acoustic quality, when given a script of dialogue and speaker turn markers. The model also performs this task in under 3 seconds on a single <a href="https://cloud.google.com/tpu/docs/v5e" rel="noopener" target="_blank">Tensor Processing Unit (TPU) v5e chip</a>, in one inference pass. This means it generates audio over 40-times faster than real time.</p>
            
          
            
            
              
              <div>
  <h2 data-block-key="uq3en">Scaling our audio generation models</h2><p data-block-key="du2ro">Scaling our single-speaker generation models to multi-speaker models then became a matter of data and model capacity. To help our latest speech generation model produce longer speech segments, we created an even more efficient speech codec for compressing audio into a sequence of tokens, in as low as 600 bits per second, without compromising the quality of its output.</p><p data-block-key="g9ht">The tokens produced by our codec have a hierarchical structure and are grouped by time frames. The first tokens within a group capture phonetic and prosodic information, while the last tokens encode fine acoustic details.</p><p data-block-key="7vshj">Even with our new speech codec, producing a 2-minute dialogue requires generating over 5000 tokens. To model these long sequences, we developed a specialized <a href="https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/" rel="noopener" target="_blank">Transformer</a> architecture that can efficiently handle hierarchies of information, matching the structure of our acoustic tokens.</p><p data-block-key="8djch">With this technique, we can efficiently generate acoustic tokens that correspond to the dialogue, within a single autoregressive inference pass. Once generated, these tokens can be decoded back into an audio waveform using our speech codec.</p>
</div>
            
          
            
            
              
              




<figure aria-labelledby="single-media-a9d3eb76-9a4f-464c-a5fa-a7f1fbd5b760-figcaption">
  
  
    <figcaption id="single-media-a9d3eb76-9a4f-464c-a5fa-a7f1fbd5b760-figcaption">
      <p data-block-key="57qqn">Animation showing how our speech generation model produces a stream of audio tokens autoregressively, which are decoded back to a waveform consisting of a two-speaker dialogue.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              <div>
  <p data-block-key="269cj">To teach our model how to generate realistic exchanges between multiple speakers, we pretrained it on hundreds of thousands of hours of speech data. Then we finetuned it on a much smaller dataset of dialogue with high acoustic quality and precise speaker annotations, consisting of unscripted conversations from a number of voice actors and realistic <a href="https://en.wikipedia.org/wiki/Speech_disfluency" rel="noopener" target="_blank">disfluencies</a> ‚Äî the ‚Äúumm‚Äùs and ‚Äúaah‚Äùs of real conversation. This step taught the model how to reliably switch between speakers during a generated dialogue and to output only studio quality audio with realistic pauses, tone and timing.</p><p data-block-key="8shit">In line with our <a href="https://ai.google/responsibility/principles/" rel="noopener" target="_blank">AI Principles</a> and our commitment to developing and deploying AI technologies responsibly, we‚Äôre incorporating our SynthID technology to watermark non-transient AI-generated audio content from these models, to help safeguard against the potential misuse of this technology.</p>
</div>
            
          
            
            
              
              <div>
  <h2 data-block-key="wao8a">New speech experiences ahead</h2><p data-block-key="dr1sf">We‚Äôre now focused on improving our model‚Äôs fluency, acoustic quality and adding more fine-grained controls for features, like prosody, while exploring how best to combine these advances with other modalities, such as video.</p><p data-block-key="82sf">The potential applications for advanced speech generation are vast, especially when combined with our Gemini family of models. From enhancing learning experiences to making content more universally accessible, we‚Äôre excited to continue pushing the boundaries of what‚Äôs possible with voice-based technologies.</p>
</div>
            
          
            
            
              
              


            
          
            
            
              
              
            
          
            
            
              
              



  
    
  

            
          
        </div>
      
    

    
  
  

  

  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[M4 MacBook Pro (703 pts)]]></title>
            <link>https://www.apple.com/newsroom/2024/10/new-macbook-pro-features-m4-family-of-chips-and-apple-intelligence/</link>
            <guid>41995701</guid>
            <pubDate>Wed, 30 Oct 2024 15:00:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2024/10/new-macbook-pro-features-m4-family-of-chips-and-apple-intelligence/">https://www.apple.com/newsroom/2024/10/new-macbook-pro-features-m4-family-of-chips-and-apple-intelligence/</a>, See on <a href="https://news.ycombinator.com/item?id=41995701">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 30, 2024</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple‚Äôs new MacBook&nbsp;Pro features the incredibly powerful M4 family of chips and ushers in a new era with Apple&nbsp;Intelligence
    

                    </h2>
                
            </div>

        <div>
                
                
                    With an advanced 12MP Center Stage camera, Thunderbolt&nbsp;5 on M4&nbsp;Pro and M4&nbsp;Max models, and an all-new nano-texture display option, MacBook&nbsp;Pro gets even more capable and even more pro
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, An almost shut MacBook Pro emits a colorful glowing light.">
        <div>
             
              
              <div>
                Supercharged by Apple Intelligence, even more powerful Apple silicon with the M4 family of chips, and new capabilities, MacBook Pro accelerates pro workloads like never before.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-hero.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-hero_big" aria-label="Download media, An almost shut MacBook Pro emits a colorful glowing light."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong><span>CUPERTINO, CALIFORNIA</span> </strong>Apple today unveiled the new <a href="https://www.youtube.com/watch?v=G0cmfY7qdmY" target="_blank" rel="nofollow" data-analytics-exit-link="">MacBook Pro</a>, powered by the M4 family of chips ‚Äî M4, M4 Pro, and M4 Max ‚Äî delivering much faster performance and enhanced capabilities. The new MacBook Pro is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. Now available in space black and silver finishes, the 14-inch MacBook Pro includes the blazing-fast performance of M4 and three Thunderbolt 4 ports, starting with 16GB of memory, all at just $1,599. The 14- and 16-inch models with M4 Pro and M4 Max offer Thunderbolt 5 for faster transfer speeds and advanced connectivity. All models include a Liquid Retina XDR display that gets even better with an all-new nano-texture display option and up to 1000 nits of brightness for SDR content, an advanced 12MP Center Stage camera, along with up to 24 hours of battery life, the longest ever in a Mac.<sup>1</sup> The new MacBook Pro is available to pre-order today, with availability beginning November 8.
</div>
                 
             
                 <div>‚ÄúMacBook Pro is an incredibly powerful tool that millions of people use to do their life‚Äôs best work, and today we‚Äôre making it even better,‚Äù said John Ternus, Apple‚Äôs senior vice president of Hardware Engineering. ‚ÄúWith the powerful M4 family of chips, and packed with pro features like Thunderbolt 5, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and Apple Intelligence, the new MacBook Pro continues to be, by far, the world‚Äôs best pro laptop.‚Äù
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="macbook-pro-details">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-6f87eb0dc4ce953520c7f9cc606f58cf" href="#gallery-6f87eb0dc4ce953520c7f9cc606f58cf" data-ac-gallery-trigger="gallery-6f87eb0dc4ce953520c7f9cc606f58cf"><span>A look at the front and the back of the new MacBook Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-e77c52288c1b1d227891ed9d8eff5844" href="#gallery-e77c52288c1b1d227891ed9d8eff5844" data-ac-gallery-trigger="gallery-e77c52288c1b1d227891ed9d8eff5844"><span>A close-up of the keyboard on the new MacBook Pro.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-6f87eb0dc4ce953520c7f9cc606f58cf" aria-labelledby="gallery-dotnav-6f87eb0dc4ce953520c7f9cc606f58cf" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:front-and-back">
                                
                                <div>
                                    <div>The new MacBook Pro is transformed with Apple Intelligence, the blazing performance of the M4 family, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-lineup.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-lineup_big" aria-label="Download media, A look at the front and the back of the new MacBook Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-e77c52288c1b1d227891ed9d8eff5844" aria-labelledby="gallery-dotnav-e77c52288c1b1d227891ed9d8eff5844" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:screen-and-keyboard">
                                
                                <div>
                                    <div>The new MacBook Pro is transformed with Apple Intelligence, the blazing performance of the M4 family, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-Magic-Keyboard-close-up.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-Magic-Keyboard-close-up_big" aria-label="Download media, A close-up of the keyboard on the new MacBook Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Supercharged by the M4 Family of Chips</strong>
</h2>
                 
             
                 <div>Built using second-generation 3-nanometer technology, the <a href="https://www.apple.com/newsroom/2024/10/apple-introduces-m4-pro-and-m4-max" target="_blank">M4 family</a> is the most advanced lineup of chips for a personal computer. The M4 family features phenomenal single-threaded CPU performance with the world‚Äôs fastest CPU core,<sup>2</sup> along with outstanding multithreaded CPU performance for the most demanding workloads. Combined with machine learning accelerators in the CPU, an advanced GPU, and a faster and more efficient Neural Engine, Apple silicon is built from the ground up to deliver incredible performance for AI. Together with faster unified memory, each chip also includes increased memory bandwidth, so large language models (LLMs) and other large projects run smoothly and on device. Additionally, the industry-leading performance per watt of the M4 family means that users get up to 24 hours of battery life, raising the bar of what users can do on a single charge.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A graphic shows the M4 family of chips: M4, M4 Pro, and M4 Max.">
        <div>
             
              
              <div>
                The new MacBook&nbsp;Pro features the M4 family of chips, the most advanced lineup of chips ever built for a pro laptop.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-chip-series-3up.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-chip-series-3up_big" aria-label="Download media, A graphic shows the M4 family of chips: M4, M4 Pro, and M4 Max."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>New 14-inch MacBook Pro with M4</strong>
</h2>
                 
             
                 <div>The 14-inch MacBook Pro with M4 is the ideal choice for entrepreneurs, students, creators, or anyone doing what they love. Featuring a more powerful 10-core CPU, with four performance cores and six efficiency cores, and a faster 10-core GPU with Apple‚Äôs most advanced graphics architecture, the new MacBook Pro starts with 16GB of faster unified memory with support for up to 32GB, along with 120GB/s of memory bandwidth. With M4, MacBook Pro is up to 1.8x faster than the 13-inch MacBook Pro with M1 for tasks like editing gigapixel photos, and even more demanding workloads like rendering complex scenes in Blender are up to 3.4x faster.<sup>1</sup> With a Neural Engine that‚Äôs over 3x more powerful than in M1, it‚Äôs great for features in Apple Intelligence and other AI workloads. The M4 model also supports two high-resolution external displays in addition to the built-in display, and now features three Thunderbolt 4 ports so users can connect all their peripherals.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A person sits on the floor, working on a MacBook Pro propped up on their lap.">
        <div>
             
              
              <div>
                MacBook Pro empowers users to work and be creative wherever they are, with even more game-changing performance and extraordinary battery life.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-lifestyle-01.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-lifestyle-01_big" aria-label="Download media, A person sits on the floor, working on a MacBook Pro propped up on their lap."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong>MacBook Pro with M4 delivers:<sup>1</sup></strong>
</div>
                 
             
                 <div><ul>
<li>Up to 7x faster image processing in Affinity Photo when compared to the 13‚Äëinch MacBook Pro with Core i7, and up to 1.8x faster when compared to the 13-inch MacBook Pro with M1.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 10.9x faster 3D rendering in Blender when compared to the 13‚Äëinch MacBook Pro with Core i7, and up to 3.4x faster when compared to the 13‚Äëinch MacBook Pro with M1.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 9.8x faster scene edit detection in Adobe Premiere Pro when compared to the 13‚Äëinch MacBook Pro with Core i7, and up to 1.7x faster when compared to the 13‚Äëinch MacBook Pro with M1.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>M4 brings phenomenal performance to the new 14-inch MacBook Pro, from creative tasks to even more demanding workloads such as rendering complex scenes in Blender.</div>
        
            <a aria-label="Download video: MacBook Pro Blender Workflow" data-analytics-title="Download video - MacBook Pro Blender Workflow" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-macbook-pro-m4-blender/downloads/Apple-MacBook-Pro-M4-Blender.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>MacBook Pro with M4 Pro: A Pro Powerhouse</strong>
</h2>
                 
             
                 <div>For researchers, developers, engineers, creative pros, or anyone that needs even faster performance for more demanding workflows, MacBook Pro with M4 Pro offers a tremendous performance boost. M4 Pro features a powerful 14-core CPU with 10 performance cores and four efficiency cores for a jump in multicore performance, along with up to a 20-core GPU that is twice as powerful as M4. With M4 Pro, the new MacBook Pro gets a massive 75 percent increase in memory bandwidth over the prior generation ‚Äî double that of any AI PC chip.<sup>3</sup> The new MacBook Pro with M4 Pro is up to 3x faster than models with M1 Pro, speeding up workflows like geo mapping, structural engineering, and data modeling.<sup>1</sup>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two people work in a lab, with one using the new MacBook Pro.">
        <div>
             
              
              <div>
                The new 14- and 16-inch MacBook Pro with M4 Pro is ideal for researchers, developers, engineers, creative pros, or for anyone looking for even faster performance.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-lifestyle-02.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-lifestyle-02_big" aria-label="Download media, Two people work in a lab, with one using the new MacBook Pro."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong>MacBook Pro with M4 Pro offers:<sup>1</sup></strong>
</div>
                 
             
                 <div><ul>
<li>Up to 4x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Core i9, and up to 3x faster when compared to the 16-inch MacBook Pro with M1 Pro.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 5x faster simulation of dynamical systems in MathWorks MATLAB when compared to the 16-inch MacBook Pro with Core i9, and up to 2.2x faster when compared to the 16-inch MacBook Pro with M1 Pro.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 23.8x faster basecalling for DNA sequencing in Oxford Nanopore MinKNOW when compared to the 16-inch MacBook Pro with Core i9, and up to 1.8x faster when compared to the 16-inch MacBook Pro with M1 Pro.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="macbook-pro-m4-pro-workflows">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-67b1179c669e36224b07ff92d8ff1291" href="#gallery-67b1179c669e36224b07ff92d8ff1291" data-ac-gallery-trigger="gallery-67b1179c669e36224b07ff92d8ff1291"><span>A user works in Fusion on the new MacBook Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-5d95f85875db4499732c2b5318c2f27b" href="#gallery-5d95f85875db4499732c2b5318c2f27b" data-ac-gallery-trigger="gallery-5d95f85875db4499732c2b5318c2f27b"><span>A user works in Luna Modeler on the new MacBook Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1d2a1510f37c521f0c1ef7d42b17661e" href="#gallery-1d2a1510f37c521f0c1ef7d42b17661e" data-ac-gallery-trigger="gallery-1d2a1510f37c521f0c1ef7d42b17661e"><span>A user works in Xcode on the new MacBook Pro.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-67b1179c669e36224b07ff92d8ff1291" aria-labelledby="gallery-dotnav-67b1179c669e36224b07ff92d8ff1291" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:fusion">
                                
                                <div>
                                    <div>The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-Fusion.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-Fusion_big" aria-label="Download media, A user works in Fusion on the new MacBook Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-5d95f85875db4499732c2b5318c2f27b" aria-labelledby="gallery-dotnav-5d95f85875db4499732c2b5318c2f27b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:luna-modeler">
                                
                                <div>
                                    <div>The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-Luna-Modeler.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-Luna-Modeler_big" aria-label="Download media, A user works in Luna Modeler on the new MacBook Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1d2a1510f37c521f0c1ef7d42b17661e" aria-labelledby="gallery-dotnav-1d2a1510f37c521f0c1ef7d42b17661e" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:xcode">
                                
                                <div>
                                    <div>The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-Cinema-4D-Slack-Finder-Xcode.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-Cinema-4D-Slack-Finder-Xcode_big" aria-label="Download media, A user works in Xcode on the new MacBook Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>MacBook Pro with M4 Max: The Ultimate in Pro Performance</strong>
</h2>
                 
             
                 <div>Designed for pros like data scientists, 3D artists, and composers who constantly push workflows to the limit, MacBook Pro with M4 Max empowers users to work on projects that were previously only imaginable on a desktop. M4 Max brings up to a 16-core CPU, up to a 40-core GPU, over half a terabyte per second of unified memory bandwidth, and a Neural Engine that is over 3x faster than M1 Max, allowing on-device AI models to run faster than ever. With M4 Max, MacBook Pro delivers up to 3.5x the performance of M1 Max, ripping through heavy creative workloads like visual effects, 3D animation, and film scoring.<sup>1</sup> It also supports up to 128GB of unified memory, so developers can easily interact with LLMs that have nearly 200 billion parameters. And with the powerful Media Engine in M4 Max, which features two ProRes accelerators, MacBook Pro performance is amazing even when taking 4K120 fps ProRes video captured with the new iPhone 16 Pro and editing it in Final Cut Pro.
</div>
                 
             
                 <div><strong>MacBook Pro with M4 Max enables:<sup>1</sup></strong>
</div>
                 
             
                 <div><ul>
<li>Up to 7.8x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Intel Core i9, and up to 3.5x faster when compared to the 16-inch MacBook Pro with M1 Max.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 4.6x faster build performance when compiling code in Xcode when compared to the 16‚Äëinch MacBook Pro with Intel Core i9, and up to 2.2x faster when compared to the 16‚Äëinch MacBook Pro with M1 Max.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 30.8x faster video processing performance in Topaz Video AI when compared to the 16‚Äëinch MacBook Pro with Intel Core i9, and up to 1.6x faster when compared to the 16-inch MacBook Pro with M1 Max.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="macbook-pro-m4-max-workflows">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-e7f3015f7a7b3c6c39f9c8f972852143" href="#gallery-e7f3015f7a7b3c6c39f9c8f972852143" data-ac-gallery-trigger="gallery-e7f3015f7a7b3c6c39f9c8f972852143"><span>Flame is shown on MacBook Pro with M4 Max.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-51972600b23331ea62e5a7a7473b2cda" href="#gallery-51972600b23331ea62e5a7a7473b2cda" data-ac-gallery-trigger="gallery-51972600b23331ea62e5a7a7473b2cda"><span>LM Studio is shown on MacBook Pro with M4 Max.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-e7f3015f7a7b3c6c39f9c8f972852143" aria-labelledby="gallery-dotnav-e7f3015f7a7b3c6c39f9c8f972852143" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:flame">
                                
                                <div>
                                    <div>With M4 Max, MacBook Pro rips through the heaviest creative workloads like visual effects, 3D animation, and film scoring.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-Flame.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-Flame_big" aria-label="Download media, Flame is shown on MacBook Pro with M4 Max."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-51972600b23331ea62e5a7a7473b2cda" aria-labelledby="gallery-dotnav-51972600b23331ea62e5a7a7473b2cda" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lm-studio">
                                
                                <div>
                                    <div>With support for up to 128GB of unified memory, developers can easily interact with LLMs that have nearly 200 billion parameters.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-LM-Studio.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-LM-Studio_big" aria-label="Download media, LM Studio is shown on MacBook Pro with M4 Max."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Industry-Leading Liquid XDR Display Gets Even Better</strong>
</h2>
                 
             
                 <div>The new MacBook Pro introduces an all-new nano-texture display option that dramatically reduces glare and distractions from reflections. In bright lighting conditions, the new MacBook Pro can now show SDR content at up to 1000 nits and still displays HDR content at up to 1600 nits of peak brightness. All together, it‚Äôs a game-changing experience for users working outdoors.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A user works on MacBook Pro outdoors in a field of vegetables.">
        <div>
             
              
              <div>
                A game changer when working outdoors, the Liquid Retina XDR display gets even better with an all-new nano-texture display option and up to 1000 nits of brightness for SDR content.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-lifestyle-03.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-lifestyle-03_big" aria-label="Download media, A user works on MacBook Pro outdoors in a field of vegetables."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>New 12MP Center Stage Camera</strong>
</h2>
                 
             
                 <div>MacBook Pro includes a new 12MP Center Stage camera that delivers enhanced video quality in challenging lighting conditions. Video calls are even more engaging with Center Stage, which automatically keeps users centered in the frame as they move around. The new camera also supports Desk View, which adds a whole new dimension to video calls. And with studio-quality mics and a phenomenal six-speaker sound system with support for Spatial Audio, MacBook Pro delivers an incredibly immersive audio experience whether users are listening to music or watching a movie in Dolby Atmos.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>MacBook Pro features a new 12MP Center Stage camera, which keeps users centered in the frame, and supports Desk View, which adds a whole new dimension to video calls.</div>
        
            <a aria-label="Download video: MacBook Pro Video Call with Center Stage" data-analytics-title="Download video - MacBook Pro Video Call with Center Stage" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-macbook-pro-m4-center-stage-camera/downloads/Apple-MacBook-Pro-M4-Center-Stage-camera.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Thunderbolt 5 Comes to the Mac</strong>
</h2>
                 
             
                 <div>MacBook Pro with M4 Pro and M4 Max features Thunderbolt 5 ports that more than double transfer speeds up to 120 Gb/s, enabling faster external storage, expansion chassis, and powerful docking and hub solutions. For example, by connecting just a single cable, pros like music producers can now light up their entire studio. All MacBook Pro models feature an HDMI port that supports up to 8K resolution, a SDXC card slot, a MagSafe 3 port for charging, and a headphone jack, along with support for Wi-Fi 6E and Bluetooth 5.3.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A close-up of the keyboard on MacBook Pro and its Thunderbolt 5 ports with plugged-in peripherals.">
        <div>
             
              
              <div>
                MacBook Pro with M4 Pro and M4 Max now features Thunderbolt 5 with faster transfer speeds that enable powerful docking and hub solutions, allowing pros to connect to higher-bandwidth gear with a single cable.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/new-macbook-pro/article/Apple-MacBook-Pro-M4-connectivity.zip" download="" data-analytics-title="download image - Apple-MacBook-Pro-M4-connectivity_big" aria-label="Download media, A close-up of the keyboard on MacBook Pro and its Thunderbolt 5 ports with plugged-in peripherals."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A New Era with Apple Intelligence on the Mac</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/newsroom/2024/10/apple-intelligence-is-available-today-on-iphone-ipad-and-mac/" target="_blank">Apple Intelligence</a> ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user‚Äôs personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Apple Intelligence transforms the things users do every day on their Mac. With brand-new Writing Tools, users can rewrite, proofread, or summarize everything from daily emails to important projects.</div>
        
            <a aria-label="Download video: Apple Intelligence Writing Tools" data-analytics-title="Download video - Apple Intelligence Writing Tools" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-macbook-pro-m4-writing-tools/downloads/Apple-MacBook-Pro-M4-Writing-Tools.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <div>Apple Intelligence does all this while protecting users‚Äô privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple‚Äôs even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in ‚Äî their IP addresses are obscured and OpenAI won‚Äôt store requests. For those who choose to connect their account, OpenAI‚Äôs data-use policies apply.
</div>
                 
             
                 <h2><strong>An Unrivaled Experience with macOS Sequoia</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/macos/macos-sequoia-preview/" target="_blank">macOS Sequoia</a> completes the new MacBook Pro experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and notifications directly from their Mac.<sup>4</sup> Safari, the world‚Äôs fastest browser,<sup>5</sup> now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin‚Äôs Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply new beautiful built-in backgrounds for video calls, which include a variety of color gradients and system wallpapers, or upload their own photos.
</div>
                 
             
                 <h2><strong>The Perfect Time to Upgrade or Switch to a Mac</strong>
</h2>
                 
             
                 <div>Upgraders will get monumental improvements over Intel-based MacBook Pro models, including the amazing features of Apple Intelligence. When compared to an Intel-based MacBook Pro, the new MacBook Pro provides nearly 10x faster performance for AI-based workloads,<sup>1</sup> and for graphics-intensive workloads, users get up to 20x faster performance.<sup>6</sup> With battery life on the new MacBook Pro now up to 24 hours, upgraders will also experience up to 14 additional hours. And with the Liquid Retina XDR display, a new 12MP Center Stage camera, an immersive six-speaker sound system, the unrivaled experience of macOS Sequoia, and more, there‚Äôs never been a better time to upgrade or switch to MacBook Pro.
</div>
                 
             
                 <h2><strong>MacBook Air: The World‚Äôs Most Popular Laptop Now Starts at 16GB</strong>
</h2>
                 
             
                 <div>MacBook Air is the world‚Äôs most popular laptop, and with Apple Intelligence, it‚Äôs even better. Now, models with M2 and M3 double the starting memory to 16GB, while keeping the starting price at just $999 ‚Äî a terrific value for the world‚Äôs best-selling laptop.
</div>
                 
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>The new MacBook Pro is built to last and incredibly durable, created from a custom alloy that uses 100 percent recycled aluminum in the enclosure. It also uses 100 percent recycled rare earth elements in all magnets, and 100 percent recycled tin soldering, gold plating, and copper in multiple printed circuit boards. The packaging for the 14-inch MacBook Pro is now entirely fiber-based, joining the 16-inch MacBook Pro and bringing Apple closer to its goal to remove plastic from its packaging by 2025.
</div>
                 
             
                 <div>Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Customers can pre-order the new MacBook Pro starting today, October 30, on <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a> and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The 14-inch MacBook Pro with M4 starts at <strong>$1,599</strong> (U.S.) and <strong>$1,499</strong> (U.S.) for education; the 14‚Äëinch MacBook Pro with M4 Pro starts at <strong>$1,999</strong> (U.S.) and <strong>$1,849 </strong>(U.S.) for education; and the 16‚Äëinch MacBook Pro starts at <strong>$2,499</strong> (U.S.) and <strong>$2,299 </strong>(U.S.) for education. All models are available in space black and silver.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Additional technical specifications, including the nano-texture display and configure-to-order options, are available at <a href="https://www.apple.com/mac/" target="_blank">apple.com/mac</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>MacBook Air with M2 and M3 comes standard with 16GB of unified memory, and is available in midnight, starlight, silver, and space gray, starting at <strong>$999</strong> (U.S.) and <strong>$899</strong> (U.S.) for education.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>New accessories with USB-C ‚Äî including Magic Keyboard (<strong>$99 </strong>U.S.), Magic Keyboard with Touch ID (<strong>$149</strong> U.S.), Magic Keyboard with Touch ID and Numeric Keypad (<strong>$179</strong> U.S.), Magic Trackpad (<strong>$129 </strong>U.S.), Magic Mouse (<strong>$79</strong> U.S.), and Thunderbolt 5 Pro Cable (<strong>$69</strong>) ‚Äî are available at <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in <em>Australia</em>, <em>Canada</em>, <em>Ireland</em>, <em>New Zealand</em>, <em>South Africa</em>, and the <em>U.K.,</em> and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a> to see what their device is worth.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Testing was conducted by Apple from August through October 2024. Battery life varies by use and configuration. See <a href="https://www.apple.com/macbook-pro/" target="_blank">apple.com/macbook-pro</a> for more information.</li>
<li>Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks.</li>
<li>Based on published technical specifications of shipping competitive chips as of October 2024.</li>
<li>Available on Mac computers with Apple&nbsp;silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user‚Äôs iPhone and Mac are signed in with the same Apple&nbsp;Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone&nbsp;Mirroring.</li>
<li>Testing was conducted by Apple in August 2024. See <a href="https://www.apple.com/safari/" target="_blank">apple.com/safari</a> for more information.</li>
<li>Results are compared to previous-generation 1.7GHz quad-core Intel Core i7-based 13-inch MacBook&nbsp;Pro systems with Intel Iris Plus Graphics 645, 16GB of RAM, and 2TB SSD.</li>
</ol>

        </div>



    
    
    






    

















		
		
			
























		
		

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internal representations of LLMs encode information about truthfulness (129 pts)]]></title>
            <link>https://arxiv.org/abs/2410.02707</link>
            <guid>41995201</guid>
            <pubDate>Wed, 30 Oct 2024 14:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2410.02707">https://arxiv.org/abs/2410.02707</a>, See on <a href="https://news.ycombinator.com/item?id=41995201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2410.02707">View PDF</a>
    <a href="https://arxiv.org/html/2410.02707v3">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as "hallucinations". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this information can be utilized to detect errors. In this work, we show that the internal representations of LLMs encode much more information about truthfulness than previously recognized. We first discover that the truthfulness information is concentrated in specific tokens, and leveraging this property significantly enhances error detection performance. Yet, we show that such error detectors fail to generalize across datasets, implying that -- contrary to prior claims -- truthfulness encoding is not universal but rather multifaceted. Next, we show that internal representations can also be used for predicting the types of errors the model is likely to make, facilitating the development of tailored mitigation strategies. Lastly, we reveal a discrepancy between LLMs' internal encoding and external behavior: they may encode the correct answer, yet consistently generate an incorrect one. Taken together, these insights deepen our understanding of LLM errors from the model's internal perspective, which can guide future research on enhancing error analysis and mitigation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Hadas Orgad [<a href="https://arxiv.org/show-email/660cb3e9/2410.02707">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2410.02707v1">[v1]</a></strong>
        Thu, 3 Oct 2024 17:31:31 UTC (2,525 KB)<br>
            <strong><a href="https://arxiv.org/abs/2410.02707v2">[v2]</a></strong>
        Mon, 7 Oct 2024 14:46:11 UTC (2,530 KB)<br>
    <strong>[v3]</strong>
        Mon, 28 Oct 2024 12:33:44 UTC (2,360 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thunderbird for Android Now Available (194 pts)]]></title>
            <link>https://blog.thunderbird.net/2024/10/thunderbird-for-android-8-0-takes-flight/</link>
            <guid>41995041</guid>
            <pubDate>Wed, 30 Oct 2024 14:11:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.thunderbird.net/2024/10/thunderbird-for-android-8-0-takes-flight/">https://blog.thunderbird.net/2024/10/thunderbird-for-android-8-0-takes-flight/</a>, See on <a href="https://news.ycombinator.com/item?id=41995041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<img src="https://blog.thunderbird.net/files/2024/10/blog-banner-TBfA.jpg" alt="featured post title image">
						<section>
												

				
<p>Just over two years ago, we <a href="https://blog.thunderbird.net/2022/06/revealed-thunderbird-on-android-plans-k9/">announced our plans</a> to bring Thunderbird to Android by taking K-9 Mail under our wing. The journey took a <a href="https://blog.thunderbird.net/2023/12/when-will-thunderbird-for-android-be-released/">little longer than we had originally anticipated</a> and there was a lot to learn along the way, but the wait is finally over! For all of you who have ever asked ‚Äúwhen is Thunderbird for Android coming out?‚Äù, the answer is ‚Äì today! We are excited to announce that the first stable release of Thunderbird for Android is out now, and we couldn‚Äôt be prouder of the newest, most mobile member of the Thunderbird family.</p>



<h2>Resources</h2>



<ul>
<li><strong>What‚Äôs New</strong>: <a href="https://support.mozilla.org/kb/new-thunderbird-android-version-8">https://support.mozilla.org/kb/new-thunderbird-android-version-8</a></li>



<li><strong>Detailed Release Notes:</strong> <a href="https://github.com/thunderbird/thunderbird-android/releases/tag/THUNDERBIRD_8_0">https://github.com/thunderbird/thunderbird-android/releases/tag/THUNDERBIRD_8_0</a></li>



<li><strong>Community Support Forum</strong>: Thunderbird for Android has its own home on the <a href="https://support.mozilla.org/en-US/products/thunderbird-android">official Mozilla Support (SUMO) forums</a>. Find the help you need to configure and use the newest Thunderbird from our community on a mobile friendly site.</li>



<li><strong>Import Settings:</strong> Whether you‚Äôre importing your information from K-9 Mail or Thunderbird on the desktop, transfer your information <a href="https://support.mozilla.org/en-US/kb/thunderbird-android-import">quickly and easily with our guide</a>.</li>



<li><strong>System Requirements</strong>: Thunderbird for Android runs on mobile devices running Android 5 and above.</li>



<li><strong>Platform Availability</strong>: Download Thunderbird for Android from the following places. Availability on F-Droid will be coming soon.


<ul>
<li><a href="https://play.google.com/store/apps/details?id=net.thunderbird.android&amp;referrer=utm_campaign%3Dandroid_release_appeal_2024%26utm_medium%3Dweb%26utm_source%3Dblog%26utm_content%3Dlink">Google Play Store</a></li>



<li><a href="https://github.com/thunderbird/thunderbird-android/releases/tag/THUNDERBIRD_8_0">GitHub Releases</a> (apk)</li>
</ul>



<ul>
<li>The <a href="https://thunderbird.net/mobile/">Thunderbird website</a> (on an Android device)</li>
</ul>
</li>



<li><strong>Get Involved:</strong> Thunderbird for Android thrives thanks to community support, and you can be part of the community! We are grateful to everyone who donates their skill and time to answer support questions, test releases, translate and more. <a href="https://blog.thunderbird.net/2024/09/contribute-to-thunderbird-for-android/">Find out all the ways to get in where you fit in.</a></li>



<li><strong>Support Us:</strong> We are 100% donor-supported. Your gift helps us develop new apps (like this one!), improve speed and stability, promote Thunderbird and software freedom, and provide downloads free-of-charge to millions. Donate on <a href="https://www.thunderbird.net/?form=tfa&amp;utm_campaign=android_release_appeal_2024&amp;utm_medium=web&amp;utm_source=blog.thunderbird.net&amp;utm_content=link">our webpage</a> or in the app.</li>



<li><strong>Suggest New Features:</strong> We know you have great ideas for future features. You can share them on Mozilla Connect, where community members can upvote and comment on them. Our team uses the feedback here to help shape our roadmap.</li>
</ul>



<h2>Thanks for Helping Thunderbird for Android Fly</h2>



<p>Thank you for being a part of the community and sharing this adventure on Android with us! We‚Äôre especially grateful to all of you who have helped us test the beta and release candidate images. Your feedback helped us find and fix bugs, test key features, and polish the stable release. We hope you enjoy using the newest Thunderbird, now and for a long time to come!</p>
				

			</section>
			

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dropbox announces 20% global workforce reduction (465 pts)]]></title>
            <link>https://blog.dropbox.com/topics/company/an-update-from-drew</link>
            <guid>41994640</guid>
            <pubDate>Wed, 30 Oct 2024 13:42:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.dropbox.com/topics/company/an-update-from-drew">https://blog.dropbox.com/topics/company/an-update-from-drew</a>, See on <a href="https://news.ycombinator.com/item?id=41994640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>










<header>
    <div>
        <div>
            
            <figure>
                <div>
                    
                    
    

        

        
        
        <!--<sly data-sly-use.assetPath1x="com.dropbox.aem.common.models.utils.RewriterHelperModel"/>-->

        
        
        <!--<sly data-sly-test.scaledImagePath=""/>-->

		 <!--optimized image webp-->
        
        
        

        
        <!--<img data-sly-test.highRes="false"
                srcset=", /cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg 2x"
                src="/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg"
                aria-hidden=""
                alt="1200x628"
                class=""
                data-sly-attribute.width="auto"
                data-sly-attribute.height="auto"
                data-sly-attribute.data-id=""
                data-aem-asset-id="8448f2b6-1123-45bd-9e1f-cb32e1e3daae:Dropbox_Glyph_grey_1200x628.jpg"
                data-trackable="true" />
        <img data-sly-test="true"
                src="/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg"
                aria-hidden="false"
                alt="1200x628"
                class=""
                data-sly-attribute.width="auto"
                data-sly-attribute.height="auto"
                data-sly-attribute.data-id=""
                data-aem-asset-id="8448f2b6-1123-45bd-9e1f-cb32e1e3daae:Dropbox_Glyph_grey_1200x628.jpg"
                data-trackable="true" />-->

	    
      <picture>
        <source media="(min-width: 800px)" srcset="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.webp" fallbackimage="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg">
        <source media="(min-width: 480px)" srcset="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.tablet.webp" fallbackimage="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.tablet.webp">
        <source media="(min-width: 0px)" srcset="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.mobile.webp" fallbackimage="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.mobile.webp">
         <img loading="lazy" src="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg/_jcr_content/renditions/Dropbox_Glyph_grey_1200x628.webp" fallbackimage="https://aem.dropbox.com/cms/content/dam/dropbox/blog/company/2023/glyphs/Dropbox_Glyph_grey_1200x628.jpg" onerror="window.failedAttempts=0;this.setAttribute('src',this.getAttribute('fallbackimage'));window.failedAttempts++;if(window.failedAttempts == 1)this.onerror=null" aria-hidden="false" alt="1200x628" data-aem-asset-id="8448f2b6-1123-45bd-9e1f-cb32e1e3daae:Dropbox_Glyph_grey_1200x628.jpg" data-trackable="true" height="auto" width="auto">
        
      </picture>

    

                    
                </div>
                
            </figure>
            
        </div>
        <div data-color="coconut">
            <p>
                
                
                    <a href="https://blog.dropbox.com/topics/company">Company</a>
                
            </p>
            
            
            <p>Published on
                October 30, 2024
            </p>
            <!-- <p data-sly-test="" class="b01-article-hero-plank__photographer"></p> -->
        </div>
    </div>
</header>
</div><div data-highlight="cloud">

<p><i>Today, our cofounder and CEO Drew Houston shared the difficult news that we‚Äôll be making reductions to our global workforce. He sent the following email to all employees:<br>
&nbsp;</i></p>
<p>Hi everyone,</p>
<p>I‚Äôm writing to let you all know that after careful consideration, we've decided to reduce our global workforce by approximately 20% or 528 Dropboxers.</p>
<p>As CEO, I take full responsibility for this decision and the circumstances that led to it, and I‚Äôm truly sorry to those impacted by this change.</p>
<h3>Why we're making this decision</h3>
<p>As we've shared over the last year, we're in a transitional period as a company. Our FSS business has matured, and we've been working to build our next phase of growth with products like Dash. However, navigating this transition while maintaining our current structure and investment levels is no longer sustainable.</p>
<p>We continue to see softening demand and macro headwinds in our core business. But external factors are only part of the story. We‚Äôve heard from many of you that our organizational structure has become overly complex, with excess layers of management slowing us down.</p>
<p>And while I'm proud of the progress we‚Äôve made in the last couple years, in some parts of the business, we‚Äôre still not delivering at the level our customers deserve or performing in line with industry peers. So we're making more significant cuts in areas where we're over-invested or underperforming while designing a flatter, more efficient team structure overall.</p>
<h3>The opportunity ahead</h3>
<p>The changes we're making today, while difficult, come at a pivotal moment when the market is accelerating precisely where we've placed our biggest bets. It's been tremendously rewarding over the last few weeks to see customers and prospects light up when using Dash for Business for the first time, much like people did when we first launched Dropbox.&nbsp;</p>
<p>And this time we're starting from a position of strength. Millions of customers trust us as the home for their most important files, making the leap to organizing all their cloud content a natural evolution.</p>
<p>But we're not operating on our own schedule. This market is moving fast and investors are pouring hundreds of millions of dollars into this space. This both validates the opportunity we've been pursuing and underscores the need for even more urgency, even more aggressive investment, and decisive action.</p>
<p>The steps we‚Äôre taking today are necessary to both strengthen our core product and accelerate the growth of our new products. We‚Äôll share more about our 2025 strategy in the days ahead.</p>
<h3>Taking care of impacted employees</h3>
<p>To those leaving Dropbox, we're committed to supporting you through this transition. You‚Äôll be eligible to receive the following benefits and support:</p>
<p><b>Severance, equity, and transition payment&nbsp;</b></p>
<ul>
<li>All impacted employees will be eligible for sixteen weeks of pay, starting today, with one additional week of pay for each completed year of tenure at Dropbox. Internationally, severance packages will vary depending on regional practices and statutory requirements.</li>
<li>All impacted employees will receive their Q4 equity vest.</li>
<li>Those on the Corporate Bonus plan will be eligible to receive a pro-rated lump sum transition payment equivalent to their 2024 bonus target based on company performance forecasts and aligned with their level.</li>
<li>We will pay out eligible remaining current and approved upcoming paid leaves, including medical or family leaves.</li>
<li>We will support impacted visa holders by providing additional time to transition and access to 1:1 immigration consultation.</li>
</ul>
<p><b>Healthcare and benefits</b></p>
<ul>
<li>US employees will be eligible for up to six months of COBRA.</li>
<li>Canada-based employees will be eligible for a one-month healthcare extension.</li>
<li>All employees will continue to have access to Modern Health to support their mental well-being.</li>
</ul>
<p><b>Devices</b></p>
<ul>
<li>Impacted employees will be eligible to keep company devices (phones, tablets, laptops, and peripherals) for personal use.</li>
</ul>
<p><b>Job placement</b></p>
<ul>
<li>Job placement services and career coaching will be available at no cost.</li>
</ul>
<h3>Next steps</h3>
<p>We'll be sharing more details on high-level changes later today and will host company-wide Town Halls later this week to answer questions and discuss our plans in more detail.</p>
<p>I know this is incredibly difficult and unwelcome news. To everyone leaving Dropbox, I‚Äôm deeply grateful for everything you've done for our company and our customers.</p>
<p>Drew</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gross Apple Marketing (237 pts)]]></title>
            <link>https://jonathanbuys.com/Gross_Apple_Marketing/</link>
            <guid>41994567</guid>
            <pubDate>Wed, 30 Oct 2024 13:33:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonathanbuys.com/Gross_Apple_Marketing/">https://jonathanbuys.com/Gross_Apple_Marketing/</a>, See on <a href="https://news.ycombinator.com/item?id=41994567">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	    <h3>Gross Apple Marketing</h3>
	    <time datetime="2024-10-29T15:47:31+00:00" pubdate="pubdate">October 29, 2024</time>

		<p>I‚Äôm not sure what‚Äôs going on over in Cupertino for them to think that <em>any</em> of the recent Apple Intelligence ads they‚Äôve been running are a good idea. They‚Äôre cringy at best, and honestly just flat out insulting.</p>

<p>In one a <a href="https://www.youtube.com/watch?v=3m0MoYKwVTM">schlub writes an email</a> to his boss and uses AI to make it sound ‚Äòmore professional‚Äô, in another a young woman uses it to <a href="https://www.youtube.com/watch?v=TPe8revsg3k">lie about remembering an acquaintance‚Äôs name</a>. In another the same young woman again uses it to <a href="https://www.youtube.com/watch?v=_eJy6QyHaFM">lie about reading an email</a> from a college, to her face, while she‚Äôs sitting with her. In yet another, <a href="https://blog.blankbaby.com/2024/10/apple-intelligence-smug-and-gross.html">linked to recently by Scott McNulty</a>, a woman uses AI to lie to her husband about getting him something for his birthday.</p>

<p>If this is what Apple thinks their AI is for, I honestly don‚Äôt know that I want any part of it.</p>

<p>Compare and contrast with the <a href="https://jonathanbuys.com/Scout/">video I posted yesterday</a>, and with this beautiful animation from Canonical.</p>

<p>
<iframe src="https://www.youtube.com/embed/q5yM4ZYwB_s?si=u4GcyOGtdR1QztNe" frameborder="0" allowfullscreen=""></iframe>
</p>

<p>I‚Äôve watched that little animation several times, and they tell a better story in a minute twenty-five than all of Apple‚Äôs AI commercials combined.</p>

	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons learned from a successful Rust rewrite (115 pts)]]></title>
            <link>https://gaultier.github.io/blog/lessons_learned_from_a_successful_rust_rewrite.html</link>
            <guid>41994189</guid>
            <pubDate>Wed, 30 Oct 2024 12:39:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gaultier.github.io/blog/lessons_learned_from_a_successful_rust_rewrite.html">https://gaultier.github.io/blog/lessons_learned_from_a_successful_rust_rewrite.html</a>, See on <a href="https://news.ycombinator.com/item?id=41994189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		<div>
			<p><a href="https://gaultier.github.io/blog"> ‚è¥ Back to all articles</a></p>

			<p>Published on 2024-10-30</p>
		</div>
		
 <p><strong>Table of contents</strong></p><ul>

<li>
	<a href="#what-worked-well">What worked well</a>
		</li>

<li>
	<a href="#what-did-not-work-so-well">What did not work so well</a>
		<ul>

<li>
	<a href="#i-am-still-chasing-undefined-behavior">I am still chasing Undefined Behavior</a>
		</li>

<li>
	<a href="#miri-does-not-always-work-and-i-still-have-to-use-valgrind">Miri does not always work and I still have to use Valgrind</a>
		</li>

<li>
	<a href="#i-am-still-chasing-memory-leaks">I am still chasing memory leaks</a>
		</li>

<li>
	<a href="#cross-compilation-does-not-always-work">Cross-compilation does not always work</a>
		</li>

<li>
	<a href="#cbindgen-does-not-always-work">Cbindgen does not always work</a>
		</li>

<li>
	<a href="#unstable-abi">Unstable ABI</a>
		</li>

<li>
	<a href="#no-support-for-custom-memory-allocators">No support for custom memory allocators</a>
		</li>

<li>
	<a href="#complexity">Complexity</a>
		</li>
</ul>
</li>

<li>
	<a href="#conclusion">Conclusion</a>
		</li>
</ul>

<p><em>Discussions: <a href="https://old.reddit.com/r/rust/comments/1gflxxh/lessons_learned_from_a_successful_rust_rewrite/?">/r/rust</a>, <a href="https://old.reddit.com/r/programming/comments/1gfljj7/lessons_learned_from_a_successful_rust_rewrite/?">/r/programming</a>, <a href="https://news.ycombinator.com/item?id=41994189">HN</a></em></p>
<p>I have written about my on-going rewrite-it-to-Rust effort at work: <a href="https://gaultier.github.io/blog/you_inherited_a_legacy_cpp_codebase_now_what.md">1</a>, <a href="https://gaultier.github.io/blog/how_to_rewrite_a_cpp_codebase_successfully.md">2</a>, <a href="https://gaultier.github.io/blog/rust_c++_interop_trick.html">3</a>. And now it's finished, meaning it's 100% Rust and 0% C++ - the public C API has not changed, just the implementation, one function at time until the end. Let's have a look back at what worked, what didn't, and what can be done about it.</p>
<p>For context, I have written projects in pure Rust before, so I won't mention all of the usual Rust complaints, like "learning it is hard", they did not affect me during this project.</p>
<h2 id="what-worked-well">
	<a href="#what-worked-well">What worked well</a>
	
</h2>
<p>The rewrite was done incrementally, in a stop-and-go fashion. At some point, as I expected, we had to add brand new features while the rewrite was on-going and that was very smooth with this approach. Contrast this with the (wrong) approach of starting a new codebase from scratch in parallel, and then the feature has to be implemented twice.</p>
<p>The new code is much, much simpler and easier to reason about. It is roughly the same number of lines of code as the old C++ codebase, or slightly more. Some people think that equivalent Rust code will be much shorter (I have heard ratios of 1/2 or 2/3), but in my experience, it's not really the case. C++ can be incredibly verbose in some instances, but Rust as well. And the C++ code will often ignore some errors that the Rust compiler forces the developer to handle, which is a good thing, but also makes the codebase slightly bigger.</p>
<p>Undergoing a rewrite, even a bug-for-bug one like ours, opens many new doors in terms of performance. For example, some fields in C++ were assumed to be of a dynamic size, but we realized that they were always 16 bytes according to business rules, so we stored them in an array of a fixed size, thus simplifying lots of code and reducing heap allocations. That's not strictly due to Rust, it's just that having this holistic view of the codebase yields many benefits.</p>
<p>Related to this: we delete lots and lots of dead code. I estimate that we removed perhaps a third or half of the whole C++ codebase because it was simply never used. Some of it were half-assed features some long-gone customer asked for, and some were simply never run or even worse, never even built (they were C++ files not even present in the CMake build system). I feel that modern programming languages such as Rust or Go are much more aggressive at flagging dead code and pestering the developer about it, which again, is a good thing.</p>
<p>We don't have to worry about out-of-bounds accesses and overflow/underflows with arithmetic. These were the main issues in the C++ code. Even if C++ containers have this <code>.at()</code> method to do bounds check, in my experience, most people do not use them. It's nice that this happens by default. And overflows/underflows checks are typically never addressed in C and C++ codebases.</p>
<p>Cross-compilation is pretty smooth, although not always, see next section.</p>
<p>The builtin test framework in Rust is very serviceable. All the ones I used in C++ were terrible and took so much time to even compile.</p>
<p>Rust is much more concerned with correctness than C++, so it sparked a lot of useful discussions. For example: oh, the Rust compiler is forcing me to check if this byte array is valid UTF8 when I try to convert it to a string. The old C++ code did no such check. Let's add this check.</p>
<p>It felt so good to remove all the CMake files. On all the C or C++ projects I worked on, I never felt that CMake was worth it and I always lost a lot of hours to coerce it into doing what I needed.</p>
<h2 id="what-did-not-work-so-well">
	<a href="#what-did-not-work-so-well">What did not work so well</a>
	
</h2>
<p>This section is surprisingly long and is the most interesting in my opinion. Did Rust hold its promises?</p>
<h3 id="i-am-still-chasing-undefined-behavior">
	<a href="#i-am-still-chasing-undefined-behavior">I am still chasing Undefined Behavior</a>
	
</h3>
<p>Doing an incremental rewrite from C/C++ to Rust, we had to use a lot of raw pointers and <code>unsafe{}</code> blocks. And even when segregating these to the entry point of the library, they proved to be a big pain in the neck.</p>
<p>All the stringent rules of Rust still apply inside these blocks but the compiler just stops checking them for you, so you are on your own. As such, it's so easy to introduce Undefined Behavior. I honestly think from this experience that it is easier to inadvertently introduce Undefined Behavior in Rust than in C++, and it turn, it's easier in C++ than in C.</p>
<p>The main rule in Rust is: <s>multiple read-only pointers XOR one mutable pointer</s> <code>multiple read-only reference XOR one mutable reference</code>. That's what the borrow checker is always pestering you about.</p>
<p>But when using raw pointers, it's so easy to silently break, especially when porting C or C++ code as-is, which is mutation and pointer heavy:</p>
<p><em>Note: Astute readers have pointed out that the issue in the snippet below is having multiple mutable references, not pointers, and that using the syntax <code>let a = &amp;raw mut x;</code> in recent Rust versions, or <code>addr_of_mut</code> in older versions, avoids creating multiple mutable references.</em></p>
<pre><code>fn main() {
    let mut x = 1;
    unsafe {
        let a: *mut usize = &amp;mut x;
        let b: *mut usize = &amp;mut x;

        *a = 2;
        *b = 3;
    }
}
</code></pre>
<p>You might think that this code is dumb and obviously wrong, but in a big real codebase, this is not so easy to spot, especially when these operations are hidden inside helper functions or layers and layers of abstraction, as Rust loves to do.</p>
<p><code>cargo run</code> is perfectly content with the code above. The Rust compiler can and will silently assume that there is only one mutable pointer to <code>x</code>, and make optimizations, and generate machine code, based on that assumption, which this code breaks.</p>
<p>The only savior here is <a href="https://github.com/rust-lang/miri">Miri</a>:</p>
<pre><code>$ cargo +nightly-2024-09-01 miri r
error: Undefined Behavior: attempting a write access using &lt;2883&gt; at alloc1335[0x0], but that tag does not exist in the borrow stack for this location
 --&gt; src/main.rs:7:9
  |
7 |         *a = 2;
  |         ^^^^^^
  |         |
  |         attempting a write access using &lt;2883&gt; at alloc1335[0x0], but that tag does not exist in the borrow stack for this location
  |         this error occurs as part of an access at alloc1335[0x0..0x8]
  |
  [...]
 --&gt; src/main.rs:4:29
  |
4 |         let a: *mut usize = &amp;mut x;
  |                             ^^^^^^
help: &lt;2883&gt; was later invalidated at offsets [0x0..0x8] by a Unique retag
 --&gt; src/main.rs:5:29
  |
5 |         let b: *mut usize = &amp;mut x;
  |                             ^^^^^^
  [...]
</code></pre>
<p>So, what could have been a compile time error, is now a runtime error. Great. I hope you have 100% test coverage! Thank god there's Miri.</p>
<p>If you are writing <code>unsafe{}</code> code without Miri checking it, or if you do so without absolutely having to, I think this is foolish. It will blow up in your face.</p>
<p>Miri is awesome. But...</p>
<h3 id="miri-does-not-always-work-and-i-still-have-to-use-valgrind">
	<a href="#miri-does-not-always-work-and-i-still-have-to-use-valgrind">Miri does not always work and I still have to use Valgrind</a>
	
</h3>
<p>I am not talking about some parts of Miri that are experimental. Or the fact that running code under Miri is excruciatingly slow. Or the fact that Miri only works in <code>nightly</code>.</p>
<p>No, I am talking about code that Miri cannot run, period:</p>
<pre><code>    |
471 |     let pkey_ctx = LcPtr::new(unsafe { EVP_PKEY_CTX_new_id(EVP_PKEY_EC, null_mut()) })?;
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ can't call foreign function `‚êÅaws_lc_0_16_0_EVP_PKEY_CTX_new_id` on OS `linux`
    |
    = help: if this is a basic API commonly used on this target, please report an issue with Miri
    = help: however, note that Miri does not aim to support every FFI function out there; for instance, we will not support APIs for things such as GUIs, scripting languages, or databases
</code></pre>
<p>If you are using a library that has parts written in C or assembly, which is usual for cryptography libraries, or video compression, etc, you are out of luck.</p>
<p>So we resorted to add a feature flag to split the codebase between parts that use this problematic library and parts that don't. And Miri only runs tests with the feature disabled.</p>
<p>That means that there is a lot of <code>unsafe</code> code that is simply not being checked right now. Bummer.</p>
<p>Perhaps there could be a fallback implementation for these libraries that's entirely implemented in software (and in pure Rust). But that's not really feasible for most libraries to maintain two implementations just for Rust developers.</p>
<p>I resorted to run the problematic tests in <code>valgrind</code>, like I used to do with pure C/C++ code. It does not detect many things that Miri would, for example having more than one mutable pointer to the same value, which is perfectly fine in C/C++/Assembly, but not in Rust.</p>
<h3 id="i-am-still-chasing-memory-leaks">
	<a href="#i-am-still-chasing-memory-leaks">I am still chasing memory leaks</a>
	
</h3>
<p>Our library offers a C API, something like this:</p>
<pre><code>void* handle = MYLIB_init();

// Do some stuff with the handle...

MYLIB_release(handle);
</code></pre>
<p>Under the hood, <code>MYLIB_init</code> allocates some memory and <code>MYLIB_release()</code> frees it. This is a very usual pattern in C libraries, e.g. <code>curl_easy_init()/curl_easy_cleanup()</code>.</p>
<p>So immediately, you are thinking: well, it's easy to forget to call <code>MYLIB_release</code> in some code paths, and thus leak memory. And you'd be right. So let's implement them to illustrate. We are good principled developers so we write a Rust test:</p>
<pre><code>#[no_mangle]
pub extern "C" fn MYLIB_init() -&gt; *mut std::ffi::c_void {
    let alloc = Box::leak(Box::new(1usize));

    alloc as *mut usize as *mut std::ffi::c_void
}

#[no_mangle]
pub extern "C" fn MYLIB_do_stuff(_handle: *mut std::ffi::c_void) {
    // Do some stuff.
}

#[no_mangle]
pub extern "C" fn MYLIB_release(handle: *mut std::ffi::c_void) {
    let _ = unsafe { Box::from_raw(handle as *mut usize) };
}

fn main() {}

#[cfg(test)]
mod test {
    #[test]
    fn test_init_release() {
        let x = super::MYLIB_init();

        super::MYLIB_do_stuff(x);

        super::MYLIB_release(x);
    }
}
</code></pre>
<p>A Rust developer first instinct would be to use RAII by creating a wrapper object which implements <code>Drop</code> and automatically calls the cleanup function.
However, we wanted to write our tests using the public C API of the library like a normal C application would, and it would not have access to this Rust feature.
Also, it can become unwieldy when there are tens of types that have an allocation/deallocation function. It's a lot of boilerplate!</p>
<p>And often, there is complicated logic with lots of code paths, and we need to ensure that the cleanup is always called. In C, this is typically done with <code>goto</code> to an <code>end:</code> label that always cleans up the resources. But Rust does not support this form of <code>goto</code>.</p>
<p>So we solved it with the <a href="https://docs.rs/scopeguard/latest/scopeguard/">defer</a> crate in Rust and implementing a <a href="https://www.gingerbill.org/article/2015/08/19/defer-in-cpp/">defer</a> statement in C++.</p>
<p>However, the Rust borrow checker really does not like the <code>defer</code> pattern. Typically, a cleanup function will take as its argument as <code>&amp;mut</code> reference and that precludes the rest of the code to also store and use a second <code>&amp;mut</code> reference to the same value. So we could not always use <code>defer</code> on the Rust side.</p>
<h3 id="cross-compilation-does-not-always-work">
	<a href="#cross-compilation-does-not-always-work">Cross-compilation does not always work</a>
	
</h3>
<p>Same issue as with Miri, using libraries with a Rust API but with parts implemented in C or Assembly will make <code>cargo build --target=...</code> not work out of the box. It won't affect everyone out there, and perhaps it can be worked around by providing a sysroot like in C or C++. But that's a bummer still. For example, I think Zig manages this situation smoothly for most targets, since it ships with a C compiler and standard library, whereas <code>cargo</code> does not.</p>
<h3 id="cbindgen-does-not-always-work">
	<a href="#cbindgen-does-not-always-work">Cbindgen does not always work</a>
	
</h3>
<p><a href="https://github.com/mozilla/cbindgen">cbindgen</a> is a conventionally used tool to generate a C header from a Rust codebase. It mostly works, until it does not. I hit quite a number of limitations or bugs. I thought of contributing PRs, but I found for most of these issues, a stale open PR, so I didn't. Every time, I thought of dumping <code>cbindgen</code> and writing all of the C prototypes by hand. I think it would have been simpler in the end.</p>
<p>Again, as a comparison, I believe Zig has a builtin C header generation tool.</p>
<h3 id="unstable-abi">
	<a href="#unstable-abi">Unstable ABI</a>
	
</h3>
<p>I talked about this point in my previous articles so I won't be too long. Basically, all the useful standard library types such as <code>Option</code> have no stable ABI, so they have to be replicated manually with the <code>repr(C)</code> annotation, so that they can be used from C or C++. This again is a bummer and creates friction. Note that I am equally annoyed at C++ ABI issues for the same reason.</p>
<p>Many, many hours of hair pulling would be avoided if Rust and C++ adopted, like C, a <a href="https://daniel.haxx.se/blog/2024/10/30/eighteen-years-of-abi-stability/">stable ABI</a>.</p>
<h3 id="no-support-for-custom-memory-allocators">
	<a href="#no-support-for-custom-memory-allocators">No support for custom memory allocators</a>
	
</h3>
<p>With lots of C libraries, the user can provide its own allocator at runtime, which is often very useful. In Rust, the developer can only pick the global allocator at compile time. So we did not attempt to offer this feature in the library API.</p>
<p>Additionally, all of the aforementioned issues about cleaning up resources would have been instantly fixed by using an <a href="https://gaultier.github.io/blog/tip_of_the_day_2.html">arena allocator</a>, which is not at all idiomatic in Rust and does not integrate with the standard library (even though there are crates for it). Again, Zig and Odin all support arenas natively, and it's trivial to implement and use them in C. I really longed for an arena while chasing subtle memory leaks.</p>
<h3 id="complexity">
	<a href="#complexity">Complexity</a>
	
</h3>
<p>From the start, I decided I would not touch async Rust with a ten-foot pole, and I did not miss it at all, for this project.</p>
<p>Whilst reading the docs for <code>UnsafeCell</code> for the fourth time, and pondering whether I should use that or <code>RefCell</code>, while just having been burnt by the pitfalls of <code>MaybeUninit</code>, and asking myself if I need <code>Pin</code>, I really asked myself what life choices had led me to this.</p>
<p>Pure Rust is already very complex, but add to it the whole layer that is mainly there to deal with FFI, and it really becomes a beast. Especially for new Rust learners.</p>
<p>Some developers in our team straight declined to work on this codebase, mentioning the real or perceived Rust complexity.
Now, I think that Rust is still mostly easier to learn than C++, but admittedly not by much, especially in this FFI heavy context.</p>
<h2 id="conclusion">
	<a href="#conclusion">Conclusion</a>
	
</h2>
<p>I am mostly satisfied with this Rust rewrite, but I was disappointed in some areas, and it overall took much more effort than I anticipated. Using Rust with a lot of C interop feels like using a completely different language than using pure Rust. There is much friction, many pitfalls, and many issues in C++, that Rust claims to have solved, that are in fact not really solved at all.</p>
<p>I am deeply grateful to the developers of Rust, Miri, cbindgen, etc. They have done tremendous work. Still, the language and tooling, when doing lots of C FFI, feel immature, almost pre v1.0. If the ergonomics of <code>unsafe</code> (which are being worked and slightly improved in the recent versions), the standard library, the docs, the tooling, and the unstable ABI, all improve in the future, it could become a more pleasant experience.</p>
<p>I think that all of these points have been felt by Microsoft and Google, and that's why they are investing real money in this area to improve things.</p>
<p>If you do not yet know Rust, I recommend for your first project to use pure Rust, and stay far away from the whole FFI topic.</p>
<p>I initially considered using Zig or Odin for this rewrite, but I really did not want to use a pre v1.0 language for an enterprise production codebase (and I anticipated that it would be hard to convince other engineers and managers). Now, I am wondering if the experience would have really been worse than with Rust. Perhaps the Rust model is really at odds with the C model (or with the C++ model for that matter) and there is simply too much friction when using both together.</p>
<p>If I have to undertake a similar effort in the future, I think I would strongly consider going with Zig instead. We'll see. In any case, the next time someone say 'just rewrite it in Rust', point them to this article, and ask them if that changed their mind ;)</p>
<p><a href="https://gaultier.github.io/blog"> ‚è¥ Back to all articles</a></p>

<blockquote id="donate">
  <p>If you enjoy what you're reading, you want to support me, and can afford it: <a href="https://paypal.me/philigaultier?country.x=DE&amp;locale.x=en_US">Donate</a>. That allows me to write more cool articles!</p>
</blockquote>

<blockquote>
  <p>
    This blog is <a href="https://github.com/gaultier/blog">open-source</a>!
    If you find a problem, please open a Github issue.
    The content of this blog as well as the code snippets are under the <a href="https://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_(%22BSD_License_2.0%22,_%22Revised_BSD_License%22,_%22New_BSD_License%22,_or_%22Modified_BSD_License%22)">BSD-3 License</a> which I also usually use for all my personal projects. It's basically free for every use but you have to mention me as the original author.
  </p>
</blockquote>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EPA cancels pesticide shown to be harmful to unborn babies (158 pts)]]></title>
            <link>https://www.thenewlede.org/2024/10/epa-cancels-pesticide-shown-to-be-harmful-to-unborn-babies/</link>
            <guid>41993832</guid>
            <pubDate>Wed, 30 Oct 2024 11:41:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thenewlede.org/2024/10/epa-cancels-pesticide-shown-to-be-harmful-to-unborn-babies/">https://www.thenewlede.org/2024/10/epa-cancels-pesticide-shown-to-be-harmful-to-unborn-babies/</a>, See on <a href="https://news.ycombinator.com/item?id=41993832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                                        
<p>Citing a need to protect the unborn babies of pregnant women, the US Environmental Protection Agency (EPA) on Tuesday banned a pesticide used to kill weeds on farms, golf courses and athletic fields.</p>



<p>The action comes after years of mounting scientific evidence of the dangers posed by exposure to the chemical dimethyl tetrachloroterephthalate, also known as DCPA or Dacthal. &nbsp;</p>



<p>‚ÄúWith the final cancellation of DCPA, we‚Äôre taking a definitive step to protect pregnant women and their unborn babies,‚Äù Michal Freedhoff, assistant administrator for the EPA Office of Chemical Safety and Pollution Prevention, said in a press release. ‚ÄúThe science showing the potential for irreversible harm to unborn babies‚Äô developing brains, in addition to other lifelong consequences from exposure, demands decisive action to remove this dangerous chemical from the marketplace.‚Äù</p>
<p>The agency said ‚Äúrobust studies‚Äù demonstrated ‚Äúthyroid toxicity,‚Äù and said that unborn babies whose pregnant mothers are exposed to DCPA could experience changes to fetal thyroid hormone levels. Such changes are ‚Äúgenerally linked to low birth weight, impaired brain development, decreased IQ, and impaired motor skills later in life, some of which may be irreversible,‚Äù the EPA said.</p>
<p>DCPA was registered to control weeds in both agricultural and non-agricultural settings, but has largely been used to control weeds in fields growing crops such as broccoli, brussels sprouts, cabbage and onions.</p>



<p>The EPA action comes after&nbsp;<a href="https://www.epa.gov/pesticides/dcpa-dacthal-technical-herbicide-product-suspended-epa" target="_blank" rel="noreferrer noopener">years of research and smaller moves</a>&nbsp;by the EPA to limit the impact of DCPA on public health.&nbsp;In April, the <a href="https://www.thenewlede.org/2024/04/concerned-about-developing-babies-epa-warns-about-danger-of-weed-killer-used-on-farms-golf-courses/" target="_blank" rel="noreferrer noopener">agency issued a rare warning</a>&nbsp;that the pesticide posed ‚Äúserious, permanent and irreversible health risks,‚Äù especially to farmworkers involved in tasks such as transplanting, weeding and harvesting after the pesticide has been applied.</p>



<p>In August, the EPA issued an&nbsp;‚Äú<a href="https://www.epa.gov/newsreleases/epa-issues-emergency-order-stop-use-pesticide-dacthal-address-serious-health-risk-4" target="_blank" rel="noreferrer noopener">emergency suspension</a>‚Äù of the chemical, marking the first time in almost 40 years the agency took such an emergency action. The agency said that, following the suspension, it received a letter from AMVAC Chemical Corporation, the sole manufacturer of DCPA, stating its intent to voluntarily cancel pesticide products containing DCPA sold in the US. AMVAC later said it would also cancel all international registrations.&nbsp;&nbsp;</p>
<p>The EPA cancellation prohibits anyone from distributing or selling DCPA pesticide products and bars anyone from using existing supplies.&nbsp;</p>
<p>(Featured photo by <a href="https://unsplash.com/@jorbrain">Jordan Gonz√°lez</a> for&nbsp;<a href="https://unsplash.com/plus?referrer=%2Fphotos%2Fa-couple-of-people-that-are-sitting-in-the-grass-jVq0I80khBs" rel="nofollow">Unsplash+</a>)</p>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Classic 3D videogame shadow techniques (309 pts)]]></title>
            <link>https://30fps.net/pages/videogame-shadows/</link>
            <guid>41993012</guid>
            <pubDate>Wed, 30 Oct 2024 08:49:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://30fps.net/pages/videogame-shadows/">https://30fps.net/pages/videogame-shadows/</a>, See on <a href="https://news.ycombinator.com/item?id=41993012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text">

<p>Towards the end of Wim Wenders‚Äôs excellent <em>Perfect Days</em>, the protagonist Hirayama is drinking beer under a bridge after he has seen a Businessman courting his crush. Suddenly the Businessman joins him under the bridge. As it turns out, things aren‚Äôt actually that simple but the point is their conversation takes them to some fundamental questions:</p>
<blockquote>
<p><strong>Businessman:</strong> Shadows. Do they get darker when they overlap?<br> <strong>Hirayama:</strong> Not sure.<br> <strong>Businessman:</strong> So many things I still don‚Äôt know‚Ä¶ That‚Äôs how life ends‚Ä¶ I guess.<br> <strong>Hirayama:</strong> Let‚Äôs find out now.<br> <strong>Businessman:</strong> What?<br></p>
</blockquote>
<p>Then they step into to the light of a street lamp and investigate their shadows (<a href="https://www.youtube.com/watch?v=C6cdPxQjHb0">the full scene</a>):</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/Perfect_Days_shadows.jpg" alt=""><figcaption>An iconic scene in <em>Perfect Days</em> (2023). Still via <a href="https://film-grab.com/2024/04/12/perfect-days/">film-grabs.com</a>.</figcaption>
</figure>
<p>Even though the Businessman sees no difference, Hirayama is convinced the overlapping shadows <em>do</em> become darker. ‚ÄúIt has to get darker to make sense.‚Äù What a moving scene.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/metalgear-crop.jpg">
<figcaption>
Shadows do become darker when<br>they overlap in Metal Gear Solid.
</figcaption>
</figure>
<p>Unfortunately Hirayama is mistaken. Shadows don‚Äôt get any darker there. There‚Äôs just one light source, and relatively far away, so the shadow is simply an absence of light. It doesn‚Äôt matter how many times the light is blocked.</p>
<p>When it comes to 3D videogames, shadows are something else. It‚Äôs easy to paint dark blob under some character‚Äôs feet and assume everything else is lit. Perhaps Hirayama was recalling the blob shadow in <em>Metal Gear Solid</em> that <em>does</em> become darker when it overlaps with others?</p>
<p>In the real world, shadows simply exist but in games they are both engineered and designed. They must run well but also look good. I find this relationship fascinating and I‚Äôm going to show you why. Let‚Äôs start simple.</p>

<h2 id="on-screen-2d-shadows">On-screen 2D shadows</h2>
<p>You can draw a shadow image to the screen before you draw a character. I‚Äôm not talking about shadow sprites <a href="https://www.mobygames.com/game/365/duke-nukem-3d/screenshots/dos/700154/">like in Duke Nukem 3D</a> but literally a 2D image without any scaling. This works if the character is in front of everything like in <em>Winter Gold</em> or <em>MDK</em>.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/16539773-winter-gold-snes-downhill-crop.png"> <img src="https://30fps.net/pages/videogame-shadows/10559518-mdk-dos-that-spaceship-is-deploying-a-lot-of-troops-crop.jpg">
<figcaption>
Winter Gold (1996, SNES) and MDK (1996, PC) draw animated 2D shadow images. Also check out Winter&nbsp;Gold‚Äôs <a href="https://www.youtube.com/watch?v=-Pr909aVsNo">sick Amiga-style intro video</a> :)
</figcaption>
</figure>
<p>I said it was simple.</p>
<h2 id="blob-shadow">Blob shadow</h2>
<p>OK now in 3D. Draw a dark disc under the character. Done.</p>
<p>Well, you should also align the shadow disc with the ground and also decide how to handle situations where the shadow would reach over a ledge. For example in <em>Super Mario 64</em>, the blobs are drawn using a special hardware feature that effectively clips the shadow to show up only on the ground plane.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/sm64_blob2.jpg"> <img src="https://30fps.net/pages/videogame-shadows/sm64_shadow_decal2.jpg"> <img src="https://30fps.net/pages/videogame-shadows/sm64_blobs.jpg">
<figcaption>
Super Mario 64 (1996, Nintendo 64) uses blob shadows for characters.<br> <strong>Left:</strong> A blob shadow overlapping with tree shadows. <strong>Center:</strong> A blob shadow getting clipped using a hardware decal feature. <strong>Right:</strong> All moving characters and objects have their own shadow. The clipped shadow inside that transparent bubble shows the limitation of the Nintendo 64 decal feature. Screenshots taken in the <a href="https://ares-emu.net/">ares</a> emulator.
</figcaption>
</figure>
<p>The blob shadow can also be animated. In Super Mario 64 it becomes smaller when jumping and <a href="https://youtu.be/F2sEmf_HzGI?t=3793">in <em>Metal Gear Solid</em> it changes shape</a>. If you‚Äôre feeling ambitious, you can also solve the shadow-over-a-ledge issue by <a href="http://blog.wolfire.com/2009/06/how-to-project-decals/">projecting the blob quad like a decal</a>.</p>
<h2 id="planar-shadows-with-a-render-texture">Planar shadows with a render texture</h2>
<p>The blob is just a texture and usually textures can be rendered to at runtime. So render the character from the top and use that instead of a dark circle. This works great in <em>Crash 3</em> (<a href="https://youtu.be/HG-NRnGp3RA?t=267">video</a>) but not so well in <em>Soldier of Fortune</em> because they kept the shadow resolution so low.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/16310901-crash-bandicoot-warped-playstation-c-boxes-allow-you-to-restart-crop2.png"> <img src="https://30fps.net/pages/videogame-shadows/soldieroffortune.jpg">
<figcaption>
<strong>Left:</strong> Crash Bandicoot: Warped (1998, PlayStation) renders shadow textures at runtime. <strong>Right:</strong> Soldier of Fortune (2000, PC) also does but at a lower resolution. A cropped still from <a href="https://www.youtube.com/watch?v=wq82etLV0a8">a video by FirstPlays HD</a>.
</figcaption>
</figure>
<p>Note that this is distinct from <a href="https://learnopengl.com/Advanced-Lighting/Shadows/Shadow-Mapping">shadow mapping</a> where a depth map is rendered from the light‚Äôs point of view. Here we render only a black &amp; white image that is used as a texture. So in a sense we‚Äôre talking about a 1-bit shadow map.</p>
<p>How could we make the shadows sharper?</p>
<h2 id="planar-shadows-with-geometry">Planar shadows with geometry</h2>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/f19-stealth-fighter-back.png">
<figcaption>
The F-117A plane casts a shadow in<br> <em>F-19 Stealth Fighter</em> (1988, DOS).
</figcaption>
</figure>
<p>One intuitive option is to flatten a shadow caster on a plane by projecting it away from the light. Then render it the second time but now in black. They are usually kept opaque to hide how object parts are drawn on top of another. Naturally the shadow will be correct only on a flat floor.</p>
<p>Some early flight simulators draw a top-down flat shadow when on a runway. During my research I expected to see examples where the shadow is also seen when in flight but couldn‚Äôt find any.</p>

<figure>
<img src="https://30fps.net/pages/videogame-shadows/kingpin.jpg"> <img src="https://30fps.net/pages/videogame-shadows/half-life-shadows1.jpg">
<figcaption>
<a href="https://quakewiki.org/wiki/GLQuake">GLQuake‚Äôs</a> planar shadows in two games. <strong>Left:</strong> <em>Kingpin: Life of Crime</em> (1999, PC) gets away with black planar shadows. <strong>Right:</strong> Shadows exhibit transparency issues in <a href="https://www.moddb.com/downloads/half-life-1-alpha-052"><em>Half-Life</em> alpha 0.52</a>. Screenshot taken via Wine on Linux.
</figcaption>
</figure>
<p>Visually these look the same as black stencil shadows cast on a flat plane.</p>
<h3 id="shadows-on-terrain">Shadows on terrain</h3>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/virus.png">
<figcaption>
Virus (1987) Atari ST port. The little ship casts<br> a neat drop shadow.
</figcaption>
</figure>
<p>David Braben‚Äôs 1987 <a href="https://www.youtube.com/watch?v=MNXypBxNGMo"><em>Virus</em></a> on Acorn Archimedes and other home computers draws spaceships that cast top-down shadows on terrain.</p>
<p>A more elaborate example is <em>Interstate ‚Äô76</em>. There they tilt and stretch a planar shadow to match the ground slope. The shadows <a href="https://30fps.net/pages/videogame-shadows/interstate76_shadow_inside_terrain.jpg">occasionally penetrate the ground</a> but are pretty convincing overall. Interestingly, the below software-rendered screenshot has slightly transparent shadows while the hardware accelerated ones are pitch black.</p>
<p>They also had the courage to try to <a href="https://youtu.be/9UyOuqsvs64?t=52">project shadows for large objects like bridges</a> which isn‚Äôt, well, entirely successful.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/interstate-76.png" alt=""><figcaption>Interstate ‚Äô76 (1997, PC) has sun casting tilted planar shadows on terrain.</figcaption>
</figure>
<p>But how do you cast shadows on any kind of scene?</p>
<h2 id="projected-texture-drop-shadow">Projected texture drop shadow</h2>
<figure><a id="projected-texture-drop-shadow">
<img src="https://30fps.net/pages/videogame-shadows/dropshadow_ownby_2010.jpg"> <img src="https://30fps.net/pages/videogame-shadows/buzzjump.jpg">
</a><figcaption><a id="projected-texture-drop-shadow">
<strong>Left:</strong> A slide from the deck </a><a href="https://advances.realtimerendering.com/s2010/Ownby,Hall%20and%20Hall%20-%20Toystory3%20(SIGGRAPH%202010%20Advanced%20RealTime%20Rendering%20Course).pdf"><em>Toy Story 3: The Video Game Rendering Techniques</em></a>. <br><strong>Right:</strong> The drop shadow gets darker when it overlaps with other shadows. A still from <a href="https://www.youtube.com/watch?v=_8fa81Spo3s">an Xbox 360 gameplay video</a> of <em>Toy Story 3: The Video Game</em> (2010).
</figcaption>
</figure>
<p>This approach bears a lot of similarity to <em>Planar shadows with a render texture</em> presented earlier but works on surfaces of any shape. The game renders a shadow texture from the top but instead of showing it on a flat plane, the <a href="https://paroj.github.io/gltut/Texturing/Tut17%20Projective%20Texture.html">texture is projected</a> to other objects. Think of it as the <a href="https://en.wikipedia.org/wiki/Bat-Signal">Bat-Signal</a> but pointed straight down from the sky.</p>
<p>Shadows like this can be made really sharp but they can look strange on vertical surfaces and occassionally even appear on the ceiling. See this <a href="https://youtu.be/EU4CbUoPBi4?t=752">gameplay video of <em>Sonic Adventure 2: Battle</em></a> (2001, GameCube).</p>
<p>This technique also works great for trees:</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/12333235-the-elder-scrolls-iv-oblivion-xbox-360-the-speedtree-engine-at-w.jpg" alt=""><figcaption>The Elder Scrolls IV: Oblivion (2006, Xbox 360) has beautiful projected tree shadows.</figcaption>
</figure>
<p>Projected shadows can show through objects which makes them suitable only for special cases. Shadow maps are something you can use anywhere.</p>
<h2 id="shadow-maps">Shadow maps</h2>
<p>The de facto approach to shadows. The game draws a depth image, the shadow map, from the point of view of the light and reads from that image when rendering the world. This is easy to do since you can reuse the game engine‚Äôs regular rendering code.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/hl2_2004_shadows.jpg" alt=""><figcaption><em>Half-Life 2 (2004, PC)</em> used shadow maps for characters. Dynamic flashlight shadows (not shown) were added in the 2007 <em>Episode Two</em> expansion.</figcaption>
</figure>
<p>The limited resolution of the shadow map gives rise to well-known artifacts with <a href="https://learn.microsoft.com/en-us/windows/win32/dxtecharts/common-techniques-to-improve-shadow-depth-maps#shadow-acne-and-erroneous-self-shadowing">inventive names such as ‚ÄúPeter Panning‚Äù and ‚Äúshadow acne‚Äù</a>. Many tricks have been proposed to allocate more shadow map area to surfaces near the camera where the extra resolution is needed the most. Shadow maps usually need some tweaking to look right.</p>
<p>Before shadow maps became dominant, there was a popular competitor.</p>
<h2 id="stencil-shadows">Stencil shadows</h2>
<p>The has-been approach to shadows. Stencil shadows draw sharp shadows on any kind of surface. They create a unique film-noir look that‚Äôs hard to emulate with shadow maps. Most well-known example is of course <em>Doom 3</em> with its dark rooms:</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/Doom3snap4.jpg" alt=""><figcaption>Doom 3 (2004) had no static level lighting and all shadows were computed at runtime. Screenshot from <a href="http://warp.povusers.org/doom3snapshots/"><em>Doom 3 shadow engine snapshots</em></a>.</figcaption>
</figure>
<p>Stencil shadows are based on the idea of <em>shadow volumes</em>, invisible geometry that cuts the world into lit and shadowed spaces. The game applies lighting only on pixels that don‚Äôt lie inside a shadow volume.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/Shadow_volume_illustration.png" alt=""><figcaption>The game needs to construct ‚Äúshadow volume‚Äù meshes shown in yellow. Surfaces inside the volumes stay unlit. <a href="https://commons.wikimedia.org/wiki/File:Shadow_volume_illustration.png">Shadow volume illustration</a> by Rainwarrior, CC BY-SA 3.0.</figcaption>
</figure>
<p>Stencil shadows need the world to be drawn many times to work. Simplified a bit, the game first draws the whole world with ambient lighting. Then for each light, all the shadow volumes, followed by the world again, affecting only unshadowed pixels. The volumes are drawn with different <a href="https://learnopengl.com/Advanced-OpenGL/Stencil-testing"><em>stencil operations</em></a> set <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/glStencilOpSeparate.xhtml">for front and back faces</a>. It‚Äôs a lot of pixels to draw.</p>
<p>Possibly the earliest shipping game with stencil shadows is <em>Severance: Blade of Darkness</em> from 2001 whose shadows <a href="https://youtu.be/irwzEDLZ2gk?t=417">look great</a>.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/11323681-blade-of-darkness-windows-blade-was-also-well-known-for-its-wond-edit.jpg" alt=""><figcaption>Severance: Blade of Darkness (2001, PC) had stencil shadows.</figcaption>
</figure>
<p>Reading the <a href="https://30fps.net/pages/videogame-shadows/blade_of_darkness_edge_review.jpg">Edge UK edition March 2001 review</a> (<a href="https://retrocdn.net/images/2/2d/Edge_UK_095.pdf">pdf</a>) of the game makes it clear that despite the graphics advancements, the world wasn‚Äôt ready for a soulslike back then.</p>
<p>Stencil shadows are not used much nowadays. One reason is their unpredictable runtime cost. The cost is dependent on how large the volume is on screen and therefore varies a lot. Also an <a href="https://en.wikipedia.org/wiki/Shadow_volume#Depth_fail">optimized algorithm</a> was patented. For Doom 3, <a href="https://web.archive.org/web/20100131044756/http://techreport.com/discussions.x/7113">Id Software apparently reached</a> some sort of <a href="https://web.archive.org/web/20090818013827/http://www.theinquirer.net/inquirer/news/1019517/creative-background-doom-iii-shadow-story">a deal</a>.</p>
<h3 id="soft-stencil-shadows">Soft stencil shadows</h3>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/silent_hill_2_shadows1_crop2.jpg"> <img src="https://30fps.net/pages/videogame-shadows/silenthill2_color_buffer.png"> <img src="https://30fps.net/pages/videogame-shadows/silenthill2_shadow_buffer.png">
<figcaption>
<strong>Left:</strong> Silent Hill 2 (2001, PlayStation 2) has soft stencil shadows. <strong>Center:</strong> 2x zoomed crop. <strong>Right:</strong> A shadow debug view with unlit areas colored black. <a href="https://imgsli.com/MzExMjcy/">Screenshots</a> from the PCSX2 emulator lightened up for visualization.
</figcaption>
</figure>
<p>Stencil shadows don‚Äôt need to be sharp. Another game from 2001, <em>Silent Hill 2</em> on the PlayStation 2, blurred the stencil shadows afterwards as seen above. <a href="https://youtu.be/nna2yt1c9gI?t=354">It looks pretty much perfect</a> on the console.</p>
<h2 id="simplified-character-shadows">Simplified character shadows</h2>
<p>What if the shadows are cast by a simpler model than what‚Äôs shown on screen? For example in Zelda on the Nintendo 64, Link‚Äôs feet cast shadows even though nothing else does:</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/15709360-the-legend-of-zelda-ocarina-of-time-nintendo-64-in-zoras-domain.jpg" alt=""><figcaption>The Legend of Zelda: Ocarina of Time (1998, Nintendo 64) has Link‚Äôs feet cast shadows as if they were tall vertical cylinders. I presume the shadows are two stretched decals.</figcaption>
</figure>
<p>One unique approach is seen in <em>Hyperblade</em> where players on a futuristic hockey arena cast planar shadows as simple animated shapes.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/hyperblade.png" alt=""><figcaption>Hyperblade (1996, PC) projects a simplified planar shadow that moves. It‚Äôs not perfect as seen in the rightmost image. Stills from a <a href="https://youtu.be/EpScHKYEEpE?t=43">video by Bit Games Reviews</a>.</figcaption>
</figure>
<h2 id="shadows-in-static-level-lighting">Shadows in static level lighting</h2>
<p>Vertex colors and lightmaps are techniques to capture lighting of a game level. They have been used in many games as the only way to show large scale shadows, which is why I‚Äôve included them here.</p>
<h3 id="vertex-colors">Vertex colors</h3>
<p><em>Ico</em> shows how sophisticated shadows can look with just old school per-vertex lighting.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/ico.jpg" alt=""><figcaption>Ico (2001, PlayStation 2) has level lighting baked to vertex colors. For characters <a href="https://youtu.be/QCOAqyOE_V4?t=438">it uses stencil shadows</a>.</figcaption>
</figure>
<p>For low-poly maps even sharp shadows can be represented with vertex colors. A prime example is <em>Tony Hawk Pro Skater 2</em> (2000, Playstation) which looks amazing considering the simplicity of the technique.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/thps-2-dreamcast-venice-beach-1.jpg" alt=""><figcaption>‚ÄúVenice Beach‚Äù level in Tony Hawk Pro Skater 2 (2000, PlayStation) with its sharp vertex color shadows. This shot is from the Dreamcast port.</figcaption>
</figure>
<h3 id="lightmaps">Lightmaps</h3>
<p>Lightmaps are the classic way to store level lighting and shadows. Instead of storing a color for each vertex, there‚Äôs a second set of textures that represent only lighting. The resolution can vary per area, making the shadows more accurate where needed. On the other hand, lightmaps consume more memory than vertex colors.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/11192353-mirrors-edge-windows-training-grounds-crop.jpg" alt=""><figcaption>Mirror‚Äôs Edge (2008, PC) is basically Lightmaps: The Game.</figcaption>
</figure>
<p>Lightmaps were popularized by <em>Quake</em> (1996, PC) and <a href="https://jbush001.github.io/2015/06/11/quake-lightmaps.html">this is how they look</a>.</p>
<p>That concludes our look into traditional shadow techniques. Let‚Äôs talk a bit about lighting in general next.</p>
<h2 id="shadows-in-modern-games">Shadows in modern games</h2>
<p>Modern games use the traditional techniques when appropriate. Some examples:</p>
<ul>
<li>Variants of <strong>shadow mapping</strong> such as <a href="https://learnopengl.com/Guest-Articles/2021/CSM">Cascaded Shadow Maps</a> to cover large areas while still staying fast.</li>
<li><strong>Lightmaps</strong> in combination with other techniques such as <a href="https://computergraphics.stackexchange.com/a/244">light probes</a>. <em>Call of Duty</em> <a href="https://30fps.net/pages/videogame-shadows/CoD_Hemispheres_Presentation_Notes_p6.jpg">still has lightmaps</a>, see the <a href="https://advances.realtimerendering.com/s2024/content/Roughton/SIGGRAPH%20Advances%202024%20-%20Hemispheres%20Presentation%20Notes.pdf">Hemispherical Lighting Insights</a> slides.</li>
<li>The <strong>simplified character model idea</strong>. <em>The Last of Us</em> (2013, PlayStation 3) casts soft character shadows with stretched spheres. See <a href="https://30fps.net/pages/videogame-shadows/tlou1.jpg">this slide</a> of the deck <a href="http://miciwan.com/SIGGRAPH2013/Lighting%20Technology%20of%20The%20Last%20Of%20Us.pdf">Lighting Technology of The Last Of Us (2013)</a>. Also Unreal Engine supports simplified <a href="https://dev.epicgames.com/documentation/en-us/unreal-engine/capsule-shadows-overview-in-unreal-engine">‚Äúcapsule shadows‚Äù</a> for characters.</li>
<li><strong>Projected shadows</strong>. In <em>Hot Wheels Track Attack</em>&nbsp;(2010, Wii) they render a shadow mesh to a texture and project that on the race track, as described in <a href="https://www.bryanmcphail.com/wp/?p=640">one of the developer‚Äôs blog</a>. The game looks great <a href="https://youtu.be/k85H5C7P0RY?t=349">in motion</a>!</li>
</ul>
<h3 id="ray-traced-shadows">Ray-traced shadows</h3>
<p>In the beginning we established that shadows are formed by a lack of light. If the game really tries to simulate physically correct lighting then shadows will naturally appear. Even small geometric details <a href="https://images.nvidia.com/geforce-com/international/comparisons/control/control-ray-traced-contact-shadows-interactive-comparison-001-on-vs-off.html">will cast accurate shadows</a>, unlike in shadow maps. Big lamps will naturally create soft shadows and indirect light will brighten dark corners. An incredible amount of time and money have been invested in ray tracing algorithms and hardware to make this dream reality.</p>
<p>In practice modern games have such complex scenes the above simulated solution has to be approximated. For example in the ray-traced shadows of <em>Alan Wake 2</em> (2023) each pixel receives lighting <a href="https://30fps.net/pages/videogame-shadows/aw2_restir.jpg">only from a single randomly chosen light</a>. The result is eventually <a href="https://30fps.net/pages/videogame-shadows/aw2_direct_lighting.jpg">fed to a denoiser</a> that intelligently smooths out the noisy picture. See <a href="https://www.nvidia.com/en-us/on-demand/session/gdc24-gdc1003/?playlistId=playList-821861a9-571a-4073-abab-d60ece4d1e49">the whole presentation</a> for details. Therefore even ray-traced shadows won‚Äôt be ‚Äúperfect‚Äù and will have their own look, depending on the tradeoffs made.</p>
<p>Finally, the obvious option.</p>
<h2 id="no-shadows">No shadows</h2>
<p>Sometimes your priorities are elsewhere.</p>
<figure>
<img src="https://30fps.net/pages/videogame-shadows/16483987-alone-in-the-dark-dos-shall-we-dance-scaled.jpg" alt=""><figcaption><em>Alone in the Dark</em> (1992, DOS) had no character shadows.</figcaption>
</figure>

<hr>
<p>In the movie scene, when Hirayama is carefully studying the shadows, his new friend makes an observation:</p>
<blockquote>
<p><strong>Businessman:</strong> You‚Äôre really into this.<br></p>
</blockquote>
<p>As computer graphics enthusiasts, I think we can symphatize.</p>
<p><em>All screenshots provided by <a href="https://www.mobygames.com/">MobyGames</a> unless noted otherwise.</em> <em>Thanks to mankeli for detailed notes on an early draft of this article. Thanks to noby, msqrt, shaiggon and Warma for feedback.</em></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Async Rust is not safe with io_uring (187 pts)]]></title>
            <link>https://tonbo.io/blog/async-rust-is-not-safe-with-io-uring</link>
            <guid>41992975</guid>
            <pubDate>Wed, 30 Oct 2024 08:42:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tonbo.io/blog/async-rust-is-not-safe-with-io-uring">https://tonbo.io/blog/async-rust-is-not-safe-with-io-uring</a>, See on <a href="https://news.ycombinator.com/item?id=41992975">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div data-svelte-h="svelte-184ng9o"> <p>October 30, 2024 by Tzu Gwo</p></div> <h2 data-svelte-h="svelte-s902pt">TL;DR</h2> <pre data-svelte-h="svelte-8brff3">	1. Clone <a href="https://github.com/ethe/io-uring-is-not-cancellation-safe">this repository</a> on a Linux system that supports io_uring.</pre> <pre data-svelte-h="svelte-vfyltr">	2. Try switching <a href="https://github.com/ethe/io-uring-is-not-cancellation-safe/blob/master/src/main.rs#L9-L10">these two lines.</a></pre> <pre data-svelte-h="svelte-1om2w1r">	3. Execute cargo run for a while.</pre> <p data-svelte-h="svelte-a92z3x">The demo shows that even though the behavior appears similar, TCP connections leak when
				using the io_uring driver but not with the epoll driver. I've also <a href="https://github.com/ethe/io-uring-is-not-cancellation-safe/branches/all">tested this across various io_uring runtimes,</a> and it turns out to be a common issue across all of them.</p> <h2 data-svelte-h="svelte-1nsv6xs">Barbara's TCP connection mysteriously leaked</h2> <p data-svelte-h="svelte-10biiqt">Barbara had a lot of experience developing web services with async Rust. One day, she read a
				blog about io_uring, which described it as the next-generation async I/O interface for
				Linux. Interested, Barbara decided to try it out in her sidecar web service.</p> <p data-svelte-h="svelte-njq492">Rust's "async/await" model is separate from the async runtime and I/O interface
				implementations, making it easy to switch between different runtimes. Barbara was very
				familiar with Tokio, the most popular async runtime in Rust, which uses epoll for I/O
				interface. So, she looked for an async runtime that supported io_uring to transform her web
				service into an io_uring-based version.</p> <p data-svelte-h="svelte-1pil8jj">After some research, Barbara discovered several async runtimes like <a href="https://github.com/DataDog/glommio">glommio,</a> <a href="https://github.com/bytedance/monoio">monoio,</a>
				and
				<a href="https://github.com/compio-rs/compio">compio</a> that supported io_uring.
				She decided to give one of them a try‚Äîmonoio, in particular, which provided both epoll and io_uring
				interfaces and allowed for easy switching. It seemed like the perfect fit for Barbara's io_uring
				exploration.</p> <p data-svelte-h="svelte-6gwc0">With her familiarity with Tokio, Barbara quickly wrote her first HTTP server demo:</p>    <p data-svelte-h="svelte-1lcrgpz">Barbara thought, "Great, this looks no different from a typical Tokio program‚Äîfirst bind to
				an address, then continuously accept new TCP connections in a loop and process them."</p> <p data-svelte-h="svelte-133qamx">Barbara then considered her next steps. She decided to learn how to implement asynchronous
				control, such as timeouts, so that if the TCP listener did not accept a connection for a
				while, it could switch to handling some sidecar tasks (like logging) before resuming
				acceptance:</p>    <p data-svelte-h="svelte-1ocoebl">Using the concurrency primitive "select" to add timeouts to futures worked well with
				io_uring. Barbara was pleased and quickly updated her web service to use io_uring,
				eventually deploying it. Everything ran smoothly until one day she noticed something odd in
				the client logs: some requests were never processed. To investigate, Barbara wrote a minimal
				example, only to find the issue was far more complex than expected.</p> <p data-svelte-h="svelte-1q7x5qs">Barbara found that while the client running in a child thread was connecting correctly, the
				server in the main thread wasn‚Äôt proceeding as it should. Instead, the timeout kept getting
				triggered, as if the client's connection had vanished. <b>A TCP connection leak had occurred.</b>
				And it wasn't just monoio‚Äîthis issue affected all async runtimes that used io_uring.</p> <h2 data-svelte-h="svelte-1ujqvyi">What‚Äôs going on?</h2> <p data-svelte-h="svelte-1q0g62a">Before understanding why using "select" for timeout control in an io_uring-based async
				runtime leads to TCP connection leaks, we need to first understand why this issue doesn‚Äôt
				occur with epoll.</p> <p data-svelte-h="svelte-1d2d4e6">The entire async Rust ecosystem is built around a core asynchronous primitive from the
				standard library: Future. Its definition is as follows:</p>    <p data-svelte-h="svelte-1efgqfq">In Rust, all asynchronous operations‚Äînot just those manually written by async library
				developers but also those written by users using "async" blocks‚Äîare defined as recursive
				future structures, which get instantiated when ".await" is called. The entire structure
				contains all the state that must be saved across suspended futures during pending
				operations. The async executor is then responsible for repeatedly calling the "poll" method
				to advance this state until completion. Consider this example async block:</p>    <p data-svelte-h="svelte-1ntevmc">will transform to below by compiler:</p>    <p data-svelte-h="svelte-d9uza6">For a more detailed explanation of futures and how they are executed, I recommend reading
				<a href="https://en.ihcblog.com/rust-runtime-design-1/">ihciah's blog.</a>
				He is one of the core authors of monoio.</p> <p data-svelte-h="svelte-w78mu4">Async Rust makes a few core assumptions about futures:</p> <pre data-svelte-h="svelte-sjik6d">	1. The state of futures only change when they are polled.</pre> <pre data-svelte-h="svelte-thrp6b">	2. Futures are implicitly cancellable by simply never polling them again.
				</pre> <p data-svelte-h="svelte-1sa0hh5">Futures bound to epoll adhere to these assumptions, which relates to the mechanism of epoll:
				epoll is not an asynchronous syscall mechanism; it‚Äôs an event notification mechanism. In the
				above example, the actual behavior of the "listener.accept()" future, simplified, is as
				follows:</p>    <p data-svelte-h="svelte-6wikbk">"self.accept()" runs synchronously, either succeeding by obtaining a TCP stream or
				encountering a "would block" exception, leaving it in a pending state until the kernel is
				ready. To cancel this operation, you simply stop polling, as the syscall only happens during
				polling.</p> <p data-svelte-h="svelte-1jfsmfl">However, io_uring-bound futures break these two assumptions:</p> <pre data-svelte-h="svelte-1l5soen">	1. The syscall is executed asynchronously by the kernel, not during polling. The kernel commit the TCP stream into a kernel / user shared ring buffer, meaning the accept event is completed implicitly.</pre> <pre data-svelte-h="svelte-17rm9ec">	2. You cannot simply cancel an io_uring-bound future by stopping polling, as the kernel might complete the syscall at any time, <b>even during the cancellation progress</b>.
				</pre> <p data-svelte-h="svelte-11qp05s">A step-by-step explanation of the earlier example will make this process clearer:</p>    <h2 data-svelte-h="svelte-ipliht">How to solve this?</h2> <p data-svelte-h="svelte-1qr0z9y">Before discussing the solution, we need to break the problem down into two parts:</p> <pre data-svelte-h="svelte-19la56n">	1. <b>I/O Safety</b>: Ensuring that accepted TCP streams are properly closed without leaking connections.</pre> <pre data-svelte-h="svelte-17qcix0">	2. <b>Halt Safety</b> (proposed by Yoshua Wuyts): Handling connections that have already been opened when they are cancelled, allowing them to continue being processed.
				</pre> <h3 data-svelte-h="svelte-6xjdyo">I/O Safety</h3> <p data-svelte-h="svelte-1a2p9rh">First of all, we are fortunate that the I/O safety problem can be addressed now, which safe
				Rust aims to ensure this in the future. Rust provides the Drop trait to define custom
				behavior when a value is cleaned up. Thus, we can do something like this:</p>    <p data-svelte-h="svelte-1jocbtu">We just need to encourage async runtimes to implement this fix.</p> <h3 data-svelte-h="svelte-6hh2fm">Halt Safety</h3> <p data-svelte-h="svelte-7uppsm">Halt safety is more complicated. Monoio provides a component called "cancellable I/O" to
				properly handle the cancellation of io_uring-bound futures. A complete example can be found
				here: <a href="https://github.com/ethe/io-uring-is-not-cancellation-safe/blob/cancelable-io/src/main.rs">cancellable I/O example.</a> You can run this branch to see that the connection handling behavior now matches that of epoll.
				Here, I‚Äôll show a simplified usage:</p>    <p data-svelte-h="svelte-1fi05wx">As you can see, besides performing the accept operation in the regular select branch, the
				timeout branch explicitly cancels the accept future. Afterwards, it proceeds to .await the
				accept future again to confirm if a TCP stream was ready during the timeout period.</p> <p data-svelte-h="svelte-usjqk4">Monoio's component partially solves the problem, but there's still an issue: since a future
				is a recursive structure, an io_uring-bound future may not be directly at the place where
				cancellation occurs:</p>    <p data-svelte-h="svelte-qxefi9">Canceling a future that contains an io_uring-bound future will also affect its inner
				io_uring-bound futures. This means that the cancellation safety of io_uring-bound futures is
				"contagious." Simply converting an io_uring-bound future to cancellable I/O does not solve
				all the issues.</p> <p data-svelte-h="svelte-1e286rt">Another key issue is that if you forget to handle the cancellation of an io_uring-bound
				future, there are no compile-time checks to catch it. For io_uring-bound futures, you need
				to ".await" them after cancellation to see if they have completed. This means they must be
				<b>used exactly once,</b>
				a concept called
				<a href="https://en.wikipedia.org/wiki/Substructural_type_system">linear types,</a> which ensures correct usage of resources at compile time.</p> <p data-svelte-h="svelte-1t3pja8">Unfortunately, Rust lacks the support for this kind of type system. For more details on why
				adding linear logic to Rust is challenging, you can refer to Without Boats' blog:
				<a href="https://without.boats/blog/changing-the-rules-of-rust/#:~:text=Let%E2%80%99s%20say%20you%20want%20Rust%20to%20support%20types%20which%20can%E2%80%99t%20go%20out%20of%20scope%20without%20running%20their%20destructor.%20This%20is%20one%20of%20the%20two%20different%20definitions%20of%20%E2%80%9Clinear%20types%2C%E2%80%9D">Changing the rules of Rust.</a></p> <h2 data-svelte-h="svelte-1tliofq">Why wrote this?</h2> <p data-svelte-h="svelte-1i0gxro">There has been a lot of discussion about memory safety in the context of io_uring. For more
				details, you can refer to these resources:</p> <pre data-svelte-h="svelte-1yhsrhe"> ‚Ä¢ <a href="https://blog.yoshuawuyts.com/async-cancellation-1/">Async Cancellation by yoshuawuyts</a></pre> <pre data-svelte-h="svelte-13a8yeb"> ‚Ä¢ <a href="https://without.boats/blog/io-uring/">Notes on io-uring by withoutboats</a></pre> <pre data-svelte-h="svelte-vye3w7"> ‚Ä¢ <a href="https://github.com/bytedance/monoio/blob/master/docs/en/why-async-rent.md">Async Rent by ihciah</a></pre> <p data-svelte-h="svelte-1wcx2zr">However, the community rarely addresses I/O safety and halt safety with io_uring in async
				Rust. I'm presenting a specific case to draw attention to this topic. The title of this blog
				might sound a bit dramatic, but everyone has different definitions and understandings of
				"safety." What do you think about this issue:</p> <pre data-svelte-h="svelte-15q3iv8"> ‚Ä¢ Keep things as they are; I/O safety and halt safety do not need guarantees from the language.</pre> <pre data-svelte-h="svelte-eoedff"> ‚Ä¢ Rust should ensure I/O safety (this is already a goal outlined in the RFC, but not yet implemented in Rust.)</pre> <pre data-svelte-h="svelte-ts4uky"> ‚Ä¢ Rust should ensure halt safety (rarely discussed!)</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eighteen Years of ABI Stability (154 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2024/10/30/eighteen-years-of-abi-stability/</link>
            <guid>41992899</guid>
            <pubDate>Wed, 30 Oct 2024 08:25:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2024/10/30/eighteen-years-of-abi-stability/">https://daniel.haxx.se/blog/2024/10/30/eighteen-years-of-abi-stability/</a>, See on <a href="https://news.ycombinator.com/item?id=41992899">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Exactly eighteen years ago today, on October 30 2006, we shipped <a href="https://curl.se/ch/7.16.0.html">curl 7.16.0</a> that among a whole slew of new features and set of bugfixes bumped the libcurl SONAME number from 3 to 4.</p>



<h2>ABI breakage</h2>



<p>This bump meant that libcurl 7.16.0 was not binary compatible with the previous releases. Users could not just easily and transparently bump up to this version from the previous, but they had to check their use of libcurl and in some cases adjust source code.</p>



<p>This was not the first ABI breakage in the curl project, but at this time our use base was larger than at any of the previous bumps and this time people complained about the pains and agonies such a break brought them.</p>



<h2>We took away FTP features</h2>



<p>In the 7.16.0 release we removed a few FTP related features and their associated options. Before this release, you could use curl to do ‚Äúthird party‚Äù transfers over FTP, and in this release you could no longer do that. That is a feature when the client (curl) connects to server A and instructs that server to communicate with server B and do file transfers among themselves, without sending data to and from the client.</p>



<p>This is an FTP feature that was not implemented well in curl and it was poorly tested. It was also a feature that barely no FTP server allowed and subsequently this was not used by many users. We ripped it out.</p>



<h2>A near pitchfork situation</h2>



<p>Because so few people used the removed features, barely anyone actually noticed the ABI breakage. It remained theoretical to most users and I believe that detail only made people more upset over the SONAME bump because they did not even see the necessity: we just made their lives more complicated for no benefit (to them).</p>



<p>The Debian project even decided to override our decision <em>‚Äúno, that is not an ABI breakage‚Äù</em> and added a local patch in their build that lowered the SONAME number back to 3 again in their builds. A patch they would stick to for many years to come.</p>



<p>The obvious friction this bump caused, even when in reality it actually did not affect many users and the loud feedback we received, made a huge impact on me. It had not previously dawned on me exactly how important this was.</p>



<p>I decided there and then to do the utmost to never go through this again. To put ABI compatibility at the top of the priority list. Make it one of the most fundamental key properties of libcurl.</p>



<p><strong>Do. Not. Break. The. ABI</strong></p>



<p>(we don‚Äôt break the API either)</p>



<h2>A never-breaking ABI</h2>



<p>The decision was initially made to avoid the negativity the bump brought, but I have since over time much more come to appreciate the upsides.</p>



<p><em>Application authors everywhere can always and without risk keep upgrading to the latest libcurl.</em></p>



<p>It sounds easy and simple, but the impact is huge. The examples, the documentation, the applications, everything can just always upgrade and continue. As libcurl over time has become even more popular and compared to 2006, used in many magnitudes more installations, it has grown into an even more important aspect of the curl life. Possibly <em>the</em> single most important properly of curl.</p>



<p>There is a small caveat here and that is that we occasionally of course have bugs and regressions, so when I say that users can always upgrade, that is true in the sense that we have not broken the ABI since. We have however had a few regressions that sometimes have triggered some users to downgrade again or wait a little longer for the next release that has the bug fixed.</p>



<p>When we took that decision in 2006 we had less than 50,000 lines of product code. Today we are approaching 180,000 lines.</p>



<h2>Effects of never breaking ABI</h2>



<p>We know that once we adopt a change, we are stuck with it for decades to come. It makes us double-check every knot before we accept new changes.</p>



<p>Once accepted and shipped, we keep supporting code and features that we otherwise could have reconsidered and perhaps removed. Sometimes we think of a better way to do something <em>after</em> the initial merge, but by then it is too late to change. We can then always introduce new and better ways to do things, but we have to keep supporting the old way as well.</p>



<p>A most fundamental effect is that we can never shrink the list of options we support. We can never actually rename something. Doing new things and features consistently over this long time is hard if not impossible, as we learn new things and paradigms vary through the decades.</p>



<h2>How</h2>



<p>The primary way we maintain this is by manual code view and code inspection of every change. Followed of course by a large range of tests that make sure that assumptions remain.</p>



<p>Occasionally we have (long) discussions around subtle details when someone proposes a change that potentially might be considered an ABI break. Or not.</p>



<p>What exactly is covered by <em>ABI compatibility</em> is not always straight forward or easy to have carved in stone. In particular since the project can be built and run on such a wide range of systems and architectures.</p>



<h2>Deprecating</h2>



<p>We <em>can</em> still remove functionality if the conditions are right.</p>



<p>Some features and options are documented and work in a way so that something is <em>requested</em> or <em>asked for</em> and libcurl then tries to satisfy that ask. Like for example libcurl once supported HTTP/1 pipelining like that.</p>



<p>libcurl still provides the option to enable pipelining and applications can still ask for it so it is still ABI and API compatible, but a modern libcurl simply will never do it because that functionality has been removed.</p>



<p>Example two: we dropped support for NPN a few years back. NPN being a TLS extension called Next Protocol Negotiation that was used briefly in the early days of HTTP/2 development before ALPN was introduced and replaced NPN.  Virtually nothing requires NPN anymore, and users can still set the option asking for it, but it will never actually happen over the wire.</p>



<p>Furthermore, a typical libcurl build involves multiple third party libraries that provide features it needs. For things like TLS, SSH, compression and binary HTTP protocol management. Over the years, we have removed support for several such libraries and introduced support for new, in ways that was never visible in the API or ABI. Some users just had to switch to building curl with different helper libraries.</p>



<p>In reality, libcurl is typically more stable than most existing servers and URLs. The libcurl examples you wrote in 2006 can still be built with the modern libcurl, but the servers and URLs you used back then most probably cannot be used anymore.</p>



<h2>If no one can spot it, it did not happen</h2>



<p>As blunt as it may sound, it has came down to this fundamental statement several times to judge if a change is an ABI breakage or not:</p>



<p><em>If no one can spot an ABI change, it is not an ABI change</em></p>



<p>Of course what makes it harder than it sounds is that it is extremely difficult to actually know if someone will notice something ahead of time. libcurl is used in so ridiculously many installations and different setups, second-guessing whatever everyone does and wants is darned close to impossible.</p>



<p>Adding to the challenge is the crazy long upgrade cycles some of our users seem to sport. It is not unusual to see questions appear on the mailing lists from users bumping from curl versions from eight or ten years ago. The fact that we have not  heard users comment on a particular change might just mean that they are still stuck on ancient versions.</p>



<p>Getting frustrated comments from users today about a change we landed five years ago is hard to handle.</p>



<h2>Forwards compatible</h2>



<p>I should emphasize that all this means that users can always upgrade to a <em>later</em> release. It does not necessarily mean that they can switch back to an older version without problems. We do add new features over time and if you start using a new feature, the application of course will not work, or even still compile, if you would switch to a libcurl version from before that feature was added.</p>



<h2>How long is never</h2>



<p>What I have laid out here is our plan and ambition. We have managed to stick to this for eighteen years now and there is no particular known blockers in the known future either.</p>



<p>I cannot rule out that we might at some point in the future run into an obstacle so huge or complicated that we will be forced to do the unthinkable. To break the ABI. But until we see absolutely no other way forward, it is not going to happen.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Flame Graphs (173 pts)]]></title>
            <link>https://www.brendangregg.com/blog//2024-10-29/ai-flame-graphs.html</link>
            <guid>41992419</guid>
            <pubDate>Wed, 30 Oct 2024 06:54:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brendangregg.com/blog//2024-10-29/ai-flame-graphs.html">https://www.brendangregg.com/blog//2024-10-29/ai-flame-graphs.html</a>, See on <a href="https://news.ycombinator.com/item?id=41992419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Imagine halving the resource costs of AI and what that could mean for the planet and the industry -- based on extreme estimates such savings could reduce the total US power usage by over 10% by 2030<span size="-2"><sup>1</sup></span>. At Intel we've been creating a new analyzer tool to help reduce AI costs called <em>AI Flame Graphs</em>: a visualization that shows an AI accelerator or GPU hardware profile along with the full software stack, based on my <strong><a href="https://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">CPU flame graphs</a></strong>. Our first version is available to customers in the <strong><a href="https://www.intel.com/content/www/us/en/developer/tools/devcloud/services.html">Intel Tiber AI Cloud</a></strong> as a preview for the Intel Data Center GPU Max Series (previously called Ponte Vecchio). Here is an example:</p>

<center><a href="https://www.brendangregg.com/blog/images/2024/matrixAIflamegraph.svg"><img src="https://www.brendangregg.com/blog/images/2024/matrixAIflamegraph.png" width="700"></a><br><span size="-1"><i>Simple example: SYCL matrix multiply microbenchmark</i></span></center>

<p>(Click for interactive <a href="https://www.brendangregg.com/blog/images/2024/matrixAIflamegraph.svg">SVG</a>.) The <span color="#00bb00">green</span> frames are the actual instructions running on the AI or GPU accelerator, <span color="#008888">aqua</span> shows the source code for these functions, and <span color="#bb0000">red</span> (C), <span color="#888800">yellow</span> (C++), and <span color="#a04000">orange</span> (kernel) show the CPU code paths that initiated these AI/GPU programs. The <span color="#808080">gray</span> "-" frames just help highlight the boundary between CPU and AI/GPU code. The x-axis is proportional to cost, so you look for the widest things and find ways to reduce them.</p>

<div><center><img src="https://www.brendangregg.com/blog/images/2024/AIflamegraph-legend.png" width="150"><br><span size="-1"><i>Layers</i></span></center></div>

<p>This flame graph shows a simple program for SYCL (a high-level C++ language for accelerators) that tests three implementations of matrix multiply, running them with the same input workload. The flame graph is dominated by the slowest implementation, multiply_basic(), which doesn't use any optimizations and consumes at 72% of stall samples and is shown as the widest tower. On the right are two thin towers for multiply_local_access() at 21% which replaces the accessor with a local variable, and multiply_local_access_and_tiling() at 6% which also adds matrix tiling. The towers are getting smaller as optimizations are added.</p>

<p>This flame graph profiler is a prototype based on Intel EU stall profiling for hardware profiling and <a href="https://ebpf.io/">eBPF</a> for software instrumentation. It's designed to be <strong>easy and low-overhead</strong>, just like a CPU profiler. You should be able to generate a flame graph of an existing AI workload whenever you want, without having to restart anything or launch additional code via an interposer.</p>

<h2>Instruction-offset Profiling</h2>

<p>This is not the first project to build an AI profiler or even something called an AI Flame Graph, however, others I've seen focus on tracing CPU stacks and timing accelerator execution, but don't profile the instruction offsets running on the accelerator; or do profile them but via expensive binary instrumentation. I wanted to build AI flame graphs that work like CPU flame graphs: Easy to use, negligible cost, production safe, and shows everything. A daily tool for developers, with most of the visualization <em>in the language of the developer</em>: source code functions.</p>

<p>This has been an internal AI project at Intel for the past year. Intel was already investing in this space, building the EU stall profiler capability for the Intel Data Center GPU Max Series that provides an approximation of HW instruction sampling. I was lucky to have <strong>Dr. Matthew (Ben) Olson</strong>, an Intel AI engineer who has also worked on eBPF performance tooling (<a href="https://github.com/intel/processwatch">processwatch</a>) as well as memory management research, join my team and do most of the development work. His background has helped us power through difficulties that seemed insurmountable. We've also recently been joined by <strong>Dr. Brandon Kammerdiener</strong> (coincidentally another graduate of the University of Tennessee, like Ben), who also has eBPF and memory internals experience, and has been helping us take on harder and harder workloads. And <strong>Gabriel Mu√±oz</strong> just joined today to help with releases. Now that our small team has shown that this is possible, we'll be joined by other teams at Intel to develop this further.</p>

<p>We could have built a harder-to-use and higher-overhead version months ago using Intel <a href="https://www.brendangregg.com/blog//2024-10-29/binary%20instrumentation">GTPin</a> but for widespread adoption it needs minimal overhead and ease of use so that developers don't hesitate to use this daily and to add it to deployment pipelines.</p>

<h2>What's a Flame Graph?</h2>

<div><center><img src="https://www.brendangregg.com/blog/images/2024/flamegraph-cost.png" width="300"></center></div>

<p>A <a href="https://www.brendangregg.com/flamegraphs.html">flame graph</a> is a visualization I invented in 2011 for showing sampled code stack traces. It has become the standard for CPU profiling and analysis, helping developers quickly find performance improvements and eliminate regressions. A CPU flame graph shows the "big picture" of running software, with x-axis proportional to CPU cost. The example picture on the right summarizes how easy it can be to go from compute costs to responsible code paths. Prior to flame graphs, it could take hours to understand a complex profile by reading through <a href="https://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html#Problem">hundreds of pages of output</a>. Now it takes seconds: all you have to do is look for the widest rectangles.</p>

<p>Flame graphs have had worldwide adoption. They have been the basis for five startups so far, have been adopted in over thirty performance analysis products, and have had <a href="https://www.brendangregg.com/Slides/YOW2022_flame_graphs/#8">over eighty implementations</a>.</p>

<p>My first implementation of flame graphs took a few hours on a Wednesday night after work. The real effort has been in the decade since, where I worked with different profilers, runtimes, libraries, kernels, compilers, and hypervisors to get flame graphs working properly in different environments, including fixing stack walking and symbolization. Earlier this year I posted about the final missing piece: Helping distros <a href="https://www.brendangregg.com/blog/2024-03-17/the-return-of-the-frame-pointers.html">enable frame pointers</a> so that profiling works across standard system libraries.</p>

<p>Similar work is necessary for AI workloads: fixing stacks and symbols and getting profiling to work for different hardware, kernel drivers, user-mode drivers, frameworks, runtimes, languages, and models. A lot more work, too, as AI analysis has less maturity than CPU analysis.</p>

<h2>Searching Samples</h2>

<p>If you are new to flame graphs, it's worth mentioning the built-in search capability. In the earlier example, most of the stall samples are caused by sbid: software scoreboard dependency. As that may be a unique search term, you can run search (Ctrl-F, or click "Search") on "sbid" and it will highlight it in magenta:</p>

<center><img src="https://www.brendangregg.com/blog/images/2024/AIflamegraph-search.png" width="530"></center>

<p>Search also shows the total number of stack samples that contained sbid in the bottom right: 78.4%. You can search for any term in the flame graph: accelerator instructions, source paths, function names, etc., to quickly calculate the percentage of stacks where it is present (excluding vertical overlap) helping you prioritise performance work.</p>

<p>Note that the samples are EU stall-based, which means theoretical performance wins can take the percentages down to zero. This is different to timer-based samples as are typically used in CPU profiling. Stalls mean you better focus on the pain, the parts of the code that aren't making forward progress, but you aren't seeing resource usage by unstalled instructions. I'd like to supuport timer-based samples in the future as well, so we can have both views.</p>

<h2>Who will use this?</h2>

<p>At a recent golang conference, I asked the audience of 200+ to raise their hands if they were using CPU flame graphs. Almost every hand went up. I know of companies where flame graphs are a daily tool that developers use to understand and tune their code, reducing compute costs. This will become a daily tool for AI developers.</p>

<p>My employer will use this as well for evaluation analysis, to find areas to tune to beat competitors, as well as to better understand workload performance to aid design.</p>

<h2>Why is AI profiling hard?</h2>

<p>Consider CPU instruction profiling: This is easy when the program and symbol table are both in the file system and in a standardized file format (such as ELF) as is the case with native compiled code (C). CPU profiling gets hard for JIT-complied code, like Java, as instructions and symbols are dynamically generated and placed in main memory (the process heap) without following a universal standard. For such JITted code we use runtime-specific methods and agents to retrieve snapshots of the heap information, which is different for each runtime.</p>

<p>AI workloads also have different runtimes (and frameworks, languages, user-mode drivers, compilers, etc.) any of which can require special tinkering to get their CPU stacks and symbols to work. These CPU stacks are shown as the red, orange, and yellow frames in the AI Flame Graph. Some AI workloads are easy to get these frames working, some (like PyTorch) are a lot more work. </p>

<div><center><img src="https://www.brendangregg.com/blog/images/2024/AIsourcezoom.png" width="450"></center></div>

<p>But the real challenge is instruction profiling of actual GPU and AI accelerator programs -- shown as the aqua and green frames -- and correctly associating them with the CPU stacks beneath them. Not only may these GPU and AI programs not exist in the file system, but they may not even exist in main memory! Even for running programs. Once execution begins, they may be deallocated from main memory and only exist in special accelerator memory, beyond the direct reach of OS profilers and debuggers. Or within reach, but only through a prohibitively high-overhead HW-specific debugger interface.</p>

<p>There's also no /proc representation for these programs either (I've been proposing building an equivalent) so there's no direct way to even tell what is running and what isn't, and all the other /proc details. Forget instruction profiling, even ps(1) and all the other process tools do not work.</p>

<p>It's been a mind-bending experience, revealing what gets taken for granted because it has existed in CPU land for decades: A process table. Process tools. Standard file formats. Programs that exist in the file system. Programs running from main memory. Debuggers. Profiliers. Core dumping. Disassembling. Single stepping. Static and dynamic instrumentation. Etc. For GPUs and AI, this is all far less mature. It can make the work exciting at times, when you think something is impossible and then find or devise a way.</p>

<p>Fortunately we have a head start as some things do exist. Depending on the runtime and kernel driver, there are debug interfaces where you can list running accelerator programs and other statistics, as used by tools like intel_gpu_top(1). You can kill -9 a GPU workload using intel_gpu_abrt(1). Some interfaces can even generate basic ELF files for the running accelerator programs that you can try to load in a debugger like gdb(1). And there is support for GPU/AI program disassembly, if you can get your hands on the binary. It feels to me like GPU/AI debugging, OS style, is about two years old. Better than zero, but still early on, and lots more ahead of us. A decade, at least.</p>

<h2>What do AI developers think of this?</h2>

<p>We've shown AI Flame Graphs to other AI developers at Intel and a common reaction is to be a bit puzzled, wondering what to do with it. AI developers think about their bit of code, but with AI Flame Graphs they can now see the entire stack for the first time, including the HW, and many layers they don't usually think about or don't know about. It basically looks like a pile of gibberish with their code only a small part of the flame graph.</p>

<div><center><a href="https://www.brendangregg.com/Slides/YOW2022_flame_graphs/#8"><img src="https://www.brendangregg.com/blog/images/2024/flamegraph-montage.png" width="190"></a><br><span size="-1"><i>CPU Flame Graph Implementations</i></span></center></div>

<p>This reaction is similar to people's first experiences with CPU flame graphs, which show parts of the system that developers and engineers typically don't work on, such as runtime internals, system libraries, and kernel internals. Flame graphs are great at highlighting the dozen or so functions that matter the most, so it becomes a problem of learning what those functions do across a few different code bases, which are typically open source. Understanding a dozen such functions can take a few hours or even a few days -- but if this leads to a 10% or 2x cost win, it is time well spent. And the next time the user looks at a flame graph, they start saying "I've seen that function before" and so on. You can get to the point where understanding the bulk of a CPU flame graph takes less than a minute: look for the widest tower, click to zoom, read the frames, done.</p>

<p>I'm encouraged by the success of CPU flame graphs, with over 80 implementations and countless real world case studies. Sometimes I'm browsing a performance issue I care about on github and hit page down and there's a CPU flame graph. They are everywhere.</p>

<p>I expect AI developers will also be able to understand AI Flame Graphs in less than a minute, but to start with people will be spending a day or more browsing code bases they didn't know were involved. Publishing case studies of found wins will also help people learn how to interpret them, and also help explain the value.</p>

<h2>What about PyTorch?</h2>

<p>Another common reaction we've had is that AI developers are using PyTorch, and initially we didn't support it as it meant walking Python stacks, which isn't trivial. But prior work has been done there (to support CPU profiling) and after a lot of tinkering we now have the first PyTorch AI Flame Graph:</p>

<center><a href="https://www.brendangregg.com/blog/images/2024/PyTorchFlamegraph.svg"><img src="https://www.brendangregg.com/blog/images/2024/PyTorchFlamegraph.png" width="700"></a><br><span size="-1"><i>PyTorch frames in pink </i></span></center>

<p>(Click for interactive <a href="https://www.brendangregg.com/blog/images/2024/PyTorchFlamegraph.svg">SVG</a>.) The PyTorch functions are at the bottom and are colored pink. This example runs oneDNN kernels that are JIT-generated, and don't have a source path so that layer just reads "jit". Getting all other the layers included was a real pain to get going, but an important milestone. We think if we can do PyTorch we can do anything.</p>

<p>In this flame graph, we show PyTorch running the Llama 2 7B model using the Intel Extensions for PyTorch (IPEX). This flame graph shows the origin of the GPU kernel execution all the way back to the Python source code shown in pink. Most samples are from a stack leading up to a gemm_kernel (matrix multiply) shown in aqua, which like the previous example has many stalls due to software scoreboarding.</p>

<p>There are two instructions (0xa30 and 0xa90) that combined are 27% of the entire profile. I expect someone will ask: Can't we just click on instructions and have it bring up a dissassembly view with full source? Yes, that should be possible, but I can't answer how we're going to provide this yet. Another expected question I can't yet answer: Since there are now multiple products providing AI auto-tuning of CPU workloads using CPU flame graphs (including <a href="https://granulate.io/">Intel Granulate</a>) can't we have AI auto-tuning of <em>AI</em> workloads using AI Flame Graphs?</p>

<h2>First Release: Sometimes hard and with moderate overhead</h2>

<p>Getting AI Flame Graphs to work with some workloads is easy, but others are currently hard and cost moderate overhead. It's similar to CPU profiling, where some workloads and languages are easy to profile, whereas others need various things fixed. Some AI workloads use many software dependencies that need various tweaks and recompilation (e.g., enabling frame pointers so that stack walking works) making setup time consuming. PyTorch is especially difficult and can take over a week of OS work to be ready for AI Flame Graphs. We will work on getting these tweaks changed upstream in their respective repositories, something involving teams inside and outside of Intel, and is a process I'd expect to take at least a year. During that time AI workloads will gradually become easier to flame graph, and with lower-overhead as well.</p>

<p>I'm reminded of eBPF in the early days: You had to patch and recompile the kernel and LLVM and Clang, which could take multiple days if you hit errors. Since then all the eBPF dependency patches have been merged, and default settings changed, so that eBPF "just works." We'll get there with AI Flame Graphs too, but right now it's still those early days.</p>

<p>The changes necessary for AI Flame Graphs are really about improving debugging in general, and are a requirement for <a href="https://www.brendangregg.com/Slides/eBPFSummit2023_FastByFriday/">Fast by Friday</a>: A vision where we can root-cause analyze anything in five days or less.</p>

<h2>Availability</h2>

<p>AI Flame Graphs will first become available on the <a href="https://www.brendangregg.com/blog//2024-10-29/yes,%20Intel%20has%20a%20public%20cloud">Intel Tiber AI Cloud</a> as a preview feature for the Intel Data Center GPU Max Series. If you are currently deployed there you can ask through the Intel service channel for early access. As for if or when it will support other hardware types, be in other Intel products, be officially launched, be open source, etc., these involve various other teams at Intel and they need to make their own announcements before I can discuss them here.</p>

<h2>Conclusions</h2>

<p>Finding performance improvements for AI data centers of just fractions of a percent can add up to planetary savings in electricity, water, and money. If AI flame graphs have the success that CPU flame graphs have had, I'd expect finding improvements of over 10% will be common, and 50% and higher will eventually be found*. But it won't be easy in these early days as there are still many software components to tweak and recompile, and software layers to learn about that are revealed in the AI flame graph.</p>

<p>In the years ahead I imagine others will build their own AI flame graphs that look the same as this one, and there may even be startups selling them, but if they use more difficult-to-use and higher-overhead technologies I fear they could turn companies off the idea of AI flame graphs altogether and prevent them from finding sorely needed wins. This is too important to do badly. AI flame graphs should be easy to use, cost negligible overhead, be production safe, and show everything. Intel has proven it's possible.</p>

<h2>Disclaimer</h2>

<p><span size="-1">
* This is a personal blog post that makes personal predictions but not guarantees of possible performance improvements. Feel free to take any claim with a grain of salt, and feel free to wait for an official publication and public launch by Intel on this technology.</span></p><p><span size="-1"><sup>1</sup> Based on halving the Arm CEO Rene Haas' estimate of 20-25% quoted in <a href="https://arstechnica.com/ai/2024/06/is-generative-ai-really-going-to-wreak-havoc-on-the-power-grid/">Taking a closer look at AI's supposed energy apocalypse</a> by Kyle Orland of ArsTechnica.
</span></p>

<h2>Thanks</h2>

<p><i>Thanks to everyone at Intel who have helped us make this happen. Markus Flierl has driven this project and made it a top priority, and Greg Lavender has expressed his support. Special thanks to Michael Cole, Matthew Roper, Luis Strano, Rodrigo Vivi, Joonas Lahtinen, Stanley Gambarin, Timothy Bauer, Brandon Yates, Maria Kraynyuk, Denis Samoylov, Krzysztof Raszknowski, Sanchit Jain, Po-Yu Chen, Felix Degrood, Piotr Rozenfeld, Andi Kleen, and all of the other coworkers that helped clear things up for us, and thanks in advance for everyone else who will be helping us in the months ahead.</i></p><p><i>My final thanks is to the companies and developers who do the actual hands-on work with flame graphs, collecting them, examining them, finding performance wins, and applying them.<br>You are helping save the planet.</i></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jaywalking legalized in New York City (181 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/oct/29/new-york-jaywalking-legal</link>
            <guid>41992399</guid>
            <pubDate>Wed, 30 Oct 2024 06:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/oct/29/new-york-jaywalking-legal">https://www.theguardian.com/us-news/2024/oct/29/new-york-jaywalking-legal</a>, See on <a href="https://news.ycombinator.com/item?id=41992399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Jaywalking ‚Äì that time-honored practice of crossing the street outside of the crosswalk or against the traffic light ‚Äì is now legal in <a href="https://www.theguardian.com/us-news/new-york" data-link-name="in body link" data-component="auto-linked-tag">New York</a> City.</p><p>Legislation passed by the city council last month officially became law over the weekend after the city‚Äôs mayor, Eric Adams, declined to take action ‚Äì either by signing or vetoing it ‚Äì after 30 days.</p><p>Council member Mercedes Narcisse, a Brooklyn Democrat who sponsored the legislation, said on Tuesday that the new law ends racial disparities in enforcement, noting that more than 90% of the jaywalking tickets issued last year went to Black and Latino people.</p><p>‚ÄúLet‚Äôs be real, every New Yorker jaywalks. People are simply trying to get where they need to go,‚Äù she said in an emailed statement. ‚ÄúLaws that penalize common behaviors for everyday movement shouldn‚Äôt exist, especially when they unfairly impact communities of color.‚Äù</p><p>The new law permits pedestrians to cross a roadway at any point, including outside of a crosswalk. It also allows for crossing against traffic signals and specifically states that doing so is no longer a violation of the city‚Äôs administrative code.</p><p>But the new law also warns that pedestrians crossing outside of a crosswalk do not have the right of way and that they should yield to other traffic that has the right of way.</p><p>Liz Garcia, an Adams spokesperson, declined to elaborate on the mayor‚Äôs decision to let the bill become law without his action.</p><p>But she noted the bill makes it clear that crossing against the light and mid-block is highly risky behavior. People may also still be liable in civil actions for accidents caused by jaywalking, Garcia added.</p><p>‚ÄúAll road users are safer when everyone follows traffic rules,‚Äù she said in a statement. ‚ÄúWe continue to encourage pedestrians to take advantage of safety mechanisms in place ‚Äì such as daylighting, pedestrian islands, and leading pedestrian intervals ‚Äì by crossing in a crosswalk with the walk signal.‚Äù</p><p>Other cities and states, from Denver and Kansas City, Missouri, to California, Nevada and Virginia, have decriminalized jaywalking in recent years, according to America Walks, a Seattle-based group that‚Äôs been tracking the proposals.</p><p>‚ÄúCities that truly care about safety focus on street design, speeding and dangerously large vehicles,‚Äù Mike McGinn, the group‚Äôs executive director, said Tuesday. ‚ÄúNot jaywalking laws.‚Äù</p><p>The laws were pushed by the auto industry in the 1930s as a way to keep people off streets and make more room for vehicles, according to America Walks.</p><p>The term ‚Äújaywalking‚Äù dates to the early 20th century and has its roots in midwestern slang for a country bumpkin or rube, according to dictionary maker Merriam-Webster.</p><p>In New York City, where struggles between pedestrians and motorists are constant, the jaywalking law had been on the books since 1958 and carried a penalty of up to $250.</p><p>In the 1969 film Midnight Cowboy, Dustin Hoffman famously yells: ‚ÄúI‚Äôm walking here!‚Äù as his character is almost hit by a cab while crossing the street in Manhattan.</p><p>The Legal Aid Society called the legislation long overdue. The non-profit organization, which provides free legal representation to New Yorkers who cannot afford a lawyer, said police for decades have used the violation as a pretext to stop, question and frisk residents ‚Äì especially those of color.</p><p>‚ÄúWith this legislation now codified, we hope that both the Adams Administration and the City Council will continue to abolish relic laws that serve no public safety purpose and only ensnare people in the criminal legal system,‚Äù the organization said in a statement.</p><p>Police department spokespeople didn‚Äôt immediately respond to emails seeking comment, and a spokesperson for its largest union declined to weigh in.</p><p>But Narcisse said officers she has spoken to say their time could be better spent on other police work, rather than issuing tickets for jaywalking.</p><p>‚ÄúNo one‚Äôs ever said: ‚ÄòI‚Äôm so glad they caught that jaywalker.‚Äô By eliminating these penalties, we allow our police officers to focus on issues that truly matter,‚Äù she said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[15 Billion Miles Away, NASA's Voyager 1 Breaks Its Silence (200 pts)]]></title>
            <link>https://scitechdaily.com/15-billion-miles-away-nasas-voyager-1-breaks-its-silence/</link>
            <guid>41992394</guid>
            <pubDate>Wed, 30 Oct 2024 06:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scitechdaily.com/15-billion-miles-away-nasas-voyager-1-breaks-its-silence/">https://scitechdaily.com/15-billion-miles-away-nasas-voyager-1-breaks-its-silence/</a>, See on <a href="https://news.ycombinator.com/item?id=41992394">Hacker News</a></p>
Couldn't get https://scitechdaily.com/15-billion-miles-away-nasas-voyager-1-breaks-its-silence/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Australia/Lord_Howe is the weirdest timezone (906 pts)]]></title>
            <link>https://ssoready.com/blog/engineering/truths-programmers-timezones/</link>
            <guid>41992314</guid>
            <pubDate>Wed, 30 Oct 2024 06:21:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssoready.com/blog/engineering/truths-programmers-timezones/">https://ssoready.com/blog/engineering/truths-programmers-timezones/</a>, See on <a href="https://news.ycombinator.com/item?id=41992314">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            Timezones are weird. But only finitely so. Here's the exact conceptual model you should have of them.
        </p><div>
            <p>The standard trope when talking about timezones is to rattle off falsehoods
programmers believe about them. These lists are only somewhat enlightening ‚Äì
it‚Äôs really hard to figure out what truth is just from the contours of
falsehood.</p>
<p>So here‚Äôs an alternative approach. I‚Äôm gonna show you some weird timezones. In
fact, the <em>weirdest</em> timezones. They‚Äôre each about as weird as timezones are
allowed to get in some way.</p>
<ul>
<li><code>Asia/Kathmandu</code> has a weird offset from UTC</li>
<li><code>Africa/Casablanca</code> doesn‚Äôt fit into the timezone model cleanly, so it‚Äôs hard-coded</li>
<li><code>America/Nuuk</code> does daylight savings at -01:00 (yes, with a negative)
<ul>
<li>and <code>Africa/Cairo</code> and <code>America/Santiago</code> do it at 24 o‚Äôclock (not 0 o‚Äôclock)</li>
</ul>
</li>
<li><code>Australia/Lord_Howe</code>, population 382 and <a href="https://en.wikipedia.org/wiki/Dryococelus_australis">some notable stick
bugs</a>, has the weirdest
daylight savings rule</li>
</ul>
<p>To learn how their weirdness is represented in software, we‚Äôll look at the raw
timezone files that all software ultimately relies on. From there, two things
will become clear:</p>
<ul>
<li>Yeah, this stuff is weird</li>
<li>But only finitely so, because ultimately a computer‚Äôs gotta implement them</li>
</ul>
<p>But first, an aside on the calendar.</p>
<h2 id="pgxiiream-pope-gregory-xiii-rules-everything-around-me">PGXIIREAM: Pope Gregory XIII rules everything around me</h2>
<p>Unless you‚Äôre doing some fairly exotic things where you‚Äôre finding yourself
saying things like</p>
<blockquote>
<p>Oh yeah the OCR on Japanese driving licenses pops out things like ‚ÄúÂπ≥Êàê 8‚Äù,
that‚Äôs just <a href="https://en.wikipedia.org/wiki/Japanese_era_name">how they sometimes say
1996</a> over there. That‚Äôs why
we have this in the parser:</p>
<pre tabindex="0"><code>eras = { "Â§ßÊ≠£": 1912, "Êò≠Âíå": 1926, "Âπ≥Êàê": 1989 }
</code></pre><p>One of these days we‚Äôll need to add <code>"‰ª§Âíå": 2019</code>, but it hasn‚Äôt come up yet.</p>
</blockquote>
<p>or</p>
<blockquote>
<p>We‚Äôre gonna need to set up a per-country feature flag when deciding whether
banks are closed for Eid. <a href="https://www.economist.com/middle-east-and-africa/2019/06/06/when-is-eid-al-fitr">Saudi Arabia and Iran don‚Äôt agree on when the lunar
month
starts</a>.</p>
</blockquote>
<p>Then yeah, sure, you may need to write software that knows about the Japanese or
Islamic calendar systems.</p>
<p>Cases like this are a small minority. The reality of the world is that the
Western system of timekeeping is the dominant one, and even in e.g. Japan and
the Muslim world, almost everyone who uses computers is familiar with the
Gregorian system.</p>
<p>With computers, we project the Gregorian system into the future and past, which
is called the proleptic Gregorian calendar and isn‚Äôt historically accurate but
nobody really cares except <a href="https://en.wikipedia.org/wiki/Old_Style_and_New_Style_dates">Russian revolution
nerds</a>.</p>
<p>This calendar system is pretty much good enough, and barring any <a href="https://en.wikipedia.org/wiki/French_Republican_calendar">rationalist
coups d‚Äôetat</a>, is the
one we‚Äôll be stuck with for a long time. It does one thing well: it‚Äôs very good
at keeping the sun at the same place in the sky across the years. It doesn‚Äôt let
the months drift around the seasons like the Roman calendar did.</p>
<p>Technically, this ‚Äúkeep the sun roughly in the same place whenever it‚Äôs the same
time-of-day‚Äù is called ‚Äúmean solar time‚Äù. And that‚Äôs why GMT, Greenwich Mean
Time, is called that way. It‚Äôs about the mean solar time of the <a href="https://en.wikipedia.org/wiki/Royal_Observatory,_Greenwich">English
observatory in
Greenwich</a>.</p>
<p>By the way, we technically don‚Äôt call it GMT anymore. Unless you‚Äôre talking
about what time people in London say it is, you probably technically mean
<a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">UTC</a>.</p>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/utc.png" alt=""></p>
<p><a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">Coordinated Universal
Time</a> is basically
just a modern formalization of GMT. It‚Äôs useful because almost everyone on the
planet has agreed to base their clocks off of an <em>offset</em> from UTC. It‚Äôs still a
solar mean time, but the connection to Greenwich isn‚Äôt really there anymore.</p>
<p>I bring this up because you may have heard of a weird modern quirk on Pope
Gregory‚Äôs sun-following endeavors:</p>
<h2 id="leap-seconds-dont-matter">Leap seconds don‚Äôt matter</h2>
<p>The Earth‚Äôs rotation is slowing down. Days are getting longer. So you need to
correct for it if you want to keep IRL days in sync with computer days.</p>
<p>The nerd task force assigned to this problem is the <a href="https://en.wikipedia.org/wiki/International_Earth_Rotation_and_Reference_Systems_Service">International Earth
Rotation and Reference Systems
Service</a>,
which has two primary goals:</p>
<ol>
<li>Watch the Earth rotate, and report back on their findings</li>
<li>Break Wikipedia‚Äôs CSS with their long name</li>
</ol>
<figure>
<div>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/iers.png"></p><figcaption>timecops</figcaption>
</div>
</figure>
<p>If the days are getting longer, and they‚Äôre doing so at a fairly unpredictable
rate, the simplest solution is to have IERS occasionally just insert an extra
second in the day to make clocks go slower. It‚Äôs called a <a href="https://en.wikipedia.org/wiki/Leap_second">leap
second</a>.</p>
<p>You should completely ignore the fact that this is a thing. It‚Äôs a cool novelty,
but it‚Äôs effectively just a detail you can ignore, because:</p>
<ol>
<li><a href="https://go.dev/play/p/9RwZu2jmlPl">It‚Äôs not like programming languages support representing 61-second minutes
anyway</a></li>
<li>You (and by you I mean your cloud provider) can just run your clocks slower
around the time of the leap second, and pretend to everyone else over
<a href="https://en.wikipedia.org/wiki/Network_Time_Protocol">NTP</a> that their clocks
are running fast. This is called leap smearing.</li>
</ol>
<p>Btw it‚Äôs called UTC (Universal Time Coordinated? huh?) because the same folks
who publish UTC also publish UT1, which is UTC sans the leap seconds. There were
other UTs before the Coordinated variant came up.</p>
<h2 id="weird-time-zones">Weird time zones</h2>
<p>OK! Let‚Äôs start looking at some weird time zones, and find out how your computer
knows to represent them.</p>
<h2 id="asiakathmandu-is-on-a-weird-offset"><code>Asia/Kathmandu</code> is on a weird offset</h2>
<p>Most of the world is on a whole number of hours before or after UTC. About a
fifth the world by population is on a half-hour offset from UTC; in particular,
India is 5h30m ahead of UTC.</p>
<p>Nepal is 5h45m ahead of UTC:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>$ TZ=UTC date ; TZ=Asia/Kathmandu date
</span></span><span><span>Tue Jul 30 23:52:11 UTC 2024
</span></span><span><span>Wed Jul 31 05:37:11 +0545 2024
</span></span></code></pre></div><p>If you‚Äôre like me, you must be have at one point wondered how in the <em>world</em>
your computer knows this fact.</p>
<p>Here‚Äôs a hint:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>$ TZ=Asia/Kathmandu strace -e trace=openat date
</span></span><span><span>...
</span></span><span><span>openat(AT_FDCWD, "/usr/share/zoneinfo/Asia/Kathmandu", O_RDONLY|O_CLOEXEC) = 3
</span></span><span><span>Wed Jul 31 05:40:49 +0545 2024
</span></span></code></pre></div><p>On your filesystem is a database called the IANA Timezone Database, aka tzdb or
zoneinfo. It‚Äôs a bunch of binary files, encoded in <a href="https://www.rfc-editor.org/rfc/rfc8536.html">Timezone Information
Format</a>. The names of those files
act as timezone identifiers, which is where you see strings like
<code>America/Los_Angeles</code> or <code>Europe/London</code> come from:</p>
<pre tabindex="0"><code>$ tree /usr/share/zoneinfo
...
‚îú‚îÄ‚îÄ America
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ Los_Angeles
‚îú‚îÄ‚îÄ Europe
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ London
...
</code></pre><p>At the very end of <code>/usr/share/zoneinfo/Asia/Kathmandu</code> is this little string:</p>
<pre tabindex="0"><code>cat /usr/share/zoneinfo/Asia/Kathmandu
...
&lt;+0545&gt;-5:45
</code></pre><p>The syntax is here pretty obtuse, but what it means is:</p>
<blockquote>
<p>Unless otherwise specified, UTC is 5h45m behind this timezone. Call this time
<code>+0545</code>.</p>
</blockquote>
<p>That‚Äôs precisely how software can figure out the time in Nepal. That‚Äôs also why
the output from <code>date</code> above has <code>+0545</code> in it.</p>
<h2 id="why-strings-like-pdt-or-cet-are-pretty-meaningless">Why strings like <code>PDT</code> or <code>CET</code> are pretty meaningless</h2>
<p>In the example above, <code>+0545</code> is called a ‚Äúdesignator‚Äù. It‚Äôs a pretty-ish string
describing which <em>part</em> of a timezone a timestamp is in. It‚Äôs meant to be used
for outputting timestamps, and is only unambiguous if you already know what
timezone the timestamp was taken in.</p>
<p>Just <em>how</em> ambiguous are these designators? I wrote a <code>tzdump</code> script that
converts TZIF files to JSON. Here‚Äôs the top hits:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>find -L /usr/share/zoneinfo -type f <span>\
</span></span></span><span><span><span></span>  <span>|</span> xargs -n1 ./tzdump <span>\
</span></span></span><span><span><span></span>  <span>|</span> jq -r <span>'"\(.ID)\t\(.Transitions[].LocalTimeType.Designation)"'</span> <span>\
</span></span></span><span><span><span></span>  <span>|</span> sort <span>|</span> uniq <span>|</span> sort -k <span>2</span> <span>|</span> uniq -f <span>1</span> -c <span>|</span> sort -n <span>|</span> awk <span>'{ print $1 "\t" $3 }'</span> <span>|</span> tail -r
</span></span></code></pre></div><p>The most popular designators are:</p>
<pre tabindex="0"><code>66	CST
58	CDT
56	CET
56	CEST
</code></pre><p>A total of <strong>66 timezones</strong> use <code>CST</code>, either in the past or future. Many
timezones are functionally exact clones of each other ‚Äì there‚Äôs no difference
between <code>America/Phoenix</code> and
<a href="https://en.wikipedia.org/wiki/Creston,_British_Columbia"><code>America/Creston</code></a>,
but they each get their own file ‚Äì but still. There‚Äôs a lot of ambiguity in
there.</p>
<p>In case you‚Äôre curious, only 33 designators are unique to a timezone. A lot more
are functionally unique, but I‚Äôm too lazy to dedupe logically-equivalent
timezones right now.</p>
<p>As an extra fun bit of trivia, designators are not strictly uppercase/numeric.
<code>ChST</code>, appearing in <code>Pacific/Saipan</code>, stands for Chamorro Standard Time. It‚Äôs
the only designator with a lowercase name. <code>CHST</code> is not taken, sadly for those
of us who love bugs.</p>
<h2 id="how-are-timezones-with-dst-represented">How are timezones with DST represented?</h2>
<p>When we looked at Kathmandu, we had this string telling us the Nepalese time
rules:</p>
<pre tabindex="0"><code>&lt;+0545&gt;-5:45
</code></pre><p>Ok, simple enough. But what about a timezone with DST transitions? The syntax
has lots of defaults (DST will be a one-hour jump, it happens at 2am by default,
etc) but <code>Europe/Athens</code> is a good example of one that uses most of the syntax:</p>
<pre tabindex="0"><code>$ cat /usr/share/zoneinfo/Europe/Athens
...
EET-2EEST,M3.5.0/3,M10.5.0/4
</code></pre><p>That syntax means:</p>
<blockquote>
<p>Standard time is called <code>EET</code>, it‚Äôs 2 hours ahead of UTC. DST is called <code>EEST</code>
(it‚Äôs 3 hours ahead, an implicit default relative to standard time). Start DST
in month <code>3</code> on the last instance of (<code>5</code>) day <code>0</code> (Sunday) in that month, at
3am local (<code>/3</code>). End DST on month <code>10</code> on the last Sunday at 4am local
(<code>5.0/4</code>).</p>
</blockquote>
<p>So yeah, your computer does a bunch of <a href="https://howardhinnant.github.io/date_algorithms.html">kind of
gnarly</a> logic to figure
out what date-and-time a timestamp corresponds to, then figures out whether it‚Äôs
inside or outside DST to figure out the current local time. Delightful.</p>
<p>In case you‚Äôre curious, the spec says ‚Äú5‚Äù means ‚Äúlast instance of‚Äù, and ‚Äú1‚Äù
means ‚Äúfirst instance of‚Äù. But only weeks ‚Äú1‚Äù, ‚Äú2‚Äù, and ‚Äú5‚Äù are used:</p>
<pre tabindex="0"><code>$ find -L /usr/share/zoneinfo -type f | xargs -n1 ./tzdump | jq -r 'if .Rules.DST == null then empty else "\(.ID)\t\(.Rules.DST.Week)" end' | sort -k2 | uniq -f 1 -c | awk '{ print $1 "\t" $3 }'
18	1
89	2
81	5
</code></pre><p>Here‚Äôs a fun twist: on my Mac 100% of timezones either don‚Äôt have DST at all or
use this nth-instance-of-day-of-month rules to do DST switching. But inside
<code>/var/db/timezone</code> there‚Äôs different versions of tzdb. In there is a version
with other kinds of timezones in it:</p>
<pre tabindex="0"><code>$ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/Africa/Casablanca
...
XXX-2&lt;+01&gt;-1,0/0,J365/23
</code></pre><p>That timezone basically means ‚Äúwe are perpetually on daylight savings‚Äù, because
the <code>J###</code> syntax means ‚Äú<code>###</code>-th day of the year, not counting Feb 29 if there
is one‚Äù (J stands for ‚ÄúJulian calendar‚Äù).</p>
<p>Technically, that timezone also exercises the prefixless (i.e. without <code>M</code> or
<code>J</code>) syntax for indicating days, where <code>###</code> means ‚Äú<code>###</code>-th day of year,
counting any Feb 29‚Äù. But in this case it‚Äôs a distinction without a difference.</p>
<p>(Aside: All this stuff comes from POSIX. <a href="https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html">GNU‚Äôs docs about the POSIX <code>TZ</code> env
var</a>, which
TZIF builds on, are the best I know of online for this stuff.)</p>
<p>But this is just the start of the weirdness that is <code>Africa/Casablanca</code>.</p>
<h2 id="africacasablanca-and-asiagaza-follow-the-moon-but-timezones-follow-the-sun"><code>Africa/Casablanca</code> and <code>Asia/Gaza</code> follow the moon, but timezones follow the sun</h2>
<p>The TZIF format supports three possible rules for deciding on your daylight
savings transition day:</p>
<ul>
<li>Rules like ‚Äúfirst Tuesday of March‚Äù</li>
<li>Rules like ‚Äú45th day of the year‚Äù</li>
<li>Rules like ‚Äú45th day of the year, Feb 29 doesn‚Äôt count‚Äù</li>
</ul>
<p>Morocco and Gaza do their daylight savings based on Ramadan. Ramadan is a month
in the Islamic calendar. The Islamic calendar is based on the moon. The lunar
calendar isn‚Äôt a clean multiple of the solar calendar; from the Gregorian
perspective, lunar months seem to slowly ‚Äúrotate‚Äù around the year, because
they‚Äôre basically on a different modulo. There‚Äôs a problem there for our heroes
at the tzdb.</p>
<p>The solution? The dumbest possible one.</p>
<p>A TZIF file ends with the footer syntax we‚Äôve been talking about to this point.
But it <em>starts</em> with a big long list of historical data about a timezone. If a
country ever changes timezone rules, TZIF represents that by encoding the new
rule in the footer, and hard-coding all the old transitions.</p>
<p>But you can also just take these hard-coded transitions and put them into the
future. The hard-coded transitions take precedence over the footer. So the TZIF
folks:</p>
<ol>
<li>Picked a year far enough into the future (2086, as it turns out)</li>
<li>Wrote a script in
<a href="https://github.com/eggert/tz/blob/339e81d1ade620e70ecc78c2b4ec1309a6b80a2f/asia#L3494-L3512">emacs</a>
<a href="https://github.com/eggert/tz/blob/339e81d1ade620e70ecc78c2b4ec1309a6b80a2f/africa#L861-L878">lisp</a>
to calculate Ramadan</li>
<li>Use the output of that script to generate transitions for Morocco and Gaza</li>
</ol>
<p>And that‚Äôs why in practice Morocco and Gaza are just hard-coded in the tzdb,
unlike every other timezone.</p>
<p>In case you‚Äôre hoping for more fun timezones like this, I‚Äôm afraid you‚Äôre out of
luck. The others at the bottom of this list, which filters for transitions
beyond 2025, are just synonyms of Casablanca and Gaza.</p>
<pre tabindex="0"><code>$ find -L /var/db/timezone/tz/2024a.1.0/zoneinfo/ -type f | xargs -n1 ./tzdump | jq 'select(.Transitions[].TransitionTime &gt; 1735689600) | .ID' -r | uniq -c | sort -n
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Cairo
...
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//US/Pacific
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//WET
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//posixrules
 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Casablanca
 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/El_Aaiun
 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Gaza
 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Hebron
</code></pre><p>It looks like every other timezone just has 26 transitions beyond 2025, which I
think are just there to make software that doesn‚Äôt know about the TZIF footer
transition rules be accurate a few years into the future anyway.</p>
<h2 id="americanuuk-transitions-to-dst-at--1-oclock"><code>America/Nuuk</code> transitions to DST at -1 o‚Äôclock</h2>
<p><a href="https://en.wikipedia.org/wiki/Nuuk">Nuuk</a> is in
<a href="https://en.wikipedia.org/wiki/Iceland">Greenland</a>, and is part of the <a href="https://en.wikipedia.org/wiki/Special_territories_of_members_of_the_European_Economic_Area">greater
EU cinematic
universe</a>.</p>
<p>All of Europe (idk whether this is an EU/EEZ/EFTA/CoE thing) syncs up their
daylight savings, except for <a href="https://en.wikipedia.org/wiki/Greenland">Iceland</a>,
which doesn‚Äôt do DST at all (<code>Atlantic/Reykjavik</code>, which is technically <a href="https://github.com/eggert/tz/blob/7748036bace8562b9c047f368c8eba5f35e8c4b4/backward#L226">an
alias for
<code>Africa/Abidjan</code></a>,
is basically just UTC; their rule string is just <code>GMT0</code>).</p>
<p>Most Europeans are familiar with three major timezones, which we can refer to as
<code>Europe/Lisbon</code> (western), <code>Europe/Brussels</code> (central), and <code>Europe/Athens</code>
(eastern). They‚Äôre each one hour ahead of the other, and so their timezone
transitions look like:</p>
<pre tabindex="0"><code># I'm gonna space these out to highlight the symmetry,
# and also spell out the implicit "/2"

Europe/Lisbon:   WET0WEST ,M3.5.0/1,M10.5.0/2
Europe/Brussels: CET-1CEST,M3.5.0/2,M10.5.0/3
Europe/Athens:   EET-2EEST,M3.5.0/3,M10.5.0/4
</code></pre><p>In other words, Lisbon springs forward at 1am, Brussels at 2am, and Athens at
3am. But those times are <em>local</em>. In reality, they‚Äôre all at the same instant.</p>
<p>This makes good sense. It‚Äôs good for business that the time difference between
any two spots in Europe is always the same.</p>
<p>Greenland would like to be part of the action. Thing is, Greenland is pretty far
west of continental Europe. Whereas Lisbon‚Äôs standard time is UTC, Greenland‚Äôs
is 3 hours behind UTC. Here‚Äôs their daylight transition rules:</p>
<pre tabindex="0"><code>$ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/America/Nuuk
&lt;-02&gt;2&lt;-01&gt;,M3.5.0/-1,M10.5.0/0
</code></pre><p>Take note of <code>M3.5.0/-1</code>. The first part is the standard European DST start day.
The <code>/-1</code> part? That means that instead of doing DST at like 2am (<code>/2</code>),
Greenland does it at -1 o‚Äôclock (<code>/-1</code>). The way the rules file is encoded,
daylight savings for Greenland is meant to happen on Sunday, but in fact happens
at 11pm on the Saturday before. Super weird.</p>
<p>I‚Äôm guessing this breaks software, because America/Nuuk and its aliases are one
of those timezones whose transition rules are just entirely ommitted in
<code>/usr/share/zoneinfo</code> on my Mac. They‚Äôre only available in other copies of tzdb
in <code>/var/db/timezone</code>.</p>
<h2 id="oh-americasantiago-and-africacairo-transition-at-24-oclock">Oh, <code>America/Santiago</code> and <code>Africa/Cairo</code> transition at 24 o‚Äôclock</h2>
<p>Nuuk is the earliest anyone does a transition. Santiago and Cairo are the
latest. They both do transitions at 24 o‚Äôclock? Like, the next day?</p>
<pre tabindex="0"><code>America/Santiago: &lt;-04&gt;4&lt;-03&gt;,M9.1.6/24,M4.1.6/24
</code></pre><pre tabindex="0"><code>Africa/Cairo: EET-2EEST,M4.5.5/0,M10.5.4/24
</code></pre><p>I think they‚Äôre both encoded like that because of weirdness in how the
governments define the rules. Like <code>M10.5.4/24</code> means ‚Äúlast Thurday of October,
24 o‚Äôclock‚Äù, which really means ‚Äúthe day after the last Thursday of October‚Äù.
But that‚Äôs not the same thing as ‚Äúlast Friday of October‚Äù if the month ends on
Thursday?</p>
<p>Both of these files are also in Mac‚Äôs list of naughty timezones that don‚Äôt go in
<code>/usr/share/zoneinfo</code>.</p>
<h2 id="australialord_howe-has-the-weirdest-dst-transition"><code>Australia/Lord_Howe</code> has the weirdest DST transition</h2>
<p>When you do a DST transition, you ‚Äúspring forward‚Äù and ‚Äúfall back‚Äù. <em>Surely</em>
everyone agrees it‚Äôs a <em>one-hour</em> jump, right?</p>
<p>Here‚Äôs a script to check. What is the time difference between standard and
daylight time in every timezone?</p>
<pre tabindex="0"><code>$ find -L /usr/share/zoneinfo -type f | xargs -n1 ./tzdump | jq 'if .Rules.DST == null then "\(.ID)\t0" else "\(.ID)\t\(.Rules.DST.LocalTimeType.UTCOffsetSeconds - .Rules.Std.LocalTimeType.UTCOffsetSeconds)" end' -r | sort -n -k 2 | uniq -c -f 1 | awk '{ print $1 "\t" $3 }'

410	0
2	1800
185	3600
1	7200
</code></pre><p>Hmm. 410 timezones just don‚Äôt DST at all. 185 have a 3600-second, i.e. 1-hour,
difference. And then there are the malcontents.</p>
<p>The 7200-second, i.e. 2-hour, jump is <code>Antarctica/Troll</code>. Fitting.</p>
<pre tabindex="0"><code>&lt;+00&gt;0&lt;+02&gt;-2,M3.5.0/1,M10.5.0/3
</code></pre><p>So during the winter (i.e. the northern summer) they use Norway time? But there
are <a href="https://en.wikipedia.org/wiki/Troll_(research_station)">like 6 people over the winter at
Troll</a>? Do these 6 souls
appreciate their contribution to software esoterica? I hope they do. Apparently
they use <a href="https://github.com/eggert/tz/blob/7748036bace8562b9c047f368c8eba5f35e8c4b4/antarctica#L212-L236">like four different times during the
year</a>
down there in practice, but there‚Äôs no syntax to express that.</p>
<p>OK but the real question is what‚Äôs up with the two 1800 transitions. They‚Äôre
synonyms for each other. It‚Äôs <code>Australia/Lord_Howe</code>, which has a <strong>powerful</strong>
30-minute DST transition:</p>
<pre tabindex="0"><code>&lt;+1030&gt;-10:30&lt;+11&gt;-11,M10.1.0,M4.1.0
</code></pre><p>10h30m ahead of UTC standard, 11h DST. Love this for them. Running cron jobs on
an hourly basis doesn‚Äôt in practice have very weird interactions with DST.
Everywhere else on the planet, every 60 minutes you‚Äôre back to the same spot on
the clock.</p>
<p>Except Lord Howe Island. Heroes. On the first Sunday of October, a 60-minute
timegap only puts you halfway around the clock. All your cron jobs are now
staggered relative to the local wall clock.</p>
<p>In case you‚Äôre curious, <a href="https://en.wikipedia.org/wiki/Lord_Howe_Island">Lord Howe
Island</a> belongs to Australia. It
has 382 people at the latest census. It‚Äôs a bit of a natural paradise, and
apparently to preserve that there‚Äôs a cap of 400 tourists at a time.</p>
<p>Probably the most famous aspect of Lord Howe is <a href="https://en.wikipedia.org/wiki/Ball%27s_Pyramid">Ball‚Äôs
Pyramid</a>.</p>
<figure>
<div>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/balls.png"></p><figcaption>Ball's Pyramid Memorial for Stickbugs and Software Engineers who write Timezone-related Code.</figcaption>
</div>
</figure>
<p>It‚Äôs an old collapsed volcano. It looks cool. It has some rare <a href="https://en.wikipedia.org/wiki/Ball%27s_Pyramid#Dryococelus_australis">stick
bugs</a>.</p>
<h2 id="big-takeaways">Big takeaways</h2>
<p>Timezones are weird, but finitely so. All they consist of is:</p>
<ul>
<li>An ID, e.g. <code>America/Los_Angeles</code></li>
<li>A set of hard-coded transitions, which range from the past into the future</li>
<li>A set of rules for how future transitions may happen</li>
</ul>
<p>Any given time in a timezone is just:</p>
<ul>
<li>An offset from UTC</li>
<li>With a ‚Äúdesignator‚Äù time that doesn‚Äôt mean much</li>
<li>(This usually isn‚Äôt outputted anywhere) Whether the time is considered DST</li>
</ul>
<p>You can always uniquely identify what UTC time someone is referring to whenever
they tell you their timezone + local time + current time designator. The
timezone + designator gives you an offset, and you can apply the offset to the
local time to get UTC.</p>
<p>Like, it‚Äôs weird, it‚Äôs quirky, but it‚Äôs not like all bets are off.</p>
<p>Also:</p>
<ul>
<li>Don‚Äôt let people bully you into thinking that just because something is
complicated, it‚Äôs impossible.</li>
<li>This is because almost every standard (except ISO8601, whatever) is
just a file, and you can read it. You are smart. You can do it. Embrace
the weirdness of Greenland‚Äôs daylight savings. Believe in yourself.</li>
<li>If I were UN secretary general, I would kick out any countries that I deem
insufficiently considerate of Paul Eggert‚Äôs time.</li>
</ul>
<h2 id="appendix-other-weird-stuff-in-zoneinfo">Appendix: Other weird stuff in zoneinfo</h2>
<p>Honestly, there‚Äôs some stuff in zoneinfo that I can‚Äôt figure out. Even I have
nerd-sniping limits. Exercises for the reader.</p>
<p>These time zones have <em>hundreds</em> of hard-coded transitions out into the future.
I don‚Äôt understand why, it‚Äôs not like they all have lunar calendar stuff going
on.</p>
<ul>
<li>Asia/Jerusalem has 780 transitions in the future, out of 901 total</li>
<li>Africa/Cairo has 800 transitions in the future, out of 929 total</li>
<li>America/Nuuk has 800 transitions in the future, out of 889 total</li>
<li>America/Santiago has 800 transitions in the future, out of 931 total</li>
<li>Pacific/Easter has 800 transitions in the future, out of 911 total</li>
<li>Asia/Gaza has 982 transitions in the future, out of 1106 total</li>
</ul>
<p>They all lack a rules footer, but our friend Africa/Casablanca has a mere 132
transitions hard-coded and lacks a rules footer too. What‚Äôs up with that?</p>
<hr>
<p>P.S. If you‚Äôre the type of weird to think this stuff is neat: email me.
<a href="mailto:ulysse.carion@ssoready.com">ulysse.carion@ssoready.com</a> ;)</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1BRC Coding Challenge: Nerd Sniping the Java Community (112 pts)]]></title>
            <link>https://www.infoq.com/presentations/1brc/</link>
            <guid>41992081</guid>
            <pubDate>Wed, 30 Oct 2024 05:02:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.infoq.com/presentations/1brc/">https://www.infoq.com/presentations/1brc/</a>, See on <a href="https://news.ycombinator.com/item?id=41992081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="presentationNotes">
                                    <h2>Transcript</h2>

<p>Morling: I would like to talk about a viral coding challenge which I did in January of this year, called, The One Billion Row Challenge. I would like to tell a little bit the story behind it, how all this went, what I experienced during January. Then, of course, also some of the things I learned, some of the things the community learned from doing that. This is how it started. On January 1st, I put out this tweet, I put out a blog post introducing this challenge. Was a little bit on my mind to do something like that for quite a while. Between Christmas and New Year's Eve, I finally found the time to do it. I thought, let me go and put out this challenge. I will explain exactly what it was, and how it worked. That's how it started. Then it got picked up quite quickly. People started to work on that. They implemented this in Java, which was the initial idea, but then they also did in other languages, other ecosystems, like .NET, Python, COBOL, with databases, Postgres, Snowflake, Apache Pinot, all those good things.</p>

<p>There was an article on InfoQ, which was the most read article for the first six months of the year, about this. There also was this guy, I didn't know him, Prime, a popular YouTuber. He also covered this on his stream. What did I do then? I learned how to print 162 PDF files and send them out to people with their individual certificate of achievement. I learned how to send coffee mugs and T-shirts to people all around the world, because I wanted to give out some prices. I sent those things to Taiwan, South America, the Republic of South Korea, and so on. That was what happened during January.</p>

<p>Who am I? I work as a software engineer at a company called Decodable. We built a managed platform for stream processing based on Apache Flink. This thing is completely a side effort for me. It was a private thing, but then Decodable helped to sponsor it and supported me with doing that.</p>

<h2>The Goals</h2>

<p>What was the idea behind this? Why did I do this? I thought I would like to learn something new. There's all those new Java versions every six months. They come with new APIs, new capabilities. It's really hard to keep track of all those developments. I would like to know what's new in those new Java versions, and what can I do with those things? I wanted to learn about it, but also, I wanted to give the community an avenue to do that so that everybody can learn something new. Then, of course, you always want to have some fun. It should be a cool thing to do. You don't want to just go and read some blogs. You would like to get some hands-on experience.</p>

<p>Finally, also, the idea was to inspire others to do the same. This was the thing, which I think was a bit specific about this challenge, you could actually go and take inspiration from other people's implementations. Nothing was secret. You could go and see what they did, and be inspired by them. Obviously, you shouldn't just take somebody else's code and submit it as your own implementation. That would make much sense. You could take inspiration, and people actually did that, and they teamed up in some cases. The other motivation for that was, I wanted to debunk this idea, which sometimes people still have, Java is slow, and nothing could be further from the truth, if you look at modern versions and their capabilities. Still, this is on people's minds, and I wanted to help and debunk this. As we will see, I think that definitely was the case.</p>

<h2>How Did it Work?</h2>

<p>Let's get a bit into it. How did it work? You can see it all here in this picture. The idea was, we have a file with temperature measurements, and it's essentially like a CSV file, only that it wasn't a comma as a separator, but a semicolon with two columns, and a station name, like Hamburg or Munich, and so on. Then, a temperature measurement value associated to that, randomized values. The task was, process that file, aggregate the values from that file, and for each of those stations, determine the minimum value, the maximum value, and the average temperature value. Easy. Then the caveat only was, this has 1 billion rows as the name of the challenge gives away.</p>

<p>This file, if you generate this on your machine, it has a size of around 13 gigabytes, so quite sizable. Then you had to print out the results, as you can see it here. This already goes to show a little bit that I didn't spend super much time to prepare this, because this is just the two-string output of the Java HashMap implementation. Random to have this as the expected output. Then as people were implementing this, for instance, with relational databases, they actually went to great lengths to emulate that output format. I should have chosen a relational output format, next time.</p>

<h2>The Rules</h2>

<p>A little bit more about the rules. First of all, this was focused on Java. Why? It's the platform I know best, I would like to support. This is also what I wanted to spread the knowledge on. Then you could choose any version. Any new versions, preview versions, all the kinds of distributions, like GraalVM, or all the different JDK providers which are out there. You managed using this tool called SDKMAN. Who has heard about SDKMAN? You should go and check out SDKMAN, and you should use it to manage Java versions. It's a very nice tool for doing that, and switching back and forth between different versions. That's it. Java only. No dependencies.</p>

<p>It wouldn't make much sense to pull in some library and do the task for you. You should program this by yourself. No caching between runs. I did five runs of each implementation. Then I discarded the fastest and the slowest one, and I took the average value from the remaining three runs. It would make sense to have any caching there. Otherwise, you could just do the task once, persist the result in the file, read it back, and it would be very fast. That doesn't make much sense. You were allowed to take inspiration by others. Of course, not again, just resubmit somebody else's implementation. You could take inspiration.</p>

<h2>Evaluation Environment</h2>

<p>In terms of how I ran this. My company spent ‚Ç¨100 on this machine which I got on the Hetzner cloud. Very beefy server with 32 cores, out of which I mostly used only 8 cores, I will explain later on. Quite a bit of RAM. Really, the file was always coming from a RAM disk. I wanted to make sure that disk I/O is not part of the equation, just because it's much less predictable, would have made the life much harder for me. Only a purely CPU bound problem here. How would we go and do this? This is my baseline implementation. I'm an average Java developer, so that's what I came up with. I use this Java Streams API. I use this files.lines method, which gives me a stream with the lines of a file. I read that file from disk, then I map each of my lines there using the split method. I want to separate the station name from the value. Then I collect the results, the lines into this grouping collector. I group it by the station name.</p>

<p>Then for each of my stations, I need to aggregate those values, which happens here in my aggregator implementation. Whenever a new value gets added to an existing aggregator object, I keep track of the min, the max, and in order to calculate average I keep track of the sum and the count of the values. Pretty much straight forward. That's adding a line. Then, if I run this in parallel, I would need to merge two aggregators. That's what's happening here. Again, pretty much straight forward. Finally, if I'm done, I need to reduce my processed results, and I emit such a result through object with the min, the max value. Then, for the average, I just divide sum by count, and I print it out. On this machine, this ran in about five minutes. Not super-fast, but also not terribly bad. Writing this code, it took me half an hour or maybe less. It's decent. Maybe, if you were to solve this problem in your job, you might call it a day and just go home, have a coffee and be done with it. Of course, for the purpose of this challenge, we want to go quite a bit faster and see how much we can move the needle here.</p>

<h2>The First Submission</h2>

<p>With this challenge, the important thing is somebody has to come and participate. That was a bit my concern like, what happens if nobody does it? It would be a bit embarrassing. Roy Van Rijn, another Java champion from the Netherlands, he was instantly interested in this, and an hour later or so, after I had put out the post, he actually created his own first implementation, and it wasn't very fancy or very elaborate. His idea just was, I want to be part of it. I want to put out a submission so other people can see, this is something we also could do. This was really great to see, because as soon as the first person comes along and takes part, then also other people will come along and take part. Of course, he kept working on that. He was one of the most active people who iterated on his implementation, but he was the very first one to submit something.</p>

<h2>Parallelization</h2>

<p>Let's dive a little bit into the means of what you can do to make this fast. People spent the entire month of January working on this, and they went down to a really deep level, essentially counting CPU instructions. My idea is, I want to give you some ideas of what exists, what you can do. Then maybe later on, if you find yourself in that situation where you would like to optimize certain things, then you might remember, I've heard about it. Then you could go and learn really deep. That's the idea.</p>

<p>Let's talk about parallelization, first of all, because we have many CPU cores. On my server, which I use to evaluate it, I have 32 cores, 64 with hyperthreading. We would like to make use of that. Would be a bit wasteful to just use a single core. How can we go about this? Going back to my simple baseline implementation, the first thing I could do is I could just say, let me add this parallel call, so this part of the Java Streams API.</p>

<p>Now this will process this pipeline, or I should say, part of this streaming pipeline in parallel. Just doing this, just adding this single method call, gets us down to 71 seconds. From 4 minutes 50 seconds, to 71 seconds by just adding a few characters for one method call. I think that's a pretty good thing. Very easy win. Of course, that's not all we can do. In particular, if you think about it, yes, it gets us down by quite a bit, but it's not eight times faster than what we had initially, but we have 8 CPU cores which I'm using here. Why is it not eight times faster? This parallel operator, this applies to the processing logic. All this aggregating and grouping logic, this happens in parallel, but this reading of the file from memory, this still happens sequentially.</p>

<p>The entire file, the reading part, that's sequentially, and we have still all our other CPU cores sitting idle, so we would like to also parallelize that. This comes back then to this notion that I would like to go out and learn something new, because all those new Java versions, they come with new APIs, the JEPs, the Java Enhancement Proposals. One of them, which was added recently, is the foreign function and memory API. You can see it here, so that's taken straight from the JEP, but essentially, it's a Java API which allows you to make use of native methods.</p>

<p>It's a replacement, much easier to use than the old JNI API. It also allows you to make use of native memory. Instead of the heap, which is managed by the JVM, you get the ability to manage your own memory section, like an off-heap memory, and you will be in charge of maintaining that, and making sure you free it, and so on. That's what we would like to use here, because we could memory map this file and then process it there in parallel. Let's see how we can go about that.</p>

<p>I mentioned there's a bit of code, but I will run you through it. That's a bit of a recurring theme. The code you will see, it gets more dense as we progress. Again, you don't really have to understand everything. I would like to give you a high-level intuition. What do we do here? First of all, we determine the degree of parallelism. We just say, how many CPU cores do we have? Eight in our case, so that's our degree of parallelism. Next, we want to memory map this file. You could have memory map files also in earlier Java versions, but for instance, you had size limits. You couldn't memory map an entire 13-gig file all at once, whereas now here with the new foreign memory API, that's possible. We can do this. You map the file. We have this Arena object there. This is essentially our representation of this memory. There's different kinds of Arenas. In this case, I'm just using this global Arena which just exists and is accessible from everywhere within my application. That's where I have that file, and now I can access that entire section of memory in parallel using multiple threads.</p>

<p>In order to do so, we need to split up that file and the memory representation. That's what happens here. First of all, roughly speaking, we divide into eight equal chunks. We take our entire size divided by eight. That's our estimate of chunk sizes. Now, of course, what would happen is, in all likelihood, we will end up in the middle of a line. This is not really desirable, where, ideally, we would like to have our worker processes, they should work on entire lines. What's happening here is, we went to roughly one-eighth of the file, we just keep going to the next line ending character. Then we say, that's the end of this chunk, and the starting point of the next chunk. Then we process those chunks, essentially, just using threads. We will see later on how to do this. We start our threads, we join them. In the end, we've got to wait. Now this parallelizes the entire thing.</p>

<p>Now we really make use of all our 8 cores for the entire time, also while we do the I/O. There's one caveat. Just by the nature of things, one of those CPU cores will always be the slowest. At some point, all the other seven, they will just wait for the last one to finish, because it's a little bit unequally distributed. What people, in the end, did, instead of using 8 chunks, they split up this file in much smaller chunks. Essentially, they had a backlog of those chunks. Whenever one of those worker threads was done with the current chunk, it would go and pick up the next one.</p>

<p>By that, you make sure that all your 8 threads are utilized equally all the time. The ideal chunk size, as it turned out, was 2 megabytes. Why 2 megabytes? This specific CPU, which is in this machine which I used, it has a second level cache size of 16 megabytes, 8 threads processing 2 megabytes at a time. It's just the best in terms of predictive I/O and so on. This is what people found out. This already goes to show, we really get down to the level of a specific CPU and the specific architecture to really optimize for that problem by doing those kinds of things. That's parallel I/O.</p>

<h2>1BRC - Mythbusters, and Trivial Task?</h2>

<p>This challenge, it was going, people were participating. They had a good time. Of course, whenever something happens, there's also conspiracy theories. That's what I fear. People said, is this actually an engineering problem? At Decodable, you had this problem and you didn't know how to do it, so you farmed it out to the community. I can tell you, this would have been the most silly thing I could have done, because I created so much work by running this challenge for myself. I didn't do much besides it during the entire month of January. It was not that. It was just a genuine thing, which I felt would be interesting to me and the community. Was it an add for GraalVM? Because many people actually used GraalVM, and we will see later on more about it. Also, no. It was just like GraalVM lends itself really well towards that problem. Finally, is it an add for this AMD EPYC processor? Also, no.</p>

<p>Really, no conspiracies going on here. Who is on Hacker News? I read Hacker News way too often. Of course, you always have the Hacker News guy who says, that's a trivial problem. Everybody who knows how to program just a little bit, they will have solved this in two hours, and it's like a boring thing. Then, on the other hand, you have all the people from the Java community, and also, big names like Thomas W√ºrthinger, who is the engineering lead at GraalVM, or Cliff Click, who was one of the original people behind the JVM, or Aleksey Shipilev, and all those people, they spend the entire month of January doing this. Of course, the Hacker News dude, he does it in two hours. Always interesting to see.</p>

<h2>Parsing</h2>

<p>Let's dive a little more into parsing that. We have seen how to make use of our CPU cores, but what actually happens there to process a line? Let's take a closer look at that. If we want to get away from what we had initially with just splitting up the file using regex and so on, that's not very efficient. Let's see what we can do here. That's, again, something I would be able to come up with just processing those input lines, character by character. What's happening here is, we have a little bit of a state machine. We read our characters. We keep reading the line until it has no more characters. Then we use the semicolon character which separates our station name from the temperature value to switch these states. Depending on which state we are, so do we either read the bytes which make up the station name, or do we read up the bytes which make up the measurement value? We need to add them into some builder or buffer which aggregates those particular values.</p>

<p>Then, if we are at the end of a line, so we have found the line ending character, then we need to consume those two buffers for the station and for the measurement, which we have built up. For the measurement, we will need to see how we convert that into an integer value, because that's also what people figured out. The problem was described as a double or a floating-point arithmetic, so with values like 21.7 degrees, but then again, randomly, I always only had a single fractional digit. People realized, this data actually, it always only has a single fractional digit. Let's take advantage of that and just consider that as an integer problem by just multiplying the number by 100, for the means of calculation. Then at the end, of course, divide it by 100, or by 10. That's something which people did a lot, and which I underestimated how much they would take advantage of the particular characteristics of that dataset.</p>

<p>For that conversion, we can see it here, and it makes sense, so we process or we consume those values. If we see the minus character, we negate the value. If we see the first one of our two digits, we multiply it by 100 or by 10. That's how we get our value there. Doing that, it gets us down to 20 seconds. This is already an order of magnitude faster than my initial baseline implementation. So far, nothing really magic has happened. One takeaway also for you should be, how much does it make sense to keep working on such a thing? Again, if this is a problem you're faced with in your everyday job, maybe stop here. It's well readable, well maintainable. It's an order of magnitude faster than the native baseline implementation, so that's pretty good.</p>

<p>Of course, for the purposes of this challenge, we probably need to go a bit further. What else can we do? We can, again, come back to the notion of parallelism and try to process multiple values at once, and now we have different means of parallelization. We already saw how to make the most out of all our CPU cores. That's one degree of parallelism. We could think about scaling out to multiple compute nodes, which is what we typically would do with our datastores. For that problem, it's not that relevant, we would have to split up that file and distribute it in a network. Maybe not that desirable, but that would be the other end of the spectrum. Whereas we also can go into the other direction and parallelize within specific CPU instructions. This is what happens here with SIMD, Single Instruction, Multiple Data.</p>

<p>Essentially all these CPUs, they have extensions which allow you to apply the same kind of operation onto multiple values at once. For instance, here, we would like to find the line ending character. Now, instead of comparing byte by byte, we can use such a SIMD instruction to apply this to 8 or maybe 16, or maybe even more bytes at once, and it will, of course, speed up things quite a bit. The problem is, in Java, you didn't really have a good means to make use of those SIMD instructions because it's a portable, abstract language, it just wouldn't allow you to get down to this level of CPU specificity. There's good news.</p>

<p>There's this vector API, which is still incubating, I think, in the eighth incubating version or so, but this API allows you now to make use of those vectorized instructions at extensions. You would have calls like this compare call with this equal operator, and then this will be translated to the right SIMD instruction of the underlying architecture. This would translate to the Intel or AMD64 extensions. Also, for Arm, it would do that. Or it would fall back to a scalar execution if your specific machine doesn't have any vector extensions. That's parallelization on the instruction level. I did another talk about it, https://speakerdeck.com/gunnarmorling/to-the-moon-and-beyond-with-java-17-apis, which shows you how to use SIMD for solving FizzBuzz.</p>

<p>Sticking to that pattern, applying the same operation to multiple values at once, we also can do what's called SWAR, SIMD Within A Register. Again, I realize, the code gets more dense. I probably wouldn't even be able right now to explain each and every single line, or it would take me a while. The idea here is, this idea of doing the same thing, like equals to multiple values all at once, we also can do this within a single variable. Because if you have 8 bytes, we also could see one long, that's 64 bits, that's also 8 bytes. We can apply the right level of bit level magic to a long value, and then actually apply this operation to all the 8 bytes. It's like bit level masking and shifting, and so on. That's what's happening here. There's a very nice blog post by Richard Startin, which shows you, step by step, how to do this, or how to use this to find the first zero byte in a string.</p>

<p>I have put the math up here on the right-hand side, so you actually can go and follow along, and you will see, this actually gives you the first zero byte in a long like that. That's SIMD Within A Register, SWAR. Now the interesting thing is, if you look at this code, something is missing here. Is somebody realizing what we don't have here? There's no ifs, there's no conditionals, no branching in that code. This is actually very relevant, because we need to remember how our CPUs actually work. If you look at how a CPU would take and go and execute our code, it always has this pipelined approach. Each instruction has this phase of, it's going to be fetched from memory, it's decoded, it's executed, and finally the result is written back. Now actually multiple of those things happen in parallel. While we decode our one instruction, the CPU will already go and fetch the next one. It's a pipelined parallelized approach.</p>

<p>Of course, in order for this to work, the CPU actually needs to know what is this next instruction, because otherwise we wouldn't know what to fetch. In order for it to know, we can't really have any ifs, because then we wouldn't know, which way will we go? Will we go left or right? If you have a way for expressing this problem in this branchless way, as we have seen it before, then this is very good, very beneficial for what's called the branch predictor in the CPU, so it always knows which are the next instructions. We never have this situation that we actually need to flush this pipeline because we took a wrong path in this predictive execution. Very relevant for that. I didn't really know much about those things, but people challenged it. One of the resources they employed a lot is this book, "Hacker's Delight". I recommend everybody to get this if this is interesting to you. Like this problem, like finding the first zero byte in a string, you can see it here. All those algorithms, routines are described in this book. If this is the thing which gets you excited, definitely check out, and get this book.</p>

<h2>Then, Disaster Struck</h2>

<p>Again, people were working on the challenge. It was going really well. They would send me pull requests every day, and I didn't expect that many people to participate. That's why I always went to the server and executed them manually. At some point, someday I woke up, I saw, that's the backlog of implementations which people had sent over the night, so let's say 10 PRs to review and to evaluate, and suddenly all those results were off. It was like twice as fast as before. I ran one of the implementations which I had run on the day before, and suddenly it was much faster. I was wondering, what's going on? What happened is, this workload, I had it initially on a virtual server. I thought, I'm smart. I try to be smart, so I get dedicated virtual CPU cores, so I won't have any noisy neighbors on that machine, this kind of thing.</p>

<p>What I didn't expect is that they would just go and move this workload to another machine. I don't know why. Maybe it was random. Maybe they saw there was lots of load in that machine. In any case, it just got moved to another host, which was faster than before. This, of course, was a big problem for me, because all the measurements which I had done so far, they were off and not comparable anymore. That was a problem. I was a bit desperate at that point in time. This is where the wonders of the community really were very apparent. Good things happened. I realized, I need to get a dedicated server so that this cannot happen again. I need to have a box, which I can use exclusively. As I was initially paying out of my own pocket for that, I thought, I don't want to go there. I don't want to spend ‚Ç¨100. As I mentioned, Decodable, my employer, they stepped up to sponsor it.</p>

<p>Then, of course, I also needed help with maintaining that, because I'm not the big operations guy. I know a little bit about it. Then for that thing, you would, for instance, like to turn off the hyperthreading, or you would like to turn off turbo boost to have stable results. I wasn't really well-versed in doing those things, but the community came to help. In particular, Ren√© came to help. He offered his help to set up the thing. We had a call. I spoke to him. I had not known him. It was the first time I ever spoke to him, but we had a great phone conversation. In the end, he just sent me his SSH key. I uploaded his key to the machine, gave him the key to the kingdom, and then he was going and configuring everything the right way. There were multiple people, many people like that, who came and helped, because otherwise I just could not have done it.</p>

<h2>The 1BRC Community</h2>

<p>All this was a bit of a spontaneous thing. Of course, I put out some rules and how this should work. Then, I wasn't very prescriptive. Like, what is the value range? How long could station names be? What sort of UTF character planes and whatnot? I didn't really specify it. Of course, people asked, how long can a station name be? What kinds of characters can it contain, and so on? We had to nail down the rules and the boundaries of the challenge. Then people actually built a TCK, a test kit. It was actually a test suite which you then had to pass. Not only you want to be fast, you also want to be correct. People built this test suite, and it grew, actually, over time. Then whenever a new submission, a new entry came in, it, first of all, had to pass those tests. Then if it was valid, then I would go and evaluate it and take the runtime. This is how this looked like. You can see it here.</p>

<p>It had example files with measurements, and an expected file, what should be the result for that file? Then the test runner would go process the implementation against that set of files, and ensure that result is right. That's the test kit. The other thing, which also was very important as well, I had to run all those things on that machine. There's quite a few things which were related to that, like just making sure the machine is configured correctly. Then, I had five runs, and I want to discard fastest and slowest, all those things. Jason, here, he came to help and scripted all that. It was actually very interesting to see how he did it. I would really recommend to go to the repo, and just check out the shell scripts which exist, which are used for running those evaluations. It's a bit like a master class in terms of writing shell scripts, with very good error handling, colored output, all this good stuff to make it really easy and also safe to run those things. If you have to do shell scripting, definitely check out those scripts.</p>

<h2>Bookkeeping</h2>

<p>Then, let's talk about one more thing, which is also very relevant, and this is what I would call bookkeeping. If you remember the initial code I showed, I had this Java Streams implementation, and I used this collector for grouping the values into different buckets, per weather station name. People realized, that's another thing which we can optimize a lot ourselves. By intuition, you would use a HashMap for that. You would use the weather station name as the key in that HashMap. Java HashMap is a generic structure. It works well for a range of use cases. Then, if we want to get the most performance for one particular use case, then we may be better off implementing a bespoke, specific data structure ourselves. This is what we can see here. I think it might sound maybe scary, but actually it is not scary. It's relatively simple. What happens here? We say, we would like to keep track of the measurements per our station name. It's like a map, but it is backed by an array, so those buckets.</p>

<p>The idea now is, we take the hash key of our station name and we use this as the index within that array, and at that particular slot in the array, we will manage the aggregator object for a particular station name. We take the hash code, and we want to make sure we don't have an overflow. That's why we take it with logical end with the size of the array. We always have it well indexed in the array. Then we need to check, at that particular position in the array, is something there already? If nothing is there, that means, we have the first instance of a particular station in our hands, so the first value for Hamburg or the first value for Munich. We just go create this aggregator object there and store it at that particular offset in the array. That makes sense. The other situation, of course, is we go to the particular index in the array, and in all likelihood, something will be there already. If you have another value for the same station, something will be there already.</p>

<p>The problem is we don't know yet, is this actually the aggregator object for that particular key we have in our hands, or is it something else? Because multiple station names could have the same key. Which means, in that case, if something exists already at this particular array slot, you need to fall back and compare the actual name. Only if the incoming name is also the name of the aggregate object in that slot, then we can go and add the value to that. That's why it's called linear probing. Otherwise, we will just keep iterating in that array until we either have found a free slot, so then we can go install it there, or we have found the slot for the key which we have in our hands. I think it's relatively simple. Now for this particular case, this performs much better, actually, than what we could get with just using Java HashMap.</p>

<p>Of course, it depends a lot on the particular hash function here which we use to find that index. This is where it goes back to people really optimized a lot for the particular dataset, so they used hash functions which would be collision free for the particular dataset. This was a bit against what I had in mind, because the problem was this file, as I mentioned, it has a size of 13 gigabytes, and I just didn't have a good way for distributing 13 gigabytes to people out there. That's why, instead, they would have to generate it themselves. I had the data generator, and everybody could use this generator to create the file for themselves and then use it for their own testing purposes. The problem was, in this data generator, I had a specific key set. I had around 400 different station names with the idea being, that's just an example, but people took it very literally, and they optimized then a lot for those 400 station names. They used hash functions, which would not have any collisions, for those 400 names. Again, people will take advantage of everything they can.</p>

<p>The problem with all that is it also creates lots of work for me, because you cannot really prove the absence of hash collisions. Actually, whenever somebody sent in their implementation, I had to go and check out, do they actually handle this case, the two stations which would create the same key, and do they handle those collisions accordingly? Because otherwise, if you don't do this fall back to the slow case, you would be very fast, but you would be incorrect because you don't deal correctly with all possible names. This was a bit of a trap, which I set up for myself, and it meant I always had to check for that and actually ask people in the pull request template, if you have a custom map implementation, where do you deal with collisions? Then we would have conversations like we see here. How do you deal with hash collisions? I don't, that's why it's so fast. Then he would go and rework it. A big foot trap for myself.</p>

<h2>GraalVM: JIT and AOT Compiler</h2>

<p>Those are three big things, parallelization, then all this parsing with SIMD and SWAR, and custom hashmapping for bookkeeping. Those were recurring themes I saw again. Then there were more specific tricks, and I just wanted to mention a few of them. I just want to give you some inspiration of what exists. One thing which exists is the Epsilon garbage collector, which is a very interesting garbage collector because it doesn't collect any garbage. It's a no-op implementation. If you have your regular Java application, that would be not a good idea. Because you keep allocating objects, and if you don't do any GC, you will run out of heap space at some point. Here, people realized, we can actually implement this in a way that we don't do any allocations on our processing loop. We'll do a few allocations initially when bootstrapping the program, but then later on, no more objects get created. We just have arrays which we can reuse, like mutable structures, which we can just update.</p>

<p>Then we don't need any garbage collection, and we don't need any CPU cycles to be spent on garbage collection, which means we just can be a bit faster. Again, I think that's an interesting thing. Maybe, for instance, if you work on some CLI tool, short-lived thing, could be an interesting option to just disable the garbage collector and see how that goes. The other thing, which you can see here is people used a lot GraalVM. GraalVM, it's two things, really. It's an ahead-of-time compiler, so it will take your Java program and emit a native binary out of it. This has two essential advantages. First of all, it uses less memory. Secondly, it's very fast to start because it doesn't have to do class loading and the compilation and everything, this all happens at build time. This is fast to start if you have this native binary. Now to the level of results we got here, this actually mattered.</p>

<p>Initially, I thought saving a few hundred milliseconds on startup won't make a difference for processing 13 gigabytes of file, but actually it does make a difference. The AOT compiler and most of the fastest implementations, they actually used the AOT compiler with GraalVM. There's also the possibility to use this as a replacement for the just-in-time compiler in your JVM. You just can use it as a replacement for the C2 compiler. I'm not saying you should always do this. It depends a little bit on your particular workload and what you do, whether it's advantageous or not. In this case, this problem, it lends itself very well to that. People just by using GraalVM as the JIT compiler in the JVM, this gave them a nice improvement of like 5% or so. It's something I can recommend for you to try out, because it's essentially free. You just need to make sure you use a JVM or a Java distribution which has GraalVM available as the C2 compiler replacement. Then it's just means of saying, that's the JIT compiler I want to use, and off you go. Either it does something for you or does not.</p>

<h2>Further Tricks and Techniques</h2>

<p>A few other things, like unsafe, what I found interesting is the construct here on the right-hand side, because if you look at that, this is our inner processing loop. We have a scanner object. We try to take next values. We try to process them, and so on. What we have here is we have the same loop three times in a program which is written up in a sequential way. If you look at it, you would say, those three loops, they run one after another. What actually happens is, as the CPUs have multiple execution units, the compiler will figure out, this can actually be parallelized, because there is no data dependencies between those loops. This is what happens, we can take those loops and run them concurrently. I found it very interesting. Why is it three times? Empirically determined.</p>

<p>Thomas, who came up with this, he tried it two times. He tried to have the loop four times and three times it was just the fastest on that particular machine. It could be different in other machines. Of course, you see already here with all those things, this creates questions around maintainability. Because I already can see the junior guys joining the team, and they're like, "That's duplication. It's like the same code three times. Let me go and refactor it. Let me clean it up", and your optimization would be out of the window. You would want to put a comment there, don't go and refactor it into one loop. That's the consideration. Are those things worth it? Should you do it for your particular context? That's what you need to ask. I found this super interesting, that this is a thing.</p>

<h2>The Results</h2>

<p>You are really curious then, how fast were we in the end? This is the leaderboard with those 8 CPU cores I initially had. I had 8 CPU cores because that was what I had with this virtual server initially. When I moved to the dedicated box, I tried to be in the same ballpark. With those 8 cores, we went down to 1.5 seconds. I would not have expected that you could go that fast with Java, processing 13 gigabytes of input in 1.5 seconds. I found that pretty impressive. It gets better because I had this beefy server with 32 cores and 64 threads with hyperthreading. Of course, I would like to see, how fast can we go there? Then we go down to 300 milliseconds. To me, it's like doubly mind blowing. Super impressive. Also, people did this, as I mentioned, in other languages, other platforms, and Java really is very much at the top, so you wouldn't be substantially better with other platforms.</p>

<p>The other thing, there was another evaluation, which there was, because I mentioned I had this data generator with those 400-something station names, and people optimized a lot for that by choosing specific hashing functions and so on. Some people realized that actually, this was not my intention. I wanted to see, how fast can this be in general? Some people agreed with that view of the world. For those, we had another leaderboard where we actually had 10k different station names. As you can see here now, it's actually a bit slower, because you really cannot optimize that much for that dataset. Also, it's different people at the top here. If I go back, here we have Thomas W√ºrthinger, and people who teamed up with him for the regular key set, and then for the 10k key set, it's other people. It's different tradeoffs, and you see how much this gets specific for that particular dataset.</p>

<h2>It's a Long Journey</h2>

<p>People worked on that for a long time. Again, the challenge went through the entire month of January. I didn't do much besides running it really. People like Thomas, who was the fastest in the end, he sent 10 PRs. There were other people who sent even more. The nice thing was, it was a community effort. People teamed up. As I mentioned before, like the fastest one, it was actually an implementation by three people who joined forces and they took inspiration. When people came up with particular tricks, then very quickly, the others would also go and adopt them into their own implementation. It was a long journey with many steps, and I would very much recommend to check this out.</p>

<p>This is, again, the implementation from Roy Van Rijn, who was the first one, because he kept this very nice log of all the things he did. You see how he progressed over time. If you go down at the very bottom, you will see, he started to struggle a bit because he did changes, and actually they were slower than what he had before. The problem was he was running on his Arm MacBook, which obviously has a different CPU with different characteristics than the machine I was running this on. He saw improvements locally, but it was actually faster on the evaluation machine. You can see it at the bottom, he went and tried to get an Intel MacBook, to have better odds to do something locally, which then also performs better on that machine. I found it really surprising to see this happening with Java, that we get down to this level where the particular CPU and even its generation would make a difference here.</p>

<h2>Should You Do Any of This?</h2>

<p>Should you do any of this? I touched on this already. It depends. If you work on an enterprise application, I know you deal with database I/O most of the times. Going to that level and trying to avoid CPU cycles in your business code probably isn't the best use of your time. Whereas if you were to work on such a challenge, then it might be an interesting thing. What I would recommend is, for instance, check out this implementation, because this is one order of magnitude faster than my baseline. This would run 20 seconds or so. It's still very well readable, and that's what I observed, like improving by one order of magnitude. We have still very well readable code. It's maintainable.</p>

<p>You don't have any pitfalls in this. It just makes sense. You are very much faster than before. Going down to the next order of magnitude, so going down to 1.5 seconds, this is where you do all the crazy mid-level magic, and you should be very conscious whether you want to do it or not. Maybe not in your regular enterprise application. If you participate in a challenge you want to win a coffee mug, then it might be a good idea. Or if you want to be hired into the GraalVM team, I just learned this the other day, actually, some person who goes by the name of Mary Kitty in the competition, he actually got hired into the GraalVM compiler team at Oracle.</p>

<h2>Wrap-Up, and Lessons Learned</h2>

<p>This was impacting the Java community, but then also people in other ecosystems, databases, in Snowflake they had a One Trillion Row Challenge. This really blew up and kept people busy for quite a while. There was this show and tell in the GitHub repo. You can go there and take a look at all those implementations in Rust, and OCaml, and all the good things I've never heard about, to see what they did in a very friendly, competitive way. Some stats, you can go to my blog post there, you will see how many PRs, and 1900 workflow runs, so quite a bit of work, 187 lines of comment in Aleksey's implementation. Really interesting to see. In terms of lessons learned there, if I ever want to do this again, I would have to be really prescriptive in terms of rules, automate more, and work with the community as it happened already today. Is Java slow? I think we have debunked that. I wouldn't really say so. You can go very fast. Will I do it again next year? We will see. So far, I don't really have a good problem which would lend itself to doing that.</p>




<p><big><strong>See more <a href="https://www.infoq.com/transcripts/presentations/">presentations with transcripts</a></strong></big></p>



                                </div></div>]]></description>
        </item>
    </channel>
</rss>