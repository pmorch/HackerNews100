<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 23 Apr 2025 14:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[MinC Is Not Cygwin (137 pts)]]></title>
            <link>https://minc.commandlinerevolution.nl/english/home.html</link>
            <guid>43770445</guid>
            <pubDate>Wed, 23 Apr 2025 10:21:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minc.commandlinerevolution.nl/english/home.html">https://minc.commandlinerevolution.nl/english/home.html</a>, See on <a href="https://news.ycombinator.com/item?id=43770445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section>
<article>
<p>Welcome to the MinC home page. MinC is a Unix emulator for Windows, based on the OpenBSD operating system.
MinC was written to help children at vocational education learn Linux without the hassle of virtualization. 
It runs on all versions of Windows, except Win95 and Win98.
</p>
<p>MinC is a tiny kernel which runs on Windows. The rest of the software was 
taken verbatim from OpenBSD, version 6.1. This means that by installing MinC, 
you run OpenBSD on your Windows machine at native speed.
</p>
</article>
<article>
<img src="https://minc.commandlinerevolution.nl/_images/ppuf1000X907_small.png" width="96" alt="Puffy, the OpenBSD mascotte" title="Puffy"></article>
</section>

<section>

<article>
<h2>Install</h2>
<p>To install MinC you no longer have to copy it "by hand". You can now use the new installation
wizard. Download the current version by clicking the link:
<a href="https://minc.commandlinerevolution.nl/minc-6.1.exe">minc-6.1.exe</a> (20Mb).
</p>
<img src="https://minc.commandlinerevolution.nl/_images/Installer-1.0_10.png" width="288"><p>After installation you will see a new icon called <b>Console</b> on your Desktop.
This starts the MinC terminal.
</p>
</article>

<article>
<h2>Use</h2>
<p>The current MinC realease contains the following functions:
</p>
<ul>
<li>All Unix standard commands, like: ls, du, ps, df, find, grep, awk, mkdir, chmod, 
chown, wc, top, diff, etc.
</li><li>Editing: less, vi, nano, hexedit
</li><li>Compression: unzip, gzip, bzip2, xz
</li><li>Networking: route, ifconfig, ping, ftp, ssh, scp, telnet, wget, curl, lynx, mutt, BitchX
</li><li>Development: vim, git, ImageMagick
</li></ul>
<p>Services and daemons, like Apache (httpd), Sendmail and sshd are not yet available, 
but will be released as soon as possible.
</p>
<p>If you like to compile code for MinC, you can install the toolchain: 
<a href="https://minc.commandlinerevolution.nl/buildtools-6.1.exe">buildtools-6.1.exe</a> The package contains BSD libc, GNU 
binutils, GNU cc, GNU make, vim and git.
</p>
</article>

<article>
<h2>Donate</h2>
<p>Writing the kernel took a lot of time. To help me finish MinC, you can make a donation
via PayPal. Any amount is welcome.
</p>

<p>Let me know if you wish to have a particular software included in the next release.
Send an e-mail to dboland@xs4all.nl.
</p>
</article>

<article>
<h2>Antivirus</h2>
<p>MinC works well with antivirus software, such as the built-in
<b>Windows Defender</b> or <b>Kaspersky</b>.
</p>
<p>In some cases you need to temporarily disable antivirus before downloading and 
installing (<a target="_blank" href="https://support.kaspersky.com/KIS/21.2/en-US/70886.htm" title="How to pause and resume computer protection">Kaspersky</a>). After that, MinC works fine.
</p>
<p>In other cases, MinC installs well, but the antivirus does not let you 
run its programs. You need to exclude the MinC root directory from scanning 
(<a target="_blank" href="https://help.f-secure.com/product.html#home/total-windows/latest/en/allow_program_on_sys_control_blocklist_to_run-latest-en" title="Allowing blocked applications">f-secure</a>).
</p>
</article>

<article>
<h2>Visual Studio</h2>
<p>MinC can be integrated into <b>MS Visual Studio Code</b> as a terminal.
Put following snippet in your personal settings.json file:
</p>
<pre>"terminal.integrated.profiles.windows": {
   "MinC": {
      "path": "<u>C:\\MinC</u>\\sbin\\bsd.exe"
   }
}
</pre>
<p>If you installed MinC at another location, make sure 
the underlined part is correct.
</p>
</article>

</section>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[America's cyber defenses are being dismantled from the inside (281 pts)]]></title>
            <link>https://www.theregister.com/2025/04/23/trump_us_security/</link>
            <guid>43770382</guid>
            <pubDate>Wed, 23 Apr 2025 10:10:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/04/23/trump_us_security/">https://www.theregister.com/2025/04/23/trump_us_security/</a>, See on <a href="https://news.ycombinator.com/item?id=43770382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> We almost lost the Common Vulnerabilities and Exposures (CVE) database system, but that's only the tip of the iceberg of what President Trump and company are doing to US cybersecurity efforts.</p>
<p>When it comes to technology security, let's face it. We're lame and we're lazy. But we don't normally go out of our way to make it worse. Until now. Until President Donald Trump and his cohort of tech minions, better known as Elon Musk's Department of Government Efficiency (DOGE), took over.</p>
<p>You might think, if you're outside the US, who cares? Unfortunately, whether you like it or not, the US has long taken the lead in technical security.</p>

    

<p>Take, for example, the fact that we <a target="_blank" href="https://www.theregister.com/2025/04/16/homeland_security_funding_for_cve/">almost lost the Common Vulnerabilities and Exposures (CVE) database</a>. Anyone familiar with cybersecurity will have heard of the CVE. It's the master list of essentially all security holes for the last 25 years.</p>

        


        

<p>As Jen Easterly, former director of the Cybersecurity and Infrastructure Security Agency (CISA), explained on LinkedIn: "It's the global catalog that helps everyone – security teams, software vendors, researchers, governments – organize and talk about vulnerabilities using the same reference system."</p>
<p>Without it, everyone is using a different catalog or no catalog at all, no one knows if they're talking about the same problem, and defenders waste precious time figuring out what's wrong. Worst of all, threat actors take advantage of the confusion.</p>

        

<p>How could such an important project go under? Easily. It wasn't funded. The group that oversees the CVE, CISA, had been targeted for staff cuts of over a third of its employees. In addition, CISA employees were given until midnight Monday to choose between <a target="_blank" rel="nofollow" href="https://www.govinfosecurity.com/cisa-braces-for-major-workforce-cuts-amid-security-fears-a-27996">staying on the job or resigning</a>. So it was that the decision to <a target="_blank" href="https://www.theregister.com/2025/04/16/cve_program_funding_save/?td=rt-3a">extend the MITRE CVE contract didn't come until literally the 11th hour</a>.</p>
<p>That contract will still run out in March 2026. Who knows if Trump et al will extend it again? Once upon a time, this kind of decision would be a no-brainer. I mean, all technology security, for better or worse, depends on the CVE system. Now? Your guess is as good as mine.</p>
<p>You can't depend on guesses when it comes to security.</p>

        

<p>The Trump administration's tenure, though, has already been marked by significant setbacks to US federal government technology security efforts, over and over again.</p>
<p>For example, General Timothy D. Haugh, the head of the National Security Agency (NSA) and US Cyber Command, was <a target="_blank" href="https://www.theregister.com/2025/04/04/nsa_boss_deputy_fired/">fired in early April</a>. General Haugh was a pivotal figure in defending the nation's cyber infrastructure, especially noted for countering Russian interference dating back to the 2016 election. His dismissal, along with the removal of other senior cyber officials, has significantly weakened the country's cyber defense. Why? What was his offense? Laura Loomer, a far-right conspiracy theorist and Trump buddy, disliked him.</p>
<p>The administration has also systematically dismantled critical cybersecurity advisory bodies. Notably, the Cyber Safety Review Board (CSRB), established under the previous Biden administration to investigate major cyber incidents, was effectively disbanded by terminating all its members. This <a target="_blank" href="https://www.theregister.com/2025/01/22/dhs_axes_cyber_advisory_boards/">move halted</a> investigations into significant cyberattacks, including the Chinese "Salt Typhoon" hacks.</p>
<p>Mind you, the Salt Typhoon attacks were also aimed at Trump and VP JD Vance, but for some reason, don't ask me why, they don't care. We already know that Trump is buddy-buddy with Russia, but China? The country he's having a major trade war with? This makes no sense to me.</p>
<p>So, who should be in charge of protecting the US's cyber resources? The state and local governments, would you believe?</p>
<p>According to Trump's <a target="_blank" rel="nofollow" href="https://www.whitehouse.gov/presidential-actions/2025/03/test/">Achieving Efficiency Through State and Local Preparedness</a> executive order: "Preparedness is most effectively owned and managed at the State, local, and even individual levels, supported by a competent, accessible, and efficient Federal Government. Citizens are the immediate beneficiaries of sound local decisions and investments designed to address risks, including cyberattacks, wildfires, hurricanes, and space weather."</p>
<ul>

<li><a href="https://www.theregister.com/2025/04/14/miyazaki_ai_and_intellectual_property/">It's fun making Studio Ghibli-style images with ChatGPT – but intellectual property is no laughing matter</a></li>

<li><a href="https://www.theregister.com/2025/02/07/opinion_column_musk/">Musk's move fast and break things mantra won't work in US.gov</a></li>

<li><a href="https://www.theregister.com/2025/01/28/windows_10_demise_linux/">Windows 10's demise nears, but Linux is forever</a></li>

<li><a href="https://www.theregister.com/2025/01/11/opinion_column_us_moves/">Is it really the plan to take over Greenland and the Panama Canal? It's been a weird week</a></li>
</ul>
<p>Part of that clearly sets the stage for getting rid of the Federal Emergency Management Administration (FEMA), but space weather!? Cyberattacks!!? Do you know how few real IT security experts are out there? Do you think all 50 states can hire enough? I don't. Oh, and let us not forget, cyberattacks aren't only made against, say, North Carolina and West Virginia, they hit everyone, everywhere. Fifty different groups trying to cope with state-sponsored elite hacking teams is too stupid for words.</p>
<p>Oh, and did I mention? Earlier in his tenure, <a target="_blank" rel="nofollow" href="https://cyberscoop.com/trump-pause-grants-aid-federal-cyber-programs/">Trump had cut funding for cybersecurity-specific federal grant programs</a>. So, good luck hiring top-flight security mavens to protect your home state.</p>
<p>Let's also not forget the enemy inside. DOGE has access to sensitive federal systems. These include the Treasury Department's payment systems and the Social Security System. It appears that this data had been copied to God alone knows where and can now be accessed by people without the right to see or use it.</p>
<p>So not only has America's external cyber defenses been dismantled, but the data is out there for the greatest security attacks ever on individual citizens. <a target="_blank" href="https://www.theregister.com/2025/04/15/landmark_admin_data_loss/?td=rt-3a">1.6 million people had their Social Security information stolen from an insurance company</a>? That's so penny-ante.</p>
<p>The US will suffer the most from these self-inflicted security wounds, but the entire world will feel the pain. "Buckle up, we're in for a bumpy ride." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple and Meta fined millions for breaching EU law (149 pts)]]></title>
            <link>https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html</link>
            <guid>43770337</guid>
            <pubDate>Wed, 23 Apr 2025 10:01:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html">https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html</a>, See on <a href="https://news.ycombinator.com/item?id=43770337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><!-- HTML_TAG_START -->By Foo Yun Chee and Jan Strupczewski<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->BRUSSELS (Reuters) -Apple was fined 500 million euros ($570 million) on Wednesday and Meta 200 million euros, as European Union antitrust regulators handed out the first sanctions under landmark legislation aimed at curbing the power of Big Tech.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU fines could stoke tensions with U.S. President Donald Trump who has threatened to levy tariffs against countries that penalise U.S. companies.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->They follow a year-long investigation by the European Commission, the EU executive, into whether the companies comply with the Digital Markets Act (DMA) that seeks to allow smaller rivals into markets dominated by the biggest companies.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The fines signal that the EU is sticking to its guns in enforcing the new rules, which were introduced in 2023. That is despite Trump citing the DMA while vowing in February to "defend American companies and innovators from overseas extortion".<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Alphabet's Google and Elon Musk's X are also facing potential fines from European regulators.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU will be encouraged by a U.S. court judgment earlier this month which found that Google illegally dominates two markets for online advertising technology, Commission sources say. That ruling could pave the way for U.S. antitrust prosecutors to seek a breakup of its ad products.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Apple said it would challenge the EU fine.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"Today's announcements are yet another example of the European Commission unfairly targeting Apple in a series of decisions that are bad for the privacy and security of our users, bad for products, and force us to give away our technology for free," Apple said in an emailed statement.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->Meta also criticised the EU decision.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"The European Commission is attempting to handicap successful American businesses while allowing Chinese and European companies to operate under different standards," its Chief Global Affairs Officer Joel Kaplan said in an emailed statement.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"This isn't just about a fine; the Commission forcing us to change our business model effectively imposes a multi-billion-dollar tariff on Meta while requiring us to offer an inferior service."<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The fines are modest compared to the penalties meted out by the previous EU antitrust chief Margrethe Vestager during her term. Sources, speaking on condition of anonymity, have said this is due to the short period of the breaches, a focus on compliance rather than sanctions, and a desire to avoid possible retaliation from Trump.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->PAY-OR-CONSENT MODEL<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU competition watchdog said Apple must remove technical and commercial restrictions that prevent app developers from steering users to cheaper deals outside the App Store.<!-- HTML_TAG_END --></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI wants to buy Chrome and make it an "AI-first" experience (127 pts)]]></title>
            <link>https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/</link>
            <guid>43770312</guid>
            <pubDate>Wed, 23 Apr 2025 09:55:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/">https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=43770312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>According to Turley, OpenAI would throw its proverbial hat in the ring if Google had to sell. When asked if OpenAI would want Chrome, he was unequivocal. "Yes, we would, as would many other parties," <a href="https://www.theinformation.com/articles/openai-buy-chrome-executive-testifies">Turley said</a>.</p>
<p>OpenAI has reportedly considered building its own Chromium-based browser to compete with Chrome. Several months ago, the company hired former Google developers Ben Goodger and Darin Fisher, both of whom worked to bring Chrome to market.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg">
    <p><img width="1000" height="665" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg" alt="Close-up of Google Chrome Web Browser web page on the web browser. Chrome is widely used web browser developed by Google." decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg 1000w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-640x426.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-768x511.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-980x652.jpg 980w" sizes="auto, (max-width: 1000px) 100vw, 1000px">
                  </p>
          <figcaption>
        <div>
    
    <p><span>
          Credit:

          
          Getty Images

                  </span>
          </p>
  </div>
      </figcaption>
      </a></figure>
<p>It's not hard to see why OpenAI might want a browser, particularly Chrome with its 4 billion users and 67 percent market share. Chrome would instantly give OpenAI a massive install base of users who have been incentivized to use Google services. If OpenAI were running the show, you can bet ChatGPT would be integrated throughout the experience—Turley said as much, predicting an "AI-first" experience. The user data flowing to the owner of Chrome could also be invaluable in training <a href="https://arstechnica.com/ai/2025/01/openai-launches-operator-an-ai-agent-that-can-operate-your-computer/">agentic AI models</a> that can operate browsers on the user's behalf.</p>
<p>Interestingly, there's so much discussion about who should buy Chrome, but relatively little about spinning off Chrome into an independent company. Google has contended that Chrome can't survive on its own. However, the existence of Google's multibillion-dollar search placement deals, which the DOJ wants to end, suggests otherwise. Regardless, if Google has to sell, and OpenAI has the cash, we might get the proposed "AI-first" browsing experience.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Gruen Transfer is consuming the internet (173 pts)]]></title>
            <link>https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet</link>
            <guid>43769936</guid>
            <pubDate>Wed, 23 Apr 2025 08:49:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet">https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet</a>, See on <a href="https://news.ycombinator.com/item?id=43769936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Have you ever walked into a supermarket, pharmacy, or department store looking to buy a specific item, only to find the layout confusing? Perhaps you ended up aimlessly strolling around, purchasing other items? This is deliberate, and known as the Gruen Transfer.  </p>
<p>The 'Transfer' part is the moment that you, as a consumer surrounded by a deliberately confusing layout, lose track of your original intentions.  </p>
<p>We've all experienced it, and now it's starting to consume the internet. It first appeared on Facebook, with the introduction of the feed. Originally intended as a way to simplify updates from your friends, and hold your attention captive for longer. However somewhere along the line, the feed became more than that. Facebook now feels more confusing than my local department store, and my original reason for visiting (keeping up to date with friends &amp; family) is quickly forgotten. The last time I checked Facebook, maybe 10% of my feed was updates from friends. The rest was a combination of ads, memes, and influencer marketing videos, leaving me doom scrolling endlessly.    </p>
<p>This isn't relegated to Facebook though, or even social media. So many websites are now designed to disorient you upon visiting, so that you start acting impulsively. This can even happen in a relatively benign way - who hasn't looked up something on Wikipedia and fell down a rabbit hole that ended looking at a <a href="https://en.wikipedia.org/wiki/List_of_animals_awarded_human_credentials">list of animals awarded human credentials</a>?  </p>
<p>It pops up in other areas as well, closely associated with several UX dark patterns. If you've tried to permanently delete your account from any major social network, you’ll know what I mean. It is utterly confusing to find and navigate to the page you need, and the site will desperately conjole you into doing something other than deleting your account. It's the same for trying to alter your insurance policy, cancel subscriptions, spend frequent flyer miles, and so on...  </p>
<p>I wonder where all this will end? There must be a point at which the friction generated by needless complexity has a detrimental effect. A kind of <a href="https://en.wikipedia.org/wiki/Laffer_curve#:~:text=In%20economics%2C%20the%20Laffer%20curve,of%20the%20government's%20tax%20revenue.">Laffer Curve</a> of web design.  </p>
<p>In the EU, it is a legal requirement to allow your customers the same method, with the same number of steps and complexity, for canceling as for subscribing. So if it takes 10 seconds to fill in a form online to get subscribed, they need to offer the same ease of use for canceling.  </p>
<p>I like this idea of ‘complexity’ as a measure for legislation. Now if only they could apply the same thing to my local Boots when I'm trying to buy toothpaste.  </p>
                  </div><p>If you've made it this far I owe you a beer the next time I see you 🍺. Want to get in touch? <a href="http://twitter.com/sebs_tweets">Follow me on Twitter(X)</a>.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advanced Python Features (299 pts)]]></title>
            <link>https://blog.edward-li.com/tech/advanced-python-features/</link>
            <guid>43769486</guid>
            <pubDate>Wed, 23 Apr 2025 07:21:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.edward-li.com/tech/advanced-python-features/">https://blog.edward-li.com/tech/advanced-python-features/</a>, See on <a href="https://news.ycombinator.com/item?id=43769486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Python is one of the <a href="https://survey.stackoverflow.co/2024/technology#most-popular-technologies">most widely adopted programming languages</a> in the world. Yet, because of it’s ease and simplicity to just “get <em>something</em> working”, it’s also one of the most underappreciated.</p>
<p>If you search for <a href="https://www.google.com/search?q=Top+10+Advanced+Python+Tricks"><code>Top 10 Advanced Python Tricks</code></a> on Google or any other search engine, you’ll find tons of blogs or LinkedIn articles going over trivial (but still useful) things like <code>generators</code> or <code>tuples</code>.</p>
<p><em><strong>However</strong></em>, as someone who’s written Python for the past 12 years, I’ve come across a lot of really interesting, underrated, unique, or (as some might say) “un-pythonic” tricks to <em>really</em> level up what Python can do.</p>
<p>That’s why I decided to compile the top 14 of said features alongside examples and additional resources if you want to dive deeper into any of them.</p>
<blockquote>
<p>These tips &amp; tricks were originally featured as part of a 14-day series on X/Twitter between March 1st and March 14th (pi-day, hence why there are 14 topics in the article).</p>
<p>All X/Twitter links will also be accompanied with a Nitter counterpart. Nitter is a privacy-abiding open source Twitter frontend. Learn more about the project <a href="https://github.com/zedeus/nitter">here</a>.</p></blockquote>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#1-typing-overloads">1. Typing Overloads</a></li>
<li><a href="#2-keyword-only-and-positional-only-arguments">2. Keyword-only and Positional-only Arguments</a></li>
<li><a href="#3-future-annotations">3. Future Annotations</a></li>
<li><a href="#4-generics">4. Generics</a></li>
<li><a href="#5-protocols">5. Protocols</a></li>
<li><a href="#6-context-managers">6. Context Managers</a></li>
<li><a href="#7-structural-pattern-matching">7. Structural Pattern Matching</a></li>
<li><a href="#8-python-slots">8. Python Slots</a></li>
<li><a href="#9-python-nitpicks">9. Python Nitpicks</a></li>
<li><a href="#10-advanced-f-string-string-formatting">10. Advanced f-string String Formatting</a></li>
<li><a href="#11-cache--lru_cache">11. Cache / lru_cache</a></li>
<li><a href="#12-python-futures">12. Python Futures</a></li>
<li><a href="#13-proxy-properties">13. Proxy Properties</a></li>
<li><a href="#14-metaclasses">14. Metaclasses</a></li>
</ul>
<h2 id="1-typing-overloads">1. Typing Overloads</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1895937864527192320">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1895937864527192320">Nitter Mirror</a></strong></p></blockquote>
<p><strong><code>@overload</code></strong> is a decorator from Python’s <code>typing</code> module that lets you define multiple signatures for the same function. Each overload tells the type checker exactly what types to expect when specific parameters are passed in.</p>
<p>For example, the code below dictates that <em>only</em> <code>list[str]</code> can be returned if <code>mode=split</code>, and <em>only</em> <code>str</code> can be returned if <code>mode=upper</code>. (The <code>Literal</code> type also forces mode to be either one of <code>split</code> or <code>upper</code>)</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> Literal, overload
</span></span><span><span>
</span></span><span><span><span>@overload</span>
</span></span><span><span><span>def</span> <span>transform</span>(data: str, mode: Literal[<span>"split"</span>]) <span>-&gt;</span> list[str]:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>@overload</span>
</span></span><span><span><span>def</span> <span>transform</span>(data: str, mode: Literal[<span>"upper"</span>]) <span>-&gt;</span> str:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>transform</span>(data: str, mode: Literal[<span>"split"</span>, <span>"upper"</span>]) <span>-&gt;</span> list[str] <span>|</span> str:
</span></span><span><span>    <span>if</span> mode <span>==</span> <span>"split"</span>:
</span></span><span><span>        <span>return</span> data<span>.</span>split()
</span></span><span><span>    <span>else</span>:
</span></span><span><span>        <span>return</span> data<span>.</span>upper()
</span></span><span><span>
</span></span><span><span>split_words <span>=</span> transform(<span>"hello world"</span>, <span>"split"</span>)  <span># Return type is list[str]</span>
</span></span><span><span>split_words[<span>0</span>]  <span># Type checker is happy</span>
</span></span><span><span>
</span></span><span><span>upper_words <span>=</span> transform(<span>"hello world"</span>, <span>"upper"</span>)  <span># Return type is str</span>
</span></span><span><span>upper_words<span>.</span>lower()  <span># Type checker is happy</span>
</span></span><span><span>
</span></span><span><span>upper_words<span>.</span>append(<span>"!"</span>)  <span># Cannot access attribute "append" for "str"</span>
</span></span></code></pre></div><p>Overloads can do more than just change return type based on arguments! In another example, we use typing overloads to ensure that either one of <code>id</code> OR <code>username</code> are passed in, but <em><strong>never both</strong></em>.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>@overload</span>
</span></span><span><span><span>def</span> <span>get_user</span>(id: int <span>=</span> <span>...</span>, username: <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> User:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>@overload</span>
</span></span><span><span><span>def</span> <span>get_user</span>(id: <span>None</span> <span>=</span> <span>None</span>, username: str <span>=</span> <span>...</span>) <span>-&gt;</span> User:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>get_user</span>(id: int <span>|</span> <span>None</span> <span>=</span> <span>None</span>, username: str <span>|</span> <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> User:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span>get_user(id<span>=</span><span>1</span>)  <span># Works!</span>
</span></span><span><span>get_user(username<span>=</span><span>"John"</span>)  <span># Works!</span>
</span></span><span><span>get_user(id<span>=</span><span>1</span>, username<span>=</span><span>"John"</span>)  <span># No overloads for "get_user" match the provided arguments</span>
</span></span></code></pre></div><blockquote>
<p>The <code>...</code> is a special value often used in overloads to indicate that a parameter is optional, but still requires a value.</p></blockquote>
<p><strong>✨ Quick bonus trick:</strong> As you probably saw, Python also has support for <strong>String Literals</strong>. These help assert that only specific string values can be passed to a parameter, giving you even more type safety. Think of them like a lightweight form of Enums!</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>set_color</span>(color: Literal[<span>"red"</span>, <span>"blue"</span>, <span>"green"</span>]) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span>set_color(<span>"red"</span>)
</span></span><span><span>set_color(<span>"blue"</span>)
</span></span><span><span>set_color(<span>"green"</span>)
</span></span><span><span>set_color(<span>"fuchsia"</span>)  <span># Argument of type "Literal['fuchsia']" cannot be assigned to parameter "color"</span>
</span></span></code></pre></div><h3 id="additional-resources">Additional Resources</h3>
<ul>
<li><a href="https://adamj.eu/tech/2021/05/29/python-type-hints-how-to-use-overload/">Python Type Hints: How to use <code>@overload</code></a></li>
<li><a href="https://peps.python.org/pep-3124/">PEP 3124 – Overloading, Generic Functions, Interfaces, and Adaptation</a></li>
<li><a href="https://docs.python.org/3/library/typing.html#overload">Python Docs - Overloads</a></li>
<li><a href="https://peps.python.org/pep-0586/">PEP 586 – Literal Types</a></li>
</ul>
<h2 id="2-keyword-only-and-positional-only-arguments">2. Keyword-only and Positional-only Arguments</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1896257050147246306">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1896257050147246306">Nitter Mirror</a></strong></p></blockquote>
<p>By default, both required parameters and optional parameters can be assigned with both positional and keyword syntax. However, what if you <em>don’t</em> want that to happen? <strong>Keyword-only and Positional-only args</strong> let you control that.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>foo</span>(a, b, <span>/</span>, c, d, <span>*</span>, e, f):
</span></span><span><span>	<span>#         ^        ^</span>
</span></span><span><span>	<span># Ever seen these before?</span>
</span></span><span><span>	<span>...</span>
</span></span></code></pre></div><p><strong><code>*</code> (asterisk)</strong> marks keyword-only parameters. Arguments <em>after</em> <code>*</code> <em>must</em> be passed as keyword arguments.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>#   KW+POS | KW ONLY</span>
</span></span><span><span><span>#       vv | vv</span>
</span></span><span><span><span>def</span> <span>foo</span>(a, <span>*</span>, b):
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span># == ALLOWED ==</span>
</span></span><span><span>foo(a<span>=</span><span>1</span>, b<span>=</span><span>2</span>)  <span># All keyword</span>
</span></span><span><span>foo(<span>1</span>, b<span>=</span><span>2</span>)  <span># Half positional, half keyword</span>
</span></span><span><span>
</span></span><span><span><span># == NOT ALLOWED ==</span>
</span></span><span><span>foo(<span>1</span>, <span>2</span>)  <span># Cannot use positional for keyword-only parameter</span>
</span></span><span><span><span>#      ^</span>
</span></span></code></pre></div><p><strong><code>/</code> (forward slash)</strong> marks positional-only parameters. Arguments <em>before</em> <code>/</code> <em>must</em> be passed positionally and cannot be used as keyword arguments.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># POS ONLY | KW POS</span>
</span></span><span><span><span>#       vv | vv</span>
</span></span><span><span><span>def</span> <span>bar</span>(a, <span>/</span>, b):
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span># == ALLOWED ==</span>
</span></span><span><span>bar(<span>1</span>, <span>2</span>)  <span># All positional</span>
</span></span><span><span>bar(<span>1</span>, b<span>=</span><span>2</span>)  <span># Half positional, half keyword</span>
</span></span><span><span>
</span></span><span><span><span># == NOT ALLOWED ==</span>
</span></span><span><span>bar(a<span>=</span><span>1</span>, b<span>=</span><span>2</span>)  <span># Cannot use keyword for positional-only parameter</span>
</span></span><span><span><span>#   ^</span>
</span></span></code></pre></div><p>Keyword-only and Positional-only arguments are especially helpful for API developers to enforce how their arguments may be used and passed in.</p>
<h3 id="additional-resources-1">Additional Resources</h3>
<ul>
<li><a href="https://thepythoncodingbook.com/2022/12/11/positional-only-and-keyword-only-arguments-in-python/">Using Positional-Only And Keyword-Only Arguments in Python</a></li>
<li><a href="https://stackoverflow.com/questions/58477827/why-use-positional-only-parameters-in-python-3-8">Stack Overflow: Why use positional-only parameters in Python 3.8+?</a></li>
<li><a href="https://peps.python.org/pep-3102/">PEP 3102 – Keyword-Only Arguments</a></li>
<li><a href="https://peps.python.org/pep-0570/">PEP 570 – Python Positional-Only Parameters</a></li>
</ul>
<h2 id="3-future-annotations">3. Future Annotations</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1896667340777091212">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1896667340777091212">Nitter Mirror</a></strong></p></blockquote>
<p>A quick history lesson into Python’s typing:</p>
<blockquote>
<p>This is less of a “Python Feature” and more of a history lesson into Python’s type system, and what <code>from __future__ import annotations</code> does if you ever encounter it in production code.</p></blockquote>
<p><em>Python’s typing system started off as a hack</em>. Function annotation syntax was first introduced with <a href="https://peps.python.org/pep-3107/">PEP 3107</a> back in Python 3.0 as purely an extra way to decorate functions with no actual type-checking functionality.</p>
<p>Proper specifications for type annotations were later added in Python 3.5 through <a href="https://peps.python.org/pep-0484/">PEP 484</a>, but they were designed to be evaluated at bound / definition time. This worked great for simple cases, but it increasingly caused headaches with one type of problem: <strong>forward references</strong>.</p>
<p>This meant that forward references (using a type before it gets defined) required falling back to string literals, making the code less elegant and more error-prone.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># This won't work</span>
</span></span><span><span><span>class</span> <span>Foo</span>:
</span></span><span><span>    <span>def</span> <span>action</span>(self) <span>-&gt;</span> Foo:
</span></span><span><span>        <span># The `-&gt; Foo` return annotation is evaluated immediately during definition,</span>
</span></span><span><span>        <span># but the class `Foo` is not yet fully defined at that point,</span>
</span></span><span><span>        <span># causing a NameError during type checking.</span>
</span></span><span><span>        <span>...</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># This is the workaround -&gt; Using string types</span>
</span></span><span><span><span>class</span> <span>Bar</span>:
</span></span><span><span>    <span>def</span> <span>action</span>(self) <span>-&gt;</span> <span>"Bar"</span>:
</span></span><span><span>        <span># Workaround with string literals, but ugly and error-prone</span>
</span></span><span><span>        <span>...</span>
</span></span></code></pre></div><p>Introduced as a PEP (Python Enhancement Proposal), <a href="https://peps.python.org/pep-0563/">PEP 563: Postponed Evaluation of Annotations</a> aimed to fix this by changing when type annotations were evaluated. Instead of evaluating annotations at definition time, PEP 563 “<em>string-ifies</em>” types behind the scenes and postpones evaluation until they’re actually needed, typically during static analysis. This allows for cleaner forward references without explicitly defining string literals and reduces the runtime overhead of type annotations.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> __future__ <span>import</span> annotations
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Foo</span>:
</span></span><span><span>    <span>def</span> <span>bar</span>(self) <span>-&gt;</span> Foo:  <span># Works now!</span>
</span></span><span><span>        <span>...</span>
</span></span></code></pre></div><p><strong>So what was the problem?</strong></p>
<p>For type checkers, this change is largely transparent. But because PEP 563 implements this by essentially treating all types as strings behind the scenes, anything that relies on accessing return types at runtime (i.e., ORMs, serialization libraries, validators, dependency injectors, etc.) will have compatibility issues with the new setup.</p>
<p>That’s why even after ten years after the initial proposal, modern Python (3.13 as of writing this) still relies on the same hacked-together type system introduced in Python 3.5.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Regular Python Typing =====</span>
</span></span><span><span><span>def</span> <span>foobar</span>() <span>-&gt;</span> int:
</span></span><span><span>    <span>return</span> <span>1</span>
</span></span><span><span>
</span></span><span><span>ret_type <span>=</span> foobar<span>.</span>__annotations__<span>.</span>get(<span>"return"</span>)
</span></span><span><span>ret_type
</span></span><span><span><span># Returns: &lt;class 'int'&gt;</span>
</span></span><span><span>new_int <span>=</span> ret_type()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== With Postponed Evaluation =====</span>
</span></span><span><span><span>from</span> __future__ <span>import</span> annotations
</span></span><span><span>
</span></span><span><span><span>def</span> <span>foobar</span>() <span>-&gt;</span> int:
</span></span><span><span>    <span>return</span> <span>1</span>
</span></span><span><span>
</span></span><span><span>ret_type <span>=</span> foobar<span>.</span>__annotations__<span>.</span>get(<span>"return"</span>)
</span></span><span><span>ret_type
</span></span><span><span><span># "int" (str)</span>
</span></span><span><span>new_int <span>=</span> ret_type()  <span># TypeError: 'str' object is not callable</span>
</span></span></code></pre></div><p>Recently, <a href="https://peps.python.org/pep-0649/">PEP 649</a> proposes a new method to handle Python function and class annotations through deferred, or “lazy,” evaluation. Instead of evaluating annotations at the time of function or class definition, as is traditionally done, this approach delays their computation until they are actually accessed.</p>
<p>This is achieved by compiling the annotation expressions into a separate function, stored in a special <code>__annotate__</code> attribute. When the <code>__annotations__</code> attribute is accessed for the first time, this function is invoked to compute and cache the annotations, making them readily available for subsequent accesses.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Example code from the PEP 649 proposal</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>function</span>:
</span></span><span><span>    <span># __annotations__ on a function object is already a</span>
</span></span><span><span>    <span># "data descriptor" in Python, we're just changing</span>
</span></span><span><span>    <span># what it does</span>
</span></span><span><span>    <span>@property</span>
</span></span><span><span>    <span>def</span> <span>__annotations__</span>(self):
</span></span><span><span>        <span>return</span> self<span>.</span>__annotate__()
</span></span><span><span>
</span></span><span><span><span># ...</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>annotate_foo</span>():
</span></span><span><span>    <span>return</span> {<span>'x'</span>: int, <span>'y'</span>: MyType, <span>'return'</span>: float}
</span></span><span><span>
</span></span><span><span><span>def</span> <span>foo</span>(x <span>=</span> <span>3</span>, y <span>=</span> <span>"abc"</span>):
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span>foo<span>.</span>__annotate__ <span>=</span> annotate_foo
</span></span><span><span>
</span></span><span><span><span>class</span> <span>MyType</span>:
</span></span><span><span>   <span>...</span>
</span></span><span><span>
</span></span><span><span>foo_y_annotation <span>=</span> foo<span>.</span>__annotations__[<span>'y'</span>]
</span></span></code></pre></div><p>This deferred evaluation strategy addresses issues like forward references and circular dependencies, as annotations are only evaluated when needed. Moreover, it enhances performance by avoiding the immediate computation of annotations that might not be used, and maintains full semantic information, supporting introspection and runtime type-checking tools.</p>
<p><strong>✨ Bonus Fact:</strong> Since Python 3.11, Python now supports a “Self” type (<a href="https://peps.python.org/pep-0673/">PEP 673</a>) that allows for proper typing of methods that return instances of their own class, solving this particular example of self-referential return types.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> Self
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Foo</span>:
</span></span><span><span>    <span>def</span> <span>bar</span>(self) <span>-&gt;</span> Self:
</span></span><span><span>        <span>...</span>
</span></span></code></pre></div><h3 id="additional-resources-2">Additional Resources</h3>
<ul>
<li><a href="https://peps.python.org/pep-0649/#a-history-of-annotations">A History Of Annotations</a></li>
<li><a href="https://blog.derlin.ch/python-type-hints-and-future-annotations">Python, Type Hints, and Future Annotations</a></li>
<li><a href="https://docs.python.org/3/library/__future__.html"><code>__future__</code> — Future Statement Definitions</a></li>
<li><a href="https://peps.python.org/pep-0484/">PEP 484 – Type Hints</a></li>
<li><a href="https://peps.python.org/pep-0563/">PEP 563 – Postponed Evaluation of Annotations</a></li>
<li><a href="https://peps.python.org/pep-0649/">PEP 649 – Deferred Evaluation Of Annotations Using Descriptors</a></li>
<li><a href="https://peps.python.org/pep-0749/">PEP 749 – Implementing PEP 649</a></li>
</ul>
<h2 id="4-generics">4. Generics</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1896994839516020825">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1896994839516020825">Nitter Mirror</a></strong></p></blockquote>
<p>Did you know that Python has <strong>Generics</strong>? In fact, <a href="https://docs.python.org/3/whatsnew/3.12.html">since Python 3.12</a>, a newer, sleeker, and sexier syntax for Generics was introduced.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>KVStore</span>[K: str <span>|</span> int, V]:
</span></span><span><span>    <span>def</span> __init__(self) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>store: dict[K, V] <span>=</span> {}
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>get</span>(self, key: K) <span>-&gt;</span> V:
</span></span><span><span>        <span>return</span> self<span>.</span>store[key]
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>set</span>(self, key: K, value: V) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>store[key] <span>=</span> value
</span></span><span><span>
</span></span><span><span>kv <span>=</span> KVStore[str, int]()
</span></span><span><span>kv<span>.</span>set(<span>"one"</span>, <span>1</span>)
</span></span><span><span>kv<span>.</span>set(<span>"two"</span>, <span>2</span>)
</span></span><span><span>kv<span>.</span>set(<span>"three"</span>, <span>3</span>)
</span></span></code></pre></div><p>Python 3.5 initially introduced Generics through the <code>TypeVar</code> syntax. However, <a href="https://peps.python.org/pep-0695/">PEP 695</a> for Python 3.12 revamped type annotations with native syntax for generics, type aliases, and more.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># OLD SYNTAX - Python 3.5 to 3.11</span>
</span></span><span><span><span>from</span> typing <span>import</span> Generic, TypeVar
</span></span><span><span>
</span></span><span><span>UnBounded <span>=</span> TypeVar(<span>"UnBounded"</span>)
</span></span><span><span>Bounded <span>=</span> TypeVar(<span>"Bounded"</span>, bound<span>=</span>int)
</span></span><span><span>Constrained <span>=</span> TypeVar(<span>"Constrained"</span>, int, float)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Foo</span>(Generic[UnBounded, Bounded, Constrained]):
</span></span><span><span>    <span>def</span> __init__(self, x: UnBounded, y: Bounded, z: Constrained) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>x <span>=</span> x
</span></span><span><span>        self<span>.</span>y <span>=</span> y
</span></span><span><span>        self<span>.</span>z <span>=</span> z
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># NEW SYNTAX - Python 3.12+</span>
</span></span><span><span><span>class</span> <span>Foo</span>[UnBounded, Bounded: int, Constrained: int <span>|</span> float]:
</span></span><span><span>    <span>def</span> __init__(self, x: UnBounded, y: Bounded, z: Constrained) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>x <span>=</span> x
</span></span><span><span>        self<span>.</span>y <span>=</span> y
</span></span><span><span>        self<span>.</span>z <span>=</span> z
</span></span></code></pre></div><p>This change also introduces an even more powerful version of <strong>variadic generics</strong>. Meaning you can have an arbitrary number of type parameters for complex data structures and operations.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Tuple</span>[<span>*</span>Ts]:
</span></span><span><span>    <span>def</span> __init__(self, <span>*</span>args: <span>*</span>Ts) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>values <span>=</span> args
</span></span><span><span>
</span></span><span><span><span># Works with any number of types!</span>
</span></span><span><span>pair <span>=</span> Tuple[str, int](<span>"hello"</span>, <span>42</span>)
</span></span><span><span>triple <span>=</span> Tuple[str, int, bool](<span>"world"</span>, <span>100</span>, <span>True</span>)
</span></span></code></pre></div><p>Finally, as part of the 3.12 typing changes, Python also introduced a new concise syntax for type aliases!</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># OLD SYNTAX - Python 3.5 to 3.9</span>
</span></span><span><span><span>from</span> typing <span>import</span> NewType
</span></span><span><span>Vector <span>=</span> NewType(<span>"Vector"</span>, list[float])
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># OLD-ish SYNTAX - Python 3.10 to 3.11</span>
</span></span><span><span><span>from</span> typing <span>import</span> TypeAlias
</span></span><span><span>Vector: TypeAlias <span>=</span> list[float]
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># NEW SYNTAX - Python 3.12+</span>
</span></span><span><span>type Vector <span>=</span> list[float]
</span></span></code></pre></div><h3 id="additional-resources-3">Additional Resources</h3>
<ul>
<li><a href="https://arjancodes.com/blog/python-generics-syntax/">Blog on Python 3.12 Generics</a></li>
<li><a href="https://realpython.com/python312-typing/">Python 3.12 Preview: Static Typing Improvements</a></li>
<li><a href="https://typing.python.org/en/latest/spec/generics.html">Python Docs - Generics</a></li>
<li><a href="https://peps.python.org/pep-0695/">PEP 695 – Type Parameter Syntax</a></li>
</ul>
<h2 id="5-protocols">5. Protocols</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1897373856475836829">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1897373856475836829">Nitter Mirror</a></strong></p></blockquote>
<p>One of Python’s major features (and also major complaints) is its support for <a href="https://realpython.com/duck-typing-python/"><strong>Duck Typing</strong></a>. There’s a saying that goes:</p>
<p><q>
    “If it walks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.”
</q></p><p>However, that raises the question: <em>How do you <strong>type</strong> duck typing?</em></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Duck</span>:
</span></span><span><span>    <span>def</span> <span>quack</span>(self): print(<span>'Quack!'</span>)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Person</span>:
</span></span><span><span>    <span>def</span> <span>quack</span>(self): print(<span>"I'm quacking!"</span>)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Dog</span>:
</span></span><span><span>    <span>def</span> <span>bark</span>(self): print(<span>'Woof!'</span>)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>run_quack</span>(obj):
</span></span><span><span>    obj<span>.</span>quack()
</span></span><span><span>
</span></span><span><span>run_quack(Duck())  <span># Works!</span>
</span></span><span><span>run_quack(Person())  <span># Works!</span>
</span></span><span><span>run_quack(Dog())  <span># Fails with AttributeError</span>
</span></span></code></pre></div><p>That’s where <strong>Protocols</strong> come in. Protocols (also known as <strong>Structural Subtyping</strong>) are typing classes in Python defining the structure or behavior that classes can follow <strong>without</strong> the use of interfaces or inheritance.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> Protocol
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Quackable</span>(Protocol):
</span></span><span><span>    <span>def</span> <span>quack</span>(self) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        <span>...</span>  <span># The ellipsis indicates this is just a method signature</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Duck</span>:
</span></span><span><span>    <span>def</span> <span>quack</span>(self): print(<span>'Quack!'</span>)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Dog</span>:
</span></span><span><span>    <span>def</span> <span>bark</span>(self): print(<span>'Woof!'</span>)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>run_quack</span>(obj: Quackable):
</span></span><span><span>    obj<span>.</span>quack()
</span></span><span><span>
</span></span><span><span>run_quack(Duck())  <span># Works!</span>
</span></span><span><span>run_quack(Dog())  <span># Fails during TYPE CHECKING (not runtime)</span>
</span></span></code></pre></div><p>In essence, Protocols check what your object <em><strong>can</strong></em> do, not what it <em><strong>is</strong></em>. They simply state that as long as an object implements certain methods or behaviors, it qualifies, regardless of its actual type or inheritance.</p>
<p><strong>✨ Additional quick tip:</strong>  Add the <code>@runtime_checkable</code> decorator if you want <code>isinstance()</code> checks to work alongside your Protocols!</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>@runtime_checkable</span>
</span></span><span><span><span>class</span> <span>Drawable</span>(Protocol):
</span></span><span><span>    <span>def</span> <span>draw</span>(self) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        <span>...</span>
</span></span></code></pre></div><h3 id="additional-resources-4">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/python-protocol/">Python Protocols: Leveraging Structural Subtyping</a></li>
<li><a href="https://mypy.readthedocs.io/en/stable/protocols.html">MyPy: Protocols and structural subtyping</a></li>
<li><a href="https://typing.python.org/en/latest/spec/protocol.html">Python Docs - Protocols</a></li>
<li><a href="https://peps.python.org/pep-0544/">PEP 544 – Protocols: Structural subtyping</a></li>
</ul>
<h2 id="6-context-managers">6. Context Managers</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1897714940297068624">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1897714940297068624">Nitter Mirror</a></strong></p></blockquote>
<p><strong>Context Managers</strong> are objects that define the methods: <code>__enter__()</code> and <code>__exit__()</code>. The <code>__enter__()</code> method runs when you enter the <code>with</code> block, and the <code>__exit__()</code> method runs when you leave it (even if an exception occurs).</p>
<p><strong><code>Contextlib</code></strong> simplifies this process by wrapping all that boilerplate code in a single easy-to-use decorator.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># OLD SYNTAX - Traditional OOP-style context manager</span>
</span></span><span><span><span>class</span> <span>retry</span>:
</span></span><span><span>    <span>def</span> __enter__(self):
</span></span><span><span>        print(<span>"Entering Context"</span>)
</span></span><span><span>
</span></span><span><span>    <span>def</span> __exit__(self, exc_type, exc_val, exc_tb):
</span></span><span><span>        print(<span>"Exiting Context"</span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># NEW SYNTAX - New contextlib-based context manager</span>
</span></span><span><span><span>import</span> contextlib
</span></span><span><span>
</span></span><span><span><span>@contextlib.contextmanager</span>
</span></span><span><span><span>def</span> <span>retry</span>():
</span></span><span><span>    print(<span>"Entering Context"</span>)
</span></span><span><span>    <span>yield</span>
</span></span><span><span>    print(<span>"Exiting Context"</span>)
</span></span></code></pre></div><p>To create your own, write a function with the <code>@contextlib.contextmanager</code> decorator. Add setup code before <code>yield</code>, cleanup code after it. Any variables on yield will be passed in as additional context. That’s it.</p>
<p>The <code>yield</code> statement instructs the context manager to pause your function and lets content within the <code>with</code> block run.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> contextlib
</span></span><span><span>
</span></span><span><span><span>@contextlib.contextmanager</span>
</span></span><span><span><span>def</span> <span>context</span>():
</span></span><span><span>    <span># Setup code here</span>
</span></span><span><span>    setup()
</span></span><span><span>    <span>yield</span> (<span>...</span>)  <span># Any variables you want to be passed to the with block</span>
</span></span><span><span>    <span># Teardown code here</span>
</span></span><span><span>    takedown()
</span></span></code></pre></div><p>Overall, this is a much more concise and readable way of creating and using context managers in Python.</p>
<h3 id="additional-resources-5">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/python-with-statement/">Context Managers and Python’s with Statement</a></li>
<li><a href="https://book.pythontips.com/en/latest/context_managers.html">Python Tips: Context Manager</a></li>
<li><a href="https://docs.python.org/3/library/contextlib.html">Python Docs: <code>contextlib</code> — Utilities for with-statement contexts</a></li>
</ul>
<h2 id="7-structural-pattern-matching">7. Structural Pattern Matching</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1898065958578929801">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1898065958578929801">Nitter Mirror</a></strong></p></blockquote>
<p>Introduced in <a href="https://docs.python.org/3/whatsnew/3.10.html">Python 3.10</a>, <strong>Structural Pattern Matching</strong> gives Python developers a powerful alternative to traditional conditional logic. At its most basic, the syntax looks like this:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>match</span> value:
</span></span><span><span>    <span>case</span> pattern1:
</span></span><span><span>        <span># code if value matches pattern1</span>
</span></span><span><span>    <span>case</span> pattern2:
</span></span><span><span>        <span># code if value matches pattern2</span>
</span></span><span><span>    <span>case</span> _:
</span></span><span><span>        <span># wildcard case (default)</span>
</span></span></code></pre></div><p>The real power comes with <strong>destructuring</strong>! Match patterns break down complex data structures and extract values in a single step.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Destructuring and matching tuples</span>
</span></span><span><span><span>match</span> point:
</span></span><span><span>    <span>case</span> (<span>0</span>, <span>0</span>):
</span></span><span><span>        <span>return</span> <span>"Origin"</span>
</span></span><span><span>    <span>case</span> (<span>0</span>, y):
</span></span><span><span>        <span>return</span> <span>f</span><span>"Y-axis at </span><span>{</span>y<span>}</span><span>"</span>
</span></span><span><span>    <span>case</span> (x, <span>0</span>):
</span></span><span><span>        <span>return</span> <span>f</span><span>"X-axis at </span><span>{</span>x<span>}</span><span>"</span>
</span></span><span><span>    <span>case</span> (x, y):
</span></span><span><span>        <span>return</span> <span>f</span><span>"Point at (</span><span>{</span>x<span>}</span><span>, </span><span>{</span>y<span>}</span><span>)"</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># Using OR pattern (|) to match multiple patterns</span>
</span></span><span><span><span>match</span> day:
</span></span><span><span>    <span>case</span> (<span>"Monday"</span>
</span></span><span><span>          <span>|</span> <span>"Tuesday"</span>
</span></span><span><span>          <span>|</span> <span>"Wednesday"</span>
</span></span><span><span>          <span>|</span> <span>"Thursday"</span>
</span></span><span><span>          <span>|</span> <span>"Friday"</span>):
</span></span><span><span>        <span>return</span> <span>"Weekday"</span>
</span></span><span><span>    <span>case</span> <span>"Saturday"</span> <span>|</span> <span>"Sunday"</span>:
</span></span><span><span>        <span>return</span> <span>"Weekend"</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># Guard clauses with inline 'if' statements</span>
</span></span><span><span><span>match</span> temperature:
</span></span><span><span>    <span>case</span> temp <span>if</span> temp <span>&lt;</span> <span>0</span>:
</span></span><span><span>        <span>return</span> <span>"Freezing"</span>
</span></span><span><span>    <span>case</span> temp <span>if</span> temp <span>&lt;</span> <span>20</span>:
</span></span><span><span>        <span>return</span> <span>"Cold"</span>
</span></span><span><span>    <span>case</span> temp <span>if</span> temp <span>&lt;</span> <span>30</span>:
</span></span><span><span>        <span>return</span> <span>"Warm"</span>
</span></span><span><span>    <span>case</span> _:
</span></span><span><span>        <span>return</span> <span>"Hot"</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># Capture entire collections using asterisk (*)</span>
</span></span><span><span><span>match</span> numbers:
</span></span><span><span>    <span>case</span> [f]:
</span></span><span><span>        <span>return</span> <span>f</span><span>"First: </span><span>{</span>f<span>}</span><span>"</span>
</span></span><span><span>    <span>case</span> [f, l]:
</span></span><span><span>        <span>return</span> <span>f</span><span>"First: </span><span>{</span>f<span>}</span><span>, Last: </span><span>{</span>l<span>}</span><span>"</span>
</span></span><span><span>    <span>case</span> [f, <span>*</span>m, l]:
</span></span><span><span>        <span>return</span> <span>f</span><span>"First: </span><span>{</span>f<span>}</span><span>, Middle: </span><span>{</span>m<span>}</span><span>, Last: </span><span>{</span>l<span>}</span><span>"</span>
</span></span><span><span>    <span>case</span> []:
</span></span><span><span>        <span>return</span> <span>"Empty list"</span>
</span></span></code></pre></div><p>You can also combine match-case with other Python features like <strong><a href="https://realpython.com/python-walrus-operator/">walrus operators</a></strong> to create even more powerful patterns.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Check if a packet is valid or not</span>
</span></span><span><span>packet: list[int] <span>=</span> [<span>0x01</span>, <span>0x02</span>, <span>0x03</span>, <span>0x04</span>, <span>0x05</span>, <span>0x06</span>, <span>0x07</span>]
</span></span><span><span>
</span></span><span><span><span>match</span> packet:
</span></span><span><span>    <span>case</span> [c1, c2, <span>*</span>data, footer] <span>if</span> (  <span># Deconstruct packet into header, data, and footer</span>
</span></span><span><span>        (checksum <span>:=</span> c1 <span>+</span> c2) <span>==</span> sum(data) <span>and</span>  <span># Check that the checksum is correct</span>
</span></span><span><span>        len(data) <span>==</span> footer  <span># Check that the data length is correct</span>
</span></span><span><span>    ):
</span></span><span><span>        print(<span>f</span><span>"Packet received: </span><span>{</span>data<span>}</span><span> (Checksum: </span><span>{</span>checksum<span>}</span><span>)"</span>)
</span></span><span><span>    <span>case</span> [c1, c2, <span>*</span>data]:  <span># Failure case where structure is correct but checksum is wrong</span>
</span></span><span><span>        print(<span>f</span><span>"Packet received: </span><span>{</span>data<span>}</span><span> (Checksum Failed)"</span>)
</span></span><span><span>    <span>case</span> [_, <span>*</span>__]:  <span># Failure case where packet is too short</span>
</span></span><span><span>        print(<span>"Invalid packet length"</span>)
</span></span><span><span>    <span>case</span> []:  <span># Failure case where packet is empty</span>
</span></span><span><span>        print(<span>"Empty packet"</span>)
</span></span><span><span>    <span>case</span> _:  <span># Failure case where packet is invalid</span>
</span></span><span><span>        print(<span>"Invalid packet"</span>)
</span></span></code></pre></div><h3 id="additional-resources-6">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/structural-pattern-matching/">Structural Pattern Matching in Python</a></li>
<li><a href="https://benhoyt.com/writings/python-pattern-matching/">Structural pattern matching in Python 3.10</a></li>
<li><a href="https://stackoverflow.com/questions/70815197/how-to-do-structural-pattern-matching-in-python-3-10-with-a-type-to-match">Good StackOverflow Thread</a></li>
<li><a href="https://docs.python.org/3/reference/compound_stmts.html#match">Python Docs: The match statement</a></li>
<li><a href="https://peps.python.org/pep-0634/">PEP 634 – Structural Pattern Matching: Specification</a></li>
<li><a href="https://peps.python.org/pep-0636/">PEP 636 – Structural Pattern Matching: Tutorial</a></li>
</ul>
<h2 id="8-python-slots">8. Python Slots</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1898596367045640193">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1898596367045640193">Nitter Mirror</a></strong></p></blockquote>
<p><strong>Slots</strong> are a way to potentially speed up the creation and access of any Python class.</p>
<p><strong>TLDR:</strong> They define a fixed set of attributes for classes, optimizing and speeding up accesses during runtime.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Person</span>:
</span></span><span><span>    __slots__ <span>=</span> (<span>'name'</span>, <span>'age'</span>)
</span></span><span><span>
</span></span><span><span>    <span>def</span> __init__(self, name, age):
</span></span><span><span>        self<span>.</span>name <span>=</span> name
</span></span><span><span>        self<span>.</span>age <span>=</span> age
</span></span></code></pre></div><p>Under the hood, Python classes store instance attributes in an internal dictionary called <code>__dict__</code>, meaning a hash table lookup is required each time you want to access a value.</p>
<p>In contrast, <code>__slots__</code> uses an array-like structure where attributes can be looked up in true O(1) time, bringing a minor overall speed bump to Python.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Without __slots__</span>
</span></span><span><span><span>class</span> <span>FooBar</span>:
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        self<span>.</span>a <span>=</span> <span>1</span>
</span></span><span><span>        self<span>.</span>b <span>=</span> <span>2</span>
</span></span><span><span>        self<span>.</span>c <span>=</span> <span>3</span>
</span></span><span><span>
</span></span><span><span>f <span>=</span> FooBar()
</span></span><span><span>print(f<span>.</span>__dict__)  <span># {'a': 1, 'b': 2, 'c': 3}</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># With __slots__</span>
</span></span><span><span><span>class</span> <span>FooBar</span>:
</span></span><span><span>    __slots__ <span>=</span> (<span>'a'</span>, <span>'b'</span>, <span>'c'</span>)
</span></span><span><span>
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        self<span>.</span>a <span>=</span> <span>1</span>
</span></span><span><span>        self<span>.</span>b <span>=</span> <span>2</span>
</span></span><span><span>        self<span>.</span>c <span>=</span> <span>3</span>
</span></span><span><span>
</span></span><span><span>f <span>=</span> FooBar()
</span></span><span><span>print(f<span>.</span>__dict__)  <span># AttributeError</span>
</span></span><span><span>print(f<span>.</span>__slots__)  <span># ('a', 'b', 'c')</span>
</span></span></code></pre></div><p>There is still debate about whether <code>__slots__</code> is worth using, as it complicates class definitions with very marginal or no performance benefits at all. However, it is a useful tool to have in your arsenal if you ever need it.</p>
<h3 id="additional-resources-7">Additional Resources</h3>
<ul>
<li><a href="https://wiki.python.org/moin/UsingSlots">Using Slots - Python Wiki</a></li>
<li><a href="https://medium.com/@apps.merkurev/dont-forget-about-slots-in-python-c397f414c490">Don’t forget about <code>__slots__</code> in Python!</a></li>
<li><a href="https://stackoverflow.com/questions/472000/usage-of-slots">StackOverflow - Usage of <code>__slots__</code></a></li>
</ul>
<h2 id="9-python-nitpicks">9. Python Nitpicks</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1898934432939290658">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1898934432939290658">Nitter Mirror</a></strong></p></blockquote>
<blockquote>
<p>This is not a Python “feature” or “tip” per se, but instead a handful of quick syntax tips to really clean up your Python codebase.</p>
<p>As someone who’s seen a lot of Python code.</p></blockquote>
<h2 id="91-for-else-statements">9.1 For-else statements</h2>
<p>If you ever need to check if a for loop completes without a break, <strong>for-else statements</strong> are a great way to accomplish this <strong>without</strong> using a temporary variable.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Don't write this =====</span>
</span></span><span><span>found_server <span>=</span> <span>False</span>  <span># Keep track of whether we found a server</span>
</span></span><span><span><span>for</span> server <span>in</span> servers:
</span></span><span><span>    <span>if</span> server<span>.</span>check_availability():
</span></span><span><span>        primary_server <span>=</span> server
</span></span><span><span>        found_server <span>=</span> <span>True</span>  <span># Set the flag to True</span>
</span></span><span><span>        <span>break</span>
</span></span><span><span><span>if</span> <span>not</span> found_server:
</span></span><span><span>    <span># Use the backup server if no server was found</span>
</span></span><span><span>    primary_server <span>=</span> backup_server
</span></span><span><span>
</span></span><span><span><span># Continue execution with whatever server we found</span>
</span></span><span><span>deploy_application(primary_server)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Write this instead =====</span>
</span></span><span><span><span>for</span> server <span>in</span> servers:
</span></span><span><span>    <span>if</span> server<span>.</span>check_availability():
</span></span><span><span>        primary_server <span>=</span> server
</span></span><span><span>        <span>break</span>
</span></span><span><span><span>else</span>:
</span></span><span><span>    <span># Use the backup server if no server was found</span>
</span></span><span><span>    primary_server <span>=</span> backup_server
</span></span><span><span>
</span></span><span><span><span># Continue execution with whatever server we found</span>
</span></span><span><span>deploy_application(primary_server)
</span></span></code></pre></div><h2 id="92-walrus-operator">9.2 Walrus Operator</h2>
<p>If you need to define and evaluate a variable all in one expression, the <strong>Walrus Operator</strong> (new in Python 3.8 with <a href="https://peps.python.org/pep-0572/">PEP 572</a>) is a quick way to accomplish just that.</p>
<blockquote>
<p>Walrus operators are really useful for using a value right after checking if it is <strong><code>not None</code></strong>!</p></blockquote>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Don't write this =====</span>
</span></span><span><span>response <span>=</span> get_user_input()
</span></span><span><span><span>if</span> response:
</span></span><span><span>    print(<span>'You pressed:'</span>, response)
</span></span><span><span><span>else</span>:
</span></span><span><span>    print(<span>'You pressed nothing'</span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Write this instead =====</span>
</span></span><span><span><span>if</span> response <span>:=</span> get_user_input():
</span></span><span><span>    print(<span>'You pressed:'</span>, response)
</span></span><span><span><span>else</span>:
</span></span><span><span>    print(<span>'You pressed nothing'</span>)
</span></span></code></pre></div><h2 id="93-short-circuit-evaluation">9.3 Short Circuit Evaluation</h2>
<p><strong>Short-circuit Evaluation</strong> is a shortcut for getting the “next available” or “next truthy” value in a list of expressions. It turns out you can simply chain <code>or</code> statements!</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Don't write this =====</span>
</span></span><span><span>username, full_name, first_name <span>=</span> get_user_info()
</span></span><span><span>
</span></span><span><span><span>if</span> username <span>is</span> <span>not</span> <span>None</span>:
</span></span><span><span>    display_name <span>=</span> username
</span></span><span><span><span>elif</span> full_name <span>is</span> <span>not</span> <span>None</span>:
</span></span><span><span>    display_name <span>=</span> full_name
</span></span><span><span><span>elif</span> first_name <span>is</span> <span>not</span> <span>None</span>:
</span></span><span><span>    display_name <span>=</span> first_name
</span></span><span><span><span>else</span>:
</span></span><span><span>    display_name <span>=</span> <span>"Anonymous"</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Write this instead =====</span>
</span></span><span><span>username, full_name, first_name <span>=</span> get_user_info()
</span></span><span><span>
</span></span><span><span>display_name <span>=</span> username <span>or</span> full_name <span>or</span> first_name <span>or</span> <span>"Anonymous"</span>
</span></span></code></pre></div><h2 id="94-operator-chaining">9.4 Operator Chaining</h2>
<p>Finally, Python lets you <strong>chain comparison operators</strong> together to shorten up integer range comparisons, making them more readable than the equivalent boolean expressions.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Don't write this =====</span>
</span></span><span><span><span>if</span> <span>0</span> <span>&lt;</span> x <span>and</span> x <span>&lt;</span> <span>10</span>:
</span></span><span><span>    print(<span>"x is between 0 and 10"</span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Write this instead =====</span>
</span></span><span><span><span>if</span> <span>0</span> <span>&lt;</span> x <span>&lt;</span> <span>10</span>:  <span># Instead of if 0 &lt; x and x &lt; 10</span>
</span></span><span><span>    print(<span>"x is between 0 and 10"</span>)
</span></span></code></pre></div><h3 id="additional-resources-8">Additional Resources</h3>
<ul>
<li><a href="https://book.pythontips.com/en/latest/for_-_else.html"><code>for/else</code> - Python Tips</a></li>
<li><a href="https://realpython.com/python-walrus-operator/">The Walrus Operator: Python’s Assignment Expressions</a></li>
<li><a href="https://peps.python.org/pep-0572/">PEP 572 – Assignment Expressions</a></li>
<li><a href="https://realpython.com/python-or-operator/#default-values-for-variables">Using the “or” Boolean Operator in Python</a></li>
<li><a href="https://mathspp.com/blog/pydonts/chaining-comparison-operators">Chaining Comparison Operators</a></li>
</ul>
<h2 id="10-advanced-f-string-string-formatting">10. Advanced f-string String Formatting</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1899162302131122430">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1899162302131122430">Nitter Mirror</a></strong></p></blockquote>
<p>Python’s <strong>f-strings</strong> are no secret by now. Introduced in Python 3.6 with <a href="https://peps.python.org/pep-0498/">PEP 498</a>, they are a better, cleaner, faster, and safer method of interpolating variables, objects, and expressions into strings.</p>
<p>But did you know there is more to f-strings than just inserting variables? There exists a hidden formatting syntax called the <strong>Format Mini-Language</strong> that allows you to have much greater control over string formatting.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"</span><span>{</span><span>' [ Run Status ] '</span><span>:</span><span>=^50</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"[</span><span>{</span>time<span>:</span><span>%H:%M:%S</span><span>}</span><span>] Training Run </span><span>{</span>run_id<span>=}</span><span> status: </span><span>{</span>progress<span>:</span><span>.1%</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Summary: </span><span>{</span>total_samples<span>:</span><span>,</span><span>}</span><span> samples processed"</span>)
</span></span><span><span>print(<span>f</span><span>"Accuracy: </span><span>{</span>accuracy<span>:</span><span>.4f</span><span>}</span><span> | Loss: </span><span>{</span>loss<span>:</span><span>#.3g</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Memory: </span><span>{</span>memory <span>/</span> <span>1e9</span><span>:</span><span>+.2f</span><span>}</span><span> GB"</span>)
</span></span></code></pre></div><p><strong>Output:</strong></p>
<pre tabindex="0"><code>=================== [ Run Status ] ===================
[11:16:37] Training Run run_id=42 status: 87.4%
Summary: 12,345,678 samples processed
Accuracy: 0.9876 | Loss: 0.0123
Memory: +2.75 GB
</code></pre><p>You can do things like enable debug expressions, apply number formatting (similar to <code>str.format</code>), add string padding, format datetime objects, and more! All within f-string format specifiers.</p>
<h2 id="regular-f-strings">Regular f-strings</h2>
<pre tabindex="0"><code>Hello World!
</code></pre><h2 id="debug-expressions">Debug Expressions</h2>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"</span><span>{</span>name<span>=}</span><span>, </span><span>{</span>age<span>=}</span><span>"</span>)
</span></span></code></pre></div><pre tabindex="0"><code>name='Claude', age=3
</code></pre><h2 id="number-formatting">Number Formatting</h2>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"Pi: </span><span>{</span>pi<span>:</span><span>.2f</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Avogadro: </span><span>{</span>avogadro<span>:</span><span>.2e</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Big Number: </span><span>{</span>big_num<span>:</span><span>,</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Hex: </span><span>{</span>num<span>:</span><span>#0x</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Number: </span><span>{</span>num<span>:</span><span>09</span><span>}</span><span>"</span>)
</span></span></code></pre></div><pre tabindex="0"><code>Pi: 3.14
Avogadro: 6.02e+23
Big Number: 1,000,000
Hex: 0x1a4
Number: 000000420
</code></pre><h2 id="string-padding">String Padding</h2>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"Left: |</span><span>{</span>word<span>:</span><span>&lt;10</span><span>}</span><span>|"</span>)
</span></span><span><span>print(<span>f</span><span>"Right: |</span><span>{</span>word<span>:</span><span>&gt;10</span><span>}</span><span>|"</span>)
</span></span><span><span>print(<span>f</span><span>"Center: |</span><span>{</span>word<span>:</span><span>^10</span><span>}</span><span>|"</span>)
</span></span><span><span>print(<span>f</span><span>"Center *: |</span><span>{</span>word<span>:</span><span>*^10</span><span>}</span><span>|"</span>)
</span></span></code></pre></div><pre tabindex="0"><code>Left: |Python    |
Right: |    Python|
Center: |  Python  |
Center *: |**Python**|
</code></pre><h2 id="date-formatting">Date Formatting</h2>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"Date: </span><span>{</span>now<span>:</span><span>%Y-%m-%d</span><span>}</span><span>"</span>)
</span></span><span><span>print(<span>f</span><span>"Time: </span><span>{</span>now<span>:</span><span>%H:%M:%S</span><span>}</span><span>"</span>)
</span></span></code></pre></div><pre tabindex="0"><code>Date: 2025-03-10
Time: 14:30:59
</code></pre><h2 id="percentage-formatting">Percentage Formatting</h2>
<div><pre tabindex="0"><code data-lang="python"><span><span>print(<span>f</span><span>"Progress: </span><span>{</span>progress<span>:</span><span>.1%</span><span>}</span><span>"</span>)
</span></span></code></pre></div><pre tabindex="0"><code>Progress: 75.0%
</code></pre><h3 id="additional-resources-9">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/python-f-strings/">Python’s F-String for String Interpolation and Formatting</a></li>
<li><a href="https://realpython.com/python-format-mini-language/">Python’s Format Mini-Language for Tidy Strings</a></li>
<li><a href="https://docs.python.org/3/tutorial/inputoutput.html">Python Docs - Input and Output</a></li>
<li><a href="https://peps.python.org/pep-0498/">PEP 498 – Literal String Interpolation</a></li>
</ul>
<h2 id="11-cache--lru_cache">11. Cache / lru_cache</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1899571802873135208">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1899571802873135208">Nitter Mirror</a></strong></p></blockquote>
<p>You can use the built-in <strong><code>@cache</code></strong> decorator to dramatically speed up recursive functions and expensive calculations! (which superseded <code>@lru_cache</code> in Python 3.9!)</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> functools <span>import</span> cache
</span></span><span><span>
</span></span><span><span><span>@cache</span>
</span></span><span><span><span>def</span> <span>fib</span>(n):
</span></span><span><span>    <span>return</span> n <span>if</span> n <span>&lt;</span> <span>2</span> <span>else</span> fib(n<span>-</span><span>1</span>) <span>+</span> fib(n<span>-</span><span>2</span>)
</span></span></code></pre></div><p>Since Python 3.2, <code>@lru_cache</code> was introduced as part of the <code>functools</code> module for quick &amp; clean function memoization. Starting with Python 3.9, <code>@cache</code> was added for the same effect with less code. <code>lru_cache</code> still exists if you want explicit control of the cache size.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span>FIB_CACHE <span>=</span> {}
</span></span><span><span>
</span></span><span><span><span># With Manual Caching :(</span>
</span></span><span><span><span>def</span> <span>fib</span>(n):
</span></span><span><span>    <span>if</span> n <span>in</span> FIB_CACHE:
</span></span><span><span>        <span>return</span> FIB_CACHE[n]
</span></span><span><span>    <span>if</span> n <span>&lt;=</span> <span>2</span>:
</span></span><span><span>        <span>return</span> <span>1</span>
</span></span><span><span>    FIB_CACHE[n] <span>=</span> fib(n <span>-</span> <span>1</span>) <span>+</span> fib(n <span>-</span> <span>2</span>)
</span></span><span><span>    <span>return</span> FIB_CACHE[n]
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> functools <span>import</span> lru_cache
</span></span><span><span>
</span></span><span><span><span># Same code with lru_cache :)</span>
</span></span><span><span><span>@lru_cache</span>(maxsize<span>=</span><span>None</span>)
</span></span><span><span><span>def</span> <span>fib</span>(n):
</span></span><span><span>    <span>return</span> n <span>if</span> n <span>&lt;</span> <span>2</span> <span>else</span> fib(n<span>-</span><span>1</span>) <span>+</span> fib(n<span>-</span><span>2</span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> functools <span>import</span> cache
</span></span><span><span>
</span></span><span><span><span># Same code with new Python 3.9's cache :D</span>
</span></span><span><span><span>@cache</span>
</span></span><span><span><span>def</span> <span>fib</span>(n):
</span></span><span><span>    <span>return</span> n <span>if</span> n <span>&lt;</span> <span>2</span> <span>else</span> fib(n<span>-</span><span>1</span>) <span>+</span> fib(n<span>-</span><span>2</span>)
</span></span></code></pre></div><h3 id="additional-resources-10">Additional Resources</h3>
<ul>
<li><a href="https://www.datacamp.com/tutorial/python-cache-introduction">Python Cache: Two Simple Methods</a></li>
<li><a href="https://realpython.com/lru-cache-python/">(outdated) Caching in Python Using the LRU Cache Strategy</a></li>
<li><a href="https://docs.python.org/3/library/functools.html#functools.cache">Python Docs - <code>@functools.cache</code></a></li>
<li><a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">Python Docs - <code>@functools.lru_cache</code></a></li>
</ul>
<h2 id="12-python-futures">12. Python Futures</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1899900763977228374">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1899900763977228374">Nitter Mirror</a></strong></p></blockquote>
<p>Did you know that Python has native <code>Promise</code>-like concurrency control?</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> concurrent.futures <span>import</span> Future
</span></span><span><span>
</span></span><span><span><span># Manually create a Future Object</span>
</span></span><span><span>future <span>=</span> Future()
</span></span><span><span>
</span></span><span><span><span># Set its result whenever you want</span>
</span></span><span><span>future<span>.</span>set_result(<span>"Hello from the future!"</span>)
</span></span><span><span>
</span></span><span><span><span># Get the result</span>
</span></span><span><span>print(future<span>.</span>result())  <span># "Hello from the future!"</span>
</span></span></code></pre></div><p>Python’s <strong><code>concurrent.futures</code></strong> module gives you direct control over async operations, just like JS Promises. For example, they let you attach callbacks that run when the result is ready (just like JS’s <code>.then()</code>).</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> concurrent.futures <span>import</span> Future
</span></span><span><span>
</span></span><span><span>future <span>=</span> Future()
</span></span><span><span>
</span></span><span><span><span># Add callbacks BEFORE or AFTER completion!</span>
</span></span><span><span>future<span>.</span>add_done_callback(<span>lambda</span> f: print(<span>f</span><span>"Got: </span><span>{</span>f<span>.</span>result()<span>}</span><span>"</span>))
</span></span><span><span>
</span></span><span><span>future<span>.</span>set_result(<span>"Async result"</span>)
</span></span><span><span><span># Prints: "Got: Async result"</span>
</span></span><span><span>
</span></span><span><span>future<span>.</span>add_done_callback(<span>lambda</span> f: print(<span>f</span><span>"After: </span><span>{</span>f<span>.</span>result()<span>}</span><span>"</span>))
</span></span><span><span><span># Prints: "After: Async result"</span>
</span></span></code></pre></div><p>Python Futures also come with primitives to handle exceptions, set timeouts, or stop tasks completely.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> concurrent.futures <span>import</span> Future
</span></span><span><span><span>import</span> time<span>,</span> threading
</span></span><span><span>
</span></span><span><span><span># Create and manage a future manually</span>
</span></span><span><span>future <span>=</span> Future()
</span></span><span><span>
</span></span><span><span><span># Background task function</span>
</span></span><span><span><span>def</span> <span>background_task</span>():
</span></span><span><span>    time<span>.</span>sleep(<span>2</span>)
</span></span><span><span>    future<span>.</span>set_result(<span>"Done!"</span>)
</span></span><span><span>
</span></span><span><span>thread <span>=</span> threading<span>.</span>Thread(target<span>=</span>background_task)
</span></span><span><span>thread<span>.</span>daemon <span>=</span> <span>True</span>
</span></span><span><span>thread<span>.</span>start()
</span></span><span><span>
</span></span><span><span><span># Try all control operations</span>
</span></span><span><span>print(<span>f</span><span>"Cancelled: </span><span>{</span>future<span>.</span>cancel()<span>}</span><span>"</span>)  <span># Likely False if started</span>
</span></span><span><span>
</span></span><span><span><span>try</span>:
</span></span><span><span>    <span># Wait at most 0.5 seconds</span>
</span></span><span><span>    result <span>=</span> future<span>.</span>result(timeout<span>=</span><span>0.5</span>)
</span></span><span><span><span>except</span> <span>TimeoutError</span>:
</span></span><span><span>    print(<span>"Timed out!"</span>)
</span></span><span><span>
</span></span><span><span><span># Create failed future</span>
</span></span><span><span>err_future <span>=</span> Future()
</span></span><span><span>err_future<span>.</span>set_exception(<span>ValueError</span>(<span>"Failed"</span>))
</span></span><span><span>print(<span>f</span><span>"Has error: </span><span>{</span>bool(err_future<span>.</span>exception())<span>}</span><span>"</span>)
</span></span></code></pre></div><p>Just like modern JS, the <code>asyncio</code> module has its own Future that works seamlessly with Python’s <code>async/await</code> syntax:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> asyncio
</span></span><span><span>
</span></span><span><span><span>async</span> <span>def</span> <span>main</span>():
</span></span><span><span>    future <span>=</span> asyncio<span>.</span>Future()
</span></span><span><span>
</span></span><span><span>    <span># Set result after delay</span>
</span></span><span><span>    asyncio<span>.</span>create_task(set_after_delay(future))
</span></span><span><span>
</span></span><span><span>    <span># Await just like a JS Promise!</span>
</span></span><span><span>    result <span>=</span> <span>await</span> future
</span></span><span><span>    print(result)  <span># "Worth the wait!"</span>
</span></span><span><span>
</span></span><span><span><span>async</span> <span>def</span> <span>set_after_delay</span>(future):
</span></span><span><span>    <span>await</span> asyncio<span>.</span>sleep(<span>1</span>)
</span></span><span><span>    future<span>.</span>set_result(<span>"Worth the wait!"</span>)
</span></span><span><span>
</span></span><span><span>asyncio<span>.</span>run(main())
</span></span></code></pre></div><p>Finally, for CPU or I/O bound tasks, Python’s <code>ThreadPoolExecutor</code> can automatically create and manage futures for you.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> concurrent.futures <span>import</span> ThreadPoolExecutor
</span></span><span><span><span>import</span> time
</span></span><span><span>
</span></span><span><span><span>def</span> <span>slow_task</span>():
</span></span><span><span>    time<span>.</span>sleep(<span>1</span>)
</span></span><span><span>    <span>return</span> <span>"Done!"</span>
</span></span><span><span>
</span></span><span><span><span>with</span> ThreadPoolExecutor() <span>as</span> executor:
</span></span><span><span>    <span># Returns a Future immediately</span>
</span></span><span><span>    future <span>=</span> executor<span>.</span>submit(slow_task)
</span></span><span><span>
</span></span><span><span>    <span># Do other work while waiting...</span>
</span></span><span><span>    print(<span>"Working..."</span>)
</span></span><span><span>
</span></span><span><span>    <span># Get result when needed</span>
</span></span><span><span>    print(future<span>.</span>result())
</span></span></code></pre></div><h3 id="additional-resources-11">Additional Resources</h3>
<ul>
<li><a href="https://medium.com/@smrati.katiyar/introduction-to-concurrent-futures-in-python-009fe1d4592c">Introduction to <code>concurrent.futures</code> in Python</a></li>
<li><a href="https://alexwlchan.net/2019/adventures-with-concurrent-futures/">Adventures in Python with <code>concurrent.futures</code></a></li>
<li><a href="https://docs.python.org/3/library/asyncio-future.html">Python Docs - Futures</a></li>
<li><a href="https://docs.python.org/3/library/concurrent.futures.html">Python Docs - <code>concurrent.futures</code></a></li>
</ul>
<h2 id="13-proxy-properties">13. Proxy Properties</h2>
<blockquote>
<p><strong><a href="https://x.com/edwardjxli/status/1900316544066007332">Original X/Twitter Thread</a>  |  <a href="https://nitter.hydranet.dev/edwardjxli/status/1900316544066007332">Nitter Mirror</a></strong></p></blockquote>
<p>Did you know you can make class attributes act as <strong>BOTH</strong> methods <strong>AND</strong> properties?!? <em>This isn’t a built-in feature of Python</em>, but instead a demonstration of what you can do with clever use of Python’s dunder (magic) methods and descriptors.</p>
<blockquote>
<p>(Note that this is very much an example implementation and should not be used in production)</p></blockquote>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> Callable, Generic, TypeVar, ParamSpec, Self
</span></span><span><span>
</span></span><span><span>P <span>=</span> ParamSpec(<span>"P"</span>)
</span></span><span><span>R <span>=</span> TypeVar(<span>"R"</span>)
</span></span><span><span>T <span>=</span> TypeVar(<span>"T"</span>)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>ProxyProperty</span>(Generic[P, R]):
</span></span><span><span>    func: Callable[P, R]
</span></span><span><span>    instance: object
</span></span><span><span>
</span></span><span><span>    <span>def</span> __init__(self, func: Callable[P, R]) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>func <span>=</span> func
</span></span><span><span>
</span></span><span><span>    <span>def</span> __get__(self, instance: object, _<span>=</span><span>None</span>) <span>-&gt;</span> Self:
</span></span><span><span>        self<span>.</span>instance <span>=</span> instance
</span></span><span><span>        <span>return</span> self
</span></span><span><span>
</span></span><span><span>    <span>def</span> __call__(self, <span>*</span>args: P<span>.</span>args, <span>**</span>kwargs: P<span>.</span>kwargs) <span>-&gt;</span> R:
</span></span><span><span>        <span>return</span> self<span>.</span>func(self<span>.</span>instance, <span>*</span>args, <span>**</span>kwargs)
</span></span><span><span>
</span></span><span><span>    <span>def</span> __repr__(self) <span>-&gt;</span> str:
</span></span><span><span>        <span>return</span> self<span>.</span>func(self<span>.</span>instance)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>proxy_property</span>(func: Callable[P, R]) <span>-&gt;</span> ProxyProperty[P, R]:
</span></span><span><span>    <span>return</span> ProxyProperty(func)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Container</span>:
</span></span><span><span>    <span>@proxy_property</span>
</span></span><span><span>    <span>def</span> <span>value</span>(self, val: int <span>=</span> <span>5</span>) <span>-&gt;</span> str:
</span></span><span><span>        <span>return</span> <span>f</span><span>"The value is: </span><span>{</span>val<span>}</span><span>"</span>
</span></span><span><span>
</span></span><span><span><span># Example usage</span>
</span></span><span><span>c <span>=</span> Container()
</span></span><span><span>print(c<span>.</span>value)      <span># Returns: The value is: 5</span>
</span></span><span><span>print(c<span>.</span>value(<span>7</span>))   <span># Returns: The value is: 7</span>
</span></span></code></pre></div><p><em>How does this work under the hood?</em> It comes down to Python’s <strong><a href="https://docs.python.org/3/howto/descriptor.html">Descriptor Protocol</a></strong>:</p>
<ol>
<li>
<p>The <code>__get__</code> method transforms the <code>ProxyProperty</code> object into a <strong>descriptor</strong>.</p>
</li>
<li>
<p>When you access <code>c.value</code>, Python calls <code>__get__</code> which returns <code>self</code> (the descriptor instance).</p>
</li>
<li>
<p>The <code>__repr__</code> method handles property access (returning default values).</p>
</li>
<li>
<p>The <code>__call__</code> method handles method calls with parameters.</p>
</li>
</ol>
<p>This creates a dual-purpose attribute that can be both read directly AND called like a function!</p>
<p>The benefit of this class is that it allows you to create intuitive APIs where a property might need configuration, or properties that should have sensible defaults but still allow for customization.</p>
<blockquote>
<p>If you want to look at a proper production-ready implementation of <strong>proxy properties</strong>, check out Codegen’s implementation of <code>ProxyProperty</code> here: <a href="https://github.com/codegen-sh/codegen/blob/590ce812c08d973d8f2c22795ab3e5055cea6b1e/src/codegen/sdk/_proxy.py#L5">codegen/src/codegen/sdk/_proxy.py</a></p></blockquote>
<h3 id="additional-resources-12">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/python-descriptors/">Python Descriptors: An Introduction</a></li>
<li><a href="https://deepsource.com/blog/demystifying-python-descriptor-protocol">Demystifying Python’s Descriptor Protocol</a></li>
<li><a href="https://docs.python.org/3/howto/descriptor.html">Descriptor Guide - Python Wiki</a></li>
<li><a href="https://wrapt.readthedocs.io/en/latest/wrappers.html">Proxies and Wrappers</a></li>
</ul>

<p>Finally, introducing one of Python’s most powerful yet mysterious features: <strong>Metaclasses</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>MyMetaclass</span>(type):
</span></span><span><span>    <span>def</span> __new__(cls, name, bases, namespace):
</span></span><span><span>        <span># Magic happens here</span>
</span></span><span><span>        <span>return</span> super()<span>.</span>__new__(cls, name, bases, namespace)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>MyClass</span>(metaclass<span>=</span>MyMetaclass):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span>obj <span>=</span> MyClass()
</span></span></code></pre></div><p>Classes in Python aren’t just blueprints for objects. They’re objects too! And every object needs a class that created it. So what creates class objects? <strong>Metaclasses</strong>.</p>
<p>By default, Python uses the <code>type</code> metaclass to create all classes. For example, these two are equivalent to each other:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Create a MyClass object</span>
</span></span><span><span><span>class</span> <span>MyClass</span>:
</span></span><span><span>    <span>...</span>
</span></span><span><span>obj <span>=</span> MyClass()
</span></span><span><span>
</span></span><span><span><span># Also creates a MyClass object</span>
</span></span><span><span>obj2 <span>=</span> type(<span>"MyClass"</span>, (), {})
</span></span></code></pre></div><p>To break down what those arguments mean, here is an example that creates a class with an attribute <code>x</code> and a method <code>say_hi</code>, that also subclasses off <code>object</code>.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># type(</span>
</span></span><span><span><span>#     name,</span>
</span></span><span><span><span>#     bases,</span>
</span></span><span><span><span>#     attributes</span>
</span></span><span><span><span># )</span>
</span></span><span><span>CustomClass <span>=</span> type(
</span></span><span><span>    <span>'CustomClass'</span>,
</span></span><span><span>    (object,),
</span></span><span><span>    {<span>'x'</span>: <span>5</span>, <span>'say_hi'</span>: <span>lambda</span> self: <span>'Hello!'</span>}
</span></span><span><span>)
</span></span><span><span>
</span></span><span><span>obj <span>=</span> CustomClass()
</span></span><span><span>print(obj<span>.</span>x)  <span># 5</span>
</span></span><span><span>print(obj<span>.</span>say_hi())  <span># Hello!</span>
</span></span></code></pre></div><p>In essence, Metaclasses let you customize and modify these arguments during class creation. For example, here is a metaclass that doubles every integer attribute for a class:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>DoubleAttrMeta</span>(type):
</span></span><span><span>    <span>def</span> __new__(cls, name, bases, namespace):
</span></span><span><span>        new_namespace <span>=</span> {}
</span></span><span><span>        <span>for</span> key, val <span>in</span> namespace<span>.</span>items():
</span></span><span><span>            <span>if</span> isinstance(val, int):
</span></span><span><span>                val <span>*=</span> <span>2</span>
</span></span><span><span>            new_namespace[key] <span>=</span> val
</span></span><span><span>        <span>return</span> super()<span>.</span>__new__(cls, name, bases, new_namespace)
</span></span><span><span>
</span></span><span><span><span>class</span> <span>MyClass</span>(metaclass<span>=</span>DoubleAttrMeta):
</span></span><span><span>    x <span>=</span> <span>5</span>
</span></span><span><span>    y <span>=</span> <span>10</span>
</span></span><span><span>
</span></span><span><span>print(MyClass<span>.</span>x)  <span># 10</span>
</span></span><span><span>print(MyClass<span>.</span>y)  <span># 20</span>
</span></span></code></pre></div><p>Here is another example of a metaclass that registers every class created into a registry.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Metaclass Solution =====</span>
</span></span><span><span><span>class</span> <span>RegisterMeta</span>(type):
</span></span><span><span>    registry <span>=</span> []
</span></span><span><span>    <span>def</span> __new__(mcs, name, bases, attrs):
</span></span><span><span>        cls <span>=</span> super()<span>.</span>__new__(mcs, name, bases, attrs)
</span></span><span><span>        mcs<span>.</span>registry<span>.</span>append(cls)
</span></span><span><span>        <span>return</span> cls
</span></span></code></pre></div><p><em>The problem is</em>, decorators could achieve this same goal without the use of black magic (and it’s often cleaner too).</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># ===== Decorator Solution =====</span>
</span></span><span><span><span>def</span> <span>register</span>(cls):
</span></span><span><span>    registry<span>.</span>append(cls)
</span></span><span><span>    <span>return</span> cls
</span></span><span><span>
</span></span><span><span><span>@register</span>
</span></span><span><span><span>class</span> <span>MyClass</span>:
</span></span><span><span>    <span>pass</span>
</span></span></code></pre></div><p>And that kind of brings to light the biggest problem with metaclasses:</p>
<p><strong>Almost 100% of the time, you will never need to touch them.</strong></p>
<p>In your day-to-day development, 99% of your code won’t ever hit a use case where metaclasses could be useful. And of that 1%, 95% of those cases could just be solved with regular decorators, dunder methods, or just plain inheritance.</p>
<p>That’s why there is that one famous Python quote that goes:</p>
<p><q>
    Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don’t. - Tim Peters
</q></p><p>But if you are that 1% which has a unique enough problem that only metaclasses can solve, they are a powerful tool that lets you tinker with the internals of the Python object system.</p>
<blockquote>
<p><strong>As for some real-world examples of metaclasses:</strong></p>
<ul>
<li>Python’s “ABC” implementation uses metaclasses to implement abstract classes.</li>
<li>Python’s “Enum” implementation uses it to create enumeration types.</li>
<li>A bunch of 3rd party libraries like Django, SQLAlchemy, Pydantic, and Pytest use metaclasses for a variety of purposes.</li>
</ul></blockquote>
<h3 id="additional-resources-13">Additional Resources</h3>
<ul>
<li><a href="https://realpython.com/python-metaclasses/">Python Metaclasses</a></li>
<li><a href="https://sentry.io/answers/what-are-Python-metaclasses/">What are Python Metaclasses?</a></li>
<li><a href="https://medium.com/@miguel.amezola/demystifying-python-metaclasses-understanding-and-harnessing-the-power-of-custom-class-creation-d7dff7b68de8">Demystifying Python Metaclasses</a></li>
<li><a href="https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/files/meta-vladimir.txt">Re: The metaclass saga using Python</a></li>
</ul>
<h2 id="fin">Fin</h2>
<p><strong>And that’s it folks!</strong> 14 of some of the most interesting &amp; underrated Python features that I’ve encountered in my Python career.</p>
<p>If you’ve made it this far, shoot me a quick message as to which ones you’ve seen before and which ones you haven’t! I’d love to hear from you.</p>
<p>Happy Python-ing, y’all 🐍!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Source Projects Receive Funding to Reclaim the Public Internet (332 pts)]]></title>
            <link>https://nlnet.nl/news/2025/20250422-announcement-grants-CommonsFund.html</link>
            <guid>43769482</guid>
            <pubDate>Wed, 23 Apr 2025 07:20:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nlnet.nl/news/2025/20250422-announcement-grants-CommonsFund.html">https://nlnet.nl/news/2025/20250422-announcement-grants-CommonsFund.html</a>, See on <a href="https://news.ycombinator.com/item?id=43769482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincolumn">
          
          <p>It is wonderful to see the growing number of people working on digital commons, inventing and improving technologies to the benefit of all humanity. 42 of such projects have been selected for funding in the October call of the NGI Zero Commons Fund. In terms of applications, it was the largest call round in NGI Zero's life time. And we'd like to take this space to thank <em>all</em> applicants for their contributions to an internet for people rather than for profit.</p>
          <p>The selected projects all contribute, one way or another, to the mission of the Commons Fund: reclaiming the public nature of the internet. For example, there are people working on <a href="https://nlnet.nl/project/MNT-Reform-Touch/">MNT Reform Touch</a> (an open hardware tablet device) and the <a href="https://nlnet.nl/project/Solar-FemtoTX/">Solar FemtoTX motherboard</a> — a collaborative effort to create an ultra-low power motherboard that can run on solar power. The Open Terms Archive offers <a href="https://nlnet.nl/project/Modular-OTA/">public tracking of the evolution of terms and conditions</a> to facilitate democratic oversight. <a href="https://nlnet.nl/project/LLM2FPGA/">LLM2FPGA</a> aims to enable running open source LLMs locally on FPGAs using a fully open-source toolchain. <a href="https://nlnet.nl/project/bcachefs-crypto-API/">bcachefs</a> readies itself as the next generation filesystem for Linux, improving performance, scalability and reliability when compared to legacy filesystems and <a href="https://nlnet.nl/project/KDEPlasma-gestures/">KDE Plasma Gestures</a> will add multi-touch and stroke gestures to the Plasma Desktop. And that's just a small sample of the wide range of important contributions being worked on. Read on to meet all the projects selected in this funding round.</p>
          <p><b>If you applied for a grant</b><br> This is the selection for the <a href="https://nlnet.nl/news/2024/20240601-call.html">October call</a> of the NGI Zero Commons Fund fund only. We always inform <em>all</em> applicants about the outcome of the review ahead of the public announcement, whether they are selected or not. If you have not heard anything, you probably applied to a later call or a different fund that is still under review.</p><details>
              <summary>How do I find out which call round I applied to?</summary>You can see which call round you applied to by checking the application number assigned to the project when you submitted the proposal. The number starts with the year and month of the call, so 2024-10- in the case of the October 2024 call. You see that same number featured in the emails we send you (It should not happen, but if you did apply to another call and did not hear anything, do contact us)</details>
          <br> <h2>Meet the new projects!</h2>
          <p><em>(you can click or tap on the project name to fold out additional information)</em></p>
          <h3>Trustworthy hardware and manufacturing</h3>
          <ul>
            <li>
              <details>
                <summary><strong>FuseSoc-compatible Web Catalog</strong> — A catalog of gateware that can be easily used with FuseSoC</summary>
                <div>
                  <p>FuseSoC is a package manager for chip designs, allowing for easy reuse and sharing of IP cores as well as combining them into larger systems. Its native core description format (CAPI2) allows describing IP cores in a tool- and vendor-independent way. Together with FuseSoC's backend library Edalize this enables creating and using portable IP cores and SoCs for a large number of EDA tools and flows.</p>
                  <p>This project will extend FuseSoC with a collaborative database and a web frontend that allows users to upload their core description files to a central repository to make it easier for others to find and inspect them. In addition, signing, SBOM generation and a web frontend will be added to increase transparency, trust and security.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/FuseSoC-catalog">https://nlnet.nl/project/FuseSoC-catalog</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>MNT Reform Touch</strong> — Open Hardware tablet device</summary>
                
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Solar FemtoTX motherboard with 802.3 cg Ethernet cards</strong> — Low-power motherboard that can run on solar power</summary>
                <div>
                  <p>Solar FemtoTX motherboard with 802.3 cg Ethernet cards is an open, collaborative effort towards designing an ultra-low power motherboard in a mobile device-sized form factor. It aims to achieve several goals: 1) to design a plug and play (PnP) motherboard that can be seamlessly integrated into an open-source hardware laptop for easy repair/replacement/upgrade. 2) to utilize the new, 802.3cg ethernet standard for a low-power LAN port, and 3) to integrate the 802.3 cg ethernet port into a single board computer with a FemtoTX-sized form factor for the lowest power consumption, facilitating minimal solar energy requirements and quick recharging.</p>
                  <p>Furthermore, the project aims to make the open-hardware framework extensible by supporting socket-based or embedded processors and peripheral devices that meet a defined size and TDP limit. This interoperability allows newer, ultra low power microprocessors to work within the FemtoTX specification, and is optimized for solar power.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Solar-FemtoTX">https://nlnet.nl/project/Solar-FemtoTX</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Tin Snipe DAQ</strong> — Digital Aquisition module</summary>
                <div>
                  <p>The Tin Snipe DAQ is a digital acquisition (DAQ) module targeting diverse professional measurement applications typically found in mid to high end hand-held Multimeters. It focuses on digital mixed signal systems while offering an upgrade over traditional Multimeters in terms of sample rate, giving usable time series data for signal integrity analysis of low speed signals. It's designed as a compact fully integrated module that comes with the necessary AFE, ADC and Signal Processor. It exposes a digital control interface over various buses (UART, I2C, USB and potentially more) to be controlled and read out via an external system processor, thus making it easy to integrate into other systems. It is targeting battery operation like traditional handheld Multimeters and will be heavily optimized for low power consumption but can also be used for bench top applications.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/TinSnipe-DAQ">https://nlnet.nl/project/TinSnipe-DAQ</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>USB 3 PHY implementation on GateMate FPGAs</strong> — USB 3 PHY implementation with Cologne Chip GateMate FPGA Transceiver</summary>
                <div>
                  <p>Since its introduction at the end of the previous century, USB has developed into the most widely used interface to connect all sorts of electronic devices. Recent versions of the USB standard provide serial communication at speeds of 5Gbps and higher, which require a dedicated hardware block (transceiver) inside a chip. Throughout the last decade, FPGA devices are gaining popularity in many applications and this trend will not stop. Even small and low-cost modern FPGA devices, such as GateMate FPGA from Cologne Chip AG, include transceivers capable of communication at 5Gbps. However, no Open Hardware and FOSS implementation of USB 3.x is available. This project will enable a universal and libre USB 3.2 Gen.1 x1 (5Gbps) connectivity on the GateMate FPGA.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/GateMate-USB3-PHY">https://nlnet.nl/project/GateMate-USB3-PHY</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Operating Systems, firmware and virtualisation</h3>
          <ul>
            <li>
              <details>
                <summary><strong>SSH Stamp</strong> — Secure SSH-to-UART bridge for devices with a serial port</summary>
                <div>
                  <p>SSH Stamp is a secure wireless-to-UART bridge implemented in Rust (no_std, no_alloc and no_unsafe whenever possible) with simplicity and robustness as its main design tenets. The firmware runs on a microcontroller running Secure SHell Protocol (RFC 4253 and related IETF standards series). This firmware can be used for multiple purposes, conveniently avoiding physical tethering and securely tunneling traffic via SSH by default: easily add telemetry to a (moving) robot, monitor and operate any (domestic) appliance remotely, conduct remote cybersecurity audits on network gear of a company, reverse engineer hardware and software for right to repair purposes, just to name a few examples -a "low level-to-SSH Swiss army knife".</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/SSH-Stamp/">https://nlnet.nl/project/SSH-Stamp/</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Ada Bootstrap Compiler</strong> — Full source bootstrap for Ada</summary>
                <div>
                  <p>Ada is an important computer language with a long history, with the compilers being built for new architectures in an ad-hoc basis based on previously existing Ada compilers from other architectures. This project aims to create a bootstrap path from the C language to an Ada compiler without relying on an existing Ada compiler binary. This will allow us to have a fully auditable trail from C to a working Ada compiler, removing concerns about hidden backdoors or other issues that may arise from using a compiler without a clear bootstrap path.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Ada-bootstrap">https://nlnet.nl/project/Ada-bootstrap</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Bcachefs userspace integration</strong> — Next generation filesystem</summary>
                <div>
                  <p>bcachefs is a next generation filesystem for Linux, with a fully modern featureset and vastly improved performance, scalability and reliability as compared to legacy filesystems. The main focus of this grant is achieving stability, but on the side there will be work on userspace integration with systemd, reworking the cryptographic API to be more robust, as well as adding the potential for users to generate telemetry data - in order to capture edge cases in the real-world.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/bcachefs-crypto-API">https://nlnet.nl/project/bcachefs-crypto-API</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>KDE Plasma Gestures</strong> — Advanced customisable gesture input on desktop and mobile</summary>
                <div>
                  <p>Plasma Desktop, made by the KDE community, is a powerful free and open source platform that competes with proprietary operating systems. This project will introduce new functionality for multi-touch and stroke gestures. Multi-touch gestures allow a user to easily switch between virtual desktops, or to open Plasma's Overview mode. They will become customizable, with a wide selection of available desktop actions. Stroke gestures allow drawing shapes to trigger actions, launch apps, and more. They will be introduced into Plasma's core desktop experience, complete with a configuration page in System Settings. Together, these features will make Plasma Desktop even more productive and intuitive to use.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/KDEPlasma-gestures">https://nlnet.nl/project/KDEPlasma-gestures</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>LeanFTL</strong> — Flash Translation Layer library for embeddedsystems</summary>
                <div>
                  <p>LeanFTL is a "Flash Translation Layer" library targeting embedded systems. An FTL library is needed on all embedded systems to deal with the constraints inherent to flash memories and to be able to resume operations safely after an unexpected loss of power (AKA "tearing events"). LeanFTL aims at being a minimal library easily portable to any MCU and able to manage both internal and external flash memories. LeanFTL goal is to avoid fragmentation by design, this means that fragmentation never occurs no matter the usage pattern. Another important feature is the emulator which allows running LeanFTL on a personal computer, allowing the integrator to provide such an emulator for its firmware. Last but not least, the emulator is able to simulate "tearing events" - this is key to ensure robustness and security of an embedded system. In other words, LeanFTL not only provide the Flash Translation Layer, it also provides a tool for validating it is correctly used, something which is typically lacking even in commercial libraries.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/LeanFTL">https://nlnet.nl/project/LeanFTL</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Maemo Leste Daedalus</strong> — Improve device coverage and advanced security for mobile Linux distro</summary>
                <div>
                  <p>Maemo Leste is a Free and Open Source mobile operating system based on GNU/Linux. The goal of the initiative is to provide a secure and modern mobile operating system that consists only of free software, obeys and respects the users' privacy and digital rights. Maemo Leste is currently focussing on upgrading and modernising it's core to the latest Debian and Devuan versions, improving the stability and security of the system as well as widening the array of supported devices.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/MaemoLeste-AppArmour">https://nlnet.nl/project/MaemoLeste-AppArmour</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Reproducible Builds in the Scala ecosystem</strong> — Deterministic builds for software written in Scala</summary>
                <div>
                  <p>While open source components can be audited through their open version history, there is no guarantee that any binaries that are distributed actually correspond to those sources. The technique to validate this is known as "Reproducible Builds": by building the same code on independent infrastructure and verifying the results are identical, you can verify the binary artifacts have not been tampered with. This is useful both for project members who want to verify no malware was inserted via their CI system or developer build machine, and for 'external' auditors who can independently verify the project as a whole is not compromised.</p>
                  <p>This project intends to improve Reproducible Builds for software written in the Scala language, which typically use the 'sbt' build tool. It will do so by making improvements to the sbt-reproducible-builds sbt plugin and other toolchain components such as sbt plugins and the Scala compiler, so that projects will be reproducible 'out of the box' as much as possible.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/ReproducibleSBT">https://nlnet.nl/project/ReproducibleSBT</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Measurement, monitoring, analysis and abuse handling</h3>
          <ul>
            <li>
              <details>
                <summary><strong>Alaveteli GDPR and Search</strong> — Better search and redacting capabilities for Alaveteli FOI request portal</summary>
                <div>
                  <p>Alaveteli is an open source platform deployed in 20+ countries that helps citizens make Freedom of Information requests and publishes them and the responses online. Access to Information laws are powerful tools by which citizens, journalists, and civil society organisations can obtain information to scrutinise government. Such legislation is an important prerequisite for accountability and bottom up participation, making it one of the cornerstones of a healthy democracy.</p>
                  <p>Alaveteli’s architecture was designed long before the introduction of GDPR. This makes it challenging to balance public access to information with protection of citizens' individual data rights. The project aims to redesign and replace Alaveteli’s antiquated search architecture and technology and implement key missing functionality to effectively locate and, when appropriate, remove personally identifiable information to ensure GDPR compliance.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Wiktionary-QA">https://nlnet.nl/project/Wiktionary-QA</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Wiktionary QA tools</strong> — QA tools to improve the quality, reliability, and consistency of Wiktionary</summary>
                <div>
                  <p>Part of the Wikimedia commons, Wiktionary.org offers a global open data set pertaining to many languages. However, this data is contributed and crowdsourced in different formats, leading to conflicting information which creates inconsistencies across languages and makes Wiktionary less reliable than it could be.</p>
                  <p>This project will develop QA modules for Wiktionary, leading to easy parsing and processing of cross-linguistic data. This helps to unify data formats across Wiktionary, and improve the overall reliability of this invaluable resource.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Wiktionary-QA/">https://nlnet.nl/project/Wiktionary-QA/</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Clearance</strong> — Curating changes to OpenStreetMap data of interest</summary>
                
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Open Terms Archive vendor lock-in break</strong> — Public tracking of the evolution of terms and conditions</summary>
                <div>
                  <p>Open Terms Archive is a digital public good that archives every version of the terms of over 800 digital services to support democratic oversight by regulators, lawmakers, journalists, researchers, and civil society. Open Terms Archive has prioritized adoption in multiple industries and jurisdictions over the past four years, by enabling easy connection from its fully open-source engine to free but proprietary platforms. The "Open Terms Archive vendor lock-in break" project aims at replacing the hardcoded interconnections with proprietary software with standardized APIs and connectors for at least one open-source platform for issue reporting, email notifications, dataset distribution, and RSS feeds publishing, while keeping compatibility with existing integrations that are used by community members.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Modular-OTA">https://nlnet.nl/project/Modular-OTA</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Middleware and identity</h3>
          <ul>
            <li>
              <details>
                <summary><strong>Accessible KDE File Management</strong> — Accessible file dialogs throughout KDE applications</summary>
                <div>
                  <p>This project aims to make a core part of computing with KDE software, namely file management, fully accessible. Many applications and frameworks by KDE are used in high-profile institutions and the public sector. Even though a main point of focus of this project is the improvement of accessibility in KDE's default file manager Dolphin, most of the work benefits framework code which is used in many of the most popular applications in the FLOSS ecosystem. As such, this project will empower people with disabilities around the world to perform more computer-driven tasks efficiently.</p>
                  <p>The accessibility improvements to "Open/Save" dialogs, the keyboard shortcut editor, and various other panels and dialogs will simplify integration of people with handicaps in various social and work contexts including public institutions and private companies, which in turn will allow more of them to base their digital infrastructure on open standards and digital commons in line with EU's value "to be free from discrimination on the basis of […] disability".</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/KDE-Dolphin-a11y">https://nlnet.nl/project/KDE-Dolphin-a11y</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Decentralised solutions, including blockchain/distributed ledger</h3>
          <ul>
            <li>
              <details>
                <summary><strong>Redwax Server Modernisation</strong> — Self-hostable X509 certificate based identity management solution</summary>
                <div>
                  <p>The Redwax Project is a set of tools and web server modules to make it easy to build and deploy secure services on the web. The Redwax modular certificate authority mod_ca provides a set of Apache http server modules that can be combined to form various types of certificate authorities, issuing certificates from a Certificate Sign Request, or with the SPKAC and SCEP protocols, servicing certificate revocation with CRLs and OCSP, and creating timestamps.</p>
                  <p>The Redwax tool provides a mechanism to read certificates and keys from a wide variety of sources, automatically associating leaf, intermediate, and trusted certificates, and optionally their private keys, then showing the metadata of or writing the certificates in a wide variety of target formats. This project will update the key modules, adjust to the current Apache API's and also fully implement the meanwhile published RFC 8894.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Redwax-SCEP-LDAP">https://nlnet.nl/project/Redwax-SCEP-LDAP</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Securing Internet protocols with decentralized identity</strong> — DIDs and Verified Credentials as SASL method</summary>
                <div>
                  <p>There has been much innovation in the last few years in the area of decentralized digital identity, including the development of standards such as Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). These technologies have led to large-scale initiatives around the world to develop digital identity wallets, including for example the European Digital Identity Wallet (EUDI). These initiatives aim at making it possible to obtain and use digital versions of identity documents such as drivers' licenses, birth certificates, university diplomas, and more.</p>
                  <p>The potential of these technologies however is much greater than just logging in to websites. In this project, we work on integrating decentralized digital identity technologies into widely used Internet protocols themselves, such as XMPP for instant messaging. In this case, a combination of identity and messaging means that you can authenticate to a messaging service using a digital identity wallet, rather than username and password. We accomplish this by specifying and building a DID-based extension for the Simple Authentication and Security Layer (SASL).</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/DID-SASL">https://nlnet.nl/project/DID-SASL</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Data and AI</h3>
          <ul>
            <li>
              <details>
                <summary><strong>Data Package implementation in TypeScript</strong> — Reference implementation of data definition language and data API</summary>
                <div>
                  <p>Data Package is a standard consisting of a set of simple yet extensible specifications to describe datasets, data files and tabular data. It is a data definition language (DDL) and data API that facilitates findability, accessibility, interoperability, and reusability (FAIR) of data. TypeScript implementation of the Data Package standard provides all the necessary functionality for working with data packages in Node.js or similar environments — including validating and extending metadata, and reading or writing data in various formats such as CSV, TSV, JSON, and OpenDocument Format (ISO/IEC 26300) as used by e.g. Excel and LibreOffice.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/DataPackage-TS">https://nlnet.nl/project/DataPackage-TS</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Livebook</strong> — Robust and distributed data and ML workflows with Python, Elixir, and Livebook</summary>
                <div>
                  <p>Livebook is an open-source interactive notebook application for the Elixir programming language and the Erlang VM ecosystem. It enables users to write, execute, and document code in real-time within a browser interface, making it ideal for exploratory programming, data analysis, teaching, and documentation. Livebook features built-in markdown support, real-time collaboration, custom visualizations, "smart cells" to automate common workflows, as well as built-in concurrent and distributed execution. The project supports the Elixir and Erlang languages and is integrating additional ones.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Livebook-Python">https://nlnet.nl/project/Livebook-Python</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>LLM2FPGA</strong> — Run Open Source LLMs locally on FPGAs</summary>
                <div>
                  <p>LLM2FPGA aims to enable local inference of open-source Large Language Models (LLMs) on FPGAs using a fully open-source toolchain. While LLM inference has been demonstrated on proprietary hardware and software, we are not aware of any widely recognized project running open-source LLMs on FPGAs through a fully open-source EDA (Electronics Design Automation) flow. To fill this gap, the project will produce an HDL implementation of a lightweight open-source LLM, verify it via simulation, and then attempt synthesis and place-and-route on freely supported FPGA devices. By providing a fully open alternative to proprietary and cloud-based LLM inference, LLM2FPGA will offer a transparent, flexible, and privacy-friendly way to run your own LLM on local hardware.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/LLM2FPGA">https://nlnet.nl/project/LLM2FPGA</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>PodOS</strong> — Personal Online Data Operating System aimed at exploring W3C Solid pods</summary>
                <div>
                  <p>PodOS is an operating system for data on Solid Pods, designed to bridge the gap between specialized apps and raw data management. It is built from the ground up for mobile-first UX, accessibility and maintainability, on top of re-usable custom elements. In the upcoming phase, PodOS will introduce new ways for users to structure, link, and repurpose their data, allowing them to organize information beyond the constraints of individual applications. Users will be able to extract information from classic documents or notes and transform them into structured resources that could be used with other Solid Apps. New developments will emphasise modularity and interoperability by integrating existing data modules, dynamically loaded dashboards and seamless transitions between PodOS and specialized apps. These advancements will give individuals and organizations greater flexibility and control over their data, making the Solid ecosystem more practical, interactive, and user-friendly.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/PodOS">https://nlnet.nl/project/PodOS</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Services + Applications (e.g. email, instant messaging, video chat, collaboration)</h3>
          <ul>
            <li>
              <details>
                <summary><strong>Mobile Typst editor</strong> — Mobile editor/viewer for Typst documents</summary>
                <div>
                  <p>Typst is a new markup-based typesetting system that is designed to be as powerful as LaTeX while being much easier to learn and use. The Typst for iOS project focuses on creating a smooth Typst document editing experience akin to Swift Playground's editing experience. Additionally it allows the compilation, presenting and sharing of pdf files all from an iPhone or iPad.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Mobile-Typst-editor/">https://nlnet.nl/project/Mobile-Typst-editor/X</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Dino</strong> — User-friendly and secure instant messaging based on XMPP</summary>
                <div>
                  <p>Dino is an open-source messaging application. It uses XMPP as an underlying protocol, which allows federated, provider-independent communication and offers a world-wide network of interconnected servers. Dino aims to be secure and privacy-friendly while at the same time offering a good user experience and a modern feature set.</p>
                  <p>This project is about adding various additional usability and privacy features such as Message moderation in groupchats (XEP-0425), message deletion (XEP-0424) and local message deletion, improved password handling and connection establishment via SASL2 (XEP-0388), Bind2 (XEP-0386), FAST (XEP-484) and storing secrets in the system keyring, improved file transfers including sending multiple images in the same message via Stateless File Sharing (XEP-0447), improving the UX in MUCs by using more efficient protocols like MUC Affiliation Versioning (XEP-0463) and by making further use of occupant IDs (XEP-0421) in the context of message correction and message deletion. It will also extending support of message formatting via Message Markup (XEP-0394).</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Dino-UX">https://nlnet.nl/project/Dino-UX</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Podlibre</strong> — Dedicated, customizable podcast editor</summary>
                <div>
                  <p>Podlibre is an all-in-one, customizable podcast editor designed to empower podcasters with a tool they can rely on daily. In the past decade, the popularity of podcasts has exploded - but so far there was no good podcast-specific workflow for creators to handle the process. Obviously one can use generic sound editors, but these are typically geared toward music production and lack features that make it easy for podcasters and journalists to produce consistent podcast content. With a customizable workflow and plugin architecture, Podlibre allows users to tailor their experience while integrating with third-party services. It provides all essential features in one place, including noise reduction, mouth noise editing, multi-channel audio editing, music insertion, local transcription with manual correction, chapter editing, metadata editing (ID3, RSS), local publishing, and publishing to hosting platforms (Castopod, Funkwale, Faircamp).</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Podlibre">https://nlnet.nl/project/Podlibre</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Signature PDF</strong> — PDF editing and server-based digital signing workflow</summary>
                <div>
                  <p>Signature PDF allows users to sign PDFs online, individually or with others. The project offers as well the possibilities to reorganize pages (merge, sort, rotate, delete, extract pages, etc.), edit metadata, and compress PDFs. This tool aims to be a free alternative to existing proprietary web services, offering users more control and guarantee of what happens to the PDF processed by the software.</p>
                  <p>Signature PDF is easily deployable on a server of any size, a laptop, a container image or a Yunohost instance. Scope of the project is to implement verification of signed PDFs, integration into third-party software, improve smartphone ergonomy and accessibility, and other improvementes to meet the requests/needs identified by users.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/SignaturePDF-UX">https://nlnet.nl/project/SignaturePDF-UX</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Flock XR</strong> — 3D visual creativity and coding tool</summary>
                <div>
                  <p>Flock XR is a visual creativity and coding tool that allows young people to create 3D experiences in a web browser. Flock XR allows young people and beginners to create apps relevant to the virtual worlds that they use socially. Through creating with Flock XR, young people develop technical and creative skills such as coding and working in 3D space with 3D models and animations. They will be able to create using extended reality features including VR, Augmented Reality, 3D printing and spatial audio. This puts them on the path to amazing career opportunities across many industries. Flock XR is being developed with an inclusion first approach using co-design techniques with young people in our pilots. After a successful schools pilot we are focussing on improving user experience, stability and access for all.</p>
                  <p>Flock XR builds on established open source tools, Blockly and Babylon.js to bring modern 3D creation to young people on the devices they already use. We’re designing Flock XR for users who may have older hardware and limited data access. And we take young people’s rights, safety and data privacy very seriously. We’re extending young people’s reality with Flock XR and giving them the skills to create the virtual worlds that humanity needs.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/FlockXR">https://nlnet.nl/project/FlockXR</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>ClassQuiz</strong> — Libre quizing tool</summary>
                <div>
                  <p>ClassQuiz is a quiz application designed for, but not limited to, classrooms. It allows anyone to create live quizzes to engage the audience in a fun way, where each player also competes against the others by answering questions as fast as possible to score high. By providing a simple setup for self-hosting, it also allows many educators to host quizzes without any privacy concerns. ClassQuiz was born as an alternative to Kahoot! because educational software for students should be built with privacy in mind.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/ClassQuiz">https://nlnet.nl/project/ClassQuiz</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Federating pedagogical immersive experiences</strong> — Framework for playful learning content in enhanced reality</summary>
                <div>
                  <p>Emerging technologies like augmented and virtual reality (XR) provide incredible avenues to teach and learn. Unfortunately, nearly all content and ways to create it remain centralized through large captive platforms. Such platforms lock users and their creations to their closed source environment and filtering mechanisms. This process risk reflecting assumptions on how teaching can be done. The project "Federating pedagogical immersive experiences" proposes a self-hostable platform to remix simple pedagogical XR games. Learners themselves can then, together with parents and teachers, freely share back pedagogically, culturally and linguistically adapted content - curated by their own instance and benefiting from immersive technologies without being locked to a platform.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/ImmersiveXP">https://nlnet.nl/project/ImmersiveXP</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Kaidan MUC + legacy OMEMO</strong> — Multi-user chat and improved legacy interoperability for Kaidan XMPP client</summary>
                <div>
                  <p>Kaidan is a user-friendly and modern chat app for every device. It uses the open communication protocol XMPP (Jabber). Unlike other chat apps, you are not dependent on one specific service provider. Instead, you can choose between various servers and clients. Kaidan is one of those XMPP clients.</p>
                  <p>It is easy to get started and switch devices with Kaidan. Additionally, it adapts to your operating system and device's dimensions. It runs on mobile and desktop systems including Linux, Windows, macOS, Android, Plasma Mobile and Ubuntu Touch. The user interface makes use of Kirigami and Qt Quick. The backend of Kaidan is entirely written in C++ using Qt and the Qt-based XMPP library QXmpp.</p>
                  <p>This project will make improvements to Kaidan across the board, ranging from multi-user chat, backups, bookmarks, support for legacy OMEMO encryption, SASL improvements, message retraction and more media sharing functionality.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Kaidan-MUC">https://nlnet.nl/project/Kaidan-MUC</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>LiberaForms</strong> — Self-hostable E2EE libre form server</summary>
                <div>
                  <p>LiberaForms is an online form tool to easily create and manage forms. It can be used by neighbours, friends, colleagues and anyone else who values privacy. The server can be self-hosted and form answers can be end-to-end OpenPGP encrypted. LiberaForms comes with a comprehensible list of features for both form authors and site administrators alike, such as integrated GDPR policies. This grant will be used to make a number of usability improvements, to make LiberaForms a relevant tool for educational use cases, and add many new features requested by the people who already use it.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/LiberaForms-Edu">https://nlnet.nl/project/LiberaForms-Edu</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Modernizing Paged.js Web-to-Print</strong> — Quality typesetting based on HTML and CSS</summary>
                <div>
                  <p>Paged.js is a free and open source JavaScript library that paginates content in the browser to create print/PDF output from HTML and CSS content. This is necessary for instance for delivering browser-native office productivity solutions - users expect these to produce good output but don't want to have the burden of legacy formats. The proposed project will fundamentally revisit/upgrade the architecture of paged.js. to support additional layouts, add advanced layout capabilities and implement PDF/UA tagging.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/PagedJS">https://nlnet.nl/project/PagedJS</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Peertube plugin livechat</strong> — Public and private messaging for Peertube content + live streams</summary>
                <div>
                  <p>Peertube is a free, decentralized and sovereign alternative to video-on-demand and live-streaming platforms. The Peertube Livechat project is a popular plugin for PeerTube that adds chatting capabilities to Peertube, so the audience can interact with streamers during their live streams. The functionality goes way beyond a mere chat system: it also provides moderation tools, polls, chat integration in the live stream, TODO-list for streamers and moderation team, and more. Its ambition is to become a complete ecosystem for live streaming.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/PeerTube-Livechat-UX">https://nlnet.nl/project/PeerTube-Livechat-UX</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>PeerTube for Institutions</strong> — Make PeerTube easier to manage and moderate at scale</summary>
                <div>
                  <p>PeerTube is a free-libre and federated video platforms that empowers anyone to self host video content without being isolated in the wide web. Many institutions have started using PeerTube, to reclaim control over their video hosting. By choosing PeerTube, they offer a wider audience the opportunity to familiarize themselves with PeerTube.</p>
                  <p>A significant part of this project focuses on enabling these institutional use cases, and is designed from their feedback. We plan to add ownership transfer and shared administration for video channels, quality of life features for moderation and administration, more control on an instance look and experience and a set-up wizard with relevant presets (and more). We also want to adapt the mobile app to tablet and TV devices, and add a watch offline option.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/PeerTube-for-Institutions/">https://nlnet.nl/project/PeerTube-for-Institutions/</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Repath Studio</strong> — SVG editor written in Clojurescript</summary>
                <div>
                  <p>Repath Studio is a cross platform vector graphics editor, that combines procedural tooling with traditional design workflows. It includes an interactive shell, which allows evaluating code to generate shapes, or even extend the editor on the fly. Supporting multiple programming languages and enriching the existing API is planned. The tool relies heavily on the SVG specification, and aims to educate users about it. Creating and editing SMIL animations - an SVG extension – is an important aspect of the project, that is yet to be fully implemented. An advanced undo/redo mechanism is used to maintain a full history tree of actions in memory, so users will never lose their redo stack. We are exploring ways to persist this history to disk. Some built-in accessibility testing tools are already included, but we want to add more. Extensibility is also something that we want to enhance, in order to allow creating and sharing custom tools and workflows. Integrations with third party tools will also be investigated.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/RepathStudio">https://nlnet.nl/project/RepathStudio</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>StreetComplete Multiplatform</strong> — OpenStreetMap editing beyond Android</summary>
                <div>
                  <p>The goal of this project is to migrate StreetComplete from an Android app to a multiplatform app, making use of Kotlin Multiplatform and Compose Multiplatform for the UI, thus, allowing the app to be released on other platforms, such as iOS and eventually Linux.</p>
                  <p>This will allow for a significantly larger audience that is able to casually contribute missing data to OpenStreetMap on the go, as StreetComplete is the go-to app for this purpose, aimed at non-tech-savvy people and presented in a slightly gamified fashion. OpenStreetMap, in turn, is the free wiki worldmap.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/StreetComplete-multiplatform">https://nlnet.nl/project/StreetComplete-multiplatform</a></p>
                </div>
              </details>
            </li>
          </ul>
          <h3>Vertical use cases, Search, Community</h3>
          <ul>
            <li>
              <details>
                <summary><strong>An OpenScience flavour of Bonfire on NixOS for preprints</strong> — Discuss preprints based on W3C ActivityPub federation</summary>
                <div>
                  <p>Preprints have revolutionised scholarly publishing, offering a rapid and open way to share research findings, establishing priority, receiving early feedback, and accelerating scientific discovery. Online discussions around preprints regularly take place on social media, but there still exists a gap in encouraging fluid discourse around science and making it a recognised academic activity.</p>
                  <p>This project aims to address the gap by facilitating and integrating these conversations into the scholarly framework using FOSS tooling. Outcomes include; establishing a Bonfire network tailored for preprints, with reproducible deployment made possible via NixOS, bringing existing communities into the Fediverse, amplifying contributions using existing scholarly infrastructure, exploring new models of peer evaluation, and supporting recognition of this crucial scholarly activity.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Sciety-ActivityPub">https://nlnet.nl/project/Sciety-ActivityPub</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>cables.gl editor features</strong> — Create beautiful, interactive, visual web content</summary>
                <div>
                  <p>Cables is a tool which allows people to create beautiful, interactive, visual web content without knowing how to type a line of code. Your work is easily exportable at any time, so you can embed it into your website, use it an immersive VR experience, or integrate into other kinds of creative output. Cables patches can be published, shared, copied and remixed by the entire community. This allows people to constantly learn new things from each other. There is both a browser based version and a standalone, offline version offering a user-friendly development environment.</p>
                  <p>This new grant adds an improved keyframing- and animation user interface (timeline) that makes cables.gl much more accessible for animators and motion designers. The team will also add a physics engine, Gaussian Splatting (a new method of rendering realistic 3d scenes), dynamic operator instancing/repeating, a stepping debugger and a comprehensive shadergraph system that allows to create complex shaders by combining small modules.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/cables.gl-editorfeatures">https://nlnet.nl/project/cables.gl-editorfeatures</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>MOTIS</strong> — European Public Transport Door to Door Real-Time Routing with MOTIS</summary>
                <div>
                  <p>This project aims to enhance MOTIS, an open-source, scalable, intermodal real-time routing system that powers the provider-neutral public transport routing service transitous.org. This grant will add support for the relevant European Transmodel data standards NeTEx, SIRI-ET, SIRI-SX, and OJP. Hereby, we will enable open and privacy friendly borderless routing across Europe from door to door using data published by European National Access Points (NAP) in compliance with EU regulation 2017/1926. Its results will be deployed via transitous.org and integrated into applications such as KDE Itinerary, KTrip, and Gnome Maps, fostering a fully open alternative to proprietary solutions.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/MOTIS">https://nlnet.nl/project/MOTIS</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Open Terms Archive vendor lock-in break</strong> — Public tracking of the evolution of terms and conditions</summary>
                <div>
                  <p>Open Terms Archive is a digital public good that archives every version of the terms of over 800 digital services to support democratic oversight by regulators, lawmakers, journalists, researchers, and civil society. Open Terms Archive has prioritized adoption in multiple industries and jurisdictions over the past four years, by enabling easy connection from its fully open-source engine to free but proprietary platforms. The "Open Terms Archive vendor lock-in break" project aims at replacing the hardcoded interconnections with proprietary software with standardized APIs and connectors for at least one open-source platform for issue reporting, email notifications, dataset distribution, and RSS feeds publishing, while keeping compatibility with existing integrations that are used by community members.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/Modular-OTA">https://nlnet.nl/project/Modular-OTA</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>PodOS</strong> — Personal Online Data Operating System aimed at exploring W3C Solid pods</summary>
                <div>
                  <p>PodOS is an operating system for data on Solid Pods, designed to bridge the gap between specialized apps and raw data management. It is built from the ground up for mobile-first UX, accessibility and maintainability, on top of re-usable custom elements. In the upcoming phase, PodOS will introduce new ways for users to structure, link, and repurpose their data, allowing them to organize information beyond the constraints of individual applications. Users will be able to extract information from classic documents or notes and transform them into structured resources that could be used with other Solid Apps. New developments will emphasise modularity and interoperability by integrating existing data modules, dynamically loaded dashboards and seamless transitions between PodOS and specialized apps. These advancements will give individuals and organizations greater flexibility and control over their data, making the Solid ecosystem more practical, interactive, and user-friendly.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/PodOS">https://nlnet.nl/project/PodOS</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>Pushing forward for CSS Print</strong> — High end print from HTML and CSS</summary>
                <div>
                  <p>The Web is one of the largest common resources, accessible to everyone across the globe, based on standards maintained by the World Wide Web Consortium (W3C). Certain CSS modules have been developed specifically for paginated design and publication: the fragmentation model, which divides content into pages, columns, or regions, and includes features such as controlling flow breakpoints (page breaks, column breaks, etc.). Additionally, three W3C CSS modules focus on formatting for "paginated media", defining how pages are structured and providing essential functionality for printed page layouts, including margin sizes, page numbering, running headers, footnotes, templates, and element positioning on the page. However, these modules remain in the Working Draft phase, and currently no web browser has fully implemented them.</p>
                  <p>In response to this limited browser support, several open-source initiatives (such as WeasyPrint and Paged.js) have emerged over the past 15 years, each with a unique approach to addressing these challenges. The user community continues to grow, new layout requirements have arisen, revealing that the current specifications are insufficient to meet the demands of modern paginated layout. As developers, maintainers and users of these open-source solutions, our goal is to address these gaps by collaborating on the development of new specifications in a structured and collective manner, demonstrating the feasibility of these new specifications by implementing them in various tools and engaging in advocacy with the CSS Working Group (CSSWG) to promote the adoption of these new specification proposals.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/CSS-Print">https://nlnet.nl/project/CSS-Print</a></p>
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary><strong>XR Fragments Teamware</strong> — Design, deploy, federate and integrate portable XR experiences</summary>
                <div>
                  <p>XR Teamware will develop a publishing platform/forge for XR content, and a Blender plugin with direct import export capabilities to said forge and to Icosa gallery. This would allow 3D creators to easily publish and share their ideas, and preview metadata in Blender before exporting.</p>
                  <p>XR Fragments itself is a simple public protocol for networked 3D content to discover, reference, navigate and query 3D online assets (read-only), making it part of the web and thus liberating 3D content creation and content from only existing inside gated products. Within the scope of this project, XR Fragments will streamline the design, deployment, hosting, and integration of portable XR experiences - and thus further simplify embedding, cross-platform support and hosting, as well as add vendor specific support.</p>
                  <p>▸ <em>For more details see</em>: <a href="https://nlnet.nl/project/XR-Teamware">https://nlnet.nl/project/XR-Teamware</a></p>
                </div>
              </details>
            </li>
          </ul>
          <hr>
          <p>Still hungry for more projects? Check out the <a href="https://nlnet.nl/project/current.html">overview of all our current and recent projects</a>...</p>
          <p>Inspired? If you are working on a project that contributes to the Next Generation Internet you can <a href="https://nlnet.nl/propose/">submit a proposal</a>. The next deadline is June 1<sup>st</sup>.</p>
          <h2 id="ack">Acknowledgements</h2>
          <p><a href="https://ec.europa.eu/info/departments/communications-networks-content-and-technology_en"><img src="https://nlnet.nl/image/logos/EC.svg" alt="Logo European Commission"></a></p>
          <p>The NGI0 Core fund is made possible with financial support from the <a href="https://ec.europa.eu/">European Commission</a>'s <a href="https://ngi.eu/">Next Generation Internet</a> programme, under the aegis of <a href="https://ec.europa.eu/info/departments/communications-networks-content-and-technology_en">DG Communications Networks, Content and Technology</a>.</p>
          <p><a href="https://nlnet.nl/core/"><img src="https://nlnet.nl/image/logos/NGI0CommonsFund_tag.svg" alt="Logo NGI Zero Commons Fund: letterlogo shaped like a tag"></a></p>
          
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Native visionOS platform support (274 pts)]]></title>
            <link>https://github.com/godotengine/godot/pull/105628</link>
            <guid>43768421</guid>
            <pubDate>Wed, 23 Apr 2025 03:37:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/godotengine/godot/pull/105628">https://github.com/godotengine/godot/pull/105628</a>, See on <a href="https://news.ycombinator.com/item?id=43768421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Dear Godot community,</p>
<p dir="auto">I'm on Apple's visionOS engineering team, and we would like to contribute Vision Pro support to the Godot engine. This is the first PR that lays the foundation for that.</p>
<p dir="auto">First, I'd like to mention that we're really excited to be working with the Godot community on adding visionOS support. We've attempted to follow Godot's coding standards and a high-quality bar for our contributions. We hope that our contributions align with Godot's goals. Lastly, even though we have tried to split the changes into smaller self-contained PRs, we acknowledge that some of these PRs can be of considerable size.</p>
<p dir="auto">We're very happy to iterate on our PRs after receiving feedback and suggestions from the community.</p>
<h2 dir="auto">High Level Overview</h2>
<p dir="auto">The immediate goals of our contributions are:</p>
<ol dir="auto">
<li>To support current Godot games running natively on a planar window on visionOS.</li>
<li>To support creating Immersive experiences by using a new Godot's visionOS VR Plugin.</li>
</ol>
<p dir="auto">To achieve that, and in order to make reviewing easier, we have structured our contributions in three incremental PRs.</p>
<ol dir="auto">
<li>Add the native <code>visionOS</code> platform. Uses iOS as the starting point. Reuses as much code as possible between the iOS and Vision Pro platforms. (This PR).</li>
<li>Add ability to compile and link Swift files within Godot, and replace <code>main.mm</code> on the <code>visionOS</code> platform by the SwiftUI app lifecycle. This is a requirement to be able to launch Immersive scenes on visionOS.</li>
<li>Introduce Vision Pro VR plugin for Immersive support.</li>
</ol>
<p dir="auto">Even though we have a working version including points 2 and 3, those PRs are not up yet. Our current plan is to open them sequentially, after each of the previous PRs merge.</p>
<h2 dir="auto">Technical Discussion</h2>
<p dir="auto">This PR implements a new native <code>visionOS</code> platform.</p>
<p dir="auto">It's very close to the <code>iOS</code> platform in terms of implementation. In order to reuse as much code as possible, it introduces a new <code>drivers/apple_embedded</code> folder, to host code shared between the <code>iOS</code> and <code>visionOS</code> (but not <code>macOS</code>) platforms. We took inspiration from the new <code>drivers/apple</code> folder, which hosts code that applies to all Apple platforms.</p>
<p dir="auto">The platform-specific logic (including app instantiation, client code, display server, os support, and export plugin) was refactored, and now the bulk of the implementation is on <code>drivers/apple_embedded</code>. The platforms provide small subclasses that specialize the concrete aspects that are different between platforms. We did this refactor with care, trying not to alter the existing iOS functionality.</p>
<p dir="auto">The <code>visionOS</code> platform doesn't have OpenGL support, as it's not supported by visionOS.</p>
<p dir="auto">In order to make reviewing easier, we have tried to split this PR into individual self-contained commits when that made sense, and we have added detailed descriptions to most of them about what's contained in each commit. It's easier to review commit by commit, to see how the changes were incrementally implemented.</p>
<h3 dir="auto">Documentation Considerations</h3>
<p dir="auto">Now, the export plugin for <code>iOS</code> and <code>visionOS</code> share the majority of the code and most of their options (with the exception of launch storyboard support, which is iOS only; and specific platform icon support). Because of this, we have renamed <code>EditorExportPlatformIOS.xml</code> to <code>EditorExportPlatformAppleEmbedded.xml</code>, and moved it to <code>drivers/apple_embedded</code>.</p>
<p dir="auto">We'd like to ask the community if this is appropriate from the docs tooling perspective, and we're requesting further guidance on how to modify this file or the docs tooling to provide specific documentation for each of the platforms.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">We have been testing this PR mainly with the <a href="https://github.com/godotengine/godot-demo-projects/tree/master/3d/platformer">Platformer demo project</a>. We have verified the project continues to work on iOS, and it now runs natively on visionOS. We have tested both the Mobile and Forward+ renderers with the Metal rendering driver on both platforms.</p>
<h3 dir="auto">Open Questions</h3>
<p dir="auto">In all our tests, we exported an Xcode project using the corresponding export plugin and template, and we then ran this project directly to an iOS or visionOS device.</p>
<p dir="auto">We'd like to ask the community to provide guidance, or to help testing the following functionality:</p>
<ul dir="auto">
<li>We have not tested the ability of the iOS/visionOS export templates to embed and link plugins at export time. We tried to preserve this functionality on the <code>visionOS</code> platform, and we assume it will work in the same way it works on iOS. If anybody can attach a project using this functionality, we can help test it.</li>
<li>We have not been able to make direct Archive/IPA export, nor One-Click-Deploy to work, not even in <code>master</code>. There are some differences between our developer account and what external developers use, so it's a bit difficult to pinpoint the problem. We'd appreciate it if anybody that has One-Click-Deploy currently working is able to test on both platforms.</li>
<li>Likewise, we have not tested deploying directly to an iOS device using <code>ios_deploy</code> (used with Xcode versions prior to 14.0). If somebody has a working setup using this, we'd appreciate it if you could test this functionality still works. Alternatively, if <code>ios_deploy</code> support is no longer desired due to its age, we're happy to remove those codepaths for code simplicity.</li>
</ul>
<h2 dir="auto">Missing Functionality</h2>
<ul dir="auto">
<li>The DPI metrics on visionOS are hardcoded for now. They can change at runtime depending on how close the window is to the viewer. We'll address this in the PR adding SwiftUI, as the metrics come from SwiftUI APIs.</li>
<li>We have not implemented building a visionOS Icon Asset Catalog into the exporter. If somebody from the community can step in and implement it, that would be awesome. Otherwise, we may submit this as a later PRs. For now, you can work around this by manually creating your visionOS icon after exporting the Xcode project. <a href="https://developer.apple.com/design/human-interface-guidelines/app-icons" rel="nofollow">Here</a> you can read how visionOS icons work. And here's an example icon showing the Asset Catalog structure: <a href="https://github.com/user-attachments/files/19839704/visionOS-icon.xcassets.zip">visionOS-icon.xcassets.zip</a></li>
<li>The SVG logo for the visionOS platform is just text, it'd be good if somebody could come up with a nice graphic.</li>
</ul>
<hr>
<p dir="auto">We're happy to answer any questions or address any concerns. We're looking forward to collaborating with all of you.</p>
<p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/BastiaanOlij/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/BastiaanOlij">@BastiaanOlij</a> <a data-hovercard-type="user" data-hovercard-url="/users/clayjohn/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/clayjohn">@clayjohn</a> <a data-hovercard-type="user" data-hovercard-url="/users/coppolaemilio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/coppolaemilio">@coppolaemilio</a> <a data-hovercard-type="user" data-hovercard-url="/users/stuartcarnie/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stuartcarnie">@stuartcarnie</a> Feel free to mention anybody who would be interested in this change.</p>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Projects for Old OS X (125 pts)]]></title>
            <link>https://jonathanalland.com/old-osx-projects.html</link>
            <guid>43767944</guid>
            <pubDate>Wed, 23 Apr 2025 01:42:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonathanalland.com/old-osx-projects.html">https://jonathanalland.com/old-osx-projects.html</a>, See on <a href="https://news.ycombinator.com/item?id=43767944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><span>I</span><span>n the fall of 2019, I came to a decision: it was time to leave modern macOS behind.</span></p>
				<p>A decade prior, switching to OS X had been a revelatory experience, as though the software was working in perfect sync with my mind. That feeling had long since disappeared.</p>
				<p>I surveyed the computing landscape. Windows was still fine, and Linux was still Linux. A normal person would have just picked one, but I was apparently not a normal person. I cared far too much about having the <em>perfect</em> computer, and I couldn't get that wonderful memory out of my head...</p>
			</div><div>
			<p><small>Most downloads include source code. Where code was omitted for practical or aesthetic reasons, it is available upon request.</small></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google won't ditch third-party cookies in Chrome after all (122 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/</link>
            <guid>43766803</guid>
            <pubDate>Tue, 22 Apr 2025 22:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/">https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/</a>, See on <a href="https://news.ycombinator.com/item?id=43766803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Maintaining the status quo</h2>
<p>While Google's sandbox project is looking more directionless today, it is not completely ending the initiative. The team still plans to deploy promised improvements in Chrome's Incognito Mode, which has been re-architected to <a href="https://arstechnica.com/tech-policy/2024/04/google-agrees-to-delete-private-browsing-data-to-settle-incognito-mode-lawsuit/">preserve user privacy</a> after <a href="https://arstechnica.com/tech-policy/2023/12/google-agrees-to-settle-in-chrome-incognito-mode-class-action-lawsuit/">numerous complaints</a>. Incognito Mode blocks all third-party cookies, and later this year, it will gain IP protection, which masks a user's IP address to protect against cross-site tracking.</p>
<figure><p><iframe allow="fullscreen" loading="lazy" src="https://www.youtube.com/embed/BGSGlFP_Sk8?start=0&amp;wmode=transparent"></iframe></p><div>
    
    <p>
      What is Topics?

          </p>
  </div>
</figure>
<p>Chavez admits that this change will mean Google's Privacy Sandbox APIs will have a "different role to play" in the market. That's a kind way to put it. Google will continue developing these tools and will work with industry partners to find a path forward in the coming months. The company still hopes to see adoption of the Privacy Sandbox increase, but the industry is unlikely to give up on cookies voluntarily.</p>
<p>While Google focuses on how ad privacy has improved since it began working on the Privacy Sandbox, the changes in Google's legal exposure are probably more relevant. Since launching the program, Google has lost three antitrust cases, two of which are relevant here: the search case <a href="https://arstechnica.com/tech-policy/2025/04/chrome-on-the-chopping-block-as-googles-search-antitrust-trial-moves-forward/">currently in the remedy phase</a> and the newly decided <a href="https://arstechnica.com/tech-policy/2025/04/google-loses-ad-tech-monopoly-trial-faces-additional-breakups/">ad tech case</a>. As the government begins arguing that Chrome gives Google too much power, it would be a bad look to force a realignment of the advertising industry using the dominance of Chrome.</p>
<p>In some ways, this is a loss—tracking cookies are undeniably terrible, and Google's proposed alternative is better for privacy, at least on paper. However, universal adoption of the Privacy Sandbox could also give Google more power than it already has, and the supposed privacy advantages may never have fully materialized as Google continues to seek higher revenue.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to quickly charge your smartphone: fast charging technologies in detail (119 pts)]]></title>
            <link>https://eb43.github.io/articles/fast-charging-technologies-in-detail.html</link>
            <guid>43766728</guid>
            <pubDate>Tue, 22 Apr 2025 22:00:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eb43.github.io/articles/fast-charging-technologies-in-detail.html">https://eb43.github.io/articles/fast-charging-technologies-in-detail.html</a>, See on <a href="https://news.ycombinator.com/item?id=43766728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>The great days are gone when charging a smartphone only required two wires. Today, <a href="https://techtoday.in.ua/news/zaryadky-usb-c-mayut-bilshe-obchyslyuvalnoyi-potuzhnosti-nizh-navigaczijnyj-kompyuter-apollo-11-shho-dopravyv-jogo-na-misyacz-125316.html">a charger is a full-fledged computer with more processing power than the Apollo 11 spacecraft</a> that brought humans to the Moon. A processor is necessary in the charger to negotiate charging parameters with the smartphone. Let's dive into fast charging technologies in detail.</p>

<h2>The Best Charger – From Your Old Feature Phone</h2>

<p>If you plug in your smartphone before bed, unplug it in the morning, and the charge lasts the whole day – you don't need to worry about specific charging standards or chargers.</p>

<p><a href="https://techtoday.in.ua/wp-content/uploads/2025/05/slow-phone-charger.jpg"><img src="https://techtoday.in.ua/wp-content/uploads/2025/05/slow-phone-charger.jpg" alt="" width="2548" height="1473"></a></p>

<p>In such a situation, the best solution is slow charging, for which a low-power charger from your old feature phone is ideal. These devices offer a small power output of 2–5 W, stretching the charging process to 5–7 hours depending on the adapter's power and the battery capacity. This way, your phone's battery charges under the best conditions, minimizing degradation. <a href="https://techtoday.in.ua/news/shvydke-zaryadzhannya-za-100-dniv-z-yidaye-1-6-yemnosti-batareyi-telefona-164005.html">Fast charging leads to up to 1.6% battery degradation every 100 days</a>, according to an experiment comparing 5W and 25W charging on six identical smartphone batteries.</p>

<p>With a regular charger, your phone will charge in 30 minutes to an hour, and the rest of the time, the battery remains under stress caused by reaching maximum voltage. You can verify this yourself by feeling the battery heating up or by <a href="https://eb43.github.io/android-battery-temperature-app.html">using the Android Battery Temperature app</a>. See battery voltage in real time with <a href="https://eb43.github.io/android-battery-voltage-indicator-in-status-bar.html">Android battery voltage indicator in status bar</a>. An ultra-slow charger will power the phone overnight while keeping the battery temperature at room level.</p>

<h2>What Is Considered Fast Charging?</h2>

<p>Fast charging is a general term whose technical meaning has changed over time.</p>

<p>Starting with Android 15, Google modified the OS so that Android smartphones display a fast charging notification when the charger delivers at least 20W of power.</p>

<p>Earlier versions of <a href="https://techtoday.in.ua/news/android-pidvyshhuye-minimalnyj-riven-potuzhnosti-zaryadky-shhob-vona-vvazhalasya-shvydkoyu-172476.html">Android consider charging to be fast if it delivers more than 7.5W of power</a>. Charging at 5–7.5W is considered normal, while anything below 5W will display “slow charging.”</p>

<h2>What You Need to Know About Fast Charging</h2>

<p>If you want to charge your phone quickly, you need to understand the technologies behind it. First, you need to know the power your phone can handle. Charging power is measured in watts. Watts are calculated by multiplying voltage (in volts) by current (in amps).</p>

<p>For example, Google claims that the Pixel 9 can "fast charge" using a 45W Google USB-C charger, but stepping away from this marketing finesse reveals that the phone’s actual maximum charging power is 27W.</p>

<p>You also need to know which charging protocol your smartphone supports. Today, there has been a shift toward standardization, and most phones now support the USB PD protocol. However, many other protocols still exist. It’s important to remember that these protocols are not compatible with each other. If the phone and charger do not support a common protocol, they won’t be able to negotiate fast charging.</p>

<p>Once you know the power and protocol, you can choose a cable and charger capable of delivering the required power. The thing is, USB cables contain ultra-thin wires inside, which are not always made of copper. This significantly reduces the cable’s energy transfer efficiency and causes it to heat up. <a href="https://techtoday.in.ua/reviews/deyaki-usb-kabeli-tse-obigrivachi-yak-magnitom-vyznachyty-duzhe-poganyj-usb-kabel-158905.html">Some USB cables heat up more than the phone or charger itself</a>.</p>

<p>Keep in mind that the technical specifications of cables, chargers, and smartphones are often exaggerated. Just because a charger says 30W doesn’t mean it can reliably deliver that power over time. At best, it will activate overheat protection and reduce power. At worst, it may fail and even cause a fire.</p>

<p>To use electronics safely, avoid running them at their maximum rated power. For example, if your phone peaks at 30W charging, it’s better to use a charger rated for 45W or more.</p>

<p>The same applies to USB cables. A cable rated for 30W might work well for phone charging but won’t be ideal for a laptop that draws 100W.</p>

<p>Remember that the best USB cables are rated for no more than 5A of current. High-quality USB cables can handle 3A without excessive heating. USB-C to USB-C cables have a special e-marker chip that tells the charger the maximum power the cable can handle. However, keep in mind that the presence of the chip doesn’t guarantee the physical wires are thick enough to safely carry the claimed power.</p>


<h2>Fast Wired Charging Technologies</h2>

<p>The fastest possible charging is only achievable when a cable is connected to the smartphone. Only wired charging ensures minimal energy loss during the transfer from the charger to the device.</p>

<p>All fast-charging technologies use the same basic principle to deliver high power at the physical level – increasing voltage to reduce current. High current is what melts cables and can potentially cause fires.</p>

<p>However, before the charging adapter starts increasing the voltage, it must first communicate with the smartphone. Incompatibility of the communication software protocol is the reason why a smartphone with USB PD, for example, cannot fast charge from a VOOC charger.</p>

<h3>USB PD Fast Charging</h3>

<p>USB Power Delivery (USB PD) is the most common charging standard for smartphones, not to mention tablets and laptops.</p>

  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/unnamed_file_from_a-us.storyblok.com_.jpg_75.jpg" alt="" width="480" height="323">

<p>USB PD is only available via a USB-C connection. USB PD is not supported with a USB-A connector (rectangular plug), unlike some other charging protocols.</p>


<table>
  <thead>
    <tr>
      <th>Version</th>
      <th>Voltage Parameters (V)</th>
      <th>Max Current (A)</th>
      <th>Max Power (W)</th>
      <th>Typical Use</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>USB PD 1.0</strong></td>
      <td>5, 12, 20</td>
      <td>Up to 3.0</td>
      <td>Up to 60</td>
      <td>Smartphones, tablets, small accessories</td>
    </tr>
    <tr>
      <td><strong>USB PD 2.0 / 3.0</strong></td>
      <td>5, 9, 15, 20</td>
      <td>Up to 5.0</td>
      <td>Up to 100</td>
      <td>Laptops, monitors, high-power peripherals</td>
    </tr>
    <tr>
      <td><strong>USB PD 3.1</strong></td>
      <td>28, 36, 48</td>
      <td>Up to 5.0</td>
      <td>Up to 240</td>
      <td>High-performance laptops, gaming devices, displays</td>
    </tr>
  </tbody>
</table>

<p>USB PD is as close to a universal standard as possible, being supported by almost every modern gadget and charger. Apple, Google, and Samsung use it in all their latest phones and other devices.</p>

<p>While there are different versions of PD, here are just a few key things to know:</p>

<ul>
  <li>USB PD 1.0 is outdated (since 2020) and supports up to 100W. Its fixed voltages are 5V, 9V, 15V, and 20V with currents of 1.5A, 2A, 3A, and 5A.</li>
  <li>Today, USB PD 2.0 is relevant. It also supports up to 100W of power but does so more flexibly. A USB PD 2.0 charger rated at 36W should support 5V 3A, 9V 3A, and 15V 2.4A. A charger rated at 45–60W adds support for 20V 3A. Chargers rated at 60–100W provide an additional 20V 5A mode.</li>
  <li>USB PD 3.0, now widely adopted, allows for even more flexible voltage negotiation via PPS mode. PPS exists alongside the list of fixed voltages. The max power of USB PD 3.0 is 100W.</li>
  <li>PPS (Programmable Power Supply) support in USB PD 3.0 allows the smartphone and charger to select any voltage within the supported range, in 0.02V steps. For example, instead of fixed 9V, the phone may request 8.7V if its charging controller deems it optimal. These finely tuned voltage levels help precisely control power consumption, minimizing heat while maintaining fast charging. Phones that support PPS require a PPS-compatible charger.</li>
  <li>Extended Power Range (EPR) in PD 3.1 adds 28V, 36V, and 48V options. PD 3.1 enables charging at up to 240W. This power is achieved by increasing voltage to 48V, since USB cables can’t handle more than 5A without melting. At 48V, 240W equals a current of 5A.</li>
</ul>

<h3>Qualcomm Quick Charge (QC) Fast Charging</h3>

<p>Qualcomm's Quick Charge (QC) technology was developed to charge batteries faster than standard USB (not USB PD, but fixed 5V 2A). Hardware fast charging is achieved by increasing the output voltage supplied by the charger.</p>

<p>Since many phones use Qualcomm processors, QC support is widespread. There have been several versions of QC, but all the latest three versions (QC 4, 4+, 5) support USB PD and can operate with power up to 100W. QC is also cross-compatible with many other standards.</p>

<p>Starting from QC 3.0, the INOV technology was introduced, which resembles USB PD PPS, allowing the charger and smartphone to adjust the voltage in 0.2V increments.</p>

<table>
  <thead>
    <tr>
      <th>Version</th>
      <th>Voltage Range</th>
      <th>Max Current</th>
      <th>Max Power</th>
      <th>Key Features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>QC 1.0</strong> (2013)</td>
      <td>Up to 6.3V</td>
      <td>2A</td>
      <td>10W</td>
      <td>Introduced higher-voltage charging</td>
    </tr>
    <tr>
      <td><strong>QC 2.0</strong> (2014)</td>
      <td>Class A: 5V, 9V, 12V<br>Class B: 5V, 9V, 12V, 20V</td>
      <td>Up to 3A</td>
      <td>Up to 36W</td>
      <td>Improved efficiency and charging speed</td>
    </tr>
    <tr>
      <td><strong>QC 3.0</strong> (2016)</td>
      <td>3.6V–20V in 0.2V steps</td>
      <td>Up to 3A</td>
      <td>Up to 36W</td>
      <td>INOV (Intelligent Negotiation for Optimal Voltage) for optimization</td>
    </tr>
    <tr>
      <td><strong>QC 4.0 / 4+</strong> (2017)</td>
      <td>3.6V–20V (Quick Charge)<br>5V, 9V (USB PD)</td>
      <td>Up to 5A</td>
      <td>Up to 100W (QC)<br>27W (USB PD)</td>
      <td>Supports USB PD, enhanced safety</td>
    </tr>
    <tr>
      <td><strong>QC 5.0</strong> (2020)</td>
      <td>3.3V–20V</td>
      <td>Up to 7A</td>
      <td>Over 100W</td>
      <td>Supports dual-cell batteries, USB PD PPS, advanced cooling</td>
    </tr>
  </tbody>
</table>


<h3>MediaTek Pump Express Fast Charging</h3>

  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/mediatek-pump-express.jpg" alt="MediaTek Pump Express" width="482" height="622">

<p>MediaTek is another major chipmaker with its own fast charging technology called Pump Express, which is quite similar to Qualcomm’s QC. It seems that MediaTek is no longer actively promoting this technology, but the Pump Express 4.0, introduced almost a decade ago, is compatible with the USB PD 3.0 standard.</p>

<table>
  <thead>
    <tr>
      <th>Version</th>
      <th>Voltage Range</th>
      <th>Max Current</th>
      <th>Max Power</th>
      <th>Key Features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Pump Express</strong></td>
      <td>Up to 5V</td>
      <td>—</td>
      <td>&lt;10W</td>
      <td>Initial version; negotiates voltage up to 5V depending on battery state.</td>
    </tr>
    <tr>
      <td><strong>Pump Express Plus</strong></td>
      <td>Up to 12V</td>
      <td>—</td>
      <td>=&lt;15W</td>
      <td>Improved version for chargers with output power of 15W or more.</td>
    </tr>
    <tr>
      <td><strong>Pump Express 2.0+</strong></td>
      <td>5V–20V (0.5V step)</td>
      <td>3A–4.5A+</td>
      <td>~15W</td>
      <td>Offers multiple charging stages: Normal, Turbo 1, and Turbo 2.</td>
    </tr>
    <tr>
      <td><strong>Pump Express 3.0</strong></td>
      <td>3V–6V (step of 0.010–0.020V)</td>
      <td>&gt;5A</td>
      <td>25–30W</td>
      <td>Uses direct charging via USB Type-C, bypassing the phone’s internal charging circuitry.</td>
    </tr>
  </tbody>
</table>

<p>Pump Express 3.0 introduced an interesting solution: direct battery charging. In a typical smartphone, the charger does not actually charge the battery directly — it supplies power to the phone. Charging is handled by the internal charging controller, which steps down the voltage from 5V, 9V, or 12V to a battery-safe level of around 4V. This process generates additional heat in both the phone and the battery.</p>

<p>With Pump Express 3.0, the smartphone disables its internal charging electronics and connects the battery directly to the charger. The charger supplies voltage matching the battery's level — between 3V and 6V — compensating for voltage drop across the USB cable and connectors. Thanks to direct charging, the smartphone heats up significantly less.</p>


<h3>VOOC and SuperVOOC Fast Charging</h3>

<p>Voltage Open Loop (VOOC) and SuperVOOC protocols remain arguably the most problematic due to the fact that the BBK conglomerate—which owns several well-known smartphone brands including Realme and Oppo—is reluctant to license it to third-party charger manufacturers. This means that owners of Vivo, Oppo, Realme, and other BBK brands get fast charging only when using the original cable and charger included with the phone.</p>

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/supervooc.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/supervooc.jpg" alt="" width="532" height="451">
</a>

<p>VOOC was first introduced in 2014 and supported 5V/4A, which was nearly twice as fast as the standard USB 5V/2A. Two years later, its successor SuperVOOC was released with a full voltage range.</p>

<p>BBK’s sub-brands received these charging technologies under different names. For example: Flash Charge (also VOOC), Warp Charge (also OnePlus Dash Charge and Realme DART), Super Flash Charge (also SuperVOOC).</p>

<p>SuperVOOC is significantly different from other fast-charging technologies. Firstly, smartphones supporting it feature a dual-cell battery. This dual design helps reduce heat when charging at high currents. Secondly, SuperVOOC moves the charging controller from the smartphone into the charger itself. This reduces heating of the smartphone, though it transfers the heat source to the charger.</p>

<p>With SuperVOOC, separating the battery and moving the controller outside the smartphone is essential, as this technology more than doubles the maximum current compared to the current 5A USB standard:</p>

<ul>
  <li>SuperVOOC (2016): 10V / 5A = 50W</li>
  <li>SuperVOOC 2.0 (2020): 10V / 6.5A = 65W</li>
  <li>SuperVOOC 2.0 (2022): 11V / 6–7.3A = up to 80W</li>
  <li>SuperVOOC 240W (2022): 20V / 12A = 240W</li>
</ul>

<h3>Mi Turbo Charge and Xiaomi HyperCharge Fast Charging</h3>

<p>Another less common charging standard that works only when using the USB cable and charger included with Xiaomi, Poco, or Redmi smartphones.</p>


  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/xiaomi-mi-turbo-charge.jpg" alt="" width="779" height="534">


<p>Mi Turbo Charge is the marketing name for Xiaomi’s early fast-charging technology. It supports up to 33W of power. Xiaomi HyperCharge has since replaced Mi Turbo Charge.</p>

<p>Xiaomi HyperCharge requires an original Xiaomi cable and charger because the USB-A connector used includes an additional physical contact—five pins instead of the usual four.</p>

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/original-xiaomi-cable-and-charger-usb-5-pin.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/original-xiaomi-cable-and-charger-usb-5-pin.jpg" alt="" width="831" height="1188">
</a>

<p>Although Xiaomi advertises up to 120W in its promotional materials, this figure is only achievable when connected to a 240V power outlet. In Brazil, the USA, Canada, Colombia, Japan, and other countries with 120V power outlets, Xiaomi HyperCharge provides only 96W of power.</p>

<p>Xiaomi HyperCharge supports up to 20V, with current reaching 6A, enabling a maximum power of 120W.</p>

<h3>Motorola TurboPower Fast Charging</h3>

<p>Earlier Motorola phones used regular fast charging, but their recent models now use TurboPower. Different phone models have different maximum charging speeds, with the fastest TurboPower charger rated for 125W.</p>

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/motorola-turbo-power.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/motorola-turbo-power.jpg" alt="" width="831" height="640">
</a>

<h3>Samsung Adaptive Fast Charge (AFC) and Super Fast Charge (SFC)</h3>
Samsung offers two main fast-charging technologies: Adaptive Fast Charge (AFC) and Super Fast Charge (SFC).

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/samsung-superfast-charging.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/samsung-superfast-charging.jpg" alt="" width="524" height="630">
</a>

<p>Samsung Adaptive Fast Charge (AFC) works with 5V for standard charging and 9V for fast charging, supporting up to 2A, which delivers a maximum of 18W. This technology is based on Qualcomm Quick Charge 2.0 and is compatible with most modern Samsung smartphones. It uses USB-A to Micro-USB or USB-C cables and is supported on Exynos and Snapdragon devices.</p>

<p>Samsung Super Fast Charge (SFC) includes two versions. The first, Super Fast Charge 1.0, uses 5V (standard) and 9V (fast) with up to 2.25A, delivering up to 25W. This version uses USB PD 3.0.</p>

<p>The second version, Super Fast Charge 2.0, supports 5V, 9V, 15V, and 20V with a maximum of 2.25A at 20V, and variable current for other voltages—up to 4.05A at 3.3V and up to 2.1A at 21V. This version can deliver up to 45W using USB PD 3.0 with PPS support. It requires a USB-C to USB-C cable rated for 5A.</p>

<h3>Huawei Fast Charge Protocol (FCP) and SuperCharge Protocol (SCP)</h3>
Huawei promotes two proprietary fast-charging technologies: Fast Charge Protocol (FCP) and SuperCharge Protocol (SCP).

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/huawei-scp.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/huawei-scp.jpg" alt="" width="379" height="400">
</a>

<p>Fast Charge Protocol (FCP) was introduced in 2015 and uses high voltage with low current for charging. It operates at 9V and 2A, providing up to 18W. FCP was widely used in early Huawei and Honor smartphones.</p>

<p>SuperCharge Protocol (SCP), introduced in 2016, is an advanced version of FCP and supports higher charging power. SCP includes different voltage and current combinations to achieve more power. For example, one SCP configuration is 10V at 4A, which delivers up to 40W. Other variations include 11V at 6A (66W) and 20V at 5A (100W). SCP is used in modern Huawei models like the Mate 20 Pro, Mate 40 Pro, and P60 Pro.</p>


<h3>Anker PowerIQ Fast Charging</h3>

<p>Fast charging is offered not only by phone and processor manufacturers. Anker, a company that produces power banks and chargers, has its own standard called PowerIQ.</p>

<p>PowerIQ 1.0 delivers a maximum power of 12W by supplying 5V at up to 2.4A. PowerIQ 2.0 is an improved version that includes VoltageBoost technology, which compensates for voltage loss due to cable heating. It still provides 5V at up to 2.4A.</p>

<p>PowerIQ 3.0 is the latest version, supporting up to 100W of power. It is compatible with USB-C Power Delivery (PD) and Qualcomm Quick Charge 3.0. For example, the PowerPort+ Atom III charger with PowerIQ 3.0 features USB-C outputs supporting 5V at 2.4A, 9V at 3A, 15V at 3A, and 20V at 2.25A, as well as a USB-A output providing 5V at 2.4A, 9V at 1.66A, and 12V at 1.25A.</p>

<h3>iPhone Fast Charging</h3>

<p>Apple provides iPhone users with a fast charging technology called Fast Charge. However, this is just a marketing name—iPhones do not have a proprietary charging protocol like Huawei’s SCP or SuperVOOC. For fast charging, iPhones use the USB PD standard.</p>

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/iphone-fast-charge.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/iphone-fast-charge.jpg" alt="iPhone Fast Charging" width="638" height="466">
</a>

<p>Compared to fast charging on Android phones (except Samsung), iPhone’s fast charging looks rather slow:</p>

<ul>
  <li>The iPhone 16, which supports up to 45W charging, uses up to 15V and 3A current.</li>
  <li>The iPhone 15 and earlier models have a maximum charging power of 29W, with 9V at 3A.</li>
  <li>For models like iPhone 12, iPhone SE (3rd generation), and newer, the recommended charging is 20W (9V / 2.2A).</li>
  <li>For iPhone 8, iPhone X, iPhone XR, iPhone 11, and older, the maximum charging power is 18W, with 9V at 2A.</li>
</ul>

<h2>Fast Wireless Charging Technologies</h2>

<p>The most important thing to remember about wireless charging is that it is extremely inefficient. Around 50% of the energy consumed by a wireless charger is lost as heat, which warms up your smartphone. Because of this, wireless charging typically has much lower power output than wired charging.</p>

<p>Wireless charging technology is more accurately described as “USB connector-less charging.” It replaces the USB plug with energy transfer based on electromagnetic induction. In simple terms, a copper coil receives alternating current, generating an alternating magnetic field. A second copper coil placed nearby enters this magnetic field and converts it into alternating electric current. As mentioned earlier, the energy losses are significant.</p>

<p>Here are the main wireless charging standards you might encounter:</p>

<h3>Qi Wireless Charging</h3>

<p>The Qi wireless charging technology (pronounced “chee”), developed by the Wireless Power Consortium (WPC) in 2010, enables energy transfer over a distance of up to 4 cm between coils. The magnetic field oscillation frequency ranges from 110–205 kHz and adjusts dynamically based on feedback control to regulate charging power.</p>

<p>Qi supports several power profiles. The Baseline Power Profile (BPP) delivers up to 5W of charging power. The Extended Power Profile (EPP) increases this to 15W and is the most common fast-charging option for smartphones. Additionally, there is a Medium Power Profile, offering between 30 and 65W.</p>

<ul>
  <li>Basic electrical parameters for Qi BPP coils:
    <ul>
      <li>Voltage at the secondary coil (device side): 5V up to 1A</li>
      <li>Voltage at the primary coil (charger side): 12V, current approx. 0.5–1A for up to 5W output</li>
    </ul>
  </li>
  <li>Extended Qi EPP parameters (up to 15W):
    <ul>
      <li>Voltage at the secondary coil: 9V, current up to 1.67A</li>
      <li>Voltage at the primary side: 12V or higher, current up to 2A</li>
    </ul>
  </li>
</ul>

<h3>Apple MagSafe</h3>

<p>The Qi standard, like any wireless energy transfer method, has a major issue—precise alignment of the coils. Some manufacturers even printed crosshairs on their devices to help with alignment. But in 2020, Apple introduced a brilliantly simple and effective solution—magnets placed around the outer edge of the coil (as seen in the photo below, with silver rectangles surrounding a yellow copper coil).</p>

<a href="https://techtoday.in.ua/wp-content/uploads/2025/05/apple-magsafe-teardown.jpg">
  <img src="https://techtoday.in.ua/wp-content/uploads/2025/05/apple-magsafe-teardown.jpg" alt="Apple MagSafe Teardown" width="672" height="397">
</a>

<p>Apple essentially took the Qi standard, added a ring of magnets that snap the charger precisely into place, and branded it as MagSafe. MagSafe has been available starting with the iPhone 12 and newer models.</p>

<p>MagSafe initially offered up to 15W of charging power, and with the iPhone 16 and MagSafe 2 (second generation), the power increased to 25W. To achieve maximum charging speed, a power adapter supporting USB Power Delivery (PD) 3.0 with output of 9V / 2.22A or 9V / 2.56A is required.</p>

<h3>Qi2 Wireless Charging</h3>

<p>Apple’s MagSafe successfully solved the primary issue of wireless charging, and fortunately, Apple shared this design for use in the Qi2 standard, introduced in 2023. Essentially, Qi2 is a marketing name for Apple’s MagSafe adapted for Android smartphones.</p>

<p>Qi2 includes the same magnetic ring as MagSafe. Qi2-compatible devices can charge using MagSafe chargers, and MagSafe-compatible iPhones can charge using Qi2 chargers. However, due to Apple's proprietary certification, only certified MagSafe chargers deliver 15W power. Qi2 chargers, lacking certification, charge iPhones at up to 7.5W.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Hell (184 pts)]]></title>
            <link>https://csshell.com/</link>
            <guid>43766715</guid>
            <pubDate>Tue, 22 Apr 2025 21:58:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://csshell.com/">https://csshell.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43766715">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Atuin Desktop: Runbooks That Run (464 pts)]]></title>
            <link>https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</link>
            <guid>43766200</guid>
            <pubDate>Tue, 22 Apr 2025 20:54:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</a>, See on <a href="https://news.ycombinator.com/item?id=43766200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://blog.atuin.sh/tag/news/">News</a>
            
                <p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p>

            <div>
                <p><a href="https://blog.atuin.sh/author/ellie/">
                                <img src="https://blog.atuin.sh/content/images/size/w160/2024/01/me2.jpg" alt="Ellie Huxtable">
                            </a>
                </p>
                
            </div>

            
        </header>

        <section>
            <figure data-kg-thumbnail="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final.mp4" poster="https://img.spacergif.org/v1/1852x1600/0a/spacer.png" width="1852" height="1600" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:27</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg"></figure><p>Most infrastructure is held together by five commands someone remembers when shit breaks. Docs are out of date, if they exist. The real answers? Buried in Slack threads, rotting in Notion, or trapped in someone's shell history.</p><p><a href="https://atuin.sh/?ref=blog.atuin.sh" rel="noreferrer">Atuin CLI</a> fixed part of this, with synced, searchable shell history. But teams need more than history. They need workflows that don't live in someone's head (or their shell).</p><p>Set up. SSH in. Export some variables. Run some commands. Hope nothing breaks. Stuff we do every day, but still have to piece together from fragments of the past, or copy paste from some document somewhere.</p><p>That's why we built the next step.</p><h2 id="introducing-atuin-desktop"><strong>Introducing Atuin Desktop</strong></h2><blockquote>A local-first, executable runbook editor for real terminal workflows</blockquote><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png" width="1581" height="1382" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.28.30.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1000w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1581w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png" width="1643" height="1386" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1643w" sizes="(min-width: 720px) 720px"></p></div></figure><p>Built to make workflows repeatable, shareable, and reliable.</p><p>Runbooks should run. Workflows shouldn't live in someone's head. Docs shouldn't rot the moment you write them.</p><p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p><ul><li><strong>Kill context switching: </strong>chain shell commands, database queries and HTTP requests</li><li><strong>Docs that don't rot: </strong>execute directly + stay relevant</li><li><strong>Reusable automation: </strong>dynamic runbooks with Jinja-style templating</li><li><strong>Instant recall: </strong>autocomplete from your real shell history</li><li><strong>Local-first, CRDT-powered: </strong>if it runs in your terminal, it runs in a runbook</li><li><strong>Sync and share with Atuin Hub: </strong>up to date, across devices and teams</li></ul><h3 id="how-we-use-it-today">How we use it today</h3><p>We’re already running real-world workflows in Atuin Desktop:</p><ul><li>Releasing Atuin CLI (no more checklist hell)</li><li>Migrating infra safely between environments</li><li>Spinning up staging or prod with confidence</li><li>Managing and collaborating on live database queries</li></ul><p>This is how we ship, manage infra, and collaborate.</p><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png" width="1693" height="1554" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1693w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png" width="1688" height="1494" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1688w" sizes="(min-width: 720px) 720px"></p></div></figure><h3 id="what%E2%80%99s-next">What’s next</h3><ul><li>Team accounts: true collaborative ops</li><li>Generate runbooks from your shell history. Workflows that write themselves</li></ul><h3 id="get-early-access">Get early access</h3><p>We're rolling out Atuin Desktop now. If you're done copy-pasting from Notion and Slack, or spelunking through shell history, join the <a href="https://wt.ls/atuin?ref=blog.atuin.sh" rel="noreferrer">early access list</a>!</p>
        </section>

    </article>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How long does it take to create a new habit? (2015) (183 pts)]]></title>
            <link>https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/</link>
            <guid>43765084</guid>
            <pubDate>Tue, 22 Apr 2025 18:47:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/">https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/</a>, See on <a href="https://news.ycombinator.com/item?id=43765084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    	 
        
			<main id="main" role="main">

			
	<article id="post-2478"> 
	
		<div>
		<h3><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg"><img fetchpriority="high" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg" alt="21 day myth" width="954" height="584" srcset="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg 954w, https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth-300x184.jpg 300w" sizes="(max-width: 954px) 100vw, 954px"></a></h3>
<h3>In 1960, Dr. Maxwell Maltz published his bestseller book “Psycho-Cybernetics” in which he defines happiness as a habit and claims that “it usually requires a minimum of about 21 days” to form a new habit. The 21 day idea caught on, because 3 weeks is neither too short (that it’s unbelievable), nor too long (that it’s discouraging).</h3>
<p><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-1.jpg"><img decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-1.jpg" alt="21 day myth" width="179" height="267"></a>However, Dr. Maltz was simply making an observation as a plastic surgeon. He was not declaring a statement of fact that is based on research. Also, the phrase “it usually requires a minimum of about 21 days” was propagated without the words “usually”, “minimum” and “about”.</p>
<p><strong>So how long does it really take to create a new habit?</strong></p>
<p>Published in the October 2010 issue of the European Journal of Social Psychology, the research article “How habits are formed: Modelling habit formation in the real world” (Phillippa Lally, et al.) attempted to answer that question. The study examined the habits of 96 people over a period of 12 week, and the data was then analyzed to determine how long it took each person to go from starting a new behavior to automatically doing it. The answer? Not 21 days.</p>
<p>According to Lally’s study, implementing meaningful change in our lives requires 2 to 8 months. The variation is due to the type of habit in question, the person developing it and his/her circumstances. On average it takes 66 days, not just 21. However here’s the good news:</p>
<ol>
<li><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-2.jpg"><img loading="lazy" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-2.jpg" alt="21 day myth" width="337" height="222"></a>The study showed that if you miss an opportunity to perform an action that’s helping you build a habit, there is no significant impact on the habit formation process. In other words, if you fall off the wagon, it doesn’t mean you’ve failed … you can go back and continue trying.</li>
<li>Initially, it takes longer to form a habit and persevere it, but over time, it starts to happen more easily and it requires less effort.</li>
</ol>
<p><strong>So what does this all mean?&nbsp; Well, a couple of things:</strong></p>
<ol>
<li>If you’re trying a new diet, attempting to quit smoking or changing any daily routine, don’t expect new habits to be created in a week, or two or even three.&nbsp; Research suggests that the process requires 66 days (on average) and up to 8 months.</li>
<li>It also means, when trying to make lasting change in your life, be cautious of general claims such as the 21 day rule. False ideas become accepted as fact if repeated too often, but that doesn’t mean they’re true. So, do your research in order to set realistic expectations and avoid future disappointment.</li>
</ol>
<p><strong><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg"><img loading="lazy" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg" alt="21 day myth" width="326" height="196" srcset="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg 600w, https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3-300x180.jpg 300w" sizes="auto, (max-width: 326px) 100vw, 326px"></a>Change is what you make it out to be</strong></p>
<p>Personally, I would not concern myself with the 21 day rule or even the Lally study. Throughout my years of research on personal transformation, I realized that generalizations are often deceiving.&nbsp; At the end of the day, it doesn’t really matter if it takes you 21, 66 or even a thousand days to create a new habit. What matters is your dedication to making that change happen. Plus, we’re all different and our circumstances vary, so there can never be one timeline that works for every person, even if it’s only a guideline.</p>
<p>I tell my clients: irrespective of how chaotic and difficult life might be, you are the master of your own behaviours. You dictate the when, where and how your habits are created, so focus on the “why” and everything else will fall into place. New habits shouldn’t have timelines … none whatsoever.</p>

				</div><!-- .entry-content -->

		<!-- .entry-footer -->  
	</article><!-- #post-## -->
  

				<!-- .navigation -->
	
			
		
			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sapphire: Rust based package manager for macOS (Homebrew replacement) (393 pts)]]></title>
            <link>https://github.com/alexykn/sapphire</link>
            <guid>43765011</guid>
            <pubDate>Tue, 22 Apr 2025 18:39:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alexykn/sapphire">https://github.com/alexykn/sapphire</a>, See on <a href="https://news.ycombinator.com/item?id=43765011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sapphire</h2><a id="user-content-sapphire" aria-label="Permalink: Sapphire" href="#sapphire"></a></p>
<blockquote>
<p dir="auto"><strong>WARNING: ALPHA SOFTWARE</strong> &gt; Sapphire is experimental, under heavy development, and may be unstable. Use at your own risk!</p>
<p dir="auto">Uninstalling a cask with brew then reinstalling it with Sapphire will have it installed with slightly different paths, your user settings etc. will not be migrated automatically.</p>
</blockquote>
<p dir="auto">Sapphire is a next‑generation, Rust‑powered package manager inspired by Homebrew. It installs and manages:</p>
<ul dir="auto">
<li><strong>Formulae:</strong> command‑line tools, libraries, and languages</li>
<li><strong>Casks:</strong> desktop applications and related artifacts on macOS</li>
</ul>
<blockquote>
<p dir="auto"><em>ARM only for now, might add x86 support eventually</em></p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Project Structure</h2><a id="user-content-️-project-structure" aria-label="Permalink: ⚙️ Project Structure" href="#️-project-structure"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>sapphire‑core</strong> Core library: fetching, dependency resolution, archive extraction, artifact handling (apps, binaries, pkg installers, fonts, plugins, zap/preflight/uninstall stanzas, etc.)</p>
</li>
<li>
<p dir="auto"><strong>sapphire‑cli</strong> Command‑line interface: <code>sapphire</code> executable wrapping the core library.</p>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚧 Current Status</h2><a id="user-content--current-status" aria-label="Permalink: 🚧 Current Status" href="#-current-status"></a></p>
<ul dir="auto">
<li>Bottle installation and uninstallation</li>
<li>Cask installation and uninstallation</li>
<li>Parallel downloads and installs for speed</li>
<li>Automatic dependency resolution and installation</li>
<li>Building Formulae from source (very early impl)</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Roadmap</h2><a id="user-content--roadmap" aria-label="Permalink: 🚀 Roadmap" href="#-roadmap"></a></p>
<ol dir="auto">
<li><strong>Upgrade</strong> command to update installed packages</li>
<li><strong>Cleanup</strong> old downloads, versions, caches</li>
<li><strong>Reinstall</strong> command for quick re‑pours</li>
<li><strong>Prefix isolation:</strong> support <code>/opt/sapphire</code> as standalone layout</li>
<li><strong><code>sapphire init</code></strong> helper to bootstrap your environment</li>
<li><strong>Ongoing</strong> Bug fixes and stability improvements</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Usage</h2><a id="user-content--usage" aria-label="Permalink: 📦 Usage" href="#-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Print help
sapphire --help

# Update metadata
sapphire update

# Search for packages
sapphire search <formula/cask>

# Get package info
sapphire info <formula/cask>

# Install bottles or casks
sapphire install <formula/cask>

# Build and install a formula from source
sapphire install --build-from-source <formula>

# Uninstall
sapphire uninstall <formula/cask>

# (coming soon)
sapphire upgrade [--all] <name>
sapphire cleanup
sapphire init"><pre><span><span>#</span> Print help</span>
sapphire --help

<span><span>#</span> Update metadata</span>
sapphire update

<span><span>#</span> Search for packages</span>
sapphire search <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Get package info</span>
sapphire info <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Install bottles or casks</span>
sapphire install <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Build and install a formula from source</span>
sapphire install --build-from-source <span>&lt;</span>formula<span>&gt;</span>

<span><span>#</span> Uninstall</span>
sapphire uninstall <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> (coming soon)</span>
sapphire upgrade [--all] <span>&lt;</span>name<span>&gt;</span>
sapphire cleanup
sapphire init</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Building from Source</h2><a id="user-content-️-building-from-source" aria-label="Permalink: 🏗️ Building from Source" href="#️-building-from-source"></a></p>
<p dir="auto"><strong>Prerequisites:</strong> Rust toolchain (stable).</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone <repo-url>
cd sapphire
cargo build --release"><pre>git clone <span>&lt;</span>repo-url<span>&gt;</span>
<span>cd</span> sapphire
cargo build --release</pre></div>
<p dir="auto">The <code>sapphire</code> binary will be at <code>target/release/sapphire</code>. Add it to your <code>PATH</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">Sapphire lives and grows by your feedback and code! We’re particularly looking for:</p>
<ul dir="auto">
<li>Testing and bug reports for Cask &amp; Bottle installation + <code>--build-from-source</code></li>
<li>Test coverage for core and cask modules</li>
<li>CLI UI/UX improvements</li>
<li>See <a href="https://github.com/alexykn/sapphire/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></li>
</ul>
<p dir="auto">Feel free to open issues or PRs. Every contribution helps!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<ul dir="auto">
<li><strong>Sapphire:</strong> BSD‑3‑Clause - see <a href="https://github.com/alexykn/sapphire/blob/main/LICENSE.md">LICENSE.md</a></li>
<li>Inspired by Homebrew BSD‑2‑Clause — see <a href="https://www.google.com/search?q=NOTICE.md" rel="nofollow">NOTICE.md</a></li>
</ul>
<hr>
<blockquote>
<p dir="auto"><em>Alpha software. No guarantees. Use responsibly.</em></p>
</blockquote>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ping, You've Got Whale: AI detection system alerts ships of whales in their path (154 pts)]]></title>
            <link>https://www.biographic.com/ping-youve-got-whale/</link>
            <guid>43764915</guid>
            <pubDate>Tue, 22 Apr 2025 18:28:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biographic.com/ping-youve-got-whale/">https://www.biographic.com/ping-youve-got-whale/</a>, See on <a href="https://news.ycombinator.com/item?id=43764915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>From inside a package about the size of a shoebox mounted to a ship’s deck, a set of highly stabilized heat-sensing cameras scans the ocean’s surface. Suddenly, against the misty waves far in the distance, they spot a small puff of white. And another. Now the algorithm catches on. A machine learning system snags the footage and runs it through a neural network trained on millions of similar snippets.&nbsp;&nbsp;</span></p><p><span>Comparing what it’s detecting against its training data, the artificial intelligence model makes a call: that small burst of heat in the distance is a spout of whale breath. The computer system pings a remote expert on standby who double-checks the machine’s work. Within a minute, the expert forwards the alert back to the ship, catching the captain’s attention with enough time for the crew to change course and, hopefully, avoid the whale becoming maritime roadkill.</span></p><p><span>This is WhaleSpotter, an artificial intelligence-powered whale detection system that aims to transmit real-time alerts to ships to prevent them from colliding with whales—a threat that leads to the injury or death of <a href="https://www.washington.edu/news/2024/11/21/whale-ship-collisions/">thousands of whales each year</a>.</span></p></div><div><p><span><em>Video courtesy of WhaleSpotter</em></span></p></div><div><p><span>Led by Daniel Zitterbart, a biophysicist at Woods Hole Oceanographic Institution in Massachusetts, scientists have been testing this new AI-powered but human-verified whale detection system on ferries, research vessels, and cruise ships, and from land-based installations along the east and west coasts of North America, as well as in parts of the Southern Ocean. </span><span>&nbsp;</span></p><p><span>Since WhaleSpotter first got underway during research trials in 2019, its capabilities have grown tremendously. Across its more than two dozen ship- and land-based installations, the global WhaleSpotter network made more than 51,000 marine mammal detections in 2024, up from just 78 its first year. All of those detections were automatically sent to a remote data center in real time, but only a few ships have opted in to receiving the 24/7 alerts.</span></p><p><span>But those ships are modestly sized. And in the quest to save whales from deadly collisions, one of the greatest challenges is protecting them from some of the biggest—and most common—vessels at sea: container ships. </span><span>&nbsp;</span></p><p><span>Strikes from container ships, which are massive and hard to maneuver, are one of the leading causes of death for large whales, according to Zitterbart. Peering out from a cargo ship’s bridge high above the waves, especially at night or in fog, a captain may struggle to see a whale soon enough to shift the course of the vessel, which can easily be 250 meters (800 feet) long. That’s why Zitterbart’s team recently began a research partnership with the Hawai‘i-based Matson Navigation Company to start adapting WhaleSpotter’s technology for this key class of vessels.</span><span>&nbsp;</span></p><p><span>Tailoring WhaleSpotter to work on container ships has required special considerations. Slower and harder to turn, container ships need more advance notice than other craft. However, container ships also tower over the ocean. Making use of the higher vantage point, Zitterbart and his team have been able to increase the distance at which their system can reliably spot whales. Testing longer-range cameras and adjusting the stabilization system on Matson’s container ships plying routes along Hawai‘i, Alaska, and the U.S. west coast, the team found that the technology can now reliably spot marine mammals up to 6 kilometers (nearly 4 miles) away. Matson’s ships are not yet receiving real-time alerts through WhaleSpotter’s systems, but Zitterbart and his colleagues continue fine-tuning their detection system to get it ready for prime time.</span><span>&nbsp;</span></p><p><span>“I think we’re almost there,” says Zitterbart. </span><span>&nbsp;</span></p><p><span>“We are excited by the early results,” adds Keoni Wagner, a Matson spokesperson. “Assuming the system achieves current expectations, we plan to expand use to our entire domestic fleet.”</span></p><p><span>From the perspective of John Calambokidis, a marine biologist with the nonprofit Cascadia Research Collective, there are, broadly, three strategies for reducing incidences of ships hitting whales: shift vessels’ routes, slow them down, and use real-time detection to avoid whales. Calambokidis says the third strategy has not received nearly enough attention, and that Zitterbart’s approach provides an important contribution. “That’s no simple feat,” he says of the expert-reviewed AI approach. He adds that the reliance on thermal cameras—which detect heat rather than light—makes the system particularly useful at night, when <a href="https://www.frontiersin.org/journals/marine-science/articles/10.3389/fmars.2019.00543/full">many whale species are more likely</a> to be near the surface than during the day. </span><span>&nbsp;</span></p><p><span>WhaleSpotter, which has just spun off into <a href="https://whalespotter.ai/">a for-profit company</a>, isn’t the only AI-enhanced thermal camera system able to detect whales. Awarion and SEA.AI can, too. But Zitterbart contends that what sets his technology apart is that WhaleSpotter is purpose-built for marine conservation. As such, he’s adamant about having humans validate the machine’s work. “Many people said, ‘Isn’t that overkill? Can’t we get rid of that?’” Zitterbart says. </span></p><p><span>While the AI system is designed to filter out false alarms—such as signals from birds, breaking waves, and boats—Zitterbart’s aim is for ship captains to receive zero false alerts, so that every ping truly requires their attention. Removing human oversight risks flooding ship captains with false reports, which could lead to frustration and alert fatigue. At risk is the very survival of species like the North Atlantic right whale, an endangered animal that has suffered heavily from ship strikes and has only 370 individuals left: “We cannot afford to ever miss an animal,” he says.</span></p><p><span>Calambokidis emphasizes that preventing collisions between whales and ships requires using multiple, complementary strategies. While Zitterbart readily agrees that WhaleSpotter is no silver bullet, he says it’s particularly suited to certain goals—like limiting the deaths of endangered species. </span></p><p><span>Ultimately, he wants more ships to carry WhaleSpotter cameras. “The true power will come to life once there are hundreds of vessels using this tech,” he says. “Then the collected information can be shared in real time with vessels not using the technology, too.” </span></p><p>Yet as he works to grow WhaleSpotter’s reach, Zitterbart’s focus remains on the animals: “Every single whale that is not struck because of the technology is a success.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The complex origin story of domestic cats (128 pts)]]></title>
            <link>https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html</link>
            <guid>43764771</guid>
            <pubDate>Tue, 22 Apr 2025 18:07:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html">https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html</a>, See on <a href="https://news.ycombinator.com/item?id=43764771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/domestic-cat.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/domestic-cat.jpg" data-sub-html="Credit: Pixabay/CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/domestic-cat.jpg" alt="domestic cat" title="Credit: Pixabay/CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: Pixabay/CC0 Public Domain
            </figcaption>        </figure>
    </div><p>Researchers looking into the origin of domestic cats have long considered that cats likely accompanied early farmers during the Neolithic, spreading through Europe alongside the adoption of agriculture.</p>


										      
																																	<p>Two new large-scale investigations, one led by the University of Rome Tor Vergata in collaboration with 42 institutions and another led by the University of Exeter with contributors from 37 institutions, reveal a more complex history than previously imagined. Both point to Tunisia as the likely origin of the domestic cat.</p>
<p>Both studies, which merge extensive genetic data with <a href="https://phys.org/tags/archaeological+evidence/" rel="tag">archaeological evidence</a>, challenge the timeline of European <a href="https://phys.org/tags/domestic+cats/" rel="tag">domestic cats</a>, and hint at cultural and religious factors that may have been pivotal in driving feline domestication and translocation.</p>
<p>Cats have long posed a puzzle for archaeologists. Their skeletal features and commonly used mitochondrial DNA markers can overlap significantly with those of their wild counterparts.</p>
<p>Researchers from the University of Rome Tor Vergata–led team conducted paleogenomic analyses of ancient cat specimens from 97 <a href="https://phys.org/tags/archaeological+sites/" rel="tag">archaeological sites</a> in Europe and Anatolia, as well as museum samples from Italy, Bulgaria, and North Africa.</p>
<p>In their study, "The dispersal of domestic cats from Northern Africa and their introduction to Europe over the last two millennia," <a href="http://biorxiv.org/lookup/doi/10.1101/2025.03.28.645893" target="_blank">published</a> on the <i>bioRxiv</i> preprint server , 70 low-coverage ancient genomes, 17 additional modern and museum genomes, and 37 radiocarbon-dated cat remains were analyzed.</p>

																																						
																																			<p>Results from these nuclear DNA analyses revealed that felines with domestic ancestry only appeared in Europe from around the 1st century CE onward, thousands of years later than traditional narratives suggest.</p>
<p>The Tor Vergata team also identified two introductory waves. An earlier one brought wildcats from Northwest Africa to Sardinia by the 2nd century BCE, giving rise to the island's present-day wild population. A subsequent wave, during the Roman Imperial period, introduced cats genetically similar to modern domestic lines across Europe, pointing towards Tunisia as a key center of early domestication.</p>
<p>In the University of Exeter collaboration study, "Redefining the timing and circumstances of cat domestication, their dispersal trajectories, and the extirpation of European wildcats," also <a href="https://www.biorxiv.org/content/10.1101/2025.03.28.645877v1" target="_blank">published</a> as a preprint on <i>bioRxiv</i>, a slightly different timeline is presented.</p>
<p>By analyzing 2,416 archaeological felid bones across 206 sites and cross-referencing morphological data with genetic findings, they concluded that domestic cats had already appeared in Europe by the early first millennium BCE, before the height of Roman expansion.</p>
<p>Distinct mitochondrial haplogroups were discovered in Britain by the 4th to 2nd centuries BCE, suggesting Iron Age contact, with subsequent waves of introduction occurring during the Roman, Late Antique, and Viking periods. Tunisia is also suggested as the origin point of domestic cats.</p>

																									
																																			<p>Whereas earlier models framed domestication as a primarily commensal relationship, cats as rodent control around <a href="https://phys.org/tags/human+populations/" rel="tag">human populations</a> and grain stores, religious and cultural dimensions emerge from both stories as a driving human interest in cats.</p>
<p>In Egypt, cats were venerated alongside deities such as Bastet, which may have fostered their mummification and movement via religious networks. Cats became symbols of Artemis and Diana in Greek/Roman <a href="https://phys.org/tags/religious+practice/" rel="tag">religious practice</a>, mirroring Bastet's significance in Egypt.</p>
<p>Norse mythology similarly featured cats linked to the goddess Freyja, implying that spiritual and ritual beliefs helped propel cats across wider geographies.</p>
<p>Both studies document admixture and competition between arriving domestic cats and Europe's native wildcats. Evidence points to a decline in wildcat populations beginning in the first millennium CE, potentially related to resource overlap, disease, and hybridization events.</p>
<p>Although the two investigations differ in their proposed arrival dates and dispersal routes for domestic cats, they share a key conclusion that the domestication and spread of cats in Europe happened more recently, and under more culturally driven circumstances, than once thought.</p>
<p>Findings dismantle the considerations that cats were ubiquitous in Neolithic settlements and underscore how previous reliance on mitochondrial markers alone can obscure the full picture of feline domestication.</p>
<p>Taken together, these studies significantly alter our understanding of one of humanity's most familiar companions. Rather than silently trailing behind <a href="https://phys.org/tags/early+farmers/" rel="tag">early farmers</a>, slinking ever closer to human activity and community, cats likely moved into Europe in multiple waves post-domestication from North Africa, propelled by human cultural practices, trade networks, and religious reverence.</p>

																																																					
																				<div>
																						<p><strong>More information:</strong>
												M. De Martino et al, The dispersal of domestic cats from Northern Africa and their introduction to Europe over the last two millennia, <i>biorxiv</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1101/2025.03.28.645893" target="_blank">DOI: 10.1101/2025.03.28.645893</a>
</p><p>Sean Doherty et al, Redefining the timing and circumstances of cat domestication, their dispersal trajectories, and the extirpation of European wildcats, <i>biorxiv</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1101/2025.03.28.645877" target="_blank">DOI: 10.1101/2025.03.28.645877</a></p>

																						
																						
																					</div>
                               											
																															 <p>
												  © 2025 Science X Network
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												The complex origin story of domestic cats: Research points to Tunisia (2025, April 16)
												retrieved 23 April 2025
												from https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[π0.5: A VLA with open-world generalization (171 pts)]]></title>
            <link>https://pi.website/blog/pi05</link>
            <guid>43764439</guid>
            <pubDate>Tue, 22 Apr 2025 17:29:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pi.website/blog/pi05">https://pi.website/blog/pi05</a>, See on <a href="https://news.ycombinator.com/item?id=43764439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Published</p><p>April 22, 2025</p><p>Email</p><p><span>research@physicalintelligence.company</span><span>Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili Yu, Ury Zhilinsky</span></p><p>Paper</p></div>

<div><p>Robots have come a long way over the past few years—they can perform impressive acrobatic feats, dance on stage, follow language commands and, <a href="https://pi.website/blog/pi0">in some of our own results</a>, perform complex tasks like folding laundry or cleaning off a table. But the biggest challenge in robotics is not in performing feats of agility or dexterity, but generalization: the ability to figure out how to correctly perform even a simple task in a new setting or with new objects. Imagine a robot that needs to clean your home: every home is different, with different objects in different places. Generalization must occur at many levels. At the low level, the robot must understand how to pick up a spoon (by the handle) or plate (by the edge), even if it has not seen these specific spoons or plates before, and even if they are placed in a pile of dirty dishes. At a higher level, the robot must understand the semantics of each task—where to put clothes and shoes (ideally in the laundry hamper or closet, not on the bed), and what kind of tool is appropriate for wiping down a spill. This generalization requires both robust physical skills and a common-sense understanding of the environment, so that the robot can generalize at many levels at the same time, from physical, to visual, to semantic. This is made even harder by the limited availability of diverse data for such robotic systems.</p><p>This is why most commercial robots operate in tightly controlled environments like factories or warehouses: in a world where the robot never needs to venture outside of a single building and where the objects and their locations are predetermined, current robotic methods that provide for only weak generalization can be very successful. Even the impressive demonstrations of robotic agility and dexterity that have been shown in recent years are typically designed to work in a specific environment, often with data collected in the test scene or very similar settings. But if we want robots to be part of our everyday lives, working in our homes, grocery stores, offices, hospitals, and other "messy" environments, we need strong generalization.</p><p>We have been developing robotic foundation models that can generalize to such messy environments, building on our vision-language-action (VLA) model <span>π<sub>0</sub></span>. While both <span>π<sub>0</sub></span> and other recent VLAs are evaluated in environments that closely match training, we've developed a new model that we call <span>π<sub>0.5</sub></span> that exhibits meaningful generalization to entirely new environments. We believe that this represents a significant step forward toward truly generalizable physical intelligence. Our current model is far from perfect: its goal is not to accomplish new skills or exhibit high dexterity, but to generalize to new settings, such as cleaning up a kitchen or bedroom in a new home that was not seen in the training data. In our experiments, <span>π<sub>0.5</sub></span> can perform a variety of tasks in entirely new homes. It does not always succeed on the first try, but it often exhibits a hint of the flexibility and resourcefulness with which a person might approach a new challenge.</p><p>The individual tasks that <span>π<sub>0.5</sub></span> performs vary in difficulty, from rearranging objects (e.g., to put dishes in the sink) to much more intricate behaviors, such as using a sponge to wipe down a spill. We show some of the more complex stages in these tasks below, and the videos of the long-horizon behaviors <a href="#long-horizon-videos">later in the post</a>.</p></div>

<div><h3 id="how-does-it-work">How does it work?</h3><p>The main principle behind <span>π<sub>0.5</sub></span> is co-training on heterogeneous data: by training our VLA model on a variety of different data sources, we can teach it not only how to physically perform diverse skills, but also how to understand the semantic context of each skill (e.g., if the task is to clean the kitchen, what are appropriate objects to pick up and put away, and where to put them), infer the high-level structure of a task (e.g., the steps required to make a bed), and even transfer physical behaviors from other robots (e.g., simpler robots that have one arm or no mobile base, or data from robots in less diverse environments).</p><p>Co-training is conceptually straightforward: because VLAs are derived from general vision-language models (VLMs), they can be trained on examples that consist of any combination of actions, images, text, and other multimodal annotations such as bounding boxes. This includes general multimodal tasks, such as image captioning, visual question answering, or object detection, and robotic oriented tasks, such as robotic demonstrations with actions, and "high-level" robot examples, consisting of observations labeled with the appropriate semantic behavior (e.g., an observation of an unmade bed with the label "pick up the pillow"). We also include "verbal instruction" demonstrations, where a person coaches the robot through a complex task by telling it what to do step by step (with natural language). The model makes both high-level inferences about the next semantic step to perform, analogously to chain-of-thought inference, and low-level predictions to output motor commands to the robot's joints:</p></div>

<p>While the basic principles of co-training are not new, training a VLA that can generalize broadly requires the right mixture of co-training tasks. Just like a person needs an appropriate curriculum to teach them the conceptual and practical aspects of a new job, VLAs need a "curriculum" provided by the mixture of co-training tasks to enable generalization at all of the necessary levels of abstraction. In our experiments, we trained versions of the <span>π<sub>0.5</sub></span> model that exclude different parts of the full training mixture: the "no WD" version excludes multimodal <strong>W</strong>eb <strong>D</strong>ata (question-answering, captioning, and object detection), the "no ME" version excludes <strong>M</strong>ultiple <strong>E</strong>nvironment data collected with non-mobile robots (e.g., static robots placed into many other homes), the "no CE" version excludes <strong>C</strong>ross <strong>E</strong>mbodiment data collect as part of the original <span>π<sub>0</sub></span> training set, and the "no ME or CE" version excludes both sources of robot data, leaving only the mobile manipulation data collected with the same robots that we use in our experiments (about 400 hours).</p>
<div><div><div><p>In-distribution Follow Rate</p></div><div><p>In-distribution Success Rate</p></div></div><p>Evaluating the full <span>π<sub>0.5</sub></span> training mixture compared to ablations that exclude various sources of data. Web data (WD) makes the biggest difference for generalizing to out-of-distribution objects, while data from other robots (ME and CE) is important across all evaluation conditions.</p></div>
<div><p>We evaluated two experimental conditions: full cleaning tasks, such as putting away dishes in the sink or cleaning up items off the floor of a bedroom, and an out-of-distribution (OOD) evaluation that tasks the robot to move specific objects indicated in the prompt into a drawer. For both evaluations, we measure the success rate, averaged over individual subtasks (e.g., the percentage of objects that were moved into their proper place), as well as the language following rate, which indicates the fraction of cases where the robot's behavior correctly accords with the user's prompt. We can see that in all cases, data from other robots (ME and CE) makes a big difference in terms of policy performance. In the OOD case, we also see a significant difference from including web data (WD), which greatly improves the robot's ability to correctly identify new object categories that were not in the data. More details on these experiments are included in the <a href="https://pi.website/download/pi05.pdf">accompanying paper</a>.</p><p>To better quantify just how much generalization <span>π<sub>0.5</sub></span> can achieve, we conducted a scaling study where we vary the number of different environments seen in the training data. We also include a baseline model in these comparisons that was trained directly on data from the test environment in addition to all of the other data sources. This model (shown with a horizontal green line) provides a sense for how well a VLA could do in this scene if the challenge of generalizing to new environments is removed.</p></div>
<div><p>Evaluating how performance scales with the number of training environments, when co-training with the other datasets in our training mixture. When using all of the available training environments (rightmost point on the graph), our model (yellow) attains similar performance as a baseline that is trained directly on test environments (green).</p></div>
<div><p>These results not only show that the generalization performance of <span>π<sub>0.5</sub></span> steadily increases with the number of distinct environments in the training set, but that after only about 100 training environments, it actually approaches the performance of the baseline model that was trained on test environment directly. This suggests that our recipe can attain effective generalization using relatively accessible amounts of mobile manipulation training data.</p><h3 id="training-and-inference">Training and inference</h3><p><span>π<sub>0.5</sub></span> is based on the <span>π<sub>0</sub></span> VLA, but because it is co-trained on tasks that require outputting a variety of label types, including actions and text, we can use the same model to control the robot at both the high and low level. When we run <span>π<sub>0.5</sub></span>, we first ask it to output a "high level" action expressed in text, and then ask it to follow this high level action by choosing an appropriate robot motor command, in the form of a 50-step (1-second) "action chunk" of continuous low-level joint actions. This approach follows our recently developed <a href="https://pi.website/research/hirobot">Hi Robot</a> system, except that the same model is used for both the high-level decisions and low-level motor control in a kind of "chain of thought" process.</p><p>The model itself includes both discrete auto-regressive token decoding and continuous decoding via flow matching, as in <span>π<sub>0</sub></span>. The discrete decoding pathway is used for inferring high-level actions, while the continuous flow-matching pathway is used for low-level motor commands, as illustrated in the diagram below.</p></div>

<div><h3 id="generalization-to-new-homes">Generalization to new homes</h3><p>We evaluated <span>π<sub>0.5</sub></span> by asking it to control mobile manipulators to clean new homes that were never seen in the training data. This is an exceptionally difficult test for a VLA: while there have been impressive demonstrations of VLA generalization, such as following new semantic commands, interactively following human instructions, and chaining together distinct primitive skills, such demonstrations typically take place in the same or very similar environment as the training data. Our recent <a href="https://pi.website/research/fast"><span>π<sub>0</sub></span>-FAST model</a> was able to generalize to new environments with the DROID setup, but for relatively simple skills like moving individual objects. Our experiments involved placing a robot equipped with <span>π<sub>0.5</sub></span> into an entirely new home and asking it to put away dishes, make the bed, or clean up a bedroom floor. These are long tasks that require not only using complex behaviors (such as using a sponge to clean a spill), but also understanding the semantics of the task and breaking it down into individual parts, with each stage interacting with the correct object. We show example evaluations of <span>π<sub>0.5</sub></span> in the videos below.</p></div>
<div id="long-horizon-videos"><div><p>Examples of our model completing long-horizon tasks in new kitchens and bedrooms.<!-- --> </p><p><strong>All experiments were done in homes that were not in the training data.</strong></p></div></div>
<p>The policies are reactive, and can handle both variability in the environment and perturbations. In the videos below, we test what happens when people interfere with the robot.</p>

<p>Lastly, the <span>π<sub>0.5</sub></span> model can accept language commands at various levels of granularity, from high-level prompts like "put the dishes in the sink" to detailed individual commands instructing the model to pick up specific objects or move in specific directions. We show some examples of language following in the videos below.</p>
<div><div><p>Our model can follow language commands at various levels of granularity.<br><strong>Yes, you know it by now - all experiments were done in homes that were not in the training data.</strong></p></div><p>We include detailed videos from our rigorous empirical evaluation below, with examples of successful and failed episodes of our model. Importantly, as with all the videos on this page, none of the scenes in the videos below are from the training data. Complete results from all experiments can be found in the <a href="https://pi.website/download/pi05.pdf">full article</a>.</p><h3 id="where-do-we-go-from-here">Where do we go from here?</h3><p>We showed that VLAs can enable broad generalization even for complex and extended robotic skills, like cleaning a kitchen or bedroom. Our <span>π<sub>0.5</sub></span> model can enable a robot to clean a new home that was never seen in the training data. <span>π<sub>0.5</sub></span> is far from perfect, and it often makes mistakes both in terms of its high-level semantic deductions and motor commands. However, by allowing robots to learn from a variety of knowledge sources, we hope that the <span>π<sub>0.5</sub></span> recipe will bring us closer to broadly generalizable and flexible physical intelligence. There is a lot left to do: while our robots can improve from verbal feedback, they could also in the future utilize their autonomous experience to get better with even less supervision, or they could explicitly request help or advice in unfamiliar situations. There is also a lot left to do to improve transfer of knowledge, both in the technical aspects of how the models are structured, and in the diversity of data sources that our models can employ.</p><p>If you are interested in collaborating, please <a href="mailto:collaborate@physicalintelligence.company" target="_blank" data-state="closed">reach out</a>. We are particularly excited to work with companies scaling up data collection with robots deployed for real-world applications, who are looking to collaborate on autonomy.</p><p>We are also hiring! If you'd be interested in <a href="https://pi.website/join-us">joining us</a> please get in touch.</p><p>For researchers interested in our work, collaborations, or other queries, please write to <a href="mailto:research@physicalintelligence.company" target="_blank" data-state="closed">research@physicalintelligence.company</a>.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are polynomial features the root of all evil? (2024) (168 pts)]]></title>
            <link>https://alexshtf.github.io/2024/01/21/Bernstein.html</link>
            <guid>43764101</guid>
            <pubDate>Tue, 22 Apr 2025 16:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexshtf.github.io/2024/01/21/Bernstein.html">https://alexshtf.github.io/2024/01/21/Bernstein.html</a>, See on <a href="https://news.ycombinator.com/item?id=43764101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="a-myth">A myth</h2>

<p>When fitting a non-linear model using linear regression, we typically generate new features using non-linear functions. We also know that any function, in theory, can be approximated by a sufficiently high degree polynomial. This result is known as <a href="https://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem">Weierstrass approximation theorem</a>. But many blogs, papers, and even books tell us that high polynomials should be avoided. They tend to oscilate and overfit, and regularization doesn’t help! They even scare us with images, such as the one below, when the polynomial fit using the data points (in red) is far away from the true function (in blue):
<img src="https://alexshtf.github.io/assets/poly_overfit.png" alt="Polynomial overfitting"></p>

<p>It turns out that it’s just a MYTH. There’s nothing inherently wrong with high degree polynomials, and in contrast to what is typically taught, high degree polynomials are easily controlled using standard ML tools, like regularization. The source of the myth stems mainly from two misconceptions about polynomials that we will explore here. In fact, not only they are great non-linear features, certain representations also provide us with powerful control over the shape of the function we wish to learn.</p>

<p>A colab notebook with the code for reproducing the above results is available <a href="https://github.com/alexshtf/alexshtf.github.io/blob/master/assets/polyfeatures.ipynb">here</a>.</p>

<h2 id="approximation-vs-estimation">Approximation vs estimation</h2>

<p>Vladimir Vapnik, in his famous book “The Nature of Statistical Learning Theory” which is cited more than 100,000 times as of today, coined the approximation vs. estimation balance. The approximation power of a model is its ability to represent the “reality” we would like to learn. Typically, approximation power increases with the complexity of the model - more parameters mean more power to represent any function to arbitrary precision. Polynomials are no different - higher degree polynomials can represent functions to higher accuracy. However, more parameters make it difficult to <em>estimate these parameters from the data</em>.</p>

<p>Indeed, higher degree polynomials have a higher capacity to approximate arbitrary functions. And since they have more coefficients, these coefficients are harder to estimate from data. But how does it differ from other non-linear features, such as the well-known <a href="https://en.wikipedia.org/wiki/Radial_basis_function">radial basis functions</a>? Why do polynomials have such a bad reputation? Are they truly hard to estimate from data?</p>

<p>It turns out that the primary source is the standard polynomial basis for n-degree polynomials \(\mathbb{E}_n = {1, x, x^2, ..., x^n}\). Indeed, any degree \(n\)  polynomial can be written as a linear combination of these functions:</p><p>

\[\alpha_0 \cdot 1 + \alpha_1 \cdot x + \alpha_2 \cdot x^2 + \cdots + \alpha_n x^n\]

</p><p>But the standard basis \(\mathbb{B}_n\) is <em>awful</em> for estimating polynomials from data. In this post we will explore other ways to represent polynomials that are appropriate for machine learning, and are readily available in standard Python packages. We note, that one advantage of polynomials over other non-linear feature bases is that the only hyperparameter is their <em>degree</em>. There is no “kernel width”, like in radial basis functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>The second source of their bad reputation is misunderstanding of Weierstrass’ approximation theorem. It’s usually cited as “polynomials can approximate arbitrary continuous functions”. But that’s not entrely true. They can approximate arbitrary continuous functions <strong>in an interval</strong>. This means that when using polynomial features, the data must be normalized to lie in an interval. It can be done using min-max scaling, computing empirical quantiles, or passing the feature through a sigmoid. But we should avoid the use of polynomials on raw un-normalized features.</p>

<h2 id="building-the-basics">Building the basics</h2>

<p>In this post we will demonstrate fitting the function</p><p>

\[f(x)=\sin(8 \pi x) / \exp(x)+x\]

</p><p>on the interval \([0, 1]\) by fitting to \(m=30\) samples corrupted by Gaussian noise. The following code implements the function and generates samples:</p>

<div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>true_func</span><span>(</span><span>x</span><span>):</span>
  <span>return</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>8</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>x</span><span>)</span> <span>/</span> <span>np</span><span>.</span><span>exp</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>x</span>

<span>m</span> <span>=</span> <span>30</span>
<span>sigma</span> <span>=</span> <span>0.1</span>

<span># generate features
</span><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>42</span><span>)</span>
<span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>m</span><span>)</span>
<span>y</span> <span>=</span> <span>true_func</span><span>(</span><span>X</span><span>)</span> <span>+</span> <span>sigma</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>m</span><span>)</span>
</code></pre></div>

<p>For function plotting, we will use uniformly-spaced points in \([0, 1]\). The following code plots the true function and the sample points:</p>

<div><pre><code><span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span>plt_xs</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1000</span><span>)</span>
<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>
<span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_func.png" alt="polyfit_func"></p>

<p>Now let’s fit a polynomial to the sampled points using the standard basis. Namely, we’re given the set of noisy points \(\{ (x_i, y_i) \}_{i=1}^m\), and we need to find the coefficients \(\alpha_0, \dots, \alpha_n\) that minimize:</p><p>

\[\sum_{i=1}^m (\alpha_0 + \alpha_1 x_i + \dots + \alpha_n x_i^n - y_i)^2\]

</p><p>As expected, this is readily accomplished by transforming each sample \(x_i\) to a vector of features \(1, x_i, \dots, x_i^n\), and fitting a linear regression model to the resulting features. Fortunately, NumPy has the <code>numpy.polynomial.polynomial.polyvander</code>function. It takes a vector containing \(x_1, \dots, x_m\) and produces the matrix</p><p>

\[\begin{pmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \dots &amp; x_1^n \\
1 &amp; x_2 &amp; x_2^2 &amp; \dots &amp; x_2^n \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_m &amp; x_m^2 &amp; \dots &amp; x_m^n \\
\end{pmatrix}\]

</p><p>The name of the function comes from the name of the matrix - the Vandermonde matrix. Let’s use it to fit a polynomial of degree \(n=50\).</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>LinearRegression</span>
<span>import</span> <span>numpy.polynomial.polynomial</span> <span>as</span> <span>poly</span>

<span>n</span> <span>=</span> <span>50</span>
<span>model</span> <span>=</span> <span>LinearRegression</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>
</code></pre></div>

<p>The reason we use <code>fit_intercept=False</code> is because the ‘intercept’ is provided by the first column of the Vandermonde matrix. Now we can plot the function we just fit:</p>

<div><pre><code><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>As expected, we got the “scary” image from the beginning of this post. Indeed, the standard basis is awful for model fitting! We hope that regularization provides a remedy, but it does not. Maybe adding some L2 regularization helps? Let’s use the <code>Ridge</code> class from the <code>sklearn.linear_model</code>  package to fit an L2 regularized model:</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>Ridge</span>

<span>reg_coef</span> <span>=</span> <span>1e-7</span>
<span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>reg_coef</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_standard_ridge.png" alt="polyfit_standard_ridge"></p>

<p>The regularization coefficient coefficient of \(\alpha=10^{-7}\) is large enough to break the model in \([0,0.8]\) but not large enough to avoid over-fitting in \([0.8, 1]\). Increasing the coefficient clearly won’t help - the model will be broken even further in \([0, 0.8]\).</p>

<p>Since we will be trying several polynomial bases, it makes sense to write a more generic function for our experiments that will accept various “Vandermonde” matrix functions of the basis of our choice, fit the polynomial using the <code>Ridge</code> class, and plot it with the original function and the sample points.</p>

<div><pre><code><span>def</span> <span>fit_and_plot</span><span>(</span><span>vander</span><span>,</span> <span>n</span><span>,</span> <span>alpha</span><span>):</span>
  <span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>alpha</span><span>)</span>
  <span>model</span><span>.</span><span>fit</span><span>(</span><span>vander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

  <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                           <span># plot the samples
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                 <span># plot the true function
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>vander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span>  <span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
  <span>plt</span><span>.</span><span>show</span><span>()</span>  
</code></pre></div>

<p>Now we can reproduce our latest experiment by invoking:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<h2 id="polynomial-bases">Polynomial bases</h2>

<p>It turns out that in our sister discipline, approximation theory, reseachers also encountered similar difficulties with the standard basis \(\mathbb{E}_n\), and developed a thoery for approximating functions by polynomials from different bases. Two prominent examples of bases of \(n\)-degree polynomials include, and their:</p>

<ol>
  <li>The <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> \(\mathbb{T}_n = \{ T_0, T_1, \dots, T_n \}\), implemented in the <code>numpy.polynomial.chebyshev</code> module.</li>
  <li>The <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomials</a> \(\mathbb{P}_n = \{ P_0, P_1, \dots, P_n \}\), implemented in the <code>numpy.polynomial.legendre</code> module.</li>
</ol>

<p>They are the computational workhorse of a large variety of numerical algorithms that are enabled by approximating a function using a polynomial, and are well-known for their advantages in approximating functions in the \([-1, 1]\) interval<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">2</a></sup>. In particular, the corresponding “Vandermonde” matrices are provided by the <code>chebvander</code> and <code>legvander</code> functions in corresponding modules above. Each row in these matrices contains the value of the basis functions at each point, just like the standard Vandermonde matrix of the standard basis. For example, the Chebyshev Vandermonde matrix is:</p><p>

\[\begin{pmatrix}
T_0(x_1) &amp; T_1(x_1) &amp; \dots &amp; T_n(x_1) \\
T_0(x_2) &amp; T_1(x_2) &amp; \dots &amp; T_n(x_2) \\
\vdots &amp; \vdots  &amp; \ddots&amp; \vdots  \\
T_0(x_m) &amp; T_1(x_m) &amp; \dots &amp; T_n(x_m) \\
\end{pmatrix}\]

</p><p>I will not elaborate their formulas and properties here for a reason that will immediately be revealed. However, I highly recomment Prof. Nick Trefethen’s “Approximation theory and approximation practice” <a href="https://people.maths.ox.ac.uk/trefethen/atapvideos.html">online video course</a> to get familiar with their advantages. His book with the same name is an excellent introduction to the subject.</p>

<p>It might be tempting to try fitting a Chebyshev polynomial using our <code>fit_and_plot</code> method above directly:</p>

<div><pre><code><span>import</span> <span>numpy.polynomial.chebyshev</span> <span>as</span> <span>cheb</span>

<span>fit_and_plot</span><span>(</span><span>cheb</span><span>.</span><span>chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<p>However, that’s not the best thing to do. We aim to fit a function sampled from \([0, 1]\), but the Chebyshev basis “lives” in \([-1, 1]\). Therefore, we will add the transformation \(x \to 2x-1\) before invoking the <code>chebvander</code> function:</p>

<div><pre><code><span>def</span> <span>scaled_chebvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
  <span>return</span> <span>cheb</span><span>.</span><span>chebvander</span><span>(</span><span>2</span> <span>*</span> <span>x</span> <span>-</span> <span>1</span><span>,</span> <span>deg</span><span>=</span><span>deg</span><span>)</span>

<span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1</span><span>)</span>
</code></pre></div>

<p>Note that a different basis requires a different regularization coefficient. We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg1.png" alt="polyfit_cheb_reg1"></p>

<p>Whoa! Seems even worse than the standard basis!. Maybe more regularization helps?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>10</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg10.png" alt="polyfit_cheb_reg10"></p>

<p>Appears that our polynomial is both a bad fit for the function, and extremely oscilatory. Even worse when the standard basis! Interested readers can repeat the experiment with Legendre polynomials and see a slightly better, but similar result. So what’s wrong? Is everything that approximation theory tries to teach us about polynomials wrong?</p>

<p>The answer stems from the fundamental difference between two tasks:</p>

<ul>
  <li><strong>Interpolation</strong> - finding a polynomial that agrees with the approximated function \(f(x)\) <em>exactly</em> at a set of <em>carefully chosen</em> points</li>
  <li><strong>Fitting</strong> - finding a polynomial that agrees <em>approximately</em> with a given <em>noisy</em> set of points, which are <em>out of our control</em>.</li>
</ul>

<p>The Chebyshev and Legendre bases perform extremely well at the the interpolation task, but not at the fitting task. It turns out that the polynomial \(T_k\) in the Chebyshev basis, and the polynomial \(P_k\) in the Legendre basis, are both \(k\)-degree polynomials. For example, \(T_1\) is a linear function, whereas \(T_{50}\) is a polynomial of degree 50. These two functions are radically different. Thus, the coefficient of \(T_1\) and \(T_{50}\) have “different units”. This property is shared with the standard basis as well. Thus, we have two issues:</p>

<ol>
  <li>A small change of the coefficient of a high degree basis function, say the coefficient \(\alpha_{50}\), has a huge effect on the shape of the polynomial. Thus, a small perturbation in the input data, be it from noise or a slighly different data point \(x_i\), has a <em>huge</em> effect of the fit model.</li>
  <li>L2 regularization makes no sense! For reasonable functions, the coefficient \(\alpha_{50}\) should be much smaller than the coefficient \(\alpha_1\). This is regardless of the choice of the basis!</li>
</ol>

<p>Both properties show that for the fitting, rather the interpolation tasks we need something else.</p>

<h2 id="the-bernstein-basis">The Bernstein basis</h2>

<p>A remedy is provided by the <a href="https://en.wikipedia.org/wiki/Bernstein_polynomial">Bernstein basis</a> \(\mathbb{B}_n = \{  b_{0,n}, \dots, b_{n, n} \}\). These are \(n\)-degree polynomials defined by on \([0, 1]\) by:</p><p>

\[b_{i,n}(x) = \binom{n}{i} x^i (1-x)^{n-i}\]

</p><p>These polynomials are widely used in computer graphics to approximate curves and surfaces, but it appears that they’re less known in the machine learning community. In fact, all the text you see on the screen when reading this post is rendered using Bernstein polynomials<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup>. We will study them more in depth in the next posts, but at this stage I would like to point out two simple properties that give an intuitive explanation of why they’re useful in machine learning.</p>

<p>First, note that each \(b_{i,n}\) is an \(n\)-degree polynomial. Thus, when representing a polynomial using</p><p>

\[p_n(x) = \alpha_0 b_{0,n}(x) + \alpha_1 b_{1,n}(x) + \dots + \alpha_n b_{n,n}(x),\]

</p><p>all the coefficients have the same “units”.</p>

<p>If the formula of \(b_{i,n}(x)\) seems familiar - you are correct. It is exactly the probability mass function of the binomial distribution for obtaining \(i\) successes in a sequence of trials whose success probability is \(x\). Therefore, \(b_{i,n}(x) \geq 0\),  and \(\sum_{i=0}^n b_{i,n}(x) = 1\) for any \(x \in [0, 1]\). Consequently, the polynomial \(p_n(x)\) is just a weighted average of the coefficients \(\alpha_0, \dots, \alpha_n\). So not only the coefficients have the same “units”, their “units” are also the same as the model’s labels. Thus, they’re much easier to regularize - they’re all on the same “scale”.</p>

<p>Finally, due to the equivalence with the binomial distribution p.m.f, we can implement a “Vandermonde” matrix in Python using the <code>scipy.stats.binom.pmf</code> function.</p>

<div><pre><code><span>from</span> <span>scipy.stats</span> <span>import</span> <span>binom</span>

<span>def</span> <span>bernvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
	<span>return</span> <span>binom</span><span>.</span><span>pmf</span><span>(</span><span>np</span><span>.</span><span>arange</span><span>(</span><span>1</span> <span>+</span> <span>deg</span><span>),</span> <span>deg</span><span>,</span> <span>x</span><span>.</span><span>reshape</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>1</span><span>))</span>
</code></pre></div>

<p>Let’s try and fit without regularization at all</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>0</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg0.png" alt="polyfit_bern_reg0"></p>

<p>We see our regular over-fitting. Now let’s see that they’re indeed easy to regularize. After trying several regularization coefficients, I came up with this:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>5e-7</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg5em4.png" alt="polyfit_bern_reg5em4"></p>

<p>Beautiful! This is a polynomial of degree 50! The fit is great, no oscillations, and the misfit near the right endpoint stems from the noise - I don’t believe there’s enough information in the data to convey the fact that it should “curve up” rather than “curve down”.</p>

<p>Let’s see what happens when we crank-up the degree. Can we produce a nice non-oscilating polynomial?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>100</span><span>,</span> <span>alpha</span><span>=</span><span>5e-4</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_100_reg5em4.png" alt="polyfit_bern_100_reg5em4"></p>

<p>This is a polynomial of degree 100, that does not overfit!</p>

<h2 id="summary">Summary</h2>

<p>The notorious reputation of high-degree polynomials in the machine learning community is primarily a myth. Despite it, papers, books, and blog posts are based on this premise as if it was an axiom. Bernstein polynomials are little known in the machine learning community, but there are a few papers<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> using them to represent polynomial features. Their main advantage is ease of use - we can use high degree polynomials to exploit their approximation power, and easily control model complexity with just one hyperparameter - the regularization coefficient.</p>

<p>In the following posts we will explore the Bernstein basis in more detail. We will use it to create polynomial features for real-world datasets and test it versus the standard basis. Moreover, we will see how to regularize the coefficients to control the shape of the function we aim to represent.. For example, what if we know that the function we’re aiming to fit is increasing? Stay tuned!</p>

<hr>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I should have loved biology too (239 pts)]]></title>
            <link>https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</link>
            <guid>43764076</guid>
            <pubDate>Tue, 22 Apr 2025 16:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too">https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</a>, See on <a href="https://news.ycombinator.com/item?id=43764076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>About a year ago, I came across James Somers’ blog post, </span><em><a href="https://jsomers.net/i-should-have-loved-biology/" rel="">I should have loved biology</a></em><span>. I began reading it and every sentence struck a chord: “I should have loved biology but found it a lifeless recitation of names”; “In textbooks, astonishing facts were presented without astonishment”; “In biology class, biology wasn’t presented as a quest for the secrets of life. The textbooks wrung out the questing.” In fact, the chord was so neatly stuck that I stopped reading about a quarter of the way through, and found myself falling into a memory. I was sitting in my 7th grade biology class, completely disinterested. Every time our teacher would turn her back to us to write on the blackboard, my friends and I would sling paper pellets at each other across the room, barely paying attention as she narrated wearily about cell walls or chloroplasts or mitochondria being the powerhouse of the cell. I liked math and physics and economics and even chemistry, to some extent (much less pellet slinging), but biology, with its endless memorization of definitions and regurgitation of facts – no, biology could go back under the soil it came from.</span></p><p>Now, I’m obsessed. I can’t get enough. I’ve read about fifteen books in the last year or so, watched countless YouTube videos, and started a bioinformatics course. And my list keeps growing. The first quarter of Somers’ post was so effective in making me consider my own disinterest-to-obsession journey – (I didn’t even read the rest until months later) – that I decided to look back and examine what caused this complete change of heart.</p><p><span>More than anything – nature documentaries, science shows, museum visits – it was great writing that allowed me to see the world of biology differently. My interest in biology, or rather the reversal of my disinterest in biology, began when I read </span><em>The Sixth Extinction</em><span> in 2016, during my second year of university. Elizabeth Kolbert’s gripping writing unveiled a completely different perspective of the subject, right alongside the scientists and researchers: driving through a Panamanian rainforest looking for golden frogs, searching a littered New Jersey creek for ammonites, scuba-diving in Castello Aragonese to inspect carbon dioxide rushing out of sea vents and in The Great Barrier Reef to look at octopi and coral reefs and blue starfish and leopard sharks and giant clams. Biology, suddenly, didn’t seem just a list of facts to memorize; it was an adventure.</span></p><p>I still remember how I felt after finishing her book: a strange mix of wonder and tragedy, awe and despair. That narrative structure – vivid reporting and meticulous research built on a foundation of context and history – changed how I saw science and scientists. No more dry paragraphs of definitions and explanations; every discovery had a story.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" width="1000" height="667" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:667,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1083159,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>The Great Barrier Reef, the world’s largest coral reef system. Elizabeth Kolbert occasionally reports about the impact of climate change there.</figcaption></figure></div><p><span>I wanted more books just like that, and luckily for me, several months later in an airport bookshop in Bangalore, I came across and picked up </span><em>The Gene</em><span>. I wasn’t aware of who Siddhartha Mukherjee was at the time (possibly the mention of Pulitzer Prize winner on the cover influenced me), and I had no prior interest in genetics, but that book would end up completely changing my worldview on biology and non-fiction writing. If Kolbert made a crack in the dam I had built around biology, Mukherjee would go on to smash the whole thing down to pieces.</span></p><p>One of the stories in the book, the discovery of the gene that caused Huntington’s disease, moved me tremendously when I first read it a few years ago. It’s the perfect example of the amount of effort that goes into a scientific discovery that then ends up as a single sentence in a textbook; in this case, that Huntington’s disease is a hereditary, neurodegenerative disorder caused by a mutation in a single gene.</p><p><span>The story of finding that mutation would make a thrilling movie: a young woman named Nancy Wexler, devastated by the news that her mother has been diagnosed with Huntignton’s and that she and her sister would have a 50-50 chance of getting it, decides to devote her life to solving this medical mystery. Her quest takes her from nursing homes in Los Angeles to interdisciplinary scientific workshops in Boston to stilt villages surrounding Lake Maracaibo in Venezuela. Her decade-long blood and skin sample collection efforts there would create the largest family tree with Huntington’s, leading to the first genetic test for the disease, followed by locating the precise genetic mutation that caused it</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-1-158089094" target="_self" rel="">1</a></span><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:231012,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Dr. Nancy Wexler in 1990, with a family tree that traced the path of Huntington’s. Acey Harper/The LIFE Collection, via Getty Images. Taken from the New York Times.</figcaption></figure></div><p><span>The gene sequence had a strange repeating structure, CAGCAGCAG… continuing for 17 repeats on average (ranging between 10 to 35 normally), encoding a huge protein that’s found in neurons and testicular tissue (its exact function is still not well understood). The mutation that causes HD increases the number of repeats to more than forty – a “molecular stutter” – creating a longer huntingtin protein, which is believed to form abnormally sized clumps when enzymes in neural cells cut it. The more repeats there are, the sooner the symptoms occur and the higher the severity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-2-158089094" target="_self" rel="">2</a></span><span>.</span></p><p>Nancy herself opted not to take the genetic test she helped create. “If the test showed I have the gene,” she wrote in 1991, “would I continue to feel the happiness, the passion, the occasional ecstasy I feel now? Is the chance of release from Huntington’s worth the risk of losing joy?”. In 2020, at the age of 74, she revealed that she had Huntington’s. The public acknowledgment was not a surprise for those close to her – for the last decade, they noticed her gait slowly deteriorate, speech slur, and limbs jerk in random directions, the same characteristics she saw in her mother half a century ago, and in the hundreds of Venezuelan patients she tended to ever since.</p><p>There’s still no cure for Huntington’s disease, but every time I hear about progress on cures, I feel a rush of emotions, like I have a personal stake in its invention. I really wish to see one found within Nancy Wexler’s lifetime; this movie deserves a happy ending.</p><p>Pick a field in biology, or a slice of history, and you’ll find countless stories just like this. Mischievous Watson and Crick figuring out the structure of DNA after getting a peek at Rosalind Franklin’s crisp x-ray crystallography photograph; Baruch Blumberg discovering hepatitis B after locating the antigen in the blood of an Australian Aboriginal, and beating NIH to its cure, the world’s first cancer vaccine; James Simpson systematically inhaling various vapors and recording its effects in the search for a better anesthetic, resulting in the discovery of chloroform; Andreas Vesalius taking prisoners’ corpses hanging in the gallows in 16th century Paris and, along with painter Andrea Mategna, publishing nearly 700 incredibly detailed drawings of the human anatomy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" width="1200" height="1678" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1678,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:161518,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>An illustration from </span><em>De Humani Corporis Fabrica</em><span> (On the Fabric of the Human Body), published in 1543 by Andreas Vesalius and Andrea Mategna. The first edition included over 200 high-detail anatomical illustrations. I particularly like this one.</span></figcaption></figure></div><p>History and stories may not be immediately applicable, but when used as a key ingredient it makes the discoveries more majestic, more impactful. That’s what I love about Mukherjee’s writing: it’s a unique stew of history, biography, experimental methods and results, scientific findings and their significance, seasoned well with personal anecdotes, and presented with the candor of a physician and the artistry of a poet. The context creates a kind of multiplier when the mind-shattering discoveries are explained – how a genotype gives rise to a phenotype, how cancer works, how a heart beats or a bone mends itself or a brain remembers a memory. Like the climax of a movie scene, the beauty and immensity of the discovery or the invention feels far more compelling after following the steps that got us there.</p><p><span>Every discovery might not have an entertaining backstory, but even when focusing on just the phenomenon, great technical writing has this striking ability to make you see the world differently. The same molecule or cell or organ, theory or experiment or discovery, suddenly seems monumental, like it’s the most important thing in the world. It makes you think: </span><em>why didn’t I learn about this before?</em></p><p><span>One of my favourites is the way Mukherjee describes how a neuron communicates in </span><em>The Song of the Cell</em><span>:</span></p><blockquote><p><em>Imagine the nerve, first, in its “resting” state. At rest, the internal milieu of the neuron contains a high concentration of potassium ions and a minimal concentration of sodium ions. This exclusion of sodium from the neuron’s interior is critical; we might imagine these sodium ions as a throng outside the citadel, locked out of the castle’s walls and banging at the gates to get inside. Natural chemical equilibrium would drive the influx of sodium into the neuron. In its resting state, the cell actively excludes sodium from entry, using energy to drive the ions out…</em></p><p><em>[...] The dendrites are the site within the neuron where the “input” of the signal originates. When a stimulus—typically a chemical called a “neurotransmitter”—arrives at one of the dendrites, it binds to a cognate receptor on the membrane. And it is at this point that the cascade of nerve conduction begins.</em></p><p><em>The binding of the chemical to the receptor causes channels in the membrane to open. The citadel’s gates are thrown ajar, and sodium floods into the cell. As more ions swarm in, the neuron’s net charge changes: every influx of ions generates a small positive pulse. And as more and more transmitters bind, and more such channels open, the pulse increases in amplitude. A cumulative charge courses through the cell body.</em></p></blockquote><p><span>The mental picture of a </span><em>throng</em><span> of sodium ions </span><em>locked out of the castle walls</em><span> is so helpful and convincing. I can see, in my mind’s eye, these shadowy ions</span><em> banging at the gates to get inside</em><span>, like an invading army</span><em>.</em><span> Then, after the neurotransmitter binds to the cognate receptor, the sodium ions don’t just enter, they </span><em>flood</em><span> and </span><em>swarm</em><span> in; the membrane doesn’t just open, its </span><em>gates are thrown ajar</em><span>. The metaphor makes the chemical process relatable without leaving out the details; the vivid language romanticizes it, creating a mental picture that not only stays with you, but makes you want to learn more.</span></p><p>A little later in the chapter, Mukherjee writes about neural connection in the fetus:</p><blockquote><p><em>Neural connections between the eyes and the brain are formed long before birth, establishing the wiring and the circuitry that allow a child to begin visualizing the world the minute she emerges from the womb. Long before the eyelids open, during the early development of the visual system, waves of spontaneous activity ripple from the retina to the brain, like dancers practicing their moves before a performance… This fetal warm-up act—the soldering of neural connections before the eyes actually function—is crucial to the performance of the visual system. The world has to be dreamed before it is seen.</em></p></blockquote><p><span>There’s something about this evocative language that leaves a sweet, lingering imprint on my mind — a new set of neural connections; my own </span><em>throng </em><span>of sodium ions </span><em>banging at the gates</em><span>, my own </span><em>ripples</em><span>. The details – which ions, the name of the receptor – might get murky after the passage of time, but the sweet feeling remains, like a memory of a heavenly meal; you may have forgotten the exact taste, but the feeling of satisfaction lingers, and occasionally, when it enters front and center, you might imagine visiting the restaurant (or home) once more. </span></p><p>That’s what I feel after reading books like this – the belief that I’ll revisit it, relive it, relearn it. It fills up a reservoir of curiosity, and every subsequent piece of stimulus – a neurology article or academic paper shared on Twitter, a documentary or YouTube video, another book (even textbooks) – opens the floodgates, and makes you want to explore a little more. I might not have the equipment to see this cell myself, but when written like this, this world too can be dreamed before it is seen.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" width="1456" height="2176" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2176,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1369914,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Santiago Ramón y Cajal’s famous drawing of neurons, circa late 19th century. He would go on to create more than 2,900 drawings detailing the nervous system’s architecture. Image taken from Quanta Magazine</figcaption></figure></div><p><span>The more you explore, the more astonishing it gets. Suddenly, you’re surrounded by these facts that stop you in your tracks. Like the fact that there are 20-30 trillion red blood cells in our body, making up roughly 84% of all our cells, and 1.2 million are created in our bone marrow every second. Or the fact that our visual system is predictive, calculating where to move the hand to catch a ball before your visual system has fully registered its trajectory</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-3-158089094" target="_self" rel="">3</a></span><span>.</span></p><p><span>One of my favorite ‘sentences that stopped me in my tracks’ comes from Nick Lane’s book, </span><em>The Vital Question</em><span>. He starts with carefully explaining that all cells derive their energy from a single type of chemical reaction, the redox reaction, where electrons are transferred from one molecule to another. Rust is a redox reaction: iron donates electrons to oxygen, being </span><em>oxidized</em><span> in the process. Same with fire: oxygen (O</span><sub>2</sub><span>) is </span><em>reduced</em><span> to water after receiving two electrons (O</span><sup>2-</sup><span>) and then two protons (H</span><sub>2</sub><span>O), balancing the charges, and releasing heat in the process. Respiration — the process that turns our food into energy — does exactly this as well, except that it conserves </span><em>some</em><span> of the energy in the form of a molecule called adenosine triphosphate (ATP). Think of ATP as an energy currency, able to be stored or converted back into energy by splitting the molecule into ADP (adenosine diphosphate) and P</span><sub>i</sub><span> (phospate). And so, he writes, “</span><strong>in the end respiration and burning are equivalent; the slight delay in the middle is what we know as life</strong><em>.”</em></p><p>Wait, what? The slight delay in the middle is what we know as life? I think when I first read that I might have skipped a heartbeat. I learned about mitochondria and ATP and redox reactions and aerobic respiration in high school, but I never pictured it as millions of molecular fires that keep us alive. Actually, not a million; it’s at least a quadrillion – per second. </p><p>ATP is synthesized by the fabled mitochondria, but that’s not all they do. They also regulate metabolism, participate in cell growth and death, manage calcium levels, and are involved in detoxification, hormone production, and cellular signalling. They even have their own genetic code. In fact, your mitochondria come from your mother and your mother only; they’re not genetically recombined like the rest of you. They’re remarkably fascinating; even the universally memed “powerhouse” doesn’t quite cover its capabilities.</p><p>All of this is still merely scratching the surface of wonder. I’ve only really described three examples in biology, all of which relate to human cells. But we’re just one of the millions of organisms on this planet. Bacteria, plants, fungi, insects, birds, reptiles, mammals, and everything in between, are all made up of cells. And every level – ecological, species, organism, tissue, cellular, organelle, protein, genome – has its own stories, each its own magic.</p><p><span>In his blog post, Somers advised to learn in small, deep slices. But I took a different approach: I went shallow and wide. Kolbert, Mukherjee, and Lane inspired exploring adjacent domains, and so I read about epidemiology, drug discovery, gene editing, molecular biology, systems and synthetic biology, immunotherapy, and memoirs from surgeons, cancer patients, and “biology watchers”. Even my fiction choices started to exhibit a biology tinge: </span><em>The Shell Collector</em><span>, </span><em>The Covenant of Water</em><span>, </span><em>The Overstory</em><span>. Eventually, I started seeing biology everywhere — the roots of a sidewalk tree battling with concrete, a group of sparrows frolicking in a bush, a young woman in an air cast fiddling with her crutches — as if it escaped the pages and began whispering its presence wherever I went.</span></p><p>Last summer, I went scuba diving for the first time in my life. I’ve wanted to go since I was a teen, a desire amplified after reading Kolbert’s adventures and watching ocean documentaries. After years and years of postponing, I finally pulled the trigger and flew to Puerto Vallarta to get Open Water certified. I could fill an entire essay with just this certification experience — the anxiety-inducing pre-dive coursework that essentially just lists the many ways you can get seriously injured or die; the silly awkwardness of training in a Mexican hotel pool surrounded by curious onlookers; the ear injury I sustained after my first ocean dive, where a rupture caused by improper depressurization caused middle ear fluid to flood my right ear canal, leaving me with partial hearing loss for a week (even PADI’s intimidating coursework could only do so much) — but I will focus on just the experience of my second dive here.</p><p>It was a picture-perfect day in Puerto Vallarta: deep blue skies, fluffy cotton-candy clouds floating above, a momentary cool breeze tempering the unrelenting summer humidity. As our boat sped along to Playa Majahuitas, about a 40 minutes ride from the main pier, I watched the lush green hills roll by just behind the shore, the ocean shimmering as the sun flung silver disks across its surface. During the ride, I asked the couple sharing the boat about their scuba experiences, and, again, I got a common response I still couldn’t relate to: that it was meditative — it was where your problems of land disappear, and you get to be a visitor in the home of sea-life, a polite guest just observing. </p><p>Our dive spot looked like a painting: water so clear you could see schools of fish just by peering over the edge of the boat. Just before we began, we got a surprise visit from a manta ray – this enormous, ethereal creature silently gliding under the water, just flicking the tips of its wings above the surface, as if to say hello, and welcome us into its home.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2068990,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The dive spot in Playa Majahuitas, Mexico</figcaption></figure></div><p>After the dive that day, I understood what the couple meant. I felt a lot more comfortable with my equipment second time around, and so, no longer apprehensive about buoyancy or breathing rate or how deep I was, I finally felt free to fully take in my surroundings. I fell into a gentle rhythm: inhale, listen to the hiss of the regulator, exhale, watch the bubbles float away. You’re distinctly aware of each and every moment, mind blank and in awe of the world around you: a large school of Cortez wrasses passing by; a camouflaged octopus hiding under the seabed; a moray eel sticking its neck out of a little hole, an angry look on its face, as if you’ve just disturbed its sleep; the vast, splendid diversity of corals – you can see it living, with little, wavy hand-like appendages collecting bits of floating food to eat, with tiny fish swimming in and out and around, as if playing a game of tag. </p><p>It was truly marvelous. Colors, too, are more vibrant underwater, as if the gods enhanced saturation as a gift to those that dare venture below. The body of spotted boxfish are a glittery blue, and the yellow speckled top shines in contrast. The corals too are rich: deep oranges, yellows, greens and browns. Even ocean documentaries, with their film-grade color editing, don’t capture the true shades.</p><p>During the boat ride back, I had this incredibly calming bliss completely take over my body. (Maybe that’s also what people attribute to its meditative quality, although meditative isn’t exactly the right word). For me, the whole experience would mark the start of a gradual realization that I wanted my role in biology to be more than just reading. My favorite science writers – Kolbert, Mukherjee, Lane, Lewis Thomas, Donald Kirsch – all wrote from experience, and if I wanted to write, or create, like that, I’d have to experience the world too. I began piecing together the things that had been swimming in my mind: namely, how to combine my past passion, interactive learning, with my latest obsession, biology. </p><p><span>I have since restarted working on my website, </span><a href="https://www.newtinteractive.com/" rel="">Newt Interactive</a><span>, to make interactive articles and accessible simulators for topics in biology. I too, like Somers mentions at the end of his blog post, want to bring the three dimensional nature of biology to life. The subject is teeming with fascinating phenomena that remain hidden or inaccessible to those outside scientific and research communities. Occasionally, I’ll come across something incredible — like a video of a molecular motor in action — but the sheer marvel of that just fundamentally doesn’t click unless you’re already well versed in the subject</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-4-158089094" target="_self" rel="">4</a></span><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" width="1456" height="851" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:851,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1749056,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>My interactive simulator of a coherent type-1 feed forward loop, a common gene circuit. My hope is that these kinds of playgrounds can make complex topics more accessible. </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">Try it out on Newt Interactive</a></figcaption></figure></div><p><span>I hope to bridge this gap and make some of biology's intricate mechanisms comprehensible and awe-inspiring for everyone. I’ve started with an </span><a href="https://www.newtinteractive.com/series/systems-biology/transcription-network-basics-1" rel="">interactive series on systems biology</a><span> (and wrote about my idea and motivation behind it in a </span><a href="https://nehalslearnings.substack.com/p/a-new-interactive-series-for-systems" rel="">previous post</a><span>), as well as some standalone simulators for a few concepts: </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">coherent type-1 feed forward loops</a><span> and </span><a href="https://www.newtinteractive.com/blocks/circuit-evolution" rel="">genetic circuit evolution</a><span>, for two. My goal is to work my way up to more sophisticated simulations, tools, and interactive articles that will help illustrate, and importantly, allow you to play with, more advanced concepts. In addition, I’d like to generally write and draw more as well (also started with this by making </span><a href="https://press.asimov.com/articles/gene-circuit" rel="">my first science graphic and biological math model for Asimov Press</a><span>).</span></p><p>Stories of science can elicit all kinds of emotions: joy, sadness, enchantment, heartbreak, optimism, valiance, apprehension, intrigue. I find, however, that one theme seems to be consistent among the characters: curiosity. This shouldn’t come as a surprise, of course, but what I hadn’t anticipated was how infectious it could be. Just reading about these scientists — their history, theories, efforts, mistakes and unwavering dedication to truth — kindled an active curiosity in me. I don’t think I have the patience to do what the scientists I read about did, experimenting day after day, week and week, year after year, exploring a small sliver in the “infinite vastness of biology”. And, since my curiosity started and ended with books, I didn’t think there was a meaningful role I could play. I couldn’t hear the calling.</p><p>But now I’m not so sure. I have this recurring desire to look down a microscope, and see a cell live its life, see its components swimming, squirming, dividing. I want to see a sequencing machine take in an organism’s DNA and spit out all its nucleotide bases; to hold a test-tube with genetic material that I edited with CRISPR-Cas9; to roam around a laboratory and peek at each bench’s weird collection of tools and equipment and liquids, slide my feet across the polished laboratory floor, smell the lingering scent of disinfectant; to go on more dives and hikes and explore the breathtaking diversity of life. It’s not quite a calling, more like hearing a faint ringtone in a distant room. You’re not sure if your phone’s ringing or your mind’s making the sound up. Maybe this time it’s worth taking a look.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rowboat – Open-source IDE for multi-agent systems (131 pts)]]></title>
            <link>https://github.com/rowboatlabs/rowboat</link>
            <guid>43763967</guid>
            <pubDate>Tue, 22 Apr 2025 16:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rowboatlabs/rowboat">https://github.com/rowboatlabs/rowboat</a>, See on <a href="https://news.ycombinator.com/item?id=43763967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rowboatlabs/rowboat/blob/main/assets/banner.png"><img src="https://github.com/rowboatlabs/rowboat/raw/main/assets/banner.png" alt="ui"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Let AI build multi-agent workflows for you in minutes</h2><a id="user-content-let-ai-build-multi-agent-workflows-for-you-in-minutes" aria-label="Permalink: Let AI build multi-agent workflows for you in minutes" href="#let-ai-build-multi-agent-workflows-for-you-in-minutes"></a></p>

<ul dir="auto">
<li>✨ <strong>Start from an idea -&gt; copilot builds your multi-agent workflows</strong>
<ul dir="auto">
<li>E.g. "Build me an assistant for a food delivery company to handle delivery status and missing items. Include the necessary tools."</li>
</ul>
</li>
<li>🌐 <strong>Connect MCP servers</strong>
<ul dir="auto">
<li>Add the MCP servers in settings -&gt; import the tools into Rowboat.</li>
</ul>
</li>
<li>📞 <strong>Integrate into your app using the HTTP API or Python SDK</strong>
<ul dir="auto">
<li>Grab the project ID and generated API key from settings and use the API.</li>
</ul>
</li>
</ul>
<p dir="auto">Powered by OpenAI's Agents SDK, Rowboat is the fastest way to build multi-agents!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Set your OpenAI key</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-openai-api-key"><pre><span>export</span> OPENAI_API_KEY=your-openai-api-key</pre></div>
</li>
<li>
<p dir="auto">Clone the repository and start Rowboat docker</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:rowboatlabs/rowboat.git
cd rowboat
docker-compose up --build"><pre>git clone git@github.com:rowboatlabs/rowboat.git
<span>cd</span> rowboat
docker-compose up --build</pre></div>
</li>
<li>
<p dir="auto">Access the app at <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a>.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Create a multi-agent assistant with MCP tools by chatting with Rowboat</h4><a id="user-content-create-a-multi-agent-assistant-with-mcp-tools-by-chatting-with-rowboat" aria-label="Permalink: Create a multi-agent assistant with MCP tools by chatting with Rowboat" href="#create-a-multi-agent-assistant-with-mcp-tools-by-chatting-with-rowboat"></a></p>
<p dir="auto"><a href="https://youtu.be/YRTCw9UHRbU" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/30795890/436225856-c8a41622-8e0e-459f-becb-767503489866.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzODY1MDMsIm5iZiI6MTc0NTM4NjIwMywicGF0aCI6Ii8zMDc5NTg5MC80MzYyMjU4NTYtYzhhNDE2MjItOGUwZS00NTlmLWJlY2ItNzY3NTAzNDg5ODY2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIzVDA1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlmM2QzMDY0NGExMGE5N2RkZGVjYjc2MTczZTNlZmM0MTliMGQyMGQ0MzQ3N2FmNThiZjIwYmRkMWZjOTVmZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.T9HThNk1WrCLJtewTpueh_T1h5MRkw6u0l-DHc2hEzk" alt="Screenshot 2025-04-23 at 00 25 31" secured-asset-link=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integrate with Rowboat agents</h2><a id="user-content-integrate-with-rowboat-agents" aria-label="Permalink: Integrate with Rowboat agents" href="#integrate-with-rowboat-agents"></a></p>
<p dir="auto">There are 2 ways to integrate with the agents you create in Rowboat</p>
<ol dir="auto">
<li>
<p dir="auto">HTTP API</p>
<ul dir="auto">
<li>You can use the API directly at <a href="http://localhost:3000/api/v1/" rel="nofollow">http://localhost:3000/api/v1/</a></li>
<li>See <a href="https://docs.rowboatlabs.com/using_the_api/" rel="nofollow">API Docs</a> for details</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="curl --location 'http://localhost:3000/api/v1/<PROJECT_ID>/chat' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer <API_KEY>' \
--data '{
    &quot;messages&quot;: [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;tell me the weather in london in metric units&quot;
        }
    ],
    &quot;state&quot;: null
}'"><pre>curl --location <span><span>'</span>http://localhost:3000/api/v1/&lt;PROJECT_ID&gt;/chat<span>'</span></span> \
--header <span><span>'</span>Content-Type: application/json<span>'</span></span> \
--header <span><span>'</span>Authorization: Bearer &lt;API_KEY&gt;<span>'</span></span> \
--data <span><span>'</span>{</span>
<span>    "messages": [</span>
<span>        {</span>
<span>            "role": "user",</span>
<span>            "content": "tell me the weather in london in metric units"</span>
<span>        }</span>
<span>    ],</span>
<span>    "state": null</span>
<span>}<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto">Python SDK
You can use the included Python SDK to interact with the Agents</p>

<p dir="auto">See <a href="https://docs.rowboatlabs.com/using_the_sdk/" rel="nofollow">SDK Docs</a> for details. Here is a quick example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from rowboat import Client, StatefulChat
from rowboat.schema import UserMessage, SystemMessage

# Initialize the client
client = Client(
    host=&quot;http://localhost:3000&quot;,
    project_id=&quot;<PROJECT_ID>&quot;,
    api_key=&quot;<API_KEY>&quot;
)

# Create a stateful chat session (recommended)
chat = StatefulChat(client)
response = chat.run(&quot;What's the weather in London?&quot;)
print(response)

# Or use the low-level client API
messages = [
    SystemMessage(role='system', content=&quot;You are a helpful assistant&quot;),
    UserMessage(role='user', content=&quot;Hello, how are you?&quot;)
]

# Get response
response = client.chat(messages=messages)
print(response.messages[-1].content)"><pre><span>from</span> <span>rowboat</span> <span>import</span> <span>Client</span>, <span>StatefulChat</span>
<span>from</span> <span>rowboat</span>.<span>schema</span> <span>import</span> <span>UserMessage</span>, <span>SystemMessage</span>

<span># Initialize the client</span>
<span>client</span> <span>=</span> <span>Client</span>(
    <span>host</span><span>=</span><span>"http://localhost:3000"</span>,
    <span>project_id</span><span>=</span><span>"&lt;PROJECT_ID&gt;"</span>,
    <span>api_key</span><span>=</span><span>"&lt;API_KEY&gt;"</span>
)

<span># Create a stateful chat session (recommended)</span>
<span>chat</span> <span>=</span> <span>StatefulChat</span>(<span>client</span>)
<span>response</span> <span>=</span> <span>chat</span>.<span>run</span>(<span>"What's the weather in London?"</span>)
<span>print</span>(<span>response</span>)

<span># Or use the low-level client API</span>
<span>messages</span> <span>=</span> [
    <span>SystemMessage</span>(<span>role</span><span>=</span><span>'system'</span>, <span>content</span><span>=</span><span>"You are a helpful assistant"</span>),
    <span>UserMessage</span>(<span>role</span><span>=</span><span>'user'</span>, <span>content</span><span>=</span><span>"Hello, how are you?"</span>)
]

<span># Get response</span>
<span>response</span> <span>=</span> <span>client</span>.<span>chat</span>(<span>messages</span><span>=</span><span>messages</span>)
<span>print</span>(<span>response</span>.<span>messages</span>[<span>-</span><span>1</span>].<span>content</span>)</pre></div>
</li>
</ol>
<p dir="auto">Refer to <a href="https://docs.rowboatlabs.com/" rel="nofollow">Docs</a> to learn how to start building agents with Rowboat.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Morphik – Open-source RAG that understands PDF images, runs locally (170 pts)]]></title>
            <link>https://github.com/morphik-org/morphik-core</link>
            <guid>43763814</guid>
            <pubDate>Tue, 22 Apr 2025 16:18:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/morphik-org/morphik-core">https://github.com/morphik-org/morphik-core</a>, See on <a href="https://news.ycombinator.com/item?id=43763814">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/morphik-org/morphik-core/blob/main/assets/morphik_logo.png"><img alt="Morphik Logo" src="https://github.com/morphik-org/morphik-core/raw/main/assets/morphik_logo.png"></a>
</p>
<p dir="auto">
  <a href="http://makeapullrequest.com/" rel="nofollow"><img alt="PRs Welcome" src="https://camo.githubusercontent.com/3ceeb4c1fe10d0b3dae91b885b84eab5ac4c2fcd2bedd074977740d2ec833e96/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d736869656c6473" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=shields"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/edd81063d3a0381e47e639ce296ae283493de189db1b412b14e1430959413944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265"><img alt="GitHub commit activity" src="https://camo.githubusercontent.com/edd81063d3a0381e47e639ce296ae283493de189db1b412b14e1430959413944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265" data-canonical-src="https://img.shields.io/github/commit-activity/m/morphik-org/morphik-core"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3af2917bb9df9346f5c2321abee02d9d02dabcf450e095354c3030dfb40cf0b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265"><img alt="GitHub closed issues" src="https://camo.githubusercontent.com/3af2917bb9df9346f5c2321abee02d9d02dabcf450e095354c3030dfb40cf0b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265" data-canonical-src="https://img.shields.io/github/issues-closed/morphik-org/morphik-core"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9f3aa2be40465db6c4acfc39be5f427e3705b055b2bd737af277da7430bcd702/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d6f727068696b"><img alt="PyPI - Downloads" src="https://camo.githubusercontent.com/9f3aa2be40465db6c4acfc39be5f427e3705b055b2bd737af277da7430bcd702/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d6f727068696b" data-canonical-src="https://img.shields.io/pypi/dm/morphik"></a>
  <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow"><img alt="Discord" src="https://camo.githubusercontent.com/3863acac16ccb546452c8227bc440c26a19e45e59dbd7d436442f156e2be13d3/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313333363532343731323831373333323237363f6c6f676f3d646973636f7264266c6162656c3d646973636f7264" data-canonical-src="https://img.shields.io/discord/1336524712817332276?logo=discord&amp;label=discord"></a>
</p>


<p dir="auto">
  <a href="https://docs.morphik.ai/" rel="nofollow">Docs</a> - <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow">Community</a> - <a href="https://docs.morphik.ai/blogs/gpt-vs-morphik-multimodal" rel="nofollow">Why Morphik?</a> - <a href="https://github.com/morphik-org/morphik-core/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md">Bug reports</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Morphik is an alternative to traditional RAG for highly technical and visual documents.</h2><a id="user-content-morphik-is-an-alternative-to-traditional-rag-for-highly-technical-and-visual-documents" aria-label="Permalink: Morphik is an alternative to traditional RAG for highly technical and visual documents." href="#morphik-is-an-alternative-to-traditional-rag-for-highly-technical-and-visual-documents"></a></p>
<p dir="auto"><a href="https://morphik.ai/" rel="nofollow">Morphik</a> provides developers the tools to ingest, search (deep and shallow), transform, and manage unstructured and multimodal documents. Some of our features include:</p>
<ul dir="auto">
<li><a href="https://docs.morphik.ai/concepts/colpali" rel="nofollow">Multimodal Search</a>: We employ techniques such as ColPali to build search that actually <em>understands</em> the visual content of documents you provide. Search over images, PDFs, videos, and more with a single endpoint.</li>
<li><a href="https://docs.morphik.ai/concepts/knowledge-graphs" rel="nofollow">Knowledge Graphs</a>: Build knowledge graphs for domain-specific use cases in a single line of code. Use our battle-tested system prompts, or use your own.</li>
<li><a href="https://docs.morphik.ai/concepts/rules-processing" rel="nofollow">Fast and Scalable Metadata Extraction</a>: Extract metadata from documents - including bounding boxes, labeling, classification, and more.</li>
<li><a href="https://docs.morphik.ai/integrations" rel="nofollow">Integrations</a>: Integrate with existing tools and workflows. Including (but not limited to) Google Suite, Slack, and Confluence.</li>
<li><a href="https://docs.morphik.ai/python-sdk/create_cache" rel="nofollow">Cache-Augmented-Generation</a>: Create persistent KV-caches of your documents to speed up generation.</li>
</ul>
<p dir="auto">The best part? Morphik has a <a href="https://www.morphik.ai/pricing" rel="nofollow">free tier</a> and is open source! Get started by signing up at <a href="https://www.morphik.ai/signup" rel="nofollow">Morphik</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#getting-started-with-morphik-recommended">Getting Started with Morphik</a></li>
<li><a href="#self-hosting-the-open-source-version">Self-hosting the open-source version</a></li>
<li><a href="#using-morphik">Using Morphik</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#open-source-vs-paid">Open source vs paid</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started with Morphik (Recommended)</h2><a id="user-content-getting-started-with-morphik-recommended" aria-label="Permalink: Getting Started with Morphik (Recommended)" href="#getting-started-with-morphik-recommended"></a></p>
<p dir="auto">The fastest and easiest way to get started with Morphik is by signing up for free at <a href="https://www.morphik.ai/signup" rel="nofollow">Morphik</a>. Your first 200 pages and 100 queries are on us! After this, you can pay based on usage with discounted rates for heavier use.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Self-hosting the open-source version</h2><a id="user-content-self-hosting-the-open-source-version" aria-label="Permalink: Self-hosting the open-source version" href="#self-hosting-the-open-source-version"></a></p>
<p dir="auto">If you'd like to self-host Morphik, you can find the dedicated instruction <a href="https://docs.morphik.ai/getting-started" rel="nofollow">here</a>. We offer options for direct isntallation and installation via docker.</p>
<p dir="auto"><strong>Important</strong>: Due to limited resources, we cannot provide full support for open-source deployments. We have an installation guide, and a <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow">Discord community</a> to help, but we can't guarantee full support.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Morphik</h2><a id="user-content-using-morphik" aria-label="Permalink: Using Morphik" href="#using-morphik"></a></p>
<p dir="auto">Once you've signed up for Morphik, you can get started with ingesting and search your data right away.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code (Example: Python SDK)</h3><a id="user-content-code-example-python-sdk" aria-label="Permalink: Code (Example: Python SDK)" href="#code-example-python-sdk"></a></p>
<p dir="auto">For programmers, we offer a <a href="https://docs.morphik.ai/python-sdk/morphik" rel="nofollow">Python SDK</a> and a <a href="https://docs.morphik.ai/api-reference/health-check" rel="nofollow">REST API</a>. Ingesting a file is as simple as:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from morphik import Morphik

morphik = Morphik(&quot;<your-morphik-uri>&quot;)
morphik.ingest_file(&quot;path/to/your/super/complex/file.pdf&quot;)"><pre><span>from</span> <span>morphik</span> <span>import</span> <span>Morphik</span>

<span>morphik</span> <span>=</span> <span>Morphik</span>(<span>"&lt;your-morphik-uri&gt;"</span>)
<span>morphik</span>.<span>ingest_file</span>(<span>"path/to/your/super/complex/file.pdf"</span>)</pre></div>
<p dir="auto">Similarly, searching and querying your data is easy too:</p>
<div dir="auto" data-snippet-clipboard-copy-content="morphik.query(&quot;What's the height of screw 14-A in the chair assembly instructions?&quot;)"><pre><span>morphik</span>.<span>query</span>(<span>"What's the height of screw 14-A in the chair assembly instructions?"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Morphik Console</h3><a id="user-content-morphik-console" aria-label="Permalink: Morphik Console" href="#morphik-console"></a></p>
<p dir="auto">You can also interact with Morphik via the Morphik Console. This is a web-based interface that allows you to ingest, search, and query your data. You can upload files, connect to different data sources, and chat with your data all within the same place.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Model Context Protocol</h3><a id="user-content-model-context-protocol" aria-label="Permalink: Model Context Protocol" href="#model-context-protocol"></a></p>
<p dir="auto">Finally, you can also access Morphik via MCP. Instructions are available <a href="https://docs.morphik.ai/using-morphik/mcp" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You're welcome to contribute to the project! We love:</p>
<ul dir="auto">
<li>Bug reports via <a href="https://github.com/morphik-org/morphik-core/issues">GitHub issues</a></li>
<li>Feature requests via <a href="https://github.com/morphik-org/morphik-core/issues">GitHub issues</a></li>
<li>Pull requests</li>
</ul>
<p dir="auto">Currently, we're focused on improving speed, integrating with more tools, and finding the research papers that provide the most value to our users. If you ahve thoughts, let us know in the discord or in GitHub!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Open source vs paid</h2><a id="user-content-open-source-vs-paid" aria-label="Permalink: Open source vs paid" href="#open-source-vs-paid"></a></p>
<p dir="auto">Certain features - such as Morphik Console - are not available in the open-source version. Any feature in the <code>ee</code> namespace is not available in the open-source version and carries a different license. Any feature outside that is open source under the MIT expat license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto">Visit our special thanks page dedicated to our contributors <a href="https://docs.morphik.ai/special-thanks" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">PS</h2><a id="user-content-ps" aria-label="Permalink: PS" href="#ps"></a></p>
<p dir="auto">We took inspiration from <a href="https://posthog.com/" rel="nofollow">PostHog</a> while writing this README. If you're from PostHog, thank you ❤️</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ClickHouse gets lazier (and faster): Introducing lazy materialization (310 pts)]]></title>
            <link>https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</link>
            <guid>43763688</guid>
            <pubDate>Tue, 22 Apr 2025 16:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</a>, See on <a href="https://news.ycombinator.com/item?id=43763688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine if you could skip packing your bags for a trip because you find out at the airport you’re not going. That’s what ClickHouse is doing with data now.</p>
<p>ClickHouse is one of the fastest analytical databases available, and much of that speed comes from avoiding unnecessary work. The less data it scans and processes, the faster queries run. Now it pushes this idea even further with a new optimization: lazy materialization, which delays reading column data until it’s actually needed.</p>
<p>This seemingly "lazy" behavior turns out to be extremely effective in real-world workloads, especially for <code>Top N</code> queries that sort large datasets and apply <code>LIMIT</code> clauses, a common pattern in observability and general analytics. In these scenarios, lazy materialization can dramatically accelerate performance, often by orders of magnitude.</p>
<blockquote>
<p><strong>Spoiler alert</strong>: We’ll show you how a ClickHouse query went from 219 seconds to just 139 milliseconds—<strong>a 1,576× speedup</strong>—without changing a single line of SQL. Same query. Same table. Same machine. The only thing that changed? When ClickHouse reads the data.</p>
</blockquote>
<p>In this post, we’ll walk through how lazy materialization works and how it fits into ClickHouse’s broader I/O optimization stack. To give a complete picture, we’ll also briefly demonstrate the other key building blocks of I/O efficiency in ClickHouse, highlighting not just what lazy materialization does, but how it differs from and complements the techniques already in place.</p>
<p>We’ll begin by describing the core I/O-saving techniques ClickHouse already uses, then run a real-world query through them, layer by layer, until lazy materialization kicks in and changes everything.</p>

<p>Over the years, ClickHouse has introduced a series of layered optimizations to aggressively reduce I/O. These techniques form the foundation of its speed and efficiency:</p>
<ul>
<li>
<p><strong><a href="https://clickhouse.com/docs/parts">Columnar storage</a></strong> allows skipping entire columns that aren’t needed for a query and also enables high compression by grouping similar values together, minimizing I/O during data loading.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/primary-indexes">Sparse primary indexes</a></strong>, <strong><a href="https://clickhouse.com/docs/optimize/skipping-indexes">secondary data-skipping indexes</a></strong>, and <strong><a href="https://clickhouse.com/docs/data-modeling/projections">projections</a></strong> prune irrelevant data by identifying which <strong>granules</strong> (row blocks) might match filters on <em>indexed columns</em>. These techniques operate at the granule level and can be used individually or in combination.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a></strong> checks matches also for filters on <em>non-indexed</em> columns to skip data early that would otherwise be loaded and discarded. It can work independently or refine the granules selected by indexes, complementing granule pruning by skipping rows that don’t match <em>all</em> column filters.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/blog/introducing-the-clickhouse-query-condition-cache">The query condition cache (deep dive)</a></strong> speeds up repeated queries by remembering which granules matched all filters last time. ClickHouse can then skip reading and filtering granules that didn’t match, even if the query shape changes. Since it simply caches the result of index and PREWHERE filtering, we won’t cover it further here.  <strong>We disabled it in all tests below to avoid skewing results.</strong></p>
</li>
</ul>
<blockquote>
<p>These techniques, including the lazy materialization introduced below, reduce I/O <em>during</em> query processing, which is the focus of this post. An orthogonal approach is to reduce table size (and query work) upfront by precomputing results with <a href="https://clickhouse.com/docs/materialized-view/incremental-materialized-view">incremental</a> or <a href="https://clickhouse.com/docs/materialized-view/refreshable-materialized-view">refreshable</a> <strong>materialized views</strong>, which we won’t cover here.</p>
</blockquote>

<p>While the aforementioned I/O optimizations can significantly reduce data read, they still assume that all columns for rows passing the <code>WHERE</code> clause must be loaded before running operations like sorting, aggregation, or <code>LIMIT</code>. But what if some columns aren’t needed until later, or some data, despite passing the <code>WHERE</code> clause, is never needed at all?</p>
<p>That’s where <strong>lazy materialization</strong> comes in. An orthogonal enhancement that completes the I/O optimization stack:</p>
<ul>
<li>
<p>Indexing, together with PREWHERE, ensures that only rows matching column filters in the <code>WHERE</code> clause are processed.</p>
</li>
<li>
<p>Lazy materialization builds on this by deferring column reads until they’re actually required by the query execution plan. Even after filtering, only the columns needed for the next operation—such as sorting—are loaded immediately. Others are postponed and, due to <code>LIMIT</code>, are often read only partially, just enough to produce the final result. This makes lazy materialization especially powerful for <em>Top N</em> queries, where the final result may only require a handful of rows from certain, often large, columns.</p>
</li>
</ul>
<blockquote>
<p>This kind of fine-grained column processing is only possible because ClickHouse stores each column independently. In <a href="https://clickhouse.com/engineering-resources/what-is-columnar-database#row-based-vs-column-based">row-oriented</a> databases, where all columns are read together, this level of deferred I/O simply isn’t feasible.</p>
</blockquote>
<p>To demonstrate its impact, we’ll now walk through a real-world example and show how each layer of optimization plays a role.</p>

<p>We’ll use the <a href="https://clickhouse.com/docs/getting-started/example-datasets/amazon-reviews">Amazon customer reviews</a> dataset, which has around 150 million product reviews from 1995 to 2015.</p>
<p>
We’re running ClickHouse 25.4 on an AWS <code>m6i.8xlarge</code> EC2 instance with:<br>
• 32 vCPUs<br>
• 128 GiB RAM<br>
• 1 TiB gp3 SSD (with default settings: 3000 IOPS, 125 MiB/s max throughput 🐌)<br>
• Ubuntu Linux 24.04
</p>
<p>On that machine, we first created the Amazon reviews table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews
</span></span></span><span>(
<span></span></span><span><span>    `review_date` </span><span><span>Date</span><span> CODEC(ZSTD(</span><span>1</span><span>)),
</span></span></span><span><span>    `marketplace` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `customer_id` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_parent` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_title` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_category` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `star_rating` UInt8 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `helpful_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `total_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `vine` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `verified_purchase` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_headline` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_body` String CODEC(ZSTD(</span><span><span>1</span><span>))
</span></span></span><span>)
<span></span></span><span><span>ENGINE </span><span><span>=</span><span> MergeTree
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> (review_date, product_category);</span></span></span></code></pre></div></pre>
<p>And then loaded the dataset from Parquet files hosted in our public example datasets S3 bucket:</p>
<pre><div><pre><code><span><span>INSERT</span><span><span> </span><span>INTO</span><span>  amazon.amazon_reviews
</span></span></span><span><span></span><span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> s3Cluster(</span><span>'default'</span><span>, </span><span>'https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_*.snappy.parquet'</span><span>);</span></span></span></code></pre></div></pre>
<p>We check the table’s size after loading:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    formatReadableQuantity(</span><span><span>sum</span><span>(</span><span>rows</span><span>)) </span><span>AS</span><span> </span><span>rows</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.parts
</span></span></span><span><span></span><span><span>WHERE</span><span> active </span><span>AND</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─rows───────────┬─data_size─┬─compressed_size─┐
</span><span></span></span><span>│ 150.96 million │ 70.47 GiB │ 30.05 GiB       │
<span></span></span><span>└────────────────┴───────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>After loading, the table contains ~150 million rows and:</p>
<ul>
<li>70 GiB uncompressed data</li>
<li>~30 GiB compressed on disk using ZSTD(1)</li>
</ul>

<p>150 million rows is hardly a challenge for ClickHouse. For example, this query sorts all 150 million values in the <code>helpful_votes</code> column (which isn’t part of the table’s sort key) and returns the top 3, in just 70 milliseconds cold (with the OS filesystem cache <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cleared</a> beforehand) and a processing throughput of 2.15 billion rows/s:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> helpful_votes
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─helpful_votes─┐
</span><span></span></span><span>│         47524 │
<span></span></span><span>│         41393 │
<span></span></span><span>│         41278 │
<span></span></span><span>└───────────────┘
<span></span></span><span>
<span></span></span><span>3 rows in set. Elapsed: 0.070 sec. Processed 150.96 million rows, 603.83 MB (2.15 billion rows/s., 8.61 GB/s.)
<span></span></span><span>Peak memory usage: 3.59 MiB.<span></span></span></code></pre></div></pre>
<p>Note that the query doesn’t benefit from indexing, PREWHERE, or other I/O reduction techniques, since it has no filters. But thanks to columnar storage, ClickHouse only reads the <code>helpful_votes</code> column and skips the rest.</p>
<p>Here’s another example query that simply selects (with cold filesystem cache) all data from a single <code>review_body</code> column:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> review_body
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Query id: b9566386-047d-427c-a5ec-e90bee027b02
</span><span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 176.640 sec. Processed 150.96 million rows, 56.02 GB (854.61 thousand rows/s., 317.13 MB/s.)
<span></span></span><span>Peak memory usage: 733.14 MiB.<span></span></span></code></pre></div></pre>
<p>😱 Almost 3 minutes! Despite reading just a single column.</p>
<p>But the bottleneck wasn’t ClickHouse, it was the disk’s throughput. This query scanned a much larger column, 56 GB vs. 600 MB in the previous example. On our test machine, which has a <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#test-setup-dataset-and-machine">relatively slow disk</a> and 32 CPU cores, ClickHouse used 32 <a href="https://clickhouse.com/docs/optimize/query-parallelism">parallel streams</a> to read the data. The <a href="https://clickhouse.com/docs/operations/system-tables/query_log">query log</a> confirms that the majority of the 3-minute runtime was spent <a href="https://github.com/ClickHouse/ClickHouse/blob/9d60aa01a83346648eae5dc9572530388271f7b0/src/Common/ProfileEvents.cpp#L101">waiting on the read syscall</a>:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> 
</span></span></span><span><span>  round(ProfileEvents[</span><span><span>'DiskReadElapsedMicroseconds'</span><span>] </span><span>/</span><span> </span><span>1e6</span><span>) </span><span>AS</span><span> disk_read_seconds,
</span></span></span><span><span>  ProfileEvents[</span><span><span>'ConcurrencyControlSlotsAcquired'</span><span>] </span><span>AS</span><span> parallel_streams,
</span></span></span><span><span>  formatReadableTimeDelta(round(disk_read_seconds </span><span><span>/</span><span> parallel_streams), </span><span>'seconds'</span><span>) </span><span>AS</span><span> time_per_stream
</span></span></span><span><span></span><span><span>FROM</span><span> system.query_log
</span></span></span><span><span></span><span><span>WHERE</span><span> query_id </span><span>=</span><span> </span><span>'b9566386-047d-427c-a5ec-e90bee027b02'</span><span> 
</span></span></span><span><span>  </span><span><span>AND</span><span> type </span><span>=</span><span> </span><span>'QueryFinish'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─disk_read_seconds─┬─parallel_streams─┬─time_per_stream─┐
</span><span></span></span><span>│              5512 │               32 │ 172 seconds     │
<span></span></span><span>└───────────────────┴──────────────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>Clearly, brute-force scans aren’t ideal, especially with cold caches. Let’s give ClickHouse something to work with.</p>

<p>Despite the airport <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">drama</a>, I’m still set on that beach holiday, and that means loading my eReader with only the best. So I ask ClickHouse to help me find the most helpful 5-star verified reviews for digital ebook purchases since 2010, showing the number of helpful votes, book title, review headline, and the review itself:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical;<span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   6376
<span></span></span><span>product_title:   Wheat Belly: Lose the Wheat, Lose the Weight, and Find Your Path Back to Health
<span></span></span><span>review_headline: Overweight? Diabetic? Got High Blood Pressure, Arthritis? Get this Book!
<span></span></span><span>review_body:     I've been following Dr. Davis' heart scan blog for the past ...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   4149
<span></span></span><span>product_title:   The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing
<span></span></span><span>review_headline: Truly life changing
<span></span></span><span>review_body:     I rarely write reviews, but this book truly sparked somethin...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   2623
<span></span></span><span>product_title:   The Fast Metabolism Diet: Eat More Food and Lose More Weight
<span></span></span><span>review_headline: Fantastic Results **UPDATED 1/23/2015**
<span></span></span><span>review_body:     I have been on this program for 7 days so far.  I know it ma...<span></span></span></code></pre></div></pre>
<p>The query above selects four columns, including three (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) of the largest in the table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    name </span><span><span>as</span><span> </span><span>column</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.columns
</span></span></span><span><span></span><span><span>WHERE</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>
</span></span></span><span><span></span><span><span>GROUP</span><span> </span><span>BY</span><span> name
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>sum</span><span>(data_uncompressed_bytes) </span><span>DESC</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─column────────────┬─data_size──┬─compressed_size─┐
</span><span></span></span><span>│ review_body       │ 51.13 GiB  │ 21.60 GiB       │
<span></span></span><span>│ product_title     │ 8.12 GiB   │ 3.53 GiB        │
<span></span></span><span>│ review_headline   │ 3.38 GiB   │ 1.58 GiB        │
<span></span></span><span>│ review_id         │ 2.07 GiB   │ 1.35 GiB        │
<span></span></span><span>│ product_id        │ 1.55 GiB   │ 720.97 MiB      │
<span></span></span><span>│ customer_id       │ 1.12 GiB   │ 524.35 MiB      │
<span></span></span><span>│ product_parent    │ 1.12 GiB   │ 571.63 MiB      │
<span></span></span><span>│ helpful_votes     │ 575.86 MiB │ 72.11 MiB       │
<span></span></span><span>│ total_votes       │ 575.86 MiB │ 83.50 MiB       │
<span></span></span><span>│ review_date       │ 287.93 MiB │ 239.43 KiB      │
<span></span></span><span>│ marketplace       │ 144.51 MiB │ 414.92 KiB      │
<span></span></span><span>│ product_category  │ 144.25 MiB │ 838.96 KiB      │
<span></span></span><span>│ star_rating       │ 143.96 MiB │ 41.99 MiB       │
<span></span></span><span>│ verified_purchase │ 143.96 MiB │ 20.50 MiB       │
<span></span></span><span>│ vine              │ 1.75 MiB   │ 844.89 KiB      │
<span></span></span><span>└───────────────────┴────────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>The example query touches 60+ GiB of (uncompressed) data. As we showed earlier, even with 32 parallel streams, just reading that from the (relatively slow) disk would take 3+ minutes with a cold cache.</p>
<p>But the query includes filters on multiple columns (<code>review_date</code>, <code>product_category</code>, <code>verified_purchase</code>, and <code>star_rating</code>), plus a <code>LIMIT</code> applied after sorting by <code>helpful_votes</code>. This is the perfect setup for ClickHouse’s layered I/O optimizations:</p>
<ul>
<li>
<p><strong>Indexing</strong> prunes rows that don’t match filters on the primary/sorting key (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p><strong>PREWHERE</strong> pushes filtering deeper and prunes rows that don’t match <em>all</em> column filters.</p>
</li>
<li>
<p><strong>Lazy materialization</strong> delays loading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until they’re actually needed—after sorting and applying <code>LIMIT</code>. Ideally, most of that large column data is never read at all.</p>
</li>
</ul>
<p>Each layer cuts down I/O further. Together, they reduce data read, memory use, and query time. Let’s see how much of a difference that makes, one layer at a time.</p>

<p>In the following sections, we clear the OS-level filesystem (page) cache before each query run using</p>
<p><code>echo 3 | sudo tee /proc/sys/vm/drop_caches &gt;/dev/null</code>.</p>
<p>on the Linux command line. This simulates the worst-case scenario and ensures the results reflect actual disk reads, not cached data.</p>
<!-- -->

<p>Before we bring in the optimizations, let’s see what happens when ClickHouse runs the query without any shortcuts—no indexing, no PREWHERE, no lazy materialization.</p>
<p>To do this, we run the example query on a version of the table without a sorting/primary key, meaning it won’t benefit from any index-based optimizations. The following command creates that baseline table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span>Engine </span><span><span>=</span><span> MergeTree 
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> ()
</span></span></span><span><span></span><span><span>AS</span><span> </span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> amazon.amazon_reviews;</span></span></span></code></pre></div></pre>
<p>Now we run the example query, with both PREWHERE and lazy materialization disabled, on the baseline table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>3 rows in set. Elapsed: 219.508 sec. Processed 150.96 million rows, 72.13 GB (687.71 thousand rows/s., 328.60 MB/s.)
</span><span></span></span><span>Peak memory usage: 953.25 MiB.<span></span></span></code></pre></div></pre>
<p>The ① query streamed all 150 million rows—organized into <a href="https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#data-is-organized-into-granules-for-parallel-data-processing">granules</a> (the smallest processing units in ClickHouse, each covering 8,192 rows by default)—of ② the 8 required columns from disk to ③ memory, processing 72 GB of data in 220 seconds and peaking at 953 MiB of memory usage:</p>

<blockquote>
<p>ClickHouse processes table data in a <a href="https://clickhouse.com/docs/optimize/query-parallelism">streaming fashion</a>, reading and operating on blocks of granules incrementally instead of loading all data into memory at once. That’s why, even for the query above which processed 72 GB of data, peak memory usage stayed under 1 GiB.</p>
</blockquote>
<p>With the baseline set, let’s see how the first layer of optimization improves things.</p>

<p>Obviously, scanning the entire dataset is far from optimal. Let’s start applying ClickHouse’s optimizations, beginning with the primary index. We run the example query, still with both PREWHERE and lazy materialization disabled, on the original table, which uses <code>(review_date, product_category)</code> as its compound sorting (primary) key:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>   optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>   query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 95.865 sec. Processed 53.01 million rows, 27.67 GB (552.98 thousand rows/s., 288.68 MB/s.)
</span><span></span></span><span>Peak memory usage: 629.00 MiB.<span></span></span></code></pre></div></pre>
<p>Because the query includes ① filters on the table’s compound sorting (primary) key, ClickHouse ② loads and evaluates the <a href="https://clickhouse.com/docs/primary-indexes">sparse primary index</a> to ③ select only granules within the primary key columns that might contain matching rows. These potentially relevant granules are then ④ streamed into memory, along with positionally aligned granules from any other columns needed for the query. The remaining filters are applied after this step:</p>

<p>As a result, only 53 million rows from the eight required columns are streamed from disk to memory, processing 28 GB instead of 72 GB of data, and cutting runtime by more than half: 96 seconds vs. 220 seconds.</p>
<blockquote>
<p>The primary index prunes granules based on filters on the primary key columns.</p>
</blockquote>
<p>However, ClickHouse still loads all other column granules that are positionally aligned with the matching key column granules, even if filters on non-key columns exclude them later. That means unnecessary data is still being read and processed.</p>
<p>To fix that, we now enable PREWHERE.</p>

<p>We run the same query again, this time with <a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a> enabled (but still without lazy materialization). PREWHERE adds an additional layer of efficiency filtering out irrelevant data before reading non-filter columns from disk:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 61.148 sec. Processed 53.01 million rows, 16.28 GB (866.94 thousand rows/s., 266.24 MB/s.)
</span><span></span></span><span>Peak memory usage: 583.30 MiB.<span></span></span></code></pre></div></pre>
<p>With PREWHERE enabled, the query processed the same 53 million rows but read significantly less column data, 16.28 GB vs. 27.67 GB, and completed 36% faster (61 seconds vs. 96 seconds), while also slightly reducing peak memory usage.</p>
<p>To understand this improvement, let’s briefly walk through how PREWHERE changes the way ClickHouse processes the query.</p>
<p>Instead of streaming all selected column granules up front, ClickHouse begins PREWHERE processing by ① loading only the primary key column granules identified by the index analysis to check which ones actually contain matches. In this case, all selected granules do match, so ② the positionally aligned granules for the next filter column—<code>verified_purchase</code>—are selected to be loaded for further filtering:</p>

<p>Next, ClickHouse ① reads the selected <code>verified_purchase</code> column granules to evaluate the filter <code>verified_purchase</code> (which is a shortcut for <code>verified_purchase == True</code> ).</p>
<p>In this case, three out of four granules contain matching rows, so only ② their positionally aligned granules from the next filter column—<code>star_rating</code>—are selected for further processing:</p>

<p>Finally, ClickHouse reads the three selected granules from the <code>star_rating</code> column to evaluate the last filter <code>star_rating &gt; 4</code>.</p>
<p>Two of the three granules contain matching rows, so just the positionally aligned granules from the remaining columns—<code>helpful_votes</code>, <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code>—are selected to be loaded for further processing:</p>

<p>With that, PREWHERE processing is complete.</p>
<blockquote>
<p>Instead of loading all column granules selected by the primary index up front and then applying the remaining filters, PREWHERE pre-filters the selected data early—hence the name. ClickHouse evaluates filters one column at a time, using a <a href="https://clickhouse.com/docs/optimize/prewhere#prewhere-optimization-is-automatically-applied">cost-based approach</a>—typically starting with the cheapest column to read—and loads data only for rows that pass each step. This progressively narrows the dataset, reducing I/O before the query runs the main operations like sorting, aggregation, <code>LIMIT</code>, and <code>SELECT</code>.</p>
</blockquote>
<p>Note that PREWHERE can also work independently of indexing. If a query has only filters on non-indexed columns, it still helps reduce I/O by skipping non-matching rows early.</p>

<p>After PREWHERE filtering, ClickHouse proceeds to ① load the selected data, ② sort it, and ③ apply the LIMIT clause:</p>

<p>Each layer we’ve added so far has chipped away at the query time, skipping unnecessary data, reducing I/O, and streamlining the work.</p>
<p>From a full scan that took 220 seconds, we’re already down to 61 seconds. But we’re not done yet. One last layer brings the biggest reduction yet.</p>

<p>Let’s see what happens when lazy materialization joins the stack. We run the query one last time, with all I/O optimizations enabled, including lazy materialization.</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 0.181 sec. Processed 53.01 million rows, 807.55 MB (292.95 million rows/s., 4.46 GB/s.)
</span><span></span></span><span>Peak memory usage: 3.88 MiB.<span></span></span></code></pre></div></pre>
<p>😮 From 61 seconds to 181 milliseconds, a 338× speedup.</p>
<p>ClickHouse processed the same 53 million rows but read 20× less column data, used 150× less memory, and finished before you could blink.</p>
<p>Let’s look under the hood to see how that happened.</p>
<p>The explanation is simple:</p>
<p>After PREWHERE filtering, ClickHouse doesn’t load all remaining columns <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#steps-after-prewhere-filtering">right away</a>.</p>
<p>Instead, it loads only what’s needed next. Since the next step is sorting by <code>helpful_votes</code> and applying the LIMIT, ClickHouse ① loads just the selected (and PREWHERE-filtered) <code>helpful_votes</code> granules, ② sorts their rows, ③ applies the LIMIT, and only then ④ loads the corresponding rows from the <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#a-more-realistic-querywhere-optimizations-matter">large</a> <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code> columns:</p>

<p>And just like that, the final layer clicks into place, bringing execution time down from 220 seconds to just 181 milliseconds. Same query. Same table. Same machine. Same slow disk…just <strong>1,215× faster</strong>. All we changed was how and when data is read.</p>
<blockquote>
<p>In this example, lazy materialization delivers the biggest gain because the query selects large text columns, and thanks to lazy materialization, only 3 rows from them are needed in the end. But depending on the dataset and query shape, earlier optimizations like indexing or PREWHERE may yield greater savings. These techniques work together, each contributes to reducing I/O in a different way.</p>
</blockquote>
<p>Note: Lazy materialization is applied automatically for <code>LIMIT N</code> queries, but only up to a <code>N</code> threshold. This is controlled by the <a href="https://clickhouse.com/docs/operations/settings/settings#query_plan_max_limit_for_lazy_materialization">query_plan_max_limit_for_lazy_materialization</a> setting (default: 10). If set to 0, lazy materialization applies to all LIMIT values with no upper bound.</p>

<p>To benefit from indexing and PREWHERE, a query needs filters, on primary key columns for indexing, and on any columns for PREWHERE. As shown above, lazy materialization layers cleanly on top, but unlike the others, it can also speed up queries with no column filters at all.</p>
<p>To demonstrate this, we remove all filters from our example query to find the reviews with the highest number of helpful votes, regardless of date, product, rating, or verification status, returning the top 3 along with their title, headline, and full text.</p>
<p>We first run that query (with <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cold filesystem caches</a>) with lazy materialization disabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 219.071 sec. Processed 150.96 million rows, 71.38 GB (689.08 thousand rows/s., 325.81 MB/s.)
<span></span></span><span>Peak memory usage: 1.11 GiB.<span></span></span></code></pre></div></pre>
<p>Now we rerun the query (again with a cold filesystem cache), but this time with lazy materialization enabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 0.139 sec. Processed 150.96 million rows, 1.81 GB (1.09 billion rows/s., 13.06 GB/s.)
<span></span></span><span>Peak memory usage: 3.80 MiB.<span></span></span></code></pre></div></pre>
<p>Boom: a <strong>1,576× speedup</strong>—from 219 seconds to just 139 milliseconds—with 40× less data read and 300× lower memory usage.</p>
<p>This example highlights what makes lazy materialization unique among ClickHouse’s I/O optimizations.</p>
<blockquote>
<p>Lazy materialization doesn’t need column filters to deliver speedups. While indexing and PREWHERE rely on query predicates to skip data, lazy materialization improves performance purely by deferring work, loading only what’s needed, when it’s needed.</p>
</blockquote>

<p>We can observe the lazy materialization for the previous query by inspecting the query’s logical execution plan using the <a href="https://clickhouse.com/docs/sql-reference/statements/explain#explain-plan">EXPLAIN</a> clause:</p>
<pre><div><pre><code><span><span>EXPLAIN actions </span><span><span>=</span><span> </span><span>1</span><span>
</span></span></span><span><span></span><span><span>SELECT</span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>...
</span><span></span></span><span>Lazily read columns: review_headline, review_body, product_title 
<span></span></span><span>  Limit                    
<span></span></span><span>    Sorting                             
<span></span></span><span>      ReadFromMergeTree<span></span></span></code></pre></div></pre>
<p>We can read the operator plan from bottom to top and observe that ClickHouse defers reading the three large String columns until after sorting and limiting.</p>

<p>This journey began with a full-table scan: 220 seconds, 72 GB read, and 1 GiB memory used. Through ClickHouse’s layered I/O optimizations, we chipped away at runtime, one technique at a time:</p>
<ul>
<li>
<p>① The <strong>primary index</strong> pruned granules that didn’t match filters on indexed columns (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p>②  <strong>PREWHERE</strong> filtered out granules early that passed the index but failed filters on non-indexed columns (<code>verified_purchase</code>, <code>star_rating</code>), reducing unnecessary reads.</p>
</li>
<li>
<p>③  <strong>Lazy materialization</strong> deferred reading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until after sorting by <code>helpful_votes</code> and applying <code>LIMIT</code>.</p>
</li>
</ul>

<p>Each layer helped, but for our dataset and query shape lazy materialization changed the game.</p>
<p>The result?</p>
<ul>
<li>From 220s → 0.18s = <strong>over 1,200× speedup</strong> on the filtered query</li>
<li>From 219s → 0.139s = <strong>over 1,500× speedup</strong> on a full-table Top N query</li>
</ul>
<p><strong>Same table. Same machine. Same SQL code.</strong> The only thing we changed? How and <em>when</em> ClickHouse reads the data.</p>
<p>Lazy materialization doesn’t just make ClickHouse faster, it completes the I/O optimization stack.
And the laziest part? It (and PREWHERE) are on by default. You get the speed without lifting a finger.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Algebraic Semantics for Machine Knitting (225 pts)]]></title>
            <link>https://uwplse.org/2025/03/31/Algebraic-Knitting.html</link>
            <guid>43763614</guid>
            <pubDate>Tue, 22 Apr 2025 15:55:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uwplse.org/2025/03/31/Algebraic-Knitting.html">https://uwplse.org/2025/03/31/Algebraic-Knitting.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As programming languages researchers, we’re entitled to a certain level of mathematical
rigor behind the languages we write and analyze. Programming languages have <em>semantics</em>, which are
definitions of what statements in the language mean. We can use those semantics to do all
sorts of useful things, like error checking, compiling for efficiency, code transformation,
and so on.</p>

<p>This blog post is about a programming domain that doesn’t yet enjoy the same level of rigor
in its semantics: machine knitting. People write programs to control massive arrays of needles
that manipulate yarn into useful 3D objects. In this blog post, I’ll run through the process
of finding “the right” semantics for machine knitting, touching on why we want semantics, connections
to traditional programming languages, and what we might use these semantics for in the future.
In our search, there are a surprising number of guest appearances by fields of study outside of programming languages:
algebraic topology, group theory, knot theory, category theory, and even quantum computing!</p>

<p>I’ll motivate semantics with a toy problem: can two given statements commute with each other?
Here’s an example where they can:</p>

<p>By “commute”, I mean that if I swapped the order of the lines, the program would do the same
thing. The commuting problem is important: a compiler might move around the order of instructions
to optimize memory usage by batching related instructions together, an analyzer might want
to see if two programs are equivalent, and we might also want to know whether we can run two instructions
in parallel. In the above example, we know that the statements commute because of the implied <em>semantics</em>
of the statements – they don’t have anything in common, so they shouldn’t affect each other!</p>

<p>Here are some more examples. These statements don’t commute because there’s a data dependency:</p>

<p>If we swapped those two statements, the statement assigning <code>x</code>’s value would use a potentially different
value for <code>y</code>.</p>

<p>Non-commuting statements might happen for reasons other than direct data dependencies. Imagine
we’re in C – do these function calls commute?</p>
<div><pre><code><span>x</span> <span>=</span> <span>f</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
<span>y</span> <span>=</span> <span>f</span><span>(</span><span>c</span><span>,</span> <span>d</span><span>);</span>
</code></pre></div>
<p>We can’t be sure that they do – perhaps the <code>f</code> function mutates some counter variable
every time it’s called.</p>

<p>Apart from explicit mutable state, there’s one more C-like thing that commonly prevents commuting:</p>
<div><pre><code><span>*</span><span>x</span> <span>=</span> <span>*</span><span>x</span> <span>+</span> <span>3</span><span>;</span>
<span>*</span><span>y</span> <span>=</span> <span>*</span><span>y</span> <span>*</span> <span>2</span><span>;</span>
</code></pre></div>
<p>If the <code>x</code> and <code>y</code> pointers are the same, these statements don’t commute.</p>

<p>It’s notable that in a <em>pure</em> language, there’s no hidden mutable state or pointer
aliasing. Haskell is a popular language that’s very close to being pure – since
it supports IO operations like printing to the console and reading/writing files, it’s
not pure. In Haskell, these functions <em>do</em> commute, as long as there’s no IO monad malarkey:</p>


<p>The reason that Haskell’s commuting result is different than C is that its semantics are different – any time we want to
prove a property of a language’s behavior, we’ll have to turn to that language’s semantics. We know that proving properties
of machine knitting programs could be a powerful tool: <a href="https://doi.org/10.1145/3654777.3676405">a 2024 paper</a> showed massive
speedups using an optimizing compiler, using only a few program transformations that are <em>intuitively</em> correct. To scale that
result and prove the compiler’s accuracy, we’ll need to develop semantics for machine knitting.</p>

<h2 id="machine-knitting-background">Machine knitting background</h2>

<p>This introduction is only for the details of machine knitting that are relevant
to this blog post. Unfortunately, the mechanisms behind a machine that automatically
creates useful objects from spools of yarn are pretty complicated! If you’d like to read
more about machine knitting, <a href="https://doi.org/10.1145/3592449">this paper</a> has a good
introduction.</p>

<p>Knitting machines have an array of hundreds of needles, called a bed. This is analogous
to the memory of a traditional computer – registers hold values, and needles hold loops
of yarn. There are also <em>carrier strands</em> that move throughout the machine, winding through,
around, and past the loops of needles to create <em>stitches</em>, which I’ll later compare to basic operations
in traditional programming languages. Here’s how a basic stitch is formed in knitting:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_pre.svg" alt="A cyan carrier strand to the left of a loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_no_box.svg" alt="The carrier strand has been pulled through the loop, creating a new cyan loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_post.svg" alt="A box has been drawn around part of the previous image; the stitch takes a cyan carrier strand and gold loop
  in and returns a cyan loop and a cyan carrier strand">
</p>

<p>A carrier strand (in cyan) is pulled through a loop (in gold) to create a new loop.
Note how the bottom gold loop is held in place as long as the top cyan loop and carrier strand
are held up. After the stitch, the knitting machine drops the bottom loop, but the bottom
loop stays connected and stable. This is like a value falling out of scope, but since some in-scope
value points to it, it’s not garbage-collected (gravity is the garbage collector of machine knitting!).</p>

<p>There are many variants of stitches, but they all follow the same
input-output pattern: loops and carrier strands in, loops and carrier strands 
out. In that way, they’re kind of like basic operations we’re used to in computer science,
like addition or bitwise AND: values in, values out. The third image above draws a box around the
stitch to show its inputs and outputs: carrier strand and loop in, loop and carrier strand out.</p>

<p>There’s one more technicality in machine knitting: in order to do a stitch
involving some values, those values must be all adjacent to each other.
In the example below, we can’t immediately knit the cyan carrier on the far left with
the gold loop on the far right – instead, 
we have to move
the values next to each other before creating a stitch.</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_pre.svg" alt="A cyan carrier strand, red loop, and gold loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_post.svg" alt="The cyan carrier strand crosses over the red loop, and makes a stitch with the gold loop">
</p>

<p>This is also true for traditional computing – to compute the
boolean AND of two bits, we need to connect those two bits to an AND gate,
getting them right next to each other. Computer architects use complicated
routing mechanisms like multiplexers to do this; when we code in traditional
programming languages, we don’t have to worry about those constraints
because the computer architects have generously handled it for us.</p>

<p>The languages used for machine knitting don’t include many of the traditional
programming language features that make code hard to analyze: no <code>if</code>
statements (branching) or <code>for</code> loops, and no functions. Machine
knitting code is just a series of operations that perform stitches and
move carrier strands and loops around. This should make analyzing machine knitting
easier: there’s far less complexity than traditional programming languages.
In fact, for our specific question of whether two operations commute, the
problem seems almost trivial: similar to pure functional programming
languages, there’s no global state or aliasing in
machine knitting. However, there’s something tricky hiding in
machine knitting that isn’t a worry in traditional computing contexts:
since knitting is done in 3 dimensions, when strands cross, one goes over and
the other goes under. This can cause operations to snag on each other, even if
no strand directly connects them. I’ll illustrate this with some diagrams.</p>

<h2 id="diagrams">Diagrams</h2>

<p>Let’s start by carefully analyzing something core to traditional computing:
combinatorial boolean circuits. Here’s a simple example <code>myfunc</code> that maps
3 bits to 3 bits.</p>
<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span> <span>// split the wire in two</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>It’s usually easier to reason about circuits when they’re drawn (forgive my very strange choices when drawing
the diagram; all will be clear once we get to knitting):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_pre.svg" alt="Circuit diagram for the above code">
</p>

<p>I pose the same question: can the
<code>dup</code> and <code>and</code> operations commute? Here, the answer is a definite yes:
global state and aliasing aren’t present, and there’s no data dependency.
Here is the same function with the operations commuted:</p>

<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_post.svg" alt="Circuit diagram for the above code">
</p>

<p>Deciding whether two operations commute in a combinatorial circuit is easy
– they can commute if and only if there’s no directed path connecting them,
just like how two functions can commute in Haskell as long as there’s no data
dependency between them and no IO trickery.</p>

<h3 id="knitting-diagrams">Knitting diagrams</h3>

<p>Now, let’s try something similar for knitting. For simplicity, we’ll work in a
made-up machine knitting language that hides some of the technicalities
that aren’t important for this post. Our knitting function takes three strands as input,
does two stitches, and returns three new strands. I’ve taken the liberty to
simplify the diagrams by not drawing
the “internals” of the stitches (now they’re just boxes)
and I’m drawing both loops and carrier strands as single strands.</p>
<div><pre><code><span>fn</span> <span>myknit</span><span>(</span><span>s1</span><span>,</span> <span>s2</span><span>,</span> <span>s3</span><span>)</span> <span>{</span>
    <span>t1</span><span>,</span> <span>t2</span> <span>=</span> <span>stitch1</span><span>(</span><span>s2</span><span>);</span>
    <span>cross</span> <span>t1</span> <span>over</span> <span>s1</span><span>;</span>
    <span>cross</span> <span>s3</span> <span>over</span> <span>t2</span><span>;</span>
    <span>cross</span> <span>s1</span> <span>over</span> <span>s3</span><span>;</span>
    <span>t3</span> <span>=</span> <span>stitch2</span><span>(</span><span>s3</span><span>,</span> <span>s1</span><span>);</span>
    <span>cross</span> <span>t2</span> <span>over</span> <span>t3</span><span>;</span>

    <span>return</span> <span>t1</span><span>,</span> <span>t2</span><span>,</span> <span>t3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_knit.svg" alt="Diagram for the above knitting code. The stitch1 and stitch2 boxes aren't directly connected by a
  strand, but due to the way the strands have crossed, there is no way to move stitch2 below stitch1">
</p>

<p>Well, the diagram looks almost the same as the circuit diagram, but now every time two
strands cross, we have to specify which one goes on top of the other. This is extra noticeable
in the code: all crossings between strands are listed and annotated. We’re careful to record and
display these over/under crossings in machine knitting because they’re a feature of working in
a physical medium: the way strands cross affects how a knitted object looks and feels, and it can
drastically change the shape of the final object!</p>

<p>These over/under crossings are what make the commuting problem difficult for machine knitting.
In the above example, there’s no data dependency (i.e., no connecting strand) between the two
operations. However, because of how their strands are crossing, the operations “snag” on each other
so they can’t commute. It’s perhaps easy for humans to look at the above diagram and decide whether
two operations snag on each other, but how can we author an accurate algorithm to
apply automated analysis to these affairs? We need some way of formalizing these ideas so a computer
can reason about them… ah yes, those semantics we mentioned earlier.</p>

<p>Now is a good time to mention that there actually ARE semantics for machine knitting:
<a href="https://doi.org/10.1145/3592449">a 2023 paper</a> set up rigorous mathematical semantics for all of machine
knitting. However, these semantics are defined in <em>tangles</em> from knot theory. This is a natural way to
define knitted objects – they really are a tangle of strands in 3D space! However, the equivalences of
knot theory are defined by continuous deformations – two knots are equivalent whenever we can stretch, move,
expand, and contract one knot into the other without tearing strands. Since the goal is to write computer
programs that analyze machine knitting, the proposed semantics aren’t directly useful to computers. Computers don’t have
any notion of what a “continuous deformation” is, and they’re particularly bad at doing anything involving
continuous quantities. The semantics are useful for humans to do basic hand-written proofs and are a great
starting point, but we’d like to extend them so we can use computers to perform automatic analysis.</p>

<h3 id="aside-quantum-computing">Aside: quantum computing</h3>

<p>It should be noted that if we actually constructed the combinatorial circuit from earlier by
plugging wires into tangible logic gates, we would also have to make some decision for each
crossing as to which wire goes on top. However, this is simply not a concern for computer scientists:
it doesn’t matter which wire goes on top, because electrons don’t care whether they go above or below
other electrons – it doesn’t change the resulting computation.</p>

<p>Models in quantum physics allow for particles that <em>do</em> remember how they pass over
and under each other. This could have big effects in quantum computing, where a so-called topological
quantum computer using these particles could be far more resistant to decoherence than
conventional quantum computing. A team at Microsoft has
<a href="https://doi.org/10.1038/s41586-024-08445-2">recently published some experimental results in topological quantum computing</a>
using a setup to braid quasiparticles together in 2+1 dimensions
of space and time respectively. The methods, setup, and goals are certainly different than machine
knitting, but it’s quite satisfying to see the two seemingly unrelated topics of machine knitting and
quantum computing bound by similar mathematical ideas.</p>

<h2 id="algebraicizing-our-topology">Algebraicizing our topology</h2>

<p>As I hinted earlier, we’d like to formalize the previous diagrams so we can study their properties, using
something more computer-friendly than knot theory. Really, this is an exercise in algebraic topology –
representing a topology (like our deformations of 3D space) with algebra, which is a lot easier to work
with. The <em>braid group</em> is a great starter example of how mathematicians represent a topological object
with algebra.</p>

<h3 id="the-braid-group">The braid group</h3>

<p>For folks familiar with group theory, the braid group on \(n\) strands is</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2,\) and it represents the equivalence classes of \(n\) strands under ambient isotopy.
For the folks confused by this deluge of notation, read on!</p>

<p>A group is a set of elements \(G = \{x_1, x_2, \ldots \}\) with</p>

<ol>
  <li>Some way to <em>combine</em> or <em>compose</em> elements together, which I’ll represent
using a semicolon. For any \(x, y \in G,\) we have \(x ; y \in G.\)</li>
  <li>Some identity element that represents “nothing”. We’ll call that element
\(\text{id}\in G,\) and it has the property \(\text{id} ; x = x = x ; \text{id}.\)</li>
  <li>Some way to <em>invert</em> elements: for any \(x \in G,\) there’s some \(x^{-1} \in G\)
where \(x;x^{-1} = \text{id} = x^{-1} ; x.\)</li>
</ol>

<p>One group we’re all familiar with is the integers under addition: the composition of integers is
addition, the identity is \(0,\) and inverting is negation.</p>

<p>For any natural number \(n\) (let’s say \(n=5\)), the <em>braid group on \(n\) strands</em> is one of
these groups. There are infinite elements in that group, and every element is 5 strands,
oriented bottom-to-top, passing over/under each other. It’s good to think of braids as
nailed or glued down at either end, and two braids are <em>equivalent</em> whenever one can be transformed
into the other by shifting around strands, keeping the nailed-down ends fixed.
Here are two examples of braids on 5 strands; I’ll call the left one \(x\) and the right one \(y\):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-2.svg" alt="Braid y = sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>Next, we’ll define what composition, the identity, and inverses are:</p>

<p>Composition is vertical concatenation, read bottom to top. So \(x ; y\) is \(x\) pasted
below \(y,\) with the strands connected in order:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>The identity in the braid group is just \(n\) strands going straight:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/ident-5.svg" alt="5 vertical strands, none of them crossing">
</p>

<p>With the definition of composition being vertical concatenation, hopefully we can agree that
pasting on the identity at either end doesn’t really change anything, so that braid is indeed the identity.
Finally, inverses are mirror images about the horizontal line through the middle of the braid – below is \(x\) on the left and
\(x^{-1}\) on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv.svg" alt="Braid x^{-1} = sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>When we compose \(x ; x^{-1},\) we get a braid that untangles to be the identity:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>This is all well and good, but we need some way to write braids down so computers can use them.
We’ll do this by listing their crossings in order, from bottom to top. We’ll use \(\sigma_i\) to
refer to the \(i\)th strand from the left crossing over the \((i+1)\)th strand, and \(\sigma_i^{-1}\)
for under. Then we can write the braid \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_1 ; \sigma_3^{-1}.\)</p>

<p>There’s one more complication: there’s more than one way to write down braids. For example, we could
write \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_3^{-1} ; \sigma_1\) instead – here’s the original \(x\)
diagram on the left and the new one on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-syn.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_3^{-1} ; sigma_1 in B_5">
</p>

<p>This diagram of \(x\) and the original are equivalent – by shifting the crossings up/down, we transform
one into the other. So the braid group has extra relations to account for this:
\(\sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}\) and \(\sigma_i ; \sigma_j = \sigma_j ; \sigma_i.\)
Here are those relations drawn out, with the left and right sides being equal in each row:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-1.svg" alt="A red strand passes over a cyan and green strand, then the cyan passes over the green">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-2.svg" alt="Cyan passes over green, then red passes over green and cyan">
</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-1.svg" alt="Red over cyan, then green over purple">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-2.svg" alt="Green over purple, then red over cyan">
</p>

<p>Physics note: the first equation is called the <a href="https://en.wikipedia.org/wiki/Yang%E2%80%93Baxter_equation">Yang-Baxter equation</a>, and
it appears in many more places than just the braid group!</p>

<p>It should be noted that the relation \(\sigma_i ; \sigma_i^{-1} = \text{id}\) is implicit in all groups:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-1.svg" alt="A red strand passes over a cyan strand, then over the cyan strand from the other side">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-2.svg" alt="The red and cyan strands don't cross">
</p>

<p>Now, we should all be on the same page for the braid group: the notation</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2\)
tells us how to write braids down (with \(\sigma_1, \ldots, \sigma_{n-1}\)) and which words mean the same thing.</p>

<p>The braid group is well-studied and comes with some powerful algorithms. The presentation is canonicalizable in polynomial time,
meaning there are algorithms that we can run to efficiently tell whether two braids written down using \(\sigma_i\) are
equivalent. This is a great sign for our goal of computable semantics for machine knitting – mathematicians have taken a topological object
with a lot of the structure we want in machine knitting, boiled it down to something computer-friendly, and even authored
some useful algorithms! However, the braid group can only represent the pieces of machine knitting programs without stitches.
Stitches operate like functions on strands, with input and output strands. The count of inputs can be different
than the count of outputs, changing the count of strands as we perform the stitch. The braid group is limited to some fixed \(n\) strands, so it can’t represent
stitches. To get the complete picture of machine knitting, we’ll need to generalize our mathematical assumptions to include the boxes
that represent stitches.</p>

<h3 id="monoidal-categories-and-their-diagrams">Monoidal categories and their diagrams</h3>

<p>In programming languages research, category theory is best known for research in type theory.
I’ve spent all my math allowance for this blog post explaining the braid group so I won’t get into the nitty-gritty
of what categories are – in short, it’s an algebraic object, like a group, but more general: composition
doesn’t always have to be defined, and inverses don’t always have to exist.</p>

<p>Of particular note are the ideas of <a href="https://ncatlab.org/nlab/show/internal+logic">internal logics</a> and internal languages
of categories: correspondences between a category, some logic, and some theoretical programming language model. The
<a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard correspondence</a> describes the connection
between logic and programming languages, and these ideas add category theory to the party.</p>

<p>One such correspondence lies between <em>linear logic</em>, where values can only be used and must be used once, and
<em>symmetric monoidal categories</em>. All categories have composition, which I’m interpreting as vertical concatenation like in the braid
group; monoidal categories additionally have horizontal concatenation (like multiple values in scope, running two circuits in sequence,
or an array of needles holding loops). Symmetric monoidal categories
can be drawn as boxes connected by strands where the over/under-ness of
strand crossings isn’t recorded or drawn: exactly the diagrams we draw for combinatorial circuits! The symmetric
monoidal category gives notation and axioms for us to rigorously study those circuits, just like the braid group
gives notation and axioms for studying braids. <em>Symmetric</em> monoidal category is a great name because it’s closely
related to the symmetric group.</p>

<p>Following the same idea, <em>braided monoidal categories</em> generalize symmetric monoidal categories by recording
over/under crossings, and we draw our diagrams as such – just like our diagram for machine knitting!
Back in 1991 when braided monoidal categories were still young,
<a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street</a> showed that the axioms of braided monoidal categories
correspond with the topology of the diagrams we use for them. Since our diagrams really do represent physical topological
objects, this means that braided monoidal categories are perfect for machine knitting!</p>

<h2 id="actually-using-these-semantics">Actually using these semantics</h2>
<p>Now that we’ve identified an algebraic structure for machine knitting, we’d like to use that formalism to perform useful
analysis of machine knitting programs. One immediate goal is program equivalence: given two machine knitting programs, will
they produce the same object up to topological equivalence? We can reduce those programs to their braided monoidal category
representations and work with those. This is closely related to the braid group’s canonicalization I mentioned earlier – can we
extend that to the braided monoidal category? I’ve developed an algorithm that does just that in polynomial time, but it’s
too complicated to fit in a blog post. To borrow some language from Fermat, I’ve
<a href="https://en.wikipedia.org/wiki/Fermat's_Last_Theorem#Fermat's_conjecture">discovered a truly marvelous algorithm and proof of correctness, which this blog post’s margin is too narrow to contain</a>.
The algorithm works by using some new ideas to canonicalize the positions and order of stitches, and then uses the braid group canonicalization to canonicalize
the crossings between stitches.</p>

<p>We could use the canonicalization algorithm to compile and optimize machine knitting programs. Normal forms are important to compilers because they can greatly
simplify the language to be compiled – a canonical form builds on that by additionally providing a uniqueness guarantee. The axioms of braided monoidal categories
lay out exactly all the program transformations we should consider. Finally, I also have an interest in developing a user-facing programming language for machine knitting
that’s closer to the abstraction provided by category theory. The current machine knitting languages are closely tied to controlling knitting machines, so they require
the user to specify which needles on the machine hold strands (like how assembly requires users to specify which registers use values). On top of usability, a new programming
language might also come with features for performance, fabrication reliability, or modularity of programs.</p>

<p>Big thanks to my advisors at UW, Gilbert Bernstein and Adriana Schulz, for being flexible as a first-year PhD student learns category
theory and topology through the lens of machine knitting. This work is in part a collaboration with folks currently and previously at CMU,
including <a href="https://jlin98.github.io/">Jenny Lin</a>, <a href="https://t0mpr1c3.github.io/">Tom Price</a>, <a href="https://www.cs.cmu.edu/~jmccann/">Jim McCann</a>,
and <a href="https://www.cmu.edu/dietrich/philosophy/people/phd/hannah-fechtner.html">Hannah Fechtner</a>.</p>

<h2 id="further-reading">Further reading</h2>

<ol>
  <li><a href="https://doi.org/10.1145/3654777.3676405">KODA, the optimizing knitting compiler</a></li>
  <li><a href="https://doi.org/10.1145/3592449">Topological machine knitting semantics</a></li>
  <li><a href="https://doi.org/10.1038/s41586-024-08445-2">Microsoft’s experimental progress in topological quantum computing</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Braid_group">Wikipedia article for the braid group</a></li>
  <li><a href="https://ncatlab.org/nlab/show/internal+logic">nLab’s page on internal logics</a></li>
  <li><a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street’s paper connecting category theory diagrams and topology</a></li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hyperwood – Open-Source Furniture (102 pts)]]></title>
            <link>https://hyperwood.org/</link>
            <guid>43763565</guid>
            <pubDate>Tue, 22 Apr 2025 15:50:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hyperwood.org/">https://hyperwood.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43763565">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <h2>Dive Deeper into Hyperwood</h2>

    <h3>Strength Through Lamination</h3>
    <p>Hyperwood's layered slat construction creates furniture that is stable, strong, and resistant to warping—similar to engineered glue-laminated timber used in building construction.</p>

    <h3>Inspired by <cite>Small is Beautiful</cite></h3>
    <p>Drawing directly from Schumacher’s philosophy, Hyperwood emphasizes sustainability, local resilience, and empowering individuals through simple, approachable technology.</p>

    <h3>Open Source Heritage (<cite>Autoprogettazione</cite>)</h3>
    <p>Like Enzo Mari’s visionary project, Hyperwood democratizes furniture-making. It encourages hands-on building, fosters design literacy, and invites collaborative innovation.</p>
  </article><article>
    <h2>Hyperwood Exchange Format (HEF)</h2>
    <p>Inspired by the <a href="https://getqubicle.com/qubicle/documentation/docs/file/qef/">Qubicle Exchange Format</a>, the Hyperwood Exchange Format (HEF) is the dedicated file structure for the Hyperwood ecosystem. While the Qubicle format is voxel-based, HEF uses lines as its primitives, reflecting the structural essence of Hyperwood’s slat-based construction. HEF facilitates seamless data exchange between various software and applications, functioning as a standardized protocol for Hyperwood.</p>

    <h3>Data Structure</h3>
    <p>HEF files are divided into 3 parts: the header, the part map and the slats data.</p>

    <h4>Header</h4>
    <p>The first part of the header always looks like this:</p>
    <pre>Hyperwood Exchange Format
Version 1
https://hyperwood.org</pre>

    <p>It doesn’t hold any valuable information. Use it to test whether this file is
    really a HEF, or simply skip it.</p>

    <p>Now a line follows describing the name of the model:</p>
    <pre>Bench</pre>

    <p>The next line contains the parameters the model has been generated from, as JSON:</p>
    <pre>{"width":17,"depth":9,"height":7}</pre>

    <p>Then, the slat variant is included, as JSON:</p>
    <pre>{"x":0.06,"y":0.04,"z":0.06}</pre>

    <p>And the properties, calculated during model generation:</p>
    <pre>{"width":1.02,"depth":0.35999998,"height":0.42}</pre>

    <h4>Part Map</h4>
    <p>HEF uses an indexed part map that contains all part names used in the following
    slats data. The first line tells you how many parts are in the parts map.</p>

    <pre>4</pre>

    <p>The following lines store the individual part names (in this case 3). Names
    must not be longer than 32 characters.</p>

    <pre>Shelf
Seat
Keel
Leg</pre>

    <h4>Lath Data</h4>

    <p>The rest of the file stores all slats, one slat per line.</p>

    <pre>3 4 1 11 0 0 4 2
0 0 7 17 0 0 0 1
...
14 7 0 0 0 7 7 3</pre>

    <ul>
      <li>the first 3 values of each line are the slats’s position in X:Y:Z</li>
      <li>the next 3 values is the slats vector, it's length in each dimension</li>
      <li>the second last value is the layer number</li>
      <li>the very last value is the part index of the partmap (starting with 0)</li>
    </ul>

    <h3>Complete Example</h3>
  <pre>Hyperwood Exchange Format
Version 1
hyperwood.org
Bench
{"width":17,"depth":9,"height":7}
{"x":0.06,"y":0.04,"z":0.06}
{"width":1.02,"depth":0.35999998,"height":0.42}
4
Shelf
Seat
Keel
Leg
3 4 1 11 0 0 4 2
0 0 7 17 0 0 0 1
0 2 7 17 0 0 2 1
0 4 7 17 0 0 4 1
0 6 7 17 0 0 6 1
0 8 7 17 0 0 8 1
2 2 2 13 0 0 2 0
2 4 2 13 0 0 4 0
2 6 2 13 0 0 6 0
3 1 0 0 0 7 1 3
14 1 0 0 0 7 1 3
3 3 1 0 0 6 3 3
14 3 1 0 0 6 3 3
3 5 1 0 0 6 5 3
14 5 1 0 0 6 5 3
3 7 0 0 0 7 7 3
14 7 0 0 0 7 7 3</pre>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Supabase raises $200M Series D at $2B valuation (314 pts)]]></title>
            <link>https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</link>
            <guid>43763225</guid>
            <pubDate>Tue, 22 Apr 2025 15:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html">https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><!-- HTML_TAG_START -->Paul Copplestone didn’t think things like this actually happened.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Then one day Accel’s Gonzalo Mocorrea asked for his New Zealand address—more than 7,000 miles from Silicon Valley.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Mocorrea “literally showed up on my doorstep in Wānaka, which is really not easy to get to,” said Copplestone, the CEO and cofounder of open source application development platform Supabase. “For the next two days, he’d pop in and we’d chat for a couple hours.”<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->After a few days in Wānaka—located on New Zealand's South Island and famous for its snow capped mountains overlooking a massive mirror of a lake—Accel’s Mocorrea called in backup, texting partner Arun Mathew.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“Arun said ‘alright, I’m coming,’” said Copplestone. “And I said, ‘Oh no, don’t come! We haven’t agreed to anything!’ But yeah, he came, we had dinner in Queenstown, another beautiful place. We caught up the next morning, and they offered a term sheet.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Accel’s Mathew had traveled more than 24 hours, across two flights and multiple car rides, to make the trip as the firm weighed its first investment in Supabase.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“I needed to sit across the table, look him in the eye, and really believe he’s going to do something else,” Mathew told <em>Fortune</em>. “That’s necessary, certainly at this valuation…We know what greatness looks like, we believe that—and I’m obviously betting with my career.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->That term sheet became Supabase’s latest funding round, a $200 million Series D valuing the company at $2 billion, <em>Fortune</em> can exclusively report. Coatue, Y Combinator, Craft Ventures, and Felicis participated in the round, as did big-name angels like OpenAI Chief Product Officer Kevin Weil, Vercel CEO Guillermo Rauch, and <a href="https://fortune.com/2024/09/05/laravel-raises-57-million-series-a-from-accel/" rel="nofollow noopener" target="_blank" data-ylk="slk:Laravel CEO Taylor Otwell;elm:context_link;itc:0;sec:content-canvas">Laravel CEO Taylor Otwell</a>.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->“The core thesis for us is that in every major platform shift, there's always value created at the database layer,” said Mathew. “It's part of the reason that Larry Ellison and <a href="https://fortune.com/europe/2025/03/17/oracle-uk-ai-boom-5-billion-cloud-investment-larry-ellison-trump-starmer/" rel="nofollow noopener" target="_blank" data-ylk="slk:Oracle;elm:context_link;itc:0;sec:content-canvas">Oracle</a> have held the same power for 40-plus years. It's partially why MongoDB is one of the most interesting enterprise software companies out there…The database layer has a lot of dead bodies, but it also has a number of companies that have created exceptional enterprise value.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Supabase is currently used by two million developers who manage more than 3.5 million databases. The startup supports Postgres, the most popular developer database system that’s an alternative to Google’s Firebase. Supabase’s goal: To be a one-stop backend for developers and "vibe coders."<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“I see our community, over the next decade, as something that will grow with us, and it’s for everyone from developers, all the way up to enterprise,” said Copplestone. “It’s more than just developers even now. Our sign-up rate just doubled in the past three months because of vibe coding—Bolt, Lovable, Cursor, all those.”<!-- HTML_TAG_END --></p> </div></div>]]></description>
        </item>
    </channel>
</rss>