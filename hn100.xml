<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jul 2023 23:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A Caltech Nobel laureate celebrates his 100th birthday, then gets back to work (186 pts)]]></title>
            <link>https://www.latimes.com/science/story/2023-07-21/caltech-nobel-laureate-rudy-marcus-turns-100-and-gets-back-to-work</link>
            <guid>36828811</guid>
            <pubDate>Sat, 22 Jul 2023 19:00:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/science/story/2023-07-21/caltech-nobel-laureate-rudy-marcus-turns-100-and-gets-back-to-work">https://www.latimes.com/science/story/2023-07-21/caltech-nobel-laureate-rudy-marcus-turns-100-and-gets-back-to-work</a>, See on <a href="https://news.ycombinator.com/item?id=36828811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Say you wake up on the morning of your 100th birthday, having achieved the pinnacle of recognition in your chosen field and the warm esteem of family, friends and colleagues. How would you celebrate the day ahead?</p><p>“Work,” quipped Caltech chemistry professor <a href="https://www.cce.caltech.edu/people/rudolph-a-rudy-marcus" target="_blank">Rudy Marcus</a> at a lunch in honor of his centenary Friday.</p><p>But the university where he’s been on the faculty for 45 years had other plans, so the Nobel laureate good-naturedly agreed to a symposium in his honor.</p><p>Generations of Marcus’ colleagues and former students gathered at <a href="https://www.athenaeumcaltech.com/" target="_blank">the Athenaeum</a>, Caltech’s faculty club, to celebrate a scientist who still reports to the book-lined office he has occupied on the Pasadena campus since 1978, and whose inquisitiveness and generous spirit remains undimmed.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/afcff15/2147483647/strip/true/crop/3775x3022+0+0/resize/320x256!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/45f4569/2147483647/strip/true/crop/3775x3022+0+0/resize/568x455!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/c8d98e8/2147483647/strip/true/crop/3775x3022+0+0/resize/768x615!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/92fc706/2147483647/strip/true/crop/3775x3022+0+0/resize/1024x820!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/bc25cb8/2147483647/strip/true/crop/3775x3022+0+0/resize/1200x961!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 1200w" sizes="100vw">     <img alt="Nobel laureate Rudy Marcus in his Caltech office, where he's a chemistry professor." srcset="https://ca-times.brightspotcdn.com/dims4/default/3e944a8/2147483647/strip/true/crop/3775x3022+0+0/resize/320x256!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/86c3606/2147483647/strip/true/crop/3775x3022+0+0/resize/568x455!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/fbcc916/2147483647/strip/true/crop/3775x3022+0+0/resize/768x615!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/0bcfd77/2147483647/strip/true/crop/3775x3022+0+0/resize/1024x820!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/34986e5/2147483647/strip/true/crop/3775x3022+0+0/resize/1200x961!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg 1200w" sizes="100vw" width="1200" height="961" src="https://ca-times.brightspotcdn.com/dims4/default/34986e5/2147483647/strip/true/crop/3775x3022+0+0/resize/1200x961!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fcf%2F58%2F3753384e478987467fb71a6beda6%2Fimg-0442.jpg" decoding="async" loading="lazy">  </picture>  <div>      <p>(Corinne Purtill / Los Angeles Times)</p>   </div>  </figure></div><p>“He’s an excellent example of what it is to be a scientist: the curiosity, the energy, the enthusiasm and the excitement for figuring things out,” said <a href="https://www.anl.gov/profile/stephen-j-klippenstein" target="_blank"><u>Stephen Klippenstein</u></a>, a former doctoral student of Marcus’ who is now a theoretical chemist at Argonne National Laboratory.</p><p>“I don’t think I’ve ever heard him say a harsh word to anyone,” Klippenstein added, echoing others who described Marcus as a role model both in and out of the lab. “He leads by example: Work hard and solve hard problems.”</p><p>As a theoretical chemist, Marcus works with concepts rather than laboratory apparatus. He received <a href="https://www.nobelprize.org/prizes/chemistry/1992/summary/" target="_blank">his Nobel Prize</a> in 1992 for work on electron transfer reactions, a deceptively simple theory describing how electrons move between molecules in chemical reactions without breaking chemical bonds.</p><p>While experimental chemists produce compelling new results in the lab, Marcus seeks the elegant architecture that undergirds their findings.</p><div data-click="enhancement" data-align-right=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/188359e/2147483647/strip/true/crop/2690x4048+0+0/resize/320x482!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/69717e7/2147483647/strip/true/crop/2690x4048+0+0/resize/568x855!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/1f8573c/2147483647/strip/true/crop/2690x4048+0+0/resize/768x1156!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/57faed8/2147483647/strip/true/crop/2690x4048+0+0/resize/1024x1541!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/22312bb/2147483647/strip/true/crop/2690x4048+0+0/resize/1200x1806!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 1200w" sizes="100vw">     <img alt="Jack Y. Zhang chats with Rudy Marcus during the Nobel laureate's 100th birthday celebration at Caltech." srcset="https://ca-times.brightspotcdn.com/dims4/default/1917cc6/2147483647/strip/true/crop/2690x4048+0+0/resize/320x482!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/55b6674/2147483647/strip/true/crop/2690x4048+0+0/resize/568x855!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/77ed181/2147483647/strip/true/crop/2690x4048+0+0/resize/768x1156!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/866348f/2147483647/strip/true/crop/2690x4048+0+0/resize/1024x1541!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/4a0bb7e/2147483647/strip/true/crop/2690x4048+0+0/resize/1200x1806!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg 1200w" sizes="100vw" width="1200" height="1806" src="https://ca-times.brightspotcdn.com/dims4/default/4a0bb7e/2147483647/strip/true/crop/2690x4048+0+0/resize/1200x1806!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F75%2F6d%2F7a265dda43a7a3c1224020db5a48%2F1324895-sci-caltech-nobel-laureate-turns-100-05-mjc.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Jack Y. Zhang, CEO and president of a pharmaceutical company, chats with Rudy Marcus, left, his former academic advisor, during the Nobel laureate’s 100th birthday celebration at Caltech.</p>   <p>(Myung J. Chun / Los Angeles Times)</p>   </div>  </figure></div><p>It’s an intellectual challenge that keeps him eager to return to his desk as his 11th decade begins. If anything, he said, his workload feels even more pressing as the sheer amount of intriguing experiments grows. </p><p>“There are all sorts of developments in the laboratory and all sorts of new techniques that have been produced,” he said Friday as well-wishers milled around his table at a pre-symposium lunch. “I have plenty of work to do, more than I can comfortably handle.”</p><p>Marcus still <a href="https://www.cce.caltech.edu/people/rudolph-a-rudy-marcus#publications-de1708b1-tab" target="_blank"><u>publishes</u></a> several research papers per year. The Office of Naval Research just renewed a grant he’s had since the 1950s.</p><p>Age has demanded some concessions. He walked to work each day from his house near the Pasadena campus until the age of 97, when the COVID-19 pandemic forced him to stop.</p><p>He hung up his skis at the age of 90, not because he couldn’t physically continue, but because it seemed unwise to do so.</p><p>“I’d love to ski, but I’d love not to break any bones,” he said. “Once people get hospitalized, for some that’s the beginning of the end, and there’s too much to do yet.”</p><p>Marcus’s work ethic is legendary, colleagues and family members said.</p><p>When his eldest son <a href="https://www.abdn.ac.uk/sll/people/profiles/a.marcus" target="_blank"><u>Alan Marcus</u></a>, a cultural historian and professor at the University of Aberdeen in Scotland, decided to shift to part-time work as his 65th birthday approached, “Dad said, ‘You’re such a slacker,’ ” the younger Marcus recalled with a laugh.</p><p>Marcus was married to Laura Hearne from 1949 until her death from multiple myeloma in 2003. Their sons Alan, Kenneth and Raymond all obtained doctoral degrees in history.</p><p>Marcus continued to teach until the age of 95, when he decided “enough is enough.”</p><p>“They should really have somebody who really knows something,” he said.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/d27f165/2147483647/strip/true/crop/5394x3711+0+0/resize/320x220!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/4c5ce67/2147483647/strip/true/crop/5394x3711+0+0/resize/568x391!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/d39ea0e/2147483647/strip/true/crop/5394x3711+0+0/resize/768x529!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/a4e0a46/2147483647/strip/true/crop/5394x3711+0+0/resize/1024x705!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/e3fe57a/2147483647/strip/true/crop/5394x3711+0+0/resize/1200x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 1200w" sizes="100vw">     <img alt="Nobel laureate Rudy Marcus celebrated his 100th birthday with a day of festivities at Caltech" srcset="https://ca-times.brightspotcdn.com/dims4/default/106ec19/2147483647/strip/true/crop/5394x3711+0+0/resize/320x220!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/0b4cf9c/2147483647/strip/true/crop/5394x3711+0+0/resize/568x391!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/ac2d5e0/2147483647/strip/true/crop/5394x3711+0+0/resize/768x529!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/aff62f1/2147483647/strip/true/crop/5394x3711+0+0/resize/1024x705!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/8525c51/2147483647/strip/true/crop/5394x3711+0+0/resize/1200x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg 1200w" sizes="100vw" width="1200" height="826" src="https://ca-times.brightspotcdn.com/dims4/default/8525c51/2147483647/strip/true/crop/5394x3711+0+0/resize/1200x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F32%2Feb%2F3d71027d4c8894a21b9fc8f35b6e%2F1324895-sci-caltech-nobel-laureate-turns-100-03-mjc.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Nobel laureate Rudy Marcus celebrated his 100th birthday with a day of festivities at Caltech, where he has worked since 1978.</p>   <p>(Myung J. Chun / Los Angeles Times)</p>   </div>  </figure></div><p>As a teacher, Marcus “has this uncanny ability to reduce very complex problems into simple essentials,” said Caltech chemist <a href="https://cce.caltech.edu/people/zhen-gang-wang" target="_blank"><u>Zhen-Gang Wang</u></a>. “The electron transfer theory” — his Nobel Prize-winning work — “is a great example of that.”</p><p>Marcus was at an electrochemistry conference when the call came in from Stockholm in 1992. At a hastily called news conference at the Toronto hotel where he was staying, the professor demurred when asked about the newfound fame that comes with being a Nobel laureate.</p><p>“I don’t know that I want to attract more attention to my work,” a bemused Marcus <a href="https://www.latimes.com/archives/la-xpm-1992-10-15-mn-394-story.html"><u>told reporters</u></a>. “I just want more time to get it done.”</p><p>He got his wish. His colleagues couldn’t have foreseen the sheer longevity of his tenure when he arrived at Caltech during the Carter administration, “but the Nobel Prize quality, yes,” said <a href="https://www.cce.caltech.edu/people/john-d-baldeschwieler?back_url=%2Fpeople" target="_blank"><u>John D. Baldeschwieler</u></a>, a retired professor emeritus of chemistry who was chair of the department at the time of Marcus’ hiring. </p><p>Marcus was born in 1923 in Montreal, the much-loved only child of Esther and Myer Marcus. His mother in particular instilled a love of learning, in part motivated by the fact that her own family lacked the money to continue her education beyond grade school.</p><p>“She told me that when I was a baby and she used to wheel me in a carriage around McGill, she told me that I would go there,” he said in an <a href="https://oralhistories.library.caltech.edu/139/1/Marcus_OHO.pdf" target="_blank"><u>oral history</u></a> collected by Caltech in 1993. (She was right: he earned both his bachelor’s degree and doctorate at the prestigious Montreal university.)</p><p>He was drawn to puzzles as a child, and has often described his approach to science as a decades-long continuation of the childlike pleasure of teasing a solution from once-scattered parts.</p><p>“The main thing is finding something that you enjoy doing, that preferably doesn’t harm others, and that tests whatever aptitude one has, that tests one’s ingenuity,” he said. “It’s almost like a kind of a game. You against nature.”</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shopify employee breaks NDA to reveal firm replacing laid off workers with AI (272 pts)]]></title>
            <link>https://thedeepdive.ca/shopify-employee-breaks-nda-to-reveal-firm-quietly-replacing-laid-off-workers-with-ai/</link>
            <guid>36828409</guid>
            <pubDate>Sat, 22 Jul 2023 18:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedeepdive.ca/shopify-employee-breaks-nda-to-reveal-firm-quietly-replacing-laid-off-workers-with-ai/">https://thedeepdive.ca/shopify-employee-breaks-nda-to-reveal-firm-quietly-replacing-laid-off-workers-with-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=36828409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
   		
<p>In a Twitter thread, a <strong><em>Shopify (TSX: SHOP)</em></strong> employee has broken their non-disclosure agreement (NDA) to shed light on the company’s controversial actions and strategic direction. The thread exposed a series of events starting from the first quarter of 2022 when Shopify promised job security to its staff, only to carry out massive layoffs in July of the same year. </p>



<p>These job cuts, according to the employee, were driven not merely by a CEO’s misguided “bet,” but rather a shift towards replacing full-time employees with cheaper contract labor and an increased reliance on artificial intelligence (AI) support.</p>



<figure><div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>WOW: A <a href="https://twitter.com/Shopify?ref_src=twsrc%5Etfw">@shopify</a> employee is violating their NDA to tell us that <a href="https://twitter.com/tobi?ref_src=twsrc%5Etfw">@tobi</a>:</p><p>-has been quietly firing their global customer service team across US, Canada and Ireland<br>-is about to replace them with AI chatbots</p><p>Good luck to all Shopify shop owners out there — shit’s about to SUCK. <a href="https://t.co/TwizyV0waP">https://t.co/TwizyV0waP</a></p></div>— Nandini Jammi (@nandoodles) <a href="https://twitter.com/nandoodles/status/1681694042256449536?ref_src=twsrc%5Etfw">July 19, 2023</a></blockquote></div></figure>



<p>Last week, Shopify announced its upcoming launch of an artificial intelligence assistant called “Sidekick” for merchants using its platform, joining the ranks of other tech companies introducing similar features. In a video shared on Twitter, Lutke demonstrated how the “Sidekick” assistant, accessible through a button on Shopify, will be capable of responding to merchant inquiries, providing information on sales trends, and more.</p>



<p>The tweet series further detailed how Shopify has been aggressively embracing AI technology, using it for various purposes, from generating product descriptions to creating virtual sidekicks and developing a new help center AI agent still in beta testing. CEO Tobi Lutke’s public statements on Twitter illustrated his belief that companies can achieve higher revenues with fewer employees, signaling a desire to cut costs and please shareholders.</p>



<p>However, the consequences of this cost-cutting strategy have negatively impacted customer satisfaction. The reduction in staff and the rise of outsourced, cheap contract labor have led to significant delays in customer support, leaving frustrated merchants waiting for hours or even struggling to receive clear answers. Additionally, teams responsible for monitoring fraudulent stores have been overwhelmed, leading to a potential increase in the number of scam businesses on the platform.</p>



<figure><div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">5. Tobi has hardly been discreet about his plans, sharing a graph on Twitter that illustrated how, over the years, companies required fewer workers to make $1 million in revenue: <a href="https://t.co/WHc8tu3ufx">https://t.co/WHc8tu3ufx</a></p>— Joe Momma (@sh0p1fyj03) <a href="https://twitter.com/sh0p1fyj03/status/1681673992476717057?ref_src=twsrc%5Etfw">July 19, 2023</a></blockquote></div></figure>



<p>The employee’s Twitter thread also raised concerns about the well-being of Shopify’s workforce. Since the layoffs, remaining staff members have reportedly faced increased workloads without proportional compensation or benefits, leading to burnout, anxiety, and stress leave. Despite these issues being brought to leadership’s attention, they were dismissed as “system” problems, and the company’s focus on AI-based solutions appeared to supersede the value once placed on human-driven customer service.</p>



<p>Furthermore, the thread highlighted Shopify’s apparent shift in target market focus. Previously known for supporting small businesses and entrepreneurs, Shopify now seems to prioritize larger players, as its revenue model relies heavily on payment transactions rather than subscription software.</p>



<p>The drastic changes in Shopify’s approach have led both employees and customers to question the company’s integrity and commitment to its original mission of empowering small businesses. Many see the company as straying from its roots, becoming more akin to the corporate giants it once aimed to oppose.</p>



<figure><div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">16. “Once we know how to fix the system, we will invest heavily in tooling, including tooling to help Support folks do their jobs better and tooling to help our merchants get answers to questions more quickly without having to talk to a human being”.</p>— Joe Momma (@sh0p1fyj03) <a href="https://twitter.com/sh0p1fyj03/status/1681674028681920514?ref_src=twsrc%5Etfw">July 19, 2023</a></blockquote></div></figure>



<p>Shopify’s leadership, including President Harley Finkelstein, has assured employees there will be no further layoffs. However, the company’s actions and secretive handling of layoffs under the veil of NDAs have caused employees to doubt these promises.</p>



<p>Despite multiple rounds of layoffs over the last year, management compensation at Shopify appears to have been largely unaffected.</p>



<p>In a regulatory filing made in May, Shopify revealed that Lutke collected just over $20.0 million in total compensation in 2022, on par with the $20.0 million he collected in 2021, and an increase over the $15.1 million he made in 2020.</p>



<figure></figure>



<p>With public scrutiny growing and concerns over its corporate values and business model mounting, Shopify faces a significant challenge in restoring trust and addressing the impact of its decisions on both employees and customers. </p>



<p>Shopify last traded at $89.91 on the TSX.</p>



<hr>



<p>Information for this briefing was found via Twitter and the sources mentioned. The author has no securities or affiliations related to the organizations discussed. Not a recommendation to buy or sell. Always do additional research and consult a professional before purchasing a security. The author holds no licenses.</p>
   	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am dying of squamous cell carcinoma, and potential treatments are out of reach (712 pts)]]></title>
            <link>https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/</link>
            <guid>36827438</guid>
            <pubDate>Sat, 22 Jul 2023 16:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/">https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/</a>, See on <a href="https://news.ycombinator.com/item?id=36827438">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7144">

	<!-- .entry-header -->

	<!-- #entry-meta -->

	<div>
						<p>Alex Tabarrok <a href="https://marginalrevolution.com/marginalrevolution/2015/08/is-the-fda-too-conservative-or-too-aggressive.html">writes about how</a> “when the FDA fails to approve a good drug, people die but the bodies are buried in an invisible graveyard.” I’d like to make that graveyard a little bit more visible because I’m going to be buried in it, in a few weeks or months. A squamous cell carcinoma tumor appeared on my tongue last September; the surgery for it occurred in October, followed by radiation in December – January, but the tumor reappeared at the base of my tongue in April. A massive surgery on May 25 appeared to produce “clean margins” (that is, no tumor cells remained where the surgeon operated), albeit at huge cost: I have no tongue any more, just a “flap” of muscle where it used to be, and no ability to swallow solid foods ever again. Monday I’m starting chemotherapy, but that’s almost certainly going to fail, because a CT scan shows four to six new gross tumors, four in my neck and two, possibly, in my lungs.</p>
<p>So what <em>might</em> help me? MRNA tumor vaccines. Head and neck squamous cell carcinomas (HNSCC) are notoriously treatment resistant, and mRNA vaccines have shown huge promise. Why aren’t they happening faster? Because the FDA is slow. There are some trials underway (<a href="https://trials.modernatx.com/study/?id=mRNA-4359-P101">here is one</a> from Moderna; <a href="https://trials.modernatx.com/study/?id=mRNA-2752-P101">here is another</a>), and, although I’m trying to enroll, I may be too late, since my cancer moves so aggressively. The FDA was loathe to approve initial mRNA human trials, even when those trials would have been full of people like me: those who are facing death sentences anyway.</p>
<p>Here is one story, from “<a href="https://www.fdareview.org/issues/why-the-fda-has-an-incentive-to-delay-the-introduction-of-new-drugs/">Why the FDA Has an Incentive to Delay the Introduction of New Drugs</a>:”</p>
<blockquote>
<p>In the early 1980s, when I headed the team at the FDA that was reviewing the NDA for recombinant human insulin, . . . we were ready to recommend approval a mere four months after the application was submitted (at a time when the average time for NDA review was more than two and a half years). With quintessential bureaucratic reasoning, my supervisor refused to sign off on the approval—even though he agreed that the data provided compelling evidence of the drug’s safety and effectiveness. “If anything goes wrong,” he argued, “think how bad it will look that we approved the drug so quickly.” (41)</p>
</blockquote>
<p>The problem is that delaying mRNA cancer vaccines kills people like me.</p>
<p>We need to have a much stronger “right to try” presumption: “<a href="https://www.newyorker.com/magazine/2023/06/26/relyvrio-als-fda-approval">When Dying Patients Want Unproven Drugs</a>,” we should let those patients try. I have weeks to months left; let’s try whatever there is to try, and advance medicine along the way. The “right to try” is part of fundamental freedom—and this is particularly true for palliative-stage patients without a route to a cure anyway. They are risking essentially nothing.</p>
<p>When I am dead and buried at least those who I love and who love me will know the FDA protected me and millions of others like me from ourselves. Thanks, FDA. But the dead do not vote and do not agitate for change, so the system is likely to grind on.</p>
<p>In computer science there is a convention in which one’s first program prints “Hello, world.” Now it is my turn to write “Goodbye, world.” I’m crying as I write this and am sorry to have to go so soon. I have to give back the gift, though with great sadness.</p>
<p><a href="https://www.slowboring.com/p/fda-cost-benefit">Here is more about the FDA being slow</a> and bureaucratic.</p>


<figure><a href="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg"><img data-attachment-id="7146" data-permalink="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/dsf4195/" data-orig-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg" data-orig-size="6240,4160" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;X-T4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1690014948&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;23&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsf4195" data-image-description="" data-image-caption="" data-medium-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=300" data-large-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=550" src="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=1024" alt="Jake Seliger, possible figurehead for the invisible graveyard of men and women killed by the FDA's slowness " srcset="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=1024 1024w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=2048 2048w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=150 150w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=300 300w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>The author on July 22, 2023, when he is, or was, still alive. </figcaption></figure>
					</div><!-- .post-content -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Important Coding Habits (216 pts)]]></title>
            <link>https://puppycoding.com/2023/07/22/healthy-coding-habits/</link>
            <guid>36826755</guid>
            <pubDate>Sat, 22 Jul 2023 14:56:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://puppycoding.com/2023/07/22/healthy-coding-habits/">https://puppycoding.com/2023/07/22/healthy-coding-habits/</a>, See on <a href="https://news.ycombinator.com/item?id=36826755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I’ve just learnt the hard way that the most important coding habits are not readability, consistency, organisation or <a href="https://hackernoon.com/few-simple-rules-for-good-coding-my-15-years-experience-96cb29d4acd9" target="_blank" rel="noreferrer noopener">any of the things that make our code better</a>. No, the most important habits are those that enable us to enjoy this craft for years and decades to come.</p>



<p>I’m writing this lying down, recovering from a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Spinal_disc_herniation" target="_blank">slipped disc (spinal disc herniation</a>) that’s a result of far too long hunched over a keyboard. I’ve tried to take steps to improve my posture over the last few years but alas, I let good habits slip and I’ve been taught a lesson.</p>



<figure><img decoding="async" width="1200" height="675" data-attachment-id="200" data-permalink="https://puppycoding.com/2023/07/22/healthy-coding-habits/back_mri/" data-orig-file="https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp" data-orig-size="1200,675" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="back_mri" data-image-description="" data-image-caption="" data-medium-file="https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=300" data-large-file="https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=1024" src="https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=1024" alt="MRI scan of the spine showing a spinal disc hernia, bulging out and pushing against the spinal nerve." srcset="https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=1024 1024w, https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=150 150w, https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=300 300w, https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp?w=768 768w, https://puppycodingcom.files.wordpress.com/2023/07/back_mri.webp 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>A slipped disc doesn’t actually mean a spinal disc has been dislodged. It’s actually when a disc, usually near the base of the spine, develops a bulge which sticks out and presses against the spinal nerve. It’s as painful as it sounds (and then some!), and also causes tingling and pain in the legs too. At times it’s made me unable to move and unable to sleep. Recovery takes weeks or months, although surgery is also an option.</p>



<p>It could happen to any of us if we develop unhealthy habits when programming, with the strain on our backs building up over time. And so, fellow keyboard warrior, here are some steps I encourage you to take to avoid this pain.</p>



<h2>Daily stretches</h2>



<p>According to my chiropractor, sitting for long periods of time had led to my stomach and thigh muscles being relatively unused, and therefore unable to assist my back in supporting my body, putting it under extra strain. Although strength-building exercises would be best, just doing daily central and lower body stretches would have a positive effect. The muscles would be more supple and more able to help support the body.</p>



<figure><img decoding="async" width="1200" height="689" data-attachment-id="206" data-permalink="https://puppycoding.com/2023/07/22/healthy-coding-habits/yoga-stretching/" data-orig-file="https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp" data-orig-size="1200,689" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="yoga-stretching" data-image-description="" data-image-caption="" data-medium-file="https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=300" data-large-file="https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=1024" src="https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=1024" alt="Photo of a man outside on a terrace, stretching forward in a yoga pose." srcset="https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=1024 1024w, https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=150 150w, https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=300 300w, https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp?w=768 768w, https://puppycodingcom.files.wordpress.com/2023/07/yoga-stretching.webp 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>You don’t have to suddenly become a yoga fanatic (although you can if you want!). Just regular stretches in the morning or after a hot bath in the evening, when the body is relaxed, should make a big difference.</p>



<h2>Take regular breaks</h2>



<p>This is so simple but so important –&nbsp;at least once an hour get up and take a short walk or some other non-screen activity. Not only is this an easy way to look after your body, I’ve often found that it helps with coding too. So many times I’ve been stuck on a problem, done something completely different, and then come back to the problem with an idea of something new to try.</p>



<p>I feel like this is something we all know we should do, but often hard to put into practice. Time to make it a habit!</p>



<h2>Don’t code late at night</h2>



<p>I think we’re all guilty of this, sometimes even turning it into a boast – “I pulled an all-nighter!” Surely it’s time we change this attitude. Our code is worse, even harmful, when we’re really tired, and we naturally concentrate less on our posture leading to being hunched over the keyboard for hours. Please set a time past which you will switch off, mentally and physically, and be strict with it.</p>



<h2>Improve your coding environment</h2>



<p>I have a laptop stand and ergonomic chair, both of which make sitting at my desk much more comfortable, but even with those I still ending up suffering with back pain. I’ve heard so many recommendations for a standing desk that at last, I’m making the switch.</p>



<p>Currently I just have a temporary setup of a small table on top of my desk, but already I can feel I move around more than when I sit, without really feeling more tired. It also naturally leads to taking more breaks so it’s a 2-in-1 habit!</p>



<p>I don’t know why it took me so long to realise the importance of this and all the other habits, and I wish I’d fixed my ways earlier. Now I’ve paid the price but hopefully it’s not too late for you, especially if you’re in the early stages of your career. </p>



<p>Please learn from my mistakes and enjoy many happy years of healthy coding!</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/_rYXNMxH5ck?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A brief history of computers (159 pts)]]></title>
            <link>https://www.lesswrong.com/posts/vfRpzyGsikujm9ujj/a-brief-history-of-computers</link>
            <guid>36826210</guid>
            <pubDate>Sat, 22 Jul 2023 13:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/vfRpzyGsikujm9ujj/a-brief-history-of-computers">https://www.lesswrong.com/posts/vfRpzyGsikujm9ujj/a-brief-history-of-computers</a>, See on <a href="https://news.ycombinator.com/item?id=36826210">Hacker News</a></p>
Couldn't get https://www.lesswrong.com/posts/vfRpzyGsikujm9ujj/a-brief-history-of-computers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Why even let users set their own passwords? (214 pts)]]></title>
            <link>https://www.devever.net/~hl/passwords</link>
            <guid>36826111</guid>
            <pubDate>Sat, 22 Jul 2023 13:36:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.devever.net/~hl/passwords">https://www.devever.net/~hl/passwords</a>, See on <a href="https://news.ycombinator.com/item?id=36826111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="nh">
          <main>
            <article><p>Today we seem to be living through a war on passwords. This is manifested in
various ways; in its most passive form, it takes the form of people blogging
about how passwords are bad. The more material changes are the general trend
towards no longer treating passwords as a sufficient condition for access in
favour of either mandatory “2FA” or, where 2FA is not used, <a href="https://www.devever.net/~hl/logindenial">risk-based
authentication</a>, in which some extra authentication step is
non-deterministically and randomly demanded.</p>
<p>This step is commonly something like “enter the code in an email we just sent”
when trying to login. Since this process is literally the same as most password
recovery processes, it raises the question of what the point of a password is
in the first place if you always have to go through this process when trying to
login.</p>
<p>Often this will be combined with fallacious notions such as “remember this
device”, the idea being you only have to go through all this the first time when
logging in from a particular device. This idea is fallacious because the web
has no notion of a “device”, and this is a <em>very intentional design choice</em>
made for privacy purposes. We are literally living through the gradual
phase-out of third-party cookies, amongst other functionality, specifically to
try and prevent this sort of thing, so why do web developers persist in
believing in this fiction of a “device”? My own browser erases all cookies from
an origin immediately after the last tab from that origin is closed, so these
sites are convinced I am logging in from a new “device” every single time, and
then demand I respond to one of these challenge emails.</p>
<p>Essentially these sites consider passwords so worthless as a form of security
that they essentially don't meaningfully allow people to have one anymore. The
login flow and the password recovery flow are essentially the same, the UI just
pretends otherwise. Other examples include PayPal, where you can literally
enter a credit card number to prove your identity and reset your password(!).
In other words, knowing your credit card number is considered a stronger or
equal proof of identity than either knowing your password or being able to
receive an email.<a href="#fn1" id="fn1b"><sup>1</sup></a></p>
<p>While at the same time every website for the masses now seems to be designed
around the assumption that everyone is going to set their password to
“password1”, web-based HTTP APIs are also widely popular nowadays. These
services almost invariably perform authentication via use of a token or “API
key”.</p>
<p>An API key is basically a password, except that it is randomly generated by a
website with a large amount of entropy and thus assumed to be secure. A given
website might obnoxiously refuse to trust in my ability to set a secure
password, assume the 24-character randomly generated password I keep in my
password safe is insecure, and demand I complete an email challenge every time
I login because I actually bother to exercise control over browser privacy and
persistent cookies, yet that same website is happy to let me authenticate using
an API key for API access as a single authentication step. No “2FA” here.</p>
<p>API keys are used to secure the highest-stakes APIs that exist today — all of
AWS's services, for example. Yet while API keys seem to be considered an
entirely reasonable and industry standard design approach, passwords are now
considered the unwelcome black sheep whose role as a sufficient criterion for
authentication is viewed with increasing dubiousness. (Moreover, all website
login schemes ultimately rely on some kind of session cookie, which is similar
to an API key in the sense that it is a high-entropy site-issued bearer token.
In other words, all website authentication schemes, “2FA” or not, ultimately
rely on the ability of a client to be enrolled in and use high-entropy
site-issued bearer authentication tokens as the sole criterion of access.<a href="#fn2" id="fn2b"><sup>2</sup></a>)</p>
<p>The fundamental premise is the same: provide token, gain access. It seems to me
that the basic problem here with passwords is that passwords are assumed to
have been chosen by users and users are assumed to be bad at choosing good
passwords.</p>
<p>There are agreed best practices for the handling of passwords, namely, to not
reuse passwords between accounts, use randomly generated passwords, and keep
those unique passwords for each account in a password safe. This raises the
question: if the industry agrees this is the (more or less only) correct way to
handle passwords, why actually allow users to set their own passwords?</p>
<p>Rather than allowing a user to set their own password, passwords can be issued
in exactly the same way as API keys are now: a high-entropy password is
randomly generated by the issuing website, and the user is shown the password
once only and asked to record it. If the password is lost, a new password must
be generated using the same process. The user cannot choose their password, but
can get a new randomly generated one in the event of compromise. The password
essentially becomes indistinguishable from an API key.</p>
<p>If we consider the password safe usage model to be the only reasonable way to
use passwords properly, there doesn't really seem to be any reason to allow any
other usage model than this. There's not really a good reason for a user to be
able to set their own password unless they want to set their password to
something lower in entropy to make it memorable, or reuse it between sites,
both of which are deviations from the “best practice” password safe usage
model.</p>
<p>With this model of password issuance, there is less need to constantly
second-guess the user's security with hazardous approaches like risk-based
authentication. Interestingly, however, it can be argued that this model is in
effect already widely deployed: namely in the form of TOTP “2FA” support.</p>
<p>In enrolling in TOTP-based 2FA with a website, you are given a high-entropy
randomly-generated secret and, for subsequent logins, are required to prove
possession of this secret. In other words, it's a site-generated
non-customisable “password” in much the same vein as I propose above. Moreover,
sites which support TOTP usually use a user's enablement of it as a “not an
idiot” flag and disable any non-deterministic risk-based authentication
mechanisms they may use for people without TOTP enabled. This is congruent
with my premise above that guaranteed use of a high-entropy secret obviates
the need for additional authentication.</p>
<p>Since the user-specified password functionality is now seemingly so distrusted
as a widespread industry practice, it raises the question of why not just
either use only TOTP for login, or issue a password in the same way that TOTP
secrets are issued: randomly and non-customisably.</p>
<p>The only discernible difference between TOTP and a site-generated password is
in how knowledge of the secret is proven. With TOTP, knowledge of the secret is
proven without sending it to the website. With a site-generated password,
knowledge of the secret is proven by sending that secret to the website. This
is a slight security benefit to TOTP. It doesn't seem to provide any useful
security against a compromised or impersonating website (an impersonating
website can just forward the TOTP challenge value to the real website and use
it to login as the user), so its main benefit seems to be to avoid having the
device the user is logging in as be able to glean the secret, in the event that
device is compromised. This is a potential upside, though since on successful
login the compromised client device has access to anything gated by that login
anyway, the benefit seems dubious.</p>
<p>It is interesting to note that TOTP ultimately can be viewed as just another
secret authentication token, like a password, yet is widely referred to as
“2FA”. Having two passwords isn't “2FA”; 2FA about having authenticators from
two different categories of {what you have, what you know, what you are}.</p>
<p>If TOTP is used “correctly”, meaning that the TOTP secret is enrolled onto a
different device than the one that contains your password safe, 2FA is more or
less realised — arguably. (You could also argue it's two copies of “what you
know” but with data partitioned between two devices which are unlikely to be
simultaneously compromised. This demonstrates that the {what you have, what you
know, what you are} triad is not necessarily the be all and end all of
authentication scheme security level classification.)</p>
<p>Of course, you don't necessarily know if someone is using TOTP “correctly”. For
example, whenever I register on some random site which offers TOTP, I enable it
and then put the TOTP secret in the same password safe that contains the
equally high-entropy password I chose. This seemingly pointless act is
obviously not 2FA. The reason I do this is for two reasons:</p>
<ol>
<li><p>it seems to increasingly serve as an “I'm not an idiot” flag and disable
stochastic risk-based authentication based around an assumption people
can't choose secure passwords, in which I might randomly be asked to
an additional challenge the potential necessity of which was not
documented at registration time, and which I may or may not be able to
complete, potentially resulting in account lockout;</p>
</li>
<li><p>it often seems to effectively disable password recovery flows, or at
least render them moot, making account recovery more difficult. Since
I don't lose my secrets I'm happy to assume responsibility for the
possibility of permanently locking myself out in exchange for higher
account security and disabling email as the “master key to all accounts”.</p>
</li>
</ol>
<p>While my own usage patterns are probably somewhat esoteric, in general it's
expected people will store TOTP secrets on a smartphone. However this again
raises questions about whether it really is “2FA” when you consider many people
may be accessing a website from their smartphone in the first place. In fact,
it's likely that a lot of TOTP-based “2FA” is not really 2FA at all because the
user's browser and password safe (e.g. the browser's built in saved password
functionality) and TOTP secret are on the same device and both instances of
“what you know”.</p>
<p>This isn't the only case of websites demanding “2FA”-that-isn't. Many supposed
cases of “2FA” are really 1FA where the single factor required for
authentication is considered to lie in a better category than “what you know”,
or where there are two factors at first glance, but one factor can be used to
reset the other factor.</p>
<p>For example, a site which requires a password and email verification for each
login is not 2FA if access to the same email account can be used to reset the
password; this scheme is no more secure than just requiring email verification
per login. Another example is if a site tries to insist on verifying logins
using SMS messages sent to a user's phone number. Since this (particularly bad)
design is based on the false premise that a user's phone number is more secure
than an email account or any password, such sites will often allow a reset of
all the other factors (like a password) by access to this phone number alone.
This is quite literally 1FA, just with a different single factor.</p>


<p>This again seems to reinforce that the major benefit of pushing people to
enable TOTP is to actually have them adopt a secure “password” and not actually
“2FA”, which is often not actually realised.</p>
<hr>
<p>1. Fun fact: Effectively only 5
digits of your credit card number are secret. PCI standards consider the last
four digits of your credit card number as non-secret — which is why every
e-commerce website is allowed to constantly quote those last four digits back
to you so you know what card they're talking about. What is less known is that
the same standard also specifies that the first 6 digits are also not
sensitive. This means that PCI compliance is fundamentally about protecting the
remaining 6 digits of a 16-digit credit card number. However, the last digit of
a credit card number is of course a check digit, which means of the possible 6
digit values, only 10% can be conceivably valid, meaning that effectively only
5 digits are really secret. This means PayPal allows your password to be reset
given knowledge of a 5 decimal digit secret. <a href="#fn1b">⏎</a></p>

<p>2. After being locked out of one account
by risk-based authentication, while still having access from another, I have
sometimes idly contemplated copying persistent cookies between machines. This
kind of lockout situation in which a password is not enough is particularly
ironic if I happen to have chosen a password which actually has higher entropy
than a site's session cookie. <a href="#fn2b">⏎</a></p>


</article>
          </main>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Redmine – open-source project management (120 pts)]]></title>
            <link>https://www.redmine.org/</link>
            <guid>36825913</guid>
            <pubDate>Sat, 22 Jul 2023 13:06:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.redmine.org/">https://www.redmine.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36825913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  


	<ul><li><strong>Table of contents</strong></li><li><a href="#Redmine">Redmine</a><ul><li><a href="#Features">Features</a></li><li><a href="#Documentation">Documentation</a></li><li><a href="#Support-amp-getting-help">Support &amp; getting help</a></li><li><a href="#Contributing-and-helping-out">Contributing and helping out</a></li><li><a href="#Who-uses-Redmine">Who uses Redmine?</a></li><li><a href="#Redmine-books">Redmine books</a></li></ul></li></ul>


	<p>Redmine is a flexible project management web application. Written using the Ruby on Rails framework, it is cross-platform and cross-database.</p>


	<p>Redmine is open source and released under the terms of the <a href="http://www.gnu.org/licenses/old-licenses/gpl-2.0.html">GNU General Public License v2</a> (GPL).</p>


	<h2>Features<a href="#Features">¶</a></h2>


	<p>Some of the main features of Redmine are:</p>


	<ul>
	<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineProjects">Multiple projects support</a></li>
		<li>Flexible <a href="https://www.redmine.org/projects/redmine/wiki/RedmineRoles">role based access control</a></li>
		<li>Flexible <a href="https://www.redmine.org/projects/redmine/wiki/RedmineIssues">issue tracking system</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineGantt">Gantt chart</a> and <a href="https://www.redmine.org/projects/redmine/wiki/RedmineCalendar">calendar</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineNews">News</a>, <a href="https://www.redmine.org/projects/redmine/wiki/RedmineDocuments">documents</a> &amp; <a href="https://www.redmine.org/projects/redmine/wiki/RedmineFiles">files</a> management</li>
		<li>Feeds &amp; email notifications</li>
		<li>Per project <a href="https://www.redmine.org/projects/redmine/wiki/RedmineWikis">wiki</a></li>
		<li>Per project <a href="https://www.redmine.org/projects/redmine/wiki/RedmineForums">forums</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineTimeTracking">Time tracking</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineCustomFields">Custom fields</a> for issues, time-entries, projects and users</li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineRepository">SCM integration</a> (SVN, CVS, Git, Mercurial and Bazaar)</li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineReceivingEmails">Issue creation via email</a></li>
		<li>Multiple <a href="https://www.redmine.org/projects/redmine/wiki/RedmineLDAP">LDAP authentication</a> support</li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineRegister">User self-registration</a> support</li>
		<li>Multilanguage support</li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/RedmineInstall#Supported-database-back-ends">Multiple databases</a> support</li>
	</ul>


	<p>Read more about <a href="https://www.redmine.org/projects/redmine/wiki/Features">Redmine features</a>.</p>


	<h2>Documentation<a href="#Documentation">¶</a></h2>


	<p>You can read the <strong><a href="https://www.redmine.org/projects/redmine/wiki/Guide">Redmine guide</a></strong>.</p>


	<ul>
	<li><a href="https://www.redmine.org/projects/redmine/wiki/Guide">User's Guide</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/Developer_Guide">Developer's Guide</a></li>
	</ul><p>


Other resources:
	</p><ul>
	<li><a href="https://www.redmine.org/projects/redmine/wiki/Changelog">Changelog</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/Security_Advisories">Security Advisories</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/FAQ">Frequently Asked Questions</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/HowTos">HowTos</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/Plugins">Plugins</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/Themes">Themes</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/Logo">Logo and Icon</a></li>
		<li><a href="https://www.redmine.org/projects/redmine/wiki/ThirdPartyTools">Third Party Tools</a></li>
	</ul>


	<h2>Support &amp; getting help<a href="#Support-amp-getting-help">¶</a></h2>


	<p>For getting help or discussing Redmine, you can browse the <strong><a href="http://www.redmine.org/projects/redmine/boards">Redmine forums</a></strong> hosted right here in Redmine.</p>


	<p>We also have a <strong><a href="https://www.redmine.org/projects/redmine/wiki/IRC">chatroom</a></strong> -  <a href="https://web.libera.chat/?channel=#redmine">join #redmine</a> on the <a href="https://libera.chat/">libera.chat</a> IRC network.</p>


	<p>There's also an unofficial workspace on <strong><a href="https://join.slack.com/t/redmineorg/shared_invite/zt-ew74bkww-9~Cs~L2oSioRXDljumZ_zg">Slack</a></strong> where you can ask questions and participate in discussions with other Redmine users.</p>


	<p>Before submitting a bug report, a patch or a feature request here, please read the <a href="https://www.redmine.org/projects/redmine/wiki/Submissions">Submission guidelines</a>.</p>


	<h2>Contributing and helping out<a href="#Contributing-and-helping-out">¶</a></h2>


	<p>Redmine is built and maintained by community volunteers. If you enjoy using it and would like to give back to the community, the <a href="https://www.redmine.org/projects/redmine/wiki/Contribute">Contribute</a> page has several ideas. Software development experience is not required. Check out the <a href="https://www.redmine.org/projects/redmine/wiki/Teams">Teams</a> Page if you are interested in a specific area to contribute regularly.</p>


	<p>You can also make a donation and get listed on the <a href="https://www.redmine.org/projects/redmine/wiki/Donors">Redmine Donors page</a>.</p>


	<h2>Who uses Redmine?<a href="#Who-uses-Redmine">¶</a></h2>


	<p><a href="https://www.redmine.org/projects/redmine/wiki/WeAreUsingRedmine">This page lists</a> some companies and projects using Redmine.</p>


	<h2>Redmine books<a href="#Redmine-books">¶</a></h2>


	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Embrace Complexity; Tighten Your Feedback Loops (108 pts)]]></title>
            <link>https://ferd.ca/embrace-complexity-tighten-your-feedback-loops.html</link>
            <guid>36825345</guid>
            <pubDate>Sat, 22 Jul 2023 11:30:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ferd.ca/embrace-complexity-tighten-your-feedback-loops.html">https://ferd.ca/embrace-complexity-tighten-your-feedback-loops.html</a>, See on <a href="https://news.ycombinator.com/item?id=36825345">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        
            <span>2023/06/20</span>
        
        
        
<p>This post contains a transcript of the talk I wrote for and gave at <a href="https://qconnewyork.com/presentation/jun2023/embrace-complexity-tighten-your-feedback-loops">QCon New York 2023</a> for <a href="https://qconnewyork.com/speakers/vanessahuertagranda">Vanessa Huerta Granda</a>'s <a href="https://qconnewyork.com/track/jun2023/resilience-engineering-culture-system-requirement">track on resilience engineering</a>.</p>

<p>The official talk title was "Embrace Complexity; Tighten Your Feedback Loops". That’s the descriptive title for the talk that follows the conference’s guidelines about good descriptive titles. Instead I decided to follow my gut feeling and go with what I think really explains my perspective and the approach I bring with me to work and even my life in general:</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/01.png" alt="" title=""></p>

<p>I take what would probably be a sardonic approach to dealing with life and systems, and so “This is all going to hell anyway” is pervasive to my approach. Things are going to be challenging. There are going to always be pressures that keep pushing our systems to the edge of chaos. I don’t think this can be fixed or avoided. Any improvement will be used to bring it right to that edge. In complex systems, the richness and variability is often there for a reason. Trying to stamp it out in favour of stronger control is likely to create weird issues.</p>

<p>So the best I personally hope for is to have some limited influence in steering things the best I can to delay going to hell as long as possible, but that’s it. And my talk is going to focus on a lot of these approaches, but first, I want to explain why I feel things are that way.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/02.png" alt="" title=""></p>

<p>In what is probably my favorite paper ever, titled <a href="https://ferd.ca/notes/paper-moving-off-the-map.html">Moving Off The Map</a>, Ruthanne Huising ran ethnological studies by embedding herself into projects within many large corporations doing planned organizational changes. In supporting these efforts, they were doing “tracing” of their functions, which meant gathering a lot of data about what activities take place, what interactions and hand-offs exist, what information and tools are used and required? How long do tasks take? How do people and teams deal with errors? Generally asking the question “what do we do here?” and wondering with whom they do it.</p>

<p>To build these maps they generally reached out to experts within the organization who were supposed to know how things were working. Even then, they were really surprised.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/03.png" alt="" title=""></p>

<p>One explained that “it was like the sun rose for the first time… I saw the bigger picture.” Participants had never seen the pieces (jobs, technologies, tools, and routines) connected in one place, and they realized that their prior view was narrow and fractured, despite being considered experts.</p>

<p>Others would state that “the problem is that it was not designed in the first place.” The system was not designed nor coordinated, but generally showed the result of various parts of the organization making their own decisions, solving local problems, and adapting in a decentralized manner.</p>

<p>The last quote comes from events when a manager at one of the organizations walked the CEO through the map, highlighting the lack of design and the disconnect between strategy and operations. The CEO sat down, put his head on the table, and said, “This is even more fucked up than I imagined.” He realized that the operation of his organization was out of his control, and that his grasp on it was imaginary.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/04.png" alt="" title=""></p>

<p>One of the most surprising results reported in there was about tracking the people who participated in organizing and running the change projects, and seeing who got promoted, who left, and who moved around the org or industry they were in.</p>

<p>She found out there were two main types of outcome. The first group turned out to be filled with people who got promotions. They were mostly folks who worked in communications, training, who managed the costs and savings of the projects, or those who helped do process design. Follow-up interviews revealed that most of them attributed their promotions to having worked on a big project to put under their belt, and to frequently working with higher-ups, which both helped with getting promoted.</p>

<p>Another group however mostly contained people who moved to the periphery: away from core roles at the organization, sometimes becoming consultants, or leaving altogether. Those who fit this category happened to be the people who collected the data and created the map. They attributed their moves to either feeling like they finally understood the organization better, felt more empowered to change things, or became so alienated by the results they wanted to get out.</p>

<p>So the question of course became how come people who feel they understand how the organization truly works and who want to change it move <em>away</em> from the central roles and positions, and into the peripheral ones?</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/05.png" alt="" title=""></p>

<p>The fatal insight, according to Huising, is something sociologists knew for a good while: the culture and the order imposed to organizations, groups, and even societies is often emergent and negotiated. And while it's obvious that these structures dictate a lot of actions, the actions themselves can preserve or change the structures around them.</p>

<p>The feelings of empowerment and alienation come in no small part because people realized that they could change a lot more than they could, albeit often from outside the core decision-making that enforces the structure (while understanding how that core works), or because the ways they thought they were impacting things was shown not to be effective and they felt disembedding.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/06.png" alt="" title=""></p>

<p>Another thing you have possibly experienced and isn’t in the paper now is one of differentiating between the nominal and actual structure of the org, the emergent one that depends on power dynamics, who knows what or whom, who likes or dislikes each other, and so on.</p>

<p>If you've ever worked in a flat organization, like the one in the middle here, is that even though you have little management structure to speak of, power dynamics and decision-making authority still exists. People who have no power attached to their role are still going to be consulted or inserted in the decision-making flow of the organization, they're still going to be influential and have the ability to make or break projects, but just with less obvious accountability.</p>

<p>The nominal structure is the one where each level of management and within the organizational ladder specifies how information flows, and how authority is applied. It's what we see on the left in a more traditional org structure, and this way of organizing groups will simultaneously be useful to align efforts and to constrain them. It makes accountability more explicit and transparent, but structurally will prevent people from doing unspecified things, whether they would be harmful or useful.</p>

<p>The emergent structure is always there as well. It is implicit, always changing, and not necessarily constrained to your own organization either. Sometimes, people who know how to run, maintain, or operate components, or whom people listen to, are not even in your org anymore. They might have moved away (to a different team or even a competitor), retired, or never been in and they have just published a really influential piece of media and people look up to them.</p>

<p>But who knows what, works with whom, and who can move things around in specific contexts can be key to successful initiatives. Even if the organizational structure has often been put in place to constrain change, as a barrier to people working in mis-aligned ways, some folks central to the emergent structure, in key contexts, have earned enough trust to be allowed tacitly to bend and break the rules. They can choose not to enforce the rules, or the rules are not enforced as tightly for them with the hopes of positive outcomes—even if sometimes it can get you the opposite result.</p>

<p>I’m not here to argue in favor of one or the other structure, but mostly that in my experience, driving change or making initiatives succeeds the most when catering to both structures at once, or rather fails when only looking at one and being blocked by the other. They're both real, both distinct, and pretending only either exists is bound to cause you grief.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/07.png" alt="" title=""></p>

<p>As a continuation of this, the way people work every day is often different from the way people around them imagine their work is being done. The gap between how work is thought to be done and how it is actually done is a major but generally invisible factor in how systems work out.</p>

<p>Based on flawed mental models of the work, procedures and prescriptions are given about how to do work, and will vary in inaccuracy. People will imagine things like, for example, writing all the tests before writing or modifying any code and that code coverage could be ideal and then that it will all be reviewed in depth by an expert, and will enshrine this as a policy.</p>

<p>But the application of these policies is never perfect. Sometimes code doesn't have an owner, or due to crunch time and based on how much the reviewer and author trust each other, the review won't be as in-depth as expected.</p>

<p>When you see this mismatch causing people to ignore or bend rules, you can choose to apply authority and ask for a stricter rule-following. This pattern of enforcing the rules harder will likely drive these adaptations underground rather than stamping them out, because real constraints drive that behavior.</p>

<p>In turn, the work as disclosed will be less adequate, and the work as imagined progressively gets worse and worse.</p>

<p>This becomes a feedback loop of misunderstanding and at some point, like our devastated CEO, you’re not managing the real world anymore.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/08.png" alt="" title=""></p>

<p>To demonstrate this, earlier this year I went to my local mastodon network—so you know this is super scientific—and ran a poll about time sheets. The question was "If you're a software developer who ever worked for an employer who had you track your time hourly into specific projects/customer accounts and you were short on time budget, did you..."</p>

<p>Multiple answers were accepted. Fewer than 15% of people either stopped work, worked without tracking their time anymore (for free), or shifted their time into other projects with more buffer space.</p>

<p>Roughly a third of people reported billing anyway, some stating that it's not their problem the time allocation wasn't realistic or adequate.</p>

<p>But the vast majority of answers, nearly 60%, came from people saying "my time tracking was always fake and lies," with some people stating they even wrote applications to generate realistic-looking time sheets.</p>

<p>What we can see here is an example of how work-as-imagined gets translated into policies ("people do their work in projects, and account for their time"), which at some point doesn't get applied right anymore. If I were to suppose, it could be things like not being allowed to go over time, or just finding the practice useless. But the end result is that the time sheet data just isn't trustworthy, and then it can get used again and again in further decision making.</p>

<p>The gap widens, and our CEO might also get to think "this is all fucked up."</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/09.png" alt="" title=""></p>

<p>Part of the reason for this is that every day decisions are made by trying to deal with all sorts of pressures coming from the workplace, which includes the values communicated both as spoken and as acted out. People generally want to do a good job and they’ll try to balance these conflicting values and pressures as well as they can.</p>

<p>The outcome of that trade-off being a success or a failure isn’t known ahead of time, but these small decisions accumulate based on the feedback we get from each of these and can end up compounding and accumulating, either as improvements, or as erosion that makes organizations more brittle, or really anywhere in between.  People adopt the organization’s constraints as their own, and this set of pressures is the kind of stuff that drives processes to the edge of chaos over and over again.</p>

<p>These accumulations of small decisions, these continuous negotiations, that’s one way your culture can define itself. Small common everyday acts and small amounts of social pressure you can apply locally has an impact, as minor as it might be, and compounds. You can easily foster your own local counterculture within a team if you want to. This can both be good (say in Skunkworks where you bypass a structure to do important work) or bad (normalizing behaviors that are counterproductive and can create conflict).</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/10.png" alt="" title=""></p>

<p>So while a lot of the work you can do to improve reliability or resilience as a whole can be driven locally, my experience is that you nevertheless get the best results by also aligning with or re-aligning some of the organizational pressures and values usually set from above.</p>

<p>The idea here is to start looking at the organization from both ends: how can we support the people dealing with the trade-offs in conflicting goals as they happen, how can we influence the higher-level values and pressures such that we can try to reduce how often these conflicts happen even though they will definitely keep happening, and how can we better carry context and feedback across both ends so that we constantly adjust as best as we can. A system perspective on interactions, rather than focusing on components is also something I've found useful. The rest of the talk is going to be spent on these ideas.</p>

<p><em>(as a note, the third drawing is <a href="https://en.wikipedia.org/wiki/Dimethylmercury">Dimethylmercury</a>, a highly volatile, reactive, flammable, and colorless liquid. It's one of the strongest known neurotoxins, and less than 0.1 mL is enough to kill you through your skin, and gloves apparently do a bad job at protecting you)</em></p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/11.png" alt="" title=""></p>

<p>So let's start with negotiating trade-offs, with a bit more of an ops-y perspective, because that's where I'm coming from.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/12.png" alt="" title=""></p>

<p>This is a painful one sometimes, especially when you have highly professional people who take their jobs seriously.</p>

<p>Locally for you as a DevOps or SRE team, there is a need for the awareness of what the organization and customers actually care about. Some availability targets become useless metrics because they’re disconnected from what users want, and you’re just going to burn people out doing it.</p>

<p>I learned this lesson when talking to the SRE manager of one of these websites where people pick their favorite images, put them on boards, and get shown ads. He was telling me how their site was having a lot of reliability issues. It would keep going down, his team would do heroics to bring it back up, and it'd open all over again.</p>

<p>He felt his team was burning out. They were losing people, and their call rotation was so painful they were also having issues hiring back into it. He was seeing the death spiral happening and was wondering what to do.</p>

<p>He added that there were perverse incentives at play: every time the site went down, they stopped showing images, but not ads. That meant that during incidents, they still earned money, but no longer paid for bandwidth. The site was more profitable when it failed than when it worked, and seemingly, users didn't mind much.</p>

<p>They were not getting help, nobody seemed to consider it a problem. Not really knowing what to say, I just asked off-hand: "are you trying to deliver more reliability than people are asking for? What if you just stopped and let it burn more and rested your people?" He thought about it seriously, and said "yeah, maybe."</p>

<p>I never actually found out what happened after this, but it still stuck with me as a really good question to ask from time to time.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/13.png" alt="" title=""></p>

<p>In some cases, the answer will be "yes, we want to be this reliable". But you just won't be given the right tools to do it.</p>

<p>At Honeycomb, we want on-call rotations to have 5-8 people on them because that’s what we think gives a good pace that maintains a balance between how rested and how out-of-practice people can be. Not too often nor not often enough.</p>

<p>But many services are owned by smaller teams of 3-4 people. If we wanted rotations to be made of people who know all their components in depth, where they could build expertise and operate what they wrote, we couldn't reach a sustainable frequency.</p>

<p>Instead, to keep the pace right, we tend to put together rotations made of multiple teams, for which people won’t understand many of the components they operate. This in turn makes us prepare to deal with more unknown: fewer runbooks, more high-level switches and manual circuit breakers to gracefully degrade parts of the system to keep it running off-hours, and with different patterns of escalation.</p>

<p>We started leaning more heavily on this when a big public product launch required shipping a new feature, which was to be operated by a team that didn't have full time to get it operationally ready. When our SRE team was discussing with them what still needed to be done, we asked for a few simple things: a way to switch the feature off for a single customer, and a way to turn it off entirely, that wouldn't break the rest of the product. The rest we could add as we went.</p>

<p>We ended up using these switches a few times, one of which prevented a surprising write-amplification bug that could have killed the whole system, and instead let us wait a few hours for the code owners to get up and fix it at a leisurely pace. We're going to accept a bit of well-scoped, partial unavailability—something that happens a lot in large distributed systems—in order to keep the system stable.</p>

<p>The person wearing the pager often does triage and that weird issues will eventually be handled by code owners, just not right now.</p>

<p>This approach means that rather than working impossible hours and making inhuman efforts foreseeing the unforeseeable, we keep moving rather fast, gather feedback, find issues, and turn around a bit more on a dime. In order to do this though, there’s a general understanding that production issues may turn parts of the roadmap upside down, that escalations outside of the call rotation can disrupt project work, and so on.</p>

<p>That’s one of the complex trade-offs we can make between staffing, training/onboarding, capacity planning, iterative development, testing approaches, operations, roadmap, and feature delivery. And you know, for some parts of our infra we make different decisions because the consequences and mechanisms differ.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/14.png" alt="" title=""></p>

<p>To make these tricky decisions, you have to be able to bring up these constraints, these challenges, and have them be discussed openly without a repression that forces them underground.</p>

<p>One of my favorite examples is from a prior job, where one of my first mandates was to try and help with their reliability story. We went over 30 or so incident reports that had been written over the previous year, and a pattern that quickly came up was how many reports mentioned "lack of tests" (or lack of good tests) as causes, and had "adding tests" in action items.</p>

<p>By looking at the overall list, our initial diagnosis was that testing practices were challenging. We thought of improving the ergonomics around tests (making them faster) and to also provide training in better ways to test. But then we had another incident where the review reported tests as an issue, so I decided to jump in.</p>

<p>I reached out to the engineers in question and asked about what made them feel like they had enough tests. I said that we often write tests up until the point we feel they're not adding much anymore, and that I was wondering what they were looking at, what made them feel like they had reached the points where they had enough tests. They just told me directly that they knew they didn't have enough tests. In fact, they knew that the code was buggy. But they felt in general that it was safer to be on-time with a broken project than late with a working one. They were afraid that being late would put them in trouble and have someone yell at them for not doing a good job.</p>

<p>When I went up to upper management, they absolutely believed that engineers were empowered and should feel safe pressing a big red button that stopped feature work if they thought their code wasn't ready. The engineers on that team felt that while this is what they were being told, in practice they'd still get in trouble.</p>

<p>There's no amount of test training that would fix this sort of issue. The engineers knew they didn't have enough tests and they were making that tradeoff willingly.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/15.png" alt="" title=""></p>

<p><em>(note: this slide was cut from the presentation since I was short on time)</em></p>

<p>Speaking of which, sometimes it’s also fine to drop reliability because there are bigger systemic threats.</p>

<p>Sometimes you can eat downtime or degraded service because it’s going to keep your workload manageable and people from burning out. or maybe you take a hit because a big customer that makes you hit your targets as an org and can prevent layoffs will put some things over the limit and a component’s performance will suffer. You can’t be the department of “no” and that negotiation has to be done across departments.</p>

<p>Conversely however, you have to be able to call out when your teams are strained, when targets aren’t being met and customers are complaining about it. It means you might be right, and some deadlines or feature delivery could be deferred to make room for others.</p>

<p>How do you deal with capacity planning when making your biggest customer renew their contract prevents you from signing up another one that’s as big? Very carefully, by talking it out by all the involved people.</p>

<p>And sometimes that trade-off is very reasonable. And good engineering requires you to move it earlier in the lifecycle of software than just around incidents. It’s much simpler to change the shape of a product’s features than it is to deliver the perfect distributed systems sometimes. Making your features take the ideal shape to deal with the reality of physics is one of the things a good collaborative approach can facilitate.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/16.png" alt="" title=""></p>

<p>So we can make tradeoff negotiation simpler by having these honest discussions, but in many cases this ability to discuss constraints to influence how work takes place brings us to this next step, where we don’t only influence the decisions people make, but surface these challenges to influence how the organization applies its pressures. This is moving from the local level to the alignment to the broader org structure.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/17.png" alt="" title=""></p>

<p>Metrics are good to direct your attention and confirm hypotheses, but not as a target, and they’re unlikely to be good for insights. <a href="https://ferd.ca/plato-s-dashboards.html">They’re compression, and it can be unreliable</a>.</p>

<p>The thing you generally care about is your customer or user's satisfaction, but there's a limit to how many times you can ask "would you recommend us to a friend?" and still get a good signal. So you start picking a surrogate variable.</p>

<p>You assume that when the site is down and slow, people are mad, and you make being up and fast a proxy for satisfaction. But then that signal is a bit messy and not super actionable, because it can include user devices or bits of the network you don't control, plus it's hard to measure, so you'll settle for response time at the edge of your infrastructure. This loses fidelity into the signal, but it'll get worse as you suddenly find some teams have more data than others, and they use features differently, so you either need a ton of alarms or fewer messier ones, but you're getting further and further away from whether people are actually satisfied.</p>

<p>This loss of context is a critical part of dealing with systems that are too complex to adequately be represented by a single aggregate. Whenever a signal is useful, an in-depth dive is usually worth it if you are looking to embrace complexity.</p>

<p>The metric is better used to attract your attention than as a target or as something that tells you what to know. Seek to explain and understand the metric first, not to change it.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/18.png" alt="" title=""></p>

<p>As a related concept, if you act on a leading indicator, it stops leading, particularly when it’s influenced by trade-offs.</p>

<p>Metrics that become their own targets and are gamed of course lose meaningfulness; this is one of the most common issues with counting incidents and then debating whether an outage should or shouldn’t be declared in a way that might affect the tally rather than addressing it directly.</p>

<p>But other metrics are of interest as well. If you evaluate your total capacity by some bottleneck’s value, and that this bottleneck is a target of optimization work, you will lose the ability to easily know when or how to scale up because that bottleneck possibly hid something else. This is contributing to a non-negligible portion of our incidents at work I believe. We fix a thing that acted as an implicit blocker and off we go into the great unknown.</p>

<p>Our storage engine's disk storage used to be our main bottleneck. We drove scaling out and rebalancing traffic based on how close we were to heavy usage across multiple partitions. This was a useful signal, but it also drove costs up, and eventually became the target of optimization.</p>

<p>An engineer successfully made our data offloading almost an order of magnitude faster, and eliminated our most glaring scaling issues at the time. Removing this limit however messed with our ability to know when to scale, which then revealed issues with file descriptors, memory, and snapshotting times.</p>

<p>The only good advice I have here is to re-evaluate your metrics often, and change them. I guess there’s also a lesson to be learned that improvements can also cause their own uncertainty and that these successes can themselves lead to destabilizations.</p>

<p>Because we no longer needed to scale out as aggressively and were free to discover new issues, and one of our best improvements to the system in recent memory is therefore also a contributor to a lot of operational challenges.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/19.png" alt="" title=""></p>

<p>Things that people think are useful are possibly going to happen even if you forbid them. If you forbid people from logging onto production hosts, and they truly think they'll need it for emergency situations, they'll make sure there's still a way for it to happen, albeit under a different name.</p>

<p>On the other hand, things that people think are useless are likely to be done in a minimal way with no enthusiasm, such as lying in your timesheets.</p>

<p>This means that writing a procedure means little unless people actually see its value and believe it’s worth following. Conversely, it means that if you can demonstrate the usefulness and make some approaches more usable, they’re likely to get adopted regardless of what is written down as a list of steps or procedures.</p>

<p>A related concept here is one here is that if you are tracking things like action items after an incident reviews and they go in the backlog to die, it may not be that your people are failing to follow through; it might also be that it’s impractical to do so, or it’s could also be that these action items were never feeling useful, and the process itself needs to be revisited rather than reinforced.</p>

<p>Seeing non-compliance is not necessarily a sign of bad workers. It may rather be a sign of a bad understanding of the workers' challenges, and point to a need to adjust how work is prescribed.</p>

<p>Getting a small real buy-in into something voluntary may be better than getting fake buy-in into something you’re forcing people to do. Of course if you manage to write a good procedure that people believe are worth following, more power to you, this is going great.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/20.png" alt="" title=""></p>

<p>The shortest feedback loop may be attained by giving people the tools to make the right decisions right there and then, and let them do it. Cut the middlemen, including yourself.</p>

<p>How do you make that work? We come back to goal alignments and top priorities being harmonized and well understood. If the pressures and goals are understood better, the decisions made also work better.</p>

<p>That does mean that you have to listen back about how these things have been going, and that not only do you need to trust your people, but they need to trust you back with critical and unpleasant information as well. The feedback flows both ways, and this hinges on psychological safety.</p>

<p>If you've ever talked to a contractor asked to help a big organization, the first thing they'll tell you they do is go talk to the workers with boots on the ground, and ask them what they think needs changing. They'll often have years of potential improvements backlogged, and that they're ready to tell anyone about. Either because management wouldn't listen to it, or because the workers lost trust that voicing that feedback would yield any result.</p>

<p>Then the contractor brings it up to management as a neutral party, and suddenly it gets listened to and acted upon.</p>

<p>If you've lost that trust, then contractors can play that specific role of workers at the periphery of the organization helping drive change, and they can play a very useful function.</p>

<p>But if you have that trust already, maintaining it is crucial because that’s how you get all the good information to help orient and influence things.</p>

<p>Trust also means that if you want people to be innovative, you have to allow them to make mistakes. You can’t get it right the first time all the time; if people can’t be allowed to get it wrong here and there, they won’t be allowed to improve and try new things either.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/21.png" alt="" title=""></p>

<p>Finally, let's look at shifting perspective away from a bare analysis and onto a more systemic point of view. People in specific teams often have a more detailed expert view than you could either have, but if you're standing outside of it, your strength might be to understand how the parts interact in a way that isn't visible to the inside.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/22.png" alt="" title=""></p>

<p>The most basic point here is that you can’t expect to change the outcome of these small little decisions that accumulate all the time if you never address the pressures within the system that foster them.</p>

<p>I used to try and weed my lawn a whole hell of a lot and pull the weeds hours a week until someone explained to me that weeds grew easier in the type of soil I had (poor, dry, unmaintained soil) than grass, and pulling the weeds wasn’t the way to go, I needed to actually make the soil good for the grass to crowd out the weeds.</p>

<p>It's similar when considering this whole idea of root cause analysis—of trying to find the one source of the problem and removing it. If your root cause is at the weed’s level, you’ll keep pulling on them forever and will rarely make decent progress. The weeds will keep growing no matter how many roots you remove.</p>

<p>If you foster good soil, if you create the right environment that encourages the type of behavior you want instead of the type of behaviour you dislike, you have hopes that the good stuff will crowd out the bad stuff. That’s a roundabout way of talking about culture change. And for these, deep dives based on <a href="https://ferd.ca/notes/paper-accident-report-interpretation.html">richer narratives</a> and <a href="https://www.jeli.io/howie/welcome">thematic analysis</a> prove more useful.</p>

<p>Also there's a warning here about trying to change the decisions your people make with carrots and sticks—with incentives. They are not going to fundamentally change what pressures the employees negotiate. The pressures stay the same, all you're doing is adding more of them, either in the form of rewards or punishments, which makes decision-making more complex and trickier.</p>

<p>Chances are people will keep making the same decisions as they were already, but then they'll report it differently to either get their bonus or to avoid getting penalized for it. Surfacing, understanding, and clarifying goal conflicts can make things easier or shape work to give them more room. Adding carrots and sticks can make things harder.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/23.png" alt="" title=""></p>

<p>But the tip here is probably: look into what are the behaviors you want to see happen, and give them room to grow.</p>

<p>My most successful initiative at Honeycomb is probably creating <a href="https://www.honeycomb.io/blog/oncallogy-sessions-best-practices">weekly discussion sessions about operational stuff and on-call</a>. They range from “how do we operate new service X” into trickier discussions like “is it okay to be visibly angry in an incident”, “how do you deal with shit you don’t know or avoid burnout” or “are there times where code freezes are actually a useful thing?”.</p>

<p>Over time we looked into all sorts of weird interactions and the meeting became its own tool.</p>

<p>When we noticed incident reviews were difficult to schedule across departments and timezones, we decided that a good wide incident review is good operational talk and started making the optional time slot, which was already on every engineer's calendar (and some other departments too), available for them. It became easier for people to run incident reviews, and over time their size grew from 7-8 people, scoped to 1 or 2 teams, to bigger events with 20 to 40 people in them.</p>

<p>We removed a huge but subtle blocker to good feedback loops existing within the organization.</p>

<p>These sorts of small changes are those you can drive locally with almost no risk of having them run afoul of organizational priorities, and when you see them work, use the org structure to expand them everywhere.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/24.png" alt="" title=""></p>

<p>I find it useful to keep focusing on what an indicator triggers as a behavior (the interaction) rather than <em>only</em> what it reports directly. This slide here is 4 error budgets from our SLOs, which combine how successful requests are both in terms of speed and errors, compared to an objective we express in terms of the desired fault rate.</p>

<p>When we have to pick targets for our platform, people often ask whether we could pick some key SLOs and turn them as the objective. My answer is almost always "I don't care if we meet the SLOs or not". I mean I care, but not like that.</p>

<p>SLOs aren’t hard and fast rules. When the error budget is empty, the main thing that matters to me is that we have a conversation about it, and decide what it is we want to happen from there on. Are we going to hold off on deploys and experiments? Are we able to meet the objectives while on-call, with some schedule corrective work, some major re-architecting? Can we just talk to the customers? Were our targets too ambitious or are we going to eat dirt for a while?</p>

<p>Kneejerk automated reactions aren’t nearly as useful as sitting down and having a cross-departmental discussion about what it is we want to do, as an organization, about these signals of unmet expectations. If it fits within on-call duty, like what is probably the case with the error budget on the top left, then fine.</p>

<p>But in other cases, such as the top right budget here, which seems to show a gradual decline, owe have to choose whether to do corrective work (and how/when) to meet the SLO—because that wasn't expected and is undesirable—or maybe to relax it—because that's actually a natural consequence of new more expensive features and we need to tweak definitions. Or we could temporarily ignore it because corrective work is already on the way, but not a top priority right now.</p>

<p>The two budgets at the bottom come from SLOs that may never page anyone. But from time to time, we re-calibrate them by asking support whether there are any issues users complain about that we aren't already aware of. So long as we're ahead of the complaints, we figure the SLOs are properly defined. But from time to time, we find out that we slipped by getting comments on things our alerting never properly captured. Or maybe we needed to better manage the user's expectations—that's also an option.</p>

<p>For any of these choices, we also have to know how this is going to be communicated to users and customers, and having these discussions is the true value of SLOs to me. SLOs that flow outside of engineering teams provide a greater feedback loop about our practices, further upstream, than those that are used exclusively by the teams defining them, regardless of their use for alerting.</p>

<p><img src="https://ferd.ca/static/img/qcon-ny2023/26.png" alt="" title=""></p>

<p>Finally, this is where SREs can be placed in a great way to shine. You can be away from the central roles, away from the decision-making, on the periphery. By being outside of silos and floating around the organization’s structure, you are allowed to take information from many levels, carry it around, and really tie the loop at the end of so many decisions made in the organization by noting and carrying their impact back once they’ve hit a production system.</p>

<p>It is an iterative exercise, our sociotechnical systems are alive, and carrying pertinent signals and amplifying them, you can influence how long it’s gonna take before it all goes to hell anyway.</p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I thought I wanted to be a professor, then I served on a hiring committee (2021) (190 pts)]]></title>
            <link>https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee</link>
            <guid>36825204</guid>
            <pubDate>Sat, 22 Jul 2023 11:00:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee">https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee</a>, See on <a href="https://news.ycombinator.com/item?id=36825204">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Simpson Fan Grows Tomacco (2003) (132 pts)]]></title>
            <link>https://www.simpsonsarchive.com/news/tomacco.html</link>
            <guid>36824856</guid>
            <pubDate>Sat, 22 Jul 2023 09:44:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simpsonsarchive.com/news/tomacco.html">https://www.simpsonsarchive.com/news/tomacco.html</a>, See on <a href="https://news.ycombinator.com/item?id=36824856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <tbody><tr>
      <td>
        <br>
        <span face="Arial" size="5">Simpson Fan Grows Tomacco</span>
        <p>
        <span face="Arial" size="3"><b>Press Release - October 2003</b></span>

        </p><hr size="1" noshade="">


<b>To: KPTV 12 News<br>
Subject: Tomacco exists!</b><p>

I thought you might be interested in the following local story as a 10 O'clock news lead into 
this season's premier of The Simpsons.
</p><p>
I am a fan of Fox 12's The Simpsons, and episode # 1105 [<a href="#notes">1</a>] is my favorite.  Homer had exposed 
a variety of seeds to Plutonium and Tomacco was the only thing that grew.  A foul tasting tomato 
that made everyone addicted after one nasty bite.  I thought it sounded familiar and I found a 
1968 reprint [<a href="#notes">2</a>] of a 1959 Scientific American article where a scientist had grafted tomato 
tops to tobacco roots and gotten nicotine in the tomato plant since the tobacco root produces 
the nicotine.  
</p><p>
I have created live Tomacco here in Lake Oswego.  I grew tomato and tobacco from seed and grafted 
then together creating a tomato plant with tobacco roots.   The leaves and fruit of the tomato 
top should have nicotine in them.  I have moved the plant inside.  Fruit is now 1.7 inches in 
diameter.
</p><center>
<img src="https://www.simpsonsarchive.com/news/tomacco1.jpg" width="302" height="227" alt="">
</center>

<h4>How I created Tomacco:</h4>

I grew the tomato and tobacco plants side by side and cut both stems open and wrapped them together.  
The two plants fused and then I cut off the tomato root leaving the tomato plant dependent on the 
tobacco root for water, nutrients and nicotine!
<center>
<img src="https://www.simpsonsarchive.com/news/tomacco2.jpg" width="352" height="219" alt="">
</center>
<br>
I do not plan on tasting Tomacco since the fatal dose of nicotine is only 50 to 60 milligrams 
[<a href="#notes">3</a>].
<p>
I did an internet search and found no one else had grown Tomacco yet.  This is yet another 
connection between Portland and the Simpsons.
</p><p>
The fruit is red now and I plan on getting it tested for nicotine.  A local lab has offered 
to do the testing for free!   I am going to try to schedule the testing done this Friday, October 24th.
</p><p>
<b>Rob Baur</b><br>
Lake Oswego, OR</p><p>

<a name="notes">Footnotes:</a><br>
[1] <a href="http://www.thesimpsons.com/episode_guide/1105.htm">http://www.thesimpsons.com/episode_guide/1105.htm</a><br>
[2] Bio-Organic Chemistry 1968 pg. 170 ISBN 0-7167-0974-0<br>
[3] <a href="http://www.chemsoc.org/exemplarchem/entries/2002/hook/nicotine.htm">http://www.chemsoc.org/exemplarchem/entries/2002/hook/nicotine.htm</a></p><hr noshade="" size="1">
        <br>
        <center>
        
        <span size="1" face="MS Sans Serif,Geneva">
                [
                  <a href="https://www.simpsonsarchive.com/lists.html">FAQs, Guides &amp; Lists</a> |
                  <a href="https://www.simpsonsarchive.com/upcoming.html">Upcoming Episodes</a> |
                  <a href="https://www.simpsonsarchive.com/episodeguide.html">Episode Guide</a> |
                  <a href="https://www.simpsonsarchive.com/episodes.html">Capsules</a> |
                  <a href="https://www.simpsonsarchive.com/misc.html">Miscellaneous</a> |
                  <a href="https://www.simpsonsarchive.com/contacts.html">Web Links</a> |
                  <a href="https://www.simpsonsarchive.com/news.html">News</a> |
                  <a href="https://www.simpsonsarchive.com/about.html">About</a> |
                  <a href="https://www.simpsonsarchive.com/">Home</a> ]
        </span><span size="2" face="Arial">
        <p>
        Last updated on November 3, 2003 by <a href="mailto:webmaster@snpp.com">webmaster@snpp.com</a>
        </p></span></center>
      </td>
    </tr>
  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Octos – HTML live wallpaper engine (133 pts)]]></title>
            <link>https://github.com/underpig1/octos</link>
            <guid>36824595</guid>
            <pubDate>Sat, 22 Jul 2023 08:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/underpig1/octos">https://github.com/underpig1/octos</a>, See on <a href="https://news.ycombinator.com/item?id=36824595">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/tray.png"><img src="https://github.com/underpig1/octos/raw/master/img/tray.png" alt="Octos icon"></a></p>
<h2 tabindex="-1" dir="auto">Octos - HTML Live Wallpaper Engine</h2>
<p dir="auto">Create, distribute, and explore live, interactive wallpapers on Windows made with HTML, CSS, and JS.</p>
<p dir="auto"><a href="https://github.com/underpig1/octos/actions/workflows/ci.yml"><img src="https://github.com/underpig1/octos/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/underpig1/octos/actions/workflows/publish.yml"><img src="https://github.com/underpig1/octos/actions/workflows/publish.yml/badge.svg" alt="Publish"></a>
<a href="https://www.npmjs.com/package/octos" rel="nofollow"><img src="https://camo.githubusercontent.com/3ebd98b3b0b61ce884d7db9c7872c7d74393a1842c57140b4613b9eef5eb0e32/68747470733a2f2f62616467652e667572792e696f2f6a732f6f63746f732e737667" alt="NPM Package" data-canonical-src="https://badge.fury.io/js/octos.svg"></a></p>
<p dir="auto"><a href="https://github.com/underpig1/octos/releases">Download</a> | <a href="https://underpig1.github.io/octos/docs" rel="nofollow">Documentation</a> | <a href="https://underpig1.github.io/octos/docs/?t=installation" rel="nofollow">Quickstart</a> | <a href="https://underpig1.github.io/octos/docs/?t=using-the-api" rel="nofollow">API Docs</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/gallery/main.png"><img src="https://github.com/underpig1/octos/raw/master/img/gallery/main.png" alt="Octos GUI"></a></p>
<h2 tabindex="-1" dir="auto"><g-emoji alias="construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png">🚧</g-emoji> Pardon the mess: thanks for testing out Octos!</h2>
<p dir="auto">Octos is currently in an early stage of development. To help out, consider <a href="https://github.com/underpig1/octos/issues/new">submitting a feature request or reporting an issue</a>. And of course, if you have an awesome wallpaper you made that you want to share, consider <a href="https://underpig1.github.io/octos/docs/?t=publishing" rel="nofollow">publishing it</a> on the platform. As always, check out the <a href="https://underpig1.github.io/octos/docs/?t=installation" rel="nofollow">API docs</a> for resources and guides. Thanks!</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<blockquote>
<p dir="auto">Download the Octos app for Windows (under construction)</p>
</blockquote>
<p dir="auto">Visit <a href="https://github.com/underpig1/octos/releases">releases</a> to download the latest binaries.</p>
<p dir="auto">Note: your OS may give a Smartscreen warning. I haven't yet gotten around to certifying/signing the app. Right now, I just want to get your impressions and testing on the app, but in the next phase (soon) I'll be working on that as well as hopefully publishing to the Microsoft Store.</p>
<h2 tabindex="-1" dir="auto">Gallery</h2>
<p dir="auto">Here are some sample mods I threw together to demo the app's capabilities. All of them are available through the Octos app. <a href="https://underpig1.github.io/octos/docs/?t=publishing" rel="nofollow">Contribute your own...</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/gallery/ethereal.gif"><img src="https://github.com/underpig1/octos/raw/master/img/gallery/ethereal.gif" alt="Ethereal" width="600px" data-animated-image=""></a></p>
<h3 tabindex="-1" dir="auto">Ethereal</h3>
<p dir="auto">An interactive media player that ripples as your mouse passes over it.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/gallery/terminal.gif"><img src="https://github.com/underpig1/octos/raw/master/img/gallery/terminal.gif" alt="Terminal" width="600px" data-animated-image=""></a></p>
<h3 tabindex="-1" dir="auto">Terminal</h3>
<p dir="auto">A digital clock with a live old TV effect and customizable 3D text art.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/gallery/imgbg.gif"><img src="https://github.com/underpig1/octos/raw/master/img/gallery/imgbg.gif" alt="Image Background" width="600px" data-animated-image=""></a></p>
<h3 tabindex="-1" dir="auto">Image Background</h3>
<p dir="auto">Set your background to any image/gif/video and add widgets like a media controller, clock, and calender.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/underpig1/octos/blob/master/img/gallery/gradient.png"><img src="https://github.com/underpig1/octos/raw/master/img/gallery/gradient.png" alt="Gradient" width="600px"></a></p>
<h3 tabindex="-1" dir="auto">Gradient</h3>
<p dir="auto">A simple analog desktop clock with a calming color-changing gradient background.</p>
<h2 tabindex="-1" dir="auto">Octos Native API</h2>
<p dir="auto">Making your own live wallpaper is super easy with Octos' native API.</p>
<div dir="auto" data-snippet-clipboard-copy-content="<html>
    <body>
        <p>Now playing: <span id=&quot;song-title&quot;></span></p>
        <button onclick=&quot;nextTrack()&quot;>Next track</button>

        <script src=&quot;https://unpkg.com/octos@latest/octos.js&quot;></script>
        <script>
            const controller = new octos.MediaController();

            controller.on(&quot;track&quot;, (e) => {
                document.getElementById(&quot;song-title&quot;).innerText = e.title;
            });

            function nextTrack() {
                controller.nextTrack();
            }
        </script>
    </body>
</html>"><pre><span>&lt;</span><span>html</span><span>&gt;</span>
    <span>&lt;</span><span>body</span><span>&gt;</span>
        <span>&lt;</span><span>p</span><span>&gt;</span>Now playing: <span>&lt;</span><span>span</span> <span>id</span>="<span>song-title</span>"<span>&gt;</span><span>&lt;/</span><span>span</span><span>&gt;</span><span>&lt;/</span><span>p</span><span>&gt;</span>
        <span>&lt;</span><span>button</span> <span>onclick</span>="<span>nextTrack()</span>"<span>&gt;</span>Next track<span>&lt;/</span><span>button</span><span>&gt;</span>

        <span>&lt;</span><span>script</span> <span>src</span>="<span>https://unpkg.com/octos@latest/octos.js</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span>
        <span>&lt;</span><span>script</span><span>&gt;</span>
            <span>const</span> <span>controller</span> <span>=</span> <span>new</span> <span>octos</span><span>.</span><span>MediaController</span><span>(</span><span>)</span><span>;</span>

            <span>controller</span><span>.</span><span>on</span><span>(</span><span>"track"</span><span>,</span> <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"song-title"</span><span>)</span><span>.</span><span>innerText</span> <span>=</span> <span>e</span><span>.</span><span>title</span><span>;</span>
            <span>}</span><span>)</span><span>;</span>

            <span>function</span> <span>nextTrack</span><span>(</span><span>)</span> <span>{</span>
                <span>controller</span><span>.</span><span>nextTrack</span><span>(</span><span>)</span><span>;</span>
            <span>}</span>
        <span>&lt;/</span><span>script</span><span>&gt;</span>
    <span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span></pre></div>
<p dir="auto">Use the Octos API to:</p>
<ul dir="auto">
<li>Get playback info</li>
<li>Media/playback controls</li>
<li>Read and write to local storage</li>
<li>Access file system</li>
<li>Read and write user preferences</li>
<li>Access system information</li>
<li><a href="https://underpig1.github.io/octos/docs/?t=using-the-api" rel="nofollow">Learn more with the API Docs</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Share your Wallpaper</h2>
<p dir="auto">Once you make your own awesome wallpaper, share it for other people to download from the Octos explore page.</p>
<p dir="auto">See the <a href="https://underpig1.github.io/octos/docs/?t=publishing" rel="nofollow">publishing guide</a> for more details. Visit the <a href="https://github.com/underpig1/octos-community/tree/master">community library</a> to see more mods available for download.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plane – open-source Jira alternative (373 pts)]]></title>
            <link>https://plane.so</link>
            <guid>36824450</guid>
            <pubDate>Sat, 22 Jul 2023 08:21:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plane.so">https://plane.so</a>, See on <a href="https://news.ycombinator.com/item?id=36824450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>START SIMPLE</h2><p>Simple, yet great UX, so you can get started in minutes</p><p>Start as a basic task tracking tool. Customize your workflows, based on Backlog, Unstarted, Started, Completed issues, in just a few seconds, and view it as you like.</p><dl><div><p><span><dt>Visualize as you like.</dt> <dd>Switch between List, Kanban, or Calendar across any views within clicks.</dd></span></p></div><div><p><span><dt>Custom workflows.</dt> <dd>Define unique issue states for each team, and extend them the way you like.</dd></span></p></div><div><p><span><dt>Easy Importers.</dt> <dd>Import issues from your existing issue tracker into Plane in just couple of minutes. Coming soon for self-hosted.</dd></span></p></div></dl></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun v0.7.0 (189 pts)]]></title>
            <link>https://bun.sh/blog/bun-v0.7.0</link>
            <guid>36823723</guid>
            <pubDate>Sat, 22 Jul 2023 06:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.sh/blog/bun-v0.7.0">https://bun.sh/blog/bun-v0.7.0</a>, See on <a href="https://news.ycombinator.com/item?id=36823723">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>We're pleased to announce Bun v0.7.0, a big leap forward in terms of Node.js compatibility.</p><p>We're hiring C/C++ and Zig engineers to build the future of JavaScript! <a href="https://bun.sh/careers">Join our team →</a></p><p>Bun is an incredibly fast JavaScript runtime, bundler, transpiler, and package manager — all in one. Over the past couple months, we've been releasing a lot of changes to Bun recently, here's a recap in case you missed it:</p><ul><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.10</code></a> - <code>fs.watch()</code>, <code>bun install</code> bug fixes, <code>bun test</code> features, and improved CommonJS support</li><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.11</code></a> - Addressed a release build issue from <code>v0.6.10</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.12"><code>v0.6.12</code></a> - Sourcemap support in <code>Error.stack</code>, <code>Bun.file().exists()</code>, and Node.js bug fixes.</li><li><a href="https://bun.sh/blog/bun-v0.6.13"><code>v0.6.13</code></a> - Implemented mock <code>Date</code>, faster base64 encoding, and fixes for <code>WebSocket</code> and <code>node:tls</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.14"><code>v0.6.14</code></a> - <code>process.memoryUsage()</code>, <code>process.cpuUsage()</code>, <code>process.on('beforeExit', cb)</code>, <code>process.on('exit', cb)</code> and crash fixes</li></ul><p>To install Bun:</p><div id="RWUelGtIHM"><div><p>curl</p><div><pre><code><span><span>curl -fsSL https://bun.sh/install </span><span>|</span><span> bash</span></span></code></pre></div></div><div><p>docker</p><div><pre><code><span><span>docker run --rm --init --ulimit memlock=-1:-1 oven/bun</span></span></code></pre></div></div></div><p>To upgrade Bun:</p><h2 level="2" anchor-id="vite-support"><a name="vite-support"></a><a href="#vite-support">Vite support</a></h2><p><em>Support is still experimental and non-optimized.</em> Vite does not use Bun's bundler, module resolver, or transpiler, even when run with Bun.</p><p>With the recent strides towards Node.js API compatibilty, Bun can now run <a href="https://vitejs.dev/"><code>vite dev</code></a>, thanks to <a href="https://github.com/paperdave">@paperdave</a>! This is one of Bun's <a href="https://github.com/oven-sh/bun/issues/250">most upvoted issues</a>.</p><p>To try this with one of Vite's starter projects, use <code>bunx</code>:</p><p>Then start the dev server.</p><p><strong>Why <code>--bun</code>?</strong> The <code>--bun</code> flag tells Bun to override the <code>#! /usr/bin/env node</code> shebang in the <code>vite</code> CLI and execute the file with Bun instead of Node.js. In a future release this will be the default behavior.</p><figure><a href="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif"><img src="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif" caption="Hot module reloading with Vite"></a><figcaption>Hot module reloading with Vite</figcaption></figure><p>This is a great way to develop frontend code with Bun's APIs on the server when building frontend apps.</p><p>Note: if you run <code>bun vite dev</code> without <code>-b</code> or <code>--bun</code>, it will still run in Node.js as <code>vite</code>'s CLI specifies <code>#!/usr/bin/env node</code> at the top which tells Bun (and other software on your computer) to run it in Node.js.</p><h2 level="2" anchor-id="concurrency-with-worker"><a name="concurrency-with-worker"></a><a href="#concurrency-with-worker">Concurrency with <code>Worker</code></a></h2><p>Bun now supports <a href="https://developer.mozilla.org/en-US/docs/Web/API/Worker"><code>Worker</code></a> which allows you to run another JavaScript instance in a separate thread. In Bun, workers support ES Modules, CommonJS, TypeScript, JSX, and the rest of Bun's features with no extra configuration.</p><p>As in browsers, <code>Worker</code> is a global class. To create a worker from the main thread:</p><div><p>main.ts</p><div><pre><code><span><span>const</span><span> worker </span><span>=</span><span> </span><span>new</span><span> </span><span>Worker</span><span>(</span><span>"</span><span>./worker.ts</span><span>"</span><span>);</span></span>
<span><span>worker.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from worker:</span><span>"</span><span>, event.data);</span></span>
<span><span>});</span></span>
<span><span>worker.</span><span>postMessage</span><span>(</span><span>"</span><span>Hello from main thread!</span><span>"</span><span>);</span></span>
<span></span></code></pre></div></div><p>On the worker thread:</p><div><p>worker.ts</p><div><pre><code><span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from main thread:</span><span>"</span><span>, event.data);</span></span>
<span><span>  </span><span>postMessage</span><span>(</span><span>"</span><span>Hello from worker thread!</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span></span>
<span></span></code></pre></div></div><p>This release <em>does not</em> include support for the <code>node:worker_threads</code> module, but this unblocks the work necessary for us to implement it in Bun.</p><p>The following globals have been added to Bun:</p><ul><li><code>postMessage</code></li><li><code>addEventListener</code></li><li><code>removeEventListener</code></li><li><code>onmessage</code> (getter/setter)</li></ul><p>Refer to <a href="https://bun.sh/docs/api/workers">Docs &gt; API &gt; Workers</a> to learn more about using <code>Worker</code> in Bun.</p><h3 level="3" anchor-id="using-comlink-with-bun"><a name="using-comlink-with-bun"></a><a href="#using-comlink-with-bun">Using <code>comlink</code> with Bun</a></h3><p>The popular <a href="https://github.com/GoogleChromeLabs/comlink"><code>comlink</code></a> package works in Bun without changes. This library makes it easier to share functions and state between main and worker threads.</p><h3 level="3" anchor-id="structuredclone-support"><a name="structuredclone-support"></a><a href="#structuredclone-support"><code>structuredClone()</code> support</a></h3><p>As in browsers, <code>postMessage</code> serializes messages using the <em>structured clone algorithm</em>. Bun now exposes this via the Web-standard<a href="https://developer.mozilla.org/en-US/docs/Web/API/structuredClone"><code>structuredClone()</code></a> function, which provides a mechanism for deep-cloning objects. It is similar to <code>JSON.parse(JSON.stringify(obj))</code>, but it supports more types.</p><div><pre><code><span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>structuredClone</span><span>(obj);</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="asynclocalstorage-support"><a name="asynclocalstorage-support"></a><a href="#asynclocalstorage-support"><code>AsyncLocalStorage</code> support</a></h2><p>Bun now implements <code>AsyncLocalStorage</code> from the <code>node:async_hooks</code> module. This provides a mechanism for passing contextual data through a chain of asynchronous code. This is a big step towards supporting Next.js and other frameworks that rely on this module.</p><div><pre><code><span><span>import</span><span> { AsyncLocalStorage } </span><span>from</span><span> </span><span>"</span><span>node:async_hooks</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> requestId </span><span>=</span><span> </span><span>new</span><span> </span><span>AsyncLocalStorage</span><span>();</span></span>
<span><span>let</span><span> lastId </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span></span>
<span><span>Bun.</span><span>serve</span><span>({</span></span>
<span><span>  </span><span>fetch</span><span>(</span><span>request</span><span>) {</span></span>
<span><span>    lastId</span><span>++</span><span>;</span></span>
<span><span>    </span><span>// Run the callback with 'requestId' set. async_hooks will preserve</span></span>
<span><span>    </span><span>// this value through any chain of asynchronous code.</span></span>
<span><span>    </span><span>return</span><span> requestId.</span><span>run</span><span>(lastId, </span><span>async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>      console.</span><span>log</span><span>(</span><span>"</span><span>Request ID: ${requestId getStore ()}</span><span>"</span><span>);</span></span>
<span><span>      </span><span>await</span><span> Bun.</span><span>sleep</span><span>(</span><span>500</span><span>);</span></span>
<span><span>      </span><span>// Even if new requests mutate 'lastId', 'requestId' is still preserved.</span></span>
<span><span>      </span><span>return</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>Request ID: ${requestId. getStore ()}</span><span>"</span><span>);</span></span>
<span><span>    });</span></span>
<span><span>  },</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="reduce-memory-usage-with-bun-smol"><a name="reduce-memory-usage-with-bun-smol"></a><a href="#reduce-memory-usage-with-bun-smol">Reduce memory usage with <code>bun --smol</code></a></h2><p><code>bun --smol</code> is a new CLI flag which configures the JavaScriptCore heap size to be smaller and grow slower, at a cost to runtime performance. This is useful for running Bun in memory-constrained environments.</p><p>To avoid setting the flag manually, you can set this as a default in <code>bunfig.toml</code>.</p><div><p>bunfig.toml</p><div><pre><code><span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span>
<span><span>[</span><span>test</span><span>]</span></span>
<span><span># set it only for tests, if you want</span></span>
<span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span></code></pre></div></div><h2 level="2" anchor-id="bail-in-bun-test"><a name="bail-in-bun-test"></a><a href="#bail-in-bun-test"><code>--bail</code> in <code>bun test</code></a></h2><p>Running <code>bun test</code> with <code>--bail=1</code> will exit after the first test failure.</p><div><pre><code><span><span>bun test v0.7.0</span></span>
<span><span></span></span>
<span><span>✓ test1 [0.02ms]</span></span>
<span><span>test2.test.js:</span></span>
<span><span>1 | import {test, expect} from 'bun:test';</span></span>
<span><span>2 |</span></span>
<span><span>3 | test('test2', () =&gt; {</span></span>
<span><span>4 |   expect(2).toEqual(3);</span></span>
<span><span>      ^</span></span>
<span><span>error: expect(received).toEqual(expected)</span></span>
<span><span>Expected: 3</span></span>
<span><span>Received: 2</span></span>
<span><span>      at /Users/colinmcd94/Documents/bun/fun/test/test2.test.js:13:8</span></span>
<span><span>✗ test2 [0.18ms]</span></span>
<span><span>Ran 2 tests across 2 files. [8.00ms]</span></span>
<span><span>Bailed out after 1 failures</span></span></code></pre></div><p>This is useful for CI environments or when you want to stop running tests after the first failure. Thanks to <a href="https://github.com/TiranexDev">@TiranexDev</a> for landing this improvement!</p><h2 level="2" anchor-id="bun-readablestreamtoformdata"><a name="bun-readablestreamtoformdata"></a><a href="#bun-readablestreamtoformdata"><code>Bun.readableStreamToFormData()</code></a></h2><p>Bun now exposes a helper for converting a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream">ReadableStream</a> into <a href="https://developer.mozilla.org/en-US/docs/Web/API/FormData">FormData</a>.</p><p>It supports multipart form data.</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>// without dashes</span></span>
<span><span>const</span><span> boundary </span><span>=</span><span> </span><span>"</span><span>WebKitFormBoundary</span><span>"</span><span> </span><span>+</span><span> </span><span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>16</span><span>).</span><span>slice</span><span>(</span><span>2</span><span>);</span></span>
<span></span>
<span><span>const</span><span> myStream </span><span>=</span><span> </span><span>getStreamFromSomewhere</span><span>(); </span><span>// ...</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> Bun.</span><span>readableStreamToFormData</span><span>(stream, boundary);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>foo</span><span>"</span><span>); </span><span>// "bar"</span></span>
<span></span></code></pre></div><p>It also supports URL-encoded form data:</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> stream </span><span>=</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>hello=123</span><span>"</span><span>).body;</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> </span><span>readableStreamToFormData</span><span>(stream);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>hello</span><span>"</span><span>); </span><span>// "123"</span></span>
<span></span></code></pre></div><p>We added this to help fix a bug causing <code>request.formData()</code> and <code>response.formData()</code> to hang when the body was a <code>ReadableStream</code> from JavaScript.</p><h2 level="2" anchor-id="serialize-and-deserialize-in-bun-jsc"><a name="serialize-and-deserialize-in-bun-jsc"></a><a href="#serialize-and-deserialize-in-bun-jsc"><code>serialize</code> and <code>deserialize</code> in <code>bun:jsc</code></a></h2><p>The <code>bun:jsc</code> module now exports <code>serialize()</code> and <code>deserialize()</code>, which convert JavaScript objects to <code>ArrayBuffer</code> and back.</p><div><pre><code><span><span>import</span><span> { serialize, deserialize } </span><span>from</span><span> </span><span>"</span><span>bun:jsc</span><span>"</span><span>;</span></span>
<span><span>import</span><span> { deepEquals } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> buffer </span><span>=</span><span> </span><span>serialize</span><span>(obj);</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>deserialize</span><span>(buffer);</span></span>
<span></span>
<span><span>if</span><span> (</span><span>deepEquals</span><span>(obj, clone)) {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>They are equal!</span><span>"</span><span>);</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>The <code>node:v8</code> module exports these same functions, for compatibility with existing libraries that serialize/deserialize data between processes.</p><h2 level="2" anchor-id="websocket-improvements"><a name="websocket-improvements"></a><a href="#websocket-improvements"><code>WebSocket</code> improvements</a></h2><p>You can now manually send &amp; receive WebSocket <code>ping</code> and <code>pong</code> frames.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>pong</span><span>"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Received pong</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span><span>ws.</span><span>ping</span><span>();</span></span>
<span></span></code></pre></div><p>This applies to both <code>ServerWebSocket</code> and <code>WebSocket</code>.</p><h3 level="3" anchor-id="nodebuffer-is-now-the-default-binarytype"><a name="nodebuffer-is-now-the-default-binarytype"></a><a href="#nodebuffer-is-now-the-default-binarytype"><code>nodebuffer</code> is now the default <code>binaryType</code></a></h3><p>By default, the <code>binaryType</code> for <code>WebSocket</code> and <code>ServerWebSocket</code> in Bun is now <code>nodebuffer</code> This means that binary data frames in <code>WebSocket</code> will be <code>Buffer</code> instances, instead of <code>ArrayBuffer</code> (as before). This is to match the bahavior of the <code>ws</code> package.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(event.data </span><span>instanceof</span><span> </span><span>Buffer</span><span>); </span><span>// true</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>To change it back to <code>ArrayBuffer</code>, set <code>ws.binaryType = "arraybuffer"</code>.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.binaryType </span><span>=</span><span> </span><span>"</span><span>arraybuffer</span><span>"</span><span>;</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  event.data; </span><span>// ArrayBuffer</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>(Note that in browsers it is <code>Blob</code> by default.)</p><h3 level="3" anchor-id="close-reasons-propagate-correctly-now"><a name="close-reasons-propagate-correctly-now"></a><a href="#close-reasons-propagate-correctly-now">Close reasons propagate correctly now</a></h3><p>A bug was fixed where <code>WebSocket</code> would not propagate close reasons from third-party servers correctly. Thanks to <a href="https://github.com/electroid">@Electroid</a> for landing these improvements!</p><h2 level="2" anchor-id="node-js-compatibility-improvements"><a name="node-js-compatibility-improvements"></a><a href="#node-js-compatibility-improvements">Node.js compatibility improvements</a></h2><p>This release adds several additional improvements to Node.js compatibility.</p><h3 level="3" anchor-id="improvements-to-tlssocket-from-node-tls"><a name="improvements-to-tlssocket-from-node-tls"></a><a href="#improvements-to-tlssocket-from-node-tls">Improvements to <code>TLSSocket</code> from <code>node:tls</code></a></h3><p>The following methods were implemented on the <code>TLSSocket</code> class. Thanks to <a href="https://github.com/cirospaciari">@cirospaciari</a> for landing these improvements in <a href="https://github.com/oven-sh/bun/pull/3596"><code>#3596</code></a>.</p><ul><li><code>.getPeerFinished()</code></li><li><code>.getFinished()</code></li><li><code>.getProtocol()</code></li><li><code>.getSharedSigalgs()</code></li><li><code>.isSessionReused()</code></li><li><code>.exportKeyingMaterial()</code></li><li><code>.setMaxSendFragment()</code></li><li><code>.getPeerCertificate()</code></li><li><code>.getCertificate()</code></li><li><code>.enableTrace()</code></li><li><code>.disableRenegotiation()</code></li><li><code>.getCipher()</code></li><li><code>.getEphemeralKeyInfo()</code></li><li><code>.getTLSTicket()</code></li><li><code>.getSession()</code></li><li><code>.setSession()</code></li></ul><h3 level="3" anchor-id="base64url-hashes-are-no-longer-data-urls"><a name="base64url-hashes-are-no-longer-data-urls"></a><a href="#base64url-hashes-are-no-longer-data-urls"><code>base64url</code> hashes are no longer <code>data:</code> urls</a></h3><p>Previously, Bun would prepend <code>data:base64,</code> to the output of <code>crypto.createHash("sha256").digest("base64url")</code>. This is not what Node.js does, and it was causing issues with libraries that expected the output to be the same string as Node.js.</p><div><pre><code><span><span>crypto.</span><span>createHash</span><span>(</span><span>"</span><span>sha256</span><span>"</span><span>).</span><span>update</span><span>(</span><span>"</span><span>abc</span><span>"</span><span>).</span><span>digest</span><span>(</span><span>"</span><span>base64url</span><span>"</span><span>);</span></span>
<span></span>
<span><span>//        Node.js:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>//     Bun v0.7.0:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>// &lt;= Bun v0.6.14:  "data:base64,ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0="</span></span>
<span></span></code></pre></div><h3 level="3" anchor-id="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"><a name="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"></a><a href="#terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows">Terminal dimensions with <code>process.stdout.columns</code> and <code>process.stdout.rows</code></a></h3><p><code>process.stdout</code> and <code>process.stderr</code> now support reading the terminal window's dimensions.</p><div><pre><code><span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stdout;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stdout.</span><span>getWindowSize</span><span>();</span></span>
<span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stderr;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stderr.</span><span>getWindowSize</span><span>();</span></span>
<span></span></code></pre></div><p>You can also use <code>process.stdout.getWindowSize()</code> if you want both dimensions at once.</p><h2 level="2" anchor-id="bugfixes"><a name="bugfixes"></a><a href="#bugfixes">Bugfixes</a></h2><p><a href="https://github.com/oven-sh/bun/pull/3656"><code>#3656</code></a> <strong>A memory leak</strong> in await <code>new Response(latin1String).arrayBuffer()</code> and <code>await Response.json(obj).json()</code> has been fixed.</p><p>After:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)    </span><span>12.9</span><span> µs</span><span>/</span><span>iter</span><span>      (</span><span>625</span><span> ns … </span><span>4.18</span><span> ms)      </span><span>1</span><span> µs </span><span>567.17</span><span> µs </span><span>711.79</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>12.85</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.67</span><span> µs … </span><span>1.56</span><span> ms)   </span><span>2.17</span><span> µs </span><span>462.75</span><span> µs </span><span>621.13</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.53</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>6.21</span><span> µs … </span><span>7.07</span><span> µs)   </span><span>6.64</span><span> µs   </span><span>7.07</span><span> µs   </span><span>7.07</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>49</span><span> MB</span></span>
<span></span></code></pre></div><p>Before:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)   </span><span>13.51</span><span> µs</span><span>/</span><span>iter</span><span>       (</span><span>541</span><span> ns … </span><span>3.2</span><span> ms)   </span><span>1.92</span><span> µs </span><span>553.42</span><span> µs </span><span>709.92</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>13.07</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.71</span><span> µs … </span><span>3.43</span><span> ms)   </span><span>2.13</span><span> µs </span><span>451.21</span><span> µs </span><span>651.67</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.25</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>5.79</span><span> µs … </span><span>6.81</span><span> µs)    </span><span>6.4</span><span> µs   </span><span>6.81</span><span> µs   </span><span>6.81</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>292</span><span> MB</span></span>
<span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/issues/3659"><code>#3659</code></a> A <strong>module resolution bug</strong> causing the <code>graphql</code> package to import both CommonJS and ESM versions of the same modules has been fixed. This was fixed by aligning the package.json main field order closer to what Node.js does.</p><div><pre><code><span><span>error: Cannot use GraphQLScalarType "String" from another module or realm.</span></span>
<span><span></span></span>
<span><span>Ensure that there is only one instance of "graphql" in the node_modules</span></span>
<span><span>directory. If different versions of "graphql" are the dependencies of other</span></span>
<span><span>relied on modules, use "resolutions" to ensure only one version is installed.</span></span>
<span><span></span></span>
<span><span>https://yarnpkg.com/en/docs/selective-version-resolutions</span></span>
<span><span></span></span>
<span><span>Duplicate "graphql" modules cannot be used at the same time since different</span></span>
<span><span>versions may have different capabilities and behavior. The data from one</span></span>
<span><span>version used in the function from another could produce confusing and</span></span>
<span><span>spurious results.</span></span>
<span><span></span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/pull/3663"><code>#3663</code></a> A <strong>bug in bun:test lifecycle hooks</strong> caused <code>beforeAll</code> and <code>afterAll</code> to not run when no tests were defined in a scope. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3670"><code>#3670</code></a> A <strong>bug when .env pointed to a directory</strong> caused Bun to crash. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3682"><code>#3682</code></a> A <strong>TypeScript parser bug related to ternaries with spread operators</strong> has been fixed</p><h3 level="3" anchor-id="changelog"><a name="changelog"></a><a href="#changelog">Changelog</a></h3><div><table><thead></thead><tbody><tr><td><a href="https://github.com/oven-sh/bun/pull/3253">#3253</a></td><td>feat(bun/test): Implement "bail" option for "bun test" by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3608">#3608</a></td><td>Improve our internal typedefs by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3257">#3257</a></td><td>Improvements to <code>WebSocket</code> and <code>ServerWebSocket</code> by @Electroid</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3630">#3630</a></td><td>$npm_lifecycle_event should have the value of the last call by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3631">#3631</a></td><td>Update docs/types for process by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3637">#3637</a></td><td>structured clone by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3650">#3650</a></td><td>docs: add one missing line in typescript.md by @capaj</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3643">#3643</a></td><td>Fixes #3641 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3614">#3614</a></td><td>Support <code>napi_wrap</code> in constructors by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3645">#3645</a></td><td>Implement Workers by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3654">#3654</a></td><td>Fixes base64url encoding for crypto by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3655">#3655</a></td><td>20% faster <code>deserialize</code> for structuredClone / postMessage with objects by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3626">#3626</a></td><td>workaround <code>readable-stream</code> compatibility by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3662">#3662</a></td><td>[install] handle duplicated workspace declarations gracefully by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3664">#3664</a></td><td>package json <code>main</code> field extension order by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3596">#3596</a></td><td>[tls] General compatibility improvements by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3667">#3667</a></td><td>zig upgrade by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3671">#3671</a></td><td>fix(tls) patch checkServerIdentity by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3672">#3672</a></td><td>feature(constants) add constants/node:constants module and tests(prisma) use prima 5.0.0 + use same connection for postgres, add prisma mssql (disabled for now) by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3678">#3678</a></td><td>Better error for workspace dependency not found by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3683">#3683</a></td><td>move constants module to cpp by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3687">#3687</a></td><td>fix #3682 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3680">#3680</a></td><td>fix createDecipheriv by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3688">#3688</a></td><td>update root certificates and add tls.rootCertificates by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3089">#3089</a></td><td>Implement <code>AsyncLocalStorage</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3693">#3693</a></td><td>Fix browser bundled string_decoder by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3694">#3694</a></td><td>Fix vite by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3698">#3698</a></td><td>Fixes #3670 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3697">#3697</a></td><td>Support streams in response.formData() &amp; request.formData, introduce Bun.readableStreamToFormData() by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3706">#3706</a></td><td>Improve types for FFI number types by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3707">#3707</a></td><td>fix start delay on Worker by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3709">#3709</a></td><td>set <code>_preload_modules</code> to empty array by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3708">#3708</a></td><td>fix 3702 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3692">#3692</a></td><td>Pass constructor arguments to TextDecoder by @Parzival-3141</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3711">#3711</a></td><td>Fix builtins generator <code>$lazy</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3710">#3710</a></td><td>fix directory caching with workaround by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3713">#3713</a></td><td>Fix builtins again by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3714">#3714</a></td><td>fix process.exit status code handling by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3715">#3715</a></td><td>fix <code>isFIFO</code> by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3717">#3717</a></td><td>string escape edgecase by @dylan-conway</td></tr></tbody></table></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Putting the “You” in CPU (297 pts)]]></title>
            <link>https://cpu.land/</link>
            <guid>36823605</guid>
            <pubDate>Sat, 22 Jul 2023 05:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cpu.land/">https://cpu.land/</a>, See on <a href="https://news.ycombinator.com/item?id=36823605">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2 id="from-the-beginning">
				From the beginning…
				<a href="https://github.com/hackclub/putting-the-you-in-cpu/tree/main/src/content/chapters/0-intro.mdx" target="_blank">Edit on GitHub</a>
			</h2>

			<p>I’ve done <a href="https://github.com/kognise" rel="noopener noreferrer" target="_blank">a lot of things with computers</a>, but I’ve always had a gap in my knowledge: what exactly happens when you run a program on your computer? I thought about this gap — I had most of the requisite low-level knowledge, but I was struggling to piece everything together. Are programs really executing directly on the CPU, or is something else going on? I’ve used syscalls, but how do they <em>work</em>? What are they, really? How do multiple programs run at the same time?</p><p>I cracked and started figuring as much out as possible. There aren’t many comprehensive systems resources if you aren’t going to college, so I had to sift through tons of different sources of varying quality and sometimes conflicting information. A couple weeks of research and almost 40 pages of notes later, I think I have a much better idea of how computers work from startup to program execution. I would’ve killed for one solid article explaining what I learned, so I’m writing the article that I wished I had.</p><p>And you know what they say… you only truly understand something if you can explain it to someone else.</p><blockquote><p>In a hurry? Feel like you know this stuff already?</p><p><a href="https://cpu.land/how-to-run-a-program">Read chapter 3</a> and I guarantee you will learn something new. Unless you’re like, Linus Torvalds himself.</p></blockquote>

			<p><a href="https://cpu.land/the-basics">
				Continue to Chapter 1: The “Basics”
				
			</a>
		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple's interactive television box: Hacking the set top box System 7.1 in ROM (200 pts)]]></title>
            <link>http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html</link>
            <guid>36823565</guid>
            <pubDate>Sat, 22 Jul 2023 05:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html">http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-7628653847015489091" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgT5ldv1fTGlQrFwP9YvESyKNAoqxHlTII0uFm4NYQRJ8gvKaGvGh0Y-2mgZNL9w-TNhZFhb77W_OvZDlmPvrRHmvLf4xlIUXLH7BbsJuOEtCPRKP3-6T3W6rUgrGEo7FDsFNujaetgxrK0BHIovLKHTwsW6njPPheMKDQFNUAv33t3jrMOxvq3HO8Ez8U/s4080/PXL_20230709_004451960.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgT5ldv1fTGlQrFwP9YvESyKNAoqxHlTII0uFm4NYQRJ8gvKaGvGh0Y-2mgZNL9w-TNhZFhb77W_OvZDlmPvrRHmvLf4xlIUXLH7BbsJuOEtCPRKP3-6T3W6rUgrGEo7FDsFNujaetgxrK0BHIovLKHTwsW6njPPheMKDQFNUAv33t3jrMOxvq3HO8Ez8U/s320/PXL_20230709_004451960.jpg"></a></p><p>

One of the coolest things to come along in the 68K Mac homebrew community is the ROM Boot Disk concept. Classic Macs have an unusually large ROM that contains a fair bit of the Mac OS, which was true even in the G3 New World Mac era (it was just on disk), so it's somewhat surprising that only one Mac officially could boot the Mac OS entirely from ROM, namely the Macintosh Classic (hold down Cmd-Option-X-O to boot from a hidden HFS volume with System 6.0.3). For many Macs that can take a ROM SIMM, you can <a href="http://synack.net/~bbraun/macromboot.html">embed a ROM volume</a> in the Mac ROM that can even be mirrored to a RAM disk. You can even <a href="http://www.bigmessowires.com/mac-rom-inator-ii/">buy them pre-populated</a>. How's <em>that</em> for immutability?
</p><p>
Well, it turns out Apple themselves were the first ones to implement a flashable Mac OS ROM volume in 1994, but hardly anyone noticed — because it was only ever used publicly in a minority subset of one of the most unusual of the Macintosh-derived systems, the Apple Interactive Television Box (a/k/a AITB or the Apple Set Top Box/STB). And that's what we're going to dig into — and reprogram! — today.
</p><p>
<a name="more"></a>
The AITB/STB was Apple's attempt to get into the early set-top box market of the 1990s. The dominance of the Apple TV today is a late phenomenon; Apple was in no position to launch such a product on their own in that era, though with the recent introduction of their QuickTime multimedia framework in 1991, they were a strong candidate for a technology partner. Apple forged an alliance with Oracle and parallel computing vendor nCube (Larry Ellison then being its single biggest stockholder), with Apple developing the front end client box and nCube boxes running Oracle Media Server handling the back end. All of this was to occur using MPEG-1 video with QuickTime as the playback system, specifically selected because of MPEG-1's bitrate of 1.5Mbit/sec and enough to run over <a href="http://oldvcr.blogspot.com/2022/05/so-long-home-t1-line-hello-hacking-t1.html">a T1/E1 line</a>. Plus, hardware decoders for the format already existed, meaning the device wouldn't have to rely on the CPU for smooth playback.
</p><p>
Apple developed the STBs in their Austin, Texas campus. It was based on stripped-down 1993 Quadra 605 hardware with extra silicon for the media features but kept serial, ADB and SCSI connections to allow it to run compatible CD-ROMs, sort of a Pippin before the Pippin, with plans to sell it for $750 [2023 dollars about $1500]. You could even hook up a printer to the serial port, but no storage was onboard: this device was to strictly boot from a central network link — in this case a T1/E1 — or from CD. Units first emerged publicly at the National Association of Broadcasters Show in Las Vegas in April 1995. There were at least two major hardware versions, STB1 and STB3 (no STB2s are known), with the STB3 being the most "common."
</p><p>
Apple partnered with cable TV companies for content delivery and AITBs were part of at least several trial deployments across the United States and Europe (most notably British Telecom), and Disney even used it briefly in at least one theme park. However, there were concerns about providing enough licensed and on-demand content, and while customers might buy that content, they tended to compensate by cutting subscriptions to the premium channels that the cable companies relied on as a regular income stream. The situation wasn't much better as a retail product given that home broadband was in its infancy and the product market was already too small for a boutique system. On top of that, the $300,000 [in 2023 over $600,000!] official development system (consisting of an nCube MediaCUBE server, 8 AITBs and 10GB of storage) made the already rarefied product thoroughly unattractive to developers, and with DOCSIS on the horizon wiring up T1 lines everywhere just didn't seem to pay off. Apple never ended up launching the hardware for retail sale, the existing trials were terminated, and most of the boxes were ultimately recalled and destroyed.
</p><p>
But, like all failed experiments, not all of them disappeared and various units have made their way into the hands of collectors and hackers. Over the years I've acquired two STB3 systems myself, one a non-working "production" model and the other a mostly functional DVT prototype. This prototype is not FCC-approved but is fundamentally identical to the "production" M4120 unit, so we'll be discussing mostly the prototype here since it works and is in much better shape. Here it is:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIZ95zeC9Bpz_wst7Jbp6FjJBHpbooJbr6pKcbpCRQjprz4vxt8yiOcrjOHVBFpSivbyHDQdPiY949VPdCNMTT_fTQc8M-QBr8d3_8ylZs_SKHPMteVNAArtSvUhw3vDYN3xQ5rcCkRVhTGmJkS4SaJaK9UoiCZba9_imv0kZqAUa-0-Z3dSEgcGg2M_g/s4080/PXL_20230709_003206578.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIZ95zeC9Bpz_wst7Jbp6FjJBHpbooJbr6pKcbpCRQjprz4vxt8yiOcrjOHVBFpSivbyHDQdPiY949VPdCNMTT_fTQc8M-QBr8d3_8ylZs_SKHPMteVNAArtSvUhw3vDYN3xQ5rcCkRVhTGmJkS4SaJaK9UoiCZba9_imv0kZqAUa-0-Z3dSEgcGg2M_g/s320/PXL_20230709_003206578.jpg"></a></p><p>

The STB3 shipped in a fairly dramatic black case with a top lid. It was designed to fit into any typical home entertainment centre and will support the weight of a typical CRT television.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTRMFQKF0pmUDYNAm0myOiQwPvl3wqRbe9tmba1nx-Briy8FRsaTBYRUR40xFfcRcyojAg9MgXynQeoiiwRdRBX92xXzI5YjQocwd9i54rFgUw3UZsGywWhrNI5LAkCevlDXE53GBqHgNFBK1m7FeK-p0skf8RsveBV8xoGsspRVyXDKRBtsyo3sY2_YM/s4080/PXL_20230709_003314972.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTRMFQKF0pmUDYNAm0myOiQwPvl3wqRbe9tmba1nx-Briy8FRsaTBYRUR40xFfcRcyojAg9MgXynQeoiiwRdRBX92xXzI5YjQocwd9i54rFgUw3UZsGywWhrNI5LAkCevlDXE53GBqHgNFBK1m7FeK-p0skf8RsveBV8xoGsspRVyXDKRBtsyo3sY2_YM/s320/PXL_20230709_003314972.jpg"></a></p><p>

The only front control was a power button. Depending on the installed ROM, the power LED might show any or no colour at all. We'll talk about that a little later. Under the Apple logo was an IR sensor for which I lack <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#/media/File:Applestb-2-3_small-23938_0.jpg">the official remote control</a>. (That's okay because it turns out we don't actually need it to hack it.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9TP-hNTksN-BhBcDH-llXtSIFtDhM3f7p9OCl3XX6tc2HF13QhKrV_ICC9uyu0NUEOTjNYoqVh2QAG4Wc9WqDhmVgfyry4nB7Wfupu5gOQ-4PykR_tc5ixBDPpnCAcoWvDPzymG3Tcpst4OmNFNQHlL5iWjGISw-ih8j2Jlrb6U3WYz5SXt32oMd21ug/s4080/PXL_20230709_003451706.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9TP-hNTksN-BhBcDH-llXtSIFtDhM3f7p9OCl3XX6tc2HF13QhKrV_ICC9uyu0NUEOTjNYoqVh2QAG4Wc9WqDhmVgfyry4nB7Wfupu5gOQ-4PykR_tc5ixBDPpnCAcoWvDPzymG3Tcpst4OmNFNQHlL5iWjGISw-ih8j2Jlrb6U3WYz5SXt32oMd21ug/s320/PXL_20230709_003451706.jpg"></a></p><p>

The rear ports. Standard, the STB3 came with connectors for power (using a regular LC power supply), SCSI (using the Apple HDI-30 connector), SCART TV and VCR (both blocked), RF in/out from an antenna or cable TV connection, 8P8C network (but not Ethernet: this is for a T1/E1), standard Mac Mini-DIN serial, Mac S-video out, composite video, and stereo phono audio. A rubber grommet covers the Kensington lock slot, which I imagine was used in the hotel deployments. On the side, not visible here, is a single ADB port which only officially supports a mouse.
</p><p>
The BT version of these systems (labeled with BT branding as a "Interactive TV System Voyager 2000") reportedly used an ADSL connection, though I've never seen such a unit personally.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTRREUvu0cy51XdH1aMLWXtD2RO4q79tAg1xqivpH0nUl9XiVV8G5QaQrzy0g9uBB298zFHJZF9AFI-lO36SbjJjpyuUWbXbQifviZaq44yfUaWpJWA3dn4NLQBFVALuZ_LkmQYk-EV_A35h8AsIxhTVYTPoeILQZUVXYoLLiUV7QEEd4f6Hs73ieAbTE/s4080/PXL_20230709_003507630.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTRREUvu0cy51XdH1aMLWXtD2RO4q79tAg1xqivpH0nUl9XiVV8G5QaQrzy0g9uBB298zFHJZF9AFI-lO36SbjJjpyuUWbXbQifviZaq44yfUaWpJWA3dn4NLQBFVALuZ_LkmQYk-EV_A35h8AsIxhTVYTPoeILQZUVXYoLLiUV7QEEd4f6Hs73ieAbTE/s320/PXL_20230709_003507630.jpg"></a></p><p>

But what this unit also has, and most STBs don't, is a developer video card with a Mac DA-15 connector. Sadly, I've never been able to get it to work. More below when we open the case.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi55I5avhed3rjQgSrTq1JHXvUQRPBij2hGebQhfZBAxbeDm4cExbWeyoyW1GMcU_p_aHZLrqUUMEMPAlsnP4sZkjuT9C1w7tRP_kmowvyDq4WzkBlRv8PI76sHDdOFyHBSo9XXCqu-y9N8VBtNMqsOvxKaQpAKF-k89t32T74-8YXvCpg71m03bl8_pLc/s4080/PXL_20230709_003615470~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi55I5avhed3rjQgSrTq1JHXvUQRPBij2hGebQhfZBAxbeDm4cExbWeyoyW1GMcU_p_aHZLrqUUMEMPAlsnP4sZkjuT9C1w7tRP_kmowvyDq4WzkBlRv8PI76sHDdOFyHBSo9XXCqu-y9N8VBtNMqsOvxKaQpAKF-k89t32T74-8YXvCpg71m03bl8_pLc/s320/PXL_20230709_003615470~2.jpg"></a></p><p>

On the underside is this disclaimer that the unit is not FCC-approved. This unit is clearly further along than an EVT prototype <a href="http://oldvcr.blogspot.com/2021/10/shiner-esb-apple-network-server.html">like our "Shiner ESB" Apple Network Server prototype</a>, but because it's not FCC approved it's probably not a PVT, so therefore I'm concluding it's a DVT <a href="http://oldvcr.blogspot.com/2023/06/new-ram-card-prototype-mac-portable.html">like our Macintosh Portable prototype</a>. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_U1RpMX2qAF0ooA_BfaqlW4-RCFB8Ddas3ZJlpirKHi6lQAdCuRcFVyuPDMC0wKGu27VcMWHToP51L0gybLQNQPHpF_ieSDJFKvkh-JOQJoqiBW6rtHmZDBVQ-EwRSfd2wOwq3SJhCwZtTzdKMUltGiyt3vkRzC_VcNbpesVLe69hWEXdX_gbaQiJ3iU/s4080/PXL_20230709_003715628~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_U1RpMX2qAF0ooA_BfaqlW4-RCFB8Ddas3ZJlpirKHi6lQAdCuRcFVyuPDMC0wKGu27VcMWHToP51L0gybLQNQPHpF_ieSDJFKvkh-JOQJoqiBW6rtHmZDBVQ-EwRSfd2wOwq3SJhCwZtTzdKMUltGiyt3vkRzC_VcNbpesVLe69hWEXdX_gbaQiJ3iU/s320/PXL_20230709_003715628~2.jpg"></a></p><p>

Removing the top lid (there's a screw you may need to remove from the back), we see the video card, the mainboard and the power supply, which is a regular Q605 supply except with a black frame around the power port (the Q605/LC475 supply is in Apple Platinum beige). Although there is a spot where a cooling fan could go, there is neither mounting nor a power connector for one in both my units. The little three solder points next to it are where one can be installed, and some units exist where a fan is present.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbRpIrtyRW2ZehmoMYfI2EtpKyA_HMIiVBBPR6b68QCOAbtOH5tEMNg_ntM5yFbk5PMafN9-VNnMo70MCwgSjqE1fldVAVwY7lw54pAvl_mHpZVaua-1R3DXpovg61H1-zKRU8ziy95qTHMaR6R-oXyUTPwQ9AiXkZ_HCNUpL_JTiB8eGEnehobdMzEi8/s4080/PXL_20230709_004316413.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbRpIrtyRW2ZehmoMYfI2EtpKyA_HMIiVBBPR6b68QCOAbtOH5tEMNg_ntM5yFbk5PMafN9-VNnMo70MCwgSjqE1fldVAVwY7lw54pAvl_mHpZVaua-1R3DXpovg61H1-zKRU8ziy95qTHMaR6R-oXyUTPwQ9AiXkZ_HCNUpL_JTiB8eGEnehobdMzEi8/s320/PXL_20230709_004316413.jpg"></a></p><p>

The CPU, like the Quadra 605, is a 25MHz 68LC040. Other chips visible here are an Apple 343S0138-A (fabbed by TI) handling the PDS slot, an Apple 34320164-b (VLSI) MEMCjr memory controller, a TI TMXE320AV110 that appears to be an audio DSP, an NCR 53C96 SCSI controller, a Zilog Z8530 SCC for the serial port, and a Philips SAA7188A digital YUV to NTSC/PAL encoder (earlier Philips chips appear in the AV Macs). The RAM and ROM SIMMs are next to that, along with 4MB of RAM soldered to the board.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUlN7v1dVzPcuWN-32LnCxp9tHw0wh_XQnSs02wAo9TM_bQIDJdYkobQzhiEY2vmq1mjKpm5UvT3fkntpSslaZ8RYkl50_sETAdjHYGnixGu5YSJrR2V6Wv0LsQJA6q0N11B9kSdvoi9h7pGzNWaMjxe1bP-kiVywaulgUV3qrSlKumWSL8KHqDRvsMaQ/s4080/PXL_20230709_004055555.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUlN7v1dVzPcuWN-32LnCxp9tHw0wh_XQnSs02wAo9TM_bQIDJdYkobQzhiEY2vmq1mjKpm5UvT3fkntpSslaZ8RYkl50_sETAdjHYGnixGu5YSJrR2V6Wv0LsQJA6q0N11B9kSdvoi9h7pGzNWaMjxe1bP-kiVywaulgUV3qrSlKumWSL8KHqDRvsMaQ/s320/PXL_20230709_004055555.jpg"></a></p><p>

In front, red lines go to the power switch and LED, blue lines to the IR sensor, and white lines to the side-mounted ADB port.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-3je5X16YlzzgFNQiFTkxtbERfgkjZ3HWhcjTFlSYgUdKEo2X6YQdnbFx_eCp2MEGYo1yaFWa-HYbPwZts2vjb3NIC4S0SrfFtnjfhBeozaJ7QcnctOhE-KyfInHLXr1vyNQMeH2rnPTJyJiZ4dcCZGW17kdo6nJOL7s5-ShDtu4jy-lwdWV_IUjZF_4/s4080/PXL_20230709_003928910~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-3je5X16YlzzgFNQiFTkxtbERfgkjZ3HWhcjTFlSYgUdKEo2X6YQdnbFx_eCp2MEGYo1yaFWa-HYbPwZts2vjb3NIC4S0SrfFtnjfhBeozaJ7QcnctOhE-KyfInHLXr1vyNQMeH2rnPTJyJiZ4dcCZGW17kdo6nJOL7s5-ShDtu4jy-lwdWV_IUjZF_4/s320/PXL_20230709_003928910~2.jpg"></a></p><p>

And inside the front, just next to the red lines, is the board copyright (1995) and number (820-0638-01, which would be a prototype board designation).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW7dYb_EPZyMaNdjPWlczKCrQjySlY-nQuiRnS3gKudh9BCusz3E1RfJFWTjlmqp6v2I0oZG1R_ev-pXIfaAijn5GxDyqz-n71j_QIjsKk7p72hr_f_krhAqobA_K47VzZI6VTEDY35UaJ78hpEEjClA7jWs_NIXyc_mCR82hnZKUbpCbmWBIerOi1jiE/s4080/PXL_20230709_003741943.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW7dYb_EPZyMaNdjPWlczKCrQjySlY-nQuiRnS3gKudh9BCusz3E1RfJFWTjlmqp6v2I0oZG1R_ev-pXIfaAijn5GxDyqz-n71j_QIjsKk7p72hr_f_krhAqobA_K47VzZI6VTEDY35UaJ78hpEEjClA7jWs_NIXyc_mCR82hnZKUbpCbmWBIerOi1jiE/s320/PXL_20230709_003741943.jpg"></a></p><p>

The board has a single PDS slot, occupied in the prototype by a video card which connects with a 90-degree adapter. This card is a simple 2D framebuffer with four 256Kx8 VRAMs to equal 1MB on board. Very few of these cards existed and seem to have only been part of developer machines.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyeOSuBpDHPhuh8x6XCMg9euneOlzeEg_9EoXM_1vNK9TsHrSiaVSCoB_GvChJaegtkrQkJC-xnHboL4clrJqApd5Pku_ap53ljBBaBole-NlO7lYE7s7Yz9mzETcjSd1QvAiqkFMZ4O1bird8QG0cN1K76GlWvUz4Mini1AL3WTVtPr0hsgYFThy464/s4080/PXL_20230709_003754651~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyeOSuBpDHPhuh8x6XCMg9euneOlzeEg_9EoXM_1vNK9TsHrSiaVSCoB_GvChJaegtkrQkJC-xnHboL4clrJqApd5Pku_ap53ljBBaBole-NlO7lYE7s7Yz9mzETcjSd1QvAiqkFMZ4O1bird8QG0cN1K76GlWvUz4Mini1AL3WTVtPr0hsgYFThy464/s320/PXL_20230709_003754651~2.jpg"></a></p><p>

The card identifies itself as a Micro Conversions X62SC01 (Revision A), which resembles the Micro Conversions 1724PD graphics card for the LC III and Performa 630. If there existed a driver specifically for this card, it must have been on whatever developer-bootable disk this unit didn't come with. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiCu5x2uBMX99H2xHVvOBOC9kyVjEnSA792712fYjmBvceBmiRc6ZWCdgmmPajESaWJ8oCh6fj0uJd-SC8bB4ee9AiLiiWBl6iAxC-H3NdfHQSRZE9Col1cJHkKE--LfDjaRm-WugBh-4BZX4zC-iCAkK8AuozM_HBgI7UF7U-p4EUpoPMX_0syNADno4/s4080/PXL_20230709_005752133.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiCu5x2uBMX99H2xHVvOBOC9kyVjEnSA792712fYjmBvceBmiRc6ZWCdgmmPajESaWJ8oCh6fj0uJd-SC8bB4ee9AiLiiWBl6iAxC-H3NdfHQSRZE9Col1cJHkKE--LfDjaRm-WugBh-4BZX4zC-iCAkK8AuozM_HBgI7UF7U-p4EUpoPMX_0syNADno4/s320/PXL_20230709_005752133.jpg"></a></p><p>

Pulling the card out of my working STB was a no-go; it's pretty much there for keeps (not interested in trying to pry it out lest I damage the card, the board, or both). Instead, we'll fill in the gap by switching here to the non-working "production" model, which unfortunately was improperly stored and suffered from oxidation damage. The chip with the white sticker is a socketed DIP ROM labeled "A3N(LS) C/SUM 519D8 95@@" which appears in other NTSC STB3s. The MPEG decoder is conveniently marked, a C-Cube Microsystems CL450-P160, the same one Apple used earlier with their <a href="https://wiki.preterhuman.net/Apple_MPEG_Media_System">MPEG Media System</a> card. Next to that is an Xilinx FPGA that likely serves as support video hardware.
</p><p>
The other marked chip, with green oxidation damage around the pins, is a Brooktree Bt8069 T1 transceiver. Other than the Zilog SCC the Bt8069 is the only networking chip obviously on the board; in particular, no Ethernet chips are visible. If the British Telecom units were truly ADSL, it would have had to have a different chip here or some sort of external transceiver box: even in situations where the T1 line is provisioned over DSL, that's usually <em>H</em>DSL, and the technologies are otherwise not interchangeable.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitI5lW1lkjFtmNsXGy7mCLOK-ITjsbO_rP0EisgRadMfXyJuSLBAOlnH2Ei1-gqR6TsLsOHgcPDWSpg92GpFv_5pH3JiXR0r0jdhLJdASwa7Yy421JqNvegmgCjomaMlRHUSHo-SGQZUE9h1nH6-0_h6_BPycF_FGe5tWVZzKT9sXfAfkgTgGgAmBNPuU/s4080/PXL_20230709_005558757~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitI5lW1lkjFtmNsXGy7mCLOK-ITjsbO_rP0EisgRadMfXyJuSLBAOlnH2Ei1-gqR6TsLsOHgcPDWSpg92GpFv_5pH3JiXR0r0jdhLJdASwa7Yy421JqNvegmgCjomaMlRHUSHo-SGQZUE9h1nH6-0_h6_BPycF_FGe5tWVZzKT9sXfAfkgTgGgAmBNPuU/s320/PXL_20230709_005558757~2.jpg"></a></p><p>

This unit is labeled as production and has an FCC ID and clearance sticker identifying it as a model M4120 (but with no formal name). This unit came from my hometown of San Diego County, California, based on the asset tag from The Lightspan Partnership, Inc. Lightspan Partnership, later just Lightspan, was founded in 1993 to develop edutainment software and produced a line of school-oriented Sony PlayStation titles which were sold to districts for classroom use. However, the original concept was to distribute the software via cable television so that students and parents could use it at home. This unit was obviously part of that initial, unrealized initiative. In 2003 Lightspan merged with PLATO Learning, Inc. (now Edmentum), one of the inheritors of the <a href="https://arstechnica.com/gadgets/2023/03/plato-how-an-educational-computer-system-from-the-60s-shaped-the-future/">Control Data PLATO legacy</a>, and subsequently ceased to exist.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZBzCEBrOKoQO0gDMcBCUq4CdepuzIG_mopk1Dy5iqOaXCMXnyxFekc7ynWOlwt_I7lNfpbnbgQ5fVh6KGN-njY1haZDHXMVc3oarJxRCzxbR2UkfMba447S9yFUkrEkSy1Thj4RTDq20YUDQLpqyUlaXE_8VQWnYyZ6W6vv4BQl9LWBrwhl5Z7uHJVpc/s4080/PXL_20230709_005931032~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZBzCEBrOKoQO0gDMcBCUq4CdepuzIG_mopk1Dy5iqOaXCMXnyxFekc7ynWOlwt_I7lNfpbnbgQ5fVh6KGN-njY1haZDHXMVc3oarJxRCzxbR2UkfMba447S9yFUkrEkSy1Thj4RTDq20YUDQLpqyUlaXE_8VQWnYyZ6W6vv4BQl9LWBrwhl5Z7uHJVpc/s320/PXL_20230709_005931032~2.jpg"></a></p><p>

But despite being labeled as a production, FCC-certified unit, it still has the same prototype motherboard code as the DVT unit.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBbysjkWCQtleUXAXloYwx_CPwNnWmBY4lnhz2hiNSxrsBw1Fzk75bTZPJzpTzwMdygyr-jjKcngjKRIZVJPCsuPWZ-TClH0lEzln6O98w3JFLlcuXMyBVDoUHIbztGZiD119CIWnoHlhCukUw01iz20XZK5_MORV5HY2ECcUEWiZmf3bx6DEnKsQQV4U/s4080/PXL_20230709_003842420.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBbysjkWCQtleUXAXloYwx_CPwNnWmBY4lnhz2hiNSxrsBw1Fzk75bTZPJzpTzwMdygyr-jjKcngjKRIZVJPCsuPWZ-TClH0lEzln6O98w3JFLlcuXMyBVDoUHIbztGZiD119CIWnoHlhCukUw01iz20XZK5_MORV5HY2ECcUEWiZmf3bx6DEnKsQQV4U/s320/PXL_20230709_003842420.jpg"></a></p><p>

Let's go back to the RAM and ROM for a second. There is a RAM slot here and you can put extra RAM into it, same as you would with a regular Q605, but the ROM's the more interesting part.
</p><p>
No, I'm not talking about these green mask ROMs that most owners of an STB3 have:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoKGMcfQsMFxby3zDQDSn0HxNIEyKk8G7PSB1i1tzjrfI7A1JF0Qpjc6Q9pjL08pRDFX0Vg5AAuyic6Ab22d_GmIIbGB-t0JwErhDhjm-E-mvVst1piB707mGtW6JjQuVCMYqDBkdgELhvdSUlF7w0-OknJMZe-d7oThG-QC-Ej-HsQ2pWsVH6PFLT9A/s4080/PXL_20230706_012249967.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoKGMcfQsMFxby3zDQDSn0HxNIEyKk8G7PSB1i1tzjrfI7A1JF0Qpjc6Q9pjL08pRDFX0Vg5AAuyic6Ab22d_GmIIbGB-t0JwErhDhjm-E-mvVst1piB707mGtW6JjQuVCMYqDBkdgELhvdSUlF7w0-OknJMZe-d7oThG-QC-Ej-HsQ2pWsVH6PFLT9A/s320/PXL_20230706_012249967.jpg"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1lgi3HJyTRqY6gQIfuaIHBKZxMgneZeEldT6eMdQmnmzQZunLaV_LpvtZ-nMNGTXbojHb4d1rDWqr_YPQ62QgnSM8Ky9rEAqEz3Xk4pUv_mRmm0JrjVsEva7SCqejjdjS-aYHhgLFoR-tpfxWtoiIfRFgG33YXFKwNLE_0gpVQ3V9bLwX6NDRIQA-y6A/s4080/PXL_20230706_012350250.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1lgi3HJyTRqY6gQIfuaIHBKZxMgneZeEldT6eMdQmnmzQZunLaV_LpvtZ-nMNGTXbojHb4d1rDWqr_YPQ62QgnSM8Ky9rEAqEz3Xk4pUv_mRmm0JrjVsEva7SCqejjdjS-aYHhgLFoR-tpfxWtoiIfRFgG33YXFKwNLE_0gpVQ3V9bLwX6NDRIQA-y6A/s320/PXL_20230706_012350250.jpg"></a></p><p>

If you dump one (I have two which are the same), you'll get a ROM checksum (</p><tt>$ff7439ee</tt><p>, SHA-1 </p><tt>1d833125adf553a50f5994746c2c01aa5a1dbbf2</tt><p>) exactly identical to the Quadra 605, which isn't surprising because the STB is derived from it. With a Q605 ROM installed, these units won't display a picture but they will let you boot over SCSI. Add something like Farallon/Netopia Timbuktu and a LocalTalk connection and you can remotely use one over the network from another classic Mac. Not too useful, but hey, they're stylish and rare, and it's great fun at parties (I'm told, I'm never invited to those sorts of parties).
</p><p>
Unfortunately, my unit, though it would initially boot from a BlueSCSI, one day suddenly decided it wouldn't. I've never been able to get it to boot from any SCSI device since, no matter what keys are held down, Option, Cmd-Option-Shift-Delete, dead chicken burnt offering, nothing. The unit otherwise works normally which leads me to suspect a fuse somewhere and/or the SCSI controller. (Don't kneejerk and say bad caps. I will hurt you.)
</p><p>
That brings us to <em>this</em> ROM.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmBZI_T5VRmpjgPQeZz_y9QkhNgeuQkWzEbZKippjHhD64Yo7_A7B3njHUyHGdf79Z3M1JMQjAGLsmnYRNd_oU-H6kUH_HG3WZUy2bJF2n36LjSiN1W5HQ1Y7YeOgdWEFvC1l57yEGCX-9l3gDtZOruEk85wa9vSLxTMPRVMTjuuFpfiMn5zItYh-OdJc/s4080/PXL_20230706_012023599.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmBZI_T5VRmpjgPQeZz_y9QkhNgeuQkWzEbZKippjHhD64Yo7_A7B3njHUyHGdf79Z3M1JMQjAGLsmnYRNd_oU-H6kUH_HG3WZUy2bJF2n36LjSiN1W5HQ1Y7YeOgdWEFvC1l57yEGCX-9l3gDtZOruEk85wa9vSLxTMPRVMTjuuFpfiMn5zItYh-OdJc/s320/PXL_20230706_012023599.jpg"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgWenRFMs0VFZsd8ghQpnC5e3SIm__VBAEDo_zrWzNoGAhChyCBwIz6qnVrkGnHvTTa8VIczcCaPFnZYI_swQ6hAAstr7IXQGOSpo9WKuojU3vDnSGpN4Ex_7Ua0kHu_5iPU1Ok6Y5IXh0ubjaZqAOyxsvQRYqHZKQ0aG9dSExhga_S2OJrnk0myi_FjPc/s4080/PXL_20230706_012041156.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgWenRFMs0VFZsd8ghQpnC5e3SIm__VBAEDo_zrWzNoGAhChyCBwIz6qnVrkGnHvTTa8VIczcCaPFnZYI_swQ6hAAstr7IXQGOSpo9WKuojU3vDnSGpN4Ex_7Ua0kHu_5iPU1Ok6Y5IXh0ubjaZqAOyxsvQRYqHZKQ0aG9dSExhga_S2OJrnk0myi_FjPc/s320/PXL_20230706_012041156.jpg"></a></p><p>

This red ROM stick, labeled AP1654-01, has four 256K flash chips front and back to equal 2MB. Notice the silkscreened name "RLC FLASH SIMM." These appear to have been made initially for the RISC LC, the famous and heavily modified LC-based development prototype that emulated a 68K Mac with full compatibility and became the direct ancestor of the Power Macintosh.
</p><p>
There are <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#/media/File:Post-2085-0-12713200-1421865679.jpg">many versions</a> of this ROM, and this one is not labeled like most of the others in that linked image. However, I have no reason to suspect this particular one behaves much differently from the others.
</p><p>
The red ROM's biggest difference from the green ROM in that the TV outputs are enabled. When you switch on (with the back power switch) an STB3 with the red ROM, after a pause of a few seconds the LED over the power button lights red, and then shortly after yellow. In the <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box_Setup_Guide">Setup Guide</a>, this indicates POST, followed by standby. This is very different from units with a Q605 ROM in which the LED never lights and the machine instead starts from the ADB power key, like any other Mac of this era would normally.
</p><p>  
Pressing the power button when the LED is yellow turns the LED green and this image appears on a connected composite or S-video display, captured on my INOGENI box:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZQNNU7QZCxPJQmdL8u-OoHW62gAEuHiH8WkwgAE77kaXxScSfbILat4PBWYpeOAGLSua-D7JlW-9g_h_vjhnvjKu1EyRY17m8sRPCa6Igofd_7tIXNTEdye2XkPOGncjRzxXWoPdzE43KdFN61IAQq0Ud5kBK54X7Hgkakhs9-JUU-JTg3Opgf_tGHVw/s1400/vlcsnap-2023-07-05-18h45m37s975.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZQNNU7QZCxPJQmdL8u-OoHW62gAEuHiH8WkwgAE77kaXxScSfbILat4PBWYpeOAGLSua-D7JlW-9g_h_vjhnvjKu1EyRY17m8sRPCa6Igofd_7tIXNTEdye2XkPOGncjRzxXWoPdzE43KdFN61IAQq0Ud5kBK54X7Hgkakhs9-JUU-JTg3Opgf_tGHVw/s320/vlcsnap-2023-07-05-18h45m37s975.png"></a></p><p>

But, invariably, 30 seconds-ish later, you get this:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjl5TiGKoVXYy-_3fE1rLsEONnN5k05NWxwFnmMugouanonw1NCenO8dW1o4CJlYxUemOhaF029_9XvFJzCdWDMuQ-0aeSh0gHoAqaLpaFF3f1yPaJ5kf-cBZbC3Tq-0MBNYdv6Gqm7O0UyCg1mSKQDNvW84yFYMw-K8q83ing1Gxgqul20Wd95HmfOOh8/s1400/vlcsnap-2023-07-05-18h46m08s434.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjl5TiGKoVXYy-_3fE1rLsEONnN5k05NWxwFnmMugouanonw1NCenO8dW1o4CJlYxUemOhaF029_9XvFJzCdWDMuQ-0aeSh0gHoAqaLpaFF3f1yPaJ5kf-cBZbC3Tq-0MBNYdv6Gqm7O0UyCg1mSKQDNvW84yFYMw-K8q83ing1Gxgqul20Wd95HmfOOh8/s320/vlcsnap-2023-07-05-18h46m08s434.png"></a></p><p>

indicating an expected response from the server never arrived. I don't know what the green button on the remote does (the manual simply says to "see the interactive service provider's instructions" for the four colour buttons). I connected speakers to the audio out but the unit makes no sound.
</p><p>
I don't know which human-readable version of the ROM this is, but we can dump it:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgspjwVenvpQVJcrOSy9-l3ozVHvKARXEWwtwRtSsP5qGKttOAzfyxT_1ElSCX5wujF3ejFIQpABxzwfFWB33dovaLAzUALV8gwnKd4Gd1aX-zOpoUxgLEVxpKfPRXKRwrVZXAB7wRDJAk757D3ddOZEwBRfFIFZL0J3bUHUywEOoj8uktud7C4VhWkjFM/s4080/PXL_20230706_013701726.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgspjwVenvpQVJcrOSy9-l3ozVHvKARXEWwtwRtSsP5qGKttOAzfyxT_1ElSCX5wujF3ejFIQpABxzwfFWB33dovaLAzUALV8gwnKd4Gd1aX-zOpoUxgLEVxpKfPRXKRwrVZXAB7wRDJAk757D3ddOZEwBRfFIFZL0J3bUHUywEOoj8uktud7C4VhWkjFM/s320/PXL_20230706_013701726.jpg"></a></p><p>

The best tool for this purpose is of course Doug Brown's <a href="https://www.downtowndougbrown.com/programmable-mac-rom-simms/">flash SIMM programmer</a>, which can both read these ROM SIMMs (used in many 68K Macs) and write to replacement flash ROM sticks. The 2MB dump we get has a checksum of </p><tt>$b7025504</tt><p> (the first four bytes as a 32-bit big-endian unsigned integer), a version word of </p><tt>$077d</tt><p> (i.e., 1917, bytes eight and nine as a 16-bit big-endian unsigned short), and a SHA-1 of </p><tt>911eaafc5ccfe6823a7be61d44aaf0a63d081118</tt><p>. What we're going to do with this dump is based on this particular ROM version. The rest of this article may or may not fully apply to other versions and of course you follow along with your real device at your own risk.
</p><p>
The first step with any dump is see what <a href="https://github.com/ReFirmLabs/binwalk"><tt>binwalk</tt></a> makes of it, and other than copyright messages, it finds a couple surprising things are present. Nine, to be exact.
</p><div><pre>% binwalk RED.rom

DECIMAL       HEXADECIMAL     DESCRIPTION
--------------------------------------------------------------------------------
941976        0xE5F98         Copyright string: "Copyright C-Cube Microsystems 1992"
1090813       0x10A4FD        Copyright string: "Copyright 1990-91 Apple Computer Inc. Copyright 1981 Linotype AG Copyright 1990-91 Type Solutions Inc.1.0"
1090851       0x10A523        Copyright string: "Copyright 1981 Linotype AG Copyright 1990-91 Type Solutions Inc.1.0"
1090878       0x10A53E        Copyright string: "Copyright 1990-91 Type Solutions Inc.1.0"
1844352       0x1C2480        JPEG image data, JFIF standard 1.01
1846358       0x1C2C56        JPEG image data, JFIF standard 1.01
1848250       0x1C33BA        JPEG image data, JFIF standard 1.01
1849933       0x1C3A4D        JPEG image data, JFIF standard 1.01
1851587       0x1C40C3        JPEG image data, JFIF standard 1.01
1853288       0x1C4768        JPEG image data, JFIF standard 1.01
1855867       0x1C517B        JPEG image data, JFIF standard 1.01
1857571       0x1C5823        JPEG image data, JFIF standard 1.01
1859146       0x1C5E4A        JPEG image data, JFIF standard 1.01
1871674       0x1C8F3A        Copyright string: "Copyright 1987-1991"
</pre></div>
<p>
The copyrights reference fonts, but also C-Cube, the manufacturer of the MPEG decoder. It also finds nine JPEG images:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4sNYPow2ybQ0P8ozChGowiiU4vkiem0E_digzZZCODCRBW7iB12EjYJuPOk1p4DQJRLIIKDHJuHqM-kXQv4dOeMPSUw88h7tcP0Eh0BrZ4IBvppjZ4C-xRIqZxNgQKdux2yDMTMj1HVj9-zjkbG4xY4VwYixfZGlMSRAMU8UB0r8OzAk3mUxDnuEYWjU/s864/stbbunchc.jpg"><img alt="" width="320" data-original-height="624" data-original-width="864" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4sNYPow2ybQ0P8ozChGowiiU4vkiem0E_digzZZCODCRBW7iB12EjYJuPOk1p4DQJRLIIKDHJuHqM-kXQv4dOeMPSUw88h7tcP0Eh0BrZ4IBvppjZ4C-xRIqZxNgQKdux2yDMTMj1HVj9-zjkbG4xY4VwYixfZGlMSRAMU8UB0r8OzAk3mUxDnuEYWjU/s320/stbbunchc.jpg"></a></p><p>

These are obviously pictures of the development team. Do you recognize any of them? Are <em>you</em> any of them?
</p><p>
Naturally, with nine pictures, you <em>know</em> what we have to do.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrmbuP_zpI2z4cr9BIvSbQ96HdOBDZfl87m8ZD1SiajarCUvCkFXgSMoTIwBakJR1_sAk968xblsWwvbBo0I4_Xb9vx5if5n7glkCr9MrIt0AB48Fn3LRKLqHlXPz3qz332BToAWNm6HEgfX9o3gVsun5IxaIE_wVQMNkhHGaZ1vXgx1QaOEfIKJLl7dw/s864/stbbunch.jpg"><img alt="" width="320" data-original-height="624" data-original-width="864" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrmbuP_zpI2z4cr9BIvSbQ96HdOBDZfl87m8ZD1SiajarCUvCkFXgSMoTIwBakJR1_sAk968xblsWwvbBo0I4_Xb9vx5if5n7glkCr9MrIt0AB48Fn3LRKLqHlXPz3qz332BToAWNm6HEgfX9o3gVsun5IxaIE_wVQMNkhHGaZ1vXgx1QaOEfIKJLl7dw/s320/stbbunch.jpg"></a></p><p>

More relevantly, though, now that we have a ROM dump we've just <em>got</em> to hack it. Since it's displaying a message, let's see if we can modify the message as a small proof of concept. </p><tt>strings</tt><p>, that always useful tool, shows that the "Sorry!" message appears in two places. Modifying the first one is sufficient:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYt8m-nsip9bekcmIMyFm6o6_OPGtMlgxE4R8sC8I0I1qQJcev4wHWKaSS7nEgcF6k3HBqaqprdBSvz_upUP1O4okVuIs9NQm96J8iJ1fevCQM6eUKAa72m_TYctmsCh5JZjRIBoLzzS4_mI9VgqGFR7B2qliH7mrhOcMF0J3iGEmUr2uix9zl1B5bKT4/s829/firsthack.png"><img alt="" height="320" data-original-height="829" data-original-width="741" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYt8m-nsip9bekcmIMyFm6o6_OPGtMlgxE4R8sC8I0I1qQJcev4wHWKaSS7nEgcF6k3HBqaqprdBSvz_upUP1O4okVuIs9NQm96J8iJ1fevCQM6eUKAa72m_TYctmsCh5JZjRIBoLzzS4_mI9VgqGFR7B2qliH7mrhOcMF0J3iGEmUr2uix9zl1B5bKT4/s320/firsthack.png"></a></p><p>

This will change the checksum of the ROM, which is computed as the sum of all the 16-bit big endian shorts from byte 4 onward and truncated to 32 bits. The tools I wrote up to handle all this are in <a href="https://github.com/classilla/stbtools">this Github project</a>. Use </p><a href="https://github.com/classilla/stbtools/blob/main/checksum.pl"><tt>checksum.pl</tt></a><p> to recompute the ROM checksum and then use the hex editor to edit the first four bytes to match.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbRxAXFDqgIzCZOMyXflYM7cDavcldVZ7qoGeL5S4jFKSzb011J-7T7Y5dSPGI1NkdtQ4JtIYWrh1a9NJ5PUGeW-hq722aW8xDBAECsgw3aMvcMqwzq1I64QdylGLHh3SVByIu43DaJnfUFwcYn0d38WBULCD943A9-hnLG-Vf6CrpJfAkQBm9oNP0s_0/s4080/PXL_20230712_210136841.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbRxAXFDqgIzCZOMyXflYM7cDavcldVZ7qoGeL5S4jFKSzb011J-7T7Y5dSPGI1NkdtQ4JtIYWrh1a9NJ5PUGeW-hq722aW8xDBAECsgw3aMvcMqwzq1I64QdylGLHh3SVByIu43DaJnfUFwcYn0d38WBULCD943A9-hnLG-Vf6CrpJfAkQBm9oNP0s_0/s320/PXL_20230712_210136841.jpg"></a></p><p>

Then get yourself a couple 2MB flash ROMs SIMMs. They must be exactly 2MB in size; larger ROMs won't work even if you "echo" the bytes. I used the 2MB <a href="http://www.bigmessowires.com/mac-rom-inator-ii/">ROM-inator II from Big Mess O'Wires</a> but <a href="https://ko-fi.com/caymacvintage/shop">CayMac's 2MB ROM</a> should also do the job; CayMac also sells new SIMM programmers (I am not affiliated with BMOW or CayMac).
</p><p>
Burn the ROM in your programmer <a href="https://github.com/dougg3/mac-rom-simm-programmer">using the SIMM programmer tool</a>, make sure your STB3 is off, and install it in the ROM SIMM slot near the RAM slot. On the programmer, the SIMM skull and crossbones should face the skull and crossbones on the circuitboard; on the STB, the SIMM skull and crossbones should face the RAM. Connect up some sort of composite monitor and switch it on.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2e7HhSAZB9z6i_KgAF8NAkqZSdAvclAVb_E-JNbzTuqAfLY5hVEiozGASWEPiCSi3yNu_vFN3tln1LIjwuUNivoO4Ynqy4v1OiTPwTV63OJa8fm7XGKvo2GGtW41ioNVnNNmoYWLhwJZ_4TZfl1GJ8vSDjhkbPrQlOWUP2m6d2IABpWT7gR94G5y83jM/s1400/vlcsnap-2023-07-12-13h57m41s443.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2e7HhSAZB9z6i_KgAF8NAkqZSdAvclAVb_E-JNbzTuqAfLY5hVEiozGASWEPiCSi3yNu_vFN3tln1LIjwuUNivoO4Ynqy4v1OiTPwTV63OJa8fm7XGKvo2GGtW41ioNVnNNmoYWLhwJZ_4TZfl1GJ8vSDjhkbPrQlOWUP2m6d2IABpWT7gR94G5y83jM/s320/vlcsnap-2023-07-12-13h57m41s443.png"></a></p><p>

Our plea for help duly appears. This simple demonstration proves that the only thing we need to do to modify the ROM is update the checksum; nothing else on the board appears to check it. It's now time to figure out what's there and how it's organized.
</p><p>
Many Apple ROMs are segmented <a href="https://preterhuman.net/macstuff/techpubs/mac/MoreToolbox/MoreToolbox-106.html#HEADING106-0">into discrete resources</a>, which are functionally equivalent with on-disk HFS resources attached to files, and can be accessed from the Toolbox in the same fashion. For example, here's the header of the (unused, disabled and not implemented) <tt>.netBOOT</tt> driver resource in the green Quadra 605 ROM:
</p><div><pre>00051c80  18 00 00 00 00 00 00 00  00 0e dc 70 00 05 1c b0  |...........p....|
00051c90  44 52 56 52 00 31 58 08  2e 6e 65 74 42 4f 4f 54  |DRVR.1X..netBOOT|
00051ca0  00 00 00 00 c0 a0 00 00  00 00 08 80 00 00 03 04  |................|
</pre></div>
<p>
We can scan the red ROM dump for similar resource headers. Starting at offset <tt>$0000</tt>, the first big-endian 32-bit word is always the ROM checksum and the second is the starting address for the boot code (technically the first sets the stack pointer, but the ROM glosses over this). We page through opaque binary data awhile until we start seeing structured patterns every so often. The first one of these patterns we get to is this.
</p><div><pre>000ac210  78 00 00 00 00 00 00 00  00 00 00 00 00 0a b3 70  |x..............p|
000ac220  62 6f 6f 74 00 03 58 04  4d 61 69 6e 6b 63 6b 63  |boot..X.Mainkckc|
000ac230  4b 75 72 74 c0 a0 00 00  00 00 07 6a 00 00 00 64  |Kurt.......j...d|
</pre></div>
<p>
This is our first ROM resource, <tt>boot#3</tt>, named <tt>MainkckcKurt</tt> (much like the string <tt>Gary</tt>, presumably <a href="https://apple.fandom.com/wiki/Gary_Davidian">Gary Davidian</a>, shows up a lot in Mac ROMs, the name <tt>Kurt</tt> is all over this one — from the "kc" bit I'm guessing <a href="https://www.linkedin.com/in/kurt-clark-529444">Kurt Clark</a>, who was an Apple senior firmware and system software engineer at the time of the AITB's development). The hex byte <tt>78</tt> indicates an enabled, live resource.
</p><p>
The ROM resources in the red ROM are stored somewhat back to front with the "header" actually serving as a footer; the resource runs from the fourth word (here <tt>$000ab370</tt>) to the beginning of the footer. How do we know it's laid out like that? Because of what we find a little later on:
</p><div><pre>000ac980  70 73 6c 74 00 14 70 73  6c 74 00 1a 73 6e 64 20  |pslt..pslt..snd |
000ac990  00 01 77 65 64 67 e9 81  77 65 64 67 e9 80 6b 63  |..wedg..wedg..kc|
000ac9a0  78 00 00 00 00 00 00 00  00 0a c2 10 00 0a c2 40  |x..............@|
000ac9b0  72 6f 76 6d 00 00 58 00  6b 63 6b 63 6b 63 6b 63  |rovm..X.kckckckc|
000ac9c0  4b 75 72 74 c0 a0 00 00  00 08 70 0c 00 00 00 6c  |Kurt......p....l|
000ac9d0  4c 4b 60 00 00 86 44 18  00 00 06 53 79 73 74 65  |LK`...D....Syste|
000ac9e0  6d 00 00 00 00 00 00 00  00 00 06 46 69 6e 64 65  |m..........Finde|
000ac9f0  72 00 00 00 00 00 00 00  00 00 07 4d 61 63 73 42  |r..........MacsB|
000aca00  75 67 00 00 00 00 00 00  00 00 0c 44 69 73 61 73  |ug.........Disas|
000aca10  73 65 6d 62 6c 65 72 00  00 00 0d 53 74 61 72 74  |sembler....Start|
000aca20  55 70 53 63 72 65 65 6e  00 00 06 46 69 6e 64 65  |UpScreen...Finde|
000aca30  72 00 00 00 00 00 00 00  00 00 09 43 6c 69 70 62  |r..........Clipb|
000aca40  6f 61 72 64 00 00 00 00  00 00 00 0a 00 14 00 00  |oard............|
</pre></div>
<p>
The characters <tt>LK</tt> herald HFS boot blocks. Yes, friends, there's an embedded disk image here, and it's doubtful the resource code <tt>rovm</tt> is used to reference it.
</p><p>
There are many fun strings in that disk image:
</p><div><pre>000af1d0  46 72 65 64 54 56 aa 0d  0d 42 72 6f 75 67 68 74  |FredTV...Brought|
000af1e0  20 74 6f 20 79 6f 75 20  62 79 20 46 72 65 64 20  | to you by Fred |
000af1f0  48 75 78 68 61 6d 20 61  6e 64 20 46 72 65 64 20  |Huxham and Fred |
000af200  4d 6f 6e 72 6f 65 2e 0d  0d a9 20 41 70 70 6c 65  |Monroe.... Apple|
000af210  20 43 6f 6d 70 75 74 65  72 2c 20 49 6e 63 2e 20  | Computer, Inc. |
000af220  31 39 39 33 0d 41 6c 6c  20 52 69 67 68 74 73 20  |1993.All Rights |
000af230  52 65 73 65 72 76 65 64  2e 0d 81 e2 20 30 01 60  |Reserved.... 0.`|
</pre></div>
<p>
Although it was known that the AITB ROM had portions of System 7.1, this red ROM actually seems to contain an entire, self-contained, miniature bootable image. There's no reason to have the string <tt>Welcome to Macintosh.</tt> unless a working System file were part of it:
</p><div><pre>000b2930  1a 00 6c 00 c0 57 65 6c  63 6f 6d 65 20 74 6f 20  |..l..Welcome to |
000b2940  4d 61 63 69 6e 74 6f 73  68 2e 00 b1 7a 00 18 00  |Macintosh...z...|
000b2950  7e 00 c0 44 65 62 75 67  67 65 72 20 69 6e 73 74  |~..Debugger inst|
000b2960  61 6c 6c 65 64 2e 00 b1  77 00 14 00 7e 00 c0 45  |alled...w...~..E|
000b2970  78 74 65 6e 73 69 6f 6e  73 20 6f 66 66 2e 00 b1  |xtensions off...|
000b2980  79 00 ca 00 5e 00 72 54  68 69 73 20 73 74 61 72  |y...^.rThis star|
000b2990  74 75 70 20 64 69 73 6b  20 77 69 6c 6c 20 6e 6f  |tup disk will no|
000b29a0  74 20 77 6f 72 6b 20 6f  6e 20 74 68 69 73 20 4d  |t work on this M|
000b29b0  61 63 69 6e 74 6f 73 68  2f 6d 6f 64 65 6c 2e 20  |acintosh/model. |
[...]
000b3e50  6d 21 40 2d 04 42 af 06  04 00 00 00 55 54 4d 61  |m!@-.B......UTMa|
000b3e60  63 69 6e 74 6f 73 68 20  53 79 73 74 65 6d 20 76  |cintosh System v|
000b3e70  65 72 73 69 6f 6e 20 37  2e 31 0d 0d 0d a9 20 41  |ersion 7.1.... A|
000b3e80  70 70 6c 65 20 43 6f 6d  70 75 74 65 72 2c 20 49  |pple Computer, I|
000b3e90  6e 63 2e 20 31 39 38 33  2d 31 39 39 32 0d 41 6c  |nc. 1983-1992.Al|
000b3ea0  6c 20 72 69 67 68 74 73  20 72 65 73 65 72 76 65  |l rights reserve|
000b3eb0  64 2e 00 00 01 f5 a8 9f  65 72 00 12 09 01 00 00  |d.......er......|
</pre></div>
<p>
Eventually we come to its footer, which now enables us to extract it.
</p><div><pre>001339d0  78 00 00 00 00 00 00 00  00 0a c9 a0 00 0a c9 d0  |x...............|
001339e0  64 69 73 6b 00 00 58 00  6b 63 6b 63 6b 63 6b 63  |disk..X.kckckckc|
001339f0  4b 75 72 74 c0 a0 00 00  00 00 07 50 00 00 00 74  |Kurt.......P...t|
</pre></div>
<p>
It's a <tt>disk</tt>, resource #0. That sounds more likely as a type code. If you look at the third and fourth 32-bit words (big-endian, again, as G-d intended), you'll find it links back to the last footer at <tt>$000ac9a0</tt> (the <tt>rovm</tt> resource), allowing us to scan the file by walking back references, and the address <tt>$000ac9d0</tt> is where we found the boot block, so that must be the starting address for this resource. That means <tt>disk#0</tt> occupies <tt>$000ac9d0</tt> to the beginning of the footer at <tt>$001339d0</tt>.
</p><p>
If this is a bootable Mac OS System 7 image, it should act like it. And, to my delight, it does. The manual says nothing about connecting an ADB keyboard to it, only a mouse, but ADB keyboards work fine. If you hold down the SHIFT key while turning the rear power switch on and waiting for it to turn yellow, you'll lose the Apple background when you power on from the front, exactly as if an extension didn't load.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglpqRWGzWyMNbo_4QZLm1sdSM6ySTqUHbz4-DpQZDZgLI5qKf7WEgaluUOQLYXGgu6kOkzweNbdrVUvlnStpGd6HOJzV3cWAZGfDP_x6JnHyA_iZOHOmXOHIKOKw5hN6kRQEX6lCgWzeiD4oSy-LRT4C3PsE7Eq-EirStt443Q8X_zUPC15riAD4NzdrM/s1400/vlcsnap-2023-07-11-20h43m06s983.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglpqRWGzWyMNbo_4QZLm1sdSM6ySTqUHbz4-DpQZDZgLI5qKf7WEgaluUOQLYXGgu6kOkzweNbdrVUvlnStpGd6HOJzV3cWAZGfDP_x6JnHyA_iZOHOmXOHIKOKw5hN6kRQEX6lCgWzeiD4oSy-LRT4C3PsE7Eq-EirStt443Q8X_zUPC15riAD4NzdrM/s320/vlcsnap-2023-07-11-20h43m06s983.png"></a></p><p>

This behaviour suggests that when you first turn it on, it's doing its memory test and POST, then turns on the red LED while searching for and booting the minimal Mac OS, then turns on the yellow LED when, I guess, the "Finder" (such as it is) is ready to find its mothership.
</p><p>
Other typical Mac key combinations work, too. Pressing Command-Q will reset the machine when the timeout error message appears, as if quitting any other app. If you press Command-Option-Escape in an attempt to kill the task, you'll reset it also, or Command-Power, though possibly only at the point the timeout error message is present — one suspects this front-end program doesn't call <tt>WaitNextEvent</tt> very much. (In fact, it turns out it doesn't by the point, but that's a spoiler from near the end of this article.) It seems virtually anything that would cause a quit or system error (or any system dialogue box) will immediately force a restart. Incidentally, there is no startup chime or system beep, though there does appear to be a System Beep resource (<tt>snd #1</tt>).
</p><p>
Can the STB3 red ROM boot from anything else? The manual says it can access a CD-ROM drive connected via SCSI, and there are strings in the ROM that make reference to SCSI, but these appear to be within the byte range we identified as part of the disk image (and my SCSI isn't bootable). Apart from that, however, we now have enough understanding of how its ROM is laid out to write something that will walk it. (Eventually I'll extend it to work with other Mac ROMs, but right now the code just works with this red one.) We'll use <a href="https://github.com/classilla/stbtools/blob/main/resscan.pl"><tt>resscan.pl</tt></a> to see what driver resources are present and if there are any other disk images.
</p><div><pre>% ../resscan.pl RED.rom | grep -ai DRVR
[78000000] found DRVR #93 at 0x00133a00 0x00134150 ".STBDiskDriverkckckckckc" 
% ../resscan.pl RED.rom | grep -ai disk
[78000000] found disk #0 at 0x000ac9d0 0x001339d0 "kckckckcKurt��" 
[78000000] found DRVR #93 at 0x00133a00 0x00134150 ".STBDiskDriverkckckckckc"
(various string resources elided)
</pre></div>
<p>
There appears to be only one <tt>DRVR</tt>, versus the multiple found in the Q605 ROM (such as one for the floppy drive), plus only one ROM disk image. If it can load from SCSI at all, it appears to be handled by the OS in the ROM disk image rather than the firmware directly, suggesting a regular MacOS volume might not boot as such. Alternatively, doing so may not have been supported with this version of the ROM. Resource <tt>STR #46396</tt> does have the interesting string "Manages file access to CDi discs for QuickTime media handlers" which suggests disc support may have been intended for <a href="https://en.wikipedia.org/wiki/CD-i">greenbook CD-i</a>.
</p><p>
Of other resources present, there are several <tt>thng</tt> resources, including an "STB3 Component" that "Supports the hardware dependent features of STB3." and an "I2C Component" that "Supports I2C using Cuda," and a number of <tt>cdec</tt> (QuickTime codec) resources for Cinepak, Photo/JPEG, Apple Animation ("Decompresses images compressed using run length encoding") and Apple Graphics ("Decompresses images compressed using Sean's secret recipe") and, of course, MPEG-1. These components are specific to the STB and embedded elsewhere in ROM, not as part of the bootable image.
</p><p>
As for the OS itself, we'll now extract that byte range we computed and treat it as a disk image. Both SheepShaver and Mini vMac will mount it, but we'll use SheepShaver first to illustrate a little of what's there.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivi109oErIiBTo1MbdgBFIq1S01HphNj3frf-D55P-qI2z5AueUhtAEnB8O17hsfc8WYrgo1LxiGewK9Z-EzXJKO_sMMKihSlojvXMWXT8sdbQ75d4bhbXvPZ72_YmrqsqSO-LCi5hzOfGSLZqTXE5dWR-wBi2-E_Z1mZiOhvHk_dJSuibrWrOQBYw23g/s899/happydisk.png"><img alt="" width="320" data-original-height="815" data-original-width="899" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivi109oErIiBTo1MbdgBFIq1S01HphNj3frf-D55P-qI2z5AueUhtAEnB8O17hsfc8WYrgo1LxiGewK9Z-EzXJKO_sMMKihSlojvXMWXT8sdbQ75d4bhbXvPZ72_YmrqsqSO-LCi5hzOfGSLZqTXE5dWR-wBi2-E_Z1mZiOhvHk_dJSuibrWrOQBYw23g/s320/happydisk.png"></a></p><p>

First off, we're dealing with a disk image smaller than an 800K floppy; it's 540K in size. As a result the System Folder is very abbreviated: two mysterious </p><tt>INIT</tt><p>s, </p><tt>NMIer</tt><p> and </p><tt>TSDrvr INIT - 8/8</tt><p>, and very small </p><tt>Finder</tt><p> and </p><tt>System</tt><p> files. There is one font in the </p><tt>Fonts</tt><p> folder (there are other font references in the System file), and nothing in </p><tt>Apple Menu Items</tt><p>. The TSDrvr extension may be related to the known set of <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#Software">Set Top Box extensions</a> though none of those files have so far worked with any STB using the green ROM booting a conventional version of Mac OS. If indeed related, then the TS part of the name likely refers to <a href="https://en.wikipedia.org/wiki/MPEG_transport_stream">MPEG transport streams</a> and handles framing as movie data comes over the wire.
</p><p>
The other file is named <tt>MPEGStill</tt>. It has a single <tt>ckid</tt> (check ID) resource from MPW Projector, which is the Macintosh Programmer's Workshop version control system, and (among other binary data) that resource contains the strings <tt>SetTopProj</tt> (the project name, no doubt), <tt>Tidbits</tt> (probably the component or subproject, probably not <a href="https://tidbits.com/">the long-lived Mac newsletter</a>), <tt>jay michael puckett</tt> (author - which one of the self-portraits is he?), and <tt>AppleMPEGStill</tt>.
</p><p>
But the last string is the most interesting. It says it's a <tt>new still for non-BT trials</tt>. So what's the still image?

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEib-hWXs8j5td0A6eAhc0ob7O-BD82dJkv_DsNBSENEi5Huz6Nhhw6Cz73L98cRhbbJRdilkN7LTi2ws6EEgNLkKcYMwWZ3R4Gh0I3rV3YF2N-CwoWlHi8oJlVNm_f6qf8pXfzEDS5bnoMsTGffFex481l45Gwxr00XtPSB3ySeUMANXGVJIg47Pm-HGL8/s813/mpegstill.png"><img alt="" width="320" data-original-height="812" data-original-width="813" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEib-hWXs8j5td0A6eAhc0ob7O-BD82dJkv_DsNBSENEi5Huz6Nhhw6Cz73L98cRhbbJRdilkN7LTi2ws6EEgNLkKcYMwWZ3R4Gh0I3rV3YF2N-CwoWlHi8oJlVNm_f6qf8pXfzEDS5bnoMsTGffFex481l45Gwxr00XtPSB3ySeUMANXGVJIg47Pm-HGL8/s320/mpegstill.png"></a></p><p>

It's ... an MPEG-1 frame. And QuickTime will play it:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi07kh4BFEuBesHidlYFP4z8lEZYzLg2ruiY5AL5cSJgU0FTRvFD4rx4cLsw2fmRc8M8Z1ffYjApx5u9OnyZ439fIFmpvcdnw9BNKBRagmRjAFO7ENfuo67KJlAYGJmcozWWxSXod9BZSkr_1hES2YN9nHZIUD9YCDsPYPyQMzUUzhPWdhQcv-PKcxIfvw/s797/ismpg.png"><img alt="" width="320" data-original-height="452" data-original-width="797" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi07kh4BFEuBesHidlYFP4z8lEZYzLg2ruiY5AL5cSJgU0FTRvFD4rx4cLsw2fmRc8M8Z1ffYjApx5u9OnyZ439fIFmpvcdnw9BNKBRagmRjAFO7ENfuo67KJlAYGJmcozWWxSXod9BZSkr_1hES2YN9nHZIUD9YCDsPYPyQMzUUzhPWdhQcv-PKcxIfvw/s320/ismpg.png"></a></p><p>

There's our image, as CIF PAL 352x288. Notice there's only one frame here; presumably the BT STBs used a British Telecom image for their backdrop still instead. Most likely the hardware MPEG decoder, via the built-in ROM codecs, is being used to decode and display the frame.
</p><p>
For our first trick, let's create a new still frame of our own. There are a few gotchas. First of all, SheepShaver seems to wipe the boot blocks when it unmounts the image, and also unblesses the System Folder, making the resulting disk image unbootable by the STB. (I'll say benignly this was the source of a lot of cussing when the red LED would turn on but then nothing else happened.) We'll use it to explore the image but for development we'll use Mini vMac instead, which also unblesses the System Folder, but if you boot the emulated Mac (I use the Macintosh II emulation) with both your boot volume and the STB volume on the command line, it leaves the boot blocks alone. We can fix the "unblessed" folder after Mini vMac unmounts it.
</p><p>
If we feed the data fork to <tt>file</tt> and <tt>ffmpeg</tt>, this is what we get.
</p><div><pre>% file MPEGStill
MPEGStill: MPEG sequence, v1, progressive Y'CbCr 4:2:0 video, CIF PAL, 25 fps
% ffmpeg -i MPEGStill
[...]
[mpegvideo @ 0x1001f8d4b70] Estimating duration from bitrate, this may be inaccurate
Input #0, mpegvideo, from 'MPEGStill':
  Duration: 00:00:00.00, bitrate: 104786 kb/s
  Stream #0:0: Video: mpeg1video, yuv420p(tv), 352x288 [SAR 1:1 DAR 11:9], 104857 kb/s, 25 tbr, 1200k tbn
</pre></div>
<p>
We'll use the famous <a href="https://en.wikipedia.org/wiki/SMPTE_color_bars#/media/File:SMPTE_Color_Bars.svg">SMPTE colour bars</a> at a 4:3 aspect ratio. Based on the specs above, we should be able to approximate it with a command line line <tt>ffmpeg -i smpte.png -s 352x288 -r 25 -c:v mpeg1video -pix_fmt yuv420p nu.mpg</tt>, but this doesn't quite work.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2Awvj72whLl1HbYjyjSnNNn5a_4xy7S8n9L59l_CIqkz_esCE16IGsgquK5thEZdHIN7yan-EIDgY_rSfi5VlCsoXOJQPhoaRI1h77BBrZrac1K4pQPfpZh1nFUoCZnbHUD8-lHE87klJgPKxzukoYXrCLv568-T8OIrzuZTSDRUJP5H8jD0FKGjT0i8/s1920/vlcsnap-2023-07-13-20h40m31s473.png"><img alt="" width="320" data-original-height="1200" data-original-width="1920" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2Awvj72whLl1HbYjyjSnNNn5a_4xy7S8n9L59l_CIqkz_esCE16IGsgquK5thEZdHIN7yan-EIDgY_rSfi5VlCsoXOJQPhoaRI1h77BBrZrac1K4pQPfpZh1nFUoCZnbHUD8-lHE87klJgPKxzukoYXrCLv568-T8OIrzuZTSDRUJP5H8jD0FKGjT0i8/s320/vlcsnap-2023-07-13-20h40m31s473.png"></a></p><p>

The reason is it doesn't is because </p><tt>ffmpeg</tt><p> generated an <a href="https://en.wikipedia.org/wiki/MPEG_program_stream">MPEG program stream</a> and the decoder hardware wants an <a href="https://en.wikipedia.org/wiki/MPEG_elementary_stream">MPEG <em>elementary</em> stream</a>.
</p><div><pre>% file nu.mpg
nu.mpg: MPEG sequence, v1, system multiplex
</pre></div>
<p>
While I'm sure we can get <tt>ffmpeg</tt> to cough up the video stream alone, sometimes the simplest approach is to use an additional tool, in this case <a href="http://www.hampa.ch/mpegdemux/"><tt>mpegdemux</tt></a>. It compiled out of the box on my Fedora Linux-based POWER9 Raptor Talos II workstation and generated a file that matches the original <tt>MPEGStill</tt> (and is smaller, too).
</p><div><pre>% mpegdemux -d -s 0xe0 nu.mpg nuu.mpg
% file nuu.mpg
nuu.mpg: MPEG sequence, v1, progressive Y'CbCr 4:2:0 video, CIF PAL, 25 fps
</pre></div>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVS8Hx0hPyVrWKhFynVy0EDgVytBicM2Imzzg-mfLZioKUQAqeA5tkwwznP3pgsowh6aPFYEt-weCq__LE6PHIMrRa43z9ub-EyTBHHbz-rPoRoNA2jMPOs_ew2GqTOfGw3ZEsx-jrrr2wkiSoyn-ZJlbTIH8wHKA7AmFFnIb_Au-XaLbNLquEBMK3cTo/s1176/edfindstr.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVS8Hx0hPyVrWKhFynVy0EDgVytBicM2Imzzg-mfLZioKUQAqeA5tkwwznP3pgsowh6aPFYEt-weCq__LE6PHIMrRa43z9ub-EyTBHHbz-rPoRoNA2jMPOs_ew2GqTOfGw3ZEsx-jrrr2wkiSoyn-ZJlbTIH8wHKA7AmFFnIb_Au-XaLbNLquEBMK3cTo/s320/edfindstr.png"></a></p><p>

Finally, we'll fire up ResEdit in Mini vMac. The strings for the error message are part of the "Finder," so we'll edit those. In this case the two message lines are in resource </p><tt>STR##128</tt><p>, strings 11 and 12. More about the other strings later.
</p><p>
When we quit Mini vMac, unmounting the new STB image, we'll need to recompute the checksum and then re-bless the System Folder. Assuming you haven't changed the layout of the folders, changing byte 1119 to 16 (<tt>$10</tt>) will fix the latter. Then the tool <a href="https://github.com/classilla/stbtools/blob/main/splicedisk0.pl"><tt>splicedisk0.pl</tt></a> will take the original red ROM dump and the new STB ROM disk image and emit a new 2MB ROM with a corrected checksum ready for use (if you pass <tt>-fix16</tt>, it will also change that byte for you, but it doesn't do it by default just in case). It will complain if the boot blocks are missing or if the System Folder isn't blessed. Assuming it's happy, burn the new ROM image it generates and fire up the 'Box.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrEBu8gbp_OeKLNDMyiBBPTmAmxxWDGOIVPQgLP6ijkxexiaKeD0c5tN2D2P1TDs27QXnw1qA6SpGpaqiQZiq9gcHgt8S1A-PCMSe9c4F6IlAqmnXZbPdmC8X9Lg6_6jj-QmJF-9wnWicsm5QpPvTbesLSr6Vd5QnJhnLg7MMZ9uT5nGzQbwu-mipyyl0/s1400/vlcsnap-2023-07-13-22h30m00s552.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrEBu8gbp_OeKLNDMyiBBPTmAmxxWDGOIVPQgLP6ijkxexiaKeD0c5tN2D2P1TDs27QXnw1qA6SpGpaqiQZiq9gcHgt8S1A-PCMSe9c4F6IlAqmnXZbPdmC8X9Lg6_6jj-QmJF-9wnWicsm5QpPvTbesLSr6Vd5QnJhnLg7MMZ9uT5nGzQbwu-mipyyl0/s320/vlcsnap-2023-07-13-22h30m00s552.png"></a></p><p>

Seems appropriate for <a href="https://en.wikipedia.org/wiki/Captain_Midnight_broadcast_signal_intrusion">hacking a cable network</a> box, don't you think? Showtime/Movie Channel, beware!
</p><p>
The abbreviated "Finder" is the piece doing all the magic here. If you simply replace it with the regular Finder or even a teensy tiny Finder substitute like <a href="http://www.pianofab.com/otherp.html">FaberFinder</a>, the yellow LED never appears, meaning to understand what's going on we'll need to figure out what it's up to.
</p><p>
Unlike the standard Finder, STB Finder is just a regular application (with type and creator codes <tt>APPL</tt> and <tt>fHfM</tt>). You can even run it from the extracted disk image, whereupon it turns the screen pink, hides the menu bar and pointer, and just sits there until you quit with Command-Q while it presumably waits for the non-existent power button to be pressed. The timeout error message never appears, even if you're Captain Midnight.
</p><p>
There are, of course, a few interesting resources in it. It was left checked out of Projector and ResEdit warns you about this; the <tt>ckid</tt> resource has the same project and author, and says it's "beta 7 - handles more ways an application can hose itself." (Oh, really?) Accordingly, its (actual) Finder information gives it a version of "<tt>1.0ß7, Copyright © Apple Computer, Inc. 1995</tt>".

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWtFnwsdGGH_31bLwnKkH4rVTlkxC_lX39TMrrbw8MWvq1Bn1-wKKIZJX8nQG7NMwgUXQw83svL5K7ZXTMVHH55IBgYxZPP4WGCpY3XV-R5pIMCqzR-TuEAZTUwAxPYe8cNjToeh7KTFgtKpzhBJoXUGPMkB1uFT4VKOoNV5YnrY1P1aWdi8nm7y3hr4g/s1176/findermen.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWtFnwsdGGH_31bLwnKkH4rVTlkxC_lX39TMrrbw8MWvq1Bn1-wKKIZJX8nQG7NMwgUXQw83svL5K7ZXTMVHH55IBgYxZPP4WGCpY3XV-R5pIMCqzR-TuEAZTUwAxPYe8cNjToeh7KTFgtKpzhBJoXUGPMkB1uFT4VKOoNV5YnrY1P1aWdi8nm7y3hr4g/s320/findermen.png"></a></p><p>

There is an actual menu bar resource for this application, though it's never used, showing the STB Finder's internal name as </p><tt>FredTVApp</tt><p>. If it has any special response to Command-O, however, it isn't evidenced by pressing the combination on an attached keyboard (only Command-Q), and there is no corresponding resource for an "about" dialogue box.
</p><p>
Let's turn to the disassembler and go through the <tt>CODE</tt> resources now. Only <tt>CODE#1</tt> has actual program data. In these and all succeeding extracts, recall that A7 is the 68000 stack pointer, A6 is the frame pointer and A5 is the app-system globals boundary pointer. <a href="https://github.com/fuzziqersoftware/resource_dasm">The <tt>resource_dasm</tt> disassembler</a> we're using here displays the destination argument first and we will use that convention for new code for consistency. I have fixed up offsets since it got a little confused by the resource layout.
</p><p>
Although there is a fair amount of preamble, here is the <tt>main</tt> function, which I have pre-annotated. Our ability to understand the code is greatly enhanced by the presence of in-line symbols.
</p><div><pre>; main 
; start up GUI 
00000548  4E56 0000                link       A6, 0
0000054C  2F03                     move.l     -[A7], D3
0000054E  7600                     moveq.l    D3, 0x00
00000550  7600                     moveq.l    D3, 0x00
00000552  A063                     syscall    MaxApplZone
; Initialize
; set up event handlers            
; InitGraf, etc.                   
00000554  4EB9 0000 07DE           jsr        [0x000007DE]
0000055A  A852                     syscall    HideCursor
; HideMenuBar
0000055C  4EB9 0000 125E           jsr        [0x0000125E]
; HideIt (nuke menu bar selector)  
00000562  4EB9 0000 12B2           jsr        [0x000012B2]
; DrawMPEGStill
00000568  4EB9 0000 15EE           jsr        [0x000015EE]
; EventLoop
0000056E  4EB9 0000 0588           jsr        [0x00000588]
; Cleanup (doesn't do anything)
00000574  4EB9 0000 096A           jsr        [0x0000096A]
0000057A  261F                     move.l     D3, [A7]+
0000057C  4E5E                     unlink     A6
0000057E  4E75                     rts
00000580  846D 6169 6E00 0000      dc.b       "main"
</pre></div>
<p>
The long and short of it is this was written in a high-level language (most likely C), and the operating system, font and painting operations are regular Macintosh Toolbox A-line traps which the disassembler has kindly filled in for us. That means everything, including the "desktop," draws to the same screen and uses the same calls as any other System 7-compatible application. This phase of the application works on regular System 7 (more about this later on), so we can test our work in Mini vMac instead of burning flash write cycles.
</p><p>
Moving or substantially altering this code in ResEdit has side effects, usually explosive ones. Very carefully and not without a lot of trial-and-error, the first cut was to turn the <tt>HideCursor</tt> syscall into a <tt>nop $4e71</tt>, then neuter <tt>HideMenuBar</tt> and <tt>HideIt</tt> (since other things call them) by setting their first instructions to <tt>rts $4e75</tt>.
</p><p>
Next, we need to redraw the menu after the MPEG still is painted but we can't move the <tt>jsr DrawMPEGStill</tt> up without causing a crash (try it yourself), so we'll insert the <tt>DrawMenuBar $a937</tt> trap into <tt>EventLoop</tt> by obliterating the seemingly superfluous <tt>clr.w</tt> at the beginning (there weren't any spare bytes after the paint in <tt>DrawMPEGStill</tt>). Here's the rest of the event loop.
</p><div><pre>; EventLoop
00000588  4E56 FFEE                link       A6, -0x0012
0000058C  426E FFEE                clr.w      [A6 - 0x12]  &lt;&lt;&lt; MARKED FOR DEATH
00000590  6020                     bra        +0x22 /* 000005B2 */
label00000592:                     
; spin event loop
00000592  554F                     subq.w     A7, 2 
00000594  3F3C FFFF                move.w     -[A7], 0xFFFF
00000598  486E FFF0                pea.l      [A6 - 0x10]
0000059C  4878 001E                push.l     0x1E
000005A0  42A7                     clr.l      -[A7]
000005A2  A860                     syscall    WaitNextEvent
000005A4  101F                     move.b     D0, [A7]+
000005A6  486E FFF0                pea.l      [A6 - 0x10]
; call event handler
000005AA  4EB9 0000 05C8           jsr        [0x000005C8]
000005B0  584F                     addq.w     A7, 4
label000005B2:
; wait for global to turn zero: if so, terminate
; this is set by the Quit menu item
000005B2  4A2D FF44                tst.b      [A5 - 0xBC]
000005B6  66DA                     bne        -0x24 /* 00000592 */
000005B8  4E5E                     unlink     A6
000005BA  4E75                     rts
000005BC  8945 7665 6E74 4C6F 6... dc.b       "EventLoop"
</pre></div>
<p>
In Mini vMac we now have what appears to be a normal, if not particularly useful, application (and no more pink screen), with a regular pointer and menu bar. On the AITB, we get a regular pointer, a black screen, and no menu bar. Eventually the failure text comes up and we crash. But we have a mouse pointer now, so that's a start.
</p><p>
Incidentally, what displays the text is another routine called <tt>DrawMessageText</tt>, which takes two string pointers and displays them centered in Helvetica in those fixed locations. This is called by multiple routines, but if you check back in that <tt>STR#</tt> resource, most of the strings it's called to draw are blank and only the error messages are populated. This is good evidence that the red ROM we have was very late in development and possibly saw production use.
</p><p>
It appears that the "pink screen" — a simple solid window, really — is how the hardware decides where to draw the MPEG frame, essentially a Margot Robbie chroma key. For the second cut, we'll put back that <tt>clr.w</tt> in case it was salient, restore <tt>HideMenuBar</tt> to spew forth the Pepto-Bismol, and put the <tt>DrawMenuBar</tt> trap into <tt>HideIt</tt> (but elide the rest of it as before). That way the menu bar will draw on top of the pink window and should not be obliterated by it. Test run in Mini vMac:
</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhm336-6lDeTovXTcY7ywiPC5-X1W9hk6EN1Vs6O-ZgN7p3vygZFmD1WzZEWlqXxajicX1vGYQSJ2VfxJNHIzTY_MXn1WKKQL_s5fznxEJXAy3OSu8zFG3zbKvMouuAaGNc8VfyGidrJGu7-3FIOQKrp9dZaPDb0sQ-QU7exb710eGgXYMpMLWBnuakBrA/s1176/hifredtv.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhm336-6lDeTovXTcY7ywiPC5-X1W9hk6EN1Vs6O-ZgN7p3vygZFmD1WzZEWlqXxajicX1vGYQSJ2VfxJNHIzTY_MXn1WKKQL_s5fznxEJXAy3OSu8zFG3zbKvMouuAaGNc8VfyGidrJGu7-3FIOQKrp9dZaPDb0sQ-QU7exb710eGgXYMpMLWBnuakBrA/s320/hifredtv.png"></a></p>
<p>
Those changes bring back the pink screen but keep the menu bar and pointer. Selecting the About option just makes it beep at us, by the way. Still, it's likely that this part is only the state of the machine <em>before</em> the power button is pressed, and we want to get the screen on (and not time out and crash), so we need to keep going through the disassembly.
</p><p>
It would seem logical to assume that since everything so far has been Toolbox-based, the signal that the power button was pressed is probably also a regular Toolbox Event. Attaching an ADB keyboard to the STB3 and pressing the Power key doesn't do anything, so we go back to the code. The event handler called by the event loop has typical handlers for mouse down, key down, update and activate events, as well as the "high level" event handler for Apple events, but also a mysterious handler for an application-specific <tt>app3Evt</tt> (event type 14).
</p><div><pre>label000006BE: ; app3Evt           
000006BE  4A2D FC76                tst.b      [A5 - 0x38A]
000006C2  6632                     bne        +0x34 /* 000006F6 */
000006C4  0CAA 0000 0115 0002      cmpi.l     [A2 + 0x2], 0x115
000006CC  6628                     bne        +0x2A /* 000006F6 */
000006CE  1B7C 0001 FC76           move.b     [A5 - 0x38A], 0x1
000006D4  2B6A 0006 FC6E           move.l     [A5 - 0x392], [A2 + 0x6]
000006DA  594F                     subq.w     A7, 4
000006DC  2F2D FD34                move.l     -[A7], [A5 - 0x2CC]
000006E0  4267                     clr.w      -[A7]
000006E2  2F3C 0002 001E           move.l     -[A7], 0x2001E
000006E8  7000                     moveq.l    D0, 0x00
000006EA  A82A                     syscall    ComponentDispatch
000006EC  201F                     move.l     D0, [A7]+
; StartTheBootProtocol             
000006EE  4EB9 0000 0A02           jsr        [0x00000A02]
000006F4  6050                     bra        +0x52 /* 00000746 */
label000006F6: 
000006F6  0C2D 0001 FC76           cmpi.b     [A5 - 0x38A], 0x1
000006FC  661E                     bne        +0x20 /* 0000071C */
000006FE  0CAA 0000 0115 0002      cmpi.l     [A2 + 0x2], 0x115
00000706  6614                     bne        +0x16 /* 0000071C */
00000708  701E                     moveq.l    D0, 0x1E
0000070A  D0AD FC6E                add.l      D0, [A5 - 0x392]
0000070E  B0AA 0006                cmp.l      D0, [A2 + 0x6]
00000712  6408                     bcc        +0xA /* 0000071C */
00000714  3F3C 0002                move.w     -[A7], 0x2
00000718  A895                     syscall    ShutDown
0000071A  602A                     bra        +0x2C /* 00000746 */
</pre></div>
<p>
Much of the special hardware control is done through the poorly documented <tt>ComponentDispatch</tt> trap, officially part of the Component Manager (makes sense as QuickTime was its major utilizer and this machine is basically a QuickTime box). Best guess is that it uses the "<tt>STB3 Component</tt>" at resource <tt>thng#48803</tt>, though being related to power-on it could also be the "<tt>I2C Component</tt>" (<tt>thng#48798</tt>). Here, it checks a global variable (i.e., via A5) and a code word, and if that variable is zero but the code word is <tt>0x115</tt>, it calls an internal component (to turn on the screen?) and then calls <tt>StartTheBootProtocol</tt> (which, completely unexpectedly, starts the remote boot sequence). But if the global variable is one with that same code word, it triggers the <tt>ShutDown</tt> trap (which forcibly reboots the AITB). All this sounds like what you'd get if the power button were pressed.
</p><p>
The timeout is in <tt>DoIdle</tt>, which is called within <tt>StartTheBootProtocol</tt>. We'll shortcircuit that.
</p><div><pre>; SendPowerUpMessage               
00000A3E  4EB9 0000 0BE8           jsr        [0x00000BE8]
00000A44  3600                     move.w     D3, D0
; SendBootMessage
00000A46  4EB9 0000 0C54           jsr        [0x00000C54]
00000A4C  3600                     move.w     D3, D0
; get current count
00000A4E  A975                     syscall    TickCount
00000A50  201F                     move.l     D0, [A7]+
00000A52  0680 0000 0708           addi.l     D0, 0x708
00000A58  2B40 FD04                move.l     [A5 - 0x2FC], D0
00000A5C  5C4F                     addq.w     A7, 6
00000A5E  6004                     bra        +0x6 /* 00000A64 */
label00000A60:
; call DoIdle if A5 - 0x300 is null - see flag notes elsewhere
00000A60  4EBA FF1A                jsr        [PC - 0xE6 /* 0000097C */]
label00000A64:
00000A64  4A2D FD00                tst.b      [A5 - 0x300]
00000A68  67F6                     beq        -0x8 /* 00000A60 */  &lt;&lt;&lt; MARKED FOR DEATH
00000A6A  594F                     subq.w     A7, 4
00000A6C  2F2D FD38                move.l     -[A7], [A5 - 0x2C8]
00000A70  2F3C 0000 0703           move.l     -[A7], 0x703
00000A76  7000                     moveq.l    D0, 0x00
00000A78  A82A                     syscall    ComponentDispatch
00000A7A  201F                     move.l     D0, [A7]+
00000A7C  3600                     move.w     D3, D0
00000A7E  3003                     move.w     D0, D3
00000A80  261F                     move.l     D3, [A7]+
00000A82  4E5E                     unlink     A6
00000A84  4E75                     rts
00000A86  9453 7461 7274 5468 6... dc.b       "StartTheBootProtocol"
</pre></div>
<p>
If we make that <tt>beq</tt> at <tt>$a68</tt> a <tt>nop</tt>, then as it won't ever branch to the exit point in <tt>DoIdle</tt>, the function will always exit back to the event loop and thus we'll <em>stay</em> in the event loop forever without timing out. Sounds like it should work!

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNl5MqR2rYXUZRQTLz4E32Xc8qEz4rLc72AUKbsR3EsW0f1tgdjYXvJ3O0eYAcVwIDFBYovJN-R9zkKPhHf2_QMPaEpb7e3K_jlWeiElsyMaWYI92o6ARVInIjxKfrlJpTdCUxjeZ9gAmiVnPoEE_SNggIP_m4qWuF2duPjhUDJxdQOAPoSyMPFMvyDZ8/s1400/vlcsnap-2023-07-15-19h10m16s019.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNl5MqR2rYXUZRQTLz4E32Xc8qEz4rLc72AUKbsR3EsW0f1tgdjYXvJ3O0eYAcVwIDFBYovJN-R9zkKPhHf2_QMPaEpb7e3K_jlWeiElsyMaWYI92o6ARVInIjxKfrlJpTdCUxjeZ9gAmiVnPoEE_SNggIP_m4qWuF2duPjhUDJxdQOAPoSyMPFMvyDZ8/s320/vlcsnap-2023-07-15-19h10m16s019.png"></a></p><p>

And, well, it sort of worked. We have a mouse pointer and we have a "desktop." In fact, our call to draw the menu bar has clearly caused something different, as you can now see the typical rounded Mac screen borders which weren't present before. (Notice the gutters: this is from the era of CRT displays, so the displayed desktop is within the safe zone.) The mouse pointer even moves with the mouse, and we don't crash or time out! But we have no menu bar despite explicitly asking to draw it and we patched out the only other function that would disable it, so what gives?
</p><p>
Unfortunately I'm not sure what's going on here, exactly. The ROM System file lacks <tt>MDEF</tt> and <tt>MBDF</tt> resources for defining the menu bar and menus, but these resources are present elsewhere in the ROM and don't seem unusually short or weird compared to regular System 7.1. I also couldn't find anywhere obvious that the <tt>DrawMenuBar</tt> trap was patched into a no-op.
</p><p>
On the other hand, our event handler code is still active: if we press Command-Q, the device restarts as usual. If we patch the code that receives a menu click to make Command-O (menu item 1) the same as Command-Q (menu item 2, i.e., change the instruction to branch to the same spot), then Command-O will also quit and restart the STB. That means that even though we can't see our menu options, we can still activate them. Since there's code in the STB Finder to handle the Apple menu, why don't we make Command-O open something else for us?
</p><p>
To the STB disk image I added the 7.1 Chooser and associated components — since eventually we'll need to mount something over LocalTalk — and a copy of the tiny Finder substitute <a href="http://www.pianofab.com/otherp.html">FaberFinder</a> in the Apple Menu Items folder. We'll pare down their resources later. FaberFinder would be item 4 in this case ("About FredTVApp," then a separator, then the Chooser, then FaberFinder). This is the relevant code in the menu handler.
</p><div><pre>00000780  0C43 0001                cmpi.w     D3, 0x1
00000784  6608                     bne        +0xA /* 0000078E */
; beep if the first item (About FredTVApp) is selected
00000786  3F3C 0001                move.w     -[A7], 0x1
0000078A  A9C8                     syscall    SysBeep
; and exit
0000078C  6034                     bra        +0x36 /* 000007C2 */
label0000078E: 
; else handle the rest of the apple menu      
0000078E  594F                     subq.w     A7, 4
00000790  3F3C 0080                move.w     -[A7], 0x80
00000794  A949                     syscall    GetMenuHandle
00000796  205F                     movea.l    A0, [A7]+
00000798  2F08                     move.l     -[A7], A0
0000079A  3F03                     move.w     -[A7], D3
0000079C  486E FF00                pea.l      [A6 - 0x100]
000007A0  A946                     syscall    GetMenuItemText/GetItem
000007A2  554F                     subq.w     A7, 2
000007A4  486E FF00                pea.l      [A6 - 0x100]
000007A8  A9B6                     syscall    OpenDeskAcc
000007AA  301F                     move.w     D0, [A7]+
000007AC  3600                     move.w     D3, D0
000007AE  6012                     bra        +0x14 /* 000007C2 */
label000007B0:
; File menu
000007B0  3003                     move.w     D0, D3
000007B2  48C0                     ext.l      D0
; Open (does nothing)
; item 1
000007B4  5380                     subq.l     D0, 1
000007B6  670A                     beq        +0xC /* 000007C2 */
; Quit (this sets the global quit flag)
; item 2
000007B8  5380                     subq.l     D0, 1
000007BA  6702                     beq        +0x4 /* 000007BE */
</pre></div>
<p>
Since the About item can't be opened on the STB right now anyway, we're going to turn the <tt>move.w -[A7],0x01:SysBeep</tt> into a <tt>bra +0x3c</tt>, opcode <tt>$603a</tt>, so that it still works. That frees up six bytes. We'll make the last two into a <tt>moveq.l D3,#4</tt> opcode <tt>$7604</tt> and fall through into the routine immediately afterwards that opens a desk accessory, then change the branch for the Open item to hit that <tt>moveq</tt>. It should then make Command-O open the fourth item on the menu.
</p><p>
We can test this in Mini vMac, and it worked (it opened the second item of the Apple menu after the separator, which happens to be the AppleCD Player). I loaded it onto the AITB and it did nothing — it didn't crash, but it didn't do anything either. In case it would only work with a real desk accessory (the Chooser is), even though <tt>OpenDeskAcc</tt> in System 7 shouldn't care, I changed it to 3. That worked fine on Mini vMac too, and still not on the AITB. Again, it's not clear if this trap was disabled or altered, or if those apps just plain can't run in this limited environment. More thoughts on that in a little bit.
</p><p>
Do even dialogue boxes work? There are some <tt>ALRT</tt> and <tt>DITL</tt> resources in the red ROM, but instead we'll create a simple dialogue box within the STB Finder and have our Command-O hook display that box. Since the Command-O hook already branches to it, we'll just overwrite the desk accessory code above with this hand-assembled snippet and pad it out with <tt>nop</tt>s.
</p><div><pre>     clr.w -[a7]       ; 4267       ; outparam
     move.w -[a7],#128 ; 3f3c 0080  ; alert 128
     clr.l -[a7]       ; 42a7       ; no filterproc
     Alert             ; a985
     addq.l a7,#2      ; 548f       ; pop outparam
</pre></div>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheTP23jqXTY71hRON91qq_RRLJjqOwNpiFbSjTaqml7oUqC9Ol2vOpq6QPd7FmSrAgQ9dR1LPhVh_vKECXdulAtYSTSRlZQxc0bgVKcUOk1LRqJKgmZS5mGoL8LaaOFDStwc29RRaiHSHOgUfxlrdi25QXKBrM4Yt0KCeV3rp6ptzlwfM8tr1KFAPHRIE/s1400/vlcsnap-2023-07-16-21h16m28s860.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheTP23jqXTY71hRON91qq_RRLJjqOwNpiFbSjTaqml7oUqC9Ol2vOpq6QPd7FmSrAgQ9dR1LPhVh_vKECXdulAtYSTSRlZQxc0bgVKcUOk1LRqJKgmZS5mGoL8LaaOFDStwc29RRaiHSHOgUfxlrdi25QXKBrM4Yt0KCeV3rp6ptzlwfM8tr1KFAPHRIE/s320/vlcsnap-2023-07-16-21h16m28s860.png"></a></p>

<p><a href="https://en.wikipedia.org/wiki/Max_Headroom_signal_hijacking">Catch the wave</a>! The OK button responds correctly to RETURN and to the mouse. The background doesn't repaint, but that's solvable (because it's no longer pink, the MPEG still is no longer painted there). Plus, it makes a beep through the stereo outputs, presumably with that ROM </p><tt>snd #1</tt><p> resource, so sound more or less works fine. Between QuickDraw, audio and some basic support for dialogue boxes at least you could do some sort of basic app with that. It seems the most likely logical resolution for the screen is 640x400, based on experimentation with the dialogue box position.
</p><p>
Still, the Promised Land is to create an AITB ROM that can run arbitrary programs it can download to memory, and the STB ROM disk must clearly do this, or it would never have worked otherwise. To discuss how it worked, it's important to remember that T1/E1 is intrinsically a serial connection: for example, <a href="http://oldvcr.blogspot.com/2022/05/so-long-home-t1-line-hello-hacking-t1.html">my old residential T1 line</a> was basically a hardwired PPP link over HDSL, and even T1-based frame relay was still just serial data with T-carrier framing. As such, the STB ROM treats the T1 connection like a serial port and executes reads and writes on it directly. AppleTalk is not involved.
</p><p>
Based on the symbols and the call chain by manually walking through the disassembly, the end state is for the local client to receive a complete HFS disk image from the remote server. As part of <tt>Initialize</tt> in <tt>main</tt>, the transmit side is setup by <tt>ITVInitWriteChannel</tt> (note the use of another acronym, ITV, which may have been in use earlier), which calls <tt>SerialOpenDrivers</tt> and <tt>SerialInitialize</tt> to handshake with the headend using <tt>SerialHandshake</tt>. When the power-on event is received, the call to <tt>StartTheBootProtocol</tt> in the event handler calls <tt>SendPowerUpMessage</tt> and <tt>SendBootMessage</tt>, which send messages through <tt>ITVWriteBytes</tt> to <tt>SerialWriteBytes</tt>. All messages to and from the cable headend are checksummed ultimately by the routine at <tt>mzbBPCalcChecksum</tt>, called by <tt>VerifyChecksum</tt> and <tt>WriteChecksum</tt>.
</p><p>
After sending the initial startup messages, <tt>StartTheBootProtocol</tt> falls into a loop repeatedly calling <tt>DoIdle</tt>, which will maintain a progress bar based on the current tick and call <tt>BackChannelDataHandler</tt> if data is available to read into the buffer. (<tt>StartTheBootProtocol</tt> is what we said didn't seem to call <tt>WaitNextEvent</tt> very much, because it turns out it doesn't.) This handler will send an abort to the headend and reset the boot state if there is a transmission failure, as will any routine where the checksum is wrong.
</p><p>
<tt>SendPowerUpMessage</tt> sets the first state, to wait for a "size" packet from the headend. Once <tt>BackChannelDataHandler</tt> assembles a complete packet, this first one goes to <tt>SizeMessageHandler</tt>; it allocates the requested memory space for the incoming disk image (or aborts) and calls <tt>SendReadyMessage</tt> which sets the next state, to start receiving data packets. These are routed to <tt>DataMessageHandler</tt> which stores the packet and calls <tt>SendAckMessage</tt>, keeping the progress bar updated. Any timeout will also abort the boot process.
</p><p>
<tt>SendAckMessage</tt> will keep the state pointing to <tt>DataMessageHandler</tt> as packets arrive until the last one, when it will call <tt>GotFinalDataMessage</tt>. <tt>GotFinalDataMessage</tt> sets a global flag to inhibit further calls to <tt>DoIdle</tt> and calls <tt>CreateDiskFromImage</tt> to mount the downloaded disk image, which in turn calls <tt>LaunchSystemUpdate</tt> to run a system update (if there is one) and finally <tt>LaunchStartupApp</tt> to run the main program. No code signature is obviously involved, meaning it will run anything it gets from the remote server assuming the checksums are all valid. The filenames it looks for appear to come from the <tt>DATA#0</tt> resource of the STB Finder, which is copied into memory early during its initialization:
</p><div><pre>00000000  00 00 00 c7 ff ff ff 44  81 01 00 20 f3 83 b9 4d  |.......D... ...M|
00000010  e5 49 1b 20 6b 44 95 eb  00 88 01 04 01 f5 0e 2e  |.I. kD..........|
00000020  53 54 42 44 69 73 6b 44  72 69 76 65 72 43 95 0c  |STBDiskDriverC..|
00000030  53 79 73 74 65 6d 55 70  64 61 74 65 0a 53 74 61  |SystemUpdate.Sta|
00000040  72 74 75 70 41 20 70 99  0a 53 74 61 72 74 75 70  |rtupA p..Startup|
00000050  44 6f 63 6f 73 3d 4d 61  63 53 54 42 3a 72 76 3d  |Docos=MacSTB:rv=|
00000060  31 2e 20 30 88 3a 63 70  3d 36 38 30 34 30 48 8e  |1. 0.:cp=68040H.|
00000070  0e 2e 53 54 42 44 69 73  6b 44 72 69 76 65 72 43  |..STBDiskDriverC|
00000080  87 09 4d 50 45 47 53 74  69 20 6c a3 09 2e 54 53  |..MPEGSti l...TS|
00000090  44 72 69 76 65 72 00 04  2e 41 49 6e 05 2e 41 4f  |Driver...AIn..AO|
000000a0  75 74 00 04 2e 42 49 6e  05 2e 42 4f 75 74 00 01  |ut...BIn..BOut..|
000000b0  00 00 00 00 28 00 00 00  00 28 00 00 00 00 00 00  |....(....(......|
000000c0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 67 40  |..............g@|
000000d0  6e 83 8a 42 30 84 83 83  83 83 9b 40 6b d6 bc 88  |n..B0......@k...|
000000e0  40 46 d7 40 c2 f0 f0 b0  90 8e a6 40 44 85 83 8e  |@F.@.......@D...|
000000f0  8e 95 92 83 84 40 57 85  a8 bc f8 b3 8c b4 8b 9f  |.....@W.........|
00000100  b2 9e ec 99 ec 97 ec b4  98 86 8b a1 a6 85 89 a0  |................|
00000110  e6 af e0 9b 88 a0 b6 ab  aa 8b 99 90 a1 42 13 7f  |.............B..|
00000120  a4 40 48 a0 95 f4 94 bc  94 88 89 40 ad d5 bb fa  |.@H........@....|
00000130  db fa 40 b4 84 40 b2 40  81 f5 b7 f5 9b f8 95 b4  |..@..@.@........|
00000140  bc f0 f0 f1 00 00 00 00                           |........|
</pre></div>
<p>
I'm not sure where those spurious spaces came from, but it appears to run <tt>SystemUpdate</tt>, if it exists, then launches one of two files, which appear to be either <tt>StartupApp</tt> or <tt>StartupDoc</tt> (again, based on what's present). The same driver <tt>.STBDiskDriver</tt> that handles accessing the ROM disk likely handles the RAM disk, which is very economical. Also note that the strings in this resource indicate the unit identifies itself as a <tt>MacSTB 1.0</tt> with a 68040, which seems to be sent by the initial message routines, and the presence of the string for <tt>MPEGStill</tt>, which is what <tt>DrawMPEGStill</tt> opens and references.
</p><p>
If you label all the <tt>STR#</tt> strings in the STB Finder with numbers, you should be able to observe the boot stages as most of them call <tt>DrawMessageText</tt>, just with empty strings. I reverted our changes to the STB Finder and just made the resource change so we'd have a "clean" show. Here's the beginning:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-fetpyr7KH0FqMT3KdYJZUMZN3KNUlCnvLpZFspSvbXZfZ_NCjrGzIxtV-eijDeMulOl2NQb0UbuUVTCDACUzlrVsfF8mrWE3cv196lE6bLQR1JpQ4qcQ960Rm5I8HKI4lyisDkBAea7UTy0i5XRa7pNiFf7iHV8H8N3scvsh802igte8bQY24U7lZTs/s1400/vlcsnap-2023-07-20-08h20m23s738.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-fetpyr7KH0FqMT3KdYJZUMZN3KNUlCnvLpZFspSvbXZfZ_NCjrGzIxtV-eijDeMulOl2NQb0UbuUVTCDACUzlrVsfF8mrWE3cv196lE6bLQR1JpQ4qcQ960Rm5I8HKI4lyisDkBAea7UTy0i5XRa7pNiFf7iHV8H8N3scvsh802igte8bQY24U7lZTs/s320/vlcsnap-2023-07-20-08h20m23s738.png"></a></p><p>

And the end:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg36gSq5Ic8BHyBsx0UTnaIOEy74u5KMwlv-XJNb6_1MsJ6bMcByY_r2CaUCzzaGZWOOWjKX1wlTVkxEpvujeHtS-IcgR4NAiYOre5bjcbK5qcUqYYRGRl1PReM3pc0WZ9Jzz6L4xWYsejUjLNwjGKqKKzUARA5ngcZCex0sA7Dsq8ZJYVTR2TtcBEAhV4/s1400/vlcsnap-2023-07-20-08h20m54s145.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg36gSq5Ic8BHyBsx0UTnaIOEy74u5KMwlv-XJNb6_1MsJ6bMcByY_r2CaUCzzaGZWOOWjKX1wlTVkxEpvujeHtS-IcgR4NAiYOre5bjcbK5qcUqYYRGRl1PReM3pc0WZ9Jzz6L4xWYsejUjLNwjGKqKKzUARA5ngcZCex0sA7Dsq8ZJYVTR2TtcBEAhV4/s320/vlcsnap-2023-07-20-08h20m54s145.png"></a></p><p>

We never get past the beginning, of course, so we only see the Alpha and the failed Omega.
</p><p>
The actual section of code that triggers execution of the downloaded apps, <tt>DoALaunch</tt>, uses the Toolbox <tt>Launch</tt> trap at <tt>$a9f2</tt>. Notably it generates a MultiFinder extended launch param block but uses an unusual fixed set of launch flags (see <a href="https://preterhuman.net/macstuff/techpubs/mac/Toolbox/Toolbox-39.html">the <tt>SIZE</tt> resource</a>) set to <tt>$4800</tt>, which designate an application that understands suspend and resume but is not MultiFinder-aware. As such it could not run arbitrary classic Mac applications even if the rest of the operating system features were present; it can only run ones coded to work with this limited environment, even though such applications should also work on vanilla System 7 modulo any specialized calls to the AITB hardware drivers. It might be possible to generate an application that could boot something else in the way that things like the Booter application start NetBSD/mac68k, but it's not clear if this could actually boot another version of Mac OS entirely, at least not without including a lot of extra resources that would ordinarily be present in a typical Toolbox ROM.
</p><p>
And that's why we have such an odd hybrid STB Finder where most of its GUI code does nothing on the real hardware. My best guess is that the development systems booted a modified full System 7.1 rather than the bowdlerized mini-System in the red ROM, including all the <tt>thng</tt>s and other necessary STB-specific components (such as the driver for the video card I don't have). It is not obvious that the red ROM is capable of booting any operating system other than itself, which explains why most of the few AITBs in collector hands have green Quadra 605 ROMs: the Q605 ROM has a normal Toolbox and will boot a System Folder from a SCSI volume, or at least others other than mine will, and is compatible enough with the AITB to at least drive the on-board NCR SCSI controller until it can load the other <tt>INIT</tt>s for the unique hardware (the red ROM already has this support). Such a setup would be perfectly cromulent for a developer machine and the surviving units probably mostly came from those settings. That said, whatever the circulating <tt>stbextensions</tt> folder does, it doesn't seem to be enough to enable the other AITB hardware components — though it may simply be incomplete or the bootable OS had other changes.
</p><p>
Either way, given the STB Finder is "just" a regular application, you can run it and the applications it triggers from a regular System 7 installation once you've got the OS booted on an AITB, but now having done so you can test all the other AITB-specific pieces. If you try to run the STB Finder on a regular Mac and forge that event code to force a power-on event, you'll crash, shut down or do nothing because the other needed system components (and hardware) are missing. The system update functionality is particularly interesting, though as there are no known surviving examples of any of the downloaded applications we don't know exactly what they did or how. It can't be excluded that the system update would have actually reflashed the onboard ROM through an unknown mechanism, but there's no obvious facility on the logic board to do so, and over the unit's short lifetime no system update may ever have been deployed.
</p><p>
Let's tie it all together and make a Hello World ROM that you could potentially use as a jumping off point for your other applications. I'm not making this red ROM dump available publicly to avoid the litigious wrath of the Cupertino mothership, but if you have or get a red ROM dump, you can try it. Set up Mini vMac running at least System 7.1 (I use it in Macintosh II mode with System 7.5.5), and, of course, get a flash ROM SIMM and programmer. You'll need ResEdit as well. Note these steps should work with SheepShaver or Basilisk II as well, but those emulators may destroy the STB image's bootblocks and you'd have to restore them afterwards.
</p><p>
Extract the <tt>disk#0</tt> resource from the ROM using <a href="https://github.com/classilla/stbtools/blob/main/resscan.pl">our resource walker</a> (something like <tt>perl resscan.pl RED.rom disk 0</tt> will create a <tt>disk-0.dump</tt> file). Name it something like <tt>stb.img</tt>. Start Mini vMac with both your System 7 boot drive and the STB image on the command line so that they are mounted simultaneously (don't worry, the emulator won't try to boot from the STB image if it's listed second).
</p><p>
Back up the Finder from the STB image and then drag it to ResEdit, which will say it was checked out read-only; you can ignore this. Remove the single <tt>ckid</tt> resource if it annoys you. Optionally, in <tt>STR#</tt> 128 change strings three and four to your desired startup message if you like, and create a new <tt>MPEGStill</tt> file using <tt>ffmpeg</tt> and <tt>mpegdemux</tt> and ensure its type and creator are <tt>MPEG</tt> and <tt>mMPG</tt>.
</p><p>
For the actual "proof of hack" dialogue box, add the <tt>DITL</tt> and <tt>ALRT</tt> resources for your alert dialogue box to the STB Finder; the code below assumes the <tt>ALRT</tt> resource is numbered 128. Open the STB Finder's <tt>CODE</tt> resource 1 and in the hex editor make the following changes:
</p><ul>
<li>Remove the Toolbox call to <tt>HideCursor</tt> at offset <tt>$055a</tt> by changing the opcode to <tt>$4e71</tt>.
</li><li>Add a new handler for our alert routine at offset <tt>$0786</tt> by changing the three opcodes at that location to <tt>$4eba $1810 $4e71</tt>.
</li><li>Change the branch at <tt>$07b6</tt> to point to the new subroutine call by making it <tt>$67ce</tt>.
</li><li>Disable the timeout by changing the opcode at offset <tt>$0a68</tt> to <tt>$4e71</tt>.
</li><li>Neuter the call to <tt>HideIt</tt> at offset <tt>$12b6</tt> by changing the three opcodes starting at that location to <tt>$a937 $4e5e $4e75</tt>.
</li></ul><p>
Finally, add these opcodes to the end, starting at </p><tt>$1f98</tt><p> (the offset after the end of the resource).
</p><div><pre>1f98: 4e56 0000 4267 3f3c
1fa0: 0081 42a7 a985 548f
1fa8: 4e5e 4e75
</pre></div>
<p>
Close and save the modified Finder on the STB disk image and shut down Mini vMac. If you changed the folder structure of the ROM, you will need to manually rebless the System Folder with a hex editor and then merge the STB image back into the ROM with <a href="https://github.com/classilla/stbtools/blob/main/splicedisk0.pl">the splicer</a> (something like <tt>perl splicedisk0.pl RED.rom stb.img NEWRED.rom</tt>). If you didn't change the folder structure, then pass the <tt>-fix16</tt> argument and the splicer will bless the System Folder for you.
</p><p>
Burn the new ROM to your flash ROM SIMM, install it into the AITB, connect an ADB keyboard and mouse, and turn on the AITB's rear power switch. When the LED in the front turns yellow, press the power button. Press Command-O after startup to open the dialogue box.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjb1x_b5kOs_9Z1hDFbdl43qlI3w50INn95aLea276FZi8dh6xgbDhpPMFKK62mHodqugHNN6ZsmRyzX5y1z0PZ-e_9BhBQw8R1gFQcONYaCnlFuh-5Q1RYFqpZBX-YjLFBTohdksV4JpVQBXWTyk6u8__udH-0NIE7RG8orVxk1cfpNuHUx7Iub1SX-Rs/s1400/vlcsnap-2023-07-20-11h09m55s803.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjb1x_b5kOs_9Z1hDFbdl43qlI3w50INn95aLea276FZi8dh6xgbDhpPMFKK62mHodqugHNN6ZsmRyzX5y1z0PZ-e_9BhBQw8R1gFQcONYaCnlFuh-5Q1RYFqpZBX-YjLFBTohdksV4JpVQBXWTyk6u8__udH-0NIE7RG8orVxk1cfpNuHUx7Iub1SX-Rs/s320/vlcsnap-2023-07-20-11h09m55s803.png"></a></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQq1IF5V5-ZrfyVypPOlwo597-SVULu2aeIo4uoqLK04w-FiJae6j9fnSTC2AXoOZ0flzqurg9C18dBFwIlqrjxKZ--wSu8M-UbKJVkNgcMCXSiNkb2dHRg2efiovV4qk4obSJb_wfdPuo4HnbhcDsCvR1AV82XGw2rFWJ3R8hjL90tgPweTbzRv-d9vM/s1400/vlcsnap-2023-07-20-11h10m13s135.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQq1IF5V5-ZrfyVypPOlwo597-SVULu2aeIo4uoqLK04w-FiJae6j9fnSTC2AXoOZ0flzqurg9C18dBFwIlqrjxKZ--wSu8M-UbKJVkNgcMCXSiNkb2dHRg2efiovV4qk4obSJb_wfdPuo4HnbhcDsCvR1AV82XGw2rFWJ3R8hjL90tgPweTbzRv-d9vM/s320/vlcsnap-2023-07-20-11h10m13s135.png"></a></p><p>

The AITB is now your own. Things to do: figure out how to branch to separate code immediately after power-on in the </p><tt>app3Evt</tt><p> handler at </p><tt>$06be</tt><p> (so far I get nothing but crashes trying to muck around there), figure out how the CD-ROM support works with the red ROM, and figure out a means to transfer an application disk image into memory with the real serial port (the AITB can use a serial printer, so there is at least some support for driving the Zilog SCC). And things <em>I</em> need to do: figure out what fuse I opened, or something, to make my own AITB not boot from SCSI. But now this exceptionally rare Apple machine should be much less of a mystery to you.
</p><p>
I would love to hear from you if you were involved in this machine's development (or can even just identify who was in our STB Bunch composite). If you'd prefer not to post a public comment, you can E-mail me at ckaiser at floodgap dawt com.
</p><p>
The code we put together to help walk and modify the red ROM dump <a href="https://github.com/classilla/stbtools">is available on Github</a>.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ElKaWe – Electrocaloric heat pumps (172 pts)]]></title>
            <link>https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</link>
            <guid>36823524</guid>
            <pubDate>Sat, 22 Jul 2023 05:20:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html">https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>In the ElKaWe lighthouse project, six Fraunhofer Institutes under the leadership of the Fraunhofer IPM are working on the development of electrocaloric heat pumps for heating and cooling. Today, heat pumps work almost exclusively on the basis of compressor technology. Electrocaloric heat pumps promise a significantly higher efficiency and do not require harmful refrigerants. As part of the project, scientists are developing ceramic and polymer-based electrocaloric materials and are working on an innovative system approach that enables particularly efficient heat dissipation. The work in the project is intended to demonstrate that electrocaloric heat pumps have the potential to replace compressors in the long term. Heat pumps are an important module in the heat revolution. Powered by regeneratively generated power, they form the missing link between power and heat generation. However, the increase in heat pumps for building air conditioning is slow, due to the poor economic efficiency of compressor-based heat pumps. In cooling technology, the gradual ban on refrigerants under the European F-Gas Regulations makes alternative, refrigerant-free technologies more desirable.</p> 
<h4>How does an electrocaloric heat pump work?</h4> 
<p>When an electrical field is applied to electrocaloric materials, the electrical dipole moments in the field are aligned – this additional order is accompanied by heating of the material according to thermodynamics laws. The resulting heat is dissipated via a heat sink, meaning the material cools down again to its initial temperature.&nbsp;If the electric field is now removed, order is reduced and the material cools, also in accordance with the laws of thermodynamics. Now it can absorb thermal energy from a heat source. The effect is reversible. This allows a cycle to be established that functions as an efficient heat pump for cooling or heating.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS networking concepts in a diagram (253 pts)]]></title>
            <link>https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/</link>
            <guid>36823516</guid>
            <pubDate>Sat, 22 Jul 2023 05:18:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/">https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/</a>, See on <a href="https://news.ycombinator.com/item?id=36823516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	<div id="content">
		<main id="main" role="main">

		
			
<article id="post-528">
	<!-- .entry-header -->

	<div>
		
<p>Before March 2023 I couldn’t for the life of me understand what was going on in the AWS VPC dashboard. I mean, look at the length of the scrolling bar on the left-hand panel!</p>



<figure><img data-attachment-id="531" data-permalink="https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/image-12/" data-orig-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png" data-orig-size="2324,2114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=300" data-large-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=660" src="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=1024" alt="" srcset="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=1024 1024w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=2048 2048w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=150 150w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=300 300w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>So, with the goal of figuring out the various resources involved in networking, I read (most of) this book: <a href="https://www.goodreads.com/book/show/60098024-aws-networking-fundamentals">AWS Networking Fundamentals</a>, by Toni Pasanen.</p>



<p>My first thought after finishing it was this: there’s so many resources involved because there’s a lot of types of connections you can have. AWS account to on-premise, account to account, VPC to VPC, subnet to subnet, VPC to internet, VPC to specific AWS services…</p>



<p>So anyway, I made this mind map to link all pieces together:</p>



<pre><code><img src="https://miparnisariblog.files.wordpress.com/2023/03/aws-networking-1.png" alt="aws networking mind map"></code></pre>



<p>Let me know if you find it useful and/or if you find any errors!</p>

				</div><!-- .entry-content -->

	
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What we talk about when we talk about System Design (228 pts)]]></title>
            <link>https://maheshba.bitbucket.io/blog/2023/07/12/Design.html</link>
            <guid>36823375</guid>
            <pubDate>Sat, 22 Jul 2023 04:47:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maheshba.bitbucket.io/blog/2023/07/12/Design.html">https://maheshba.bitbucket.io/blog/2023/07/12/Design.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Early in my research career, I had a chance to work with some of the best system researchers<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" rel="footnote">1</a></sup> in the world on a number of really interesting system designs. One of the enjoyable aspects of research was the particular process used by researchers (particularly in the SOSP/OSDI community) to come up with novel yet practical designs. This design process can be characterized as “fighting complexity with abstraction”: in any complex environment, how do you corral that complexity into cleanly defined boxes (or more technically, abstractions) and then divide functionality across these boxes?</p>

<p>Later, when I switched to “real” jobs in industry (ranging from mission-critical production services to applied R&amp;D), I found that the same design process worked quite well in solving real-world problems in production settings<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">2</a></sup>. In these settings, the sources of complexity are varied (hardware, software, distributed protocols, org boundaries, deployment cycles, customers…) and so are the end-goals (reliability, scale, code velocity, performance, dollar cost); but abstraction-driven design still enabled my teams to hit production goals quickly and safely.</p>

<p>This post is a dump of some rules to follow in this particular design process.</p>

<p>[1] <strong><em>Late-bind on designs</em></strong>. The goal of the design process is not to generate a single point solution, but to instead characterize the design space for a given problem: a single point should then fall naturally out of that space given the problem constraints. Converging early on a single design is harmful; the team should have the ability to jump from one part of the space to another right until a solution is picked.</p>

<p>[2] <strong><em>Each point solution is a DoS attack on the design process</em></strong>. Talking about individual designs in isolation slows down design. Talking about designs in the context of the design space accelerates design. New designs should be described in terms of the design space, so you can immediately convey their relative position compared to other point solutions. Expect a lot of statements of the form: “all solutions must do X”; “solution Y is just X with one change”; “any solution that does X has to also do Y”; etc. Talking about the design space rather than point designs allows you to efficiently late-bind on designs (as in point 1) by lowering the cost of switching designs at any point in the discussion.</p>

<p>[3] <strong><em>Think in parallel; Design together; Implement in parallel; Review together</em></strong>. Certain parts of the design and development process are creative and should be parallelized / sharded, while others require discipline and should be centralized / broadcast<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup>.</p>
<ul>
  <li>Thinking / brainstorming is a creative process and should happen in parallel with no coordination.</li>
  <li>Design should be centralized. The design space is (strongly consistent) shared state between team members; new ideas should be slotted into this space with synchronous coordination.</li>
  <li>Implementation can happen in parallel. After the centralized design phase, anyone should be able to implement any part of the design. Late-binding to developers is critical; it’s typical (and preferable) for the person implementing an idea to be different from the person who came up with it. Developers often get attached to ideas if they know they’ll get to implement it.</li>
  <li>Reviewing should be centralized. The code base is shared state. API changes in particular have to be reviewed carefully by multiple people to make sure they are not one-way doors. 
In a healthy design process, Design and Review end up being centralized bottlenecks, which is okay. (In research, you have the same four steps; but the carefully reviewed deliverable is typically a paper rather than a codebase).</li>
</ul>

<p>[4] <strong><em>Talk about the problem, not existing systems</em></strong>. It’s tempting to start the design process by looking at similar systems. This carries two types of risk:</p>
<ul>
  <li><em>Solution Complexity&nbsp;» Problem Complexity</em>: Problems have some fundamental complexity (e.g., there’s some space of solutions that can solve atomic commit); however, individual solutions can have unbounded complexity limited only by human creativity (e.g., what does phase 5 of this ‘two-phase commit’ protocol really do?) and exacerbated by project pivots (due to changing business needs or getting scooped in research), team churn (or graduating students), timeline pressures (for publishing papers or landing code). You will often expend more cycles understanding the existing design than you would solving the problem from first principles.</li>
  <li><em>Solution Bias</em>: Even good solutions can bias your thinking towards a particular part of the design space. For example, someone reading the Raft paper might think that collocating learners and acceptors is fundamental (which is not true for Paxos); or someone reading Paxos might think that quorums have to constitute a majority (which is not true for Flexible Paxos).
A great time to look at other systems is after the Design phase, to see if you can map those solutions to your space. Even better, you can often reverse-engineer the details of solutions simply by understanding where they fit in your design space.</li>
</ul>

<p>[5] <strong><em>Always talk about a second application</em></strong>. For each abstraction, the “app” is the layer above it. For example, a filesystem is an app for a block device; TCP is an app for IP. You should be able to describe the functionality of a layer without ever referring to the specifics of the app (e.g., you don’t need to know what a file is when talking about an SSD’s internals). Practically, even if you are implementing only one app, it helps to always consider a second app (or even implement one in tests); to prevent application specifics from leaking into the abstraction.</p>

<p>[6] <strong><em>For each abstraction, build one implementation; plan for a second; hope for a third</em></strong>. In the opposite direction, you don’t want the abstraction’s semantics to rely on its implementation details. One way to ensure this is to talk about multiple implementations in the design process. For instance, if your replication layer is TCP-based (but you plan to also have a UDP-based variant; and you are hopeful that it’ll also work over carrier pigeons), then keeping the UDP variant in your head will prevent you from defining semantics in terms of TCP/IP channels.</p>

<p>[7] <strong><em>Abstraction is not free</em></strong>. Each abstraction layer introduces new semantics that developers have to define precisely and then reason about in generic ways (e.g., a new filesystem has to work with every possible correct implementation of a block device). As a result, abstraction is a balancing act between two types of complexity: the complexity of concreteness (where you have to understand inessential detail – e.g., a filesystem developer reasoning about an FTL implementation) and the complexity of abstractness (where you have to understand a range of possibilities – e.g., a filesystem developer thinking about all the possible implementations of the block device trim API). Each time you add a layer of abstraction, have a precise characterization for why it has to exist, as well as the division of functionality between this layer and the ones around it.</p>

<p>[8] <strong><em>Be critical (but about the right things)</em></strong>. Researchers are used to seeing new ideas emerge from the primordial swamp and are often overly optimistic (part of the PhD training is to make students think more critically about their own ideas). In contrast, developers typically work with well-established systems; and as a result can be more critical of new ideas. New projects tend to look underbaked, feeble, and full of holes<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">4</a></sup>. But every well-established system at some point was just 2-3 people tossing around half-baked ideas. One way to approach design is to continually de-risk the pieces that are truly unknown; while deferring work on the pieces that are difficult but known. (In the opposite direction, researchers need to be more focused on details and practicality, but this happens naturally in an industry environment).</p>

<hr>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compromised Microsoft Key: More Impactful Than We Thought (271 pts)]]></title>
            <link>https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</link>
            <guid>36823007</guid>
            <pubDate>Sat, 22 Jul 2023 03:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr">https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</a>, See on <a href="https://news.ycombinator.com/item?id=36823007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">Microsoft</a> and <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">CISA</a> recently disclosed a security incident impacting multiple customers of Exchange Online and Outlook.com. According to Microsoft, this incident stemmed from a threat actor attributed to China, Storm-0558, acquiring a private encryption key (MSA key) and using it to forge access tokens for Outlook Web Access (OWA) and Outlook.com. Additionally, the threat actor reportedly exploited two security issues in Microsoft’s token verification process. </p><p>Microsoft have said that Outlook.com and Exchange Online were the only applications known to have been affected via the token forging technique, but Wiz Research has found that the compromised signing key was more powerful than it may have seemed, and was not limited to just those two services. Our researchers concluded that the compromised MSA key could have allowed the threat actor to forge access tokens for multiple types of Azure Active Directory applications, including every application that supports personal account authentication, such as SharePoint, Teams, OneDrive, customers’ applications that support the “login with Microsoft” functionality, and multi-tenant applications in certain conditions.</p><p>In addition, while Microsoft mitigated this risk by revoking the impacted encryption key and publishing <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">attacker IOCs,</a> we discovered that it may be difficult for customers to detect the use of forged tokens against their applications due to lack of logs on crucial fields related to the token verification process.</p><p>Why is it so impactful?&nbsp; Identity provider’s signing keys are probably the most powerful secrets in the modern world.&nbsp; For example, they are much more powerful than TLS keys. Even if an attacker got access to the google.com TLS key, they would still need to somehow impersonate a google.com server to gain significant impact. With identity provider keys, one can gain immediate single hop access to everything, any email box, file service or cloud account. This isn’t a Microsoft specific issue, if a signing key for Google, Facebook, Okta or any other major identity provider leaks, the implications are hard to comprehend. Our industry – and especially cloud service providers – must commit to a greater level of security and transparency concerning how they protect critical keys such as this one, to prevent future incidents and limit their potential impact.&nbsp;</p><p>In this post, we will share how we were able to confirm which private key was acquired by the threat actor and how we determined its permissions. We will also unpack some of the technical aspects of this incident and help detect potential use of this compromised key within your environments.</p><h2><span></span><a id="compromised-consumer-signing-key--who-are-you-5"></a>Compromised consumer signing key – who are you?&nbsp;</h2><p>On July 11th, 2023, Microsoft revealed that a malicious actor had obtained an MSA consumer signing key, allowing them to forge access tokens for Exchange Online and Outlook.com accounts.</p><p>Determined to learn more about the incident, we launched an investigation.</p><p>First, we checked which keys could sign OpenID tokens for Microsoft accounts and Azure Active Directory applications. We therefore examined Microsoft’s <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official documentation for OpenID token verification</a>. Interestingly, we discovered that all Azure personal account v2.0 applications depend on a list of <a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">8 public keys</a>, and all Azure multi-tenant v2.0 applications with Microsoft account enabled depend on a list of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">7 public keys</a> (at the time of writing).</p><p>Using the Internet Archive’s Wayback Machine, we noticed that one of the listed public keys that had been present <a href="http://web.archive.org/web/20160801114452/https:/login.microsoftonline.com/common/discovery/v2.0/keys">since at least 2016</a> was replaced sometime between <a href="http://web.archive.org/web/20230627150747/https:/login.microsoftonline.com/common/discovery/v2.0/keys">June 27th</a> and <a href="http://web.archive.org/web/20230705095601/https:/login.microsoftonline.com/common/discovery/v2.0/keys">July 5th</a>, 2023, matching the time frame in which Microsoft replaced the acquired key according to their blog post.</p><p><em>Metadata of the public key replaced between June 27th and July 5th</em>&nbsp;</p><p>The old public key’s certificate revealed it was issued on April 5th, 2016, and expired on April 4th, 2021, and its thumbprint matched the thumbprint of the key Microsoft <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=d4b4cccda9228624656bff33d8110955779632aa">listed in their latest blog post</a>, named “Thumbprint of acquired signing key”:</p><div><p>The decoded certificate of the old key (1LTMzakihiRla_8z2BEJVXeWMqo). Obtained from the list intended June 27th, 2023 version of the certificate list for Azure common (mixed audience) applications.</p></div><p>This led us to believe that although the compromised key acquired by Storm-0558 was a private key designed for Microsoft's MSA tenant in Azure, it was also able to sign OpenID v2.0 tokens for multiple types of Azure Active Directory applications.</p><h2><span></span><a id="what-is-the-significance-of-a-compromised-openid-signing-key-16"></a>What is the significance of a compromised OpenID signing key?&nbsp;</h2><p>The Azure identity platform publishes multiple lists of trusted keys scoped to different application types. These serve to validate the integrity of tokens which are issued by Azure Active Directory (AAD). During the authentication process for an AAD application, the application must confirm the token's authenticity by verifying its signature against the correct trusted public key list. This verification determines whether the token should be trusted.</p><p># Azure Active Directory multi-tenant applications:&nbsp;<br></p><p><em>Azure Active Directory public certificates’ lists</em>&nbsp;</p><p>If any of the keys from one of these lists are compromised, there is a significant risk for applications using that list for validation. Such a compromise could enable unauthorized parties to forge valid access tokens for consumption by any application that depends on the Azure identity platform under certain conditions (see below).</p><div><p>The risks of compromised OpenID signing key </p></div><p>Based on what we can deduce from Microsoft’s blog post, Storm-0558 seemingly managed to obtain access to one of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">several keys</a> that were intended for signing and verifying AAD access tokens. The compromised key was trusted to sign any OpenID v2.0 access token for personal accounts and mixed-audience (multi-tenant or personal account) AAD applications.</p><div><p>The types of applications that could trust the key acquired by Storm-0558</p></div><p>In other words, Storm-0558 could have theoretically used the private key it acquired to forge tokens to authenticate as any user to any affected application that trusts Microsoft OpenID v2.0 mixed audience and personal-accounts certificates.</p><h2><span></span><a id="which-applications-are-affected-27"></a>Which applications are affected?&nbsp;</h2><p>Based on our analysis, only Azure Active Directory applications that work with Microsoft’s OpenID v2.0 were affected. Version 1.0 applications were not using the compromised key for token validation and therefore were not affected.</p><h3><span></span><a id="applications-supporting-personal-microsoft-accounts-only-29"></a><strong>Applications supporting Personal Microsoft accounts only</strong></h3><p>Any Azure Active Directory application that supports “Personal Microsoft accounts only” and works against Microsoft’s v2.0 protocol was affected<strong>. This includes </strong>managed Microsoft applications, such as Outlook, SharePoint, OneDrive, and Teams, as well as customers’ applications that support Microsoft Account authentication, including those who allow the “Login with Microsoft” functionality.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-and-personal-microsoft-accounts-eg-skype-xbox-31"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant) and personal Microsoft accounts (e.g. Skype, Xbox)</strong></h3><p>Any Azure Active Directory application that supported “mixed audience” and works against Microsoft’s v2.0 protocol was affected as well. The threat actor could forge valid access tokens and impersonate application users who signed in with their Personal Microsoft account.</p><p>To restrict the power of MSA keys in impersonating organizational accounts, Microsoft introduced an extension to the OpenID protocol. This extension advises developers to validate the issuer claim by comparing it with the issuer field in the list of the OpenID public keys. By doing this, it aims to prevent an MSA key from signing access tokens with an issuer different than the MSA tenant (9188040d-6c67-4c5b-b112-36a304b66dad). This extension is specific to Microsoft and the responsibility of its implementation rests with the application owner. Therefore, there is a concern that many applications lack this procedure and as a result, the threat actor could potentially impersonate organizational accounts as well (according to Microsoft’s blogpost, OWA was affected by a similar issue).</p><p>To assist Azure developers with adopting this validation functionality, Microsoft added it to their <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/issues/2134">official Azure SDK</a> on July 12.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-35"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant)</strong></h3><p>IIf the multi-tenant application is configured to rely on the “<a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">common</a>” v2.0 keys endpoint (instead of “Organizations”), then it is affected but also should be considered misconfigured. The official Microsoft <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">documentation</a> is not clear on when the “common” endpoint should be used, and therefore, some multi-tenant applications could be affected as well.</p><h3><span></span><a id="applications-supporting-accounts-in-this-organizational-directory-only-singletenant-37"></a><strong>Applications supporting accounts in this organizational directory only (Singletenant)</strong></h3><p>Single tenant applications were not affected.&nbsp;</p><div><p>How different types of users may have been affected depending on the application type and whether it was properly validating access tokens</p></div><h2><span></span><a id="how-does-key-forging-work-40"></a>How does key forging work?&nbsp;</h2><p>OpenID keys are fundamentally JWTs signed by an authorized private key. As part of the Azure Active Directory token validation procedure, the app developer must confirm that the key is indeed signed by the relevant authority for the intended scope, and that the token's <code>aud</code> field matches the targeted application’s scope.</p><p>To confirm whether the token was truly signed by a trusted Azure authority, the application developer queries a metadata endpoint (named <code>jwks_uri</code>) to pull the permitted certificates for signature verification and verify the token against it.</p><p>To forge a valid access token, the threat actor could have crafted a JWT token, populated it with a victim’s data (e.g. email address), and finally signed it with the trusted compromised key that is listed under the Azure Active Directory public certificates’ endpoint. By submitting the signed token to a targeted application, the malicious actor could have then impersonated the victim.</p><p>Here is a fictitious example of such a forged OpenID token signed by the compromised encryption key, <code>1LTMzakihiRla_8z2BEJVXeWMqo</code>:</p><p>According to Microsoft's guidelines, in order for the token to be considered valid, the issuer claim (<code>iss</code>) must be set to https: //sts.windows.net/9188040d-6c67-4c5b-b112-36a304b66dad/v2.0 since it was specified in the issuer field within the <code>jwks_uri</code> endpoint. As for the tenant ID claim (<code>tid</code>), it must accordingly be set to <code>9188040d-6c67-4c5b-b112-36a304b66dad</code>, the MSA tenant’s ID.</p><p>For AAD mixed-audience applications (multi-tenant and personal-account), any token signed by the MSA tenant for an Azure AD account could be deemed valid, as long as it impersonates a personal account.</p><p>For additional details, check out Microsoft's <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official guidelines</a> on how to verify ID Tokens.</p><h2><span></span><a id="are-azure-customers-still-at-risk-49"></a>Are Azure customers still at risk?&nbsp;</h2><p>Due to Microsoft's revocation of the compromised key, Azure Active Directory applications will no longer accept forged tokens as valid tokens. Tokens with extended expiration dates will also be rejected by these applications.</p><p>However, during previously established sessions with customer applications prior to the revocation, the malicious actor could have leveraged its access to establish persistence. This could have occurred by leveraging the obtained application permissions to issue application-specific access keys or setting up application-specific backdoors. A notable example of this is how, prior to Microsoft’s mitigation, Storm-0558 issued valid Exchange Online access tokens by forging access tokens for Outlook Web Access (OWA).</p><p>There is another potential risk to applications that retained copies of the AAD public keys prior to Microsoft's certificate revocation. Applications that rely on local certificate stores or cached keys and still trust the compromised key remain susceptible to token forgery. It is imperative for these applications to immediately refresh the list of trusted certificates. Microsoft advises refreshing the cache of local stores and certificates at least once a day.</p><h2><span></span><a id="recommendations-for-azure-users-53"></a>Recommendations for Azure users&nbsp;</h2><p>To identify whether a compromised key was used in your environment, identify all potentially affected applications in your environment, search for forged tokens usage (as explained in the next section) and leverage the Indicators of Compromise (IoCs) <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=Indicators%20of%20compromise">published by Microsoft</a> on their blog to look for any activity that originates from the IP addresses provided by Microsoft.</p><p>In addition, make sure that none of the applications use a cached version of the Microsoft OpenID public certificates, and if so, refresh the cache.</p><p>Microsoft has added additional verifications to the official Azure SDK, which are designed to prevent the use of MSA keys to authenticate to organization accounts. Users of the package are advised to update it to the <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet">latest version</a>.</p><h2><span></span><a id="how-to-detect-the-compromised-key-in-your-environment-57"></a>How to detect the compromised key in your environment&nbsp;</h2><p>Since the threat actor can forge access tokens offline, there is no trail in the Azure portal for token issuance. The only way for cloud customers to identify whether the key was used to target their apps or users is by reviewing application-specific logs for potentially affected AAD apps. Therefore, application owners who want to protect their systems will have to check whether a forged token has been used against their applications.</p><p>To the best of our knowledge, the only affected applications were those that utilized Microsoft v2.0 access token verification using the endpoints ”<a href="https://login.microsoftonline.com/common/discovery/v2.0/keyshttps:/login.microsoftonline.com/common/discovery/v2.0/keys%20common">https://login.microsoftonline.com/common/discovery/v2.0/keyscommon</a>“ and “<a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">https://login.microsoftonline.com/consumers/discovery/v2.0/keys</a>“. These parameters make it feasible to filter out applications that were not exposed to this issue.&nbsp;</p><p>First, to identify which AAD applications in your environment might be affected, you can run the following Azure CLI command:&nbsp;</p><p>Additionally, your AAD applications might also be associated with Azure WebApps. To identify which AAD apps are redirecting to any of your WebApps, you can run the following CLI command:&nbsp;</p><p>Next, to identify potentially malicious activities in applications, it is necessary to examine suspicious authentication attempts via OpenID tokens signed by the compromised key. This can be done by unpacking the access tokens used against the application and searching for the string <code>1LTMzakihiRla_8z2BEJVXeWMqo</code> within the <code>kid</code> field of the JOSE Header.&nbsp;</p><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=inactive%20MSA">According to Microsoft</a>, the compromised key was inactive and therefore any access token signed by this key must be considered suspicious.</p><p>Unfortunately, there is a lack of standardized practices when it comes to application-specific logging. Therefore, in most cases, application owners do not have detailed logs containing the raw access token or its signing key. As a result, identifying and investigating such events can prove exceedingly challenging for app owners.</p><p>When examining an AAD application configured solely for multi-tenant authentication (without support for Microsoft personal accounts), it is possible to detect forged tokens by filtering for `iss` and `tid` claims within the access token. Applications commonly use these fields and they are more likely to be present in application logs. Moreover, any attempt to connect with an access token signed by the MSA tenant ID <code>9188040d-6c67-4c5b-b112-36a304b66dad</code> may indicate the use of a compromised key.</p><p>Finally, if you’ve enabled <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appservicehttplogs">HTTP Logs</a> in your WebApp, you might be able to see which IP addresses have accessed your application. Based on Microsoft’s blogpost, the following IP addresses are associated with the threat actor, so you should validate if your WebApp might have been impacted by running the following query in Log Analytics for each of your potentially affected Web Apps:&nbsp;</p><p>For additional guidance on searching for signs of persistence in your environment, see our <a href="https://www.wiz.io/blog/hunting-for-signs-of-persistence-in-the-cloud-an-ir-guide#hunting-for-signs-of-persistence-in-azure-24">“CircleCI Incident Sign of Persistence” blog</a>.&nbsp;</p><h2><span></span><a id="key-takeaways-72"></a>Key Takeaways&nbsp;</h2><p>The full impact of this incident is much larger than we Initially understood it to be. We believe this event will have long lasting implications on our trust of the cloud and the core components that support it, above all, the identity layer which is the basic fabric of everything we do in cloud. We must learn from it and improve.</p><p>At this stage, it is hard to determine the full extent of the incident as there were millions of applications that were potentially vulnerable, both Microsoft apps and customer apps, and the majority of them lack the sufficient logs to determine if they were compromised or not. However there are some critical actions items that application owners should perform. The first and foremost is to update their Azure SDK to the latest version and ensure their application cache is updated, otherwise their apps may still be vulnerable to a threat actor using the compromised key.</p><p>We will continue to closely monitor this incident and provide updates; this is still an ongoing investigation and there are many unanswered questions (how did the threat actor acquire the key? When exactly did it happen? Were other keys compromised as well?). Finally, we want to thank the Microsoft team for working closely with us on this blog and helping us ensure it is technically accurate.</p><div><div><p><span>See for yourself...</span></p><p>Learn what makes Wiz the platform to enable your cloud security operation</p></div><svg viewBox="0 0 162 177" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#request-demo-block_svg__a)"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect><path fill="#0254EC" d="M1 1h160v22H1z"></path><g clip-path="url(#request-demo-block_svg__b)"><path d="M23.151 7.883c.202.21.593.315.825.36a.03.03 0 0 1 .017.011.032.032 0 0 1 .007.02.032.032 0 0 1-.007.02.03.03 0 0 1-.017.01c-.232.047-.623.152-.825.361-.19.197-.29.57-.337.815a.03.03 0 0 1-.011.018.029.029 0 0 1-.038-.001.031.031 0 0 1-.01-.019c-.034-.228-.123-.572-.354-.813-.202-.21-.593-.314-.825-.36a.03.03 0 0 1-.017-.01.032.032 0 0 1 0-.04.03.03 0 0 1 .017-.011c.233-.046.624-.15.825-.36.2-.21.302-.617.346-.859a.031.031 0 0 1 .01-.018.029.029 0 0 1 .038 0c.005.005.009.011.01.018.044.242.145.649.346.858Zm-8.61 1.626v6.395c0 .025.01.05.027.068a.09.09 0 0 0 .065.028h1.365a.09.09 0 0 0 .065-.028.098.098 0 0 0 .027-.068V9.509c0-.025-.01-.05-.027-.067a.09.09 0 0 0-.065-.028h-1.365a.089.089 0 0 0-.065.028.096.096 0 0 0-.027.067Zm2.132 6.367a.087.087 0 0 0 .034.113c.012.007.026.01.04.01h4.957a.09.09 0 0 0 .066-.027.098.098 0 0 0 .027-.068v-1.252a.098.098 0 0 0-.027-.068.093.093 0 0 0-.066-.028h-2.5a.08.08 0 0 1-.041-.01.087.087 0 0 1-.032-.115l2.6-4.892a.087.087 0 0 0-.002-.084.083.083 0 0 0-.03-.03.08.08 0 0 0-.04-.011h-4.91a.089.089 0 0 0-.066.027.099.099 0 0 0-.028.068v1.387a.1.1 0 0 0 .028.068.09.09 0 0 0 .066.028h2.18c.015 0 .029.003.041.01a.087.087 0 0 1 .034.113l-2.331 4.761Zm-2.706-6.463h-1.435a.09.09 0 0 0-.052.017.095.095 0 0 0-.033.045l-1.01 2.755a.034.034 0 0 1-.012.015.031.031 0 0 1-.037.002.033.033 0 0 1-.012-.015L10.17 9.494a.166.166 0 0 0-.056-.069.157.157 0 0 0-.081-.03h-.002a.157.157 0 0 0-.084.03.166.166 0 0 0-.057.07l-1.207 2.737a.033.033 0 0 1-.012.015.032.032 0 0 1-.036-.001.033.033 0 0 1-.012-.016l-1.01-2.755a.095.095 0 0 0-.034-.045.09.09 0 0 0-.052-.017H6.092a.09.09 0 0 0-.043.011.094.094 0 0 0-.033.031.099.099 0 0 0-.01.09l2.373 6.431a.032.032 0 0 0 .029.022.031.031 0 0 0 .019-.005.034.034 0 0 0 .012-.014l1.446-3.013a.166.166 0 0 1 .06-.069.157.157 0 0 1 .17 0c.027.017.047.04.06.069l1.446 3.013c.003.006.008.011.013.014a.032.032 0 0 0 .036-.001.035.035 0 0 0 .011-.016l2.372-6.432a.1.1 0 0 0-.01-.089.09.09 0 0 0-.076-.042Z" fill="#fff"></path></g><path fill="#fff" d="M-22 34h192v136H-22z"></path><path d="M111 45.416h21.6" stroke="url(#request-demo-block_svg__c)" stroke-linecap="round"></path><path d="M76.2 45.416h31.2" stroke="#FFAB31" stroke-linecap="round"></path><ellipse cx="142.2" cy="46.631" rx="9.6" ry="9.715" fill="#0073CF"></ellipse><path d="M145.674 37.96c-.022-.123-.043-.243 0-.363a.854.854 0 0 0-.059-.048 9.412 9.412 0 0 0-1.286-.393c-.402-.085-.801-.15-1.195-.195a9.608 9.608 0 0 0-.934-.045c-3.792 0-7.071 2.225-8.631 5.456.172.289.231.631.283.927.012.072.024.14.037.205.16.79.418 1.501.988 2.107.19.2.339.436.489.672.198.31.396.622.689.86.358.293.738.546 1.195.606 1.473.196 2.378 2.156 1.608 3.373-.244.386-.187.732.14 1.09a6.8 6.8 0 0 1 .546.712c.228.327.457.654.757.924.181.164.205.4.201.635a11.3 11.3 0 0 1-.16 1.68 9.534 9.534 0 0 0 2.264.174c-.011-.45.139-.77.627-.87a.993.993 0 0 0 .617-.462c.378-.611.917-1.05 1.466-1.483.443-.351.736-.789.8-1.37.07-.637 0-.737-.614-.808-.183-.021-.366-.038-.549-.054l-.28-.026c-.024-.003-.05-.004-.076-.006-.145-.01-.308-.02-.341-.152-.122-.488-.486-.64-.85-.793-.14-.059-.28-.117-.407-.195-.614-.375-1.249-.65-1.982-.733-.629-.07-1.387-.304-1.59-.86-.101-.276-.299-.47-.494-.662-.252-.249-.499-.491-.516-.895-.004-.131-.164-.291-.341-.28-.154.009-.163.127-.172.24a.797.797 0 0 1-.009.089c-.031.164-.077.324-.258.355-.21.033-.308-.133-.393-.289-.247-.455-.193-1.234.098-1.492.505-.444 1.246-.47 1.75-.055l.047.04c.077.07.155.14.268.1.164-.06.166-.22.153-.358-.033-.38.092-.683.36-.948.287-.282.429-.628.392-1.048-.022-.24.032-.504.332-.495.386.011.685-.164.989-.342.067-.04.135-.08.204-.117.273-.151.391-.276.251-.613-.151-.36.081-.642.485-.657.075-.002.15.008.225.018.081.011.161.022.241.017.225-.013.419-.144.483-.348.058-.193-.06-.21-.18-.228-.06-.009-.12-.017-.159-.047a2.994 2.994 0 0 0-.21-.144c-.12-.077-.24-.154-.336-.256-.319-.338-.697-.573-1.104-.782-.872-.448-1.536-.026-1.523.975.002.14.002.282-.004.422-.007.13-.048.25-.175.302-.153.062-.306-.002-.361-.131-.186-.437-.549-.652-.914-.868a7.05 7.05 0 0 1-.239-.145c-.387-.246-.387-.548-.081-.872.29-.306.601-.586.948-.824.175-.117.345-.237.402-.464.07-.268.188-.517.496-.537.238-.015.322.158.405.33.025.052.051.105.08.152.284.453.63.87 1.11 1.085.179.08.333-.028.493-.14.111-.078.224-.158.351-.18.142-.024.345-.064.332-.27-.013-.211-.208-.26-.38-.3a1.786 1.786 0 0 0-.09-.017.844.844 0 0 1-.164-.04c-.19-.078-.347-.207-.295-.436.051-.217.236-.293.444-.293.264-.002.461.14.631.324.122.133.241.27.359.405.25.287.501.574.778.83.544.504 1.234.357 1.521-.26.066-.142.041-.28.017-.417ZM150.261 41.353a9.749 9.749 0 0 1 1.539 5.278c0 .436-.028.866-.084 1.288a.311.311 0 0 1-.176.088 5.561 5.561 0 0 1-.115-.102c-.092-.082-.184-.165-.283-.236-.142-.1-.304-.128-.389.074l-.044.115c-.073.202-.149.412-.399.397l-.082-.004c-.343-.017-.693-.034-1.004-.273-1.036-.8-1.198-2.298-.483-3.188.096-.12.185-.278.199-.426.052-.666.526-.902 1.04-1.11.031-.013.062-.025.094-.036.082-.03.164-.061.24-.104.094-.054.162-.147.131-.265-.033-.12-.138-.148-.249-.14-.035.003-.07.009-.105.015a.905.905 0 0 1-.1.014c-.046.003-.093.008-.141.013-.221.024-.453.049-.563-.19-.093-.202.041-.27.179-.34.076-.038.154-.077.195-.14a7.55 7.55 0 0 1 .499-.61l.101-.118Z" fill="#71D96A"></path><path d="M139.704 46.19a.398.398 0 0 1 .112.014l.081.026h.001c.283.088.624.195.539.527-.05.194-.272.125-.481.06a1.659 1.659 0 0 0-.207-.056.56.56 0 0 1-.195-.073 1.113 1.113 0 0 0-.135-.061c-.144-.057-.294-.117-.256-.29.035-.165.18-.156.32-.148.06.004.118.007.167-.003l-.002.002.056.003ZM141.204 46.935a1.417 1.417 0 0 1-.142-.025l-.002-.002c-.029.004-.06.006-.091.008-.149.01-.307.02-.289.223.022.24.266.246.452.237.034-.001.073.002.114.005.157.012.336.025.319-.205-.014-.19-.192-.216-.361-.24Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM75 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM136.2 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path d="M45 87.919v25.501" stroke="url(#request-demo-block_svg__d)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251-30 7.286-30 25.502" stroke="url(#request-demo-block_svg__e)" stroke-linecap="round"></path><path d="M45 87.918c0 21.251-30 7.286-30 25.501" stroke="url(#request-demo-block_svg__f)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251 30 7.286 30 25.502" stroke="#FFAB31" stroke-linecap="round"></path><path d="M45 87.918c0 21.251 30 7.286 30 25.501" stroke="url(#request-demo-block_svg__g)" stroke-linecap="round"></path><path d="M105 87.918c0 21.251 31.2 7.286 31.2 25.501" stroke="#FFAB31" stroke-linecap="round"></path><path d="M136 126c0 21.667-30 7.429-30 26" stroke="url(#request-demo-block_svg__h)" stroke-linecap="round"></path><path d="M75 126c0 21.251 31.2 7.286 31.2 25.501" stroke="url(#request-demo-block_svg__i)" stroke-linecap="round"></path><path d="M79.8 81.846h20.4" stroke="url(#request-demo-block_svg__j)" stroke-linecap="round"></path><path d="M111 81.846h19.2" stroke="url(#request-demo-block_svg__k)" stroke-linecap="round"></path><path d="M70.2 81.846H51" stroke="url(#request-demo-block_svg__l)" stroke-linecap="round"></path><path d="M81 156h19.2" stroke="url(#request-demo-block_svg__m)" stroke-linecap="round"></path><path d="M69.2 156H50" stroke="url(#request-demo-block_svg__n)" stroke-linecap="round"></path><path d="M39 81.846H21" stroke="url(#request-demo-block_svg__o)" stroke-linecap="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M15 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FF1721"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#3679DB"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM75 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM45 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM135 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM15 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#36AD82"></path></g><rect x="0.5" y="0.574" width="161" height="175" rx="3" stroke="#fff"></rect><defs><linearGradient id="request-demo-block_svg__c" x1="134.657" y1="45.416" x2="111.514" y2="45.416" gradientUnits="userSpaceOnUse"><stop stop-color="#0073CF"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__d" x1="0" y1="113.42" x2="0" y2="95.569" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__e" x1="45.001" y1="77.168" x2="60.065" y2="84.104" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__f" x1="15.001" y1="113.598" x2="30.065" y2="120.534" gradientUnits="userSpaceOnUse"><stop stop-color="#71D96A"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__g" x1="45" y1="87.918" x2="75.294" y2="113.065" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#36AD82"></stop></linearGradient><linearGradient id="request-demo-block_svg__h" x1="121" y1="134" x2="121" y2="144.5" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__i" x1="90.6" y1="126" x2="90.6" y2="151.501" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__j" x1="79.8" y1="81.846" x2="103.037" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__k" x1="111" y1="81.846" x2="130.2" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__l" x1="70.327" y1="81.846" x2="48.457" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__m" x1="80.873" y1="156" x2="102.743" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__n" x1="69.327" y1="156" x2="47.457" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__o" x1="37.925" y1="81.719" x2="21" y2="81.719" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FF1721"></stop></linearGradient><clipPath id="request-demo-block_svg__a"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect></clipPath><clipPath id="request-demo-block_svg__b"><path fill="#fff" transform="translate(6 7)" d="M0 0h18v9H0z"></path></clipPath></defs></svg></div><h2><span></span><a id="references-77"></a>References&nbsp;</h2><ul><li><p><a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/">https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/</a>&nbsp;</p></li><li><p><a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a</a>&nbsp;</p></li><li><p><a href="https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/">https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/</a>&nbsp;</p></li><li><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/</a>&nbsp;</p></li><li><p><a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files">https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files</a>&nbsp;</p></li><li><p><a href="https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c">https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c</a>&nbsp;</p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet search tips (199 pts)]]></title>
            <link>https://gwern.net/search</link>
            <guid>36822880</guid>
            <pubDate>Sat, 22 Jul 2023 03:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gwern.net/search">https://gwern.net/search</a>, See on <a href="https://news.ycombinator.com/item?id=36822880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-metadata">
        <p>A description of advanced tips and tricks for effective Internet research of papers/​books, with real-world examples.</p>
        
        
      </div><div id="markdownBody">
        <div>
          <blockquote>
            <p>Over time, I developed a certain google-fu and expertise in finding references, papers, and books online. Some of these tricks are not well-known, like checking the Internet Archive (IA) for books.</p>
            <p>I try to write down my search workflow, and give general advice about finding and hosting documents, with <a href="#case-studies">demonstration case studies</a>⁠.</p>
          </blockquote>
        </div>
        <p>Google-fu search skill is something I’ve prided myself ever since elementary school, when the librarian challenged the class to find things in the almanac; not infrequently, I’d win. And I can still remember the exact moment it dawned on me in high school that much of the rest of my life would be spent dealing with searches, paywalls, and broken links. The Internet is the greatest almanac of all, and to the curious, a never-ending cornucopia, so I am sad to see many fail to find things after a cursory search—or not look at all. For most people, if it’s not the first hit in Google/​Google Scholar, it doesn’t exist. Below, I reveal my best Internet search tricks and try to provide a rough flowchart of how to go about an online search, explaining the subtle tricks and <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">tacit knowledge</a> of search-fu.</p>
        <p>Roughly, we need to have proper tools to create an occasion for a search: we cannot search well if we avoid searching at all. Then each search will differ by which search engine &amp; type of medium we are searching—they all have their own quirks, blind spots, and ways to modify a failed search. Often, we will run into walls, each of which has its own circumvention methods. But once we have <em>found</em> something, we are not done: we would often be foolish &amp; short-sighted if we did not then make sure it <em>stayed</em> found. Finally, we might be interested in advanced topics like ensuring in advance resources can be found in the future if need be, or learning about new things we might want to then go find. To illustrate the overall workflow &amp; provide examples of tacit knowledge, I include many Internet case studies of finding hard-to-find things.</p>
        <section id="papers">
          <h2><a href="#papers" title="Link to section: § 'Papers'">Papers</a></h2>
          <section id="search">
            <h2><a href="#search" title="Link to section: § 'Search'">Search</a></h2>
            <section id="preparation">
              <h3><a href="#preparation" title="Link to section: § 'Preparation'">Preparation</a></h3>
              <p><span>Do or do not; there is no try.</span> The first thing you must do is develop a habit of searching when you have a question: “Google is your friend.” Your only search guaranteed to fail is the one you never run. ( <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences" id="alexander-2009-trivial-inconveniences" data-link-icon="LW" data-link-icon-type="text" title="'Beware Trivial Inconveniences', Alexander 2009">Beware trivial inconveniences!</a>)</p>
              <ol>
                <li>
                  <p><strong>Query Syntax Knowledge</strong></p>
                  <p>Know your basic <a href="https://en.wikipedia.org/wiki/Logical_connective" data-link-icon="wikipedia" data-link-icon-type="svg">Boolean operators</a> &amp; the <a href="https://support.google.com/websearch/answer/2466433" data-link-icon="alphabet" data-link-icon-type="svg">key G search operators</a>: double quotes for exact matches, hyphens for negation/​exclusion, and <code>site:</code> for search a specific website or specific directory of that website (eg. <code>foo site:gwern.net/docs/genetics/</code>, or to exclude folders, <code>foo site:gwern.net -site:gwern.net/docs/</code>). You may also want to play with <a href="https://gwern.net/doc/www/www.google.com/ad76c5678e80cfed004ec8c7d6704944cee44b28.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.google.com/advanced_search" title="(Original URL: https://www.google.com/advanced_search )">Advanced Search</a> to understand what is possible. (There are <a href="https://gwern.net/doc/www/ahrefs.com/dc5e68b27bd732a5613f29f62ee9596826aaafc8.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ahrefs.com/blog/google-advanced-search-operators/" title="(Original URL: https://ahrefs.com/blog/google-advanced-search-operators/ )">many more G search operators</a> ( <a href="https://docs.google.com/document/d/1ydVaJJeL1EYbWtlfj9TPfBTE5IBADkQfZrQaBZxqXGs/mobilebasic" data-link-icon="worddoc" data-link-icon-type="svg" title="Google's Advanced Search Operators">Russell description</a>) but they aren’t necessarily worth learning, because they implement esoteric functionality and most seem to be buggy<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>⁠.)</p>
                </li>
                <li>
                  <p><strong>Hotkey Shortcuts</strong> (<em>strongly recommended</em>)</p>
                  <p>Enable some kind of hotkey search with both prompt and copy-paste selection buffer, to turn searching Google (G)/​Google Scholar (GS)/​Wikipedia (WP) into a reflex.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> You should be able to search instinctively within a split second of becoming curious, with a few keystrokes. (If you can’t use it while IRCing without the other person noting your pauses, it’s not fast enough.)</p>
                  <p>Example tools: <a href="https://en.wikipedia.org/wiki/AutoHotkey#Examples" data-link-icon="wikipedia" data-link-icon-type="svg">AutoHotkey</a> (Windows), <a href="https://en.wikipedia.org/wiki/Quicksilver_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Quicksilver</a> (Mac), <a href="https://github.com/astrand/xclip" data-link-icon="github" data-link-icon-type="svg">xclip</a>+<a href="https://web.archive.org/web/20220427164018/https://en.wikipedia.org/wiki/Surfraw" data-link-icon="internetarchive" data-link-icon-type="svg">Surfraw</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/StumpWM" data-link-icon="wikipedia" data-link-icon-type="svg">StumpWM’s</a> <a href="https://github.com/stumpwm/stumpwm-contrib/blob/master/util/searchengines/README.org" data-link-icon="github" data-link-icon-type="svg"><code>search-engines</code></a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Xmonad" data-link-icon="wikipedia" data-link-icon-type="svg">XMonad’s</a> <a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Actions-Search.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Actions.Search</code></a>⁠/ ​<a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Prompt-Shell.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Prompt.Shell</code></a> (Linux). <a href="https://duckduckgo.com/bangs#bangs-list">DuckDuckGo</a> offers <a href="https://duckduckgo.com/bang_lite.html">‘bangs’</a>⁠, within-engine special searches (most are equivalent to a kind of Google <code>site:</code> search), which can be used similarly or combined with prompts/​macros/​hotkeys.</p>
                  <p><a href="https://wiki.haskell.org/Xmonad/Config_archive/Gwern's_xmonad.hs" data-link-icon="code" data-link-icon-type="svg">I make</a> heavy use of the XMonad hotkeys, which I wrote, and which gives me window manager shortcuts: while using any program, I can highlight a title string, and press <code>Super-shift-y</code> to open the current selection as a GS search in a new Firefox tab within an instant; if I want to edit the title (perhaps to add an author surname, year, or keyword), I can instead open a prompt, <code>Super-y</code>, paste with <code>C-y</code>, and edit it before a <code>\n</code> launches the search. As can be imagined, this is extremely helpful for searching for many papers or for searching. (There are in-browser equivalents to these shortcuts but I disfavor them because they only work if you are in the browser, typically require more keystrokes or mouse use, and don’t usually support hotkeys or searching the copy-paste selection buffer: <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠, <a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a>)</p>
                </li>
                <li>
                  <p><strong>Web Browser Hotkeys</strong></p>
                  <p>For navigating between sets of results and entries, you should have good command of your tabbed web browser. You should be able to go to the address bar, move left/​right in tabs, close tabs, open new blank tabs, unclose tabs, go to the <em>n</em><sup>th</sup> tab, etc. (In <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠/ ​<a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a> Win/​Linux, those are, respectively: <code>C-l</code>, <code>C-PgUp</code>/​<code>C-PgDwn</code>, <code>C-w</code>, <code>C-t</code>/​<code>C-T</code>, <code>M-[1–9]</code>.)</p>
                </li>
              </ol>
            </section>
            <section id="searching">
              <h3><a href="#searching" title="Link to section: § 'Searching'">Searching</a></h3>
              <p>Having launched your search in, presumably, Google Scholar, you must navigate the GS results. For GS, it is often as simple as clicking on the <code>[PDF]</code> or <code>[HTML]</code> link in the top right which denotes (what GS believes to be) a fulltext link, eg:</p>
              <figure>
                <img alt="An example of a hit in Google Scholar: note the [HTML] link indicating there is a fulltext Pubmed version of this paper (often overlooked by newbies)." decoding="async" height="387" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlescholar-search-highlightfulltextlink.png" width="1400">
                
              </figure>
              <p><span>GS: if no fulltext in upper right, look for soft walls.</span> In GS, remember that a fulltext link is <em>not</em> always denoted by a “[PDF]” link! Check the top hits by hand: there are often ‘soft walls’ which block web spiders but still let you download fulltext (perhaps after substantial hassle, like SSRN).</p>
              <p>Note that GS supports other useful features like alerts for search queries, alerts for anything citing a specific paper, and reverse citation searches (to followup on a paper to look for failures-to-replicate or criticisms of it).</p>
              <section id="drilling-down">
                <h4><a href="#drilling-down" title="Link to section: § 'Drilling Down'">Drilling Down</a></h4>
                <p>A useful hit may not turn up immediately. Life is like that.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> You may have to get creative:</p>
                <ul>
                  <li>
                    <p><strong>Title searches</strong>: if a paper fulltext doesn’t turn up on the first page, start tweaking (hard rules cannot be given for this, it requires development of <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">“mechanical sympathy”</a> and asking a mixture of “how would a machine think to classify this” and “how would other people think to write this”):</p>
                  </li>
                  <li>
                    <p><strong>The Golden Mean</strong>: Keep mind when searching, you want some but not too many or too few results. A few hundred hits in GS is around the sweet spot. If you have less than a page of hits, you have made your search too specific.</p>
                    <p>If nothing is turning up, try trimming the title. Titles tend to have more errors towards the end than the beginning, and people often drop So start cutting words off the end of the title to broaden the search. Think about what kinds of errors you make when you recall titles: you drop punctuation or subtitles, substitute in more familiar synonyms, or otherwise simplify it. (How might OCR software screw up a title?)</p>
                    <p>Pay attention to technical terms that pop up in association with your own query terms, particularly in the snippets or full abstracts. Which ones look like they might be more popular than yours, or indicate yours are usually used slightly different from you think they mean? You may need to switch terms.</p>
                    <p>If deleting a few terms then yields way too many hits, try to filter out large classes of hits with a negation <code>foo -bar</code>, adding as many as necessary; also useful is using OR clauses to open up the search in a more restricted way by adding in possible synonyms, with parentheses for group. This can get quite elaborate, and border on <a href="https://en.wikipedia.org/wiki/Google_hacking" data-link-icon="wikipedia" data-link-icon-type="svg">hacking</a>—I have on occasion resorted to search queries as baroque as <code>(foo OR baz) AND (qux OR quux) -bar -garply -waldo -fred</code> to the point where I hit search query length limits and CAPTCHA barriers.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> (By that point, it is time to consider alternate attacks.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Title</strong>: quote the title; delete any subtitle; try the subtitle instead; be suspicious of any character which is not alphanumeric and if there are colons, split it into two title quotes (instead of searching <code>Foo bar: baz quux</code>, or <code>"Foo bar: baz quux"</code>, search <code>"Foo bar" "baz quux"</code>); swap their order.</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Metadata</strong>:</p>
                    <ul>
                      <li>Add/​remove the year.</li>
                      <li>Add/​remove the first author’s surname. Try searching GS for <em>just</em> the author (<code>author:foo</code>).</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Delete Odd Characters/​Punctuation</strong>:</p>
                    <p>Libgen had trouble with colons for a long time, and many websites still do (eg. <a href="https://en.wikipedia.org/wiki/Goodreads" data-link-icon="wikipedia" data-link-icon-type="svg">GoodReads</a>); I don’t know why colons in particular are such trouble, although hyphens/​em-dashes and any kind of quote or apostrophe or period are problematic too. Watch out for words which may be space-separated—if you want to find <a href="https://en.wikipedia.org/wiki/Arpad_Elo" data-link-icon="wikipedia" data-link-icon-type="svg">Arpad Elo’s</a> epochal <a href="https://gwern.net/doc/statistics/order/comparison/1978-elo-theratingofchessplayerspastandpresent.pdf" id="elo-1978" data-link-icon="pdf" data-link-icon-type="svg" title="'<em>The Rating of Chessplayers, Past and Present (Second Edition)</em>', Elo 1978"><em>The Rating of Chessplayers</em></a> in Libgen, you need to search “The Rating of Chess Players” instead! (This is also an example of why falling back to search by author is a good idea.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Try alternate spellings of British/​American terms. This shouldn’t be necessary, but then, deleting colons or punctuation shouldn’t be necessary either.</p>
                  </li>
                  <li>
                    <p><strong>Check For Book Publication</strong>: many papers are published in the form of <em>book anthologies</em>, not journal articles. So look for the book if the paper is mysteriously abent.</p>
                    <p>A book will not necessarily turn up in GS and thus its constituent papers may not either; similarly, while SH does a good job of linking article paywalls to their respective book compilation in LG, it is far from infallible. If a paper was published in any kind of ‘proceeding’ or ‘conference’ or ‘series’ or anything with an ISBN, the paper may be absent from the usual places but the book readily available. It can be quite frustrating to be searching hard for a paper and realize the book was there in plain sight all along. (My suggestion in such cases for <a href="#post-finding">post-finding</a> is to cut out the relevant page range &amp; upload the paper for others to more easily find.)</p>
                  </li>
                  <li>
                    <p><strong>Use URLs</strong>: if you have a URL, try searching chunks of it, typically towards the end, stripping out dates and domain names.</p>
                  </li>
                  <li>
                    <p><strong>Date Search</strong>:</p>
                    <p>Use a search engine (eg. G/​GS) date range feature (in “Tools”) to search ±4 years: metadata can be wrong, publishing conventions can be odd (eg. a magazine published in ‘June’ may actually be published several months before or after), publishers can be <em>extremely</em> slow. This is particularly useful if you add a date constraint &amp; simultaneously loosen the search query to turn up the most temporally-relevant of what would otherwise be far too many hits. If this doesn’t turn up the relevant target, it might turn up related discussions or fixed citations, since most things are cited most shortly after publication and then vanish into obscurity.</p>
                    <figure>
                      <img alt="Click “Tools” on the far right to access date-range &amp; “verbatim” search modes in Google Search." decoding="async" height="842" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-daterange.png" width="1283">
                      
                    </figure>
                    <figure>
                      <img alt="The “verbatim” mode is useful for forcing more literal matching: without it, a search for “foobar” will insist on hits about music players, hiring contests, etc rather than the programming term itself." decoding="async" height="548" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-verbatim.png" width="1333">
                      
                    </figure>
                    <p>If a year is not specified, try to guess from the medium: popular media has heavy recentist bias &amp; prefers only contemporary research which is ‘news’, while academic publications go back a few more years; the style of the reference can give a hint as to how relatively old some mentioned research or writings is. Frequently, given the author surname and a reasonable guess at some research being a year or two old, the name + date-range + keyword in GS will be enough to find the paper.</p>
                    <ul>
                      <li>
                        <span>Consider errors</span>: typos are common. If nothing is showing up in the date-range despite a specific date, perhaps there was a typographic error. Even a diligent typist will occasionally copy metadata from a previous entry or type the same character twice or 2 characters in the wrong order, and for numbers, there is no spellcheck to help catch such errors. Authors <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="'Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?', Branwen 2014">frequently propagate bibliographic errors</a> without correcting them (demonstrating, incidentally, that they probably did not read the original and so any summaries should be taken with a grain of salt). Think about transpositions &amp; neighboring keys on a QWERTY keyboard: eg. a year like “1976” may actually be 1966, 1967, 1975, 1977, or 1986.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Add Jargon</strong>: Add technical terminology which <em>might</em> be used by relevant papers; for example, if you are looking for an article on college admissions statistics, any such analysis would probably be using <a href="https://en.wikipedia.org/wiki/Logistic_regression" data-link-icon="wikipedia" data-link-icon-type="svg">logistic regression</a> and, even if they do not say “logistic regression” (in favor of some more precise yet unguessable term) would express their effects in terms of “odds”.</p>
                    <p>If you don’t know what jargon might be used, you may need to back off and look for a review article or textbook or WP page and spend some quality time reading. If you’re using the wrong term, period, nothing will help you; you can spend hours going through countless pages, but that won’t make the wrong term work. You may need to read through overviews until you finally recognize the skeleton of what you want under a completely different (and often rather obtuse) name. Nothing is more frustrating that <em>knowing</em> there must be a large literature on a topic (“Cowen’s Law”) but being unable to <em>find</em> it because it’s named something completely different from expected—and many fields have different names for the same concept or tool. (Occasionally people compile “Rosetta stones” to translate between fields: eg. <a href="https://gwern.net/doc/www/arxiv.org/999c2f28682d1581b2fa3d939a54c2c9bc05cad6.pdf" id="baez-stay-2009" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/0903.0340?fallback=original" title="Physics, Topology, Logic and Computation: A Rosetta Stone (Original URL: https://arxiv.org/abs/0903.0340 )"><span><span>Baez &amp; Stay</span><span>2009</span></span></a>⁠, <a href="https://gwern.net/doc/www/arxiv.org/e43cd8342289fecff435e5142a48f10bbdf8e849.pdf" id="bertsekas-2018" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1804.04577?fallback=original" title="Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and Some New Implementations (Original URL: https://arxiv.org/abs/1804.04577 )"><span><span>Bertsekas</span><span>2018</span></span></a>⁠, <a href="https://gwern.net/backstop#meta-learning-paradigms" id="gwern-backstop-meta-learning-paradigms"><span><span><span title="et al">Metz</span> <span>et al</span> <span>2018</span></span>’s Table 1</span></a>⁠. These are invaluable.)</p>
                  </li>
                  <li>
                    <p><strong>Even The Humble Have A Tale To Tell</strong>: Beware hastily dismissing ‘bibliographic’ websites as useless—they may have more than you think.</p>
                    <p>While a bibliographic-focused library site like <code>elibrary.ru</code> is (almost) always useless &amp; clutters up search results by hosting only the citation metadata but not fulltext, every so often I run into a peculiar foreign website (often Indian or Chinese) which happens to have a scan of a book or paper. (eg. <a href="https://gwern.net/doc/genetics/heritable/1954-darlington.pdf" id="darlington-1954" data-link-icon="pdf" data-link-icon-type="svg" title="Heredity and Environment"><span><span>Darlington</span><span>1954</span></span></a>⁠, which eluded me for well over half an hour until, taking the alternate approach of hunting its volume, I out of desperation clicked on an <a href="https://gwern.net/doc/www/krishikosh.egranth.ac.in/3df4adaed8ad670bbe2efc9d5ebbb928d4b073b2.html" rel="archived alternate nofollow" data-url-original="http://krishikosh.egranth.ac.in/handle/1/21169" title="(Original URL: http://krishikosh.egranth.ac.in/handle/1/21169 )">Indian index / ​library website</a> which… had it. Go figure.) Sometimes you have to check every hit, just in case.</p>
                  </li>
                  <li>
                    <p><strong>Search The Internet Archive</strong>:</p>
                    <p>The Internet Archive (IA) deserves special mention as a target because it has a remarkable assortment of scans &amp; uploads from all sorts of sources, including the aforementioned Indian/​Chinese libraries with more laissez-faire approaches. It also exposes OCR of them all. So not infrequently, a book may be available, or a paper exists in the middle of a scan of an entire journal volume, but the IA will be ranked very low in search queries and the snippet will be misleading due to bad OCR. A good search strategy is to drop the quotes around titles or excerpts and focus down to <code>site:archive.org</code> and check the first few hits by hand.</p>
                  </li>
                </ul>
                <section id="hard-cases">
                  <h5><a href="#hard-cases" title="Link to section: § 'Hard Cases'">Hard Cases</a></h5>
                  <p>If the basic tricks aren’t giving any hints of working, you will have to get serious. The title may be completely wrong, or it may be indexed under a different author, or not directly indexed at all, or hidden inside a database. Here are some indirect approaches to finding articles:</p>
                  <ul>
                    <li>
                      <p><strong>Reverse Citations</strong>: Take a look in GS’s “related articles” or “cited by” to find similar articles such as later versions of a paper which may be useful. (These are also good features to know about if you want to check things like “has this ever been replicated?” or are still figuring out the right jargon to search.)</p>
                    </li>
                    <li>
                      <p><strong>Anomalous Hits</strong>: Look for hints of hidden bibliographic connections and anomalous hits.</p>
                      <p>Does a paper pop up high in the search results which doesn’t <em>seem</em> to make sense, such as not containing your keywords in the displayed snippet? GS generally penalizes items which exist as simply bibliographic entries, so if one is ranked high in a sea of fulltexts, that should make you wonder why it is being prioritized. Similarly, for Google Books (GB): a book might be forbidden from displaying even snippets but rank high; that might be for a good reason—it may actually contain the fulltext hidden inside it, or something else relevant.</p>
                      <p>Likewise, you cannot trust metadata too much. The inferred or claimed title may be wrong, and a hit may be your desired target lurking in disguise.</p>
                    </li>
                    <li>
                      <p><strong>Compilation Files</strong>: Some papers can be found by searching for the volume or book title to find it indirectly, especially conference proceedings or anthologies; many papers <em>appear</em> to not be available online but are merely buried deep inside a 500-page PDF, and the G snippet listing is misleading.</p>
                      <p>Conferences are particularly complex bibliographically, so you may need to apply the same tricks as for page titles: drop parts, don’t fixate on the numbers, know that the authors or ISBN or ordering of “title:subtitle” can differ between sources, etc.</p>
                      
                    </li>
                    <li>
                      <p><strong>Search By Issue</strong>: Another approach is to look up the listing for a journal issue, and find the paper by hand; sometimes papers are listed in the journal issue’s online Table of Contents, but just don’t appear in search engines (‽). In particularly insidious cases, a paper may be digitized &amp; available—but lumped in with another paper due to error, or only as part of a catch-all file which contains the last 20 miscellaneous pages of an issue. Page range citations are particularly helpful here because they show where the overlap is, so you can download the suspicious overlapping ‘papers’ to see what they <em>really</em> contain.</p>
                      <p>Esoteric as this may sound, this has been a problem on multiple occasions. (I searched in vain for any hint of <a href="https://gwern.net/doc/psychology/animal/maze/1929-shepard.pdf" id="shepard-1929" data-link-icon="pdf" data-link-icon-type="svg" title="An Unexpected Cue in Maze Learning"><span><span>Shepard</span><span>1929</span></span></a>’s existence, half-convinced it was a typo for his 19<em>5</em>9 publication, until I turned to the raw journal scans. A particularly epic example was <a href="https://gwern.net/doc/genetics/heritable/1966-shockley.pdf" id="shockley-1966" data-link-icon="pdf" data-link-icon-type="svg" title="'Possible Transfer of Metallurgical and Astronomical Approaches to Problem of Environment versus Ethnic Heredity', Shockley 1966"><span><span>Shockley</span><span>1966</span></span></a> where after an hour of hunting, all I had was bibliographic echoes despite apparently being published in a high-profile, easily obtained, &amp; definitely digitized journal, <em>Science</em>—leaving me thoroughly baffled. I eventually looked up the ToC and inferred it had been hidden in a set of abstracts!<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> Or a number of <a href="https://gwern.net/smpy" id="gwern-smpy" title="'SMPY Bibliography', Branwen 2018">SMPY</a> papers turned out to be split or merged with neighboring items in journal issues, and I had to fix them by hand.)</p>
                    </li>
                    <li>
                      <p><strong>Masters/​PhD Theses</strong>: sorry. It may be hopeless if it’s pre-2000. You may well find the citation and even an abstract, but actual fulltext…?</p>
                      <p>If you have a university proxy, you may be able to get a copy off <a href="https://en.wikipedia.org/wiki/ProQuest" data-link-icon="wikipedia" data-link-icon-type="svg">ProQuest</a> (specializing in US theses). If ProQuest does not allow a download but indexes it, that usually means it has a copy archived on microfilm/​microfiche, but no one has yet paid for a scan to be made; you can sign up without any special permission, and then purchase ProQuest scans for ~$43 (as of 2023), and that gives you a downloadable PDF. (They apparently scan non-digital works from their vast backlog only on request, so it’s almost like ransoming papers; which means that buying a scan makes it available to academic subscribers as part of the ProQuest database.)</p>
                      <p>Otherwise, you need full university ILL services<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>⁠, and even that might not be enough (a surprising number of universities appear to restrict access only to the university students/​faculty, with the complicating factor of most theses being stored on microfilm).</p>
                    </li>
                    <li>
                      <p><strong><a href="https://en.wikipedia.org/wiki/Reverse_image_search" data-link-icon="wikipedia" data-link-icon-type="svg">Reverse Image Search</a></strong>: If images are involved, a reverse image search in Google Images or <a href="https://tineye.com/">TinEye</a> or <a href="https://en.wikipedia.org/wiki/Yandex_Search" data-link-icon="wikipedia" data-link-icon-type="svg">Yandex Search</a> can turn up important leads.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Bellingcat" data-link-icon="wikipedia" data-link-icon-type="svg">Bellingcat</a> has a good guide by Aric Toller: <a href="https://gwern.net/doc/www/www.bellingcat.com/bd9929bbe1245e2647608c98c34b3ca746cdc0d7.html" id="toller-2019" rel="archived alternate nofollow" data-url-original="https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/" title="'Guide To Using Reverse Image Search For Investigations', Toller 2019 (Original URL: https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/ )">“Guide To Using Reverse Image Search For Investigations”</a>⁠. (Yandex image search appears to exploit face recognition, text OCR, and other capabilities Google Images will not, and bows less to copyright concerns.)</p>
                      <div>
                        <p>
                          Use Browser <strong>Page Info</strong> to Bypass Image Restrictions
                        </p><p>If you are having trouble downloading an image from a web page which is badly/​maliciously designed to stop you, use <a href="https://support.mozilla.org/en-US/kb/firefox-page-info-window" data-link-icon="FF" data-link-icon-type="text,sans">“View Page Info”’s</a> (<code>C-I</code>) “Media” tab ( <a href="https://gwern.net/doc/cs/2021-04-18-gwern-firefox-viewpageinfo-mediatab.png" data-link-icon="image" data-link-icon-type="svg" data-image-height="1421" data-image-width="1600" title="Screenshot of Firefox's 'View Page Info: Media' dialogue, showing all the images used on a web page for easy review &amp; download, bypassing any restrictions or obstacles the website may try to impose on the reader.">eg</a>), which will list the images in a page and let one download them directly.
                      </p></div>
                    </li>
                    <li>
                      <p><strong>Enemy Action</strong>: Is a page or topic not turning up in Google/​IA that you <em>know</em> ought to be there? Check the website’s <a href="https://en.wikipedia.org/wiki/Robots.txt" data-link-icon="wikipedia" data-link-icon-type="svg"><code>robots.txt</code></a> &amp; <a href="https://en.wikipedia.org/wiki/Sitemaps" data-link-icon="wikipedia" data-link-icon-type="svg">sitemap</a>⁠. While not as relevant as they used to be (due to increasing use of dynamic pages &amp; entities ignoring it), <code>robots.txt</code> can sometimes be relevant: key URLs may be excluded from search results, and overly-restrictive <code>robots.txt</code> can cause enormous holes in IA coverage, which may be impossible to fix (but at least you’ll know why).</p>
                    </li>
                    <li>
                      <p><strong>Patience</strong>: not every paywall can be bypassed immediately, and papers may be embargoed or proxies not immediately available.</p>
                      <p>If something is not available at the moment, it may become available in a few months. Use calendar reminders to check back in to see if an embargoed paper is available or if LG/​SH have obtained it, and whether to proceed to additional search steps like manual requests.</p>
                    </li>
                    <li>
                      <p><strong>Domain Knowledge-Specific Tips</strong>:</p>
                      <ul>
                        <li>
                          <p><span>Twitter</span>: Twitter is indexed in Google so web searches <em>may</em> turn up hits, but if you know any metadata, Twitter’s native search functions are still relatively powerful (although Twitter limits searches in many ways in order to drive business to its staggeringly-expensive ‘firehose’ &amp; historical analytics). Use of <a href="https://twitter.com/search-advanced?lang=en" data-link-icon="twitter" data-link-icon-type="svg">Twitter’s “advanced search”</a> interface, particularly the <code>from:</code> &amp; <code>to:</code> <a href="https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators" data-link-icon="twitter" data-link-icon-type="svg">search query operators</a>⁠, can vastly cut down the search space. (Also of note: <code>list:</code>, <code>-filter:retweets</code>, <code>near:</code>, <code>url:</code>, &amp; <code>since:</code>/​<code>until:</code>.)</p>
                        </li>
                        <li>
                          <p><span>US federal courts</span>: US federal court documents can be downloaded off <a href="https://en.wikipedia.org/wiki/PACER_(law)" data-link-icon="wikipedia" data-link-icon-type="svg">PACER</a> after registration; it is pay-per-page ($0.10/​page) but users under a certain level each quarter (currently $15) have their fees waived, so if you are careful, you may not need to pay anything at all. There is a public mirror, called <a href="https://www.courtlistener.com/recap/" data-link-icon="PACR" data-link-icon-type="text,quad">RECAP</a>⁠, which can be searched &amp; downloaded from for free. If you fail to find a case in RECAP and must use PACER (as often happens for obscure cases), please install the <a href="https://en.wikipedia.org/wiki/Free_Law_Project#RECAP" data-link-icon="wikipedia" data-link-icon-type="svg">Firefox /  Chrome RECAP browser extension</a>⁠, which will copy anything you download into RECAP. (This can be handy if you realize later that you should’ve kept a long PDF you downloaded or want to double-check a docket.)</p>
                          <p>Navigating PACER can be difficult because it is an old &amp; highly specialized computer system which assumes you are a lawyer, or at least very familiar with PACER &amp; the American federal court system. As a rule of thumb, if you are looking up a particular case, what you want to do is to search for the first name &amp; surname (even if you have the case ID) for either criminal or civil cases as relevant, and pull up all cases which might pertain to an individual; there can be multiple cases, cases can hibernate for years, be closed, reopened as a different case number, etc. Once you have found the most active or relevant case, you want to look at the “docket”, and check the options to see <em>all</em> documents in the case. This will pull up a list of many documents as the case unfolds over time; most of these documents are legal bureaucracy, like rescheduling hearings or notifications of changed lawyers. You want the <em>longest</em> documents, as those are most likely to be useful. In particular, you want the “indictment”, the “criminal complaint”<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>⁠, and any transcripts of trial testimony.<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> Shorter documents, like 1–2pg entries in the docket, <em>can</em> be useful, but are much less likely to be useful unless you are interested in the exact details of how things like pre-trial negotiations unfold. So carelessly choosing the ‘download all’ option on PACER may blow through your quarterly budget without getting you anything interesting (and also may interfere with RECAP uploading documents).</p>
                          <p>There is no equivalent for state or county court systems, which are balkanized and use a thousand different systems (often privatized &amp; charging far more than PACER); those must be handled on a case by case basis. (Interesting trivia point: according to Nick Bilton’s account of the Silk Road 1 case, the FBI and other federal agencies in the SR1 investigation would deliberately steer cases into state rather than federal courts in order to hide them from the relative transparency of the PACER system. The use of multiple court systems can backfire on them, however, as in the case of SR2’s DoctorClu (see <a href="https://gwern.net/dnm-arrest" id="gwern-dnm-arrest" title="'DNM-related arrests, 2011–2015', Branwen 2012">the DNM arrest census</a> for details), where the local police filings revealed the use of hacking techniques to deanonymize SR2 <a href="https://en.wikipedia.org/wiki/Tor_(network)" data-link-icon="wikipedia" data-link-icon-type="svg">Tor</a> users, implicating CMU’s CERT center—details which were belatedly scrubbed from the PACER filings.)</p>
                        </li>
                        <li>
                          <p><span>charity financials</span>: for USA charity financial filings, do <code>Form 990 site:charity.com</code> and then check <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a> (eg. looking at <a href="https://gwern.net/girl-scouts" id="gwern-girl-scouts" title="'Girl Scouts &amp; Good Corporate Governance', Branwen 2011">Girl Scouts filings</a> or <a href="https://www.lesswrong.com/posts/PmrD2T6F82RkRkhQv/case-study-reading-edge-s-financial-filings" data-link-icon="LW" data-link-icon-type="text">“Case Study: Reading Edge’s financial filings”</a>). For UK charities, the <a href="https://en.wikipedia.org/wiki/Charity_Commission_for_England_and_Wales" data-link-icon="wikipedia" data-link-icon-type="svg">Charity Commission for England and Wales</a> may be helpful.</p>
                        </li>
                        <li>
                          <p><span>education research</span>: for anything related to education, do a site search of <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a>⁠, which is similar to IA in that it will often have fulltext which is buried in the usual search results</p>
                        </li>
                        <li>
                          <p><span>Wellcome Library</span>: the <a href="https://wellcomecollection.org/">Wellcome Library</a> has many old journals or books digitized which are impossible to find elsewhere; unfortunately, their SEO is awful &amp; their PDFs are unnecessarily hidden behind click-through EULAs, so they will not show up normally in Google Scholar or elsewhere. If you see the Wellcome Library in your Google hits, check it out carefully.</p>
                        </li>
                        <li>
                          <p><span>magazines</span> (as opposed to scholarly or trade journals) are hard to get.</p>
                          <p>They are not covered in Libgen/​Sci-Hub, which outsource that to MagzDB; coverage is poor, however. An alternative is <a href="https://pdf-giant.top/" data-link-icon="pdf" data-link-icon-type="svg">pdf-giant</a>⁠. Particularly for pre-2000 magazines, one may have to resort to looking for old used copies on eBay. Some magazines are easier than others—I generally give up if I run into a <em>New Scientist</em> citation because it’s never worth the trouble.</p>
                        </li>
                      </ul>
                    </li>
                    <li>
                      <p><strong>Newspapers</strong>: like theses, tricky. I don’t know of any general solutions short of a LexisNexis subscription.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> An interesting resource for American papers is <a href="https://gwern.net/doc/www/chroniclingamerica.loc.gov/973fc0451da75b2330531f477d417fcc1328ad3f.html" rel="archived alternate nofollow" data-url-original="https://chroniclingamerica.loc.gov/newspapers/" title="(Original URL: https://chroniclingamerica.loc.gov/newspapers/ )">Chronicling America’s “Historic American Newspaper”</a> scans.</p>
                    </li>
                  </ul>
                </section>
              </section>
              <section id="by-quote-or-description">
                <h4><a href="#by-quote-or-description" title="Link to section: § 'By Quote or Description'">By Quote or Description</a></h4>
                <p>For quote/​description searches: if you don’t have a title and are falling back on searching quotes, try varying your search similarly to titles:</p>
                <ul>
                  <li>
                    <p><strong>Novel sentences</strong>: Try the easy search first—whatever looks most memorable or unique.</p>
                  </li>
                  <li>
                    <p><strong>Short quotes are unique</strong>: Don’t search too long a quote, a sentence or two is usually enough to be near-unique, and can be helpful in turning up other sources quoting different chunks which may have better citations.</p>
                    <ul>
                      <li><span>Break up quotes</span>: Because even phrases can be unique, try multiple sub-quotes from a big quote, especially from the beginning and end, which are likely to overlap with quotes which have prior or subsequent passages.</li>
                      <li><span>Odd idiosyncratic wording</span>: Search for oddly-specific phrases or words, especially numbers. 3 or 4 keywords is usually enough.</li>
                      <li><span>Paraphrasing</span>: Look for passages in the original text which seem like they might be based on the same source, particularly if they are simply dropped in without any hint at sourcing and don’t sound like the author; authors typically don’t cite every time they draw on a source, usually only the first time, and during editing the ‘first’ appearance of a source could easily have been moved to later in the text. All of these additional uses are something to add to your searches.</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Robust Quotes</strong>: You are fighting a game of Chinese whispers, so look for unique-sounding sentences and terms which can survive garbling in the repeated transmissions.</p>
                    <p>Memories are urban legends told by one neuron to another over the years. Pay attention to how you mis-remember things: you distort them by simplifying them, rounding them to the nearest easiest version, and by adding in details which <em>should</em> have been there. Avoid phrases which could be easily reworded in multiple equivalent ways, as people usually will reword them when quoting from memory, screwing up literal searches. Remember the fallibility of memory and the basic principles of <a href="https://en.wikipedia.org/wiki/Textual_criticism" data-link-icon="wikipedia" data-link-icon-type="svg">textual criticism</a>: people substitute easy-to-remember versions for the <a href="https://en.wikipedia.org/wiki/Lectio_difficilior_potior" data-link-icon="wikipedia" data-link-icon-type="svg">hard</a>⁠, long<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>⁠, or unusual original.</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Watch out for punctuation and spelling differences hiding hits.</p>
                  </li>
                  <li>
                    <p><strong>Gradient Ascent</strong>: Longer, less witty versions are usually closer to the original and a sign you are on the right trail. The worse, the better. Sniff in the direction of worse versions. (Authors all too often fail to write what they were supposed to write—as Yogi Berra remarked, <a href="https://gwern.net/doc/www/quoteinvestigator.com/9901447988c3e611b2ff9a241679b89bcb56adad.html" rel="archived alternate nofollow" data-url-original="https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/" title="(Original URL: https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/ )">“I really didn’t say everything I said.”</a>)</p>
                  </li>
                  <li>
                    <p><strong>Search Books</strong>: Switch to GB and hope someone paraphrases or quotes it, and includes a real citation; if you can’t see the full passage or the reference section, look up the <em>book</em> in Libgen.</p>
                  </li>
                </ul>
                <section id="dealing-with-paywalls">
                  <h5><a href="#dealing-with-paywalls" title="Link to section: § 'Dealing With Paywalls'">Dealing With Paywalls</a></h5>
                  <div>
                    <blockquote>
                      <p>Gold once out of the earth is no more due unto it; What was unreasonably committed to the ground is reasonably resumed from it: Let Monuments and rich Fabricks, not Riches adorn mens ashes. The commerce of the living is not to be transferred unto the dead: It is not injustice to take that which none complains to lose, and no man is wronged where no man is possessor.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Hydriotaphia,_Urn_Burial" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Hydriotaphia, Urn Burial</em></a>⁠, Sir <a href="https://en.wikipedia.org/wiki/Thomas_Browne" data-link-icon="wikipedia" data-link-icon-type="svg">Thomas Browne</a></p>
                    </blockquote>
                  </div>
                  <p><span>Use Sci-Hub/​Libgen for books/​papers.</span> A paywall can usually be bypassed by using Libgen (LG)/​Sci-Hub (SH): <a href="http://libgen.rs/scimag/" data-link-icon="raven" data-link-icon-type="svg">papers</a> can be searched directly (ideally with the <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" data-link-icon="wikipedia" data-link-icon-type="svg">DOI</a><a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>⁠, but title+author with no quotes will usually work), or an easier way may be to prepend<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a> <code>sci-hub.st</code> (or whatever SH mirror you prefer) to the URL of a paywall. Occasionally Sci-Hub will not have a paper or will persistently error out with some HTTP or proxy error, but searching the DOI in Libgen directly will work. Finally, there is a <a href="https://z-lib.is/fulltext">LibGen / Sci-Hub fulltext search engine</a> on the Z-Library mirror, which is a useful alternative to Google Books (despite the poor OCR).</p>
                  <p><span>Use university Internet.</span> If those don’t work and you do not have a university proxy or alumni access, many university libraries have IP-based access rules and also open WiFi or Internet-capable computers with public logins inside the library, which can be used, if you are willing to take the time to visit a university in person, for using their databases (probably a good idea to keep a list of needed items before paying a visit).</p>
                  <p><span>Public libraries too.</span> Public libraries often subscribe to commercial newspapers or magazine databases; they are inconvenient to get to, but you can usually at least check what’s available on their website. Public &amp; school libraries also have a useful trick for getting common schooling-related resources, such as the OED, or the archives of the <em>New York Times</em> or <em>New Yorker</em>: because of their usually unsophisticated &amp; transient userbase, some public &amp; school libraries will post lists of usernames/​passwords on their website (sometimes as a PDF). They shouldn’t, but they do. Googling phrases like “public library <a href="https://en.wikipedia.org/wiki/The_New_Yorker" data-link-icon="wikipedia" data-link-icon-type="svg">New Yorker</a> username password” can turn up examples of these. Used discreetly to fetch an article or two, it will do them no harm. (This trick works less well with passwords to anything else.)</p>
                  <p>If that doesn’t work, there is a more opaque ecosystem of filesharing services: booksc/​bookfi/​bookzz, private torrent trackers like Bibliotik, <a href="https://gwern.net/doc/www/old.reddit.com/f0d2bc439c217ff55bc7659a1ba27eb72ddd68e7.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/" title="(Original URL: https://www.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/ )">IRC</a> channels with <a href="https://en.wikipedia.org/wiki/XDCC" data-link-icon="wikipedia" data-link-icon-type="svg">XDCC</a> bots like <code>#bookz</code>/​<a href="https://gwern.net/doc/www/ebooks.byethost6.com/49a1f20ea30a50b5e73e590542a13d11e7a1278f.html" rel="archived alternate nofollow" data-url-original="http://ebooks.byethost6.com/?i=1" title="(Original URL: http://ebooks.byethost6.com/?i=1 )"><code>#ebooks</code></a>⁠, old P2P networks like <a href="https://en.wikipedia.org/wiki/EMule" data-link-icon="wikipedia" data-link-icon-type="svg">eMule</a>⁠, private <a href="https://en.wikipedia.org/wiki/DC%2B%2B" data-link-icon="wikipedia" data-link-icon-type="svg">DC++</a> hubs…</p>
                  <p>Site-specific notes:</p>
                  <ul>
                    <li>
                      <p><strong>PubMed</strong>: most papers with a <a href="https://en.wikipedia.org/wiki/PubMed" data-link-icon="wikipedia" data-link-icon-type="svg">PMC</a> ID can be purchased through the Chinese scanning service <a href="https://eurekamag.com/">Eureka Mag</a>⁠; scans are $30 &amp; electronic papers are $20.</p>
                    </li>
                    <li>
                      <p><strong>Elsevier/​<code>sciencedirect.com</code></strong>: easy, always available via SH/​LG</p>
                      <p>Note that many Elsevier journal websites do not work with the SH proxy, although their <code>sciencedirect.com</code> version <em>does</em> and/​or the paper is already in LG. If you see a link to <code>sciencedirect.com</code> on a paywall, try it if SH fails on the journal website itself.</p>
                    </li>
                    <li>
                      <p><a href="https://en.wikipedia.org/wiki/PsycINFO" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>PsycNET</strong></a>: one of the worst sites; SH/​LG never work with the URL method, rarely work with paper titles/​DOIs, and with my university library proxy, loaded pages ‘expire’ and redirect while breaking the browser back button (‽‽‽), combined searches don’t usually work (frequently failing to pull up even bibliographic entries), and only DOI or manual title searches in the EBSCOhost database have a chance of fulltext. (EBSCOhost itself is a fragile search engine which is difficult to query reliably in the absence of a DOI.)</p>
                      <p>Try to find the paper anywhere else besides PsycNET!</p>
                    </li>
                    <li>
                      <p><strong>ProQuest/​JSTOR</strong>: ProQuest/​JSTOR are not standard academic publishers, but have access to or mirrors of a surprisingly large number of publications.</p>
                      <p>I have been surprised how often I have hit deadends, and then discovered a copy sitting in ProQuest/​JSTOR, poorly-indexed by search engines.</p>
                    </li>
                    <li>
                      <p><strong>Custom journal websites</strong>: sometimes a journal will have its own website (eg. <em>Cell</em> or <em>Florida Tax Review</em>), but will still be ultimately run by one of the giants like Elsevier or HeinOnline. (You can often see hints of this in the site design, such as the footer, the URL structure, direct links to the publisher version, etc.)</p>
                      <p>When this is the case, it is usually a waste of time to try to use the journal website: it won’t whitelist university IPs, SH/​LG won’t know how to handle it, etc. Instead, look for the alternative version.</p>
                    </li>
                  </ul>
                </section>
              </section>
            </section>
          </section>
          <section id="request">
            <h2><a href="#request" title="Link to section: § 'Request'">Request</a></h2>
            <p><span>Human flesh search engine.</span> Last resort: if none of this works, there are a few places online you can request a copy (however, they will usually fail if you have exhausted all previous avenues):</p>
            <ul>
              <li>
                <a href="https://gwern.net/doc/www/old.reddit.com/53e945ba27eb68f361a04735673fcab833c8d5b6.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Scholar/" title="(Original URL: https://www.reddit.com/r/Scholar/ )"> / ​r / ​scholar</a>
              </li>
              <li>
                <a href="https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=%23icanhazpdf&amp;src=typd" data-link-icon="twitter" data-link-icon-type="svg"><code>#icanhazpdf</code></a>
              </li>
              <li>
                <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Resource_Exchange/Resource_Request" data-link-icon="wikipedia" data-link-icon-type="svg">Wikipedia Resource Request</a>
              </li>
              <li>
                <a href="https://www.lesswrong.com/posts/4sAsygakd4oCpbEKs/lesswrong-help-desk-free-paper-downloads-and-more-2014" data-link-icon="LW" data-link-icon-type="text" title="Free research help, editing and article downloads for LessWrong">LW help desk</a>
              </li>
            </ul>
            <p>Finally, you can always try to contact the author. This only occasionally works for the papers I have the hardest time with, since they tend to be old ones where the author is dead or unreachable—any author publishing a paper since 1990 will usually have been digitized <em>somewhere</em>—but it’s easy to try.</p>
          </section>
          <section id="post-finding">
            <h2><a href="#post-finding" title="Link to section: § 'Post-finding'">Post-finding</a></h2>
            <p>After finding a fulltext copy, you should find a reliable long-term link/​place to store it and make it more findable (remember—if it’s not in Google/​Google Scholar, it doesn’t exist!):</p>
            <ul>
              <li>
                <p><strong>Never Link Unreliable Hosts</strong>:</p>
                <ul>
                  <li>
                    <p><span>LG/​SH</span>: Always operate under the assumption they could be gone tomorrow. (As my uncle found out with Library.nu shortly after paying for a lifetime membership!) There are no guarantees either one will be around for long under their legal assaults or the behind-the-scenes dramas, and no guarantee that they are being properly mirrored or will be restored elsewhere.</p>
                    <p>When in doubt, make a copy. Disk space is cheaper every day. Download anything you need and keep a copy of it yourself and, ideally, host it publicly.</p>
                  </li>
                  <li>
                    <p><span>NBER</span>: never rely on a <code>papers.nber.org/tmp/</code> or <code>psycnet.apa.org</code> URL, as they are temporary. (SSRN is also undesirable due to making it increasingly difficult to download, but it is at least reliable.)</p>
                  </li>
                  <li>
                    <p><span>Scribd</span>: never link Scribd—they are a scummy website which impede downloads, and anything on Scribd usually first appeared elsewhere anyway. (In fact, if you run into anything vaguely useful-looking which exists only on Scribd, you’ll do humanity a service if you copy it elsewhere just in case.)</p>
                  </li>
                  <li>
                    <p><span>RG</span>: avoid linking to <a href="https://en.wikipedia.org/wiki/ResearchGate" data-link-icon="wikipedia" data-link-icon-type="svg">ResearchGate</a> (compromised by new ownership &amp; PDFs get deleted routinely, apparently often by authors) or <code>Academia.edu</code> (the URLs are one-time and break)</p>
                  </li>
                  <li>
                    <p><span>high-impact journals</span>: be careful linking to Nature.com or <a href="https://en.wikipedia.org/wiki/Cell_(journal)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Cell</em></a> (if a paper is not <em>explicitly</em> marked as Open Access, even if it’s available, it may disappear in a few months!<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>); similarly, watch out for <code>wiley.com</code>, <code>tandfonline.com</code>, <code>jstor.org</code>, <code>springer.com</code>, <code>springerlink.com</code>, &amp; <code>mendeley.com</code>, who pull similar shenanigans.</p>
                  </li>
                  <li>
                    <p><code>~/</code>: be careful linking to academic personal directories on university websites (often noticeable by the <a href="https://en.wikipedia.org/wiki/Unix" data-link-icon="wikipedia" data-link-icon-type="svg">Unix</a> convention <code>.edu/~user/</code> or by directories suggestive of ephemeral hosting, like <code>.edu/cs/course112/readings/foo.pdf</code>); they have short half-lives.</p>
                  </li>
                  <li>
                    <p><code>?token=</code>: beware any PDF URL with a lot of trailing garbage in the URL such as query strings like <code>?casa_token</code> or <code>?cookie</code> or <code>?X</code> (or hosted on S3/​AWS); such links may or may not work for other people but will surely stop working soon. (Academia.edu, Nature, and Elsevier are particularly egregious offenders here.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>PDF Editing</strong>: if a scan, it may be worth editing the PDF to crop the edges, threshold to binarize it (which, for a bad grayscale or color scan, can drastically reduce filesize while increasing readability), and OCR it.</p>
                <p>I use <a href="https://gscan2pdf.sourceforge.net/" id="ratcliffe-2019" title="'gscan2pdf: A GUI to produce PDFs or DjVus from scanned documents', Ratcliffe 2019">gscan2pdf</a> but there are alternatives worth checking out.</p>
              </li>
              <li>
                <p><strong>Check &amp; Improve Metadata</strong>.</p>
                <p>Adding metadata to papers/​books is a good idea because it makes the file findable in G/​GS (if it’s not online, does it really exist?) and helps you if you decide to use bibliographic software like <a href="https://en.wikipedia.org/wiki/Zotero" data-link-icon="wikipedia" data-link-icon-type="svg">Zotero</a> in the future. Many academic publishers &amp; LG are terrible about metadata, and will not include even title/​author/​DOI/​year.</p>
                <p>PDFs can be easily annotated with metadata using <a href="https://en.wikipedia.org/wiki/ExifTool" data-link-icon="wikipedia" data-link-icon-type="svg">ExifTool</a>:: <code>exiftool -All</code> prints all metadata, and the metadata can be set individually using similar fields.</p>
                <p>For papers hidden inside volumes or other files, you should extract the relevant page range to create a single relevant file. (For extraction of PDF page-ranges, I use <a href="https://en.wikipedia.org/wiki/PDFtk" data-link-icon="wikipedia" data-link-icon-type="svg"><code>pdftk</code></a>⁠, eg: <code>pdftk 2010-davidson-wellplayed10-videogamesvaluemeaning.pdf cat 180-196 output 2009-fortugno.pdf</code>. Many publishers insert a spam page as the first page. You can drop that easily with <code>pdftk INPUT.pdf cat 2-end output OUTPUT.pdf</code>, but note that PDFtk may drop all metadata, so do that before adding any metadata. To delete pseudo-encryption or ‘passworded’ PDFs, do <code>pdftk INPUT.pdf input_pw output OUTPUT.pdf</code>; PDFs using actual encryption are trickier but <a href="#astronomy">can often be beaten</a> by off-the-shelf password-cracking utilities.)</p>
                <p>I try to set at least title/​author/​DOI/​year/​subject, and stuff any additional topics &amp; bibliographic information into the “Keywords” field. Example of setting metadata:</p>
                <div id="cb1">
                  <pre><code><span id="cb1-1"><span>exiftool</span> <span>-Author</span><span>=</span><span>"Frank P. Ramsey"</span> <span>-Date</span><span>=</span>1930 <span>-Title</span><span>=</span><span>"On a Problem of Formal Logic"</span> <span>-DOI</span><span>=</span><span>"10.1112/plms/s2-30.1.264"</span> <span>\</span></span>
<span id="cb1-2">    <span>-Subject</span><span>=</span><span>"mathematics"</span> <span>-Keywords</span><span>=</span><span>"Ramsey theory, Ramsey's theorem, combinatorics, mathematical logic, decidability, </span><span>\</span></span>
<span id="cb1-3"><span>    first-order logic,  Bernays-Schönfinkel-Ramsey class of first-order logic, _Proceedings of the London Mathematical </span><span>\</span></span>
<span id="cb1-4"><span>    Society_, Volume s2-30, Issue 1, 1930-01-01, pg264-286"</span> 1930-ramsey.pdf</span></code></pre>
                </div>
                <div>
                  <p>
                    “PDF Plus” is better than “PDF”.
                  </p><p>If two versions are provided, the “PDF” one may be intended (if there is any real difference) for printing and exclude features like hyperlinks .
                </p></div>
              </li>
              <li>
                <p><strong>Public Hosting</strong>: if possible, host a public copy; especially if it was very difficult to find, even if it was useless, it should be hosted. The life you save may be your own.</p>
              </li>
              <li>
                <p><strong>Link On WP/​Social Media</strong>: for bonus points, link it in appropriate places on Wikipedia or Reddit or Twitter; this makes people aware of the copy being available, and also supercharges visibility in search engines.</p>
              </li>
              <li>
                <p><strong>Link Specific Pages</strong>: as noted before, you can link a specific page by adding <code>#page=N</code> to the URL. Linking the relevant page is helpful to readers. (I recommend against doing this if this is done to link an <em>entire article</em> inside a book, because that article will still have bad SEO and it will be hard to find; in such cases, it’s better to crop out the relevant page range as a standalone article, eg. using <code>pdftk</code> again for <code>pdftk 1900-BOOK.pdf cat 123-456 output 1900-PAPER.pdf</code>.)</p>
              </li>
            </ul>
          </section>
          <section id="advanced">
            <h2><a href="#advanced" title="Link to section: § 'Advanced'">Advanced</a></h2>
            <p>Aside from the (highly-recommended) use of hotkeys and Booleans for searches, there are a few useful tools for the researcher, which while expensive initially, can pay off in the long-term:</p>
            <ul>
              <li>
                <p><a href="https://gwern.net/archiving#remote-caching" id="gwern-archiver-bot"><code>archiver-bot</code></a>: automatically archive your web browsing and/​or links from arbitrary websites to forestall linkrot; particularly useful for detecting &amp; recovering from dead PDF links</p>
              </li>
              <li>
                <p><strong>Subscriptions</strong> like <a href="https://pubmed.ncbi.nlm.nih.gov/" data-link-icon="nlm-ncbi" data-link-icon-type="svg">PubMed</a> &amp; GS search alerts: set up alerts for a specific search query, or for new citations of a specific paper. ( <a href="https://en.wikipedia.org/wiki/Google_Alerts" data-link-icon="wikipedia" data-link-icon-type="svg">Google Alerts</a> is not as useful as it seems.)</p>
                <ol>
                  <li><span>PubMed</span> has straightforward conversion of search queries into alerts: “Create alert” below the search bar. (Given the volume of PubMed indexing, I recommend carefully tailoring your search to be as narrow as possible, or else your alerts may overwhelm you.)</li>
                  <li>To create generic <span>GS</span> search query alert, simply use the “Create alert” on the sidebar for any search. To follow citations of a key paper, you must: 1. bring up the paper in GS; 2. click on “Cited by X”; 3. <em>then</em> use “Create alert” on the sidebar.</li>
                </ol>
              </li>
              <li>
                <p><strong>GCSE</strong>: a <a href="https://programmablesearchengine.google.com/about/" data-link-icon="alphabet" data-link-icon-type="svg">Google Custom Search Engines</a> is a specialized search queries limited to whitelisted pages/​domains etc (eg. my <a href="https://cse.google.com/cse?cx=009114923999563836576%3A1eorkzz2gp4" data-link-icon="alphabet" data-link-icon-type="svg">Wikipedia-focused anime / ​manga CSE</a>).</p>
                <p>A GCSE can be thought of as a saved search query on steroids. If you find yourself regularly including scores of the same domains in multiple searches search, or constantly blacklisting domains with <code>-site:</code> or using many negations to filter out common false positives, it may be time to set up a GCSE which does all that by default.</p>
              </li>
              <li>
                <p><strong>Clippings</strong>: <a href="https://en.wikipedia.org/wiki/Comparison_of_note-taking_software" data-link-icon="wikipedia" data-link-icon-type="svg">note-taking services</a> like <a href="https://en.wikipedia.org/wiki/Evernote" data-link-icon="wikipedia" data-link-icon-type="svg">Evernote</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Microsoft_OneNote" data-link-icon="wikipedia" data-link-icon-type="svg">Microsoft OneNote</a>: regularly making and keeping excerpts creates a personalized search engine, in effect.</p>
                <p>This can be vital for refinding old things you read where the search terms are hopelessly generic or you can’t remember an <em>exact</em> quote or reference; it is one thing to search a keyword like “autism” in a few score thousand clippings, and another thing to search that in the entire Internet! (One can also reorganize or edit the notes to add in the keywords one is thinking of, to help with refinding.) I make heavy use of Evernote clipping and it is key to refinding my references.</p>
              </li>
              <li>
                <p><strong>Crawling Websites</strong>: sometimes having copies of whole websites might be useful, either for more flexible searching or for ensuring you have anything you might need in the future. (example: <a href="https://gwern.net/dnm-archive" id="gwern-dnm-archive" title="'Darknet Market Archives (2013–2015)', Gwern 2013">“Darknet Market Archives (2013–2015)”</a>).</p>
                <p>Useful tools to know about: <a href="https://en.wikipedia.org/wiki/Wget" data-link-icon="wikipedia" data-link-icon-type="svg">wget</a>⁠, <a href="https://en.wikipedia.org/wiki/CURL" data-link-icon="wikipedia" data-link-icon-type="svg">cURL</a>⁠, <a href="https://en.wikipedia.org/wiki/HTTrack" data-link-icon="wikipedia" data-link-icon-type="svg">HTTrack</a>⁠; Firefox plugins: <a href="https://gwern.net/doc/www/noscript.net/aa40da7a98a144ecc776d63453662c8e00469bb8.html" rel="archived alternate nofollow" data-url-original="https://noscript.net/" title="(Original URL: https://noscript.net/ )">NoScript</a>⁠, <a href="https://github.com/gorhill/uBlock" data-link-icon="github" data-link-icon-type="svg">uBlock origin</a>⁠, <a href="https://addons.mozilla.org/en-US/firefox/addon/http-header-live/" data-link-icon="FF" data-link-icon-type="text,sans">Live HTTP Headers</a>⁠, <a href="https://github.com/iamadamdev/bypass-paywalls-chrome" data-link-icon="github" data-link-icon-type="svg">Bypass Paywalls</a>⁠, cookie exporting.</p>
                <p>Short of downloading a website, it might also be useful to pre-emptively archive it by using <code>linkchecker</code> to crawl it, compile a list of all external &amp; internal links, and store them for processing by another archival program (see <a href="https://gwern.net/archiving" id="gwern-archiving" title="'Archiving URLs', Gwern 2011">Archiving URLs</a> for examples). In certain rare circumstances, security tools like <a href="https://en.wikipedia.org/wiki/Nmap" data-link-icon="wikipedia" data-link-icon-type="svg"><code>nmap</code></a> can be useful to examine a mysterious server in more detail: what web server and services does it run, what else might be on it (sometimes interesting things like old anonymous FTP servers turn up), has a website moved between IPs or servers, etc.</p>
              </li>
            </ul>
          </section>
        </section>
        <section id="web-pages">
          <h2><a href="#web-pages" title="Link to section: § 'Web pages'">Web Pages</a></h2>
          <p>With proper use of pre-emptive archiving tools like <code>archiver-bot</code>, fixing linkrot in one’s own pages is much easier, but that leaves other references. Searching for lost web pages is similar to searching for papers:</p>
          <ul>
            <li>
              <p><strong>Just Search The Title</strong>: if the page title is given, search for the title.</p>
              <p>It is a good idea to include page titles in one’s own pages, as well as the URL, to help with future searches, since the URL may be meaningless gibberish on its own, and pre-emptive archiving can fail. HTML supports both <code>alt</code> and <code>title</code> parameters in link tags, and, in cases where displaying a title is not desirable (because the link is being used inline as part of normal hypertextual writing), titles can be included cleanly in <a href="https://en.wikipedia.org/wiki/Markdown" data-link-icon="wikipedia" data-link-icon-type="svg">Markdown</a> documents like this: <code>[inline text description](URL "Title")</code>.</p>
            </li>
            <li>
              <p><strong>Clean URLs</strong>: check the URL for weirdness or trailing garbage like `<code>or</code>?utm_source = feedburner&amp;utm_medium = feed&amp;utm_campaign = Feed%3A+blogspot%2FgJZg+%28Google+AI+Blog%29<code>? Or a variant domain, like a</code>mobile.foo.com<code>/</code>m.foo.com<code>/</code>foo.com/​amp/​` URL? Those are all less likely to be findable or archived than the canonical version.</p>
            </li>
            <li>
              <p><strong>Domain Site Search</strong>: restrict G search to the original domain with <code>site:</code>, or to related domains</p>
            </li>
            <li>
              <p><strong>Time-Limited Search</strong>: restrict G search to the original date-range/​years</p>
            </li>
            <li>
              <p><strong>Switch Engines</strong>: try a different search engine: corpuses can vary, and in some cases G tries to be too smart for its own good when you need a literal search; <a href="https://en.wikipedia.org/wiki/DuckDuckGo" data-link-icon="wikipedia" data-link-icon-type="svg">DuckDuckGo</a> (especially for ‘bang’ special searches), <a href="https://en.wikipedia.org/wiki/Microsoft_Bing" data-link-icon="wikipedia" data-link-icon-type="svg">Bing</a>⁠, and Yandex are usable alternatives</p>
            </li>
            <li>
              <p><strong>Check Archives</strong>: if nowhere on the clearnet, try the Internet Archive (IA) or the <a href="http://timetravel.mementoweb.org/" data-link-icon="internetarchive" data-link-icon-type="svg">Memento meta-archive search engine</a>:</p>
              <p>IA is the default backup for a dead URL. If IA doesn’t Just Work, there may be other versions in it:</p>
              <ul>
                <li>
                  <p><span>misleading redirects</span>: did the IA ‘helpfully’ redirect you to a much-later-in-time error page? Kill the redirect and check the earliest stored version for the exact URL rather than the redirect. Did the page initially load but then error out/​redirect? Disable JS with NoScript and reload.</p>
                </li>
                <li>
                  <p><span>Within-Domain Archives</span>: IA lets you list all URLs with any archived versions, by searching for <code>URL/*</code>; the list of available URLs may reveal an alternate newer/​older URL. It can also be useful to filter by filetype or substring.</p>
                  <p>For example, one might list all URLs in a domain, and if the list is too long and filled with garbage URLs, then using the “Filter results” incremental-search widget to search for “uploads/​” on a WordPress blog.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
                  <figure>
                    <img alt="Screenshot of an oft-overlooked feature of the Internet Archive: displaying all available/​archived URLs for a specific domain, filtered down to a subset matching a string like *uploads/*." decoding="async" height="1360" loading="lazy" src="https://gwern.net/doc/cs/2019-gwern-internetarchive-domainsearch-screenshot.png" width="1036">
                    
                  </figure>
                  <ul>
                    <li>
                      <a href="https://github.com/hartator/wayback-machine-downloader" data-link-icon="github" data-link-icon-type="svg"><code>wayback_machine_downloader</code></a> (not to be confused with the <a href="https://github.com/jjjake/internetarchive" data-link-icon="github" data-link-icon-type="svg"><code>internetarchive</code> Python package</a> which provides a CLI interface to uploading files) is a Ruby tool which lets you download whole domains from IA, which can be useful for running a local fulltext search using regexps (a good <code>grep</code> query is often enough), in cases where just looking at the URLs via <code>URL/*</code> is not helpful. (An alternative which might work is <a href="https://websitedownloader.io/" title="Wayback Machine Downloader: Download the source code and assets from Wayback Machine"><code>websitedownloader.io</code></a>⁠.)
                    </li>
                  </ul>
                  <p>Example:</p>
                  <div id="cb2">
                    <pre><code><span id="cb2-1"><span>gem</span> install <span>--user-install</span> wayback_machine_downloader</span>
<span id="cb2-2"><span>~/.gem/ruby/2.7.0/bin/wayback_machine_downloader</span> wayback_machine_downloader <span>--all-timestamps</span> <span>'https://blog.okcupid.com'</span></span></code></pre>
                  </div>
                </li>
                <li>
                  <p>did <span>the domain change</span>, eg. from <code>www.foo.com</code> to <code>foo.com</code> or <code>www.foo.org</code>? Entirely different as far as IA is concerned.</p>
                </li>
                <li>
                  <p>does the <span>internal evidence of the URL</span> provide any hints? You can learn a lot from URLs just by paying attention and thinking about what each directory and argument means.</p>
                </li>
                <li>
                  <p>is this a <span>Blogspot blog</span>? Blogspot is uniquely horrible in that it has versions of each blog for every country domain: a <code>foo.blogspot.com</code> blog could be under any of <code>foo.blogspot.de</code>, <code>foo.blogspot.au</code>, <code>foo.blogspot.hk</code>, <code>foo.blogspot.jp</code>…<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
                </li>
                <li>
                  <p>did the website provide <span>RSS feeds</span>?</p>
                  <p>A little known fact is that <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> (GR; October 2005–July 2013) stored all RSS items it crawled, so if a website’s RSS feed was configured to include full items, the RSS feed history was an alternate mirror of the whole website, and since GR never removed RSS items, it was possible to retrieve pages or whole websites from it. GR has since closed down, sadly, but before it closed, <a href="https://en.wikipedia.org/wiki/Archive_Team" data-link-icon="wikipedia" data-link-icon-type="svg">Archive Team</a> <a href="https://wiki.archiveteam.org/index.php/Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">downloaded</a> a large fraction of GR’s historical RSS feeds, and <em>those</em> archives are <a href="https://archive.org/details/archiveteam_greader" data-link-icon="internetarchive" data-link-icon-type="svg">now hosted on IA</a>⁠. The catch is that they are stored in mega-<a href="https://en.wikipedia.org/wiki/Web_ARChive" data-link-icon="wikipedia" data-link-icon-type="svg">WARCs</a>⁠, which, for all their archival virtues, are not the most user-friendly format. The raw GR mega-WARCs are difficult enough to work with that I <a href="#searching-the-google-reader-archives" data-link-icon="alphabet" data-link-icon-type="svg">defer an example to the appendix</a>⁠.</p>
                </li>
                <li>
                  <p><a href="https://archive.is/" data-link-icon="internetarchive" data-link-icon-type="svg"><code>archive.today</code></a>: an IA-like mirror. (Sometimes bypasses paywalls or has snapshots other services do not; I strongly recommend against treating archive.today/​archive.is/​etc as anything but a temporary mirror to grab snapshots from, as <a href="https://blog.archive.today/post/660719734341386240/is-there-any-structure-in-place-to-assure-the" data-link-icon="internetarchive" data-link-icon-type="svg">it has no long-term plans</a>⁠.)</p>
                </li>
                <li>
                  <p>any <span>local archives</span>, such as those made with my <a href="#gwern-archiver-bot"><code>archiver-bot</code></a></p>
                </li>
                <li>
                  <p><span>Google Cache</span> ( <a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29" data-link-icon="wikipedia" data-link-icon-type="svg">GC</a>): GC works, sometimes, but the copies are usually the worst around, ephemeral &amp; cannot be relied upon. Google also appears to have been steadily deprecating GC over the years, as GC shows up less &amp; less in search results. A last resort.</p>
                </li>
              </ul>
            </li>
          </ul>
        </section>
        <section id="books">
          <h2><a href="#books" title="Link to section: § 'Books'">Books</a></h2>
          <section id="digital">
            <h2><a href="#digital" title="Link to section: § 'Digital'">Digital</a></h2>
            <p>E-books are rarer and harder to get than papers, although the situation has improved vastly since the early 2000s. To search for books online:</p>
            <ul>
              <li>
                <p><strong>More Straightforward</strong>: book searches tend to be faster and simpler than paper searches, and to require less cleverness in search query formulation, perhaps because they are rarer online, much larger, and have simpler titles, making it easier for search engines.</p>
                <p>Search G, not GS, for books:</p>
                <div>
                  <p>
                    No Books in Google Scholar
                  </p><p>Book fulltexts usually don’t show up in G<em>S</em> (for unknown reasons). You need to check G when searching for books.
                </p></div>
                <p>To double-check, you can try a <code>filetype:pdf</code> search; then check LG. Typically, if the main title + author doesn’t turn it up, it’s not online. (In some cases, the author order is reversed, or the title:subtitle are reversed, and you can find a copy by tweaking your search, but these are rare.).</p>
              </li>
              <li>
                <p><strong>IA</strong>: the Internet Archive has many books scanned which do not appear easily in search results (poor SEO?).</p>
                <ul>
                  <li>
                    <p>If an IA hit pops up in a search, <em>always check it</em>; the OCR may offer hints as to where to find it. If you don’t find anything or the provided, try doing an IA site search in G (<em>not</em> the IA built-in search engine), eg. <code>book title site:archive.org</code>.</p>
                  </li>
                  <li>
                    <p><span>DRM workarounds</span>: if it <em>is</em> on IA but the IA version is DRMed and is only available for “checkout”, you can jailbreak it.</p>
                    <p>Check the book out for the full period, 14 days. Download the PDF (not EPUB) version to Adobe Digital Elements version ≤4.0 (which can be run in Wine on Linux), and then import it to <a href="https://en.wikipedia.org/wiki/Calibre_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Calibre</a> with <a href="https://gwern.net/doc/www/apprenticealf.wordpress.com/f294474f6b56273006d0c67c61ffbbaed6438408.html" rel="archived alternate nofollow" data-url-original="https://apprenticealf.wordpress.com/" title="(Original URL: https://apprenticealf.wordpress.com/ )">the De-DRM plugin</a>⁠, which will produce a DRM-free PDF inside Calibre’s library. (Getting De-DRM running can be tricky, especially under Linux. I wound up having to edit some of the paths in the Python files to make them work with Wine. It also appears to fail on the most recent Google Play ebooks, ~2021.) You can then add metadata to the PDF &amp; upload it to LG<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a>⁠. (LG’s versions of books are usually better than the IA scans, but if they don’t exist, IA’s is better than nothing.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/Google_Play" data-link-icon="wikipedia" data-link-icon-type="svg">Google Play</a></strong>: use the same PDF DRM as IA, can be broken same way</p>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/HathiTrust" data-link-icon="wikipedia" data-link-icon-type="svg">HathiTrust</a></strong> also hosts many book scans, which can be searched for clues or hints or jailbroken.</p>
                <p>HathiTrust blocks whole-book downloads but it’s easy to download each page in a loop and stitch them together, for example:</p>
                <div id="cb3">
                  <pre><code><span id="cb3-1"><span>for</span> i <span>in</span> <span>{</span><span>1</span><span>..</span><span>151</span><span>}</span></span>
<span id="cb3-2"><span>do</span> <span>if</span> <span>[[</span> <span>!</span> <span>-s</span> <span>"</span><span>$i</span><span>.pdf"</span> <span>]];</span> <span>then</span></span>
<span id="cb3-3">    <span>wget</span> <span>"https://babel.hathitrust.org/cgi/imgsrv/download/pdf?id=mdp.39015050609067;orient=0;size=100;seq=</span><span>$i</span><span>;attachment=0"</span> <span>\</span></span>
<span id="cb3-4">          <span>-O</span> <span>"</span><span>$i</span><span>.pdf"</span></span>
<span id="cb3-5">    <span>sleep</span> 20s</span>
<span id="cb3-6"> <span>fi</span></span>
<span id="cb3-7">done</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>pdftk</span> <span>*</span>.pdf cat output 1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span>exiftool</span> <span>-Title</span><span>=</span><span>"Scientific Careers and Vocational Development Theory: A review, a critique and some recommendations"</span> <span>\</span></span>
<span id="cb3-12">    <span>-Date</span><span>=</span>1957 <span>-Author</span><span>=</span><span>"Donald E. Super, Paul B. Bachrach"</span> <span>-Subject</span><span>=</span><span>"psychology"</span> <span>\</span></span>
<span id="cb3-13">    <span>-Keywords</span><span>=</span><span>"Bureau Of Publications (Teachers College Columbia University), LCCCN: 57-12336, National Science Foundation, public domain, </span><span>\</span></span>
<span id="cb3-14"><span>    https://babel.hathitrust.org/cgi/pt?id=mdp.39015050609067;view=1up;seq=1 https://psycnet.apa.org/record/1959-04098-000"</span> <span>\</span></span>
<span id="cb3-15">    1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span></code></pre>
                </div>
                <p>Another example of this would be the Wellcome Library; while looking for <a href="https://wellcomecollection.org/works/d63gy9b7"><em>An Investigation Into The Relation Between Intelligence And Inheritance</em><span>, <span><span>Lawrence</span><span>1931</span></span></span></a>⁠, I came up dry until I checked one of the last search results, a “Wellcome Digital Library” hit, on the slim off-chance that, like the occasional Chinese/​Indian library website, it just might have fulltext. As it happens, it did—good news? Yes, but with a caveat: it provides <em>no</em> way to download the book! It provides OCR, metadata, and individual page-image downloads all under CC-BY-NC-SA (so no legal problems), but… not the book. (The OCR is also unnecessarily zipped, so that is why Google ranked the page so low and did not show any revealing excerpts from the OCR transcript: because it’s hidden in an opaque archive to save a few kilobytes while destroying SEO.) Examining the download URLs for the highest-resolution images, they follow an unfortunate schema:</p>
                <ol>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/5c27d7de-6d55-473c-b3b2-6c74ac7a04c6/full/2212,/0/default.jpg</code></li>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/d514271c-b290-4ae8-bed7-fd30fb14d59e/full/2212,/0/default.jpg</code></li>
                  <li>etc</li>
                </ol>
                <p>Instead of being sequentially numbered 1–90 or whatever, they all live under a unique hash or ID. Fortunately, one of the metadata files, the ‘manifest’ file, provides all of the hashes/​IDs (but not the high-quality download URLs). Extracting the IDs from the manifest can be done with some quick <code>sed</code> &amp; <code>tr</code> string processing, and fed into another short <code>wget</code> loop for download</p>
                <div id="cb4">
                  <pre><code><span id="cb4-1"><span>grep</span> <span>-F</span> <span>'@id'</span> manifest<span>\?</span>manifest<span>\=</span>https<span>\:</span>%2F%2Fwellcomelibrary.org%2Fiiif%2Fb18032217%2Fmanifest <span>|</span> <span>\</span></span>
<span id="cb4-2">   <span>sed</span> <span>-e</span> <span>'s/.*imageanno\/\(.*\)/\1/'</span> <span>|</span> <span>grep</span> <span>-E</span> <span>-v</span> <span>'^ .*'</span> <span>|</span> <span>tr</span> <span>-d</span> <span>','</span> <span>|</span> <span>tr</span> <span>-d</span> <span>'"'</span> <span># "</span></span>
<span id="cb4-3"># bf23642e-e89b-43a0-8736-f5c6c77c03c3</span>
<span id="cb4-4"># 334faf27-3ee1-4a63-92d9-b40d55ab72ad</span>
<span id="cb4-5"># 5c27d7de-6d55-473c-b3b2-6c74ac7a04c6</span>
<span id="cb4-6"># d514271c-b290-4ae8-bed7-fd30fb14d59e</span>
<span id="cb4-7"># f85ef645-ec96-4d5a-be4e-0a781f87b5e2</span>
<span id="cb4-8"># a2e1af25-5576-4101-abee-96bd7c237a4d</span>
<span id="cb4-9"># 6580e767-0d03-40a1-ab8b-e6a37abe849c</span>
<span id="cb4-10"># ca178578-81c9-4829-b912-97c957b668a3</span>
<span id="cb4-11"># 2bd8959d-5540-4f36-82d9-49658f67cff6</span>
<span id="cb4-12"># ...etc</span>
<span id="cb4-13"><span>I</span><span>=</span>1</span>
<span id="cb4-14"><span>for</span> HASH <span>in</span> <span>$HASHES</span><span>;</span> <span>do</span></span>
<span id="cb4-15">    <span>wget</span> <span>"https://dlcs.io/iiif-img/wellcome/1/</span><span>$HASH</span><span>/full/2212,/0/default.jpg"</span> <span>-O</span> <span>$I</span>.jpg</span>
<span id="cb4-16">    <span>I</span><span>=</span><span>$((I</span><span>+</span><span>1</span><span>))</span></span>
<span id="cb4-17">done</span></code></pre>
                </div>
                <p>And then the 59MB of JPGs can be cleaned up as usual with <code>gscan2pdf</code> (empty pages deleted, tables rotated, cover page cropped, all other pages binarized), compressed/​OCRed with <code>ocrmypdf</code>, and metadata set with <code>exiftool</code>, producing a readable, downloadable, highly-search-engine-friendly 1.8MB PDF.</p>
              </li>
              <li>
                <p>remember the <a href="https://en.wikipedia.org/wiki/Analog_hole" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>Analog Hole</strong></a> works for papers/​books too:</p>
                <p>if you can find a copy to <em>read</em>, but cannot figure out how to <em>download</em> it directly because the site uses JS or complicated cookie authentication or other tricks, you can always exploit the ‘analogue hole’—fullscreen the book in high resolution &amp; take screenshots of every page; then crop, OCR etc. This is tedious but it works. And if you take screenshots at sufficiently high resolution, there will be relatively little quality loss. (This works better for books that are scans than ones born-digital.)</p>
              </li>
            </ul>
          </section>
          <section id="physical">
            <h2><a href="#physical" title="Link to section: § 'Physical'">Physical</a></h2>
            <p><span>Expensive but feasible.</span> Books are something of a double-edged sword compared to papers/​theses. On the one hand, books are much more often unavailable online, and must be bought offline, but at least you almost always <em>can</em> buy used books offline without much trouble (and often for &lt;$10 total); on the other hand, while paper/​theses are often available online, when one is not unavailable, it’s usually <em>very</em> unavailable, and you’re stuck (unless you have a university ILL department backing you up or are willing to travel to the few or only universities with paper or microfilm copies).</p><!-- TODO: outsourcing to the IA? https://openlibrary.org/sponsorship -->
            <p>Purchasing from used book sellers:</p>
            <ul>
              <li>
                <p><strong>Sellers</strong>:</p>
                <ul>
                  <li>
                    <p><span>used book search engines</span>: Google Books/​<a href="https://www.find-more-books.com/">find-more-books.com</a>: a good starting point for seller links; if buying from a marketplace like AbeBooks/​Amazon/​Barnes &amp; Noble, it’s worth searching the seller to see if they have their own website, which is potentially much cheaper. They may also have multiple editions in stock.</p>
                  </li>
                  <li>
                    <p><span>bad</span>: eBay &amp; Amazon are often bad, due to high-minimum-order+S&amp;H and sellers on Amazon seem to assume Amazon buyers are easily rooked; but can be useful in providing metadata like page count or ISBN or variations on the title</p>
                  </li>
                  <li>
                    <p><span>good</span>: <a href="https://www.abebooks.com/">AbeBooks</a>⁠, <a href="https://www.thriftbooks.com/">Thrift Books</a>⁠, <a href="https://www.betterworldbooks.com/">Better World Books</a>⁠, <a href="https://www.barnesandnoble.com/">B&amp;N</a>⁠, <a href="https://www.discoverbooks.com/">Discover Books</a>⁠.</p>
                    <p>Note: on AbeBooks, international orders can be useful (especially for behavioral genetics or psychology books) but be careful of international orders with your credit card—many debit/​credit cards will fail on international orders and trigger a fraud alert, and <a href="https://en.wikipedia.org/wiki/PayPal" data-link-icon="wikipedia" data-link-icon-type="svg">PayPal</a> is not accepted.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Price Alerts</strong>: if a book is not available or too expensive, set price watches: AbeBooks supports email alerts on stored searches, and Amazon can be monitored via <a href="https://camelcamelcamel.com/">CamelCamelCamel</a> (remember the CCC price alert you want is on the <em>used third-party</em> category, as new books are more expensive, less available, and unnecessary).</p>
              </li>
            </ul>
            <p>Scanning:</p>
            <ul>
              <li>
                <p><strong>Destructive Vs Non-Destructive</strong>: the fundamental dilemma of book scanning—destructively debinding books with a razor or guillotine cutter works much better &amp; is much less time-consuming than spreading them on a flatbed scanner to scan one-by-one<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a>⁠, because it allows use of a sheet-fed scanner instead, which is easily 5x faster and will give higher-quality scans (because the sheets will be flat, scanned edge-to-edge, and much more closely aligned), but does, of course, require effectively destroying the book.</p>
              </li>
              <li>
                <p><strong>Tools</strong>:</p>
                <ul>
                  <li>
                    <p><span>cutting</span>: For simple debinding of a few books a year, an X-acto knife/​razor is good (avoid the ‘triangle’ blades, get curved blades intended for large cuts instead of detail work).</p>
                    <p>Once you start doing more than one a month, it’s time to upgrade to a guillotine blade paper cutter (a fancier swinging-arm paper cutter, which uses a two-joint system to clamp down and cut uniformly).</p>
                    <p>A guillotine blade can cut chunks of 200 pages easily without much slippage, so for books with more pages, I use both: an X-acto to cut along the spine and turn it into several 200-page chunks for the guillotine cutter.</p>
                  </li>
                  <li>
                    <p><span>scanning</span>: at some point, it may make sense to switch to a scanning service like <a href="https://1dollarscan.com/">1DollarScan</a> (1DS has acceptable quality for the black-white scans I have used them for thus far, but watch out for their nickel-and-diming fees for OCR or “setting the PDF title”; these can be done in no time yourself using <code>gscan2pdf</code>/​<code>exiftool</code>/​<code>ocrmypdf</code> and will save a <em>lot</em> of money as they, amazingly, bill by 100-page units). Books can be sent directly to 1DS, reducing logistical hassles.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Clean Up</strong>: after scanning, crop/​threshold/​OCR/​add metadata</p>
                <ul>
                  <li><span>Adding metadata</span>: same principles as papers. While more elaborate metadata can be added, like bookmarks, I have not experimented with those yet.</li>
                </ul>
              </li>
              <li>
                <p><strong>File format</strong>: PDF, <a href="https://gwern.net/design-graveyard#djvu-files" id="gwern-design-graveyard-djvu-files">not DjVu</a></p>
                <p>Despite being a worse format in many respects, I now recommend PDF and have stopped using DjVu for new scans<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a> and have converted my old DjVu files to PDF.</p>
              </li>
              <li>
                <p><strong>Uploading</strong>: to LibGen, usually, and Gwern.net sometimes. For backups, filelockers like Dropbox, Mega, MediaFire, or Google Drive are good. I usually upload 3 copies including LG. I rotate accounts once a year, to avoid putting too many files into a single account. [I discourage <a href="https://gwern.net/archiving#why-not-internet-archive" id="gwern-archiving-why-not-internet-archive" title="‘Archiving URLs § Why Not Internet Archive?’, Branwen 2011">reliance on IA links.</a>)</p>
                <div>
                  <p>
                    Do Not Use Google Docs/​Scribd/​Dropbox/​IA/​etc for Long-Term Documents
                  </p>
                  <p>‘Document’ websites like Google Docs (GD) should be strictly avoided as primary hosting. GD does <em>not</em> appear in G/​GS, dooming a document to obscurity, and Scribd is ludicrously user-hostile with changing <a href="https://en.wikipedia.org/wiki/Dark_pattern" data-link-icon="wikipedia" data-link-icon-type="svg">dark patterns</a>⁠. Such sites cannot be searched, scraped, downloaded reliably, clipped, used on many devices, archived<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a>⁠, or counted on for the long haul. (For example, Google Docs has made many documents ‘private’, breaking public links, to the surprise of even the authors when I contact them about it, for unclear reasons.)</p><p>Such sites may be useful for collaboration or surveys, but should be regarded as strictly temporary <em>working files</em>, and moved to clean static HTML/​PDF/​XLSX hosted elsewhere as soon as possible.
                </p></div>
              </li>
              <li>
                <p><strong>Hosting</strong>: hosting papers is easy but books come with risk:</p>
                <p>Books can be dangerous; in deciding whether to host a book, my rule of thumb is host only books pre-2000 and which do not have Kindle editions or other signs of active exploitation and is effectively an ‘<a href="https://en.wikipedia.org/wiki/Orphan_work" data-link-icon="wikipedia" data-link-icon-type="svg">orphan work</a>’.</p>
                <p>As of 2019-10-23, hosting 4090 files over 9 years (very roughly, assuming linear growth, &lt;6.7 million document-days of hosting: 3763 × 0.5 × 8 × 365.25 = 6722426), I’ve received 4 takedown orders: a behavioral genetics textbook (2013), <em>The Handbook of Psychopathy</em> (2005), a recent <a href="https://en.wikipedia.org/wiki/Meta-analysis" data-link-icon="wikipedia" data-link-icon-type="svg">meta-analysis</a> <span>paper (<span><span title="et al">Roberts</span> <span>et al</span> <span>2016</span></span>), and a CUP DMCA takedown order for 27 files. I broke my rule of thumb to host the 2 books (my mistake), which leaves only the 1 paper, which I think was a fluke. So, as long as one avoids relatively recent books, the risk should be minimal.</span> <!-- Sep 2020 update: +2: IEEE, and newspaper over mirrored page; Oct 2020: CUP, 1 book --></p>
              </li>
            </ul>
          </section>
        </section>
        <section id="case-studies">
          <h2><a href="#case-studies" title="Link to section: § 'Case Studies'">Case Studies</a></h2>
          <p>Followup section to the article covering how to search the Internet effectively: &gt;14 case studies of challenging Internet searches drawn from the past 10 years. I present the problem, and step through the process of finding it, and describe my tacit knowledge and implicit strategies. These case studies make the prior tips more understandable by showing them off in practice.</p>
          <section id="missing-appendix">
            <h2><a href="#missing-appendix" title="Link to section: § 'Missing Appendix'">Missing Appendix</a></h2>
            <p><a href="https://en.wikipedia.org/wiki/Anders_Sandberg" data-link-icon="wikipedia" data-link-icon-type="svg">Anders Sandberg</a> <a href="https://twitter.com/anderssandberg/status/1176040327679029249" data-link-icon="twitter" data-link-icon-type="svg">asked</a>:</p>
            <blockquote>
              <p>Does anybody know where the online appendix to Nordhaus’ <a href="https://pdfs.semanticscholar.org/f60f/e757587be15c29ad6ee5695bc48a44df3e8a.pdf" data-link-icon="pdf" data-link-icon-type="svg" title="Nordhaus 2007">“Two Centuries of Productivity Growth in Computing”</a> is hiding?</p>
            </blockquote>
            <p>I look up the title in Google Scholar; seeing a friendly <code>psu.edu</code> PDF link (CiteSeerx), I click. The paper says “The data used in this study are provided in a background spreadsheet available at <code>http://www.econ.yale.edu/~nordhaus/Computers/Appendix.xls</code>”. Sadly, this is a lie. (Sandberg would, of course, have tried that already.)</p>
            <p>I immediately check the URL in the IA—nothing. The IA didn’t catch it at all. Maybe the <a href="https://www.cambridge.org/core/journals/journal-of-economic-history/article/two-centuries-of-productivity-growth-in-computing/856EC5947A5857296D3328FA154BA3A3" id="nordhaus-2007" data-link-icon="⛨" data-link-icon-type="text" title="'Two Centuries of Productivity Growth in Computing', Nordhaus 2007">official published paper website</a> has it? Nope, it references the same URL, and doesn’t provide a copy as an appendix or supplement. (What do we pay these publishers such enormous sums of money for, exactly?) So I back off to checking <code>http://www.econ.yale.edu/~nordhaus/</code>, to check Nordhaus’s personal website for a newer link. The Yale personal website is empty and appears to’ve been replaced by a Google Sites personal page. It links nothing useful, so I check a more thorough index, Google, by searching <code>site:sites.google.com/site/williamdnordhaus/</code>. Nothing there either (and it appears almost empty, so Nordhaus has allowed most of his stuff to be deleted and bitrot). I try a broader Google: <code>nordhaus appendix.xls</code>. This turns up some spreadsheets, but still nothing.</p>
            <p>Easier approaches having been exhausted, I return to the IA and I pull up <em>all</em> URLs archived for his original personal website: <code>https://web.archive.org/web/*/http://www.econ.yale.edu/~nordhaus/*</code> This pulls up way too many URLs to manually review, so I filter results for <code>xls</code>, which reduces to a more manageable 60 hits; reading through the hits, I spot <code>http://www.econ.yale.edu/~nordhaus/homepage/documents/Appendix_Nordhaus_computation_update_121410.xlsx</code> from 2014-10-10; this sounds right, albeit substantially later in time than expected (either 2010 or 2012, judging from the filename).</p>
            <p><a href="https://gwern.net/doc/cs/2010-nordhaus-nordhaus2007twocenturiesofproductivitygrowthincomputing-appendix.xlsx" data-link-icon="spreadsheet" data-link-icon-type="svg">Downloading it</a>⁠, opening it up and cross-referencing with the paper, it has the same spreadsheet ‘sheets’ as mentioned, like “Manual” or “Capital_Deep”, and seems to be either the original file in question or an updated version thereof (which may be even better). The spreadsheet metadata indicates it was created “04/​09/​2001, 23:20:43, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System" data-link-icon="wikipedia" data-link-icon-type="svg">ITS</a> Academic Media &amp; Technology”, and modified “12/​22/​2010, 02:40:20”, so it seems to be the latter—it’s the original spreadsheet Nordhaus created when he began work several years prior to the formal 2007 publication (6 years seems reasonable given all the delays in such a process), and then was updated 3 years afterwards. Close enough.</p>
          </section>
          <section id="misremembered-book">
            <h2><a href="#misremembered-book" title="Link to section: § 'Misremembered Book'">Misremembered Book</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/e4be352758223ce0ec474b7824e48ef8e469dd6c.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/" title="(Original URL: https://www.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/ )">A Redditor asked</a>:</p>
            <blockquote>
              <p>I was in a consignment type store once and picked up a book called “Eat fat, get thin”. Giving it a quick scan through, it was basically the same stuff as Atkins but this book was from the 50s or 60s. I wish I’d have bought it. I think I found a reference to it once online but it’s been drowned out since someone else released a book with the same name (and it wasn’t Barry Groves either).</p>
            </blockquote>
            <p>The easiest way to find a book given a corrupted title, a date range, and the information there are many similar titles drowning out a naive search engine query, is to skip to a specialized search engine with clean metadata (ie. a library database).</p>
            <p>Searching in WorldCat for 1950s–1970s, “Eat fat, get thin” turns up nothing relevant. This is unsurprising, as he was unlikely to’ve remembered the title <em>exactly</em>, and this title doesn’t quite sound right for the era anyway (a little too punchy and ungrammatical, and ‘thin’ wasn’t a desirable word back then compared to words like ‘slim’ or ‘sleek’ or ‘svelte’). People often oversimplify titles, so I dropped back to just “Eat fat”.</p>
            <p>This immediately turned up the book: <a href="https://en.wikipedia.org/wiki/Richard_Mackarness" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Mackarness’s</a> 1958 <em>Eat Fat and Grow Slim</em>—note that it is <em>almost</em> the same title, with a comma serving as conjunction and ‘slim’ rather than the more contemporary ‘thin’, but just different enough to screw up an overly-literal search.</p>
            <p>With the same trick in mind, we could also have found it in a regular Google search query by adding additional terms to hint to Google that we want old books, not recent ones: both <code>"Eat Fat" 1950s</code> or <code>"Eat Fat" 1960s</code> would have turned it up in the first 5 search results. If we didn’t use quotes, the searches get harder because broader hits get pulled in. For example, <code>Eat fat, get thin 1950s -Hyman</code> excludes the recent book mentioned, but you still have to go down 15 hits before finding Mackarness, and <code>Eat fat, get thin -Hyman</code> requires going down 18 hits.</p>
          </section>
          <section id="missing-website">
            <h2><a href="#missing-website" title="Link to section: § 'Missing Website'">Missing Website</a></h2>
            <p><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/anie.201410356" id="bučar-et-al-2015" data-link-icon="W" data-link-icon-type="text,sans" title="Disappearing Polymorphs Revisited"><span><span title="et al">Bučar</span> <span>et al</span> <span>2015</span></span></a>⁠, on the phenomenon of <a href="https://en.wikipedia.org/w/index.php?title=Polymorphism_(materials_science)&amp;oldid=999770848#Disappearing_polymorphs" data-link-icon="wikipedia" data-link-icon-type="svg">disappearing polymorphs</a> quotes striking transcripts from a major example of a disappearing crystal, when ~1998 Abbott suddenly became unable to manufacture the anti-retroviral drug <a href="https://en.wikipedia.org/wiki/Ritonavir" data-link-icon="wikipedia" data-link-icon-type="svg">ritonavir</a> (Norvir™) due to a rival (and less effective) crystal form spontaneously infecting all its plants, threatening many AIDS patients, but notes:</p>
            <blockquote>
              <p>The transcripts were originally published on the website<sup>42</sup> of the International Association of Physicians in AIDS Care [IAPAC], but no longer appear there.</p>
            </blockquote>
            <p>A search using the quotes confirms that the originals have long since vanished from the open Internet, turning up only quotes of the quotations. Unfortunately, no URL is given. The Internet Archive has comprehensive mirrors of the IAPAC, but too many to easily search through. Using the filter feature, I keyword-searched for “ritonavir”, but while this turned up a number of pages from roughly the right time period, they do not mention it and none of the quotes appear. The key turned out to be to use the trademark name instead which pulls up many more pages, and after checking a few, the IAPAC turned out to have organized all the Norvir material into a single subdirectory with a convenient <a href="https://gwern.net/doc/biology/2000-iapac-norvir/index.html"><code>index.html</code></a>⁠; the articles/​transcripts, in turn, were indexed under the linked <a href="https://gwern.net/doc/biology/2000-iapac-norvir/description.html" id="care-2000" title="'Norvir Advisory', Care 2000">“Description of the Problem” index page</a>⁠.</p>
            <p>I then pulled the Norvir subdirectory with a <code>~/.gem/ruby/2.5.0/bin/wayback_machine_downloader wayback_machine_downloader 'http://www.iapac.org/norvir/'</code> command and hosted a mirror to make it visible in Google.</p>
          </section>
          <section id="speech-book">
            <h2><a href="#speech-book" title="Link to section: § 'Speech → Book'">Speech → Book</a></h2>
            <p><a href="https://www.lesswrong.com/posts/cHEQSEPz4eipGHFy9/differential-reproduction-for-men-and-women#comment-TZQqzYPDv6vsWqfut" data-link-icon="LW" data-link-icon-type="text">Nancy Lebovitz</a> asked about a citation in a <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="'Is There Anything Good About Men?', Roy F. Baumeister 2007">Roy Baumeister speech about sex differences</a>:</p>
            <blockquote>
              <p>There’s an idea I’ve seen a number of times that 80% of women have had descendants, but only 40% of men. A little research tracked it back to <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="‘Is There Anything Good About Men?’, Baumeister 2007">this</a>⁠, but the speech doesn’t have a cite and I haven’t found a source.</p>
            </blockquote>
            <p>This could be solved by guessing that the formal citation is given in the book, and doing keyword search to find a similar passage. The second line of the speech says:</p>
            <blockquote>
              <blockquote>
                <p>For more information on this topic, read Dr.&nbsp;Baumeister’s book <em>Is There Anything Good About Men?</em> available in bookstores everywhere, including here.</p>
              </blockquote>
            </blockquote>
            <p>A search of <em>Is There Anything Good About Men</em> in Libgen turns up a copy. Download. What are we looking for? A reminder, the key lines in the speech are:</p>
            <blockquote>
              <blockquote>
                <p>…It’s not a trick question, and it’s not 50%. True, about half the people who ever lived were women, but that’s not the question. We’re asking about all the people who ever lived who have a descendant living today. Or, put another way, yes, every baby has both a mother and a father, but some of those parents had multiple children. Recent research using DNA analysis answered this question about two years ago. Today’s human population is descended from twice as many women as men. I think this difference is the single most under-appreciated fact about gender. To get that kind of difference, you had to have something like, throughout the entire history of the human race, maybe 80% of women but only 40% of men reproduced.</p>
              </blockquote>
            </blockquote>
            <p>We could search for various words or phrase from this passage which seem to be relatively unique; as it happens, I chose the rhetorical “50%” (but “80%”, “40%”, “underappreciated”, etc. all would’ve worked with varying levels of efficiency since the speech is heavily based on the book), and thus jumped straight to chapter 4, “The Most Underappreciated Fact About Men”. (If these had not worked, we could have started searching for years, based on the quote “about two years ago”.) A glance tells us that Baumeister is discussing exactly this topic of reproductive differentials, so we read on and a few pages later, on page 63, we hit the jackpot:</p>
            <blockquote>
              <p>The correct answer has recently begun to emerge from DNA studies, notably those by Jason Wilder and his colleagues. They concluded that among the ancestors of today’s human population, women outnumbered men about two to one. Two to one! In percentage terms, then, humanity’s ancestors were about 67% female and 33% male.</p>
            </blockquote>
            <p>Who’s Wilder? A C-f for “Wilder” takes us to pg286, where we immediately read:</p>
            <blockquote>
              <p>…The DNA studies on how today’s human population is descended from twice as many women as men have been the most requested sources from my earlier talks on this. The work is by Jason Wilder and his colleagues. I list here some sources in the mass media, which may be more accessible to laypersons than the highly technical journal articles, but for the specialists I list those also. For a highly readable introduction, you can Google the article <a href="https://web.archive.org/web/20040922020546/http://www.scienceagogo.com/news/20040819224859data_trunc_sys.shtml" data-link-icon="internetarchive" data-link-icon-type="svg">“Ancient Man Spread the Love Around,”</a> which was published September, 20, 2004 and is still available (last I checked) online. There were plenty of other stories in the media at about this time, when the research findings first came out. In <a href="https://www.medicalnewstoday.com/">“Medical News Today,”</a>⁠, on the same date in 2004, a story under “Genes expose secrets of sex on the side” covered much the same material.</p>
              <p>If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). <a href="https://academic.oup.com/mbe/article/21/11/2047/1147770" data-link-icon="OUP" data-link-icon-type="text,tri">“Genetic evidence for unequal effective population sizes of human females and males”</a>⁠. <em>Molecular Biology and Evolution</em>, 21, 2047–2057. If that went down well, you might try Wilder, J. A., Kingan, S. B., Mobasher, Z., Pilkington, M. M., &amp; Hammer, M. F. (2004). <a href="https://www.nature.com/articles/ng1428" data-link-icon="n" data-link-icon-type="text">“Global patterns of human mitochondrial DNA and Y-chromosome structure are not influenced by higher migration rates of females versus males”</a>⁠. <em>Nature Genetics</em>, 36, 1122–1125. That one was over my head, I admit. A more readable source on these is Shriver, M. D. (2005), <a href="https://www.nature.com/articles/5201329" data-link-icon="n" data-link-icon-type="text">“Female migration rate might not be greater than male rate”</a>⁠. <em>European Journal of Human Genetics</em>, 13, 131–132. Shriver raises another intriguing hypothesis that could have contributed to the greater preponderance of females in our ancestors: Because couples mate such that the man is older, the generational intervals are smaller for females (ie. baby’s age is closer to mother’s than to father’s). As for the 90% to 20% differential in other species, that I believe is standard information in biology, which I first heard in one of the lectures on testosterone by the late James Dabbs, whose book <em>Heroes, Rogues, and Lovers</em> remains an authoritative source on the topic.</p>
            </blockquote>
            <p><span><span><span title="et al">Wilder</span> <span>et al</span> <span>2004</span></span>, incidentally, fits well with Baumeister remarking in 2007 that the research was done 2 or so years ago. And of course you could’ve done the same thing using Google Books: search</span> <a href="https://books.google.com/books?id=qqprY-YiWY8C&amp;printsec=frontcover&amp;dq=Baumeister+anything+good+about+men&amp;sa=X&amp;ei=4vNaUZffIoe9igLB74DQBA&amp;ved=0CDAQ6AEwAA" data-link-icon="alphabet" data-link-icon-type="svg">“Baumeister anything good about men”</a> to get to the book, then search-within-the-book for “50%”, jump to page 53, read to page 63, do a second search-within-the-book for “Wilder” and the second hit of page 287 even luckily gives you the snippet:</p>
            <blockquote>
              <p><em>Sources and References</em> 287</p>
              <p>…If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). “Genetic evidence for unequal effective population sizes of human females and males”. <em>Molecular Biology and Evolution</em>…</p>
            </blockquote>
          </section>
          <section id="rowling-quote-on-death">
            <h2><a href="#rowling-quote-on-death" title="Link to section: § 'Rowling Quote On Death'">Rowling Quote On Death</a></h2>
            <p>Did <a href="https://en.wikipedia.org/wiki/J._K._Rowling" data-link-icon="wikipedia" data-link-icon-type="svg">J.K. Rowling</a> say the <em>Harry Potter</em> books were about ‘death’? There are a lot of Rowling statements, but checking WP and opening up each interview links (under the theory that the key interviews are linked there) and searching for ‘death’ soon turns up a relevant quote from <a href="https://gwern.net/doc/www/www.accio-quote.org/763e66fc7f7ae146fdfa894b9d224c297e0fae9d.html" rel="archived alternate nofollow" data-url-original="http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm" title="'Harry Potter and Me' (BBC Christmas Special, British version), BBC, 2001-12-28 (Original URL: http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm )">2001</a>:</p>
            <blockquote>
              <p>Death is an extremely important theme throughout all seven books. I would say possibly the most important theme. If you are writing about Evil, which I am, and if you are writing about someone who is essentially a <a href="https://en.wikipedia.org/wiki/Psychopathy" data-link-icon="wikipedia" data-link-icon-type="svg">psychopath</a>⁠, you have a duty to show the real evil of taking human life.</p>
            </blockquote>
          </section>
          <section id="crowley-quote">
            <h2><a href="#crowley-quote" title="Link to section: § 'Crowley Quote'">Crowley Quote</a></h2>
            <p><a href="https://www.lesswrong.com/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience#comment-3bc4kL4QnNc9TjNTz" data-link-icon="LW" data-link-icon-type="text">Scott Alexander</a> posted a piece linking to an except titled “<a href="https://en.wikipedia.org/wiki/Aleister_Crowley" data-link-icon="wikipedia" data-link-icon-type="svg">Crowley</a> on Religious Experience”.</p>
            <p>The link was broken, but Alexander brought it up in the context of an <a href="https://www.lesswrong.com/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane#comment-qAHp6JRjeY7ixgYas" data-link-icon="LW" data-link-icon-type="text">earlier discussion</a> where he also quoted Crowley; searching <em>those</em> quotes reveals that it must have been excerpts from <em>Magick: Book 4</em>.</p>
          </section>
          <section id="finding-the-right-sage">
            <h2><a href="#finding-the-right-sage" title="Link to section: § 'Finding The Right SAGE'">Finding The Right ‘SAGE’</a></h2>
            <p><a href="https://www.lesswrong.com/posts/CKpByWmsZ8WmpHtYa/competent-elites#comment-jzCu3bdgoQ77Y5hZN" data-link-icon="LW" data-link-icon-type="text">Phil Goetz</a> noted that an anti-aging conference named “SAGE” had become impossible to find in Google due to a <em>LGBT</em> aging conference also named SAGE.</p>
            <p>Regular searches would fail, but a combination of tricks worked: <code>SAGE anti-aging conference</code> combined with restricting Google search to 2003–2005 time-range turned up a citation to its website as the fourth hit, <code>http://www.sagecrossroads.net</code> (which has ironically since died).</p>
          </section>
          <section id="uk-charity-financials">
            <h2><a href="#uk-charity-financials" title="Link to section: § 'UK Charity Financials'">UK Charity Financials</a></h2>
            <p>The <a href="https://www.lesswrong.com/posts/qqhdj3W3vSfB5E9ss/siai-an-examination?commentId=7CwWf6wN2DtNfv3tF" data-link-icon="LW" data-link-icon-type="text">Future of Humanity Institute (FHI) doesn’t clearly provide</a> charity financial forms akin to the US Form 990s, making it hard to find out information about its budget or results.</p>
            <p>FHI doesn’t show up in the CC, NPC, or <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a>⁠, which are the first places to check for charity finances, so I went a little broader afield and tried a site search on the FHI website: <code>budget site:fhi.ox.ac.uk</code>. This immediately turned up FHI’s own documentation of its activities and budgets, such as the 2007 annual report; I used part of its title as a new Google search: <code>future of humanity institute achievements report site:fhi.ox.ac.uk</code>.</p>
          </section>
          <section id="nobel-lineage-research">
            <h2><a href="#nobel-lineage-research" title="Link to section: § 'Nobel Lineage Research'">Nobel Lineage Research</a></h2>
            <p><a href="https://www.lesswrong.com/posts/hC83eKp9LFpw9FBks/link-holistic-learning-ebook#comment-egNZtRAF8C2KTPKsu" data-link-icon="LW" data-link-icon-type="text">John Maxwell</a> referred to a forgotten study on high correlation between Nobelist professors &amp; Nobelist grad students (almost entirely a selection effect, I would bet). I was able to refind it in 7 minutes.</p>
            <p>I wasted a few searches like <code>factor predicting Nobel prize</code> or <code>Nobel prize graduate student</code> in Google Scholar, until I search for <code>Nobel laureate "graduate student"</code>; the second hit was a citation, which is a little unusual for Google Scholar and meant it was important, and it had the critical word <em>mutual</em> in it—simultaneous partners in Nobel work is somewhat rare, but temporally separated teams don’t work for prizes, and I suspected that it was exactly what I was looking for. Googling the title, I soon found a PDF like <a href="https://gwern.net/doc/psychology/2004-viau.pdf" id="pilc2501-2004" data-link-icon="pdf" data-link-icon-type="svg" title="pilc2501 2004">“Eminent Scientists’ Demotivation in School: A symptom of an incurable disease?”<span>, <span><span>Viau</span><span>2004</span></span></span></a> <span>which confirmed it (and <span><span>Viau</span><span>2004</span></span> is interesting in its own right as a contribution to the Conscientious vs IQ question). I then followed it to a useful paragraph:</span></p>
            <blockquote>
              <p>In a study conducted with 92 American winners of the Nobel Prize, Zuckerman (1977) discovered that 48 of them had worked as graduate students or assistants with professors who were themselves Nobel Prize award-winners. As pointed out by Zuckerman (1977), the fact that 11 Nobel prizewinners have had the great physicist Rutherford as a mentor is an example of just how significant a good mentor can be during one’s studies and training. It then appears that most eminent scientists did have people to stimulate them during their childhood and mentor(s) during their studies. But, what exactly is the nature of these people’s contribution.</p>
              <ul>
                <li>Zuckerman, H. (1977). <em>Scientific Elite: Nobel Laureates in the United States</em>. New York: Free Press.</li>
              </ul>
            </blockquote>
            <p>GS lists &gt;900 citations of this book, so there may well be additional or followup studies covering the 40 years since. Or, also relevant is “Zuckerman, H. (1983). The scientific elite: Nobel laureates’ mutual influences. In R. S. Albert (Ed.), <em>Genius and eminence</em> (pp.&nbsp;241–252). New York: Pergamon Press”, and “Zuckerman H. ‘Sociology of Nobel Prizes’, <em>Scientific American</em> 217 (5): 25&amp; 1967.”</p>
          </section>
          <section id="dead-url">
            <h2><a href="#dead-url" title="Link to section: § 'Dead URL'">Dead URL</a></h2>
            <p><a href="https://www.lesswrong.com/posts/wAhgxmCf2ebHha5BJ/psa-please-list-your-references-don-t-just-link-them#comment-MMH9H4Y7iNDjfirZF" data-link-icon="LW" data-link-icon-type="text">A link to a research article in a post by Morendil</a> broke, he had not provided any formal citation data, <em>and</em> the original domain blocks all crawlers in its <code>robots.txt</code> so IA would not work. What to do?</p>
            <p>The simplest solution was to search a direct quote, turning up a Scribd mirror; Scribd is a parasite website, where people upload copies from elsewhere, which ought to make one wonder where the <em>original</em> came from. (It often shows up before the original in any search engine, because it automatically runs OCR on submissions, making them more visible to search engines.) With a copy of the journal issue to work with, you can easily find the official HP archives and <a href="https://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1989-04.pdf" data-link-icon="pdf" data-link-icon-type="svg">download the original PDF</a>⁠.</p>
            <p>If that hadn’t worked, searching for the URL without <code>/pg_2/</code> in it yields the full citation, and then that can be looked up normally. Finally, somewhat more dangerous would be trying to find the article just by author surname &amp; year.</p>
          </section>
          <section id="description-but-no-citation">
            <h2><a href="#description-but-no-citation" title="Link to section: § 'Description But No Citation'">Description But No Citation</a></h2>
            <p>A 2013 <a href="https://gwern.net/doc/www/www.medicaldaily.com/edf8f97057799b156cf565a4ffd0494f310d3395.html" rel="archived alternate nofollow" data-url-original="https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435" title="Psychologists Discover How People Subconsciously Become Their Favorite Fictional Characters (Original URL: https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435 )">Medical Daily</a> on the effects of reading fiction omitted any link or citation to the research in question. But it is easy to find.</p>
            <p>The article says the authors are one Kaufman &amp; Libby, and implies it was published in the last year. So: go to Google Scholar, punch in <code>Kaufman Libby</code>, limit to ‘Since 2012’; and the correct paper ( <a href="https://gwern.net/doc/www/tiltfactor.org/227553b28ae45d80f73f5e2ffa17420c06c85833.pdf" id="kaufman-libby-2012" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf" title="Kaufman &amp; Libby 2012 (Original URL: https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf )">“Changing beliefs and behavior through experience-taking”</a>) is the first hit with fulltext available on the right-hand side as the text link “[PDF] from <code>tiltfactor.org</code>” &amp; many other domains.</p>
          </section>
          <section id="finding-followups">
            <h2><a href="#finding-followups" title="Link to section: § 'Finding Followups'">Finding Followups</a></h2>
            <p><a href="https://www.lesswrong.com/posts/X6APQeHhXH9mbredM/soylent-orange-whole-food-open-source-soylent#comment-PWDQq3f5qSqWRc82c" data-link-icon="LW" data-link-icon-type="text">Is soy milk bad for you</a> as one study suggests? Has anyone replicated it? This is easy to look into a little if you use the power of reverse citation search!</p>
            <p>Plug <code>Brain aging and midlife tofu consumption</code> into Google Scholar, one of the little links under the first hit points to “Cited by 176”; if you click on that, you can hit a checkbox for “Search within citing articles”; then you can search a query like <code>experiment OR randomized OR blind</code> which yields <a href="https://scholar.google.com/scholar?q=experiment+OR+randomized+OR+blind&amp;btnG=&amp;as_sdt=20005&amp;sciodt=0%2C9&amp;cites=14459450472515815282&amp;scipsc=1" data-link-icon="google-scholar" data-link-icon-type="svg">121 results</a>⁠. The <a href="https://gwern.net/doc/www/n.neurology.org/d3d3621441fed99260a76d7b3a08b1eacafd1fbb.html" id="henderson-al-2012" rel="archived alternate nofollow" data-url-original="https://n.neurology.org/content/78/23/1841.short" title="'Long-term soy isoflavone supplementation and cognition in women: A randomized, controlled trial', Henderson et al 2012 (Original URL: https://n.neurology.org/content/78/23/1841.short )">first result</a> shows no negative effect and a trend to a benefit, the second is inaccessible, the second &amp; third are reviews whose abstract suggests it would argue for benefits, and the fourth discusses sleep &amp; mood benefits to soy diets. At least from a quick skim, this claim is not replicating, and I am dubious about it.</p>
          </section>
          <section id="how-many-homeless">
            <h2><a href="#how-many-homeless" title="Link to section: § 'How Many Homeless?'">How Many Homeless?</a></h2>
            <p>Does NYC really have 114,000+ homeless school children? This case study demonstrates the critical skill of <em>noticing</em> the need to search at all, and the search itself is almost trivial.</p>
            <p><span>Won’t someone think of the children?</span> In March 2020, as <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States" data-link-icon="wikipedia" data-link-icon-type="svg">New York coronavirus cases began their exponential increase</a> centered in Manhattan (with a similar trend to Wuhan/​Iran/​Italy), NYC Mayor <a href="https://en.wikipedia.org/wiki/Bill_de_Blasio" data-link-icon="wikipedia" data-link-icon-type="svg">Bill de Blasio</a> refused to take social distancing/​quarantine measures like ordering the NYC public school system closed, and this delay until 16 March contributed to the epidemic’s unchecked spread in NYC; one justification was that there were “114,085 homeless children” who received social services like free laundry through the schools. This number has been widely cited in the media by the <em>NYT</em>, <em>WSJ</em>, etc, and was vaguely sourced to “state data” reported by “Advocates for Children of New York”. This is a terrible reason to not deal with a pandemic that could kill tens of thousands of New Yorkers, as there are many ways to deliver services which do not require every child in NYC to attend school &amp; spread infections—but first, is this number even true?</p>
            <p><span>Basic numeracy: implausibly-large!</span> Activists of any stripe are untrustworthy sources, and a number like 114k should make any numerate person uneasy even without any <a href="https://en.wikipedia.org/wiki/Fermi_problem" data-link-icon="wikipedia" data-link-icon-type="svg">Fermi estimation</a> or fact-checking; “114,085” is suspiciously precise for such a difficult-to-measure or define thing like homelessness, and it’s well-known that the population of NYC is ~8m or 8,000k—is it really the case that around 1 in every 70 people living in NYC is a homeless child age ~5–18 attending a public school? They presumably have at least 1 parent, and probably younger siblings, so that would bring it up to &gt;228k or 1 in every &lt;35 inhabitants of NYC being homeless in general. Depending on additional factors like transiency &amp; turnover, the fraction could go much higher still. Does that make sense? No, not really. This quoted number is either surprising, or there is something missing.</p>
            <p><span>Redefining “homeless”.</span> Fortunately, the suspiciously-precise number and attribution make this a good place to start for a search. Searching for the number and the name of the activist group instantly turns up <a href="https://gwern.net/doc/www/www.advocatesforchildren.org/4396d149ff553a24534dfa3063f32211fbb8fe9c.html" rel="archived alternate nofollow" data-url-original="https://www.advocatesforchildren.org/node/1403" title="New Data Show Number of NYC Students who are Homeless Topped 100,000 for Fourth Consecutive Year (Original URL: https://www.advocatesforchildren.org/node/1403 )">the source press release</a>⁠, and the reasons for the bizarrely high number are revealed: the statistic actually redefines ‘homelessness’ to include living with relatives or friends, and counts any experience of any length in the previous year as rendering that student ‘homeless’ at the moment.</p>
            <blockquote>
              <p>The data, which come from the New York State Education Department, show that in the 2018-2019 school year, New York City district and charter schools identified 114,085, or one in ten, students as homeless. More than 34,000 students were living in New York City’s shelters, and more than twice that number (73,750) were living ‘doubled-up’ in temporary housing situations with relatives, friends, or others…“This problem is immense. The number of New York City students who experienced homelessness last year—85% of whom are Black or Hispanic—could fill the Barclays Center six times,” said Kim Sweet, AFC’s Executive Director. “The City won’t be able to break the cycle of homelessness until we address the dismal educational outcomes for students who are homeless.”</p>
            </blockquote>
            <p>The <a href="https://gwern.net/doc/www/www.coalitionforthehomeless.org/376804c98cc59e6939f6e3879828c286a3f1ee22.html" rel="archived alternate nofollow" data-url-original="https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/" title="Today's Read: New York City Had 114,000 Homeless Students Last Year (Original URL: https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/ )"><em>WSJ</em>’s article</a> (but not headline) confirms that ‘experienced’ does indeed mean ‘at any time in the year for any length of time’, rather than ‘at the moment’:</p>
            <blockquote>
              <p>City district and charter schools had 114,085 students without their own homes at some point last year, topping 100,000 for the fourth year in a row, according to state data released in a report Monday from Advocates for Children of New York, a nonprofit seeking better services for the disadvantaged. Most children were black or Hispanic, and living “doubled up” with friends, relatives or others. But more than 34,000 slept in city shelters at some point, a number larger than the entire enrollment of many districts, such as Buffalo, Rochester or Yonkers.</p>
            </blockquote>
            <p><span>Less than meet the eye.</span> So the actual number of ‘homelessness’ (in the sense that everyone reading those media articles understands it) is less than a third the quote, 34k, and that 34k number is likely itself a loose estimate of how many students would be homeless at the time of a coronavirus closure. This number is far more plausible and intuitive, and while one might wonder about what the underlying NYS Education Department numbers would reveal if fact-checked further, that’s probably unnecessary for showing how ill-founded the anti-closure argument is, since even by the activists’ own description, the relevant number is far smaller than 114k.</p>
          </section>
          <section id="citation-url-with-typo">
            <h2><a href="#citation-url-with-typo" title="Link to section: § 'Citation URL With Typo'">Citation URL With Typo</a></h2>
            <p><a href="https://gwern.net/doc/iq/high/2015-hofman.pdf" id="hofman-2015" data-link-icon="pdf" data-link-icon-type="svg" title="'Evolution of the Human Brain: From Matter to Mind', Hofman 2015">“Evolution of the Human Brain: From Matter to Mind”<span>, <span><span>Hofman</span><span>2015</span></span></span></a>⁠, discusses the limits to the intelligence of increasingly large primate brains due to considerations like increasing latency and overheating. One citation attempting to extrapolate upper bounds is “Biological limits to information processing in the human brain”<span>, <span><span title="et al">Cochrane</span> <span>et al</span> <span>1995</span></span>.</span></p>
            <p>The source information is merely a broken URL: <code>http://www.cochrane.org.uk/opinion/archive/articles.phd</code> which stands out for looking doubly-wrong: “.phd” is almost certainly a typo for “.ph<em>p</em>” (probably muscle memory on the part of Hofman from “PhD”), but it also gives a hint that the entire URL is wrong: why would an article or essay be named anything like <code>archive/articles.php</code>? That sounds like an <em>index</em> page listing all the available articles.</p>
            <p>After trying and failing to find Cochrane’s paper in the usual places, I returned to the hint. The Internet Archive doesn’t have that page under either possible URL, but the directory strongly hints that all of the papers would exist at URLs like <code>archive/brain.php</code> or <code>archive/information-processing.php</code>, and we can look up all of the URLs the IA has under that directory—how many could there be? <a href="https://web.archive.org/web/*/http://www.cochrane.org.uk/opinion/archive/*" data-link-icon="internetarchive" data-link-icon-type="svg">A lot</a>⁠, but only one has the keyword “brain” in it, providing us <a href="https://gwern.net/doc/iq/1995-cochrane-biologicallimitstoinformationprocessinginthebrain.html" id="cochrane-et-al-1995" title="'Biological limits to information processing in the human brain', Cochrane et al 1995">the paper itself</a>⁠.</p>
            <p>If that hadn’t worked, there was at least one other version hiding in the IA. When I googled the quoted title “Biological limits to information processing in the human brain”, the hits all appeared to be useless citations repeating the original Hofman citation—but for a crucial difference, as they cite a different URL (note the shift to an ‘archive.cochrane.org’ subdomain rather than the subdirectory <code>cochrane.org.uk/opinion/archive/</code>, and change of extension from <code>.html</code> to <code>.php</code>):</p>
            <ul>
              <li>
                <p>hit 5:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Retrieved from: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code></p>
                </blockquote>
              </li>
              <li>
                <p>hit 7:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Available online at: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code>; Da Costa …</p>
                </blockquote>
              </li>
            </ul>
            <p>Aside from confirming that it was indeed a ‘.php’ extension, that URL gives you <a href="https://web.archive.org/web/20161201053731/http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php" data-link-icon="internetarchive" data-link-icon-type="svg">a second copy of the paper in the IA</a>⁠. Unfortunately, the image links are broken in both versions, and the image subdirectories also seem to be empty in both IA versions, though there’s no weird JS image loading badness, so I’d guess that the image links were always broken, at least by 2004. There’s no indication it was ever published or mirrored anywhere else, so there’s not much you can do about it other than to contact Peter Cochrane (who is still alive and actively publishing although he leaves this particular article off his <a href="https://gwern.net/doc/www/petercochrane.com/d4de8653934460ebcbfc19cbf90149aa967b7949.html" rel="archived alternate nofollow" data-url-original="https://petercochrane.com/personal/publications" title="(Original URL: https://petercochrane.com/personal/publications )">publication list</a>).</p>
          </section>
          <section id="connotations">
            <h2><a href="#connotations" title="Link to section: § 'Connotations'">Connotations</a></h2>
            <p>A commenter <a href="https://www.lesswrong.com/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex#comment-AJ5xdSRjq7mwtR7Ea" data-link-icon="LW" data-link-icon-type="text">who shall remain nameless</a> wrote</p>
            <blockquote>
              <p>I challenge you to find an example of someone saying “this den of X” where X does not have a negative connotation.</p>
            </blockquote>
            <p>I found a <a href="https://www.memphisdailynews.com/news/2012/nov/15/this-den-of-grizzlies-players-doesnt-bluff/" title="This Den of Grizzlies Players Doesn't Bluff">positive connotation within 5s</a> using my Google hotkey for <code>"this den of "</code>, and, curious about further ones, found additional uses of the phrase in regard to dealing with rattlesnakes in Google Books.</p>
          </section>
          <section id="too-narrow">
            <h2><a href="#too-narrow" title="Link to section: § 'Too Narrow'">Too Narrow</a></h2>
            <p>A failure case study: <a href="https://www.lesswrong.com/posts/wKWvodoAt3zRhyC4x/rationality-quotes-november-2012#comment-c4yECdhdDHoMvNWEs" data-link-icon="LW" data-link-icon-type="text">The_Duck</a> looked for but failed to find other uses of a famous <a href="https://en.wikipedia.org/wiki/Ludwig_Wittgenstein" data-link-icon="wikipedia" data-link-icon-type="svg">Wittgenstein</a> anecdote. His mistake was being <em>too specific</em>:</p>
            <blockquote>
              <p>Yes, clearly my Google-fu is lacking. I think I searched for phrases like “sun went around the Earth,” which fails because your quote has “sun went round the Earth.”</p>
            </blockquote>
            <p>As discussed in the search tips, when you’re formulating a search, you want to balance how many hits you get, aiming for a sweet spot of a few hundred high-quality hits to review—the broader your formulation, the more likely the hits will include your target (if it exists) but the more hits you’ll return. In The_Duck’s case, he used an overly-specific search, which would turn up only 2 hits at most; this should have been a hint to loosen the search, such as by dropping quotes or dropping keywords.</p>
            <p>In this case, my reasoning would go something like this, laid out explicitly: ‘“Wittgenstein” is almost guaranteed to be on the same page as any instance of this quote, since the quote is about Wittgenstein; LW, however, doesn’t discuss Wittgenstein much, so there won’t be many hits in the first place; to find this quote, I only need to narrow down those hits a <em>little</em>, and after “Wittgenstein”, the most fundamental core word to this quote is “Earth” or “sun”, so I’ll toss one of them in and… ah, there’s the quote!’</p>
            <p>If I were searching the general Internet, my reasoning would go more like “‘Wittgenstein’ will be on, like, a <em>million</em> websites; I need to narrow that down a <em>lot</em> to hope to find it; so maybe ‘Wittgenstein’ <em>and</em> ‘Earth’ <em>and</em> ‘Sun’… nope, nothing on the first page, so toss in <code>'goes around' OR 'go around'</code>—ah there it is!”</p>
            <p>(Actually, for the general Internet, just <code>Wittgenstein earth sun</code> turns up a first page mostly about this anecdote, several of which include all the details one could need.)</p>
          </section>
          <section id="try-it">
            <h2><a href="#try-it" title="Link to section: § 'Try It'">Try It</a></h2>
            <p>Someone asked on IRC: “anybody here know that one artist with the really creepy art sytle [sic] that starts with a z?”</p>
            <p>I googled: ‘that one artist with the really creepy art sytle [sic] that starts with a z’. It was hit #2, <a href="https://en.wikipedia.org/wiki/Zdzis%C5%82aw_Beksi%C5%84ski" data-link-icon="wikipedia" data-link-icon-type="svg">Zdzisław Beksiński</a>⁠. (DuckDuckGo, incidentally, buries Beksiński several pages in, and I didn’t find him in Bing at all.)</p>
          </section>
          <section id="really-just-try-it">
            <h2><a href="#really-just-try-it" title="Link to section: § 'Really, Just Try It'">Really, Just Try It</a></h2>
            <p>Quanticle asked:</p>
            <blockquote>
              <p>There’s a sci-fi book I’m thinking of, where the protagonist is a scout soldier fighting an endless war against an insectoid species. It reads like a cross between <em>Ender’s Game</em> and <em>Starship Troopers</em> (but is not written by John Sclazi or is <em>The Forever War</em>) and the main story takes place inside a frame story where two other people are actually “reading” this soldier’s memories from his salvaged battlesuit. There is a planet called “Golden”, where the soldier is allegedly from. Does anyone have any idea what I’m talking about?</p>
            </blockquote>
            <p>The search <code>book about a soldier from the planet golden</code> immediately turned up <a href="https://en.wikipedia.org/wiki/John_Steakley" data-link-icon="wikipedia" data-link-icon-type="svg">John Steakley’s</a> <a href="https://en.wikipedia.org/wiki/Armor_(novel)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Armor</em></a>⁠. (This was showing off a little—<em>Armor</em> is well-regarded and difficult to forget, and I’d read it a long time ago and already knew the answer, pace the hacker koan<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a>⁠.)</p>
            <p>Quanticle noted that “You know, I searched for similar phrases, but I ended up fixating on the soldier’s key phrase, where he called his battle-trance”The Machine”, and that dragged in lots of irrelevancies.” (A good intuition for search engine use would shy away from using any word or phrase as incredibly generic as “the machine”.)</p>
          </section>
          <section id="try-it-1">
            <h2><a href="#try-it-1" title="Link to section: § '(Try It!)'">(Try It!)</a></h2>
            <p>FeepingCreature asked, while designing a compiler for a custom language,</p>
            <blockquote>
              <p>Hey, what was the official name for Lisp’s “data and code” thing?</p>
            </blockquote>
            <p>I already knew that it is “<a href="https://en.wikipedia.org/wiki/Homoiconicity" data-link-icon="wikipedia" data-link-icon-type="svg">homoiconicity</a>”, but I bet that <code>official name for Lisp's "data and code" thing</code> would work if I tried it in Google. It did.</p>
          </section>
          <section id="yes-that-works-too">
            <h2><a href="#yes-that-works-too" title="Link to section: § 'Yes, That Works Too'">Yes, That Works Too</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/4780683b1e77b3f92360405ebe92ba3f468fefe9.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/ )">Grayson81</a>:</p>
            <blockquote>
              <p>One thing that’s rather shocking to those of us who used search engines (and even directories like Yahoo before they got the idea of becoming real search engines from Google) is just how good they’ve got at understanding a vague, poorly written or mistaken search.</p>
              <p>…I remember trying to explain how Google works to my mother ten years ago and explaining why “who’s that actress? You know, the one with the eyes. Not <a href="https://en.wikipedia.org/wiki/Katy_Perry" data-link-icon="wikipedia" data-link-icon-type="svg">Katy Perry</a>” isn’t a question that a computer can answer. Now she can Google exactly that and all of the top results are telling her that she’s thinking of <a href="https://en.wikipedia.org/wiki/Zooey_Deschanel" data-link-icon="wikipedia" data-link-icon-type="svg">Zooey Deschanel</a>!</p>
            </blockquote>
          </section>
          <section id="comics">
            <h2><a href="#comics" title="Link to section: § 'Comics'">Comics</a></h2>
            <p><a href="https://juliagalef.com/">Julia Galef</a> tweeted:</p>
            <blockquote>
              <p>I read a webcomic ~15 years ago that I’ve been unable to find since, even with my best google-fu. It involved a robot living a bleak life as a working stiff. At the end he cracked open his “skull” and there was a small dying creature inside. The art style was less cartoony, and more like Moebius, I think? And maybe it was wordless? And, sorry, it wasn’t a “webcomic” in the sense of a long-running thing. It was a self-contained story, maybe 15 pages long?</p>
            </blockquote>
            <p>Ultimately rediscovering that</p>
            <blockquote>
              <p>The comic was called <a href="https://gwern.net/doc/fiction/science-fiction/2004-chivers-headcase.pdf" id="chivers-2004" data-link-icon="pdf" data-link-icon-type="svg" title="'Headcase', Chivers 2004">“Headcase”</a> and it was by Sam Chivers.</p>
            </blockquote>
            <p>Unfortunately, no mirrors of it appeared online or on Chivers’s current website, and discussions of it mentioned that it was interesting for being an <a href="https://en.wikipedia.org/wiki/Adobe_Flash" data-link-icon="wikipedia" data-link-icon-type="svg">Adobe Flash</a> webcomic. Worse still, nothing useful appeared <a href="https://web.archive.org/web/2020*/http://www.realitytax.com/*" data-link-icon="internetarchive" data-link-icon-type="svg">in the Internet Archive for the original website</a>—somehow the IA appeared to have missed any relevant <code>.swf</code> files, and ‘head’/​‘case’ turned up no relevant looking filenames. It might have been buried in the opaquely-named images, and my usual next step would be to download the IA archives and inspect every image, but in other hits, I found that an obscure comics publisher had published an anthology involving Chivers, and <a href="https://gwern.net/doc/www/theslingsandarrows.com/8a9eded3ebec4e1a610ff3ca854d8a0c2c5fe963.html" id="plowright-2020" rel="archived alternate nofollow" data-url-original="https://theslingsandarrows.com/prophecy-anthology-volume-1/" title="'<em>Prophecy Anthology Volume 1</em>, review', Plowright 2020 (Original URL: https://theslingsandarrows.com/prophecy-anthology-volume-1/ )">closer inspection</a> confirmed that “Headcase” was in fact published in their (long out of print) 2004 anthology <em>Prophecies: Volume 1</em>. (Not a prophetic name inasmuch as there was no volume 2.)</p>
            <p>In one of the usual ironies of linkrot, Chivers presumably taking down “Headcase” for print publication in <em>Prophecy</em> may have preserved it, as while I am unable to find any digital copies, the paper version is easily obtained as a used book &amp; scanned at modest cost.</p>
          </section>
          <section id="beating-pdf-passwords">
            <h2><a href="#beating-pdf-passwords" title="Link to section: § 'Beating PDF Passwords'">Beating PDF Passwords</a></h2>
            <p><span id="astronomy"><a href="https://cognitivemedium.com/vme" data-link-icon="MN" data-link-icon-type="text">A physics article</a></span> mentioned they had been unable to get <a href="https://gwern.net/doc/science/1973-drake.pdf" id="drake-1973" data-link-icon="pdf" data-link-icon-type="svg" title="'Life on a Neutron Star: An Interview With Frank Drake', Drake 1973">an old 1973 interview</a> in a popular magazine; as is usually the case for non-scholarly magazines, after looking thoroughly, I could find no trace of it anywhere (not even in libraries or used-magazine sellers) other than an expensive DVD collection of back issues 1970–2010 still being sold by the publisher. Reasoning that if they had digitized the archives and were even selling it as a DVD collection, they ought to provide subscribers access to them as well, I signed up—they didn’t! So I resorted to the DVD, as, worst-case, I should be able to get it running under <a href="https://en.wikipedia.org/wiki/Wine_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">WINE</a> if nothing else, and can screenshot the interview.</p>
            <p>The DVDs turned out to store all the PDFs as encrypted PDFs and the metadata in an ancient opaque database format I’d never heard of. Despite WINE AppDB’s claims, the viewing software only partially worked, and I set about attacking the PDFs directly. They used actual encryption, so pdftk couldn’t strip the passwording. Given the viewing software, I hypothesized that there was either a single master password or per-PDF passwords stored in the database.</p>
            <p>In the hopes of it being a single short master password, I installed <a href="https://en.wikipedia.org/wiki/John_the_Ripper" data-link-icon="wikipedia" data-link-icon-type="svg">John the Ripper</a> (JtR) jumbo edition and extracted the hash of a random file to attack: <code>/snap/john-the-ripper/current/run/pdf2john.pl *.pdf &gt; ~/hash</code>. (Note: pdf2john is not in the default JtR, and it depends on JtR internal files so you can’t easily just copy it out of the <a href="https://en.wikipedia.org/wiki/GitHub" data-link-icon="wikipedia" data-link-icon-type="svg">Github</a> repo &amp; run it, as I discovered the hard way. You need to install the jumbo edition.) The password hashes of all the PDFs indeed turned out to be the same, so it used a master password. A simple attack with default password-space could be executed as <code>john-the-ripper ~/hash</code>. While I waited for all of the DVDs to copy, I saw that JtR was getting something like only a hundred thousand hashes/​s on my 16 Threadripper CPU cores, and did not have any success up to 5-character passwords.</p>
            <p>If the password wasn’t really short, CPU wouldn’t be enough. I decided to switch to <a href="https://en.wikipedia.org/wiki/Hashcat" data-link-icon="wikipedia" data-link-icon-type="svg">Hashcat</a> to put my 2×1080ti Nvidia GPUs to good use, as they ought to run hundreds of times faster than JtR. (To convert the JtR hash format to Hashcat hash format, you delete the colon-separated filename field at the beginning of each line.) Hashcat uses a <a href="https://gwern.net/doc/www/hashcat.net/87fbd82f8b8794603fb3b0cca174c21310b4741b.html" rel="archived alternate nofollow" data-url-original="https://hashcat.net/wiki/doku.php?id=mask_attack" title="(Original URL: https://hashcat.net/wiki/doku.php?id=mask_attack )">powerful but confusing</a> DSL of specifying the exact password-space, and I made a reasonable guess that if the original programmer was so lazy as to use a single master password, he would also use a simple alphanumeric password (uppercase + lowercase + decimal numbers), and nothing harder to type or read. To specify the PDF hash type and an attack starting at 1-character alphanumeric &amp; increasing, I wound up with the incantation <code>hashcat -m 10500 ~/hash.cat -w 3 --force -a 3 --increment -1 '?l?u?d' ?1?1?1?1?1?1?1?1?1?1?1</code>.</p>
            <p>Hashcat worked much better and within an hour had bruteforced on the order of 170 billion hashes and up somewhere around 8 characters. This did not succeed either. At this point, another programmer thought it’d be fun to participate and, while reverse-engineering the executable to see how it decrypted PDFs, suggested that the master password was probably hardcoded as a string literal inside the viewer executable. One could just dump all the strings inside it with the CLI utility <code>strings *.exe &gt; strings.txt</code>, and then use it as a Hashcat password list. To my chagrin, when I finally got around to trying <code>cat strings.txt | hashcat -m 10500 ~/hash.cat -w 3</code>, it finished within 1s.</p>
            <p>The password turned out to be <code>B775tO11dQvu74</code>. I was right that it was alphanumerical, but at a length of 14 characters, I doubt I would have brute-forced it. (He successfully reverse-engineered it and discovered the viewer had been used for several other magazine archives as well, apparently, and simply switched master passwords to decrypt each one; the other passwords left in the executable were <code>PbS19LuXd2pTXw</code>, <code>1386r8wRrH01</code>, &amp; <code>mfU33QQNlAFGI1</code>.)</p>
            <p>I then decrypted the PDF (<code>for PDF in *.pdf; do pdftk "$PDF" input_pw "B775tO11dQvu74" output foo.pdf &amp;&amp; mv foo.pdf "$PDF"; done</code>), extracted &amp; uploaded the interview, and archived the collection elsewhere.</p>
          </section>
          <section id="lewontins-thesis">
            <h2><a href="#lewontins-thesis" title="Link to section: § 'Lewontin’s Thesis'">Lewontin’s Thesis</a></h2>
            <p>In <a href="https://gwern.net/doc/www/www.nature.com/e4b871d14e7cf16b5f751d743dcdba1981962da0.pdf" data-link-icon="n" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://www.nature.com/articles/266283a0.pdf" title="Caricature of Darwinism (Original URL: https://www.nature.com/articles/266283a0.pdf )">a vituperative review in <em>Nature</em></a> in 1977-03-17, the Harvard-professor <a href="https://en.wikipedia.org/wiki/Richard_Lewontin" data-link-icon="wikipedia" data-link-icon-type="svg">R. C. Lewontin</a> excoriated <a href="https://en.wikipedia.org/wiki/Richard_Dawkins" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Dawkins’s</a> classic <a href="https://en.wikipedia.org/wiki/The_Selfish_Gene" data-link-icon="wikipedia" data-link-icon-type="svg"><em>The Selfish Gene</em></a> and <a href="https://en.wikipedia.org/wiki/Sociobiology" data-link-icon="wikipedia" data-link-icon-type="svg">sociobiology</a> in general, giving as an example</p>
            <blockquote>
              <p>For more than 40 years evolutionary theory has remained free of a naive selectionism, but in recent times there has been a return to the extreme form of the adaptationist program, as evolutionists have rediscovered behaviour. Beginning with the undoubted truth that behaviour must, like morphology and physiology, be subject to the force of <a href="https://en.wikipedia.org/wiki/Natural_selection" data-link-icon="wikipedia" data-link-icon-type="svg">natural selection</a>⁠, the new Panglossians end with the old error that all describable behaviour must be the direct product of natural selection. The scientific manifestation of this trend can be seen in every issue of say, <em>The American Naturalist</em>, which is permeated by the language, if not the formal apparatus, of <a href="https://en.wikipedia.org/wiki/Game_theory" data-link-icon="wikipedia" data-link-icon-type="svg">game theory</a>⁠, and in the development of the school of ‘sociobiology’, among whose more extraordinary productions is a recent highly praised dissertation explaining <a href="https://en.wikipedia.org/wiki/Fellatio" data-link-icon="wikipedia" data-link-icon-type="svg"><em>fellatio</em></a> and <a href="https://en.wikipedia.org/wiki/Cunnilingus" data-link-icon="wikipedia" data-link-icon-type="svg"><em>cunnilingus</em></a> among the upper middle classes as an adaptive response to constant resources. The popular manifestation of this new caricature of Darwinism reaches its most extreme form in <em>The Selfish Gene</em> by Richard Dawkins.</p>
            </blockquote>
            <p>As is common in book reviews, Lewontin provides no citations, and <a href="https://twitter.com/DevoEvoMed/status/1478785200964476929" data-link-icon="twitter" data-link-icon-type="svg">2 biologists</a> were curious but unable to figure out what Lewontin was referring to despite searching.</p>
            <p>The thesis in question is easy to find in under a minute, because the context gives so many hints: Lewontin refers to it as notorious &amp; widely discussed so it will have many substantive citations (if only to attack it); it is ‘recent’ (and sociobiology was a heated controversy so it is unlikely to be ‘recent’ in the sense of ‘a quiet field of research still mulling over a provocative paper from 2 decades’ before, but more like ‘within the past 2 or 3 years’ &amp; certainly at least 1970–1977), it is a ‘dissertation’ and so single-authored &amp; almost certainly a PhD thesis by someone who became at least a postgrad researcher (because a master’s thesis would be too low-status to be discussed or praised, or singled out for abuse in <em>Nature</em>—it would be unclassy for a chaired Harvard professor to attack such a junior grad student’s work there like that), and it likely uses the words “fellatio” and “cunnilingus” as technical terms &amp; decorous Latinate scientific censoring.</p>
            <p>If we plug into Google Scholar a date-range of 1970–1977 and the simplest possible query <code>fellatio cunninglingus "evolutionary psychology" OR sociobiology</code> or <code>fellatio cunninglingus sociobiology</code> or <code>fellatio cunninglingus "evolutionary psychology"</code>, we see in GS 2 hits (for the former) or among the hits (latter), the immediately-relevant looking <a href="https://gwern.net/doc/genetics/selection/natural/human/1977-weinrich.pdf" id="weinrich-1977" data-link-icon="pdf" data-link-icon-type="svg" title="'Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)', Weinrich 1977">“Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)”<span>, <span><span>Weinrich</span><span>1977</span></span></span></a> and <a href="https://gwern.net/doc/genetics/selection/natural/human/1976-weinrich.pdf" id="weinrich-1976" data-link-icon="pdf" data-link-icon-type="svg" title="'Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And Race. II. Homosexuality And Non-Reproduction; Some Evolutionary Models', Weinrich 1976">“Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And…”<span>, <span><span>Weinrich</span><span>1976</span></span></span></a>⁠, both by the same author ( <a href="https://scholar.google.com/scholar?cites=15430285300114043496&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">148</a>+<a href="https://scholar.google.com/scholar?cites=4719348106040602943&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">16</a> citations, quite healthy); the single-authorship &amp; <code>search.proquest.com</code> domain for the latter immediately tells us that it’s a PhD thesis; clicking verifies that the thesis was at Harvard (which gives it both prestige Lewontin loathes &amp; ensures he could easily hear of it); the similarity of titles suggests that the paper is a condensed version of the thesis (reading the paper suggests this isn’t entirely true but is more of an update); Weinrich did indeed go on to a long career (at <a href="https://en.wikipedia.org/wiki/San_Diego_University" data-link-icon="wikipedia" data-link-icon-type="svg">San Diego University</a>⁠, publishing <a href="https://scholar.google.com/citations?user=qIeHxgkAAAAJ&amp;view_op=list_works&amp;alert_preview_top_rm=2&amp;sortby=pubdate" data-link-icon="google-scholar" data-link-icon-type="svg">up until 2014</a>); there are attacks like <a href="https://gwern.net/doc/genetics/selection/natural/human/1978-lande.pdf" id="lande-weinrich-1978" data-link-icon="pdf" data-link-icon-type="svg" title="Are Humans Maximizing Reproductive Success? [with Reply]"><span><span>Lande</span><span>1987</span></span></a> showing it did not pass without notice; and even the ProQuest preview of the abstract looks consistent with Lewontin’s summary (there can’t be that many such theses!).</p>
            <p><span>So, we can be sure that Lewontin is referring to <span><span>Weinrich</span><span>1976</span></span>.</span></p>
          </section>
          <section id="edward-tellers-atom-alphabet">
            <h2><a href="#edward-tellers-atom-alphabet" title="Link to section: § 'Edward Teller’s Atom Alphabet'">Edward Teller’s “Atom Alphabet”</a></h2>
            <p>Nuclear physicist <a href="https://en.wikipedia.org/wiki/Edward_Teller" data-link-icon="wikipedia" data-link-icon-type="svg">Edward Teller</a> wrote a rhyming ‘atom alphabet’ about the nuclear era, but only a few of the letters like A/​B/​S are ever quoted. Did he write a <em>whole</em> alphabet?</p>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/a2b78313f9aa5bc4e79048c9003b6e1509d3448a.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/" title="(Original URL: https://www.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/ )">Tracing citations back</a> to a <em>Time</em> magazine &amp; <a href="https://en.wikipedia.org/wiki/Laura_Fermi" data-link-icon="wikipedia" data-link-icon-type="svg">Laura Fermi’s</a> memoir strongly implies that he did not, and only write A/​B/​F/​H/​S. (There has been at least one effort <a href="https://www.reddit.com/r/unsong/comments/zckyg0/completing_edward_tellers_atom_alphabet_with/" data-link-icon="reddit" data-link-icon-type="svg">to write the rest</a>⁠.)</p>
          </section>
          <section id="pressley-et-al-1989">
            <h2><a href="#pressley-et-al-1989" title="Link to section: § 'Pressley et al 1989'"><span><span title="et al">Pressley</span> <span>Et Al</span> <span>1989</span></span></a></h2>
            <p>In <a href="https://www.patreon.com/posts/reading-and-85345515" data-link-icon="patreon" data-link-icon-type="svg">a discussion of learning</a>⁠, <a href="https://gwern.net/doc/www/andymatuschak.org/991e56a3a61f84d8cb1025af60ccfa6c60da6ccb.html" rel="archived alternate nofollow" data-url-original="https://andymatuschak.org/" title="(Original URL: https://andymatuschak.org/ )">Andy Matuschak</a> referenced a paper on an <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/index" title="'illusion-of-depth bias tag', N/A 2023">illusion-of-depth</a> in reading comprehension (related to illusions of learning from using cramming rather than <a href="https://gwern.net/spaced-repetition" id="gwern-spaced-repetition" title="‘Spaced Repetition for Efficient Learning’, Gwern 2009">spaced repetition</a>), but mentioned he had been unable to find a copy anywhere to verify it. The citation for this paper was:</p>
            <blockquote>
              <p>Pressley, M., Ghatala, E. S., Pirie, J., &amp; Woloshyn, V. E. (1990). <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/1990-pressley.pdf" id="pressley-et-al-1990" data-link-icon="pdf" data-link-icon-type="svg" title="'Being really, really certain you know the main idea doesn&amp;#39;t mean you do', Pressley et al 1990">“Being really, really certain you know the main idea doesn’t mean you do”</a>⁠. <a href="https://gwern.net/doc/psychology/1990-zutell-literacytheoryandresearch39thnationalreadingconference.pdf" id="zutell-mccormick-1990" data-link-icon="pdf" data-link-icon-type="svg" title="‘<em>Literacy Theory and Research: Analyses from Multiple Paradigms. Proceedings of the Annual Meeting of the National Reading Conference (39th, AUstin, Texas, November 28–December 2, 1989)’, Zutell &amp; McCormick 1990"><em>National Reading Conference Yearbook</em>, 39</a>⁠, 249–256.</p>
            </blockquote>
            <p>I rose to the challenge.</p>
            <p><span>Standard checks.</span> Matuschak is indeed correct that this paper does not show up in any of the usual places, nor does ‘yearbook’ #9 seem to show up; this nut will not be cracked instantly. We do not see any encouraging hints if we google the citation (only a sporadic handful of later citations to it, which are sporadic enough to suggest that they too <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="‘Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?’, Gwern 2014">are citing papers they have not read</a> &amp; that this will be hard to find). University &amp; ProQuest databases turn up nothing for either.</p>
            <p>This begins to look anomalous, so I broadened the search in Google. Here I stumbled across several of the yearbooks hosted at what looks like the National Reading Conference’s website; a targeted <code>site:</code> search, alas, fails to turn up anything useful. They may have scanned some later yearbooks, but apparently not the 1989 one…? Unfortunately, a dead end.</p>
            <p><span>Barkless dogs.</span> So we turn to book sources, like used-book search engines. We can find many of these yearbooks used at reasonable prices, but <em>not</em> #39—not a trace of it! This is odd. Being the 39<sup>th</sup> yearbook, with the others often available, would imply that it is available too: such serial publications don’t usually vary that much from year to year—if the ones before &amp; after it are easy to get, it should be too. What one notices is that the titles don’t look anything like “<em>National Reading Conference Yearbook</em>, 39”: this citation must be wrong, that’s not how they were titled! With this in mind, we can search for a used copy to buy &amp; scan, but this would be premature to do: now we have explained the prior absence of hits, and need to redo our searches; we thought there was no scan online before, but we know that was misleading so it may exist after all.</p>
            <p><span>Alternate titles.</span> Knowing this, we can search more broadly in Google, and skimming search results, look what we find! The PDF snippet reveals that our quarry, “Proceedings of the Annual Meeting of The National Reading Conference (39<sup>th</sup>…)” has been hidden behind the long uncited title “<em>Literacy Theory and Research: Analyses from Multiple Paradigms</em>”. Well, no wonder you can’t find it normally, and also (disappointingly but unsurprisingly), no wonder everyone copies the same incorrect citation.</p>
            <figure>
              <img alt="Screenshot of key Google search hit, revealing the Academia.edu PDF copy of ERIC scan of National Reading Conference Yearbook #39." decoding="async" height="301" loading="lazy" src="https://gwern.net/doc/technology/google/2023-07-08-gwern-google-searchcasestudy-pressleyetal1990academiaeduhit.png" width="1227">
              
            </figure>
            <p><span>Alternate paths.</span> <span>Downloading it, <span><span title="et al">Pressley</span> <span>et al</span> <span>1989</span></span> turns out to be buried on pg256 of this PDF; now that we know what to look for, this book turns out to have been easily findable after all—we can readily find the original non-Academia.edu PDF on our old friend</span> <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a><a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> and can find other yearbooks easily. We can also doublecheck other strategies: for example, if we had known the full names of the authors rather than the abbreviated ones in the citation, and we had googled something like “Michael Pressley, Elizabeth Ghatala, Jennifer Pirie, Vera E. Woloshyn”, that would have matched the indexed fulltext PDFs immediately. (Since you can often find the full names of authors even if the citation abbreviates them, this is a good tactic to know.)</p>
            <p>Thus, in this instance, it’s crucial to remember that citations can be inaccurate and one must try variations. Over-fixating on the book title can hamper efforts to locate the article, which was, in reality, merely a click away.</p>
          </section>
        </section>
        <section id="see-also">
          <h2><a href="#see-also" title="Link to section: § 'See Also'">See Also</a></h2>
          <div>
            <ul>
              <li>
                <a href="https://gwern.net/fulltext" id="gwern-fulltext" title="Jailbreak copies of these and I will pay you money.">My outstanding research paper /  book bounties</a>
              </li>
              <li>
                <a href="https://gwern.net/tank" id="gwern-tank" title="AI folklore tells a story about a neural network trained to detect tanks which instead learned to detect time of day; investigating, this probably never happened.">“The Neural Net Tank Urban Legend”</a>
              </li>
              <li>
                <a href="https://gwern.net/leprechaun" id="gwern-leprechaun" title="'Leprechaun Hunting &amp; Citogenesis', Branwen 2014">“Leprechaun hunting and historical context”</a>
              </li>
            </ul>
          </div>
        </section>
        <section id="external-links">
          <h2><a href="#external-links" title="Link to section: § 'External Links'">External Links</a></h2>
          <ul>
            <li>
              <a href="https://www.millionshort.com/">“Million Short”</a> (search engine overlay which removes top 100/​1k/​10k/​100k/​1m domains from hits, exposing obscurer sites which may be highly novel)
            </li>
            <li>Practice G search problems: <a href="https://web.archive.org/web/20140221080504/https://www.wired.com/geekdad/tag/a-google-a-day/" data-link-icon="alphabet" data-link-icon-type="svg">“A Google A Day”</a>⁠; <a href="https://gwern.net/doc/www/www.codespaces.com/5a3860e4bcce8a5dd82b5ae5ab7ccf8abaec643e.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.codespaces.com/power-searching-with-google.html" title="(Original URL: https://www.codespaces.com/power-searching-with-google.html )">Google Power Searching course</a> (OK for beginners but you may want to skip the videos in favor of the slides)
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" data-link-icon="LW" data-link-icon-type="text">“Scholarship: How to Do It Efficiently”</a>
            </li>
            <li>
              <a href="https://www.drmaciver.com/2019/05/how-to-do-hard-things/">“How to do hard things”</a>
            </li>
            <li>
              <a href="https://xkcd.com/627/" data-link-icon="XKCD" data-link-icon-type="text,quad,sans">“Tech Support Cheat Sheet”</a>
            </li>
            <li>
              <a href="https://academia.stackexchange.com/questions/90318/do-repositories-of-translated-papers-exist/93209#93209" data-link-icon="stackexchange" data-link-icon-type="svg">“Do repositories of translated papers exist?”</a>
            </li>
            <li>
              <a href="https://gwern.net/doc/www/old.reddit.com/c15cf848ea8449716b62762738bbe5cd16ba50c2.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/DataHoarder/" title="(Original URL: https://www.reddit.com/r/DataHoarder/ )"> / ​r / ​DataHoarder</a>⁠/ ​<a href="https://gwern.net/doc/www/old.reddit.com/ece168c0ec8756bd91bf377d211255fd692a04a5.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/" title="(Original URL: https://www.reddit.com/r/Piracy/ )"> / ​r / ​Piracy</a>
            </li>
            <li>Archive Team’s <a href="https://wiki.archiveteam.org/index.php?title=ArchiveBot" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Bot</a>
            </li>
            <li>
              <a href="https://beepb00p.xyz/pkm-search.html" id="gerasimov-2019" data-link-icon="🤖" data-link-icon-type="text" title="'Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine', Gerasimov 2019">“Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/d6yNW5T6J9rtnGizc/give-it-a-google" data-link-icon="alphabet" data-link-icon-type="svg">“Give it a google!”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/TCTtaFPqbMrQhttCD/five-routes-of-access-to-scientific-literature" data-link-icon="LW" data-link-icon-type="text">DeepDyve suggestion</a>
            </li>
            <li>
              <a href="https://blog.gingerbeardman.com/2023/05/24/ordering-photocopies-from-japans-national-library/">“Ordering photocopies from Japan’s National Library”</a>
            </li>
            <li>Discussion: <a href="https://en.wikipedia.org/wiki/Hacker_News" data-link-icon="wikipedia" data-link-icon-type="svg">HN</a>: <a href="https://gwern.net/doc/www/news.ycombinator.com/1825cf2969c723cbf78c03c2d1b7ac593e927f8c.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=18666574" title="(Original URL: https://news.ycombinator.com/item?id=18666574 )">1</a>⁠, <a href="https://gwern.net/doc/www/news.ycombinator.com/30721ae2ac80c788520ed537f405c797d8eac58b.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=26847596" title="(Original URL: https://news.ycombinator.com/item?id=26847596 )">2</a>⁠; <a href="https://gwern.net/doc/www/old.reddit.com/0d023966a0c138c7c6861c80a2054b9b3c114aa3.html" data-link-icon="SSC" data-link-icon-type="text,tri" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/ )">Reddit</a>⁠; <a href="https://www.lesswrong.com/posts/EF6YAq2aD5dt2sgeN/summary-internet-search-tips-by-gwern-branwen" data-link-icon="LW" data-link-icon-type="text">LW</a>
            </li>
          </ul>
        </section>
        <section id="appendix">
          <h2><a href="#appendix" title="Link to section: § 'Appendix'">Appendix</a></h2>
          <section id="searching-the-google-reader-archives">
            <h2><a href="#searching-the-google-reader-archives" title="Link to section: § 'Searching the Google Reader archives'">Searching the Google Reader Archives</a></h2>
            <div>
              <blockquote>
                <p>A tutorial on how to do manual searches of the 2013 <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> archives on the <a href="https://en.wikipedia.org/wiki/Internet_Archive" data-link-icon="wikipedia" data-link-icon-type="svg">Internet Archive</a>⁠. Google Reader provides fulltext mirrors of many websites which are long gone and not otherwise available even in the IA; however, the Archive Team archives are extremely user-unfriendly and challenging to use even for programmers. I explain how to find &amp; extract specific websites.</p>
              </blockquote>
            </div>
            <p>A little-known way to ‘undelete’ a blog or website is to use Google Reader (GR). <span>Unusual archive: Google Reader.</span> GR crawled regularly almost all blogs’ RSS feeds; RSS feeds often contain the fulltext of articles. If a blog author writes an article, the fulltext is included in the RSS feed, GR downloads it, and then the author changes their mind and edits or deletes it, GR would redownload the new version but it would continue to show the version the old version as well (you would see two versions, chronologically). If the author blogged regularly and so GR had learned to check regularly, it could hypothetically grab different edited versions, even, not just ones with weeks or months in between. Assuming that GR did not, as it sometimes did for inscrutable reasons, stop displaying the historical archives and only showed the last 90 days or so to readers; I was never able to figure out why this happened or if indeed it really did happen and was not some sort of UI problem. Regardless, if all went well, this let you undelete an article, albeit perhaps with messed up formatting or something. Sadly, GR was closed back in 2013 and you cannot simply log in and look for blogs.</p>
            <p><span>Archive Team mirrored Google Reader.</span> However, before it was closed, <a href="https://wiki.archiveteam.org/index.php?title=Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Team</a> launched a major effort to download as much of GR as possible. So in that dump, there may be archives of all of a random blog’s posts. Specifically: if a GR user subscribed to it; if Archive Team knew about it; if they requested it in time before closure; and if GR did keep full archives stretching back to the first posting.</p>
            <p><span>AT mirror is raw binary data.</span> Downside: the Archive Team dump is <em>not</em> in an easily browsed format, and merely figuring out what it <em>might</em> have is difficult. In fact, it’s so difficult that before researching Craig Wright in November–December 2015, I never had an urgent enough reason to figure out how to get anything out of it before, and I’m not sure I’ve ever seen anyone actually use it before; Archive Team takes the attitude that it’s better to preserve the data somehow and let posterity worry about <em>using</em> it. (There is a site which claimed to be a frontend to the dump but when I tried to use it, <a href="https://github.com/hubgit/archiveteam-reader-warc-extract/issues/1" data-link-icon="github" data-link-icon-type="svg">it was broken</a> &amp; still is in December 2018.)</p>
            
            <section id="results">
              <h3><a href="#results" title="Link to section: § 'Results'">Results</a></h3>
              <p><span>Success: raw HTML.</span> My <code>dd</code> extraction was successful, and the resulting HTML/​RSS could then be browsed with a command like <code>cat *.warc | fold --spaces -width=200 | less</code>. They can probably also be converted to a local form and browsed, although they won’t include any of the site assets like images or CSS/​JS, since the original RSS feed assumes you can load any references from the original website and didn’t do any kind of <a href="https://en.wikipedia.org/wiki/Data_URI_scheme" data-link-icon="wikipedia" data-link-icon-type="svg">data-URI</a> or mirroring (not, after all, having been intended for archive purposes in the first place…)</p>
            </section>
          </section>
        </section>
        <section role="doc-endnotes" id="footnotes">
          <hr>
          <ol>
            <li id="fn1" role="doc-endnote">
              <p>For example, the <code>info:</code> operator is entirely useless. The <code>link:</code> operator, in almost a decade of me trying it once in a great while, has never returned remotely as many links to my website as Google Webmaster Tools returns for inbound links, and seems to have been disabled entirely at some point.<a href="#fnref1" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn2" role="doc-endnote">
              <p>WP is increasingly out of date &amp; unrepresentative due to increasingly narrow policies about sourcing &amp; preprints, part of its overall <a href="https://gwern.net/inclusionism" id="gwern-inclusionism" title="'In Defense of Inclusionism', Branwen 2009">deletionist decay</a>⁠, so it’s not a good place to look for references. It is a good place to look for key terminology, though.<a href="#fnref2" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn3" role="doc-endnote">
              <p>When I was a kid, I knew I could just ask my reference librarian to request any book I wanted by providing the unique ID, the <a href="https://en.wikipedia.org/wiki/ISBN" data-link-icon="wikipedia" data-link-icon-type="svg">ISBN</a>⁠, and there was a physical copy of the book inside the Library of Congress; made sense. I never understood how I was supposed to get these “paper” things my popular science books or newspaper articles would sometimes cite—where <em>was</em> a paper, exactly? If it was published in <em>The Journal of Papers</em>, where did I get this journal? My library only had a few score magazine subscriptions, certainly not all of these <em>Science</em> and <em>Nature</em> and beyond. The bitter answer turns out to be: ‘nowhere’. There is no unique identifier (the majority of papers lack any DOI still), and there is no central repository nor anyone in charge—only a chaotic patchwork of individual libraries and defunct websites. Thus, books tend to be easy to get, but a paper can be a multi-decade odyssey taking one to the depths of the Internet Archive or purchasing from sketchy Chinese websites who hire pirates to infiltrate private databases.<a href="#fnref3" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn4" role="doc-endnote">
              <p>Most search engines will treat any space or separation as an implicit <code>AND</code>, but I find it helpful to be explicit about it to make sure I’m searching what I think I’m searching.<a href="#fnref4" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn5" role="doc-endnote">
              <p>This probably explains part of why no one cites that paper, and those who cite it clearly have not actually read it, even though it invented racial admixture analysis, which, since reinvented by others, has become a major method in medical genetics.<a href="#fnref5" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn6" role="doc-endnote">
              <p>University ILL privileges are one of the most underrated fringe benefits of being a student, if you do any kind of research or hobbyist reading—you can request almost anything you can find in <a href="https://en.wikipedia.org/wiki/WorldCat" data-link-icon="wikipedia" data-link-icon-type="svg">WorldCat</a>⁠, whether it’s an ultra-obscure book or a master’s thesis from 1950! Why <em>wouldn’t</em> you make regular use of it‽ Of things I miss from being a student, ILL is near the top.<a href="#fnref6" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn7" role="doc-endnote">
              <p>The complaint and indictment are not necessarily the same thing. An indictment frequently will leave out many details and confine itself to listing what the defendant is accused of. Complaints tend to be much richer in detail. However, sometimes there will be only one and not the other, perhaps because the more detailed complaint has been sealed (possibly precisely because it is more detailed).<a href="#fnref7" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn8" role="doc-endnote">
              <p>Trial testimony can run to hundreds of pages and blow through your remaining PACER budget, so one must be careful. In particular, testimony operates under an interesting &amp; <a href="https://slate.com/news-and-politics/2017/03/outrageous-trial-transcript-fees-are-bad-for-defendants-journalists-and-democracy.html" id="eisenberg-2017" data-link-icon="S" data-link-icon-type="text,sans" title="Public Record, Astronomical Price: Court reporters charge outrageous fees to reproduce trial transcripts. That's bad for defendants, journalists, and democracy.">controversial</a> <a href="https://en.wikipedia.org/wiki/Price_discrimination" data-link-icon="wikipedia" data-link-icon-type="svg">price discrimination</a> system related to how <a href="https://en.wikipedia.org/wiki/Court_reporter" data-link-icon="wikipedia" data-link-icon-type="svg">court stenographers</a> report—who are not necessarily paid employees but may be contractors or freelancers—intended to ensure covering transcription costs: the transcript initially may cost hundreds of dollars, intended to extract full value from those who need the trial transcript immediately, such as lawyers or journalists, but then a while later, PACER drops the price to something more reasonable. That is, the first “original” fee costs a fortune, but then “copy” fees are cheaper. So for <a href="https://www.uscourts.gov/services-forms/federal-court-reporting-program">the US federal court system</a>⁠, the “original”, when ordered within hours of the testimony, will cost &lt;$7.25/​page but then the second person ordering the same transcript pays only &lt;$1.20/​page &amp; everyone subsequently &lt;$0.90/​page, and as further time passes, that drops to &lt;$0.60 (and I believe after a few months, PACER will then charge only the standard $0.10). So, when it comes to trial transcript on PACER, patience pays off.<a href="#fnref8" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn9" role="doc-endnote">
              <p>I’ve heard that LexisNexis terminals are sometimes available for public use in places like federal libraries or courthouses, but I have never tried this myself.<a href="#fnref9" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn10" role="doc-endnote">
              <p>Curiously, in historical textual criticism of copied manuscripts, it’s the opposite: <a href="https://en.wikipedia.org/wiki/Lectio_brevior" data-link-icon="wikipedia" data-link-icon-type="svg">shorter = truer</a>⁠. But with memories or paraphrases, longer = truer, because those tend to elide details and mutate into catchier versions when the transmitter is not ostensibly exactly copying a text.<a href="#fnref10" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn11" role="doc-endnote">
              <p>The quick summary of DOIs is that they are “ISBNs but for research papers”; they are those odd slash-separated alphanumeric strings you see around, typically of a form like <code>10.000/abc.1234</code>. (Unlike ISBNs, the DOI standard is <em>very</em> loose, with about the only hard requirement being that there must be one <code>/</code> character in it, so almost any string is a DOI, even hateful ones like this genuine DOI: <code>10.1890/0012-9658(2001)082[1655:SVITDB]2.0.CO;2</code>.) Many papers have no DOI, or the DOI was assigned retroactively, but if they have a DOI, it can be the most reliable way to query any database for them.<a href="#fnref11" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn12" role="doc-endnote">
              <p>I advise prepending, like <code>https://sci-hub.st/https://journal.com</code> instead of appending, like <code>https://journal.com.sci-hub.st/</code> because the former is slightly easier to type but more importantly, Sci-Hub does not have SSL certificates set up properly (I assume they’re missing a wildcard) and so appending the Sci-Hub domain will fail to work in many web browsers due to HTTPS errors! However, if prepended, it’ll always work correctly.<a href="#fnref12" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn13" role="doc-endnote">
              <p>Academic publishers like to use the dark pattern of putting a little icon, labeled “full access” or “access” etc, where an Open Access indicator would go, knowing that if you are not intimately familiar with that publisher’s site design &amp; examining it carefully, you’ll be fooled. Another dark pattern is the unannounced temporary paper: in particular, the <a href="https://en.wikipedia.org/wiki/American_Psychological_Association" data-link-icon="wikipedia" data-link-icon-type="svg">APA</a>⁠, <a href="https://en.wikipedia.org/wiki/National_Bureau_of_Economic_Research" data-link-icon="wikipedia" data-link-icon-type="svg">NBER</a>⁠, &amp; <em>Cell</em> are fond of unpaywalling PDFs to exploit media coverage, and then unpredictably, silently, revoking access later and breaking links.<a href="#fnref13" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn14" role="doc-endnote">
              <p>To further illustrate this IA feature: if one was looking for Alex St.&nbsp;John’s entertaining memoir <a href="https://web.archive.org/web/20130227012620/http://www.alexstjohn.com/WP/2013/02/16/judgment-day-continued/" data-link-icon="internetarchive" data-link-icon-type="svg">“Judgment Day Continued…”</a>⁠, a 2013 account of organizing the wild <a href="https://doomwiki.org/wiki/Judgment_Day">1996 <em>Doom</em> tournament</a> thrown by Microsoft, but one didn’t have the URL handy, one could search the entire domain by going to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/*</code> and using the filter with “judgment”, or if one at least remembered it was in 2013, one could narrow it down further to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/WP/2013/*</code> and then filter or search by hand.<a href="#fnref14" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn15" role="doc-endnote">
              <p>If any Blogspot employee is reading this, <em>for god’s sake stop this insanity</em>!<a href="#fnref15" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn16" role="doc-endnote">
              <p>Uploading is not as hard as it may seem. <a href="https://library.bz/main/upload/" data-link-icon="raven" data-link-icon-type="svg">There is a web interface</a> (user/​password: “genesis”/​“upload”). Uploading large files can fail, so I usually use the FTP server: <code>curl -T "$FILE" ftp://anonymous@ftp.libgen.is/upload/</code>. <a href="#fnref16" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn17" role="doc-endnote">
              <p>Although flatbed scanning is sometimes destructive too—I’ve cracked the spine of books while pressing them flat into a flatbed scanner.<a href="#fnref17" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn18" role="doc-endnote">
              <p>My workaround is to export from gscan2pdf as DjVu, which avoids the bug, then convert the DjVu files with <code>ddjvu -format=pdf</code>; this strips any OCR, so I add OCR with <a href="https://github.com/ocrmypdf/OCRmyPDF" data-link-icon="github" data-link-icon-type="svg"><code>ocrmypdf</code></a> and metadata with <code>exiftool</code>.<a href="#fnref18" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn19" role="doc-endnote">
              <p>One exception is Google Docs: one can append <code>/mobilebasic</code> to (as of 2023-01-04) get a simplified HTML view which can be archived. For example, <a href="https://web.archive.org/web/20230104213430/https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic" data-link-icon="alphabet" data-link-icon-type="svg" title="BerSevenTimes, 2022-11-21">“A Comprehensive Guide to Dakimakuras as a Hobby”</a> is available only as a Google Docs page but the URL <code>https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic</code> will work with the Internet Archive.<a href="#fnref19" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn20" role="doc-endnote">
              <p><a href="http://www.catb.org/jargon/html/koans.html" data-link-icon="ESR" data-link-icon-type="text,tri,sans" title="Some AI Koans">“Tom Knight and the Lisp Machine”</a> (from the <a href="https://en.wikipedia.org/wiki/Jargon_File" data-link-icon="wikipedia" data-link-icon-type="svg">Jargon File</a>):</p>
              <blockquote>
                <p>A novice was trying to fix a broken <a href="https://en.wikipedia.org/wiki/Lisp_machine" data-link-icon="wikipedia" data-link-icon-type="svg">Lisp machine</a> by turning the power off and on.</p>
                <p><a href="https://en.wikipedia.org/wiki/Tom_Knight_(scientist)" data-link-icon="wikipedia" data-link-icon-type="svg">Knight</a>⁠, seeing what the student was doing, spoke sternly: “You cannot fix a machine by just power-cycling it with no understanding of what is going wrong.”</p>
                <p>Knight turned the machine off and on.</p>
              </blockquote><a href="#fnref20" role="doc-backlink">↩︎</a>
            </li>
            <li id="fn21" role="doc-endnote">
              <p>ERIC is one of the good websites for fulltext &amp; scans. It’s always a harbor in the storms of the Internet, with irreplaceable scans, especially of older gray literature like pre-WWW government publications or preprints.<a href="#fnref21" role="doc-backlink">↩︎</a></p>
            </li>
          </ol>
        </section>
        <section id="backlinks-section">
          <h2><a href="#backlinks-section" title="Link to section: § 'Further Reading'">Further Reading</a></h2><a id="backlinks" href="https://gwern.net/metadata/annotation/backlink/%252Fsearch.html" title="Reverse citations/backlinks for this page (the list of other pages which link to this page).">[Backlinks]</a>
        </section>
        <section id="link-bibliography-section">
          <h2><a href="#link-bibliography-section" title="Link to section: § 'Link Bibliography'">Link Bibliography</a></h2><a id="link-bibliography" href="https://gwern.net/metadata/annotation/link-bibliography/%252Fsearch.html" title="Bibliography of links cited in this page (forward citations). Lazily-transcluded version at footer of page for easier scrolling.">[Link bibliography]</a>
        </section>
        <section id="similars-section">
          <h2><a href="#similars-section" title="Link to section: § 'Similar Links'">Similar Links</a></h2><a id="similars" href="https://gwern.net/metadata/annotation/similar/%252Fsearch.html" title="Similar links for this link (by text embedding). Lazily-transcluded version at footer of page for easier scrolling.">[Similars]</a>
        </section>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI improperly used 702 surveillance powers on US senator (321 pts)]]></title>
            <link>https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</link>
            <guid>36822654</guid>
            <pubDate>Sat, 22 Jul 2023 02:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/">https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</a>, See on <a href="https://news.ycombinator.com/item?id=36822654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
<p>The FBI improperly used surveillance powers to conduct searches for information on a U.S. senator, a state lawmaker and a state judge, according to court records released Friday as part of a public records request.&nbsp;</p>



<p>The FBI’s improper use of Section 702 of the Foreign Intelligence Surveillance Act was documented in an opinion from the Foreign Intelligence Surveillance Court (FISC) and is sure to pose challenges for an intelligence community lobbying for the reauthorization for what it sees as one of its most vital tools.</p>





<p>The tool – which allowed for warrantless spying on foreigners located abroad – has long been criticized as a backdoor tool for gaining information on Americans who may be communicating with those being surveilled.</p>



<p>And critics complain the information gathered by the agency through 702 is too easily tapped for investigations with no foreign nexus.</p>



<p>The surveillance court outlined three examples of instances where FBI personnel conducted searches of “sensitive query terms,” like those of U.S. public officials or candidates, without first seeking approval from the FBI’s deputy director.</p>



<p>“In June 2022, an analyst conducted four queries of Section 702 information using the last names of a U.S. Senator and a state senator, without further limitation,” the opinion states.&nbsp;</p>



<p>While the two were believed to be targets of “a specific foreign intelligence service,” the National Security Division at the Department of Justice determined the FBI did not meet the needed standard for running such a query.&nbsp;</p>



<p>And in October of that year, “a Staff Operations Specialist ran a query using the Social Security number of a state judge who “had complained to [the] FBI about alleged civil right violations perpetrated by a municipal chief of police.”</p>





<p>The opinion does not make clear the identity of those searched.</p>



<p>The American Civil Liberties Union (ACLU), whose efforts prompted the release of the court opinion, highlighted other alarming patterns.</p>



<p>“These disturbing new revelations show how Section 702 surveillance, a spy program the government claims is focused on foreign adversaries, is routinely used against Americans, immigrants, and people who are not accused of any wrongdoing,” Patrick Toomey, deputy director of the ACLU’s National Security Project, said in a statement.</p>





<p>“The FBI continues to break the rules put in place to protect Americans, running illegal searches on public officials including a U.S. senator, and it’s long past time for Congress to step in. As Congress debates reauthorizing Section 702, these opinions make clear why fundamental reforms are urgently needed.”</p>



<p>The FBI and Justice Department in recent weeks have noted the roll out of some FISA reforms – pointing to a&nbsp;<a href="https://thehill.com/policy/national-security/3978746-fisa-702-searches-foreign-nationals-rise-citizen-queries-drop/" target="_blank" rel="noreferrer noopener">drop in overall queries</a>&nbsp;that involved U.S. citizens.</p>



<p>The opinion, originally filed in April, does comment on improvements from the bureau.</p>





<p>“Despite the reported errors, there is reason to believe that the FBI has been doing a better job in applying the querying standard,” Judge Rudolph Contreras writes in the opinion.</p>



<p>“In some cases, F.B.I. personnel apparently misapplied the querying standard to a group of similarly situated persons, but those violations do not approach the scale of a number of prior ones.”</p>



<p>The FBI stressed that detail in its response to the opinion’s release.</p>





<p>“The 2023 FISC Opinion confirms the significant improvement in the FBI’s Section 702 querying compliance since the implementation of our substantial reforms,” FBI Director Christopher Wray said in a statement.&nbsp;</p>



<p>“Section 702 is critical in our fight against foreign adversaries. We take seriously our role in protecting national security and we take just as seriously our responsibility to be good stewards of our Section 702 authorities. Compliance is an ongoing endeavor, and we recently announced new additional accountability measures. We will continue to focus on using our Section 702 authorities to protect American lives and keeping our Homeland safe, while safeguarding civil rights and liberties.”</p>



<p>It’s not the first time a lawmaker has been improperly searched via FISA 702, with Rep. Darin LaHood (R-Ill.) saying in March that his name was searched using the tool.</p>





<p>Section 702 is set to expire at the end of the year, and lawmakers on both sides of the aisle have said they will refuse to back its reauthorization without significant reforms.</p>



<p>The FBI on Friday sent a letter to House and Senate leaders noting that several different reviews found agents have complied with FISA guidelines at least 98 percent of the time.</p>



<p>But in a call with reporters Friday, a senior FBI official said the agency is working on building trust with lawmakers who may feel personally impacted by the issue.</p>





<p>“We are communicating as much as we can to build that level of confidence so that they understand how we are using the tool and how we are holding people accountable for when they are not using the tool correctly. But also to make sure they understand when we do and do not do such things as query members of Congress,” the official said in response to a question from The Hill.</p>



<p>“There was an unacceptably high level of non compliance and various non compliance queering behavior that was going on,” the official added.&nbsp;</p>



<p>“We’ve been very open about [how] we accepted the fact that that was unacceptable. That’s not what we expect from ourselves as an organization.”&nbsp;</p>







<p>Sen. Ron Wyden (D-Ore.), however, said lawmakers are not assured that intelligence agencies are being fully forthcoming about how they use FISA.</p>



<p>“For years, as government officials have provided misleadingly narrow testimony about who is targeted under Section 702, I have pushed to get the government to come clean.&nbsp; The revelation that 702 is used against ‘foreign governments and related entities’ directly impacts Americans’ privacy, as American journalists, businesspeople, students and others all have legitimate reason to communicate with foreign governments,” Wyden said in a statement.</p>



<p>“The fact they can be swept up in 702 collection further highlights the need for reforms to protect their privacy.”</p>

</div><p>Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Prolog in Windows NT Network Configuration (1996) (116 pts)]]></title>
            <link>https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm</link>
            <guid>36821871</guid>
            <pubDate>Sat, 22 Jul 2023 00:24:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm">https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm</a>, See on <a href="https://news.ycombinator.com/item?id=36821871">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Employees Bid on Anchor Brewery (173 pts)]]></title>
            <link>https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</link>
            <guid>36821861</guid>
            <pubDate>Sat, 22 Jul 2023 00:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/">https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</a>, See on <a href="https://news.ycombinator.com/item?id=36821861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<p><em>This is a developing story, check back for updates.</em></p>
<p>At a meeting last Wednesday at Anchor Brewing Co., executives told brewery employees that the historic San Francisco firm would be shut down after over a century and a half in business. One week later, employees have something to tell the executives: if you’ll sell us Anchor, we’ll figure out a way to buy it.</p>
<p>In a brief letter sent Wednesday evening and shared with VinePair, the business agent for Anchor Brewing Union advised Sapporo USA president Mike Minami “that workers of Anchor Brewing have met, discussed, and decided to launch an effort to purchase the brewery and run it as a worker co-op.”</p>
<p>“We are not asking for a handout or charity,” wrote Pedro de Sá, a business agent at International Longshore and Warehouse Union Local 6, which represents roughly 40 workers at the brewery. “All we want is a fair shot at being able to continue to do our jobs, make the beer we love, and keep this historic institution open. We do not want the brewery and brand we love to be sold off before we even had a chance.”</p>
<p>de Sá, speaking on behalf of union workers who voted earlier in the day to take this step, asked Minami to respond by the end of the day on Friday, July 21 indicating whether Sapporo USA was open to working “cooperatively and transparently through this process” with the union, specifically with regards to “creat[ing] the framework and rais[ing] the funds necessary for this purchase.”</p>
<p>Patrick Machel, a production worker at the brewery and a shop steward for the Anchor Brewing Union, says that the vast majority of the union’s rank-and-file workers, as well as an unspecified number of managers, support the longshot effort. “Most of us that work here were born and raised here. We work here because we love it, we grew up with Steam Beer,” he tells VinePair. Now, they’ll try to save Anchor from the scrap heap.</p>
<p>VinePair first <a href="https://vinepair.com/booze-news/anchor-brewing-company-sale/">reported</a> that Sapporo USA was on the verge of selling or shuttering Anchor on the evening of July 11. Less than 12 hours after our initial report, Sam Singer, a representative for Anchor and Sapporo USA, issued a press release announcing the brewery would “cease operations and liquidate the business following a combination of challenging economic factors and declining sales.” (The release did not mention Sapporo USA, but current and former workers were quick to tell <a href="https://vinepair.com/articles/sapporo-usa-anchor-brewing-liquidation-analysis/">VinePair’s Hop Take column</a> that the parent company mismanaged the brewery into dysfunction.)</p>
<p>As word spread of Anchor’s imminent closure last week, San Franciscans <a href="https://www.sfgate.com/food/article/anchor-brewing-final-beers-flying-off-shelves-sf-18199789.php">flocked</a> to the unmistakable Art Deco plant on Potrero Hill to pay their respects to the brewery that has kept the City by The Bay stocked with steam beer since 1871. Lines at the neighboring Anchor Public Taps stretched around the block as people clamored to buy whatever beer was left in the tanks.</p>
<p>What would happen to Anchor? In a year of searching, the company’s release claims, no buyer had emerged to acquire it whole, as a going concern. (The release does not state the price Sapporo USA was asking for the firm; it acquired Anchor six years ago in a provisional $85 million deal.) Last week, Narragansett Beer <a href="https://vinepair.com/booze-news/narragansett-beer-petition-anchor-brewing/">circulated</a> a petition to drum up support for rescuing the brewery, and several private-equity investors, perhaps impressed by the outpouring of local love for the august old brand, expressed interest to this reporter about acquiring it.</p>
<p>This past weekend, a handful of San Francisco entrepreneur types <a href="https://www.sfchronicle.com/food/wine/article/save-anchor-steam-18199818.php">described</a> to the hometown paper their plans for resurrecting Anchor; the ideas included a website to tease future crowdfunding opportunities, and a reality show about bringing the idiosyncratic brewery back to life working-titled “How hard could it be.” But the plan outlined last week in the release still stands: to turn Anchor over to an assignee for the benefit of creditors (A.B.C.), a third-party manager tasked with the orderly wind-down and sale of the business and its assets to whoever would buy them, and for whatever purpose.</p>
<p>Workers want to preempt Anchor’s real estate, equipment, and intellectual property being sold off piecemeal to the highest bidders by acquiring it from Sapporo USA and running it as a co-op, says Machel.</p>
<p>“We couldn’t go down without some way of fighting for ourselves and the community we love.”</p>
<p><em><strong>This story is a part of <a href="https://vinepair.com/business-of-drinks/">VP Pro</a>, our free content platform and newsletter for the drinks industry, covering wine, beer, and liquor — and beyond. <a href="https://vinepair.com/vp-pro-join/">Sign up for VP Pro now!</a></strong></em></p>		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hollywood is on strike because CEOs fell for Silicon Valley’s magical thinking (144 pts)]]></title>
            <link>https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</link>
            <guid>36821347</guid>
            <pubDate>Fri, 21 Jul 2023 23:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking">https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=36821347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>In one respect, the <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-16/sag-aftra-strike-actors-writers-strike-hollywood-production-film-tv-disruption-fall-season"><u>actors and writers of Hollywood</u></a> uniting on the picket lines in <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-14/actors-strike-sag-aftra-joins-writers-guild-picket-lines"><u>a historic, industry-shaking strike</u></a> is a tale as old as time: one of workers fighting bosses for better pay. Yet the reason this battle is shaping up to be so uniquely intractable and momentous — as you might have gathered from all the headlines about  artificial intelligence and streaming economics — is very much of our moment.</p><p>But it’s not, ultimately, technology that’s at the root of the problem. It’s that the studio executives both new and old have embraced the powerful — and ultimately disastrous — magical thinking pumped out by Silicon Valley for the last  10 years.</p><p>Studio heads are touting the disruptive properties of digital streaming, the transformative power of AI, a brave, unpredictable new world for entertainment writ large — and how writers and actors must adapt to this new future. But just as it did when it was issuing from the tech sector during the 2010s, this talk too often amounts to a smokescreen that lets executives and investors line their pockets and risks leaving workers holding the bag.</p><p>“These companies blew up a successful business model that the public enjoyed,  that was immensely profitable,  and they replaced it with a mishmash that we have now,” Adam Conover, the star of “Adam Ruins Everything”<i> </i>and a  negotiating committee member of the Writers Guild of America, tells me. “And now, they’re refusing to update the contract to reflect those changes.”</p><p>We’ve heard a lot about the ways that studios want to reserve the right to use AI — to create endlessly usable digital replicas of actors, to generate scripts that writers <a href="https://www.latimes.com/business/technology/story/2023-05-11/column-the-writers-strike-is-only-the-beginning-a-rebellion-against-ai-is-underway"><u>will be paid lower rates to fix up</u></a>. We’ve also heard about the new economic picture ushered in by streaming, about an industry in the throes of change, and the necessity of belt-tightening as a result. </p><p>We’ve heard Disney Chief Executive Bob Iger saying the  demand by the Screen Actors Guild for fair payment in the new digital landscape “isn’t realistic,” and heard how Netflix saw declining user sign-ups and stock prices last year. Yet  Iger reportedly makes <a href="https://www.rollingstone.com/tv-movies/tv-movie-features/disney-staffers-angry-ceo-bob-iger-actors-strike-writers-strike-1234789713/" target="_blank"><u>$27 million a year</u></a>, while Netflix <a href="https://www.wsj.com/articles/netflix-nflx-q2-earnings-report-2023-92a620c8" target="_blank"><u>just raked in $1.5 billion in net profit in the last quarter</u></a>.</p><p>So what’s really going on? And how did we get here?</p><p>First, we need to understand why the 2010s may well come to be remembered as the great decade of magical thinking for Silicon Valley. Drunk on a truly transformational first decade of the 21st century — one that saw Google, Amazon, the iPhone and social media storm the world stage — flush tech investors turned their sights toward the next generation of startups, eager to see them do the same.</p><p>The formula for seeking out that next multibillion-dollar “unicorn,” in hindsight, was pretty simple: The next wave of startups had to promise that it would disrupt a stale industry with a newer, high-tech, app-driven alternative, promise the potential for vast scale and promise that it could do so fast. So we saw the rise of Uber and Lyft, each of which vowed to revolutionize transit, and we got the likes of WeWork, which set out to usher in the future of co-working, and Theranos, which would do the same for at-home blood testing.</p><p>We know how it ended. Uber and Lyft have never been sustainably profitable, WeWork collapsed dramatically when it became clear that it was merely a wildly over-leveraged real estate company, and Theranos’ futuristic medical technology was outright fraudulent. </p><p>Unlike many of the 21st century’s first-wave tech companies and products, which found both markets and roads to profitability, these were pipe dreams, propped up by a fire hose of investment cash, big-talking founders and the very real — and at the time, quite understandable! — sense that Silicon Valley was the place that determined how the future was made.</p><p>As the 2010s began, Netflix sat somewhere between the old guard and the new. It introduced online streaming in 2007, and had a real product with real demand, as well as an established business in its DVD-by-mail rental service. Yet its ambitions were hypercharged by a newfangled sense that it could disrupt the old school Hollywood industry and scale endlessly — there was no reason everyone in the world with access to a screen couldn’t subscribe.</p><p><a href="https://www.reuters.com/article/us-netflix-stock/netflix-shares-soar-after-icahn-reports-10-percent-stake-purchase-idUSBRE89U1GA20121101" target="_blank"><u>Big-name investors</u></a> sank hundreds of millions into Netflix’s new vision. As it began producing original content in 2013, it applied a distinctly next-wave Silicon Valley ethos. It would make massive upfront investments, bankrolling huge productions such as the David Fincher-helmed, Kevin Spacey-starring “House of Cards,” elbowing its way into the prestige TV pack, promising not only to compete but also to do it better: It would offer all the episodes at once, on demand, and viewers could consume them whenever and however they wanted. Cable would become obsolete. The future was cutting the cord.</p><p>As with Uber and Lyft, whose bottomless chests of venture capital allowed them to conquer new markets once dominated by stodgy old competitors — in their case, the taxi cartels and livery cab companies — price was no object.</p><p>Right out the gate, episodes for original Netflix shows such as “House of Cards” and “Orange Is the New Black”<i> </i>cost $4 million a pop. (So did episodes of shows that few remember today, such as “Hemlock Grove.”) The spending was profligate — it soon rose to rates of <a href="https://www.indiewire.com/features/general/netflix-originals-budget-15-billion-1202036683/" target="_blank"><u>$15 billion a year</u></a> on new content — but as it did for the magical valley startups, the strategy “worked.”</p><p>“What happens is Netflix becomes the Wall Street darling, and all these other companies,” like Amazon, Disney, Apple, HBO, Paramount and NBC, “race to adopt Netflix’s business model,” Conover says. </p><p>Herein lies the trouble. Amid this boom, which for a few years ushered in a gold rush for writers and talent, Netflix et al. adopted another key ingredient of Silicon Valley’s approach: secrecy. Data about shows’ performance and viewer habits were kept proprietary; we  knew only what the streamers wanted us to know. That went for customers, performers, writers and for investors. Streaming is an inscrutable black box, about which so many stories might be told.</p><p>It’s a sticking point in the negotiations — actors and writers on streaming series want a better way to calculate the value of their work, given that the residuals they earn are so much lower than for network or cable shows. The studios have resisted. “The reason nobody really wants to open the books on this is because if Wall Street got a look,” one Hollywood insider <a href="https://www.vulture.com/2023/06/streaming-industry-netflix-max-disney-hulu-apple-tv-prime-video-peacock-paramount.html" target="_blank"><u>told New York Magazine</u></a>, “they’d have a collective stroke.”</p><p>What we’re seeing now is the fantastical thinking that Netflix and its followers could continue endless expansion running up against the physics of the real world — there are now 238 million Netflix subscribers, but those numbers <a href="https://www.latimes.com/entertainment-arts/business/story/2022-04-19/lat-et-ct-netflix-loses-subscriber-first-quarter">dropped for the first time</a> last year, and the company had to claw them back by nibbling at the corners, <a href="https://www.latimes.com/entertainment-arts/business/story/2021-03-11/netflix-password-sharing-policing">cutting off password sharing</a> and launching new, cheaper tiers that run ads.</p><p>The boom times are over. Executives know it. Wall Street knows it. And the story that we’re in a revolutionary moment of technological transformation will run out of gas soon. So the bosses are using that moment to do what Silicon Valley wound up doing when its other big swings didn’t pan out: squeeze labor. </p><p>Just as Uber and Lyft, which promised drivers rich rewards and flexible fares, started reducing rates and making it harder to earn those rewards, Netflix and the streaming cohort cut in its mold are now trying to square their promises of world conquest by slashing worker pay under the fog of magical thinking.</p><p>It’s been noted, and correctly so, that entertainment industry labor disputes often erupt when there’s a change in technology — from theaters screening projected films to the cathode ray tube of the home television, say, or the rise of YouTube and other online content in the 2000s  — and that happens for a reason. Historically, executives and management use a disorienting new technology to try to justify lowering wages of their workers, and they have done so since the days of the Industrial Revolution. </p><p>“The old CEOs knew they had to work with the unions, bargain with us,” Conover says. “The new ones don’t. So part of the point of the strike is us as labor showing the tech CEOs that no, you actually do have to deal fairly with the unions.”</p><p>Conover notes that it’s jarring to see the streamers plead poverty as an excuse not to negotiate with talent in good faith, given that show budgets and profits have both gone up. </p><p>“Netflix lied to the public and Wall Street,” he says, telling them, “‘you can watch every show ever made in perpetuity, with no ads, for $15.99 a month forever.’ That’s like Movie Pass” (the much-hyped app that allowed users to see unlimited movies for a monthly fee, before quickly going bankrupt). “That’s ludicrous.” </p><p>Ludicrous if you want to pay the people who actually create those shows for you, anyway.</p><p>What Netflix and the streamers are trying to do now is seal in a new standard under which writers and actors are treated in much the way that Uber and the gig app companies treat their independent contractor drivers. </p><p>“Uber is a perfect example,” Conover says. “Its drivers need to supply their own cars, their own gas, their own insurance and so on.” The drivers are on their own, with few to no benefits or protections, and are expected to maximize profits for the company. “And Netflix is trying to do the same thing.”</p><p>Unlike Uber, Netflix really <i>is </i>quite profitable. But in order to sustain the mythical levels of growth it has promised investors, it is turning to similar tactics — cutting workers’ hours, making work more precarious and unpredictable and reducing pay. It’s a far cry from the sleek, automated futures promised by the studio executives.</p><p>As with the biggest companies of Silicon Valley’s magical thinking era, it’s often hard to parse whether the ones touting the game-changing technologies themselves even believe in these visions — do studio execs really think consumers want to watch a parade of digital replicas of their favorite actors parroting lines from an AI-generated script? Or are they simply aware that the mere threat of such a future gives them leverage and power over the workers of today?</p><p>In the end, the answer is immaterial. Silicon Valley’s invasion of Hollywood brought with it science fictional notions of growth for the industry, a penchant for secrecy and unaccountability and the expectation that it could get away with treating workers like robots or invisible code. We’re seeing what happens when those notions meet, for one of the first times, with a powerful, organized resistance.</p><p>Personally, I’m hoping this one gets a Hollywood ending — and not the ending so many Silicon Valley startups got over the last 10 years.</p> </div></div>]]></description>
        </item>
    </channel>
</rss>