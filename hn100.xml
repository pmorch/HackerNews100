<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 26 Sep 2024 12:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Sam Altman: Long con was "child's play for me" (144 pts)]]></title>
            <link>https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/</link>
            <guid>41657001</guid>
            <pubDate>Thu, 26 Sep 2024 11:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/">https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/</a>, See on <a href="https://news.ycombinator.com/item?id=41657001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h6><a href="http://www.reddit.com/r/askreddit/submit?selftext=true&amp;title=%5BSerious%5D"> [ SERIOUS ] </a></h6>

<h5><a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_rules">Rules</a>:</h5>

<ol>
<li><p>You must post a clear and direct question in the title. The title may contain two, short, necessary context sentences.
No text is allowed in the textbox. Your thoughts/responses to the question can go in the comments section. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_1-">more &gt;&gt;</a></p></li>
<li><p>Any post asking for advice should be generic and not specific to your situation alone. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_2-">more &gt;&gt;</a></p></li>
<li><p>AskReddit is for open-ended discussion questions. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_3-">more &gt;&gt;</a></p></li>
<li><p>Posting, or seeking, any identifying personal information, real or fake, will result in a ban without a prior warning. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_4-">more &gt;&gt;</a></p></li>
<li><p>AskReddit is not your soapbox, personal army, or advertising platform. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_5-">more &gt;&gt;</a></p></li>
<li><p>[Serious] tagged posts are off-limits to jokes or irrelevant replies. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_6-">more &gt;&gt;</a></p></li>
<li><p>Soliciting money, goods, services, or favours is not allowed. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_7-">more &gt;&gt;</a></p></li>
<li><p>Mods reserve the right to remove content or restrict users' posting privileges as necessary if it is deemed detrimental to the subreddit or to the experience of others. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_8-">more &gt;&gt;</a></p></li>
<li><p>Comment replies consisting solely of images will be removed. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_9-">more &gt;&gt;</a></p></li>
<li><p>Do not post harmful misinformation. <a href="https://www.reddit.com/r/AskReddit/wiki/index/#wiki_-rule_10-">more &gt;&gt;</a></p></li>
<li><p>Spam, machine-generated content, and karma farming are not permitted. <a href="https://www.reddit.com/r/AskReddit/wiki/index/#wiki_-rule_11-">more &gt;&gt;</a></p></li>
</ol>

<h5>If you think your post has disappeared, see spam or an inappropriate post, please do not hesitate to <a href="https://www.reddit.com/message/compose?to=%2Fr%2FAskReddit">contact the mods</a>, we're happy to help.</h5>

<hr>

<h4>Tags to use:</h4>

<blockquote>
<h2><a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_6-">[Serious]</a></h2>
</blockquote>

<h3>Use a <strong>[Serious]</strong> post tag to designate your post as a serious, on-topic-only thread.</h3>



<h4>Filter posts by subject:</h4>

<p><a href="http://ud.reddit.com/r/AskReddit/#ud">Mod posts</a>
<a href="https://www.reddit.com/r/AskReddit/search/?q=flair%3Aserious&amp;sort=new&amp;restrict_sr=on&amp;t=all">Serious posts</a>
<a href="http://bu.reddit.com/r/AskReddit/#bu">Megathread</a>
<a href="http://nr.reddit.com/r/AskReddit/#nr">Breaking news</a>
<a href="https://old.reddit.com/r/AskReddit">Unfilter</a></p>



<h3>Please use spoiler tags to hide spoilers. <code>&gt;!insert spoiler here!&lt;</code></h3>



<h4>Other subreddits you might like:</h4>

<table><thead>
<tr>
<th>Related</th>
<th>Subreddits</th>
</tr>
</thead><tbody>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_advice_and_relationships">Advice and Assistance</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_ask_a_______">Ask Others</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_askreddit_offshoots">AskReddit Offshoots</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_general_discussion">General Discussion</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_requests_.26amp.3B_assistance">Requests &amp; Assistance</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_what_is_this______">Help Me Identify This</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_reddit.2Fmeta">Reddit/Meta</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_find_subreddits">Find Subreddits</a></td>
</tr>
</tbody></table>



<h3>Ever read the reddiquette? <a href="https://old.reddit.com/wiki/reddiquette">Take a peek!</a></h3>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to Become For-Profit Company (195 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639</link>
            <guid>41655954</guid>
            <pubDate>Thu, 26 Sep 2024 08:34:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639">https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639</a>, See on <a href="https://news.ycombinator.com/item?id=41655954">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Rewriting Rust (277 pts)]]></title>
            <link>https://josephg.com/blog/rewriting-rust/</link>
            <guid>41654871</guid>
            <pubDate>Thu, 26 Sep 2024 05:37:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://josephg.com/blog/rewriting-rust/">https://josephg.com/blog/rewriting-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=41654871">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>The Rust programming language feels like a first generation product.</p>

<p>You know what I mean. Like the first iPhone - <a href="https://www.youtube.com/watch?v=MnrJzXM7a6o">which was amazing by the way</a>. They made an entire operating system around multitouch. A smart phone with no keyboard. And a working web browser. Within a few months, we all realised what the iPhone really wanted to be. Only, the first generation iphone wasn't quite there. It didn't have 3G internet. There was no GPS chip. And there was no app store. In the next few years, iPhones would get a lot better.</p>

<p>Rust feels a bit like that first iPhone.</p>

<p>I fell in love with Rust at the start. Algebraic types? Memory safety without compromising on performance? A modern package manager? Count me in. But now that I've been programming in rust for 4 years or so, it just feels like its never quite there.</p>

<p>And I don't know if it will ever be there. Progress on the language has slowed <em>so much</em>. When I first started using it, every release seemed to add new, great features in stable rust. Now? Crickets. The <a href="https://doc.rust-lang.org/unstable-book/the-unstable-book.html">rust "unstable book"</a> lists <em>700</em> different unstable features - which presumably are all implemented, but which have yet to be enabled in stable rust. Most of them are changes to the standard library - but seriously. Holy cow.</p>

<p>How much of this stuff will <em>ever</em> make it into the language proper? The rust RFC process is a graveyard of good ideas.</p>

<p>Features like <a href="https://doc.rust-lang.org/unstable-book/language-features/coroutines.html">Coroutines</a>. This RFC is 7 years old now. Make no mistake - coroutines are implemented in the compiler. They're just, not available for us "stable rust" peasants to use. If coroutines were a child, they would be in grade school by now. At this point, the coroutines RFC has lasted longer than World War 1 or 2.</p>

<p>I suspect rust is calcifying because its consensus process just doesn't scale. Early on, rust had a small group of contributors who just <em>decided</em> things. The monsters. Now, there are issue threads like <a href="https://github.com/rust-lang/rust/issues/93740#issuecomment-1041391284">this</a>, in which 25 smart, well meaning people spent 2 years and over 200 comments trying to figure out how to improve <code>Mutex</code>. And as far as I can tell, in the end they more or less gave up.</p>

<p>Maybe this is by design. Good languages are stable languages. It might be time to think of rust as a fully baked language - warts and all. Python 2.7 for life.</p>

<p>But that doesn't change anything for me. I want a better rust, and I feel powerless to make that happen. Where are my coroutines? Even javascript has <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function*">coroutines</a>.</p>

<h2 id="fantasylanguage">Fantasy language</h2>

<p>Sometimes I lie awake at night fantasising about forking the compiler. I know how I'd do it. In my fork, I'd leave all the rust stuff alone and but make my own "seph" <a href="https://doc.rust-lang.org/edition-guide/editions/">edition</a> of the rust language. Then I could add all sorts of breaking features to that edition. So long as my compiler still compiles mainline rust as well, I could keep using all the wonderful crates on Cargo.</p>

<p>I think about this a lot. If I did it, here's what I'd change:</p>

<h3 id="functiontraitseffects">Function traits (effects)</h3>

<p>Rust has traits on structs. These are used in all sorts of ways. Some are markers. Some are understood by the compiler (like <code>Copy</code>). Some are user defined.</p>

<p>Rust should also define a bunch of traits for functions. In other languages, function traits are called "effects".</p>

<p>This sounds weird at first glance - but hear me out. See, there's lots of different "traits" that functions have. Things like:</p>

<ul>
<li>Does the function ever panic?</li>
<li>Does the function have a fixed stack size?</li>
<li>Does the function run to the end, or does it yield / await?</li>
<li>If the function is a coroutine, what is the type of the continuation?</li>
<li>Is the function "pure" (ie, the same input produces the same output, and it has no side effects)</li>
<li>Does the function (directly or indirectly) run unsafe code in semi-trusted libraries?</li>
<li>Is the function guaranteed to terminate?</li>
</ul>

<p>And so on.</p>

<p>A function's parameters and return type are just associated types on the function:</p>

<pre><code>fn some_iter() -&gt; impl Iterator&lt;Item = usize&gt; {  
    vec![1,2,3].into_iter()
}

fn main() {  
    // Why doesn't this work already via FnOnce?
    let x: some_iter::Output = some_iter();
}
</code></pre>

<p><a href="https://rust-lang.github.io/rfcs/2515-type_alias_impl_trait.html">TAIT</a> eat your heart out.</p>

<p>Exposing these properties is super useful. For example, the linux kernel wants to guarantee (at compile time) that some block of code will never panic. This is impossible to do in rust today. But using function traits, we could explicitly mark a function as being able - or unable - to panic:</p>

<pre><code>#[disallow(Panic)] // Syntax TBD.
fn some_fn() { ... }  
</code></pre>

<p>And if the function does anything which could panic (even recursively), the compiler would emit an error.</p>

<p>The compiler already sort of implements traits on functions, like <code>Fn</code>, <code>FnOnce</code> and <code>FnMut</code>. But for some reason they're anemic. (Why??)</p>

<p>I want something like this:</p>

<pre><code>/// Automatically implemented on all functions.
trait Function {  
  type Args,
  type Output,
  type Continuation, // Unit type () for normal functions
  // ... and so on.

  fn call_once(self, args: Self::Args) -&gt; Self::Output;
}

trait NoPanic {} // Marker trait, implemented automatically by the compiler.

/// Automatically implemented on all functions which don't recurse.
trait KnownStackSize {  
  const STACK_SIZE: usize,
}
</code></pre>

<p>Then you could write code like this:</p>

<pre><code>fn some_iter() -&gt; impl Iterator&lt;Item = usize&gt; {  
  vec![1,2,3].into_iter();
}

struct SomeWrapperStruct {  
  iter: some_iter::Output, // In 2024 this is still impossible in stable rust.
}
</code></pre>

<p>Or with coroutines:</p>

<pre><code>coroutine fn numbers() -&gt; impl Iterator&lt;Item = usize&gt; {  
  yield 1;
  yield 2;
  yield 3;
}

coroutine fn double&lt;I: Iterator&lt;Item=usize&gt;&gt;(inner: I) -&gt; impl Iterator&lt;Item = usize&gt; {  
  for x in inner {
    yield x * 2;
  }
}

struct SomeStruct {  
  // Suppose we want to store the iterator. We can name it directly:
  iterator: double&lt;numbers&gt;::Continuation,
}
</code></pre>

<p>Or, say, take a function parameter but require that the parameter itself doesn't panic:</p>

<pre><code>fn foo&lt;F&gt;(f: F)  
    where F: NoPanic + FnOnce() -&gt; String
{ ... }
</code></pre>

<p>Yoshua Wuyts has an excellent <a href="https://blog.yoshuawuyts.com/extending-rusts-effect-system/">talk &amp; blog post</a> going into way more detail about effects - why they're useful and how this could work.</p>

<h3 id="compiletimecapabilities">Compile-time Capabilities</h3>

<p>Most rust projects pull in an insane number of 3rd party crates. Most of these crates are small utility libraries - like the <a href="https://crates.io/crates/human-size"><code>human-size</code></a> crate which formats file sizes for human consumption. Great stuff! But unfortunately, all of these little crates add supply chain risk. Any of those authors could push out an update which contains malicious code - cryptolockering our computers, our servers or sneaking bad code into our binaries.</p>

<p>I think this problem is similar to the problem of memory safety. Sure - its sometimes useful to write memory-unsafe code. The rust standard library is full of it. But rust's <code>unsafe</code> keyword lets authors opt in to potentially unsafe things. We only add <code>unsafe</code> blocks when its necessary.</p>

<p>Lets do the same thing for privileged function calls - like reading and writing to and from the filesystem or the network. This is useful stuff, but its potentially dangerous. Developers should actively whitelist code that is allowed to call these functions.</p>

<p>To implement this, first we want to add marker traits to all the security-sensitive functions in the standard library (opening a file from a string, <code>exec</code>, FFI, opening network connections, most unsafe functions that interact with raw pointers, and so on). So, for example, <a href="https://doc.rust-lang.org/std/fs/fn.write.html"><code>std::fs::write(path, contents)</code></a> writes to an arbitrary path on disk with the credentials of the user. We add some <code>#[cap(fs_write)]</code> marker tag to the function itself, marking that this can only be called from code which is in some way trusted. The compiler automatically "taints" any other functions which call <code>write</code> in the entire call tree.</p>

<p>Suppose I call a function in a 3rd party crate which needs the <code>fs_write</code> capability. In order to call that function, I need to explicitly whitelist that call. (Either by adding the permission explicitly in my <code>Cargo.toml</code> or maybe with an annotation at the call site).</p>

<p>So, lets say the <code>foo</code> crate contains a function like this. The function will be marked (tainted) with the "writes to filesystem" tag:</p>

<pre><code>// In crate `foo`.

// (this function is implicitly tagged with #[cap(fs_write)])
pub fn do_stuff() {  
  std::fs::write("blah.txt", "some text").unwrap();
}
</code></pre>

<p>When I try to run that function from my code:</p>

<pre><code>fn main() {  
  foo::do_stuff();
}
</code></pre>

<p>The compiler can give me a nice rusty error, like this:</p>

<pre><code>Error: foo::do_stuff() writes to the local filesystem, but the `foo` crate has not been trusted with this capability in Cargo.toml.

Tainted by this line in do_stuff:

  std::fs::write("blah.txt", "some text").unwrap();

Add this to your Cargo.toml to fix:

foo = { version = "1.0.0", allow_capabilities: ["fs_write"] }  
</code></pre>

<p>Obviously, most uses of <code>unsafe</code> would also require explicit whitelisting.</p>

<p>Most crates I use - like <code>human-size</code> or <code>serde</code> don't need any special capabilities to work. So we don't need to worry so much about their authors "turning evil" and adding malicious code to our software. Reducing the supply chain risk from the 100 or so crates I currently transitively depend on down to just a few would be massive.</p>

<p>This is a very simple, static way that capabilities could be introduced to Rust. But it might be possible &amp; better to change privileged code to require an extra <code>Capability</code> parameter (some unit struct type). And heavily restrict how <code>Capability</code> objects can be instantiated. Eg:</p>

<pre><code>struct FsWriteCapability;

impl FsWriteCapability {  
    fn new() { Self } // Only callable from the root crate
}

// Then change std::fs::write's signature to this:
pub fn write(path: Path, contents: &amp;[u8], cap: FsWriteCapability) { ... }  
</code></pre>

<p>This requires more boilerplate, but its much more flexible. (And obviously, we'd also need to, somehow, apply a similar treatment to <code>build.rs</code> scripts and <code>unsafe</code> blocks.)</p>

<p>The result of all of this is that utility crates become "uncorruptable". Imagine if crates.io is hacked and serde is maliciously updated to include with cryptolocker code. Today, that malicious code would be run automatically on millions of developer machines, and compiled into programs everywhere. With this change, you'd just get a compiler error.</p>

<p>This is huge, and singlehandedly this one feature is probably worth the cost of forking rust. At least, to someone. (Anyone want to sponsor this work?)</p>

<h3 id="pinmoveandstructborrows">Pin, Move and Struct Borrows</h3>

<blockquote>
  <p>Feel free to skip this section if Pin &amp; the borrow checker gives you a migraine.</p>
</blockquote>

<p><code>Pin</code> in rust is a weird, complicated hack to work around a hole in the borrow checker. Its a band-aid from the land of bizzaro choices that only make sense when you need to maintain backwards compatibility at all costs.</p>

<ul>
<li>Its the reverse of the trait you actually want. It would make way more sense to have a <code>Move</code> marker trait (like <code>Copy</code>) indicating objects which <em>can</em> move.</li>
<li>But <code>Pin</code> isn't an actual trait. There's only <code>Unpin</code> (double negative now) and <code>!Unpin</code> - which is not-not-not-<code>Move</code>. For example <a href="https://doc.rust-lang.org/1.81.0/src/core/marker.rs.html#923"><code>impl !Unpin for PhantomPinned</code></a>. Is <code>!Unpin</code> the same as <code>Pin</code>? Uhhhh, ... No? Because .. reasons? I get an instant headache when I think about this stuff. Here's the <a href="https://doc.rust-lang.org/std/marker/trait.Unpin.html">documentation for Unpin</a> if you want to try your luck.</li>
<li>Pin only applies to reference types. If you read through code which uses <code>Pin</code> a lot, you'll find unnecessary <code>Box</code>-ing of values <em>everywhere</em>. For example, <a href="https://docs.rs/tokio-stream/latest/src/tokio_stream/wrappers/broadcast.rs.html#11-18">in tokio</a>, or helper libraries like <a href="https://lib.rs/crates/ouroboros">ouroboros</a>, <a href="https://docs.rs/async-trait/latest/async_trait/">async<em>trait</em></a><em> and <a href="https://docs.rs/self_cell/latest/self_cell/">self</a></em><a href="https://docs.rs/self_cell/latest/self_cell/">cell</a>.</li>
<li>The pain spreads. Any function that takes a pinned value needs the value wrapped using some horrible abomonation <a href="https://doc.rust-lang.org/std/future/trait.Future.html">like <code>Future::poll(self: Pin&lt;&amp;mut Self&gt;, ..)</code></a>. And then you need to figure out how to read the actual values out using projections, which are so complicated there are <a href="https://docs.rs/pin-project/latest/pin_project/">multiple</a> <a href="https://crates.io/crates/pin-project-lite/">crates</a> for dealing with them. The pain cannot be confined. It spreads outwards, forever, corrupting everything.</li>
</ul>

<p>I swear, it took more effort to learn pinning in rust than it took me to learn the entire Go programming language. And I'm still not convinced I'm totally across it. And I'm not alone. I've heard the <a href="https://fuchsia.dev/">Fuchsia operating system project</a> abandoned Rust for C++ in some parts because of how impossibly complex Pin makes everything.</p>

<p>Why is <code>Pin</code> needed, anyway?</p>

<p>We can write rust functions like this:</p>

<pre><code>fn main() {  
    let x = vec![1,2,3];
    let y = &amp;x;

    //drop(x); // error[E0505]: cannot move out of `x` because it is borrowed
    dbg!(y);
}
</code></pre>

<p>All variables in a rust function are actually, secretly in one of 3 different states:</p>

<ul>
<li>Normal (owned)</li>
<li>Borrowed</li>
<li>Mutably borrowed</li>
</ul>

<p>While a variable is borrowed (<code>y = &amp;x</code>), you can't move, mutate or drop the variable. In this example, <code>x</code> is put into a special "borrowed" state throughout the lifetime of <code>y</code>. Variables in the "borrowed" state are pinned, immutable, and have a bunch of other constraints. This "borrowed state" is visible to the compiler, but its completely invisible to the programmer. You can't tell that something is borrowed until you try to compile your program. (Aside: I wish Rust IDEs made this state visible while programming!)</p>

<p>But at least this program <em>works</em>.</p>

<p>Unfortunately, there's no equivalent to this for structs. Lets turn the function <code>async</code>:</p>

<pre><code>async fn foo() {  
    let x = vec![1,2,3];
    let y = &amp;x;

    some_future().await;

    dbg!(y);
}
</code></pre>

<p>When you compile this, the compiler creates a hidden struct for you, which stores the suspended state of this function. It looks something like this:</p>

<pre><code>struct FooFuture {  
  x: Vec&lt;usize&gt;,
  y: &amp;'_ Vec&lt;usize&gt;,
}

impl Future for FooFuture { ... }  
</code></pre>

<p><code>x</code> is borrowed by <code>y</code>. So it needs to be placed under all the constraints of a borrowed variable:</p>

<ul>
<li>It must not move in memory. (It needs to be Pinned)</li>
<li>It must be immutable</li>
<li>We can't take mutable references to <code>x</code> (because of the &amp; xor &amp;mut rule).</li>
<li><code>x</code> must outlive <code>y</code>.</li>
</ul>

<p>But there's no syntax for this. Rust doesn't have syntax to mark a struct field as being in a borrowed state. And we can't express the lifetime of <code>y</code>.</p>

<p>Remember: the rust compiler already generates and uses structs like this whenever you use <code>async</code> functions. The compiler just doesn't provide any way to write code like this ourselves. Lets just extend the borrow checker and fix that!</p>

<p>I don't know what the ideal syntax would be, but I'm sure we can come up with something. For example, maybe <code>y</code> gets declared as a "local borrow", written as <code>y: &amp;'Self::x Vec&lt;usize&gt;</code>. The compiler uses that annotation to figure out that <code>x</code> is borrowed. And it puts it under the same set of constraints as a borrowed variable inside a function.</p>

<p>This would also let you work with self-referential structs, like an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree (AST)</a> in a compiler:</p>

<pre><code>struct Ast {  
  source: String,
  ast_nodes: Vec&lt;&amp;'Self::source str&gt;,
}
</code></pre>

<p>This syntax could also be adapted to support partial borrows:</p>

<pre><code>impl Foo {  
  fn get_some_field&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a::some_field usize {
    &amp;self.some_field
  }
}
</code></pre>

<p>This isn't a complete solution.</p>

<p>We'd also need a <code>Move</code> marker trait, to replace <code>Pin</code>. Any struct with borrowed fields can't be Moved - so it wouldn't have <code>impl Move</code>. I'd also consider a <code>Mover</code> trait, which would allow structs to intelligently move themselves in memory. Eg:</p>

<pre><code>trait Mover {  
  // Something like that.
  unsafe fn move(from: *Self, to: MaybeUninit&lt;&amp;mut Self&gt;);
}
</code></pre>

<p>We'd also need a sane, safe way to construct structs like this in the first place. I'm sure we can do better than <code>MaybeUninit</code>.</p>

<p>Miguel Young de la Sota <a href="https://www.youtube.com/watch?v=UrDhMWISR3w">gave a fantastic talk a few years ago</a> talking about <code>Move</code> in rust. But I think it would be much more "rusty" to lean on the borrow checker instead.</p>

<p>If you ask me, <code>Pin</code> is a dead end solution. Rust already has a borrow checker. Lets use it for structs.</p>

<h3 id="comptime">Comptime</h3>

<p>This is a hot opinion. I haven't spent a lot of time with zig, but at least from a distance I adore <a href="https://zig.guide/language-basics/comptime/">comptime</a>.</p>

<p>In the rust compiler we essentially implement two languages: Rust and the Rust Macro language. (Well, arguably there's 3 - because proc macros). The Rust programming language is lovely. But the rust macro languages are horrible.</p>

<p>But, if you already know rust, why not just use rust itself instead of sticking another language in there? This is the genius behind Zig's <code>comptime</code>. The compiler gets a little interpreter tacked on that can run parts of your code at compile time. Functions, parameters, if statements and loops can all be marked as compile-time code. Any non-comptime code in your block is emitted into the program itself.</p>

<p>I'm not going to explain the feature in full here. Instead, take in just how <em>gorgeous</em> this makes Zig's <a href="https://ziglang.org/documentation/master/#Case-Study-print-in-Zig">std <code>print</code> function</a>.</p>

<p>Its entirely implemented using comptime. So when you write this in zig:</p>

<pre><code>pub fn main() void {  
    print("here is a string: '{s}' here is a number: {}\n", .{ a_string, a_number });
}
</code></pre>

<p><code>print</code> takes the format string as a comptime parameter, and parses it within a <code>comptime</code> loop. Aside from a couple keywords, the function is just regular zig code - familiar to anyone who knows the language. It just gets executed within the compiler. And the result? It emits this beauty:</p>

<pre><code>pub fn print(self: *Writer, arg0: []const u8, arg1: i32) !void {  
    try self.write("here is a string: '");
    try self.printValue(arg0);
    try self.write("' here is a number: ");
    try self.printValue(arg1);
    try self.write("\n");
    try self.flush();
}
</code></pre>

<p>Read the <a href="https://ziglang.org/documentation/master/#Case-Study-print-in-Zig">full case study</a> for more details.</p>

<p>In comparison, I tried to look up how rust's <code>println!()</code> macro is implemented. But <a href="https://doc.rust-lang.org/src/std/macros.rs.html#138-145">println! calls some secret <code>format_args_nl</code> function</a>. I assume that function is hardcoded in the rust compiler itself.</p>

<p>Its not a great look when even the rust compiler authors don't want to use rust's macro language.</p>

<h3 id="weirdlittlefixes">Weird little fixes</h3>

<p>Bonus round time. Here's some other little "nits" I'd love to fix while we're at it:</p>

<ul>
<li><code>impl&lt;T: Copy&gt; for Range&lt;T&gt;</code>. If you know, you know.</li>
<li>Fix <a href="https://github.com/rust-lang/rust/issues/26925">derive with associated types</a>. <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=6fd2c813f411f6eb1abb66a473425c89">Full example here</a>.</li>
<li>Make if-let expressions support logical AND. Its so simple, so obvious, and so useful. This should work:</li>
</ul>

<pre><code>// Compile error! We can't have nice things.
if let Some(x) = some_var &amp;&amp; some_expr { }  
</code></pre>

<p>You can sort of work around this problem today as below, but its awkward to write, hard to read and the semantics are different from how normal <code>if</code> statements work because it lacks short-circuit evaluation.</p>

<pre><code>// check_foo() will run even if some_var is None.
if let (Some(x), true) = (some_var, check_foo()) { ... }  
</code></pre>

<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=e4c4521e6a0ab49462c0b9d55da97480">Full example here</a>.</p>

<p>Rust's ergonomics for raw pointers are also uniquely horrible. When I work with unsafe code, my code should be as easy to read &amp; write as humanly possible. But the rust compiler seems intent on punishing me for my sins. For example, if I have a reference to a struct in rust, I can write <code>myref.x</code>. But if I have a pointer, rust insists that I write <code>(*myptr).x</code> or, worse: <code>(*(*myptr).p).y</code>. Horrible. Horrible and entirely counterproductive. Unsafe code should be clear.</p>

<p>I'd also change all the built in collection types to take an <code>Allocator</code> as a constructor argument. I personally don't like Rust's decision to use a global allocator. Explicit is better than implicit.</p>

<h2 id="closingthoughts">Closing thoughts</h2>

<p>Thats all the ideas I have. I mean, async needs some love too. But there's so much to say on the topic that async deserves a post of its own.</p>

<p>Unfortunately, most of these changes would be incompatible with existing rust. Even adding security capabilities would require a new rust edition, since it introduces a new way that crates can break semver compatibility.</p>

<p>A few years ago I would have considered writing RFCs for all of these proposals. But I like programming more than I like dying slowly in the endless pit of github RFC comments. I don't want months of work to result in yet another idea in <a href="https://doc.rust-lang.org/reference/items/associated-items.html">rust's landfill of unrealised dreams</a>.</p>

<p>Maybe I should fork the compiler and do it myself. Urgh. So many projects. If I could live a million lifetimes, I'd devote one to working on compilers.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git-absorb: Git commit –fixup, but automatic (286 pts)]]></title>
            <link>https://github.com/tummychow/git-absorb</link>
            <guid>41653191</guid>
            <pubDate>Thu, 26 Sep 2024 00:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tummychow/git-absorb">https://github.com/tummychow/git-absorb</a>, See on <a href="https://news.ycombinator.com/item?id=41653191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">git absorb</h2><a id="user-content-git-absorb" aria-label="Permalink: git absorb" href="#git-absorb"></a></p>
<p dir="auto">This is a port of Facebook's <a href="https://www.mercurial-scm.org/repo/hg/rev/5111d11b8719" rel="nofollow"><code>hg absorb</code></a>, which I first read about on <a href="https://groups.google.com/forum/#!msg/mozilla.dev.version-control/nh4fITFlEMk/ZNXgnAzxAQAJ" rel="nofollow">mozilla.dev.version-control</a>:</p>
<blockquote>
<ul dir="auto">
<li>Facebook demoed <code>hg absorb</code> which is probably the coolest workflow enhancement I've seen to version control in years. Essentially, when your working directory has uncommitted changes on top of draft changesets, you can run <code>hg absorb</code> and the uncommitted modifications are automagically folded ("absorbed") into the appropriate draft ancestor changesets. This is essentially doing <code>hg histedit</code> + "roll" actions without having to make a commit or manually make history modification rules. The command essentially looks at the lines that were modified, finds a changeset modifying those lines, and amends that changeset to include your uncommitted changes. If the changes can't be made without conflicts, they remain uncommitted. This workflow is insanely useful for things like applying review feedback. You just make file changes, run <code>hg absorb</code> and the mapping of changes to commits sorts itself out. It is magical.</li>
</ul>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Elevator Pitch</h2><a id="user-content-elevator-pitch" aria-label="Permalink: Elevator Pitch" href="#elevator-pitch"></a></p>
<p dir="auto">You have a feature branch with a few commits. Your teammate reviewed the branch and pointed out a few bugs. You have fixes for the bugs, but you don't want to shove them all into an opaque commit that says <code>fixes</code>, because you believe in atomic commits. Instead of manually finding commit SHAs for <code>git commit --fixup</code>, or running a manual interactive rebase, do this:</p>
<div data-snippet-clipboard-copy-content="git add $FILES_YOU_FIXED
git absorb --and-rebase"><pre><code>git add $FILES_YOU_FIXED
git absorb --and-rebase
</code></pre></div>
<p dir="auto"><code>git absorb</code> will automatically identify which commits are safe to modify, and which staged changes belong to each of those commits. It will then write <code>fixup!</code> commits for each of those changes.</p>
<p dir="auto">With the <code>--and-rebase</code> flag, these fixup commits will be automatically integrated into the corresponding ones. Alternatively, you can check its output manually if you don't trust it, and then fold the fixups into your feature branch with git's built-in <a href="https://git-scm.com/docs/git-rebase#Documentation/git-rebase.txt---autosquash" rel="nofollow">autosquash</a> functionality:</p>
<div data-snippet-clipboard-copy-content="git add $FILES_YOU_FIXED
git absorb
git log # check the auto-generated fixup commits
git rebase -i --autosquash master"><pre><code>git add $FILES_YOU_FIXED
git absorb
git log # check the auto-generated fixup commits
git rebase -i --autosquash master
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing</h2><a id="user-content-installing" aria-label="Permalink: Installing" href="#installing"></a></p>
<p dir="auto">The easiest way to install <code>git absorb</code> is to download an artifact from the latest <a href="https://github.com/tummychow/git-absorb/releases">tagged release</a>. Artifacts are available for Windows, MacOS, and Linux (built on Ubuntu with statically linked libgit2). If you need a commit that hasn't been released yet, check the <a href="https://github.com/tummychow/git-absorb/actions/workflows/build.yml?query=event%3Apush+branch%3Amaster">latest CI artifact</a> or file an issue.</p>
<p dir="auto">Alternatively, <code>git absorb</code> is available in the following system package managers:</p>
<a href="https://repology.org/project/git-absorb/versions" rel="nofollow">
    <img src="https://camo.githubusercontent.com/782be13a15856ff171807dc4f47a704c26e7dd85ca9250a4f191dfdd1264fa03/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f6769742d6162736f72622e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/git-absorb.svg">
</a>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Arch Linux</td>
<td><code>pacman -S git-absorb</code></td>
</tr>
<tr>
<td>Debian</td>
<td><code>apt install git-absorb</code></td>
</tr>
<tr>
<td>DPorts</td>
<td><code>pkg install git-absorb</code></td>
</tr>
<tr>
<td>Fedora</td>
<td><code>dnf install git-absorb</code></td>
</tr>
<tr>
<td>FreeBSD Ports</td>
<td><code>pkg install git-absorb</code></td>
</tr>
<tr>
<td>Homebrew and Linuxbrew</td>
<td><code>brew install git-absorb</code></td>
</tr>
<tr>
<td>MacPorts</td>
<td><code>sudo port install git-absorb</code></td>
</tr>
<tr>
<td>nixpkgs stable and unstable</td>
<td><code>nix-env -iA nixpkgs.git-absorb</code></td>
</tr>
<tr>
<td>openSUSE</td>
<td><code>zypper install git-absorb</code></td>
</tr>
<tr>
<td>Ubuntu</td>
<td><code>apt install git-absorb</code></td>
</tr>
<tr>
<td>Void Linux</td>
<td><code>xbps-install -S git-absorb</code></td>
</tr>
<tr>
<td>GNU Guix</td>
<td><code>guix install git-absorb</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling from Source</h2><a id="user-content-compiling-from-source" aria-label="Permalink: Compiling from Source" href="#compiling-from-source"></a></p>
<p dir="auto"><a href="https://crates.io/crates/git-absorb" rel="nofollow"><img src="https://camo.githubusercontent.com/f476a92ce2878451af440486bc81ef2165b4c3717400beb4b8a9b189ddfcff10/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6769742d6162736f72622e737667" alt="crates.io badge" data-canonical-src="https://img.shields.io/crates/v/git-absorb.svg"></a> <a href="https://github.com/tummychow/git-absorb/actions/workflows/build.yml"><img src="https://github.com/tummychow/git-absorb/actions/workflows/build.yml/badge.svg?branch=master&amp;event=push" alt="Build"></a></p>
<p dir="auto">You will need the following:</p>
<ul dir="auto">
<li><a href="https://github.com/rust-lang/cargo">cargo</a></li>
</ul>
<p dir="auto">Then <code>cargo install git-absorb</code>. Make sure that <code>$CARGO_HOME/bin</code> is on your <code>$PATH</code> so that git can find the command. (<code>$CARGO_HOME</code> defaults to <code>~/.cargo</code>.)</p>
<p dir="auto">Note that <code>git absorb</code> does <em>not</em> use the system libgit2. This means you do not need to have libgit2 installed to build or run it. However, this does mean you have to be able to build libgit2. (Due to <a href="https://github.com/alexcrichton/git2-rs/commit/76f4b74aef2bc2a54906ddcbf7fbe0018936a69d">recent changes</a> in the git2 crate, CMake is no longer needed to build it.)</p>
<p dir="auto">Note: <code>cargo install</code> does not currently know how to install manpages (<a href="https://github.com/rust-lang/cargo/issues/2729" data-hovercard-type="issue" data-hovercard-url="/rust-lang/cargo/issues/2729/hovercard">cargo#2729</a>), so if you use <code>cargo</code> for installation then <code>git absorb --help</code> will not work. Here is a manual workaround, assuming your system has a <code>~/.local/share/man/man1</code> directory that <code>man --path</code> knows about:</p>
<div data-snippet-clipboard-copy-content="wget https://raw.githubusercontent.com/tummychow/git-absorb/master/Documentation/git-absorb.1
mv git-absorb.1 ~/.local/share/man/man1"><pre><code>wget https://raw.githubusercontent.com/tummychow/git-absorb/master/Documentation/git-absorb.1
mv git-absorb.1 ~/.local/share/man/man1
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li><code>git add</code> any changes that you want to absorb. By design, <code>git absorb</code> will only consider content in the git index (staging area).</li>
<li><code>git absorb</code>. This will create a sequence of commits on <code>HEAD</code>. Each commit will have a <code>fixup!</code> message indicating the message (if unique) or SHA of the commit it should be squashed into.</li>
<li>If you are satisfied with the output, <code>git rebase -i --autosquash</code> to squash the <code>fixup!</code> commits into their predecessors. You can set the <a href="https://stackoverflow.com/a/29094904" rel="nofollow"><code>GIT_SEQUENCE_EDITOR</code></a> environment variable if you don't need to edit the rebase TODO file.</li>
<li>If you are not satisfied (or if something bad happened), <code>git reset --soft</code> to the pre-absorption commit to recover your old state. (You can find the commit in question with <code>git reflog</code>.) And if you think <code>git absorb</code> is at fault, please <a href="https://github.com/tummychow/git-absorb/issues/new">file an issue</a>.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works (roughly)</h2><a id="user-content-how-it-works-roughly" aria-label="Permalink: How it works (roughly)" href="#how-it-works-roughly"></a></p>
<p dir="auto"><code>git absorb</code> works by checking if two patches P1 and P2 <em>commute</em>, that is, if applying P1 before P2 gives the same result as applying P2 before P1.</p>
<p dir="auto"><code>git absorb</code> considers a range of commits ending at HEAD. The first commit can be specified explicitly with <code>--base &lt;ref&gt;</code>. By default the last 10 commits will be considered (see <a href="#configuration">Configuration</a> below for how to change this).</p>
<p dir="auto">For each hunk in the index, <code>git absorb</code> will check if that hunk commutes with the last commit, then the one before that, etc. When it finds a commit that does not commute with the hunk, it infers that this is the right parent commit for this change, and the hunk is turned into a fixup commit. If the hunk commutes with all commits in the range, it means we have not found a suitable parent commit for this change; a warning is displayed, and this hunk remains uncommitted in the index.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Stack size</h3><a id="user-content-stack-size" aria-label="Permalink: Stack size" href="#stack-size"></a></p>
<p dir="auto">When run without <code>--base</code>, git-absorb will only search for candidate commits to fixup within a certain range (by default 10). If you get an error like this:</p>
<div data-snippet-clipboard-copy-content="WARN stack limit reached, limit: 10"><pre><code>WARN stack limit reached, limit: 10
</code></pre></div>
<p dir="auto">edit your local or global <code>.gitconfig</code> and add the following section</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    maxStack=50 # Or any other reasonable value for your project"><pre><span>[absorb]</span>
    <span>maxStack</span>=50 <span><span>#</span> Or any other reasonable value for your project</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">One fixup per fixable commit</h3><a id="user-content-one-fixup-per-fixable-commit" aria-label="Permalink: One fixup per fixable commit" href="#one-fixup-per-fixable-commit"></a></p>
<p dir="auto">By default, git-absorb will generate separate fixup commits for every absorbable hunk. Instead, can use the <code>-F</code> flag to create only 1 fixup commit for all hunks that absorb into the same commit.
To always have this behavior, set</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    oneFixupPerCommit = true"><pre><span>[absorb]</span>
    <span>oneFixupPerCommit</span> = true</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Auto-stage all changes if nothing staged</h3><a id="user-content-auto-stage-all-changes-if-nothing-staged" aria-label="Permalink: Auto-stage all changes if nothing staged" href="#auto-stage-all-changes-if-nothing-staged"></a></p>
<p dir="auto">By default, git-absorb will only consider files that you've staged to the index via <code>git add</code>. However, sometimes one wants to try and absorb from all changes, which would require to stage them first via <code>git add .</code>. To avoid this extra step, set</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    autoStageIfNothingStaged = true"><pre><span>[absorb]</span>
    <span>autoStageIfNothingStaged</span> = true</pre></div>
<p dir="auto">which tells git-absorb, when no changes are staged, to auto-stage them all, create fixup commits where possible, and unstage remaining changes from the index.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fixup target always SHA</h3><a id="user-content-fixup-target-always-sha" aria-label="Permalink: Fixup target always SHA" href="#fixup-target-always-sha"></a></p>
<p dir="auto">By default, git-absorb will create fixup commits with their messages pointing to the target commit's summary, and if there are duplicate summaries, will fallback to pointing to the target's SHA. Instead, can always point to the target's SHA via:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    fixupTargetAlwaysSHA = true"><pre><span>[absorb]</span>
    <span>fixupTargetAlwaysSHA</span> = true</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO</h2><a id="user-content-todo" aria-label="Permalink: TODO" href="#todo"></a></p>
<ul dir="auto">
<li>implement force flag</li>
<li>implement remote default branch check</li>
<li>add smaller force flags to disable individual safety checks</li>
<li>stop using <code>failure::err_msg</code> and ensure all error output is actionable by the user</li>
<li>slightly more log output in the success case</li>
<li>more tests (esp main module and integration tests)</li>
<li>document stack and commute details</li>
<li>more commutation cases (esp copy/rename detection)</li>
<li>don't load all hunks in memory simultaneously because they could be huge</li>
<li>implement some kind of index locking to protect against concurrent modifications</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WP Engine is banned from WordPress.org (132 pts)]]></title>
            <link>https://wordpress.org/news/2024/09/wp-engine-banned/</link>
            <guid>41652760</guid>
            <pubDate>Wed, 25 Sep 2024 22:59:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/news/2024/09/wp-engine-banned/">https://wordpress.org/news/2024/09/wp-engine-banned/</a>, See on <a href="https://news.ycombinator.com/item?id=41652760">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Any WP Engine customers having trouble with their sites should <a href="https://wpengine.com/contact/">contact WP Engine support and ask them to fix it</a>.</p>



<p>I won’t bore you with the story of how WP Engine <a href="https://x.com/photomatt/status/1838502185879167069">broke thousands of customer sites yesterday in their haphazard attempt to block our attempts to inform the wider WordPress community</a> regarding their disabling and locking down a WordPress core feature in order to extract profit.</p>



<p><strong>What I will tell you is that, pending their legal claims and litigation against WordPress.org, WP Engine no longer has free access to WordPress.org’s resources.</strong></p>



<p>WP Engine wants to control your WordPress experience, they need to run their own user login system, update servers, plugin directory, theme directory, pattern directory, block directory, translations, photo directory, job board, meetups, conferences, bug tracker, forums, Slack, Ping-o-matic, and showcase. Their servers can no longer access our servers for free.</p>



<p>The reason WordPress sites don’t get hacked as much anymore is we work with hosts to block vulnerabilities at the network layer, WP Engine will need to replicate that security research on their own.</p>



<p>Why should WordPress.org provide these services to WP Engine for free, given their attacks on us?</p>



<p>WP Engine is free to offer their hacked up, bastardized simulacra of WordPress’s GPL code to their customers, and they can experience WordPress as WP Engine envisions it, with them getting all of the profits and providing all of the services.</p>



<p>If you want to experience WordPress, use any other host in the world besides WP Engine. <a href="https://wordpress.org/news/2024/09/wp-engine/">WP Engine is not WordPress</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to remove non-profit control and give Sam Altman equity (323 pts)]]></title>
            <link>https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/</link>
            <guid>41651548</guid>
            <pubDate>Wed, 25 Sep 2024 20:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/">https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41651548">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Mira Exits OpenAI (696 pts)]]></title>
            <link>https://twitter.com/miramurati/status/1839025700009030027</link>
            <guid>41651038</guid>
            <pubDate>Wed, 25 Sep 2024 19:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/miramurati/status/1839025700009030027">https://twitter.com/miramurati/status/1839025700009030027</a>, See on <a href="https://news.ycombinator.com/item?id=41651038">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Httpdbg – A tool to trace the HTTP requests sent by your Python code (157 pts)]]></title>
            <link>https://github.com/cle-b/httpdbg</link>
            <guid>41650905</guid>
            <pubDate>Wed, 25 Sep 2024 19:18:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cle-b/httpdbg">https://github.com/cle-b/httpdbg</a>, See on <a href="https://news.ycombinator.com/item?id=41650905">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">httpdbg</h2><a id="user-content-httpdbg" aria-label="Permalink: httpdbg" href="#httpdbg"></a></p>
<p dir="auto"><code>httpdbg</code> is a tool for Python developers to easily debug the HTTP(S) client requests in a Python program.</p>
<p dir="auto">To use it, execute your program using the <code>pyhttpdbg</code> command instead of <code>python</code> and that's it. Open a browser to <code>http://localhost:4909</code> to view the requests:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/cle-b/httpdbg/blob/main/ui.png?raw=true"><img src="https://github.com/cle-b/httpdbg/raw/main/ui.png?raw=true" alt=""></a></p>
<p dir="auto">Full documentation =&gt; <a href="https://httpdbg.readthedocs.io/en/latest/" rel="nofollow">https://httpdbg.readthedocs.io/</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">installation</h2><a id="user-content-installation" aria-label="Permalink: installation" href="#installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">usage</h2><a id="user-content-usage" aria-label="Permalink: usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">interactive console</h3><a id="user-content-interactive-console" aria-label="Permalink: interactive console" href="#interactive-console"></a></p>
<p dir="auto">Open an interactive console using the command <code>pyhttpdbg</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(venv) dev@host:~/dir$ pyhttpdbg 
.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.
  httpdbg - HTTP(S) requests available at http://localhost:4909/
.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.
Python 3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
(InteractiveConsole)
>>> "><pre><span>(venv) dev@host:~/dir</span>$ <span>pyhttpdbg </span>
<span>.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.</span>
<span>  httpdbg - HTTP(S) requests available at http://localhost:4909/</span>
<span>.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.</span>
<span>Python 3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0] on linux</span>
<span>Type "help", "copyright", "credits" or "license" for more information.</span>
<span>(InteractiveConsole)</span>
<span>&gt;&gt;&gt; </span></pre></div>
<p dir="auto">Perform HTTP requests.</p>
<p dir="auto">You can inspect the HTTP requests directly in your web browser at <a href="http://localhost:4909/" rel="nofollow">http://localhost:4909</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">script</h3><a id="user-content-script" aria-label="Permalink: script" href="#script"></a></p>
<p dir="auto">You can trace all the HTTP requests performed by a script</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg --script filename.py [arg1 --arg2 ...]"><pre><span>pyhttpdbg --script filename.py [arg1 --arg2 ...]</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">pytest</h3><a id="user-content-pytest" aria-label="Permalink: pytest" href="#pytest"></a></p>
<p dir="auto">You can trace all the HTTP requests performed during your tests</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -m pytest [arg1 --arg2 ...]"><pre><span>pyhttpdbg -m pytest [arg1 --arg2 ...]</span></pre></div>
<p dir="auto">If you use the <code>pytest-xdist</code> plugin to execute your tests in parallel, then you must install the <code>pytest-httpdbg</code> plugin if you want to trace the requests done by the pytest workers.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install httpdbg[pytest]"><pre><span>pip install httpdbg[pytest]</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">module</h3><a id="user-content-module" aria-label="Permalink: module" href="#module"></a></p>
<p dir="auto">You can trace all the HTTP requests performed by a library module run as a script using the <code>-m</code> command line argument.</p>
<p dir="auto">For example, you can view which HTTP requests are performed by <code>pip</code> when you install a package.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -m pip install hookdns --upgrade"><pre><span>pyhttpdbg -m pip install hookdns --upgrade</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Initiators</h2><a id="user-content-initiators" aria-label="Permalink: Initiators" href="#initiators"></a></p>
<p dir="auto">An initiator is the function/method that is at the origin of the HTTP requests. By default, we already support some packages but you can add your own initiators.</p>
<p dir="auto">To add a new package in the list of initiators, you can use the <code>-i</code> command line argument:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -i api_client_pck --script my_script.py"><pre><span>pyhttpdbg -i api_client_pck --script my_script.py</span></pre></div>
<p dir="auto">You can use any package as an initiator, this is not limited to HTTP requests.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Already supported packages</h3><a id="user-content-already-supported-packages" aria-label="Permalink: Already supported packages" href="#already-supported-packages"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>packages</th>
<th>status</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests</td>
<td>supported</td>
</tr>
<tr>
<td>urllib3</td>
<td>supported</td>
</tr>
<tr>
<td>httpx</td>
<td>supported</td>
</tr>
<tr>
<td>aiohttp</td>
<td>supported</td>
</tr>
<tr>
<td>pytest</td>
<td>supported</td>
</tr>
<tr>
<td><em>your_package</em></td>
<td>yes, with the arg <em>-i your_package</em></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">configuration</h2><a id="user-content-configuration" aria-label="Permalink: configuration" href="#configuration"></a></p>
<p dir="auto">No configuration is necessary to start but some few settings are available for particular use.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">command line</h3><a id="user-content-command-line" aria-label="Permalink: command line" href="#command-line"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="usage: pyhttpdbg [-h] [--port PORT] [--version] [--initiator INITIATOR] [--keep-up | --force-quit]
                 [--console | --module MODULE | --script SCRIPT]

httdbg - a very simple tool to debug HTTP(S) client requests

options:
  -h, --help            show this help message and exit
  --port PORT, -p PORT  the web interface port
  --version, -v         print the httpdbg version
  --initiator INITIATOR, -i INITIATOR
                        add a new initiator (package)
  --keep-up, -k         keep the server up even if the requests have been read
  --force-quit, -q      stop the server even if the requests have not been read
  --console             run a python console (default)
  --module MODULE, -m MODULE
                        run library module as a script (the next args are passed to pytest as is)
  --script SCRIPT       run a script (the next args are passed to the script as is)"><pre><span>usage: pyhttpdbg [-h] [--port PORT] [--version] [--initiator INITIATOR] [--keep-up | --force-quit]</span>
<span>                 [--console | --module MODULE | --script SCRIPT]</span>

<span>httdbg - a very simple tool to debug HTTP(S) client requests</span>

<span>options:</span>
<span>  -h, --help            show this help message and exit</span>
<span>  --port PORT, -p PORT  the web interface port</span>
<span>  --version, -v         print the httpdbg version</span>
<span>  --initiator INITIATOR, -i INITIATOR</span>
<span>                        add a new initiator (package)</span>
<span>  --keep-up, -k         keep the server up even if the requests have been read</span>
<span>  --force-quit, -q      stop the server even if the requests have not been read</span>
<span>  --console             run a python console (default)</span>
<span>  --module MODULE, -m MODULE</span>
<span>                        run library module as a script (the next args are passed to pytest as is)</span>
<span>  --script SCRIPT       run a script (the next args are passed to the script as is)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">web interace</h3><a id="user-content-web-interace" aria-label="Permalink: web interace" href="#web-interace"></a></p>
<p dir="auto">Clic on the <strong>⚙</strong> button on the top right of the page.</p>
<p dir="auto">Some options are available:</p>
<ul dir="auto">
<li>Hide the netloc in the url</li>
<li>Hide the initiator rows</li>
</ul>
<p dir="auto">To keep your configuration, bookmark the page with the full search query.</p>
<p dir="auto">Fox example, if you want to hide the initiator rows by default, the url will be:</p>
<div data-snippet-clipboard-copy-content="http://localhost:4909/?hi=on"><pre><code>http://localhost:4909/?hi=on
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">web interface</h2><a id="user-content-web-interface" aria-label="Permalink: web interface" href="#web-interface"></a></p>
<p dir="auto">All the requests recorded are available on the web interface.</p>
<p dir="auto">The requests:</p>
<ul dir="auto">
<li>are still available in the web page even if the python process stopped (except if you force quit before the requests have been loaded by the web page).</li>
<li>are automatically cleaned if a new execution is detected.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">documentation</h2><a id="user-content-documentation" aria-label="Permalink: documentation" href="#documentation"></a></p>
<p dir="auto"><a href="https://httpdbg.readthedocs.io/" rel="nofollow">https://httpdbg.readthedocs.io</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eliminating Memory Safety Vulnerabilities at the Source (228 pts)]]></title>
            <link>https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html</link>
            <guid>41650647</guid>
            <pubDate>Wed, 25 Sep 2024 18:49:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html">https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html</a>, See on <a href="https://news.ycombinator.com/item?id=41650647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to avoid a BSOD on your 2B dollar spacecraft (143 pts)]]></title>
            <link>https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/</link>
            <guid>41650534</guid>
            <pubDate>Wed, 25 Sep 2024 18:40:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/">https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/</a>, See on <a href="https://news.ycombinator.com/item?id=41650534">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/satellitesafemode-480.webp 480w,https://clarkwakeland.com/assets/img/satellitesafemode-800.webp 800w,https://clarkwakeland.com/assets/img/satellitesafemode-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/satellitesafemode.png" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Short answer: turn it off and turn it back on</p> <p>Long Answer…</p> <h3 id="background">Background</h3> <p>The lifecycle of most spacecraft consists of a final phase where all the systems are tested to various levels of synergy. One of the most important and complex set of tests are the <strong>C</strong>losed <strong>L</strong>oop <strong>T</strong>ests (<strong>CLT</strong>s), where the spacecraft is sent simulated orbital data, and then its attitude response is observed. It’s a closed loop because the attitude telemetry is fed back into the simulation while the test is occurring, effectively making the spacecraft and whatever hardware is currently being used part of the simulation. This particular test involved observing the response from control thrusters on the spacecraft when commanded to perform a slew and engine burn to a transfer orbit.</p> <p>To get the spacecraft response data back to in the loop, a set of memory addresses mapped to the sim needs to be uploaded onto the spacecraft RAM. These memory addresses were not determined while this test was being developed. Instead, a set of placeholder addresses meant for the previous spacecraft was used in the development environment.</p> <p>Ok, fair enough. When we’re developing our tests prior to them being run on the spacecraft, it’s useful to have <em>something</em> to upload, even if it’s not the final product.</p> <h2 id="the-vehicle">The Vehicle</h2> <p>The placeholder memory addresses were the <strong>actual memory addresses used for a previously developed spacecraft</strong>. As such, the name of the file containing the addresses was something like “XProp_transducer_addr_val.upx”. In all of the review meetings, this was most likely ignored because of how official it looked. All the engineers who worked on the last spacecraft assumed the naming convention was the same on this one, and those like me who were working on their first spacecraft had no other point of reference.</p> <p>The day comes and it’s finally time to run this test. Naturally, we get an unexplainable error, which is something I wish I could say we weren’t used to. The standard procedure is to stop the test and asses the vehicle state before deciding if we can redo the test or continue with other tests on different systems. We decide to run a seperate test but are still getting some strange errors, so we agree to turn the spacecraft off and back on to get it in a nominal configuration. Again, fairly standard procedure.</p> <p>Except turning the spacecraft off and on isn’t as simple as just flipping a switch or unplugging it. There are about a dozen steps that need to happen in a fairly specific order to ensure no hardware gets damaged in the process. We’re constantly checking telemetry during this teardown to see that nothing is on when a component further down the process is about to turn off.</p> <p>In our teardown script, we get an error we’ve never seen before. Some of the motors on the vehicle are not turning off. Ok, that’s weird. Let’s send the off command again, maybe there was a routing failure. Still nothing, but the commands are showing as “received”. Hmmmm. Well, unfortunately we can’t just continue, but we’ve got a few ideas as to what’s happening.</p> <p>Some of the telemetry that’s being downlinked from the satellite is displaying as active but showing no variation. I.e., a voltage or temperature reading is actively being downlinked as the same value, down to five sig figs, with no change. Further inspection of telemetry shows errors on the connection between the onboard computer and the ERIU.</p> <p>The <strong>E</strong>nhanced <strong>R</strong>emote <strong>I</strong>nterface <strong>U</strong>nits (<strong>ERIU</strong>s) are how the computer onboard the spacecraft communicates with all the different sensors and systems that read actual orbit and mission data. Think of the ERIUs as the pony express, relaying commands from the onboard computer to the wild west frontier of the satellite sensors. The sensors in turn send their telemetry back through the ERIU to the onboard computer for processing, or anywhere else that was specified in memory, like a CLT sim.</p> <div> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/ponyExpress-480.webp 480w,https://clarkwakeland.com/assets/img/ponyExpress-800.webp 800w,https://clarkwakeland.com/assets/img/ponyExpress-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/ponyExpress.jpg" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p> They don't make ERIUs like they used to </p> </div> <p>I think you can see where this is going. The addresses we loaded at the start of the test are meant for a completely different spacecraft and simulation setup. When the ERIU tried to send telemetry back to the sim, the addresses it was given weren’t actually pointing to anything, and it bascially throws a null pointer dereference and crashes. Some bus communication quirk is causing the last valid telemetry broadcast by the ERIU to be continously sent to the onboard computer.</p> <h2 id="the-problems">The Problems</h2> <p>There are two significant problems that are immediately apparent to us:</p> <ol> <li>Because the ERIU has crashed, we have no way of commanding different subsystems off, and cannot safely enter a powered off vehicle state.</li> <li>We are no longer getting active telemetry from the vehicle, which means that if something bad were happening to any system, we would not know about it.</li> </ol> <p>Problem #1 can luckily be put off for the time being while we focus on the more time sensitive problem #2. I should clarify that the vehicle is in a very safe and stable configuration at the moment. There is almost zero chance that something significant would break while we’re in this tricky spot of not recieving valid telemetry. That being said, as an engineer, having no way of describing your state is incredibly concering. An apt comparison would be if you were the flying an airplane at cruise altitude and your altimeter, airspeed indicator, and attitude indicator suddenly stopped updating. You’re <em>probably</em> not going to have anything bad happen to you, and there’s not much reason to believe your state is rapidly changing, but I doubt any pilot would want to experience that.</p> <p>Ok, we’ve got a clear goal: reboot the ERIU. Just like waking up for a morning swim, it is much easier said than done. In fact, the only way to reboot the ERIU is to reboot the whole damn onboard computer. This of course comes with its own set of issues and risks.</p> <p>The onboard computer, as part of its normal operation, continuously restarts a watchdog timer. If the watchdog timer has not been restarted and instead times out after ~30 seconds, the satellite enters something called <strong>safemode</strong>. Safemode is when all non critical functions are automatically shut down and the satellite becomes entirely focused on generating power by pointing its solar panels towards the Sun and trying to reestablish any communication that was lost. It’s a state the vehicle goes into when something bad happens, like total loss of attitude control or some other system failure.</p> <div> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/vaderfighter-480.webp 480w,https://clarkwakeland.com/assets/img/vaderfighter-800.webp 800w,https://clarkwakeland.com/assets/img/vaderfighter-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/vaderfighter.gif" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p> Vader's tie fighter entering safemode </p> </div> <p>Safemode is the satellite equivalent of a blue screen of death. An unexpected safemode occurring on the satellite during testing is something that must be communicated to the customer, even though it’s completely recoverable. Again, I wish I could say this hasn’t happened before. Long story short, the US government isn’t burning taxpayer dollars on a ten figure spaceship just to have us push a Crowdstrike update on it. They would be pretty upset, to put it lightly.</p> <p>Alright. Let’s not focus on the worst outcome. We can disable the watchdog timer, turn off some other telemetry, finally power cycle the onboard computer, and then turn everything else back on. Oh, and we need to do the exact same thing at the same time on the redundant computer as well. And there are a couple dozen commands in this manually created sequence, and getting one of them wrong could send the satellite to safemode. We got this. Did I mention that all of this is happening at midnight on a Saturday?</p> <p>After confirming our commands with a very tired flight software lead, we send the sequence, and it works! The onboard computer is back on, the ERIU is back on, and we’re getting what looks like reasonable telemetry from the other systems. We continue with the power off sequence and sure enough everything is powering down as expected. After ~12 hours of troubleshooting and communicating with other system engineers, we finally power down the vehicle safely at 1:45am.</p> <h2 id="retrospective">Retrospective</h2> <p>I hope I managed to explain the relevant systems in enough detail and not use too many acronyms, and at least explain the ones I did use. Working on space systems has exposed me to a seemingly infinite amount of different acronyms, some of which are the same but have different meanings. There was also a lot I glossed over, with the main time sink being the proper identification of the issue. There were many red herrings that were chased before we correctly determined that it was an ERIU crash. This would have ended much worse without the support of the amazing systems engineers who answered our calls in the middle of the night on a Saturday.</p> <p>I think what surprised me the most was how nonchalant the response was. We had documented all of our actions, so other people had read what happened and knew something had gone on. I wasn’t expecting any fanfare but we weren’t even debriefed on what happened. I guess this is the event that really got the point across to me about how if you do your job right, it’ll be like nothing ever happened. But I’ll take that over a BSOD on a multi billion dollar satellite any day.</p> </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Orion, Our First True Augmented Reality Glasses (989 pts)]]></title>
            <link>https://about.fb.com/news/2024/09/introducing-orion-our-first-true-augmented-reality-glasses/</link>
            <guid>41650047</guid>
            <pubDate>Wed, 25 Sep 2024 17:56:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.fb.com/news/2024/09/introducing-orion-our-first-true-augmented-reality-glasses/">https://about.fb.com/news/2024/09/introducing-orion-our-first-true-augmented-reality-glasses/</a>, See on <a href="https://news.ycombinator.com/item?id=41650047">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span>Five years ago, we announced to the world that we were building AR glasses. We don’t think people should have to make the choice between a world of information at your fingertips and being present in the physical world around you.</span></p>
<p><span>That’s why today, we’re unveiling </span><a href="https://about.meta.com/realitylabs/orion"><span>Orion</span></a><span>, which we believe is the most advanced pair of AR glasses ever made. Orion bridges the physical and virtual worlds, putting people at the center so they can be more present, connected and empowered in the world.&nbsp;&nbsp;&nbsp;</span></p>

<p><span>There are three primary reasons why AR glasses are key to unlocking the next great leap in human-oriented computing.</span></p>
<ul>
<li><span>They enable digital experiences that are unconstrained by the limits of a smartphone screen. With large holographic displays, you can use the physical world as your canvas, placing 2D and 3D content and experiences anywhere you want.</span></li>
<li><span>They seamlessly integrate contextual AI that can sense and understand the world around you in order to anticipate and proactively address your needs.</span></li>
<li><span>They’re lightweight and great for both indoor and outdoor use, and they let people see each other’s face, eyes and expressions.</span></li>
</ul>
<p>This slideshow requires JavaScript.</p>
<p><span>That’s the north star our industry has been building towards: a product combining the convenience and immediacy of wearables with a large display, high-bandwidth input and contextualized AI in a form that people feel comfortable wearing in their daily lives.&nbsp;</span></p>
<h2>The Evolution of Smart Glasses</h2>
<p><span>Ray-Ban Meta glasses have demonstrated the power of giving people hands-free access to key parts of their digital lives from their physical ones. We can talk to a smart AI assistant, connect with friends and capture the moments that matter – all without ever having to pull out a phone.</span></p>
<p><span>Yet while Ray-Ban Meta opened up an entirely new category of display-less glasses super-charged by AI, the XR industry has long dreamt of true AR glasses – a product that combines the benefits of a large holographic display and personalized AI assistance in a comfortable, all-day wearable form factor. Orion rises to the challenge.</span></p>
<h2>Groundbreaking AR Display in an Unparalleled Form</h2>
<p><span>We’ve been hard at work for years to take the incredible spatial experiences afforded by VR and MR headsets and miniaturize the technology necessary to deliver those experiences in a pair of lightweight, stylish glasses.&nbsp;</span></p>
<p><span>Nailing the form factor, delivering holographic displays, developing compelling AR experiences, creating new human-computer interaction (HCI) paradigms – and doing it all in one cohesive product – is one of the most difficult challenges our industry has ever faced. It was so challenging that we thought we had less than a 10% chance of pulling it off successfully. Until now.</span></p>
<p><span>Orion is a feat of miniaturization – t</span><span>he components are packed down to a fraction of a millimeter.</span><span> Dozens of innovations were required to get the design down to a contemporary form that you’d be comfortable wearing every day.&nbsp;</span></p>
<p><span>Orion has the largest field of view in the smallest AR glasses form to date. That field of view unlocks truly immersive use cases for Orion, from multitasking windows and big-screen entertainment to life-size holograms of people – all digital content that can seamlessly blend with your view of the physical world.</span></p>
<p><a href="https://about.fb.com/wp-content/uploads/2024/09/03_multiscreens.gif?resize=960%2C836"><img src="https://about.fb.com/wp-content/uploads/2024/09/03_multiscreens.gif?resize=960%2C836" alt="Video from the POV of someone looking at multiple holographic screens" width="960" height="836" data-recalc-dims="1"></a></p>
<p><span>But what makes Orion unique is that it is unmistakably a pair of glasses in both look and feel – complete with transparent lenses. Unlike MR headsets or other AR glasses today, you can still see other people’s eyes and expressions, so you can be present and share the experience with the people around you.&nbsp;</span></p>
<h2>Augmented Reality Experiences</h2>
<p><span>Of course, as with any piece of hardware, Orion is only as good as the things you can do with it. And while it’s still early days, the experiences afforded by Orion are an exciting glimpse of what’s to come.</span></p>
<p><span>We’ve got our smart assistant, </span><a href="https://www.meta.ai/"><span>Meta AI</span></a><span>, running on Orion. It understands what you’re looking at in the physical world and can help you with useful visualizations. So you can open up your refrigerator and ask for a recipe based on what’s inside. Or video call a friend while adjusting a digital family calendar as you wash the dishes.</span></p>
<p><a href="https://about.fb.com/wp-content/uploads/2024/09/04_recipes.gif?resize=960%2C836"><img loading="lazy" src="https://about.fb.com/wp-content/uploads/2024/09/04_recipes.gif?resize=960%2C836" alt="Video of ingredients with a recipe on a holographic screen next to it" width="960" height="836" data-recalc-dims="1"></a></p>
<p><span>You can take a hands-free video call to catch up with friends and family in real time, and you can stay connected on WhatsApp and Messenger to view and send messages. No need to pull out your phone, unlock it, find the right app and let your friend know you’re running late for dinner – you can do it all through your glasses.</span></p>
<p><span>Our teams continue to iterate on the experiences available through Orion today to build new immersive social experiences, and we can’t wait to share what’s next.</span></p>
<h2>A Purposeful Product Prototype</h2>
<p><span>While Orion won’t make its way into the hands of consumers, make no mistake: this is not a research prototype. It’s one of the most polished product prototypes we’ve ever developed, and is truly representative of something that could ship to consumers. Rather than rushing to put it on shelves, we decided to focus on internal development first, which means we can keep building quickly and continue to push the boundaries of the technology, helping us arrive at an even better consumer product faster.</span></p>
<p><a href="https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836"><img loading="lazy" src="https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836" alt="Picture of Orion glasses, wristband, and controller " width="960" height="836" srcset="https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=1920 1920w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=300 300w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=768 768w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=1024 1024w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=1536 1536w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=1240 1240w, https://about.fb.com/wp-content/uploads/2024/09/05_whatcomesnext.png?resize=960%2C836?w=689 689w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<h2>What Comes Next</h2>
<p><span>Beginning today at Connect and continuing throughout the year, we’re opening up access to our Orion product prototype for Meta employees and select external audiences so our development team can learn, iterate and build towards our consumer AR glasses product line, which we plan to begin shipping in the near future.</span></p>
<p><span>And now that we’ve shared Orion with the world, we’re focused on a few things:</span></p>
<ul>
<li><span>Tuning the AR display quality to make the visuals even sharper</span></li>
<li><span>Optimizing wherever we can to make the form factor even smaller</span></li>
<li><span>Building at scale to make them more affordable</span></li>
</ul>
<p><span>In the next few years, you can expect to see new devices from us that build on our R&amp;D efforts. Orion isn’t just a window into the future – it’s a look at the very real possibilities within reach today. From Ray-Ban Meta glasses to Orion, we’ve seen the good that can come from letting people stay more present and empowered in the physical world, while tapping into all that the digital world has to offer.</span></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Quest 3S (150 pts)]]></title>
            <link>https://www.meta.com/tw/en/quest/quest-3s/</link>
            <guid>41649983</guid>
            <pubDate>Wed, 25 Sep 2024 17:50:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.meta.com/tw/en/quest/quest-3s/">https://www.meta.com/tw/en/quest/quest-3s/</a>, See on <a href="https://news.ycombinator.com/item?id=41649983">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.2: Revolutionizing edge AI and vision with open, customizable models (677 pts)]]></title>
            <link>https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/?_fb_noscript=1</link>
            <guid>41649763</guid>
            <pubDate>Wed, 25 Sep 2024 17:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/?_fb_noscript=1">https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/?_fb_noscript=1</a>, See on <a href="https://news.ycombinator.com/item?id=41649763">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>We’ve been excited by the <a href="https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/" target="_blank" data-lnfb-mode="ie"><u>impact the Llama 3.1 herd of models have made</u></a> in the two months since we announced them, including the <a href="https://www.meta.ai/?utm_source=llama_meta_site&amp;utm_medium=web&amp;utm_content=Llama_nav&amp;utm_campaign=July_moment" target="_blank" data-lnfb-mode="ie"><u>405B</u></a>—the first open frontier-level AI model. While these models are incredibly powerful, we recognize that building with them requires significant compute resources and expertise. We’ve also heard from developers who don’t have access to these resources and still want the opportunity to build with Llama. As Meta Founder and CEO Mark Zuckerberg shared today at Connect, they won’t have to wait any longer. Today, we’re releasing Llama 3.2, which includes small and medium-sized vision LLMs (11B and 90B) and lightweight, text-only models (1B and 3B) that fit onto select edge and mobile devices.</p><p>It’s only been a year and a half since we first announced Llama, and we’ve made incredible progress in such a short amount of time. This year, <a href="https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/" target="_blank" data-lnfb-mode="ie"><u>Llama has achieved 10x growth</u></a> and become the standard for responsible innovation. Llama also continues to lead on openness, modifiability, and cost efficiency, and it’s competitive with closed models—even leading in some areas. We believe that openness drives innovation and is the right path forward, which is why we continue to share our research and collaborate with our partners and the developer community.</p><p>We’re making Llama 3.2 models available for download on <a href="https://llama.meta.com/" target="_blank" data-lnfb-mode="ie"><u>llama.com</u></a> and <a href="https://huggingface.co/meta-llama" target="_blank" data-lnfb-mode="ie"><u>Hugging Face</u></a>, as well as available for immediate development on our broad ecosystem of partner platforms. Partners are an important part of this work, and we’ve worked with over 25 companies, including AMD, AWS, Databricks, Dell, Google Cloud, Groq, IBM, Intel, Microsoft Azure, NVIDIA, Oracle Cloud, and Snowflake, to enable services on day one. For the Llama 3.2 release, we’re also working with on-device partners Arm, MediaTek, and Qualcomm to offer a broad range of services at launch. Starting today, we’re also making <a href="https://github.com/meta-llama/llama-stack" target="_blank" data-lnfb-mode="ie"><u>Llama Stack</u></a> available to the community. More details on the latest release, including information on the <a href="https://euneedsai.com/" target="_blank" data-lnfb-mode="ie"><u>multimodal availability</u></a> in Europe, can be found in <a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md" target="_blank" data-lnfb-mode="ie"><u>our acceptable use policy</u></a>.</p></div><p>Meet Llama 3.2</p></div><div><div><p>The two largest models of the Llama 3.2 collection, 11B and 90B, support image reasoning use cases, such as document-level understanding including charts and graphs, captioning of images, and visual grounding tasks such as directionally pinpointing objects in images based on natural language descriptions. For example, a person could ask a question about which month in the previous year their small business had the best sales, and Llama 3.2 can then reason based on an available graph and quickly provide the answer. In another example, the model could reason with a map and help answer questions such as when a hike might become steeper or the distance of a particular trail marked on the map. The 11B and 90B models can also bridge the gap between vision and language by extracting details from an image, understanding the scene, and then crafting a sentence or two that could be used as an image caption to help tell the story.</p><p>The lightweight 1B and 3B models are highly capable with multilingual text generation and tool calling abilities. These models empower developers to build personalized, on-device agentic applications with strong privacy where data never leaves the device. For example, such an application could help summarize the last 10 messages received, extract action items, and leverage tool calling to directly send calendar invites for follow-up meetings.</p><p>Running these models locally comes with two major advantages. First, prompts and responses can feel instantaneous, since processing is done locally. Second, running models locally maintains privacy by not sending data such as messages and calendar information to the cloud, making the overall application more private. Since processing is handled locally, the application can clearly control which queries stay on the device and which may need to be processed by a larger model in the cloud.</p></div><p>Model evaluations</p><div><p>Our evaluation suggests that the Llama 3.2 vision models are competitive with leading foundation models, Claude 3 Haiku and GPT4o-mini on image recognition and a range of visual understanding tasks. The 3B model outperforms the Gemma 2 2.6B and Phi 3.5-mini models on tasks such as following instructions, summarization, prompt rewriting, and tool-use, while the 1B is competitive with Gemma.</p><p>We evaluated performance on over 150 benchmark datasets that span a wide range of languages. For the vision LLMs, we evaluated performance on benchmarks for image understanding and visual reasoning.</p><br></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/461288018_1255239495501495_271827633811450582_n.png?_nc_cat=102&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=oeAoi7_K9ggQ7kNvgE8Zpdb&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=ADyiZ_xNTdS_fAeqWnELSPZ&amp;oh=00_AYDMbCATap9ZGIWGhs6IVu17rVzyVC_Le8VgxoFJIFee1w&amp;oe=670EE46D" alt="" id="u_0_4_2L"></p><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/461157789_931406385491961_1692349435372036848_n.png?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=cgqzw-5Xp68Q7kNvgH3D7-A&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=ADyiZ_xNTdS_fAeqWnELSPZ&amp;oh=00_AYAtWvlCUwgtC2Tnoa7QT0N1wrgXCaXa_3Qylh6SV2gKzA&amp;oe=670EC398" alt="" id="u_0_5_Mg"></p><p>Vision models</p><div><p>As the first Llama models to support vision tasks, the 11B and 90B models required an entirely new model architecture that supports image reasoning.</p><p>To add image input support, we trained a set of adapter weights that integrate the pre-trained image encoder into the pre-trained language model. The adapter consists of a series of cross-attention layers that feed image encoder representations into the language model. We trained the adapter on text-image pairs to align the image representations with the language representations. During adapter training, we also updated the parameters of the image encoder, but intentionally did not update the language-model parameters. By doing that, we keep all the text-only capabilities intact, providing developers a drop-in replacement for Llama 3.1 models.</p><p>Our training pipeline consists of multiple stages, starting from pretrained Llama 3.1 text models. First, we add image adapters and encoders, then pretrain on large-scale noisy (image, text) pair data. Next, we train on medium-scale high quality in-domain and knowledge-enhanced (image, text) pair data.</p><p>In post-training, we use a similar recipe as the text models by doing several rounds of alignment on supervised fine-tuning, rejection sampling, and direct preference optimization. We leverage synthetic data generation by using the Llama 3.1 model to filter and augment question and answers on top of in-domain images, and use a reward model to rank all the candidate answers to provide high quality fine-tuning data. We also add safety mitigation data to produce a model with a high level of safety while retaining helpfulness of the mode</p><p>The end result is a set of models that can take in both image and text prompts, and deeply understand and reason on the combination. This is another step toward Llama models having even richer agentic capabilities.</p><br></div><p>Lightweight models</p><div><p>As we talked about with Llama 3.1, powerful teacher models can be leveraged to create smaller models that have improved performance. We used two methods—pruning and distillation—on the 1B and 3B models, making them the first highly capable lightweight Llama models that can fit on devices efficiently.</p><p>Pruning enabled us to reduce the size of extant models in the Llama herd while recovering as much knowledge and performance as possible. For the 1B and 3B models, we took the approach of using structured pruning in a single shot manner from the Llama 3.1 8B. This involved systematically removing parts of the network and adjusting the magnitude of the weights and gradients to create a smaller, more efficient model that retains the performance of the original network.</p><p>Knowledge distillation uses a larger network to impart knowledge on a smaller network, with the idea that a smaller model can achieve better performance using a teacher than it could from scratch. For the 1B and 3B in Llama 3.2, we incorporated logits from the Llama 3.1 8B and 70B models into the pre-training stage of the model development, where outputs (logits) from these larger models were used as token-level targets. Knowledge distillation was used after pruning to recover performance.</p><br></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/461209081_511117684875670_45564063096782202_n.png?_nc_cat=101&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=ieNr4u425SwQ7kNvgGrbiWa&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=ADyiZ_xNTdS_fAeqWnELSPZ&amp;oh=00_AYDsxVu1KvPuqspn62ZVregQPBGZXtIPMO9ExVdzqB4gxw&amp;oe=670EE3DE" alt="" id="u_0_9_Gn"></p><div><p>In post-training, we use a similar recipe as Llama 3.1 and produce final chat models by doing several rounds of alignment on top of the pre-trained model. Each round involves supervised fine-tuning (SFT), rejection sampling (RS), and direct preference optimization (DPO).</p><p>In post-training, we scale context length support to 128K tokens, while maintaining the same quality as the pre-trained model. We also engage in synthetic data generation that goes through careful data processing and filtering to ensure high quality. We carefully blend the data to optimize for high quality across multiple capabilities like summarization, rewriting, instruction following, language reasoning, and tool use.</p><p>To enable the community to innovate on these models, we worked closely with Qualcomm and Mediatek, the top two mobile system on a chip (SoC) companies in the world, and Arm, who provides the foundational compute platform for <a href="https://www.arm.com/company" target="_blank" data-lnfb-mode="ie"><u>99</u></a><a href="https://www.arm.com/company" target="_blank" data-lnfb-mode="ie">%</a> of mobile devices. The weights being released today are based on BFloat16 numerics. Our teams are actively exploring quantized variants that will run even faster, and we hope to share more on that soon.</p><br></div><div><p>This demo is based on an unreleased quantized model.</p></div><div><p>This demo is based on an unreleased quantized model.</p></div><div><p>Llama Stack distributions</p><div><p>In July, we released a <a href="https://github.com/meta-llama/llama-stack/issues/6" target="_blank" data-lnfb-mode="ie"><u>request for comment</u></a> on the Llama Stack API, a standardized interface for canonical toolchain components (fine-tuning, synthetic data generation) to customize Llama models and build agentic applications. The engagement has been great.</p><p>Since then, we have been working hard to make the API real. We built a reference implementation of the APIs for inference, tool use, and RAG. In addition, we have been working with partners to adapt them to become providers for the APIs. Finally, we have introduced Llama Stack Distribution as a way to package multiple API Providers that work well together to provide a single endpoint for developers. We are now sharing with the community a simplified and consistent experience that will enable them to work with Llama models in multiple environments, including on-prem, cloud, single-node, and on-device.</p><br></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/460924239_3402957093334534_4357083070437107157_n.png?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=zKTWaIWC3AIQ7kNvgH8H9c8&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=ADyiZ_xNTdS_fAeqWnELSPZ&amp;oh=00_AYCvn28-wNqLSj9fc0cz1oxYweRRaHRS6smL3no1_ill3Q&amp;oe=670EC620" alt="" id="u_0_j_Ys"></p><div><div><p>The full set of releases includes:</p><ol><li>Llama CLI (command line interface) to build, configure, and run Llama Stack distributions</li><li>Client code in multiple languages, including python, node, kotlin, and swift</li><li>Docker containers for Llama Stack Distribution Server and Agents API Provider</li><li>Multiple distributions<ol><li>Single-node Llama Stack Distribution via Meta internal implementation and Ollama</li><li>Cloud Llama Stack distributions via AWS, Databricks, Fireworks, and Together</li><li>On-device Llama Stack Distribution on iOS implemented via PyTorch ExecuTorch</li><li>On-prem Llama Stack Distribution supported by Dell</li></ol></li></ol><p>We look forward to working with developers and partners to simplify all aspects of building with Llama models and welcome feedback.</p><br></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/460942153_931942502081982_4461283719059292584_n.png?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=yPZiTRUpQyIQ7kNvgGmAxck&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=ADyiZ_xNTdS_fAeqWnELSPZ&amp;oh=00_AYAln3XFhMf0mccyDv_zyuK2uKI2xqDCVc1PiKB__kZ7jQ&amp;oe=670ED455" alt="" id="u_0_k_yb"></p><div><p>System level safety</p><div><p>Taking an open approach has many benefits. It helps ensure that more people around the world can access the opportunities that AI provides, guards against concentrating power in the hands of a small few, and deploys technology more equitably and safely across society. As we continue to innovate, we also want to make sure we’re empowering developers to build safe and responsible systems.</p><p>Building on our previous release and continuous effort to support responsible innovation, today we’re adding new updates to our family of safeguards:</p><ul><li>First, we’re releasing Llama Guard 3 11B Vision, which is designed to support Llama 3.2’s new image understanding capability and filter text+image input prompts or text output responses to these prompts.</li><li>Second, as we released 1B and 3B Llama models to be used in more constrained environments like on-device, we also optimized Llama Guard to drastically reduce its deployment cost. Llama Guard 3 1B is based on the Llama 3.2 1B model and has been pruned and quantized bringing its size from 2,858 MB down to 438 MB, making it more efficient than ever to deploy.</li></ul><p>These new solutions are integrated into our reference implementations, demos, and applications and are ready for the open source community to use on day one.</p><br></div><div><p>Try Llama 3.2 today</p><div><p>Llama 3.2 is poised to reach more people than ever before and enable exciting new use cases. We believe sharing these models with the open source community isn’t enough. We want to make sure developers also have the tools they need to build with Llama responsibly. As part of our continued responsible release efforts, we’re offering developers new <a href="https://ai.meta.com/blog/responsible-ai-connect-2024/" target="_blank" data-lnfb-mode="ie"><u>tools and resources</u></a>, and as always, we’ll update best practices in our <a href="https://ai.meta.com/static-resource/responsible-use-guide/" target="_blank" data-lnfb-mode="ie"><u>Responsible Use Guide</u></a>.</p><p>We continue to share the latest advancements in the Llama ecosystem because we believe openness drives innovation and is good for developers, Meta, and the world. We’re excited to continue the conversations we’re having with our partners and the open source community, and as always, we can’t wait to see what the community builds using Llama 3.2 and Llama Stack.</p><p><i>This work was supported by our partners across the AI community. We’d like to thank and acknowledge (in alphabetical order): Accenture, AMD, Arm, AWS, Cloudflare, Databricks, Dell, Deloitte, Fireworks.ai, Google Cloud, Groq, Hugging Face, IBM watsonx, Infosys, Intel, Kaggle, Lenovo, LMSYS, MediaTek, Microsoft Azure, NVIDIA, OctoAI, Ollama, Oracle Cloud, PwC, Qualcomm, Sarvam AI, Scale AI, Snowflake, Together AI, and UC Berkeley - vLLM Project.</i></p><br></div><a href="https://www.llama.com/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_o_MJ"><div><p>Learn more on the Llama website</p><svg viewBox="0 0 36 36" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.746 10H26V21.254L24.0301 21.2735L24.0297 13.377L11.4067 26L10 24.5933L22.6039 11.9894L14.746 11.9894V10Z" fill="CurrentColor"></path></svg></div></a></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Timeshare owner? The Mexican drug cartels want you (190 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/09/timeshare-owner-the-mexican-drug-cartels-want-you/</link>
            <guid>41649134</guid>
            <pubDate>Wed, 25 Sep 2024 16:28:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/09/timeshare-owner-the-mexican-drug-cartels-want-you/">https://krebsonsecurity.com/2024/09/timeshare-owner-the-mexican-drug-cartels-want-you/</a>, See on <a href="https://news.ycombinator.com/item?id=41649134">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>The FBI is warning timeshare owners to be wary of a prevalent telemarketing scam involving a violent Mexican drug cartel that tries to trick people into believing someone wants to buy their property. This is the story of a couple who recently lost more than $50,000 to an ongoing timeshare scam that spans at least two dozen phony escrow, title and realty firms.</p>
<div id="attachment_68950"><p><img aria-describedby="caption-attachment-68950" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc.png" alt="" width="751" height="405" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc.png 2330w, https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc-768x414.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc-1536x828.png 1536w, https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc-2048x1104.png 2048w, https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc-782x422.png 782w, https://krebsonsecurity.com/wp-content/uploads/2024/09/realestateassets-llc-370x200.png 370w" sizes="(max-width: 751px) 100vw, 751px"></p><p id="caption-attachment-68950">One of the phony real estate companies trying to scam people out of money over fake offers to buy their timeshares.</p></div>
<p>One evening in late 2022, someone phoned <strong>Mr. &amp; Mrs. Dimitruk</strong>, a retired couple from Ontario, Canada and asked whether they’d ever considered selling their timeshare in Florida. The person on the phone referenced their timeshare address and said they had an interested buyer in Mexico. Would they possibly be interested in selling it?</p>
<p>The Dimitruks had purchased the timeshare years ago, but it wasn’t fully paid off — they still owed roughly $5,000 before they could legally sell it. That wouldn’t be an issue for this buyer, the man on the phone assured them.</p>
<p>With a few days, their contact at a escrow company in New York called <strong>ecurrencyescrow[.]llc</strong> faxed them forms to fill out and send back to start the process of selling their timeshare to the potential buyer, who had offered an amount that was above what the property was likely worth.</p>
<p>After certain forms were signed and faxed, the Dimitruks were asked to send a small wire transfer of more than $3,000 to handle “administrative” and “processing” fees, supposedly so that the sale would not be held up by any bureaucratic red tape down in Mexico.</p>
<p><img decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/09/ecurrencyesc.png" alt="" width="749" height="751" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/09/ecurrencyesc.png 1410w, https://krebsonsecurity.com/wp-content/uploads/2024/09/ecurrencyesc-768x770.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/09/ecurrencyesc-782x784.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p>
<p>These document exchanges went on for almost a year, during which time the real estate brokers made additional financial demands, such as tax payments on the sale, and various administrative fees. Mrs. Dimitruk even sent them a $5,000 wire to pay off her remaining balance on the timeshare they thought they were selling.</p>
<p>In a phone interview with KrebsOnSecurity, Mr. Dimitruk said they lost over $50,000.</p>
<p>“They kept calling me after that saying, ‘Hey your money is waiting for you here’,” said <strong>William Dimitruk</strong>, a 73-year-old retired long-haul truck driver. “They said ‘We’re going to get in trouble if the money isn’t returned to you,’ and gave me a toll-free number to call them at.”</p>
<p>In the last call he had with the scammers, the man on the other end of the line confessed that some bad people had worked for them previously, but that those employees had been fired.</p>
<p>“Near the end of the call he said, ‘You’ve been dealing with some bad people and we fired all those bad guys,'” Dimitruk recalled. “So they were like, yeah it’s all good. You can go ahead and pay us more and we’ll send you your money.”</p>
<p>According to the FBI, there are indeed some very bad people behind these scams. The FBI warns the timeshare fraud schemes have been linked to the <strong>Jalisco New Generation drug cartel</strong> in Mexico.</p>
<p>In July 2024, the FBI and the Treasury Department’s <strong>Financial Crimes Enforcement Network</strong> (FinCEN) <a href="https://www.fincen.gov/news/news-releases/fincen-ofac-and-fbi-joint-notice-timeshare-fraud-associated-mexico-based" target="_blank" rel="noopener">warned</a> the Jalisco cartel is running boiler room-like call centers that target people who own timeshares:</p>
<blockquote><p>“Mexico-based [transnational criminal organizations] such as the Jalisco New Generation Cartel are increasingly targeting U.S. owners of timeshares in Mexico through complex and often yearslong telemarketing, impersonation, and advance fee schemes. They use the illicit proceeds to diversify their revenue streams and finance other criminal activities, including the manufacturing and trafficking of illicit fentanyl and other synthetic drugs into the United States.”</p></blockquote>
<p>A <a href="https://www.cbsnews.com/news/us-sanctions-cartel-accountants-timeshare-scams-target-americans/" target="_blank" rel="noopener">July 2024 CBS News story</a> about these scams notes that U.S. and Mexican officials last year confirmed that as many as eight young workers were confirmed dead after they apparently tried to quit jobs at a call center operated by the Jalisco cartel.</p>
<div id="attachment_68958"><p><img aria-describedby="caption-attachment-68958" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/09/jaliscocartel.png" alt="" width="750" height="580" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/09/jaliscocartel.png 788w, https://krebsonsecurity.com/wp-content/uploads/2024/09/jaliscocartel-768x594.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/09/jaliscocartel-782x604.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-68958">Source: US Department of the Treasury’s Office of Foreign Assets Control.</p></div>
<p>The phony escrow company the Dimitruks dealt with — <strong>ecurrencyescrow[.]llc</strong> — is no longer online. But the documents sent by their contact there referenced a few other still-active domains, including <strong>realestateassetsllc[.]com</strong></p>
<p>The original registration records of both of these domains reference another domain — <strong>datasur[.]host</strong> — that is associated with dozens of other real estate and escrow-themed domains going back at least four years. Some of these domains are no longer active, while others have been previously suspended at different hosting providers. <span id="more-68943"></span></p>
<p>061nyr[.]net<br>
061-newyorkrealty[.]net<br>
1nydevelopersgroupllc[.]com<br>
1oceanrealtyllc[.]com<br>
advancedclosingservicesllc[.]com<br>
americancorporatetitle[.]com<br>
asesorialegalsiglo[.]com<br>
atencion-tributaria.[]com<br>
carolinasctinc[.]net<br>
closingandsettlementservices[.]com<br>
closingandsettlementsllc[.]com<br>
closingsettlementllc[.]com<br>
crefaescrowslimited[.]net<br>
ecurrencyescrow[.]llc<br>
empirerllc[.]com<br>
fiduciarocitibanamex[.]com<br>
fondosmx[.]org<br>
freightescrowcollc[.]com<br>
goldmansachs-investment[.]com<br>
hgvccorp[.]com<br>
infodivisionfinanciera[.]com<br>
internationaladvisorllc[.]com<br>
jadehillrealtyllc[.]com<br>
lewisandassociaterealty[.]com<br>
nyreputable[.]org<br>
privateinvestment.com[.]co<br>
realestateassetsllc[.]com<br>
realestateisinc[.]com<br>
settlementandmanagement[.]com<br>
stllcservices[.]com<br>
stllcservices[.]net<br>
thebluehorizonrealtyinc[.]com<br>
walshrealtyny[.]net<br>
windsorre[.]com</p>
<p>By loading ecurrencyescrowllc[.]com into <a href="https://web.archive.org/web/20230214194256/http://ecurrencyescrow.llc/" target="_blank" rel="noopener">the Wayback Machine at archive.org</a>, we can see text at the top of the page that reads, “Visit our resource library for videos and tools designed to make managing your escrow disbursements a breeze.”</p>
<p>Searching on that bit of text at <a href="https://publicwww.com/" target="_blank" rel="noopener">publicwww.com</a> shows the same text appears on the website of an escrow company called <strong>Escshieldsecurity Network</strong> (escshieldsecurity[.]com). This entity claims to have been around since 2009, but the domain itself is less than two years old, and there is no contact information associated with the site. The Pennsylvania Secretary of State also has no record of a business by this name at its stated address.</p>
<p>Incredibly, Escshieldsecurity pitches itself as a solution to timeshare closing scams.</p>
<p>“By 2015, cyber thieves had realized the amount of funds involved and had targeted the real estate, title and settlement industry,” the company’s website states. “As funding became more complex and risky, agents and underwriters had little time or resources to keep up. The industry needed a simple solution that allowed it to keep pace with new funding security needs.”</p>
<p>The domains associated with this scam will often reference legitimate companies and licensed professionals in the real estate and closing businesses, but those real professionals often have no idea they’re being impersonated until someone starts asking around. The truth is, the original reader tip that caused KrebsOnSecurity to investigate this scheme came from one such professional whose name and reputation was being used to scam others.</p>
<p>It is unclear whether the Dimitruks were robbed by people working for the Jalisco cartel, but it is clear that whoever is responsible for managing many of the above-mentioned domains — including the DNS provider datasur[.]host — recently compromised their computer with information-stealing malware.</p>
<p>That’s according to data collected by the breach tracking service <a href="https://www.constella.ai/" target="_blank" rel="noopener">Constella Intelligence</a> [Constella is currently an advertiser on KrebsOnSecurity]. Constella found that someone using the email address exposed in the DNS records for datasur[.]host — jyanes1920@gmail.com — also was relieved of credentials for managing most of the domains referenced above at a Mexican hosting provider.</p>
<p>It’s not unusual for victims of such scams to keep mum about their misfortune. Sometimes, it’s shame and embarrassment that prevents victims from filing a report with the local authorities. But in this case, victims who learn they’ve been robbed by a violent drug cartel have even more reason to remain silent.</p>
<p>William Dimitruk acknowledged that he and his wife haven’t yet filed a police report. But after acknowledging it could help prevent harm to other would-be victims, Mr. Dimitruk said he would consider it.</p>
<p>There is another reason victims of scams like this should notify authorities: Occasionally, the feds will bust up one of these scam operations and seize funds that were stolen from victims. But those investigations can take years, and it can be even more years before the government starts trying to figure out who got scammed and how to remunerate victims. All too often, the real impediment to returning some of those losses is that the feds have no idea who the victims are.</p>
<p>If you are the victim of a timeshare scam like this, please consider filing a report with the FBI’s Internet Crime Complaint Center (IC3), at <a href="https://www.ic3.gov/" target="_blank" rel="noopener">ic3.gov</a>. Other places where victims may wish to file a complaint:</p>
<p><strong>Federal Trade Commission – </strong><a href="https://www.ftccomplaintassistant.gov/" target="_blank" rel="noopener noreferrer">https://www.ftccomplaintassistant.gov</a><br>
<strong>International Consumer Protection and Enforcement Network – </strong><a href="https://www.econsumer.gov/en/Home/FileAComplaint/1#crnt" target="_blank" rel="noopener noreferrer">https://www.econsumer.gov/en</a><br>
<strong>Profeco – Mexican Attorney General</strong> –&nbsp;<a href="https://consulmex.sre.gob.mx/montreal/index.php/en/foreigners/services-foreigners/318-consumer-protection">https://consulmex.sre.gob.mx/montreal/index.php/en/foreigners/services-foreigners/318-consumer-protection</a></p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Fast and Exact Algorithm for Image Merging (103 pts)]]></title>
            <link>https://github.com/C-Naoki/image-stitcher</link>
            <guid>41648965</guid>
            <pubDate>Wed, 25 Sep 2024 16:10:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/C-Naoki/image-stitcher">https://github.com/C-Naoki/image-stitcher</a>, See on <a href="https://news.ycombinator.com/item?id=41648965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">image-stitcher</h2><a id="user-content-image-stitcher" aria-label="Permalink: image-stitcher" href="#image-stitcher"></a></p>
<p dir="auto"><a href="https://www.python.org/downloads/release/python-390/" rel="nofollow"><img src="https://camo.githubusercontent.com/067bfbd6b45e87f5aceb63a0e83a1b3403ce6910b5a01c12c84eed6fa6e4274d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e31302d677265656e2e737667" alt="Python 3.10" data-canonical-src="https://img.shields.io/badge/Python-3.10-green.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
<a href="https://zenn.dev/naoki0103/articles/image-stitcher-application" rel="nofollow"><img src="https://camo.githubusercontent.com/ef720357cffe2ced181e44b515aedc77083c4531e2eadd7d30a58101eecdcbf0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462539332539415a656e6e2d646f63756d656e746174696f6e2d696e666f726d6174696f6e616c2e737667" alt="RubyDoc" data-canonical-src="https://img.shields.io/badge/%F0%9F%93%9AZenn-documentation-informational.svg"></a></p>
<p dir="auto">This is a python implementation for stitching images by automatically searching for overlap region.</p>
<ul dir="auto">
<li><a href="#-usage">👨‍💻 Usage</a></li>
<li><a href="#-preview-of-results">🎯 Preview of results</a></li>
<li><a href="#-main-idea">🧠 Main Idea</a></li>
<li><a href="#%EF%B8%8F-support">🙋‍♂️ Support</a></li>
<li><a href="#%EF%B8%8F-contact">✉️ Contact</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">👨‍💻 Usage</h2><a id="user-content--usage" aria-label="Permalink: 👨‍💻 Usage" href="#-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from src.main import main
from src.utils.visualizer import result_visualize

merged_image, cand = main(
    image1=image1,              # The first image to be combined
    image2=image2,              # The second image to be combined
    min_overlap=(5, 5),         # The minimum overlap region
    verbose=False,              # Whether to print the log
)
result_visualize(
    image1=image1,              # The first image to be combined
    image2=image2,              # The second image to be combined
    merged_image=merged_image,  # The output image
    cand=cand,                  # The parameters
)"><pre><span>from</span> <span>src</span>.<span>main</span> <span>import</span> <span>main</span>
<span>from</span> <span>src</span>.<span>utils</span>.<span>visualizer</span> <span>import</span> <span>result_visualize</span>

<span>merged_image</span>, <span>cand</span> <span>=</span> <span>main</span>(
    <span>image1</span><span>=</span><span>image1</span>,              <span># The first image to be combined</span>
    <span>image2</span><span>=</span><span>image2</span>,              <span># The second image to be combined</span>
    <span>min_overlap</span><span>=</span>(<span>5</span>, <span>5</span>),         <span># The minimum overlap region</span>
    <span>verbose</span><span>=</span><span>False</span>,              <span># Whether to print the log</span>
)
<span>result_visualize</span>(
    <span>image1</span><span>=</span><span>image1</span>,              <span># The first image to be combined</span>
    <span>image2</span><span>=</span><span>image2</span>,              <span># The second image to be combined</span>
    <span>merged_image</span><span>=</span><span>merged_image</span>,  <span># The output image</span>
    <span>cand</span><span>=</span><span>cand</span>,                  <span># The parameters</span>
)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Preview of results</h2><a id="user-content--preview-of-results" aria-label="Permalink: 🎯 Preview of results" href="#-preview-of-results"></a></p>
<p dir="auto">The results using <a href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow"><code>CIFAR-10</code></a> are shown below. I would refer you to <a href="https://github.com/C-Naoki/image-stitcher/blob/main/notebooks/tutorial.ipynb"><code>tutorial.ipynb</code></a> for detailed results.</p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/C-Naoki/image-stitcher/blob/main/docs/assets/input.png"><img src="https://github.com/C-Naoki/image-stitcher/raw/main/docs/assets/input.png" alt=""></a></p><p>
<b>Figure 1.</b> The example of input images. The red area represents an empty region. This application can combine these images while considering their rotation.
</p></div>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/C-Naoki/image-stitcher/blob/main/docs/assets/rotated.png"><img src="https://github.com/C-Naoki/image-stitcher/raw/main/docs/assets/rotated.png" alt=""></a></p><p>
<b>Figure 2.</b> The preprocessed input images. This rotation process is necessary to accurately combine the images. The green frame represents the overlap region between the input images.
</p></div>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/C-Naoki/image-stitcher/blob/main/docs/assets/result.png"><img src="https://github.com/C-Naoki/image-stitcher/raw/main/docs/assets/result.png" alt=""></a></p><p>
<b>Figure 3.</b> The output image.
</p></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧠 Main Idea</h2><a id="user-content--main-idea" aria-label="Permalink: 🧠 Main Idea" href="#-main-idea"></a></p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/C-Naoki/image-stitcher/blob/main/docs/assets/case1.png"><img src="https://github.com/C-Naoki/image-stitcher/raw/main/docs/assets/case1.png" width="500" alt=""></a></p><p>
<b>Figure 4.</b> The overview of this application in limited case.
</p></div>
<p dir="auto">This application is designed based on the overlap region's width <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$w_c$</math-renderer> and height <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$h_c$</math-renderer>. Thanks to this idea, we can simply limit the search space, thus preventing it from capturing overly small, suboptimal overlap region.</p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/C-Naoki/image-stitcher/blob/main/docs/assets/case2.png"><img src="https://github.com/C-Naoki/image-stitcher/raw/main/docs/assets/case2.png" width="500" alt=""></a></p><p>
<b>Figure 5.</b> The overview of this application.
</p></div>
<p dir="auto">However, the above approach is not always applicable, specifically when <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$\min(h_1, h_2) &amp;lt; h_c$</math-renderer> or <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$\min(w_1, w_2) &amp;lt; w_c$</math-renderer>. To address this issue, I change the perspective of <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$w_c$</math-renderer> and <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="cfa9fe4674a4e7a09012a373241fef5f">$h_c$</math-renderer> like the above figure. Therefore, this application can handle images of arbitrary sizes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙋‍♂️ Support</h2><a id="user-content-️-support" aria-label="Permalink: 🙋‍♂️ Support" href="#️-support"></a></p>
<p dir="auto">💙 If you like this app, give it a ⭐ and share it with friends!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">✉️ Contact</h2><a id="user-content-️-contact" aria-label="Permalink: ✉️ Contact" href="#️-contact"></a></p>
<p dir="auto">💥 For questions or issues, feel free to open an <a href="https://github.com/C-Naoki/image-stitcher/issues">issue</a>. I appreciate your feedback and look forward to hearing from you!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Haystack (YC S24) – Visualize and edit code on an infinite canvas (271 pts)]]></title>
            <link>https://github.com/haystackeditor/haystack-editor</link>
            <guid>41648564</guid>
            <pubDate>Wed, 25 Sep 2024 15:31:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/haystackeditor/haystack-editor">https://github.com/haystackeditor/haystack-editor</a>, See on <a href="https://news.ycombinator.com/item?id=41648564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Haystack Editor Source Available</h2><a id="user-content-haystack-editor-source-available" aria-label="Permalink: Haystack Editor Source Available" href="#haystack-editor-source-available"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Repository</h2><a id="user-content-the-repository" aria-label="Permalink: The Repository" href="#the-repository"></a></p>
<p dir="auto">This repository ("<code>Haystack Editor</code>") is where we (Haystack Software) develop the <a href="https://haystackeditor.com/" rel="nofollow">Haystack Editor</a> product together with the community. Not only do we work on code and issues here, we also publish our <a href="https://github.com/haystackeditor/haystack-editor/wiki/Roadmap">roadmap</a>. This source code is available under the [PolyForm Strict License 1.0.0] (<a href="https://polyformproject.org/licenses/strict/1.0.0" rel="nofollow">https://polyformproject.org/licenses/strict/1.0.0</a>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Haystack Editor</h2><a id="user-content-haystack-editor" aria-label="Permalink: Haystack Editor" href="#haystack-editor"></a></p>
<p dir="auto"><a href="https://haystackeditor.com/" rel="nofollow">Haystack Editor</a> is a distribution of the <code>Haystack Editor</code> repository with specific customizations released under a <a href="https://github.com/haystackeditor/haystack-tos/blob/main/license.txt/">terms of service</a>.</p>
<p dir="auto"><a href="https://haystackeditor.com/" rel="nofollow">Haystack Editor</a> combines the simplicity of a code editor with a canvas UI that makes it easier to understand code at a glance It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.</p>
<p dir="auto">Haystack is updated weekly with new features and bug fixes. You can download it for Windows, macOS, and Linux on <a href="https://haystackeditor.com/" rel="nofollow">Haystack’s website</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">There are many ways in which you can participate in this project, for example:</p>
<ul dir="auto">
<li><a href="https://github.com/haystackeditor/haystack-editor/issues">Submit bugs and feature requests</a>, and help us verify as they are checked in</li>
<li>Review <a href="https://github.com/haystackeditor/haystack-editor/pulls">source code changes</a></li>
<li>Review the <a href="https://github.com/haystackeditor/haystack-editor/wiki">documentation</a> and make pull requests for anything from typos to additional and new content</li>
</ul>
<p dir="auto">If you are interested in fixing issues and contributing directly to the code base, please see the document <a href="https://github.com/haystackeditor/haystack-editor/wiki/How-to-Contribute">How to Contribute</a>, which covers the following:</p>
<ul dir="auto">
<li><a href="https://github.com/haystackeditor/haystack-editor/wiki/How-to-Contribute#build">How to build and run from source</a></li>
<li><a href="https://github.com/haystackeditor/haystack-editor/wiki/How-to-Contribute#build">The development workflow, including debugging and running tests</a></li>
<li><a href="https://github.com/haystackeditor/haystack-editor/wiki/How-to-Contribute#build">Submitting pull requests</a></li>
<li><a href="https://github.com/haystackeditor/haystack-editor/wiki/How-to-Contribute#build">Finding an issue to work on</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback</h2><a id="user-content-feedback" aria-label="Permalink: Feedback" href="#feedback"></a></p>
<ul dir="auto">
<li>Ask a question on <a href="https://discord.gg/apFrN6ABxc" rel="nofollow">Discord</a></li>
<li><a href="https://github.com/haystackeditor/haystack-editor/issues">File an issue</a></li>
<li>Follow <a href="https://x.com/AkshaySubr42403" rel="nofollow">@AkshaySubr42403</a> and let us know what you think!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Related Projects</h2><a id="user-content-related-projects" aria-label="Permalink: Related Projects" href="#related-projects"></a></p>
<p dir="auto">Many of the core components and extensions to Haystack live in their own repositories on GitHub. For example, the <a href="https://github.com/microsoft/vscode-node-debug">node debug adapter</a> and the <a href="https://github.com/microsoft/vscode-mono-debug">mono debug adapter</a> repositories are separate from each other. Another example is the <a href="https://github.com/haystackeditor/pixijs">Pixi repository</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bundled Extensions</h2><a id="user-content-bundled-extensions" aria-label="Permalink: Bundled Extensions" href="#bundled-extensions"></a></p>
<p dir="auto">Haystack includes a set of built-in extensions located in the <a href="https://github.com/haystackeditor/haystack-editor/blob/main/extensions">extensions</a> folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix <code>language-features</code>. For example, the <code>json</code> extension provides coloring for <code>JSON</code> and the <code>json-language-features</code> extension provides rich language support for <code>JSON</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Copyright (c) Haystack Software Inc. All rights reserved.</p>
<p dir="auto">Licensed under the [PolyForm Strict License 1.0.0] (<a href="https://polyformproject.org/licenses/strict/1.0.0" rel="nofollow">https://polyformproject.org/licenses/strict/1.0.0</a>).</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[System Intiative is generally available (115 pts)]]></title>
            <link>https://www.systeminit.com/blog-system-initiative-is-the-future/</link>
            <guid>41648483</guid>
            <pubDate>Wed, 25 Sep 2024 15:21:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.systeminit.com/blog-system-initiative-is-the-future/">https://www.systeminit.com/blog-system-initiative-is-the-future/</a>, See on <a href="https://news.ycombinator.com/item?id=41648483">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-31a58bc8=""><!--[--><p><img src="https://www.systeminit.com/images/screenshots/basic-screenshot.png" alt="System Initiative"></p><p>I’m incredibly proud to announce the general availability of System Initiative. It’s a revolutionary technology that is the future of how you will build DevOps automation. That’s a daunting sentence to write. As soon as I do - my brain immediately recoils. It says, “You shouldn’t say that. How can you be sure? Won’t it just read as meaningless hype?”</p><p>But if I’ve learned anything about building products for people, it’s this: you have to build the thing you believe should exist in the world, you have to fall in love with it, and then you have to let other people (hopefully) love it as you do. And the truth is - I <em>love</em> System Initiative. It’s bold, it’s novel, it’s fun to use, a delight to program, and extremely powerful. If I didn’t start by telling you it’s the future, I’d be doing you a disservice. But worse - I’d be doing <em>myself</em> a disservice. I would be shrinking from what I know to be true because I’m afraid about how you’ll receive it. At this point in my career? I’m done holding back. It’s the future.</p><p>I’ve been working on it for the last 5 years, but it feels like I’ve been working on it my entire career. All I’ve ever done professionally is build tools to help people build things on the Internet. I’ve always admired people who took incredible risks and built technology that changed the way we think about what’s possible. The kind of technology that, even if it isn’t a commercial success, leaves an indelible mark. System Initiative is that technology for me. It’s the best thing I can imagine building. It holds nothing back. It’s as close to a pure expression of what I love about technology, about startups, and about entrepreneurship as I can imagine making.</p><p>I built it because the path we have been on, where we build infrastructure with the same approaches and tools we use to build applications - is a technological dead end. We’ve pushed it as far as it can go. We can still make small improvements on the margins, but that’s all they will be. Small improvements that don’t really move the needle much at all on the outcome. Without System Initiative, I feel like we’re all going to be stuck - replaying the same essential pattern over and over again, pretending it will be different this time. The choice wasn’t to make System Initiative or something else - the choice was to make System Initiative or find something else to love because loving DevOps and automation was no longer an option. I simply couldn’t watch the people who love what I love struggle the same way anymore.</p><p>So we (myself, my co-founders, and everyone who works here, past and present) took a step back. We asked ourselves what we would want the experience of building technology businesses to be like if we weren’t constrained at all by prior art. If there were no limits to what we could build. No rules we couldn’t break. No problem too big to tackle. To succeed, we would have to do the best work we’ve ever done. Build the best team possible. Push each other to go further. To not settle. System Initiative is the result.</p><p>Let’s discuss how it works and why it’s the revolutionary new foundation we need.</p><p>One undeniable truth about the experience of “doing DevOps” today - the feedback loops are awful. It takes forever to get started, it takes forever to know if you did something right or wrong. It takes forever for your pipelines to run, to get your code reviewed, to know if you’ve caused a security vulnerability, to know if you’ve gone over budget. It’s like we are all driving our own submarines, communicating only by radio. It’s deeply annoying how slow it is.</p><p>One cause of our feedback loop problem is that we’re bound up by the constraints of how other people implement their systems. For example - it might take AWS up to 10 minutes to provision an EKS cluster. The current tools can tell you if you have the syntax right, but they can’t tell you if it will <em>work</em> or not. To learn that? Gotta wait 10 minutes and pray for rain.</p><p>The other source of poor feedback loops is that we represent the definition of our infrastructure as code in the first place. This was a good idea at the time - we gained all the benefits of version control, we could do code review, build pipelines, and do continuous integration and delivery. But code is less malleable than data - it gets locked up behind syntax, it grows in complexity as the problem domain expands, as the abstractions pile up. It’s a static representation of a dynamic environment. With application code it works great - because the results are usually straightforward: an application artifact. But with infrastructure? It turns out to be a very awkward fit. It works, I’m not contesting that. But all you need to do to understand why it’s awkward is look at how hard we’ve pushed to effectively store and manage state, to artificially segment our infrastructure due to constraints of the implementation, and our failure to inspire our peers to work with us on complex infrastructure. It works, but it’s not nearly good enough.</p><p>How do other industries solve this problem? They build simulators. So that’s what we did too - we built a system of 1:1 digital twins of cloud infrastructure. We decoupled tracking the real state of the infrastructure from what you might hypothetically want to change. This lets us solve the feedback problem - the simulator doesn’t need to build that EKS cluster; it just needs to know if your proposed configuration <em>would</em> build an EKS cluster that works. We keep track of both things - the real data about your cluster (what we call a resource), and the hypothetical configuration in your digital twin (a component). Both are the “truth” in different contexts. Both are structured data, updated at different intervals. They are not code.</p><p>One excellent side effect of building digital twins? They eliminate the 200% problem. In case you don’t know, the 200% problem is a perennial issue with automation abstractions - to automate something, you need to understand both 100% of the underlying domain <em>and</em> 100% of how that domain maps to the way the tool understands the problem. With digital twins, if you know how a VPC works in AWS, you already know how to automate it in System Initiative. Because it’s a literal 1:1 translation. There is no loss of fidelity. You don’t learn AWS and then System Initiative. You just learn AWS, and use System Initiative to express what you already know.</p><p>Here’s another truth about DevOps - it’s always complicated. When I was the CTO of Chef, I had the privilege of working with teams from some of the largest, most complex enterprises - from leading technology companies to global banks and manufacturing. What is the number one thing they all had in common? They had unique, complex technology solutions. None of them did anything the same way. None of them had the exact same solutions to the same problem. All of them had pragmatic reasons for the choices they made. If you worked at Meta on Facebook, you wore this as a source of pride - you built things most people couldn’t imagine building. If you worked at a global bank, you probably started by apologizing about how backward everything was, followed by letting me know it’s like this because you power the entire global economy (which, for the record, is an <em>outstanding</em> reason for technical complexity). But I never once encountered a company whose technology infrastructure was “simple.”</p><p>That’s why System Initiative was designed, from the start, to be as powerful and expressive as possible. You can’t predict what people will need a platform like this to do. No matter how hard you try to reduce it or how much you learn, the world will remind you that it’s more complicated than you think. On the bright side - the people working in those companies are some of the most intelligent, capable people I’ve ever met. If you give them the power to solve their problems, they will.</p><p>So the next challenge was to make these high fidelity digital twins programmable. It had to be easy to create new models, modify existing ones, express policy, and use the information from one model to inform the configuration of another. The answer was moving the digital twins to sit on top of a graph of reactive functions. Everything about them - their schema, the values of their properties, the actions they can take to impact the real world, their validations and qualifications - is defined as source code that is reactive to its inputs. You declare the inputs and the outputs, and the system executes the right code at the right time. You can quickly and easily write any code you need - from the most straightforward model to the most highly customized enterprise requirement, directly within System Initiative.</p><p>The impacts here are profound. When modeling AWS IAM policy in System Initiative, we realized that AWS provides a sophisticated <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html">Policy Simulator</a>. So we modeled it, connected our IAM Policies and resources to it, and had a new, real time interface to test the validity of IAM policy. It took less than an hour from start to finish.</p><p>Let your imagination go for a minute about what you can build with this primitive. How would application deployment be expressed differently? Security and compliance policy? Financial budgeting? Network configuration? It’s a significantly more powerful way to program complex automation.</p><p>Of course, moving to a big graph of reactive functions brings a significant problem - what do you do about source control? The answer is both straightforward and audacious: you build version control into the platform directly, making it a hypergraph of functions[^1]. System Initiative has built in Change Sets - essentially forks of the entire graph, which allow you to make changes safely without impacting the real world. Change Sets include trivial things (like setting properties) and complex operations (like changing the source code). A lovely side effect of integrated Change Sets is that they automatically update when the “real world” changes - as resources change, or as people apply their changes to the world, they are immediately reflected in any open change sets. Your view never gets stale, you never wind up with a situation where the ‘plan’ no longer reflects the ‘apply’, there is nothing to ‘rebase’, and there is nothing to set up or maintain.</p><p>This brings us to another core problem with the status quo of DevOps automation. We’ve known from the start that the biggest key to unlocking great results in an organization is the amount of collaboration between the stakeholders. How close can Dev and Ops get? Security? Finance? Legal? The closer they get, the better the outcome. Even with a new software development primitive like a reactive hypergraph of functions, there is no reason to believe it would bring about better outcomes unless it also brings people together by default.</p><p>We accomplish this in System Initiative by building models that exist at various levels of semantic scale, and then building interfaces that make sense at those levels. For example - your application likely has properties that are configurable, actions it can take (like being deployed or built) and infrastructure it requires. You can use the same fundamental system of digital twins we use for low level infrastructure and express the impact with relationships. Eventually[^2], we will provide a custom interface specifically for each job, built from the same underlying data and kept up to date through simple usage. By giving people a view into the data that best fits their needs, we enable them to work together - even when they’re just doing “their” part of the job.</p><p>The second part: we extended the reactivity of functions to the user interface and made everything fully multiplayer. Need some help from an expert figuring out how to get that container deployed? They can log in to System Initiative and go directly to your Change Set. Then, you can make changes together and see the impact in real time. The difference here is remarkable - people can easily work together again. It makes the whole experience of working on infrastructure dramatically more effective and way more fun.</p><p>Think about the product implications here - fully multiplayer experiences, with interfaces designed for the specific semantics of a particular job, all working from a common baseline of reactive digital twins. This approach will create radically better experiences than the status quo - both in huge technology companies and our most complex enterprises. It will unlock the level of capability we’ve all been striving for the last 15 years.</p><p>Our first example of this is with managing infrastructure. With System Initiative, infrastructure engineers work together on a living architecture diagram. The relationships between components are configuring reactive inputs to functions that set their properties. It keeps track of the actions you’ll need to take to reconcile the simulation with reality. You can extend the system, embed policy, and collaborate in real time. It’s intuitive, it’s powerful, it’s multiplayer - and it’s incredibly fun.</p><p>The final piece of the puzzle was thinking through how a technology with this much potential gets set up to be as successful as possible. For me, there was only one answer to that question: it needed to be 100% open source software, with an open and welcoming community. We welcome you to build it with us, to build on top of it, to build a business on it, to fork it - whatever you need or want to do. Our goal is to be an incredible steward of this technology. I have complete faith that if we do that, we can all prosper.</p><p>System Initiative is the best work I can imagine doing. I love it. I believe it’s the future of DevOps Automation. Today it replaces Infrastructure as Code. Tomorrow, it will transform how you work together with your peers in the most complex environments on the planet. As of today, it no longer belongs to me. It belongs to all of you. I hope you love it too. Use it to make your work life dramatically better. Work more closely with your peers. Have fun. Build a better future for yourself. I know I am. </p><p>[^1]: It’s not actually a Hypergraph in the mathematical sense - those are when a graph has edges that can point to many nodes. It’s just what we started calling the design, and it stuck before we noticed it was a prior term of art. Forgive us, math friends.</p><p>[^2]: You can model applications today, but it’s a little awkward. The near-in road map includes building more complex management components, and slightly further out the ability to make role-specific visualizations. Today, System Initiative is great at the layer of Infrastructure.</p><p>Image from <a href="https://www.flickr.com/photos/tsaiproject/18720223738">tsaiproject flickr</a> under the <a href="https://creativecommons.org/licenses/by/2.0/">CC-BY-2.0</a></p><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Audio Masking (119 pts)]]></title>
            <link>https://www.cryptomuseum.com/covert/bugs/masking/</link>
            <guid>41647923</guid>
            <pubDate>Wed, 25 Sep 2024 14:27:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cryptomuseum.com/covert/bugs/masking/">https://www.cryptomuseum.com/covert/bugs/masking/</a>, See on <a href="https://news.ycombinator.com/item?id=41647923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Audio masking, or just <i>masking</i>, is a technique that is often used with
<a href="https://www.cryptomuseum.com/covert/bugs/index.htm"><span data-balloon-pos="up" aria-label="More about: covert listening devices">covert listening devices</span></a>,
or <a href="https://www.cryptomuseum.com/covert/bugs/index.htm"><span data-balloon-pos="up" aria-label="More about: ..."><i>bugs</i></span></a>, for hiding the intelligence of
the intercepted audio (e.g. human speech), from a casual or professional
interceptor.
In some cases, obscure modulation techniques are used that defeat any
non-compatible surveillance receiver.
Some of these masking schemes are described below.
<p>

The following audio masking techniques are currently covered:
          </p></span>
          </p>
<br>        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><a href="#sc">Subcarrier (SC)</a><br>
            </li><li><a href="#dsbsc">Double Sideband with Suppressed Carrier (DSBSC)</a><br>
            </li><li><a href="#tp">Triple Pulse (TP)</a><br>
            </li><li><a href="#rp">Rejected Pulse (RP)</a><br>
            </li><li><a href="#dp">Dirty Pulse (DP)</a><br>
            </li><li><a href="#sp">Super Pulse (SP)</a><br>
          </li></ul>
        </span></p>
        <a name="sc"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
One of the first and most widespread techniques is the use of subcarrier modulation.
It works on the basis that the audible audio signal is modulated onto another
audio signal that is well above the audible range. The combined signal is then
modulated onto an <span data-balloon-pos="up" aria-label="Radio Frequency">RF</span> carrier. In its basic form, an interceptor will only hear
a silent carrier once the <span data-balloon-pos="up" aria-label="Radio Frequency">RF</span> signal has been demodulated. The actual audio
modulation can only be recovered by demodulating the demodulated signal once more.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/sc_mod.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
With this scheme, Frequency Modulation (<span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span>) is commonly used to add the audio
signal to the subcarrier (<span data-balloon-pos="up" aria-label="Subcarrier">SC</span>) signal, whilst the combined signal (SC+FM) can be
added to the <span data-balloon-pos="up" aria-label="Radio Frequency">RF</span> with either <span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span> or Amplitude Modulation (<span data-balloon-pos="up" aria-label="Amplitude Modulation">AM</span>).
The diagram above shows how the modulated subcarrier signal would appear
as the two sidebands of an <span data-balloon-pos="up" aria-label="Amplitude Modulation">AM</span> signal. Pretty much any
frequency above the audible range can be used for the subcarrier.
Common <span data-balloon-pos="up" aria-label="Subcarrier">SC</span> frequencies are 12.5 kHz, 22 kHz and 40 kHz.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/sc_fm.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
When frequency modulating the carrier with a frequency-modulated subcarrier,
the presence of the audio signal is even less noticable, especially when the
channel's baseband is modulated with a strong noise or hum signal
(<a href="#sc_imp"><span data-balloon-pos="up" aria-label="Jump to: see below">see below</span></a>).
In such cases, the contribution of the audio signal is marginal compared
to the subcarrier, which itself is marginal compared to the injected noise.
<p>

One of the first known uses of subcarrier modulation is in wired telephony,
where it was used to send multiple telephone coversations over a single wire pair,
thereby effectively increasing the capacity of the network.
One of the first uses in <a href="https://www.cryptomuseum.com/covert/bugs/index.htm"><span data-balloon-pos="up" aria-label="More about: covert listening devices">covert listening devices</span></a>
was in 1958 with the
<span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>'s <a href="https://www.cryptomuseum.com/covert/bugs/ec/ec3/index.htm"><span data-balloon-pos="up" aria-label="More about: Easy Chair Mark III">Easy Chair Mark III</span></a>,
where it was used to hide the audio.
In the later <a href="https://www.cryptomuseum.com/covert/bugs/ec/ec5/index.htm"><span data-balloon-pos="up" aria-label="More about: Easy Chair Mark V">Easy Chair Mark V</span></a>
it was even used to listen to up to three
Passive Elements (PEs) in the same target area simultaneously.
</p><p>

SC-modulation is arguably the most commonly used audio masking scheme for
professional as well as semi-professional bugs. During the Cold War, it was
used heavily by inteligence services like the American <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> and the
East-German Stasi. Especially the latter (Stasi) is known to have produced
a wide range of telephone and room bugging devices that feature SC-techniques.
          </p></span>
          </p>
<br>        <a name="sc_cm"></a>
        
        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Despite the fact that SC-modulated bugs are often used by intelligence
serices, even today, the system is easily defeated with a professional
<a href="https://www.cryptomuseum.com/df/index.htm"><span data-balloon-pos="up" aria-label="More about: surveillance receiver">surveillance receiver</span></a>,
or <a href="https://www.cryptomuseum.com/df/tscm.htm"><span data-balloon-pos="up" aria-label="More about: ..."><i>bug tracer</i></span></a>.
One of the first bug tracers
that was able to demodulate an SC signal, was the
<a href="https://www.cryptomuseum.com/df/scanlock/mark3/index.htm"><span data-balloon-pos="up" aria-label="More about: Scanlock Mark 3">Scanlock Mark 3</span></a> in 1976.
<p>

Its successor, the <a href="https://www.cryptomuseum.com/df/scanlock/markvb/index.htm"><span data-balloon-pos="up" aria-label="More about: ScanLock Mark VB">ScanLock Mark VB</span></a>
shown in the image on the right, can even discover the SC frequency automatically
and will generally find and demodulate an SC bug within seconds.
</p><span color="#E7E">➤</span>&nbsp;<a href="https://www.cryptomuseum.com/df/scanlock/index.htm">More about the Scanlock range</a>
          </span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/df/scanlock/index.htm">            </a><div data-balloon-pos="up" aria-label="Scanlock Mark VB in operation"><a href="https://www.cryptomuseum.com/df/scanlock/index.htm">            <p><img src="https://www.cryptomuseum.com/df/scanlock/markvb/img/300020/083/small.jpg" alt="Scanlock Mark VB in operation" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
<br>        <a name="sc_imp"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Silent carriers are very difficult to identify, as they are
also produced as <i>spurious</i> by-products of domestic equipment, computers
and even by the surveillance receiver itself. When scanning a frequency band,
it will be difficult to distinguish an SC-modulated bug from a spurious signal.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
To make identification of the signal even more difficult, some manufacturers
injected noise or a strong 50/60 Hz hum into the signal's base­band, so that the
carrier was no longer silent.
<p>

A good example of the latter is the
<b>bug that was found in the {?OPEC</b> headquarters=../opec/index.htm}
in Vienna in the late 1970s. By injecting a very strong 50 Hz hum into the baseband,
it was hoped that a sweep team checking the room for bugs, would discard it as
interference from a domestic applience or a transformer.
Despite the improvement however, this scheme is defeated by a
<a href="https://www.cryptomuseum.com/df/scanlock/index.htm"><span data-balloon-pos="up" aria-label="More about: Scanlock receiver">Scanlock receiver</span></a>.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/covert/bugs/opec/index.htm">            </a><div data-balloon-pos="up" aria-label="Opened OPEC bug"><a href="https://www.cryptomuseum.com/covert/bugs/opec/index.htm">            <p><img src="https://www.cryptomuseum.com/covert/bugs/opec/img/302391/016/small.jpg" alt="Opened OPEC bug" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
<br>        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Around 1974, the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> introduced the <a href="https://www.cryptomuseum.com/covert/bugs/srt105/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-105">SRT-105</span></a>,
a miniature bug with <span data-balloon-pos="up" aria-label="Subcarrier">SC</span> audio masking, in which noise was injected into the baseband.
When scanning the frequency band, this noise is difficult to distinguish from the
background noise that is present in any empty radio channel. Nevertheless,
noise-injected SC bugs are just as easily defeated by a Scanlock receiver
as normal SC bugs, so they hardly
provide any effective protection against discovery by a professional sweep team.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Despite that, and the availabily of other, often superior, masking schemes,
the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> kept using this scheme for many years. In 1981, they even introduced
the <a href="https://www.cryptomuseum.com/covert/bugs/ec/srs153/srt153.htm"><span data-balloon-pos="up" aria-label="More about: SRT-153">SRT-153</span></a>,
which was modelled after a discovered device from an adversary.
<p>

This suggests that the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> may have done this deliberately, so that the
adversary would be blamed for planting the bugs, whilst the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> also had other,
less easy to find, bugs planted in the same room.
There is an unwritten law in the surveillance business, that for every
bug that has been found, there are four undiscovered ones.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srs153/srt153.htm">            </a><div data-balloon-pos="up" aria-label="SRT-153 and QRR-153"><a href="https://www.cryptomuseum.com/covert/bugs/ec/srs153/srt153.htm">            <p><img src="https://www.cryptomuseum.com/covert/bugs/ec/srs153/img/302521/050/small.jpg" alt="SRT-153 and QRR-153" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1958</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1962</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1966</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> <sup><span color="#FF8800">3</span></sup>            </li><li><p>1975</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> <sup><span color="#FF8800">1,3</span></sup>            </li><li><p>1974</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> <sup><span color="#FF8800">1,3</span></sup>            </li><li><p>1981</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> <sup><span color="#FF8800">1,4</span></sup>            </li><li><p>1978 ~</p>? <sup><span color="#FF8800">2,5</span></sup>            </li><li><p>1984</p>Bulgaria, <span data-balloon-pos="up" aria-label="Deutsche Demokratische Republik (East-Germany)">DDR</span> (<span aria-label="Ministerium für Staatssicherheit (DDR)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/stasi">Stasi</a></span>) <sup><span color="#FF8800">5</span></sup>            </li><li><p>1990</p><a href="https://www.cryptomuseum.com/manuf/audiotel">Audiotel</a>          </li></ul>
</span></p>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1966</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1975</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1981</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1976</p><a href="https://www.cryptomuseum.com/manuf/audiotel">Audiotel</a>            </li><li><p>1978</p><a href="https://www.cryptomuseum.com/manuf/audiotel">Audiotel</a>          </li></ul>
</span></p>        <p><img src="https://www.cryptomuseum.com/covert/bugs/img/blank.gif" width="1" height="5"></p>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#888888"><small>
          <ol>
          <li>
Noise injected into baseband.
          </li>
          <li>
50 or 60 Hz hum injected into baseband.
          </li>
          <li>
40 kHz subcarrier
          </li>
          <li>
22 kHz subcarrier
          </li>
          <li>
12.5 kHz subcarrier
          </li>
          <li>
24 kHz subcarrier
          </li></ol>
          </small></span></p>
        <br>

        
<br>        <a name="dsbsc"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Double Sideband with Suppressed Carrier (<span data-balloon-pos="up" aria-label="Double Sideband with Suppressed Carrier">DSBSC</span>) is a rarely used
audio masking scheme that defeats most bug finding equipment. In most cases,
the audio signal is amplitude modulated (<span data-balloon-pos="up" aria-label="Amplitude Modulation">AM</span>) onto a carrier above the
audible range (e.g. 20 kHz), which in turn is frequency modulated (<span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span>)
onto the <span data-balloon-pos="up" aria-label="Radio Frequency">RF</span> carrier. The 20 kHz subcarrier itself is suppressed, or
ideally eliminated.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/sc_fm.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
On a spectrum analyser, the signal will look like any modulated <span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span> signal.
However, after demodulating the <span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span> signal, the result is an <span data-balloon-pos="up" aria-label="Audio Frequency">AF</span> signal
that contains speech information well above the audible range. Furthermore,
the original sub-carrier (20 kHz) as been removed, as a result of which it
cannot be re-inserted automatically by a bug tracer like the
<a href="https://www.cryptomuseum.com/df/scanlock/markvb"><span data-balloon-pos="up" aria-label="More about: Scanlock Mark VB">Scanlock Mark VB</span></a>.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/dsbsc_mod.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
The diagram above shows the audio frequency spectrum (<span data-balloon-pos="up" aria-label="Audio Frequency">AF</span>) after demodulation
of the <span data-balloon-pos="up" aria-label="Frequency Modulation">FM</span> radio frequency carrier (<span data-balloon-pos="up" aria-label="Radio Frequency">RF</span>). The audible range is approx. from
30 to 10,000 Hz (in practice often 30-300 Hz). The <span data-balloon-pos="up" aria-label="Amplitude Modulation">AM</span> modulated subcarrier
has two sidebands: an upper sideband (USB) and a lower sideband (LSB),
but as the subcarrier is removed, the relation between the sidebands and their
carrier is lost. The signal can only be recovered in a compatible receiver,
in which the 20 kHz carrier is added in again, but for this to work, the
recipient has to know the exact frequency.
<p>

This masking scheme can be further improved by injecting noise or a strong
50/60 Hz hum in the baseband. This will obscure the (faint) sidebands in
the 20 kHz range.
          </p></span>
          </p>
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1967</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>          </li></ul>
</span></p>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li>SRR-40 with SRT-57 20 kHz demodulator          </li></ul>
</span></p>        <a name="tp"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Triple Pulse (TP) is an audio masking technique based on Pulse Position
Modulation (PPM), developed around 1964 by the
<a href="https://www.cryptomuseum.com/manuf/nrp/index.htm"><span data-balloon-pos="up" aria-label="More about: Dutch Radar Laboratory (NRP)">Dutch Radar Laboratory (NRP)</span></a>,
for the US <a href="https://www.cryptomuseum.com/intel/cia/index.htm"><span data-balloon-pos="up" aria-label="More about: Central Intelligence Agency (CIA)">Central Intelligence Agency (CIA)</span></a>,
as part of a long-term research contract under the codename
<a href="https://www.cryptomuseum.com/covert/bugs/ec/index.htm"><span data-balloon-pos="up" aria-label="More about: Easy Chair">Easy Chair</span></a>.
This masking scheme was first used with the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-52">SRT-52</span></a>, and is
also known as <b>Type 52</b> or <b>52 System</b>.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/tp_timing.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
The system takes sound samples at random intervals,
under control of a noise generator, and transmits these in pulse
position modulation (PPM). In the above diagram, the random samples are shown in red
as T1, T2 and T3. Each pulse is enclosed within two reference pulses (green)
that have a fixed distance (d). Each pulse has the same width and amplitude.
The actual audio intelligence is carried in the position
of the red pulse, relative to the two green reference pulses.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/tp_mod.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
Each pulse is approx. 0.5 µs long and resembles a square wave. As a result
of this,
this type of modulation produces a multitude of sidebands at either side of
the carrier. In practice, the band­width of the signal can be up to
100 MHz, especially when in close proximity of the transmitter.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
The <span data-balloon-pos="up" aria-label="Triple Pulse audio masking">TP</span> masking scheme was first used in 1969 with the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-52">SRT-52</span></a>, which is why
it is also known as <b>Type 52</b> or <b>System 52</b>. The SRT-52 consists of two
or three metal cylindrical enclosures that contain the RF unit,
the audio masking unit (also known as the video module) and (optionally)
a 110/220V AC mains power supply unit (PSU).
<p>

The image on the right shows a genuine <a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-52 set">SRT-52 set</span></a>,
as used by the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>.
The units can generally be recognised by their blue colour, although
some units may seem to be green, due to colourisation of the varnish,
caused by aging.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm">            </a><div data-balloon-pos="up" aria-label="SRT-52 transmitter consisting of an SRK-29 RF unit, an SWE-52 video coder and an UWP-52 power supply unit" data-balloon-length="large"><a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm">            <p><img src="https://www.cryptomuseum.com/covert/bugs/ec/srt52/img/302615/021/small.jpg" alt="SRT-52 transmitter consisting of an SRK-29 RF unit, an SWE-52 video coder and an UWP-52 power supply unit" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
<br>
The <span data-balloon-pos="up" aria-label="Triple Pulse audio masking">TP</span> masking scheme was only used in the video coder of the SRT-52
that was in production from 1969 to 1971. According to the currently
available information, it was not used in any bugs after 1971. The
<span data-balloon-pos="up" aria-label="Triple Pulse audio masking">TP</span> scheme was superceeded by the more stable RP and <span data-balloon-pos="up" aria-label="Dirty Pulse audio masking">DP</span> masking schemes.
          </span>
          </p>
<br>        <a name="tp_cm"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
There are currently no known commercially available
<a href="https://www.cryptomuseum.com/df/receivers.htm"><span data-balloon-pos="up" aria-label="More about: surveillance receivers">surveillance receivers</span></a>
that can readily demodulate a <span data-balloon-pos="up" aria-label="Pulse Position Modulation">PPM</span>-masked signal. Furthermore, existing
bug tracers like the <a href="https://www.cryptomuseum.com/df/scanlock/index.htm"><span data-balloon-pos="up" aria-label="More about: Scanlock range">Scanlock range</span></a>,
do not lock onto a <span data-balloon-pos="up" aria-label="Pulse Position Modulation">PPM</span> signal at all.
This means that automatic discovery of the bug is not evident.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
The only way to discover the presence of the bug is to search
the entire frequency spectrum in the target area manually
with a portable spectrum analyser, such as the
<a href="https://www.cryptomuseum.com/df/rs/fsh3/index.htm"><span data-balloon-pos="up" aria-label="More about: Rohde &amp; Schwarz FSH-3">Rohde &amp; Schwarz FSH-3</span></a>.
<p>

When using it in combination with a
directional antenna, such as the
<a href="https://www.cryptomuseum.com/df/rs/he100/index.htm"><span data-balloon-pos="up" aria-label="More about: HE-100">HE-100</span></a>,
the spectrum in the building or room under investigation
can be searched for the
<a href="https://www.cryptomuseum.com/covert/bugs/masking/img/tp_mod.png"><span data-balloon-pos="up" aria-label="More about: typical fingerprint">typical fingerprint</span></a>
of the SRT transmitter, which consists of a 6 to 10 MHz
wide carrier and several sidebands at either side.
The image on the right shows the portable
<a href="https://www.cryptomuseum.com/df/rs/fsh3"><span data-balloon-pos="up" aria-label="More about: FSH-3 spectrum analyser">FSH-3 spectrum analyser</span></a>,
with an </p><span color="#F52E00">HE-100 antenna</span>.
          </span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/df/rs/fsh3/index.htm">            </a><div data-balloon-pos="up" aria-label="FSH-3 with HE-100 (20-200 MHZ)"><a href="https://www.cryptomuseum.com/df/rs/fsh3/index.htm">            <p><img src="https://www.cryptomuseum.com/df/rs/fsh3/img/301889/040/small.jpg" alt="FSH-3 with HE-100 (20-200 MHZ)" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
<br>
Once a suspicious signal is found, the directional antenna can be used
to find its location, simply by looking for the bearing with
the strongest signal and walking towards it. Finding the strongest
signal by means of a spectrum analyser is not easy though, even not
when it is a portable one.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
In such situations, the use of a modern portable surveillance
receiver, such as the
<a href="https://www.cryptomuseum.com/df/rs/pr100/index.htm"><span data-balloon-pos="up" aria-label="More about: PR-100">PR-100</span></a>
from <a href="https://www.cryptomuseum.com/manuf/rs/index.htm"><span data-balloon-pos="up" aria-label="More about: Rohde &amp; Schwarz">Rohde &amp; Schwarz</span></a>,
would be more appropriate.
The <a href="https://www.cryptomuseum.com/df/rs/pr100/index.htm"><span data-balloon-pos="up" aria-label="More about: PR-100">PR-100</span></a>
is shown in the image on the right, together with
the <span color="#F52E00">HE-300 directional antenna</span>.
<p>

This device has a 10 MHz wide panorama viewer,
a waterfall display and an accurate field strength meter
with an acoustic indicator (tone). After tuning to the desired
frequency, as found with help of the
<a href="https://www.cryptomuseum.com/df/rs/fsh3/index.htm"><span data-balloon-pos="up" aria-label="More about: FSH-3">FSH-3</span></a>,
the tone will lead you straight
to the transmitter. A test with the
<a href="https://www.cryptomuseum.com/df/rs/pr100/index.htm"><span data-balloon-pos="up" aria-label="More about: PR-100">PR-100</span></a>
in our collection showed that this was easily possible.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/df/rs/pr100/index.htm">            </a><div data-balloon-pos="up" aria-label="PR-100 portable monitoring receiver and HE-300 anenna" data-balloon-length="large"><a href="https://www.cryptomuseum.com/df/rs/pr100/index.htm">            <p><img src="https://www.cryptomuseum.com/df/rs/pr100/img/302623/036/small.jpg" alt="PR-100 portable monitoring receiver and HE-300 anenna" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
<br>
The PR-100 can pick up the signal from the SRT from a distance
of at least 100 metres.
It is capable of demodulating AM, FM, PM, CW and SSB
signals. Although it can be used to locate the SRT transmitter,
it can not be used to demodulate its signal, as was to be expected
of course.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
A quick test with the portable
<a href="https://www.cryptomuseum.com/df/scanlock/deltav/index.htm"><span data-balloon-pos="up" aria-label="More about: Audiotel Delta-V">Audiotel Delta-V</span></a>
differential RF detector, shown in the image on the right,
immediately revealed the presence of a bug in the room.
Due to the low energy density of the PPM bugs,
caused by the low signal level and the low duty cycle of
the transmitted pulses, the Delta-V has to be closer to
the transmitter than normal, before it produces a usable tone.
<p>

Once a tone is obtained, the transmitter can be located
within seconds, which is remarkable for a simple, small
and rather inexpensive tool like this.
The one shown here is the
<a href="https://www.cryptomuseum.com/df/scanlock/deltav/index.htm#ecm"><span data-balloon-pos="up" aria-label="More about: Delta-V ECM">Delta-V ECM</span></a>.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/df/scanlock/deltav/index.htm#ecm">            </a><div data-balloon-pos="up" aria-label="Click to see more"><a href="https://www.cryptomuseum.com/df/scanlock/deltav/index.htm#ecm">            <p><img src="https://www.cryptomuseum.com/df/scanlock/deltav/img/300551/005/small.jpg" alt="Click to see more">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
<br>
It is also remarkable that the Delta-V does not suffer from the strong
RF signal from the nearby broadcasting station that has caused us
many headaches before.
It can be concluded from the above tests, that finding a
PPM bug is not evident, but with the right tools it certainly is
possible.
<br>
          </span>
          </p>
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1969</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>          </li></ul>
</span></p>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1969</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1972</p>SRR-52 retrofitted with modification          </li></ul>
</span></p>        
<br>        <a name="rp"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Rejected Pulse (RP) is an audio masking technique based on Pulse Position
Modulation (PPM), developed around 1965 by the
<a href="https://www.cryptomuseum.com/manuf/nrp/index.htm"><span data-balloon-pos="up" aria-label="More about: Dutch Radar Laboratory (NRP)">Dutch Radar Laboratory (NRP)</span></a>,
for the <span data-balloon-pos="up" aria-label="United States of America (USA)">US</span> <a href="https://www.cryptomuseum.com/intel/cia/index.htm"><span data-balloon-pos="up" aria-label="More about: Central Intelligence Agency (CIA)">Central Intelligence Agency (CIA)</span></a>,
as part of a long-term research contract under the codename
<a href="https://www.cryptomuseum.com/covert/bugs/ec/index.htm"><span data-balloon-pos="up" aria-label="More about: Easy Chair">Easy Chair</span></a>.
This masking scheme was first used with the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt56/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-56">SRT-56</span></a>,
and is also known as <i>Type 56</i> or <i>56 Modulation</i>.
In some internal <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> litarature it is referred to as the <i>Dropped Pulse
Audio Masking Scheme</i>.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/rp_timing.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
In this scheme, samples are taken at fixed intervals 'i' (shown in red)
and transmitted in Pulse Position Modulation (PPM). Under control of a noise
generator, up to five consecutive pulses are rejected (shown in grey),
resulting in a noisy pulse pattern. The relative position of each
surviving pulse carries the actual intelligence, which can be only recovered
in an RP-compatible receiver.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/tp_mod.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
Each pulse is approx. 0.5 µs long and resembles a square wave. As a result
of this,
this type of modulation produces a multitude of sidebands at either side of
the carrier. In practice, the band­width of the signal can be up to
100 MHz, especially when in close proximity of the transmitter.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
The RP-masking scheme was first used in 1968 with the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt56/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-56">SRT-56</span></a>, and is therefore
also known as <b>Type 56</b> or <b>System 56</b>. An
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt56/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-56 transmitter">SRT-56 transmitter</span></a> consists of
an RF unit (which is nearly identical to that of the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt52/index.htm#rf"><span data-balloon-pos="up" aria-label="More about: SRT-52">SRT-52</span></a>), an audio masking
unit (video coder) and (optionally) a mains PSU. The PSU could also be replaced
by Mercury batteries.
<p>

The image on the right shows a typical SRT-56 set, as used by the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>.
It can be identified by its green colour. The RP video coder is at the left.
It was later also used as part of the SRT-145 high-band
transmitter that operated on 1350 MHz.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt56/index.htm">            </a><div data-balloon-pos="up" aria-label="SRT-56 transmitter consisting of RF unit, video coder and PSU" data-balloon-length="large"><a href="https://www.cryptomuseum.com/covert/bugs/ec/srt56/index.htm">            <p><img src="https://www.cryptomuseum.com/covert/bugs/ec/srt56/img/302620/000/small.jpg" alt="SRT-56 transmitter consisting of RF unit, video coder and PSU" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
<br>
The RP masking scheme appeared to be reliable and was difficult to crack.
As a result it was also used in 1974 in the fully integrated high-band
SRT-107 transmitter. Bugs with RP masking can be decoded on nearly all
<span aria-label="Nederlands Radar Proefstation (Dutch Radar Laboratory)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/manuf/nrp">NRP</a></span>-built surveillance receivers, including the retrofitted
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srr52/index.htm"><span data-balloon-pos="up" aria-label="More about: SRR-52-M">SRR-52-M</span></a>.
          </span>
          </p>
<br>        <a name="rp_cm"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Same as for <a href="#tp_cm"><span data-balloon-pos="up" aria-label="Jump to: TP-modulated bugs">TP-modulated bugs</span></a>.
          </span>
          </p>
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1968</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1968</p>Rectangular version of SRT-56            </li><li><p>1971</p>High-band version of SRT-56            </li><li><p>1974</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>          </li></ul>
</span></p>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1972</p>SRR-52 retrofitted with modification            </li><li><p>1968</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1975</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1970</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>          </li></ul>
</span></p>        
<br>        <a name="dp"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Dirty Pulse (DP) is an audio masking technique based on Pulse Position
Modulation (PPM), developed around 1966 by the
<a href="https://www.cryptomuseum.com/manuf/nrp/index.htm"><span data-balloon-pos="up" aria-label="More about: Dutch Radar Laboratory (NRP)">Dutch Radar Laboratory (NRP)</span></a>,
for the US <a href="https://www.cryptomuseum.com/intel/cia/index.htm"><span data-balloon-pos="up" aria-label="More about: Central Intelligence Agency (CIA)">Central Intelligence Agency (CIA)</span></a>,
as part of a long-term research contract under the codename
<a href="https://www.cryptomuseum.com/covert/bugs/ec/index.htm"><span data-balloon-pos="up" aria-label="More about: Easy Chair">Easy Chair</span></a>.
This masking scheme was first used with the <a href="https://www.cryptomuseum.com/covert/bugs/ec/srt91/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-91">SRT-91</span></a>,
and is also known as <b>Type 91</b> or <b>91 System</b>.
<table><tbody><tr><td>
            </td></tr><tr><td>
          </td></tr></tbody></table>
<br>
In this scheme, samples are taken at fixed intervals (i) and are transmitted
as Pulse Position Modulation (PPM). Under control of a noise generator, the
back porch of each pulse is delayed in time by a randomly determined
value (r). Only the relative position of the front porch contains intelligence.
The spectrum diagram is nearly identical to the previous two schemes.
<p>

It was later discovered that when a DP-masked signal was received by
an overloaded or blocking receiver, automatic demodulation could occur,
as a result of which the transmitter would loose its masking capability.
A similar scheme, known as Super Pulse (SP) did not have this drawback as
it moved the rising edge of the pulse forward in time. In the end,
the Super Pulse masking scheme was renamed Dirty Pulse, and the existing
transmitters and receivers were all modified.
</p><table><tbody><tr><td>
            </td></tr><tr><td>
          </td></tr></tbody></table>
<br>
In this scheme, samples are taken at fixed intervals (i) and are transmitted
as Pulse Position Modulation (PPM). Under control of a noise generator, the
front porch of each pulse is moved forward in time by a randomly determined
value (r). Only the relative position of the back porch contains intelligence.
The spectrum diagram is nearly identical to the previous two schemes.
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/tp_mod.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
Each pulse is approx. 0.5 µs long and resembles a square wave. As a result
of this,
this type of modulation produces a multitude of sidebands at either side of
the carrier. In practice, the band­width of the signal can be up to
100 MHz, especially when in close proximity of the transmitter.
          </span>
          </p>
<br>        <table>
          <tbody><tr>
          <td>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
The DP masking scheme was first used in 1974 with the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt91/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-91">SRT-91</span></a>,
which is why it is also known as <b>Type 91</b> or <b>System 91</b>.
Compared to earlier pulse-modulated transmitters, the SRT-91
was very compact and housed both the RF unit and the video
encoder in a single rectangular case.
<p>

In addition it needed only 2.7V DC power, so that it could be powered
by just two mercury battery cells.
The image on the right shows a genuine
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt91/index.htm"><span data-balloon-pos="up" aria-label="More about: SRT-91">SRT-91</span></a>, as used by the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>.
It can generally be recognised by its typical grey colour and the
colour-coded dots in one of the corners.
          </p></span></td>
          <td>&nbsp;&nbsp;</td>
          <td>
          <table><tbody><tr><td>
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srt91/index.htm">            </a><div data-balloon-pos="up" aria-label="SRT-91 transmitter"><a href="https://www.cryptomuseum.com/covert/bugs/ec/srt91/index.htm">            <p><img src="https://www.cryptomuseum.com/covert/bugs/ec/srt91/img/302502/000/small.jpg" alt="SRT-91 transmitter" width="298" height="200">
            </p>
            </a>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
          </td></tr>
        </tbody></table>
<br>        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
The <span data-balloon-pos="up" aria-label="Dirty Pulse audio masking">DP</span> masking scheme appeared to be reliable and was difficult to
crack. As a result it was also used in later transmitters and in
transmitters from other manufacturers, such as the
<span color="#F52E00">SRT-99</span>.
As far as we know, there are currently no known commercially
available <a href="https://www.cryptomuseum.com/df/receivers.htm"><span data-balloon-pos="up" aria-label="More about: surveillance receivers">surveillance receivers</span></a>
that can readily demodulate a DP-masked signal.
Suitable <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span> receivers are the
<a href="https://www.cryptomuseum.com/covert/bugs/ec/srr90/index.htm"><span data-balloon-pos="up" aria-label="More about: SRR-90">SRR-90</span></a>
and <a href="https://www.cryptomuseum.com/covert/bugs/ec/srr91/index.htm"><span data-balloon-pos="up" aria-label="More about: SRR-91">SRR-91</span></a>.
          </span>
          </p>
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1975</p>Low-power version of SRT-91            </li><li><p>1974</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1975</p>Stereo version of SRT-91            </li><li><p>SRT-99</p><p>?</p>CIA            </li><li><p>1973</p>Super Pulse          </li></ul>
</span></p>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><p>1968</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1968</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1974</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>            </li><li><p>1974</p><span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>          </li></ul>
</span></p>        
<br>        <a name="sp"></a>
        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
Super Pulse (SP) is the name of a
<a href="https://www.cryptomuseum.com/covert/bugs/ec/sp/index.htm"><span data-balloon-pos="up" aria-label="More about: research project">research project</span></a>,
carried out by the
<a href="https://www.cryptomuseum.com/manuf/nrp/index.htm"><span data-balloon-pos="up" aria-label="More about: Dutch Radar Laboratory (NRP)">Dutch Radar Laboratory (NRP)</span></a>
on behalf of the <span aria-label="Central Intelligence Agency (USA)" data-balloon-pos="up"><a href="https://www.cryptomuseum.com/intel/cia">CIA</a></span>, with the aim to develop a
<a href="https://www.cryptomuseum.com/covert/bugs/ec/sp/index.htm"><span data-balloon-pos="up" aria-label="More about: sub-miniature transmitter">sub-miniature transmitter</span></a>.
As part of this project, the Super Pulse
audio masking scheme was developed, in which the position of the rising
edge of the pulse is masked with noise. This scheme was later renamed to
Dirty Pulse (DP).
<table><tbody><tr><td>
            <div>
            <p><img src="https://www.cryptomuseum.com/covert/bugs/masking/svg/dp_timing.svg">
            </p>
            </div></td></tr><tr><td>
          </td></tr></tbody></table>
<br>
In a later version of the SP hardware, a digitally coded switch receiver
was added to design, allowing the transmitted signal to be turned OFF
when surveillance was not required. This saved batteries and minimized the
risk of being discovered.
<span color="#E7E">➤</span>&nbsp;<a href="https://www.cryptomuseum.com/covert/bugs/ec/sp/index.htm">About the Super Pulse (SP) project</a>
</span>
          </p>
<br>        
<br>        
        <p>
          <span size="-1" face="Lucida Grande,Arial,Verdana,sans-serif" color="#555555">
          <ul>
            <li><a href="https://www.cryptomuseum.com/covert/bugs/index.htm">Covert listening devices (bugs)</a><br>
            </li><li><a href="https://www.cryptomuseum.com/intel/cia/index.htm">About the CIA</a><br>
            </li><li><a href="https://www.cryptomuseum.com/manuf/nrp/index.htm">About the NRP</a><br>
          </li></ul>
        </span></p>
        </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The lost language extensions of MetaWare's High C compiler (2023) (267 pts)]]></title>
            <link>https://duriansoftware.com/joe/the-lost-language-extensions-of-metaware%27s-high-c-compiler</link>
            <guid>41647843</guid>
            <pubDate>Wed, 25 Sep 2024 14:19:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://duriansoftware.com/joe/the-lost-language-extensions-of-metaware%27s-high-c-compiler">https://duriansoftware.com/joe/the-lost-language-extensions-of-metaware%27s-high-c-compiler</a>, See on <a href="https://news.ycombinator.com/item?id=41647843">Hacker News</a></p>
Couldn't get https://duriansoftware.com/joe/the-lost-language-extensions-of-metaware%27s-high-c-compiler: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Coros – A Modern C++ Library for Task Parallelism (104 pts)]]></title>
            <link>https://github.com/mtmucha/coros</link>
            <guid>41647025</guid>
            <pubDate>Wed, 25 Sep 2024 13:05:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mtmucha/coros">https://github.com/mtmucha/coros</a>, See on <a href="https://news.ycombinator.com/item?id=41647025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Coros</h2><a id="user-content-coros" aria-label="Permalink: Coros" href="#coros"></a></p>
<p dir="auto"><a href="https://github.com/mtmucha/coros/actions/workflows/gcc_test.yml"><img src="https://github.com/mtmucha/coros/actions/workflows/gcc_test.yml/badge.svg?branch=main" alt="GCC"></a>
<a href="https://github.com/mtmucha/coros/actions/workflows/clang_test.yml"><img src="https://github.com/mtmucha/coros/actions/workflows/clang_test.yml/badge.svg?branch=main" alt="Clang"></a>
<a href="https://github.com/mtmucha/coros/actions/workflows/test_build.yml"><img src="https://github.com/mtmucha/coros/actions/workflows/test_build.yml/badge.svg" alt="tests"></a>
<a href="https://github.com/mtmucha/coros/actions/workflows/add_build.yml"><img src="https://github.com/mtmucha/coros/actions/workflows/add_build.yml/badge.svg?branch=main" alt="address sanitizer"></a>
<a href="https://github.com/mtmucha/coros/actions/workflows/tsan_build.yml"><img src="https://github.com/mtmucha/coros/actions/workflows/tsan_build.yml/badge.svg" alt="thread sanitizer"></a></p>
<p dir="auto">Coros is a header-only C++23 library designed for task-based parallelism,
that utilizes coroutines and the new expected type. Key features include:</p>
<ul dir="auto">
<li><strong>Ease of use</strong>: Straightforward interface and header-only installation.</li>
<li><strong>Performance</strong>: Optimized to ensure you don't miss out on performance (<a href="#benchmarks">see benchmarks below</a>).</li>
<li><strong>Exception handling</strong>: Utilizes <code>std::expected</code> for error management.</li>
<li><strong>Monadic operations</strong>: Supports easy chaining of tasks with <code>and_then</code> method.</li>
</ul>
<p dir="auto">Transforming a standard sequential function into a parallel task with Coros is as simple as:</p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/mtmucha/coros/raw/main/images/what_black.png">
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/mtmucha/coros/raw/main/images/what_white.png">
    <img alt="Shows an illustrated sun in light mode and a moon with stars in dark mode." src="https://github.com/mtmucha/coros/raw/main/images/what_black.png" width="80%">
  </picture></themed-picture>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">We have conducted two benchmarks to evaluate the performance of our library:</p>
<ul dir="auto">
<li><strong>Fibonacci Calculation</strong>: Calculating the 30th Fibonacci number to assess the scheduling overhead.</li>
<li><strong>Matrix Multiplication</strong>: A standard workload that tests overall performance.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Calculating Fibonacci number</h3><a id="user-content-calculating-fibonacci-number" aria-label="Permalink: Calculating Fibonacci number" href="#calculating-fibonacci-number"></a></p>
<p dir="auto">
  
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/mtmucha/coros/blob/main/images/graph_w1.png"><img src="https://github.com/mtmucha/coros/raw/main/images/graph_w1.png" alt="Code Screenshot 1" width="48%"></a>
  
  
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/mtmucha/coros/blob/main/images/graph_w2.png"><img src="https://github.com/mtmucha/coros/raw/main/images/graph_w2.png" alt="Code Screenshot 2" width="48%"></a>
  
</p> 
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix multiplication</h3><a id="user-content-matrix-multiplication" aria-label="Permalink: Matrix multiplication" href="#matrix-multiplication"></a></p>
<p dir="auto">
  
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/mtmucha/coros/blob/main/images/coros_graphs_13.png"><img src="https://github.com/mtmucha/coros/raw/main/images/coros_graphs_13.png" alt="Code Screenshot 1" width="48%"></a>
  
  
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/mtmucha/coros/blob/main/images/coros_graphs_14.png"><img src="https://github.com/mtmucha/coros/raw/main/images/coros_graphs_14.png" alt="Code Screenshot 2" width="48%"></a>
  
</p> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Using the Coros library is straightforward, there are three main components:</p>
<ul dir="auto">
<li><code>coros::ThreadPool</code>: As the name suggests, this is a thread pool that manages a desired number of worker
threads and executes individual tasks.</li>
<li><code>coros::Task&lt;T&gt;</code>: This object serves as the task container, which must be used as the return value from tasks.
The T parameter specifies the type the task returns. For a simple example, refer to the accompanying image.</li>
<li><strong>Awaiters</strong>: These are objects that support the <code>co_await</code> operator, allowing them to be awaited within tasks.
They are typically used for control flow, for example, waiting for other tasks to finish.</li>
</ul>
<p dir="auto">For additional details about the library, refer to the documentation provided below and check out the examples in the example folder.</p>
<ul dir="auto">
<li><a href="#documentation">Documentation</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#creating-tasks-and-starting-execution">Creating tasks and starting execution</a></li>
<li><a href="#waiting-for-other-tasks">Waiting for other tasks</a></li>
<li><a href="#enqueueing-tasks">Enqueueing tasks</a></li>
<li><a href="#chaining-tasks">Chaining tasks</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install the Coros library, simply place the include folder into your project directory and set the include path.
There are four key headers you can include:</p>
<ul dir="auto">
<li><code>#include "start_tasks.h"</code>:  Provides the functionality to set up tasks, thread pool object, and launch task execution from the main thread.</li>
<li><code>#include "wait_tasks.h"</code>: Enables suspension of individual tasks while waiting for others to complete.</li>
<li><code>#include "enqueue_tasks.h"</code>: Allows for the enqueuing of tasks into a thread pool without awaiting their completion.</li>
<li><code>#include "chain_tasks.h"</code>: Supports chaining of tasks, this chain is then executed on a thread pool.</li>
</ul>
<p dir="auto">To compile the library, ensure your compiler supports C++23 feature std::expected. Compatible compilers:</p>
<ul dir="auto">
<li>GCC 13 or newer</li>
<li>Clang 17 or newer</li>
<li>MSVC (not yet supported)</li>
</ul>
<p dir="auto">Do not forget to enable coroutines for given compiler, for example <code>-fcoroutines</code> for GCC.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">The library uses <code>std::hardware_destructive_interference_size</code> if supported by the compiler.
You can also set this value manually by passing a flag to the compiler, or you may choose to ignore it.
This is used as an optimization to avoid false sharing.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Creating tasks and starting execution</h2><a id="user-content-creating-tasks-and-starting-execution" aria-label="Permalink: Creating tasks and starting execution" href="#creating-tasks-and-starting-execution"></a></p>
<p dir="auto">To set up a task and start parallel execution the necessary steps are:</p>
<ul dir="auto">
<li>Construct a <code>coros::ThreadPool</code>: This will be the execution environment for your tasks.</li>
<li>Construct tasks using <code>coros::Task&lt;T&gt;</code>: Define the tasks and create a task object. These tasks can be run
on the thread pool object.</li>
<li>Start execution: Use <code>coros::start_sync</code> or <code>coros::start_async</code> to initiate execution from the main thread.</li>
</ul>
<p dir="auto"><code>coros::start_sync</code>/<code>coros::start_async</code> are functions designed to start parallel execution from the main thread.</p>
<p dir="auto"><strong>To create <code>coros::Task&lt;T&gt;</code>, <code>coros::ThreadPool</code> or use <code>coros::start_sync</code>/<code>coros::start_async</code>
include the <code>#include "start_tasks"</code> header.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::Task&lt;T&gt;</code></h2><a id="user-content-corostaskt" aria-label="Permalink: coros::Task<T>" href="#corostaskt"></a></p>
<p dir="auto">Task is a coroutine(added in C++20) that returns a <code>coros::Task&lt;T&gt;</code> object. To
transform a regular function into a coroutine, instead of <code>return</code> keyword a <code>co_return</code>
keyword must be used. And to transform a coroutine into a task a <code>coros::Task&lt;T&gt;</code> must
be a return type of the coroutine. Tasks support two keywords :</p>
<p dir="auto">A <code>coros::Task&lt;T&gt;</code> is a coroutine object, a feature introduced in C++20. To convert a standard function into a coroutine, replace the <code>return</code> keyword with <code>co_return</code>.
Additionally, the function must specify <code>coros::Task&lt;T&gt;</code> as its return type to function as a task. Tasks support two keywords:</p>
<ul dir="auto">
<li><code>co_return</code>: Use this keyword instead of return in your return statements.</li>
<li><code>co_await</code>: Use this for flow control with awaitable objects(objects that support <code>co_await</code> operator).</li>
</ul>
<p dir="auto">The return type <code>T</code> <strong>must satisfy</strong> constraint <code>std::is_constructible&lt;T,T&gt;</code>.
This requirement ensures that return values can be constructed from an r-value reference, utilizing either a move or a copy constructor.
This constraint arises because coroutine parameters themselves must also satisfy the std::is_constructible&lt;T,T&gt; condition.</p>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
  co_return val + 1;
}

int main() {
  coros::ThreadPool tp{/*number_of_threads=*/2};
  // Create the task object by calling the coroutine.
  coros::Task<int> task = add_one(41);
  // Wait until the task is finished, this call blocks.
  coros::start_sync(tp, task);
  // After this point, task is completed.
  // Optional check for stored value.
  if (task.has_value()) {
    std::cout << &quot;Result : &quot; << *task << std::endl;
  } else {
    // It is possible to process the caught exception.
    std::cout << &quot;Task failed&quot; << std::endl;
  }
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>1</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span><span>/*</span>number_of_threads=<span>*/</span></span><span>2</span>};
  <span><span>//</span> Create the task object by calling the coroutine.</span>
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(<span>41</span>);
  <span><span>//</span> Wait until the task is finished, this call blocks.</span>
  <span>coros::start_sync</span>(tp, task);
  <span><span>//</span> After this point, task is completed.</span>
  <span><span>//</span> Optional check for stored value.</span>
  <span>if</span> (task.<span>has_value</span>()) {
    std::cout &lt;&lt; <span><span>"</span>Result : <span>"</span></span> &lt;&lt; *task &lt;&lt; std::endl;
  } <span>else</span> {
    <span><span>//</span> It is possible to process the caught exception.</span>
    std::cout &lt;&lt; <span><span>"</span>Task failed<span>"</span></span> &lt;&lt; std::endl;
  }
}</pre></div>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">While it's possible to use lambda coroutines to construct tasks, be cautious with captures and references.
Best practice is passing values and references through coroutine parameters rather than captures to ensure safety and avoid unexpected behavior.
For more detail <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#SScp-coro" rel="nofollow">see the C++ Core Guidelines</a>.</p>
</div>
<p dir="auto">Under the hood, <code>coros::Task&lt;T&gt;</code> employs <code>std::expected&lt;T, std::exception_ptr&gt;</code> to store the outcome of the coroutine/task.
This structure holds either a value, indicating successful completion, or an <code>std::exception_ptr</code> if an exception occurred.
For convenience, <code>coros::Task&lt;T&gt;</code> offers methods analogous to those of std::expected:</p>
<ul dir="auto">
<li><code>T value()</code>: Accesses the stored value directly.</li>
<li><code>std::exception_ptr error()</code>: Retrieves the stored <code>std::exception_ptr</code>.</li>
<li><code>operator*()</code>: Provides direct access to the result.</li>
<li><code>T value_or(T defaultValue)</code>: Returns the stored value if the task contains a value; otherwise, it returns the specified default value.</li>
<li><code>std::expected&lt;T, std::exception_ptr&gt; expected()</code>: Returns the underlying std::expected object.</li>
<li><code>operator bool()</code>: Returns true if the task contains a successfully stored value.</li>
<li><code>bool has_value()</code>: Returns true if the task contains a successfully stored value.</li>
</ul>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Methods <code>value()</code> and <code>operator*()</code> <strong>are not supported</strong> for specialization <code>coros::Task&lt;void&gt;</code>.</p>
</div>
<p dir="auto"><code>coros::Task&lt;T&gt;</code> supports the <code>co_await</code> operator, making it an awaitable object.
When a task is awaited using <code>co_await</code>, it behaves similarly to a regular function call: the awaited task executes and, upon completion, control returns to the calling task.
The difference is that this operation typically does not consume additional stack space, thanks to the coroutine-to-coroutine control transfer.</p>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
  co_return val + 1;
}

coros::Task<int> add_value(int val) {
  coros::Task<int> another_task = add_one(val);
  // Once the another task finishes, control is returned,
  // this works like a regular function. 
  co_await another_task;
  // Accesses the another_task's result and increments it by one.
  // NOTE : check for the value is omitted.  
  co_return *another_task + 1;
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>1</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>add_value</span>(<span>int</span> val) {
  coros::Task&lt;<span>int</span>&gt; another_task = <span>add_one</span>(val);
  <span><span>//</span> Once the another task finishes, control is returned,</span>
  <span><span>//</span> this works like a regular function. </span>
  <span>co_await</span> another_task;
  <span><span>//</span> Accesses the another_task's result and increments it by one.</span>
  <span><span>//</span> NOTE : check for the value is omitted.  </span>
  <span>co_return</span> *another_task + <span>1</span>;
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::start_sync(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></h2><a id="user-content-corosstart_synccorosthreadpool-tasks" aria-label="Permalink: coros::start_sync(coros::ThreadPool&amp;, Tasks&amp;&amp;...)" href="#corosstart_synccorosthreadpool-tasks"></a></p>
<p dir="auto">To start tasks on a thread pool, you specify the desired thread pool and the tasks to be executed.
It is crucial that the <code>coros::ThreadPool</code> object outlives the execution of the tasks.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
  co_return val + 1;
}

int main() {
  coros::ThreadPool tp{/*number_of_threads=*/2};
  coros::Task<int> task = add_one(41);
  coros::start_sync( 
    tp, 
    // Lambda function that does the same ad add_one. Creates a temporary task object, which means
    // we cannot access its value.
    [](int val) -> coros::Task<int> {co_return val + 1;}(41),
    task
  );
  // Cannot retrieve value from the lambda function, but can retrieve 
  // value from the task.
  std::cout << *task << std::endl; // prints : 42
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>1</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span><span>/*</span>number_of_threads=<span>*/</span></span><span>2</span>};
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(<span>41</span>);
  <span>coros::start_sync</span>( 
    tp, 
    <span><span>//</span> Lambda function that does the same ad add_one. Creates a temporary task object, which means</span>
    <span><span>//</span> we cannot access its value.</span>
    [](<span>int</span> val) -&gt; coros::Task&lt;<span>int</span>&gt; {<span>co_return</span> val + <span>1</span>;}(<span>41</span>),
    task
  );
  <span><span>//</span> Cannot retrieve value from the lambda function, but can retrieve </span>
  <span><span>//</span> value from the task.</span>
  std::cout &lt;&lt; *task &lt;&lt; std::endl; <span><span>//</span> prints : 42</span>
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::start_async(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></h2><a id="user-content-corosstart_asynccorosthreadpool-tasks" aria-label="Permalink: coros::start_async(coros::ThreadPool&amp;, Tasks&amp;&amp;...)" href="#corosstart_asynccorosthreadpool-tasks"></a></p>
<p dir="auto">A task can be started asynchronously from the main thread, which allows the main thread to continue working while other tasks execute on the thread pool.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
  co_return val + 1;
}

int main() {
  coros::ThreadPool tp{/*number_of_threads=*/2};
  coros::Task<int> task = add_one(41);
  auto start_task = coros::start_async( 
    tp, 
    [](int val) -> coros::Task<int> {co_return val + 1;}(41), 
    task
  );
  //
  // Main thread can do some work.
  //
  // Call wait, blocks if tasks hasn't finished
  start_task.wait()
  std::cout << *task << std::endl; // prints : 42
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>1</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span><span>/*</span>number_of_threads=<span>*/</span></span><span>2</span>};
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(<span>41</span>);
  <span>auto</span> start_task = <span>coros::start_async</span>( 
    tp, 
    [](<span>int</span> val) -&gt; coros::Task&lt;<span>int</span>&gt; {<span>co_return</span> val + <span>1</span>;}(<span>41</span>), 
    task
  );
  <span><span>//</span></span>
  <span><span>//</span> Main thread can do some work.</span>
  <span><span>//</span></span>
  <span><span>//</span> Call wait, blocks if tasks hasn't finished</span>
  start_task.<span>wait</span>()
  std::cout &lt;&lt; *task &lt;&lt; std::endl; <span><span>//</span> prints : 42</span>
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Waiting for other tasks</h2><a id="user-content-waiting-for-other-tasks" aria-label="Permalink: Waiting for other tasks" href="#waiting-for-other-tasks"></a></p>
<p dir="auto">The Coros library provides mechanisms to wait for other tasks to complete.
This is achieved by suspending the current task (if necessary) and resuming it later.
There are two main methods and their overloads for handling task waiting:</p>
<ul dir="auto">
<li><code>coros::wait_tasks(Tasks&amp;&amp;...)</code></li>
<li><code>coros::wait_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></li>
<li><code>coros::wait_tasks(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;)</code></li>
<li><code>coros::wait_tasks(coros::ThreadPool&amp;, std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;)</code></li>
<li><code>coors::wait_tasks_async(Tasks&amp;&amp;...)</code></li>
<li><code>coors::wait_tasks_async(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;)</code></li>
</ul>
<p dir="auto">The main difference between the synchronous and asynchronous versions is in how they schedule tasks into a thread pool:</p>
<ul dir="auto">
<li>The <strong>asynchronous version</strong> schedules tasks into a thread pool upon creation.</li>
<li>The <strong>synchronous version</strong> schedules tasks into a thread pool only when they are explicitly <code>co_await</code>-ed.</li>
</ul>
<p dir="auto">Each of these function returns an awaitable object which can be <code>co_await</code>-ed by
calling the <code>co_await</code> operator.</p>
<p dir="auto"><strong>To use <code>coros::wait_tasks</code> include the <code>#include "wait_tasks"</code> header.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::wait_tasks(Tasks&amp;&amp;...)</code></h2><a id="user-content-coroswait_taskstasks" aria-label="Permalink: coros::wait_tasks(Tasks&amp;&amp;...)" href="#coroswait_taskstasks"></a></p>
<p dir="auto">Calling <code>coros::wait_tasks()</code> generates an awaitable object that supports the <code>co_await</code> operator.
This can be awaited to suspend the current task, which resumes only after the specified tasks have completed.
This approach allows individual threads to perform useful work without blocking.</p>
<details>
<summary>code example</summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
    co_return val + 1;
}

coros::Task<int> add_to_number(int val) {
  coros::Task<int> task = add_one(val);
  // The current task is suspended until task add_one completes.
  co_await coros::wait_tasks(task);
  co_return *task;
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
    <span>co_return</span> val + <span>1</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>add_to_number</span>(<span>int</span> val) {
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(val);
  <span><span>//</span> The current task is suspended until task add_one completes.</span>
  <span>co_await</span> <span>coros::wait_tasks</span>(task);
  <span>co_return</span> *task;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::wait_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></h2><a id="user-content-coroswait_taskscorosthreadpool-tasks" aria-label="Permalink: coros::wait_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)" href="#coroswait_taskscorosthreadpool-tasks"></a></p>
<p dir="auto"><code>coros::wait_task()</code> accepts variable number of tasks and it is also possible to specify
the <code>coros::ThreadPool&amp;</code> parameter, which moves tasks between thread pools.
Once the awaiting tasks are finished, the task is resumed on the specified thread pool.</p>
<p dir="auto">The <code>coros::wait_tasks()</code> function can accept a variable number of tasks, and it also allows for specifying a <code>coros::ThreadPool&amp;</code>.
This makes it possible to move tasks between thread pools.
Once the tasks being awaited are completed, the awaiting task resumes on the specified thread pool.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::ThreadPool tp{/*number_of_threads=*/2};

coros::Task<int> add_one(int val) {
    co_return val + 1;
}

coros::Task<int> add_to_number(int val) {
  
  coros::Task<int> task = add_one(val);
  // The awaitable returned from the function can be directly co_awaited or 
  // stored into a variable and co_awaited later.
  auto awaitable = coros::wait_tasks(tp, task);
  // Store awaitable into a variable and suspend later.
  co_await awaitable;
  // This part is resumed on the thread pool specified by the
  // parameter.
  co_return *task;
}"><pre>coros::ThreadPool tp{<span><span>/*</span>number_of_threads=<span>*/</span></span><span>2</span>};

coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
    <span>co_return</span> val + <span>1</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>add_to_number</span>(<span>int</span> val) {
  
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(val);
  <span><span>//</span> The awaitable returned from the function can be directly co_awaited or </span>
  <span><span>//</span> stored into a variable and co_awaited later.</span>
  <span>auto</span> awaitable = <span>coros::wait_tasks</span>(tp, task);
  <span><span>//</span> Store awaitable into a variable and suspend later.</span>
  <span>co_await</span> awaitable;
  <span><span>//</span> This part is resumed on the thread pool specified by the</span>
  <span><span>//</span> parameter.</span>
  <span>co_return</span> *task;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::wait_tasks(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;)</code></h2><a id="user-content-coroswait_tasksstdvectorcorostaskt" aria-label="Permalink: coros::wait_tasks(std::vector<coros::Task<T>>&amp;)" href="#coroswait_tasksstdvectorcorostaskt"></a></p>
<p dir="auto">It's possible to pass a vector of <code>coros::Task&lt;T&gt;</code> into the <code>coros::wait_tasks()</code> function to await the completion of multiple tasks.
This version <strong>can also move tasks between thread pools</strong> if a thread pool parameter is specified.</p>
<details> 
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one_and_sum(int n) {
  std::vector<coros::Task<int>> vec;
  for (size_t i = 1; i <= n;i++) {
    // Constructs tasks with lambda function.
    // Simple task that adds one to passed parameter.
    vec.push_back(
      [](int num) -> coros::Task<int> {
        co_return num + 1;
      }(i)
    );
  }
  // Suspends the current task and is resumed once all tasks are finished.
  co_await coros::wait_tasks(vec);

  int result_sum = 0;
  for (auto&amp; task : vec) {
    result_sum += *task;
  }

  co_return result_sum;
};"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one_and_sum</span>(<span>int</span> n) {
  std::vector&lt;coros::Task&lt;<span>int</span>&gt;&gt; vec;
  <span>for</span> (<span>size_t</span> i = <span>1</span>; i &lt;= n;i++) {
    <span><span>//</span> Constructs tasks with lambda function.</span>
    <span><span>//</span> Simple task that adds one to passed parameter.</span>
    vec.<span>push_back</span>(
      [](<span>int</span> num) -&gt; coros::Task&lt;<span>int</span>&gt; {
        <span>co_return</span> num + <span>1</span>;
      }(i)
    );
  }
  <span><span>//</span> Suspends the current task and is resumed once all tasks are finished.</span>
  <span>co_await</span> <span>coros::wait_tasks</span>(vec);

  <span>int</span> result_sum = <span>0</span>;
  <span>for</span> (<span>auto</span>&amp; task : vec) {
    result_sum += *task;
  }

  <span>co_return</span> result_sum;
};</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::wait_tasks_async(Tasks&amp;&amp;...)</code></h2><a id="user-content-coroswait_tasks_asynctasks" aria-label="Permalink: coros::wait_tasks_async(Tasks&amp;&amp;...)" href="#coroswait_tasks_asynctasks"></a></p>
<p dir="auto">This function operates similarly to <code>coros::wait_tasks</code>, with the primary distinction being that the async version schedules the tasks as soon as the
awaitable is created(when <code>coros::wait_tasks_async</code> is called).
Note that the async version <strong>does not support moving tasks between thread pools</strong>. When the awaitable is <code>co_await</code>-ed, one of two scenarios may occur:</p>
<ul dir="auto">
<li>If all tasks are already completed, the task is not suspended and continues execution immediately.</li>
<li>If at least one task has not yet finished, the task is suspended and will resume once all tasks have completed.</li>
</ul>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one(int val) {
    co_return val + 1;
}

coros::Task<int> add_to_number(int val) {
  coros::Task<int> task = add_one(val);
  auto awaitable = coros::wait_tasks_async(task);
  // Store awaitable into a variable and suspend later.
  //
  // Do some work.
  //
  // Checks if the task have already finished, if not it suspends the task.
  co_await awaitable;
  co_return *task;
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one</span>(<span>int</span> val) {
    <span>co_return</span> val + <span>1</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>add_to_number</span>(<span>int</span> val) {
  coros::Task&lt;<span>int</span>&gt; task = <span>add_one</span>(val);
  <span>auto</span> awaitable = <span>coros::wait_tasks_async</span>(task);
  <span><span>//</span> Store awaitable into a variable and suspend later.</span>
  <span><span>//</span></span>
  <span><span>//</span> Do some work.</span>
  <span><span>//</span></span>
  <span><span>//</span> Checks if the task have already finished, if not it suspends the task.</span>
  <span>co_await</span> awaitable;
  <span>co_return</span> *task;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::wait_tasks_async(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;)</code></h2><a id="user-content-coroswait_tasks_asyncstdvectorcorostaskt" aria-label="Permalink: coros::wait_tasks_async(std::vector<coros::Task<T>>&amp;)" href="#coroswait_tasks_asyncstdvectorcorostaskt"></a></p>
<p dir="auto">A <code>std::vector&lt;coros::Task&lt;T&gt;&gt;</code> can be passed into <code>coros::wait_tasks_async</code>, similar to its non-async counterpart.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_one_and_sum(int n) {
  std::vector<coros::Task<int>> vec;
  for (size_t i = 1; i <= n;i++) {
    // Constructs tasks with lambda function.
    vec.push_back(
      [](int num) -> coros::Task<int> {
        co_return num + 1;
      }(i)
    );
  }
  // Async version can also be directly co_await-ed.
  co_await  coros::wait_tasks_async(vec);
  
  int result_sum = 0;
  for (auto&amp; task : vec) {
    result_sum += *task;
  }

  co_return result_sum;
};"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_one_and_sum</span>(<span>int</span> n) {
  std::vector&lt;coros::Task&lt;<span>int</span>&gt;&gt; vec;
  <span>for</span> (<span>size_t</span> i = <span>1</span>; i &lt;= n;i++) {
    <span><span>//</span> Constructs tasks with lambda function.</span>
    vec.<span>push_back</span>(
      [](<span>int</span> num) -&gt; coros::Task&lt;<span>int</span>&gt; {
        <span>co_return</span> num + <span>1</span>;
      }(i)
    );
  }
  <span><span>//</span> Async version can also be directly co_await-ed.</span>
  <span>co_await</span>  <span>coros::wait_tasks_async</span>(vec);
  
  <span>int</span> result_sum = <span>0</span>;
  <span>for</span> (<span>auto</span>&amp; task : vec) {
    result_sum += *task;
  }

  <span>co_return</span> result_sum;
};</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Enqueueing tasks</h2><a id="user-content-enqueueing-tasks" aria-label="Permalink: Enqueueing tasks" href="#enqueueing-tasks"></a></p>
<p dir="auto">Contrary to to awaiting tasks with <code>coros::wait_tasks</code> or <code>coros::wait_tasks_async</code>
is <code>coros::enqueue_tasks</code>, which schedules tasks into a threadpool without waiting for them.
Given that these tasks are not awaited, their results cannot be retrieved and
any exception thrown inside these tasks is immediately rethrown.</p>
<p dir="auto">Unlike <code>coros::wait_tasks</code> or <code>coros::wait_tasks_async</code>, which suspend the current task until others are completed, <code>coros::enqueue_tasks</code>
schedules tasks into a threadpool without awaiting their completion.
Since these tasks are not awaited, their results cannot be retrieved directly, and any exceptions thrown within these tasks are immediately rethrown.</p>
<p dir="auto">Overloads for the <code>coros::enqueue_tasks</code> are :</p>
<ul dir="auto">
<li><code>enqueue_tasks(Tasks&amp;&amp;...)</code></li>
<li><code>enqueue_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></li>
<li><code>enqueue_tasks(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;&amp;)</code></li>
<li><code>enqueue_tasks(coros::ThreadPool&amp;, std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;&amp;)</code></li>
</ul>
<p dir="auto">All these functions are constrained to <strong>only accept r-value references</strong>
because the tasks are enqueued and not awaited, which means their <code>coros::Task&lt;T&gt;</code> objects are temporary(destroyed when finished) and cannot be used to retrieve values.</p>
<p dir="auto"><strong>To use <code>coros::enqueue_tasks</code> include the <code>#include "enqueue_tasks"</code> header.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::enqueue_tasks(Tasks&amp;&amp;...)</code></h2><a id="user-content-corosenqueue_taskstasks" aria-label="Permalink: coros::enqueue_tasks(Tasks&amp;&amp;...)" href="#corosenqueue_taskstasks"></a></p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="std::atomic<int> counter = 0;

coros::Task<void> add_one() {
  counter++; // Atomic operation to increase the counter.
  co_return;
}

coros::Task<void> increase_counter() {
  coros::enqueue_tasks(add_one(), add_one());
  co_return;
}

int main() {
  coros::ThreadPool tp{2};
  coros::Task<void> t = increase_counter();
  coros::start_sync(tp, t);
  // The resulting counter value can be 0, 1, or 2. The increase_counter
  // task is finished at this point; however, this does not guarantee
  // that the add_one tasks have also completed their execution.
  std::cout << counter.load() << std::endl;
}"><pre>std::atomic&lt;<span>int</span>&gt; counter = <span>0</span>;

coros::Task&lt;<span>void</span>&gt; <span>add_one</span>() {
  counter++; <span><span>//</span> Atomic operation to increase the counter.</span>
  <span>co_return</span>;
}

coros::Task&lt;<span>void</span>&gt; <span>increase_counter</span>() {
  <span>coros::enqueue_tasks</span>(<span>add_one</span>(), <span>add_one</span>());
  <span>co_return</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span>2</span>};
  coros::Task&lt;<span>void</span>&gt; t = <span>increase_counter</span>();
  <span>coros::start_sync</span>(tp, t);
  <span><span>//</span> The resulting counter value can be 0, 1, or 2. The increase_counter</span>
  <span><span>//</span> task is finished at this point; however, this does not guarantee</span>
  <span><span>//</span> that the add_one tasks have also completed their execution.</span>
  std::cout &lt;&lt; counter.<span>load</span>() &lt;&lt; std::endl;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::enqueue_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)</code></h2><a id="user-content-corosenqueue_taskscorosthreadpool-tasks" aria-label="Permalink: coros::enqueue_tasks(coros::ThreadPool&amp;, Tasks&amp;&amp;...)" href="#corosenqueue_taskscorosthreadpool-tasks"></a></p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="std::atomic<int> counter = 0;

coros::Task<void> add_one() {
  counter++;
  co_return;
}

coros::Task<void> increase_counter(coros::ThreadPool&amp; tp) {
  // Both tasks will be executed on the specified thread pool.
  coros::enqueue_tasks(tp, add_one(), add_one());
  co_return;
}

int main() {
  coros::ThreadPool tp{2};
  coros::ThreadPool tp2{2};
  coros::Task<void> t = increase_counter(tp2);
  coros::start_sync(tp, t);
  // The resulting counter value can be 0, 1, or 2. The increase_counter
  // task is finished at this point; however, this does not guarantee
  // that the add_one tasks have also completed their execution.
  std::cout << counter.load() << std::endl;
}"><pre>std::atomic&lt;<span>int</span>&gt; counter = <span>0</span>;

coros::Task&lt;<span>void</span>&gt; <span>add_one</span>() {
  counter++;
  <span>co_return</span>;
}

coros::Task&lt;<span>void</span>&gt; <span>increase_counter</span>(coros::ThreadPool&amp; tp) {
  <span><span>//</span> Both tasks will be executed on the specified thread pool.</span>
  <span>coros::enqueue_tasks</span>(tp, <span>add_one</span>(), <span>add_one</span>());
  <span>co_return</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span>2</span>};
  coros::ThreadPool tp2{<span>2</span>};
  coros::Task&lt;<span>void</span>&gt; t = <span>increase_counter</span>(tp2);
  <span>coros::start_sync</span>(tp, t);
  <span><span>//</span> The resulting counter value can be 0, 1, or 2. The increase_counter</span>
  <span><span>//</span> task is finished at this point; however, this does not guarantee</span>
  <span><span>//</span> that the add_one tasks have also completed their execution.</span>
  std::cout &lt;&lt; counter.<span>load</span>() &lt;&lt; std::endl;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::enqueue_tasks(std::vector&lt;coros::Task&lt;T&gt;&gt;&amp;&amp;)</code></h2><a id="user-content-corosenqueue_tasksstdvectorcorostaskt" aria-label="Permalink: coros::enqueue_tasks(std::vector<coros::Task<T>>&amp;&amp;)" href="#corosenqueue_tasksstdvectorcorostaskt"></a></p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="std::atomic<int> counter = 0;

coros::Task<void> add_one() {
  counter++;
  co_return;
}

coros::Task<void> increase_counter() {
  std::vector<coros::Task<void>> vec;
  vec.push_back(add_one());
  vec.push_back(add_one());
  coros::enqueue_tasks(std::move(vec));
  co_return;
}

int main() {
  coros::ThreadPool tp{2};
  coros::Task<void> t = increase_counter();
  coros::start_sync(tp, t);
  // The resulting counter value can be 0, 1, or 2. The increase_counter
  // task is finished at this point; however, this does not guarantee
  // that the add_one tasks have also completed their execution.
  std::cout << counter.load() << std::endl;
}"><pre>std::atomic&lt;<span>int</span>&gt; counter = <span>0</span>;

coros::Task&lt;<span>void</span>&gt; <span>add_one</span>() {
  counter++;
  <span>co_return</span>;
}

coros::Task&lt;<span>void</span>&gt; <span>increase_counter</span>() {
  std::vector&lt;coros::Task&lt;<span>void</span>&gt;&gt; vec;
  vec.<span>push_back</span>(<span>add_one</span>());
  vec.<span>push_back</span>(<span>add_one</span>());
  <span>coros::enqueue_tasks</span>(<span>std::move</span>(vec));
  <span>co_return</span>;
}

<span>int</span> <span>main</span>() {
  coros::ThreadPool tp{<span>2</span>};
  coros::Task&lt;<span>void</span>&gt; t = <span>increase_counter</span>();
  <span>coros::start_sync</span>(tp, t);
  <span><span>//</span> The resulting counter value can be 0, 1, or 2. The increase_counter</span>
  <span><span>//</span> task is finished at this point; however, this does not guarantee</span>
  <span><span>//</span> that the add_one tasks have also completed their execution.</span>
  std::cout &lt;&lt; counter.<span>load</span>() &lt;&lt; std::endl;
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Chaining tasks</h2><a id="user-content-chaining-tasks" aria-label="Permalink: Chaining tasks" href="#chaining-tasks"></a></p>
<p dir="auto">The Coros library supports a monadic operation with the <code>and_then</code> method, similar to <code>std::expected</code>, but with a key difference:
the Coros version executes the chain of tasks on a thread pool.
If an exception occurs during the chain, it is captured into the result, and the chain is halted. The resulting type of this operation is <code>std::expected</code>.
There are three overloads for this function:</p>
<ul dir="auto">
<li><code>coros::chain_tasks(T&amp;&amp;)</code>: Starts a chain of tasks with a value.</li>
<li><code>coros::chain_tasks(coros::Task&lt;T&gt;&amp;&amp;)</code>: Starts a chain of tasks with a
<strong>unstarted</strong> task</li>
<li><code>coros::chain_tasks(std::expected&lt;T, std::exception_ptr&gt;&amp;&amp;)</code>: Starts a chain
of tasks with an expected value</li>
</ul>
<p dir="auto"><strong>All of these overloads accept r-value references</strong>.
Given that this operation mimics monadic behavior, each task in the chain must accept exactly one argument.
Additionally, it must be possible to construct the argument of each subsequent task with the result from the previous task.</p>
<p dir="auto"><strong>To use <code>coros::chain_tasks</code> include the <code>#include "chain_tasks"</code> header.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::chain_tasks(T&amp;&amp;)</code></h2><a id="user-content-coroschain_taskst" aria-label="Permalink: coros::chain_tasks(T&amp;&amp;)" href="#coroschain_taskst"></a></p>
<p dir="auto">One way to start a task chain is by passing a starting value. The function requires an <code>r-value reference</code>, indicating that the starting value should be movable,
or copyable through r-value reference.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_two(int val) {
  co_return val + 2;
}

coros::Task<int> multiply_by_six(int val) {
  co_return val * 6;
}

coros::Task<int> compute_value() {
  // Each task must accept exactly one argument.
  // Each subsequent task's parameter must be
  // constructible from the previous task return value.
  std::expected<int, std::exception_ptr> res = 
    co_await coros::chain_tasks(3).and_then(add_two)
                                  .and_then(add_two)
                                  .and_then(multiply_by_six);
  if (res.has_value()) {
    // Return the computed value if the chain completes successfully.
    co_return *res;
  } else {
    // In case the chain did not successfully finish, an exception occurred.
    co_return -1;
  }
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_two</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>2</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>multiply_by_six</span>(<span>int</span> val) {
  <span>co_return</span> val * <span>6</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>compute_value</span>() {
  <span><span>//</span> Each task must accept exactly one argument.</span>
  <span><span>//</span> Each subsequent task's parameter must be</span>
  <span><span>//</span> constructible from the previous task return value.</span>
  std::expected&lt;<span>int</span>, std::exception_ptr&gt; res = 
    <span>co_await</span> <span>coros::chain_tasks</span>(<span>3</span>).<span>and_then</span>(add_two)
                                  .<span>and_then</span>(add_two)
                                  .<span>and_then</span>(multiply_by_six);
  <span>if</span> (res.<span>has_value</span>()) {
    <span><span>//</span> Return the computed value if the chain completes successfully.</span>
    <span>co_return</span> *res;
  } <span>else</span> {
    <span><span>//</span> In case the chain did not successfully finish, an exception occurred.</span>
    <span>co_return</span> -<span>1</span>;
  }
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::chain_tasks(coros::Task&lt;T&gt;&amp;&amp;)</code></h2><a id="user-content-coroschain_taskscorostaskt" aria-label="Permalink: coros::chain_tasks(coros::Task<T>&amp;&amp;)" href="#coroschain_taskscorostaskt"></a></p>
<p dir="auto">It is also possible to start a chain with <strong>unstarted</strong> <code>coros::task&lt;T&gt;</code> object.
The unstarted task will be executed first and then each subsequent task.</p>
<p dir="auto">It is possible to initiate a task chain with an unstarted <code>coros::Task&lt;T&gt;</code>.
The chain will start by executing this unstarted task, followed by each subsequent task in the sequence.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_two(int val) {
  co_return val + 2;
}

coros::Task<int> multiply_by_six(int val) {
  co_return val * 6;
}

coros::Task<int> return_three() {
  co_return 3;
}

coros::Task<int> compute_value() {
  // Each task must accept exactly  most one argument.
  // Each subsequent task's parameter must be
  // constructible from the previous task return value.
  std::expected<int, std::exception_ptr> res = 
    co_await coros::chain_tasks(return_three()) // Initializes the chain with a task that returns 3.
        .and_then(add_two)  // First subsequent operation, adds two to the value 3.
        .and_then(add_two)
        .and_then(multiply_by_six);

  if (res.has_value()) {
    // Return the computed value if the chain completes successfully.
    co_return *res;
  } else {
    // In case the chain did not successfully finish, an exception occurred.
    co_return -1;
  }
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_two</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>2</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>multiply_by_six</span>(<span>int</span> val) {
  <span>co_return</span> val * <span>6</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>return_three</span>() {
  <span>co_return</span> <span>3</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>compute_value</span>() {
  <span><span>//</span> Each task must accept exactly  most one argument.</span>
  <span><span>//</span> Each subsequent task's parameter must be</span>
  <span><span>//</span> constructible from the previous task return value.</span>
  std::expected&lt;<span>int</span>, std::exception_ptr&gt; res = 
    <span>co_await</span> <span>coros::chain_tasks</span>(<span>return_three</span>()) <span><span>//</span> Initializes the chain with a task that returns 3.</span>
        .<span>and_then</span>(add_two)  <span><span>//</span> First subsequent operation, adds two to the value 3.</span>
        .<span>and_then</span>(add_two)
        .<span>and_then</span>(multiply_by_six);

  <span>if</span> (res.<span>has_value</span>()) {
    <span><span>//</span> Return the computed value if the chain completes successfully.</span>
    <span>co_return</span> *res;
  } <span>else</span> {
    <span><span>//</span> In case the chain did not successfully finish, an exception occurred.</span>
    <span>co_return</span> -<span>1</span>;
  }
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>coros::chain_tasks(std::expected&lt;T, std::exception_ptr&gt;&amp;&amp;)</code></h2><a id="user-content-coroschain_tasksstdexpectedt-stdexception_ptr" aria-label="Permalink: coros::chain_tasks(std::expected<T, std::exception_ptr>&amp;&amp;)" href="#coroschain_tasksstdexpectedt-stdexception_ptr"></a></p>
<p dir="auto">This overload is particularly useful when you need to start a new chain from the result of a previous chain,
potentially extending the computation or handling with new tasks.</p>
<details>
<summary> code example </summary>
<div dir="auto" data-snippet-clipboard-copy-content="coros::Task<int> add_two(int val) {
  co_return val + 2;
}

coros::Task<int> multiply_by_six(int val) {
  co_return val * 6;
}

coros::Task<int> return_three() {
  co_return 3;
}

coros::Task<int> compute_value() {
  std::expected<int, std::exception_ptr> res = 
    co_await coros::chain_tasks(return_three()).and_then(add_two)
                                               .and_then(add_two)
                                               .and_then(multiply_by_six);
  if (res.has_value()) {
    // Return the computed value if the chain completes successfully.
    auto another_res = co_await coros::chain_tasks(std::move(res)).and_then(add_two);
    co_return *another_res; // returns 44
  } else {
    // In case the chain did not successfully finish, an exception occurred.
    co_return -1;
  }
}"><pre>coros::Task&lt;<span>int</span>&gt; <span>add_two</span>(<span>int</span> val) {
  <span>co_return</span> val + <span>2</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>multiply_by_six</span>(<span>int</span> val) {
  <span>co_return</span> val * <span>6</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>return_three</span>() {
  <span>co_return</span> <span>3</span>;
}

coros::Task&lt;<span>int</span>&gt; <span>compute_value</span>() {
  std::expected&lt;<span>int</span>, std::exception_ptr&gt; res = 
    <span>co_await</span> <span>coros::chain_tasks</span>(<span>return_three</span>()).<span>and_then</span>(add_two)
                                               .<span>and_then</span>(add_two)
                                               .<span>and_then</span>(multiply_by_six);
  <span>if</span> (res.<span>has_value</span>()) {
    <span><span>//</span> Return the computed value if the chain completes successfully.</span>
    <span>auto</span> another_res = <span>co_await</span> <span>coros::chain_tasks</span>(<span>std::move</span>(res)).<span>and_then</span>(add_two);
    <span>co_return</span> *another_res; <span><span>//</span> returns 44</span>
  } <span>else</span> {
    <span><span>//</span> In case the chain did not successfully finish, an exception occurred.</span>
    <span>co_return</span> -<span>1</span>;
  }
}</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">References</h2><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<ul dir="auto">
<li><a href="https://github.com/cameron314/concurrentqueue?tab=readme-ov-file">Concurrent deque</a>: Used in the project as part of the scheduling algorithm.</li>
<li><a href="https://inria.hal.science/hal-00802885/document" rel="nofollow">Deque implementation</a>: Used as a reference for implementing our own double-ended queue.</li>
<li><a href="https://lewissbaker.github.io/" rel="nofollow">Lewis Baker's blog</a>: Provides excellent explanations of coroutines.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licence</h2><a id="user-content-licence" aria-label="Permalink: Licence" href="#licence"></a></p>
<p dir="auto">Boost Software License - Version 1.0 - August 17th, 2003</p>
<p dir="auto">Permission is hereby granted, free of charge, to any person or organization
obtaining a copy of the software and accompanying documentation covered by
this license (the "Software") to use, reproduce, display, distribute,
execute, and transmit the Software, and to prepare derivative works of the
Software, and to permit third-parties to whom the Software is furnished to
do so, all subject to the following:</p>
<p dir="auto">The copyright notices in the Software and this entire statement, including
the above license grant, this restriction and the following disclaimer,
must be included in all copies of the Software, in whole or in part, and
all derivative works of the Software, unless such copies or derivative
works are solely in the form of machine-executable object code generated by
a source language processor.</p>
<p dir="auto">THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>