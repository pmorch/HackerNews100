<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 26 Nov 2024 06:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Fly.io outage (restoration in progress) (162 pts)]]></title>
            <link>https://status.flyio.net</link>
            <guid>42241851</guid>
            <pubDate>Tue, 26 Nov 2024 01:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://status.flyio.net">https://status.flyio.net</a>, See on <a href="https://news.ycombinator.com/item?id=42241851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<p><span>
      AMS - Amsterdam, Netherlands
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      ARN - Stockholm, Sweden
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      ATL - Atlanta, Georgia (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      BOG - Bogotá, Colombia
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      BOM - Mumbai, India
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      CDG - Paris, France
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      DEN - Denver, Colorado (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      DFW - Dallas, Texas (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      EZE - Ezeiza, Argentina
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      FRA - Frankfurt, Germany
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<div data-component-id="qsy0b4zwvsvw" data-component-status="operational" data-js-hook="">

   <p><span>
      GDL - Guadalajara, Mexico
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<p><span>
      GRU - Sao Paulo, Brazil
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      HKG - Hong Kong
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      IAD - Ashburn, Virginia (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      JNB - Johannesburg, South Africa
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      LAX - Los Angeles, California (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      LHR - London, United Kingdom
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      MAD - Madrid, Spain
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      MEL - Melbourne, Australia
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      MIA - Miami, Florida (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      NRT - Tokyo, Japan
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      ORD - Chicago, Illinois (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      OTP - Bucharest, Romania
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      QRO - Querétaro, Mexico
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      SCL - Santiago, Chile
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      SEA - Seattle, Washington (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      SIN - Singapore
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      SJC - San Jose, California (US)
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      SYD - Sydney, Australia
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<p><span>
      YYZ - Toronto, Canada
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span>

</p>

      
<div data-component-id="q94911jjt9cn" data-component-status="operational" data-js-hook="">

   <p><span>
      GIG - Rio de Janeiro, Brazil
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon S3 Adds Put-If-Match (Compare-and-Swap) (288 pts)]]></title>
            <link>https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-functionality-conditional-writes/</link>
            <guid>42240678</guid>
            <pubDate>Mon, 25 Nov 2024 22:11:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-functionality-conditional-writes/">https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-functionality-conditional-writes/</a>, See on <a href="https://news.ycombinator.com/item?id=42240678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="aws-page-content" data-page-alert-target="true"> 
   <main id="aws-page-content-main" role="main" tabindex="-1"> 
    <div data-eb-tpl-root="" data-reactroot="" data-eb-tpl-n="awsm-whats-new/whats-new-post" data-eb-tpl-v="1.0.0" data-eb-ce="" data-eb-c-scope="d105f9bc-63d3-11ee-8c99-0242ac120002" data-eb-d-scope="DIRECTORIES" data-eb-locale="en-US" data-eb-1e70fe18="" data-eb-ssr-ce="" data-eb-tpl-ns="awsmWhatsNew" data-eb-slot="d105f9bc-63d3-11ee-8c99-0242ac120002" data-eb-slot-meta="{'version':'1.0','slotId':'d105f9bc-63d3-11ee-8c99-0242ac120002','experienceId':'d105f9bc-63d3-11ee-8c99-0242ac120002','allowBlank':false,'hasAltExp':false,'isRTR':false,'filters':{'limit':1,'query':'id \u003d \'p169217422\''}}"> 
         <main> 
           
           
          <div><p>Amazon S3 can now perform conditional writes that evaluate if an object is unmodified before updating it. This helps you coordinate simultaneous writes to the same object and prevents multiple concurrent writers from unintentionally overwriting the object without knowing the state of its content. You can use this capability by providing the ETag of an object using S3 PutObject or CompleteMultipartUpload API requests in both S3 general purpose and directory buckets.</p><p>  Conditional writes simplify how distributed applications with multiple clients concurrently update data across shared datasets. Similar to using the <a href="https://aws.amazon.com/about-aws/whats-new/2024/08/amazon-s3-conditional-writes/" target="_blank">HTTP if-none-match conditional header to check for the existence of an object before creating it</a>, clients can now perform conditional-write checks on an object’s Etag, which reflects changes to the object, by specifying it via the HTTP if-match header in the API request. S3 then evaluates if the object's ETag matches the value provided in the API request before committing the write and prevents your clients from overwriting the object until the condition is satisfied. This new conditional header can help improve the efficiency of your large-scale analytics, distributed machine learning, and other highly parallelized workloads by reliably offloading compare and swap operations to S3.</p><p>  This new conditional-write functionality is available at no additional charge in all AWS Regions. You can use the AWS SDK, API, or CLI to perform conditional writes. To learn more about conditional writes, visit the <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/conditional-requests.html" target="_blank">S3 User Guide</a>.</p></div> 
         </main> 
        </div> 
   </main> 
  </div><div data-lb-comp="modal" data-lb-modal-id="ie-deprecation-msg" data-ie10-deprecation-msg="You are using an outdated browser. Please upgrade to a modern browser to improve your experience."> 
      
     <p>
       AWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. 
      <a href="https://aws.amazon.com/blogs/aws/heads-up-aws-support-for-internet-explorer-11-is-ending/" rel="noopener">Learn more »</a> 
     </p> 
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do you need ID to read the REAL-ID rules? (196 pts)]]></title>
            <link>https://papersplease.org/wp/2024/11/25/do-you-need-id-to-read-the-real-id-rules/</link>
            <guid>42239952</guid>
            <pubDate>Mon, 25 Nov 2024 20:40:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papersplease.org/wp/2024/11/25/do-you-need-id-to-read-the-real-id-rules/">https://papersplease.org/wp/2024/11/25/do-you-need-id-to-read-the-real-id-rules/</a>, See on <a href="https://news.ycombinator.com/item?id=42239952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><a href="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop.jpg"><img loading="lazy" src="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop-1024x485.jpg" alt="" width="960" height="455" srcset="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop-1024x485.jpg 1024w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop-300x142.jpg 300w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop-768x363.jpg 768w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop-1536x727.jpg 1536w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-gatehouse-crop.jpg 2016w" sizes="(max-width: 960px) 100vw, 960px"></a><em>[“The welcoming, friendly and visually pleasing appearance” of the TSA’s headquarters at 6595 Springfield Center Drive, Springfield, VA.]</em></p>
<p>We spent most of a day last week outside the headquarters of the Transportation Security Administration (TSA), trying and failing to find out what the rules are for the <a href="https://papersplease.org/wp/2024/11/04/tsa-launches-smartphone-based-digital-id-scheme/">TSA’s new digital-ID scheme</a>.&nbsp; What we did learn is that, by TSA policy and practice, you can’t read the <a href="https://papersplease.org/wp/category/real-id/">REAL-ID</a> rules, get to the TSA’s front door, or talk to any TSA staff unless you already have ID, bring it with you, and show it to the private guards outside the TSA’s gates.</p>
<p>The problems we have faced just trying to get access to the text of the TSA’s rules raise issuess about (recursive) incorporation by reference of third-party, nongovernmental text in regulations, secret law, and access to Federal services and rights by those without ID, as well as the underlying issues of REAL-ID, mobile driver’s licenses, and digital IDs.</p>
<p>In late October, <a href="https://papersplease.org/wp/2024/11/04/tsa-launches-smartphone-based-digital-id-scheme/">as we’ve previously reported</a>, the TSA issued a <a href="https://www.govinfo.gov/content/pkg/FR-2024-10-25/pdf/2024-23881.pdf">final rule</a> establishing “standards” for smartphone-based digital IDs that would be deemed by the TSA to comply with the <a href="https://papersplease.org/wp/category/real-id/">REAL-ID Act of 2005</a>. These mobile driver’s licenses (mDLs) will be issued by state driver’s license agencies, but the standards incorporated into the TSA rule require that they be deployed through smartphone platforms (i.e. Google and/or Apple) and operate through government apps that collect photos of users and log usage of these credentials.</p>
<p>The standards themselves — the meat of the TSA’s rule — weren’t published in the <em>Federal Register</em> or made public either when the rule was <a href="https://papersplease.org/wp/2023/10/16/the-tsa-wants-to-put-a-government-tracking-app-on-your-smartphone/">proposed</a> or when it&nbsp; was <a href="https://papersplease.org/wp/2024/11/04/tsa-launches-smartphone-based-digital-id-scheme/">finalized</a>. Instead, thousands of pages of documents from private third parties were <a href="https://www.archives.gov/federal-register/write/ibr">incorporated by reference</a> into the TSA’s rules, giving them the force of law, on the basis of false and fraudulent claims — the falsehood of which was easy for anyone who checked to verify — that they were “reasonably accessible” to affected individuals.</p>
<p><a href="https://papersplease.org/wp/category/secret-law/">Secret laws</a> are <em>per se</em> a violation of due process, and should be<em> per se</em> null and void. How can it be that “ignorance of the law is no excuse” if the government has kept you ignorant of the law, even when you try to find out what the law says?</p>
<p>You shouldn’t need ID to read the law, just as you shouldn’t need ID to travel by common carrier. But the TSA doesn’t seem to have read the Constitution.</p>
<p><span id="more-19215"></span>In its <a href="https://www.govinfo.gov/content/pkg/FR-2024-10-25/pdf/2024-23881.pdf">final</a> rule, the TSA repeated some of the same <a href="https://papersplease.org/wp/2024/11/04/tsa-launches-smartphone-based-digital-id-scheme/">easily disproved lies</a> about the availability of the material incorporated by reference in the rule that <a href="https://papersplease.org/wp/2023/10/16/the-tsa-wants-to-put-a-government-tracking-app-on-your-smartphone/">it had made in its earlier Notice of Proposed Rulemaking</a> (NPRM). But the TSA also made a new claim that the material incorporated by reference in the rule was available for public inspection, by appointment, both at the Office of the Federal Register (a component of the National Archives and Records Administration) and at TSA Headquarters:</p>
<blockquote><p>All approved incorporation by reference (IBR) material is available for inspection at the Transportation Security Administration (TSA) and at the National Archives and Records Administration (NARA). Please contact TSA at Transportation Security Administration, Attn.: OS/ESVP/REAL ID Program, TSA Mail Stop 6051, 6595 Springfield Center Dr., Springfield, VA 20598–6051, (866) 289–9673, or visit www.tsa.gov. You may also contact the REAL ID Program Office at REALID-mDLwaiver@tsa.dhs.gov or visit www.tsa.gov/REAL-ID/mDL. For information on the availability of this material at NARA, visit www.archives.gov/federal-register/cfr/ibr-locations.html or email fr.inspection@nara.gov.</p></blockquote>
<p>We immediately contacted both NARA and the TSA at these email addresses, requesting to inspect the material incorporated by reference in this rule.</p>
<p>NARA told us that this material isn’t stored at the office where it will (eventually, if and when it is found) be made available by NARA for public inspection. It might take up to six weeks, possibly longer, to locate and retrieve from offsite storage:</p>
<blockquote><p>I don’t have an estimated date for your appointment. The system we had for public access is not working and we are working to replace it. But how long that will take depends on our parent agency (the National Archives and Records Administration)….</p>
<p>If you wish to inspect all of the material listed in 6 CFR 37.4… it is in storage at a Federal Records Center. We will have to contact the FRC to get the material returned to us. That process generally can take up to 6 weeks; however, given the upcoming change in administration (and increased workloads for all involved), it could take longer.</p></blockquote>
<p>If it might take months for even the Office of the Federal Register to find the text which has been incorporated in Federal regulations and has the force of law, there’s a problem. But NARA says that whether documents incorporated in regulations are reasonably available is determined by whether they are available from the agency which promulgated the regulations — in this case, the TSA — and not by whether they are available from NARA.</p>
<p>The TSA’s initial answer seemed more promising:</p>
<blockquote><p>We would be delighted to coordinate a visit to TSA so you may examine the materials requested and will work to provide you with information on how to access our facilities soon.</p></blockquote>
<p>After some back and forth by email, I arranged an appointment at the TSA’s headquarters at 9 a.m. on Monday, November 18th, for an escorted visit to inspect the documents incorporated by reference in the TSA’s “mobile driver’s license” rule. I was told that to inspect the rules I would have to provide my Social Security number and date of birth, “so that you can be cleared through Security.” I did so, reluctantly.</p>
<p>Despite my efforts to avoid any surprises and anticipate any problems, my visit didn’t go well.</p>
<p>The TSA occupies a <a href="https://www.bizjournals.com/washington/news/2021/05/27/inside-the-new-tsa-headquarters.html">purpose-built but privately owned new building</a> in Springfield, VA, an hour outside Washington, DC, and a short-ish walk past the Washington Metro Transit Police Academy from the last stop on one of the Washington Metrorail lines. (There’s a <a href="https://visualconstruction.com/TSA/">virtual tour here</a> of some parts of the interior that I never got to see.)</p>
<p><a href="https://www.lsginc.com/lsg_projects/transportation-security-administration-headquarters/">According to the architects</a>, the fortifications around&nbsp; the building were designed to<em> look</em> “welcoming” and “friendly”, while actually keeping the building secure against public access:</p>
<blockquote><p>LSG’s involvement was focused on the design of the entrance plaza and arrival sequence along the North facing public entrance of the project… LSG assisted with integration of elaborate security requirements in the site design. Security measures included K12 barriers, fences, gates, cameras and a specific vehicular circulation pattern for employees, visitors and services, etc. LSG’s focus was to integrate the security measures necessary without compromising the welcoming, friendly and visually pleasing appearance expected for TSA Headquarters.</p></blockquote>
<p>I arrived at the guardhouse outside the gate in the TSA’s perimeter fence at 8:45 a.m., to allow time for whatever security theater might be required before my 9 a.m. appointment.</p>
<p>I described what happened next in an email message I sent shortly afterward:</p>
<blockquote><p>I am outside the entrance to your building, but a guard who refuses to give his name with a badge that says “Golden Services Security” refuses either to admit me without ID, which I don’t have, or attempt to contact anyone with the TSA.</p>
<p>I specifically asked you, in my email message of November 1, to advise me of any access procedures for individuals without ID, who are obviously in the class of individuals impacted by the rules I want to access. You did not advise me of any ID requirement.</p>
<p>I request that you either admit me to access the rules, as scheduled, or provide formal notice of your decision to deny me access identifying by name and title the decision maker, the basis for the denial including any rules relied on, and any available procedures for administrative review of that decision, so that I can attempt to exercise any available administrative appeals before returning to California empty-handed, having wasted more time and money in a diligent but unsuccessful last-resort attempt to access these rules after all other access methods claimed by you proved to be unavailable.</p>
<p>As I noted in my first email message to you, it is impossible to reach you at the phone number specified in the final rule for access requests. You have provided me with no other phone number, and the guard refused my request that they call whatever point of<br>
contact or escort is listed on the visitor list.</p>
<p>I will wait outside the entrance to your building for one hour, until 10 am, unless I am ordered to leave.</p></blockquote>
<p>I waited on an uncomfortable metal bench, exposed to the elements, just outside the fence. At 9:57 a.m., as I was about to give up and leave, someone called me from inside the building. They told me they had been assigned to escort me and were waiting for me at the “Visitor Center” inside the building. I told them, as I had said in my email message, that the guard wouldn’t let me get to the building without ID, which (as I had told them in advance) I didn’t have. They said they could only escort me once I got to the Visitor Center inside the building, and that they didn’t have “clearance” to come out to the fenceline to meet me. Catch-22.</p>
<p>Eventually they conferenced in — at their initiative — Mr. Anurag Maheshwary, an attorney in the Office of the Chief Counsel of the TSA. Mr. Maheshwary was <a href="https://www.govinfo.gov/content/pkg/FR-2024-10-25/pdf/2024-23881.pdf">listed in the <em>Federal Register</em></a> as the point of contact for legal questions about the mobile driver’s license (mDL) rule.</p>
<p>Mr. Maheshwary professed surprise and disbelief that I didn’t have ID, despite having been copied on my earlier queries about access procedures and protocols for people without ID. “What ID did you use to fly here from California? You must have ID.” (Wrong, even if I had flown, which I hadn’t said I had done.)</p>
<p>When I repeated the request I had made in my email message that, if I was to be denied access to the documents incorporated in the TSA’s rules, I be given formal notice of that denial, Mr. Maheshwary immediately demanded that the person who had called me, and had conferenced him in, disconnect him from the call. “You’ve conferenced in the wrong person!” He repeated that demand and hung up when she called back and tried again to get him to talk to me.</p>
<p>A little later, as I was again preparing to give up and leave, the same person called me again to say that, “We’re trying to work out how to get you access to the documents.”</p>
<p>As with travel by common carrier, the TSA wants to create the impression that ID is required to read the text of its regulations, and acts in practice as though ID is required, but knows that it would have a hard time defending such a policy in court. So the TSA doesn’t put this policy in writing, and backs down (or at least claims that some alternative, albeit an inconvenient one, is available for people without ID) when confronted with people without ID who it perceives as sufficiently able and willing to assert their rights.</p>
<p>Shortly after 11 a.m., by which time I had been sitting on the <a href="https://www.urbandictionary.com/define.php?term=Group%20W%20Bench">Group W bench</a> for more than two hours, a TSA staffer came out with two large TSA-logo tote bags of documents.</p>
<div id="attachment_19216"><p><a href="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop.jpg"><img aria-describedby="caption-attachment-19216" loading="lazy" src="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop-485x1024.jpg" alt="" width="379" height="800" srcset="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop-485x1024.jpg 485w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop-142x300.jpg 142w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop-768x1623.jpg 768w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop-727x1536.jpg 727w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-minder-crop.jpg 954w" sizes="(max-width: 379px) 100vw, 379px"></a></p><p id="caption-attachment-19216">[The face of the TSA]</p></div><div id="attachment_19218"><p><a href="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop.jpg"><img aria-describedby="caption-attachment-19218" loading="lazy" src="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop-535x1024.jpg" alt="" width="418" height="800" srcset="https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop-535x1024.jpg 535w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop-157x300.jpg 157w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop-768x1470.jpg 768w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop-802x1536.jpg 802w, https://papersplease.org/wp/wp-content/uploads/2024/11/TSA-documents-crop.jpg 954w" sizes="(max-width: 418px) 100vw, 418px"></a></p><p id="caption-attachment-19218">[Some of the documents I was allowed to look at, but not to take with me.]</p></div>&nbsp;
<p><br clear="all">One bag, which I was allowed to take with me, contained about ten pounds of copies of documents that are (purportedly) freely available online. Getting these documents directly from the TSA allowed me to be certain that they matched — or at least were claimed by the TSA to match — the text incorporated by reference into the TSA’s rules. That wouldn’t be possible with copies obtained from a private publisher or other third party, who would be neither able, willing, nor required to warrant that the copies they provided or sold matched what the TSA had depostied with the Office of the Federal Register. So that take-home bag had some official significance, but held no big surprises.</p>
<p>The other bag, only slightly smaller, contained copies of documents that the TSA conceded weren’t freely available, but that it wouldn’t allow me to take with me. I was alloted not more than three hours to inspect them, sitting on a bench outside with my TSA minder sitting at the other end of the bench (equally uncomfortably, I presume) to make sure I didn’t try to take away any of the non-public documents included in the TSA’s rules.</p>
<p>After another hour, around noon, my minder found another bench at a bus stop nearby that, while equally uncomfortable for us both, was at least partially shielded from the wind.</p>
<p>After yet another hour, a little after 1 p.m. — by which time I needed a toilet and was getting increasingly cold, not having dressed to spend five hours outside —&nbsp; my TSA minder (who had been busy texting persons unknown on his phone) told me that arrangements had been made for me to be escorted into the building to continue my reading of the bag of non-public documents. I was given no explanation as to why this hadn’t been done four hours earlier when I arrived for my scheduled appointment.</p>
<p>An armed guard came out, and he and the business-suited minder who had been sitting on the bench with me escorted me through the gate in the fence and across no-man’s-land to the entrance to the building. After going theough a metal detector, I was escorted to a restroom (at least they waited outside) and then back out past the metal detector to a conference room just inside the outer entry door that appeared to be there specifically for the purpose of meetings with visitors not cleared to go further into the building.</p>
<p>In the limited time that I was allowed to spend with these documents, I was able to confirm that they require that mDL credentials be “provisioned” through a TSA-approved app on a TSA-approved device, with that device biometrically “bound” to an individual. The process of “presenting” a digital ID will be a four-way interaction between the&nbsp; individual, the app (it’s unclear whether or how the user will be able to authenticate the app or know what it is doing), functions on the device to collect biometrics (controlled, in all likelihood, by an operating system with root privileges whose actions can’t be monitored or controlled by the individual), and the credential-issuing driver’s license agency.</p>
<p>mDL apps will be required to log each time a digital ID is presented, and to whom. This is described as a measure to protect ID-holders’ privacy, despite the obvious risk posed by police or others being able to know when and to whom you have shown your ID. If you use your digital ID for <a href="https://papersplease.org/wp/2024/11/05/what-will-the-future-bring-for-id-demands/">age verificaiton</a> to show that you are old enough ton be allowed to access adult information about sexual health or <a href="https://papersplease.org/wp/2022/09/22/freedom-to-travel-to-get-an-abortion/">abortion</a>, that fact will be logged on your device.</p>
<p>Supposely these logs will be available only to the device owner. But in reality, they will also be available to anyone who seizes the device while it is unlocked, cracks the device lock with forensic or criminal tools, or forces an individual — legally or illegally — to unlock it.</p>
<p>The TSA is already issuing <a href="https://www.dhs.gov/sites/default/files/2024-03/24_0315_st_mdl_investigative_aid_journey.pdf#page=4">guidance to other law enforcement agencies</a> on the information about the usage of these digital IDs that may be available to and via Google or Apple.</p>
<p>But there’s more. To my dismay, if not surprise, I found that the non-public documents incorporated by reference in the TSA’s rules themselves incorporate by reference<em> other</em> documents, many of them also non-public.</p>
<p>How mnay levels of recursion do we have to follow to get to the bottom of the TSA’s rules? <a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down">It’s turtles all the way down.</a></p>
<p>After leaving the area, I sent the following message to the TSA:</p>
<blockquote><p>Yesterday we finally saw the non-public documents incorporated by reference in the mDL NPRM and Final Rule. It was immediately apparent from the volume and technical nature of this material that understanding, much less assessing or responding to, these documents would require at least several weeks and consultation with technical specialists who are not necessarily available or willing to travel to Springfield.</p>
<p>It is clear that neither we nor other members of the public have been provided with “reasonable” access to this material.</p>
<p>It also appears that your agency knew when you designated your building in Springfield as the location where these documents were purportedly accessible to the public [that it] was encircled by a guarded fence, and that members of the public without ID were not permitted even to approach the building or speak with any TSA employee. Having fenced yourself off from the public, it is fraudulent[,] and compelling evidence of bad faith[,] to claim that this inaccessible building is accessible to the public.</p>
<p>You cannot claim to have been taken by surprise. In our comments on the false and fraudulent claim in the NPRM that these documents were available for inspection at some unspecified DHS facility, we specifically raised the potential problem of access or entry without ID:</p>
<p>“Access procedures are especially critical with respect to this proposed rule because ‘the class of persons affected’ – the relevant category pursuant to 1 CFR § 51.7(3), as quoted above – obviously includes individuals who do not have ID deemed compliant with the REAL-ID Act.</p>
<p>“It is unclear what, if any, procedures have been established to enable individuals who do not have ID deemed compliant with the REAL-ID Act to obtain access to the relevant premises at ‘DHS Headquarters’, at whichever of the many possible locations that might be, to inspect the material proposed to be incorporated by reference into the proposed rule.</p>
<p>“Individuals seeking to review this material can’t simply go the specifiedaddress, since no address is specified, even if they would be allowed in the door, which they probably wouldn’t.”</p>
<p>We diligently sought to avoid these problems. We asked explicitly, in writing, in advance of our appointment, whether there was any protocol for access to this building by people without ID. We also asked for a point of contact and phone number we could call in case of access problems. We were provided with no point of contact or phone number, and were told of no ID requirement.</p>
<p>Individuals may need a license from a government agency to operate a motor vehicle. They do not need a license to read the law or to travel by common carrier. If the TSA or any other agency proposed a rule to require ID to read the law or travel by common carrier, we and many others would oppose it, for multiple reasons. But no such rules have been promulgated.</p>
<p>One of your staff asked me yesterday how I had traveled to the DC area, whether I had traveled by air, and whether I has shown any ID to do so. As a matter of principle and personal security, I do not wish to discuss my travel history, modes, or plans with you, and I am not required to do so. But the consistent position of your agency in litigation has been that no Federal law or regulation requires airline passengers to have, to carry, or to show ID. The responses by your agency to some of our FOIA requests confirm that, as you know, <a href="https://papersplease.org/wp/2022/03/15/how-many-people-fly-without-real-id/">people fly without ID every day</a>.</p>
<p>“The public” includes individuals who do not have ID, and to be accessible to the public, documents or services need to be accessible to those without ID.</p>
<p>After two hours waiting outside your gatehouse, getting increasingly cold, I was able to leaf through some of the non-public IBRs documents in the brief and inadequate time available. But the material I was allowed to look at was incomplete. Many of the non-public documents incorporated by reference in the Final Rule themselves incorporate by reference additional documents, some of them also non-public, which I was not shown. I have attached to this message, as a non-exhaustive example, the <a href="https://papersplease.org/wp/wp-content/uploads/2024/11/recursive-IBR.pdf">list of documents</a> incorporated by reference in one of the ISO/IEC documents incorporated by reference in the Final Rule.</p>
<p>By the explicit terms of the documents IBRd in the final rule, these *additional* documents constitute part of, are essential to understanding, and are included in the requirements of the documents IBRd in the rule.</p>
<p>Just as the IBRd documents form part of the rule and have the force of law, all of the these documents IBRd in the documents IBRd in the rule form part of the rule and have the force of law. Compliance with these other recursively IBRd documents is required for compliance with the rule.</p>
<p>All such documents, at any level of recursion, are included in our right of access and our request for access to all documents IBRd in the rule….</p>
<p>Presumably you have them in house, since by their own explicit terms they are essential to understanding, and form part of, the documents IBRd in your rules. If you don’t have them available for me to look at today, I request that you make them accessible to the public without my having to return to the DC area.</p></blockquote>
<p>We’ve been promised a response from the TSA by December 2nd. In the meantime, we have reported to the Office of the Federal Register that many of the documents incorporated by reference in the TSA’s mDL rule, including those recursively incorporated by reference, are not reasonably available from the TSA. The approval for incorporation by reference of these documents should be rescinded, and the rule should be withdrawn.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Short Introduction to Automotive Lidar Technology (118 pts)]]></title>
            <link>https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar</link>
            <guid>42239721</guid>
            <pubDate>Mon, 25 Nov 2024 20:12:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar">https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar</a>, See on <a href="https://news.ycombinator.com/item?id=42239721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Ubiquitous adoption of lidar in self driving cars needs one major thing: lower cost. </p><p><span>Lidar has proven to be a capable technology for </span><a href="https://www.sae.org/blog/sae-j3016-update" rel="">level 4</a><span> autonomous driving, and is already used in self driving taxis by Waymo and Cruise. But the spinning lidar domes on top of these cars cost thousands of dollars, and that number needs to drop by at least an order of magnitude.</span></p><p><span>There are </span><a href="https://tracxn.com/d/companies/lidar/__S0h0aWT4FqieGUvRDUJ0Jly7aZjCfw3Yk5P2sJUm04Y/competitors#competitive-landscape" rel="">over 140 startups</a><span> in the lidar space looking to make that happen and more.</span></p><p><strong>In this post, we will cover the basics of automotive lidar technology:</strong></p><ul><li><p>Lidar for autonomous vehicles</p></li><li><p>Wavelength of operation</p></li><li><p>Photodetectors</p></li><li><p>Ranging techniques</p></li><li><p>Mechanical lidar</p><ul><li><p>Scanning systems</p></li><li><p>MEMS mirrors</p></li></ul></li><li><p>Solid-state lidar</p><ul><li><p>Flash lidar</p></li><li><p>Optical phased arrays</p></li></ul></li><li><p>References</p></li></ul><p><strong>Read time</strong><span>: 12 mins</span></p><p><em>The post may be too long for email. Please read it online.</em></p><p>Lidar stands for Light Detection and Ranging and is a method where infrared laser light is used to measure the distance to a remote object. This technology is not new. For years, it has been used for imaging vegetation, urban terrain, hidden archeological sites, building construction and recently, in augmented reality. Its particular superpower is that it can generate high resolution images of its surroundings much better than radar can. While lidar and radar are fundamentally similar in operation, the use of shorter wavelengths (lasers) compared to radar (microwaves) gives it the ability to generate highly detailed images.</p><p>In last week’s article, we looked at the camera versus lidar debate for self driving cars. If you missed that, you can read it below.</p><div data-component-name="DigestPostEmbed"><a href="https://www.viksnewsletter.com/p/teslas-big-bet-cameras-over-lidar" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa10835d4-e008-4f1b-8763-fc1da126c6e2_1456x1048.png"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa10835d4-e008-4f1b-8763-fc1da126c6e2_1456x1048.png" sizes="100vw" alt="Tesla’s Big Bet: Cameras over LiDAR for Self Driving Cars" width="140" height="140"></picture></div></a></div><p>Since 2020, lidar has become especially relevant as the “eyes” of autonomous vehicles. Its ability to rapidly generate precise 3D images of the surroundings is critical in making accurate distance estimations for self driving. The downside of lidar is cost. Laser sources, detectors and associated electronics and mechanics are expensive. The rise of solid-state lidar technologies may still offer a competitive price point for widespread adoption of lidar in self driving cars. </p><p>The next sections will explain the inner workings of lidar technology.</p><p>Lidar systems are predominantly designed to operate in one of two wavelengths that are in the infrared region (750 nanometers to 15 micrometers) of the electromagnetic spectrum, but outside visible range (380 to 700 nanometers).</p><ol><li><p>905 nm (near infrared, or NIR)</p></li><li><p>1550 nm (short wave infrared, or SWIR)</p></li></ol><p>The choice of wavelength in a lidar system depends on the output power of laser sources, sensitivity of detectors and the interference from natural and artificial light sources in the same spectrum.</p><p><span>Sunlight is one of the dominant sources of interference which has a lot of energy in the infrared region of the spectrum. A measure of sunlight’s impact is called the </span><em>solar photon flux</em><span>, which is the amount of sunlight hitting the earth at any given wavelength.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png" width="1110" height="524" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:524,&quot;width&quot;:1110,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:346506,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Impact of sunlight at ground level versus wavelength. Source: </span><a href="https://ouster.com/insights/blog/how-multi-beam-flash-lidar-works" rel="">Ouster</a></figcaption></figure></div><p>There are some noticeable dips at 905, 940 and 1550 nm due to absorption by water vapor in the upper atmosphere, which conveniently reduces interference in systems at ground level. Unfortunately, the same effect absorbs radiation in foggy and rainy road conditions. The proximity of the 905 nm wavelength to the visible range causes two other concerns:</p><ol><li><p>905 nm laser wavelengths are easily absorbed by the retina causing damage from prolonged exposure. As a result, there are strict standards for lidar eye safety that must be adhered to.</p></li><li><p>There are plenty of interference sources near visible light, both from the sun and from vehicle headlamps that degrade the system performance.</p></li></ol><p><span>However, at shorter wavelengths, photodetectors are generally more sensitive and laser sources are more powerful and inexpensive. </span><a href="https://ouster.com/" rel="">Ouster</a><span>, for example, has actually adopted 850 nm for its lidar technology despite high solar photon flux due to better visibility in damp conditions, improved source and detector performance, with patented approaches to rejecting environmental interference.</span></p><p>1550 nm wavelength mitigates some problems; lower interference from solar radiation, and lower eye safety concerns because this wavelength only penetrates up to the cornea, thus protecting the retina. Better eye safety implies that more power can be used at 1550 nm for longer periods of time, providing longer detection range. The downside of 1550 nm wavelength is that the high absorption by water vapor makes it difficult to use in wet conditions.</p><p>The choice of wavelength also depends on the capabilities and economics of photodetectors.</p><p>Avalanche photodiodes (APDs) are the most commonly used detectors in lidar. They are specially engineered PN semiconductor junctions that utilize the photoelectric effect to generate electron-hole pairs in response to incident photons. They generate a current proportional to the number of photos incident, which depends on the amount of reverse bias on the diode. </p><p>APDs are most often built with Silicon (Si), Germanium (Ge), and Indium Gallium Arsenide (InGaAs), but each of them respond differently to infrared wavelengths. Silicon APDs respond well to NIR and are inexpensive to manufacture, while InGaAs works well for SWIR wavelengths but are more expensive.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp" width="610" height="431.575" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0292f4a-da98-4104-898b-009a3d06305c_800x566.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:566,&quot;width&quot;:800,&quot;resizeWidth&quot;:610,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;APD response curves&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="APD response curves" title="APD response curves" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Responsivity curves for various infrared sensor APDs. Source: </span><a href="https://phluxtechnology.com/latest/the-role-of-infrared-sensors-in-light-detection-and-ranging-lidar" rel="">Phlux</a></figcaption></figure></div><p>A popular detector used in lidar systems is the single-photon avalanche diode (SPAD). SPADs are especially interesting as photodetectors. Unlike traditional avalanche photodiodes (APDs) which generate a signal proportional to the amount of light, SPADs generate a near binary response to the arrival of a photon by operating in “Geiger-mode” where the photodiode is heavily reverse-biased. </p><p>The avalanche breakdown effect in the diode generates massive amounts of current  when incident even with a single photon. With this, the timing of photon arrivals can be determined to pico-second (trillionth of a second) accuracies which allows accurate distance measurements using these sensors. An added benefit is that SPADs can be implemented in a CMOS process making them low cost. This also allows massive amounts of signal processing to be integrated right next to the detector array.</p><p><span>Especially at 905 nm, silicon photomultipliers (SiPMs) have largely replaced Si APDs. SiPMs are arrays of microcells comprising of a SPAD with a </span><em>quenching </em><span>resistor to self-limit the flow of avalanche current. SiPMs provide very high photoelectric gain and are capable of detecting the precise number of incident photons depending on output current levels.</span></p><p>The detection of object distance using lidar is called ranging, and there are two popular approaches that are often used.</p><p>Much like how sonar echo-location or pulsed doppler radar works, ToF sensing using lidar involves emitting laser bursts and measuring the time taken to detect the reflected signal. The total time elapsed from signal emission to reception is called the round-trip delay. Since the actual time to the object is half the round-trip delay, the distance is calculated using the speed of light in the propagating medium.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png" width="552" height="284.1017612524462" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:526,&quot;width&quot;:1022,&quot;resizeWidth&quot;:552,&quot;bytes&quot;:307963,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>ToF lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf</figcaption></figure></div><p>The smallest distance that can be measured using ToF depends on the resolution of the timing electronics. A nearby object might have a short round-trip delay that the detector might not resolve. Hence the minimum depth of such radars are usually limited to a few centimeters.</p><p>The largest distance that can be measured depends on the transmitted power, detector sensitivity and free space path loss. If the reflected signal is indistinguishable from background noise, then the distance to the object cannot be resolved. Commercial dToF systems have a maximum range of 100-200 meters.</p><p>Most lidar systems today use dToF ranging methods due to simplicity. A slightly different temporal detection approach is to use continuous wave signals, and detect the phase shift of the reflected wave. This method is called indirect ToF (iToF), or more specifically amplitude modulated continuous wave (AMCW). It is less sensitive to timing drift and better suited to short distance measurements.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png" width="526" height="273.293542074364" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:531,&quot;width&quot;:1022,&quot;resizeWidth&quot;:526,&quot;bytes&quot;:350913,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>AMCW lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf</figcaption></figure></div><p>While ToF uses pulsed or continuous wave signals of a fixed wavelength, there are benefits to modulating it. Lidars that use the modulation of the wavelength or frequency of the transmitted pulse are called FMCW lidars. While many sources online claim that FMCW lidar is new technology, it is not. It has been around since the 1960s and the concept is widely used in automotive radar technology.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png" width="564" height="290.27788649706457" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:526,&quot;width&quot;:1022,&quot;resizeWidth&quot;:564,&quot;bytes&quot;:339118,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>FMCW LiDAR. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf</figcaption></figure></div><p><span>Each burst of frequency modulated signal is called a “chirp”, and the reflected signal received after a time delay has an instantaneous frequency difference between transmitted and reflected pulses. This “beat” frequency can be downconverted using a mixer and used to compute </span><em>both</em><span> distance and velocity of the object. I have explained before how this works for radar, and the same principles apply to lidar. </span></p><div data-component-name="DigestPostEmbed"><a href="https://www.viksnewsletter.com/p/how-automotive-radar-uses-chirp-signals" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e2dc2a5-7b48-4d51-95e2-14a2c310e184_1092x786.gif"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e2dc2a5-7b48-4d51-95e2-14a2c310e184_1092x786.gif" sizes="100vw" alt="How Automotive Radar uses Chirp Signals for Sensing" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://www.viksnewsletter.com/p/how-automotive-radar-measures-velocity" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05261946-b4bd-4db6-83c8-d78ecff6ce5a_1092x786.gif"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05261946-b4bd-4db6-83c8-d78ecff6ce5a_1092x786.gif" sizes="100vw" alt="How Automotive Radar Measures the Velocity of Objects" width="140" height="140"></picture></div></a></div><p>FMCW lidar systems are complex to implement due to the need for a frequency tunable laser source for modulation and additional electronics needed to extract information from the transmitted and received signals. But they do give lower interference from nearby lidar systems because the frequencies are different at any point in time. Also, FMCW lidar requires lower peak power from a laser compared to ToF which has implications in eye safety requirements especially at 905 nm.</p><p><span>A mechanical lidar has an infrared laser that is mounted on a brushless DC motor that rotates the sensor thus providing it a 360° field of view (FOV) in the horizontal direction and eliminating any blindspots. The FOV in the vertical direction is still limited to about 90-95°. An example of a mechanical scanning lidar sensor is Waymo’s </span><a href="https://waymo.com/blog/2019/03/bringing-3d-perimeter-lidar-to-partners/" rel="">Laser Bear Honeycomb</a><span>, which is often seen mounted on top of its self driving fleet of cars. The motors and its associated precision moving parts add to the bill of materials, and are subject to wear and tear from repeated use. As a result, scanning lidar systems are bulky and expensive.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic" width="562" height="322.93537015276144" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:489,&quot;width&quot;:851,&quot;resizeWidth&quot;:562,&quot;bytes&quot;:28913,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Waymo’s Jaguar iPace with a scanning Lidar sensor. Source: Waymo</figcaption></figure></div><p><span>Instead of moving the laser source and sensor around like in mechanical scanning, another approach is to reflect the laser light off a movable micro-electromechanical (MEMS) mirror. By oscillating the MEMS mirror back and forth at a fixed rate, the lidar can be scanned across 3D space. MEMS mirrors can be made to move with electrostatic (only electric field), electromagnetic (electric and magnetic field), or electrothermal (with heat) actuation mechanisms. Below is a nice demonstration of the concept; video credits: </span><a href="https://www.ttp.com/insights/building-the-perfect-mems-mirror-for-next-generation-lidar-what-have-we-learned/" rel="">TTP</a><span>. </span></p><p>A trade-off in MEMS mirror design is weight versus scanning rate; a heavy mirror will have low scanning rate. While the video above shows 1D scanning, 2D MEMS mirrors have also been implemented where the mirrors have a slow and fast axis. The mirrors move quickly along one direction allowing fast raster scanning, while moving slower in the perpendicular direction to only produce a static positional shift for a new rapid scan.</p><p>Arguably, the greatest benefit is the fact that MEMS mirrors can be fabricated using back-end-of-line processes in a legacy CMOS foundry and are considered a mature technology. This enables low-cost implementations of scanning lidar technology.</p><p>Instead of scanning 3D space, think of flash lidar as a photographic capture that illuminates the space in front of it. Flash lidar consists of a vertical-cavity surface-emitting laser (VCSEL) as laser source that is diffused to illuminate a target. The reflected signals are detected with an SiPM array. These lidar flashes are taken at rates up to 30 frames per second providing a real-time rendering of 3D space. By the nature of how it works, flash lidar has a reduced FOV compared to a rotating mechanical lidar scanner.</p><p>The resolution of flash lidar is limited by how many pixels fit into a given area, much like a digital camera. Compared to the scanning type, flash lidar has lower signal-to-noise ratio (SNR) because the limited optical laser power needs to be distributed to all pixels in the array. The detection sensitivity is also limited by background noise in the environment at the same wavelength as the laser. SNR is the ultimate limiting factor in the detection range of flash lidar with sensing distances up to 100 meters and centimeter-scale resolutions being reported in literature.</p><p><span>Some companies have adopted a </span><em>multi-beam </em><span>approach to flash lidar, illuminating only those parts of the environment where the detector is looking for information. This allows greater optical power to be directed at fewer, but more relevant pixels in the array, enhancing SNR. It is a combination of scanning and flash lidar, with the advantages of both.</span></p><p>Overall, the lack of moving parts means that the system is much more reliable, immune to vibration effects, and has increased data capture rate.</p><p>The most recent approach still in the research phase is to use silicon photonics to implement scanning lidar on a chip. The idea is borrowed from phased array antennas which allow scanning of the radiated beam by adjusting the phase shift of each signal fed to an antenna array. Phase shifts are implemented either with integrated optical waveguides, or by using integrated heaters to slow light through the mechanism of thermo-optic coupling. Depending on the phase shift, the direction of the radiated wavefront can be scanned in 3D space. I have explained this in a previous article.</p><div data-component-name="DigestPostEmbed"><a href="https://www.viksnewsletter.com/p/basics-of-phased-array-antennas-and" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10cc2e24-476f-4f04-998d-ce32e7573756_1456x1048.png"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10cc2e24-476f-4f04-998d-ce32e7573756_1456x1048.png" sizes="100vw" alt="How does a Phased Array Antenna work? Types of Beamforming Architectures" width="140" height="140"></picture></div></a></div><p>Now, the same approach is being utilized to steer infrared lasers by implementing phase shifts to integrated optical modulators in a photonics platform. The benefits of OPA are greatly increased scanning speeds due to electronic control and no moving parts. The cost and reliability benefits from a purely integrated approach on 300-mm diameter silicon wafers is also attractive.</p><p>The use of optical frequencies presents its own challenges in the context of phased arrays:</p><ol><li><p><strong>Thermal management</strong><span>: The heat generated from many on chip laser sources must be dissipated effectively.</span></p></li><li><p><strong>Proximity of elements</strong><span>: Phased arrays require elements spaced half a wavelength apart. At 1550 nm laser wavelength, that means each laser source needs to be spaced under a micron apart.</span></p></li><li><p><strong>Scanning angle</strong><span>: In phased arrays, the best quality beam is at “boresight” or right in front of the array. As the beam is scanned away from the center, say beyond 60°, grating lobes degrade the beam width. </span></p></li></ol><p><a href="https://www.analogphotonics.com/home/" rel="">Analog Photonics</a><span> is a spin off from MIT, founded by Prof. Michael Watts, that is working on commercializing OPA technology and is worth keeping an eye on.</span></p><ul><li><p><span>EETimes: </span><a href="https://www.eetimes.com/whats-the-direction-for-automotive-lidar-905-nm-or-1550-nm/" rel="">What’s the Direction for Automotive LiDAR: 905 nm or 1550 nm?</a></p></li><li><p><span>Texas Instruments: </span><a href="https://www.ti.com/lit/wp/slyy150b/slyy150b.pdf?ts=1703269882036" rel="">An introduction to automotive lidar</a></p></li><li><p><span>Onsemi: </span><a href="https://www.onsemi.com/pub/Collateral/AND9770-D.PDF" rel="">Introduction to the Silicon Photomultiplier</a></p></li><li><p><span>Aeye: </span><a href="https://www.aeye.ai/resources/white-papers/time-of-flight-vs-fmcw-lidar-a-side-by-side-comparison/" rel="">Time of Flight vs. FMCW LiDAR: A side-by-side comparison</a></p></li><li><p><span>IEEE Spectrum: </span><a href="https://spectrum.ieee.org/lidar-on-a-chip" rel="">Lidar on a chip puts self driving cars in the fast lane</a></p></li><li><p><span>Phlux: </span><a href="https://phluxtechnology.com/latest/the-role-of-infrared-sensors-in-light-detection-and-ranging-lidar" rel="">The role of infrared sensors in light detection and ranging - lidar</a></p></li><li><p><span>N. Li </span><em>et al.</em><span>, “A Progress Review on Solid‐State LiDAR and Nanophotonics‐Based LiDAR Sensors,” </span><em>Laser &amp; Photonics Reviews</em><span>, vol. 16, no. 11, p. 2100511, Nov. 2022, doi: </span><a href="https://doi.org/10.1002/lpor.202100511" rel="">10.1002/lpor.202100511</a><span>.</span></p></li><li><p><span>D. Wang, C. Watkins, and H. Xie, “MEMS Mirrors for LiDAR: A Review,” </span><em>Micromachines</em><span>, vol. 11, no. 5, p. 456, Apr. 2020, doi: </span><a href="https://doi.org/10.3390/mi11050456" rel="">10.3390/mi11050456</a><span>.</span></p></li></ul><p>If you like this post, please click ❤️ on Substack, subscribe to the publication, and tell someone if you like it. 🙏🏽 </p><p><span>If you enjoyed this issue, </span><strong>reply to the email</strong><span> and let me know your thoughts, or leave a comment on this post.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar/comments" rel=""><span>Leave a comment</span></a></p><p>Join a Discord community of professionals, enthusiasts and students, and get in on the discussion.</p><p data-attrs="{&quot;url&quot;:&quot;https://discord.gg/e6ysnA9c7q&quot;,&quot;text&quot;:&quot;Join Discord&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://discord.gg/e6ysnA9c7q" rel=""><span>Join Discord</span></a></p><p><em>The views, thoughts, and opinions expressed in this newsletter are solely mine; they do not reflect the views or positions of my employer or any entities I am affiliated with. The content provided is for informational purposes only and does not constitute professional or investment advice.</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Redis is trying to take over the all of the OSS Redis libraries (103 pts)]]></title>
            <link>https://twitter.com/TomHacohen/status/1861137484249252093</link>
            <guid>42239607</guid>
            <pubDate>Mon, 25 Nov 2024 20:00:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/TomHacohen/status/1861137484249252093">https://twitter.com/TomHacohen/status/1861137484249252093</a>, See on <a href="https://news.ycombinator.com/item?id=42239607">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing The Model Context Protocol (620 pts)]]></title>
            <link>https://www.anthropic.com/news/model-context-protocol</link>
            <guid>42237424</guid>
            <pubDate>Mon, 25 Nov 2024 16:14:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/model-context-protocol">https://www.anthropic.com/news/model-context-protocol</a>, See on <a href="https://news.ycombinator.com/item?id=42237424">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Today, we're open-sourcing the <a href="https://modelcontextprotocol.io/">Model Context Protocol</a> (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.</p><p>As AI assistants gain mainstream adoption, the industry has invested heavily in model capabilities, achieving rapid advances in reasoning and quality. Yet even the most sophisticated models are constrained by their isolation from data—trapped behind information silos and legacy systems. Every new data source requires its own custom implementation, making truly connected systems difficult to scale.</p><p>MCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.</p><h3>Model Context Protocol</h3><p>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.</p><p>Today, we're introducing three major components of the Model Context Protocol for developers:</p><ul><li>The Model Context Protocol <a href="https://github.com/modelcontextprotocol">specification and SDKs</a></li><li>Local MCP server support in the <a href="https://claude.ai/download">Claude Desktop apps</a></li><li>An <a href="https://github.com/modelcontextprotocol/servers">open-source repository</a> of MCP servers</li></ul><p>Claude 3.5 Sonnet is adept at quickly building MCP server implementations, making it easy for organizations and individuals to rapidly connect their most important datasets with a range of AI-powered tools. To help developers start exploring, we’re sharing pre-built MCP servers for popular enterprise systems like Google Drive, Slack, GitHub, Git, Postgres, and Puppeteer.</p><p>Early adopters like Block and Apollo have integrated MCP into their systems, while development tools companies including Zed, Replit, Codeium, and Sourcegraph are working with MCP to enhance their platforms—enabling AI agents to better retrieve relevant information to further understand the context around a coding task and produce more nuanced and functional code with fewer attempts.</p><p>"At Block, open source is more than a development model—it’s the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all,” said Dhanji R. Prasanna, Chief Technology Officer at Block. “Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to build agentic systems, which remove the burden of the mechanical so people can focus on the creative.”</p><p>Instead of maintaining separate connectors for each data source, developers can now build against a standard protocol. As the ecosystem matures, AI systems will maintain context as they move between different tools and datasets, replacing today's fragmented integrations with a more sustainable architecture.</p><h3>Getting started</h3><p>Developers can start building and testing MCP connectors today. Existing Claude for Work customers can begin testing MCP servers locally, connecting Claude to internal systems and datasets. We'll soon provide developer toolkits for deploying remote production MCP servers that can serve your entire Claude for Work organization.</p><p>To start building:</p><ul><li>Install pre-built MCP servers through the <a href="https://claude.ai/download">Claude Desktop app</a></li><li>Follow our <a href="https://modelcontextprotocol.io/quickstart">quickstart guide</a> to build your first MCP server</li><li>Contribute to our <a href="https://github.com/modelcontextprotocol">open-source repositories</a> of connectors and implementations</li></ul><h3>An open community</h3><p>We’re committed to building MCP as a collaborative, open-source project and ecosystem, and we’re eager to hear your feedback. Whether you’re an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rill – Composable concurrency toolkit for Go (179 pts)]]></title>
            <link>https://github.com/destel/rill</link>
            <guid>42237166</guid>
            <pubDate>Mon, 25 Nov 2024 15:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/destel/rill">https://github.com/destel/rill</a>, See on <a href="https://news.ycombinator.com/item?id=42237166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Rill is a toolkit that brings composable concurrency to Go, making it easier to build concurrent programs from simple, reusable parts.
It reduces boilerplate while preserving Go's natural channel-based model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="go get -u github.com/destel/rill"><pre>go get -u github.com/destel/rill</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Goals</h2><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Make common tasks easier.</strong><br>
Rill provides a cleaner and safer way of solving common concurrency problems, such as parallel job execution or
real-time event processing.
It removes boilerplate and abstracts away the complexities of goroutine, channel, and error management.
At the same time, developers retain full control over the concurrency level of all operations.</p>
</li>
<li>
<p dir="auto"><strong>Make concurrent code composable and clean.</strong><br>
Most functions in the library take Go channels as inputs and return new, transformed channels as outputs.
This allows them to be chained in various ways to build reusable pipelines from simpler parts,
similar to Unix pipes.
As a result, concurrent programs become clear sequences of reusable operations.</p>
</li>
<li>
<p dir="auto"><strong>Centralize error handling.</strong><br>
Errors are automatically propagated through a pipeline and can be handled in a single place at the end.
For more complex scenarios, Rill also provides tools to intercept and handle errors at any point in a pipeline.</p>
</li>
<li>
<p dir="auto"><strong>Simplify stream processing.</strong><br>
Thanks to Go channels, built-in functions can handle potentially infinite streams, processing items as they arrive.
This makes Rill a convenient tool for real-time processing or handling large datasets that don't fit in memory.</p>
</li>
<li>
<p dir="auto"><strong>Provide solutions for advanced tasks.</strong><br>
Beyond basic operations, the library includes ready-to-use functions for batching, ordered fan-in, map-reduce,
stream splitting, merging, and more. Pipelines, while usually linear, can have any cycle-free topology (DAG).</p>
</li>
<li>
<p dir="auto"><strong>Support custom extensions.</strong><br>
Since Rill operates on standard Go channels, it's easy to write custom functions compatible with the library.</p>
</li>
<li>
<p dir="auto"><strong>Keep it lightweight.</strong><br>
Rill has a small, type-safe, channel-based API, and zero dependencies, making it straightforward to integrate into existing projects.
It's also lightweight in terms of resource usage, ensuring that the number of memory allocations and goroutines
does not grow with the input size.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">Let's look at a practical example: fetch users from an API, activate them, and save the changes back.
It shows how to control concurrency at each step while keeping the code clean and manageable.
<strong>ForEach</strong> returns on the first error, and context cancellation via defer stops all remaining fetches.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Convert a slice of user IDs into a channel
	ids := rill.FromSlice([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, nil)

	// Read users from the API.
	// Concurrency = 3
	users := rill.Map(ids, 3, func(id int) (*mockapi.User, error) {
		return mockapi.GetUser(ctx, id)
	})

	// Activate users.
	// Concurrency = 2
	err := rill.ForEach(users, 2, func(u *mockapi.User) error {
		if u.IsActive {
			fmt.Printf(&quot;User %d is already active\n&quot;, u.ID)
			return nil
		}

		u.IsActive = true
		err := mockapi.SaveUser(ctx, u)
		if err != nil {
			return err
		}

		fmt.Printf(&quot;User saved: %+v\n&quot;, u)
		return nil
	})

	// Handle errors
	fmt.Println(&quot;Error:&quot;, err)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>context</span>.<span>Background</span>())
	<span>defer</span> <span>cancel</span>()

	<span>// Convert a slice of user IDs into a channel</span>
	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>}, <span>nil</span>)

	<span>// Read users from the API.</span>
	<span>// Concurrency = 3</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>ids</span>, <span>3</span>, <span>func</span>(<span>id</span> <span>int</span>) (<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>return</span> <span>mockapi</span>.<span>GetUser</span>(<span>ctx</span>, <span>id</span>)
	})

	<span>// Activate users.</span>
	<span>// Concurrency = 2</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>2</span>, <span>func</span>(<span>u</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>if</span> <span>u</span>.<span>IsActive</span> {
			<span>fmt</span>.<span>Printf</span>(<span>"User %d is already active<span>\n</span>"</span>, <span>u</span>.<span>ID</span>)
			<span>return</span> <span>nil</span>
		}

		<span>u</span>.<span>IsActive</span> <span>=</span> <span>true</span>
		<span>err</span> <span>:=</span> <span>mockapi</span>.<span>SaveUser</span>(<span>ctx</span>, <span>u</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>err</span>
		}

		<span>fmt</span>.<span>Printf</span>(<span>"User saved: %+v<span>\n</span>"</span>, <span>u</span>)
		<span>return</span> <span>nil</span>
	})

	<span>// Handle errors</span>
	<span>fmt</span>.<span>Println</span>(<span>"Error:"</span>, <span>err</span>)
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Batching</h2><a id="user-content-batching" aria-label="Permalink: Batching" href="#batching"></a></p>
<p dir="auto">Processing items in batches rather than individually can significantly improve performance in many scenarios,
particularly when working with external services or databases. Batching reduces the number of queries and API calls,
increases throughput, and typically lowers costs.</p>
<p dir="auto">To demonstrate batching, let's improve the previous example by using the API's bulk fetching capability.
The <strong>Batch</strong> function transforms a stream of individual IDs into a stream of slices. This enables the use of <code>GetUsers</code> API
to fetch multiple users in a single call, instead of making individual <code>GetUser</code> calls.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Batching" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Convert a slice of user IDs into a channel
	ids := rill.FromSlice([]int{
		1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
		21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
	}, nil)

	// Group IDs into batches of 5
	idBatches := rill.Batch(ids, 5, -1)

	// Bulk fetch users from the API
	// Concurrency = 3
	userBatches := rill.Map(idBatches, 3, func(ids []int) ([]*mockapi.User, error) {
		return mockapi.GetUsers(ctx, ids)
	})

	// Transform the stream of batches back into a flat stream of users
	users := rill.Unbatch(userBatches)

	// Activate users.
	// Concurrency = 2
	err := rill.ForEach(users, 2, func(u *mockapi.User) error {
		if u.IsActive {
			fmt.Printf(&quot;User %d is already active\n&quot;, u.ID)
			return nil
		}

		u.IsActive = true
		err := mockapi.SaveUser(ctx, u)
		if err != nil {
			return err
		}

		fmt.Printf(&quot;User saved: %+v\n&quot;, u)
		return nil
	})

	// Handle errors
	fmt.Println(&quot;Error:&quot;, err)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>context</span>.<span>Background</span>())
	<span>defer</span> <span>cancel</span>()

	<span>// Convert a slice of user IDs into a channel</span>
	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{
		<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>, <span>13</span>, <span>14</span>, <span>15</span>, <span>16</span>, <span>17</span>, <span>18</span>, <span>19</span>, <span>20</span>,
		<span>21</span>, <span>22</span>, <span>23</span>, <span>24</span>, <span>25</span>, <span>26</span>, <span>27</span>, <span>28</span>, <span>29</span>, <span>30</span>, <span>31</span>, <span>32</span>, <span>33</span>, <span>34</span>, <span>35</span>, <span>36</span>, <span>37</span>, <span>38</span>, <span>39</span>, <span>40</span>,
	}, <span>nil</span>)

	<span>// Group IDs into batches of 5</span>
	<span>idBatches</span> <span>:=</span> <span>rill</span>.<span>Batch</span>(<span>ids</span>, <span>5</span>, <span>-</span><span>1</span>)

	<span>// Bulk fetch users from the API</span>
	<span>// Concurrency = 3</span>
	<span>userBatches</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>idBatches</span>, <span>3</span>, <span>func</span>(<span>ids</span> []<span>int</span>) ([]<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>return</span> <span>mockapi</span>.<span>GetUsers</span>(<span>ctx</span>, <span>ids</span>)
	})

	<span>// Transform the stream of batches back into a flat stream of users</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Unbatch</span>(<span>userBatches</span>)

	<span>// Activate users.</span>
	<span>// Concurrency = 2</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>2</span>, <span>func</span>(<span>u</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>if</span> <span>u</span>.<span>IsActive</span> {
			<span>fmt</span>.<span>Printf</span>(<span>"User %d is already active<span>\n</span>"</span>, <span>u</span>.<span>ID</span>)
			<span>return</span> <span>nil</span>
		}

		<span>u</span>.<span>IsActive</span> <span>=</span> <span>true</span>
		<span>err</span> <span>:=</span> <span>mockapi</span>.<span>SaveUser</span>(<span>ctx</span>, <span>u</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>err</span>
		}

		<span>fmt</span>.<span>Printf</span>(<span>"User saved: %+v<span>\n</span>"</span>, <span>u</span>)
		<span>return</span> <span>nil</span>
	})

	<span>// Handle errors</span>
	<span>fmt</span>.<span>Println</span>(<span>"Error:"</span>, <span>err</span>)
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Real-Time Batching</h2><a id="user-content-real-time-batching" aria-label="Permalink: Real-Time Batching" href="#real-time-batching"></a></p>
<p dir="auto">Real-world applications often need to handle events or data that arrives at unpredictable rates. While batching is still
desirable for efficiency, waiting to collect a full batch might introduce unacceptable delays when
the input stream becomes slow or sparse.</p>
<p dir="auto">Rill solves this with timeout-based batching: batches are emitted either when they're full or after a specified timeout,
whichever comes first. This approach ensures optimal batch sizes during high load while maintaining responsiveness during quiet periods.</p>
<p dir="auto">Consider an application that needs to update users' <em>last_active_at</em> timestamps in a database. The function responsible
for this - <code>UpdateUserTimestamp</code> can be called concurrently, at unpredictable rates, and from different parts of the application.
Performing all these updates individually may create too many concurrent queries, potentially overwhelming the database.</p>
<p dir="auto">In the example below, the updates are queued into <code>userIDsToUpdate</code> channel and then grouped into batches of up to 5 items,
with each batch sent to the database as a single query.
The <strong>Batch</strong> function is used with a timeout of 100ms, ensuring zero latency during high load,
and up to 100ms latency with smaller batches during quiet periods.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-BatchingRealTime" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	// Start the background worker that processes the updates
	go updateUserTimestampWorker()

	// Do some updates. They'll be automatically grouped into
	// batches: [1,2,3,4,5], [6,7], [8]
	UpdateUserTimestamp(1)
	UpdateUserTimestamp(2)
	UpdateUserTimestamp(3)
	UpdateUserTimestamp(4)
	UpdateUserTimestamp(5)
	UpdateUserTimestamp(6)
	UpdateUserTimestamp(7)
	time.Sleep(500 * time.Millisecond) // simulate sparse updates
	UpdateUserTimestamp(8)
}

// This is the queue of user IDs to update.
var userIDsToUpdate = make(chan int)

// UpdateUserTimestamp is the public API for updating the last_active_at column in the users table
func UpdateUserTimestamp(userID int) {
	userIDsToUpdate <- userID
}

// This is a background worker that sends queued updates to the database in batches.
// For simplicity, there are no retries, error handling and synchronization
func updateUserTimestampWorker() {

	ids := rill.FromChan(userIDsToUpdate, nil)

	idBatches := rill.Batch(ids, 5, 100*time.Millisecond)

	_ = rill.ForEach(idBatches, 1, func(batch []int) error {
		fmt.Printf(&quot;Executed: UPDATE users SET last_active_at = NOW() WHERE id IN (%v)\n&quot;, batch)
		return nil
	})
}"><pre><span>func</span> <span>main</span>() {
	<span>// Start the background worker that processes the updates</span>
	<span>go</span> <span>updateUserTimestampWorker</span>()

	<span>// Do some updates. They'll be automatically grouped into</span>
	<span>// batches: [1,2,3,4,5], [6,7], [8]</span>
	<span>UpdateUserTimestamp</span>(<span>1</span>)
	<span>UpdateUserTimestamp</span>(<span>2</span>)
	<span>UpdateUserTimestamp</span>(<span>3</span>)
	<span>UpdateUserTimestamp</span>(<span>4</span>)
	<span>UpdateUserTimestamp</span>(<span>5</span>)
	<span>UpdateUserTimestamp</span>(<span>6</span>)
	<span>UpdateUserTimestamp</span>(<span>7</span>)
	<span>time</span>.<span>Sleep</span>(<span>500</span> <span>*</span> <span>time</span>.<span>Millisecond</span>) <span>// simulate sparse updates</span>
	<span>UpdateUserTimestamp</span>(<span>8</span>)
}

<span>// This is the queue of user IDs to update.</span>
<span>var</span> <span>userIDsToUpdate</span> <span>=</span> <span>make</span>(<span>chan</span> <span>int</span>)

<span>// UpdateUserTimestamp is the public API for updating the last_active_at column in the users table</span>
<span>func</span> <span>UpdateUserTimestamp</span>(<span>userID</span> <span>int</span>) {
	<span>userIDsToUpdate</span> <span>&lt;-</span> <span>userID</span>
}

<span>// This is a background worker that sends queued updates to the database in batches.</span>
<span>// For simplicity, there are no retries, error handling and synchronization</span>
<span>func</span> <span>updateUserTimestampWorker</span>() {

	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromChan</span>(<span>userIDsToUpdate</span>, <span>nil</span>)

	<span>idBatches</span> <span>:=</span> <span>rill</span>.<span>Batch</span>(<span>ids</span>, <span>5</span>, <span>100</span><span>*</span><span>time</span>.<span>Millisecond</span>)

	<span>_</span> <span>=</span> <span>rill</span>.<span>ForEach</span>(<span>idBatches</span>, <span>1</span>, <span>func</span>(<span>batch</span> []<span>int</span>) <span>error</span> {
		<span>fmt</span>.<span>Printf</span>(<span>"Executed: UPDATE users SET last_active_at = NOW() WHERE id IN (%v)<span>\n</span>"</span>, <span>batch</span>)
		<span>return</span> <span>nil</span>
	})
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Errors, Termination and Contexts</h2><a id="user-content-errors-termination-and-contexts" aria-label="Permalink: Errors, Termination and Contexts" href="#errors-termination-and-contexts"></a></p>
<p dir="auto">Error handling can be non-trivial in concurrent applications. Rill simplifies this by providing a structured approach to the problem.
Pipelines typically consist of a sequence of non-blocking channel transformations, followed by a blocking stage that returns a final result and an error.
The general rule is: any error occurring anywhere in a pipeline is propagated down to the final stage,
where it's caught by some blocking function and returned to the caller.</p>
<p dir="auto">Rill provides a wide selection of blocking functions. Here are some commonly used ones:</p>
<ul dir="auto">
<li><strong>ForEach:</strong> Concurrently applies a user function to each item in the stream.
<a href="https://pkg.go.dev/github.com/destel/rill#example-ForEach" rel="nofollow">Example</a></li>
<li><strong>ToSlice:</strong> Collects all stream items into a slice.
<a href="https://pkg.go.dev/github.com/destel/rill#example-ToSlice" rel="nofollow">Example</a></li>
<li><strong>First:</strong> Returns the first item or error encountered in the stream and discards the rest
<a href="https://pkg.go.dev/github.com/destel/rill#example-First" rel="nofollow">Example</a></li>
<li><strong>Reduce:</strong> Concurrently reduces the stream to a single value, using a user provided reducer function.
<a href="https://pkg.go.dev/github.com/destel/rill#example-Reduce" rel="nofollow">Example</a></li>
<li><strong>All:</strong> Concurrently checks if all items in the stream satisfy a user provided condition.
<a href="https://pkg.go.dev/github.com/destel/rill#example-All" rel="nofollow">Example</a></li>
<li><strong>Err:</strong> Returns the first error encountered in the stream or nil, and discards the rest of the stream.
<a href="https://pkg.go.dev/github.com/destel/rill#example-Err" rel="nofollow">Example</a></li>
</ul>
<p dir="auto">All blocking functions share a common behavior. In case of an early termination (before reaching the end of the input stream or in case of an error),
such functions initiate background draining of the remaining items. This is done to prevent goroutine leaks by ensuring that
all goroutines feeding the stream are allowed to complete.</p>
<p dir="auto">Rill is context-agnostic, meaning that it does not enforce any specific context usage.
However, it's recommended to make user-defined pipeline stages context-aware.
This is especially important for the initial stage, as it allows to stop feeding the pipeline with new items after the context cancellation.
In practice the first stage is often naturally context-aware through Go's standard APIs for databases, HTTP clients, and other external sources.</p>
<p dir="auto">In the example below the <code>CheckAllUsersExist</code> function uses several concurrent workers to check if all users<br>
from the given list exist. When an error occurs (like a non-existent user), the function returns that error<br>
and cancels the context, which in turn stops all remaining user fetches.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Context" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// ID 999 doesn't exist, so fetching will stop after hitting it.
	err := CheckAllUsersExist(ctx, 3, []int{1, 2, 3, 4, 5, 999, 7, 8, 9, 10, 11, 12, 13, 14, 15})
	fmt.Printf(&quot;Check result: %v\n&quot;, err)
}

// CheckAllUsersExist uses several concurrent workers to check if all users with given IDs exist.
func CheckAllUsersExist(ctx context.Context, concurrency int, ids []int) error {
	// Create new context that will be canceled when this function returns
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	// Convert the slice into a stream
	idsStream := rill.FromSlice(ids, nil)

	// Fetch users concurrently.
	users := rill.Map(idsStream, concurrency, func(id int) (*mockapi.User, error) {
		u, err := mockapi.GetUser(ctx, id)
		if err != nil {
			return nil, fmt.Errorf(&quot;failed to fetch user %d: %w&quot;, id, err)
		}

		fmt.Printf(&quot;Fetched user %d\n&quot;, id)
		return u, nil
	})

	// Return the first error (if any) and cancel remaining fetches via context
	return rill.Err(users)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// ID 999 doesn't exist, so fetching will stop after hitting it.</span>
	<span>err</span> <span>:=</span> <span>CheckAllUsersExist</span>(<span>ctx</span>, <span>3</span>, []<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>999</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>, <span>13</span>, <span>14</span>, <span>15</span>})
	<span>fmt</span>.<span>Printf</span>(<span>"Check result: %v<span>\n</span>"</span>, <span>err</span>)
}

<span>// CheckAllUsersExist uses several concurrent workers to check if all users with given IDs exist.</span>
<span>func</span> <span>CheckAllUsersExist</span>(<span>ctx</span> context.<span>Context</span>, <span>concurrency</span> <span>int</span>, <span>ids</span> []<span>int</span>) <span>error</span> {
	<span>// Create new context that will be canceled when this function returns</span>
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>ctx</span>)
	<span>defer</span> <span>cancel</span>()

	<span>// Convert the slice into a stream</span>
	<span>idsStream</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>(<span>ids</span>, <span>nil</span>)

	<span>// Fetch users concurrently.</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>idsStream</span>, <span>concurrency</span>, <span>func</span>(<span>id</span> <span>int</span>) (<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>u</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>GetUser</span>(<span>ctx</span>, <span>id</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>nil</span>, <span>fmt</span>.<span>Errorf</span>(<span>"failed to fetch user %d: %w"</span>, <span>id</span>, <span>err</span>)
		}

		<span>fmt</span>.<span>Printf</span>(<span>"Fetched user %d<span>\n</span>"</span>, <span>id</span>)
		<span>return</span> <span>u</span>, <span>nil</span>
	})

	<span>// Return the first error (if any) and cancel remaining fetches via context</span>
	<span>return</span> <span>rill</span>.<span>Err</span>(<span>users</span>)
}</pre></div>
<p dir="auto">In the example above only the second stage (<code>mockapi.GetUser</code>) of the pipeline is context-aware.
<strong>FromSlice</strong> works well here since the input is small, iteration is fast and context cancellation prevents expensive API calls regardless.
The following code demonstrates how to replace <strong>FromSlice</strong> with <strong>Generate</strong> when full context awareness becomes important.</p>
<div dir="auto" data-snippet-clipboard-copy-content="idsStream := rill.Generate(func(send func(int), sendErr func(error)) {
	for _, id := range ids {
		if ctx.Err() != nil {
			return
		}
		send(id)
	}
})"><pre><span>idsStream</span> <span>:=</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>int</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
	<span>for</span> <span>_</span>, <span>id</span> <span>:=</span> <span>range</span> <span>ids</span> {
		<span>if</span> <span>ctx</span>.<span>Err</span>() <span>!=</span> <span>nil</span> {
			<span>return</span>
		}
		<span>send</span>(<span>id</span>)
	}
})</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Order Preservation (Ordered Fan-In)</h2><a id="user-content-order-preservation-ordered-fan-in" aria-label="Permalink: Order Preservation (Ordered Fan-In)" href="#order-preservation-ordered-fan-in"></a></p>
<p dir="auto">Concurrent processing can boost performance, but since tasks take different amounts of time to complete,
the results' order usually differs from the input order. While out-of-order results are acceptable in many scenarios,
some cases require preserving the original order. This seemingly simple problem is deceptively challenging to solve correctly.</p>
<p dir="auto">To address this, Rill provides ordered versions of its core functions, such as <strong>OrderedMap</strong> or <strong>OrderedFilter</strong>.
These functions perform additional synchronization under the hood to ensure that if value <strong>x</strong> precedes value <strong>y</strong> in the input stream,
then <strong>f(x)</strong> will precede <strong>f(y)</strong> in the output.</p>
<p dir="auto">Here's a practical example: finding the first occurrence of a specific string among 1000 large files hosted online.
Downloading all files at once would consume too much memory, processing them sequentially would be too slow,
and traditional concurrency patterns do not preserve the order of files, making it challenging to find the first match.</p>
<p dir="auto">The combination of <strong>OrderedFilter</strong> and <strong>First</strong> functions solves this elegantly,
while downloading and keeping in memory at most 5 files at a time. <strong>First</strong> returns on the first match,
this triggers the context cancellation via defer, stopping URL generation and file downloads.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Ordering" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// The string to search for in the downloaded files
	needle := []byte(&quot;26&quot;)

	// Generate a stream of URLs from https://example.com/file-0.txt 
	// to https://example.com/file-999.txt
	// Stop generating URLs if the context is canceled
	urls := rill.Generate(func(send func(string), sendErr func(error)) {
		for i := 0; i < 1000 &amp;&amp; ctx.Err() == nil; i++ {
			send(fmt.Sprintf(&quot;https://example.com/file-%d.txt&quot;, i))
		}
	})

	// Download and process the files
	// At most 5 files are downloaded and held in memory at the same time
	matchedUrls := rill.OrderedFilter(urls, 5, func(url string) (bool, error) {
		fmt.Println(&quot;Downloading:&quot;, url)

		content, err := mockapi.DownloadFile(ctx, url)
		if err != nil {
			return false, err
		}

		// keep only URLs of files that contain the needle
		return bytes.Contains(content, needle), nil
	})

	// Find the first matched URL
	firstMatchedUrl, found, err := rill.First(matchedUrls)
	if err != nil {
		fmt.Println(&quot;Error:&quot;, err)
		return
	}

	// Print the result
	if found {
		fmt.Println(&quot;Found in:&quot;, firstMatchedUrl)
	} else {
		fmt.Println(&quot;Not found&quot;)
	}
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>context</span>.<span>Background</span>())
	<span>defer</span> <span>cancel</span>()

	<span>// The string to search for in the downloaded files</span>
	<span>needle</span> <span>:=</span> []<span>byte</span>(<span>"26"</span>)

	<span>// Generate a stream of URLs from https://example.com/file-0.txt </span>
	<span>// to https://example.com/file-999.txt</span>
	<span>// Stop generating URLs if the context is canceled</span>
	<span>urls</span> <span>:=</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>string</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
		<span>for</span> <span>i</span> <span>:=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>1000</span> <span>&amp;&amp;</span> <span>ctx</span>.<span>Err</span>() <span>==</span> <span>nil</span>; <span>i</span><span>++</span> {
			<span>send</span>(<span>fmt</span>.<span>Sprintf</span>(<span>"https://example.com/file-%d.txt"</span>, <span>i</span>))
		}
	})

	<span>// Download and process the files</span>
	<span>// At most 5 files are downloaded and held in memory at the same time</span>
	<span>matchedUrls</span> <span>:=</span> <span>rill</span>.<span>OrderedFilter</span>(<span>urls</span>, <span>5</span>, <span>func</span>(<span>url</span> <span>string</span>) (<span>bool</span>, <span>error</span>) {
		<span>fmt</span>.<span>Println</span>(<span>"Downloading:"</span>, <span>url</span>)

		<span>content</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>DownloadFile</span>(<span>ctx</span>, <span>url</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>false</span>, <span>err</span>
		}

		<span>// keep only URLs of files that contain the needle</span>
		<span>return</span> <span>bytes</span>.<span>Contains</span>(<span>content</span>, <span>needle</span>), <span>nil</span>
	})

	<span>// Find the first matched URL</span>
	<span>firstMatchedUrl</span>, <span>found</span>, <span>err</span> <span>:=</span> <span>rill</span>.<span>First</span>(<span>matchedUrls</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>fmt</span>.<span>Println</span>(<span>"Error:"</span>, <span>err</span>)
		<span>return</span>
	}

	<span>// Print the result</span>
	<span>if</span> <span>found</span> {
		<span>fmt</span>.<span>Println</span>(<span>"Found in:"</span>, <span>firstMatchedUrl</span>)
	} <span>else</span> {
		<span>fmt</span>.<span>Println</span>(<span>"Not found"</span>)
	}
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stream Merging and FlatMap</h2><a id="user-content-stream-merging-and-flatmap" aria-label="Permalink: Stream Merging and FlatMap" href="#stream-merging-and-flatmap"></a></p>
<p dir="auto">Rill comes with the <strong>Merge</strong> function that combines multiple streams into a single one. Another, often overlooked,
function that can combine streams is <strong>FlatMap</strong>. It's a powerful tool that transforms each input item into its own stream,
and then merges all these streams together.</p>
<p dir="auto">In the example below, <strong>FlatMap</strong> transforms each department into a stream of users, then merges these streams into one.
Like other Rill functions, <strong>FlatMap</strong> gives full control over concurrency.
In this particular case the concurrency level is 3, meaning that users are fetched from at most 3 departments at the same time.</p>
<p dir="auto">Additionally, this example demonstrates how to write a reusable streaming wrapper over paginated API calls - the <code>StreamUsers</code> function.
This wrapper can be useful both on its own and as part of larger pipelines.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-FlatMap" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Start with a stream of department names
	departments := rill.FromSlice([]string{&quot;IT&quot;, &quot;Finance&quot;, &quot;Marketing&quot;, &quot;Support&quot;, &quot;Engineering&quot;}, nil)

	// Stream users from all departments concurrently.
	// At most 3 departments at the same time.
	users := rill.FlatMap(departments, 3, func(department string) <-chan rill.Try[*mockapi.User] {
		return StreamUsers(ctx, &amp;mockapi.UserQuery{Department: department})
	})

	// Print the users from the combined stream
	err := rill.ForEach(users, 1, func(user *mockapi.User) error {
		fmt.Printf(&quot;%+v\n&quot;, user)
		return nil
	})
	fmt.Println(&quot;Error:&quot;, err)
}

// StreamUsers is a reusable streaming wrapper around the mockapi.ListUsers function.
// It iterates through all listing pages and uses [Generate] to simplify sending users and errors to the resulting stream.
// This function is useful both on its own and as part of larger pipelines.
func StreamUsers(ctx context.Context, query *mockapi.UserQuery) <-chan rill.Try[*mockapi.User] {
	return rill.Generate(func(send func(*mockapi.User), sendErr func(error)) {
		var currentQuery mockapi.UserQuery
		if query != nil {
			currentQuery = *query
		}

		for page := 0; ; page++ {
			currentQuery.Page = page

			users, err := mockapi.ListUsers(ctx, &amp;currentQuery)
			if err != nil {
				sendErr(err)
				return
			}

			if len(users) == 0 {
				break
			}

			for _, user := range users {
				send(user)
			}
		}
	})
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>context</span>.<span>Background</span>())
	<span>defer</span> <span>cancel</span>()

	<span>// Start with a stream of department names</span>
	<span>departments</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>string</span>{<span>"IT"</span>, <span>"Finance"</span>, <span>"Marketing"</span>, <span>"Support"</span>, <span>"Engineering"</span>}, <span>nil</span>)

	<span>// Stream users from all departments concurrently.</span>
	<span>// At most 3 departments at the same time.</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>FlatMap</span>(<span>departments</span>, <span>3</span>, <span>func</span>(<span>department</span> <span>string</span>) <span>&lt;-</span><span>chan</span> rill.<span>Try</span>[<span>*</span>mockapi.<span>User</span>] {
		<span>return</span> <span>StreamUsers</span>(<span>ctx</span>, <span>&amp;</span>mockapi.<span>UserQuery</span>{<span>Department</span>: <span>department</span>})
	})

	<span>// Print the users from the combined stream</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>1</span>, <span>func</span>(<span>user</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>fmt</span>.<span>Printf</span>(<span>"%+v<span>\n</span>"</span>, <span>user</span>)
		<span>return</span> <span>nil</span>
	})
	<span>fmt</span>.<span>Println</span>(<span>"Error:"</span>, <span>err</span>)
}

<span>// StreamUsers is a reusable streaming wrapper around the mockapi.ListUsers function.</span>
<span>// It iterates through all listing pages and uses [Generate] to simplify sending users and errors to the resulting stream.</span>
<span>// This function is useful both on its own and as part of larger pipelines.</span>
<span>func</span> <span>StreamUsers</span>(<span>ctx</span> context.<span>Context</span>, <span>query</span> <span>*</span>mockapi.<span>UserQuery</span>) <span>&lt;-</span><span>chan</span> rill.<span>Try</span>[<span>*</span>mockapi.<span>User</span>] {
	<span>return</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>*</span>mockapi.<span>User</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
		<span>var</span> <span>currentQuery</span> mockapi.<span>UserQuery</span>
		<span>if</span> <span>query</span> <span>!=</span> <span>nil</span> {
			<span>currentQuery</span> <span>=</span> <span>*</span><span>query</span>
		}

		<span>for</span> <span>page</span> <span>:=</span> <span>0</span>; ; <span>page</span><span>++</span> {
			<span>currentQuery</span>.<span>Page</span> <span>=</span> <span>page</span>

			<span>users</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>ListUsers</span>(<span>ctx</span>, <span>&amp;</span><span>currentQuery</span>)
			<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
				<span>sendErr</span>(<span>err</span>)
				<span>return</span>
			}

			<span>if</span> <span>len</span>(<span>users</span>) <span>==</span> <span>0</span> {
				<span>break</span>
			}

			<span>for</span> <span>_</span>, <span>user</span> <span>:=</span> <span>range</span> <span>users</span> {
				<span>send</span>(<span>user</span>)
			}
		}
	})
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Go 1.23 Iterators</h2><a id="user-content-go-123-iterators" aria-label="Permalink: Go 1.23 Iterators" href="#go-123-iterators"></a></p>
<p dir="auto">Starting from Go 1.23, the language added <em>range-over-function</em> feature, allowing users to define custom iterators
for use in for-range loops. This feature enables Rill to integrate seamlessly with existing iterator-based functions
in the standard library and third-party packages.</p>
<p dir="auto">Rill provides <strong>FromSeq</strong> and <strong>FromSeq2</strong> functions to convert an iterator into a stream,
and <strong>ToSeq2</strong> function to convert a stream back into an iterator.</p>
<p dir="auto"><strong>ToSeq2</strong> can be a good alternative to <strong>ForEach</strong> when concurrency is not needed.
It gives more control and performs all necessary cleanup and draining, even if the loop is terminated early using <em>break</em> or <em>return</em>.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-ToSeq2" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	// Convert a slice of numbers into a stream
	numbers := rill.FromSlice([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, nil)

	// Transform each number
	// Concurrency = 3
	squares := rill.Map(numbers, 3, func(x int) (int, error) {
		return square(x), nil
	})

	// Convert the stream into an iterator and use for-range to print the results
	for val, err := range rill.ToSeq2(squares) {
		if err != nil {
			fmt.Println(&quot;Error:&quot;, err)
			break // cleanup is done regardless of early exit
		}
		fmt.Printf(&quot;%+v\n&quot;, val)
	}
}"><pre><span>func</span> <span>main</span>() {
	<span>// Convert a slice of numbers into a stream</span>
	<span>numbers</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>}, <span>nil</span>)

	<span>// Transform each number</span>
	<span>// Concurrency = 3</span>
	<span>squares</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>numbers</span>, <span>3</span>, <span>func</span>(<span>x</span> <span>int</span>) (<span>int</span>, <span>error</span>) {
		<span>return</span> <span>square</span>(<span>x</span>), <span>nil</span>
	})

	<span>// Convert the stream into an iterator and use for-range to print the results</span>
	<span>for</span> <span>val</span>, <span>err</span> <span>:=</span> <span>range</span> <span>rill</span>.<span>ToSeq2</span>(<span>squares</span>) {
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>fmt</span>.<span>Println</span>(<span>"Error:"</span>, <span>err</span>)
			<span>break</span> <span>// cleanup is done regardless of early exit</span>
		}
		<span>fmt</span>.<span>Printf</span>(<span>"%+v<span>\n</span>"</span>, <span>val</span>)
	}
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing Strategy</h2><a id="user-content-testing-strategy" aria-label="Permalink: Testing Strategy" href="#testing-strategy"></a></p>
<p dir="auto">Rill has a test coverage of over 95%, with testing focused on:</p>
<ul dir="auto">
<li><strong>Correctness</strong>: ensuring that functions produce accurate results at different levels of concurrency</li>
<li><strong>Concurrency</strong>: confirming that correct number of goroutines is spawned and utilized</li>
<li><strong>Ordering</strong>: ensuring that ordered versions of functions preserve the order, while basic versions do not</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Whether it's reporting a bug, suggesting a feature, or submitting a pull request, your support helps improve Rill.
Please ensure that your code adheres to the existing style and includes relevant tests._</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hey, wait – is employee performance Gaussian distributed? (282 pts)]]></title>
            <link>https://timdellinger.substack.com/p/hey-wait-is-employee-performance</link>
            <guid>42236841</guid>
            <pubDate>Mon, 25 Nov 2024 15:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timdellinger.substack.com/p/hey-wait-is-employee-performance">https://timdellinger.substack.com/p/hey-wait-is-employee-performance</a>, See on <a href="https://news.ycombinator.com/item?id=42236841">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>tl;dr:</p><p><em>It’s probably Pareto-distributed, not Gaussian, which elucidates a few things about some of the problems that performance management processes have at large corporations, and also speaks to why it’s so hard to hire good people. Oh, and for the economists: the Marginal Productivity Theory of Wages is cleverly combined with the Gini Coefficient to arrive at the key insight.</em></p><p>Ahhh, it’s Q4 at Fortune 500 companies. That means it’s performance management season, when millions of employees are ranked and graded on their accomplishments over the past 12 months. Their bonuses and raises next year – or lack thereof, accompanied by a statement about their future at the company – depend on the outcome of this process.</p><p><span>I’ll graciously sidestep the discussion of how accurate these Fortune 500 managers could possibly be as they assess and rank their direct reports.&nbsp; (Accuracy here is certainly questionable, given issues such as apples-to-oranges comparisons, the principal-agent problem, the many flavors of bias, etc.). Similarly, I’ll also sidestep the negative effects that these performance management processes have on a company’s culture and work environment (don’t get me started!). Let’s instead focus on the statistical foundations of the process through the lens of a data scientist. </span><em>Spoiler alert: it’s built on shaky ground.</em></p><p>As a quick reminder of the process at a typical Fortune 500 company, managers will annually hold a series of meetings, with the express purpose of slotting all employees into place on a “vitality curve” that looks something like this:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png" width="576" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:576,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:13446,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff58fbd1b-a66c-4884-bd46-516a0d84f666_576x432.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Dividing lines are drawn that vary from company to company, and from year to year. The categories above reflect General Electric's original 10-70-20 split from the early 1980s, which is often cited as the canonical system: the top 20% of employees are given a handsome monetary bonus, and the bottom 10% are shown the door.</p><p>Sometimes I like to visualize the same data using a percentile chart instead – you can think of it as literally lining everyone up from shortest to tallest; each person’s “percentile” is the percent of the population that they’re taller than.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png" width="571" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:571,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:20705,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f16aa1-9c11-42bd-9c3a-6a628ec0f84d_571x432.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The unspoken first step here was to assume a Gaussian bell curve when it comes to employee performance. And, heck, why not? The folks in HR who were paying attention during psychology class recall that a great many things in this world follow a Gaussian distribution, including traits that have predictive power when it comes to workplace performance. IQ is Gaussian. The Big Five Personality Trait known as Conscientiousness is likewise Gaussian. For what it’s worth, human height is also Gaussian, and that’s correlated with workplace success. And it turns out that many combinations of Gaussian variables (sums, convolutions…) are also Gaussian.</p><p><span>Giving it the data scientist “smell test” though, a few things jump out. First, are we really paying corporate salaries to people on the low end of the bell curve? The median individual income in the US is less than $50k, so my instinct is that those in corporate jobs are likely the top half of any bell curve – not the full bell curve. Also: the symmetry of the distribution doesn’t quite line up with my lived experience. I’ve seen many employees making delightful amounts (sometimes millions of dollars worth) of positive impact, but I don’t recall that their impact was offset by </span><em>the exact same number of employees</em><span> on the other end of the performance spectrum, making impact of the same millions-of-dollars magnitude, but directionally… un-stellar.</span></p><p>As we think about the impact of an employee, measured in dollars, let’s draw a connection that I haven’t seen made anywhere else. Economists will teach you something called the Marginal Productivity Theory of Wages, the idea being that the amount of money that a company is willing to spend on an employee is essentially the value that the company expects to get out of their work. This strikes me as mostly true, most of the time, and likely to be the case in the corporate world that we’re considering here.</p><p>And then on a different day, in a different part of the microeconomics textbook, there’s often a histogram of the distribution of wages: the Pareto distribution, a mathematically interesting power-law. Let’s put these two ideas from Economics together. In any given salary band, employers across the United States are paying folks wages that collectively form a Pareto distribution:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png" width="584" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:584,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18058,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F086a9b80-e288-4bee-a9b6-9faa20386937_584x432.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em>And thus we arrive at my central idea: this is also the distribution of *performance* that we should expect from employees. Performance Management would do well to start with a Pareto assumption instead of a Gaussian assumption.</em></p><p>Like a good data scientist, I’m sweeping the mathematical details into the endnotes [0] so as to not befuddle the decision-makers, but fear not, the fun statistical stuff that I can’t shut up about is there in spades. Fun preview: the fact that corporate job postings these days include salary min/max lets us get an estimate of the size of a salary band, which was perhaps the piece of data that earlier thinkers who pondered such things were missing.</p><p>A Pareto distribution also passes the “sniff test” with respect to success and failure. I sometimes think that everything at a Fortune 500 company is Pareto distributed at every scale: my productivity this week, my productivity this year, the productivity of my team/project compared to others, and the success of my company compared to others. A few are quite successful, most are less successful. Supporting that notion with data is a task for another day, but let’s just say that I’ve already started the spreadsheet. In any case, let’s move forward to interpreting what we’ve discovered.</p><p>So what can be learned from realizing that performance follows this Pareto distribution?&nbsp;&nbsp;</p><p>Oh, here’s the percentile plot:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png" width="571" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a979784a-35aa-4852-b83c-c867d777ed96_571x432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:571,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:21721,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa979784a-35aa-4852-b83c-c867d777ed96_571x432.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>There are a few striking things here that have practical implications that inform how we might change the performance management process.</p><p><span>First, the Gaussian perspective holds that there is a bottom ~10% that performs </span><em>egregiously poorly,</em><span> and that this is an intrinsic part of the distribution. Corporations are in a constant battle to remove this portion from their payroll annually. On the other hand, looking at the Pareto percentile plot, the bottom 10% aren’t really all that different from the folks in the next 10%. As a matter of fact, there’s not an obvious place to draw a line to identify the “lowest end” employees to expunge. ~65% of employees are performing below the expectations that are associated with the salary midpoint (the green dashed line)!</span></p><p><span>But there </span><em>are</em><span> low-performing employees at large corporations; we’ve all seen them. My perspective is that they’re hiring errors. Yes, hiring errors should be addressed, but it’s not clear that there’s an obvious specific percentage of the workforce that is the result of hiring errors. We also know that some managers are great at hiring, and have a very low error rate – it’s a bit of a tragedy to force them to cut employees who are performing relatively reasonably.</span></p><p>What percentage of employees should be given extra financial rewards? Unfortunately, the Pareto plot doesn’t reveal an obvious cutpoint in this regard either. The top 35% are performing above what’s expected at the salary midpoint, so that’s a starting point. Many companies take a more granular approach than GE’s original formula, i.e. they have “good - better - best” categories for bonuses. That seems reasonable.</p><p>Regarding the very top performers, the performance management process often identifies employees who are candidates for promotion. Much like hiring errors that aren’t reflected by the Pareto distribution, I think that promotion candidates should similarly be seen as outliers. Reward them handsomely (but within bounds) since their performance is, in this case, literally off the charts, and be honest in recognizing that they’re currently being underpaid despite being at the top of the pay band.&nbsp; This is a small market inefficiency that the promotion will soon remedy.</p><p>Second, let’s consider what the Pareto percentile plot reveals about the process of firing and backfilling. Or more broadly, hiring in general. We can see from the performance vs frequency plot that in any given salary band, low performers are 3x as common as high performers! Wow. This aligns with my experience, and is an insight that speaks to the difficulty of hiring. And to the expected effectiveness of firing the bottom 10% and then expecting to hire people who are remarkably better.</p><p>Summarizing:</p><p><em><strong>There is no intrinsic bottom 10% that needs to be expunged annually.</strong></em><span> Let managers identify any hiring errors if they think their team can do better, but don’t set a target for this number based on faulty statistical notions.</span></p><p><em><strong>Hiring in general is difficult because low performers are 3x as common as high performers.</strong></em><strong> </strong><span>The Gaussian-inspired idea that you’ll probably get someone better if you fire the low end is inaccurate – the most likely replacement might not be remarkably better.</span></p><p>If someone were designing a performance management system from scratch, and they let data scientists into the room, the data scientists would likely note the following issues. These issues will all require thought, and a design that is specific to a given company (which is another way of saying that there are no easy answers that can be implemented tomorrow by everyone).</p><p>Any statistically driven system that results in decisions that cost lots of money should be monitored to make sure that it’s achieving its goals, and that it continues to work as time goes on. How do we know it’s working? What are our actual goals? There might need to be measures in place that let us know if the company is inaccurately categorizing people. Or if managers are hiring sacrificial lambs to protect their valued team. Or if there really is differentiation in performance between those who are being fired and those who are being kept.</p><p>The performance management process itself requires quite a bit of time and effort. Firing 10% of the company comes with costs (severance pay). Replacing those people is also costly (a helpful order of magnitude estimate is that the hiring process all told costs the company approximately a year’s salary). That new person will statistically be with the company for, say, three to five years. Is the increase in performance greater than the cost of the entire process? Are there opportunity costs, such that the company is better off with a less intense performance management system?&nbsp;</p><p>Performance management is a snapshot in time – one year. If an employee’s performance has been exemplary for three years in their current role, then has a down year, should the employee be shown the door? Would a longer term perspective on the employee’s suitability be a wiser approach?</p><p>Data scientists worry about this a lot. (Well, the good ones do!) Is one employee's success rate lower because they’re given all of the most difficult challenges? Now you’re measuring the way that projects are assigned. Are extroverts consistently given better ratings despite equal performance? Now you’re measuring personality traits and managerial bias.</p><p>Things like this can be somewhat accounted for and watched for when designing the assessment process, but there might be trickier things afoot. It’s a manager’s job to set their employees up for success, and managers are highly unlikely to admit that they weren’t doing so, especially during performance management season when they themselves are being graded.</p><p>It’s my opinion that the biggest factor in an employee's performance – perhaps bigger than the employee’s abilities and level of effort – is whether their manager set them up for success. It’s not easy for employees to change teams to get a better manager (perhaps it should be easier!). Maybe the rate at which employees jump ship these days and get jobs at other companies is an indicator that managers aren’t giving their employees the chance to succeed.</p><p>Similarly, it’s my observation that managers who are new to a company tend to do less-than-optimally their first time through the performance management process, especially when it comes to securing preferred performance slots for the people who work under them. The inevitable gamesmanship and political horse trading inherent in the process will go down differently at each company, and the first time through the process can be a harsh learning experience. What’s being measured might be your manager’s persuasiveness in the performance management sessions, and their political capital, as much as it is a measure of your performance.</p><p>Performance management, as practiced in many large corporations in 2024, is an outdated technology that is in need of an update. Abandoning the Gaussian assumption, and instead assuming a Pareto distribution reveals that there is no statistical basis for firing the bottom 10% of workers annually. Companies would be better off treating hiring mistakes as outliers, and should also think about whether it’s really worth it to fire 10% of their workforce annually. Monitoring to measure whether goals are being achieved, and cost analysis to determine if it’s worth it, are likely wise given the expenses of performance management.</p><p>I’ll also mention here that the conditions that birthed the modern performance management&nbsp; system (GE in the early 1980s) included an assumption of lifetime employment at a company, as long as major mistakes weren’t made. It was likely valuable, in those days, to implement some sort of carrots-and-sticks program. Forty years later, employees jump ship regularly. Perhaps withholding carrots (i.e. giving an insultingly small bonus for the lowest performers) might be enough of a stick, and healthier for all involved. Figuring all this out will take more work.</p><p><em>Executive summary: yep, there’s data from the early 20th Century that’s supportive, but seems to have been forgotten. The literature basically agrees that assessing an employee’s performance is quite subjective; identifying objective numbers isn’t an easy task, but what’s out there is consistent with the Pareto view and not the Gaussian view.&nbsp;</em></p><p>Attempting to be brief so as not to lose the reader entirely:</p><p><span>In 1957, William Shockley (Nobel Prize winner and noted jerkwad) looked at scientific publications and patents from the early 1950s from Los Alamos, Brookhaven, and Bell Labs. His conclusion – and the data are compelling in my view – was that performance is </span><em>definitely not Gaussian</em><span>. His take was that the distribution is Log-Normal (a distribution that can be very similar-looking to Pareto) based on a pet theory. In 1970, Clarence Zener (yes, he of the Zener diode) in a later publication looked at Shockley’s data along with some earlier data from a couple of other publication, including “a large sample of 6891 authors, everyone, in fact, listed in Chemical Abstracts during 1907-1916 whose names started with either A or B”, and put a lot of ink into the Log-Normal vs. Pareto question, since the answer is obviously </span><em>not Gaussian or anything even close to Gaussian.</em></p><p>More recently: Herman Anguinis has looked through data from sports, entertainment, politics, and amusingly enough, Materials Science journal publications, which makes me a part of his dataset (!). I don’t think he’s managed to put his finger on a slam-dunk dataset, but his data is directionally correct. My take on his work is that his data tends to center around total lifetime output, which speaks more to the length of one’s career than annual output, but his instincts are correct.</p><p>There are a few other references in the end notes for the curious, including a link to an AI-assisted lit search from undermind.ai.</p><p>References are all in endnote [1].</p><p><em>Executive summary: omg we’re unjustly penalizing ~5% of our employees and we didn’t know it. If we had a really big sample size, ~5% of employees would be placed into a higher performance tier based on their performance. We’re departing from objective standards by using a “forced distribution”.</em></p><p>Is there anything else that a Data Science perspective can elucidate regarding typical performance management practices? Ah yes! Let’s say that managers are sitting in a meeting evaluating a batch of 27 employees, aiming to identify the bottom 10%. That would be… 2.7 people. Someone says, “Hey, there’s no way that we can hit these percentages exactly. And what if this batch has no underperformers?”, and the response is often something like “the percentages will work out when all of the batches across the larger organization are rolled up together. So we rank-order the employees that are borderline cases, and the final cutoff lines will be drawn when everything is combined.” Everyone in the meeting nods at the idea that the Vitality Curve will emerge and all will be fair when there are enough employees batched up together. It occurs to me that this is testable with a little simulation, so I’ll believe it when I see some data!&nbsp; Perhaps a minimum cohort size might emerge where “rolling up” causes very little collateral damage?</p><p>Let’s simulate the performance of a cohort of Gaussian-distributed employees, and further let’s pretend that managers are miraculously perfect at evaluating employee performance, so a list of best-to-worst employees is generated in exactly correct order. (For the data scientists: AUROC = Mann-Whitney U-Test = 1). The question before us is thus: does the “rolling up” process introduce any inaccuracies?&nbsp; More specifically, since we secretly know every employee’s exact performance, are they correctly categorized by the process of rank ordering and drawing lines at specific percentiles?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png" width="576" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/306d61bb-0494-4da3-acab-b39901287a42_576x432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:576,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:32057,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F306d61bb-0494-4da3-acab-b39901287a42_576x432.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Here is a plot of the percent mis-categorized unjustly vs. cohort size, with 32 simulated annual performance reviews for each cohort size. The Welch GE cutoffs were used (bottom 10%, top 20%). I’ve only counted the number of employees who would have been in a </span><em>higher</em><span> category if objective standards were used instead of rank-and-chop; the numbers basically double if we decide to also count employees who are (beneficially) bumped up a category instead of down.&nbsp; My takeaway here is that there’s a very good chance of mis-categorizing 2.5% of a cohort no matter the cohort size, and 5% happens commonly even if the cohort size is a couple hundred.</span></p><p><strong>Size of a pay band</strong><span>: when posting corporate job openings, there’s a marvelous new practice of displaying a salary band (min,max). A casual browse has revealed the tendency that a minimum salary is generally around 0.65x of the maximum, for any given pay band. This allows us to visualize the Pareto distribution </span><em>within a pay band</em><span>, which I haven’t seen done anywhere in the literature yet. For those looking to play along at home: a pay band of 78.1 → 121.2 is centered on 100 and has min/max = 0.65.</span></p><p><strong>Pareto alpha</strong><span>=1.75 this was drawn from a fit to individual salary data in the US (thank you, IPUMS for the data, details below), which can also be cross-checked using the Gini Coefficient as follows: G = 1/(2a-1), where G = 0.4 is commonly cited for the US individual income (not household income!). Note that this one parameter, along with the size of the pay band, is all we need in order to specify the distribution! </span><a href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="nofollow ugc noopener">https://en.wikipedia.org/wiki/Pareto_distribution</a><span> is a great starting place for those who wish to ponder the equations.</span></p><p><strong>Gaussian sigma</strong><span>: the outer edges of the pay band were assumed to be 3 sigma, but using e.g. 2.5 sigma gives similar results. Toss the outliers, which is 0.27% or 1.24% of the simulated data. (Easily justified: HR has rules about staying within the pay band, and is perfectly happy to underpay or overpay folks a little at the edges). Use 7.06 for the 3 sigma scenario, or 8.48 for the 2.5 sigma scenario, fits the 100 +/- 21.2 payband.</span></p><p><strong>Centering at 100 “performance units”</strong><span>: These plots are centered at 100 not so much to represent a salary of $100k, but rather because humans are fond of thinking of things on a scale of 0-100. A fun mathematical aspect of Pareto distributions is that they’re scale-invariant / self-similar, i.e., the dropoff from 100k to 90k is the same as the dropoff from 100 million to 90 million. So the choice of 100 is arbitrary, and the calculations work for any value that you might choose; the only quantity that matters here is the width of the pay band as a percent of, say, the minimum value. And similarly, with the Gaussian, the choice of median is arbitrary, the only thing that matters is sigma / xbar.</span></p><p>Plots are n=25_000</p><p>Perhaps I’ll clean up the Jupyter notebook and put it on GitHub at some point.</p><p>A few takeaways:&nbsp;</p><p>My reading of the more modern literature is that they’ve basically forgotten the Zener &amp; Shockley papers, which I find to have the most compelling data. Regarding Pareto vs. Log-Normal for employee performance (and for individual income): to me, there’s not much practical difference. (I do have my own pet theory about the origin of the Pareto (or LogNormal) in these circumstances, which involves neural networks and hopefully ends with a Renormalization Group universality class, but that’s a bigger project for a later time.) Back to the literature: there are a number of other papers and articles not listed here that champion the idea of “it’s not Gaussian”, but they’re a bit short on listing concrete suggestions on what one should do once that realization sinks in.</p><p>Clarence Zener “Statistical Theories of Success” Proceedings of the National Academy of Sciences Vol. 66, No. 1, pp. 18-24, May 1970</p><p>William Shockley “On the Statistics of Individual Variations of Productivity in Research Laboratories” Proceedings Of The IRE 1957 page 279</p><p>Richard J. Chambers II “Evaluating indicators of job performance: Distributions and types of analyses” Doctoral Dissertation College Of Education Louisiana Tech University November 2016</p><p>Ernest O’Boyle Jr. And Herman Aguinis “The Best And The Rest: Revisiting The Norm Of Normality Of Individual Performance” Personnel Psychology 2012, 65, 79–119</p><p>A. Drăgulescu and V.M. Yakovenkoa “Evidence for the exponential distribution of income in the USA” Eur. Phys. J. B 20, 585–589 (2001)</p><p>A. Christian Silva and Victor M. Yakovenko “Temporal evolution of the thermal and superthermal income classes in the USA during 1983–2001” Europhys. Lett., 69 (2), pp. 304–310 (2005)</p><p>Additionally, I did an AI-assisted literature search to make sure I wasn’t missing anything big and important, which you can access here:</p><p><a href="http://www.undermind.ai/query_app/display_one_search/41a512c42dbfb3065285856443c5399f87b275ff2fb77ec2b41fa5aec8972467/" rel="nofollow ugc noopener">http://www.undermind.ai/query_app/display_one_search/41a512c42dbfb3065285856443c5399f87b275ff2fb77ec2b41fa5aec8972467/</a></p><p>The data that I used to fit the Pareto to individual income (not household income!) came from the variables</p><ol><li><p>INCWAGE (Wage and salary income)</p></li><li><p>ASECWT (Annual Social and Economic Supplement Weight)</p></li></ol><p>from</p><p><span>Sarah Flood, Miriam King, Renae Rodgers, Steven Ruggles, J. Robert Warren, Daniel Backman, Annie Chen, Grace Cooper, Stephanie Richards, Megan Schouweiler, and Michael Westberry. IPUMS CPS: Version 11.0 [dataset]. Minneapolis, MN: IPUMS, 2023. </span><a href="https://doi.org/10.18128/D030.V11.0" rel="nofollow ugc noopener">https://doi.org/10.18128/D030.V11.0</a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Noise-Canceling Single-Layer Woven Silk and Cotton Fabric (149 pts)]]></title>
            <link>https://onlinelibrary.wiley.com/doi/10.1002/adma.202313328</link>
            <guid>42235909</guid>
            <pubDate>Mon, 25 Nov 2024 13:00:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onlinelibrary.wiley.com/doi/10.1002/adma.202313328">https://onlinelibrary.wiley.com/doi/10.1002/adma.202313328</a>, See on <a href="https://news.ycombinator.com/item?id=42235909">Hacker News</a></p>
Couldn't get https://onlinelibrary.wiley.com/doi/10.1002/adma.202313328: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Lonely individuals tend to think and talk in an unusual way, study finds (129 pts)]]></title>
            <link>https://www.psypost.org/lonely-individuals-tend-to-think-and-talk-in-an-unusual-way-study-finds/</link>
            <guid>42234695</guid>
            <pubDate>Mon, 25 Nov 2024 09:40:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/lonely-individuals-tend-to-think-and-talk-in-an-unusual-way-study-finds/">https://www.psypost.org/lonely-individuals-tend-to-think-and-talk-in-an-unusual-way-study-finds/</a>, See on <a href="https://news.ycombinator.com/item?id=42234695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="psypo-1505383099"><p><a href="https://news.google.com/publications/CAAqBwgKMLz2gwsw-5CAAw" aria-label="Follow PsyPost on Google News"><img decoding="async" src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" data-src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" alt="Follow PsyPost on Google News" data-srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w" data-sizes="(max-width: 510px) 100vw, 510px" width="250" height="85" srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w"></a></p></div><p>Two neuroimaging studies found that lonely individuals’ neural representations of well-known celebrities diverged from those typical for their group in the medial prefrontal cortex, a region of the brain. Lonelier individuals were also more likely to use unusual language when describing well-known celebrities and to describe them in ways that were not typical for their group. The research was published in <em>Communications Psychology</em>.</p><p>Loneliness is the subjective feeling of being socially isolated or lacking meaningful connections, regardless of actual social contact. It can arise from life transitions, such as moving, losing a loved one, or retiring, as well as from social rejection or a lack of supportive relationships.</p><p>Chronic loneliness is linked to mental health issues like depression and anxiety, as well as physical health problems, including weakened immunity, cardiovascular disease, and an increased risk of mortality. Lonely individuals tend to experience lower self-esteem, heightened sensitivity to social rejection, and difficulty forming or maintaining relationships. They may also perceive social interactions more negatively, creating a cycle that reinforces their isolation. In older adults, loneliness is particularly concerning, as it is strongly associated with cognitive decline and dementia. In children and adolescents, it can hinder social development and academic performance.</p><p>Study author Timothy W. Broom and his colleagues hypothesized that lonely individuals form mental representations of contemporary culture that deviate from those generally accepted in their social environment. In other words, they think in unusual ways. Because of this, lonely individuals tend to perceive that their ideas are not shared by others, which is a defining feature of loneliness.</p><p>Research has shown that socially connected individuals (e.g., friends or romantic partners) tend to have similar neural responses to popular culture media. Building on this, the researchers hypothesized that lonely individuals would have neural responses to popular culture topics (e.g., celebrities) that differ from those of the majority in their group. Additionally, the way they speak about these topics would also be unusual. The researchers conducted two studies to explore these ideas.</p><p>The first study analyzed functional magnetic resonance imaging (fMRI) data collected from two groups of participants, consisting of 80 individuals in total, with an average age of 20–21 years. While undergoing fMRI scans, participants completed an evaluation asking them to assess their own traits, traits of selected close others, acquaintances, and five well-known celebrities (Justin Bieber, Ellen DeGeneres, Kim Kardashian, Barack Obama, and Mark Zuckerberg). They also rated how close they felt to each of the individuals they evaluated and completed a separate assessment of loneliness using the UCLA Loneliness Scale.</p><p>The second study was an online survey conducted with 923 Amazon Mechanical Turk workers, whose average age was 40 years. Participants completed the same loneliness assessment as in the first study and answered a series of questions about a prominent celebrity. Participants were first given a list of 10 celebrities and asked to indicate which ones they were familiar with. A celebrity from their list was then randomly chosen, and participants were asked to describe that celebrity in their own words, as if they were describing them to a friend. Following this, participants rated how close they felt to the celebrity and assessed the extent to which the celebrity possessed various psychological traits from a presented list.</p><p>The results of the first study indicated that lonely participants’ neural representations of celebrities diverged from those of the rest of the group. Pairwise comparisons of participants’ brain responses while performing the celebrity evaluation task focused on the medial prefrontal cortex, a region of the brain involved in encoding and retrieving social knowledge. The researchers found that brain responses of lonely individuals in this region were less similar to those of other participants, compared to individuals who felt less lonely. This likely suggests that lonely individuals think about celebrities in more unusual ways.</p><p>Interestingly, the study also revealed a particularly strong consensus among participants regarding the neural representations of Justin Bieber compared to the other four celebrities.</p><p>In the second study, the researchers conducted a text analysis using Google’s Universal Sentence Encoder to examine the descriptions participants provided about celebrities. They computed the semantic similarity between all possible pairs of participant texts. The analysis revealed that texts written by lonelier individuals tended to be less similar to those written by other participants. Moreover, lonelier individuals were more likely to report feeling that their perceptions of celebrities were inaccurate or not shared by those around them.</p><p>“Shared reality fosters social connections between people and increases confidence in one’s knowledge because it is corroborated by others. Our findings provide evidence that loneliness is associated with deviations from the zeitgeist, specifically when it comes to perceptions of well-known celebrities,” the study authors concluded.</p><p>“Loneliness corresponded with idiosyncratic [unusual, unique] neural representations of celebrities as well as more idiosyncratic communication about celebrities, particularly when an otherwise strong consensus existed between less lonely people. Lonely individuals’ feeling that their ideas are not shared by the people around them is more than metaphorical; it is objectively reflected in idiosyncratic knowledge of contemporary culture that strays from the consensus.”</p><p>This study contributes to the scientific understanding of loneliness. However, it primarily focused on chronic loneliness, as assessed by the study’s measures. Loneliness can also be a temporary or transitory state, and it remains uncertain whether these findings apply solely to chronically lonely individuals or if they also extend to temporary experiences of loneliness.</p><p>The paper, “<a href="https://doi.org/10.1038/s44271-024-00088-3">Loneliness corresponds with neural representations and language use that deviate from shared cultural perceptions,</a>” was authored by Timothy W. Broom, Siddhant Iyer, Andrea L. Courtney, and Meghan L. Meyer.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I have resigned from the Royal Society (129 pts)]]></title>
            <link>http://deevybee.blogspot.com/2024/11/why-i-have-resigned-from-royal-society.html</link>
            <guid>42234497</guid>
            <pubDate>Mon, 25 Nov 2024 09:03:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://deevybee.blogspot.com/2024/11/why-i-have-resigned-from-royal-society.html">http://deevybee.blogspot.com/2024/11/why-i-have-resigned-from-royal-society.html</a>, See on <a href="https://news.ycombinator.com/item?id=42234497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1326298114103223151" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2Y-vThaI32BMolboVeqFScPWCpnjWhhmMRnj_tIxkrmET28q_V0IK0kYMFC_eH9ptMiYOyPhMK3Dexs3gLkB6ClY3Po2CaiyINEPcxv8G88dGEBA8J1xTS5753holfA3TOyt58ymqZ0XDC7TeplvQeAQNCePpiaTsmZA3IgbxwxLlLBJvLNdjch7DSBc/s800/TRS_location_image_1.jpg"><img data-original-height="300" data-original-width="800" height="120" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2Y-vThaI32BMolboVeqFScPWCpnjWhhmMRnj_tIxkrmET28q_V0IK0kYMFC_eH9ptMiYOyPhMK3Dexs3gLkB6ClY3Po2CaiyINEPcxv8G88dGEBA8J1xTS5753holfA3TOyt58ymqZ0XDC7TeplvQeAQNCePpiaTsmZA3IgbxwxLlLBJvLNdjch7DSBc/s320/TRS_location_image_1.jpg" width="320"></a></p><p>The Royal Society is a venerable institution founded in 1660, whose original members included such eminent men as Christopher Wren, Robert Hooke, Robert Boyle and Isaac Newton. It promotes science in many ways: administering grants, advising government, holding meetings and lectures, and publishing expert reports on scientific matters of public importance. &nbsp;</p><div><p>There are currently around 1,800 Fellows and Foreign Members of the Royal Society, all elected through a <a href="https://royalsociety.org/fellows-directory/election" target="_blank">stringent and highly competitive process</a> which includes nomination by two Fellows of the Royal Society (FRS), detailed scrutiny of the candidate's achievements and publications, reports by referees, and consideration by a committee of experts in their broad area of research. &nbsp;Although most Fellows are elected on the basis of their scientific contributions, others are nominated on the basis of "<i>wider contributions to science, engineering or medicine through leadership, organisation, scholarship or communication</i>".</p><div><p>For many scientists, election to the Royal Society is the pinnacle of their scientific career. It establishes that their achievements are recognised as exceptional, and the title FRS brings immediate respect from colleagues. Of course, things do not always work out as they should. Some Fellows may turn out to have published fraudulent work, or go insane and start promoting crackpot ideas. Although there are procedures that allow a fellow to be expelled from the Royal Society, I have been told this has not happened for over 150 years. It seems that election as a Fellow of the Royal Society, like loss of virginity, is something that can't readily be reversed.</p><div><p>This brings us, then, to the case of Elon Musk, who was <a href="https://royalsociety.org/people/elon-musk-13829/" target="_blank">elected as a Fellow of the Royal Society in 2018</a>&nbsp;on the basis of his technological achievements, notably in space travel and electrical vehicle development. Unfortunately,  since that time, his interests have extended to <a href="https://www.nbcnews.com/tech/social-media/elon-musk-turned-x-trump-echo-chamber-rcna174321" target="_blank">using social media for political propaganda</a>, while at the same time battling what he sees as "<a href="https://eu.usatoday.com/story/tech/2024/07/22/elon-musk-jordan-peterson-interview/74506785007/" target="_blank">woke mind virus</a>" and <a href="https://www.nbcnews.com/tech/tech-news/elon-musk-worries-free-speech-advocates-calls-prosecute-researchers-cr-rcna179194" target="_blank">attacks on free speech</a>.  Whereas previously he seemed to agree with mainstream scientific opinion on issues such as climate change and medicine, over the past year or two, he's started promoting alternative ideas. &nbsp;&nbsp;</p><div><p>In summer of 2024, a number of FRSs became concerned at how Musk was using his social media platform (previously Twitter, now termed X) to stir up racial unrest and anti-government sentiment in the UK.  Notable tweets by him from this period included incendiary comments and frank misinformation, as documented in this <a href="https://www.theguardian.com/commentisfree/article/2024/aug/09/uk-far-right-riots-elon-musk-x" target="_blank">Guardian article</a>.&nbsp;</p><div><p>This led to a number of Fellows expressing dismay that Musk had been elected. There was no formal consultation of the Fellowship but via informal email contacts, a group of 74 Fellows formulated a letter of concern that was sent in early August to the President of the Royal Society, raising doubts as to whether he was "<i>a fit and proper person to hold the considerable honour of being a Fellow of the Royal Society".</i>&nbsp;The letter specifically mentioned the way Musk had used his platform on X to make unjustified and divisive statements that served to inflame right-wing thuggery and racist violence in the UK.&nbsp;</p><div><p>I gather that at this point the Royal Society Council opted to consult a top lawyer to determine whether Musk's behaviour breached their Code of Conduct.  The problem with this course of action is that if you are uncertain about doing something that seems morally right but may have consequences, then it is easy to find a lawyer who will advise against doing it. That's just how lawyers work. They're paid to rescue people from ethical impulses that may get them into trouble.  And, sure enough, the lawyer determined that Musk hadn't breached the Code of Conduct.  If you want to see if you agree, you can find the Code of Conduct <a href="https://royalsociety.org/about-us/how-we-are-governed/governance" target="_blank">here</a>.</p><p>Many of the signatories of the letter, including me, were unhappy with this response.  We set about assembling further evidence of behaviours incompatible with the Code of Conduct.  There is a lot of material, which can be broadly divided into two categories, depending on whether it relates to "Scientific conduct" or "Principles". &nbsp;</p><div><p>
  

On <b>Scientific conduct</b>, the most relevant points from the Code of Conduct are:</p><blockquote><p><i>
  
2.6. Fellows and Foreign Members shall carry out their scientific research with regard to the Society's statement on research integrity and to the highest standards.&nbsp;</i></p><p><i>2.10. Fellows and Foreign Members shall treat all individuals in the scientific enterprise collegially and with courtesy, including supervisors, colleagues, other Society Fellows and Foreign Members, Society staff, students and other early‐career colleagues, technical and clerical staff, and interested members of the public.&nbsp;</i></p><p><i>2.11. Fellows and Foreign Members shall not engage in any form of discrimination, harassment, or bullying.</i></p></blockquote><div><p>Most of those I've spoken to agree that a serious breach of these principles was in 2022, when <a href="https://x.com/elonmusk/status/1601894132573605888?s=20&amp;t=aLV0JH6LGhKMYKYed2T9Fw" target="_blank">Musk tweeted</a>: "<i>My pronouns are Prosecute/Fauci</i>", thereby managing to simultaneously offend the LGBTQ community, express an antivaxx sentiment, and put Fauci, <a href="https://www.theguardian.com/us-news/article/2024/jun/03/anthony-fauci-covid-19-threats-harassment" target="_blank">already under attack from antivaxxers</a>, at further risk.  Fauci was not a Fellow at the time these comments were made, but that should not matter given the scope of the statement is "<i>individuals in the scientific community</i>".  This incident was <a href="https://www.cbsnews.com/news/elon-musk-anthony-fauci-viral-tweet-backlash-health-experts/" target="_blank">covered by CBS News.</a></p><p>Now that the US election is over, Musk seems emboldened to ramp up his attacks. On 19th November 2024, he&nbsp;<a href="https://x.com/elonmusk/status/1858873877184627039?s=58&amp;t=RqV9ku4ADjOWHIF2HcuosQ" target="_blank">retweeted this</a> to his millions of followers, followed by a <a href="https://x.com/elonmusk/status/1859596285549920658?s=58&amp;t=RqV9ku4ADjOWHIF2HcuosQ" target="_blank">compilation of attacks</a> on Fauci on 21st November,</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-zZemJ-PPwsC6435Xfdf_jg-kbsqzKuam70Da9TDWjBk03RwGvKQMyV2s0dbcok7QmTUPxqIZz5B6BPh6J56pnk0wap3G3Fg9VSKaKVPgKu6bwKmUFLaReQFMcc-wk7T1O_LQOlayiVleniufKTA38fFtDlLWYKqlmqvzWoTW6HdNCQGgTMFyVdemK8s/s548/Screenshot%202024-11-24%20at%2010.43.21.png"><img data-original-height="548" data-original-width="467" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-zZemJ-PPwsC6435Xfdf_jg-kbsqzKuam70Da9TDWjBk03RwGvKQMyV2s0dbcok7QmTUPxqIZz5B6BPh6J56pnk0wap3G3Fg9VSKaKVPgKu6bwKmUFLaReQFMcc-wk7T1O_LQOlayiVleniufKTA38fFtDlLWYKqlmqvzWoTW6HdNCQGgTMFyVdemK8s/s320/Screenshot%202024-11-24%20at%2010.43.21.png" width="273"></a></p><p><b><i>Neuralink</i></b></p><p>There are also questions about the management of Musk's research project, Neuralink, which involves developing a brain-computer interface to help people who are paralysed.  While this is clearly a worthy goal, his approach to conducting research is characterised by refusal to let anyone interfere with how he does things. This has led to <a href="https://pcrm.widen.net/s/llzr7cg57q/request-for-glp-investigation-re-neuralink---with-enclosures---12.13.22" target="_blank">accusations of failure to adhere to regulatory procedures for Good Laboratory Practic</a>e. For instance, consider these quotes from <a href="https://spectrum.ieee.org/neuralink-human-trials" target="_blank">this article</a>:&nbsp;</p><div><div><blockquote><i>'I think what concerns people is that Neuralink could be cutting corners, and so far nobody has stopped them,' says Nick Ramsey, a clinical neuroscientist at University Medical Center Utrecht, in the Netherlands. &nbsp;</i><i>There’s an incredible push by Neuralink to bypass the conventional research world, and there’s little interaction with academics, as if they think that we’re on the wrong track—that we’re inching forward while they want to leap years forward.</i></blockquote></div><div><blockquote><i>In response to Musk's claim that no monkey had died because of Neuralink, the Physicians Committee for Responsible Medicine wrote to the SEC, claiming Musk’s comments were false. The group said it had obtained veterinary records from Neuralink’s experiments showing that at least 12 young, healthy monkeys were euthanized as a result of problems with Neuralink’s implant. The group alleged that Musk’s comments are misleading investors, and urged SEC regulators to investigate Musk and Neuralink for securities fraud.</i></blockquote></div><div><p>The problems with Neuralink do not stop with the ethics of the animals and the secrecy surrounding them.  In a <a href="https://doi.org/10.1038/d41586-024-00304-4" target="_blank">piece in Nature</a>, various scientists were interviewed about the first human trial that was conducted earlier this year. The main concern was lack of transparency. Human trials are usually recorded in <i>clinical.trials.gov</i>, which was set up precisely to make it easier to track if studies had followed a protocol.  Musk did not do this. His approach to the human trials again reflects his distaste for any regulations.  But the regulations are there for a purpose, and one would expect a Fellow of the Royal Society to abide by them; otherwise we end up with scandals such as <a href="https://www.panmacmillan.com/blogs/literary/theranos-elizabeth-holmes-john-carreyrou" target="_blank">Theranos</a>&nbsp;or the <a href="https://www.science.org/content/article/two-controversial-stem-cell-trials-could-harm-patients-critics-say" target="_blank">stem cell experiments</a> by Macchiarini and Birchall. The <a href="https://www.statnews.com/2024/07/08/neuralink-elon-musk-scientific-ethics-brain-computer-interface/" target="_blank">ethics of this kind of trial</a> also needs careful handling, especially in terms of the patient's understanding of possible adverse effects, their expectations of benefits, and the undertaking of researchers to provide long-term support for the prosthesis.</p><div><p>
  

If we turn to the more general issues that come under <b>Principles</b>, then the Code of Conduct states:&nbsp;</p><div><blockquote><i>Fellows and Foreign Members shall not act or fail to act in any way which would undermine the Society's mission or bring the Society into disrepute</i>.</blockquote></div><p>&nbsp;Here are some examples that I would regard as contrary to the Society's mission.</p><div><p><b><i>
  

 
Promoting vaccine hesitation</i></b></p><p>The Royal Society has done good work promoting public understanding of vaccines, as with<a href="https://royalsociety.org/blog/2021/01/why-we-know-vaccines-work/" target="_blank"> this blogpost</a> by Charles Bangham FRS.  In contrast, <a href="https://www.livemint.com/news/world/elon-musk-factchecked-after-misleading-post-on-covid-19-vaccine-efficacy-know-more-11697730755260.html" target="_blank">as described here</a>, Musk has promoted <a href="https://www.bbc.com/news/health-66313916" target="_blank">vaccine conspiracy theories</a> and anti-vaccine views on his platform. 
<a href="https://x.com/elonmusk/status/1817357502725407024" target="_blank">This Tweet</a> had 85 million views:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgg3N6oEahfkSpd0OHN-VK6TtLpOZMbP9r5VGszAJn4Vnha17tlUxfuZlhJf6SsHND_1mIO5OR__l5JYFqOVvLUdLj3yR_hCHs_G_yUeOiRcK_rsj89RE81ubkWmRQp3Y3cSWQhne03NMyDRHPY5jWZVhTbj_Hqtl2mEsL7RMz7U9H7K2My6TmzTODgjQY/s338/dead%20unvacc.png"><img data-original-height="338" data-original-width="295" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgg3N6oEahfkSpd0OHN-VK6TtLpOZMbP9r5VGszAJn4Vnha17tlUxfuZlhJf6SsHND_1mIO5OR__l5JYFqOVvLUdLj3yR_hCHs_G_yUeOiRcK_rsj89RE81ubkWmRQp3Y3cSWQhne03NMyDRHPY5jWZVhTbj_Hqtl2mEsL7RMz7U9H7K2My6TmzTODgjQY/s320/dead%20unvacc.png" width="279"></a></p><br><div><p><b><i>
  
 
Downplaying the climate emergency </i></b></p><p>In 2023 Musk <a href="https://www.theguardian.com/environment/2023/nov/20/elon-musk-green-credentials-clean-energy-climate-deniers" target="_blank">played down the seriousness of climate change</a>, and 2024 participated in a bizarre <a href="https://www.theguardian.com/environment/article/2024/aug/13/trump-musk-x-climate" target="_blank">interview with Donald Trump</a>, which dismayed climate experts.  Among the commenters was Michael Mann, who said “<i>It is sad that Elon Musk has become a climate change denier, but that’s what he is. He’s literally denying what the science has to say here</i>.”  Mann was elected as a Foreign Member of the Royal Society in 2024.</p><div><p><b><i>
  
 
Spreading deep fakes and misinformation on X</i></b></p><p>As recently as 2022, the Royal Society published<a href="https://royalsociety.org/-/media/policy/projects/online-information-environment/the-online-information-environment.pdf" target="_blank"> a report</a>&nbsp;in which Frank Kelly (FRS) <span>noted&nbsp;<span>the high priority that the Royal Society gives to accurate scientific communication:</span></span></p><div><div><blockquote><i>The Royal Society’s mission since it was established in 1660 has been to promote science for the benefit of humanity, and a major strand of that is to communicate accurately. But false information is interfering with that goal. It is accused of fuelling mistrust in vaccines, confusing discussions about tackling the climate crisis and influencing the
debate about genetically modified crops.&nbsp;</i></blockquote></div><div><blockquote><i>&nbsp;Musk’s reason for buying Twitter was to influence the social discourse. And influence he did—by using his enormous platform (203 million followers) to endorse Trump, spread disinformation about voter fraud and deep fakes of Kamala Harris, and amplify conspiracy theories about everything from vaccines to race replacement theory to misogyny.</i></blockquote><p>The most recent development is the announcement that Musk is to be co-director of the new Department of Government Efficiency (DOGE, an allusion to the cryptocurrency Dogecoin) in the Trump Administration, with a brief to cut waste and bureaucracy. The future for US science is starting to look bleak, with Musk being given unfettered powers to cut budgets to NIH and NASA, among others. &nbsp;<a href="https://x.com/america/status/1857228761915412814" target="_blank">This tweet</a>, which he endorsed, indicates that rather than using objective evidence, the cuts will fall on those who have criticized Trump, who will find bowdlerized summaries of their work used to generate public outrage. The tweet reads: &nbsp;"<i>Here’s what the U.S. Government wasted $900 Billion of your tax dollars on in 2023.  The Department of Government Efficiency (@DOGE) will fix this. America deserves leaders that prioritize sensible spending</i>" before presenting a chart listing items for cuts, with unsourced descriptions of expenditure, including:</p><div><div><ul><li><i>Dr Fauci's monkey business on NIH's "monkey island": &nbsp; $33,200,000&nbsp;</i></li><li><i>NIH's meth-head monkeys: &nbsp;portion of $12,000,000&nbsp;</i></li><li><i>Dr Fauci's transgender monkey study: $477,121</i></li></ul><p>I'm sad to say I agree with Alex Wild, Curator of Entomology at University of Texas Austin, who&nbsp;<a href="http://deevybee.blogspot.com/2024/11/%22https://bsky.app/profile/alexwild.bsky.social/post/3lbmvdzmxos2e" target="_blank">wrote</a>&nbsp;a few days ago: <i>"I hope federally funded scientists are preparing for large scale, bad faith attacks by Musk and his troll army. &nbsp;It’s pretty clear the DOGE operation is going to take snippets of grant proposals and papers, present them out of context, and direct weaponized harassment of individual people."</i></p></div><div><p><b>What next? &nbsp;</b></p><p>I've been told that in the light of the evolving situation, the Royal Society Council will look again at the case of Elon Musk.  In conversations I have had with them, they emphasise that they must adhere to their own procedures, which are specified in the Statutes, and which involve a whole series of stages of legal scrutiny, committee evaluation, discussion with the Fellow in question,  and ultimately a vote from the Fellowship, before a Fellow or Foreign Member could be expelled. While I agree that if you have a set of rules you should stick to them, I find the fact that nobody has been expelled for over 150 years telling. It does suggest that the Statutes are worded so that it is virtually impossible to do anything about Fellows who breach the Code of Conduct. In effect the Statutes serve a purpose of protecting the Royal Society from ever having to take action against one of its Fellows.</p><div><p>In the course of investigating this blogpost, I've become intimately familiar with the Code of Conduct, which requires me to "<i>treat all individuals in the scientific enterprise collegially and with courtesy, including ... foreign Members</i>".   I'm not willing to treat Elon Musk "<i>collegially and with courtesy</i>".  Any pleasure I may take in the distinction of the honour of an FRS is diminished by the fact it is shared with someone who appears to be modeling himself on a Bond villain, a man who has immeasurable wealth and power which he will use to threaten scientists who disagree with him. Accordingly, last week I resigned my FRS. I don't do this in the expectation of having any impact: in the context of over 350 years of Royal Society history, this is just a blip. I just feel far more comfortable to be dissociated from an institution that continues to honour this disreputable man.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><p><span>Note: Comments will be accepted if they are by a named individual, civil, and on topic. They are moderated and there may be a delay before they appear online.&nbsp;</span></p></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deprecating outdated issues on the GitHub public roadmap (104 pts)]]></title>
            <link>https://github.com/github/roadmap/discussions/1014</link>
            <guid>42234415</guid>
            <pubDate>Mon, 25 Nov 2024 08:48:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/github/roadmap/discussions/1014">https://github.com/github/roadmap/discussions/1014</a>, See on <a href="https://news.ycombinator.com/item?id=42234415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="7514944" data-target-translation-type="discussion">
        <tr>
    <td>
        <h2 dir="auto"><strong>Deprecating Outdated Issues on the GitHub Public Roadmap</strong></h2>
<p dir="auto">At GitHub, transparency and clarity are at the heart of our relationship with the community. As part of our ongoing efforts to keep you informed about our product roadmap, we’ve already begun hosting <a href="https://github.com/roadmap-webinar-series">quarterly roadmap webinars</a> to share updates and engage with the community in real-time.</p>
<p dir="auto"><strong>This week, we’re taking the next step in achieving our roadmap goals by refreshing the public roadmap project board.</strong></p>
<p dir="auto">After an in-depth review, we’ve identified a number of open issues that have become outdated over time—some for several years. To better align with our current product direction and to build trust with our users, we are deprecating these outdated issues and updating the board with new and accurate information.</p>
<p dir="auto">This refresh will make it easier for you to follow our progress, ensure higher-quality updates, and provide a more accurate reflection of GitHub’s development priorities. Moving forward, we are also committing to regular updates, so you can rely on the roadmap as a trusted source of information about GitHub’s ongoing and upcoming features.</p>
<h3 dir="auto"><strong>What’s Changing?</strong></h3>
<ul dir="auto">
<li><strong>Deprecation of Outdated Issues:</strong> We will be removing a number of issues that are no longer relevant due to changes in priorities or project timelines. These issues have been stagnant and no longer represent our product direction.</li>
<li><strong>Full Board Refresh:</strong> A complete update to the roadmap board will be made, adding new features and plans that better reflect where GitHub is headed.</li>
<li><strong>Ongoing Maintenance:</strong> To ensure the roadmap stays accurate, we will be conducting regular reviews and updates.</li>
</ul>
<h3 dir="auto"><strong>FAQ</strong></h3>
<p dir="auto"><strong>Why are we deprecating these issues?</strong></p>
<ul dir="auto">
<li>Many of the issues marked for deprecation are out of date and no longer align with GitHub’s current roadmap. By cleaning up the board, we aim to provide more accurate, actionable insights to the community.</li>
</ul>
<p dir="auto"><strong>What can I expect from the refreshed roadmap?</strong></p>
<ul dir="auto">
<li>The refreshed roadmap will feature up-to-date information about new initiatives and priorities. Our goal is to make the roadmap a reliable resource that users can check regularly for accurate and relevant details.</li>
</ul>
<p dir="auto"><strong>Will the roadmap be updated regularly?</strong></p>
<ul dir="auto">
<li>Yes! We’re committing to regularly updating the roadmap to ensure it reflects the latest developments. This is part of our effort to build and maintain trust with our community.</li>
</ul>
<p dir="auto"><strong>What should I do if an issue I care about is deprecated?</strong></p>
<ul dir="auto">
<li>While some issues may no longer be represented in the public roadmap, we are always listening to community feedback. If you have concerns about a specific feature or request, feel free raise your thoughts in the <a href="https://github.com/orgs/community/discussions">discussions</a>.</li>
</ul>
<h3 dir="auto"><strong>Deprecated Issues</strong></h3>
<p dir="auto">As part of this update, the following issues will be deprecated. If you have questions on a specific issue/roadmap item, please reach out to your GitHub contact.</p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>Deprecated Issue</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/github/roadmap/issues/355" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/355/hovercard">Command Palette [GA]</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/637" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/637/hovercard">GitHub Actions: Secure Shell Debugging (Beta)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/988" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/988/hovercard">Actions: Managing Environments at Scale</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/930" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/930/hovercard">GitHub Actions: Artifacts v4 available in GitHub Enterprise Server</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/474" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/474/hovercard">Precise code navigation for Java</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/371" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/371/hovercard">Precise code navigation for JavaScript and TypeScript</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/277" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/277/hovercard">Issue level custom metadata</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/274" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/274/hovercard">Ability to add a project to a project</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/276" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/276/hovercard">Cross repository milestones and labels</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/281" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/281/hovercard">Create custom automation flows</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/816" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/816/hovercard">Projects: Activity History</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/761" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/761/hovercard">Projects: Updated Projects header</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/760" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/760/hovercard">[Public Beta] Issue Hierarchy powered by Tasklists</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/560" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/560/hovercard">Packages: Granular permissions and easy organization sharing for enterprise customers</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/578" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/578/hovercard">Packages: maven - granular permissions and easy organization sharing</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/636" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/636/hovercard">GitHub Actions secrets improvements for Reusable workflows [GA]</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/824" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/824/hovercard">More control over required status checks for pull requests using merge queue</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/552" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/552/hovercard">Reply to PR-level comments</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/537" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/537/hovercard">Codespaces: Pull Request Validation for prebuild-enabled repositories</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/828" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/828/hovercard">Pull Request Dashboard</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/946" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/946/hovercard">Dependabot on Actions Forced Migration</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/969" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/969/hovercard">Secret scanning push protection for gists</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/449" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/449/hovercard">Secret scanning: Extend coverage to Actions logs</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/494" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/494/hovercard">Dependabot alerts shows transitive dependency paths</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/756" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/756/hovercard">GHES Cluster High Availability</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/581" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/581/hovercard">Open ID Connect (OIDC) for GHEC Audit Log Streaming to Azure Blob Storage</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/360" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/360/hovercard">Azure AD (AAD) Service Principal Support for GHEC EMUs (Beta)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/772" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/772/hovercard">GitHub Actions Starter workflow improvements</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/774" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/774/hovercard">Automatic security check information on each Actions listing</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/982" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/982/hovercard">Actions: Private networking for GitHub-hosted macOS runners</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/791" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/791/hovercard">Security manager improvements and custom organization security roles (Preview)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/921" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/921/hovercard">Expanding access to historical log data via audit log exports (Preview)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/781" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/781/hovercard">Code security transaction report in PDF</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/916" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/916/hovercard">Code scanning: AI-powered autofixes for CodeQL alerts integrated into VS Code</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/993" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/993/hovercard">Increase GitHub Enterprise Importer's (GEI) repository size limit to 40GB (Preview)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap-internal/issues/1423">Enterprise Apps and installation automation (Public Beta)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/627" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/627/hovercard">GitHub Security Advisory private forks support Actions</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/773" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/773/hovercard">GitHub Actions configuration variables - GA</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/821" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/821/hovercard">Actions: Outbound network control for GitHub-hosted runners</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/753" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/753/hovercard">Enterprise access for GitHub apps</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/534" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/534/hovercard">Codespaces: Private networking with Azure VNETs (Preview)</a></td>
</tr>
<tr>
<td><a href="https://github.com/github/roadmap/issues/347#top" data-hovercard-type="issue" data-hovercard-url="/github/roadmap/issues/347/hovercard">Commenting on unchanged lines in a pull request</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">We appreciate your understanding as we make these changes. Our aim is to keep you better informed and involved in our development process. Thank you for being a valued member of the GitHub community!</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge's Investigation into Patent Troll Results in Criminal Referrals (113 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/11/judges-investigation-patent-troll-ip-edge-results-criminal-referrals</link>
            <guid>42234147</guid>
            <pubDate>Mon, 25 Nov 2024 07:55:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/11/judges-investigation-patent-troll-ip-edge-results-criminal-referrals">https://www.eff.org/deeplinks/2024/11/judges-investigation-patent-troll-ip-edge-results-criminal-referrals</a>, See on <a href="https://news.ycombinator.com/item?id=42234147">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span></span><span>In 2022, three companies with strange names and no clear business purpose beyond&nbsp; patent litigation filed dozens of lawsuits in Delaware federal court, accusing businesses of all sizes of patent infringement. Some of these complaints claimed patent rights over basic aspects of modern life; one, for example, involved a&nbsp; </span><a href="https://www.eff.org/deeplinks/2023/02/stupid-patent-month-clocking-work-app"><span>patent that pertains to the process of clocking in to work through an app</span></a><span>.</span></p>
<p><span>These companies–named Mellaconic IP, Backertop Licensing, and Nimitz Technologies–seemed to be typical examples of “patent trolls,”</span> <span>companies whose primary business is suing others over patents or demanding licensing fees rather than providing actual products or services.&nbsp;</span></p>
<p><span>However, the cases soon took an unusual turn. The Delaware federal judge overseeing the cases, U.S. District Judge Colm Connolly, sought more information about the patents and their ownership. One of the alleged owners was a food-truck operator who had been promised “passive income,” but was entitled to only a small portion of any revenue generated from the lawsuits. Another owner was the spouse of an attorney at IP Edge, the patent-assertion company linked to all three LLCs.&nbsp;</span></p>
<p><span>Following an extensive investigation, the judge determined that attorneys associated with these shell companies had violated legal ethics rules. He pointed out that the attorneys may have misled Hau Bui, the food-truck owner, about his potential liability in the case. Judge Connolly wrote:&nbsp;</span></p>
<blockquote><p><span>[T]he disparity in legal sophistication between Mr. Bui and the IP Edge and Mavexar actors who dealt with him underscore that counsel's failures to comply with the Model Rules of Professional Conduct while representing Mr. Bui and his LLC in the Mellaconic cases are not merely technical or academic.</span></p>
</blockquote>
<p><span>Judge Connolly also concluded that IP Edge, the patent-assertion company behind hundreds of patent lawsuits and linked to the three LLCs, was the “de facto owner” of the patents asserted in his court, but that it attempted to hide its involvement. He wrote, “IP Edge, however, has gone to great lengths to hide the ‘we’ from the world,” with "we" referring to IP Edge. Connolly further noted, “IP Edge arranged for the patents to be assigned to LLCs it formed under the names of relatively unsophisticated individuals recruited by [IP Edge office manager] Linh Deitz.”&nbsp;</span></p>
<p><span>The judge </span><a href="https://news.bloomberglaw.com/ip-law/judges-litigation-funding-probe-reveals-ip-edges-human-toll"><span>referred</span></a><span> three IP Edge attorneys to the </span><a href="https://www.bloomberglaw.com/public/desktop/document/NimitzTechnologiesLLCvCNETMediaIncDocketNo121cv01247DDelAug302021/12?doc_id=X1MU2O97VP39OFRLOSOF11VA4JP"><span>Supreme Court of Texas’ Unauthorized Practice of Law Committee</span></a><span> for engaging in “unauthorized practices of law in Texas.” Judge Connolly also sent a </span><a href="https://www.bloomberglaw.com/public/desktop/document/NimitzTechnologiesLLCvCNETMediaIncDocketNo121cv01247DDelAug302021/11?doc_id=X2DE7OM6SOT9VIOU8VQAC5CBUSF"><span>letter to the Department of Justice</span></a><span>, suggesting an investigation into “individuals associated with IP Edge LLC and its affiliate Maxevar LLC.”&nbsp;</span></p>
<h3><span>Patent Trolls Tried To Shut Down This Investigation</span></h3>
<p><span>The attorneys involved in this wild patent trolling scheme challenged Judge Connolly’s authority to proceed with his investigation. However, because transparency in federal courts is essential and applicable to all parties, including patent assertion entities, </span><a href="https://www.eff.org/deeplinks/2022/12/judges-investigation-patent-trolls-must-be-allowed-move-forward"><span>EFF and two other patent reform groups filed a brief in support of the judge’s investigation</span></a><span>. The brief argued that “[t]he public has a right—and need—to know who is controlling and benefiting from litigation in publicly-funded courts.” Companies targeted by the patent trolls, as well as the Chamber of Commerce, filed their own briefs supporting the investigation.&nbsp;</span></p>
<p><span>The </span><a href="https://www.eff.org/files/2022/12/08/44_-_order_denying_nimitz_writ.pdf"><span>appeals court sided with us</span></a><span>, </span><a href="https://www.eff.org/deeplinks/2022/12/victory-judges-critical-investigation-patent-troll-companies-can-move-forward"><span>upholding</span></a><span> Judge Connolly’s authority to proceed, which led to the referral of the involved attorneys to the disciplinary counsel of their respective bar associations.&nbsp;</span></p>
<p><span>After this damning ruling, one of the patent troll companies and its alleged owner made a final effort at appealing this outcome. In July of this year, the U.S. Court of Appeals for the Federal Circuit </span><a href="https://cafc.uscourts.gov/opinions-orders/23-2367.OPINION.7-16-2024_2350699.pdf"><span>ruled </span></a><span>that investigating Backertop Licensing LLC and ordering its alleged owner to testify was “an appropriate means to investigate potential misconduct involving Backertop.”&nbsp;</span></p>
<p><span>In EFF’s view, these types of investigations into the murky world of patent trolling are not only appropriate but should happen more often. Now that the appeals court has ruled, let’s take a look at what we learned about the patent trolls in this case.&nbsp;</span></p>
<h3><span>Patent Troll Entities Linked To French Government</span></h3>
<p><span>One of the patent trolling entities, Nimitz Technologies LLC, asserted a single patent, U.S. Patent No. 7,848,328, against 11 companies. When the judge required Nimitz’s supposed owner, a man named Mark Hall, to testify in court, Hall could not describe anything about the patent or explain how Nimitz acquired it. He didn’t even know the name of the patent (“Broadcast Content Encapsulation”). When asked what technology was covered by the patent, he said, “I haven’t reviewed it enough to know,” and when asked how he paid for the patent, Hall replied, “no money exchanged hands.”&nbsp;</span></p>
<p><span>The exchange between Hall and Judge Connolly went as follows:&nbsp;</span></p>
<blockquote><p><span>Q. S</span>o how do you come to own something if you never paid for it with money?</p>
<p>A. I wouldn't be able to explain it very well. That would be a better question for Mavexar.</p>
<p>Q. Well, you're the owner?</p>
<p>A. Correct.</p>
<p>Q. How do you know you're the owner if you didn't pay anything for the patent?</p>
<p>A. Because I have the paperwork that says I'm the owner.</p>
</blockquote>
<p><span>(</span><a href="https://www.eff.org/document/nimitz-technologies-v-cnet-et-al-memorandum-order"><span>Nov. 27, 2023 Opinion</span></a><span>, pages 8-9.)&nbsp;</span></p>
<p><span>The Nimitz patent originated from the Finnish cell phone company Nokia, which later&nbsp;assigned it and several other patents to France Brevets, a French sovereign investment fund, in 2013. France Brevets, in turn, assigned&nbsp;the patent to a US company called Burley Licensing LLC, an entity linked to IP Edge, in 2021. Hau Bui (the food truck owner) signed on behalf of Burley, and Didier Patry, </span><a href="https://www.privateequitywire.co.uk/didier-patry-appointed-ceo-france-brevets-sovereign-investment-fund/"><span>then the CEO of France Brevets</span></a><span>, signed on behalf of the French fund.&nbsp;</span></p>
<p><span>France Brevets was </span><a href="https://www.iam-media.com/article/france-brevets-public-sector-links-hindered-its-monetisation-efforts-says-ceo"><span>an investment fund formed in 2009</span></a><span> with €100 million in seed money from the French government to manage intellectual property. France Brevets was set to receive 35% of any revenue related to “monetizing and enforcement” of the patent, with Burley agreeing to file at least one patent infringement lawsuit within a year, and collect a “total minimum Gross Revenue of US $100,000” within 24 months, or the patent rights would be given back to France Brevets.&nbsp;</span></p>
<p><span>Burley Licensing LLC, run by IP Edge personnel, then created Nimitz Technologies LLC— a company with no assets except for the single patent. They obtained a mailing address for it from a Staples in Frisco, Texas, and assigned the patent to the LLC in August 2021, while the obligations to France Brevets remained unchanged until the fund </span><a href="https://www.iam-media.com/article/france-brevets-public-sector-links-hindered-its-monetisation-efforts-says-ceo"><span>shut down in 2022</span></a><span>.</span></p>
<h3><span>The Bigger Picture</span></h3>
<p><span></span><span>It’s troubling that patent lawsuits are often funded by entities with no genuine interest in innovation, such as private equity firms. However, it’s even more concerning when foreign government-backed organizations like France Brevets manipulate the US patent system for profit. In this case, a Finnish company sold its patents to a French government fund, which used US-based IP lawyers to file baseless lawsuits against American companies, including well-known establishments like Reddit and Bloomberg, as well as smaller</span><a href="https://www.tastemade.com/about"><span> ones like Tastemade</span></a><span> and </span><a href="https://www.crunchbase.com/organization/skillshare"><span>Skillshare</span></a><span>.</span></p>
<p><span>Judges should enforce rules requiring transparency about third-party funding in patent lawsuits. When ownership is unclear, it’s appropriate to insist that the real owners show up and testify—before dragging dozens of companies into court over dubious software patents.&nbsp;</span></p>
<p><span>Related documents:&nbsp;</span></p>
<ul>
<li><a href="https://www.eff.org/files/2024/09/09/1_22-cv-00413-cfc_34_primary_document.pdf"><span>Memorandum and Order</span></a><span> referring counsel to disciplinary bodies (Nov. 23, 2023)&nbsp;</span></li>
<li><a href="https://cafc.uscourts.gov/opinions-orders/23-2367.OPINION.7-16-2024_2350699.pdf"><span>Federal Circuit Opinion</span></a><span> affirming the order requiring Lori LaPray to appear “for testimony regarding potential fraud on the court,” as well as the District Court’s order of monetary sanction against Ms. LaPray for subsequently failing to appear</span></li>
</ul>


</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
    </channel>
</rss>