<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 04 Dec 2024 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Grifters, believers, grinders, and coasters (118 pts)]]></title>
            <link>https://www.seangoedecke.com/programmer-archetypes/</link>
            <guid>42319997</guid>
            <pubDate>Wed, 04 Dec 2024 17:52:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/programmer-archetypes/">https://www.seangoedecke.com/programmer-archetypes/</a>, See on <a href="https://news.ycombinator.com/item?id=42319997">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header></header><section><p>Why do engineers get mad at each other so often?<sup id="fnref-1"><a href="#fn-1">1</a></sup> </p>
<p>I think a lot of programmer arguments bottom out in a cultural clash between different kinds of engineers: believers vs grifters, or coasters vs grinders. I’m going to argue that good companies actually have a healthy mix of all four types of engineer, so it’s probably sensible to figure out how to work with them.</p>
<p>Despite the names, I think grifters and coasters can be as good at their jobs as believers and grinders. I’m naming them this way because these are the names you’d give them when you’re complaining about your coworkers, and this article is really aimed at people who are trying to have a bit more empathy for the assholes they work with. I myself fall mostly in the grifter + coaster quadrant, and <a href="https://www.seangoedecke.com/how-to-ship">I think I’m great at my job</a>. Here’s a beautiful diagram:</p>
<p><span>
      <a href="https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/081d5/quadrants.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="quadrants" title="quadrants" src="https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/fcda8/quadrants.png" srcset="https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/12f09/quadrants.png 148w,
https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/e4a3f/quadrants.png 295w,
https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/fcda8/quadrants.png 590w,
https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/efc66/quadrants.png 885w,
https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/c83ae/quadrants.png 1180w,
https://www.seangoedecke.com/static/463a9c7a46c66e8232c46aaad5523766/081d5/quadrants.png 1264w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>These aren’t immutable aspects of your personality. They’re more categories for how you approach the job of software engineering - you’ll move around between quadrants as you change your approach to work, for all the usual reasons.</p>
<h2>Grifters</h2>
<p>Grifters play the game to win. They think carefully about the image they’re presenting to leadership, they make tactical decisions around performance cycles, and they are comfortable speaking the language of the organization. They respect the company mission as written, but what they really value is what the leaders of the company show they care about. Despite the name, grifters are not <em>frauds</em>. In an organization that rewards shipping good code and delighting customers, grifters will ship good code and delight customers. But they won’t sacrifice their own interests to ship good code and delight customers in an organization that rewards other behavior.</p>
<p>Grifters are good at getting stuff done in large organizations. You want a grifter leading a complicated engineering project, because a grifter understands the levers of power in a large organization and how to use them. Without any grifter involvement, projects tend to mysteriously stall out from lack of buy-in. However, Grifters aren’t very good at changing the culture of their organizations. They tend to go with the current instead. If all you have are grifters, your organization will probably naturally devolve into a lowest-common-denominator culture. Grifters also aren’t good at important work that’s unrewarding. In most software companies, you really want a handful of engineers obsessing about issues like accessibility, security and performance all the time, even when the organization as a whole doesn’t care about it. Those people probably won’t be grifters. </p>
<h2>Believers</h2>
<p>Believers just want to do good work. They think making tactical decisions and “managing up” is slimy, and they don’t do it. They truly value the company mission, or they wouldn’t be there. Typically they’re heavily invested in product decisions, and prioritize the user experience over profit. Believers are often under-promoted, either due to alienating leadership or just not investing enough effort into the promotion cycle. They’re not <em>suckers</em>, though - they know the political cost they’re paying by refusing to play the game. They’re willing to pay that cost in order to work in accordance with their values.</p>
<p>Believers are good at keeping an organization focused on the customer. They’re out there walking the walk and talking the talk, drumming into new hires that At This Company We Do Things Right. They’re also good at keeping code quality up and obsessing over issues that require long-term maintenance (like performance). However, they can struggle when an organization changes focus. In my experience, as companies grow and move more into the enterprise market, there’s usually a cohort of alienated believers who are made very unhappy. If your entire organization is believers, you’ll be very well-equipped to execute but have zero flexibility. You’re going to stick to the mission that everyone believes in, even if it runs the org directly into the ground.</p>
<h2>Coasters</h2>
<p>Coasters are chill. They work enough to get the job done, but typically no further - above all else they avoid work they see as unnecessary. They typically do a lot of “hammock time”: non-work activities where they ponder a work problem in the back of their minds (this is particularly true for senior+ engineers). They still take work seriously: when they’re working, work has their full attention. But they don’t force themselves to produce code when they’re really not feeling it. Why go to a ton of effort to push out mediocre work when they can come back to it later and do it right?</p>
<p>Coasters are good at maintaining a calm, safe environment on teams. They’re also good for teams that have a lot of last-minute requests or questions, because coasters have “slack in the system”: they’ll rarely be completely consumed by a particular task for days. But they’re not as good for teams that have a lot of well-defined work queued up - for that, you want a grinder. A software engineering org could survive with all coasters, but when the pressure ramps up it’s easier to have some grinders around.</p>
<h2>Grinders</h2>
<p>Grinders are locked in. There’s always something that needs doing and the grinder is ready to do it. They just love the mechanics of the job - writing code, reviewing PRs, answering questions on Slack - or at least they love being useful. They’re always heads-down on a problem, sometimes to the point where they can’t see the forest for the trees. Still, if you need something done fast, give it to a grinder.</p>
<p>The strengths of a grinder are obvious: they do a lot of work. The weaknesses are also pretty straightforward: when a grinder burns out, they burn out <em>hard</em>. In my experience, grinders also tend to be pretty high-strung, since operating with intensity for a long time puts strain on the whole system. If it’s not obvious from the way I’m writing about this, I don’t think being a grinder is sustainable as a general mode of operating (of course I’d say that, since I’m a coaster by nature). I’ve met a lot of junior engineers who are grinders, but very few staff+ engineers. I think that’s no accident. You either learn to dial it back a bit in the first 5-10 years or you flame out of the industry entirely.</p>
<h2>Summary</h2>
<ul>
<li>If you’re a grifter, you need to figure out how to work with believers, because an all-grifter company isn’t the kind of place you want to work.</li>
<li>If you’re a believer, you don’t have to figure out how to work with grifters, but you’ll probably have to be very selective about the companies you work for.</li>
<li>If you’re a grinder, you need to figure out how to work with coasters, because you’re likely to become one at some point if you want to stay in the industry (or at minimum many of your peers will).</li>
<li>If you’re a coaster, you should try and be understanding about grinders running around stressing everyone out. You’re only able to coast because someone is willing to occasionally grind.</li>
</ul>
</section><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UnitedHealthcare CEO fatally shot in midtown Manhattan (149 pts)]]></title>
            <link>https://www.cnn.com/2024/12/04/us/brian-thompson-united-healthcare-death/index.html</link>
            <guid>42317968</guid>
            <pubDate>Wed, 04 Dec 2024 14:52:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/12/04/us/brian-thompson-united-healthcare-death/index.html">https://www.cnn.com/2024/12/04/us/brian-thompson-united-healthcare-death/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42317968">Hacker News</a></p>
Couldn't get https://www.cnn.com/2024/12/04/us/brian-thompson-united-healthcare-death/index.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Genie 2: A large-scale foundation world model (531 pts)]]></title>
            <link>https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/</link>
            <guid>42317903</guid>
            <pubDate>Wed, 04 Dec 2024 14:45:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/">https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/</a>, See on <a href="https://news.ycombinator.com/item?id=42317903">Hacker News</a></p>
Couldn't get https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Speeding up Ruby by rewriting C in Ruby (154 pts)]]></title>
            <link>https://jpcamara.com/2024/12/01/speeding-up-ruby.html</link>
            <guid>42316799</guid>
            <pubDate>Wed, 04 Dec 2024 12:31:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jpcamara.com/2024/12/01/speeding-up-ruby.html">https://jpcamara.com/2024/12/01/speeding-up-ruby.html</a>, See on <a href="https://news.ycombinator.com/item?id=42316799">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><img src="https://cdn.uploads.micro.blog/98548/2024/yjitvsc.drawio.png" alt=""></p>
<p>There is a recent <a href="https://github.com/bddicken/languages">language comparison repo</a> which has been getting shared a lot. In it, CRuby was the third slowest option, only beating out R and Python.</p>
<p>The repo author, <a href="https://x.com/BenjDicken">@BenjDicken</a>, <a href="https://x.com/BenjDicken/status/1861072804239847914">created a fun visualization</a> of each language’s performance. Here’s one of the visualizations, which shows Ruby as the third slowest language benchmarked:</p>

<blockquote>
<p>The code for this visualization is from <a href="https://benjdd.com/languages/">https://benjdd.com/languages/</a>, with permission from <a href="https://x.com/BenjDicken/status/1862623583803253149">@BenjDicken</a></p>
</blockquote>
<p>The repository describes itself as:</p>
<blockquote>
<p>A repo for collaboratively building small benchmarks to compare languages.</p>
</blockquote>
<p>It contains two different benchmarks:</p>
<ol>
<li>“Loops”, which “Emphasizes loop, conditional, and basic math performance”</li>
<li>“Fibonacci”, which “Emphasizes function call overhead and recursion.”</li>
</ol>
<p>The loop example iterates 1 billion times, utilizing a nested loop:</p>
<div><pre tabindex="0"><code data-lang="ruby">u <span>=</span> <span>ARGV</span><span>[</span><span>0</span><span>].</span>to_i       
r <span>=</span> rand(<span>10_000</span>)                          
a <span>=</span> Array<span>.</span>new(<span>10_000</span>, <span>0</span>)                 
	
(<span>0</span><span>...</span><span>10_000</span>)<span>.</span>each <span>do</span> <span>|</span>i<span>|</span>                     
  (<span>0</span><span>...</span><span>100_000</span>)<span>.</span>each <span>do</span> <span>|</span>j<span>|</span>               
    a<span>[</span>i<span>]</span> <span>+=</span> j <span>%</span> u                     
  <span>end</span>
  a<span>[</span>i<span>]</span> <span>+=</span> r                      
<span>end</span>
	
puts a<span>[</span>r<span>]</span>
</code></pre></div><p>The Fibonacci example is a basic “naive” Fibonacci implementation<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>:</p>
<pre><code>def fibonacci(n)
  return 0 if n == 0
  return 1 if n == 1
  fibonacci(n - 1) + fibonacci(n - 2)
end

u = ARGV[0].to_i
r = 0

(1...u).each do |i|
  r += fibonacci(i)
end

puts r
</code></pre>
<p>Run on <a href="https://x.com/BenjDicken">@BenjDicken</a>’s M3 MacBook Pro, Ruby 3.3.6 takes 28 seconds to run the loop iteration example, and 12 seconds to run the Fibonacci example. For comparison, node.js takes a little over a second for both examples - it’s not a great showing for Ruby.</p>
<table>
  <thead>
    <tr>
      <th></th>
      <th>Fibonacci</th>
      <th>Loops</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ruby</td>
      <td>12.17s</td>
      <td>28.80s</td>
    </tr>
    <tr>
      <td>node.js</td>
      <td>1.11s</td>
      <td>1.03s</td>
    </tr>
  </tbody>
</table>
<p>From this point on, I’ll use benchmarks relative to my own computer. Running the same benchmark on my M2 MacBook Air, I get 33.43 seconds for the loops and 16.33 seconds for fibonacci - even worse 🥺. Node runs a little over 1 second for fibonacci and 2 seconds for the loop example.</p>
<table>
  <thead>
    <tr>
      <th></th>
      <th>Fibonacci</th>
      <th>Loops</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ruby</td>
      <td>16.33s</td>
      <td>33.43s</td>
    </tr>
    <tr>
      <td>node.js</td>
      <td>1.36s</td>
      <td>2.07s</td>
    </tr>
  </tbody>
</table>
<h3 id="who-cares">Who cares?</h3>
<p>In most ways, these types of benchmarks are meaningless. Python was the slowest language in the benchmark, and yet at the same time it’s the <a href="https://github.blog/news-insights/octoverse/octoverse-2024/">most used language on Github as of October 2024</a>. Ruby runs some of the <a href="https://x.com/tobi/status/1863935229620363693">largest web apps in the world</a>. I ran a <a href="https://x.com/jpcamara/status/1849984009515966958">benchmark recently of websocket performance between the Ruby Falcon web server and node.js</a>, and the Ruby results were close to the node.js results. Are you doing a billion loop iterations or using web sockets?</p>
<p>A programming language should be reasonably efficient - after that the usefulness of the language, the type of tasks you work on, and language productivity outweigh the speed at which you can run a billion iterations of a loop, or complete an intentionally inefficient implementation of a Fibonacci method.</p>
<p>That said:</p>
<ol>
<li>The programming world loves microbenchmarks 🤷‍♂️</li>
<li>Having a fast benchmark may not be valuable in practice but it has meaning for people’s interest in a language. Some would claim it means you’ll have an easier time scaling performance, but that’s arguable<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></li>
<li>It’s disappointing if your language of choice doesn’t perform well. It’s nice to be able to say “I use and enjoy this language, and it runs fast in all benchmarks!”</li>
</ol>
<p>In the case of this Ruby benchmark, I had a feeling that YJIT wasn’t being applied in the Ruby code, so I checked the repo. Lo and behold, the command was as follows:</p>
<pre><code>ruby ./code.rb 40
</code></pre>
<p>We know my results from earlier (33 seconds and 16 seconds). What do we get with YJIT applied?</p>
<pre><code>ruby --yjit ./code.rb 40
</code></pre>
<table>
  <thead>
    <tr>
      <th></th>
<th>Fibonacci</th>
<th>Loops</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ruby</td>
<td>2.06s</td>
<td>25.57s</td>
</tr>
</tbody>
</table>
<p>Nice! With YJIT, Fibonacci gets a massive boost - going from 16.88 seconds down to 2.06 seconds. It’s close to the speed of node.js at that point!</p>
<p>YJIT makes a more modest difference for the looping example - going from 33.43 seconds down to 25.57 seconds. Why is that?</p>
<h3 id="a-team-effort">A team effort</h3>
<p>I wasn’t alone in trying out these code samples with YJIT. On twitter, <a href="https://x.com/bsilva96">@bsilva96</a> had asked the same questions:</p>
<p><img src="https://cdn.uploads.micro.blog/98548/2024/screenshot-2024-12-01-at-8.38.46pm.png" alt=""></p>
<blockquote>
<p><a href="https://x.com/bsilva96/status/1861136096689606708">https://x.com/bsilva96/status/1861136096689606708</a></p>
</blockquote>
<p><a href="https://bsky.app/profile/k0kubun.com">@k0kubun</a> came through with insights into why things were slow and ways of improving the performance:</p>
<p><img src="https://cdn.uploads.micro.blog/98548/2024/screenshot-2024-12-01-at-8.41.03pm.png" alt=""></p>
<blockquote>
<p><a href="https://x.com/k0kubun/status/1861149512640979260">https://x.com/k0kubun/status/1861149512640979260</a></p>
</blockquote>
<p>Let’s unpack his response. There are three parts to it:</p>
<ol>
<li><code>Range#each</code> is still written in C as of Ruby 3.4</li>
<li><code>Integer#times</code> was converted from C to Ruby in Ruby 3.3</li>
<li><code>Array#each</code> was converted from C to Ruby in Ruby 3.4</li>
</ol>
<h3 id="1-rangeeach-is-still-written-in-c-which-yjit-cant-optimize">1. <code>Range#each</code> is still written in C, which YJIT can’t optimize</h3>
<p>Looking back at our Ruby code:</p>
<pre><code>(0...10_000).each do |i|                     
  (0...100_000).each do |j|               
    a[i] += j % u                     
  end
  a[i] += r                      
end
</code></pre>
<p>It’s written as a range, and range has its own <code>each</code> implementation, which is apparently written in C. The CRuby codebase is pretty easy to navigate - let’s find that implementation 🕵️‍♂️.</p>
<p>Most core classes in Ruby have top-level C files named after them - in this case we’ve got <code>range.c</code> at the root of the project. CRuby has a pretty readable interface for exposing C functions as classes and methods - there is an <code>Init</code> function, usually at the bottom of the file. Inside that <code>Init</code> our classes, modules and methods are exposed from C to Ruby. Here are the relevant pieces of <code>Init_Range</code>:</p>
<pre><code>void
Init_Range(void)
{
  //...
  rb_cRange = rb_struct_define_without_accessor(
    "Range", rb_cObject, range_alloc,
    "begin", "end", "excl", NULL);

  rb_include_module(rb_cRange, rb_mEnumerable);
  // ...
  rb_define_method(rb_cRange, "each", range_each, 0);
</code></pre>
<p>First, we define our <code>Range</code> class using <code>rb_struct_define...</code>. We name it <code>“Range”</code>, with a super class of <code>Object</code> (<code>rb_cObject</code>), and some initialization parameters (<code>“begin”</code>, <code>“end”</code> and whether to exclude the last value, ie the <code>..</code> vs <code>...</code> range syntax).</p>
<p>Second, we include <code>Enumerable</code> using <code>rb_include_module</code>. That gives us all the great Ruby enumeration methods like <code>map</code>, <code>select</code>, <code>include?</code> and <a href="https://docs.ruby-lang.org/en/3.3/Enumerable.html">a bajillion others</a>. All you have to do is provide an <code>each</code> implementation and it handles the rest.</p>
<p>Third, we define our <code>“each”</code> method. It’s implemented by the <code>range_each</code> function in C, and takes zero explicit arguments (blocks are not considered in this count).</p>
<p><code>range_each</code> is hefty. It’s almost 100 lines long, and specializes into several versions of itself. I’ll highlight a few, collapsed all together:</p>
<pre><code>static VALUE
range_each(VALUE range)
{
  //...
  range_each_fixnum_endless(beg);
  range_each_fixnum_loop(beg, end, range);
  range_each_bignum_endless(beg);
  rb_str_upto_endless_each(beg, sym_each_i, 0);
  // and even more...
</code></pre>
<p>These C functions handle all the variations of ranges you might use in your own code:</p>
<div><pre tabindex="0"><code data-lang="ruby">(<span>0</span><span>...</span>)<span>.</span>each
(<span>0</span><span>...</span><span>100</span>)<span>.</span>each
(<span>"a"</span><span>...</span><span>"z"</span>)<span>.</span>each
<span># and on...</span>
</code></pre></div><p>Why does it matter that <code>Range#each</code> is written in C? It means YJIT can’t inspect it - optimizations stop at the function call and resume when the function call returns. C functions are fast, but YJIT can take things further by creating specializations for hot paths of code. There is a great article from Aaron Patterson called <a href="https://railsatscale.com/2023-08-29-ruby-outperforms-c/">Ruby Outperforms C</a> where you can learn more about some of those specialized optimizations.</p>
<h3 id="2-optimizing-our-loop-integertimes-was-converted-from-c-to-ruby-in-ruby-33">2. Optimizing our loop: <code>Integer#times</code> was converted from C to Ruby in Ruby 3.3</h3>
<p>The hot path (<em>where most of our CPU time is spent</em>) is <code>Range#each</code>, which is a C function. YJIT can’t optimize C functions - they’re a black box. So what can we do?</p>
<blockquote>
<p>We converted Integer#times to Ruby in 3.3</p>
</blockquote>
<p>Interesting! In Ruby 3.3, <code>Integer#times</code> was <a href="https://github.com/ruby/ruby/pull/8388">converted from a C function to a Ruby method</a>! Here’s the 3.3+ version - its pretty simple:</p>
<pre><code>def times
  #... a little C interop code
  i = 0
  while i &lt; self
    yield i
    i = i.succ
  end
  self
end
</code></pre>
<p>Very simple. It’s just a basic while loop. Most importantly, it’s all Ruby code, which means YJIT should be able to introspect and optimize it!</p>
<h3 id="an-aside-on-integersucc">An aside on <code>Integer#succ</code></h3>
<p>The slightly odd part of that code is <code>i.succ</code>. I’d never heard of <code>Integer#succ</code>, which apparently gives you the “successor” to an integer.</p>
<p><img src="https://cdn.uploads.micro.blog/98548/2024/0c8bd56f64.png" alt=""></p>
<blockquote>
<p>I’ve never seen this show, and yet it’s the first thing I thought of when I learned about this method. Thanks, advertising.</p>
</blockquote>
<p>There was a PR to improve the performance of <code>Integer#succ</code> in early 2024, which helped me understand why anyone would ever use it:</p>
<blockquote>
<p>We use Integer#succ when we rewrite loop methods in Ruby (e.g. Integer#times and Array#each) because opt_succ (i = i.succ) is faster to dispatch on the interpreter than putobject 1; opt_plus (i += 1).</p>
<p><a href="https://github.com/ruby/ruby/pull/9519">https://github.com/ruby/ruby/pull/9519</a></p>
</blockquote>
<p><code>Integer#success</code> is like a virtual machine cheat code. It takes a common operation (adding 1 to an integer) and turns it from two virtual machine operations into one. We can call <code>disasm</code> on the <code>times</code> method to see that in action:</p>
<pre><code>puts RubyVM::InstructionSequence.disasm(1.method(:times))
</code></pre>
<p>The <code>Integer#times</code> method gets broken down into a lot of Ruby VM bytecode, but we only care about a few lines:</p>
<pre><code>...
0025 getlocal_WC_0   i@0
0027 opt_succ        &lt;calldata!mid:succ, ARGS_SIMPLE&gt;[CcCr]
0029 setlocal_WC_0   i@0
...
</code></pre>
<ul>
<li><code>getlocal_WC_0</code> gets our <code>i</code> variable from the current scope. That’s the <code>i</code> in <code>i.succ</code></li>
<li><code>opt_succ</code> performs the <code>succ</code> call in our <code>i.succ</code>. It will either call the actual <code>Integer#succ</code> method, or an optimized C function for small numbers</li>
<li>In Ruby 3.4 with YJIT enabled, small numbers get optimized even further into machine code (just a note, not shown in the VM machine code)</li>
<li><code>setlocal_WC_0</code> sets the result of <code>opt_succ</code> to our local variable <code>i</code></li>
</ul>
<p>If we change from <code>i = i.succ</code> to <code>i += 1</code>, we now have two VM operations take the place of <code>opt_succ</code>:</p>
<pre><code>...
0025 getlocal_WC_0        i@0
0027 putobject_INT2FIX_1_
0028 opt_plus             &lt;calldata!mid:+, argc:1, ARGS_SIMPLE&gt;
0029 setlocal_WC_0        i@0
...
</code></pre>
<p>Everything is essentially the same as before, except now we have two steps to go through instead of one:</p>
<ul>
<li><code>putobject_INT2FIX_1_</code> pushes the integer <code>1</code> onto the virtual machine stack</li>
<li><code>opt_plus</code> is the <code>+</code> in our <code>+= 1</code>, and calls either the Ruby <code>+</code> method or an optimized C function for small numbers</li>
<li>There is probably a YJIT optimization for <code>opt_plus</code> as well</li>
</ul>
<p>If there is nothing else to learn from this code, it’s this: the kinds of optimizations you do at the VM and JIT level are <em>deep</em>. When writing general Ruby programs we typically don’t and <em>shouldn’t</em> consider the impact of one versus two <em>machine code instructions</em>. But at the JIT level, on the scale of millions and billions of operations, it matters!</p>
<h3 id="back-to-integertimes">Back to <code>Integer#times</code></h3>
<p>Let’s try running our benchmark code again, using <code>times</code>! Instead of iterating over ranges, we simply iterate for <code>10_000</code> and <code>100_000</code> <code>times</code>:</p>
<div><pre tabindex="0"><code data-lang="ruby">u <span>=</span> <span>ARGV</span><span>[</span><span>0</span><span>].</span>to_i        
r <span>=</span> rand(<span>10_000</span>)        
a <span>=</span> Array<span>.</span>new(<span>10_000</span>, <span>0</span>)
	
<span>10_000</span><span>.</span>times <span>do</span> <span>|</span>i<span>|</span>
  <span>100_000</span><span>.</span>times <span>do</span> <span>|</span>j<span>|</span>
    a<span>[</span>i<span>]</span> <span>+=</span> j <span>%</span> u
  <span>end</span>
  a<span>[</span>i<span>]</span> <span>+=</span> r
<span>end</span>
	
puts a<span>[</span>r<span>]</span>
</code></pre></div><table>
<thead>
<tr>
<th></th>
<th>Loops</th>
</tr>
</thead>
<tbody>
<tr>
<td>Range#each</td>
<td>25.57s</td>
</tr>
<tr>
<td>Integer#times</td>
<td>13.66s</td>
</tr>
</tbody>
</table>
<p>Nice! YJIT makes a much larger impact using <code>Integer#times</code>. That trims things down significantly, taking it down to 13.66 seconds on my machine. On <a href="https://bsky.app/profile/k0kubun.com">@k0kobun</a>’s machine it actually goes down to 9 seconds (and 8 seconds on Ruby 3.4).</p>
<blockquote>
<p>It’s probably Ruby 3.5’s job to make it faster than 8s though.</p>
</blockquote>
<p>We might look forward to even faster performance in Ruby 3.5. We’ll see!</p>
<h3 id="3-arrayeach-was-converted-from-c-to-ruby-in-ruby-34">3. <code>Array#each</code> was converted from C to Ruby in Ruby 3.4</h3>
<p>CRuby continues to see C code rewritten in Ruby, and in Ruby 3.4 <code>Array#each</code> was one of those changes. Here is an <a href="https://github.com/ruby/ruby/pull/6687/files">example of the first attempt at implementing it</a>:</p>
<pre><code>def each
  unless block_given?
    return to_enum(:each) { self.length }
  end
  i = 0
  while i &lt; self.length
    yield self[i]
    i = i.succ
  end
  self
end
</code></pre>
<p>Super simple and readable! And YJIT optimizable!</p>
<p>Unfortunately, due to something related to CRuby internals, it contained <a href="https://jpcamara.com/2024/06/23/your-ruby-programs.html#race-conditions">race conditions</a>. A later implementation <a href="https://github.com/ruby/ruby/pull/11955">landed in Ruby 3.4</a>.</p>
<pre><code>def each
  Primitive.attr! :inline_block, :c_trace

  unless defined?(yield)
    return Primitive.cexpr! 'SIZED_ENUMERATOR(self, 0, 0, ary_enum_length)'
  end
  _i = 0
  value = nil
  while Primitive.cexpr!(%q{ ary_fetch_next(self, LOCAL_PTR(_i), LOCAL_PTR(value)) })
    yield value
  end
  self
end
</code></pre>
<p>Unlike the first implementation, and unlike <code>Integer#times</code>, things are a bit more cryptic this time. This is definitely not pure Ruby code that anyone could be expected to write. Somehow, the <code>Primitive</code> module seems to allow evaluating C code from Ruby, and in doing so avoids the race conditions present in the pure Ruby solution<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p>
<p>By fetching indexes and values using C code, I think it results in a more atomic operation. I have no idea why the <code>Primitive.cexpr!</code> is used to return the enumerator, or what value <code>Primitive.attr! :inline_block</code> provides. Please comment if you have insights there!</p>
<p>I was a little loose with my earlier <code>Integer#times</code> source code as well. That actually had a bit of this <code>Primitive</code> syntax as well. The core of the method is what we looked at, and it’s all Ruby, but the start of the method contains the same <code>Primitive</code> calls for <code>:inline_block</code> and returning the enumerator:</p>
<pre><code>def times
  Primitive.attr! :inline_block
  unless defined?(yield)
    return Primitive.cexpr! 'SIZED_ENUMERATOR(self, 0, 0, int_dotimes_size)'
  end
  #...
</code></pre>
<p>Ok - it’s more cryptic than <code>Integer#times</code> was, but <code>Array#each</code> is mostly Ruby (on Ruby 3.4+). Let’s give it a try using arrays instead of ranges or <code>times</code>:</p>
<div><pre tabindex="0"><code data-lang="ruby">u <span>=</span> <span>ARGV</span><span>[</span><span>0</span><span>].</span>to_i
r <span>=</span> rand(<span>10_000</span>)
a <span>=</span> Array<span>.</span>new(<span>10_000</span>, <span>0</span>)
	
outer <span>=</span> (<span>0</span><span>...</span><span>10_000</span>)<span>.</span>to_a<span>.</span>freeze
inner <span>=</span> (<span>0</span><span>...</span><span>100_000</span>)<span>.</span>to_a<span>.</span>freeze
outer<span>.</span>each <span>do</span> <span>|</span>i<span>|</span>
  inner<span>.</span>each <span>do</span> <span>|</span>j<span>|</span>
    a<span>[</span>i<span>]</span> <span>+=</span> j <span>%</span> u
  <span>end</span>
  a<span>[</span>i<span>]</span> <span>+=</span> r
<span>end</span>
	
puts a<span>[</span>r<span>]</span>
</code></pre></div><p>Despite the embedded C code, YJIT still seems capable of making some hefty performance optimizations. It’s within the same range as <code>Integer#times</code>!</p>
<table>
<thead>
<tr>
<th></th>
<th>Loops</th>
</tr>
</thead>
<tbody>
<tr>
<td>Range#each</td>
<td>25.57s</td>
</tr>
<tr>
<td>Integer#times</td>
<td>13.66s</td>
</tr>
<tr>
<td>Array#each</td>
<td>13.96s</td>
</tr>
</tbody>
</table>
<h3 id="microbenchmarking-ruby-performance">Microbenchmarking Ruby performance</h3>
<p>I’ve forked the original language implementation repo, and created my own repository called “Ruby Microbench”. It takes all of the examples discussed, as well as several other forms of doing the iteration in Ruby: <a href="https://github.com/jpcamara/ruby_microbench">https://github.com/jpcamara/ruby_microbench</a></p>
<p>Here is the output of just running those using Ruby 3.4 with and without YJIT:</p>
<table>
<thead>
<tr>
<th></th>
<th>fibonacci</th><th>array#each</th>
<th>range#each</th>
<th>times</th>
<th>for</th>
<th>while</th>
<th>loop do</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ruby 3.4 YJIT</td>
<td>2.19s</td>
<td>14.02s</td>
<td>26.61s</td>
<td>13.12s</td>
<td>27.38s</td>
<td>37.10s</td>
<td>13.95s</td></tr>
<tr>
<td>Ruby 3.4</td>
<td>16.49s</td>
<td>34.29s</td>
<td>33.88s</td>
<td>33.18s</td>
<td>36.32s</td>
<td>37.14s</td>
<td>50.65s</td>
</tr>
</tbody>
</table>
<p>I have no idea why the <code>for</code> and <code>while</code> loop examples I wrote seem to be so slow. I’d expect them to run much faster. Maybe there’s an issue with how I wrote them - feel free to open an issue or PR if you see something wrong with my implementation. The <code>loop do</code> (taken from <a href="https://bsky.app/profile/timtilberg.bsky.social">@timtilberg</a>’s <a href="https://x.com/timtilberg/status/1861194052516864004">example</a>) runs around the same speed as <code>Integer#times</code> - although its performance is <em>awful</em> with YJIT turned off.</p>
<p>In addition to running Ruby 3.4, for fun I have it using <code>rbenv</code> to run:</p>
<ul>
<li>Ruby 3.3</li>
<li>Ruby 3.3 YJIT</li>
<li>Ruby 3.2</li>
<li>Ruby 3.2 YJIT</li>
<li>TruffleRuby 24.1</li>
<li>Ruby Artichoke</li>
<li>MRuby</li>
</ul>
<p>A few of the test runs are listed here:</p>
<table>
<thead>
<tr>
<th></th>
<th>fibonacci</th>
<th>
array#each
</th>
<th>range#each</th>
<th>times</th>
<th>for</th>
<th>while</th>
<th>loop do</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ruby 3.4 YJIT</td><td>2.19s</td>
<td>14.02s</td>
<td>26.61s</td>
<td>13.12s</td>
<td>27.38s</td>
<td>37.10s</td>
<td>13.95s</td></tr>
<tr>
<td>Ruby 3.4</td>
<td>16.49s</td>
<td>34.29s</td><td>33.88s</td>
<td>33.18s</td>
<td>36.32s</td>
<td>37.14s</td>
<td>50.65s</td>
</tr>
<tr><td>TruffleRuby 24.1</td><td>0.92s</td>
<td>0.97s</td>
<td>0.92s</td><td>2.39s</td>
<td>2.06s</td><td>3.90s</td>
<td>0.77s</td>
</tr><tr>
<td>MRuby 3.3</td>
<td>28.83s</td>
<td>144.65s</td>
<td>126.40s</td>
<td>128.22s</td>
<td>133.58s</td><td>91.55s</td>
<td>144.93s</td>
</tr>
<tr>
<td>Artichoke</td>
<td>19.71s</td>
<td>236.10s</td><td>214.55s</td>
<td>214.51s</td>
<td>215.95s</td>
<td>174.70s</td>
<td>264.67s</td>
</tr>
</tbody>
</table>
<p>Based on that, I’ve taken the original visualization and made a Ruby specific one here just for the <code>fibonacci</code> run:</p>

<h3 id="speeding-up-rangeeach">Speeding up <code>range#each</code></h3>
<p>Can we, the non <a href="https://bsky.app/profile/k0kubun.com">@k0kobun</a>’s of the world, make <code>range#each</code> faster? If I monkey patch the <code>Range</code> class with a pure-ruby implementation, things <em>do</em> get much faster! Here’s my implementation:</p>
<pre><code>class Range
  def each
    beginning = self.begin
    ending = self.end
    i = beginning
    loop do
      break if i == ending
      yield i
      i = i.succ
    end
  end
end
</code></pre>
<p>And here is the change in performance - 2 seconds slower than <code>times</code> - not bad!</p>
<table>
<thead>
<tr>
<th>				
</th>
<th>
Time spent
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Range#each in C</td>
<td>25.57s</td>
</tr>
<tr>
<td>Range#each in Ruby</td>
<td>16.64s</td>
</tr>
</tbody>
</table>
<p>This is obviously over-simplified. I don’t handle all of the different cases of <code>Range</code>, and there may be nuances I am missing. Also, most of the Ruby rewritten methods I’ve seen invoke a <code>Primitive</code> class for certain operations. I’d love to learn more about when and why it’s needed.</p>
<p>But! It goes to show the power of moving things <em>out</em> of C and letting YJIT optimize our code. It can improve performance in ways that would be difficult or impossible to replicate in regular C code.</p>
<h3 id="yjit-standard-library">YJIT standard library</h3>
<p>Last year Aaron Patterson wrote an article called <a href="https://railsatscale.com/2023-08-29-ruby-outperforms-c/">Ruby Outperforms C</a>, in which he rewrote a C extension in Ruby for some GraphQL parsing. The Ruby code outperformed C thanks to YJIT optimizations.</p>
<p>This got me thinking that it would be interesting to see a kind of “YJIT standard library” emerge, where core ruby functionality run in C could be swapped out for Ruby implementations for use by people using YJIT.</p>
<p>As it turns out, this is almost exactly what the core YJIT team has been doing. In many cases they’ve completely removed C code, but more recently they’ve created a <code>with_yjit</code> block. The code will only take effect if YJIT is enabled, and otherwise the C code will run. For example, this is how<code>Array#each</code> is implemented:</p>
<pre><code>with_yjit do
  if Primitive.rb_builtin_basic_definition_p(:each)
    undef :each

    def each # :nodoc:
      # ... we examined this code earlier ...
    end
  end
end
</code></pre>
<p>As of Ruby 3.3, YJIT can be lazily initialized. Thankfully the <code>with_yjit</code> code handles this - the appropriate <code>with_yjit</code> versions of methods will be run once YJIT is enabled:</p>
<pre><code># Uses C-builtin
[1, 2, 3].each do |i|
  puts i
end

RubyVM::YJIT.enable

# Uses Ruby version, which can be YJIT optimized
[1, 2, 3].each do |i|
  puts i
end
</code></pre>
<p>This is because <code>with_yjit</code> is a YJIT “hook”, which is called the moment YJIT is enabled. After being called, it is removed from the runtime using <code>undef :with_yjit</code>.</p>
<h3 id="investigating-yjit-optimizations">Investigating YJIT optimizations</h3>
<p>We’ve looked at Ruby code. We’ve looked at C code. We’ve looked at Ruby VM bytecode. Why not take it one step deeper and look at some <em>machine code</em>? And maybe some Rust code? Hey - where are you going! Don’t walk away while I’m talking to you!</p>
<p>If you <em>haven’t</em> walked away, or skipped to the next section, let’s take a look at a small sliver of YJIT while we’re here!</p>
<p>We can see the machine code YJIT generates 😱. It’s possible by building CRuby from source with YJIT debug flags. If you’re on a Mac you can see <a href="https://jpcamara.com/2024/12/02/my-macos-setup.html">my MacOS setup for hacking on CRuby</a> or <a href="https://jpcamara.com/2024/11/27/my-docker-setup.html">my docker setup for hacking on CRuby</a> for more elaborate instructions on building Ruby. But the simplified step is when you go to <code>./configure</code> Ruby, you hand in an option of <code>--enable-yjit=dev</code>:</p>
<pre><code>./configure --enable-yjit=dev
make install
</code></pre>
<p>Let’s use our <code>Integer#times</code> example from earlier as our example Ruby code:</p>
<div><pre tabindex="0"><code data-lang="ruby">u <span>=</span> <span>ARGV</span><span>[</span><span>0</span><span>].</span>to_i
r <span>=</span> rand(<span>10_000</span>)
a <span>=</span> Array<span>.</span>new(<span>10_000</span>, <span>0</span>)
	
<span>10_000</span><span>.</span>times <span>do</span> <span>|</span>i<span>|</span>
  <span>100_000</span><span>.</span>times <span>do</span> <span>|</span>j<span>|</span>
    a<span>[</span>i<span>]</span> <span>+=</span> j <span>%</span> u
  <span>end</span>
  a<span>[</span>i<span>]</span> <span>+=</span> r
<span>end</span>
	
puts a<span>[</span>r<span>]</span>
</code></pre></div><p>Because you’ve built Ruby with YJIT in dev mode, you can hand in the <code>--yjit-dump-disasm</code> flag when running your ruby program:</p>
<pre><code>./ruby --yjit --yjit-dump-disasm test.rb 40
</code></pre>
<p>Using this, we can see the machine code created. We’ll just focus in on one tiny part - the machine code equivalent of the Ruby VM bytecode we read earlier. Here is the original VM bytecode for <code>opt_succ</code>, which is generated when you call <code>i.succ</code>, the <code>Integer#succ</code> method:</p>
<pre><code>...
0027 opt_succ        &lt;calldata!mid:succ, ARGS_SIMPLE&gt;[CcCr]
...
</code></pre>
<p>And here is the machine code YJIT generates in this scenario, on my Mac M2 arm64 architecture:</p>
<pre><code># Block: times@&lt;internal:numeric&gt;:259 
# reg_mapping: [Some(Stack(0)), None, None, None, None]
# Insn: 0027 opt_succ (stack_size: 1)
# call to Integer#succ
# guard object is fixnum
0x1096808c4: tst x1, #1
0x1096808c8: b.eq #0x109683014
0x1096808cc: nop 
0x1096808d0: nop 
0x1096808d4: nop 
0x1096808d8: nop 
0x1096808dc: nop 
# Integer#succ
0x1096808e0: adds x11, x1, #2
0x1096808e4: b.vs #0x109683048
0x1096808e8: mov x1, x11
</code></pre>
<p>To be honest, I about 25% understand this, and 75% am combining my own logic and AI to learn it 🤫. Feel free to yell at me if I get it a little wrong, I’d love to learn more. But here’s how I break this down.</p>
<pre><code># Block: times@&lt;internal:numeric&gt;:259
</code></pre>
<p>👆🏼This roughly corresponds to the line <code>i = i.succ</code> in the <code>Integer#times</code> method in <code>numeric.rb</code>. I say roughly because in my current code I see that on line 258, but maybe it shows the end of the block it’s run in since YJIT compiles “blocks” of code:</p>
<pre><code>256: while i &lt; self
257:   yield i
258:   i = i.succ
259: end

# reg_mapping: [Some(Stack(0)), None, None, None, None]
# Insn: 0027 opt_succ (stack_size: 1)
# call to Integer#succ
</code></pre>
<p>👆🏼I have no idea what <code>reg_mapping</code> means - probably mapping how it uses a CPU register? <code>Insn: 0027 opt_succ</code> looks very familiar! That’s our VM bytecode! <code>call to Integer#succ</code> is just a helpful comment added. YJIT is capable of adding comments to the machine code. We still haven’t even left the safety of the comments 😅.</p>
<pre><code># guard object is fixnum
</code></pre>
<p>👆🏼This is interesting. I can find a corresponding bit of Rust code that maps directly to this. Let’s take a look at it:</p>
<pre><code>fn jit_rb_int_succ(
  //...
  asm: &amp;mut Assembler,
  //...
) -&gt; bool {
  // Guard the receiver is fixnum
  let recv_type = asm.ctx.get_opnd_type(StackOpnd(0));
  let recv = asm.stack_pop(1);
  if recv_type != Type::Fixnum {
    asm_comment!(asm, "guard object is fixnum");
    asm.test(recv, Opnd::Imm(RUBY_FIXNUM_FLAG as i64));
         asm.jz(Target::side_exit(Counter::opt_succ_not_fixnum));
  }

  asm_comment!(asm, "Integer#succ");
  let out_val = asm.add(recv, Opnd::Imm(2)); // 2 is untagged Fixnum 1
  asm.jo(Target::side_exit(Counter::opt_succ_overflow));

  // Push the output onto the stack
  let dst = asm.stack_push(Type::Fixnum);
  asm.mov(dst, out_val);

  true
}
</code></pre>
<p>Oh nice! This is the actual YJIT Rust implementation of the <code>opt_succ</code> call. This is that optimization <a href="https://bsky.app/profile/k0kubun.com">@k0kobun</a> made to further improve <code>opt_succ</code> performance beyond the bytecode C function calls. We’re in the section that is checking if what we’re operating on is a Fixnum, which is a way small integers are stored internally in CRuby:</p>
<pre><code>if recv_type != TypeFixnum 
  asm_comment!(asm, "guard object is fixnum");
  asm.test(recv, Opnd::Imm(RUBY_FIXNUM_FLAG as i64));
  asm.jz(Target::side_exit(Counter::opt_succ_not_fixnum));
}
</code></pre>
<p>That becomes this machine code:</p>
<pre><code># guard object is fixnum
0x1096808c4: tst x1, #1
0x1096808c8: b.eq #0x109683014
</code></pre>
<p><code>asm.test</code> generates <code>tst x1, #1</code>, which according to an AI bot I asked is checking the least significant bit, which is a Fixnum “tag” that indicates this is a Fixnum. If it’s Fixnum, the result is 1 and <code>b.eq</code> is false. If it’s not a Fixnum, the result is <code>0</code> and <code>b.eq</code> is true and jumps away from this code.</p>
<pre><code>0x1096808cc: nop 
0x1096808d0: nop 
0x1096808d4: nop 
0x1096808d8: nop 
0x1096808dc: nop 
</code></pre>
<p>🤖 “NOPs for alignment/padding”. Thanks AI. I don’t know why it is needed, but at least I know what it probably is.</p>
<p>Finally, we <em>actually</em> add 1 to the number.</p>
<pre><code>asm_comment!(asm, "Integer#succ");
let out_val = asm.add(recv, Opnd::Imm(2)); // 2 is untagged Fixnum 1
asm.jo(Target::side_exit(Counter::opt_succ_overflow));

// Push the output onto the stack
let dst = asm.stack_push(Type::Fixnum);
asm.mov(dst, out_val);
</code></pre>
<p>The Rust code generates our <code>Integer#succ</code> comment. Then, to add 1, because of the “Fixnum tag” data embedded within our integer, actually means we have to add 2 using <code>adds x11, x1, #2</code> 😵‍💫. If we overflow the space available, it exits to a different code path - <code>b.vs</code> is a branch on overflow. Otherwise, it stores the result with <code>mov x1, x11</code>!</p>
<pre><code># Integer#succ
0x1096808e0: adds x11, x1, #2
0x1096808e4: b.vs #0x109683048
0x1096808e8: mov x1, x11
</code></pre>
<p>😮‍💨. That was a lot. And it seems like <em>alot</em> of working is being done, but because it’s such low level machine code it’s presumably super fast. We examined a teensy tiny portion of what YJIT is capable of generating - JITs are complicated!</p>
<p>Thanks to <a href="https://bsky.app/profile/k0kubun.com">@k0kobun</a> for providing me with the commands and pointing me at the <a href="https://github.com/ruby/ruby/blob/master/doc/yjit/yjit.md">YJIT docs</a> which contain tons of additional options as well.</p>
<h3 id="the-future-of-cruby-optimizations">The future of CRuby optimizations</h3>
<p>The irony of language implementation is that you often work less in the language you’re implementing than you do in something lower-level - in Ruby’s case, that’s mostly C and some Rust.</p>
<p>With a layer like YJIT, it potentially opens up a future where more of the language becomes plain Ruby, and Ruby developer contribution is easier. Many languages have a smaller low level core, and the majority of the language is written in itself (like Java, for instance). Maybe that’s a future for CRuby, someday! Until then, keep the YJIT optimizations coming, YJIT team!</p>


<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Naive in this case meaning that there are more efficient ways to calculate fibonacci numbers in a program&nbsp;<a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>MJIT, the precursor to YJIT, made Ruby much faster on certain benchmarks. But on large realistic Rails applications it actually <a href="https://bugs.ruby-lang.org/issues/14490">made things <em>slower</em></a>&nbsp;<a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>When C code is running, it has to opt-in to releasing the GVL, so it’s more difficult for threads to corrupt or modify data mid-operation. The original Ruby version could yield the GVL at points that would invalidate the array. That’s my understanding of the situation anyways.&nbsp;<a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to grow professional relationships (262 pts)]]></title>
            <link>https://tej.as/blog/how-to-grow-professional-relationships-tjs-model</link>
            <guid>42315946</guid>
            <pubDate>Wed, 04 Dec 2024 09:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tej.as/blog/how-to-grow-professional-relationships-tjs-model">https://tej.as/blog/how-to-grow-professional-relationships-tjs-model</a>, See on <a href="https://news.ycombinator.com/item?id=42315946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Over my career, I’ve had the opportunity to get to know some of the world’s <a href="https://x.com/TejasKumar_/status/1862048032973324369">most</a> <a href="https://x.com/DavidKPiano">incredible</a> <a href="https://x.com/swyx">builders</a>. This same career has also seen quite a significant amount of gatekeeping: various <code>(m|b)</code>illionaire boys clubs and cliques have made it quite clear that they’d prefer to keep their world small and exclusive, and that there’s no room at their table. To each their own, but this dynamic has led to some thinking and reflection around the nature of professional relationships, friendships, and identity—ultimately resulting in what I’m calling <strong>TJS (The Journey to Synergy)</strong> Collaboration Model.</p>
<p><img src="https://tej.as/_astro/tjs.Dlc-SqUb_z1FF9.svg" alt="The TJS Collaboration Model" width="1775" height="801" loading="lazy" decoding="async"></p>
<p>This spectrum is how I measure professional relationships and where I stand in those relationships. It outlines seven states moving from a competitive, zero-sum mindset to one of shared identity (which is equally problematic).</p>
<p>Let’s briefly understand each state. One way we can make this information really practical is to understand it in context. A great illustrative context for this is <a href="https://tej.as/podcast">my podcast</a>, because it requires regularly interacting with people that inevitably reveals where we land on this spectrum.</p>
<h2 id="states-of-the-tjs-collaboration-model">States of the TJS Collaboration Model</h2>
<p>The TJS collaboration model is made up of the following seven distinct states.</p>
<ol>
<li>
<p><strong>Everything is a competition</strong>: in this initial state, interactions are characterized by <strong>gatekeeping and a zero-sum mentality</strong>: the idea that <em>for one party to eat, the other must starve</em>. People are not willing to share information, resources, or opportunities. There’s usually discrimination and exclusionary behavior here, either from racism, sexism, xenophobia, etc. I tend to not spend too much time with parties that hold this perspective.</p>
<p>In the context of the podcast, this is usually characterized not by rejection but instead by outright refusal to participate in any interaction whatsoever: what some call <a href="https://en.wikipedia.org/wiki/Ghosting_(behavior)#:~:text=Ghosting%2C%20simmering%20and%20icing%20are,any%20subsequent%20attempts%20to%20communicate.">“ghosting”</a>. I’m not entirely sure if they leave read receipts on to make their point, but I’ve found this behavior to be a pretty good indicator of where we stand on this spectrum. Of course, there are those that simply don’t receive any notifications and have read receipts turned off: these folks are likely not in this state and are just as busy as the rest of us.</p>
<p>Also in the context of the podcast, I’ve had guests accept an invitation and then later decline closer to the time of recording because they got invited to go on <a href="https://x.com/lexfridman">Lex Fridman</a> and mention “thanks for the invite, but now I don’t need this anymore”. There is no judgment at all here, but such behavior indicates where on this spectrum these relationships stand.</p>
</li>
<li>
<p><strong>Coexist</strong>: parties acknowledge each other’s existence but maintain minimal interaction, summarized as “I know <em>of</em> them, but we don’t really talk”. This is usually characterized by mutual respect, but a general distancing for myriad reasons that might include:</p>
<ul>
<li>
<p><strong>Personal differences</strong>: people might not get along personally, and while they may respect each other, they choose to maintain a distance. Ultimately, human beings are more or less big bundles of chemicals with legs. When chemicals interact, there’s usually a reaction: sometimes positive <code>(2H₂ + O₂ → 2H₂O)</code>, sometimes negative <code>(SO₃ + H₂O → H₂SO₄)</code>. This is usually natural and nothing personal.</p>
</li>
<li>
<p><strong>Professional differences</strong>: people may have different professional goals or values, which can lead to a lack of shared interests or collaboration. Some might want to be influencers, some might want to be builders, some might want to be investors—they pick the right relationships to be in for them at the time.</p>
</li>
<li>
<p><strong>Values differences</strong>: people may have different values that lead them to invest in different relationships. Some might value emotionality highly, leading them to be friends with other emotional people; others might value logic and reason, leading them to be friends with other logical people. Some might value money, leading them to be friends with other wealthy people, etc.</p>
</li>
</ul>
<p>In the context of the podcast, I’ve experienced folks who are aware it exists and even talk about it, but have never expressed interest in being a guest on it. I too have not extended invites here because we’re both in the same state of the spectrum. There’s nothing wrong with this: instead it’s kind of beautiful that both parties clearly understand where the other one stands on this spectrum and can move without any drama. It also doesn’t exclude the relationship from ever progressing and is usually just a matter of time before it does.</p>
</li>
<li>
<p><strong>Communicate</strong>: basic information exchange occurs, where either party would describe the other as “we spoke about something once” but the relationship doesn’t progress much further for similar reasons as above.</p>
<p>In the context of the podcast, this is where a conversation eventually leads to <em>“yeah, let’s do it”</em>, and then nothing ever happens, or an event is scheduled but has not yet taken place. Communication has happened, positive communication even, but—specifically in the case of the podcast—we have not yet cooperated on anything.</p>
<p>This is where the vast majority of western relationships live: a “comfortable distance” of sorts. We see traits of this outside a professional context as well, where shallow friends will talk and say <em>“let’s get coffee some time!”</em>, but then never actually follow up. Perhaps even worse, people in this state often make plans and then cancel at the last minute because it’s simply not convenient.</p>
<p>It’s pretty remarkable that this state is quite prominent in western culture and less so in other parts of the world as eloquently highlighted by my former <a href="https://x.com/TejasKumar_/status/1384524632263471106">Spotify</a> colleague <a href="https://x.com/orkohunter">Himanshu</a> in his <a href="https://orkohunter.net/blog/why-dont-you-move-abroad/">blog post about moving back to India</a>.</p>
</li>
<li>
<p><strong>Cooperate</strong>: parties participate in a neutral task together, where they’re both contributing to the same goal. The stakes are usually low, and the relationship is still mostly transactional.</p>
<p>A great experiential example of this from my career is when I’ve spoken at conferences with some folks who I’ve heard of but haven’t really developed much rapport with. The relationship is cordial, but not much else. How this low-stakes cooperation goes strongly influences next states: from here, either party can choose to remain in earlier states, or progress to the next state, <strong>Coordinate</strong>, based on how well they were able to work together (as popular culture calls it, <em>“the vibezzz”</em>).</p>
<p>In the context of the podcast, this is where we actually spend time in conversation together on an episode: both parties are contributing to the same goal, cooperating with each other to meet it. It’s slightly less convenient than the previous state, but given the quality of the cooperation, leads to far better outcomes.</p>
</li>
<li>
<p><strong>Coordinate</strong>: at this stage, one or both parties take deliberate steps to coordinate their actions toward a goal that belongs to one of the parties. This goal is often “adopted” by the other, looking something like:</p>
<ul>
<li>
<p><em>“we’re both going to be at this conference a day earlier, shall we go explore the city together?”</em> — one person’s goal of exploration is adopted by the other.</p>
</li>
<li>
<p><em>”I see you’re <a href="https://x.com/kentcdodds/status/1861808243590549572">working on a new course</a>—shall I do a <a href="https://x.com/TejasKumar_/status/1845140333933322311">giveaway</a> on my podcast when you launch?”</em> — one person’s goal of promoting their course is adopted by the other.</p>
</li>
</ul>
<p>Both of these cases are coordinated efforts. Though the latter is a more advanced state of coordination, the main gist here is that one or both parties take deliberate steps to coordinate their actions to achieve a newly shared goal: to support each other.</p>
<p>Either party can make the first move, and this tends to be a pretty chaotic space because it calls into question a number of topics like motivation, trust, and alignment. The party that makes the first move risks the other one thinking they’re being too aggressive, pushy, or plain weird.</p>
<p>They also risk the other party questioning their motivations:</p>
<ul>
<li>
<p><em>“Why is this person offering to amplify my course launch?"</em></p>
</li>
<li>
<p><em>"Why do they want to explore the city together?"</em></p>
</li>
<li>
<p><em>"What’s the catch?"</em></p>
</li>
<li>
<p><em>"Will I owe them a favor later?”</em></p>
</li>
</ul>
<p>The coordination state is usually perceived as risky—though empirical evidence proves it is not because <strong>people are on average more good than evil</strong> according to research from the lab of <a href="https://psychology.stanford.edu/people/jamil-zaki">Dr. Jamil Zaki</a> at Stanford University’s Department of Psychology, where they have demonstrated that <a href="https://www.youtube.com/watch?v=M7aUF3hi_8Q">coordinated efforts can lead to increased trust, motivation, and even happiness</a>.</p>
<p>Coordination is typically an inflection point in the relationship, as referenced in the diagram. If people have not spent enough time in previous states, this state usually will not work. If there were intense positive vibes in previous states, this will feel natural and seamless. Ultimately, both parties grow synergistically from coordinated efforts while working on entirely separate but complementary topics.</p>
<p>Folks that I’ve coordinated well with include:</p>
<ul>
<li>
<p><strong><a href="https://x.com/kentcdodds">Kent C. Dodds</a></strong> on deprecating his library <a href="https://github.com/paypal/glamorous">glamorous</a> in favor of <a href="https://github.com/emotion-js/emotion">emotion</a>: we built <em>separate things</em> that were complementary and coordinated on them together.</p>
</li>
<li>
<p><strong><a href="https://x.com/Aymen_Ben_Amor">Aymen Ben Amor</a></strong>, <strong><a href="https://x.com/theclarksell">Clark Sell</a></strong>, and <strong><a href="https://x.com/joshuakgoldberg">Josh Goldberg</a></strong> on <a href="https://tej.as/podcast/tell-me-about-that-conference">supporting their conferences via the podcast</a>: they were building a conference, I was building a podcast, and we coordinated on promoting the conference together (I adopted their goal of promoting the conference).</p>
</li>
<li>
<p><strong><a href="https://x.com/alexnmoldovan">Alex Moldovan</a></strong> who runs <a href="https://jsheroes.io/">JS Heroes</a> and has me as an ambassador: he creates the conference and coordinates with a set of ambassadors. We do not <em>create the conference</em> together. If we did, this would be the next step—<strong>Collaboration</strong>.</p>
</li>
</ul>
</li>
<li>
<p><strong>Collaborate</strong>: something beautiful happens when two or more people repeatedly execute successful coordinated efforts: there is a common recognition of high-quality synergy; that together, they are greater than the sum of their parts and they can continually share joy in their work. Collaboration is not when people coordinate efforts on building separate things that are complementary, but instead when they <strong>build the same thing together</strong>.</p>
<p>I’ve had the privilege of collaborating with a number of great folks over my career. If I was to start a company, go to war, or happen to be in a zombie apocalypse, I’d want these folks by my side. At this stage, all parties have established a high level of trust and understanding of each other. They understand boundaries and each other’s value systems extremely well. They are able to push boundaries and challenge ideas respectfully, with grace, without ego, at the right time and in the right circumstance.</p>
<p>Folks that I’ve had and continue to have excellent collaboration with include:</p>
<ul>
<li>
<p><strong><a href="https://x.com/fabien0102">Fabien Bernard</a></strong> and <strong><a href="https://x.com/mpotomin">Mikhail Potomin</a></strong>, where we built some software that was cool at the time but is now obsolete. Specifically,</p>
<ul>
<li>
<p><strong><a href="https://github.com/contiamo/restful-react">Restful React</a></strong>: a RESTful data layer for React applications that had a fully type-safe interface for working with REST APIs predictably.</p>
</li>
<li>
<p><strong><a href="https://github.com/contiamo/operational-ui">Operational UI</a></strong>: a React component library whose documentation had interactive <a href="https://microsoft.github.io/monaco-editor/">Monaco Editor</a> playgrounds with IntelliSense for TypeScript autocompletion <em>in the browser</em>. I did a talk about this at <a href="https://www.youtube.com/watch?v=ZsBW4S8hYMU">React Finland</a> in 2019 where I first met</p>
</li>
</ul>
</li>
<li>
<p><strong><a href="https://x.com/davidkpiano">David Khourshid</a></strong> and <strong><a href="https://x.com/jen_ayy_">Jenny Truong</a></strong>, where we built their wedding ceremony together where I was the officiant. This is a collaboration and not a coordination because we built the same thing (a wedding ceremony) together, instead of coordinating on building separate things that are complementary.</p>
</li>
<li>
<p><strong><a href="https://x.com/danieljcafonso">Daniel Afonso</a></strong>, <strong><a href="https://x.com/sergiikirianov">Sergii Kirianov</a></strong>, <strong><a href="https://x.com/ythecombinator">Matheus Albuquerque</a></strong>, <strong><a href="https://x.com/acemarke">Mark Erikson</a></strong>, <strong><a href="https://x.com/rickhanlonii">Rick Hanlon II</a></strong>, and more where we built my book <a href="https://www.amazon.com/Fluent-React-Performant-Intuitive-Applications/dp/1098138716/ref=sr_1_1?dib=eyJ2IjoiMSJ9.eigFqxPBQ8MG8Reub4v6d26VACrOAWNNB4flZUD6j_lArvmiIuT-RzRq5-7vyhvJd3ZruoaI9ZRp_I3r3-a5SNuGE_MAKaNluhRqBfjh6FQ.JAAVgZuJ8Rxht6r7T-dw4pSLd6FOIt8ckVtmo5QIHZ4&amp;dib_tag=se&amp;keywords=fluent+react&amp;qid=1732797223&amp;sr=8-1">Fluent React</a> together. I may have authored the book, but it was a strong collaborative effort where they reviewed it and continued to provide high-quality feedback until it was ready for publication. It was <em>one thing</em> that we all built together: a collaboration.</p>
</li>
</ul>
<p>I don’t yet build the podcast with anyone, but I’m open to it.</p>
</li>
<li>
<p><strong>We are the same</strong>: the final state represents a shared identity and enmeshment, which is <strong>not a positive state</strong>. Keeping with the old adage of “too much of a good thing is a bad thing”, this is a state where parties are co-dependent and enmeshed, where one or more members unhealthily depend on the other. There is a dissolution of individuality, a loss of identity and boundaries: this is a toxic state. <strong>In this state, we find and experience burnout.</strong></p>
<p>It’s easy to exploit this state and take advantage of one or more members. Ownership over collaborative efforts is also disputed in this state, and it’s not uncommon to see folks take credit for things that they didn’t do, or to see people step down from collaborative efforts because they feel they’re not being valued.</p>
<p>Attempts to reach ideal and healthy levels of collaboration often go wrong and end up here, usually by employers using toxic positivity and platitudes like <em>“we’re a startup family”</em>. You may recognize you’re in this state by several key warning signs:</p>
<ul>
<li>
<p><strong>Loss of Personal Identity</strong>: inability to develop or maintain a strong sense of self, only being able to describe yourself in relation to others, being uncomfortable taking credit for your own good work, and difficulty knowing your own wants and needs.</p>
</li>
<li>
<p><strong>Difficulty Making Independent Decisions</strong>: struggling to make choices without consulting others, feeling unable to function independently, anxious overthinking, and constantly seeking approval before taking action.</p>
</li>
<li>
<p><strong>Lack of Boundaries</strong>: having trouble saying “no,” allowing others to invade your privacy, and being unable to separate your emotions from those of others.</p>
</li>
</ul>
<p>I’ve fallen into this state a few times for very short periods and what has helped me get out of it is to redevelop <strong>my identity alone</strong> as a separate and beautiful thing from really any other party. That and separation from the problematic party. The combination of rediscovering self-identity, establishing healthy boundaries, separation, and working with a board-certified therapist is something that can be helpful for folks that find themselves in this state.</p>
<p>Ideally, we learn to recognize quality collaboration as the peak of synergy and protect against this state. I am thankful to rarely if ever find myself here and take strong measures to avoid it. If you’re in this state, it is my hope that this diagram and post will help you understand where you are and how to move forward. Keep reading for some actionable steps you can take to move your relationships forward.</p>
</li>
</ol>
<h2 id="making-it-practical">Making it Practical</h2>
<p>Take a moment to think about where your relationships stand on this spectrum. It’s a great exercise to help you understand where you are and where you want to be. I’ve already mentioned a few of my own excellent collaborators and folks with whom I coordinate well—who are yours? Who can you credit? For real, scroll up, copy the image, place it beside you, and ponder it closely.</p>
<p>Who are folks that you coexist with? Why? Who gatekeeps and excludes you? Who would you build a company with? I’d encourage carefully considering the answers to these questions and even copying the graph and placing avatars along its axis to help you visualize the status of your relationships. From there, you can start to take action to move relationships to where you want them to be, ultimately bringing your social setting into alignment with your goals and values.</p>
<p>Should you decide you’d like to move some relationships forward, here are some actionable pathways you can take.</p>
<h2 id="moving-relationships-forward">Moving Relationships Forward</h2>
<p>There’s plenty of evidence that shows that we’re at our worst when we are exclusionary and <em>zero-sum</em>. The inverse is also true: we are at our best when we are collaborating well with others. For example, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC4360764/">this paper</a> has two key ideas that I think are worth repeating here:</p>
<p>Working in isolation creates significant limitations:</p>
<ol>
<li>It creates a <strong>false sense of security</strong> because ideas are not likely to be challenged.</li>
<li>It results in work that <strong>will not reach as wide an audience</strong>.</li>
<li>It <strong>wastes limited resources</strong> through duplicated efforts.</li>
</ol>
<p>The paper also states that:</p>
<blockquote>
<p>The benefits of collaboration allow participants to achieve together more than they can individually, serve larger groups of people, and grow on individual and organizational levels.</p>
</blockquote>
<p>With this, we can see that <strong>collaboration is not just a nice-to-have but a necessity</strong>. It’s not just about getting along with others, but about building greater things together. Should you decide to move some relationships forward, here’s what has worked well for me:</p>
<ol>
<li>
<p><strong>Cultivate an abundance mindset</strong>: not virtue signaling, but I often <a href="https://x.com/Beccalytics/status/1858935386757886175">give away money</a> and time to folks. People question this from time to time and ultimately, the answer I end up giving is that <strong>there is so much to go around</strong>. The world is abundant and not zero-sum. I intentionally let people take advantage of me because I know I’ll recover whatever I need in another way. If you pour your entire bucket into others, it may become empty but it will never <em>stay empty</em>: it has rained on this planet since the beginning of time on rich and poor alike, and it will continue to rain. <strong>The rain will fill your bucket again.</strong></p>
<p>To cultivate this mindset, these practical steps from <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10039809/">these</a> <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10794476/">scientific</a> <a href="https://www.researchgate.net/publication/236137739_Volunteering_Predicts_Health_Among_Those_Who_Value_Others_Two_National_Studies">papers</a> may help:</p>
<ul>
<li>
<p><strong>Start Small</strong>: begin with micro-giving. Allocate a small percentage of your resources to deliberately give away. I do 10%, but you can start with 5% and see how it feels. Another useful habit is to practice random acts of kindness daily, whenever convient.</p>
</li>
<li>
<p><strong>Build Social Connections</strong>: join giving circles, participate in community service, and create giving networks. This is a great way to meet like-minded people and cultivate relationships. It’s like <em>“scarcity mindsets anonymous”</em>: a rehab group for those that suffer with scarcity mindset. Cooperate and collaborate with each other to achieve goals that are greater than the sum of your parts.</p>
</li>
<li>
<p><strong>Mindfulness Practice</strong>: daily gratitude journaling, abundance visualization, and regular meditation focusing on interconnectedness have all been scientifically proven (papers above) to help shift your mindset towards abundance.</p>
</li>
<li>
<p><strong>Track Impact</strong>: keep a “giving diary” to document your positive outcomes and ripple effects. This can help you remember to do it again and track your personal growth.</p>
</li>
</ul>
</li>
<li>
<p><strong>Abandon lost causes</strong>: people have literally blocked me on social media, ghosted me, or outright said “there’s no room for you at this table”. Anti-foreigner folks have physically attacked me and mentioned “go home” (to your country) in Germany, where I am a tax-paying permanent resident.</p>
<p>A lesson I learned from reading <a href="https://www.amazon.com.mx/Models-Attract-Women-Through-Honesty/dp/1463750358">Mark Manson’s “Models”</a> as an awkward stupid teenager who wanted to get girls is that the world is an abundant one full of all kinds of people: some who shun us, others who love us. When someone reveals that there’s no room for a relationship, they do us a huge favor and free us up to go pursue others who are open to it. I’ve seen great success in quickly being thankful for the data and moving on.</p>
</li>
<li>
<p><strong>Love your neighbor as yourself</strong>: I really love myself well. I feed myself good food, I give myself good exercise, I make money to invest in myself. I’ve seen enormous value and joy in extending the same love to others, beyond just one’s physical neighbor. It would be strange of me to expect something in return from myself as I take care of myself. When I treat people the way I want to be treated—and honor them appropriately, <strong>giving expecting nothing in return</strong>, there usually ends up being quite a wonderful return that leads to quality collaboration.</p>
<p>Obviously this isn’t <em>every time</em>, but the few times it works is worth all the times it doesn’t. It does open you up to abuse and being taken advantage of, but the few times it has worked for me heavily outweighs the times it hasn’t. I’d recommend reading <a href="https://www.amazon.com/Hope-Cynics-Surprising-Science-Goodness/dp/B0D5SD8W2B/ref=sr_1_1?dib=eyJ2IjoiMSJ9.YGSiHm0vKfPnGGrkfEHzjo81gfFIgxL-9JYZ3wynncT9hkigUoOdVe5Xf7co4vmVoA67pcbuC0blFH61PwRXw-jsQYC2X4Tmt7MvGdhEs1ew59RSDe-NSq2RvklLU_ZKA0xljACwL2T2dUUYYhzVow.6TyURxQ4Lkcxjo6baEUiRI0cpgny4R5Bay4IUE9Hu0k&amp;dib_tag=se&amp;keywords=hope+for+cynics&amp;qid=1732808871&amp;sr=8-1">Hope for Cynics</a> by the aforementioned Dr. Jamil Zaki for more on this topic.</p>
</li>
<li>
<p><strong>Sweat the details</strong>: we live in an age where we’re constantly bombarded by random nonsense vying for our attention. Conforming to the pattern of this world, it’s fairly common to respond to folks with low-effort communication.</p>
<ul>
<li><em>”sup"</em></li>
<li><a href="https://x.com/TejasKumar_/status/1747176544433230198"><em>"lgtm"</em></a></li>
<li><em>"sounds good”</em></li>
</ul>
<p>This is characteristic of the <strong>communicate</strong> state in our diagram.</p>
<p>Every single time a relationship has moved forward for me has been when <strong>I cared. A lot.</strong> It has been when folks have mentioned something that’s stressing them out and I listened. It has been when I followed up with them about it weeks later. It has been when my people and I have <strong>shown up and done the work</strong> that puts them at ease or actively invests in their goals—when we don’t conform to the pattern of the world, but instead transform our behavior to align closer to our values.</p>
<p>To circle back, <strong>coordination happens when one party adopts the goal of the other and takes initiative to support it</strong>. Sweating the details and doing the work, even at a cost to ourselves, is a great way to move from cooperation to coordination. When there are repeatedly successful coordinated efforts, the relationship will naturally progress to collaboration.</p>
</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>If you’ve made it this far, I hope you’ve found this useful. I also hope that you have actually <em>done the exercise</em> (and cooperated with me) to identify the current state of your relationships and feel empowered to move the ones that you’d like to forward.</p>
<p>If you’d like to join a <strong>coordinated</strong> effort to bring this information to more people, you can do so in the following ways:</p>
<ul>
<li>Share this post on social media however/wherever you want.</li>
<li>Share your version of the graph above with avatars superimposed on it with your collaborators and others.</li>
<li>Share your thoughts about this text with me on <a href="https://x.com/tejaskumar_">𝕏</a> or other platforms.</li>
</ul>
<p>If you’d like to <strong>collaborate</strong> on this post or its ideas, some great ways to do so are:</p>
<ul>
<li>Translate it into other languages to make it more accessible to more people.</li>
<li>Suggest typo fixes and studies to include.</li>
<li>Fact check and suggest removal of any inaccuracies.</li>
</ul>
<p>Notice how for <strong>collaboration</strong>, we’re working on the same thing (this post) together, and for <strong>coordination</strong> you’re creating separate things that are complementary? Okay, I think I’ve made my point.</p>
<p>Goodbye.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why America's economy is soaring ahead of its rivals (101 pts)]]></title>
            <link>https://www.ft.com/content/1201f834-6407-4bb5-ac9d-18496ec2948b</link>
            <guid>42314797</guid>
            <pubDate>Wed, 04 Dec 2024 05:53:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/1201f834-6407-4bb5-ac9d-18496ec2948b">https://www.ft.com/content/1201f834-6407-4bb5-ac9d-18496ec2948b</a>, See on <a href="https://news.ycombinator.com/item?id=42314797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offer-f9443aa4-795a-4bf5-8525-ee99e05b93a4" data-component="heroOffer" data-component-unique-name="Hero offer"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Try unlimited access</span></h2><h2><strong><span>Only </span><span>Skr10</span><span> for 4 weeks</span></strong></h2></p><p><span>Then </span><span>Skr739</span><span> per month.
Complete digital access to quality FT journalism on any device. 
Cancel anytime during your trial.</span></p></div></div><div id="recommendedOffers-Recommended offers-d039683e-d169-47ab-b84d-893ae968a297" data-component="recommendedOffers" data-component-unique-name="Recommended offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_standard.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Standard Digital</h3></p></div><p><span>Skr479</span><span> per month</span></p><p><span>Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>Skr739</span><span> per month</span></p><p><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_ftprofessional.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>Pay per reader</span></p><p><span>Complete digital access for organisations. Includes exclusive features and content.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=1201f834-6407-4bb5-ac9d-18496ec2948b">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenTTD is an open source simulation game based upon Transport Tycoon Deluxe (295 pts)]]></title>
            <link>https://www.openttd.org/</link>
            <guid>42314700</guid>
            <pubDate>Wed, 04 Dec 2024 05:29:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openttd.org/">https://www.openttd.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42314700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>I was once the hottest new model on the street.
Newspapers heralded my arrival in every town.
The titans of industry were inspired to produce more goods when I visited their factories.</p>

<p>But as the years have passed, so do their eyes pass over me, to eye curiously my replacements.
Will you try the new style, ma’am?
It’s so much better than <em>that old thing</em>.</p>

<p>I’ve watched my friends grow old and die.
My brother got caught in traffic and caused a horrific level crossing collision.
I get sick more often, wheezing to a halt wherever I am.
When I visit the doctor for a spot of renewal, they tell me,
“Sorry, I can’t help. You’re too old.”
When will I be autoreplaced?</p>

<p>Woe is the tale of the Balogh Goods Truck.
But what if we could slow or pause the steady march of time?
In OpenTTD 14, you can.</p>



        
            <p><a href="https://www.openttd.org/news/2024/03/23/timekeeping.html">Read more</a></p>
        
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IMG_0001 (1400 pts)]]></title>
            <link>https://walzr.com/IMG_0001/</link>
            <guid>42314547</guid>
            <pubDate>Wed, 04 Dec 2024 04:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://walzr.com/IMG_0001/">https://walzr.com/IMG_0001/</a>, See on <a href="https://news.ycombinator.com/item?id=42314547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Between 2009 and 2012, iPhones had a built-in "Send to YouTube" button in the Photos app. Many of these uploads kept their default IMG_XXXX filenames, creating a time capsule of raw, unedited moments from random lives. </p><p>Inspired by <a href="https://ben-mini.github.io/2024/img-0416" target="_blank">Ben Wallace</a>, I made a bot that crawled YouTube and found 5 million of these videos! Watch them below, ordered randomly.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A particle physics course for high-school students (223 pts)]]></title>
            <link>https://ppc.web.cern.ch/</link>
            <guid>42314340</guid>
            <pubDate>Wed, 04 Dec 2024 03:49:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ppc.web.cern.ch/">https://ppc.web.cern.ch/</a>, See on <a href="https://news.ycombinator.com/item?id=42314340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      


<h2>About this Course</h2>



<p>This is the pilot version of a particle physics course for high-school students – a research-based product of CERN’s <a href="https://per.web.cern.ch/" target="_blank">Physics Education Research</a> team. It contains 16 chapters with videos and quizzes and covers a core curriculum that introduces you to fundamental questions, such as “What is a particle?” or “What are charges and interactions?”, leading to more applied questions, such as “What is a particle accelerator?” and “What is a particle detector?”.</p>

<ul>
	<li>The total length of the pilot version of the course videos is close to 4 hours.</li>
	<li>The course features instructions for DIY experiments that you can try out at home.</li>
	<li>You can complete chapters in any order you like, so feel free to jump around and explore the full content of the course!</li>
	<li>If you complete all chapters by answering the corresponding quiz questions correctly, you qualify for a digital certificate!</li>
</ul>

<p>In the future, we want to further develop this particle physics course. That’s why we have also included feedback questions for every chapter to collect your feedback on the content of the course and its design. <span>Indeed, we need you to tell us how to improve this course and which topics to add in the future! </span>Your feedback will, of course, be collected anonymously, and your responses will have no impact on your completion of the course! Here’s a trailer to give you an idea of what this course is all about:</p>

<p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="615" src="https://www.youtube.com/embed/OjrycTZxG4M"></iframe></p>






<h2>Are you ready?</h2>

<p>We’re excited to get you started! To access the particle physics course, you just need to create a <a href="https://users-portal.web.cern.ch/guest-registration" target="_blank">CERN guest account</a>.</p>

<p><label for="myCheckOver16"> I am 16 years old or above. </label></p>



<p><label for="myCheckUnder16"> I am younger than 16 years. </label></p>



<p>Once you have created a CERN guest account:<br>
Step 1: <a href="https://ppc.web.cern.ch/user/login">Sign in</a><br>
Step 2: <a href="https://ppc.web.cern.ch/chapters-0">Start the Course!</a></p>





<!-- <div class="button-container"><button class="take-course-btn" id="takeCourseBtn">Start the Course!</button></div> -->



    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf 2024 (142 pts)]]></title>
            <link>https://emacsconf.org/2024/</link>
            <guid>42314024</guid>
            <pubDate>Wed, 04 Dec 2024 02:42:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://emacsconf.org/2024/">https://emacsconf.org/2024/</a>, See on <a href="https://news.ycombinator.com/item?id=42314024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pagebody" role="main" class="page">


<p>EmacsConf 2024 | Online Conference<br>
<b>December 7 and 8, 2024 (Sat-Sun)</b></p>




<p><a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a></p>




<p><strong><a href="https://emacsconf.org/2024/watch/">How to watch/participate</a></strong> | <strong><a href="https://emacsconf.org/2024/talks/">Talks</a></strong> | <a href="https://emacsconf.org/volunteer/">Volunteer</a> | <a href="https://emacsconf.org/conduct/">Guidelines for Conduct</a></p>




<p>EmacsConf is the conference about the joy of
<a href="https://www.gnu.org/software/emacs/">GNU Emacs</a> and
Emacs Lisp.</p>


<p>We are busy putting things together for EmacsConf 2024, and we would
love to have <em>your</em> help to make EmacsConf 2024 amazing, much like the
previous EmacsConfs.  Missed the proposal deadline but got a great idea anyway? <a href="https://emacsconf.org/2024/cfp/">Let us know</a> just in case we can still squeeze you in somehow.</p>

<p>We are holding EmacsConf 2024 as an online conference again this year.
We remain fully committed to freedom, and we will continue using our
infrastructure and streaming setup consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free
software</a>, much like previous EmacsConf conferences.</p>

<p>There is also a satellite event in
<a href="https://200ok.ch/posts/2024-09-16_announcing_emacsconf__official_swiss_satellite.html">Lucerne, Switzerland</a>.
Let us know if you want to organize one too!</p>

<p>For general EmacsConf discussions, join the
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a>
mailing list.  For discussions related to organizing EmacsConf, join
the
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-org">emacsconf-org</a>
mailing list.  You can email us publicly at
<a href="mailto:emacsconf-org@gnu.org">emacsconf-org@gnu.org</a> or privately at
<a href="mailto:emacsconf-org-private@gnu.org">emacsconf-org-private@gnu.org</a>.</p>

<p>Come hang out with us in the <code>#emacsconf</code> channel on <code>irc.libera.chat</code>
(<a href="https://libera.chat/">Libera.Chat</a> IRC network).  You can join the chat using
<a href="ircs://irc.libera.chat:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Formaldehyde Causes More Cancer Than Any Other Toxic Air Pollutant (183 pts)]]></title>
            <link>https://www.propublica.org/article/formaldehyde-epa-trump-public-health-danger</link>
            <guid>42313910</guid>
            <pubDate>Wed, 04 Dec 2024 02:16:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/formaldehyde-epa-trump-public-health-danger">https://www.propublica.org/article/formaldehyde-epa-trump-public-health-danger</a>, See on <a href="https://news.ycombinator.com/item?id=42313910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pp-location="article body">

        
                    <div data-pp-location="top-note">
                

                                                
            <p>ProPublica is a nonprofit newsroom that investigates abuses of power. Sign up to receive <a href="https://www.propublica.org/newsletters/the-big-story?source=www.propublica.org&amp;placement=top-note&amp;region=national">our biggest stories</a> as soon as they’re published.</p>

                

            </div><!-- end .article-body__top-notes -->
        
                    

<div>
    <h3>Reporting Highlights</h3>
    <ul>
                    <li><span>An Ever-Present Danger: </span> Formaldehyde is all around us and causes more cancer than any other chemical in the air. It can also trigger asthma, miscarriages and fertility problems.</li>
            <li><span>Industry Fights Back: </span> Companies use formaldehyde for everything from making furniture to sterilizing food. Industry has repeatedly thwarted government efforts to limit its health risks.</li>
            <li><span>Closer Than Ever: </span> Federal regulators were recently on track to make modest reforms, but those are all but guaranteed to hit a dead end when Donald Trump takes office.</li>
            </ul>
    <p>
        These highlights were written by the reporters and editors who worked on this story. <span id="survey-placeholder"></span>
    </p>
</div>





        
        




                    

<figure data-pp-id="2" data-pp-blocktype="embed">

    


                        
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="3.0">In a world flush with hazardous air pollutants, there is one that causes far more cancer than any other, one that is so widespread that nobody in the United States is safe from it.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="4.0">It is a chemical so pervasive that a new analysis by ProPublica found it exposes everyone to elevated risks of developing cancer no matter where they live. And perhaps most worrisome, it often poses the greatest risk in the one place people feel safest: inside their homes.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="5.0">As the backbone of American commerce, formaldehyde is a workhorse in major sectors of the economy, preserving bodies in funeral homes, binding particleboards in furniture and serving as a building block in plastic. The risk isn’t just to the workers using it; formaldehyde threatens everyone as it pollutes the air we all breathe and leaks from products long after they enter our homes. It is virtually everywhere.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="6.0">Federal regulators have known for more than four decades that formaldehyde is toxic, but their attempts to limit the chemical have been repeatedly thwarted by the many companies that rely on it.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="7.0">This year, the Biden administration finally appeared to make some progress. The Environmental Protection Agency is expected to take a step later this month toward creating new rules that could restrict formaldehyde.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="8.0">But the agency responsible for protecting the public from the harms of chemicals has significantly underestimated the dangers posed by formaldehyde, a ProPublica investigation has found.</p>
        
    
                    <figure data-pp-id="9" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>Formaldehyde threatens everyone as it pollutes the air we all breathe and leaks from products long after they enter our homes. It is virtually everywhere.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="10.0">The EPA is moving ahead after setting aside some of its own scientists’ conclusions about how likely the chemical is to cause myeloid leukemia, a potentially fatal blood cancer that strikes an estimated 29,000 people in the U.S. each year. The result is that even the EPA’s alarming estimates of cancer risk vastly underestimate — by as much as fourfold — the chances of formaldehyde causing cancer.</p>
        
    
                    
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="12.0">The agency said it made the decision because its estimate for myeloid leukemia was “too uncertain” to include. The EPA noted that the National Academies of Sciences, Engineering and Medicine, which the agency paid to review its report, agreed with its decision not to include myeloid leukemia in its cancer risk. But four former government scientists with experience doing statistical analyses of health harms told ProPublica that the myeloid leukemia risk calculation was sound. One said the risk was even greater than the agency’s estimate.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="13.0">Jennifer Jinot, one of the EPA scientists who spent years calculating the leukemia risk, said there is always uncertainty around estimates of the health effects of chemicals. The real problem, she said, was cowardice.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="14.0">“In the end, they chickened out,” said Jinot, who retired in 2017 after 26 years working at the EPA. “It was kind of heartbreaking.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="15.0">The EPA has also retreated from some of its own findings on the other health effects of formaldehyde, which include asthma in both children and adults; other respiratory ailments, including reduced lung function; and reproductive harms, such as miscarriages and fertility problems. In a draft report expected to be finalized this month, the agency identified many instances in which formaldehyde posed a health threat to the public but questioned whether most of those rose to a level the agency needed to address. In response to questions from ProPublica, the EPA wrote in an email that the report was not final and that the agency was in the process of updating it.</p>
        
    
                    <figure data-pp-id="17" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>Even the EPA’s alarming estimates of cancer risk vastly underestimate — by as much as fourfold — the chances of formaldehyde causing cancer.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="18.0">Still, if the past is any guide, even the limited efforts of President Joe Biden’s administration are all but guaranteed to hit a dead end after Donald Trump is inaugurated. And one of the longest-running attempts to restrict a dangerous chemical in American history would be set back yet again.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="19.0">ProPublica reporters have spent months investigating formaldehyde, its sweeping dangers and the government’s long, frustrating battle to curb how much of it we breathe.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="20.0">They have analyzed federal air pollution data from each of the nation’s 5.8 million populated census blocks and done their own testing in homes, cars and neighborhood businesses. They have interviewed more than 50 experts and pored through thousands of pages of scientific studies and EPA records. They’ve also reviewed the actions of the previous Trump administration and what’s been disclosed about the next.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="21.0">The conclusion: The public health risks from formaldehyde are greater and more prevalent than widely understood — and any hope of fully addressing them may well be doomed, at least for the foreseeable future.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="22.0">Since its inception, the EPA has been outgunned by the profitable chemical industry, whose experts create relatively rosy narratives about their products. That battle intensified over the last four years as the EPA tried to evaluate the scope of the public health threat posed by formaldehyde.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="23.0">Regulatory rules put the onus on the government to prove a chemical is harmful rather than on industry to prove its products are safe. Regardless of who is in the White House, the EPA has staff members with deep ties to chemical companies. During some administrations, it is run by industry insiders, who often cycle between jobs in the private sector and the government.</p>
        
    
                    <figure data-pp-id="24" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>If the past is any guide, even the limited efforts of President Joe Biden’s administration are all but guaranteed to hit a dead end after Donald Trump is inaugurated.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="25.0">Trump has already vowed to roll back regulations he views as anti-business — an approach that promises to upend the work of government far beyond formaldehyde protections. Still, this one chemical makes clear the potential human toll of crafting rules to serve commerce rather than public health. And Trump’s last term as president shows how quickly and completely the efforts now underway might be stopped.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="26.0">At the EPA, he appointed a key figure from the chemical industry who had previously defended formaldehyde. The agency then quietly shelved a report on the chemical’s toxicity. It refused to enforce limits on formaldehyde released from wood products until a judge forced its hand. And it was under Trump that the agency first decided not to include its estimate of the risk of developing myeloid leukemia in formaldehyde’s overall cancer risk calculation, weakening the agency’s ability to protect people from the disease.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="27.0">The latest efforts to address formaldehyde pollution are likely to meet a similar fate, according to William Boyd, a professor at UCLA School of Law who specializes in environmental governance. Boyd <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4753197">has described formaldehyde</a> as a sort of poster child for the EPA’s inability to regulate chemicals. Because formaldehyde is key to so many lucrative industrial processes, companies that make and use it have spent lavishly on questioning and delaying government efforts to rein it in.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="28.0">“The Biden administration was finally bringing some closure to that process,” said Boyd. “But we have every reason to suspect that those efforts will now be revised. And it will likely take years for the EPA to do anything on this.”</p>
        
    
                    
<h3>Invisible Threat</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="30.0">Perhaps best known for preserving dead frogs in high school biology labs, formaldehyde is as ubiquitous in industry as salt is in cooking. Between 1 billion and 5 billion pounds are manufactured in the U.S. each year, according to EPA data from 2019.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="31.0">Outdoor air is often suffused with formaldehyde gas from cars, smoke, factories, and oil and gas extraction, sometimes at worrying levels that are predicted to worsen with climate change. Much of the formaldehyde outdoors is also spontaneously formed from other pollutants.</p>
        
    
                    <figure data-pp-id="32" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>The public health risks from formaldehyde are greater and more prevalent than widely understood — and any hope of fully addressing them may well be doomed, at least for the foreseeable future.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="33.0">Invisible to the eye, the gas increases the chances of getting cancer — severely in some parts of the country.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="34.0">This year, the EPA released its most sophisticated estimate of the chance of developing cancer as a result of exposure to chemicals in outdoor air in every populated census block across the United States. The <a href="https://www.epa.gov/AirToxScreen/2020-airtoxscreen">agency’s sprawling assessment</a> shows that, among scores of individual air pollutants, formaldehyde poses the greatest cancer risk — by far.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="35.0">But ProPublica’s analysis of that same data showed something far more concerning: It isn’t just that formaldehyde poses the greatest risk. It’s that its risk far exceeds the agency’s own goals, sometimes by significant amounts.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="36.0">ProPublica found that, in every census block, the risk of getting cancer from exposure to formaldehyde in outdoor air over a lifetime is higher than the limit of one incidence of cancer in a million people, the agency’s goal for air pollutants. That risk level means that if a million people in an area are continuously exposed to formaldehyde over 70 years, the chemical would cause at most one case of cancer, on top of those from other risks people already face.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="37.0">According to ProPublica’s analysis of the EPA’s 2020 AirToxScreen data, some 320 million people live in areas of the U.S. where the lifetime cancer risk from outdoor exposure to formaldehyde is 10 times higher than the agency’s ideal.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="38.0">(ProPublica is <a href="https://projects.propublica.org/formaldehyde-cancer-risk-map">releasing a lookup tool</a> that allows anyone in the country to understand their outdoor risk from formaldehyde.)</p>
        
    
                    <figure data-pp-id="39" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>Trump has already vowed to roll back regulations he views as anti-business — an approach that promises to upend the work of government far beyond formaldehyde protections.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="40.0">In the Los Angeles/San Bernardino, California, area alone, some 7.2 million people are exposed to formaldehyde at a cancer risk level more than 20 times higher than the EPA’s goal. In an industrial area east of downtown Los Angeles that is home to several warehouses, the lifetime cancer risk from air pollution is 80 times higher, most of it stemming from formaldehyde.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="41.0">Even those alarming figures underestimate the true danger. As the EPA admits, its cancer risk calculation fails to reflect the chances of developing myeloid leukemia. If it had used its own scientists’ calculation — “the best estimate currently available,” according to the agency’s August report — the threat of the chemical would be shown to be far more severe. Instead of causing 20 cancer cases for every million people in the U.S., formaldehyde would be shown to cause approximately 77.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="42.0">Using the higher figure to set regulations of the chemical could eventually help prevent thousands of cases of myeloid leukemia, according to ProPublica’s analysis. </p>

<p data-pp-blocktype="copy" data-pp-id="42.1">As Mary Faltas knows, the diagnosis can upend a life.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="43.0">Faltas, 60, is still sorting through the aftermath of having myeloid leukemia, which she developed in 2019. “It’s like having a storm come through,” she said recently. “It’s gone, but now you’re left with everything else to deal with.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="44.0">It wasn’t always clear she’d survive. There are two types of myeloid leukemia. Faltas had the more deadly acute form and spent a year and a half undergoing chemotherapy, fighting life-threatening infections and receiving a bone marrow transplant. Too sick to work, she lost her job as a dental assistant. She and her husband were forced to sell their house in Apopka, Florida, and downsize to a small condo — a move that took place when she was too weak to pack a box.</p>
        
    
                                  
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="46.0">It’s almost always impossible to pinpoint a single cause for someone’s cancer. But Faltas has spent her entire life in places where the EPA’s data shows there is a cancer risk 30 times the level the agency says it strives to meet. And in that way, she’s typical. Nationwide, that’s the average lifetime cancer risk from air pollution; formaldehyde accounts for most of it. Factor in the EPA’s myeloid leukemia calculation, and Faltas has lived in places where cancer risk from formaldehyde alone is 50 to 70 times the agency’s goal.</p>
        
    
                    <figure data-pp-id="47" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>According to ProPublica’s analysis of the EPA’s 2020 AirToxScreen data, some 320 million people live in areas of the U.S. where the lifetime cancer risk from outdoor exposure to formaldehyde is 10 times higher than the agency’s ideal.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="48.0">Layered on top of the outdoor risk we all face is the much more considerable threat indoors — posed by formaldehyde in furniture, flooring, printer ink and dozens of other products. The typical home has a formaldehyde level more than three times higher than the one the EPA says would protect people against respiratory symptoms. The agency said it came up with its recommended level to protect sensitive subgroups and that the potential for health effects just above it are “unknown.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="49.0">The EPA’s own calculations show that formaldehyde exposure in those homes would cause as many as 255 cancer cases in every million people exposed over their lifetimes — and that doesn’t reflect the risk of myeloid leukemia. The agency also said “there may not be a feasible way currently to reduce the average indoor level of formaldehyde to a point where there is no or almost no potential risk.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="50.0">ProPublica will delve more into indoor risks, and how to guard against them, in the coming days. </p>

<h3>The Long Road to Nowhere</h3>
<p data-pp-blocktype="copy" data-pp-id="50.1">The fruitless attempts to limit public exposure to formaldehyde stretch back to the early ’80s, soon after the chemical was shown to cause cancer in rats.</p>
        
    
                    <figure data-pp-id="51" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>The typical home has a formaldehyde level more than three times higher than the one the EPA says would protect people against respiratory symptoms.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="52.0">The EPA planned to take swift action to reduce the risks from formaldehyde, but an appointee of President Ronald Reagan named John Todhunter stopped the effort. He argued that formaldehyde didn’t pose a significant risk to people. A House investigation later revealed he had met with chemical industry representatives, including a lobbyist from the Formaldehyde Institute, just before making his decision. Todhunter denied being influenced but resigned under pressure.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="53.0">In 1991, under President George H.W. Bush, the EPA finally deemed formaldehyde a probable human carcinogen and calculated the likelihood of it causing an extremely rare cancer that affects a part of the throat called the nasopharynx. But it quickly became clear that more protection was needed.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="54.0">A <a href="https://pubmed.ncbi.nlm.nih.gov/14600094/">2003 study</a> showed that factory workers exposed to high levels of formaldehyde were 3 1/2 times more likely to develop myeloid leukemia than workers exposed to low levels of the chemical. “Having human data showing an effect like that … it’s a rare thing,” said Jinot, the former EPA statistician and toxicologist. “You want to seize that opportunity.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="55.0">She and colleagues at the agency crunched numbers, immersed themselves in the medical literature and consulted with other scientists to conclude that formaldehyde was a known carcinogen and caused myeloid leukemia, among other cancers.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="56.0">But in 2004, their work hit a roadblock. Sen. James Inhofe, R-Okla., persuaded the EPA to delay the update of its formaldehyde report until the National Cancer Institute released the results of a study that was underway.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="57.0">The harms, meanwhile, continued to mount. In 2006, people who lost their homes in Hurricane Katrina and were housed in government trailers began to report feeling sick. The symptoms, which included breathing difficulties, eye irritation and nosebleeds, were traced to high levels of formaldehyde.</p>
        
    
                    <figure data-pp-id="58" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>In 2006, people who lost their homes in Hurricane Katrina and were housed in government trailers began to report feeling sick. The symptoms, which included breathing difficulties, eye irritation and nosebleeds, were traced to high levels of formaldehyde.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="59.0">In 2009, under the Obama administration, the EPA was once again poised to release its report on the toxicity of formaldehyde. By then, the <a href="https://pubmed.ncbi.nlm.nih.gov/19436030/">National Cancer Institute’s study</a> had been published, making the link between formaldehyde and myeloid leukemia even clearer.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="60.0">This time, another U.S. senator intervened. David Vitter, R-La., who had received donations from chemical companies and a formaldehyde lobbyist, <a href="https://www.propublica.org/article/hhs-declares-formaldehyde-a-carcinogen-impact-on-regulations-remains-unknow">held up the confirmation of an EPA nominee</a>. He agreed to approve the nomination in exchange for <a href="https://www.politico.com/story/2010/04/vitter-fights-for-formaldehyde-035834">an additional review of the formaldehyde report</a> by a panel of the National Academies of Sciences, Engineering and Medicine.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="61.0">The outside review found “problems with clarity and transparency of the methods” used in the EPA report and recommended that, in its next version, the EPA employ “vigorous editing” and explain its arguments more clearly.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="62.0">But the EPA would not issue that next version for more than a decade. After the outside review, the chemical industry seized on its findings as evidence of fundamental problems at the agency. For years afterward, the EPA’s release of chemical assessments — and its work on the formaldehyde assessment — slowed. “They became completely cowardly,” Jinot said. “They were shell-shocked and retreated.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="63.0">As the EPA went about revising its report, it fell behind others around the world in recognizing that formaldehyde causes cancer. The World Health Organization’s arm that researches cancer had already concluded in 2006 that the chemical is a carcinogen. Five years later, scientists with the Department of Health and Human Services found that formaldehyde causes cancer, citing studies linking it to myeloid leukemia.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="64.0">Between 2011 and 2017, the Foundation for Chemistry Research and Initiatives, which had been created by an industry trade group, funded 20 studies of the chemical. The research presented formaldehyde as relatively innocuous. The industry trade group still <a href="https://www.americanchemistry.com/industry-groups/formaldehyde">disputes the mainstream science</a>, insisting that “the weight of scientific evidence” shows that formaldehyde does not cause myeloid leukemia.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="65.0">The trade group’s panel on formaldehyde also complained that regulation would be devastating for business. The argument was undercut by one of the few limits the EPA did manage to put in place.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="66.0">In 2016, the EPA issued a rule limiting the release of formaldehyde from certain wood products sold in the U.S. Under Trump, the agency did not implement the rule until a <a href="https://earthjustice.org/press/2018/june-1-no-more-formaldehyde-in-wood-products-made-sold-in-u-s">court ordered it to</a> in 2018.</p>
        
    
                    <figure data-pp-id="67" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>The World Health Organization’s arm that researches cancer had already concluded in 2006 that the chemical is a carcinogen.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="68.0">But once the regulation was in effect, many companies complied with it. Necessity bred invention, and furniture and wood products makers found glues and binders with no added formaldehyde.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="69.0">Still, under Trump, the EPA refused to move forward with other efforts that had been underway to tighten regulations of formaldehyde. When he assumed office, the agency was yet again preparing to publish the toxicity report that Jinot had been working on.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="70.0">One of the new Trump appointments to the EPA was David Dunlap, a chemical engineer who, as the director of environmental regulatory affairs for Koch Industries, had tried to persuade the EPA that formaldehyde doesn’t cause leukemia. Koch’s subsidiary, Georgia-Pacific, made formaldehyde and many products that emit it. (Georgia-Pacific has since sold its chemicals business to Bakelite Synthetics.) At the EPA, Dunlap had authority over the division where Jinot and other scientists were working on the toxicity report.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="71.0">Ethics rules require federal employees not to participate in matters affecting former clients for two years. Dunlap complied with the law, recusing himself in 2018 from work on formaldehyde, but only after <a href="https://www.epw.senate.gov/public/index.cfm/2019/3/members-urge-epa-to-complete-formaldehyde-health-assessment-open-investigations-on-compliance-with-agency-s-scientific-integrity-policy-and-political-appointee-s-potential-ethics-violation">taking part in internal agency discussions</a> about its health effects. He signed his recusal paperwork the same day <a href="https://www.politico.com/news/2019/10/17/koch-dunlap-epa-formaldehyde-049060">the EPA killed the toxicity report</a>. Dunlap did not respond to requests for comment.</p>
        
    
                    
<h3>Imperfect Progress, Inevitable Disruption</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="73.0">This August, the Biden EPA finally managed to carry that report across the finish line, getting it reviewed by other agencies and the White House. For the first time, it also set a threshold to protect people from breathing difficulties caused by formaldehyde, such as increased asthma symptoms and reduced lung function.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="74.0">In a draft of another key report on formaldehyde released this year, the EPA found that levels of the chemical were high enough to potentially trigger health problems in dozens of scenarios, including workers using lawn and garden products and consumers who might inhale the chemical as it wafts from cleaners, foam seating and flooring. But the agency is required to address risks only if they are deemed “unreasonable.” For many of those risks, the EPA said it wasn’t certain they were unreasonable.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="75.0">The EPA made the decision after employing a variety of unusual scientific strategies. One involved outdoor air. The EPA first estimated the amount of formaldehyde in the air near some of the country’s biggest polluters. To determine whether those amounts posed an unreasonable risk of harm, the agency compared them to a specific benchmark — the highest concentration of formaldehyde measured by government monitors in outdoor air between 2015 and 2020. EPA records show that peak level was recorded in 2018 in Fontana, California, about 50 miles east of Los Angeles. The EPA concluded the levels near polluting factories would not be unreasonable if they were below this record high, even though local scientists had noted that the Fontana reading didn’t meet their quality control standards, according to documents obtained by ProPublica. Local air quality officials said they didn’t know what caused the temporary spike in the level of formaldehyde near the Fontana monitor.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="76.0">The fact that an air monitor in Fontana once registered a fluke reading that dwarfs the level of formaldehyde in the air near her home is of little comfort to Rocky Rissler.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="77.0">A retired teacher, Rissler shares her home in Weld County, Colorado, with her husband, Rick, two horses, one dog and 12 highland cows; she calls it the “Ain’t Right Ranch” — a name that feels increasingly fitting as the number of oil and gas facilities near her home has ballooned in recent years.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="78.0">The rural area is one of hundreds around the country — many of them in Colorado, New Mexico, North Dakota and West Virginia — where the formaldehyde risk is elevated because of oil and gas production. Gusts of nausea-inducing pollution have become so frequent that Rissler now carries a peppermint spray with her at all times to ease the discomfort. She has frequent headaches, and her asthma has worsened to the point where she’s been hospitalized three times in recent years.</p>
        
    
                    <figure data-pp-id="79" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>During the past four years, no fewer than 75 trade groups have pushed back against the EPA’s findings.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="80.0">Rissler, who is 60 but says she feels “closer to 99,” has also been diagnosed with chronic bronchitis and chronic obstructive pulmonary disease, or COPD — conditions that have been linked to formaldehyde exposure. Just walking up the slight hill from her horse barn to her front door can leave her winded.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="81.0">“It feels like a gorilla is sitting on my chest,” she said. And while she used to jog in her youth, “these days, I’m only running if there’s a bear chasing me.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="82.0">Under Biden, EPA scientists have been sharply divided over how to gauge all the dangers of formaldehyde. Some employees throughout the agency  have been working to strengthen the final health assessment expected later this month. But they are fighting against immense outside pressure.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="83.0">During the past four years, no fewer than 75 trade groups have pushed back against the EPA’s findings. Among them are the Fertilizer Institute, the Golf Course Superintendents Association of America, the Toy Association, the National Chicken Council, the Asphalt Roofing Manufacturers Association, the Independent Lubricant Manufacturers Association, the RV Industry Association, the Halogenated Solvents Industry Alliance and the American Chemistry Council, which represents more than 190 companies and led the charge. Meanwhile, scientists with ties to the industry are pushing the EPA to abandon its own toxicity calculations and use theirs instead — a move that could seriously weaken future limits on the chemical.</p>
        
    
                    <figure data-pp-id="84" data-pp-blocktype="pull-quote">

    <blockquote>
        <p>Despite campaign assurances that he wants <span>“</span>really clean water, really clean air,” Trump is expected to eviscerate dozens of environmental protections, including many that limit pollution in water and air.</p>

    </blockquote>
    
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="85.0">“I’ve seen the industry engage on lots of different risk assessments,” said Tracey Woodruff, a professor and director of the Program on Reproductive Health and the Environment at the University of California, San Francisco. “This one feels next level.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="86.0">An EPA spokesperson wrote in an email that the agency’s draft risk evaluation of formaldehyde was “based purely on the best available science.”</p>

<p data-pp-blocktype="copy" data-pp-id="86.1">The industry’s fortunes have now shifted with Trump’s election.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="87.0">Despite campaign assurances that he wants “<a href="https://www.c-span.org/video/?538809-1/president-trump-campaigns-waunakee-wisconsin">really clean water, really clean air</a>,” Trump is expected to eviscerate dozens of environmental protections, including many that limit pollution in water and air. He will have support from a Republican Congress, where some have long wanted to rewrite environmental laws, including the one regulating chemicals.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="88.0">Trump has already laid out a plan to require federal agencies to cut 10 rules for every one they introduce, a far more aggressive approach than he took during his last time in the White House, when he rolled back <a href="https://www.nytimes.com/interactive/2020/climate/trump-environment-rollbacks-list.html">more than 100 environmental rules</a>. And his transition team has floated the idea of relocating the EPA headquarters, a move that would surely cause massive reductions in staff.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="89.0">According to regulatory experts consulted by ProPublica, the incoming administration could directly interfere with the ongoing review of formaldehyde in several ways. The EPA could simply change its reports on the chemical’s health effects.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="90.0">“They can just say they’re reopening the risk assessment and take another look at it. There may be some legal hurdles to overcome, but they can certainly try,” said Robert Sussman, an attorney who represents environmental groups and served in the EPA under Presidents Bill Clinton and Barack Obama.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="91.0">Project 2025, the conservative playbook organized by the Heritage Foundation, calls for the EPA’s structure and mission to be “greatly circumscribed.” Its chapter on the agency specifically recommends the elimination of the division that evaluated the toxicity of formaldehyde and <a href="https://iris.epa.gov/AtoZ/?list_type=alpha">hundreds of other chemicals</a> over the past three decades. Project 2025 also aims to take away funding for research on the health effects of toxic chemicals and open the EPA to industry-funded science.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="92.0">Trump distanced himself from Project 2025, saying, “I don’t know what the hell it is.” But after the election, some of his surrogates have <a href="https://newrepublic.com/post/188097/steve-bannon-donald-trump-project-2025">openly embraced the document</a>, and Trump picked an architect of the conservative plan to fill a key cabinet post.  </p>

<p data-pp-blocktype="copy" data-pp-id="92.1">Last month, Trump announced he had chosen former U.S. Rep. Lee Zeldin of New York to head the EPA. Zeldin could not be reached for comment, and the Trump transition team did not respond to questions about formaldehyde. In his announcement, Trump said Zeldin would deliver deregulatory decisions “to unleash the power of American businesses.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="93.0">“The election of Trump is a dream for people who want to deregulate all chemicals,” said Woodruff, the University of California, San Francisco, professor. “We are going to continue to see people get sick and die from this chemical.”</p>
        
    
                    
    
    
    <figure data-pp-id="94" data-pp-blocktype="callout" data-pp-location="callout" callout-slug="do-you-work-for-the-federal-government-propublica-wants-to-hear-from-you">

        
<div>
            <p id="do-you-work-for-the-federal-government-propublica-wants-to-hear-from-you">Do You Work for the Federal Government? ProPublica Wants to Hear From You.</p>
                <p>We’re expanding our coverage of government agencies and federal policy. With your help, we can dig deeper.</p>
    </div>


        

        
        <a href="#" data-pp-view="" data-pp-category="get involved" data-pp-action="expand">Expand</a>

    </figure>

    
            
    
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No Nat November: My Month Without IPv4 (201 pts)]]></title>
            <link>https://blog.infected.systems/posts/2024-12-01-no-nat-november/</link>
            <guid>42313507</guid>
            <pubDate>Wed, 04 Dec 2024 01:03:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.infected.systems/posts/2024-12-01-no-nat-november/">https://blog.infected.systems/posts/2024-12-01-no-nat-november/</a>, See on <a href="https://news.ycombinator.com/item?id=42313507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="day-0-challenge-accepted">Day 0: Challenge accepted</h2><p>Near the beginning of November, nixCraft posted this challenge on Mastodon, daring people to take the No NAT November challenge and disable IPv4 for the month, relying only on IPv6:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/ChallengeAccepted.png" alt="nixCraft’s No NAT November challenge post on Mastodon"></figure><p>With the challenge laid out like that, I couldn’t resist.</p><h2 id="conclusions">Conclusions</h2><p>I know this is quite a long and technical post, so I figured it makes sense to put a conclusion about my experience near the beginning.</p><p>So, after a month, what do I think? Do I recommend that you go and disable IPv4 in your home network and go IPv6-only?</p><p>Well no. Not quite yet.</p><p>But you absolutely should go IPv6-<em>mostly</em>. Which is something we’ll get into in quite some depth as this post goes on. It’s really a win-win, and I’ll be deploying all my networks as IPv6-mostly from now onwards.</p><h2 id="why-try-this">Why try this?</h2><p>In this post, I don’t really want to get into the detail of why IPv6 is an improvement over IPv4. The initial RFC was ratified in 1998 and there’s been over 2 decades of content generated about the benefits it brings since then. IPv6 is the current version of the IP protocol and IPv4 is legacy. I consider that a settled matter.</p><p>The key point here is that the ‘default’ IPv6 capable end-user network is a dual stack network (i.e. one which deploys IPv4 alongside IPv6). This might work nice and transparently from the perspective of end-users, but running two separate network stacks with different addressing scheme and configuration alongside each other means we’ve now got 2x as many things to consider and 2x as much admin and maintenance work to do.</p><p>I know some network administrators use this increased maintenance burden as a reason to justify not having to learn or deploy IPv6 in the first place, but what if we used it as a reason to disable IPv4 instead?</p><p>And since there’s no faster way to learn the downsides of something than simply just doing it, so began my journey of spending November on a single-stack IPv6-only network.</p><h2 id="scope">Scope</h2><p>So throughout the month of November, I decided that I would disable IPv4 connectivity on my main home network and see what broke, and whether there were any steps I could take to work around the breakage or fix it.</p><p>Throughout the process, I wanted to follow an iterative approach. I would first take the network back to pure IPv6-only, without even any transitional technologies in place. And then I would add in the transitional technologies until I determined whether I could live without IPv4 connectivity long-term.</p><p>Please note that throughout this post I’m really <strong>only focusing on the challenges of going IPv6-only from a home networking standpoint</strong>, rather than anything at an enterprise or carrier level. Though you may be interested to note from the enterprise standpoint that <a href="https://labs.ripe.net/author/mirjam/ipv6-only-at-microsoft/">Microsoft were transitioning their corporate network to be IPv6-only as early as 2017</a>. And from the carrier standpoint, Sky appear to be <a href="https://www.ipv6.org.uk/wp-content/uploads/2024/10/02_Sky-UK-MAP-T-UK-IPv6-Council-Nov2024.pdf">actively working on IPv6-only deployments for their UK home broadband customers</a>.</p><h2 id="day-1-pure-ipv6-only-without-transitional-tech">Day 1: Pure IPv6-only (without transitional tech)</h2><p>For this first stage, I simulated going IPv6-only by disabling the DHCPv4 server on my router.</p><p>So… what broke?</p><p>Well - unfortunately quite a lot. Including some real showstoppers.</p><h3 id="desktop-os-support">Desktop OS support</h3><p>At a platform level, every desktop operating system I tried offered seamless support for operating on an IPv6-only network. I was a little surprised actually, since when I’ve tried this in the past, I’ve seen operating systems report a lack of IPv4 as if the network was suffering problems or was unconnectable.</p><p>I was pleasantly surprised to see all my devices, across macOS Sequoia, Win 11, Ubuntu 24.04, and Fedora 41 seamlessly accepting without any protest that my network had no IPv4 connectivity, all dutifully setting up the connection with single-stack IPv6.</p><h3 id="mobile-os-support">Mobile OS support</h3><p>The only devices I have in this category are iOS devices and they handled the situation similarly flawlessly.</p><h3 id="embedded-device-support">Embedded device support</h3><p>Things aren’t quite so rosy on the embedded front unfortunately.</p><p>I tried a Nintendo Switch and it completely refused to connect to the network without a working IPv4 stack:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/MoreLikeNintendont.jpg" alt="Screenshot of Nintendo Switch screen, failing to connect to the network"></figure><p>That didn’t surprise me hugely, as Nintendo have historically lagged behind a bit in terms of networking capabilities, but what did disappoint me quite a bit was the way the Steam Deck behaves.</p><p>As a Linux-based device with a recent kernel and a full desktop environment available, I had quite hoped the Steam Deck would act much like my other desktop devices. Unfortunately it’s even more frustrating than the Switch, because it actually does set up a full IPv6 stack - and even shows the IP in the network connection settings menu - but overall it seems to decide that the lack of IPv4 connectivity means the network isn’t working. It just gets stuck ‘Connecting’ for a while, before eventually failing altogether:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/DeckDisappointment.jpg" alt="Screenshot of a Steam Deck network settings page, showing it having retrieved an IPv6 address but still failing to connect"></figure><p>Surprisingly, the Deck reacted the same way in desktop mode. Having partially-working network support also seemed to cause the Steam Deck to get very confused when shutting down in either mode, causing it to hang for a long time on the shutdown screen. All of which was a touch disappointing.</p><p>Having exhausted my collection of current-gen consoles, the other obvious problem I encountered right away is that despite being able to route IPv6 traffic without any concerns, all of my home networking gear seems to be IPv4-only when it comes to management interfaces.</p><p>Most of my network is made up of TP-Link access points <a href="https://www.tp-link.com/uk/business-networking/ceiling-mount-ap/eap245/">like this one</a> and their cheap VLAN-capable switches <a href="https://www.tp-link.com/us/business-networking/easy-smart-switch/tl-sg116e/">like this one</a>. Generally I wouldn’t hesitate to recommend these to anyone, as they’re very cost-effective VLAN-aware pieces of equipment that are great for a home environment.</p><p>Unfortunately, as seems to be a common theme with home networking gear, the management interface configurability is a bit lacking and restricted to IPv4 only:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/v4OnlySwitchMGMT.png" alt="TP-Link switch interface showing the ability to only configure the switch for IPv4 and not IPv6"></figure><p>This isn’t particularly a huge problem since I put these management interfaces on a dedicated network anyway for security reasons. But it’s one that I thought would be useful to call out, since it might affect you if you’re trying to opt for a simpler network design. Being unable to manage any of your switches or access points once you remove the IPv4 addresses from your clients could be a real pain.</p><h3 id="web-service-support">Web service support</h3><p>Well… this is where things really fall down.</p><p>I’m certainly not the biggest fan of the increasing centralisation of the web behind a number of large cloud/CDN providers, but one of the things it has brought us is easy IPv6 ‘for the masses’. I do think the relative ease of adoption of IPv6 within the interfaces of providers like Cloudflare has led to a huge increase in the overall reachability of the web over IPv6.</p><p>Unfortunately, there’s still some surprising holdouts. GitHub quite infamously still haven’t deployed IPv6. And neither have Reddit, Discord, or Steam. On my pure IPv6 connection these sites simply don’t load and plenty of others don’t either.</p><p>You can get to a <em>lot</em> of the internet over pure IPv6 these days. But all it really takes is for an end user to rely on anything in the list above, and the idea of using a pure IPv6 connection is dead on arrival.</p><h2 id="day-2-about-those-ipv6-transition-technologies">Day 2: About those IPv6 transition technologies</h2><p>So it was clear pretty immediately at this point in the challenge that I wasn’t going to be able to continue without deploying some level of transitional technology that would allow me to continue to access the services which only operate over IPv4.</p><p>Luckily, now with zero working game consoles, I had plenty of free time to investigate.</p><h3 id="464xlat">464XLAT</h3><p>The primary transitional technology that’s going to be relevant for home users is going to be 464XLAT. As far as I can tell, 464XLAT is a combination of a number of different concepts which often get referenced interchangeably, such as NAT64 and DNS64. I’ll do my best to explain them here.</p><h3 id="nat64-with-dns64">NAT64 with DNS64</h3><p>Broadly, DNS64 works like this:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/Mermaid1.png" alt="Diagram showing the flow of DNS64"></figure><p>What’s happening here is that our IPv6 device makes DNS requests as normal, but to a DNS server which is running in DNS64 mode. This is effectively a normal DNS server speaking the regular DNS protocol, but when in this mode, the server will detect when a domain has only A records and no AAAA records, and will synthesise ‘fake’ AAAA records for sites in this category.</p><p>The synthetic AAAA records sent back by the DNS64 server make use of the fact that the entire IPv4 internet can fit into an IPv6 block which is only <code>/96</code> wide. So they’re comprised of a prefix, which points to a NAT64 Gateway (also called a PLAT), and a suffix, which is just an encoded version of the IPv4 address.</p><p>For example, on my current host <code>github.com</code> resolves to:</p><pre tabindex="0"><code>64:ff9b::141a:9cd7
</code></pre><p>Where <code>64:ff9b::</code> is the well-known prefix used by many NAT64 implementations, and <code>141a:9cd7</code> is simply an encoded version of the A record that <code>github.com</code> was returning for me (<code>20.26.156.215</code>).</p><p>As a random note - If you’re interested in decoding a NAT64 mapped address back to the IPv4 literal address it represents, there’s a <a href="https://www.whatsmydns.net/ipv6-to-ipv4?q=%3A%3Affff%3A141a%3A9cd7">useful tool here</a> that can do it if you replace the NAT64 prefix with <code>::ffff:</code>. I’ll leave the details of why that works for another day, and there’s probably many other ways of doing this, but this has been useful to me in the past.</p><p>Once we have our encoded AAAA records in our DNS response, our client can act as normal, sending packets to the IPv6 addresses as if they were official AAAA records served by the site itself. Those packets will be routed to the NAT64 gateway which will listen for packets targeting the entire NAT64 prefix (in our case, the whole of <code>64:ff9b::/96</code>). When it receives a packet like this, it will use the encoded suffix to decode the IPv4 address the packet is intended for, and will forward it accordingly to the site over IPv4.</p><p>Through this process, we’re able to get rid of any requirement for IPv4 connectivity anywhere prior to the NAT64 gateway. In terms of our challenge, this allows us to stay IPv4 free on our LAN entirely, and delegate all remaining IPv4 requirements to our NAT64 gateway.</p><h3 id="wait-nat64-isnt-that-cheating">Wait, NAT64? Isn’t that cheating?</h3><p>At this point, a few of you have probably already objected on the basis that this post is titled ‘No NAT November’ and I’m busy describing deploying something called <strong>NAT</strong>64 on only the second day of the challenge.</p><p>I guess that’s a fair complaint, but NAT64 has some useful qualities that set it apart from standard private-IPv4-inside-public-IPv4-outside type home networks (more commonly called NAT44).</p><p>The main difference here is that we don’t have to host the gateway within our own network. Unlike using NAT44 where the internal IP ranges are usually going to be RFC 1918 private addresses that we can’t route over the internet, our IPv6 addresses are globally publicly routable. Which means, in theory, anyone anywhere can host our NAT64 gateway for us.</p><p>In my case, I have a very forward-thinking ISP (shoutout to <em>Andrews &amp; Arnold</em> in the UK), and <a href="https://support.aa.net.uk/Server_List">they host a NAT64 gateway for customers to use, along with DNS64 servers</a>. So since all of the burden of doing NAT exists completely outside my network, I’m considering this within the spirit of nixCraft’s challenge. If you disagree, please do argue as much as possible about it. It boosts engagement.</p><p>For those without such forward-thinking ISPs, there are also <a href="https://nat64.net/public-providers">public-facing NAT64 and DNS64 providers</a> that you can use. Being in security I can’t exactly in good conscience recommend sending all your traffic thorough an un-vetted third party. But they do exist, so I figured I should mention them.</p><p>It is also entirely possible to host your own NAT64 gateway, either on your regular firewall/gateway, or on a host elsewhere within your network. This host will need IPv4 connectivity to forward on the packets, and there is a fair learning curve to setting one of these up, but <em>apalrd’s adventures</em> on YouTube <a href="https://www.youtube.com/watch?v=WZSdpY_VgyY">has a great guide to doing this on OPNsense</a>.</p><h3 id="nat64-with-clat">NAT64 with CLAT</h3><p>NAT64 using DNS64 gets us most of the way to having a much happier experience running an IPv6-only LAN. But it doesn’t quite get us all the way.</p><p>Since DNS64 is based around, well… DNS, it can’t help us in situations where we have an app or tool that wants to connect to IPv4 literals (i.e. hard-coded IPv4 addresses without using DNS).</p><p>To solve this problem, we can use a CLAT.</p><p>A CLAT is an extra layer that an IPv6-only device can implement which will allow it to translate IPv4 packets to IPv6 packets on the fly. This is done using much the same mechanism as DNS64. The packets get rewritten into IPv6 packets with a prefix matching the NAT64 gateway address, and with a suffix matching the encoded IPv4 address of the destination host.</p><p><a href="https://www.rfc-editor.org/rfc/rfc6877">The RFCs</a> suggest that CLAT stands for <em>Customer-side Translator</em> but that doesn’t seem to fit so well, so I prefer to read it as ‘Client-Layer Address Translator’ as it keeps it straight in my own head where in the flow the translation is actually happening.</p><p>The way this works is that a compatible host will set up the local IPv4 stack of the device to use a ‘fake’ gateway and client IP. Here’s an example of what this looks like on iOS:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/iOSCLAT.jpg" alt="A screenshot of iOS’s network settings showing an active CLAT"></figure><p>What’s going on here is that the ‘Router’ represents the fake CLAT gateway, which exists within the device itself. And the ‘IP Address’ represents the fake endpoint IP that the device has assigned itself.</p><p>This allows the device to act like it has a fully normal and functional IPv4 stack, while transparently translating packets in the background to be able to handle an IPv6-only transit layer.</p><p>That looks like this and, as you can see, the end result is that we only have IPv6 packets leaving and returning to the device, allowing us to operate quite happily on an IPv6-only network segment:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/Mermaid2.png" alt="Diagram showing how NAT64 works with a CLAT on the client device"></figure><p>This allows us to effectively deal with applications and other tooling which might expect or require the ability to be able to communicate with hard-coded IPv4 literals.</p><p>When using only DNS64, our clients don’t really need a way of learning the NAT64 prefix they should be using, because it’ll be transparently included in the AAAA responses sent back by the DNS64 server. But now that we’ve moved into using a CLAT, we’re no longer using DNS to look up addresses before connecting to them. So we need a mechanism for our client to learn the prefix that should be prepended to NAT64 packets before sending them out.</p><p>There’s a few of these, but the two main ones seem to be:</p><ul><li><a href="https://www.rfc-editor.org/rfc/rfc7050">RFC 7050</a> - Which allows a client to discover it from a DNS64 server by looking up the special domain <code>ipv4only.arpa</code>.</li><li><a href="https://www.rfc-editor.org/rfc/rfc8781">RFC 8781</a> - aka PREF64, which allows it to be served to clients on an IPv6 network through Router Advertisements.</li></ul><p>Happily, all DNS64 servers I’ve encountered implement RFC 7050 which means realistically if you’re using an operating system that fully supports setting up a CLAT, there’s probably no extra work for you to do here if you’ve also got DNS64 enabled.</p><h3 id="os-level-clat-support">OS-level CLAT support</h3><p>With that in mind, it’s time to talk OS support for using a CLAT.</p><p>A CLAT is a complex piece of network engineering which needs to be fairly deeply integrated into the host OS to work <em>well</em>, so it requires a fairly forward-thinking implementation on the part of the vendor.</p><h4 id="apple">Apple</h4><p>I’m not the world’s biggest Apple fan, but honestly their implementation here is the gold standard. 10/10, no notes. All their devices support automatically setting up a CLAT in a way that’s transparent to the end-user and they can discover the prefix using either RFC 7050 or 8781. Apple even make this work on the devices where you’d normally expect a vendor to pay less attention, such as the Apple TV and on the HomePod.</p><p>Once I deployed my NAT64+DNS64 support, all my Apple devices seamlessly configured CLAT interfaces and worked out of the box with no config required. Right away I can do things like <code>ping 1.1.1.1</code> without even thinking, despite the complete lack of IPv4 on the network segment the devices are on.</p><h4 id="microsoft">Microsoft</h4><p>Sadly, the same cannot be said about Windows. Although as of March 2024, <a href="https://techcommunity.microsoft.com/blog/networkingblog/windows-11-plans-to-expand-clat-support/4078173">Microsoft have committed to bring CLAT support to Windows 11</a>, which is great news. Unfortunately, as of Win 11 24H2, it still hasn’t landed yet so we may be waiting a bit longer.</p><h4 id="linux">Linux</h4><p>In the CLAT space, Linux is… interesting. <a href="https://github.com/toreanderson/clatd">clatd</a> exists and does see some maintenance, though the only distributions that seem to package it are <a href="https://pkgs.org/search/?q=clatd">Fedora and openSUSE</a>, and neither ship it by default.</p><p>I’ve had mixed results using <code>clatd</code>. It’s a touch finnicky and seems to get a bit confused when carrying out very regular tasks, such as switching between ethernet and Wi-Fi when docking/undocking a laptop.</p><p>I’d like to see something emerge for Linux which is a bit more embedded into the core of the OS and functions a bit more smoothly, like Apple’s implementation. There’s been an issue open on <a href="https://github.com/systemd/systemd/issues/23674">systemd’s GitHub</a> for a couple of years now asking for something like this. Who knows, maybe we’ll see <code>systemd-clatd</code> eventually.</p><h2 id="day-3-to-30-ipv6-only-with-transitional-tech">Day 3 to 30: IPv6-only (with transitional tech)</h2><p>So by Day 3, I still have my IPv6-only network deployed, and I also have NAT64+DNS64 along with CLATs on devices which support them.</p><p>At this point, things are far more functional than they were on Day 1. DNS64 is really taking care of almost everything on my Windows and Linux hosts, and on my Apple hosts the CLAT is getting me the rest of the way.</p><p>There’s still a few things annoyingly broken though, but now that the transitional tech has been deployed, they all revolve around the apps that insist on using IPv4 literals.</p><p>A selection of things that I’ve discovered are still broken on an IPv6 only network with NAT64+DNS64:</p><table><thead><tr><th>Thing</th><th>Why it’s still broken</th></tr></thead><tbody><tr><td>Steam</td><td>Client relies on IPv4 literals. Broken without a CLAT.</td></tr><tr><td>Discord WebRTC</td><td>Seems to rely on IPv4 literals for setting up calls. Broken without a CLAT.</td></tr><tr><td>Network device WebUIs</td><td>I can’t really fix this one. They simply don’t support IPv6 on their WebUIs.</td></tr><tr><td>Steam Deck</td><td>Annoyingly broken despite successfully assigning itself an IPv6 address. But I doubt it would work anyway given the Steam client is broken as above.</td></tr><tr><td>Nintendo Switch</td><td>Doesn’t seem to connect at all if IPv4 is not available.</td></tr></tbody></table><p>What you’ll notice from the above is that it really isn’t a particularly long list. It’s based on my own workloads so no doubt if you try this you’ll find a great number of other things that don’t work and are a dealbreaker for your own personal workflow.</p><p>But it’s quite striking that we’re a long long way from the “everything is broken” territory people might instinctively expect when they think about the fallout of disabling IPv4, even when considering systems without a functioning CLAT.</p><p>Once we put it all together, we now have a network that consists of:</p><ul><li>A NAT64 gateway (whether hosted by our ISP, or elsewhere);</li><li>A DNS64 server (whether hosted by our ISP, or elsewhere);</li><li>IPv6-only clients using DNS64 to direct <em>most</em> of their legacy IPv4 traffic via the NAT64 gateway, getting them 99% of the way; and</li><li>IPv6-only clients <strong>that also support a CLAT</strong> directing <em>all</em> of their legacy IPv4 traffic via the NAT64 gateway, getting them the remaining 1% of the way.</li></ul><p>But for the devices that don’t work at all, or which don’t support a CLAT, we’re still left in one of a few non-ideal situations:</p><ul><li>Waiting for our OS vendor to implement a CLAT;</li><li>Begging our device vendor to not treat IPv6-only networks as ‘broken’; or</li><li>Complaining about individual apps using IPv4 literals <a href="https://github.com/ValveSoftware/steam-for-linux/issues/3372">on GitHub issues which are sometimes over 10 years old</a>.</li></ul><p>None of these are particularly great options. But there is an alternative.</p><p>As of 2020, there’s a shining fix to our predicament available, in the form of IPv6-<em>mostly</em>. In order to understand where IPv6-mostly comes from, I can’t avoid relaying the wonderful story of its inception, even though I know this post is already far too long.</p><h2 id="how-to-manage-the-unmanaged-orchestration-by-rfc">How to manage the unmanaged: orchestration by RFC</h2><p>How would you deal with deploying OS-level config to a fleet of devices?</p><p>Some form of config management, you presumably reply. Ansible? Puppet? Salt? Chef? They’re all good choices… when you have control over the devices you want to manage with them.</p><p>But what if you have a fleet of BYOD employee-owned devices. Devices which are all running a disparate selection of operating systems, versions, and technologies? How do you effectively… manage the unmanaged?</p><p>This was the problem faced by Jen Linkova, a Network Engineer at Google, when attempting to disable IPv4 on a fleet of unmanaged devices as part of their corporate network IPv6 transition.</p><p>The answer, it turns out, is a stroke of genius.</p><p>You simply:</p><ul><li>Author a bunch of IETF RFCs that define a standard for using DHCPv4 messages to reconfigure willing hosts to switch into IPv6-only mode;</li><li>Get those RFCs ratified;</li><li>Get support to send these messages landed in all the major DHCPv4 servers;</li><li>Get the functionality to deal with these messages landed in all the major OSes;</li><li>Enjoy your new-found configuration powers over the devices on your network.</li></ul><p>Move over orchestration by Ansible Playbook. We have orchestration by RFC now.</p><p>Jen lays all this out in their presentation titled <a href="https://www.youtube.com/watch?v=UTRsi6mbAWM">Mission <del>Im</del>Possible - Turning IPv4 Off in an Enterprise Network</a> which is extremely entertaining and well worth a watch!</p><p>Jen and team are responsible for a number of relevant RFCs in this space, but the one that’s most interesting to us right now is <a href="https://www.rfc-editor.org/rfc/rfc8925.html">RFC 8925</a> which describes the new DHCPv4 “Option 108”, aka “IPv6-Only Preferred”.</p><h2 id="dhcpv4-option-108-ipv6-only-preferred">DHCPv4 Option 108: IPv6-Only Preferred</h2><p>At its core, this is a deceptively simple concept. The idea is that you continue to deploy your network dual-stack with both IPv4 and IPv6 support as before, but you instruct clients which are capable of operating in an IPv6-only mode to switch into an IPv6-only mode.</p><p>IPv6-Only Preferred generally relies on having IPv6 transition technologies in place so that when the client switches into IPv6-only mode, it is not cut off from the IPv4 internet entirely. But that’s not a strict requirement. You <em>could</em> enable this on a network without any NAT64 access at all. But you probably don’t want to, so bear that in mind.</p><p>Clients which support operating in IPv6-only mode and see a DHCPv4 server sending Option 108 will dutifully switch into that mode and avoid taking an IPv4 address from the DHCPv4 server, while clients that are incapable of operating in IPv6-only mode will set themselves up as dual-stack clients just as they would have done previously. Clients which are too old to even understand the option will simply ignore it and carry on taking an IPv4 address as they always have.</p><p>With this, we create what’s called an IPv6-<em>mostly</em> network. Effectively the technological equivalent of having our cake and eating it. In this configuration, the network is dual-stacked, but clients will only take an IPv4 address if they <em>need</em> one. This allows us to watch our DHCPv4 lease table tick down in size until the day finally comes when we can disable IPv4 entirely.</p><h2 id="ipv6-mostly---your-road-to-eventual-single-stack-success">IPv6-mostly - your road to (eventual) single-stack-success</h2><p>IPv6-mostly networks really end up being the best of all worlds. I would revisit the table from the prior section and compare an IPv6-only+464XLAT setup with an IPv6-mostly setup, but the truth of the matter is that on IPv6-mostly I haven’t experienced anything that breaks at all.</p><p><em>It just works</em>.</p><p>All my IPv6-only supporting devices like those in Apple’s ecosystem seamlessly operate in IPv6-only mode, and the others that still require IPv4 addresses operate dual-stack. I fully expect that when Microsoft deploys CLAT support for Windows 11, my Windows machines will start respecting Op108 and stop taking IPv4 addresses from my pool since they won’t need them anymore.</p><p>With IPv6-mostly, we can build a clear pathway to transition all the way from an IPv4-only to an IPv6-only network, with a smooth transitional phase in the middle:</p><figure><img src="https://blog.infected.systems/posts/2024-12-01-no-nat-november/Mermaid3.png" alt="Flow diagram showing a pathway from IPv4-only networking to IPv6-only with a transitional IPv6-mostly phase in the middle"></figure><h2 id="potential-follow-ups">Potential follow-ups</h2><p>In this post, I’ve focused quite specifically on home networks, and on desktop/mobile devices. That was pretty necessary to avoid the post becoming even longer than it already was. There’s a lot to be said in the server space for this too. Broadly, I found that applications deployed directly onto IPv6-only servers suffer largely the same pitfalls and successes as the desktop ones listed above.</p><p>The one big caveat there is that containerisation and virtualisation technologies seem to all handle this situation in quirky and interesting ways. That could (and probably will) justify a post in itself at some point in the future. Docker, Podman, WSL, QEMU - your mileage may certainly vary when trying any of the above on an IPv6-only network. If you do try it, I’d be interested to see what your conclusions and experiences are.</p><p>As part of this experimentation, I ended up deploying a full OpenBSD home router setup to create an IPv6-mostly network which implements all of the relevant RFCs (including NAT64, DNS64, PREF64 and Op108). I noticed while putting the config together that a lot of OpenBSD router config guides online focus very heavily on IPv4 networking and leave out most, if not all, of this kind of functionality. At some point I’ll pull it all together and publish it as a guide as it might be useful to the community at large.</p><h2 id="day-30-conclusions-and-recommendations-for-the-future">Day 30+: Conclusions and recommendations for the future</h2><p>Considering everything from my experience so far, I’ve come away with a few general recommendations:</p><ul><li>You should deploy IPv6 if your ISP supports it and you haven’t bothered yet;</li><li>You should deploy IPv6-<em>mostly</em> if you’re adventurous and you have access to a NAT64 gateway or you can host one yourself;</li><li>You should deploy IPv6-<em>only</em> if you’re involved in developing software or devices that rely on networking. You’ll probably learn a <em>lot</em> from how your apps and devices react, and you might be inspired to fix it. I’ll buy you a beer if you do.</li></ul><p>Speaking of learning, I learned a lot from this wild ride as always. I did end up surviving the month without re-enabling IPv4 on my LAN, but I decided that all future networks I deploy will be of the IPv6-mostly variety.</p><p>One day, I will absent-mindedly log into my router and check my DHCPv4 lease table. And there will be no entries. All my devices will behave as they should, using IPv6 and avoiding taking an IPv4 lease at all. On that day I’ll be able to head over to my networking config and remove IPv4 entirely. Perhaps I’m dreaming, but having delved into transitional technologies through this project, it really does seem plausible that day might come in the next few years. That will be a good day.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phoenix LiveView 1.0.0 is here (701 pts)]]></title>
            <link>https://www.phoenixframework.org/blog/phoenix-liveview-1.0-released?release=1.0</link>
            <guid>42312301</guid>
            <pubDate>Tue, 03 Dec 2024 22:28:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoenixframework.org/blog/phoenix-liveview-1.0-released?release=1.0">https://www.phoenixframework.org/blog/phoenix-liveview-1.0-released?release=1.0</a>, See on <a href="https://news.ycombinator.com/item?id=42312301">Hacker News</a></p>
Couldn't get https://www.phoenixframework.org/blog/phoenix-liveview-1.0-released?release=1.0: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A new home for Python-build-standalone (112 pts)]]></title>
            <link>https://astral.sh/blog/python-build-standalone</link>
            <guid>42312277</guid>
            <pubDate>Tue, 03 Dec 2024 22:26:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astral.sh/blog/python-build-standalone">https://astral.sh/blog/python-build-standalone</a>, See on <a href="https://news.ycombinator.com/item?id=42312277">Hacker News</a></p>
Couldn't get https://astral.sh/blog/python-build-standalone: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My son (9 yrs old) used plain JavaScript to make a game, and wants your feedback (832 pts)]]></title>
            <link>https://www.armaansahni.com/game/</link>
            <guid>42312121</guid>
            <pubDate>Tue, 03 Dec 2024 22:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.armaansahni.com/game/">https://www.armaansahni.com/game/</a>, See on <a href="https://news.ycombinator.com/item?id=42312121">Hacker News</a></p>
Couldn't get https://www.armaansahni.com/game/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Porsche Macan EV is being recalled because its headlights are too bright (126 pts)]]></title>
            <link>https://insideevs.com/news/742893/porsche-macan-electric-ev-recall-headlights/</link>
            <guid>42311912</guid>
            <pubDate>Tue, 03 Dec 2024 21:47:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insideevs.com/news/742893/porsche-macan-electric-ev-recall-headlights/">https://insideevs.com/news/742893/porsche-macan-electric-ev-recall-headlights/</a>, See on <a href="https://news.ycombinator.com/item?id=42311912">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                            
                    <ul>
<li>Porsche is recalling certain Macan Electric models in the United States.</li>
<li>The issue lies with the headlamps, which may be too bright.</li>
<li>A visit to a Porsche service center will be necessary to fix the problem.</li>
</ul>
<hr>
<p>The electric <a href="https://insideevs.com/porsche/macan/" data-inline-widget="internal-links">Porsche Macan</a> has been on sale in the United States for two months, and now there’s already a recall with its name on it. Thankfully, there’s no need for spare parts and it’s not the kind of recall that deals with <a href="https://insideevs.com/news/723427/tesla-cybertruck-wiper-recall-june/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22723427%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22tesla-cybertruck-wiper-recall-june%22%7D">flapping body panels</a>.</p>
<p>However, despite this being a software-related problem, owners will still need to go to a <a href="https://insideevs.com/porsche/" data-inline-widget="internal-links">Porsche</a> service center to get it sorted out. That’s because the headlights are too bright and the headlight control unit software will need to be reprogrammed to comply with federal regulation. And that can't be done via an over-the-air update.</p>
<p>As per the <a href="https://www.nhtsa.gov/?nhtsaId=24V889000" target="_blank" rel="noopener">National Highway Traffic Safety Administration</a> (NHTSA), the upper beams on certain Macan Electric models aren’t calibrated properly and may shine too bright, which could reduce visibility for incoming drivers and thus increase the risk of a crash. Due to a software data set error, the affected vehicles were programmed from the factory after the Economic Commission for Europe (ECE) specs, whereas U.S.-spec vehicles need to conform to the requirements of the Federal Motor Vehicle Safety Standard (FMVSS).</p>
<section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22741586%22%2C%22title%22%3A%222025%20Porsche%20Taycan%20GTS%20First%20Drive%3A%20An%20EV%20That's%20Maybe%20Too%20Fast%22%2C%22alias%22%3A%222025-porsche-taycan-gts-first-drive%22%2C%22section%22%3A%222%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2F1ZEqGp%2Fs5%2F2025-porsche-taycan-gts-first-drive.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22740686%22%2C%22title%22%3A%22The%20Porsche%20Taycan%20Gets%20Three%20New%20Models%20For%202025%22%2C%22alias%22%3A%22porsche-taycan-updates-2025%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FmM3eoA%2Fs5%2F2025-porsche-taycan-gts.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22740461%22%2C%22title%22%3A%22The%20Porsche%20Macan%20Turbo%20EV%20Beat%20Its%20EPA%20Range%20In%2070%20MPH%20Test%22%2C%22alias%22%3A%22porsche-macan-highway-range-test%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FqklLbG%2Fs5%2Fmacan-ev.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22739163%22%2C%22title%22%3A%222025%20Porsche%20Taycan%2070-MPH%20Range%20Test%3A%20Way%20Better%20Than%20Advertised%22%2C%22alias%22%3A%222025-porsche-taycan-base-range-test%22%2C%22section%22%3A%222%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FjlwN01%2Fs5%2Fporsche-taycan-range-test.jpg%22%7D%7D%5D%7D"> <p>More Porsche Stuff</p>  </section>
            <p>
            <h2>
                Gallery: 2024 Porsche Macan            </h2>
        </p>
    

<p>In total, 2,941 Porsche Macan Electric built between March 15, 2024, and November 4, 2024, are affected by the recall. Cars assembled after November 18 were shipped with the correct headlight software that complies with FMVSS No. 108.</p>
<p>The fix for the affected EVs is free of charge. Porsche will notify dealers on December 11, while owners will be notified on January 24, 2025.&nbsp;</p>
<p>The Porsche Macan Electric is sold alongside the gas-powered model in the United States. In Europe, however, the combustion-powered version <a href="https://www.motor1.com/news/706105/porsche-continuing-gas-macan-sales/" target="_blank" rel="noopener">has been retired due to new cybersecurity regulations</a> and not because of tightening emissions regulations.</p>
<p>Stateside, the most affordable Macan Electric starts at $75,300, but in traditional Porsche fashion, <a href="https://insideevs.com/news/735840/porsche-macan-deliveries-price/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22735840%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22porsche-macan-deliveries-price%22%7D">one could double the price tag</a> relatively easily by going down the (very) long options list.</p>
                    <!-- new gallery place, attached gallery -->
                                        
                                                                
                                            

                                            

                                                    
                                                
                        
                        
                                                    
                            
                        
                        
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Egoless Engineering (721 pts)]]></title>
            <link>https://egoless.engineering</link>
            <guid>42311069</guid>
            <pubDate>Tue, 03 Dec 2024 20:38:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://egoless.engineering">https://egoless.engineering</a>, See on <a href="https://news.ycombinator.com/item?id=42311069">Hacker News</a></p>
Couldn't get https://egoless.engineering: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My C compiler compiled itself (244 pts)]]></title>
            <link>https://github.com/keyvank/30cc</link>
            <guid>42311031</guid>
            <pubDate>Tue, 03 Dec 2024 20:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/keyvank/30cc">https://github.com/keyvank/30cc</a>, See on <a href="https://news.ycombinator.com/item?id=42311031">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">30 C Compiler!</h2><a id="user-content-30-c-compiler" aria-label="Permalink: 30 C Compiler!" href="#30-c-compiler"></a></p>
<p dir="auto"><code>30cc</code> (Pronounced as <em>CCC</em>, because in the Persian language, the number 30 is pronounced as C) is a toy C compiler written in C, which is strong enough to compile itself 🤝 This was my first attempt in writing a self-hosting software! What is a self-hosting software?</p>
<ul dir="auto">
<li>Imagine <code>30cc</code> gets strong enough to be able to compile itself.</li>
<li>I will first compile <code>30cc</code> with <code>gcc</code> to get the <code>30cc</code> compiler's binary.</li>
<li>I will then use the <code>gcc</code>-generated <code>30cc</code> binary file to compile the <code>30cc</code> again.</li>
<li>I now have a <code>30cc</code>-compiled version of <code>30cc</code>, which I can use for further developing the compiler!</li>
<li>I can forget about <code>gcc</code>, as if it never existed! Beautiful hah? <code>30cc</code> is now all alive by itself!</li>
</ul>
<p dir="auto"><code>30cc</code> emits x86-64 assembly as its output. The outputs are totally unoptimized, but that's fine, the project aims to be educational.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ul dir="auto">
<li>You'll first need to bootstrap the compiler by running <code>make</code>. This will compile the 30cc compiler and store its binary in <code>a.out</code>.</li>
<li>Then run <code>./build.py</code>. This will use the bootstrapped 30cc-compiler to compile 30cc itself. It then again uses the 30cc-compiled compiler to compile 30cc once again. The final compiler is then stored as <code>./30cc</code>.</li>
<li>In the end, you will have 3 binary files which should all behave the same:
<ol dir="auto">
<li><code>a.out</code> which is the bootstrapped gcc-compiled version of 30cc</li>
<li><code>30cc_gcc</code> which is the output of gcc-compiled 30cc compiler, compiling the 30cc compiler</li>
<li><code>30cc</code> which is the output of 30cc-compiled 30cc compiler, compiling the 30cc compiler</li>
</ol>
</li>
</ul>
<p dir="auto">Running independent source-files through <code>make</code>:</p>
<div data-snippet-clipboard-copy-content="make run program=./examples/inp.c arguments=something"><pre><code>make run program=./examples/inp.c arguments=something
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribute</h2><a id="user-content-contribute" aria-label="Permalink: Contribute" href="#contribute"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tests</h3><a id="user-content-tests" aria-label="Permalink: Tests" href="#tests"></a></p>
<p dir="auto">To run tests use</p>
<div data-snippet-clipboard-copy-content="python scripts/test.py update"><pre><code>python scripts/test.py update
</code></pre></div>
<p dir="auto">Then check the output of the tests.</p>
<p dir="auto">If you are on mac use <code>./scripts/test_mac.sh</code> to run the tests in docker.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>