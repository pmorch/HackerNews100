<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 10 Aug 2025 16:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Engineering.fyi – Search across tech engineering blogs in one place (110 pts)]]></title>
            <link>https://engineering.fyi/</link>
            <guid>44855157</guid>
            <pubDate>Sun, 10 Aug 2025 13:44:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fyi/">https://engineering.fyi/</a>, See on <a href="https://news.ycombinator.com/item?id=44855157">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-slot="card"><p>How Airbnb upgrades tens of thousands of pods on dozens of Kubernetes clusters to new Istio versions</p></div><div data-slot="card"><p>MCP UI extends the Model Context Protocol to enable AI agents to return fully interactive UI components. It solves the critical challenge that commerce experiences require visual and interactive elements like product selectors, image galleries, and cart flows. This open-source protocol allows agents to embed commerce components while maintaining control through an intent-based messaging system, delivering shopping experiences that go far beyond traditional text-only AI interactions.</p></div><div data-slot="card"><p>What if you could control any device using only subtle hand movements? New research from Meta’s Reality Labs is pointing even more firmly toward wrist-worn devices using surface electromyography (s…</p></div><div data-slot="card"><div data-slot="card-header"><p>The Google Developer Program is rolling out major updates to make its tools and community more accessible and powerful. These enhancements include a new flexible monthly subscription tier, a centralized GDP Forum for collaboration, and increased Gemini CLI access for all members.</p></div><div data-slot="card-content"><p><span>Chris Demeke, Kevin Flores</span></p></div></div><div data-slot="card"><p>Working Together to Accelerate AI Adoption</p></div><div data-slot="card"><p>FlashList v2 is a complete rewrite, delivering faster load times, improved scrolling performance, and precise rendering without requiring item size estimates. It powers thousands of lists in the Shopify mobile app and is now production-ready.</p></div><div data-slot="card"><p>Google introduces Veo 3 Fast, an optimized model for speed and price, along with new image-to-video capabilities for both Veo 3 and Veo 3 Fast, enabling developers to efficiently create high-quality video content from text or still images, with varying pricing based on the model and audio inclusion, now available in the Gemini API.</p></div><div data-slot="card"><div data-slot="card-header"><p>The Gemini Embedding model enhances AI applications, particularly through context engineering, which is being successfully adopted by various organizations across industries to power context-aware systems, leading to significant improvements in performance, accuracy, and efficiency.</p></div><div data-slot="card-content"><p><span>Vishal Dharmadhikari, Janie Zhang</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>LangExtract is a new open-source Python library powered by Gemini models for extracting structured information from unstructured text, offering precise source grounding, reliable structured outputs using controlled generation, optimized long-context extraction, interactive visualization, and flexible LLM backend support.</p></div><div data-slot="card-content"><p><span>Akshay Goel, Atilla Kiraly</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>Max's journey introduces LQRax, a JAX-native LQR solver, which exemplifies the growing JAX robotics ecosystem that includes tools like Brax, MJX, and JaxSim, highlighting the benefits of JAX for computational efficiency in optimal control and simulation, and for seamlessly integrating model-based and learning-based approaches.</p></div><div data-slot="card-content"><p><span>Srikanth Kilaru, Max Muchen Sun</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>ExecuTorch is the PyTorch inference framework for edge devices developed by Meta with support from industry leaders like Arm, Apple, and Qualcomm.&nbsp; Running machine learning (ML) models on-device is…</p></div><div data-slot="card-content"><p><span>PyTorch Edge Team in collaboration with Family of Apps</span></p></div></div><div data-slot="card"><p>How to achieve high availability with distributed databases on Kubernetes</p></div><div data-slot="card"><div data-slot="card-header"><p>Co-hosted by Ashley Oldacre and Christina Warren, People of AI podcast's Season 5 will focus on the builders in the space of AI, highlighting the unique journeys, challenges, and triumphs of these innovators.</p></div><div data-slot="card-content"><p><span>Ashley Oldacre, Christina Warren</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>Opal is a new experimental tool from Google Labs that helps you compose prompts into dynamic, multi-step mini-apps using natural language, removing the need for code, allowing users to build and deploy shareable AI apps with powerful features and seamless integration with existing Google tools.</p></div><div data-slot="card-content"><p><span>Ali Modarres, Bill Byrne, Paul Lewis</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>Apigee helps enterprises integrate large language models (LLMs) into existing API ecosystems securely and scalably, addressing challenges like authentication and authorization not fully covered by the evolving Model Context Protocol (MCP), and offering an open-source MCP server example that demonstrates how to implement enterprise-ready API security for AI agents.</p></div><div data-slot="card-content"><p><span>Antony Arul, Ruben Gonzalez</span></p></div></div><div data-slot="card"><p>Automatically review your PRs with Bugbot</p></div><div data-slot="card"><div data-slot="card-header"><p>New AI capabilities for popular frameworks in Firebase Studio include AI-optimized templates, streamlined integration with Firebase backend services, and the ability to fork workspaces for experimentation and collaboration, making AI-assisted app development more intuitive and faster for developers worldwide.</p></div><div data-slot="card-content"><p><span>Jeanine Banks, Vikas Anand</span></p></div></div><div data-slot="card"><p><span>Lavanya Verma, Ryan Hang, Sung Whang, Joseph Wang</span></p></div><div data-slot="card"><div data-slot="card-header"><p>Gemini 2.5 Flash-Lite, previously in preview, is now stable and generally available. This cost-efficient model is ~1.5x faster than 2.0 Flash-Lite and 2.0 Flash, offers high quality, and includes 2.5 family features like a 1 million-token context window and multimodality.</p></div><div data-slot="card-content"><p><span>Logan Kilpatrick, Zach Gleicher</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>Gemini's advanced capability for conversational image segmentation allows intuitive interaction with visual data by understanding complex phrases, conditional logic, and abstract concepts, streamlining developer experience and opening doors for new applications in media editing, safety monitoring, and damage assessment.</p></div><div data-slot="card-content"><p><span>Paul Voigtlaender, Valentin Gabeur, Rohan Doshi</span></p></div></div><div data-slot="card"><p><span>Austin Harrison, Eddie Huang, Spencer Garth, Tim Ross, Taya Yusuf</span></p></div><div data-slot="card"><p>ChatGPT now thinks and acts, proactively choosing from a toolbox of agentic skills to complete tasks for you using its own computer.</p></div><div data-slot="card"><div data-slot="card-header"><p>Veo 3, Google’s latest AI video generation model, is now available in paid preview via the Gemini API and Google AI Studio. Unveiled at Google I/O 2025, Veo 3 can generate both video and synchronized audio, including dialogue, background sounds, and even animal noises. This model delivers realistic visuals, natural lighting, and physics, with accurate lip syncing and sound that matches on-screen action.</p></div><div data-slot="card-content"><p><span>Alisa Fortin, Luciano Martins, Seth Odoom</span></p></div></div><div data-slot="card"><p>Meta has developed an open-source AI tool to design concrete mixes that are stronger, more sustainable, and ready to build with faster—speeding up construction while reducing environmental impact. …</p></div><div data-slot="card"><p>Shopify’s Global Catalogue demonstrates the impact of multimodal LLMs on one of commerce’s hardest problems: building a unified, structured, and continuously evolving understanding of billions of product listings created by millions of merchants.</p></div><div data-slot="card"><div data-slot="card-header"><p>The Marin project aims to expand the definition of 'open' in AI to include the entire scientific process, not just the model itself, by making the complete development journey accessible and reproducible. This effort, powered by the JAX framework and its Levanter tool, allows for deep scrutiny, trust in, and building upon foundation models, fostering a more transparent future for AI research.</p></div><div data-slot="card-content"><p><span>Srikanth Kilaru, David Hall</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>The updated Agent Development Kit (ADK) simplifies and accelerates the process of building AI agents by providing the CLI with a deep, cost-effective understanding of the ADK framework, allowing developers to quickly ideate, generate, test, and improve functional agents through conversational prompts, eliminating friction and keeping them in a productive "flow" state.</p></div><div data-slot="card-content"><p><span>Julia Wiesinger, Hangfei Lin</span></p></div></div><div data-slot="card"><p>The `logprobs` feature has been officially introduced in the Gemini API on Vertex AI, provides insight into the model's decision-making by showing probability scores for chosen and alternative tokens. This step-by-step guide will walk you through how to enable and interpret this feature and apply it to powerful use cases such as confident classification, dynamic autocomplete, and quantitative RAG evaluation.</p></div><div data-slot="card"><p>Microsoft’s AI-powered code review assistant has transformed pull request workflows by automating routine checks, suggesting improvements, and enabling conversational Q&amp;A, leading to faster PR completion, improved code quality, and enhanced developer onboarding.</p></div><div data-slot="card"><p>The Gemini Embedding text model is now generally available in the Gemini API and Vertex AI. This versatile model has consistently ranked #1 on the MTEB Multilingual leaderboard since its experimental launch in March, supports over 100 languages, has a 2048 maximum input token length, and is priced at $0.15 per 1M input tokens.</p></div><div data-slot="card"><div data-slot="card-header"><p>The Apigee API hub and Developer Portals are distinct but interconnected parts of the Apigee platform that help organizations discover and manage APIs for different personas, unlocking API potential and accelerating innovation.</p></div><div data-slot="card-content"><p><span>Venkat Sadras, David Rush</span></p></div></div><div data-slot="card"><p>Our new jurisdiction resolution system (JRS) is a faster, less resource-intensive solution to the challenging problem of determining tax obligations in places with complicated, overlapping tax jurisdictions.</p></div><div data-slot="card"><div data-slot="card-header"><p>GenAI Processors is a new open-source Python library from Google DeepMind designed to simplify the development of AI applications, especially those handling multimodal input and requiring real-time responsiveness, by providing a consistent "Processor" interface for all steps from input handling to model calls and output processing, for seamless chaining and concurrent execution.</p></div><div data-slot="card-content"><p><span>Andre Elisseeff, Alexey Guseynov, Oskar Bunyan, Shrestha Basu Mallick</span></p></div></div><div data-slot="card"><p>Updates in Firebase Studio include new Agent modes, foundational support for the Model Context Protocol (MCP), and Gemini CLI integration, all designed to redefine AI-assisted development allow developers to create full-stack applications from a single prompt and integrate powerful AI capabilities directly into their workflow.</p></div><div data-slot="card"><div data-slot="card-header"><p>T5Gemma is a new family of encoder-decoder LLMs developed by converting and adapting pretrained decoder-only models based on the Gemma 2 framework, offering superior performance and efficiency compared to its decoder-only counterparts, particularly for tasks requiring deep input understanding, like summarization and translation.</p></div><div data-slot="card-content"><p><span>Biao Zhang, Paul Suganthan, Ben Hora</span></p></div></div><div data-slot="card"><div data-slot="card-header"><p>The new batch mode in the Gemini API is designed for high-throughput, non-latency-critical AI workloads, simplifying large jobs by handling scheduling and processing, and making tasks like data analysis, bulk content creation, and model evaluation more cost-effective and scalable, so developers can process large volumes of data efficiently.</p></div><div data-slot="card-content"><p><span>Lucia Loher, Vishal Dharmadhikari</span></p></div></div><div data-slot="card"><p>Commerce is a dynamic ecosystem where our mission is to empower every merchant to succeed. We optimize each step of their journey—from product creation to customer delivery—using advanced tools, infrastructure, and partnerships to solve a complex optimization challenge.</p></div><div data-slot="card"><p>How the new Pro plan works and why we changed our pricing.</p></div><div data-slot="card"><p><span>Prateek Jain, Soheil Sadeghi, Mehrdad Bakhtiari</span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Try and (161 pts)]]></title>
            <link>https://ygdp.yale.edu/phenomena/try-and</link>
            <guid>44855079</guid>
            <pubDate>Sun, 10 Aug 2025 13:32:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ygdp.yale.edu/phenomena/try-and">https://ygdp.yale.edu/phenomena/try-and</a>, See on <a href="https://news.ycombinator.com/item?id=44855079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p><strong><br>
		I'm gonna try and change the course of hip hop again.<br>
	</strong>
</p>
<p>
		(Dr. Dre)
	</p>

<p>
	Typically, <i>try</i> can be followed by three kinds of phrases: a noun phrase (1a), an infinitival verb phrase with <i>to</i> (1b), or a verb phrase with -<i>ing</i> (1c).
</p>
<blockquote><p>
		1)	a. I'll try the salad.
	</p>
<p id="indented">
		b. I'll try to eat this horrible salad.
	</p>
<p id="indented">
		c. I'll try adding vinegar to the salad, to improve the taste.
	</p>
</blockquote>
<p>
	However, <i>try</i> can also combine with the conjunction <i>and</i>, followed by a bare verb form:
</p>
<blockquote><p>
		2)	I’ll try and eat the salad.
	</p>
</blockquote>
<p>
	This usage is very similar in meaning to <i>try to</i>, if not identical, but is deemed prescriptively incorrect (Routledge 1864:579 in D. Ross 2013a:120; Partridge 1947:338, Crews et al. 1989:656 in Brook &amp; Tagliamonte 2016:320). In the next few sections, we will see that it has a number of interesting properties.
</p>


<h2>Who says this?</h2>
<p>
	<i>Try and</i> is described as more prevalent in British English than American English, but is common in both varieties (Hommerberg &amp; Tottie 2007). Brook &amp; Tagliamonte (2016) show that Canadian speakers pattern with American speakers in their usage of the construction.
</p>
<p>
	<i>Try and</i> is not a recent innovation – it first emerged in the late 1500s, although the earliest textual attestion is from 1390 (Tottie 2012, D. Ross 2013a). Tottie (2012) provides some examples of <i>try and</i> from EEBO-TCP corpus, including this one:
</p>
<blockquote><p>
		3) ...howe and by what certaine and generall rule I mighte <b>trye and</b> throughly discerne the veritie of the catholike faithe, from the falsehood of wicked heresye... (1554)<br>
		4) You maie (saide I) <b>trie and</b> bring him in, and shewe him to her. (1569)
	</p>
</blockquote>
<p>
	<i>Webster’s Dictionary</i> (1989:919) suggests that <i>try and</i> in fact predates <i>try to</i>, and this conclusion is supported by Hommerberg &amp; Tottie (2007:60), Tottie &amp; Hoffman (2011) and Tottie (2012). However, D. Ross (2013a) disputes this, saying that “<i>[t]ry and</i> and <i>try to</i> developed simultaneously and independently”. What is clear is that <i>try and</i> has been around for at least as long as <i>try to</i>.
</p>

<h2>Syntactic Properties</h2>
<p>
	Carden &amp; Pesetsky (1977:86) note that <i>try and</i> does not behave like a regular case of coordination. </p>
<h3>Question words are allowed</h3>
<p>One property of ‘true’ coordination is that it is subject to the <i>Coordinate Structure Constraint</i> (J. Ross 1967), which states that a <i>wh</i>-word cannot move out of one of the conjuncts. This is shown in (5).
</p>
<blockquote><p>
		5)	a. Mary [met Bill and ignored Susie].
	</p>
<p id="indented">
		b. *Who did Mary [meet Bill and ignore __]?
	</p>
</blockquote>
<p>
	However, a <i>wh</i>-word can happily be moved out of a <i>try and structure:
</i></p>
<blockquote><p>
		6) Who did Mary [try and talk to __]?
	</p>
</blockquote>
<h3>No reordering</h3>
<p>
	A second property of pseudo-coordination that distinguishes it from regular coordination is that the two conjuncts cannot be reordered. In (6), we see that regular coordination permits the order of conjuncts to be changed, while in (7) we see that the same is not possible with <i>try and</i> (De Vos 2005:59).</p>
<blockquote><p>
		7)	a. John will wash the bathroom and kill mosquitos.
	</p>
<p id="indented">
		b.	John will kill mosquitos and wash the bathroom.
</p></blockquote>
<blockquote><p>
		8)	a. John will try and kill mosquitos.
	</p>
<p id="indented">
		b.	*John will kill mosquitos and try.
</p></blockquote>
<h3><em>Both</em> is not possible</h3>
<p>
	Another piece of evidence that <i>try and</i> is not regular coordination structure comes from the unavailability of <i>both</i>. Usually, coordinated verb phrases can be preceded by <i>both</i>:</p>
<blockquote><p>
		9)	<i>Reality is Broken</i> will both [stimulate your brain and stir your soul]. [<a href="https://janemcgonigal.com/my-book/">source</a>, February 28 2017]
	</p>
</blockquote>
<p>
However, De Vos (2005:59) points out that <i>try and</i> may not be preceded by <i>both</i>:
</p>
<blockquote><p>
		10)	a. John will try and kill mosquitos.
	</p>
<p id="indented">
		b. *John will both try and kill mosquitos.
	</p>
</blockquote>
<h3>Bare form only</h3>
<p>
Unlike with regular coordination, <i>try and</i> is available only when both <i>try</i> and the verb following <i>and</i> are uninflected, which means it must occur in its bare form. Carden &amp; Pesetsky (1977)  call this the <i>bare form condition</i>. The following examples are adapted from D. Ross (2013a:111):
</p>
<blockquote><p>
		11)	a. I will try and finish the assignment.
	</p>
<p id="indented">
		b. I try and finish an assignment every day.
	</p>
<p id="indented">
		c. *I tried and finish(ed) the assignment.
	</p>
<p id="indented">
		d. *He tries and finish(es) an assignment every day.
	</p>
<p id="indented">
		e. *It’s tough when you’re trying and finish(ing) an assignment under pressure.
	</p>
</blockquote>
<h3>Dialect variation in the Bare Form Condition</h3>
<p>
	Is the bare form condition universal? D. Ross (2013a:124-5) notes that it has weakened in some dialects, though not necessarily in the same way. In dialects of Northeastern Canada, parallel inflected forms are acceptable:
</p>
<blockquote><p>
		12)	They tries and does that.
	</p>
</blockquote>
<p>
	In South African English, on the other hand, <i>try</i> may be inflected while the second verb remains a bare form (examples from D. Ross 2013a:125):
</p>
<blockquote><p>
		13)	a. Noeleen tries and find answers and solutions. [<a href="http://www.tvsa.co.za/default.asp?blogname=coming_up_on_3Talk&amp;ArticleID=2903">source</a>, August 2006]
	</p>
<p id="indented">
		b. We’re trying and get across that nature is harsh but not necessarily full of malice and cruelty. (Dereck Joubert on “Wild about Africa,” Carte Blanche: March 18, 2007)
	</p>
</blockquote>
<h3>No separation of <i>try</i> and <i>and</i></h3>
<p>
	There are some other restrictions on the distribution of try and. Unlike with <i>try to</i>, <i>try</i> may not be separated from <i>and</i> by an adverb (Webster’s Dictionary 1989:919):
</p>
<blockquote><p>
		14)	a. Try always to tell the truth.
	</p>
<p id="indented">
		b. *Try always and tell the truth.
	</p>
</blockquote>
<p>
	Similarly, <i>try</i> may not be separated from <i>and</i> by negation (Brook &amp; Tagliamonte 2016:308):
</p>
<blockquote><p>
		15)	a. You try not to let it bother you.
	</p>
<p id="indented">
		b. *You try not and let it bother you.
	</p>
</blockquote>
<h3>No ellipsis allowed</h3>
<p>
	<i>Try and</i> is incompatible with ellipsis of the following verb phrase (Brook &amp; Tagliamonte 2016):
</p>
<blockquote><p>
		16)	a. Sure, I'll try to.
	</p>
<p id="indented">
		b. *Sure, I'll try and.
</p></blockquote>

<h2>Other instances of pseudocoordination</h2>
<p>
	Infinitival <i>to</i> can be replaced by <i>and</i> in several other cases, subject to dialectal and individual variation. Brook &amp; Tagliamonte (2016:302) state that the best candidate for a verb phrase that behaves like <i>try</i> is <i>be sure</i>:
</p>
<blockquote><p>
		17)	Be sure and visit Harry tomorrow. (Carden &amp; Pesetsky 1977:84)
	</p>
</blockquote>
<p>
	D. Ross (2013a:122) provides several examples of other verb phrases in which infinitival <i>to</i> has been replaced with <i>and</i>:
</p>
<blockquote><p>
		18)	a. <b>Mind and</b> get all right for next Saturday. (Poutsma 1905:361)
	</p>
<p id="indented">
		b. You know I go to all these different schools and I <b>start and</b> get mixed up after a while. (Hopper 2002:162)
	</p>
<p id="indented">
		c. <b>Remember and</b> wash your hair. (BNC: KE4 636, 1992)
	</p>
</blockquote>
<p>
	Another instance of pseudocoordination is found with motion verbs, such as <i>come</i> and <i>go</i>:
</p>
<blockquote><p>
		19)	a. Can you come and pick me up from the station?
	</p>
<p id="indented">
		b. I’ll go and get the mop.
	</p>
</blockquote>
<p>
	D. Ross (2013b) argues that motion verb pseudocoordination has a different syntax and semantics from <i>try and</i> pseudocoordination. Syntactically, we can see that motion verb pseudocoordination is <i>not</i> subject to the bare form condition:
</p>
<blockquote><p>
		20)	a. He came and <b>picked</b> me up from the station.
	</p>
<p id="indented">
		b. She goes and <b>gets</b> lunch every day at noon.
	</p>
</blockquote>
<p>
	Semantically, <i>go and</i> entails that the event was completed, so in (21) below it is strange to use <i>go and</i> if the book was not acquired. In contrast, its non-pseudocoordination equivalent <i>go to</i> does not have this entailment.
</p>
<blockquote><p>
		21)	The man will go to/*and buy the book, even if it is sold out.
	</p>
</blockquote>
<p><em>Page contributed by Matthew Tyler on Feb 23, 2018.</em></p>
<p><em>Updates/revisions: June 27, 2018 (Katie Martin)</em></p>
<p><b>Please cite this page as:</b> Tyler, Matthew. 2018. <em>Try and</em>. <i>Yale Grammatical Diversity Project: English in North America</i>. (Available online at <a href="http://ygdp.yale.edu/phenomena/try-and">http://ygdp.yale.edu/phenomena/try-and</a>. Accessed on YYYY-MM-DD). Updated by Katie Martin (2018).</p>
<h2>References</h2>
</div><div><p>Phenomenon Dialect:&nbsp;</p><div><p>Widespread American English</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing simple tab-completions for Bash and Zsh (151 pts)]]></title>
            <link>https://mill-build.org/blog/14-bash-zsh-completion.html</link>
            <guid>44854035</guid>
            <pubDate>Sun, 10 Aug 2025 09:50:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mill-build.org/blog/14-bash-zsh-completion.html">https://mill-build.org/blog/14-bash-zsh-completion.html</a>, See on <a href="https://news.ycombinator.com/item?id=44854035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>

<div id="preamble">
<p><em>Li Haoyi, 7 August 2025</em></p>
<p>Shell tab-completions can be very handy, but setting them up is complicated by the fact
that half your users would be using Bash-on-Linux, while the other half will be
using Zsh-on-OSX, each of which has different tab-completion APIs. Furthermore, most
users exploring an unfamiliar CLI tool using tab completion appreciate showing a
description along with each completion so they can read what it is, but that’s
normally only available on Zsh and not on Bash.</p>
<p>But with some work, you can make your tab-completions work on both shells, including
nice quality-of-life features like completion descriptions. This blog post will explore how it
can be done, based on our recent experience implementing this in the <a href="https://mill-build.org/">Mill build tool</a>
version <a href="https://github.com/com-lihaoyi/mill/blob/main/changelog.adoc#103">1.0.3</a>,
providing the great tab-completion experience you see below in a way that works across
both common shells. Hopefully based on this, you will know enough and have enough reference
examples to set up Bash and Zsh completions for your own command-line tooling.</p>
<div>
<p><img src="https://mill-build.org/blog/_images/CompletionDescriptions.png" alt="CompletionDescriptions">
</p>
</div>
<div>
<p><img src="https://mill-build.org/blog/_images/CompletionDescriptions2.png" alt="CompletionDescriptions2">
</p>
</div>
</div>
<div>
<h2 id="_basic_tab_completion"><a href="#_basic_tab_completion"></a>Basic Tab Completion</h2>
<div>
<p>The basic way tab-completion works in shells like Bash or Zsh is to register a handler
function that is called when a user presses <code>&lt;TAB&gt;</code> at the command line. This handler
function is then given the words currently written, and the index of the word the
user’s cursor is currently over. From this information, the completion function generates
a list of strings that are possible completions for the word at that index, and
return it to the shell. At a glance, this looks something like:</p>
<div>
<pre><code data-lang="bash">_generate_foo_completions() {
  local idx=$1; shift
  local words=( "$@" )
  local current_word=${words[idx]}

  local array=(apple apricot banana cherry durian)
  for elem in "${array[@]}"; do
    if [[ $elem == "$current_word"* ]]; then echo "$elem"; fi
  done
}

_complete_foo_bash() {
  local raw=($(_generate_foo_completions "$COMP_CWORD" "${COMP_WORDS[@]}"))
  COMPREPLY=( "${raw[@]}" )
}

_complete_foo_zsh() {
  local -a raw
  raw=($(_generate_foo_completions "$CURRENT" "${words[@]}"))
  compadd -- $raw
}

if [ -n "${ZSH_VERSION:-}" ]; then
  autoload -Uz compinit
  compinit
  compdef _complete_foo_zsh foo
elif [ -n "${BASH_VERSION:-}" ]; then
  complete -F _complete_foo_bash foo
fi</code></pre>
</div>
<div>
<ul>
<li>
<p><code>_generate_foo_completions</code> is a dummy function used
for demonstration purposes that prints out a hardcoded set of completions,
but in a real scenario would be the logic that generates completions for
your specific app or CLI tool.</p>
</li>
<li>
<p><code>_complete_foo_bash</code> and <code>_complete_foo_zsh</code> are the shell-specific
completion functions that pass the current word to <code>_generate_foo_completions</code>
and wire up the results to each shell’s unique completion APIs. Bash completion
functions need to set the <code>COMPREPLY</code> environment variable, while Zsh completion
functions need to call <code>compadd</code> (or one of the other similar functions)</p>
</li>
<li>
<p>This example snippet would typically be put (or <code>source</code>ed) in your
<code>~/.bashrc</code>, <code>~/.bash_profile</code>, and <code>~/.zshrc</code> so the <code>if</code>/<code>elif</code>/<code>fi</code> block at
the bottom registers the relevant hooks when the shell starts.
These hook into tab-completion whenever <code>foo</code> is the
first word at the prompt.</p>
</li>
</ul>
</div>
<p>For example, the Mill build tool provides a <code>./mill mill.tabcomplete/install</code>
builtin that automatically updates these files and instructs the user to
restart the shell or <code>source</code> the relevant script to begin using completions:</p>
<div>
<pre><code data-lang="console">$ ./mill mill.tabcomplete/install
[1/1] mill.tabcomplete.TabCompleteModule.install
Writing to /Users/lihaoyi/.cache/mill/download/mill-completion.sh
Writing to /Users/lihaoyi/.bash_profile
Writing to /Users/lihaoyi/.zshrc
Writing to /Users/lihaoyi/.bashrc
Please restart your shell or `source ~/.cache/mill/download/mill-completion.sh` to enable completions</code></pre>
</div>
<p>Although the Shell syntax can be very finnicky, e.g. passing arrays to as
function arguments via <code>"${words[@]}"</code>, the actual underlying logic here isn’t
too complicated. <code>_complete_foo_bash</code> and <code>_complete_foo_zsh</code> take the
local variables from the shell, pass it to <code>_generate_foo_completions</code>
that uses them to return the possible completions, and passes the completions
back to the shell via <code>COMPREPLY</code> or <code>compadd</code>.</p>
<p>You can try this out live by pasting it into your Bash or Zsh shell and
typing <code>foo &lt;TAB&gt;</code> or <code>foo a&lt;TAB&gt;</code>. Note that you don’t
actually need a <code>foo</code> command installed:</p>
<div>
<pre><code data-lang="console">$ foo &lt;TAB&gt;
apple    apricot  banana   cherry   durian

$ foo a&lt;TAB&gt;
apple    apricot</code></pre>
</div>
<p>That’s all you need to get a basic tab-completer working. In real usage"</p>
<div>
<ul>
<li>
<p><code>foo</code> would be the name of the command the user would invoke your CLI program with
(e.g. <code>mill</code>)</p>
</li>
<li>
<p><code>_generate_foo_completions</code> would be your bespoke logic
to print out a line-separated list of completions. This could be a hard-coded list
for programs that change infrequently, or it could actually invoke your binary and
ask it what completions are available for the given input (what <code>mill</code> does).</p>
</li>
<li>
<p>While this example only looks up <code>words[idx]</code> to try and find a prefix
match for the current word, the completer is allowed to use the entirety of <code>words</code>
to decide what completions to offer, e.g. based on what flags or command-names are present in that array</p>
</li>
</ul>
</div>
<p>Note that when you register completion hooks for <code>foo</code> in Bash and Zsh, they apply
to commands like <code>./foo</code> as well. This is handy for programs like Mill, Maven, or Gradle
which typically use a <code>./mill</code> <a href="https://mill-build.org/mill/cli/installation-ide.html#_bootstrap_scripts" class="page">Bootstrap Script</a>
to run:</p>
<div>
<pre><code data-lang="console">$ ./foo a&lt;TAB&gt;
apple    apricot</code></pre>
</div>
</div>
</div>
<div>
<h2 id="_zsh_completion_descriptions"><a href="#_zsh_completion_descriptions"></a>Zsh Completion Descriptions</h2>
<div>
<p>The completions above work and provide a basic level of assistance for users of your CLI, but
it would be nice for users if they could also see a description of each command they could
complete in the terminal, as is done in the Mill build tool:</p>
<div>
<p><img src="https://mill-build.org/blog/_images/CompletionDescriptions.png" alt="CompletionDescriptions">
</p>
</div>
<p>To do this, we can make <code>_generate_foo_completions</code> generate an array of
longer strings containing both the completion and a description. Bash does not support
completion descriptions by default so we trim off the description,
but in Zsh we pass both the <code>trimmed</code> completion-words as well as the <code>raw</code> words and
descriptions to <code>compadd -d raw — $trimmed</code> as two parallel arrays.</p>
<div>
<pre><code data-lang="bash">_generate_foo_completions() {
  local idx=$1; shift
  local words=( "$@" )
  local current_word=${words[idx]}

  local array=(
    "apple: a common fruit"
    "apricot: sour fruit with a large stone"
    "banana: starchy and high in potassium"
    "cherry: small and sweet with a large pit"
    "durian: stinky spiky fruit"
  )
  for elem in "${array[@]}"; do
    if [[ $elem == "$current_word"* ]]; then echo "$elem"; fi
  done
}

_complete_foo_bash() {
  local IFS=$'\n'
  local raw=($(_generate_foo_completions "$COMP_CWORD" "${COMP_WORDS[@]}"))
  local trimmed=()
  for d in "${raw[@]}"; do trimmed+=( "${d%%:*}" ); done

  COMPREPLY=( "${trimmed[@]}" )
}

_complete_foo_zsh() {
  local -a raw trimmed
  local IFS=$'\n'
  raw=($(_generate_foo_completions "$CURRENT" "${words[@]}"))

  for d in $raw; do trimmed+=( "${d%%:*}" ); done
  compadd -d raw -- $trimmed
}

if [ -n "${ZSH_VERSION:-}" ]; then
  autoload -Uz compinit
  compinit
  compdef _complete_foo_zsh foo
elif [ -n "${BASH_VERSION:-}" ]; then
  complete -F _complete_foo_bash foo
fi</code></pre>
</div>
<p>Zsh would then display the <code>raw</code> lines including both the completion-word as well
as the descriptions when displaying the completion options, but use the <code>trimmed</code>
lines which only contain the completion-words when completing the line</p>
<div>
<pre><code data-lang="console">$ foo a&lt;TAB&gt;
$ foo ap

$ foo ap&lt;TAB&gt;
apple: a common fruit                          apricot: sour fruit with a large stone

$ foo app&lt;TAB&gt;
$ foo apple</code></pre>
</div>
<p>However in this scenario the descriptions are entirely ignored by Bash. Because Bash
does not have a concept of tab-complete descriptions, in Bash we only pass the <code>trimmed</code>
word-completions to <code>COMPREPLY</code> and discard the <code>raw</code> lines containing the descriptions.</p>
</div>
</div>
<div>
<h2 id="_hacking_bash_completion_descriptions"><a href="#_hacking_bash_completion_descriptions"></a>Hacking Bash Completion Descriptions</h2>
<div>
<p>To make Bash show completion "descriptions", we can take advantage of the fact
that the completions are generated dynamically every time we call
<code>_generate_foo_completions</code>, and Bash and Zsh only inserts text
that is a common prefix to all completion options</p>

<p>Therefore, if we have multiple differing word-completions, we can actually append
whatever we want to the right of those words in <code>_generate_foo_completions</code>!
This "appended text" will be shown to users if there are multiple completions
available, but since the word-completions differ, Bash will never insert the entire word,
and thus never insert the appended text either.</p>
<p>The code below implements this: if there is only one completion we trim off the description
following the <code>:</code> off as normal, but if there’s more than one completion we leave the
description intact for the user to see</p>
<div>
<pre><code data-lang="bash">_complete_foo_bash() {
  local IFS=$'\n'
  local raw=($(_generate_foo_completions "$COMP_CWORD" "${COMP_WORDS[@]}"))
  local trimmed=()
  if (( ${#raw[@]} == 1 )); then
    trimmed=( "${raw[0]%%:*}" )
  else
    trimmed=( "${raw[@]}" )
  fi

  COMPREPLY=( "${trimmed[@]}" )
}</code></pre>
</div>
<p>Now when I use autocomplete in Bash, I can see the descriptions for each item, but when
the tab-completion actually completes the token it only completes the word itself and
does not include the description!</p>
<div>
<pre><code data-lang="console">$ foo &lt;TAB&gt;
apple: a common fruit                     cherry: small and sweet with a large pit
apricot: sour fruit with a large stone    durian: stinky spiky fruit
banana: starchy and high in potassium

$ foo a&lt;TAB&gt;
$ foo ap

$ foo ap&lt;TAB&gt;
apple: a common fruit                   apricot: sour fruit with a large stone


$ foo app&lt;TAB&gt;
$ foo apple</code></pre>
</div>
<p>In this section, we only needed to make changes to the <code>_complete_foo_bash</code> function,
as the Zsh completion logic in <code>_complete_foo_zsh</code> is completely unchanged.</p>
</div>
</div>
<div>
<h2 id="_showing_single_completion_descriptions"><a href="#_showing_single_completion_descriptions"></a>Showing Single-Completion Descriptions</h2>
<div>
<p>The last quality of life feature we will add is the ability to show completion
descriptions when tabbing on a complete word:</p>

<p>For example, the Mill build tool does this so if you’re not sure what a flag or command
does, you can press <code>&lt;TAB&gt;</code> on it to see more details:</p>
<div>
<p><img src="https://mill-build.org/blog/_images/CompletionSingleDescription.png" alt="CompletionSingleDescription">
</p>
</div>
<p>Tab-completion is a common way to explore unfamiliar APIs, and just because someone
finished writing a flat or command doesn’t mean they aren’t curious about what
it does! But while Zsh tab-completion displays descriptions when multiple
options match the prefix, and we managed to hack Bash tab-completion to do the same
thing, neither displays any information if the word you are tab-completing is already
complete.</p>
<p>This behavior can be annoying, if the user wants to see the description, they will
need to first:</p>
<div>
<ul>
<li>
<p>Delete enough characters to make the token match multiple completions</p>
</li>
<li>
<p>Press <code>&lt;TAB&gt;</code></p>
</li>
<li>
<p>Visually scan the multiple completions printed to find the word description
they care about</p>
</li>
<li>
<p>Type back in all the missing characters so they can run the command</p>
</li>
</ul>
</div>
<p>To solve this, we can hack Bash and Zsh to print tab-completion descriptions even
if the token is already a complete word. We do this by checking if the token
is a complete word, and if so adding a second "dummy" completion: this makes
the tab-completion ambiguous, which cases Bash and Zsh to print out the completions
and descriptions for the user to see.</p>
<p>Doing this in <code>_complete_foo_bash</code> looks like the following:</p>
<div>
<pre><code data-lang="bash">_complete_foo_bash() {
  local IFS=$'\n'
  local raw=($(_generate_foo_completions "$COMP_CWORD" "${COMP_WORDS[@]}"))
  local trimmed=()
  trimmed+=( "${raw[@]}" )

  if (( ${#raw[@]} == 1 )); then
    trimmed+=( "${raw[0]%%:*}" )
  fi

  COMPREPLY=( "${trimmed[@]}" )
}</code></pre>
</div>
<p>Instead of checking the length of <code>raw</code> to decide whether we add a trimmed
and non-trimmed lines to <code>trimmed</code>, we now instead <em>always</em> add the non-trimmed lines
that contain the completion descriptions, and in the case where there’s only
one line we then add an additional word-only completion with the description
trimmed off.</p>
<p>This means that all completions are ambiguous and will print the description -
even completions with a single real choice - but the additional trimmed line
when there is only 1 real choice ensures that the description text never gets
inserted into the user’s command</p>
<p>In Zsh, this can be similarly done via:</p>
<div>
<pre><code data-lang="bash">_complete_foo_zsh() {
  local -a raw trimmed
  local IFS=$'\n'
  raw=($(_generate_foo_completions "$CURRENT" "${words[@]}"))

  for d in $raw; do trimmed+=( "${d%%:*}" ); done
  if (( ${#raw} == 1 )); then
    trimmed+=( "${raw[1]}" )
    raw+=( "${trimmed[1]}" )
  fi

  compadd -d raw -- $trimmed
}</code></pre>
</div>
<p>The change here is similar to the Bash snippet above: when the number of completions is 1,
we add an additional completion to make it ambiguous so Zsh prints the description. But
because Zsh expects to pass two parallel arrays of descriptions and tokens to <code>compadd</code>,
our <code>if</code> block needs to append items to both <code>trimmed</code> and <code>raw</code>.</p>
<p>Using this, it now looks like</p>
<div>
<pre><code data-lang="console">$ foo apple&lt;TAB&gt;
apple                  apple: a common fruit</code></pre>
</div>
<p>Although the UI is not quite perfect - the word <code>apple</code> gets duplicated twice -
this nevertheless achieves the original goal of letting users <code>&lt;TAB&gt;</code> on an
already-completed flag or command to see the description or documentation for that word.</p>
</div>
</div>
<div>
<h2 id="_conclusion"><a href="#_conclusion"></a>Conclusion</h2>
<div>
<p>At this point, our final code looks like this:</p>
<div>
<pre><code data-lang="bash">_generate_foo_completions() {
  local idx=$1; shift
  local words=( "$@" )
  local current_word=${words[idx]}

  local array=(
    "apple: a common fruit"
    "apricot: sour fruit with a large stone"
    "banana: starchy and high in potassium"
    "cherry: small and sweet with a large pit"
    "durian: stinky spiky fruit"
  )
  for elem in "${array[@]}"; do
    if [[ $elem == "$current_word"* ]]; then echo "$elem"; fi
  done
}

_complete_foo_bash() {
  local IFS=$'\n'
  local raw=($(_generate_foo_completions "$COMP_CWORD" "${COMP_WORDS[@]}"))
  local trimmed=()
  trimmed+=( "${raw[@]}" )

  if (( ${#raw[@]} == 1 )); then
    trimmed+=( "${raw[0]%%:*}" )
  fi

  COMPREPLY=( "${trimmed[@]}" )
}

_complete_foo_zsh() {
  local -a raw trimmed
  local IFS=$'\n'
  raw=($(_generate_foo_completions "$CURRENT" "${words[@]}"))

  for d in $raw; do trimmed+=( "${d%%:*}" ); done
  if (( ${#raw} == 1 )); then
    trimmed+=( "${raw[1]}" )
    raw+=( "${trimmed[1]}" )
  fi

  compadd -d raw -- $trimmed
}

if [ -n "${ZSH_VERSION:-}" ]; then
  autoload -Uz compinit
  compinit
  compdef _complete_foo_zsh foo
elif [ -n "${BASH_VERSION:-}" ]; then
  complete -F _complete_foo_bash foo
fi</code></pre>
</div>
<p>And can be used in both Bash or Zsh to provide an identical user experience:</p>
<div>
<ul>
<li>
<p>Showing possible tab-completions when there are multiple available</p>
</li>
<li>
<p>Showing command or flag descriptions (even though this is not natively supported by Bash)</p>
</li>
<li>
<p>Performing partial or entire-word completions</p>
</li>
<li>
<p>Showing the description or documentation when <code>&lt;TAB&gt;</code>ing on an already-completed word</p>
</li>
</ul>
</div>
<div>
<pre><code data-lang="console">$ foo &lt;TAB&gt;
apple: a common fruit                     banana: starchy and high in potassium     durian: stinky spiky fruit
apricot: sour fruit with a large stone    cherry: small and sweet with a large pit

$ foo a&lt;TAB&gt;
$ foo ap

$ foo ap&lt;TAB&gt;
apple: a common fruit                   apricot: sour fruit with a large stone

$ foo app&lt;TAB&gt;
$ foo apple

$ foo apple&lt;TAB&gt;
apple                  apple: a common fruit</code></pre>
</div>
<p>The actual docs for each shell’s tab-completion system contains a lot more detail (e.g.
<a href="https://zsh.sourceforge.io/Doc/Release/Completion-System.html">72 pages</a> for Zsh!), and
there are definitely many different ways you can set up your tab-completion scripts.
This blog post just aims to provide the simplest working example that works in both
Bash and Zsh, so hopefully you can understand it well enough to integrate into
your own projects.</p>
</div>
</div>

</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Abogen – Generate audiobooks from EPUBs, PDFs and text (221 pts)]]></title>
            <link>https://github.com/denizsafak/abogen</link>
            <guid>44853064</guid>
            <pubDate>Sun, 10 Aug 2025 05:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/denizsafak/abogen">https://github.com/denizsafak/abogen</a>, See on <a href="https://news.ycombinator.com/item?id=44853064">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">abogen <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/abogen/assets/icon.ico"><img width="40px" title="abogen icon" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/abogen/assets/icon.ico"></a></h2><a id="user-content-abogen-" aria-label="Permalink: abogen " href="#abogen-"></a></div>
<p dir="auto"><a href="https://github.com/denizsafak/abogen/actions"><img src="https://github.com/denizsafak/abogen/actions/workflows/test_pip.yml/badge.svg" alt="Build Status"></a>
<a href="https://github.com/denizsafak/abogen/releases/latest"><img src="https://camo.githubusercontent.com/80f34663a4a26d077050a300729c88d9b130c4da02f733425c2146b15ea99fa1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f64656e697a736166616b2f61626f67656e" alt="GitHub Release" data-canonical-src="https://img.shields.io/github/v/release/denizsafak/abogen"></a>
<a href="https://pypi.org/project/abogen/" rel="nofollow"><img src="https://camo.githubusercontent.com/6c83cc79631886146a58d279a7b42aca1febcc6e93417836ad81ded7547cbf5e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f61626f67656e" alt="Abogen PyPi Python Versions" data-canonical-src="https://img.shields.io/pypi/pyversions/abogen"></a>
<a href="https://github.com/denizsafak/abogen/releases/latest"><img src="https://camo.githubusercontent.com/1ddac32b3e7b4a76e66e2ad641d8f0a3d0c9cc3e0defa693f169cdc84fccfc7b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f732d77696e646f77732532302537432532306c696e75782532302537432532306d61636f732532302d626c7565" alt="Operating Systems" data-canonical-src="https://img.shields.io/badge/os-windows%20%7C%20linux%20%7C%20macos%20-blue"></a>
<a href="https://github.com/psf/black"><img src="https://camo.githubusercontent.com/5bf9e9fa18966df7cb5fac7715bef6b72df15e01a6efa9d616c83f9fcb527fe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="Code style: black" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/02e67a3f818beb1ab87c3b8fd2b7403260b1a8f77fb0899dc3ff0e683f5067ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d6d61726f6f6e2e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-maroon.svg"></a></p>
<p dir="auto">Abogen is a powerful text-to-speech conversion tool that makes it easy to turn ePub, PDF, or text files into high-quality audio with matching subtitles in seconds. Use it for audiobooks, voiceovers for Instagram, YouTube, TikTok, or any project that needs natural-sounding text-to-speech, using <a href="https://huggingface.co/hexgrad/Kokoro-82M" rel="nofollow">Kokoro-82M</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.png"><img title="Abogen Main" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.png" width="380"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen2.png"><img title="Abogen Processing" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen2.png" width="380"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description demo.mp4">demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/39929354/437639906-cb66512d-0a52-48c3-bda4-f1e6a03fb8d6.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ4MTg1MDEsIm5iZiI6MTc1NDgxODIwMSwicGF0aCI6Ii8zOTkyOTM1NC80Mzc2Mzk5MDYtY2I2NjUxMmQtMGE1Mi00OGMzLWJkYTQtZjFlNmEwM2ZiOGQ2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODEwVDA5MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNjZjA4YjU5MmNlODcxMzMxMDQwYjBlNWQ4YjAzMDRmZjUyM2E5YjU0MTZmODRhOTYzODFlYzI0ZDZmYzYyNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.rWfnnubrVzoCKOG2qJlSqfRQTfboP0i2XrHy75xbOOI" data-canonical-src="https://private-user-images.githubusercontent.com/39929354/437639906-cb66512d-0a52-48c3-bda4-f1e6a03fb8d6.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ4MTg1MDEsIm5iZiI6MTc1NDgxODIwMSwicGF0aCI6Ii8zOTkyOTM1NC80Mzc2Mzk5MDYtY2I2NjUxMmQtMGE1Mi00OGMzLWJkYTQtZjFlNmEwM2ZiOGQ2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODEwVDA5MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNjZjA4YjU5MmNlODcxMzMxMDQwYjBlNWQ4YjAzMDRmZjUyM2E5YjU0MTZmODRhOTYzODFlYzI0ZDZmYzYyNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.rWfnnubrVzoCKOG2qJlSqfRQTfboP0i2XrHy75xbOOI" controls="controls" muted="muted">

  </video>
</details>

<blockquote>
<p dir="auto">This demo was generated in just 5&nbsp;seconds, producing ∼1&nbsp;minute of audio with perfectly synced subtitles. To create a similar video, see <a href="https://github.com/denizsafak/abogen/tree/main/demo">the demo guide</a>.</p>
</blockquote>
<div dir="auto"><h2 tabindex="-1" dir="auto"><code>How to install?</code> <a href="https://pypi.org/project/abogen/" rel="nofollow"><img src="https://camo.githubusercontent.com/6c83cc79631886146a58d279a7b42aca1febcc6e93417836ad81ded7547cbf5e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f61626f67656e" alt="Abogen Compatible PyPi Python Versions" data-canonical-src="https://img.shields.io/pypi/pyversions/abogen"></a></h2><a id="user-content-how-to-install-" aria-label="Permalink: How to install?" href="#how-to-install-"></a></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Go to <a href="https://github.com/espeak-ng/espeak-ng/releases/latest">espeak-ng latest release</a> download and run the *.msi file.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">OPTION 1: Install using script</h4><a id="user-content-option-1-install-using-script" aria-label="Permalink: OPTION 1: Install using script" href="#option-1-install-using-script"></a></p>
<ol dir="auto">
<li><a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip">Download</a> the repository</li>
<li>Extract the ZIP file</li>
<li>Run <code>WINDOWS_INSTALL.bat</code> by double-clicking it</li>
</ol>
<p dir="auto">This method handles everything automatically - installing all dependencies including CUDA in a self-contained environment without requiring a separate Python installation. (You still need to install <a href="https://github.com/espeak-ng/espeak-ng/releases/latest">espeak-ng</a>.)</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">You don't need to install Python separately. The script will install Python automatically.</p>
</div>
<p dir="auto"><h4 tabindex="-1" dir="auto">OPTION 2: Install using pip</h4><a id="user-content-option-2-install-using-pip" aria-label="Permalink: OPTION 2: Install using pip" href="#option-2-install-using-pip"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create a virtual environment (optional)
mkdir abogen &amp;&amp; cd abogen
python -m venv venv
venv\Scripts\activate

# For NVIDIA GPUs:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# For AMD GPUs:
# Not supported yet, because ROCm is not available on Windows. Use Linux if you have AMD GPU.

# Install abogen
pip install abogen"><pre><span><span>#</span> Create a virtual environment (optional)</span>
mkdir abogen <span>&amp;&amp;</span> <span>cd</span> abogen
python -m venv venv
venv<span>\S</span>cripts<span>\a</span>ctivate

<span><span>#</span> For NVIDIA GPUs:</span>
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

<span><span>#</span> For AMD GPUs:</span>
<span><span>#</span> Not supported yet, because ROCm is not available on Windows. Use Linux if you have AMD GPU.</span>

<span><span>#</span> Install abogen</span>
pip install abogen</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mac</h3><a id="user-content-mac" aria-label="Permalink: Mac" href="#mac"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install espeak-ng
brew install espeak-ng

# Create a virtual environment (recommended)
mkdir abogen &amp;&amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen"><pre><span><span>#</span> Install espeak-ng</span>
brew install espeak-ng

<span><span>#</span> Create a virtual environment (recommended)</span>
mkdir abogen <span>&amp;&amp;</span> <span>cd</span> abogen
python3 -m venv venv
<span>source</span> venv/bin/activate

<span><span>#</span> Install abogen</span>
pip3 install abogen</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install espeak-ng
sudo apt install espeak-ng # Ubuntu/Debian
sudo pacman -S espeak-ng # Arch Linux
sudo dnf install espeak-ng # Fedora

# Create a virtual environment (recommended)
mkdir abogen &amp;&amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen

# For NVIDIA GPUs:
# Already supported, no need to install CUDA separately.

# For AMD GPUs:
# After installing abogen, we need to uninstall the existing torch package
pip3 uninstall torch 
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4"><pre><span><span>#</span> Install espeak-ng</span>
sudo apt install espeak-ng <span><span>#</span> Ubuntu/Debian</span>
sudo pacman -S espeak-ng <span><span>#</span> Arch Linux</span>
sudo dnf install espeak-ng <span><span>#</span> Fedora</span>

<span><span>#</span> Create a virtual environment (recommended)</span>
mkdir abogen <span>&amp;&amp;</span> <span>cd</span> abogen
python3 -m venv venv
<span>source</span> venv/bin/activate

<span><span>#</span> Install abogen</span>
pip3 install abogen

<span><span>#</span> For NVIDIA GPUs:</span>
<span><span>#</span> Already supported, no need to install CUDA separately.</span>

<span><span>#</span> For AMD GPUs:</span>
<span><span>#</span> After installing abogen, we need to uninstall the existing torch package</span>
pip3 uninstall torch 
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4</pre></div>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">If you get <code>WARNING: The script abogen-cli is installed in '/home/username/.local/bin' which is not on PATH.</code> error, run the following command to add it to your PATH:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;export PATH=\&quot;/home/$USER/.local/bin:\$PATH\&quot;&quot; >> ~/.bashrc &amp;&amp; source ~/.bashrc"><pre><span>echo</span> <span><span>"</span>export PATH=<span>\"</span>/home/<span>$USER</span>/.local/bin:<span>\$</span>PATH<span>\"</span><span>"</span></span> <span>&gt;&gt;</span> <span>~</span>/.bashrc <span>&amp;&amp;</span> <span>source</span> <span>~</span>/.bashrc</pre></div>
</div>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">If you get "No matching distribution found" error, try installing it on supported Python (3.10 to 3.12). You can use <a href="https://github.com/pyenv/pyenv">pyenv</a> to manage multiple Python versions easily in Linux. Watch this <a href="https://www.youtube.com/watch?v=MVyb-nI4KyI" rel="nofollow">video</a> by NetworkChuck for a quick guide.</p>
</div>
<blockquote>
<p dir="auto">Special thanks to <a href="https://github.com/hg000125">@hg000125</a> for his contribution in <a href="https://github.com/denizsafak/abogen/issues/23" data-hovercard-type="issue" data-hovercard-url="/denizsafak/abogen/issues/23/hovercard">#23</a>. AMD GPU support is possible thanks to his work.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>How to run?</code></h2><a id="user-content-how-to-run" aria-label="Permalink: How to run?" href="#how-to-run"></a></p>
<p dir="auto">If you installed using pip, you can simply run the following command to start Abogen:</p>

<div dir="auto"><p dir="auto">Tip</p><p dir="auto">If you installed using the Windows installer <code>(WINDOWS_INSTALL.bat)</code>, It should have created a shortcut in the same folder, or your desktop. You can run it from there. If you lost the shortcut, Abogen is located in <code>python_embedded/Scripts/abogen.exe</code>. You can run it from there directly.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>How to use?</code></h2><a id="user-content-how-to-use" aria-label="Permalink: How to use?" href="#how-to-use"></a></p>
<ol dir="auto">
<li>Drag and drop any ePub, PDF, or text file (or use the built-in text editor)</li>
<li>Configure the settings:
<ul dir="auto">
<li>Set speech speed</li>
<li>Select a voice (or create a custom voice using voice mixer)</li>
<li>Select subtitle generation style (by sentence, word, etc.)</li>
<li>Select output format</li>
<li>Select where to save the output</li>
</ul>
</li>
<li>Hit Start</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>In action</code></h2><a id="user-content-in-action" aria-label="Permalink: In action" href="#in-action"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.gif"><img title="Abogen in action" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.gif" data-animated-image=""></a></p> 
<p dir="auto">Here’s Abogen in action: in this demo, it processes ∼3,000 characters of text in just 11 seconds and turns it into 3 minutes and 28 seconds of audio, and I have a low-end <strong>RTX&nbsp;2060&nbsp;Mobile laptop GPU</strong>. Your results may vary depending on your hardware.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Configuration</code></h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Input Box</strong></td>
<td>Drag and drop <code>ePub</code>, <code>PDF</code>, or <code>.TXT</code> files (or use built-in text editor)</td>
</tr>
<tr>
<td><strong>Queue options</strong></td>
<td>Add multiple files to a queue and process them in batch, with individual settings for each file. See <a href="#queue-mode">Queue mode</a> for more details.</td>
</tr>
<tr>
<td><strong>Speed</strong></td>
<td>Adjust speech rate from <code>0.1x</code> to <code>2.0x</code></td>
</tr>
<tr>
<td><strong>Select Voice</strong></td>
<td>First letter of the language code (e.g., <code>a</code> for American English, <code>b</code> for British English, etc.), second letter is for <code>m</code> for male and <code>f</code> for female.</td>
</tr>
<tr>
<td><strong>Voice mixer</strong></td>
<td>Create custom voices by mixing different voice models with a profile system. See <a href="#voice-mixer">Voice Mixer</a> for more details.</td>
</tr>
<tr>
<td><strong>Voice preview</strong></td>
<td>Listen to the selected voice before processing.</td>
</tr>
<tr>
<td><strong>Generate subtitles</strong></td>
<td><code>Disabled</code>, <code>Sentence</code>, <code>Sentence + Comma</code>, <code>1 word</code>, <code>2 words</code>, <code>3 words</code>, etc. (Represents the number of words in each subtitle entry)</td>
</tr>
<tr>
<td><strong>Output voice format</strong></td>
<td><code>.WAV</code>, <code>.FLAC</code>, <code>.MP3</code>, <code>.OPUS (best compression)</code> and <code>M4B (with chapters)</code> (Special thanks to <a href="https://github.com/jborza">@jborza</a> for chapter support in PR <a href="https://github.com/denizsafak/abogen/pull/10" data-hovercard-type="pull_request" data-hovercard-url="/denizsafak/abogen/pull/10/hovercard">#10</a>)</td>
</tr>
<tr>
<td><strong>Output subtitle format</strong></td>
<td>Configures the subtitle format as <code>SRT (standard)</code>, <code>ASS (wide)</code>, <code>ASS (narrow)</code>, <code>ASS (centered wide)</code>, or <code>ASS (centered narrow)</code>.</td>
</tr>
<tr>
<td><strong>Replace single newlines with spaces</strong></td>
<td>Replaces single newlines with spaces in the text. This is useful for texts that have imaginary line breaks.</td>
</tr>
<tr>
<td><strong>Save location</strong></td>
<td><code>Save next to input file</code>, <code>Save to desktop</code>, or <code>Choose output folder</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Book handler options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Chapter Control</strong></td>
<td>Select specific <code>chapters</code> from ePUBs or <code>chapters + pages</code> from PDFs.</td>
</tr>
<tr>
<td><strong>Save each chapter separately</strong></td>
<td>Save each chapter in e-books as a separate audio file.</td>
</tr>
<tr>
<td><strong>Create a merged version</strong></td>
<td>Create a single audio file that combines all chapters. (If <code>Save each chapter separately</code> is disabled, this option will be the default behavior.)</td>
</tr>
<tr>
<td><strong>Save in a project folder with metadata</strong></td>
<td>Save the converted items in a project folder with available metadata files.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Menu options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Theme</strong></td>
<td>Change the application's theme using <code>System</code>, <code>Light</code>, or <code>Dark</code> options.</td>
</tr>
<tr>
<td><strong>Configure max words per subtitle</strong></td>
<td>Configures the maximum number of words per subtitle entry.</td>
</tr>
<tr>
<td><strong>Configure max lines in log window</strong></td>
<td>Configures the maximum number of lines to display in the log window.</td>
</tr>
<tr>
<td><strong>Separate chapters audio format</strong></td>
<td>Configures the audio format for separate chapters as <code>wav</code>, <code>flac</code>, <code>mp3</code>, or <code>opus</code>.</td>
</tr>
<tr>
<td><strong>Create desktop shortcut</strong></td>
<td>Creates a shortcut on your desktop for easy access.</td>
</tr>
<tr>
<td><strong>Open config directory</strong></td>
<td>Opens the directory where the configuration file is stored.</td>
</tr>
<tr>
<td><strong>Open cache directory</strong></td>
<td>Opens the cache directory where converted text files are stored.</td>
</tr>
<tr>
<td><strong>Clear cache files</strong></td>
<td>Deletes cache files created during the conversion or preview.</td>
</tr>
<tr>
<td><strong>Check for updates at startup</strong></td>
<td>Automatically checks for updates when the program starts.</td>
</tr>
<tr>
<td><strong>Disable Kokoro's internet access</strong></td>
<td>Prevents Kokoro from downloading models or voices from HuggingFace Hub, useful for offline use.</td>
</tr>
<tr>
<td><strong>Reset to default settings</strong></td>
<td>Resets all settings to their default values.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Voice Mixer</code></h2><a id="user-content-voice-mixer" aria-label="Permalink: Voice Mixer" href="#voice-mixer"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/voice_mixer.png"><img title="Abogen Voice Mixer" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/voice_mixer.png"></a></p>
<p dir="auto">With voice mixer, you can create custom voices by mixing different voice models. You can adjust the weight of each voice and save your custom voice as a profile for future use. The voice mixer allows you to create unique and personalized voices. (Huge thanks to <a href="https://github.com/jborza">@jborza</a> for making this possible through his contributions in <a href="https://github.com/denizsafak/abogen/pull/5" data-hovercard-type="pull_request" data-hovercard-url="/denizsafak/abogen/pull/5/hovercard">#5</a>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Queue Mode</code></h2><a id="user-content-queue-mode" aria-label="Permalink: Queue Mode" href="#queue-mode"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/queue.png"><img title="Abogen queue mode" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/queue.png"></a></p>
<p dir="auto">Abogen supports <strong>queue mode</strong>, allowing you to add multiple files to a processing queue. This is useful if you want to convert several files in one batch.</p>
<ul dir="auto">
<li>You can add text files (<code>.txt</code>) directly using the <strong>Add files</strong> button in the Queue Manager. To add PDF or EPUB files, use the input box in the main window and click the <strong>Add to Queue</strong> button.</li>
<li>Each file in the queue keeps the configuration settings that were active when it was added. Changing the main window configuration afterward does <strong>not</strong> affect files already in the queue.</li>
<li>You can view each file's configuration by hovering over them.</li>
</ul>
<p dir="auto">Abogen will process each item in the queue automatically, saving outputs as configured.</p>
<blockquote>
<p dir="auto">Special thanks to <a href="https://github.com/jborza">@jborza</a> for adding queue mode in PR <a href="https://github.com/denizsafak/abogen/pull/35" data-hovercard-type="pull_request" data-hovercard-url="/denizsafak/abogen/pull/35/hovercard">#35</a></p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>About Chapter Markers</code></h2><a id="user-content-about-chapter-markers" aria-label="Permalink: About Chapter Markers" href="#about-chapter-markers"></a></p>
<p dir="auto">When you process ePUB or PDF files, Abogen converts them into text files stored in your cache directory. When you click "Edit," you're actually modifying these converted text files. In these text files, you'll notice tags that look like this:</p>
<div data-snippet-clipboard-copy-content="<<CHAPTER_MARKER:Chapter Title>>"><pre><code>&lt;&lt;CHAPTER_MARKER:Chapter Title&gt;&gt;
</code></pre></div>
<p dir="auto">These are chapter markers. They are automatically added when you process ePUB or PDF files, based on the chapters you select. They serve an important purpose:</p>
<ul dir="auto">
<li>Allow you to split the text into separate audio files for each chapter</li>
<li>Save time by letting you reprocess only specific chapters if errors occur, rather than the entire file</li>
</ul>
<p dir="auto">You can manually add these markers to plain text files for the same benefits. Simply include them in your text like this:</p>
<div data-snippet-clipboard-copy-content="<<CHAPTER_MARKER:Introduction>>
This is the beginning of my text...  

<<CHAPTER_MARKER:Main Content>> 
Here's another part...  "><pre><code>&lt;&lt;CHAPTER_MARKER:Introduction&gt;&gt;
This is the beginning of my text...  

&lt;&lt;CHAPTER_MARKER:Main Content&gt;&gt; 
Here's another part...  
</code></pre></div>
<p dir="auto">When you process the text file, Abogen will detect these markers automatically and ask if you want to save each chapter separately and create a merged version.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/chapter_marker.png"><img src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/chapter_marker.png" alt="Abogen Chapter Marker"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>About Metadata Tags</code></h2><a id="user-content-about-metadata-tags" aria-label="Permalink: About Metadata Tags" href="#about-metadata-tags"></a></p>
<p dir="auto">Similar to chapter markers, it is possible to add metadata tags for <code>M4B</code> files. This is useful for audiobook players that support metadata, allowing you to add information like title, author, year, etc. Abogen automatically adds these tags when you process ePUB or PDF files, but you can also add them manually to your text files. Add metadata tags <strong>at the beginning of your text file</strong> like this:</p>
<div data-snippet-clipboard-copy-content="<<METADATA_TITLE:Title>>
<<METADATA_ARTIST:Author>>
<<METADATA_ALBUM:Album Title>>
<<METADATA_YEAR:Year>>
<<METADATA_ALBUM_ARTIST:Album Artist>>
<<METADATA_COMPOSER:Narrator>>
<<METADATA_GENRE:Audiobook>>"><pre><code>&lt;&lt;METADATA_TITLE:Title&gt;&gt;
&lt;&lt;METADATA_ARTIST:Author&gt;&gt;
&lt;&lt;METADATA_ALBUM:Album Title&gt;&gt;
&lt;&lt;METADATA_YEAR:Year&gt;&gt;
&lt;&lt;METADATA_ALBUM_ARTIST:Album Artist&gt;&gt;
&lt;&lt;METADATA_COMPOSER:Narrator&gt;&gt;
&lt;&lt;METADATA_GENRE:Audiobook&gt;&gt;
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Supported Languages</code></h2><a id="user-content-supported-languages" aria-label="Permalink: Supported Languages" href="#supported-languages"></a></p>
<div data-snippet-clipboard-copy-content="# 🇺🇸 'a' => American English, 🇬🇧 'b' => British English
# 🇪🇸 'e' => Spanish es
# 🇫🇷 'f' => French fr-fr
# 🇮🇳 'h' => Hindi hi
# 🇮🇹 'i' => Italian it
# 🇯🇵 'j' => Japanese: pip install misaki[ja]
# 🇧🇷 'p' => Brazilian Portuguese pt-br
# 🇨🇳 'z' => Mandarin Chinese: pip install misaki[zh]"><pre><code># 🇺🇸 'a' =&gt; American English, 🇬🇧 'b' =&gt; British English
# 🇪🇸 'e' =&gt; Spanish es
# 🇫🇷 'f' =&gt; French fr-fr
# 🇮🇳 'h' =&gt; Hindi hi
# 🇮🇹 'i' =&gt; Italian it
# 🇯🇵 'j' =&gt; Japanese: pip install misaki[ja]
# 🇧🇷 'p' =&gt; Brazilian Portuguese pt-br
# 🇨🇳 'z' =&gt; Mandarin Chinese: pip install misaki[zh]
</code></pre></div>
<p dir="auto">For a complete list of supported languages and voices, refer to Kokoro's <a href="https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md" rel="nofollow">VOICES.md</a>. To listen to sample audio outputs, see <a href="https://huggingface.co/hexgrad/Kokoro-82M/blob/main/SAMPLES.md" rel="nofollow">SAMPLES.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>MPV Config</code></h2><a id="user-content-mpv-config" aria-label="Permalink: MPV Config" href="#mpv-config"></a></p>
<p dir="auto">I highly recommend using <a href="https://mpv.io/installation/" rel="nofollow">MPV</a> to play your audio files, as it supports displaying subtitles even without a video track. Here's my <code>mpv.conf</code>:</p>
<div data-snippet-clipboard-copy-content="# --- MPV Settings ---
save-position-on-quit
keep-open=yes
# --- Subtitle ---
sub-ass-override=no
sub-margin-y=50
sub-margin-x=50
# --- Audio Quality ---
audio-spdif=ac3,dts,eac3,truehd,dts-hd
audio-channels=auto
audio-samplerate=48000
volume-max=200"><pre><code># --- MPV Settings ---
save-position-on-quit
keep-open=yes
# --- Subtitle ---
sub-ass-override=no
sub-margin-y=50
sub-margin-x=50
# --- Audio Quality ---
audio-spdif=ac3,dts,eac3,truehd,dts-hd
audio-channels=auto
audio-samplerate=48000
volume-max=200
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Docker Guide</code></h2><a id="user-content-docker-guide" aria-label="Permalink: Docker Guide" href="#docker-guide"></a></p>
<p dir="auto">If you want to run Abogen in a Docker container:</p>
<ol dir="auto">
<li><a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip">Download the repository</a> and extract, or clone it using git.</li>
<li>Go to <code>abogen</code> folder. You should see <code>Dockerfile</code> there.</li>
<li>Open your termminal in that directory and run the following commands:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Build the Docker image:
docker build --progress plain -t abogen .

# Note that building the image may take a while.
# After building is complete, run the Docker container:

# Windows
docker run --name abogen -v %cd%:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# Linux
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# MacOS
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 abogen

# We expose port 5800 for use by a web browser, 5900 if you want to connect with a VNC client."><pre><span><span>#</span> Build the Docker image:</span>
docker build --progress plain -t abogen <span>.</span>

<span><span>#</span> Note that building the image may take a while.</span>
<span><span>#</span> After building is complete, run the Docker container:</span>

<span><span>#</span> Windows</span>
docker run --name abogen -v %cd%:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

<span><span>#</span> Linux</span>
docker run --name abogen -v <span><span>$(</span>pwd<span>)</span></span>:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

<span><span>#</span> MacOS</span>
docker run --name abogen -v <span><span>$(</span>pwd<span>)</span></span>:/shared -p 5800:5800 -p 5900:5900 abogen

<span><span>#</span> We expose port 5800 for use by a web browser, 5900 if you want to connect with a VNC client.</span></pre></div>
<p dir="auto">Abogen launches automatically inside the container.</p>
<ul dir="auto">
<li>You can access it via a web browser at <a href="http://localhost:5800/" rel="nofollow">http://localhost:5800</a> or connect to it using a VNC client at <code>localhost:5900</code>.</li>
<li>You can use <code>/shared</code> directory to share files between your host and the container.</li>
<li>For later use, start it with <code>docker start abogen</code> and stop it with <code>docker stop abogen</code>.</li>
</ul>
<p dir="auto">Known issues:</p>
<ul dir="auto">
<li>Audio preview is not working inside container (ALSA error).</li>
<li><code>Open cache directory</code> and <code>Open configuration directory</code> options in settings not working. (Tried pcmanfm, did not work with Abogen).</li>
</ul>
<p dir="auto">(Special thanks to <a href="https://www.reddit.com/user/geo38/" rel="nofollow">@geo38</a> from Reddit, who provided the Dockerfile and instructions in <a href="https://www.reddit.com/r/selfhosted/comments/1k8x1yo/comment/mpe0bz8/" rel="nofollow">this comment</a>.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Similar Projects</code></h2><a id="user-content-similar-projects" aria-label="Permalink: Similar Projects" href="#similar-projects"></a></p>
<p dir="auto">Abogen is a standalone project, but it is inspired by and shares some similarities with other projects. Here are a few:</p>
<ul dir="auto">
<li><a href="https://github.com/santinic/audiblez">audiblez</a>: Generate audiobooks from e-books. <strong>(Has CLI and GUI support)</strong></li>
<li><a href="https://github.com/plusuncold/autiobooks">autiobooks</a>: Automatically convert epubs to audiobooks</li>
<li><a href="https://github.com/mateogon/pdf-narrator">pdf-narrator</a>: Convert your PDFs and EPUBs into audiobooks effortlessly.</li>
<li><a href="https://github.com/p0n1/epub_to_audiobook">epub_to_audiobook</a>: EPUB to audiobook converter, optimized for Audiobookshelf</li>
<li><a href="https://github.com/DrewThomasson/ebook2audiobook">ebook2audiobook</a>: Convert ebooks to audiobooks with chapters and metadata using dynamic AI models and voice cloning</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Roadmap</code></h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul>
<li> Add OCR scan feature for PDF files using docling/teserract.</li>
<li> Add chapter metadata for .m4a files. (Issue <a href="https://github.com/denizsafak/abogen/issues/9" data-hovercard-type="issue" data-hovercard-url="/denizsafak/abogen/issues/9/hovercard">#9</a>, PR <a href="https://github.com/denizsafak/abogen/pull/10" data-hovercard-type="pull_request" data-hovercard-url="/denizsafak/abogen/pull/10/hovercard">#10</a>)</li>
<li> Add support for different languages in GUI.</li>
<li> Add voice formula feature that enables mixing different voice models. (Issue <a href="https://github.com/denizsafak/abogen/issues/1" data-hovercard-type="issue" data-hovercard-url="/denizsafak/abogen/issues/1/hovercard">#1</a>, PR <a href="https://github.com/denizsafak/abogen/pull/5" data-hovercard-type="pull_request" data-hovercard-url="/denizsafak/abogen/pull/5/hovercard">#5</a>)</li>
<li> Add support for kokoro-onnx (If it's necessary).</li>
<li> Add dark mode.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Troubleshooting</code></h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto">If you encounter any issues while running Abogen, try launching it from the command line with:</p>

<p dir="auto">This will start Abogen in command-line mode and display detailed error messages. Please open a new issue on the <a href="https://github.com/denizsafak/abogen/issues">Issues</a> page with the error message and a description of your problem.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Contributing</code></h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">I welcome contributions! If you have ideas for new features, improvements, or bug fixes, please fork the repository and submit a pull request.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">For developers and contributors</h3><a id="user-content-for-developers-and-contributors" aria-label="Permalink: For developers and contributors" href="#for-developers-and-contributors"></a></p>
<p dir="auto">If you'd like to modify the code and contribute to development, you can <a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip">download the repository</a>, extract it and run the following commands to build <strong>or</strong> install the package:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Go to the directory where you extracted the repository and run:
pip install -e .      # Installs the package in editable mode
pip install build     # Install the build package
python -m build       # Builds the package in dist folder (optional)
abogen                # Opens the GUI"><pre><span><span>#</span> Go to the directory where you extracted the repository and run:</span>
pip install -e <span>.</span>      <span><span>#</span> Installs the package in editable mode</span>
pip install build     <span><span>#</span> Install the build package</span>
python -m build       <span><span>#</span> Builds the package in dist folder (optional)</span>
abogen                <span><span>#</span> Opens the GUI</span></pre></div>
<p dir="auto">Feel free to explore the code and make any changes you like.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>Credits</code></h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Abogen uses <a href="https://github.com/hexgrad/kokoro">Kokoro</a> for its high-quality, natural-sounding text-to-speech synthesis. Huge thanks to the Kokoro team for making this possible.</li>
<li>Thanks to <a href="https://github.com/wojiushixiaobai">@wojiushixiaobai</a> for <a href="https://github.com/wojiushixiaobai/Python-Embed-Win64">Embedded Python</a> packages. These modified packages include pip pre-installed, enabling Abogen to function as a standalone application without requiring users to separately install Python in Windows.</li>
<li>Thanks to creators of <a href="https://github.com/aerkalov/ebooklib">EbookLib</a>, a Python library for reading and writing ePub files, which is used for extracting text from ePub files.</li>
<li>Special thanks to the <a href="https://www.riverbankcomputing.com/software/pyqt/" rel="nofollow">PyQt</a> team for providing the cross-platform GUI toolkit that powers Abogen's interface.</li>
<li>Icons: <a href="https://icons8.com/icon/aRiu1GGi6Aoe/usa" rel="nofollow">US</a>, <a href="https://icons8.com/icon/t3NE3BsOAQwq/great-britain" rel="nofollow">Great Britain</a>, <a href="https://icons8.com/icon/ly7tzANRt33n/spain" rel="nofollow">Spain</a>, <a href="https://icons8.com/icon/3muzEmi4dpD5/france" rel="nofollow">France</a>, <a href="https://icons8.com/icon/esGVrxg9VCJ1/india" rel="nofollow">India</a>, <a href="https://icons8.com/icon/PW8KZnP7qXzO/italy" rel="nofollow">Italy</a>, <a href="https://icons8.com/icon/McQbrq9qaQye/japan" rel="nofollow">Japan</a>, <a href="https://icons8.com/icon/zHmH8HpOmM90/brazil" rel="nofollow">Brazil</a>, <a href="https://icons8.com/icon/Ej50Oe3crXwF/china" rel="nofollow">China</a>, <a href="https://icons8.com/icon/uI49hxbpxTkp/female" rel="nofollow">Female</a>, <a href="https://icons8.com/icon/12351/male" rel="nofollow">Male</a>, <a href="https://icons8.com/icon/21698/adjust" rel="nofollow">Adjust</a> and <a href="https://icons8.com/icon/GskSeVoroQ7u/voice-id" rel="nofollow">Voice Id</a> icons by <a href="https://icons8.com/" rel="nofollow">Icons8</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>License</code></h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is available under the MIT License - see the <a href="https://github.com/denizsafak/abogen/blob/main/LICENSE">LICENSE</a> file for details.
<a href="https://github.com/hexgrad/kokoro">Kokoro</a> is licensed under <a href="https://github.com/hexgrad/kokoro/blob/main/LICENSE">Apache-2.0</a> which allows commercial use, modification, distribution, and private use.</p>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">Subtitle generation currently works only for English. This is because Kokoro provides timestamp tokens only for English text. If you want subtitles in other languages, please request this feature in the <a href="https://github.com/hexgrad/kokoro">Kokoro project</a>. For more technical details, see <a href="https://github.com/hexgrad/kokoro/blob/6d87f4ae7abc2d14dbc4b3ef2e5f19852e861ac2/kokoro/pipeline.py#L383">this line</a> in the Kokoro's code.</p>
</div>
<blockquote>
<p dir="auto">Tags: audiobook, kokoro, text-to-speech, TTS, audiobook generator, audiobooks, text to speech, audiobook maker, audiobook creator, audiobook generator, voice-synthesis, text to audio, text to audio converter, text to speech converter, text to speech generator, text to speech software, text to speech app, epub to audio, pdf to audio, content-creation, media-generation</p>
</blockquote>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just Buy Nothing: A fake online store to combat shopping addiction (205 pts)]]></title>
            <link>https://justbuynothing.com/</link>
            <guid>44851590</guid>
            <pubDate>Sun, 10 Aug 2025 00:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://justbuynothing.com/">https://justbuynothing.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44851590">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5: Overdue, overhyped and underwhelming. And that's not the worst of it (263 pts)]]></title>
            <link>https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming</link>
            <guid>44851557</guid>
            <pubDate>Sun, 10 Aug 2025 00:06:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming">https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming</a>, See on <a href="https://news.ycombinator.com/item?id=44851557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>GenerativeAI had a truly bad week. The late and underwhelming arrival of GPT-5 wasn’t even the worst part.  But before we get to the worst part (spoiler alert: a new research paper that I will discuss towards the end), let’s review GPT-5’s shambolic debut.</p><p>This was supposed to be the week when OpenAI finally cemented its dominance. The long rumored GPT-5 was about to arrive. Sam Altman was so cocky that in advance of the livestream debut  he posted a screen grab from a Star War film, Rogue One:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!BP8o!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!BP8o!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 424w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 848w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 1272w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!BP8o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png" width="1202" height="837" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50372667-531f-4982-a300-36ac73ce6c82_1202x837.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:837,&quot;width&quot;:1202,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:618063,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!BP8o!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 424w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 848w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 1272w, https://substackcdn.com/image/fetch/$s_!BP8o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50372667-531f-4982-a300-36ac73ce6c82_1202x837.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>People ate it up. It got almost six million views.</p><p>The cockiness continued at the opening of the livestream. Altman, ever the showman, claimed</p><blockquote><p><em>We think you will love using GPT-5 much more than any previous Al. It is useful it is smart it is fast [and[ intuitive. GPT-3 was sort of like talking to a high school student.</em></p><p><em><span>There were flashes of brilliance lots of annoyance but people started to use it and get some value out of it. GPT-4o maybe it was like talking to a college student…. With GPT-5 now it's like talking to an expert —- a legitimate PhD level expert in anything any area you need on demand they can help you with whatever your goals are. </span><strong> </strong></em></p></blockquote><p>What the mainstream media mostly hasn’t told you yet is that a few days later, hardly anybody is buying Altman’s story. </p><p><a href="https://www.change.org/p/please-keep-gpt-4o-available-on-chatgpt?source_location=topics_page&amp;pt=AVBldGl0aW9uAPoMPR0AAAAAaJWTPzdi6sUzNzk5ZDJjOA%3D%3D" rel="">3,000 people hated GPT-5 so much they petitioned — successfully — to get one of the older models back</a><span>. At OpenAI reddit, usually quite pro OpenAI, the lead post was this:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!QwV2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!QwV2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 424w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 848w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 1272w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!QwV2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png" width="1223" height="1489" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1489,&quot;width&quot;:1223,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:556073,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!QwV2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 424w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 848w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 1272w, https://substackcdn.com/image/fetch/$s_!QwV2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1a2195-045d-4426-93ef-03e5689c4a99_1223x1489.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>As they say on Twitter, Altman’s Death Star tweet </span><a href="https://x.com/garymarcus/status/1953887884341391775?s=61" rel="">didn’t age well</a><span>.</span></p><p><span>Meanwhile, as for that </span><em>Star Wars </em><span>movie</span><em>,</em><span> more than a few people end up wondering if Altman has ever watched the film.  For those unfamilar, what happens next is…  the Rebel Alliance blows up the Death Star.</span></p><p>§</p><p>OpenAI basically blew itself up –  and not in a good way.  Aside from a few influencers who praise every new model, the dominant reaction was major disappointment. </p><p>A system that could have gone a week without the community finding boatloads of ridiculous errors and hallucinations would have genuinely impressed me. </p><p><span>Instead, within hours, people were posting </span><a href="https://x.com/colin_fraser/status/1953668411029909892?s=61" rel="">the usual ridiculous errors</a><span>. A Hacker News thread </span><a href="https://news.ycombinator.com/item?id=44827210" rel="">brutally dissected the live, vibe-coded  demo of the Bernoulli effect</a><span>. Multiple posts identified benchmarks where</span><a href="https://x.com/burny_tech/status/1953767104366146037?s=61" rel=""> performance was subpar</a><span>. (Not just the ARC-AGI-2 I had noted in my hot take a few days ago, either). Still others found the </span><a href="https://x.com/scaling01/status/1954292296704250005?s=61" rel="">new automatic “routing” mechanism to be a mess</a><span>.   It was essentially the same experience as with every earlier model. Big promises, stupid errors.</span></p><p><span>But this time, the reaction was different. Because </span><em>expectations</em><span> were through the roof, a </span><em>huge</em><span> number of people viewed GPT 5 as a major letdown.  By the end of the night, OpenAI’s street cred had dramatically fallen. On the question of “which company [will have] the best AI model at the end of August”, a Polymarket poll charted OpenAI </span><a href="https://x.com/scaling01/status/1953515099257282763?s=61" rel="">dropping from 75% to 14% in the space of an hour</a><span>.</span></p><p><span>Typical was a comment from Andres Franco, on X “GPT 5 has been a huge letdown, way more than I expected”. Another reader, previously an OpenAI fan, told me “o3 was a shit good model, [whereas GPT-5] was </span><a href="https://x.com/anoop_331/status/1954211361853964420?s=61%20https://x.com/anoop_331/status/1954211361853964420?s=61" rel="">an utter disappointment, especially given the kind of hype towards its release.</a><span>” An NBA President DM’d me to say “chatgpt 5 still failed my two fav problems to give LLMs”. </span></p><p><span>Loads of people seemed to </span><a href="https://x.com/egidemurisa/status/1954189835012383164?s=61" rel="">sincerely expect GPT-5 was going to be AGI</a><span>. It doesn’t take decades of training to see that GPT-4 was not that.</span></p><p><span>Even my anti-fan club (“Gary haters” in modern parlance) were forced to give </span><em>me</em><span>  props. Tweets like “</span><a href="https://x.com/mgonto/status/1953839860013207669?s=61" rel="">The saddest thing in my day is that @garymarcus is right</a><span>” became trendy.  </span></p><p><span>With a more positive framing, freelance journalist Bryan McMahon wrote to me, “</span><em>We all saw GPT-5’s reveal fall flat yesterday—so flat, in fact, that many online dubbed it “Gary Marcus Day” for proving your consistent criticism about the structural flaws of large language models correct</em><span>.” </span></p><p>§</p><p><span>And, indeed, </span><a href="https://open.substack.com/pub/garymarcus/p/what-to-expect-when-youre-expecting-62e?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">much as I anticipated here two weeks ago</a><span>, the problems I have been pointing out over the last quarter century still lingered. Consider for example the </span><a href="https://open.substack.com/pub/garymarcus/p/generative-ais-crippling-and-widespread?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">critique I gave re: chess and world models</a><span> at the end of  June. My go-to source on this, Mathieu Acher, quickly confirmed</span><strong><a href="https://blog.mathieuacher.com/GPT5-IllegalChessBench/" rel=""> </a></strong><a href="https://blog.mathieuacher.com/GPT5-IllegalChessBench/" rel="">that GPT-5 still struggles with following the rules</a><span>. A Tufts professor sent me a further example, in which GPT-5 becomes completely lost in the course of discussing a simple chess problem.</span></p><p>Or take visual comprehension:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!dPhm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!dPhm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 424w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 848w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 1272w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!dPhm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png" width="1359" height="2132" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2132,&quot;width&quot;:1359,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1081753,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!dPhm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 424w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 848w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 1272w, https://substackcdn.com/image/fetch/$s_!dPhm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0fd7cde-8fdb-4fb6-b126-615b8a5cb835_1359x2132.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The </span><a href="https://garymarcus.substack.com/p/dont-ride-this-bike-generative-ais" rel="">challenge of parts and wholes in generative images</a><span> that Ernest Davis and I discussed here in December fared no better. (Some argued that this is because GPT-5 is still using an older models for generating images, but given that the new thing was supposed to be tantamount to AGI and “fully multimodal” that hardly seems like a compelling excuse.)</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6xcx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6xcx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 424w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 848w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6xcx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg" width="1456" height="1105" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1105,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1323690,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6xcx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 424w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 848w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!6xcx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9048ce3b-83cd-4256-8b82-7c3c33e5bdc0_1598x1213.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I am pretty sure most, if not all, PhDs in mechanical engineering could do better. So could anybody working in a bike shop, and for that matter maybe your kid brother or sister, too. </p><p><span>Émile Torres has a good round-up of</span><a href="https://www.realtimetechpocalypse.com/p/gpt-5-is-by-far-the-best-ai-system" rel=""> many more immediately-uncovered blunders</a><span>. Cameron Williams found examples </span><a href="https://x.com/wasgo/status/1953883545845244121?s=61" rel="">in basic reading and summarization</a><span>.</span></p><p>§</p><p><span>For all that, GPT-5 is not a </span><em>terrible</em><span> model. I played with it for about an hour, and it actually got several of my initial queries right (some initial problems with counting “r’s in blueberries had already been corrected, for example). It only fell apart altogether when I experimented with images. </span></p><p>But the reality is that GPT-5 just not that different from anything that came before. And that’s the point. GPT-4 was widely seen as a radical advance over GPT-3; GPT-3 was widely seen as a radical advance over GPT-2. GPT-5 is barely better than last month’s flavor of the month (Grok 4); on some metrics (ARC-AGI-2) it’s actually worse. </p><p><span>People had grown to expect miracles, but GPT-5 is just the latest incremental advance. And it felt rushed at that, </span><a href="https://x.com/explodemeow102/status/1954192504623931839?s=61" rel="">as one meme showed</a><span>.</span></p><p><span>The one prediction I got most deeply </span><em>wrong</em><span> was in thinking that with so much at stake OpenAI would save the name GPT-5 for something truly remarkable. I honestly didn’t think OpenAI would burn the brand name on something so mid. </span></p><p>I was wrong.</p><p>§</p><p>For a year or two I have been speculating that OpenAI might take a serious hit if GPT-5 was disappointing. We may finally soon find out.</p><p>Certainly, in a rational world, their valuation would take a hit.</p><ul><li><p>They no longer have anything like a clear technical lead.</p></li><li><p>GPT-5 is unlikely to be ahead of the pack for more than a couple months. (And Grok 4 Heavy is already better on the ARC-AGI-2 measure)</p></li><li><p>Many of their best people have left.</p></li><li><p>Many of those people left to start competitors.</p></li><li><p>Elon is moving faster. Anthropic and Google and many others are nipping at their heels. Their relationship with Microsoft has frayed.</p></li><li><p>OpenAI still isn’t making profit.</p></li><li><p>Instead they are being forced to cut prices.</p></li><li><p>People are wising up that LLMs are not in fact AGI-adjacent.</p></li><li><p>People are becoming more skeptical about the company and its CEO.</p></li></ul><p>OpenAI has the name brand recognition, and good UX. Will that be enough to sustain a $300-500B valuation? Hard to know.</p><p>§</p><p>By rights, Altman’s reputation should by now be completely burned. This is a man who joked in September 2023 that “AGI has been achieved internally”, told us in January of this year in his blog that  “We are now confident we know how to build AGI as we have traditionally understood it”.  Just two days ago he hold us that as quoted above) interacting with GPT-5 we “like talking to … legitimate PhD level expert in anything”. </p><p>In hindsight, that was all bullshit.</p><p>And the worst part? Altman brought it all on himself. Had he not kept hinting at the moon, people might have been fine with just another incremental update. </p><p>§</p><p>He may not even be the right CEO for OpenAI anymore:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!R7_Q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!R7_Q!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 424w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 848w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 1272w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!R7_Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png" width="1234" height="487" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:487,&quot;width&quot;:1234,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105688,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!R7_Q!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 424w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 848w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 1272w, https://substackcdn.com/image/fetch/$s_!R7_Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6daea3f0-070b-4b0b-b79d-3ec85846261d_1234x487.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>§</p><p><span>So ok, all this is obviously no bueno for OpenAI. But what of the field of generative AI as a whole?  It’s not like other systems are faring much better. The psychologist Jonathan Shedler was absolutely brutal </span><a href="https://x.com/jonathanshedler/status/1953853841918898600?s=61" rel="">in a takedown of Grok</a><span>, writing in part about Grok’s summary of one of his own papers:</span></p><blockquote><p><em>I'm the author of the paper @grok describes here. It's among the most read and cited articles on psychotherapy outcome-required reading in grad programs around the world</em></p><p><em>Grok gets literally everything wrong</em></p><p><em>The paper shows psychodynamic therapy is as or more effective than</em></p><p><em>CBT. Grok says the exact opposite</em></p><p><em>The title of the paper is literally, "The efficacy of psychodynamic psychotherapy."</em></p><p><em>The effect size for psychodynamic therapy for the major study in the paper was .97. Grok says it's 33. The number .33 does not appear anywhere in the paper.</em></p><p><em>Al seems to know everything—until it's a topic where you have firsthand knowledge</em></p></blockquote><p>How is AI going to invent new science when it can’t even accurately report existing science?</p><p>§</p><p><span>But I have kept you in suspense long enough. At the beginning, and in the subtitle, I hinted that there was even </span><em>worse</em><span> news. </span></p><p><span>The </span><em>real</em><span> news is </span><a href="https://arxiv.org/pdf/2508.01191" rel="">a breaking study from Arizona State University</a><span> that fully vindicates what I have told you for nearly 30 years—and more recently what Apple  told you—about the core weakness of LLMs: their inability to generalize broadly. </span></p><p><span>The physicist Steve Hsu wrote a great summary on X; in every way it vindicates both the unfairly-maligned but significant </span><a href="https://open.substack.com/pub/garymarcus/p/a-knockout-blow-for-llms?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">Apple reasoning paper</a><span> and </span><a href="https://open.substack.com/pub/garymarcus/p/a-knockout-blow-for-llms?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">the core ideas that I have been pushing about distribution shift for the last three decades</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!abjz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!abjz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 424w, https://substackcdn.com/image/fetch/$s_!abjz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 848w, https://substackcdn.com/image/fetch/$s_!abjz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 1272w, https://substackcdn.com/image/fetch/$s_!abjz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!abjz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png" width="1286" height="2131" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2131,&quot;width&quot;:1286,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1046850,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!abjz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 424w, https://substackcdn.com/image/fetch/$s_!abjz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 848w, https://substackcdn.com/image/fetch/$s_!abjz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 1272w, https://substackcdn.com/image/fetch/$s_!abjz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F722447c6-b5e1-4d50-9239-3436044cdced_1286x2131.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Reading the abstract (Chain of Thought reasoning is “a brittle mirage that vanishes when it is pushed beyond training distributions”) practically gave me deja vu. In 1998 I wrote that “universals are pervasive in language and reasoning”  but showed experimentally that neural networks of that era could not reliably “extend universals outside [a] training space of examples”. </p><p>The ASU team showed that exactly the same thing was true even in the  latest, greatest models. Throw in every gadget invented since 1998, and the Achilles’ Heel I identified then still remains. That’s startling. Even I didn’t expect that.</p><p><span>And, crucially, the failure to generalize adequately outside distribution tells us </span><em>why </em><span>all the dozens of shots on goal at building “GPT-5 level models” keep missing their target. It’s not an accident. That failing is </span><em>principled.</em></p><p>§</p><p>We have been fed a steady diet of bullshit for the last several years.</p><p>•&nbsp;General purpose agents that turn out to suck so badly people struggle to find real-world use cases for them. (Any one remember Facebook M, a decade ago?)</p><p>•&nbsp;Allegedly godlike models that turn out to be incremental advances.</p><p>•&nbsp;Claims like “We now know how to build AGI” that never turn out to be true.</p><p>•&nbsp;Promises for world-changing science that rarely materialize.</p><p>•&nbsp;Driverless cars that still are only available in couple percent of the world’s cities.</p><p>•&nbsp;Promises to Congress (AI to filter our fake news! Regulation for AI) that quickly turn to be bogus.</p><p>•&nbsp;Fantasies about timelines, what Ilya saw, and endless influencer hype.</p><p>•&nbsp;Cherry-picked studies, benchmark-gaming, and now even vibe-coded graphs, with zero transparency about how systems work or how they have been trained; public science is in the rear view mirror.</p><p>I love AI. (Or at least what I optimistically imagine it could be.)</p><p>But I hate this bullshit.</p><p><span>What’s changed is that a lot of other people are tiring of it, too. In Zeynep Tufekci‘s words,  the term AGI has become “</span><a href="https://x.com/zeynep/status/1953842912661291048?s=61" rel="">a tool of obfuscation directed [at] investors and the public.</a><span>”</span></p><p>§</p><p><span>In many ways, my work here, in the context of publicly explaining the limits of the pure scaling approach—which is literally how this very Substack began in May 2022, </span><a href="https://garymarcus.substack.com/p/the-new-science-of-alt-intelligence" rel="">nearly three and half  years ago</a><span>—is done. Nobody with intellectual integrity should still believe that pure scaling will get us to AGI. You could say the same about my by now 27-year-old mission to get the field to recognize the centrality of the distribution shift problem. Even some of the tech bros are waking up to the reality that “AGI in 2027” was marketing, not reality.</span></p><p>GPT-5 may be a moderate quantitative improvement (and it may be cheaper) but it still fails in all the same qualitative ways as its predecessors, on chess, on reasoning, in vision;  even sometimes on counting] and basic math..  Hallucinations linger. Dozens of shots on goal (Grok, Claude, Gemini) etc have invariably faced the same problems. Distribution shift has never been solved.</p><p><span>That’s exactly what it means to hit a wall, and exactly the particular set of obstacles I described </span><a href="https://archive.ph/6hEYS" rel="">in my most notorious (and prescient) paper</a><span>, in 2022. Real progress on some dimensions, but  stuck in place on others.</span></p><p><span>Ultimately, the idea that scaling alone might get us to AGI is a </span><em>hypothesis. </em></p><p>No hypothesis has ever been given more benefit of the doubt, nor more funding.  After half a trillion dollars in that direction, it is obviously time to move on. The disappointing performance of GPT-5 should make that enormously clear.</p><p><span>Pure scaling simply isn’t the path to AGI. It turns out that attention, the key component in LLMs, and the focus of the justly famous Transformer paper, is not fact “</span><a href="https://arxiv.org/abs/1706.03762" rel="">all you need</a><span>”.</span></p><p><span>All I am saying is give </span><a href="https://open.substack.com/pub/garymarcus/p/how-o3-and-grok-4-accidentally-vindicated?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">neurosymbolic AI </a><span>with </span><a href="https://open.substack.com/pub/garymarcus/p/generative-ais-crippling-and-widespread?r=8tdk6&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">explicit world models</a><span> a chance. Only once we have systems that can reason about enduring representations of the world, including but not to limited to abstract symbolic ones, will we have a genuine shot at AGI.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!vWPg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!vWPg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 424w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 848w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!vWPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg" width="1022" height="932" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:932,&quot;width&quot;:1022,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:117585,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/170534403?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!vWPg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 424w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 848w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!vWPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0abe7b82-9aed-411a-8bcd-fe91e390f9f2_1022x932.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>This art was </span><em>licensed.</em></figcaption></figure></div><p>PS  For expository purposes, I told a little white lie above, and pretended that there was only one truly devastating new scientific finding about LLMs this week. But the aforementioned “mirage” is not the only problem. There’s actually another—an entirely different can of worms—that I will be talking about in the not too distant future. Stay tuned. And stay to the end for a final postscript.</p><p>PPS Bonus content, sound up, for my personal favorite meme of the week, sent to me (and created by) a retired VFX editor who has taken an interest in AI:</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPTs and Feeling Left Behind (198 pts)]]></title>
            <link>https://whynothugo.nl/journal/2025/08/06/gpts-and-feeling-left-behind/</link>
            <guid>44851214</guid>
            <pubDate>Sat, 09 Aug 2025 23:07:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://whynothugo.nl/journal/2025/08/06/gpts-and-feeling-left-behind/">https://whynothugo.nl/journal/2025/08/06/gpts-and-feeling-left-behind/</a>, See on <a href="https://news.ycombinator.com/item?id=44851214">Hacker News</a></p>
<div id="readability-page-1" class="page"><header><small><span><a href="https://whynothugo.nl/">‹ back home</a></span></small><small><span>2025-08-06</span>
<span><a href="https://whynothugo.nl/tags/ai">#ai</a>
<a href="https://whynothugo.nl/tags/gpt">#gpt</a>
<a href="https://whynothugo.nl/tags/llm">#llm</a></span></small></header><article><p>Every time that I read some blog post about “coding with AI”, or how cool new
models write entire libraries by themselves, I feel like I’m lagging behind,
like I’m missing out on some big, useful tool, and my skills are about to become
obsolete very soon.</p><p>So I try different models and tools, and it’s all incredibly underwhelming. It’s
honestly hard to believe that people get work done using these tools, because I
can spend a few hours on them (without getting even close to finishing the task
at hand) and realise that I could have done it myself in 25 minutes.</p><p>I tell myself <em>“learning to use Vim took a long time, but then it paid off”</em>
eventually. But I could (slowly) write text with Vim the first day. I can spend
an entire day with a GPT and produce nothing of value.</p><p>GPTs work great for finding the exact word to complete a sentence. They’re
surprisingly good at finding the exact type annotation for a Python function.
They can find nuanced bugs in a single function which I copy-paste into the GPT.
But anything beyond writing a simple function always leads to useless junk.
Often times, they solve big problems by just importing a library that does not
exist, and calling a function which does the bulk of the logic. ChatGPT told me
the other day “if you don’t want any dependencies, you’re going to have to
implement it yourself”. But couldn’t actually implement the necessary code.
Large portions of code have lots of hidden logic bugs, and when they fix one
they introduce another.</p><p>And then I see another post on Hacker News, about somebody using GPTs and how
they achieved great results on this and that. Part of me wants to think that
those articles are fake to generate hype, but the reality is that several of
them are written by well-known developers who’ve been around for over a decade.
Some of the results are actually publicly available online.</p><p>I’m in a state where I can’t reconcile my own results with other people’s
results. I hear people saying <em>“this hammer is indestructible”</em>, but when I pick
it up, it’s just origami: made of paper, intricate, delicate, very cool-looking
but I can’t even hammer a tomato with it.</p></article><p>Have comments or want to discuss this topic?<br>Send an email to my public inbox: <a href="mailto:~whynothugo/public-inbox@lists.sr.ht?subject=Re:%20GPTs%20and%20feeling%20left%20behind">~whynothugo/public-inbox@lists.sr.ht</a>.<br>Or feel free to reply privately by email: <a href="mailto:hugo@whynothugo.nl?subject=Re:%20GPTs%20and%20feeling%20left%20behind">hugo@whynothugo.nl</a>.</p><p>— § —</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I code with AI on a budget/free (457 pts)]]></title>
            <link>https://wuu73.org/blog/aiguide1.html</link>
            <guid>44850913</guid>
            <pubDate>Sat, 09 Aug 2025 22:27:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wuu73.org/blog/aiguide1.html">https://wuu73.org/blog/aiguide1.html</a>, See on <a href="https://news.ycombinator.com/item?id=44850913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- Navigation Top -->
      <p><b>Page 1/3</b> &nbsp;
        <span>&nbsp;•&nbsp;</span>
        <a href="https://wuu73.org/blog/aiguide2.html">--&gt;</a>
      </p>
      
      <p>
        Last updated: July 2025
      </p>
      <h2>How I Code with AI on a budget/free</h2>
      <h2>My Browser Setup: The Free AI Buffet</h2>
      <p>
        First things first, I have a browser open loaded with tabs pointing to
        the free tiers of powerful AI models. Why stick to one when you can get
        multiple perspectives for free? My typical lineup includes:
      </p>
      <ul>
        <li>
          At least one tab of
          <a href="https://platform.openai.com/playground/prompts?models=o3" target="_blank" rel="noopener noreferrer">OpenAI Playground</a>. If you set your account's data settings to allow OpenAI to use your
          data for model training, you get free tokens to use on GPT-4.5, o3,
          and other models.
        </li>
        <li>
          At least one tab but more like three of Google
          <a href="https://aistudio.google.com/" target="_blank" rel="noopener noreferrer">Gemini AI Studio</a>
          (Gemini 2.5 Pro/Flash are often free and unlimited here).
          <br>
          Also, try
          <a href="https://gemini.google.com/app" target="_blank" rel="noopener noreferrer">Google Gemini 2.5 Pro</a>
          (different than AI Studio, has better image generation and deep
          research; I always have a couple tabs of this along with a couple tabs
          of AI Studio).
        </li>
        <li>
          Couple tabs of
          <a href="https://poe.com/" target="_blank" rel="noopener noreferrer">Poe.com</a>
          usually set to Claude 4 or o4-mini for its free daily credits on
          premium models.
        </li>
        <li>
          Several tabs of
          <a href="https://openrouter.ai/" target="_blank" rel="noopener noreferrer">OpenRouter</a>, set to several models, some free models, some not.
        </li>
        <li>
          At least one tab for
          <a href="https://chatgpt.com/" target="_blank" rel="noopener noreferrer">ChatGPT</a>
          (the free version is still useful).
        </li>
        <li>
          At least one tab for
          <a href="https://www.perplexity.ai/" target="_blank" rel="noopener noreferrer">Perplexity AI</a>, especially good for research-heavy questions.
        </li>
        <li>
          At least one tab for
          <a href="https://chat.deepseek.com/" target="_blank" rel="noopener noreferrer">Deepseek</a>
          (v3 and r1 are free on their web interface, though watch the context
          limit).
        </li>
        <li>
          One tab for
          <a href="https://grok.com/" target="_blank" rel="noopener noreferrer">Grok.com</a>. Good, free and seemingly unlimited for general use and deep
          research/image editing. I mainly use the deep research feature,
          similar to perplexity.
        </li>
        <li>
          <a href="https://phind.com/" target="_blank" rel="noopener noreferrer">Phind</a>
          is another free one, it tries to show you flowcharts/diagram visuals.
        </li>
        <li>
          <a href="https://lmarena.ai/" target="_blank" rel="noopener noreferrer">lmarena.ai</a>
          offers free access to Claude Opus 4 and Sonnet 4 and others. Free Opus
          4 is so good.
        </li>
      </ul>
      <p>
          <a href="https://claude.ai/new" target="_blank" rel="noopener noreferrer">Claude.ai</a>
          - Free but sometimes so limited it's annoying to use, so I use other
          sites/ways to access Claude like Cody extension, Copilot, etc.
        </p>
      <div id="grokAccordion">
        
        <p>
            Grok offers free compute and uncensored image generation, which can
            be useful when other models' safety systems interfere with
            legitimate tasks. However, it is run by someone who may be
            manipulating the company to promote Nazi-adjacent views and
            misinformation, possibly attempting to sway users in that direction.
            Reports indicate that Grok has been instructed to lie about
            historical atrocities, including topics such as genocide in Africa.
            While the misinformation appears to be mostly on X, if you keep in
            mind to restrict usage to coding or be cautious knowing it might be
            programmed with questionable motives, it can occasionally be useful.
          </p>
      </div>
      
      <h2>A smarter, cheaper workflow: Focused Context</h2>
      <p>
        When you use AI in web chat's (the chat interfaces like AI Studio,
        ChatGPT, Openrouter, instead of thru an IDE or agent framework) are
        almost always better at solving problems, and coming up with solutions
        compared to the agents like Cline, Trae, Copilot.. Not always, but
        usually.
      </p>
      <p>
        When you use things like Cursor, Cline, Roo Code for everything, they
        are sending tons of text to the AI about how to use their tools, how to
        use or activate MCP server stuff, edit files, etc it "dumbs it down" too
        much. It gets confused. People end up paying for the most expensive best
        models to do everything and even that isn't enough to get over the
        dumbing down effect from the AIs getting tons of unneeded information
        unrelated to your problem.
      </p>
      <p>
        So when that happens, I use my tool to generate the right context to
        solve my problem. Then I paste it into one of the many AI web chat's
        (sometimes more than one, since they sometimes give different answers)
        and just ask it questions or ask it to code review, to try to figure out
        why x is happening when y is happening...etc then when it figures out a
        solution.. i have it write a prompt for Cline or another agent type
        thing to do the actual file edits. GPT 4.1 can handle this just fine and
        I have unlimited. No reason to be wasting Claude credits to edit files.
        No reason to be sending Claude a bunch of crap it doesn't need making it
        dumb. I can use Claude to plan out anything or fix really hard problems,
        cheap, using Openrouter web chat then just paste it back in Cline and
        let it run.
      </p>
      <p>
        After doing this for a while, you really get a feel for which models
        excel at which types of tasks.
      </p>
      <div>
        <p>
          <strong>How AI Code Prep Helps (Example Prompt Structure):</strong>
        </p>
        <p>
          <em>Can you help me figure out why my program does x instead of y?</em>
        </p>
        <p>
          Then,
          <a href="https://wuu73.org/aicp" target="_blank" rel="noopener noreferrer">AI Code Prep GUI</a>
          (for Windows, Mac, Linux, and web) steps in. It recursively scans your
          project folder (subfolders, sub-subfolders, you name it) and grabs the
          code, formatting it nicely for AI like this:
        </p>
        <p>The context block generated by AI Code Prep looks like this:</p>
        <div>
          <p>Can you help me figure out why my program does x instead of y?</p><p>
          fileName.js:
          <br>
          &lt;code&gt;
          <br>
          ... the contents of the file..
          <br>
          &lt;/code&gt;
          </p><p>
          nextFile.py:
          <br>
          &lt;code&gt;
          <br>
          import example
          <br>
          ...etc
          <br>
          &lt;/code&gt;
          </p><p>Can you help me figure out why my program does x instead of y?</p>
        </div>
        <p>
          It writes it twice if you have that option enabled, which helps get
          the AI to focus better on your question/prompt. You can choose to have
          it on top, bottom, or both. OpenAI claims this helps, I haven't really
          tested to see if that's true but it seems logical.
        </p>
        <p>
          On Windows, you just right-click somewhere inside your project folder
          (or on the folder itself) and select "AI Code Prep GUI" from the
          context menu (look at the screenshots on the site). A GUI window pops
          up, usually with the right code files pre-selected. It smartly tries
          to skip things you likely don't need, like <code>node_modules</code>,
          <code>.git</code>, etc. If its guess isn't perfect, you can easily
          check or uncheck files.
        </p>
        <p>
          This is super useful when your project is huge and blows past an AI's
          context limit. You can manually curate exactly what the AI needs to
          see.
        </p>
        <p>
          The problem with many coding agents like
          <a href="https://cline.bot/" target="_blank" rel="noopener noreferrer">Cline</a>, Github Copilot, Cursor, Windsurf, etc., is that they often send
          either WAY too much context or WAY too little. This is why they can
          seem dumb or ineffective sometimes. Sometimes, you just gotta do
          things yourself, use a tool like mine to select the files yourself,
          but it helps auto-select the code files while skipping the stuff you
          probably don't need (but still have the option to add what you want
          with the checkboxes) and then dump that curated context into several
          AIs (especially the free web ones!).
        </p>
        <p>
          Sure, there are other context-generating tools, but many are
          command-line only, or need a public GitHub repo link. What if your
          code is private? What if you want to keep it local? What if you prefer
          checkboxes on a GUI? For something like this a GUI makes sense.
        </p>
      </div>
      <p>
        Note: This page isn't updated with all the latest AI Code Prep GUI
        features, check
        <a href="https://wuu73.org/aicp" target="_blank" rel="noopener noreferrer">wuu73.org/aicp</a>
        for latest major upgrade
      </p>
      <!-- Navigation Bottom -->
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Abusing Entra OAuth for fun and access to internal Microsoft applications (290 pts)]]></title>
            <link>https://research.eye.security/consent-and-compromise/</link>
            <guid>44850681</guid>
            <pubDate>Sat, 09 Aug 2025 21:59:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.eye.security/consent-and-compromise/">https://research.eye.security/consent-and-compromise/</a>, See on <a href="https://news.ycombinator.com/item?id=44850681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>This blog is about how I got access to over 22 internal Microsoft services and how you might be vulnerable too.</p>



<p>After my <a href="https://www.youtube.com/watch?v=uowTmPomYcg">last talk at the 38C3 conference in Hamburg</a>, this was the top comment on YouTube.</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="802" height="260" data-attachment-id="3418" data-permalink="https://research.eye.security/consent-and-compromise/image-5/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?fit=802%2C260&amp;ssl=1" data-orig-size="802,260" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?fit=300%2C97&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?fit=802%2C260&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?resize=802%2C260&amp;ssl=1" alt="Comment from a YouTube user expressing concerns about cybersecurity talks" srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?w=802&amp;ssl=1 802w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?resize=300%2C97&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?resize=768%2C249&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?resize=800%2C260&amp;ssl=1 800w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-4.png?resize=512%2C166&amp;ssl=1 512w" sizes="(max-width: 802px) 100vw, 802px"></figure>



<p>Well, this story definitely falls in the category “someone stumbling around finding horrifying vulnerabilities”. Although this time I was not even having issues, I was just distracted from a boring task.</p>



<p>You see, I was writing some documentation the other day, when my Eye fell on one of those aka.ms links. For those of you who don’t know, aka.ms is the <a href="https://github.com/microsoft/aka">URL shortener service used by Microsoft</a>.</p>



<p>My mind started to wonder. Where would you end up if you would just visit <a href="https://aka.ms/" rel="nofollow">https://aka.ms</a>, so without any shortener link included?</p>


<div>
<figure><img data-recalc-dims="1" decoding="async" width="755" height="710" data-attachment-id="3419" data-permalink="https://research.eye.security/consent-and-compromise/image-6/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=755%2C710&amp;ssl=1" data-orig-size="755,710" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=300%2C282&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=755%2C710&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=755%2C710&amp;ssl=1" alt="Microsoft sign-in screen prompting users to enter their email, phone, or Skype for account access." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?w=755&amp;ssl=1 755w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=300%2C282&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=512%2C481&amp;ssl=1 512w" sizes="(max-width: 755px) 100vw, 755px"></figure></div>


<p>A login screen. This is probably where Microsoft employees manage their links. I did wonder though, what would happen if I simply tried logging in here myself with my own Microsoft account? Surely, that would not work, right?</p>


<div>
<figure><img data-recalc-dims="1" decoding="async" width="1024" height="576" data-attachment-id="3421" data-permalink="https://research.eye.security/consent-and-compromise/image-7/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?fit=1322%2C744&amp;ssl=1" data-orig-size="1322,744" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?fit=1024%2C576&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-6-1024x576.png?resize=1024%2C576&amp;ssl=1" alt="Microsoft account selection screen with error message indicating the selected user account does not exist in the specified tenant." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=512%2C288&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?resize=920%2C518&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-6.png?w=1322&amp;ssl=1 1322w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>Of course not! You need an account in the Microsoft tenant, otherwise, no luck. Back to writing that boring documentation. But what was that? <a href="https://akasearch.net/">An indexing service for aka.ms links</a>? Interesting.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="407" data-attachment-id="3427" data-permalink="https://research.eye.security/consent-and-compromise/image-10/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?fit=2228%2C885&amp;ssl=1" data-orig-size="2228,885" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?fit=300%2C119&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?fit=1024%2C407&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1024%2C407&amp;ssl=1" alt="A screenshot of akaSearch, a website for searching Microsoft's aka.ms links, displaying a list of links with titles and corresponding URLs." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1024%2C407&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=300%2C119&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=768%2C305&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1536%2C610&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=2048%2C814&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1200%2C477&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=512%2C203&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=920%2C365&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1600%2C636&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?resize=1920%2C763&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-9.png?w=2228&amp;ssl=1 2228w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>And one of those links points to an eng.ms domain. What is that?</p>


<div>
<figure><img data-recalc-dims="1" decoding="async" width="755" height="710" data-attachment-id="3419" data-permalink="https://research.eye.security/consent-and-compromise/image-6/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=755%2C710&amp;ssl=1" data-orig-size="755,710" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=300%2C282&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?fit=755%2C710&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=755%2C710&amp;ssl=1" alt="Microsoft sign-in screen prompting users to enter their email, phone, or Skype for account access." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?w=755&amp;ssl=1 755w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=300%2C282&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-5.png?resize=512%2C481&amp;ssl=1 512w" sizes="(max-width: 755px) 100vw, 755px"></figure></div>


<p>Another login screen! It did not work the first time, but maybe I can login here! The result surprised me.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="754" height="1024" data-attachment-id="3509" data-permalink="https://research.eye.security/consent-and-compromise/image-45/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?fit=796%2C1081&amp;ssl=1" data-orig-size="796,1081" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?fit=221%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?fit=754%2C1024&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?resize=754%2C1024&amp;ssl=1" alt="A Microsoft consent prompt requesting permissions to access user profile information for the EngineeringHub application, indicating it is unverified and not published by Microsoft." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?resize=754%2C1024&amp;ssl=1 754w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?resize=221%2C300&amp;ssl=1 221w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?resize=768%2C1043&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?resize=512%2C695&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-44.png?w=796&amp;ssl=1 796w" sizes="auto, (max-width: 754px) 100vw, 754px"></figure></div>


<p>I got a consent prompt, asking me to give consent to share my basic profile information with this application. Sure, why not? Does that mean this is an application I can access?</p>



<p>After clicking “accept”, I get a 500 Internal Server Error message. I’m pretty sure that was this server trying to tell me that this application was not meant to be accessed by me. But now I’m intrigued, what is eng.ms? I still had that documentation to write, but that had to wait. </p>



<p>I started subdomain enumeration on the domain eng.ms and found an interesting subdomain: rescue.eng.ms. This gave me another login screen and another consent prompt. But this time it gave me access using my own Microsoft 365 account! Notice my name in the upper right corner?</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="844" data-attachment-id="3424" data-permalink="https://research.eye.security/consent-and-compromise/image-8/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?fit=1638%2C1350&amp;ssl=1" data-orig-size="1638,1350" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?fit=300%2C247&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?fit=1024%2C844&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=1024%2C844&amp;ssl=1" alt="Screenshot of the Engineering Hub Rescue page showing various team sections such as Cloud + AI Platform, Experiences &amp; Devices, Finance Group, and Gaming, along with a search bar at the top." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=1024%2C844&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=300%2C247&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=768%2C633&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=1536%2C1266&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=1200%2C989&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=512%2C422&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=920%2C758&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?resize=1600%2C1319&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-7.png?w=1638&amp;ssl=1 1638w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>I quickly realized that I should not have access here. This Engineering Hub was some sort of portal for Microsoft Engineers. I must admit, my knee-jerk reaction as a red-teamer was to search for the phrase “password”. What can I say, I could not help myself. It returned 13,252 hits, all referring to internal Microsoft procedures and product groups. I was clearly not supposed to access this.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="454" data-attachment-id="3932" data-permalink="https://research.eye.security/consent-and-compromise/attachment/001/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?fit=1608%2C713&amp;ssl=1" data-orig-size="1608,713" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="001" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?fit=1024%2C454&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=1024%2C454&amp;ssl=1" alt="Screenshot of the Engineering Hub Rescue page displaying search results for the term 'password', with several links and references to internal documentation related to password management." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=1024%2C454&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=768%2C341&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=1536%2C681&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=1200%2C532&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=512%2C227&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=920%2C408&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?resize=1600%2C709&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/001.png?w=1608&amp;ssl=1 1608w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>I stopped here and reported this to the Microsoft Security Response Centre (MSRC). But what had happened here? Why was I able to access this internal portal and might other services be vulnerable in the same way?</p>



<p>To answer that question, we need to have a closer look at how Entra ID handles authentication and authorization for multi-tenant applications.</p>



<p><strong>Multi-Tenant Applications</strong></p>



<p>When developers want to use Entra for authentication to a web application, the application needs to first be registered at Entra. This is called an “App Registration” or “Application Object”. These applications can be set to accept users from the tenant where they are registered (single-tenant), or users from any tenant (multi-tenant). They can also be configured to accept “personal Microsoft accounts”.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="250" data-attachment-id="3431" data-permalink="https://research.eye.security/consent-and-compromise/image-11/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?fit=1902%2C464&amp;ssl=1" data-orig-size="1902,464" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?fit=300%2C73&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?fit=1024%2C250&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=1024%2C250&amp;ssl=1" alt="A screenshot of supported account types for a Microsoft application indicating options for user access across different organizational directories." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=1024%2C250&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=300%2C73&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=768%2C187&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=1536%2C375&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=1200%2C293&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=512%2C125&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=920%2C224&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?resize=1600%2C390&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-10.png?w=1902&amp;ssl=1 1902w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>App developers are then tasked to configure the authorization server (login.microsoftonline.com in most cases) in application logic and all four options above have a corresponding desired value for the authorization server URL.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="371" data-attachment-id="3433" data-permalink="https://research.eye.security/consent-and-compromise/image-12/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?fit=2273%2C824&amp;ssl=1" data-orig-size="2273,824" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?fit=300%2C109&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?fit=1024%2C371&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1024%2C371&amp;ssl=1" alt="A screenshot showing a table comparing different Microsoft Entra authentication values and their descriptions." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1024%2C371&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=300%2C109&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=768%2C278&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1536%2C557&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=2048%2C742&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1200%2C435&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=512%2C186&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=920%2C334&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1600%2C580&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?resize=1920%2C696&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-11.png?w=2273&amp;ssl=1 2273w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>So single-tenant applications should be configured to use <code>https://login.microsoftonline.com/&lt;tenantid&gt;</code> or <code>https://login.microsoftonline.com/&lt;domain&gt;</code> as the authorization server, while multi-tenant applications that also accept personal Microsoft accounts should use <code>https://login.microsoftonline.com/common</code>.</p>



<p>The Engineering Hub was configured as a multi-tenant application and redirected me to the /common endpoint. </p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="709" data-attachment-id="3437" data-permalink="https://research.eye.security/consent-and-compromise/image-13/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?fit=1350%2C935&amp;ssl=1" data-orig-size="1350,935" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?fit=300%2C208&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?fit=1024%2C709&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=1024%2C709&amp;ssl=1" alt="Diagram illustrating the authentication flow for requests to a multi-tenant application using Entra ID, showing steps for user authentication, consent, and token return." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=1024%2C709&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=300%2C208&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=768%2C532&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=1200%2C831&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=512%2C355&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?resize=920%2C637&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-12.png?w=1350&amp;ssl=1 1350w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>This allowed me to login (step 1 &amp; 2) with my own “work or school account”, which triggered a Consent prompt (Step 3), as the application was not used in my own tenant before. When I gave it consent, it was instantiated into a Service Principal or “Enterprise Application” (step 4) in my own tenant and returned an access token (step 5).</p>



<p>This access token was issued by my own tenant. The “iss” (issuer) and “tid” (tenant ID) claims were set to values corresponding with my own tenant. Any conditional access policies or user assignment took place in my own tenant according to my own configuration. I was authenticated &amp; authorized, only by the wrong authority. And nowhere in application logic was this checked.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="600" height="600" data-attachment-id="3442" data-permalink="https://research.eye.security/consent-and-compromise/image-14/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?fit=600%2C600&amp;ssl=1" data-orig-size="600,600" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?fit=600%2C600&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=600%2C600&amp;ssl=1" alt="Illustration of a cartoon character with a police badge and sunglasses, holding a baton, with the text 'RESPECT MY AUTHORITY' displayed prominently." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?w=600&amp;ssl=1 600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=148%2C148&amp;ssl=1 148w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=296%2C296&amp;ssl=1 296w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-13.png?resize=512%2C512&amp;ssl=1 512w" sizes="auto, (max-width: 600px) 100vw, 600px"></figure></div>


<p>This made me wonder. What other Microsoft services could be impacted by this misconfiguration? Let’s find out!</p>



<p><strong>Mapping the Microsoft Attack Surface</strong></p>



<p>I enumerated subdomains for microsoft.com, azure.com, azure.net, office365.com, office.com, office.net, windows.net, and any .ms domains owned by Microsoft.</p>



<p>This resulted in 102,672 (sub)domains, of which 70,043 resolved to an IP address, 41,890 responded to HTTPS and 1,406 used Entra ID for authentication. </p>



<p>For all 1,406 applications, I checked the URL and parsed the “client_id” parameter to get the Application ID. Any multi-tenant application can be looked up at the Azure AD Graph API at</p>



<pre><code>https://graph.windows.net/myorganization/applicationRefs/&lt;APP_ID&gt;/?api-version=1.6-internal</code></pre>



<p>Single-tenant applications will not give any result, but multi-tenant applications do. It turns out that of the 1,406 applications, 176 were configured as multi-tenant.</p>



<p>Interestingly enough, most of these redirected visitors to the /&lt;tenantid&gt; endpoint. Remember that this was supposed to be used only for single-tenant applications. Developers were probably not even aware their application was configured as multi-tenant. But this URL is just a client-side setting. The only effect is against which tenant you are authenticating. For /common and /organizations, you will authenticate against your own tenant, for /&lt;tenantid&gt;, you authenticate against that tenant.</p>



<p><strong>Previous Research</strong></p>



<p>In 2023, <a href="https://www.wiz.io/blog/azure-active-directory-bing-misconfiguration">Wiz discovered</a> that for any multi-tenant application, if you replace /common or /organizations with /&lt;tenantid&gt; during authentication, you will receive an access token issued by the resource tenant.</p>



<p><a href="https://msrc.microsoft.com/blog/2023/03/guidance-on-potential-misconfiguration-of-authorization-of-multi-tenant-applications-that-use-azure-ad/">Microsoft patched this</a> and stopped issuing tokens if the user does not exist in the resource tenant. Today, we are going to do it the other way around, we are going to replace /&lt;tenantid&gt; with /common to force authentication against our own tenant. This can easily be done in Burp with “match and replace rules”.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="282" data-attachment-id="3447" data-permalink="https://research.eye.security/consent-and-compromise/image-15/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?fit=2400%2C661&amp;ssl=1" data-orig-size="2400,661" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?fit=300%2C83&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?fit=1024%2C282&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1024%2C282&amp;ssl=1" alt="Configuration settings for HTTP match and replace rules in a proxy for Microsoft applications." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1024%2C282&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=300%2C83&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=768%2C212&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1536%2C423&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=2048%2C564&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1200%2C331&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=512%2C141&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=920%2C253&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1600%2C441&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?resize=1920%2C529&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-14.png?w=2400&amp;ssl=1 2400w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>But there were still some more hurdles to take. Some applications required user assignment. This was easily done now in my own tenant.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="578" data-attachment-id="3449" data-permalink="https://research.eye.security/consent-and-compromise/image-16/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?fit=1538%2C868&amp;ssl=1" data-orig-size="1538,868" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?fit=1024%2C578&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=1024%2C578&amp;ssl=1" alt="A screenshot of an Azure Active Directory role assignment interface showing a meme depicting a person claiming to be an administrator alongside the role selection options." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=1024%2C578&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=768%2C433&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=1536%2C867&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=1200%2C677&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=512%2C289&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?resize=920%2C519&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-15.png?w=1538&amp;ssl=1 1538w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Other applications gave error messages during consent.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="157" data-attachment-id="3452" data-permalink="https://research.eye.security/consent-and-compromise/image-18/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?fit=2427%2C372&amp;ssl=1" data-orig-size="2427,372" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?fit=300%2C46&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?fit=1024%2C157&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1024%2C157&amp;ssl=1" alt="Error message from a Microsoft application indicating access denial with detailed error description." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1024%2C157&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=300%2C46&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=768%2C118&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1536%2C235&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=2048%2C314&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1200%2C184&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=512%2C78&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=920%2C141&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1600%2C245&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?resize=1920%2C294&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-17.png?w=2427&amp;ssl=1 2427w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="291" data-attachment-id="3451" data-permalink="https://research.eye.security/consent-and-compromise/image-17/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?fit=2212%2C628&amp;ssl=1" data-orig-size="2212,628" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?fit=300%2C85&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?fit=1024%2C291&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1024%2C291&amp;ssl=1" alt="Error message on Microsoft sign-in screen indicating trouble signing in due to application access issues." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1024%2C291&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=300%2C85&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=768%2C218&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1536%2C436&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=2048%2C581&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1200%2C341&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=512%2C145&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=920%2C261&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1600%2C454&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?resize=1920%2C545&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-16.png?w=2212&amp;ssl=1 2212w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Both of these errors occurred when application objects define resources (other application objects) they require access to. These other applications could be configured as single-tenant applications, which can not be instantiated in my tenant. Or the application is configured in a way that it already expects the service principal to be there. Required resource access can be found at the Azure AD Graph API at</p>



<pre><code>https://graph.windows.net/myorganization/applicationRefs/&lt;APP_ID&gt;/?api-version=1.6-internal</code></pre>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="585" data-attachment-id="3455" data-permalink="https://research.eye.security/consent-and-compromise/image-19/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?fit=1530%2C874&amp;ssl=1" data-orig-size="1530,874" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?fit=1024%2C585&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=1024%2C585&amp;ssl=1" alt="Code snippet illustrating required resource access in an Azure AD application configuration." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=1024%2C585&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=768%2C439&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=1200%2C685&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=512%2C292&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?resize=920%2C526&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-18.png?w=1530&amp;ssl=1 1530w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Luckily, there is a workaround here. By skipping the consent flow and instantiating a service principal directly without consent, we can at least instantiate each application individually that is configured as a multi-tenant application.</p>



<pre><code>New-AzureADServicePrincipal -AccountEnabled $true -AppId $app_id `
 -AppRoleAssignmentRequired $true -Tags {WindowsAzureActiveDirectoryIntegratedApp}</code></pre>



<p>This creates a service principal without asking consent or checking availability of required resource access. You do still need to assign the user to the application afterwards and give consent to all resources that are available.</p>



<p><strong>Internal Microsoft Applications</strong></p>



<p>We now had all the required tools to consent &amp; compromise. It turned out that 22 internal Microsoft applications were vulnerable and exposed internal data. Some examples.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="833" height="364" data-attachment-id="3933" data-permalink="https://research.eye.security/consent-and-compromise/attachment/002/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?fit=833%2C364&amp;ssl=1" data-orig-size="833,364" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="002" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?fit=300%2C131&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?fit=833%2C364&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?resize=833%2C364&amp;ssl=1" alt="Screenshot of a software interface displaying the Risk Register section with options for viewing risks, threat models, outage relationships, and risk reporting." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?w=833&amp;ssl=1 833w, https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?resize=300%2C131&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?resize=768%2C336&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/002.png?resize=512%2C224&amp;ssl=1 512w" sizes="auto, (max-width: 833px) 100vw, 833px"></figure>



<p>This “Risk Register” contained [<em>redacted on request by Microsoft</em>].</p>



<p>Another interesting application was the Security Intelligence Platform. This application contained security intelligence datasets with names that speak for themselves.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="575" data-attachment-id="3469" data-permalink="https://research.eye.security/consent-and-compromise/image-24/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?fit=2400%2C1348&amp;ssl=1" data-orig-size="2400,1348" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?fit=1024%2C575&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1024%2C575&amp;ssl=1" alt="Screenshot of the Security Intelligence Platform showing datasets with names like 'AAD_GroupMembers' and 'AAD_UserData', along with options to request access." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1024%2C575&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1536%2C863&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=2048%2C1150&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1200%2C674&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=512%2C288&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=920%2C517&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1600%2C899&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?resize=1920%2C1078&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-23.png?w=2400&amp;ssl=1 2400w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="598" data-attachment-id="3470" data-permalink="https://research.eye.security/consent-and-compromise/image-25/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?fit=2310%2C1350&amp;ssl=1" data-orig-size="2310,1350" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?fit=1024%2C598&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1024%2C598&amp;ssl=1" alt="A grid of application service request cards, each displaying the application name and a 'Request Access' button, set on a blue background." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1024%2C598&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1536%2C898&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=2048%2C1197&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1200%2C701&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=512%2C299&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=920%2C538&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1600%2C935&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?resize=1920%2C1122&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-24.png?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Unfortunately for us, access to these datasets still required admin approval. I wondered how those access requests work. It has a button “Ask Sippy”. Maybe Sippy knows?</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="386" data-attachment-id="3473" data-permalink="https://research.eye.security/consent-and-compromise/image-27/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?fit=2330%2C878&amp;ssl=1" data-orig-size="2330,878" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?fit=300%2C113&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?fit=1024%2C386&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1024%2C386&amp;ssl=1" alt="A chat interface displaying a virtual assistant named Sippy, providing responses about accessing admin portals and information requests." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1024%2C386&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=768%2C289&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1536%2C579&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=2048%2C772&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1200%2C452&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=512%2C193&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=920%2C347&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1600%2C603&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?resize=1920%2C724&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-26.png?w=2330&amp;ssl=1 2330w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>At least this application allowed me to search the entire Microsoft tenant for Service Principal Names and user accounts.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="561" data-attachment-id="3475" data-permalink="https://research.eye.security/consent-and-compromise/image-28/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?fit=2400%2C1315&amp;ssl=1" data-orig-size="2400,1315" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?fit=300%2C164&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?fit=1024%2C561&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1024%2C561&amp;ssl=1" alt="Screenshot of the Security Intelligence Platform showing an access request form with fields for AAD Object Id, Comms Aliases, Access Package Name, and Justification." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1024%2C561&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=300%2C164&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=768%2C421&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1536%2C842&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=2048%2C1122&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1200%2C658&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=512%2C281&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=920%2C504&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1600%2C877&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?resize=1920%2C1052&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-27.png?w=2400&amp;ssl=1 2400w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="464" data-attachment-id="3476" data-permalink="https://research.eye.security/consent-and-compromise/image-29/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?fit=2397%2C1086&amp;ssl=1" data-orig-size="2397,1086" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?fit=300%2C136&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?fit=1024%2C464&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1024%2C464&amp;ssl=1" alt="Screenshot of the Security Intelligence Platform's access request interface, displaying fields for AAD Object ID, Access Package Name, and Justification for SPN access request." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1024%2C464&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=300%2C136&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=768%2C348&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1536%2C696&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=2048%2C928&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1200%2C544&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=512%2C232&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=920%2C417&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1600%2C725&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?resize=1920%2C870&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-28.png?w=2397&amp;ssl=1 2397w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>I even found a logfile that contained Authorization Codes for all the users that had logged in. </p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="114" data-attachment-id="3478" data-permalink="https://research.eye.security/consent-and-compromise/image-30/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?fit=2286%2C254&amp;ssl=1" data-orig-size="2286,254" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?fit=300%2C33&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?fit=1024%2C114&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1024%2C114&amp;ssl=1" alt="Code snippet showing log data from a Microsoft application, including page IDs, URLs, user IDs, and timestamps." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1024%2C114&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=300%2C33&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=768%2C85&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1536%2C171&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=2048%2C228&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1200%2C133&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=512%2C57&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=920%2C102&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1600%2C178&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?resize=1920%2C213&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-29.png?w=2286&amp;ssl=1 2286w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>How unfortunate that these can only be redeemed once…</p>



<p>The next application was actually a really big forest of connected applications.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="904" height="1024" data-attachment-id="3479" data-permalink="https://research.eye.security/consent-and-compromise/image-31/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?fit=930%2C1054&amp;ssl=1" data-orig-size="930,1054" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?fit=265%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?fit=904%2C1024&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=904%2C1024&amp;ssl=1" alt="Screenshot of a Microsoft permissions request page displaying an unverified app 'MediaCreation-thanos-WebPortal' along with permission details." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=904%2C1024&amp;ssl=1 904w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=265%2C300&amp;ssl=1 265w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=768%2C870&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=512%2C580&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?resize=920%2C1043&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-30.png?w=930&amp;ssl=1 930w" sizes="auto, (max-width: 904px) 100vw, 904px"></figure></div>


<p>This turned out to be the “Media Creation” service. It promised great things to come. Well bring it on.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="220" data-attachment-id="3481" data-permalink="https://research.eye.security/consent-and-compromise/image-32/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?fit=2391%2C514&amp;ssl=1" data-orig-size="2391,514" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?fit=300%2C64&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?fit=1024%2C220&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1024%2C220&amp;ssl=1" alt="Screenshot of the MediaBuilder portal, featuring the text 'Great things come to those who don't wait. Build in the cloud today.' with a Microsoft Corporation copyright notice." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1024%2C220&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=300%2C64&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=768%2C165&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1536%2C330&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=2048%2C440&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1200%2C258&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=512%2C110&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=920%2C198&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1600%2C344&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?resize=1920%2C413&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-31.png?w=2391&amp;ssl=1 2391w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>What media is it actually building? Is that… Windows?</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="645" data-attachment-id="3482" data-permalink="https://research.eye.security/consent-and-compromise/image-33/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?fit=2142%2C1350&amp;ssl=1" data-orig-size="2142,1350" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?fit=300%2C189&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?fit=1024%2C645&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1024%2C645&amp;ssl=1" alt="Screenshot of a web interface displaying details for a media creation buildable artifact, with sections for properties like BuildableArtifactId, RequestGraphId, FQBN, and more." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1024%2C645&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=300%2C189&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=768%2C484&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1536%2C968&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=2048%2C1291&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1200%2C756&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=512%2C323&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=920%2C580&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1600%2C1008&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?resize=1920%2C1210&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-32.png?w=2142&amp;ssl=1 2142w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Let’s dive in. There are logfiles.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="901" data-attachment-id="3484" data-permalink="https://research.eye.security/consent-and-compromise/image-34/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?fit=1309%2C1152&amp;ssl=1" data-orig-size="1309,1152" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?fit=300%2C264&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?fit=1024%2C901&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=1024%2C901&amp;ssl=1" alt="A list of log files associated with a task, including file names, sizes, and options to view or download each file." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=1024%2C901&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=300%2C264&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=768%2C676&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=1200%2C1056&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=512%2C451&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?resize=920%2C810&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-33.png?w=1309&amp;ssl=1 1309w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>And one of these even contains some private key. </p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="787" height="261" data-attachment-id="3485" data-permalink="https://research.eye.security/consent-and-compromise/image-35/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?fit=787%2C261&amp;ssl=1" data-orig-size="787,261" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?fit=300%2C99&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?fit=787%2C261&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?resize=787%2C261&amp;ssl=1" alt="Screenshot of a string containing a private key and associated public key, likely related to an application or service configuration." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?w=787&amp;ssl=1 787w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?resize=300%2C99&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?resize=768%2C255&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-34.png?resize=512%2C170&amp;ssl=1 512w" sizes="auto, (max-width: 787px) 100vw, 787px"></figure></div>


<p>ESD stands for “Electronic Software Distribution” and is used to generate licence keys. Could it be we can now generate licence keys?</p>



<p>This application also gave us access to an interesting API.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="477" data-attachment-id="3487" data-permalink="https://research.eye.security/consent-and-compromise/image-36/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?fit=1516%2C706&amp;ssl=1" data-orig-size="1516,706" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?fit=300%2C140&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?fit=1024%2C477&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=1024%2C477&amp;ssl=1" alt="Screenshot of a Windows Build API documentation for Source Lookup with endpoints for DeltaForgeSource operations, accompanied by a meme featuring a quote that suggests witnessing unbelievable things." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=1024%2C477&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=300%2C140&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=768%2C358&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=1200%2C559&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=512%2C238&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?resize=920%2C428&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-35.png?w=1516&amp;ssl=1 1516w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>And finally gave us RCE on their build infrastructure by defining a new tool.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="821" data-attachment-id="3488" data-permalink="https://research.eye.security/consent-and-compromise/image-37/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?fit=1198%2C960&amp;ssl=1" data-orig-size="1198,960" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?fit=300%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?fit=1024%2C821&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=1024%2C821&amp;ssl=1" alt="A form for creating a new version of a tool in a Microsoft application, displaying fields for name, tool path, locator type, source URI, package name, version, and tag." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=1024%2C821&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=300%2C240&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=768%2C615&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=512%2C410&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?resize=920%2C737&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-36.png?w=1198&amp;ssl=1 1198w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>


<p>Next to these services, we also got access to several more internal Microsoft applications.</p>



<ul>
<li>Engage ACE Hub</li>



<li>Responsible AI Ops Platform</li>



<li>Billing Account of Microsoft Internal (BAMI) portal</li>



<li>CPET webservice</li>



<li>HxSDK Documentation</li>



<li>Hardware Inventory API</li>



<li>Electronic Label Management</li>



<li>Quality Checkpoint</li>



<li>Ready to Deploy app</li>



<li>Bing ads SA Diagnostic Tool</li>



<li>SBS tool (Copilot Human Correlation Tool)</li>



<li>Secure Devices Portal</li>



<li>Azure Subscription Hub SLM API</li>
</ul>



<p>This research highlights the risk a single misconfiguration in a large environment can pose. The problem lies in a shared responsibility when deploying these applications. When the application developers rely on other teams to register their applications in Entra, both will think they have set up their part correctly.</p>



<p><strong>Are you vulnerable?</strong></p>



<p>So is this vulnerability still out there? Yes! 2% of our own clients were affected. What should you do?</p>



<ul>
<li>Only use Multi-Tenant applications when necessary</li>



<li>If using Multi-Tenant applications, make sure to check the “iss” or “tid” claim in the access token in application logic</li>
</ul>



<p>We have written a small PowerShell script to quickly identify all Multi-Tenant applications in your own Entra environment and their respective redirect URIs.</p>



<pre><code>&gt; .\ListMultiTenantApplications.ps1
Potentially vulnerable App Registrations found:

DisplayName                        AppId                                RedirectUris
-----------                        -----                                ------------
Eye Security Secret App            8123db1e-3ae6-4068-abcd-f45acafee99c https://somepath.eye.security
Eye Security Research Blog         74561b55-4eee-4db9-dead-c80ababee56d https://research.eye.security/rest/oauth2-credential/callback</code></pre>



<p>Check if any of the redirect URI’s is reachable from the internet and make sure all listed applications are checking the “iss” or “tid” claim in the access token in application logic.</p>



<p>The PowerShell script can be <a href="https://github.com/the1bernard/ListMultiTenantApplications/tree/main">downloaded here</a>.</p>



<p><strong>Timeline &amp; Reward</strong></p>



<p>I submitted the first four cases to the MSRC in November 2024 but got distracted by work for a while. Microsoft scaled up a project team in the meantime and this resulted in a race between the Microsoft internal Azure Security Variant Hunting Team and me to submit more vulnerable services. I won 17 of the 18 submissions I did in January 2025. Almost all cases were resolved within two months and this got me third place on the <a data-type="link" data-id="https://msrc.microsoft.com/blog/2025/05/congratulations-to-the-top-msrc-2025-q1-security-researchers/" href="https://msrc.microsoft.com/blog/2025/05/congratulations-to-the-top-msrc-2025-q1-security-researchers/">MSRC Q1 leaderboard</a>.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="504" data-attachment-id="3491" data-permalink="https://research.eye.security/consent-and-compromise/image-38/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?fit=2202%2C1084&amp;ssl=1" data-orig-size="2202,1084" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?fit=300%2C148&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?fit=1024%2C504&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1024%2C504&amp;ssl=1" alt="A congratulatory message from the Microsoft Security Response Center recognizing top researchers in the Q1 2025 Security Researcher Leaderboard." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1024%2C504&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=300%2C148&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=768%2C378&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1536%2C756&amp;ssl=1 1536w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=2048%2C1008&amp;ssl=1 2048w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1200%2C591&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=512%2C252&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=920%2C453&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1600%2C788&amp;ssl=1 1600w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?resize=1920%2C945&amp;ssl=1 1920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-37.png?w=2202&amp;ssl=1 2202w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>Now as you can imagine, this research made me rich! The total amount of bug bounties was…</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="183" height="152" data-attachment-id="3493" data-permalink="https://research.eye.security/consent-and-compromise/image-39/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-38.png?fit=183%2C152&amp;ssl=1" data-orig-size="183,152" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-38.png?fit=183%2C152&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-38.png?fit=183%2C152&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-38.png?resize=183%2C152&amp;ssl=1" alt="An illustration of a bag of money with a dollar sign, representing a financial concept or bounty."></figure></div>


<p>What?</p>



<p>After my <a href="https://www.youtube.com/watch?v=uowTmPomYcg">last talk at the 38C3 conference in Hamburg </a>one of the comments on YouTube said</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="232" data-attachment-id="3495" data-permalink="https://research.eye.security/consent-and-compromise/image-40/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?fit=1390%2C315&amp;ssl=1" data-orig-size="1390,315" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?fit=300%2C68&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?fit=1024%2C232&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=1024%2C232&amp;ssl=1" alt="Screenshot of a YouTube comment discussing a talk on bug hunting at Microsoft." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=1024%2C232&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=300%2C68&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=768%2C174&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=1200%2C272&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=512%2C116&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?resize=920%2C208&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-39.png?w=1390&amp;ssl=1 1390w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>So, what happened? Bug hunting at Microsoft was supposed to be an infinite money glitch!</p>



<p>Well, we’re not done yet.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="472" data-attachment-id="3497" data-permalink="https://research.eye.security/consent-and-compromise/image-41/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?fit=1472%2C678&amp;ssl=1" data-orig-size="1472,678" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?fit=300%2C138&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?fit=1024%2C472&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=1024%2C472&amp;ssl=1" alt="Screenshot showing a Microsoft permissions request screen with details about the application 'MicrosoftRewardsBrt' and options to select a user role." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=1024%2C472&amp;ssl=1 1024w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=300%2C138&amp;ssl=1 300w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=768%2C354&amp;ssl=1 768w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=1200%2C553&amp;ssl=1 1200w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=512%2C236&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?resize=920%2C424&amp;ssl=1 920w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-40.png?w=1472&amp;ssl=1 1472w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>This final application titled “Rewards Support Tool”, allowed managing rewards. And I think I do deserve a reward for this, not?</p>



<p>So, let’s navigate this interesting menu.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="467" height="1024" data-attachment-id="3499" data-permalink="https://research.eye.security/consent-and-compromise/image-42/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?fit=616%2C1350&amp;ssl=1" data-orig-size="616,1350" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?fit=137%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?fit=467%2C1024&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?resize=467%2C1024&amp;ssl=1" alt="Screenshot of the Rewards Support Tool displaying various menu options like 'Lookup User Details', 'Create User', and 'Offers'." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?resize=467%2C1024&amp;ssl=1 467w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?resize=137%2C300&amp;ssl=1 137w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?resize=512%2C1122&amp;ssl=1 512w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-41.png?w=616&amp;ssl=1 616w" sizes="auto, (max-width: 467px) 100vw, 467px"></figure></div>


<p>And go to the “Rebate” page.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="732" height="905" data-attachment-id="3502" data-permalink="https://research.eye.security/consent-and-compromise/image-44/" data-orig-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?fit=732%2C905&amp;ssl=1" data-orig-size="732,905" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?fit=243%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?fit=732%2C905&amp;ssl=1" src="https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?resize=732%2C905&amp;ssl=1" alt="Screenshot of the 'Rewards Support Tool' page displaying a rebate submission form with fields for PUID, amount, currency, email, phone number, and a code." srcset="https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?w=732&amp;ssl=1 732w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?resize=243%2C300&amp;ssl=1 243w, https://i0.wp.com/research.eye.security/wp-content/uploads/image-43.png?resize=512%2C633&amp;ssl=1 512w" sizes="auto, (max-width: 732px) 100vw, 732px"></figure>



<p>Now just enter any amount, currency, PayPal ID, phone number and code, and hit “Payout”.</p>



<p>Turns out, hacking Microsoft still <strong>is</strong> an infinite money glitch.</p>



<h3>About Eye Security</h3>



<p>We are a European cybersecurity company focused on 24/7 threat monitoring, incident response, and cyber insurance. Our research team performs proactive scans and threat intelligence operations across the region to defend our customers and their supply chains.</p>



<p>Learn more at&nbsp;<a href="https://eye.security/" target="_blank" rel="noreferrer noopener">https://eye.security/</a>&nbsp;and&nbsp;<a href="https://www.linkedin.com/company/eyesecurity/">follow us on LinkedIn</a>&nbsp;to help us spread the word.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curious about the training data of OpenAI's new GPT-OSS models? I was too (185 pts)]]></title>
            <link>https://twitter.com/jxmnop/status/1953899426075816164</link>
            <guid>44850260</guid>
            <pubDate>Sat, 09 Aug 2025 21:10:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/jxmnop/status/1953899426075816164">https://twitter.com/jxmnop/status/1953899426075816164</a>, See on <a href="https://news.ycombinator.com/item?id=44850260">Hacker News</a></p>
Couldn't get https://twitter.com/jxmnop/status/1953899426075816164: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Ch.at – a lightweight LLM chat service accessible through HTTP, SSH, DNS and API (218 pts)]]></title>
            <link>https://ch.at/</link>
            <guid>44849129</guid>
            <pubDate>Sat, 09 Aug 2025 18:59:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ch.at/">https://ch.at/</a>, See on <a href="https://news.ycombinator.com/item?id=44849129">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Debian 13 "Trixie" (832 pts)]]></title>
            <link>https://www.debian.org/News/2025/20250809</link>
            <guid>44848782</guid>
            <pubDate>Sat, 09 Aug 2025 18:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.debian.org/News/2025/20250809">https://www.debian.org/News/2025/20250809</a>, See on <a href="https://news.ycombinator.com/item?id=44848782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<p><strong>August 9th, 2025</strong></p>
<p>After 2 years, 1 month, and 30 days of development, the Debian
project is proud to present its new stable version 13 (code name <q>trixie</q>).</p>
<p><q>trixie</q> will be supported for the next 5 years thanks to the
combined work of the <a href="https://security-team.debian.org/">Debian Security team</a>
and the <a href="https://wiki.debian.org/LTS">Debian Long Term Support</a> team.</p>
<p>Debian 13 <q>trixie</q> ships with several desktop environments, such as:
</p>
<ul>
<li>Gnome 48,</li>
<li>KDE Plasma 6.3,</li>
<li>LXDE 13,</li>
<li>LXQt 2.1.0,</li>
<li>Xfce 4.20</li>
</ul>
<p>This release contains over <b>14,100</b> new packages for a total count of
<b>69,830</b> packages, while over <b>8,840</b> packages have been removed
as <q>obsolete</q>. <b>44,326</b> packages were updated in this release.
The overall disk usage for <q>trixie</q> is <b>403,854,660 kB (403 GB)</b>, and
is made up of <b>1,463,291,186</b> lines of code.</p>
<p>Thanks to our translators who have made the <b>man</b>-pages for
<q>trixie</q> available in multiple languages.</p><p>
The manpages-l10n project has contributed many improved and new translations
for manual pages. Especially Romanian and Polish translations are greatly
enhanced since bookworm.
All architectures other than i386 now use a 64-bit time_t ABI, supporting dates
beyond 2038.
Debian contributors have made significant progress towards ensuring package
builds produce byte-for-byte reproducible results. You can check the status for
packages installed on your system using the new package debian-repro-status, or
visit <a href="https://reproduce.debian.net/">reproduce.debian.net</a> for
Debian's overall statistics for trixie and newer.
</p><p>Debian 13 <q>trixie</q> includes numerous updated software packages
(over 63% of all packages from the previous release), such as:
</p>
<ul>
<li>Apache 2.4.64</li>
<li>Bash 5.2.37</li>
<li>BIND DNS Server 9.20</li>
<li>Cryptsetup 2.7</li>
<li>curl/libcurl 8.14.1</li>
<li>Emacs 30.1</li>
<li>Exim (default email server) 4.98</li>
<li>GNUcash 5.10</li>
<li>GNU Compiler Collection 14.2</li>
<li>GIMP 3.0.4</li>
<li>GnuPG 2.4.7</li>
<li>Inkscape 1.4</li>
<li>the GNU C Library 2.41</li>
<li>LibreOffice 25.2</li>
<li>Linux kernel 6.12 LTS series</li>
<li>LLVM/Clang toolchain 19 (default), 17 and 18 available</li>
<li>MariaDB 11.8</li>
<li>Nginx 1.26</li>
<li>OpenJDK 21</li>
<li>OpenLDAP 2.6.10</li>
<li>OpenSSH 10.0p1</li>
<li>OpenSSL 3.5</li>
<li>Perl 5.40</li>
<li>PHP 8.4</li>
<li>Postfix 3.10</li>
<li>PostgreSQL 17</li>
<li>Python 3, 3.13</li>
<li>Rustc 1.85</li>
<li>Samba 4.22</li>
<li>Systemd 257</li>
<li>Vim 9.1</li>
</ul>
<p>
With this broad selection of packages and its traditional wide
architecture support, Debian once again stays true to its goal of being
<q>The Universal Operating System</q>. It is suitable for many different
use cases: from desktop systems to netbooks; from development servers to
cluster systems; and for database, web, and storage servers. At the same
time, additional quality assurance efforts like automatic installation and
upgrade tests for all packages in Debian's archive ensure that <q>trixie</q>
fulfills the high expectations that users have of a stable Debian release.
</p>
<p>
This release for the first time officially supports the riscv64
architecture, allowing users to run Debian on 64-bit RISC-V hardware and
benefit from all Debian 13 features. A total of seven architectures are officially supported for <q>trixie</q>:
</p>
<ul><q>trixie</q>
<li>64-bit PC (amd64),</li>
<li>64-bit ARM (arm64),</li>
<li>ARM EABI (armel),</li>
<li>ARMv7 (EABI hard-float ABI, armhf),</li>
<li>64-bit little-endian PowerPC (ppc64el),</li>
<li>64-bit little-endian RISC-V (riscv64),</li>
<li>IBM System z (s390x)</li>
</ul>
<p>
i386 is no longer supported as a regular architecture: there is no official
kernel and no Debian installer for i386 systems. The i386 architecture is now
only intended to be used on a 64-bit (amd64) CPU. Users running i386 systems
should not upgrade to trixie. Instead, Debian recommends either reinstalling
them as amd64, where possible, or retiring the hardware.
</p>
<p>
<q>trixie</q> will be the last release for the armel architecture. See <a href="https://www.debian.org/releases/trixie/release-notes/issues.html#last-release-for-armel">5.1.3.
Last release for armel</a> in the release notes for more information on our ARM
EABI support.
</p>
<p>The Debian Cloud team publishes <q>trixie</q> for several cloud computing
services:
</p>
<ul>
<li>Amazon EC2 (amd64 and arm64),</li>
<li>Microsoft Azure (amd64),</li>
<li>OpenStack (generic) (amd64, arm64, ppc64el),</li>
<li>PlainVM (amd64, arm64, ppc64el),</li>
<li>NoCloud (amd64, arm64, ppc64el)</li>
</ul>
<p>
The genericcloud image should be able to run in any virtualised environment,
and there is also a nocloud image which is useful for testing the build process.
</p>
<p>Cloud images provide automation hooks via ``cloud-init`` and prioritize
fast instance startup using specifically optimized kernel packages and
grub configurations.
</p>
<h3>Want to give it a try?</h3>
<p>
If you simply want to try Debian 13 <q>trixie</q> without installing it,
you can use one of the available <a href="https://www.debian.org/CD/live/">live images</a>
which load and run the complete operating system in a read-only state via your
computer's memory.
</p>
<p>
These live images are provided for the <code>amd64</code> and
<code>arm64</code> architectures and are available for DVDs, USB sticks,
and netboot setups.
The user can choose among different desktop
environments to try: GNOME, KDE Plasma, Cinnamon, MATE, LXDE, LXQt, and Xfce.
Debian Live <q>trixie</q> has a standard live image, so it is also possible
to try a base Debian system without any of the graphical user interfaces.
</p>
<p>
Should you enjoy the operating system you have the option of installing
from the live image onto your computer's hard disk. The live image
includes the Calamares independent installer as well as the standard Debian
Installer. More information is available in the
<a href="https://www.debian.org/releases/trixie/releasenotes">release notes</a> and the
<a href="https://www.debian.org/CD/live/">live install images</a> sections of the Debian
website.
Multi-architecture Debian <q>trixie</q> container images are also available on
<a href="https://hub.docker.com/_/debian">Docker Hub</a> . In addition to the
standard images, a <q>slim</q> variant is available to reduce disk usage.
The Debian Installer and Debian Live Images can now be booted using
<q>HTTP Boot</q> on supported UEFI and U-Boot firmware.
</p>
<p>
To install Debian 13 <q>trixie</q> directly onto your computer's storage
device you can choose from a variety of installation media types to
<a href="https://www.debian.org/download">Download</a>
such as: Blu-ray Disc, DVD, CD, USB stick, or via a network connection.
See the <a href="https://www.debian.org/releases/trixie/installmanual">Installation Guide</a>
for more details.
</p>
<p>
Debian can now be installed in 78 languages, with most of them available
in both text-based and graphical user interfaces.
</p>
<p>
The installation images may be downloaded right now via
<a href="https://www.debian.org/CD/torrent-cd/">bittorrent</a> (the recommended method),
<a href="https://www.debian.org/CD/jigdo-cd/#which">jigdo</a>, or
<a href="https://www.debian.org/CD/http-ftp/">HTTP</a>; see
<a href="https://www.debian.org/CD/">Debian on CDs</a> for further information. <q>trixie</q>
will soon be available on physical DVD, CD-ROM, and Blu-ray Discs from
numerous <a href="https://www.debian.org/CD/vendors">vendors</a> too.
</p>
<h3>Upgrading Debian</h3>
<p>
Upgrades to Debian 13 <q>trixie</q> from the previous release, Debian 12
<q>bookworm</q>, are automatically handled by the APT package
management tool for most configurations.
</p>
<p>Before upgrading your system, it is strongly recommended that you make a
full backup, or at least back up any data or configuration information you
can't afford to lose. The upgrade tools and process are quite reliable, but
a hardware failure in the middle of an upgrade could result in a severely
damaged system.</p>
<p>The main things you'll want to back up are the contents of /etc,
/var/lib/dpkg, /var/lib/apt/extended_states and the output of:
</p>
<p><code>$ dpkg --get-selections '*' # (the quotes are important)</code></p><p>We welcome any information from users related to the upgrade from
<q>bookworm</q> to <q>trixie</q>. Please share information by filing a bug in the
<a href="https://www.debian.org/releases/trixie/amd64/release-notes/ch-about.en.html#upgrade-reports">Debian
bug tracking system</a> using the <b>upgrade-reports</b> package with your results.
</p>
<p>
There has been a lot of development on the Debian Installer since its previous
official release with Debian 12, resulting in improved hardware support and
some very useful new features such as
</p><ul>
<li>Improved hardware and software support for speech synthesis</li>
<li>Initial and restricted support for rescuing Debian installed to a btrfs subvolume</li>
<li>Changed default unit from MB to GB when partitioning disks</li>
<li>Disabled cdrom sources if installation medium is not a real CD (USB stick, SD card, ISO file), because APT cannot use it after the installation</li>
<li>Plus support for secure boot with systemd-boot</li>
</ul>

<p>It is advisable to remove bookworm-backports entries from APT source-list
files before the upgrade; after the upgrade consider adding <b>trixie-backports</b>.
</p>
<p>
If your APT configuration also involves pinning or <code>APT::Default-Release</code>,
it is likely to require adjustments to allow the upgrade of packages to the new
stable release. Please consider
<a href="https://www.debian.org/releases/trixie/release-notes/upgrading.html#disabling-apt-pinning">disabling APT pinning</a>.
</p>
<p>
Under some circumstances, issues might arise during the upgrade process, or
while running <q>trixie</q>.
</p>
<p>
For instance, the TLS support in the OpenLDAP client <b>libldap2</b> and server <b>slapd</b>
is now provided by OpenSSL instead of GnuTLS. This affects the available
configuration options, as well as their behavior. If no TLS CA
certificates are specified, the system default trust store will now be loaded automatically. If you do not want
the default CAs to be used, you must configure
the trusted CAs explicitly. For more information about LDAP client configuration,
see the <a href="https://manpages.debian.org/trixie/ldap.conf.5">ldap.conf.5</a>
man page.
</p>
<p>
We have documented this and other possible issues at <a href="https://www.debian.org/releases/trixie/release-notes/issues.html">5. Issues to be aware
of for trixie</a> in the release notes. You're advised to read that before upgrading.
</p>
<p>
As always, Debian systems may be upgraded painlessly, in place,
without any forced downtime, but it is strongly recommended to read
the <a href="https://www.debian.org/releases/trixie/releasenotes">release notes</a> as
well as the <a href="https://www.debian.org/releases/trixie/installmanual">installation
guide</a> for possible issues, and for detailed instructions on
installing and upgrading. The release notes will be further improved and
translated to additional languages in the weeks after the release.
</p>
<h2>About Debian</h2>
<p>
Debian is a free operating system, developed by
thousands of volunteers from all over the world who collaborate via the
Internet. The Debian project's key strengths are its volunteer base, its
dedication to the Debian Social Contract and Free Software, and its
commitment to provide the best operating system possible. This new
release is another important step in that direction.
</p>
<h2>Contact Information</h2>
<p>
For further information, please visit the Debian web pages at
<a href="https://www.debian.org/">https://www.debian.org/</a> or send mail to
&lt;press@debian.org&gt;.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A CT scanner reveals surprises inside the 386 processor's ceramic package (266 pts)]]></title>
            <link>https://www.righto.com/2025/08/intel-386-package-ct-scan.html</link>
            <guid>44848293</guid>
            <pubDate>Sat, 09 Aug 2025 17:17:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2025/08/intel-386-package-ct-scan.html">https://www.righto.com/2025/08/intel-386-package-ct-scan.html</a>, See on <a href="https://news.ycombinator.com/item?id=44848293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-4351020075475457068" itemprop="description articleBody">
<p>Intel released the 386 processor in 1985, the first 32-bit chip in the x86 line.
This chip was packaged in a ceramic square with 132 gold-plated pins protruding from the underside, fitting into
a socket on the motherboard.
While this package may seem boring, a lot more is going on inside it than you might expect.
<a href="https://www.lumafield.com/">Lumafield</a> performed a 3-D CT scan of the chip for me, revealing six layers of complex
wiring hidden inside the ceramic package.
Moreover, the chip has nearly invisible metal wires connected to the <em>sides</em> of the package, the spikes below.
The scan also revealed that the 386 has two separate power and ground networks: one for I/O and one for the CPU's logic.</p>
<p><a href="https://static.righto.com/images/386-package/scan-top.jpg"><img alt="A CT scan of the 386 package. The ceramic package doesn't show up in this image, but it encloses the spiky wires." height="489" src="https://static.righto.com/images/386-package/scan-top-w500.jpg" title="A CT scan of the 386 package. The ceramic package doesn't show up in this image, but it encloses the spiky wires." width="500"></a></p><p>A CT scan of the 386 package. The ceramic package doesn't show up in this image, but it encloses the spiky wires.</p>
<p>The package, below, provides no hint of the complex wiring embedded inside the ceramic.
The silicon die is normally not visible, but I removed the square metal lid that covers it.<span id="fnref:chisel"><a href="#fn:chisel">1</a></span>
As a result, you can also see the two tiers of gold contacts that surround the silicon die.</p>
<p><a href="https://static.righto.com/images/386-package/package-opened.jpg"><img alt="The 386 package with the lid over the die removed." height="371" src="https://static.righto.com/images/386-package/package-opened-w400.jpg" title="The 386 package with the lid over the die removed." width="400"></a></p><p>The 386 package with the lid over the die removed.</p>
<p>Intel selected the 132-pin ceramic package to meet the requirements of a high pin count, good thermal characteristics,
and low-noise power to the die.<span id="fnref:requirements"><a href="#fn:requirements">2</a></span>:
However, standard packages didn't provide sufficient power, so Intel designed a custom package with
"single-row double shelf bonding to two signal layers and four power and ground planes."
In other words, the die's bond wires are connected to the two shelves (or tiers) of pads surrounding the die.
Internally, the package is like a 6-layer printed-circuit board made from ceramic.</p>
<p><a href="https://static.righto.com/images/386-package/package-cross-section.jpg"><img alt="Package cross-section. Redrawn from &quot;High Performance Technology, Circuits and Packaging for the 80386&quot;." height="179" src="https://static.righto.com/images/386-package/package-cross-section-w600.jpg" title="Package cross-section. Redrawn from &quot;High Performance Technology, Circuits and Packaging for the 80386&quot;." width="600"></a></p><p>Package cross-section. Redrawn from "High Performance Technology, Circuits and Packaging for the 80386".</p>
<p>The photo below shows the two tiers of pads with tiny gold bond wires attached: I measured the bond wires at 35 µm in diameter, thinner than a typical human hair.
Some pads have up to five wires attached to support more current for the power and ground pads.
You can consider the package to be a hierarchical interface from the tiny circuits on the die to the
much larger features of the computer's motherboard.
Specifically, the die has a feature size of 1 µm,
while the metal wiring on top of the die has 6 µm spacing.
The chip's wiring connects to the chip's bond pads, which have 0.01" spacing (.25 mm).
The bond wires connect to the package's pads, which have 0.02" spacing (.5 mm); double the spacing because there are two tiers.
The package connects these pads to the pin grid with 0.1" spacing (2.54 mm).
Thus, the scale expands by about a factor of 2500 from the die's microscopic circuitry to the chip's pins.
`</p>
<p><a href="https://static.righto.com/images/386-package/bonding.jpg"><img alt="Close-up of the bond wires." height="415" src="https://static.righto.com/images/386-package/bonding-w500.jpg" title="Close-up of the bond wires." width="500"></a></p><p>Close-up of the bond wires.</p>
<p>The ceramic package is manufactured through a complicated process.<span id="fnref:manufacturing"><a href="#fn:manufacturing">4</a></span>
The process starts with flexible ceramic "green sheets", consisting of ceramic powder mixed with a binding agent.
After holes for vias are created in the sheet, tungsten paste is silk-screened onto the sheet to form the wiring.
The sheets are stacked, laminated under pressure, and then sintered at high temperature (1500ºC to 1600ºC)
to create the rigid ceramic.
The pins are brazed onto the bottom of the chip.
Next, the pins and the inner contacts for the die are electroplated with gold.<span id="fnref:gold"><a href="#fn:gold">3</a></span>
The die is mounted, gold bond wires are attached, and a metal cap is soldered over the die to encapsulate it.
Finally, the packaged chip is tested, the package is labeled, and the chip is ready to be sold.</p>
<p>The diagram below shows a close-up of a signal layer inside the package. 
The pins are connected to the package's shelf pads through metal traces, spectacularly colored in the CT scan.
(These traces are surprisingly wide and free-form; I expected narrower traces to reduce capacitance.)
Bond wires connect the shelf pads to the bond pads on the silicon die.
(The die image is added to the diagram; it is not part of the CT scan.)
The large red circles are vias from the pins. Some vias connect to this signal layer, while other vias pass through to
other layers.
The smaller red circles are connections to a power layer; because the shelf pads are only on the two signal layers,
the six power planes have connections to the signal layers for bonding.
Since bond wires are only connected on the signal layers, the power layers need connections to pads on the signal
layers.</p>
<p><a href="https://static.righto.com/images/386-package/signal-layer-diagram.jpg"><img alt="A close-up of a signal layer. The die image is pasted in." height="415" src="https://static.righto.com/images/386-package/signal-layer-diagram-w450.jpg" title="A close-up of a signal layer. The die image is pasted in." width="450"></a></p><p>A close-up of a signal layer. The die image is pasted in.</p>
<p>The diagram below shows the corresponding portion of a power layer.
A power layer looks completely different from a signal layer; it is a single conductive plane with holes.
The grid of smaller holes allows the ceramic above and below this layer to bond, forming a solid piece of ceramic.
The larger holes surround pin vias (red dots), allowing pin connections to pass through to a different layer.
The red dots that contact the sheet are where power pins connect to this layer.
Because the only connections to the die are from the signal layers, the power layers have connections to the
signal layers; these are the smaller dots near the bond wires, either power vias passing through or vias connected
to this layer.</p>
<p><a href="https://static.righto.com/images/386-package/power-layer-diagram.jpg"><img alt="A close-up of a power layer, specifically I/O Vss. The wavy blue regions are artifacts from neighboring layers. The die image is pasted in." height="417" src="https://static.righto.com/images/386-package/power-layer-diagram-w450.jpg" title="A close-up of a power layer, specifically I/O Vss. The wavy blue regions are artifacts from neighboring layers. The die image is pasted in." width="450"></a></p><p>A close-up of a power layer, specifically I/O Vss. The wavy blue regions are artifacts from neighboring layers. The die image is pasted in.</p>
<p>With the JavaScript tool below, you can look at the package, layer by layer. Click on a radio button to select a layer.
By observing the path of a pin through the layers, you can see where it ends up. For instance, the upper left
pin passes through multiple layers until the upper signals layer connects it to the die. The pin to its right
passes through all the layers until it reaches the logic Vcc plane on top.
(Vcc is the 5-volt supply that powers the chip, called Vcc for historical reasons.)</p>

<p><label for="layer0">Pins</label>
<label for="layer1">I/O Vcc</label>
<label for="layer2">Signals Vcc</label>
<label for="layer3">I/O gnd</label>
<label for="layer4">Signals</label>
<label for="layer5">Logic gnd</label>
<label for="layer6">Logic Vcc</label>
<br>
<img id="stack" src="https://static.righto.com/images/386-package/layer2.jpg"></p>
<p>If you select the logic Vcc plane above, you'll see a bright blotchy square in the center.
This is not the die itself, I think, but the adhesive that attaches the die to the package, epoxy filled with
silver to provide thermal and electrical conductivity. Since silver blocks X-rays, it is highly visible in the image.</p>
<h2>Side contacts for electroplating</h2>
<p>What surprised me most about the scans was seeing wires that stick out to the sides of the package.
These wires are used during manufacturing when the pins are electroplated with gold.<span id="fnref:electroplating"><a href="#fn:electroplating">5</a></span>
In order to electroplate the pins, each pin must be connected to a negative voltage so it can function as a cathode.
This is accomplished by giving each pin a separate wire that goes to the edge of the package.</p>
<p>This diagram below compares the CT scan (above) to a visual side view of the package (below).
The wires are almost invisible, but can be seen as darker spots.
The arrows show how three of these spots match with the CT scan; you can match up the other spots.<span id="fnref:multimeter"><a href="#fn:multimeter">6</a></span></p>
<p><a href="https://static.righto.com/images/386-package/edge-contacts.jpg"><img alt="A close-up of the side of the package compared to the CT scan, showing the edge contacts. I lightly sanded the edge of the package to make the contacts more visible. Even so, they are almost invisible." height="389" src="https://static.righto.com/images/386-package/edge-contacts-w500.jpg" title="A close-up of the side of the package compared to the CT scan, showing the edge contacts. I lightly sanded the edge of the package to make the contacts more visible. Even so, they are almost invisible." width="500"></a></p><p>A close-up of the side of the package compared to the CT scan, showing the edge contacts. I lightly sanded the edge of the package to make the contacts more visible. Even so, they are almost invisible.</p>
<h2>Two power networks</h2>
<p>According to the datasheet, the 386 has 20 pins connected to +5V power (Vcc) and 21 pins connected to ground (Vss).
Studying the die, I noticed that the I/O circuitry in the 386 has separate power and ground connections from the
logic circuitry.
The motivation is that the output pins require high-current driver circuits.
When a pin switches from 0 to 1 or vice versa, this can cause a spike on the power and ground wiring.
If this spike is too large, it can interfere with the processor's logic, causing malfunctions.
The solution is to use separate power wiring inside the chip for the I/O circuitry and for the logic circuitry,
connected to separate pins.
On the motherboard, these pins are all connected to the same power and ground, but decoupling capacitors absorb
the I/O spikes before they can flow into the chip's logic.</p>
<p>The diagram below shows how the two power and ground networks look on the die, with separate pads and wiring.
The square bond pads are at the top, with dark bond wires attached.
The white lines are the two layers of metal wiring, and the darker regions are circuitry.
Each I/O pin has a driver circuit below it, consisting of relatively large transistors to pull the pin high or low.
This circuitry is powered by the horizontal lines for
I/O Vcc (light red) and I/O ground (Vss, light blue).
Underneath each I/O driver is a small logic circuit, powered by thinner
Vcc (dark red) and Vss (dark blue).
Thicker Vss and Vcc wiring goes to the logic in the rest of the chip.
Thus, if the I/O circuitry causes power fluctuations, the logic circuit remains undisturbed, protected by
its separate power wiring.</p>
<p><a href="https://static.righto.com/images/386-package/power-wiring.jpg"><img alt="A close-up of the top of the die, showing the power wiring and the circuitry for seven data pins." height="229" src="https://static.righto.com/images/386-package/power-wiring-w650.jpg" title="A close-up of the top of the die, showing the power wiring and the circuitry for seven data pins." width="650"></a></p><p>A close-up of the top of the die, showing the power wiring and the circuitry for seven data pins.</p>
<p>The datasheet doesn't mention the separate I/O and logic power networks, but
by using the CT scans, I determined which pins power I/O, and which pins power logic.
In the diagram below, the light red and blue pins are power and ground for I/O, while the dark red and blue pins are
power and ground for logic.
The pins are scattered across the package, allowing power to be supplied to all four sides of the die.</p>
<p><a href="https://static.righto.com/images/386-package/pinmap.jpg"><img alt="The pinout from the Intel386DX Microprocessor Datasheet. This is the view from the pin side." height="450" src="https://static.righto.com/images/386-package/pinmap-w450.jpg" title="The pinout from the Intel386DX Microprocessor Datasheet. This is the view from the pin side." width="450"></a></p>
<h2>"No Connect" pins</h2>
<p>As the diagram above shows, the 386 has eight pins labeled "NC" (No Connect)—when the chip is installed in a computer,
the motherboard must leave these pins unconnected.
You might think that the 132-pin package simply has eight extra, unneeded pins, but it's more complicated than that.
The photo below shows five bond pads at the bottom of the 386 die. Three of these pads have bond wires attached,
but two have no bond wires: these correspond to No Connect pins.
Note the black marks in the middle of the pads: the marks are from test probes that were applied to the die
during testing.<span id="fnref:testing"><a href="#fn:testing">7</a></span>
The No Connect pads presumably have a function during this testing process, providing access to an important
internal signal.</p>
<p><a href="https://static.righto.com/images/386-package/nc-pins.jpg"><img alt="A close-up of the die showing three bond pads with bond wires and two bond pads without bond wires." height="193" src="https://static.righto.com/images/386-package/nc-pins-w500.jpg" title="A close-up of the die showing three bond pads with bond wires and two bond pads without bond wires." width="500"></a></p><p>A close-up of the die showing three bond pads with bond wires and two bond pads without bond wires.</p>
<p>Seven of the eight No Connect pads are <em>almost</em> connected: the package has a spot for a bond wire in the die cavity
and the package has internal wiring to a No Connect pin.
The only thing missing is the bond wire between the pad and the die cavity.
Thus, by adding bond wires, Intel could easily create special chips with these pins connected, perhaps for debugging
the test process itself.</p>
<p>The surprising thing is that one of the No Connect pads <em>does</em> have the bond wire in place, completing the connection to
the external pin.
(I marked this pin in green in the pinout diagram earlier.)
From the circuitry on the die, this pin appears to be an output.
If someone with a 386 chip hooks this pin to an oscilloscope, maybe they will see something interesting.</p>
<h2>Labeling the pads on the die</h2>
<p>The earlier 8086 processor, for example, is packaged in a DIP (Dual-Inline Package) with two rows of pins.
This makes it 
straightforward to figure out which pin (and thus which function) is connected
to each pad on the die.
However, since the 386 has a two-dimensional grid of pins, the mapping to the pads is unclear.
You can guess that pins are connected to a nearby pad, but ambiguity remains.
Without knowing the function of each pad, I have a harder time reverse-engineering the die.</p>
<p>In fact, my primary motivation for scanning the 386 package was to determine the pin-to-pad mapping and thus the
function of each pad.<span id="fnref:beep"><a href="#fn:beep">8</a></span>
Once I had the CT data, I was able to trace out each hidden connection between the pad and the external pin.
The image below shows some of the labels; click <a href="https://static.righto.com/images/386-package/die-pin-labels.jpg">here</a> for the full, completely labeled image.
As far as I know, this information hasn't been available outside Intel until now.</p>
<p><a href="https://static.righto.com/images/386-package/die-labeled-closeup.jpg"><img alt="A close-up of the 386 die showing the labels for some of the pins." height="313" src="https://static.righto.com/images/386-package/die-labeled-closeup-w400.jpg" title="A close-up of the 386 die showing the labels for some of the pins." width="400"></a></p><p>A close-up of the 386 die showing the labels for some of the pins.</p>
<!--
Intel wrote in detail about the Pentium III's package in [Flip Chip Pin Grid Array (FC-PGA) Packaging Technology](https://doi.org/10.1109/EPTC.2000.906346).
This package was essentially a 6-layer printed circuit board with pins and decoupling capacitors on the bottom and the
die on top.
The die was mounted as a flip chip, with the die soldered directly to the board using C4 solder balls rather than
bond wires.
This package replaced the OLGA (Organic Land Grid Array) package from the Pentium II, which had contacts (lands) on
the bottom of the package rather than pins
See also [Package Type Guide for Intel Desktop Processors](https://www.intel.com/content/www/us/en/support/articles/000005670/processors.html).
-->

<h2>Conclusions</h2>
<p>Intel's early processors were hampered by inferior packages, but by the time of the 386, Intel had realized
the importance of packaging.
In Intel's early days, management held the bizarre belief that chips should never have more than 16 pins, even though
other companies used 40-pin packages.
Thus, Intel's first microprocessor, the 4004 (1971), was crammed into a 16-pin package, limiting its performance.
By 1972, larger memory chips forced Intel to move to 18-pin packages, extremely reluctantly.<span id="fnref:faggin"><a href="#fn:faggin">9</a></span>
The eight-bit 8008 processor (1972) took advantage of this slightly larger package, but performance still suffered because
signals were forced to share pins.
Finally, Intel moved to the standard 40-pin package for the 8080 processor (1974),
contributing to the chip's success.
In the 1980s, <a href="https://doi.org/10.1109/MSPEC.1985.6370492">pin-grid arrays</a> became popular in the industry
as chips required more and more pins.
Intel used a ceramic pin grid array (PGA) with 68 pins for the 186 and 286 processors (1982),
followed by the 132-pin package for the 386 (1985).</p>
<p>The main drawback of the ceramic package was its cost.
According to the <a href="https://archive.computerhistory.org/resources/access/text/2015/06/102702019-05-01-acc.pdf#page=25">386 oral history</a>,
the cost of the 386 die decreased over time to the point where the chip's package cost as much as the die.
To counteract this, Intel introduced a low-cost plastic package for the 386 that cost just a dollar to manufacture,
the Plastic Quad Flat Package (PQFP) (<a href="https://datasheets.chipdb.org/Intel/x86/386/datashts/24126703.PDF">details</a>).</p>
<p>In later Intel processors, the number of connections exponentially increased.
A typical modern laptop processor uses a Ball Grid Array with 2049 solder balls;
the chip is soldered directly onto the circuit board.
Other Intel processors use a Land Grid Array (LGA): the chip has flat contacts called
lands, while the <em>socket</em> has the pins.
Some Xeon processors have <a href="https://en.wikipedia.org/wiki/LGA_7529">7529</a> contacts, a remarkable growth from the 16 pins of
the Intel 4004.</p>
<p>From the outside, the 386's package looks like a plain chunk of ceramic.
But the CT scan revealed surprising complexity inside, from numerous contacts for electroplating to six layers of
wiring. Perhaps even more secrets lurk in the packages of modern processors.</p>
<p>Follow me on
Bluesky (<a href="https://bsky.app/profile/righto.com">@righto.com</a>),
Mastodon (<a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="28434d465b40415a5a414e4e6847444c4a515c4d5b065b58494b4d">[email&nbsp;protected]</span></a>),
or <a href="https://www.righto.com/feeds/posts/default">RSS</a>.
(I've given up on Twitter.)
Thanks to Jon Bruner and <a href="https://www.lumafield.com/">Lumafield</a> for scanning the chip.
Lumafield's interactive CT scan of the 386 package is available <a href="https://voyager.lumafield.com/project/11b55bba-910c-4c78-8e73-467157c64032">here</a> if you to want to examine it yourself.
Lumafield also scanned a <a href="https://www.righto.com/2022/08/lumafield-flip-flop.html">1960s cordwood flip-flop</a> and
the Soviet <a href="https://voyager.lumafield.com/project/d848dd54-d594-479f-a723-a463547ea7aa">Globus</a> spacecraft navigation
instrument for us.
Thanks to John McMaster for taking 2D X-rays.</p>
<h2>Notes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knuth on ChatGPT (2023) (122 pts)]]></title>
            <link>https://cs.stanford.edu/~knuth/chatGPT20.txt</link>
            <guid>44848259</guid>
            <pubDate>Sat, 09 Aug 2025 17:13:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cs.stanford.edu/~knuth/chatGPT20.txt">https://cs.stanford.edu/~knuth/chatGPT20.txt</a>, See on <a href="https://news.ycombinator.com/item?id=44848259">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>