<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 12 Nov 2024 10:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Influencers Database with Promotion History (121 pts)]]></title>
            <link>https://old.reddit.com/r/SaaSSales/comments/1gpg45t/influencers_database_with_audio_signals_insights/</link>
            <guid>42113741</guid>
            <pubDate>Tue, 12 Nov 2024 08:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/SaaSSales/comments/1gpg45t/influencers_database_with_audio_signals_insights/">https://old.reddit.com/r/SaaSSales/comments/1gpg45t/influencers_database_with_audio_signals_insights/</a>, See on <a href="https://news.ycombinator.com/item?id=42113741">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/SaaSSales/comments/1gpg45t/influencers_database_with_audio_signals_insights/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky adds 700k new users in a week (137 pts)]]></title>
            <link>https://www.theverge.com/2024/11/11/24293920/bluesky-700000-new-users-week-x-threads</link>
            <guid>42112432</guid>
            <pubDate>Tue, 12 Nov 2024 03:07:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/11/11/24293920/bluesky-700000-new-users-week-x-threads">https://www.theverge.com/2024/11/11/24293920/bluesky-700000-new-users-week-x-threads</a>, See on <a href="https://news.ycombinator.com/item?id=42112432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="content"><div><div><div><h2>Bluesky adds 700,000 new users in a week</h2><p><span><span> / </span><h2>A ‘majority' of the new users are from the US, indicating that people are searching for a new platform as an alternative to X.</h2></span></p></div><div><p><span>By</span> <span><span></span> <span><a href="https://www.theverge.com/authors/jay-peters">Jay Peters</a></span><span>, <span>a news editor who writes about technology, video games, and virtual worlds. He’s submitted several accepted emoji proposals to the Unicode Consortium.</span></span></span></p><p><time datetime="2024-11-11T22:30:51.448Z"> <!-- -->Nov 11, 2024, 10:30 PM UTC</time></p><div><h2>Share this story</h2></div></div></div><div><figure><span><span></span><img alt="A graphic of the Bluesky logo." sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/16x11/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/32x21/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/48x32/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/64x43/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/96x64/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/128x85/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/256x171/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/376x251/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/384x256/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/415x277/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/480x320/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/540x360/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/640x427/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/750x500/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/828x552/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/1080x720/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/1200x800/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/1440x960/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/1920x1280/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/2048x1365/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/2400x1600/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x1260/2400x1600/filters:focal(1200x630:1201x631):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25269608/bluesky_media_kit_banner_4.png" decoding="async" data-nimg="responsive"></span><p><cite>Image: Bluesky</cite></p></figure></div></div><div><div><p>Bluesky gained more than 700,000 new users in the last week and now has more than 14.5 million users total, Bluesky COO Rose Wang confirmed to <em>The Verge</em>. The “majority” of the new users on the decentralized social network are from the US, Wang says. The app is currently the number two free social networking app in the US App Store, only trailing Meta’s Threads.</p><div><p>People posting on Threads, on the other hand, have raised complaints about <a href="https://www.theverge.com/2024/10/7/24264382/threads-engagement-bait-problem-mosseri-meta">engagement bait</a>, <a href="https://www.theverge.com/2024/10/11/24267898/mosseri-acknowledges-mistakes-threads-instagram-broken-moderation">moderation issues</a>, and, as of late, misinformation, <a href="https://www.usermag.co/p/metas-threads-overrun-with-liberal-election-fraud-conspiracies">reports Taylor Lorenz</a>. And like our very own <a href="https://www.threads.net/@tomwarrenuk/post/DCL59cZNuBt">Tom Warren</a>, I’ve come to dislike the algorithmic “For You” feed that you <a href="https://www.theverge.com/2023/7/25/23807340/threads-following-feed-for-you-default-instagram-meta">can’t permanently escape</a>, and it certainly seems like we’re not alone in that opinion.</p></div><p>But the Instagram-bootstrapped Threads, which recently crossed <a href="https://www.theverge.com/2024/10/30/24284013/threads-hits-275-million-users">275 million monthly users</a>, is still significantly larger than Bluesky.</p><p>The independent platform has seen a lot of growth in recent weeks — on October 24th, Bluesky announced <a href="https://www.theverge.com/2024/10/24/24278666/bluesky-working-on-premium-subscription">it had 13 million users</a>. After X’s recent announcement that it would let blocked users still see posts from the person that blocked them, for example, Bluesky said it added <a href="https://www.theverge.com/2024/10/18/24273435/bluesky-user-spike-x-tos-ai-changes-blocking">500,000 new users <em>in one day</em></a>.</p><p>The results of the US presidential election could be part of Bluesky’s new influx of users. People may be looking to use a platform that’s not owned by Musk or, like <a href="https://www.wired.com/story/taylor-swift-fans-leaving-x-following-trumps-election/">some Taylor Swift fans</a>, may be looking for a new platform following <a href="https://www.isdglobal.org/digital_dispatches/your-body-my-choice-hate-and-harassment-towards-women-spreads-online/">an increase in hate speech on X</a>.</p><div><p>Bluesky is also becoming an increasingly better app, with recently added features like <a href="https://www.theverge.com/2024/10/11/24267678/bluesky-app-update-pinned-posts-font-size-threads-pitch">pinned posts</a>, <a href="https://www.theverge.com/2024/9/11/24241994/bluesky-share-videos-update">support for posting videos</a>, and <a href="https://www.theverge.com/2024/5/22/24162749/bluesky-send-direct-messages">the ability to send DMs</a> to bring it up to what you might expect from X. It also allows users to custom create and select feeds to follow, and allows for building starter packs to quickly find posters who you may be already familiar with — <a href="https://bsky.app/starter-pack/theverge.com/3laotg2fqva2h">here’s a list of <em>Verge </em>staffers on the platform</a>.</p></div></div><div><p>Most Popular</p><p>Most Popular</p><ol><li><a href="https://www.theverge.com/2024/11/11/24293580/cash-app-class-action-settlement-lawsuit-claim-deadline"><h2>Cash App users have a week left to claim part of a $15 million settlement</h2></a><hr></li><li><a href="https://www.theverge.com/2024/10/16/24265587/analogue-3d-nintendo-64-price-preorder-date"><h2>Analogue’s 4K Nintendo 64 launches next year for $249</h2></a><hr></li><li><a href="https://www.theverge.com/2024/11/11/24293395/mattel-wicked-doll-porn-website-url-misprint-error"><h2>Mattel accidentally linked a porn site on Wicked doll packaging</h2></a><hr></li><li><a href="https://www.theverge.com/2024/11/11/24293920/bluesky-700000-new-users-week-x-threads"><h2>Bluesky adds 700,000 new users in a week</h2></a><hr></li><li><a href="https://www.theverge.com/2024/11/11/24294106/valve-white-steam-deck"><h2>Valve finally made a white Steam Deck that you can actually buy</h2></a><hr></li></ol></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This morning for no obvious reason, I remembered the Fuel Rats (157 pts)]]></title>
            <link>https://hachyderm.io/@danderson/113465421567555186</link>
            <guid>42112005</guid>
            <pubDate>Tue, 12 Nov 2024 01:21:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hachyderm.io/@danderson/113465421567555186">https://hachyderm.io/@danderson/113465421567555186</a>, See on <a href="https://news.ycombinator.com/item?id=42112005">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Bus Number – The GitHub plugin my coworkers asked me not to write (154 pts)]]></title>
            <link>https://www.scannedinavian.com/the-github-plugin-my-coworkers-asked-me-not-to-write.html</link>
            <guid>42111260</guid>
            <pubDate>Mon, 11 Nov 2024 23:11:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scannedinavian.com/the-github-plugin-my-coworkers-asked-me-not-to-write.html">https://www.scannedinavian.com/the-github-plugin-my-coworkers-asked-me-not-to-write.html</a>, See on <a href="https://news.ycombinator.com/item?id=42111260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
	    
	    <p>
    Posted on 2024-11-11
    
</p>

<p><img src="https://www.scannedinavian.com/images/holastafur.png"></p>
<p>This blog post was written together with <a href="https://mclare.blog/">&lt;mclare&gt;</a>, who made coooool visualizations like the picture at the end of the post!</p>
<h2 id="whats-a-bus-factor-or-truck-factor">What’s a Bus Factor or Truck Factor?</h2>
<p>According to <a href="https://en.wikipedia.org/wiki/Bus_factor">wikipedia</a>:</p>
<blockquote>
<p>The “bus factor” is the minimum number of team members that have to suddenly disappear from a project before the project stalls due to lack of knowledgeable or competent personnel.</p>
</blockquote>
<h2 id="why">Why?</h2>
<p>In 2015 or so, my employer had layoffs.
One of them was the only contributor to part of the codebase that made money for our company.
I remembered reading about <a href="https://wiki.c2.com/?TruckNumber">Truck Number</a> on the original wiki, so I thought it’d be fun to write a github enterprise plugin that calculates who you can’t afford to fire.
I enjoy reading research papers, and found this <a href="http://aserg.labsoft.dcc.ufmg.br/truckfactor/">truck factor</a> research paper.</p>
<p>I started writing the plugin, and talked five minutes on it at our Thursday afternoon lightning talks.
My coworkers said it would immediately hit <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s Law</a>. They saw this as a way for management to easily calculate who you <strong>can</strong> fire!</p>
<h2 id="what">What?</h2>
<p>The original authors calculated how many people had to be hit by a bus for a bunch of popular GitHub projects to stall.
This includes the Linux kernel among others. In the first preprint, they said 80 people would have to leave the project for Linux to stop.</p>
<p>Last week I mentioned this blog post idea to mclare, and she said we should try to reproduce the results and see if the truck factor has improved in the past ten years.</p>
<p>The authors’ <a href="https://github.com/aserg-ufmg/Truck-Factor">github repo</a> is available and still works!</p>
<h2 id="are-we-able-to-reproduce-the-results">Are we able to reproduce the results?</h2>
<p>The Truck Factor research paper links to a <a href="https://github.com/aserg-ufmg/Truck-Factor">github repository</a>!
The data from the paper is available as JSON!
Their <a href="http://aserg.labsoft.dcc.ufmg.br/truckfactor/target.html">visualization</a> is backed by a CSV we can scrape!</p>
<p>But, we don’t know the <strong>date</strong> they pulled the data.</p>
<p>The README instructions don’t quite work, and we spent an hour figuring out how to execute the pieces.
Fortunately, the issues on the github repository told us how to fix the problem. I wanted results, not an afternoon of debugging their use of awk in shell scripts.
mclare got the list of github repos out of the first column of their CSV. We needed to clone them all!
We had fun learning about <a href="https://www.gnu.org/software/parallel/">gnu parallel</a> to run a bunch of git clone commands at the same time.</p>
<h3 id="gnu-parallel">Gnu Parallel</h3>
<p>Why does <a href="https://www.gnu.org/software/parallel/">gnu parallel</a> use <strong>all</strong> the cores when we tell it to use only 8?
We only saw eight <code>git clone</code> processes at a time, but a large number of <code>git index-pack</code> processes that maxed out all 32 cores on my laptop.
I’m guessing git’s index-pack is a forked subprocess and allows parallel to start another git clone?
If you know the answer, send us a message!</p>
<h3 id="ruby-gems-in-nixos">Ruby Gems in NixOS</h3>
<p>The Truck Factor code uses <a href="https://github.com/github-linguist/linguist">linguist</a> to filter out files that are only documentation. Later in the paper the authors say that documentation is the best way to keep your project alive, so I’m not convinced that’s good.</p>
<p>In any case, I’m running NixOS and have no experience with Ruby, thus installing Ruby Gems did not fit in the time I had.
If you know a good way to install the linguist plugin in a Nix flake, please send me a message! (or even a <a href="https://github.com/spite-driven-development/Truck-Factor">pull request</a>)</p>
<h2 id="but-how-did-you-recalculate-the-results">But, <strong>how</strong> did you recalculate the results?</h2>
<p>We forked the original repository on github, cloned it locally, and puzzled our way through the README.
We used <code>mvn package</code> to compile the Java source into a jar, and tried each of the steps on the numpy github repository.
Then we were ready to recalculate all the things.</p>
<p>mclare downloaded the CSV from the authors’ <a href="http://aserg.labsoft.dcc.ufmg.br/truckfactor/target.html">visualization</a> and we converted the first column into a <a href="https://github.com/spite-driven-development/Truck-Factor/blob/master/meta/repo_list.txt">list of github repositories</a>.
I started with a for loop, but mclare switched to gnu parallel, because it’s cool. Also because everything gets done faster.</p>
<div id="cb1"><pre><code><span id="cb1-1"><span># clone the repositories</span></span>
<span id="cb1-2"><span>parallel</span> <span>-j</span> 8 git clone ::: <span>$(</span><span>cat</span> ../meta/repo_list.txt<span>)</span></span>
<span id="cb1-3"><span># change into the directory so you don't get the awk error</span></span>
<span id="cb1-4"><span>cd</span> gittruckfactor/scripts</span>
<span id="cb1-5"><span># scrape out all the git commit info</span></span>
<span id="cb1-6"><span>for</span> x <span>in</span> ../../repos/<span>*</span><span>;</span> <span>do</span> <span>./commit_log_script.sh</span> <span>$x</span><span>;</span> <span>done</span><span>;</span></span>
<span id="cb1-7"><span># run the java code that ingests the scraped commit data</span></span>
<span id="cb1-8"><span>for</span> x <span>in</span> ../repos/<span>*</span><span>;</span> <span>do</span> <span>dirname</span> <span>$x</span> <span>&gt;&gt;</span> ../results.txt <span>&amp;&amp;</span> <span>echo</span> java <span>-jar</span> ./target/gittruckfactor-1.0.jar <span>$x</span> <span>$x</span> <span>&gt;&gt;</span> ../results.txt<span>;</span> <span>done</span><span>;</span></span></code></pre></div>
<p>I have a fast gigabit internet connection at home, it took 17.5 minutes to clone all the repos one at a time.
Processing each repo took about the same time, eighteen minutes maybe?</p>
<p>Here’s one example output for the linux kernel repository:</p>
<pre><code>linux
TF = 12 (coverage = 49.98%)
TF authors (Developer;Files;Percentage):
Linus Torvalds;5712;6.59
Mauro Carvalho Chehab;2479;2.86
Rob Herring;1313;1.51
Thomas Gleixner;1228;1.42
Krzysztof Kozlowski;1222;1.41
Ben Skeggs;1211;1.40
Arnaldo Carvalho de Melo;911;1.05
Greg Kroah-Hartman;852;0.98
David Howells;718;0.83
Ian Rogers;599;0.69
Masahiro Yamada;598;0.69
Takashi Iwai;581;0.67
</code></pre>
<h2 id="problems">Problems</h2>
<p><a href="https://mclare.blog/">&lt;mclare&gt;</a> This calculation neglects the review process. As you go up the career ladder, developers should do more review and less hands on keyboard.</p>
<h2 id="further-work">Further Work</h2>
<ul>
<li><label>does the truck factor calculation take into account git’s co-authored-by and reviewer headers? If not, could it?</label></li>
<li><label>why is our number for Linux so very different ten years later? The original paper gives a truck factor of 80, we get EIGHT!</label>
<ul>
<li><label>The original paper uses a <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> of one to find and merge developer aliases. I don’t think we did that. Maybe that changes our number?</label></li>
<li><label>Would this version of the truck factor code still give us 80 if we checkout the Linux kernel repo at mid-2015 ? According to the git history, the algorithm was updated in 2016, could we get new numbers for a later blog post?</label></li>
</ul></li>
<li><label>We could look at some of the <a href="https://scholar.google.com/scholar?cluster=5286537198548981618&amp;hl=en&amp;as_sdt=0,22">156 citations</a> of this paper and see if someone came up with a better calculation.</label></li>
<li><label>We could compare popular projects of today to their history. Rust and other recent big names are not mentioned in the 2015 paper. For that matter, we could write a script to find yearly truck numbers for any git repo.</label></li>
<li><label>Shae wants to figure out how to install Ruby Gems in NixOS so the linguist plugin can filter out which files are only documentation.</label></li>
</ul>
<h2 id="conclusion---bus-factors-got-scarier">Conclusion - Bus Factors got scarier.</h2>
<p>The biggest question we both had was, did it get any better?</p>
<p>I’m gonna say no, it’s gotten worse.
The 2015 <a href="https://peerj.com/preprints/1233v1.pdf">preprint</a> of this paper gave the linux kernel a truck factor of ninety!
The <a href="https://arxiv.org/pdf/1604.06766">full publication</a> gave that same repository a truck number of fifty seven.</p>
<p>Without the linguist plugin to filter out documentation and third party libraries, we got a truck factor of twelve for the Linux kernel repository.
After mclare installed the plugin on her system, she got a truck factor of eight for the Linux kernel.</p>
<p>This is not an improvement.</p>
<p>If you want more articles on this subject, send us a message!</p>
<h2 id="visualize">Visualize!</h2>
<p>For more visualizations and nifty details, check out <a href="https://mclare.blog/">mclare’s blog</a>.
<img src="https://www.scannedinavian.com/images/truck-factor.png"></p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I converted a Macbook into a PC (102 pts)]]></title>
            <link>https://community.frame.work/t/i-converted-a-macbook-into-a-pc/60063</link>
            <guid>42111120</guid>
            <pubDate>Mon, 11 Nov 2024 22:43:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.frame.work/t/i-converted-a-macbook-into-a-pc/60063">https://community.frame.work/t/i-converted-a-macbook-into-a-pc/60063</a>, See on <a href="https://news.ycombinator.com/item?id=42111120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="I converted a Macbook into a PC">
      
      <meta itemprop="datePublished" content="2024-11-07T10:20:36Z">
        <meta itemprop="articleSection" content="Mainboard">
      <meta itemprop="keywords" content="">
      


          <div id="post_1">
            <div>
              

                

              <p><span>
                  <time datetime="2024-11-07T10:20:36Z">
                    November 7, 2024, 10:20am
                  </time>
                  <meta itemprop="dateModified" content="2024-11-07T10:20:36Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>And I thought I’d share.<br>
</p><div><a href="https://static-community.frame.work/original/3X/1/1/11a8b350bd01329fef85d425433a9ff047debe99.jpeg" data-download-href="/uploads/short-url/2wdytrpQcVeAReXJRCfqTJ9WjXz.jpeg?dl=1" title="IMG_3399" rel="noopener nofollow ugc"><img src="https://static-community.frame.work/optimized/3X/1/1/11a8b350bd01329fef85d425433a9ff047debe99_2_666x500.jpeg" alt="IMG_3399" data-base62-sha1="2wdytrpQcVeAReXJRCfqTJ9WjXz" width="666" height="500" srcset="https://static-community.frame.work/optimized/3X/1/1/11a8b350bd01329fef85d425433a9ff047debe99_2_666x500.jpeg, https://static-community.frame.work/optimized/3X/1/1/11a8b350bd01329fef85d425433a9ff047debe99_2_999x750.jpeg 1.5x, https://static-community.frame.work/optimized/3X/1/1/11a8b350bd01329fef85d425433a9ff047debe99_2_1332x1000.jpeg 2x" data-dominant-color="73675C"></a></div><br>
<div><a href="https://static-community.frame.work/original/3X/a/b/ab100efeb0ac40e69f122389ac96fa06cc733ce5.jpeg" data-download-href="/uploads/short-url/opi3gTwt57MCYBECXfbHasgDr0N.jpeg?dl=1" title="IMG_3401" rel="noopener nofollow ugc"><img src="https://static-community.frame.work/optimized/3X/a/b/ab100efeb0ac40e69f122389ac96fa06cc733ce5_2_666x500.jpeg" alt="IMG_3401" data-base62-sha1="opi3gTwt57MCYBECXfbHasgDr0N" width="666" height="500" srcset="https://static-community.frame.work/optimized/3X/a/b/ab100efeb0ac40e69f122389ac96fa06cc733ce5_2_666x500.jpeg, https://static-community.frame.work/optimized/3X/a/b/ab100efeb0ac40e69f122389ac96fa06cc733ce5_2_999x750.jpeg 1.5x, https://static-community.frame.work/optimized/3X/a/b/ab100efeb0ac40e69f122389ac96fa06cc733ce5_2_1332x1000.jpeg 2x" data-dominant-color="646457"></a></div>
<p>I used a Framework 13 mainboard as the core, added IO board to both sides of it and a couple of extra boards for the keyboard, Magsafe and the charge state button.</p>
            </div>

            

            

          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p><img src="https://static-community.frame.work/original/3X/1/5/15ca7768e9c7eb4a3f18590312498f3a515e8df1.gif" alt="image0 (1)" data-base62-sha1="36LOaHGWxuldmdSiDfwJXglUbkt" width="381" height="216"></p>

            

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/Gmanny"><span itemprop="name">Gmanny</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-07T18:00:15Z">
                    November 7, 2024,  6:00pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-07T18:00:15Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>Are the green PCBs custom by you? This looks both really professional and like a first prototype <img src="https://community.frame.work/images/emoji/apple/slight_smile.png?v=12" title=":slight_smile:" alt=":slight_smile:" loading="lazy" width="20" height="20"> Super impressive!</p>

            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>hey and you even got the apple battery mounting!!!</p>

            

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/pkunk"><span itemprop="name">pkunk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-08T05:18:05Z">
                    November 8, 2024,  5:18am
                  </time>
                  <meta itemprop="dateModified" content="2024-11-08T05:18:05Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Great job <a href="https://community.frame.work/u/kcb">@KCB</a>!</p>
<p>Even with the Framework board inverted and extras inside it is still easier to upgrade/repair than a Macbook!</p>
<p>Is that a pre or post touchbar Macbook?  Nobody will ever suspect your allegiance to the fruit has been compromised!</p>
            </div>

            

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-08T07:15:09Z">
                    November 8, 2024,  7:15am
                  </time>
                  <meta itemprop="dateModified" content="2024-11-08T07:15:09Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <p>Thanks for the replies.<br>
The Macbook is a 2010 17" so it would have been pretty easy to upgrade and repair (socketed Ram and HDD, screwed in battery) but the age would have made this laptop not only unusably slow but it was also dead as a doornail. Its one of the still good Macbooks with the glowing apple logo.<br>
Yes, all the green PCBs are made by me.</p>

            

            

          </div>
          <div itemprop="comment" id="post_7" itemscope="" itemtype="http://schema.org/Comment">
              <p>Did you use a new LCD or a converter? Are the LVDS connectors also handled on your circuit boards?</p>
<p>K3n.</p>
            </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-08T17:25:34Z">
                    November 8, 2024,  5:25pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-08T17:25:34Z">
              <span itemprop="position">8</span>
              </span>
            </p>
            <p>Ive replaced the screen with a lp170wq1 from lg. Its directly attached to the mainboard via the framework 16 edp cable.</p>

            

            

          </div>
          <div itemprop="comment" id="post_9" itemscope="" itemtype="http://schema.org/Comment">
              <p>This is really cool! What is the function of top left board that requires cooling from what looks like a framework fan? If it is a Framework fan can you explain how the lower section was liberated from it’s heatsink?</p>
<p>Thanks</p>
            </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-09T09:10:20Z">
                    November 9, 2024,  9:10am
                  </time>
                  <meta itemprop="dateModified" content="2024-11-09T09:10:20Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            <p>Its to compensate for apples innovative cooling design. Ive desoldered the old heatpipe from the heatsink and soldered a new one on that i press against the main heatpipe.</p>

            

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/Usernames"><span itemprop="name">Usernames</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-09T19:50:04Z">
                    November 9, 2024,  7:50pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-09T19:50:04Z">
              <span itemprop="position">11</span>
              </span>
            </p>
            <p>Sorry it isn’t quite clear to me, is that additional fan adding to the existing cpu cooling solution because you saw overheating or to get the most thermal performance?</p>

            

            

          </div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-09T20:22:15Z">
                    November 9, 2024,  8:22pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-09T20:22:15Z">
              <span itemprop="position">12</span>
              </span>
            </p>
            <p>Yes its adding to the existing cpu cooling. The first prototype of this I build was using an i5 1135 cpu and was getting pretty hot. So I figured adding an additional heatsink and fan would help. On the Ryzen board im not sure I would have gone through that trouble again, its running much cooler.</p>

            

            

          </div>
          <div itemprop="comment" id="post_13" itemscope="" itemtype="http://schema.org/Comment">
              <p>This is excellent! Curiously wondering if a smaller Macbook Pro would have been also a worthy candidate? Or would the space provided there just not be sufficient?</p>
<p>Excellent work!</p>
            </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-10T11:24:31Z">
                    November 10, 2024, 11:24am
                  </time>
                  <meta itemprop="dateModified" content="2024-11-10T11:24:31Z">
              <span itemprop="position">14</span>
              </span>
            </p>
            <p>If you dont add a second cooling fan I dont think that would be an issue on the 15 inch. The 13 might be difficult to fit the battery but I think it would be possible.</p>

            

            

          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/KCB"><span itemprop="name">KCB</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2024-11-11T17:43:37Z">
                    November 11, 2024,  5:43pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-11T17:43:37Z">
              <span itemprop="position">15</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>I had to take it apart to replace the edp cable so I took a couple more pictures (without the tape).<br>
</p><div><a href="https://static-community.frame.work/original/3X/3/a/3aa8f816e85117a6c2ef68a2e450af8ed06d2279.jpeg" data-download-href="/uploads/short-url/8mVHTdiMfkzp66cqmAjJMcNFjCN.jpeg?dl=1" title="IMG_3424" rel="noopener nofollow ugc"><img src="https://static-community.frame.work/optimized/3X/3/a/3aa8f816e85117a6c2ef68a2e450af8ed06d2279_2_666x500.jpeg" alt="IMG_3424" data-base62-sha1="8mVHTdiMfkzp66cqmAjJMcNFjCN" width="666" height="500" srcset="https://static-community.frame.work/optimized/3X/3/a/3aa8f816e85117a6c2ef68a2e450af8ed06d2279_2_666x500.jpeg, https://static-community.frame.work/optimized/3X/3/a/3aa8f816e85117a6c2ef68a2e450af8ed06d2279_2_999x750.jpeg 1.5x, https://static-community.frame.work/optimized/3X/3/a/3aa8f816e85117a6c2ef68a2e450af8ed06d2279_2_1332x1000.jpeg 2x" data-dominant-color="6F6453"></a></div><br>
<div><a href="https://static-community.frame.work/original/3X/c/8/c8ffc909e81e453ea00847a9695889dd52602866.jpeg" data-download-href="/uploads/short-url/sG7vIwFVHOOscW9XkOyp9thUyXA.jpeg?dl=1" title="IMG_3428" rel="noopener nofollow ugc"><img src="https://static-community.frame.work/optimized/3X/c/8/c8ffc909e81e453ea00847a9695889dd52602866_2_666x500.jpeg" alt="IMG_3428" data-base62-sha1="sG7vIwFVHOOscW9XkOyp9thUyXA" width="666" height="500" srcset="https://static-community.frame.work/optimized/3X/c/8/c8ffc909e81e453ea00847a9695889dd52602866_2_666x500.jpeg, https://static-community.frame.work/optimized/3X/c/8/c8ffc909e81e453ea00847a9695889dd52602866_2_999x750.jpeg 1.5x, https://static-community.frame.work/optimized/3X/c/8/c8ffc909e81e453ea00847a9695889dd52602866_2_1332x1000.jpeg 2x" data-dominant-color="736455"></a></div><br>
<div><a href="https://static-community.frame.work/original/3X/c/0/c00ddcb4ef2a90ae18dd965e841b6741704a3941.jpeg" data-download-href="/uploads/short-url/roZnaWE8Es17sLgGnQR0qtQueIN.jpeg?dl=1" title="IMG_3434" rel="noopener nofollow ugc"><img src="https://static-community.frame.work/optimized/3X/c/0/c00ddcb4ef2a90ae18dd965e841b6741704a3941_2_666x500.jpeg" alt="IMG_3434" data-base62-sha1="roZnaWE8Es17sLgGnQR0qtQueIN" width="666" height="500" srcset="https://static-community.frame.work/optimized/3X/c/0/c00ddcb4ef2a90ae18dd965e841b6741704a3941_2_666x500.jpeg, https://static-community.frame.work/optimized/3X/c/0/c00ddcb4ef2a90ae18dd965e841b6741704a3941_2_999x750.jpeg 1.5x, https://static-community.frame.work/optimized/3X/c/0/c00ddcb4ef2a90ae18dd965e841b6741704a3941_2_1332x1000.jpeg 2x" data-dominant-color="685F4E"></a></div>
            </div>

            

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.frame.work/u/MJ1"><span itemprop="name">MJ1</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-11-11T17:53:53Z">
                    November 11, 2024,  5:53pm
                  </time>
                  <meta itemprop="dateModified" content="2024-11-11T17:53:53Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <p>Damn, that’s impressive.<br>
It was already, but seeing the back with the second heat pipe attached gives the sense that almost nothing could stop you.</p>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Misguided Apple Intelligence ads (109 pts)]]></title>
            <link>https://tidbits.com/2024/11/11/misguided-apple-intelligence-ads/</link>
            <guid>42111094</guid>
            <pubDate>Mon, 11 Nov 2024 22:39:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tidbits.com/2024/11/11/misguided-apple-intelligence-ads/">https://tidbits.com/2024/11/11/misguided-apple-intelligence-ads/</a>, See on <a href="https://news.ycombinator.com/item?id=42111094">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-68633">
															
												
		<div>
			

			
							<p>Apple apparently hasn’t learned much from the criticism it took earlier this year for an ad showing creative works unceremoniously crushed in an industrial press (see “<a href="https://tidbits.com/2024/05/10/apple-apologizes-for-tone-deaf-crush-ipad-pro-ad/">Apple Apologizes for Tone-Deaf “Crush!” iPad Pro Ad</a>,” 10 May 2024). A pair of new ads for Apple Intelligence portray the Writing Tools and Memories movies as tools for those unwilling to put in any effort.</p>
<p>In the <a href="https://www.youtube.com/watch?v=3m0MoYKwVTM">first ad</a>, Apple Intelligence enables a goof-off who wastes time and annoys his colleagues to surprise his boss with an unexpectedly well-written email. It’s not clear that the boss is impressed; he just can’t believe the guy would have written a professional message.</p>
<p><iframe loading="lazy" title="Apple Intelligence | Writing Tools | iPhone 16" width="500" height="281" src="https://www.youtube.com/embed/3m0MoYKwVTM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Is the message that Apple Intelligence is aimed at the perpetually lazy? Where’s the positive ad with a dyslexic child using Writing Tools to proofread a school essay or a businessperson using it to understand a complex report dumped on them minutes before a meeting?</p>
<p>The <a href="https://www.youtube.com/watch?v=A0BXZhdDqZM">second ad</a> channels a similar suggestion—that Apple Intelligence is a crutch for the thoughtless. In it, a woman realizes that she has forgotten her husband’s birthday only after their kids give him thoughtful, homemade gifts, so she quickly uses Apple Intelligence to create a Memories movie of the children doing woodworking with their father. Apple Intelligence to the rescue! Apparently, making a Memories movie is easier than creating a repeating annual calendar event.</p>
<p><iframe loading="lazy" title="Apple Intelligence | Create memory movies | iPhone 16" width="500" height="281" src="https://www.youtube.com/embed/A0BXZhdDqZM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Why would Apple want to promote the idea that Apple Intelligence can bail you out from failing to pay attention to the most important people in your life? It’s trivially easy to imagine positive scenarios enhanced by a Memories movie, such as a teen sharing photos with an ailing grandparent in the hospital or high school friends reconnecting over shared sports photos. They might be a touch cloying, but Memories movies trend in that direction anyway.</p>
<p>As it stands now, and likely as it will be in its next release, Apple Intelligence won’t change the world or even your everyday Mac experience. But it can make a difference for some, and Apple would be better served by showing it helping those who are already trying to do good work and be good people.</p>
<p>Imagine you work at Apple’s ad agency. What ads would you like to see showcasing Apple Intelligence features?</p>


									</div>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I ship projects at big tech companies (668 pts)]]></title>
            <link>https://www.seangoedecke.com/how-to-ship/</link>
            <guid>42111031</guid>
            <pubDate>Mon, 11 Nov 2024 22:30:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/how-to-ship/">https://www.seangoedecke.com/how-to-ship/</a>, See on <a href="https://news.ycombinator.com/item?id=42111031">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header></header><section><p>I have shipped a lot of different projects over the last ~10 years in tech. I often get tapped to lead new ones when it’s important to get it right, because I’m good at it. Shipping in a big tech company is a very different skill to writing code, and lots of people who are great at writing code are terrible at shipping.</p>
<p>Here’s what I think about when I’m leading a project and what I’ve seen people get wrong.</p>
<h2>Shipping is hard</h2>
<p>The most common error I see is to assume that shipping is easy. The default state of a project is to <em>not ship</em>: to be delayed indefinitely, cancelled, or to go out half-baked and burst into flames. Projects do not ship automatically once all the code has been written or all the Jira tickets closed. They ship because someone takes up the difficult and delicate job of shipping them.</p>
<p>That means that in almost all cases, <strong>shipping has to come first</strong>. You cannot have anything else as your top priority. If you spend all your time worrying about polishing the customer experience (for example), you will not ship! Obsessing over UX is praiseworthy behaviour when you are an engineer on the team, but a blunder if you are leading the project. You should cherish the other engineers on your team who are doing that work, and give them as much support as you can. But your primary concern has to be shipping the project. It is too hard a job to do in your spare time.</p>
<p>In my experience, projects almost always ship because one single person makes them ship. To be clear, that person doesn’t write all the code or do all the work, and I’m not saying the project could ship without an entire team behind it. But it’s <em>really important</em> that one person on the project has an end-to-end understanding of the whole thing: how it hangs together technically, and what product or business purpose it serves. Good teams and companies understand this, and make sure every project has a single responsible engineer (typically this position is called a “technical lead” or “DRI” role). Bad teams and companies don’t do this, and projects live and die based on whether an engineer steps up into this role of their own accord.</p>
<h2>What is shipping?</h2>
<p>Why do so many engineers think shipping is easy? I know it sounds extreme, but I think many engineers do not understand what shipping even is inside a large tech company. What does it mean to ship? It does <em>not</em> mean deploying code or even making a feature available to users. Shipping is a social construct within a company.Concretely, that means that <strong>a project is shipped when the important people at your company believe it is shipped.</strong> If you deploy your system, but your manager or VP or CEO is very unhappy with it, <em>you did not ship</em>. (Maybe you shipped something, but you didn’t ship the actual project.) You only know you’ve shipped when your company’s leadership acknowledge you’ve shipped. A congratulations message in Slack from your VP is a good sign, as is an internal blog post that claims victory. For small ships, an atta-boy from your manager will do.</p>
<p>This probably sounds circular, but I think it’s a really important point. Of course if you deploy something that users love and makes a ton of money, you’ve shipped. But that’s only true because satisfying users and making money is something that makes your leadership team happy. If you ship something users hate and makes no money, but your leadership team is happy, <em>you still shipped</em>. You can feel any way you like about that, but it’s true. If you don’t like it, you should probably go work for companies that really care how happy their users are.</p>
<p>Engineers who think shipping means delivering a spec or deploying code will repeatedly engineer their way into failed ships.</p>
<h2>Communication</h2>
<p>So if your primary job when shipping something is to make your company’s leadership happy with the project, what does that mean in practice? First, <strong>you have to get clear on what the company is looking to get out of the project</strong>. Sometimes it’s extracting more money from a small set of users (e.g. enterprise features). Sometimes it’s spending money to grow the total set of users (e.g. splashy free-tier features). Sometimes it’s mollifying a particular very large customer by building a feature specifically for them. Sometimes it’s just an influential VP or CEO’s pet project, and you need to align with their vision. There are lots of potential reasons, and if you want to ship the project you need to know which ones apply in this case. Align your work and communication accordingly! For instance, enterprise features often don’t need splashy UI but are completely inflexible on requirements, end-user features need to be polished, pet projects mean you need to be in active communication with the specific mover and shaker whose pet it is, and so on.</p>
<p>Second, no matter the project goal, your leadership team (the people in your reporting chain who care about the project) will always have basically zero technical context about the project compared to you. That means they will be trusting you for estimates, to answer technical questions, and to anticipate technical problems. <strong>Maintaining that trust should be your top priority</strong>. If they don’t have faith in your ability to do the job and to keep them informed, you will not ship. They’ll de-risk by cancelling the project, or letting it roll out with zero attention or celebration (remember that an un-celebrated launch is not a ship!) Alternatively, they’ll sideline you and go to another engineer, who will then formally or informally be the one who actually ships the project. Either way, you’ll feel it at review time and they’ll go to someone else for the next one.</p>
<p>How do you maintain trust with your leadership team? This could be a whole article (or book) by itself, but here’s my summary:</p>
<ul>
<li>The best thing is a track record of having shipped in the past, if you can get it</li>
<li>Project confidence (if you’re visibly worried, they will be too)</li>
<li>Project competence. You want to aim for something like a NASA mission control vibe</li>
<li>Communicate professionally and concisely, and don’t make them chase you for updates: post a daily or weekly thread somewhere</li>
</ul>
<p>It is much, much more important to do these things than for the project to ship with zero bugs on the exact deadline. If a project has to be delayed for technical reasons, in my experience you will not suffer consequences so long as you communicate it clearly, confidently (and ideally with some warning). In fact, it’s paradoxically often <em>better</em> for you if there is some kind of problem that forces a delay, for the same reason that the heroic on-call engineer who hotfixes an incident gets more credit than the careful engineer who prevents one.</p>
<h2>Getting into production</h2>
<p>Even so, you typically still have to get the project into production. The most common problem here is missing a key detail. Sometimes it’s a technical detail: maybe we rely on storing the user documents in Memcached, but many documents are multiple megabytes and will be larger than the Memcached block size. Sometimes it’s a detail of coordination: maybe the platform team that owns Memcached was expecting one-tenth of the traffic our project will send them, so they call a meeting with the VPs and delay the project. Sometimes it’s a legal detail: maybe the user data is unexpectedly sensitive, and our system doesn’t have the controls we’d need to handle it safely. These issues can come from anywhere, and are very hard to anticipate. Dealing with them requires a deep technical understanding of the system and the ability to pivot quickly.</p>
<p>For instance, you may have read that first example and are now thinking “well, you could split the documents across multiple Memcached keys, or increase the block size, or move to Redis, etc…“. All of those are potential solutions! But knowing which of those solutions will work - and more importantly, which of those solutions will not blow out the project timeline - is impossible unless you’ve got a deep understanding.</p>
<p>This is doubly important because the problem in question doesn’t even need to be real. In the lead up to a project launch, it’s very common for other teams or engineers to raise <em>potential</em> problems (e.g. “hey, are we sure the user data will fit in Memcached?“) If nobody steps forward and explains why this isn’t a problem (or if it is, how it’s being addressed before launch), the project will be delayed, and it will be your responsibility. Why? Because your manager (or their manager) will not know whether this is a serious problem. That’s what they pay you for! If you’re not stepping up to address it, they will naturally err on the side of caution and <em>not ship</em>.</p>
<p>You need to stay light on your feet so that when these issues come up you’re not neck-deep in other work. That usually means not being fully heads-down on implementation (i.e. delegating tasks to other engineers on the project). Ideally you should have at least 20% of your time free from implementation in the early stages of the project, scaling up to 90-100% in the final days. If you do that, when issues do come up you’ll be able to grant them your full attention.</p>
<h2>Can we ship right now?</h2>
<p>Feature flags are the best way I’ve seen to do this, but staging environments also work, and so on. The key thing is to get whatever you’re building in front of as many eyes as possible: yours, but also other engineers, and ideally leadership, product, design and so on. Five minutes playing with the actual feature, even in a very rough state, will bring up issues that nobody anticipated. Being able to directly see it themselves also does wonders for reassuring leadership that you’ve got things under control.</p>
<p>The best way to anticipate problems is to deploy early. In general, a helpful question to ask is <strong>can I ship this right now?</strong> Not this week, not today: right this second. If not, what would have to change for me to be able to ship <em>something</em>? If the ship needs a deploy, can that happen now behind a feature flag? If we’re waiting on some other team to make a change on their end, can I make it so the system doesn’t strictly require their change after all? For instance, if the platform team is setting up a cache layer, I could make it so my feature still works (albeit a little slower) if it can’t find the cache.</p>
<p>Remember, your main priority is maintaining trust with your leadership team. Nothing builds trust like having fallback plans, because in case of emergency fallback plans indicate control over the situation. If the worst does happen and you can’t release on the day, your manager will be much happier going to their manager about it if they can say something like “our options are to delay four days, or ship tomorrow by sacrificing X” - even if sacrificing X is a non-starter. That means they’ll be more likely to interpret the delay as an unavoidable problem that you handled effectively, instead of as a mistake you made that means they can’t rely on you.</p>
<p>I think a lot of engineers hold off on deploys essentially out of fear. If you want to ship, you need to do the exact opposite: you need to deploy as much as you can as early as possible, and you need to do the scariest changes as early as you can possibly do them. Remember that you have the most end-to-end context on the project, which means <strong>you should be the least scared of scary changes</strong>. Everyone else is dealing with more unknowns and is going to be even less keen to pull the big lever. (If there’s some other engineer who is across all of this who you’re waiting for, bad news: they’re probably the one actually shipping your project).</p>
<h2>Summary</h2>
<ul>
<li>Shipping is really hard and you have to make it your main priority if you want to ship</li>
<li>Shipping doesn’t mean deploying code, it means making your leadership team happy</li>
<li>You need your leadership team to trust you in order to ship</li>
<li>Most of the essential technical work is in anticipating problems and creating fallback plans</li>
<li>You should asking yourself “can I ship right this second?”</li>
<li>Have courage!</li>
</ul></section><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: YubiKey still selling old stock with vulnerable firmware (246 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42110901</link>
            <guid>42110901</guid>
            <pubDate>Mon, 11 Nov 2024 22:12:55 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42110901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="42110901">
      <td><span></span></td>      <td><center><a id="up_42110901" href="https://news.ycombinator.com/vote?id=42110901&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=42110901">YubiKey still selling old stock with vulnerable firmware</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_42110901">110 points</span> by <a href="https://news.ycombinator.com/user?id=MaKey">MaKey</a> <span title="2024-11-11T22:12:55 1731363175"><a href="https://news.ycombinator.com/item?id=42110901">5 hours ago</a></span> <span id="unv_42110901"></span> | <a href="https://news.ycombinator.com/hide?id=42110901&amp;goto=item%3Fid%3D42110901">hide</a> | <a href="https://hn.algolia.com/?query=YubiKey%20still%20selling%20old%20stock%20with%20vulnerable%20firmware&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=42110901&amp;auth=4021db3eafedc4759e57670a23cc146521a8461c">favorite</a> | <a href="https://news.ycombinator.com/item?id=42110901">19&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><p>FYI, YubiKey is apparently still selling old stock with firmware vulnerable to the EUCLEAK attack instead of disposing of them, as a reader of Fefe's Blog reported:
https://blog.fefe.de/?ts=99ccc8dc</p></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="42111444"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42111444" href="https://news.ycombinator.com/vote?id=42111444&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>I hadn’t noticed the announcement of the vulnerability, looks like it’s nothing I care about for my “thread model”.</p><p><a href="https://www.theverge.com/2024/9/4/24235635/yubikey-unfixable-security-vulnerability-side-channel-explot" rel="nofollow">https://www.theverge.com/2024/9/4/24235635/yubikey-unfixable...</a></p><p>&gt;“The attacker would need physical possession of the YubiKey, Security Key, or YubiHSM, knowledge of the accounts they want to target, and specialized equipment to perform the necessary attack,” the company said in its security advisory. “Depending on the use case, the attacker may also require additional knowledge including username, PIN, account password, or authentication key.” But those aren’t necessarily deterrents to a highly motivated individual or state-sponsored attack.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42111985"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42111985" href="https://news.ycombinator.com/vote?id=42111985&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>The attacker would need physical possession of the [key]... Depending on the use case, the attacker may also require additional knowledge including... PIN, account password, or authentication key.</p><p>If you already had both these things, any vulnerability in the key's firmware would be moot, surely? It's hardly a surprise that 2FA can be compromised by compromising both factors.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42112037"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42112037" href="https://news.ycombinator.com/vote?id=42112037&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>The vulnerability allows extracting the secret key from a vulnerable device. If I remember correctly, it's after a successful auth / sign flow, which requires the login/password of the target website.</p><p>I could give you my security key and you'll be able to login once. If you can extract the key, then you could login without the security key. In the context of a targeted attack, that could heavily change the impact.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42112377"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42112377" href="https://news.ycombinator.com/vote?id=42112377&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>The whole point of a YubiKey is that it can produce inextractable keys so it cannot be forged/cloned.</p><p>Without that property, might as well use a &lt; 1$ Arduino clone that's 100x cheaper.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42111653"><td></td></tr>
                <tr id="42112030"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42112030" href="https://news.ycombinator.com/vote?id=42112030&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div>
                  <p>Yeah, but what isn't ever(?) mentioned is, "other" ECC keys are (should be) impacted by this too, not just FIDO2, i.e. ECC smart card certificates if you're using those.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42112057"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42112057" href="https://news.ycombinator.com/vote?id=42112057&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div>
                  <p>That's why I said it. I primarily use mine for signing commits with gpg. This use case isn't impacted since I use rsa keys.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42111262"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42111262" href="https://news.ycombinator.com/vote?id=42111262&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>Relevant bit:</p><p>&gt; Update: Ist sogar noch krasser, wie ein Leser anmerkt:</p><p>&gt; zu der Yubikey-Geschichte sei noch angemerkt, dass die aktuell sogar so dreist sind erstmal ihre Lagerbestände mit verwundbaren Keys abzuverkaufen anstatt die zu verschrotten. Hab neulich zwei von den Dingern bestellt (die teure FIPS-Variante!) und was bekomme ich geliefert? Die Keys mit der alten, verwundbaren Firmware. Hintergrund soll wohl sein, dass die zunächst Behörden und andere "priorisierte" Kunden mit den Keys mit der neuen Firmware beliefern.</p><p>Machine Translation:</p><p>&gt; Update: It's even more extreme, as a reader points out:</p><p>&gt; Regarding the Yubikey story, it should be noted that they are currently so brazen as to sell off their stock of vulnerable keys instead of scrapping them. I recently ordered two of those things (the expensive FIPS version!) and what do I get delivered? The keys with the old, vulnerable firmware. The background seems to be that they are initially supplying authorities and other "prioritized" customers with the keys that have the new firmware.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42112363"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42112363" href="https://news.ycombinator.com/vote?id=42112363&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>wtf.</p><p>And these YubiKey aren't exactly cheap. You'd expect the price to cover whatever they have to do on their end so that you do not receive a known vulnerable device.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42111666"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42111666" href="https://news.ycombinator.com/vote?id=42111666&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div>
                  <p>I would gladly take an old stock yubikey at a discount - my threat model doesn't have a serious need for resistance to stolen keys, because at the user level they're unlikely to not notice them missing for long enough to successfully attack and then replace to a keychain.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42111851"><td></td></tr>
                <tr id="42111869"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42111869" href="https://news.ycombinator.com/vote?id=42111869&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>The vulnerability, as another commenter mentions, is extremely hard to exploit and requires both physical access and the specific accounts to clone the key for.</p><p>That may be too much of a risk for enterprises, but as a personal security key? That seems like a completely reasonable choice to make.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42112061"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42112061" href="https://news.ycombinator.com/vote?id=42112061&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>A yubikey vulnerable to this attack perfectly protects against phishing, which is the attack the 99.9% of us have a practical reason to worry about.</p><p>Not all vulnerabilities are equal.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42112402"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42112402" href="https://news.ycombinator.com/vote?id=42112402&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div>
                  <p>If he understands the risks and deems those manageable according to their threat model, I don't see a problem.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42111935"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42111935" href="https://news.ycombinator.com/vote?id=42111935&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div>
                  <p>No, I'm not. I've got a bunch of yubikeys locked in lockboxes when they're not in use, serving as trust anchors for internal PKI, but also using certificate logging. If one is compromised, there's a short window until it's known, and access to the box has a very small group of people. My threat model does not include "Insider under the watchful eye of two other insiders"</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42112157"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42112157" href="https://news.ycombinator.com/vote?id=42112157&amp;how=up&amp;goto=item%3Fid%3D42110901"></a></center>    </td><td><br><div><p>&gt; My threat model does not include "Insider under the watchful eye of two other insiders"</p><p>Some Mastodon infosec grifter is going to name this "Insider Triple Threat".</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42112408"><td></td></tr>
                                    <tr id="42112025"><td></td></tr>
                <tr id="42112459"><td></td></tr>
                  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Don't Have Spotify (409 pts)]]></title>
            <link>https://github.com/sjdonado/idonthavespotify</link>
            <guid>42110877</guid>
            <pubDate>Mon, 11 Nov 2024 22:10:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sjdonado/idonthavespotify">https://github.com/sjdonado/idonthavespotify</a>, See on <a href="https://news.ycombinator.com/item?id=42110877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_product_navbar&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>

                  <li>
      
      
</li>

                  <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;white_papers_ebooks_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;white_papers_ebooks_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:sjdonado/idonthavespotify" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="KaBKyqNWJI7MJFx8B4Km1TrDWihtLkotgzdoUcU_etG9MIcNXLY01AOLSmVF3ewmvuQoQzzexAcbu8Omsum9-w" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="sjdonado/idonthavespotify" data-current-org="" data-current-owner="sjdonado" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=sjdonado%2Fidonthavespotify" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/sjdonado/idonthavespotify&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="47c22b4abf5f364d70e50b1b8f4f277b47f169180a011a7279d5ce3e785004da" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
          
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Steam Client Stability on Linux (312 pts)]]></title>
            <link>https://ttimo.typepad.com/blog/2024/11/the-steam-client-update-earlier-this-week-mentions-fixed-some-miscellaneous-common-crashes-in-the-linux-notes-which-i-wante.html</link>
            <guid>42110677</guid>
            <pubDate>Mon, 11 Nov 2024 21:41:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ttimo.typepad.com/blog/2024/11/the-steam-client-update-earlier-this-week-mentions-fixed-some-miscellaneous-common-crashes-in-the-linux-notes-which-i-wante.html">https://ttimo.typepad.com/blog/2024/11/the-steam-client-update-earlier-this-week-mentions-fixed-some-miscellaneous-common-crashes-in-the-linux-notes-which-i-wante.html</a>, See on <a href="https://news.ycombinator.com/item?id=42110677">Hacker News</a></p>
Couldn't get https://ttimo.typepad.com/blog/2024/11/the-steam-client-update-earlier-this-week-mentions-fixed-some-miscellaneous-common-crashes-in-the-linux-notes-which-i-wante.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[High Levels of Banned PFAS Detected in Hershey's Packaging (104 pts)]]></title>
            <link>https://grizzlyreports.com/hsy/</link>
            <guid>42110407</guid>
            <pubDate>Mon, 11 Nov 2024 21:02:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grizzlyreports.com/hsy/">https://grizzlyreports.com/hsy/</a>, See on <a href="https://news.ycombinator.com/item?id=42110407">Hacker News</a></p>
Couldn't get https://grizzlyreports.com/hsy/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The online sports gambling experiment (110 pts)]]></title>
            <link>https://thezvi.substack.com/p/the-online-sports-gambling-experiment</link>
            <guid>42110194</guid>
            <pubDate>Mon, 11 Nov 2024 20:29:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thezvi.substack.com/p/the-online-sports-gambling-experiment">https://thezvi.substack.com/p/the-online-sports-gambling-experiment</a>, See on <a href="https://news.ycombinator.com/item?id=42110194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Related: </span><a href="https://thezvi.substack.com/p/book-review-on-the-edge-the-gamblers" rel="">Book Review: On the Edge: The Gamblers</a></p><p>I have previously been heavily involved in sports betting. That world was very good to me. The times were good, as were the profits. It was a skill game, and a form of positive-sum entertainment, and I was happy to participate and help ensure the sophisticated customer got a high quality product. I knew it wasn’t the most socially valuable enterprise, but I certainly thought it was net positive. </p><p>When sports gambling was legalized in America, I was hopeful it too could prove a net positive force, far superior to the previous obnoxious wave of daily fantasy sports. </p><p>It brings me no pleasure to conclude that this was not the case. The results are in. Legalized mobile gambling on sports, let alone casino games, has proven to be a huge mistake. The societal impacts are far worse than I expected. </p><ol><li><p><a href="https://thezvi.substack.com/i/149404877/the-short-answer" rel="">The Short Answer.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/paper-one-bankruptcies" rel="">Paper One: Bankruptcies.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/paper-two-reduced-household-savings" rel="">Paper Two: Reduced Household Savings.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/paper-three-increased-domestic-violence" rel="">Paper Three: Increased Domestic Violence.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/the-product-as-currently-offered-is-terrible" rel="">The Product as Currently Offered is Terrible.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/things-sharp-players-do" rel="">Things Sharp Players Do.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/people-cannot-handle-gambling-on-smartphones" rel="">People Cannot Handle Gambling on Smartphones.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/yay-and-also-beware-trivial-inconveniences-a-future-full-post" rel="">Yay and Also Beware Trivial Inconveniences (a future full post).</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/how-does-this-relate-to-elite-hypocrisy" rel="">How Does This Relate to Elite Hypocrisy?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/the-standard-libertarian-counterargument" rel="">The Standard Libertarian Counterargument.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/what-about-other-prediction-markets" rel="">What About Other Prediction Markets?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/149404877/what-should-be-done" rel="">What Should Be Done.</a></p></li></ol><blockquote><p><a href="https://x.com/TheStalwart/status/1838750550738751772" rel="">Joe Weisenthal</a><span>: Why is it that sports gambling, specifically, has elicited a lot of criticism from people that would otherwise have more laissez faire sympathies?</span></p></blockquote><p>This full post is the long answer. </p><p>The short answer is that it is clear from studies and from what we see with our eyes that ubiquitous sports gambling on mobile phones, and media aggressively pushing wagering, is mostly predation on people who suffer from addictive behaviors. </p><p>That predation, due to the costs of customer acquisition and retention and the regulations involved, involves pushing upon them terrible products offered at terrible prices, pushed throughout the sports ecosystem and via smartphones onto highly vulnerable people. </p><p>This is not a minor issue. This is so bad that you can pick up the impacts in overall economic distress data. The price, on so many levels, is too damn high. </p><p><span>We start with discussion of one of several new </span><a href="https://x.com/econominable/status/1816217758490632485?s=46&amp;t=Yex5BoOgYCcDjK-O5XldbQ" rel="">working</a><span> </span><a href="https://t.co/ZFnnggqfrM" rel="">papers</a><span> studying the financial consequences of legalized sports betting. The impacts include a 28% overall increase in bankruptcies (!). </span></p><blockquote><p>Brett Hollenbeck: *Working Paper Alert*: “The Financial Consequences of Legalized Sports Gambling” by Poet Larsen, @dade_us and myself. </p><p>We study how the widespread legalization of sports gambling over the past five years has impacted consumer financial health.</p><p>In 2018, SCOTUS ruled that states cannot be prohibited from allowing sports betting, and 38 states have since legalized sports gambling. This has led to a large new industry and a large increase in gambling accessibility. Roughly $300 billion has been bet and is growing fast.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png" width="432" height="288" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:288,&quot;width&quot;:432,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b4ee037-1f08-4ba3-b795-79ce98c492a7_432x288.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>While for most gamblers it is a harmless form of recreation, we know that some fraction become problem gamblers with potentially severe financial consequences.</p><p>We study these financial outcomes using a large and comprehensive dataset on consumer finances known as the UC Consumer Credit Panel (maintained by @CAPolicyLab). This allows us to track all credit and debt outcomes for roughly 7 million Americans. </p><p>We leverage this data and compare states implementing sports gambling to those that don’t and study both sports gambling of any type as well as online/mobile gambling specifically. We study 8 financial/debt outcomes and find the following results:</p><p>First, credit scores, a summary metric of overall creditworthiness, decrease by modest but statistically significant amounts (~1%). We also test for evidence of pre-trends between treated/control states and find none.</p><p>…</p><p>Second, several measures of excessive debt increase substantially. We find a roughly 28% increase in bankruptcies and an 8% increase in debt transferred to debt collectors. Similarly, auto loan delinquencies increase substantially as does use of debt consolidation loans.</p><p>Interestingly, we find that banks restrict access to credit on average in affected states. Credit card limits decrease and the ratio of secured to unsecured loans increases. After three years post-legalization we actually find a decrease in credit card delinquencies as a result.</p></blockquote><p>I expected some negative impacts. But a 28% increase in bankruptcies is far more than I would have predicted. The typical adult bankruptcy rate is about 0.16%, so this would mean about 4bps (0.04%)/year of additional bankruptcies, or an over 1% additional chance a typical person goes bankrupt during their lifetime. </p><p>Alternatively as a sanity check, that’s on the order of 100,000 additional bankruptcies a year, which will rise over time if we don’t intervene. We are talking about an average handle of maybe 120 billion in 2023, but on average lower during this time period, let’s say average of 70 billion, with a likely sportsbook hold (before expenses) of something like 10% if we exclude advantage betters who are definitely not going bankrupt, given all the parlays and shaded lines and in-game betting and generally atrocious odds, so total net losses to ‘normal gamblers’ of 7 billion per year. </p><p>That suggests that for every $70k in net sportsbook gross profits from regular gamblers, someone filed for bankruptcy. That seems like a lot? It means those who are inclined to bet on sports are either often doing it out of desperation, or that the same causes that lead them to bet on sports and pushing them to the financial edge in other ways as well, and this is the straw breaking the camel’s back. Claude found it all plausible when I had it do a bunch of estimations. I do notice I am skeptical.</p><p>The result is clear. A bankruptcy is extremely socially expensive, on the order of $200k. That alone is almost triple the profits, and clearly wipes out all the social gains. </p><p>Legalized online sports betting is currently a deeply, deeply horrible deal. </p><p>I wish it were different. I am all for letting people do things, and I have enjoyed and benefited greatly from the ability to bet on sports. </p><p>And yes, I do think the majority of people who play plausibly get their money’s worth in entertainment, even at the outrageous prices charged. The problem is if a majority get a small benefit, and others get a huge loss, that is on net a disaster.</p><p>I can’t look at these findings, even if I don’t fully believe them, and not see a huge disaster from these effects alone.</p><p>I also can’t see a way in which the positive-sum benefits could justify that disaster.</p><p><span>We can then add a second paper, “</span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4881086" rel="">Gambling Away Stability: Sports Betting’s Impact on Vulnerable Households</a><span>.” They found that sports betting greatly reduced traditional net investments, while traditional gambling stays unchanged. </span></p><blockquote><p><a href="https://www.maximum-progress.com/p/should-sports-betting-be-banned" rel="">Maxwell Tabarrok</a><span>: The negative effects on investment are large relative to the sample mean. The average household invests about $360 a quarter so a $50 decrease in investment is a loss of 14%.</span></p></blockquote><p>This includes households that never bet.</p><p>If this is fully real, that’s holy **** territory. It’s an apocalypse. We are decreasing net household investment by 14%? Can there possibly be compensation for that? Alex Tabarrok notes that various details seem like they prove too much, and I agree it seems unlikely the effects are this large. But it can be a lot smaller than that, and still way too high. </p><p>There are a variety of goods households can choose to consume, including traditional gambling. If sports gambling were a regular consumption good that consumers were choosing because they enjoy it more, it wouldn’t be having these effects. Eating dramatically into savings rather than shifting the consumption basket, while not even reducing traditional gambling, says that consumers are clearly not responding rationally, and do not understand the choices they are making. </p><p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4938642" rel="">Here’s a third paper</a><span>, showing that sports betting increases domestic violence. When the home team suffers an upset loss while sports betting is legal, domestic violence that day goes up by 9% for the day, with lingering effects. </span></p><p>It is estimated 10 million Americans are victims of domestic violence each year.</p><p>Claude estimates if you extrapolate from this result that there might be a 3% overall increase in domestic violence as the result of legalized sports betting, which seems non-crazy given that betting on NFL home favorites is only a tiny portion of overall losses. </p><p><span>Again, this is an overall effect for the entire population. The percentage of people who bet on sports is rising rapidly, </span><a href="https://www.shu.edu/business/news/sports-poll-finds-slowed-growth-for-sports-betting.html#:~:text=Among%20the%20general%20population%2C%2037,2022%20it%20was%2041%20percent." rel="">but even so only 34% said they placed even one bet</a><span> in 2023, and many of those will be limited to nominal wagers on things like the Super Bowl and March Madness. </span><a href="https://www.wamc.org/news/2024-02-09/new-poll-finds-39-of-americans-bet-on-sporting-events-ahead-of-super-bowl-sunday" rel="">This survey has 39% sports betting participation</a><span>, with about 35% of betters betting at least once a week. So again, the effects on the households that actually gamble are far higher.</span></p><p>This is a huge direct cost to bear. Domestic violence ruins lives. It also is a huge indicator that this is causing large amounts of distress in various forms, and that those gambling on sports are not making rational or wise consumption decisions.</p><p>Meanwhile, frankly, the product emphasis and implementation sucks. Almost all of the legal implementations (e.g. everyone I know about except Circa) are highly predatory. That’s what can survive in this market.</p><p>Why? Predation is where the money is. There is no physical overhead at an online casino, but after paying for all the promotions and credit card payments and advertisements and licenses and infrastructure, the only way to make all that back under the current laws and business models is the above-mentioned 10%-style hold that comes from toxic offerings. </p><p>Thus high prices even on the main lines, even higher ones on parlays and in-game betting. Whenever I see lines on the TV I usually want to puke at how wide the prices are. In game odds are beyond obnoxious. Anyone this drives away is a customer they have decided not to want.</p><p>This is what the in-game odds look like when they’re relatively reasonable, and seriously, ow my balls:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg" width="420" height="559.9038461538462" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:420,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae7cec0b-1dc0-4075-968e-95a6f0958a02_3000x4000.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>(This still shows how crazy the ‘win probability’ calculation they do is, given it’s well outside the odds they themselves are offering and also makes no sense, although an inning later it went far more insane and I can’t help but share, then aside over…)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png" width="930" height="270" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:270,&quot;width&quot;:930,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:534811,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab969e0d-17e4-42f4-b8a1-958e8bca6397_930x270.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>All this is complemented by a strategy centered around free bet promotions (which makes the bonuses sound a lot bigger than they are), advertisements, promotional texts and emails and especially a barrage of push notifications. </p><p>Anyone showing any skill? They are shown the door.  </p><p><span>I don’t think this is central to the case that current legal sports betting is awful, </span><a href="https://www.bloomberg.com/news/articles/2024-09-27/sports-betting-apps-are-even-more-toxic-than-you-imagined?cmpid=BBD093024_MONEYSTUFF&amp;utm_medium=email&amp;utm_source=newsletter&amp;utm_term=240930&amp;utm_campaign=moneystuff" rel="">but it is illustrative what pros do in order to disguise themselves and get their wagers down</a><span>. That to do that, they make themselves look like the whales. Which means addicts.</span></p><p>I’m used to stories like this one, that’s normal:</p><blockquote><p><span>Ira Boudway (Bloomberg): If I open an account in New York, maybe for a few weeks I just bet the Yankees right before the game begins,” says Rufus Peabody, a pro bettor and co-host of the </span><em><a href="https://x.com/bettheprocess?lang=en" rel="">Bet the Process</a></em><span> podcast. If this trick works, the book sees these normie, hometown bets as a sign that it’s safe to raise his limits.</span></p></blockquote><p>It seems players have upped their game.</p><blockquote><p>One pro bettor I know set up a bot which logs in to his accounts every day between 2 and 4 a.m., to make it seem like he can’t get through the night without checking his bets. Another withdraws money and then reverses those withdrawals so it looks like he can’t resist gambling.</p><p><span>Simulating addictive behavior, says Peabody, is an effective way to get online sportsbooks to send you </span><a href="https://www.bloomberg.com/news/features/2022-03-30/sports-betting-app-promos-make-bettors-look-for-new-edge?sref=VBucTHzi" rel="">bonus money</a><span> and keep your accounts open. This isn’t necessarily because operators are targeting problem bettors, he says; they’re simply looking to identify and encourage customers who are likely to spend—and lose—the most. This just happens to be a good way to find and enable addicts, too.</span></p></blockquote><p>The rest of the post is filled with the usual statistics and tragic stories.</p><p>What I find interesting about these examples is that they are very level-1 plays.</p><p>As in, this is exactly what someone would do if they thought they were up against a system that was looking for signs of what type of player you are, but only in the most mechanical and simple sense. For this type of thing to work, the book must not be looking at details or thinking clearly or holistically.</p><p>If you had tried this stuff on me when I was watching customers, to the extent I noticed it at all, I am pretty sure I would if anything have caught you faster. </p><p>Vices and other distractions are constant temptations. When you carry a phone around with you, that temptation is ever present. </p><p>Indeed, I recently got a Pixel Watch, and the biggest benefit of it so far is that I can stay connected enough to not worry, and not be tempted to check for things, without the pull of what a phone can do. And we have repeatedly seen how distracting it is for kids in school to have the smartphone right there in their pocket. I have learned to be very, very careful with mobile games, even ones with no relevant microtransactions. </p><p>Putting gambling in your pocket makes the temptation to gamble ever-present. Even for those who can resist it, that is a not so cheap mental tax to pay, and likely to result in the occasional impulse bet, even without the constant notifications. First hit’s free. Constant offers that adjust to your responses, to get you to keep coming back. </p><p>Now consider that at least several percent of people have an acute gambling addiction or vulnerability. For them, this is like an alcoholic being forced to carry a flask around in their pocket 24/7, while talk of what alcohol to choose and how good it would be to use that flask right now gets constantly woven into all their entertainment, and they by default get notifications asking if now is a good time for a beer. You can have the apps back up and running within a minute, even if you delete them. </p><p>It was plausible that this was an acceptable situation, that people could mostly handle that kind of temptation. We have now run the experiment, and it is clear that too many of them cannot.</p><p>I am coming around to a generalized version of this principle. There is a vast difference between:</p><ol><li><p>Something being legal, ubiquitous, frictionless and advertised.</p></li><li><p>Something being available, mostly safe to get, but we make it annoying.</p></li><li><p>Something being actively illegal, where you can risk actual legal trouble.</p></li><li><p>Something being actively illegal and we really try to stop you (e.g. rape, murder). </p></li></ol><p>We’ve placed far too many productive and useful things in category 2 that should be in category 1. By contrast, we’ve taken too many destructive things, too many vices, that we long had the wisdom to put in category 2, and started putting them in category 1. </p><p>Prohibitions, putting such things into categories 3 and especially 4, tends to work out extremely poorly. Don’t do that unless absolutely necessary. Let people do privately destructive things if they want to do that. </p><p>Often, it is important that you make doing the wrong thing a little annoying. It is especially important to not make it annoying to do the productive things, and not annoying to instead do the destructive things. </p><p><a href="https://x.com/KelseyTuoc/status/1823112217979478260" rel="">The elite refrains from irresponsible gambling, but here sets up conditions where such irresponsible actions are the inevitable result. The actual big elite hypocrisy is not the failure to impose paternalistic rules on the non-elite, it is that we constantly</a><span> imposing extreme and expensive consumption requirements and restrictions on the non-elite when they are trying to live their lives and get their needs met. We impose these deeply restrictive, expensive and stupid elite norms on others all the time. </span></p><p>This paternalism severely damages their lives in numerous ways. This is the core reason why it is so difficult for ordinary people to pay their bills or raise families, despite earnings that would make them rich elsewhere or elsewhen. </p><p>These productive actions are severely restricted, because if you are going to be productive then you have to do so ‘correctly’ and obey all sorts of rules and requirements. Whereas if your actions are destructive, well then, go ahead, and it would be wrong of us to even enforce existing law.</p><p>That is a deeply toxic approach. We should reverse it. We should allow people to do productive actions as freely as possible, and put up frictions to sufficiently destructive actions. </p><p>Mobile gambling has shown itself to be a highly destructive action for its users, well in excess of any profits earned, sufficiently so as to substantially damage economic conditions. A that point, we need to draw the line.</p><p><a href="https://www.maximum-progress.com/p/should-sports-betting-be-banned" rel="">Maxwell Tabarrok makes the contrary case</a><span> that sports gambling is ordinary consumption, and we should not assume that so-called ‘vulnerable populations’ need protections from deciding to increase their consumption. He says the evidence is not compelling here. </span></p><p>His view is that this is no different from people buying Taylor Swift tickets. </p><p>In general I am highly sympathetic to this argument. I am not looking to tell people how much to invest or what goods to consume. But here I must strongly disagree.</p><p>I’ve certainly enjoyed consuming gambling, including in a few narrow small stakes cases where I wasn’t trying to be an advantage player. I think many others do so in ways that are not mistakes, or are mistakes we should allow them to make. </p><p>But ‘this is normal consumption’ seems to me like an absurd interpretation of the evidence above, and fails to understand the nature of the consumption being offered. You can’t place this ability to wager directly onto everyone’s phones at all times, putting the temptation at arm’s reach, see these consequences, and pretend these consequences are merely revealed preferences. </p><p>Most other prediction markets do not pose the same problems. They would not even if they greatly expanded and became more ‘normie’ friendly. </p><p>In particular, sports markets are highly related to and integrated into the most ‘normie’ of activities and into the related media, and they pay off quickly, and they’re ubiquitous, with something for you every day.</p><p>The legalized mobile online sports betting experiment is a clear failure. It should end. </p><p>You should need to go to a physical location to place fully legal bets of a non-trivial size, or at least interact with a human or bear some other cost or risk. </p><p>I’m fine with that location being the local sports bar, especially if the bar gets to book your action. Yes, I realize that will mean more illegal and untaxed online sports betting, but it is what it is. The barriers to doing that would do a lot of good work.  </p><p>At a bare minimum, the advertising and dark pattern complexes feeding this must be disempowered. The Federal Government should do what it can. The states should realize they are not doing themselves any favors and resist or undo this cash grab.</p><p>Legalized online casino gaming, allowing roulette or similar games from one’s phone, is of course far worse. That certainly should not be allowed via the internet. I am not keen to be expansive in what ‘counts as gambling’ but the obvious gambling that resolves in seconds and pays real money absolutely must go. We will need to figure out where to draw the line on ‘loot boxes’ and other game features, but if the more obnoxious and toxic versions of that got banned as well, that would be good too. </p><p><a href="https://www.slowboring.com/p/online-sports-betting-hurts-consumers" rel="">Ben Krauss and Milan Singh reach the same conclusion at Slow Boring</a><span>, although they are less willing to fully bite the bullet. </span><a href="https://x.com/KelseyTuoc/status/1822333974548537644" rel="">Kelsey Piper, who similar to me is loathe to tell people what they cannot do, does bite the bullet</a><span>. </span><a href="https://x.com/esaagar/status/1838200488698732944" rel="">Here Saagar Enjeti bites the bullet</a><span>. </span><a href="https://archive.fo/FeAy9#selection-687.0-687.45" rel="">Here Charles Fain Lehman at The Atlantic bites the bullet</a><span>. </span></p><p>Otherwise, as the amount of gambling expands, it is only going to get worse.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Security Is a Useless Controls Problem (108 pts)]]></title>
            <link>https://securityis.substack.com/p/security-is-a-useless-controls-problem</link>
            <guid>42110149</guid>
            <pubDate>Mon, 11 Nov 2024 20:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://securityis.substack.com/p/security-is-a-useless-controls-problem">https://securityis.substack.com/p/security-is-a-useless-controls-problem</a>, See on <a href="https://news.ycombinator.com/item?id=42110149">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>In this blog, I cover:</p><ul><li><p>A somewhat popular StackOverflow answer to introduce a metaphor about useless security posts</p></li><li><p>How to tell if a control is probably useless </p></li><li><p>Why useless bad for the industry, advising where to go from here, and tease a future series of blogs diving into specific common, useless controls in depth</p></li></ul><p><span>A resource that I (and many others, us security bloggers are all very original) advise aspiring security minds to do to learn security is to go on the </span><a href="https://security.stackexchange.com/" rel="nofollow ugc noopener">Security StackExchange</a><span> and read a bunch of the top questions and answers.</span></p><p><span>If you carry out this sage advice, you'll come across </span><a href="https://security.stackexchange.com/users/5411/tom-leek" rel="nofollow ugc noopener">Tom Leek</a><span>, the highest karma'ed answerer on the InfoSec exchange. He has a great way of explaining things. </span><a href="https://security.stackexchange.com/questions/33470/what-technical-reasons-are-there-to-have-low-maximum-password-lengths/33471#33471" rel="nofollow ugc noopener">My favorite answer he ever gave</a><span> responds to a query as to why so many applications still had character length restrictions (this was some years ago), typically eight characters, on passwords:</span></p><pre><code><code>Take five chimpanzees. Put them in a big cage. Suspend some bananas from the roof of the cage. Provide the chimpanzees with a stepladder. BUT also add a proximity detector to the bananas, so that when a chimp goes near the banana, water hoses are triggered and the whole cage is thoroughly soaked.

Soon, the chimps learn that the bananas and the stepladder are best ignored.

Now, remove one chimp, and replace it with a fresh one. That chimp knows nothing of the hoses. He sees the banana, notices the stepladder, and because he is a smart primate, he envisions himself stepping on the stepladder to reach the bananas. He then deftly grabs the stepladder... and the four other chimps spring on him and beat him squarely. He soon learns to ignore the stepladder.

Then, remove another chimp and replace it with a fresh one. The scenario occurs again; when he grabs the stepladder, he gets mauled by the _four_ other chimps -- yes, including the previous "fresh" chimp. He has integrated the notion of "thou shallt not touch the stepladder".

Iterate. After some operations, you have five chimps who are ready to punch any chimp who would dare touch the stepladder -- and none of them knows why.

---

Originally, some developer, somewhere, was working on an old Unix system from the previous century, which used the old [DES-based "crypt"](https://ftp.gnu.org/old-gnu/Manuals/glibc-2.2.3/html_chapter/libc_32.html), actually a password _hashing_ function derived from the DES block cipher. In that hashing function, only the first eight characters of the password are used (and only the low 7 bits of each character, as well). Subsequent characters are ignored. That's the banana.

The Internet is full of chimpanzees.
</code></code></pre><p><span>I love this answer.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-139798543" href="https://securityis.substack.com/p/security-is-a-useless-controls-problem#footnote-1-139798543" target="_self" rel="nofollow ugc noopener">1</a></span><span> The internet is indeed full of chimpanzees. Worse, this isn't just the lowly, uneducated masses; our security ecosystem is very much full of chimps. Our chimp behaviors are similar to the original DES issue above: we tend to invest in useless</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-139798543" href="https://securityis.substack.com/p/security-is-a-useless-controls-problem#footnote-2-139798543" target="_self" rel="nofollow ugc noopener">2</a></span><span> controls that don’t make sense, usually impacting operational effectiveness. </span></p><p><span>This is a huge problem for the security industry: I’d argue at least half of our efforts (or at least our budgets) go towards controls of minimal to non-existent value. I'd like to go over the implications of this; the next several (and probably many more a year until I retire or die) will be to understand the </span><em>why</em><span> for common, useless security controls.</span></p><p>If the control can only be explained in a nebulous way, such as "to improve security" or "for compliance reasons", that's probably a useless control. If the security-ish person forcing the control on you cannot adequately explain it, it's probably because they have no idea why themselves. If that security-ish person doesn't understand why, it's a good heuristic that there isn't a legitimate why at all.</p><p>"But Jon," you say, unhappily trapped in this conversation, "What if the reasoning is very complex and hard to explain to people who are not experienced security masters?". This is a fair question on the surface.</p><p>How many controls can you think of that you know are useful, and you genuinely know why they are, but you can't explain it in 2-3 sentences to someone with a modicum of technical understanding? Some examples:</p><ul><li><p>Encryption in transit is valuable because it prevents anyone with access to points on the network between you and your friend from viewing or modifying your messages</p></li><li><p>Private S3 buckets are valuable so you don't leak your data all over the place and have embarrassing articles written about you</p></li><li><p>Cross-site scripting (XSS) safe front-end frameworks like React are good because they prevent XSS. XSS is bad because it allows an attacker to take over your active web session and do horrible things</p></li></ul><p><span>See? Easy. There are many complex things about security, but these are almost all in </span><em>how</em><span> we do things. The why is almost always pretty simple.</span></p><p><span>You won't be able to give wonderful off-the-cuff explanations for </span><em>every </em><span>security control you ever implement. It's more that every control you consider, spend resources implementing, and spend other teams' resources in dealing with the implantation should be explainable after you think about it. The reason should never just be "to support our robust security posture." That's a tautology, and tautologies </span><a href="https://xkcd.com/703/" rel="nofollow ugc noopener">outside of XKCD comics</a><span> are bad.</span></p><p>When I rant about this with my peers, mentors, friends, family, and unfortunate bystanders at the bar, a common reframe is, "Why is this so bad"? It's still people caring about security. So what if some of that isn't as effective as it could be?</p><p>We are so resource-constrained as an industry. There's not enough manpower, budget, and political capital. We can't be wasteful while still being effective stewards of the systems and data entrusted to us. We can't waste any of it! And we certainly can't keep asking for more budget when we're blowing 50% of what we already have on useless crap.</p><p>People, going about their everyday lives and jobs with their own problems, deadlines, and OKRs, have a finite amount of fucks to give about security. You have to use those fucks very sparingly. We can only get the average person to do a few things to help secure themselves or their company; wasting most of those slots on uselessness is devastating. We can't afford to be chimps.</p><p>These also aren't decisions that only affect the implementing company. Many useless controls are in compliance and control frameworks and standard maturity models, forcing waste on whole swaths of companies.</p><p>Many, many more are added by well-meaning security teams to security questionnaires, forcing every company that tries to sell to them to at least spend time discussing why they don't do it. Sometimes this leads to much back and forth, wasting time on both sides. I've spent depressing amounts of time implementing useless controls, not for their value (there was none), but because the time cost was lower than explaining to prospects why we don't do them every single week. This is devastating to security teams at medium-sized companies; I know several 3-4-person security teams whose roadmaps are hamstrung due to the cost of customer requests for useless dribble. </p><p>Worse, useless controls may be added to contractual security addendums. Worst, these contractual requirements can be recursive: As a signing company, I not only have to implement the useless control myself but require all of my significant sub-processors to implement it as well. These types of contractual requirements can be depressingly hard to unwind, leaving the entire industry in a less secure state, not because we even think the control is useful anymore, but because we're contractually bound to beat up any chimp who tries to effect change and grab a banana.</p><p>Don't be a chimp.</p><p>Don't implement controls without knowing why! You should be able to figure out the threat model related to the control, understand the threat this control is mitigating or the outcome you're looking for, and vaguely, how. You don't need to understand the TLS handshake process, how keys are computed, or how cipher suites are negotiated, but you need to understand what TLS buys you and where that is actually useful.</p><p>If you're on a security team, you should demand this from your peers. </p><p><span>If you're a normal employee, engineer, or executive reading this post for some reason, you should demand this from your security team. Make them tell you why. If they can't in a satisfactory way, it's </span><em>probably</em><span> not because it's complicated but because they don't really know themselves. Send them this post as a response; I can use the impressions.</span></p><p>I'll be publishing a series of posts diving into useless controls that we still demand everywhere. Many of these are ones we call for all the time in industry everywhere, so I hope it'll be interesting!</p><p>Some of these are controls many of my friendly enterprise clients care deeply about still, and to avoid giving them an aneurysm, I'll confirm I actually carry those out where appropriate. I do carry them out, very well, because I like their money. </p><p>Do you agree? Disagree? Intensely? Do you have any other feedback for me? Please leave a comment below; I'd love to hear it! </p><p>In case you enjoy that kind of stack overflow answer as much as I do, here are my other favorites:</p><p><a href="https://security.stackexchange.com/questions/123234/how-can-i-explain-to-non-techie-friends-that-cryptography-is-good/123235#123235" rel="nofollow ugc noopener">https://security.stackexchange.com/questions/123234/how-can-i-explain-to-non-techie-friends-that-cryptography-is-good/123235#123235</a></p><p><a href="https://security.stackexchange.com/questions/93611/password-rules-should-i-disallow-leetspeak-dictionary-passwords-like-xkcds-t/93618#93618" rel="nofollow ugc noopener">https://security.stackexchange.com/questions/93611/password-rules-should-i-disallow-leetspeak-dictionary-passwords-like-xkcds-t/93618#93618</a></p><p><a href="https://security.stackexchange.com/questions/30410/how-do-i-know-a-piece-of-software-only-does-what-the-author-claims/30417#30417" rel="nofollow ugc noopener">https://security.stackexchange.com/questions/30410/how-do-i-know-a-piece-of-software-only-does-what-the-author-claims/30417#30417</a></p><p><a href="https://security.stackexchange.com/questions/54120/is-google-overreaching-by-forcing-me-to-use-tls/54129#54129" rel="nofollow ugc noopener">https://security.stackexchange.com/questions/54120/is-google-overreaching-by-forcing-me-to-use-tls/54129#54129 </a><span>(I enjoy that there was a time when people were concerned that Google was evil </span><em>for enforcing HTTPS</em><span>)</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every arthouse buff you know is pirating films (110 pts)]]></title>
            <link>https://i-d.co/article/streaming-arthouse-movies-john-waters-netflix-2024/</link>
            <guid>42109544</guid>
            <pubDate>Mon, 11 Nov 2024 18:58:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://i-d.co/article/streaming-arthouse-movies-john-waters-netflix-2024/">https://i-d.co/article/streaming-arthouse-movies-john-waters-netflix-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=42109544">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<div><p>Earlier this year, Daniel, a filmmaker from England, wanted to watch Béla Tarr’s take on <em>Macbeth</em>, a TV movie by the <a href="https://i-d.co/article/krisztian-eder-april-breeze-photo-zine/" data-type="link" data-id="https://i-d.co/article/krisztian-eder-april-breeze-photo-zine/">Hungarian</a> auteur that had aired in 1982 on the Magyar Televízió network. On <a href="https://i-d.co/article/arthouse-cannibal-movies/" data-type="link" data-id="https://i-d.co/article/arthouse-cannibal-movies/">arthouse</a> subreddits like /<a href="https://www.reddit.com/r/ObscureMedia/comments/ao6f3x/macbeth_1982_a_hungarian_tv_movie_adaptation_by/">ObscureMedia</a> and /<a href="https://www.reddit.com/r/criterion/comments/ku779v/does_anyone_here_know_where_i_can_watch_b%C3%A9la/">Criterion</a>, the film had become the subject of intrigue. It’s composed of just two takes, the first five minutes long, the second 57 minutes. The famous three witches are all played by men.&nbsp;</p><p>But in an era of supposedly infinite choices, Béla Tarr’s <em>Macbeth </em>is impossible to find.&nbsp;</p><p>No streaming service hosts the film, even the specialist ones, and a DVD that included it as a bonus feature is long out of print. But, like many a determined cinephile, Daniel did some digging, found an illegal stream on a “a random archive website” and let himself be flooded by Tarr’s existential universe.</p><p>For anyone interested in movies and their history, breaking the law is a common situation. If it’s not on iTunes, or Amazon, or any of the big streamers, niche streamers, or the scrappy upstarts like the ad-supported B-movie haven Tubi, what else is there to do? For every <em>Atlantics</em> (2019) or <em>All Quiet on the Western Front</em> (2022) – festival hits that got splashy streaming deals with Netflix – there are films from visionary, award-winning directors, like Hong Sang-soo, <a href="https://en.wikipedia.org/wiki/Vivian_Qu">Vivian Qu</a> and <a href="https://i-d.co/article/xavier-dolan-controversy-interview-new-film/">Xavier Dolan</a>, which never got official US or UK releases.&nbsp;</p><p>In other parts of the world, access is even more restricted. “The kinds of movies that get mainstream distribution in India are super limited,” says the Chennai-based filmmaker Ashwin Arvind. His discovery of arthouse cinema coincided with the realisation that Spanish director <a href="https://i-d.co/article/pedro-almodovar-strange-way-of-life-interview-pedro-pascal/">Pedro Almodóvar</a>’s films had no Indian distribution, so he streamed them illegally instead. “With India’s censor board there’s no way that we were getting any films with any graphic content uncut.”&nbsp;</p></div>


		<div data-image="408809" data-post="408773">
		
		<figure>
			<p><img decoding="async" width="2000" height="1250" src="https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?quality=90&amp;w=2000" alt="" loading="lazy" data-lazy-image="true" srcset="https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?w=3200&amp;quality=90 3200w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?resize=1024,640&amp;quality=90 1024w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?resize=768,480&amp;quality=90 768w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?resize=2000,1250&amp;quality=90 2000w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?resize=1536,960&amp;quality=90 1536w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Macbeth_001.jpg?resize=2048,1280&amp;quality=90 2048w" sizes="(max-width: 2000px) 100vw, 2000px">			</p>
					</figure>

		</div>


<div><p>Pre-2010 arthouse is even more scarce. The transition from physical media to streaming in the late 00s led to the quiet loss of a slew of films that had previously been available from specialist companies like Tartan, Artificial Eye <em>et al.</em> Apichatpong Weerasethakul’s <em>Blissfully Yours</em> won the <a href="https://i-d.co/article/photos-cannes-film-festival-francesc-planes-gonzo-glamour-debauchery/">Cannes Film Festival</a>’s Un Certain Regard prize back in 2002 and is not legally viewable anywhere. Federico Fellini’s rare circus documentary <em>I Clowns</em> (1970) was re-released a decade ago, only for its distribution deal to expire<em>. The Falls</em> (1980), the abstract three-hour debut movie of Peter Greenaway, known best for <em>The Cook, the Thief, His Wife &amp; Her Lover</em> (1989), has fallen into the abyss.&nbsp;</p><p>A slew of sites – most of them legally dubious – are making these forgotten films available to everyone. Rarefilmm is a curated online archive of hundreds of niche, hard-to-find movies, often lifted from their original film print, from 1910s silent films about New York starlets to Nicaraguan <a href="https://i-d.co/article/coming-of-age-documentaries/">coming-of-age</a> dramas from the 1980s. A regularly updated <a href="https://letterboxd.com/rhettman417/list/movies-on-rarefilmmcom/">list</a> on Letterboxd includes every film they feature, and an <a href="https://rarefilmm.com/chat-room/">online chatroom</a> sees visitors share recommendations based on what they’ve watched. Similarly, a collection of sites specialise in doing the same thing, organising films by their area of origin: be it <a href="https://sovietmoviesonline.com/">Soviet</a>, <a href="https://easterneuropeanmovies.com/">Eastern European</a> or <a href="https://asian-movies-online.com/">Asian</a>. Beyond these platforms, users on reddit regularly point people towards other sites, like archive.org, through which a quick search can uncover a hard to find film uploaded illegally online, if poorly signposted, years ago. Since May, the Rarefilmm following on X has <a href="https://web.archive.org/web/20240518064721/https://x.com/rarefilmm">nearly doubled</a>.&nbsp;</p></div>



<figure><blockquote><p>“I send my film to people all the time”</p><cite>crystal moselle</cite></blockquote></figure>



<div><p>Of course, cinephiles have been torrenting and sharing hard-to-find movies for two decades and change, but it’s occured mostly via private communities like <a href="https://en.wikipedia.org/wiki/Karagarga">Karagarga</a>, where users share links to barely-seen films and add subtitles to unsubtitled foreign language features. But a new boom in interest in those films, perhaps fuelled by Letterboxd’s rise to prominence, has created a greater appetite for the stuff that’s trickier to find.</p><p>Some filmmakers are all for it. “I send my film to people all the time,” says the director <a href="https://i-d.co/article/skate-kitchen-crystal-moselle/" data-type="link" data-id="https://i-d.co/article/skate-kitchen-crystal-moselle/">Crystal Moselle</a> (<em>The Black Sea</em>, HBO’s <em>Betty</em>). She won’t say which one. “There’s people that don’t have it in their countries, and spreading the word of the work to me is more important [than adhering to distribution rules].” Moselle says that pirated material was key to honing her craft. When she was in her early 20s, she would buy bootleg VHS copies of <em>Grey Gardens </em>and<em> </em>movies by Wong Kar-wai from vendors on the <a href="https://i-d.co/article/nuevayorkinos-instagram-photography/">New York City</a> sidewalk. The former, she says, was “the kind of film that really inspired me to make documentaries [that were] fly on the wall and voyeuristic.”&nbsp;</p><p>Filmmakers are moulded versions of their influences, so if the budding ones are only able to access whatever surfaces on VOD, then the possibility of making art that pushes against that standard becomes near-impossible. Examples like<em> All Quiet…</em> and <em>Atlantics</em> are the anomaly; for the most part, Netflix isn‘t prioritising arthouse and foreign language film. Streaming services operate in the world of media for mass consumption, subject to the same strict distribution rules as every other competitor. As a result, films fall out of their hands, or they can choose to remove a project – or sell off the rights of their projects to other services – should they choose. Their guiding principle is distribution, not preservation.&nbsp;</p><p>Master of scuzzy and distasteful American comedy <a href="https://i-d.co/article/john-waters-on-karma-the-art-of-selling-out-and-dropping-acid-at-70/">John Waters</a> has an allergy towards these new media behemoths. If filmmakers are more concerned with their film existing forever over the money it will make them in the short term, “don’t sell to Netflix,” is his advice. “It’s called show business, not show art.”</p><p>But even with his underground heritage, Waters equally represents the mixed feelings many filmmakers have towards the illegitimate way their work is seen. On one hand, he wants audiences to have access to the films that he makes. Simultaneously, he wants to ensure that he retains control over what those titles are.</p></div>


		<div data-image="408810" data-post="408773">
		
		<figure>
			<p><img decoding="async" width="2000" height="1250" src="https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?quality=90&amp;w=2000" alt="" loading="lazy" data-lazy-image="true" srcset="https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?w=3200&amp;quality=90 3200w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?resize=1024,640&amp;quality=90 1024w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?resize=768,480&amp;quality=90 768w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?resize=2000,1250&amp;quality=90 2000w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?resize=1536,960&amp;quality=90 1536w, https://i-d.co/wp-content/uploads/2024/11/01112024_Piracy_Pink-Flamingos_001.jpg?resize=2048,1280&amp;quality=90 2048w" sizes="(max-width: 2000px) 100vw, 2000px">			</p>
					</figure>

		</div>


<div><p>Waters‘ early work, so salacious it has routinely been destroyed by the censorship boards asked to grade it, has become arthouse catnip:&nbsp;films that young cinephiles once had to scourge for on shared VHS tapes are now find on digital clouds and drives. Films like <em>Eat Your Makeup </em>(1968), his 16mm comedy about a kidnapping nanny, and his Divine-starring short <em>The Diane Linkletter Story </em>(1970), have never been officially released, but have found cult audiences online via pirated streams. The source? “Don’t ask me!” he says.</p><p>Waters keeps an eye on what leaks online from his unreleased catalogue and files a Digital Millennium Copyright Act (DMCA) request for it to be removed when he spots something. “If you don’t watch over it and you allow it, you lose your copyright,” he says. While he accepts that the ones that have been officially released have been pirated and shared already, he really doesn’t want you to watch the unreleased ones illegally. “I don’t sign them at book signings. Some of those films I don’t want in distribution. They’re too old.” Even so, he appreciates the curated platforms that specialise in vintage films. “When I was starting, the only place you could ever see rare films was college film series,” he says. “Now you can look at every scene and every cut.”</p><p>Even so, no archive is perfect, and that’s where the global community of <em>extremely</em>&nbsp;online cinephiles come in. This June, Rarefilmm’s Whitehead posted a download of <em>Four Letter Word</em>, <a href="https://i-d.co/article/sean-baker-on-the-magical-honesty-of-the-florida-project-and-sliding-into-his-actors-dms/">Sean Baker</a>’s offbeat early comedy from 2000. After posting it, Baker himself reached out, asking Whitehead to delete it as well as&nbsp; <a href="https://i-d.co/wp-content/uploads/2024/10/bakerrarefilmm.jpg">sharing the news</a> that the film’s 4K restoration would be coming soon. And, later this month, Béla Tarr’s <em>Macbeth</em> will finally <a href="https://film.curzon.com/film/bela-tarr-a-curzon-collection/#synopsis">receive an official release</a> in the UK, via Curzon.&nbsp;</p><p>In the 15 years since Tarr’s <em>Macbeth</em> was last available to purchase, the illegal downloads and streams have helped quell the desires of those who were desperate to watch it, its legacy kept alive by some intrepid internet-literate cinephiles. The work that survives, it turns out, is the work that is out there to be seen.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making a trading Gameboy: A pocket exchange and algo trading platform (121 pts)]]></title>
            <link>https://questdb.io/blog/making-a-trading-gameboy/</link>
            <guid>42108907</guid>
            <pubDate>Mon, 11 Nov 2024 17:41:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://questdb.io/blog/making-a-trading-gameboy/">https://questdb.io/blog/making-a-trading-gameboy/</a>, See on <a href="https://news.ycombinator.com/item?id=42108907">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>QuestDB is a next-generation
  database for <a href="https://questdb.io/market-data/">market data</a>. It offers premium ingestion throughput,
  enhanced SQL analytics that can power through analysis, and cost-saving hardware efficiency. It's
  <a href="https://github.com/questdb/questdb">open source</a>, applies open formats, and is ideal for <a href="https://questdb.io/glossary/tick-data/">tick data</a>.</p>
<hr>
<p>So in a nutshell I made this:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/gb-vid.gif" loading="lazy"></p><figcaption>A trading Gameboy</figcaption></div></figure>
<h2 id="the-story">The story<a aria-label="Direct link to The story" title="Direct link to The story" href="https://questdb.io/blog/making-a-trading-gameboy/#the-story">​</a></h2>
<p>I didn't wake up one day thinking I'd make a trading Gameboy.</p>
<p>It all came about gradually. Some might say I fell into a rabbit hole.</p>
<p>While it's satisfying to create something, I took the most pleasure in learning
new things and gradually solving new problems.</p>
<p>This post is to share much of that I have learned.</p>
<h2 id="from-displaying-a-price">From displaying a price...<a aria-label="Direct link to From displaying a price..." title="Direct link to From displaying a price..." href="https://questdb.io/blog/making-a-trading-gameboy/#from-displaying-a-price">​</a></h2>
<p>My kid had a <a href="https://questdb.io/blog/raspberry-pi-5-benchmark/" rel="">Raspberry Pi</a> and he loved it.</p>
<p>Debian came pre-installed with a version of minecraft, and he really enjoyed
having a tiny single-board computer with dangling wires. Unfortunately, the
bare-bones setup was also a weakness and we ended up stepping on the HDMI
connector and rendering the board unusable.</p>
<p>One day, he asked if I could get him a replacement. Upon checking the
<a href="https://www.raspberrypi.com/" rel="noopener noreferrer nofollow">Raspberry Pi website</a>, I came across the
Raspberry Pi Pico microcontroller and a basic electronic kit with buttons, LEDs,
and a two-line display which seemed more appropriate for his age.</p>
<p>Unlike the Raspberry Pi computer, the Pico is a microcontroller. Mostly this
means it's not running an operating system and instead can run simple code. They
are also typically less powerful with only 256kb of RAM instead of Gigabytes for
the bigger brother, and have a lower clock speed.</p>
<p>However, this also means the controller starts immediately running your code
upon power up, and it does not have to share resources to maintain an underlying
system. This results in low power consumption, making them appropriate for
battery-powered use cases.</p>
<p>After blinking a few coloured LEDs, we found that we could use potentiometers to
control how much electricity would go through the circuit. We could then read
this value from a screen. With some tinkering, we made a calculator which would
multiply two numbers which are set using the potentiometer:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/calculator.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>This was a pretty cool object to bring to school for a demo, and both of us were
pretty satisfied. But it then occurred to me that we could do so much more with
these, particularly as I found that some versions of the Pico microcontroller
contained a wireless chip.</p>
<p>So, as someone deeply interested in finance, I knew that <em>technically</em> nothing
could stop me from connecting to, say, an API and then display stock prices on
the screen. And that's what I ended up doing with the Raspberry Pi Pico, and a
matrix of LEDs:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/led-matrix.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>There were a few variations of this idea with train times and so on, but the
main concept was there. It then occurred to me that simply looking at a price
may not be as interesting, so I started experimenting with charts instead.</p>
<p>This meant using a different display, able to render more details. I found one
called the
<a href="https://shop.pimoroni.com/products/pico-display-pack-2-0?variant=39374122582099" rel="noopener noreferrer nofollow">Pimoroni Pico Display Pack 2.0</a>,
which came with a lot of benefits for my use case.</p>
<ul>
<li>First, it included a socket, which means one can simply fit the
microcontroller to the back of the display and not worry with wires.</li>
</ul>
<ul>
<li>
<p>Second, it came with 4 built-in buttons which also simplifies wiring.</p>
</li>
<li>
<p>Lastly, it has a
<a href="https://github.com/pimoroni/pimoroni-pico/blob/main/micropython/modules/picographics/README.md" rel="noopener noreferrer nofollow">pretty robust library</a>
which allows you to display primitives on a screen such as text, lines,
squares, circles, polygons, etc.</p>
</li>
</ul>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/display-pack.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>Above I used the buttons to allow the player to take a long or short position in
the underlying. However, I quickly found the game uninteresting because it was
purely based on luck: Watch a line on the screen and go long/short/flat.</p>
<p>I knew I wanted to gamify this, but had to find a different model to make it
enjoyable.</p>
<h2 id="to-making-markets">...To making markets<a aria-label="Direct link to ...To making markets" title="Direct link to ...To making markets" href="https://questdb.io/blog/making-a-trading-gameboy/#to-making-markets">​</a></h2>
<p>It then occurred to me that a market-making game would be more interesting.</p>
<p>When market-making, you are quoting on both exchanges and over the counter,
hedging in the underlying market and taking/managing risk. A large difference
between market making and the previous game is that in market making, you are
constantly quoting both sides, and other participants come and trade against
you.</p>
<p>But you don't decide whether to buy or sell, your counterparties do. However,
you can then decide what to do with this position, for example hedge it
immediately, warehouse it, etc.</p>
<p>One particularly satisfying dynamic was to offset the flow: Get a position
through someone hitting your quotes and shortly after receive an opposite trade
which closes this position. While you could have closed the position yourself,
waiting for passive flow instead means you don't cross the bid-ask spread and
maximise your margin.</p>
<p>It quickly dawned on me that four buttons would not be sufficient. This led me
to the rabbit hole of 3D printing. I won't go into too much detail here, but I
bought a
<a href="https://www.prusa3d.com/fr/produit/kit-de-l-original-prusa-mini-2/" rel="noopener noreferrer nofollow">Prusa Mini +</a>,
some calipers, and after some measurements, a lot of trial and error, and a
lousy soldering job, I ended up with this.</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/gameboy-first.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<h2 id="game-on">Game on!<a aria-label="Direct link to Game on!" title="Direct link to Game on!" href="https://questdb.io/blog/making-a-trading-gameboy/#game-on">​</a></h2>
<p>In this game, there is a red line representing the fair value, and your bid and
offer prices in green and blue. You can control your quotes by increasing or
decreasing the spread, and skewing your quotes up and down to attract more flow
on the side you're axed on (where you have a preference or bias towards buying
or selling).</p>
<p>Say you just bought a lot of XYZ. You probably want to sell and don't want to
buy more of it. You would then skew your quotes down by a few basis points which
makes it more likely for you to sell (you are giving a more aggressive sell
price), and conversely less likely to buy.</p>
<p>However, at this stage I started running into some issues. The first was that
building this was very tedious. I had to solder a lot of cables within this box.
In addition, I was unsatisfied with the software side and the game felt slow and
clunky.</p>
<p>So with the same concept, I went for a complete overhaul.</p>
<h3 id="the-idea-of-the-game">The idea of the game<a aria-label="Direct link to The idea of the game" title="Direct link to The idea of the game" href="https://questdb.io/blog/making-a-trading-gameboy/#the-idea-of-the-game">​</a></h3>
<p>In this game, you act as a market-maker on the ETF markets. Your job is to quote
a tradeable bid price and ask price on the exchange at all times, while
answering OTC requests for larger trades and managing your risk. You control
your prices through algo parameters and fight for being first in the orderbook
on the side you prefer to trade on. You can also place orders manually.</p>
<p>To manage your risk, you can trade in the underlying markets. For example, if
you sell S&amp;P 500 ETFs, you are short. To mitigate this risk, you can buy a hedge
instrument (for example S&amp;P500 futures) which are perfectly correlated to the
ETF and therefore render yourself immune to market movements.</p>
<p>As you trade the ETFs on exchange and OTC, you accumulate risk which you can
choose to neutralise in the hedge markets. Doing so has a cost and reduces the
margin you make on each trade. So does trading the ETF directly with the market
as you'd pay the spread. You can execute hedges via algos such as TWAP which
make your hedge adjust slower, but also at a lower cost since you spread
execution over time.</p>
<p>If you're doing a good job, you capture a lot of flow, win a lot of trade
requests, and don't lose money nor take disproportionate risk. Events such as a
release new financial figures or major news happen from time to time, so you
want to make sure you're not outright long or short when this happens.
Additionally, you don't have the best latency, so you want to avoid keeping your
quotes during figures as you'd be subject to latency arbitrage.</p>
<p>Overall this is a good representation of the dynamics of market-making in the
ETF space, and a good entry point for beginners or junior traders to understand
the basic principles behind it.</p>
<h2 id="improving-the-hardware">Improving the hardware<a aria-label="Direct link to Improving the hardware" title="Direct link to Improving the hardware" href="https://questdb.io/blog/making-a-trading-gameboy/#improving-the-hardware">​</a></h2>
<p>Let's dig more into the constructive details.</p>
<h3 id="pcb">PCB<a aria-label="Direct link to PCB" title="Direct link to PCB" href="https://questdb.io/blog/making-a-trading-gameboy/#pcb">​</a></h3>
<p>To avoid cutting and soldering wires, the solution was a printed circuit board
(PCB). I downloaded <a href="https://www.kicad.org/" rel="noopener noreferrer nofollow">Kicad</a>, which is an open-source PCB
design tool, and got started. To my surprise, the process was much easier than I
thought and I could go from complete zero to ordering my PCBs online in a couple
of days.</p>
<p>The first step is to design the diagram, which means listing all components and
their connections in a schematic way. In my case, the diagram looks like the
following:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/kicad-schema.webp" loading="lazy"></p><figcaption>Click to zoom</figcaption></div></figure>
<p>The buttons are on the left-hand side. The microcontroller in the middle, the
display on the right. Other items include the speaker, the on-off button and the
battery management system which handles the lithium battery's charge and
discharge.</p>
<p>Once they are connected like this, the system knows I will need to route traces
between all these connector points, and we can start making the PCB.</p>
<p>To my surprise, the drawing of traces (the electrical connection between two
points) is done by hand. The schematic we just made only helps guiding
connections from one point to another and making sure all connections are
implemented.</p>
<p>So after designing the schematic, it was time to place the components on the
board and to draw the traces to join the related connectors:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/kicad-pcb.webp" loading="lazy"></p><figcaption>Click to zoom</figcaption></div></figure>
<p>I was particularly pleased to find that I could leave some copper exposed to
display text. It's something I found visually attractive.</p>
<p>Anyways, once the components are placed on the board and the connections are
drawn, you can export gerber files which you can then upload on
<a href="https://www.pcbway.com/" rel="noopener noreferrer nofollow">PCB Way</a> to order the boards. They arrived within 4
days which is impressive considering that their manufacturing involves many
steps, and that they shipped from China.</p>
<h3 id="3d-printed-case">3D printed Case<a aria-label="Direct link to 3D printed Case" title="Direct link to 3D printed Case" href="https://questdb.io/blog/making-a-trading-gameboy/#3d-printed-case">​</a></h3>
<p>Kicad allows us to export the PCB 3D model and footprint. This meant I could
design a case around it to 3D print later:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/pcb-3d.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>What's nice is that you can import the model into something like Autodesk Fusion
360, and then design the case around it. In this instance, I projected the PCB
sketch imported from Kicad (the purple lines) and created a structure around it
using offsets from the Kicad drawing. I left some holes for the screws and used
the feature which automatically models the thread in 3D:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/box-drawing.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>I designed this with the intent of leaving the PCB exposed, so the case was
simply covering the back of the PCB and the battery. The result is the simple
case displayed in red below which 3D-prints in half an hours or so:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/case-view.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<h2 id="rewriting-the-software">Rewriting the software<a aria-label="Direct link to Rewriting the software" title="Direct link to Rewriting the software" href="https://questdb.io/blog/making-a-trading-gameboy/#rewriting-the-software">​</a></h2>
<p>As mentioned, there was a lot to improve in the first software iteration.</p>
<p>For this new one, I decided to start from scratch.</p>
<h3 id="reference-price">Reference price<a aria-label="Direct link to Reference price" title="Direct link to Reference price" href="https://questdb.io/blog/making-a-trading-gameboy/#reference-price">​</a></h3>
<p>The previous game model was based on a random walk of the price. I know, it's
not ideal. But I started this fetching real prices and I soon found that this
was not ideal for a game for a few reasons.</p>
<p>First, in the space of few minutes, the prices don't change that much. Creating
the reference price myself meant I could inject events such as market crashes
and whatnot to spice things up a bit.</p>
<p>Another consideration was that the API calls from the Pico took a long time, and
this was a blocking operation.</p>
<p>The model looks like the following:</p>
<div><pre tabindex="0"><code><span><span>async</span><span> </span><span>def</span><span> </span><span>flow</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>BLUE</span><span>}</span><span>EXCHANGE</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>GREEN</span><span>}</span><span>Start Ref Price Service</span><span>{</span><span>ENDC</span><span>}</span><span>'</span><span>)</span><span></span><br></span><span><span>    </span><span>while</span><span> self</span><span>.</span><span>running</span><span>:</span><span></span><br></span><span><span>        self</span><span>.</span><span>price </span><span>=</span><span> </span><span>round</span><span>(</span><span>self</span><span>.</span><span>price</span><br></span><span><span>                           </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>+</span><span> self</span><span>.</span><span>next_jump</span><span>)</span><span></span><br></span><span><span>                           </span><span>+</span><span> random</span><span>.</span><span>uniform</span><span>(</span><span>-</span><span>0.01</span><span>,</span><span> </span><span>0.01</span><span>)</span><span> </span><span>*</span><span> random</span><span>.</span><span>uniform</span><span>(</span><span>0.0</span><span>,</span><span> </span><span>5.0</span><span>)</span><span> </span><span>*</span><span> self</span><span>.</span><span>vol_multiplier</span><span>,</span><span> </span><span>2</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>next_jump </span><span>=</span><span> </span><span>0</span><span></span><br></span><span><span></span><br></span><span><span></span><br></span><span><span>        </span><span>if</span><span> self</span><span>.</span><span>figures_mode</span><span>:</span><span></span><br></span><span><span>            self</span><span>.</span><span>figures_elapsed </span><span>+=</span><span> </span><span>1</span><span></span><br></span><span><span>            </span><span>if</span><span> self</span><span>.</span><span>figures_elapsed </span><span>&gt;</span><span> self</span><span>.</span><span>figures_duration</span><span>:</span><span></span><br></span><span><span>                self</span><span>.</span><span>figures_mode </span><span>=</span><span> </span><span>False</span><span></span><br></span><span><span>                self</span><span>.</span><span>figures_elapsed </span><span>=</span><span> </span><span>0</span><span></span><br></span><span><span>                self</span><span>.</span><span>reset_volatility</span><span>(</span><span>)</span><span></span><br></span><span><span>                </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>RED</span><span>}</span><span>JUMP</span><span>{</span><span>ENDC</span><span>}</span><span>: Exit high vola mode'</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>        </span><span>else</span><span>:</span><span></span><br></span><span><span>            self</span><span>.</span><span>ticks_to_next_jump </span><span>-=</span><span> </span><span>1</span><span></span><br></span><span><span>            </span><span>if</span><span> self</span><span>.</span><span>ticks_to_next_jump </span><span>&lt;</span><span> </span><span>0</span><span>:</span><span></span><br></span><span><span>                </span><span>from</span><span> config </span><span>import</span><span> FIGURES_VOL_MULT</span><br></span><span><span>                self</span><span>.</span><span>figures_mode </span><span>=</span><span> </span><span>True</span><span></span><br></span><span><span>                self</span><span>.</span><span>set_next_jump_time</span><span>(</span><span>)</span><span></span><br></span><span><span>                self</span><span>.</span><span>introduce_jump</span><span>(</span><span>)</span><span></span><br></span><span><span>                self</span><span>.</span><span>change_volatility</span><span>(</span><span>FIGURES_VOL_MULT </span><span>*</span><span> self</span><span>.</span><span>vol_multiplier</span><span>)</span><span></span><br></span><span><span>                </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>RED</span><span>}</span><span>JUMP</span><span>{</span><span>ENDC</span><span>}</span><span>: Jump triggered'</span><span>)</span><span></span><br></span><span><span>                </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>RED</span><span>}</span><span>JUMP</span><span>{</span><span>ENDC</span><span>}</span><span>: Enter high vola mode'</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>        </span><span>await</span><span> aio</span><span>.</span><span>sleep_ms</span><span>(</span><span>self</span><span>.</span><span>tick_rate</span><span>)</span><br></span></code></pre></div>
<p>Essentially, the whole game is based around a reference price, and that
reference price moves between two ticks following a random walk.</p>
<p>However, I introduced a figures concept whereby at certain moments, economic
figures are released, and the price jumps at that time. Then, markets are more
volatile (the price changes by a larger amount between two ticks), until such
point that it reverts to normal trading mode with standard volatility.</p>
<p>You can think of this reference price as the 'fair' price for the consensus of
market participants.</p>
<h3 id="exchange">Exchange<a aria-label="Direct link to Exchange" title="Direct link to Exchange" href="https://questdb.io/blog/making-a-trading-gameboy/#exchange">​</a></h3>
<p>With a reference price, I can start constructing other concepts. In the previous
iteration, there was only one bid and offer, meaning the player always won the
trades.</p>
<p>Because of this, I simulated the effects of player actions (skew and spread) by
affecting the relative probabilities that a player would receive a trade on
either bid or offer sides at each tick.</p>
<p>In this iteration, I wanted to simulate the dynamics of a real orderbook and
queue position. In the real world, you only get the trade if you're first in the
queue, and I wanted a similar dynamic:</p>
<div><pre tabindex="0"><code><span><span>def</span><span> </span><span>__init__</span><span>(</span><span>self</span><span>,</span><span> exchange</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>from</span><span> config </span><span>import</span><span> MAX_OB_SIZE</span><br></span><span><span>    self</span><span>.</span><span>sell_orders </span><span>=</span><span> </span><span>[</span><span>]</span><span></span><br></span><span><span>    self</span><span>.</span><span>buy_orders </span><span>=</span><span> </span><span>[</span><span>]</span><span></span><br></span><span><span>    self</span><span>.</span><span>exchange </span><span>=</span><span> exchange</span><br></span><span><span>    self</span><span>.</span><span>max_order_count </span><span>=</span><span> MAX_OB_SIZE</span><br></span><span><span>    self</span><span>.</span><span>last_order_type </span><span>=</span><span> </span><span>None</span><span></span><br></span><span><span></span><br></span><span><span></span><span>def</span><span> </span><span>add_order</span><span>(</span><span>self</span><span>,</span><span> trader_id</span><span>,</span><span> order_type</span><span>,</span><span> price</span><span>,</span><span> quantity</span><span>,</span><span> is_quote</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>"""</span><br></span><span><span>    Adds an order to the correct heap.</span><br></span><span><span>    Sets self.last_order_type so that the matching engine knows who</span><br></span><span><span>    was the aggressor. Otherwise, it may execute trades at the limit from the</span><br></span><span><span>    aggressor instead of the resting order.</span><br></span><span><span>    """</span><span></span><br></span><span><span>    </span><span>if</span><span> trader_id </span><span>in</span><span> self</span><span>.</span><span>exchange</span><span>.</span><span>traders</span><span>:</span><span></span><br></span><span><span>        order </span><span>=</span><span> Order</span><span>(</span><span>trader_id</span><span>,</span><span> price</span><span>,</span><span> quantity</span><span>,</span><span> is_quote</span><span>)</span><span></span><br></span><span><span>        </span><span>if</span><span> order_type </span><span>==</span><span> </span><span>'buy'</span><span>:</span><span></span><br></span><span><span>            heapq</span><span>.</span><span>heappush</span><span>(</span><span>self</span><span>.</span><span>buy_orders</span><span>,</span><span> </span><span>(</span><span>-</span><span>price</span><span>,</span><span> order</span><span>)</span><span>)</span><span></span><br></span><span><span>        </span><span>elif</span><span> order_type </span><span>==</span><span> </span><span>'sell'</span><span>:</span><span></span><br></span><span><span>            heapq</span><span>.</span><span>heappush</span><span>(</span><span>self</span><span>.</span><span>sell_orders</span><span>,</span><span> </span><span>(</span><span>price</span><span>,</span><span> order</span><span>)</span><span>)</span><span></span><br></span><span><span>        </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>BLUE</span><span>}</span><span>EXCHANGE</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>ORANGE</span><span>}</span><span>new </span><span>{</span><span>"quote"</span><span> </span><span>if</span><span> is_quote </span><span>else</span><span> </span><span>"order"</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span>: trader:</span><span>{</span><span>GREEN</span><span>}</span><span>{</span><span>trader_id</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> - </span><span>{</span><span>RED</span><span>}</span><span>{</span><span>order_type</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> - </span><span>{</span><span>CYAN</span><span>}</span><span>{</span><span>quantity</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> @ </span><span>{</span><span>RED</span><span>}</span><span>{</span><span>price</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span>'</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>last_order_type </span><span>=</span><span> order_type</span><br></span><span><span>        self</span><span>.</span><span>_match_orders</span><span>(</span><span>)</span><span></span><br></span><span><span>    </span><span>else</span><span>:</span><span></span><br></span><span><span>        </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>BLUE</span><span>}</span><span>EXCHANGE</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>RED</span><span>}</span><span>REJECTED ORDER</span><span>{</span><span>ENDC</span><span>}</span><span> trader_id </span><span>{</span><span>trader_id</span><span>}</span><span> is not registered'</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span></span><span>def</span><span> </span><span>_match_orders</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>"""</span><br></span><span><span>    This is the main logic of the matching engine</span><br></span><span><span>    Checks buy and sell orders both exist</span><br></span><span><span>    Then enters a loop while the best bid &gt;= best ask</span><br></span><span><span>    Exits loop and matching when that stops being the case</span><br></span><span><span>    When there is a match, issues a trade on both sides and reduces the</span><br></span><span><span>    remaining order by the matching size.</span><br></span><span><span>    """</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>while</span><span> self</span><span>.</span><span>buy_orders </span><span>and</span><span> self</span><span>.</span><span>sell_orders</span><span>:</span><span></span><br></span><span><span>        best_buy </span><span>=</span><span> self</span><span>.</span><span>buy_orders</span><span>[</span><span>0</span><span>]</span><span>[</span><span>1</span><span>]</span><span></span><br></span><span><span>        best_sell </span><span>=</span><span> self</span><span>.</span><span>sell_orders</span><span>[</span><span>0</span><span>]</span><span>[</span><span>1</span><span>]</span><span></span><br></span><span><span></span><br></span><span><span>        </span><span>if</span><span> </span><span>-</span><span>self</span><span>.</span><span>buy_orders</span><span>[</span><span>0</span><span>]</span><span>[</span><span>0</span><span>]</span><span> </span><span>&gt;=</span><span> self</span><span>.</span><span>sell_orders</span><span>[</span><span>0</span><span>]</span><span>[</span><span>0</span><span>]</span><span>:</span><span></span><br></span><span><span>            trade_quantity </span><span>=</span><span> </span><span>min</span><span>(</span><span>best_buy</span><span>.</span><span>quantity</span><span>,</span><span> best_sell</span><span>.</span><span>quantity</span><span>)</span><span></span><br></span><span><span>            </span><span>if</span><span> self</span><span>.</span><span>last_order_type </span><span>==</span><span> </span><span>'buy'</span><span>:</span><span></span><br></span><span><span>                trade_price </span><span>=</span><span> best_sell</span><span>.</span><span>price</span><br></span><span><span>            </span><span>else</span><span>:</span><span></span><br></span><span><span>                trade_price </span><span>=</span><span> </span><span>-</span><span>self</span><span>.</span><span>buy_orders</span><span>[</span><span>0</span><span>]</span><span>[</span><span>0</span><span>]</span><span></span><br></span><span><span></span><br></span><span><span>            best_buy</span><span>.</span><span>quantity </span><span>-=</span><span> trade_quantity</span><br></span><span><span>            best_sell</span><span>.</span><span>quantity </span><span>-=</span><span> trade_quantity</span><br></span><span><span>            edge </span><span>=</span><span> </span><span>int</span><span>(</span><span>(</span><span>trade_price </span><span>/</span><span> self</span><span>.</span><span>exchange</span><span>.</span><span>rpm</span><span>.</span><span>get_ref_price</span><span>(</span><span>)</span><span> </span><span>-</span><span>1</span><span>)</span><span> </span><span>*</span><span> </span><span>10_000</span><span>)</span><span></span><br></span><span><span>            </span><span>print</span><span>(</span><span>f"</span><span>{</span><span>BLUE</span><span>}</span><span>EXCHANGE</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>ORANGE</span><span>}</span><span>New trade</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>GREEN</span><span>}</span><span>{</span><span>trade_quantity</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> @ </span><span>{</span><span>RED</span><span>}</span><span>{</span><span>trade_price</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> between </span><span>{</span><span>GREEN</span><span>}</span><span>trader </span><span>{</span><span>best_buy</span><span>.</span><span>trader_id</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> and </span><span>{</span><span>GREEN</span><span>}</span><span>trader </span><span>{</span><span>best_sell</span><span>.</span><span>trader_id</span><span>}</span><span>{</span><span>ENDC</span><span>}</span><span> EDGE: </span><span>{</span><span>edge</span><span>}</span><span>"</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>notify_trade_listeners</span><span>(</span><span>Trade</span><span>(</span><span>best_buy</span><span>.</span><span>trader_id</span><span>,</span><span> best_sell</span><span>.</span><span>trader_id</span><span>,</span><span> trade_quantity</span><span>,</span><span> trade_price</span><span>,</span><span> edge</span><span>,</span><span> self</span><span>.</span><span>last_order_type</span><span>,</span><span> </span><span>False</span><span>,</span><span> </span><span>False</span><span>)</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>risk_engine</span><span>.</span><span>register_etf_trade</span><span>(</span><span>best_buy</span><span>.</span><span>trader_id</span><span>,</span><span> </span><span>'buy'</span><span>,</span><span> trade_quantity</span><span>,</span><span> trade_price</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>risk_engine</span><span>.</span><span>register_etf_trade</span><span>(</span><span>best_sell</span><span>.</span><span>trader_id</span><span>,</span><span> </span><span>'sell'</span><span>,</span><span> trade_quantity</span><span>,</span><span> trade_price</span><span>)</span><span></span><br></span><span><span>            </span><span>if</span><span> best_buy</span><span>.</span><span>quantity </span><span>==</span><span> </span><span>0</span><span>:</span><span></span><br></span><span><span>                heapq</span><span>.</span><span>heappop</span><span>(</span><span>self</span><span>.</span><span>buy_orders</span><span>)</span><span></span><br></span><span><span>            </span><span>if</span><span> best_sell</span><span>.</span><span>quantity </span><span>==</span><span> </span><span>0</span><span>:</span><span></span><br></span><span><span>                heapq</span><span>.</span><span>heappop</span><span>(</span><span>self</span><span>.</span><span>sell_orders</span><span>)</span><span></span><br></span><span><span>        </span><span>else</span><span>:</span><span></span><br></span><span><span>            </span><span>break</span><br></span></code></pre></div>
<p>The logic is that traders can add orders to the bid and ask sides of the
orderbook. These are then stored in a heapq.</p>
<p>Since the micropython implementation only implements minheap, I had to store one
of the sides by taking the opposite of the price so that it would be stored in
the correct order. This is why some negative signs appear in the code suce as
this <code>-self.buy_orders[0][0] &gt;= self.sell_orders[0][0]</code>.</p>
<h3 id="creating-agents">Creating agents<a aria-label="Direct link to Creating agents" title="Direct link to Creating agents" href="https://questdb.io/blog/making-a-trading-gameboy/#creating-agents">​</a></h3>
<p>Having done this, I could start creating agents. These agents would, for
example, place orders randomly in the book with a price relative to the current
reference price:</p>
<div><pre tabindex="0"><code><span><span>async</span><span> </span><span>def</span><span> </span><span>start_bot</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>from</span><span> random </span><span>import</span><span> choice</span><span>,</span><span> randint</span><br></span><span><span>    </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>BLUE</span><span>}</span><span>EXCHANGE</span><span>{</span><span>ENDC</span><span>}</span><span>: </span><span>{</span><span>GREEN</span><span>}</span><span>bot online</span><span>{</span><span>ENDC</span><span>}</span><span>'</span><span>)</span><span></span><br></span><span><span>    </span><span>while</span><span> </span><span>True</span><span>:</span><span></span><br></span><span><span>        ref_price </span><span>=</span><span> self</span><span>.</span><span>rpm</span><span>.</span><span>get_ref_price</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>orderbook</span><span>.</span><span>add_order</span><span>(</span><span>randint</span><span>(</span><span>0</span><span>,</span><span> self</span><span>.</span><span>bot_count</span><span>-</span><span>1</span><span>)</span><span>,</span><span></span><br></span><span><span>                                 choice</span><span>(</span><span>[</span><span>'buy'</span><span>,</span><span> </span><span>'sell'</span><span>]</span><span>)</span><span>,</span><span></span><br></span><span><span>                                 randint</span><span>(</span><span>int</span><span>(</span><span>0.995</span><span> </span><span>*</span><span> ref_price </span><span>*</span><span> </span><span>100</span><span>)</span><span>,</span><span> </span><span>int</span><span>(</span><span>1.005</span><span> </span><span>*</span><span> ref_price </span><span>*</span><span> </span><span>100</span><span>)</span><span>)</span><span> </span><span>/</span><span> </span><span>100</span><span>,</span><span></span><br></span><span><span>                                 randint</span><span>(</span><span>20</span><span>,</span><span> </span><span>800</span><span>)</span><span>,</span><span></span><br></span><span><span>                                 </span><span>False</span><span>)</span><span></span><br></span><span><span>        </span><span>await</span><span> aio</span><span>.</span><span>sleep_ms</span><span>(</span><span>self</span><span>.</span><span>bot_loop_ms</span><span>)</span><br></span></code></pre></div>
<p>The result of the above is a stream of orders coming on both sides of the
orderbook.</p>
<p>Some of these orders are resting, and populate the orderbook.</p>
<p>Some are crossing the spread, taking liquidity from the book, and resulting in
trade matches.</p>
<p>When a trade happens, both counterparties are notified, and the risk engine is
updated with the new positions.</p>
<p>This is a simple placeholder for now, but it's relatively easy to implement a
set of smarter agents, each with their own logic and incentives, including
competing market-makers, and arbitrageurs.</p>
<p>The player logic is different and more akin to controlling an algo:</p>
<div><pre tabindex="0"><code><span><span>def</span><span> </span><span>player_turn</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>from</span><span> master</span><span>.</span><span>cash_market_manager </span><span>import</span><span> HedgeOrder</span><br></span><span><span>    </span><span>if</span><span> self</span><span>.</span><span>turns_awaited </span><span>&gt;=</span><span> self</span><span>.</span><span>turn_latency</span><span>:</span><span></span><br></span><span><span>        self</span><span>.</span><span>turns_awaited </span><span>=</span><span> </span><span>0</span><span></span><br></span><span><span>        self</span><span>.</span><span>cancel_quotes</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>calculate_quotes</span><span>(</span><span>)</span><span></span><br></span><span><span>        </span><span>if</span><span> self</span><span>.</span><span>quoting</span><span>:</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>orderbook</span><span>.</span><span>add_order</span><span>(</span><span>self</span><span>.</span><span>trader_id</span><span>,</span><span> </span><span>'buy'</span><span>,</span><span> self</span><span>.</span><span>own_bid</span><span>,</span><span> self</span><span>.</span><span>clip_size</span><span>,</span><span> </span><span>True</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>orderbook</span><span>.</span><span>add_order</span><span>(</span><span>self</span><span>.</span><span>trader_id</span><span>,</span><span> </span><span>'sell'</span><span>,</span><span> self</span><span>.</span><span>own_ask</span><span>,</span><span> self</span><span>.</span><span>clip_size</span><span>,</span><span> </span><span>True</span><span>)</span><span></span><br></span><span><span>        </span><span>if</span><span> self</span><span>.</span><span>auto_hedge_active</span><span>:</span><span></span><br></span><span><span>            self</span><span>.</span><span>exchange</span><span>.</span><span>cash_market</span><span>.</span><span>cancel_hedges</span><span>(</span><span>self</span><span>.</span><span>trader_id</span><span>)</span><span></span><br></span><span><span>            risk </span><span>=</span><span> self</span><span>.</span><span>exchange</span><span>.</span><span>risk_engine</span><span>.</span><span>risk_metrics</span><span>[</span><span>self</span><span>.</span><span>trader_id</span><span>]</span><span></span><br></span><span><span>            q </span><span>=</span><span> </span><span>-</span><span>risk</span><span>.</span><span>etf_position </span><span>-</span><span> risk</span><span>.</span><span>hedge_position</span><br></span><span><span>            </span><span>if</span><span> </span><span>abs</span><span>(</span><span>q</span><span>)</span><span> </span><span>&gt;</span><span> self</span><span>.</span><span>auto_hedge_threshold</span><span>:</span><span></span><br></span><span><span>                side_is_buy </span><span>=</span><span> </span><span>True</span><span> </span><span>if</span><span> q </span><span>&gt;</span><span> </span><span>0</span><span> </span><span>else</span><span> </span><span>False</span><span></span><br></span><span><span>                self</span><span>.</span><span>exchange</span><span>.</span><span>cash_market</span><span>.</span><span>add_cash_order</span><span>(</span><span>HedgeOrder</span><span>(</span><span>side_is_buy</span><span>,</span><span> </span><span>abs</span><span>(</span><span>q</span><span>)</span><span>,</span><span> self</span><span>.</span><span>trader_id</span><span>,</span><span> </span><span>max</span><span>(</span><span>20</span><span>,</span><span>int</span><span>(</span><span>abs</span><span>(</span><span>q</span><span>)</span><span>/</span><span>20</span><span>)</span><span>)</span><span>)</span><span>)</span><span></span><br></span><span><span>    </span><span>else</span><span>:</span><span></span><br></span><span><span>        self</span><span>.</span><span>turns_awaited </span><span>+=</span><span> </span><span>1</span><span></span><br></span><span><span></span><br></span><span><span></span><span>def</span><span> </span><span>calculate_quotes</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    spot </span><span>=</span><span> self</span><span>.</span><span>rpm_price</span><br></span><span><span>    spot_skewed </span><span>=</span><span> spot </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>+</span><span> self</span><span>.</span><span>skew_bps </span><span>/</span><span> </span><span>10000</span><span>)</span><span></span><br></span><span><span>    half_spread </span><span>=</span><span> spot_skewed </span><span>*</span><span> self</span><span>.</span><span>spread_bps </span><span>/</span><span> </span><span>10000</span><span> </span><span>/</span><span> </span><span>2</span><span></span><br></span><span><span>    self</span><span>.</span><span>own_bid</span><span>,</span><span> self</span><span>.</span><span>own_ask </span><span>=</span><span> </span><span>round</span><span>(</span><span>spot_skewed </span><span>-</span><span> half_spread</span><span>,</span><span> </span><span>2</span><span>)</span><span>,</span><span> </span><span>round</span><span>(</span><span>spot_skewed </span><span>+</span><span> half_spread</span><span>,</span><span> </span><span>2</span><span>)</span><br></span></code></pre></div>
<p>The parameter <code>turn_latency</code> is so that a player's algo can only update quotes
periodically. This replicates the throttling implemented by exchanges whereby
traders cannot continuously update their quotes with every tick.</p>
<p>When the latency has elapsed, a few things happen:</p>
<ol>
<li>The current player quotes are cancelled with the exchange</li>
<li>New quotes are calculated using the current quoting parameters</li>
<li>The quotes are sent back to the exchange.</li>
</ol>
<p>In addition, other orders may be sent automatically to another market for
hedging if the player sets up their algo to automatically hedge the flow.</p>
<h3 id="display">Display<a aria-label="Direct link to Display" title="Direct link to Display" href="https://questdb.io/blog/making-a-trading-gameboy/#display">​</a></h3>
<p>I decided to split the display into a bunch of sections which can be rendered
separately.</p>
<p>For example, here is the class displaying the current ref price on the screen.</p>
<div><pre tabindex="0"><code><span><span>from</span><span> frames</span><span>.</span><span>bounded_area </span><span>import</span><span> BoundedArea</span><br></span><span><span></span><span>from</span><span> config </span><span>import</span><span> CHART_WIDTH</span><br></span><span><span></span><br></span><span><span></span><span>class</span><span> </span><span>PriceSection</span><span>:</span><span></span><br></span><span><span>    </span><span>def</span><span> </span><span>__init__</span><span>(</span><span>self</span><span>,</span><span> player</span><span>,</span><span> display</span><span>)</span><span>:</span><span></span><br></span><span><span>        </span><span>from</span><span> config </span><span>import</span><span> PRICE_SECTION_HEIGHT</span><br></span><span><span>        self</span><span>.</span><span>player </span><span>=</span><span> player</span><br></span><span><span>        self</span><span>.</span><span>area </span><span>=</span><span> BoundedArea</span><span>(</span><span>display</span><span>,</span><span> </span><span>1</span><span> </span><span>+</span><span> CHART_WIDTH</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>320</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>-</span><span> CHART_WIDTH </span><span>-</span><span> </span><span>1</span><span>,</span><span></span><br></span><span><span>                                PRICE_SECTION_HEIGHT</span><span>,</span><span> </span><span>'GRAY'</span><span>,</span><span> </span><span>'BLACK'</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>def</span><span> </span><span>plot_all</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>        self</span><span>.</span><span>area</span><span>.</span><span>draw_background</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>display_price</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>area</span><span>.</span><span>draw_perimeter</span><span>(</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>def</span><span> </span><span>display_price</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>        price </span><span>=</span><span> self</span><span>.</span><span>player</span><span>.</span><span>ref_prices</span><span>.</span><span>array</span><span>[</span><span>-</span><span>1</span><span>]</span><span></span><br></span><span><span>        self</span><span>.</span><span>area</span><span>.</span><span>write_centred</span><span>(</span><span>'{0:.2f}'</span><span>.</span><span>format</span><span>(</span><span>price</span><span>)</span><span>,</span><span> </span><span>'WHITE'</span><span>,</span><span> </span><span>1</span><span> </span><span>+</span><span> CHART_WIDTH</span><span>,</span><span></span><br></span><span><span>                                </span><span>320</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>-</span><span> CHART_WIDTH </span><span>-</span><span> </span><span>1</span><span>,</span><span> </span><span>5</span><span>,</span><span> </span><span>2</span><span>)</span><br></span></code></pre></div>
<p>So in this case, this is what displays the price in the top-right corner with a
value of 50.22:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/display-price.webp" loading="lazy"></p><figcaption></figcaption></div></figure>
<p>There are multiple other sections like this. The one displaying the chart area,
the one with the controls, the news, the risk section, the market depth chart,
the orderbook table, the trades feed, and so on.</p>
<p>By rendering them independently, I can then place them relatively to one another
and potentially schedule their update cycles at different moments if needed.</p>
<h2 id="some-things-i-learned">Some things I learned<a aria-label="Direct link to Some things I learned" title="Direct link to Some things I learned" href="https://questdb.io/blog/making-a-trading-gameboy/#some-things-i-learned">​</a></h2>
<h3 id="buttons-are-not-that-simple">Buttons are not that simple<a aria-label="Direct link to Buttons are not that simple" title="Direct link to Buttons are not that simple" href="https://questdb.io/blog/making-a-trading-gameboy/#buttons-are-not-that-simple">​</a></h3>
<p>It is really easy to program a microcontroller to react to a button press.
Connect the button, and write some micropython like the following:</p>
<div><pre tabindex="0"><code><span><span>import</span><span> machine</span><br></span><span><span>button </span><span>=</span><span> machine</span><span>.</span><span>Pin</span><span>(</span><span>12</span><span>,</span><span> machine</span><span>.</span><span>Pin</span><span>.</span><span>IN</span><span>,</span><span> machine</span><span>.</span><span>Pin</span><span>.</span><span>PULL_UP</span><span>)</span><span></span><br></span><span><span></span><span>while</span><span> </span><span>True</span><span>:</span><span></span><br></span><span><span>    </span><span>if</span><span> </span><span>not</span><span> button</span><span>.</span><span>value</span><span>(</span><span>)</span><span>:</span><span></span><br></span><span><span>        </span><span>print</span><span>(</span><span>'Button pressed!'</span><span>)</span><br></span></code></pre></div>
<p>However when the program becomes larger, this approach stops working. One of the
reasons is that you may be pressing the button at the moment where the loop is
executing some other code.</p>
<p>By the time your code gets back to evaluating <code>button.value()</code>, you may have
released it. Ideally, you'd want your inputs to be immediately registered.</p>
<p>Another consideration is that button presses, from a signal perspective, are not
how one intuitively may think. Instinct tells us that the button is an on/off
switch, and therefore pressing it should look like the following:</p>
<div><pre tabindex="0"><code><span><span></span><br></span><span><span>____________|-----------------------|__________________</span><br></span><span><span>            ^                       v</span><br></span><span><span>          press                  release</span><br></span></code></pre></div>
<p>However, in practice, it looked more like the following.</p>
<div><pre tabindex="0"><code><span><span></span><br></span><span><span>____________|-|_|-|_|-|_|--------|__________________</span><br></span><span><span>            ^                       v</span><br></span><span><span>          press                  release</span><br></span></code></pre></div>
<p>It seems like the signal needs to stabilise after a button press and may
oscillate initially, even if the button is pressed continuously. This has two
consequences.</p>
<ul>
<li>First, it means you may register several presses instead of one.</li>
</ul>
<ul>
<li>Second, depending on timing, your software may not register a button press if
the signal jumped to the low state at that exact time.</li>
</ul>
<p>To circumvent this, I used <code>interrupt requests</code> which will monitor a signal
change and interrupt execution to run the routine called by the button press. I
coupled this with a timeout to avoid processing the same button input multiple
times.</p>
<p>In this case, the trigger is the 'falling' edge of the signal:</p>
<div><pre tabindex="0"><code><span><span>    </span><span>def</span><span> </span><span>__init__</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>        </span><span>from</span><span> machine </span><span>import</span><span> Pin</span><br></span><span><span>        self</span><span>.</span><span>last_change_ms </span><span>=</span><span> ticks_ms</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>callbacks </span><span>=</span><span> </span><span>{</span><span>}</span><span></span><br></span><span><span></span><br></span><span><span>        self</span><span>.</span><span>red_button </span><span>=</span><span> Pin</span><span>(</span><span>13</span><span>,</span><span> mode</span><span>=</span><span>Pin</span><span>.</span><span>IN</span><span>,</span><span> pull</span><span>=</span><span>Pin</span><span>.</span><span>PULL_UP</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>red_button</span><span>.</span><span>irq</span><span>(</span><span>trigger</span><span>=</span><span>Pin</span><span>.</span><span>IRQ_FALLING</span><span>,</span><span> handler</span><span>=</span><span>self</span><span>.</span><span>red_isr</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>def</span><span> </span><span>red_isr</span><span>(</span><span>self</span><span>,</span><span> pin</span><span>)</span><span>:</span><span></span><br></span><span><span>        </span><span>if</span><span> </span><span>'RE'</span><span> </span><span>in</span><span> self</span><span>.</span><span>callbacks </span><span>and</span><span> time</span><span>.</span><span>ticks_diff</span><span>(</span><span>ticks_ms</span><span>(</span><span>)</span><span>,</span><span> self</span><span>.</span><span>last_change_ms</span><span>)</span><span> </span><span>&gt;</span><span> BTN_FREQ_MS</span><span>:</span><span></span><br></span><span><span>            </span><span>print</span><span>(</span><span>f'</span><span>{</span><span>RED</span><span>}</span><span>BUTTONS</span><span>{</span><span>ENDC</span><span>}</span><span>: notifying button listener </span><span>{</span><span>RED</span><span>}</span><span>RED</span><span>{</span><span>ENDC</span><span>}</span><span>'</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>callbacks</span><span>[</span><span>'RE'</span><span>]</span><span>(</span><span>)</span><span></span><br></span><span><span>            self</span><span>.</span><span>last_change_ms </span><span>=</span><span> ticks_ms</span><span>(</span><span>)</span><br></span></code></pre></div>
<p>Since the same button may have different functions depending on the context, for
example depending on which menu you are currently in, each button press is
triggering a callback.</p>
<p>Changes in menu context send a list of callbacks to override the previous one
and setup the new actions. I found this made the buttons more generic.</p>
<h3 id="ram-issues">RAM issues<a aria-label="Direct link to RAM issues" title="Direct link to RAM issues" href="https://questdb.io/blog/making-a-trading-gameboy/#ram-issues">​</a></h3>
<p>I quickly ended up with memory issues whereby the program would crash with an
error message such as <code>Memory allocation failed, failed to allocate 256 bytes</code>
or something like this.</p>
<p>What happened here is two things.</p>
<ul>
<li>First, 256kb is not so much</li>
<li>Second, it is relatively easy to end up with memory fragmentation.
Fragmentation means that I have enough bytes in memory to allocate to my
object, however these bytes are not contiguous and scattered across the memory
range making the allocation impossible.</li>
</ul>
<p>I watched a few videos from the creator of
<a href="https://micropython.org/" rel="noopener noreferrer nofollow">MicroPython</a>, and read documentation online. This led
to a few discoveries which helped.</p>
<h4 id="using-const">Using const()<a aria-label="Direct link to Using const()" title="Direct link to Using const()" href="https://questdb.io/blog/making-a-trading-gameboy/#using-const">​</a></h4>
<p>Say you have config values which won't change at runtime. When defining them as
<code>LOOP_FREQUENCY_MS = 250</code>, this may create a variable which requires more
memory. In this example, the system may allocate 32 bits for an <code>int</code> whereas I
only need 8 bits.</p>
<p>In some instances, for example when writing <code>c = 22 ... a = b x c</code>, I now
understand the compiler may detect that 22 is a constant and therefore apply
this for you, but being explicit does not hurt.</p>
<h4 id="proactive-memory-defragmentation">Proactive memory defragmentation<a aria-label="Direct link to Proactive memory defragmentation" title="Direct link to Proactive memory defragmentation" href="https://questdb.io/blog/making-a-trading-gameboy/#proactive-memory-defragmentation">​</a></h4>
<p>MicroPython has a garbage collection mechanism which triggers automatically.</p>
<p>However, it may only trigger once the memory is already fragmented, and not be
able to help. When starting up the game, I create a lot of objects. As a result,
this may not immediately trigger a connection.</p>
<p>I used <code>gc.collect()</code> profusely at startup and found that this helps make sure
that whatever memory is consumed by my objects is packed tighter together to
reduce fragmentation and its effects down the line.</p>
<h4 id="precompiling">Precompiling<a aria-label="Direct link to Precompiling" title="Direct link to Precompiling" href="https://questdb.io/blog/making-a-trading-gameboy/#precompiling">​</a></h4>
<p>MicroPython is an interpreted language whereby the code you write is transformed
into bytecode at compilation time. However, this compilation happens at startup
on the board itself, and can leave a significant memory footprint behind.</p>
<p>As I was struggling with memory issues, I considered compiling ahead of time,
and copying the files to the board.</p>
<p>The compile script uses <a href="https://pypi.org/project/mpy-cross/" rel="noopener noreferrer nofollow">mpy-cross</a> and
looks like this:</p>
<div><pre tabindex="0"><code><span><span>#!/bin/sh</span><br></span><span><span></span><br></span><span><span>MPY_CROSS="mpy-cross/./mpy-cross"</span><br></span><span><span>SOURCE_DIR="."</span><br></span><span><span>BUILD_DIR="$HOME/build"</span><br></span><span><span></span><br></span><span><span>echo "### Starting build"</span><br></span><span><span></span><br></span><span><span>compile_to_mpy() {</span><br></span><span><span>    local src_file="$1"</span><br></span><span><span>    local dest_file="$2"</span><br></span><span><span>    mkdir -p "$(dirname "$dest_file")"</span><br></span><span><span>    $MPY_CROSS "$src_file" -o "$dest_file"</span><br></span><span><span>}</span><br></span><span><span></span><br></span><span><span>copy_file() {</span><br></span><span><span>    local src_file="$1"</span><br></span><span><span>    local dest_file="$2"</span><br></span><span><span>    mkdir -p "$(dirname "$dest_file")"</span><br></span><span><span>    cp "$src_file" "$dest_file"</span><br></span><span><span>}</span><br></span><span><span></span><br></span><span><span># Clear the build directory at the start</span><br></span><span><span>rm -rf "$BUILD_DIR"</span><br></span><span><span>mkdir -p "$BUILD_DIR"</span><br></span><span><span></span><br></span><span><span>echo "### Starting build"</span><br></span><span><span>find "$SOURCE_DIR" -type d -name "mpy-cross" -prune -o -type f -print | while read -r src_file; do</span><br></span><span><span>    relative_path="${src_file#$SOURCE_DIR/}"</span><br></span><span><span>    if [[ "$src_file" == *.py ]]; then</span><br></span><span><span>        dest_file="$BUILD_DIR/${relative_path%.py}.mpy"</span><br></span><span><span>        echo "### Compiling $dest_file"</span><br></span><span><span>        compile_to_mpy "$src_file" "$dest_file"</span><br></span><span><span>    elif [[ "$src_file" == *.txt ]]; then</span><br></span><span><span>        echo "### Copying raw $dest_file"</span><br></span><span><span>        dest_file="$BUILD_DIR/$relative_path"</span><br></span><span><span>        copy_file "$src_file" "$dest_file"</span><br></span><span><span>    fi</span><br></span><span><span>    if [[ "$src_file" == *ain.py ]]; then</span><br></span><span><span>        echo "### Copying raw $dest_file"</span><br></span><span><span>        dest_file="$BUILD_DIR/$relative_path"</span><br></span><span><span>        copy_file "$src_file" "$dest_file"</span><br></span><span><span>    fi</span><br></span><span><span>done</span><br></span></code></pre></div>
<p>This creates a set of <code>.mpy</code> files which are bytecode instead of the <code>.py</code>
files. Taking the compilation step from the board to the computer means less
memory usage and a faster startup time, although the onboard compilation is
quite quick and not noticeable.</p>
<h4 id="buffering">Buffering<a aria-label="Direct link to Buffering" title="Direct link to Buffering" href="https://questdb.io/blog/making-a-trading-gameboy/#buffering">​</a></h4>
<p>I have a few files such as a <code>.txt</code> containing information such as the list of
'fun' news to display during the game. I may be in situations where I cannot
load the file in memory in one go. So to avoid crashing when reading it, I count
the number of lines by reading it in a buffer:</p>
<div><pre tabindex="0"><code><span><span>def</span><span> </span><span>count_lines</span><span>(</span><span>file</span><span>)</span><span>:</span><span></span><br></span><span><span>    count </span><span>=</span><span> </span><span>0</span><span></span><br></span><span><span>    </span><span>while</span><span> </span><span>True</span><span>:</span><span></span><br></span><span><span>        </span><span>buffer</span><span> </span><span>=</span><span> </span><span>file</span><span>.</span><span>read</span><span>(</span><span>1024</span><span>)</span><span></span><br></span><span><span>        </span><span>if</span><span> </span><span>not</span><span> </span><span>buffer</span><span>:</span><span></span><br></span><span><span>            </span><span>break</span><span></span><br></span><span><span>        count </span><span>+=</span><span> </span><span>buffer</span><span>.</span><span>count</span><span>(</span><span>'\n'</span><span>)</span><span></span><br></span><span><span>    </span><span>return</span><span> count</span><br></span></code></pre></div>
<p>In a similar way, I tried to steer clear of string variables and holding text in
memory as this can quickly accumulate when collecting objects with text. So
things like <code>side = 'buy'</code> would be transformed into <code>'side_is_buy: True</code> etc.</p>
<h3 id="speed-issues">Speed issues<a aria-label="Direct link to Speed issues" title="Direct link to Speed issues" href="https://questdb.io/blog/making-a-trading-gameboy/#speed-issues">​</a></h3>
<p>While I tried to be efficient, the game can be slow if not careful, even when
the microcontroller clocks 133 million times per second. In this section, we'll
look at some learnings which helped me make the game feel more fluid.</p>
<h4 id="multiprocessing">Multiprocessing<a aria-label="Direct link to Multiprocessing" title="Direct link to Multiprocessing" href="https://questdb.io/blog/making-a-trading-gameboy/#multiprocessing">​</a></h4>
<p>The first item is that the Pico has two cores, which means it can run two
processes in parallel. This means I can split the work two-ways and
theoretically do two things at the same time thereby (I simplify) run at twice
the speed.</p>
<p>One difficulty with multiprocessing is potential contention over resources. For
example, trying to modify a variable from one process while the other process is
reading it.</p>
<p>In this case, I decided to organise my two processes such that they are
independent. One runs the background game such as the exchange, bots, the
matching engine, and similar. The other handles the player side such as
rendering the game on screen, processing inputs, and so on.</p>
<p>The initialisation looks like this:</p>
<div><pre tabindex="0"><code><span><span>### Within the main thread...</span><span></span><br></span><span><span></span><span>### Start second thread</span><span></span><br></span><span><span>self</span><span>.</span><span>second_thread </span><span>=</span><span> _thread</span><span>.</span><span>start_new_thread</span><span>(</span><span>self</span><span>.</span><span>second_thread</span><span>,</span><span>(</span><span>)</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span></span><span>def</span><span> </span><span>second_thread</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    aio</span><span>.</span><span>create_task</span><span>(</span><span>self</span><span>.</span><span>exchange</span><span>.</span><span>flow</span><span>(</span><span>)</span><span>)</span><span></span><br></span><span><span>    aio</span><span>.</span><span>create_task</span><span>(</span><span>self</span><span>.</span><span>exchange</span><span>.</span><span>simulate_order_book</span><span>(</span><span>)</span><span>)</span><span></span><br></span><span><span>    aio</span><span>.</span><span>create_task</span><span>(</span><span>self</span><span>.</span><span>exchange</span><span>.</span><span>cash_market</span><span>.</span><span>flow</span><span>(</span><span>)</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span></span><span>### Do something else with the first thread</span><span></span><br></span><span><span></span><span>from</span><span> game </span><span>import</span><span> Game</span><br></span><span><span>next_step </span><span>=</span><span> Game</span><span>(</span><span>resources</span><span>)</span><span></span><br></span><span><span></span><span>while</span><span> </span><span>True</span><span>:</span><span></span><br></span><span><span>    next_step </span><span>=</span><span> </span><span>await</span><span> next_step</span><span>.</span><span>flow</span><span>(</span><span>)</span><br></span></code></pre></div>
<h4 id="coroutines">Coroutines<a aria-label="Direct link to Coroutines" title="Direct link to Coroutines" href="https://questdb.io/blog/making-a-trading-gameboy/#coroutines">​</a></h4>
<p>The game consists of many small loops. The bots send orders in a loop at a given
frequency. The player's algo reacts to market data at a given frequency. The
display refreshes at a given frequency; there are many such intervals.</p>
<p>Having all these steps in a loop such as this is not optimal because it forces
all steps to execute sequentially:</p>
<div><pre tabindex="0"><code><span><span>while</span><span> </span><span>True</span><span>:</span><span></span><br></span><span><span>    loop1</span><span>(</span><span>)</span><span></span><br></span><span><span>    loop2</span><span>(</span><span>)</span><span></span><br></span><span><span>    </span><span>.</span><span>.</span><span>.</span><br></span></code></pre></div>
<p>Fortunately, micropython comes with a built-in implementation of <code>asyncio</code>.</p>
<p>This allows us to setup co-routines, then let them run at a given frequency by
using <code>await aio.sleep_ms(interval)</code>. This pauses the current co-routine and
opens up resources to schedule another co-routine whose execution is due.</p>
<p>Here is an example for the player turn loop, and asynchronous wait:</p>
<div><pre tabindex="0"><code><span><span>async</span><span> </span><span>def</span><span> </span><span>play</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>while</span><span> self</span><span>.</span><span>playing</span><span>:</span><span></span><br></span><span><span>        self</span><span>.</span><span>rpm_price </span><span>=</span><span> self</span><span>.</span><span>exchange</span><span>.</span><span>rpm</span><span>.</span><span>get_ref_price</span><span>(</span><span>)</span><span></span><br></span><span><span>        self</span><span>.</span><span>player_turn</span><span>(</span><span>)</span><span></span><br></span><span><span>        </span><span>await</span><span> aio</span><span>.</span><span>sleep_ms</span><span>(</span><span>self</span><span>.</span><span>player_turn_ms</span><span>)</span><br></span></code></pre></div>
<p>What's nice about this is that we can then easily separate the loop frequencies
for all routines, and increase the frequency for critical ones, while decreasing
it for background tasks which don't need a high update rate. All frequencies can
then be setup as <code>Const()</code> in a config file.</p>
<h4 id="overclocking">Overclocking<a aria-label="Direct link to Overclocking" title="Direct link to Overclocking" href="https://questdb.io/blog/making-a-trading-gameboy/#overclocking">​</a></h4>
<p>It would not be a real trading machine if it was not overclocked! Overclocking
means increasing the CPU clock frequency over its default value, in this case
133 Mhz. Doing so is easy in micropython and I found that I could double the
clock frequency without any issues:</p>
<div><pre tabindex="0"><code><span><span>from</span><span> machine </span><span>import</span><span> freq</span><br></span><span><span></span><span>from</span><span> config </span><span>import</span><span> OVERCLOCK_MHZ</span><span>,</span><span> MAX_OVERCLOCK_MHZ</span><span>,</span><span> OVERCLOCK</span><br></span><span><span></span><br></span><span><span></span><span>async</span><span> </span><span>def</span><span> </span><span>main</span><span>(</span><span>)</span><span>:</span><span></span><br></span><span><span>    </span><span>if</span><span> OVERCLOCK </span><span>and</span><span> OVERCLOCK_MHZ </span><span>&lt;</span><span> MAX_OVERCLOCK_MHZ</span><span>:</span><span></span><br></span><span><span>        freq</span><span>(</span><span>OVERCLOCK_MHZ </span><span>*</span><span> </span><span>1_000_000</span><span>)</span><br></span></code></pre></div>
<p>Overclocking is not without risks however, and the CPU may become unstable or
overheat as a result. So increasing it is possible but with some risks and
downsides such as shortening the life of your device. But doubling the clock
speed in a situation such as this is a quick and easy way to get the performance
boost I need.</p>
<h3 id="practical-issues">Practical issues<a aria-label="Direct link to Practical issues" title="Direct link to Practical issues" href="https://questdb.io/blog/making-a-trading-gameboy/#practical-issues">​</a></h3>
<p>Generally, users are guided towards <a href="https://thonny.org/" rel="noopener noreferrer nofollow">Thonny</a> as an IDE. It
is great in many ways. The REPL mode allows you to connect to your board, modify
your code on the device, and run it.</p>
<p>While it's perfect for small scripts such as collecting readings or controlling
a small item, it becomes much more complicated when using more advanced objects,
classes, etc. There is no version control, and very few syntax checks or
highlights.</p>
<p>The process mostly looked like this:</p>
<ul>
<li>Update a file on the Pico</li>
<li>Update another file</li>
<li>Save the first file</li>
<li>Run</li>
<li>Error message because the second file was not saved and therefore your code is
broken</li>
<li>Save the second file</li>
<li>Run</li>
<li>Get an error message because you made a small syntax error which was not
highlighted in the IDE</li>
</ul>
<p>A lot of issues I had at runtime were because of typos or small syntax issues
which IDEs equipped with syntax checks would catch instantly and highlight.</p>
<p>On the other hand, using a fully fledged IDE also makes life harder because you
lose the ability to browse and edit files on device. While this would have been
a no-go due to the annoying overhead of copying the code across many times over,
I found that using a small script helped a lot and rendered this step painless.</p>
<p>To that end, I used
<a href="https://docs.micropython.org/en/latest/reference/mpremote.html" rel="noopener noreferrer nofollow">mpremote</a> to
copy all my files to the board and lastly start the program:</p>
<div><pre tabindex="0"><code><span><span>echo </span><span>"### Copying to device"</span><span></span><br></span><span><span></span><br></span><span><span>cd $BUILD_DIR</span><br></span><span><span>mpremote cp main</span><span>.</span><span>py </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r animations</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r frames</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r helpers</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r master</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r menus</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r resources</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote fs cp </span><span>-</span><span>r slave</span><span>/</span><span> </span><span>:</span><span></span><br></span><span><span>mpremote cp config</span><span>.</span><span>mpy </span><span>:</span><span></span><br></span><span><span>mpremote cp game</span><span>.</span><span>mpy </span><span>:</span><span></span><br></span><span><span>mpremote cp main</span><span>.</span><span>mpy </span><span>:</span><span></span><br></span><span><span>mpremote cp main</span><span>.</span><span>mpy </span><span>:</span><span></span><br></span><span><span>mpremote cp about</span><span>.</span><span>txt </span><span>:</span><span></span><br></span><span><span>mpremote cp news</span><span>.</span><span>txt </span><span>:</span><span></span><br></span><span><span>mpremote run main</span><span>.</span><span>py</span><br></span></code></pre></div>
<h2 id="does-it-questdb">Does it QuestDB?<a aria-label="Direct link to Does it QuestDB?" title="Direct link to Does it QuestDB?" href="https://questdb.io/blog/making-a-trading-gameboy/#does-it-questdb">​</a></h2>
<p>QuestDB is a monster for <a href="https://questdb.io/market-data/" rel="">market data</a>. The Pico microcontroller
includes a wireless chip. So it's possible to connect it to the network, and
then to issue http requests to send data to a QuestDB instance.</p>
<p>Connecting to the wifi is pretty simple in micropython:</p>
<div><pre tabindex="0"><code><span><span>def</span><span> </span><span>connect_to_wifi</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>  wlan </span><span>=</span><span> network</span><span>.</span><span>WLAN</span><span>(</span><span>network</span><span>.</span><span>STA_IF</span><span>)</span><span></span><br></span><span><span>  wlan</span><span>.</span><span>active</span><span>(</span><span>True</span><span>)</span><span></span><br></span><span><span>  wlan</span><span>.</span><span>connect</span><span>(</span><span>self</span><span>.</span><span>ssid</span><span>,</span><span> self</span><span>.</span><span>pwd</span><span>)</span><span></span><br></span><span><span>  </span><span>print</span><span>(</span><span>f'connecting </span><span>{</span><span>self</span><span>.</span><span>ssid</span><span>}</span><span>'</span><span>)</span><br></span></code></pre></div>
<p>And then we can sending data using a raw HTTP request. For example something
like this:</p>
<div><pre tabindex="0"><code><span><span>def</span><span> </span><span>send_results</span><span>(</span><span>self</span><span>)</span><span>:</span><span></span><br></span><span><span>    query </span><span>=</span><span> </span><span>f"INSERT INTO game(ref_price,timestamp, p_bid, p_ask, skew, pnl) "</span><span> \</span><br></span><span><span>            </span><span>f"VALUES("</span><span> \</span><br></span><span><span>            </span><span>f"</span><span>{</span><span>str</span><span>(</span><span>self</span><span>.</span><span>current_ref_price</span><span>)</span><span>}</span><span>,"</span><span> \</span><br></span><span><span>            </span><span>f"systimestamp(),"</span><span> \</span><br></span><span><span>            </span><span>f"</span><span>{</span><span>str</span><span>(</span><span>self</span><span>.</span><span>current_player_bid</span><span>)</span><span>}</span><span>,"</span><span> \</span><br></span><span><span>            </span><span>f"</span><span>{</span><span>str</span><span>(</span><span>self</span><span>.</span><span>current_player_ask</span><span>)</span><span>}</span><span>,"</span><span> \</span><br></span><span><span>            </span><span>f"</span><span>{</span><span>str</span><span>(</span><span>self</span><span>.</span><span>player_skew</span><span>)</span><span>}</span><span>,"</span><span> \</span><br></span><span><span>            </span><span>f"</span><span>{</span><span>str</span><span>(</span><span>self</span><span>.</span><span>player_pnl</span><span>)</span><span>}</span><span>)"</span><span></span><br></span><span><span>    full_url </span><span>=</span><span> self</span><span>.</span><span>url </span><span>+</span><span> </span><span>"?query="</span><span> </span><span>+</span><span> self</span><span>.</span><span>url_encode</span><span>(</span><span>query</span><span>)</span><span></span><br></span><span><span>    </span><span>print</span><span>(</span><span>full_url</span><span>)</span><span></span><br></span><span><span>    </span><span>try</span><span>:</span><span></span><br></span><span><span>        requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>=</span><span>full_url</span><span>)</span><br></span></code></pre></div>
<p>I can then setup a Grafana dashboard with queries such as the following:</p>
<div><pre tabindex="0"><code><span><span>SELECT</span><span> </span><span>timestamp</span><span>,</span><span> ref_price</span><span>,</span><span> p_bid player_bid</span><span>,</span><span> p_ask player_ask</span><br></span><span><span></span><span>FROM</span><span> game</span><br></span><span><span></span><span>WHERE</span><span> $__timeFilter</span><span>(</span><span>timestamp</span><span>)</span><br></span></code></pre></div>
<p>And tada!</p>
<p>Game stats are flowing in realtime into a QuestDB instance and displayed live in
a <a href="https://questdb.io/docs/third-party-tools/grafana/" rel="">Grafana</a> dashboard. Of course, I
<a href="https://questdb.io/blog/increase-grafana-refresh-rate-frequency/" rel="">set the refresh frequency to 250ms</a>
for more of a true HFT feel:</p>
<figure><div><p><img alt="An image" src="https://questdb.io/img/blog/2024-10-24/game-on-grafana.webp" loading="lazy"></p><figcaption>Click to zoom</figcaption></div></figure>
<p>It's pretty satisfying to see the quotes adjusting automatically to market
price. With more time, I could change the algo to adjust to the orderbook, fight
for position, or come up with many other creative situations.</p>
<p>Another satisfying thing is to watch the autohedge get to work when I cross my
threshold parameter. This threshold is dynamic, meaning that I can adjust it
over the game depending on my current risk appetite. As soon as it's crossed, it
sends orders in the other orderbook to hedge in the underlying.</p>
<p>What's less satisfying is my performance in this game. In this instance, it was
all going well until figures occurred. I was making money from the spread
collected on the flow. But when figures came out, I had a small short
position... and the markets jumped up.</p>
<p>Consequently, my PnL went from positive to negative. While I remembered to pull
quotes (I would have been demolished by arbitrage otherwise because I have
higher latency than the market), I didn't completely flatten my position.</p>
<p>I'll do better next time!</p>
<h2 id="in-conclusion">In conclusion<a aria-label="Direct link to In conclusion" title="Direct link to In conclusion" href="https://questdb.io/blog/making-a-trading-gameboy/#in-conclusion">​</a></h2>
<p>While accidental, this experience was very enriching for a few reasons.</p>
<p>First, as someone who always worked in dematerialised things (data, trading,
computers), it was great to work on something tangible and physical. There is a
pleasure in creation and this opened new perspectives in terms of daring to do
things with my hands such as fixing something at home or building.</p>
<p>I naturally feel more at home with a computer than with a hammer, and people in
the opposite situation tell me they are scared of computers. It's great to
realise that going from one to the other is possible, and feels great.</p>
<p>Second, I was amazed to discover 3D printers and CAD design. The state of
tooling is such that one can very easily design a part (PCB or other physical
object) to solve real world problems with infinitely more satisfaction than just
buying something off-the-shelf.</p>
<p>For example, my bedside table lamp comes with shades, and there is a set of two
disks which screw on the lamp shaft to hold the shade in place. These broke, and
within a few minutes I could print replacements for a fraction of the cost with
multiples of the satisfaction.</p>
<p>Most people I know have never seen such a machine before and I envy them for
their ability to see it in action for the first time materialising an object
before their eyes.</p>
<p>Third, I am truly impressed by the Raspberry Pi Pico, and the micropython
language. When I think microcontroller, I think toothbrush control or small RC
remote. But seeing it run an exchange, orderbook, matching engine, and
refreshing a display for a cost of around $8 is truly impressive.</p>
<p>They just released a new version with more cores, more memory, and other
features, and I can't wait to try it for other projects and to see what more
skilled makers will make of it!</p>
<h3 id="want-more-pi">Want more Pi?<a aria-label="Direct link to Want more Pi?" title="Direct link to Want more Pi?" href="https://questdb.io/blog/making-a-trading-gameboy/#want-more-pi">​</a></h3>
<p>If this sort of thing is up your alley, we've got more fun Pi projects:</p>
<ul>
<li><a href="https://questdb.io/blog/time-series-monitoring-dashboard-grafana-questdb/" rel="">Fluid real-time dashboards with QuestDB and Grafana</a></li>
<li><a href="https://questdb.io/blog/build-resource-monitor-grafana/" rel="">Build your own resource monitor</a></li>
<li><a href="https://questdb.io/blog/tracking-sea-faring-ships-ais-grafana/" rel="">Tracking sea faring ships with AIS data and Grafana</a></li>
<li><a href="https://questdb.io/blog/realtime-nyc-cab-data-visualized/" rel="">Visualizing real-time NYC cab data and geodata</a></li>
<li><a href="https://questdb.io/blog/analyzing-the-ecb-historical-fx-rates/" rel="">Analyzing the beautiful charts and history behind ECB FX rates</a></li>
<li><a href="https://questdb.io/blog/increase-grafana-refresh-rate-frequency/" rel="">Increase Grafana refresh rate frequency</a></li>
<li>Or check out our <a href="https://questdb.io/blog/tags/GRAFANA/" rel="">Grafana blog tag</a></li>
</ul>
<p>Want to chat with us? Holler on social media or join in our engaging
<a href="https://community.questdb.io/" rel="noopener noreferrer nofollow">Community Forum</a> or our public
<a href="https://slack.questdb.io/" rel="noopener noreferrer nofollow">Slack</a>.</p><div><p><span>Subscribe to our newsletters for the latest. Secure and never shared or sold.</span></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing a WebGPU Matmul Kernel for 1 TFLOP (143 pts)]]></title>
            <link>https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel</link>
            <guid>42108816</guid>
            <pubDate>Mon, 11 Nov 2024 17:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel">https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel</a>, See on <a href="https://news.ycombinator.com/item?id=42108816">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I work at </span><a href="https://nomic.ai/" rel="nofollow ugc noopener">Nomic</a><span>, where many of my colleagues work on building large TSNE-like visualizations </span><em>work</em><span> in the browser</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-1-150233403" target="_self" rel="nofollow ugc noopener">1</a></span><span>. Showing tens of millions of data points in the browser without rendering your computer an oven is no easy challenge. I overhear many of the scaling problems solved by </span><a href="https://github.com/nomic-ai/deepscatter" rel="nofollow ugc noopener">Deepscatter</a><span>, first developed by Ben Schmidt.  </span></p><p><span>However, many conversations that I overhear tend to revolve around Typescript and how awesome WebGPU is. At the time of writing, I couldn’t find any autograd libraries built with WebGPU</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-2-150233403" target="_self" rel="nofollow ugc noopener">2</a></span><span>. So as an educational exercise to learn WebGPU and Typescript, I decided to build </span><strong>Surfgrad</strong><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-3-150233403" target="_self" rel="nofollow ugc noopener">3</a></span><span>, a high-performant, WebGPU-powered autograd library that enables browser-based tensor operations. </span></p><p><span>In this post, I’ll cover how I optimized a naive WebGPU Matrix Multiplication (matmul) Kernel to 1</span><a href="https://en.wikipedia.org/wiki/Floating_point_operations_per_second" rel="nofollow ugc noopener">TFLOPS</a><span>+ of arithmetic intensity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-4-150233403" target="_self" rel="nofollow ugc noopener">4</a></span><span>. The goal isn’t to build the  </span><strong>fastest</strong><span> autograd library, but to show the nuances of WebGPU and how it might differ from CUDA.</span></p><p>Perhaps in the future, we can even use Surfgrad for running the next Llama models. </p><p><span>WebGPU is an API designed for people to write GPU code that runs on any phone or computer with a web browser.  Previously, people hacked around WebGL to run machine learning workloads like rendering </span><a href="https://benschmidt.org/post/2023-03-07-webGPU-day/" rel="nofollow ugc noopener">invisible canvas and reading numbers as colors</a><span>.  Now people can take advantage of the increasing power of GPUs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-5-150233403" target="_self" rel="nofollow ugc noopener">5</a></span><span> in laptops and run compute kernels (e.g. data in, data out without any funny business). </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png" width="1456" height="769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:769,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:212600,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7fca0b4e-318c-43ec-8d23-c84393b86723_1704x900.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>WebGPU was created to give the “compute” shader first-class support and open the doors for in-browser, private machine learning development. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png" width="1456" height="734" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:734,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:222165,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0071d1ea-8ad5-4fc9-8972-99ad3f7501a7_1742x878.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>The compute (and vertex and fragment) shaders are written in </span><a href="https://www.w3.org/TR/WGSL/" rel="nofollow ugc noopener">WGSL</a><span>. WGSL is designed for developers to write a single shader that gets compiled to lower level languages like SPIR-V for Vulkan and MSL for Metal. </span></p><p>Ben’s also written some great articles on what WebGPU is and why it’s important:</p><ul><li><p><a href="https://benschmidt.org/post/2020-01-15/2020-01-15-webgpu/" rel="nofollow ugc noopener">Javascript and the next decade of data programming</a></p></li><li><p><a href="https://benschmidt.org/post/2023-03-07-webGPU-day/" rel="nofollow ugc noopener">Happy WebGPU Day</a></p></li></ul><p>NVIDIA is the most popular choice for hardware and CUDA, its API, is one of the reasons for it but their API only works on NVIDIA hardware. </p><p><span>WebGPU and NVIDIA share similar </span><a href="https://github.com/googlefonts/compute-shader-101/blob/main/docs/glossary.md" rel="nofollow ugc noopener">terminologies</a><span>, but don’t have the exact same functionality. WebGPU </span><em>just </em><span>introduced support for </span><a href="https://developer.chrome.com/blog/new-in-webgpu-128#experimenting_with_subgroups" rel="nofollow ugc noopener">subgroups</a><span> which allows threads within a group to efficiently share data, which is a big win for things like matrix multiplies where you may recalculate similar values. </span></p><p>WebGPU also sits a half step above CUDA in that it can compiles to other GPU languages like Vulkan and Metal. It’s kind of like React Native for GPU compute shaders. </p><p><span>The smallest unit is a </span><strong>thread</strong><span> which executes the compute shader. </span></p><p><strong>workGroups </strong><span>are groups of threads: they are grouped together and run in parallel (they’re called threadBlocks in CUDA). They can access the same shared memory.</span></p><p><span>WebGPU can dispatch many of these </span><strong>workGroups</strong><span> at once, whereas CUDA calls this a Grid (which is made of threadBlocks). </span></p><p><span>Similarly to CUDA, </span><strong>workGroups</strong><span> and </span><strong>dispatching work groups</strong><span> are defined in 3D. The size of a </span><strong>workGroup </strong><span>is defined by </span><code>@workgroup_size(x, y, z) </code><span>where the number of threads per workgroup is </span><code>x * y * z</code><span>. </span></p><p><span>Matrix multiplications makes up most of the floating point operations per second (</span><a href="https://en.wikipedia.org/wiki/Floating_point_operations_per_second" rel="nofollow ugc noopener">FLOPs</a><span>) in Large Language Models like  GPT-4 and Llama. It is the basic primitive for most training and inference workloads.</span></p><p><span>Native WebGPU support for Matrix Multiply is limited to </span><a href="https://webgpu.rocks/wgsl/language/types/#matrix" rel="nofollow ugc noopener">small matrices</a><span>, which aren’t useful for modern Deep Learning workloads when your matrices can be large</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-6-150233403" target="_self" rel="nofollow ugc noopener">6</a></span><span>.</span></p><p>A quick few notes on notation. </p><p><span>First, a </span><a href="https://en.wikipedia.org/wiki/Matrix_multiplication" rel="nofollow ugc noopener">matrix multiply</a><span> is defined by three matrices: A, B, C. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png" width="1456" height="888" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:888,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:225493,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3171894-84a2-467d-adcd-4fd6446217fc_1926x1174.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The total </span><a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#math-mem" rel="nofollow ugc noopener">FLOPs required of a matrix multiply</a><span> are </span><code>2 * M * K * N </code><span>as each operation requires both a multiply and an add (hence the 2). </span></p><p><span>Following the example </span><a href="https://siboehm.com/articles/22/CUDA-MMM#lower-bounding-the-fastest-possible-runtime" rel="nofollow ugc noopener">Siobehm’s great article</a><span>, we have two 4092x4092 matrices followed by the addition of a 4092x4092 matrix. Similarly, we have </span></p><ol><li><p>Total FLOPS: 137GFLOPs</p></li><li><p>Total data to read: 201MB</p></li><li><p>Total data to store: 67MB</p></li></ol><p><span>However, I am developing on a </span><a href="https://www.cpu-monkey.com/en/igpu-apple_m2_pro_16_core" rel="nofollow ugc noopener">Mac M2 Pro which has ~6 TFLOP/</a><span>s of arithmetic intensity and </span><a href="https://pocketnow.com/apple-m2-vs-pro-vs-max/" rel="nofollow ugc noopener">200GB/s of memory bandwidth</a><span>.</span></p><p>So, the fastest the compute kernel can take is </p><p><span>(</span><code>137GFLOP) / (6TFLOPS/s) = 22ms</code></p><p>and memory access takes </p><p><code>(267MB) / (200GB/s) = 1.34ms</code></p><p>so we should be compute bound (by ~16x too!). </p><p><span>The simplest way to compute a dot product between matrix A and B and write to matrix C is for each row in A (of shape </span><strong>M), </strong><span>iterate over the columns of A (of shape </span><strong>K</strong><span>) and multiply by the corresponding value of B. In Python, this looks like </span></p><pre><code>def matmul(a, b, c):
    """
    Perform naive matrix multiplication: C = A * B
    
    :param a: Input matrix A of shape (m, k)
    :param b: Input matrix B of shape (k, n)
    :param c: Output matrix C of shape (m, n) to store the result
    """
    m = len(a)
    k = len(a[0])
    n = len(b[0])
    
    # Perform the matrix multiplication
    for i in range(m):
        for j in range(n):
            c[i][j] = 0
            for l in range(k):
                c[i][j] += a[i][l] * b[l][j]</code></pre><p><span>Similar to the Python code above, we define</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-7-150233403" target="_self" rel="nofollow ugc noopener">7</a></span><span> our inputs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-8-150233403" target="_self" rel="nofollow ugc noopener">8</a></span></p><pre><code>struct Dimensions {
  M: u32,
  K: u32,
  N: u32,
}

@group(0) @binding(0) var&lt;uniform&gt; dimensions: Dimensions;
@group(0) @binding(1) var&lt;storage, read&gt; a: array&lt;f32&gt;;
@group(0) @binding(2) var&lt;storage, read&gt; b: array&lt;f32&gt;;
@group(0) @binding(3) var&lt;storage, read_write&gt; result: array&lt;f32&gt;;</code></pre><p>and our compute kernel:</p><pre><code>@compute @workgroup_size(1)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {
  let index = global_id.x;
  let row = index / dimensions.N;
  let col = index % dimensions.N;

  if (index &lt; dimensions.M * dimensions.N) {
    var sum = 0.0;
    for (var i: u32 = 0u; i &lt; dimensions.K; i = i + 1u) {
      sum = sum + a[row * dimensions.K + i] * b[i * dimensions.N + col];
    }
    result[row * dimensions.N + col] = sum;
  }
}</code></pre><p><span>The code is functionally equivalent to the Python code above! We define how big our </span><strong>workGroup</strong><span> size is with  </span><code>workgroup_size(1)</code><span> (remember this is represented in 3D). </span></p><p><span>So, each workGroup, since it’s only one thread, processes one </span><code>result[i, j]</code><span>. </span></p><p><span>To calculate the full matrix, we need to launch as many entries as there are in the matrix and call </span><a href="https://developer.mozilla.org/en-US/docs/Web/API/GPUComputePassEncoder/dispatchWorkgroups" rel="nofollow ugc noopener">dispatchWorkgroups</a><span> </span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-9-150233403" target="_self" rel="nofollow ugc noopener">9</a></span><span> </span></p><pre><code>pass.dispatchWorkgroups(a.shape[0] * b.shape[1]) </code></pre><p><span>where </span><code>a.shape == M, b.shape[1] == N</code><span> for (most) any MxN matrix. </span></p><p>Now as we see below, we have lots of room for improvement!</p><p><span>The largest square matrix multiply we can calculate is 128x128 due to limits in WebGPU (more on this later). We only achieve 1.64 </span><strong>GFLOPS/s </strong><span>a far cry from the theoretical max of 6 </span><strong>TFLOPS/s</strong><span>. </span></p><p>Why is this kernel so slow? In effect, each workgroup calculates a single entry of the 16,384 total elements (128^2). Although we are running in parallel, each workGroup loads its own copy of the matrices. The overhead to launch more workGroups is likely more than if our workGroup had more threads and calculated more results per workGroup and each workGroup isn’t able to take advantage of any caching of the inputs. </p><p><span>With the first kernel, we’re only able to compute small square matrices due to limits on the number of </span><strong>workGroups</strong><span> (</span><a href="https://developer.mozilla.org/en-US/docs/Web/API/GPUSupportedLimits" rel="nofollow ugc noopener">maxComputeWorkgroupsPerDimension</a><span>) you can </span><strong>dispatch </strong><span>at once. </span></p><p>Since we’re launching one workgroup per entry, a 256x256 matrix is larger than our limit!</p><p>Remember this line?</p><pre><code><code>@compute @workgroup_size(1)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {</code><span> </span></code></pre><p><span>We can reduce the number of </span><strong>dispatched workGroups</strong><span> by increasing the number of </span><strong>threads </strong><span>per </span><strong>workGroup</strong><span>! </span></p><p>If we update our code </p><pre><code><code>@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) { </code></code></pre><p>we can reduce the number of total dispatched workGroups per dimension:</p><pre><code><code>const WORKGROUP_SIZE = 256;
pass.dispatchWorkgroups((a.shape[0] * b.shape[1]) / WORKGROUP_SIZE);</code></code></pre><p><span>Why 256? Well, there’s another </span><a href="https://www.w3.org/TR/webgpu/#limits" rel="nofollow ugc noopener">limit</a><span> :) </span></p><p>Increasing the workgroupSize, we’re able to improve our kernel by 200x! </p><p><span>However doing all the computation in “1 dimension” limits the matrix size we can calculate</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-10-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-10-150233403" target="_self" rel="nofollow ugc noopener">10</a></span></p><p>Although we don’t change much about our code, if we distribute our work in 2 dimensions we’re able to bypass these limits and launch more workGroups that are larger. This allows us to calculate a 4096x4096 matmul. </p><p><span>We update our </span><code>@workgroup_size(8, 8)</code><span>, check our bounds, </span></p><pre><code>@compute @workgroup_size(8, 8)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {
  let row = global_id.x;
  let col = global_id.y;

  if (row &lt; dimensions.M &amp;&amp; col &lt; dimensions.N) {
    var sum : f32 = 0.0;
    for (var i: u32 = 0u; i &lt; dimensions.K; i = i + 1u) {
      sum = sum + a[row * dimensions.K + i] * b[i * dimensions.N + col];
    }
    result[row * dimensions.N + col] = sum;
  }
}</code></pre><p>and dispatch workgroups in 2D </p><pre><code>const WORKGROUP_SIZE = 16; 
pass.dispatchWorkgroups(    
          Math.ceil(a.shape[0]  / WORKGROUP_SIZE), 
          Math.ceil(b.shape[1] / WORKGROUP_SIZE),
);    </code></pre><p>But this is slower than our original kernel! What’s going on? </p><p>If we make a small change to the code</p><pre><code>@compute @workgroup_size(8, 8)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {
  let row = global_id.y;
  let col = global_id.x;</code></pre><p>we get much better kernel performance. </p><p><span>Why is this? We’re able to take more advantage of cached inputs. The x dimension is incremented before the y dimension in the </span><code>global_invocation_id</code><span> and therefore more threads in each workgroup use the same row in matrix A. Otherwise, the row variable is overwritten at each invocation within the workGroup and each thread has to spend a few extra cycles to read from global memory rather than the cache. </span></p><p>Another thing to consider is how much work each thread does. </p><p>Up to now, each thread only computes one entry. But there is some overhead to launching each workGroup versus computing more than 1 element per thread! </p><p><span>If calculating more elements per thread is faster than the overhead to launch each workGroup, we should see a big speedup</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-11-150233403" href="https://zanussbaum.substack.com/p/optimizing-a-webgpu-matmul-kernel#footnote-11-150233403" target="_self" rel="nofollow ugc noopener">11</a></span><span>.</span></p><p>To do so, we calculate 4 results per thread (e.g. a 1x4 Tile). </p><pre><code>const BLOCKSIZE: u32 = 16;
const TILESIZE: u32 = 4;
@compute @workgroup_size(BLOCKSIZE, BLOCKSIZE)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {
    let row = global_id.y;
    let col = global_id.x * TILESIZE;

    if (row &gt;= dimensions.M || col &gt;= dimensions.N) {
        return;
    }

    var sum00: f32 = 0.0;
    var sum01: f32 = 0.0;
    var sum02: f32 = 0.0;
    var sum03: f32 = 0.0;

    for (var i: u32 = 0u; i &lt; dimensions.K; i = i + 1u) {
        let a_elem = a[row * dimensions.K + i];
        sum00 = sum00 + a_elem * b[i * dimensions.N + col];
        sum01 = sum01 + a_elem * b[i * dimensions.N + col + 1u];
        sum02 = sum02 + a_elem * b[i * dimensions.N + col + 2u];
        sum03 = sum03 + a_elem * b[i * dimensions.N + col + 3u];
    }

    result[row * dimensions.N + col] = sum00;
    result[row * dimensions.N + col + 1u] = sum01;
    result[row * dimensions.N + col + 2u] = sum02;
    result[row * dimensions.N + col + 3u] = sum03;
}</code></pre><p><span>The kernel looks roughly the same as before except we’ve </span><a href="https://en.wikipedia.org/wiki/Loop_unrolling" rel="nofollow ugc noopener">unrolled</a><span> the computation and are calculating </span><code>TILESIZE </code><span>results per thread.  </span></p><p>We can take this a step further and calculate 2D results per thread! Instead of calculating 4 elements per single row, we can calculate 4 elements for 4 rows (e.g. a 2D tile). </p><pre><code>const BLOCKSIZE: u32 = 16;
const TILE_M: u32 = 4;  // Tile size in M dimension
const TILE_N: u32 = 4;  // Tile size in N dimension

@compute @workgroup_size(BLOCKSIZE, BLOCKSIZE)
fn main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {
    let row = global_id.y * TILE_M;
    let col = global_id.x * TILE_N;

    // initialize the array with all 0s
    var sums: array&lt;array&lt;f32, TILE_N&gt;, TILE_M&gt;;
    for (var i = 0u; i &lt; TILE_M; i++) {
        for (var j = 0u; j &lt; TILE_N; j++) {
            sums[i][j] = 0.0;
        }
    }

    // Compute the 2D tile
    for (var k = 0u; k &lt; dimensions.K; k++) {
        // for each row
        for (var i = 0u; i &lt; TILE_M; i++) {
            let a_element = a[(row + i) * dimensions.K + k];
            // calculate the dot product
            for (var j = 0u; j &lt; TILE_N; j++) {
                let b_element = b[k * dimensions.N + (col + j)];
                sums[i][j] += a_element * b_element;
            }
        }
    }

    // Write results
    for (var i = 0u; i &lt; TILE_M; i++) {
        for (var j = 0u; j &lt; TILE_N; j++) {
            let output_row = row + i;
            let output_col = col + j;
            if (output_row &lt; dimensions.M &amp;&amp; output_col &lt; dimensions.N) {
                result[output_row * dimensions.N + output_col] = sums[i][j];
            }
        }
    }
}</code></pre><p>Each thread now calculates a 4x4 grid of the output matrix and we see a slight improvement over the last kernel. </p><p>Surprisingly, 2D tiling is quite slow. Why haven’t we amortized the time it takes to launch workGroups by doing more work? And why are we slower than doing one item of work per thread? </p><p>To answer the last question, we will need to dig into the compiled WebGPU kernels. </p><p>Some compilers will automatically unroll loops if the bounds of the loop are known at compile time. However we’ve been writing a general kernel for variable shaped inputs!</p><p> Also when writing at WGSL, we don’t have any control over the directives of the compiler. </p><p>Looking at the assembly bitcode compiled from Metal, we can see that the instruction set still includes the for loop!  </p><pre><code>%51 = phi i32 [ 0, %41 ], [ %61, %50 ]
%52 = add i32 %37, %51
%53 = zext i32 %52 to i64
%54 = getelementptr inbounds [1 x float], ptr addrspace(1) %3, i64 0, i64 %53
%55 = load float, ptr addrspace(1) %54, align 4, !tbaa !27, !alias.scope !43, !noalias !44
%56 = zext i32 %51 to i64
%57 = getelementptr inbounds %struct.type_5, ptr %7, i64 0, i32 0, i64 %49, i32 0, i64 %56
%58 = load float, ptr %57, align 4, !tbaa !27
%59 = fmul fast float %55, %48
%60 = fadd fast float %58, %59
store float %60, ptr %57, align 4, !tbaa !27
%61 = add nuw nsw i32 %51, 1
%62 = icmp eq i32 %61, 4
br i1 %62, label %38, label %50 // branching for loop</code></pre><p>Whereas the unrolled WGSL code gets compiled to </p><pre><code>...
%141 = fmul fast float %112, %103
%142 = fadd fast float %141, %82
%143 = fmul fast float %116, %103
%144 = fadd fast float %143, %81
%145 = fmul fast float %120, %103
%146 = fadd fast float %145, %80
%147 = fmul fast float %124, %103
%148 = fadd fast float %147, %79
%149 = fmul fast float %112, %107
%150 = fadd fast float %149, %78
%151 = fmul fast float %116, %107
%152 = fadd fast float %151, %77
%153 = fmul fast float %120, %107
%154 = fadd fast float %153, %76
%155 = fmul fast float %124, %107
%156 = fadd fast float %155, %75
%157 = add nuw i32 %91, 1
%158 = icmp eq i32 %157, %27
br i1 %158, label %159, label %74 </code></pre><p>Because of the manual unrolling, the GPU is able to reduce overhead by not having to initialize and increment the inner loop, take advantage of instruction level parallelism, and amortize the cost of launching fewer workGroups by doing more work per thread. When we had our loop, the kernel (#4) wasn’t able to take advantage of these optimizations and was slower than just launching more workGroups (#3). </p><p>And if we make our grid 8x8, we get a 3x boost over the 4x4 loop and surpass 1TFLOP! </p><p>Through our efforts, we were able to build a performant matmul kernel that is 1000x faster than the naive kernel and approach Apple M2 Pro’s theoretical peak. </p><p><span>And with frequent updates to WebGPU, there are still optimizations to be made! For example, we didn’t take advantage of </span><a href="https://github.com/gpuweb/gpuweb/issues/3950" rel="nofollow ugc noopener">subgroups</a><span>, a feature that is new as of Chrome 125 and should allow for faster memory access and sharing across subgroups to reduce repeated computations. </span></p><p><span>And a big thank you to </span><a href="https://x.com/owl_poster" rel="nofollow ugc noopener">Abhishaike Mahajan</a><span> (who writes an </span><a href="https://www.owlposting.com/?utm_source=global-search" rel="nofollow ugc noopener">incredible blog</a><span>) and </span><a href="https://x.com/elmanmansimov" rel="nofollow ugc noopener">Elman Mansimov</a><span> for feedback and encouragement to writing this article!</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Death and Life of Prediction Markets at Google (237 pts)]]></title>
            <link>https://asteriskmag.com/issues/08/the-death-and-life-of-prediction-markets-at-google</link>
            <guid>42108360</guid>
            <pubDate>Mon, 11 Nov 2024 16:34:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/08/the-death-and-life-of-prediction-markets-at-google">https://asteriskmag.com/issues/08/the-death-and-life-of-prediction-markets-at-google</a>, See on <a href="https://news.ycombinator.com/item?id=42108360">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Dan Schwarz</span>
							</h2>
			</section>
	
			<section id="rangyscope">
					<p>Over the past two decades, Google has hosted two different internal platforms for predictions. Why did the first one fail — and will the other endure?</p>
				<div>
											<div><p>It’s July 2005. Google is the darling of Silicon Valley. It has just unveiled Google Maps; Gmail is still in beta. Next year it will acquire YouTube and launch Google Translate.</p><p>The week’s new hires file past a full-size dinosaur skeleton in the courtyard on the way to their first TGIF — the company’s weekly all-hands. They wear beanies with red, yellow, green, and blue colors — like the yet-to-be-designed Chrome logo — with a propeller on top. They are here to see Google’s founders, Larry Page and Sergey Brin, both wearing shorts and plain colored t-shirts, banter about new tech.</p><p>In the first line of their Founders’ IPO letter, Page and Brin wrote “Google is not a conventional company.” They sought to provide “unbiased, accurate and free access to information.” On this Friday, Patri Friedman, the grandson of Milton Friedman, and Bo Cowgill, now an economics professor at Columbia University, are here to talk about Google’s next bet to do this: an internal prediction market called Prophit.</p><p>On stage next to Larry Page, Friedman and Cowgill announce winners from Prophit’s first quarter and show statistical results on its forecasting accuracy. Prophit was popular inside Google. Over the next three years, about 20% of all Google employees would place bets.</p><p>Two months after this presentation, <em>The </em><a href="https://www.nytimes.com/2005/09/26/business/at-google-the-workers-are-placing-their-bets.html"><em>New York Times</em> covered Prophit</a>. They wrote about it again <a href="https://www.nytimes.com/2008/01/07/technology/07link.html">in 2008</a>, and it became a <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=34562"><em>Harvard Business Review</em> case-study</a>. Despite the momentum, in March 2010, Prophit hit a major roadblock in its public launch as an external product. It attempted a pivot, and ultimately shut down in 2011.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-death-and-life-of-prediction-markets-at-google/380d5c1bc4-1728060078/1-google_1.png" alt="">
  </p>
  </figure>
</div>
											<div><p>In April 2020, almost exactly 15 years after Prophit launched, and one month after employees worldwide were sent home due to COVID-19, I launched Google’s second internal prediction market, called Gleangen.<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
 By late 2022, about 8% of Google employees had placed a bet on Gleangen. The company had grown so large that 8% represented 15,000 people — ten times the number of employees that placed bets on Prophit. Gleangen sustained over 1,000 monthly traders, more than the popular forecasting platforms <a href="https://www.metaculus.com/">Metaculus</a> (where I later served as CTO) and <a href="https://manifold.markets/stats">Manifold</a> at the time.<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
</p><p>Outside of Google, prediction markets have once again been thrust into the spotlight. Weeks before it became a mainstream view, users on sites like PredictIt and Metaculus predicted not only that President Biden would drop his reelection campaign but that <a href="https://www.astralcodexten.com/p/prediction-markets-suggest-replacing">doing so would increase the Democrats’ chance of winning</a>. Over the next few months, swings in election prediction markets regularly made national news,  and despite some distortions caused by aggressive whales, the markets <a href="https://www.bloomberg.com/news/articles/2024-11-06/donald-trump-win-betting-markets-prediction-websites-nailed-election-forecast?cmpid=BBD110724_MONEYSTUFF&amp;utm_medium=email&amp;utm_source=newsletter&amp;utm_term=241107&amp;utm_campaign=moneystuff&amp;embedded-checkout=true">ultimately </a><a href="https://www.bloomberg.com/news/articles/2024-11-06/donald-trump-win-betting-markets-prediction-websites-nailed-election-forecast?embedded-checkout=true">performed</a><a href="https://www.bloomberg.com/news/articles/2024-11-06/donald-trump-win-betting-markets-prediction-websites-nailed-election-forecast?cmpid=BBD110724_MONEYSTUFF&amp;utm_medium=email&amp;utm_source=newsletter&amp;utm_term=241107&amp;utm_campaign=moneystuff&amp;embedded-checkout=true"> well</a>. Theoretically, prediction markets are equally powerful when used by companies to anticipate events, such as predicting their competitors’ next moves.</p><p>But as Cowgill has shown, corporate prediction markets have <a href="https://academic.oup.com/restud/article-abstract/82/4/1309/2607345?login=false">a mixed track record</a>, as evidenced by attempts at Google and many other companies. Why is this? What does it take to make them work? The inside story of Prophit and Gleangen, the two largest corporate prediction markets ever run, offers some lessons.</p></div>
											<p><h2>A new type of information economy</h2>
</p>
											<div><p>Probably the first corporate prediction market was built in 1990 by economist Robin Hanson for employees of the doomed hypertext startup Project Xanadu. It had 18 participants, who bet on questions like whether cold fusion would be developed by 1991. The decade was dotted with other prediction market experiments, like the Iowa Electronic Markets (an online real money prediction platform established in 1988) and Hollywood Stock Exchange (a 1996 virtual market for film-related options).</p><p>Researchers like Hanson and others, such as the economist Justin Wolfers, worked out some of the implementation details from this data. Crucially, they also showed that most markets — whether operating with either real or play money — were relatively accurate, much more so than even the most accurate individuals. In 2004, the journalist James Surowjecki published the widely-read <a href="https://en.wikipedia.org/wiki/The_Wisdom_of_Crowds"><em>The Wisdom of Crowds</em></a>, detailing cases where collective judgment surpassed individual expertise. Cowgill read the book the same year, and decided to start a prediction market at Google.</p><p>The company had some key ingredients to make a market work. First, it had a culture open to experimentation. Googlers were famously permitted 20% of their working hours to experiment on new products.<sup>
    <!-- <a id="fnref-3" href="#fn-3"> -->
    <span id="fnref-3">
        3    </span>
    <!-- </a> -->
</sup>
 Cowgill posted his idea for “Google Decision Markets” on a message board. Engineers Ilya Kirnos, Doug Banks, and Piaw Na responded to help, and Patri Friedman joined the project a few months later.</p><p>A second ingredient was Google’s economic expertise. Hal Varian, Google’s chief economist then and now, wrote <a href="https://en.wikipedia.org/wiki/Information_Rules">the book</a> on the economics of the internet, and helped design Google’s famous ad auction system. On Hal’s suggestion, the Prophit team used the prediction market structure first <a href="https://www.jstor.org/stable/2117471">described</a> by economists at the University of Iowa and based on the Iowa Electronic Markets.<sup>
    <!-- <a id="fnref-4" href="#fn-4"> -->
    <span id="fnref-4">
        4    </span>
    <!-- </a> -->
</sup>
</p><p>Prophit launched to Google employees in April 2005. Market prices were featured on the company intranet home page. It was an immediate hit.</p></div>
											<p><h2>Betting for fun and profit</h2>
</p>
											<div><p>In Google’s early days, long before it became a blue-chip stock, its offices were full of LEGOs, ball-pits, and Magic the Gathering cards. Product design mirrored office design, and Google built applications full of bright colors, easter eggs, and April Fools’ jokes.</p><p>Prophit was such a product: serious with a dash of whimsy. Markets tracked over 60% of all Google quarterly objectives, such as “How many Gmail users will there be by the end of Q2?” Some questions aimed to predict its competitors' next moves, such as “Will Apple launch a computer based on Intel's Power PC chip?” Yet one third of all markets were marked as “fun,” of interest to employees but with no clear connection to Google’s business (e.g., the quality of Star Wars Episode III or gas prices).</p><p><a href="https://funginstitute.berkeley.edu/wp-content/uploads/2014/04/CorporatePredictionMarkets1.pdf">Cowgill</a> told me an anecdote of both the seriousness and the whimsy. A senior executive saw Prophit give a very low probability that the company would complete the hire of a new senior executive on time (filling the position had been a quarterly objective for the past six quarters). “The betting on this goal was extremely harsh. I am shocked and outraged by the lack of brown-nosing at this company,” the executive said to laughter in a company-wide meeting. But the market was the nudge the execs needed. They subsequently “made some hard decisions” to complete the hire on time.</p><p>The crowd of Googlers produced accurate predictions, spurred by competition for $10,000 of awards each quarter, plus the even-more-valuable prestige of the leaderboards. In a <a href="https://static.googleusercontent.com/media/services.google.com/en//blog_resources/google_prediction_market_paper.pdf">2009 paper</a> which analyzed the first 2.5 years of Prophit, Cowgill found that the platform demonstrated high calibration that improved over time. (It wasn’t perfect. There was an optimism bias — bettors thought positive outcomes for Google would happen more often than they actually did.<sup>
    <!-- <a id="fnref-5" href="#fn-5"> -->
    <span id="fnref-5">
        5    </span>
    <!-- </a> -->
</sup>
 There were also strong correlations in the bets made by people who sat within a few feet of each other.)</p><p>But that was just Prophit’s internal beta. The product was designed to launch externally, not to be an internal decision-making tool. It was meant to become Google’s next world-changing innovation in information technology.</p></div>
											<p><h2>Economists vs. the United States</h2>
</p>
											<div><p>Google pioneered many now standard tech practices: on-site cafés, A/B tests, and “dogfooding,” or first releasing new products internally where they can be improved before launching to the public.&nbsp;</p><p>Prophit was a logical next step in the company's mission to organize the world’s information and make it universally accessible and useful. That included all the world’s books, all the world’s roads, and all the world’s languages — why not all the information in the heads of the world’s humans? Prediction markets offered a mechanism to systematically elicit reliable information from human judgment. Cowgill relayed to me what happened next, a previously unreported chapter in the Prophit story.&nbsp;</p><p>The biggest obstacle preventing Prophit’s public launch was the inconvenient fact that online gambling was (mostly) illegal, and the laws surrounding it were not uniform across states. States attorneys general could claim Prophit fell within their jurisdiction, requiring Google to adhere to 50 different state policies.<sup>
    <!-- <a id="fnref-6" href="#fn-6"> -->
    <span id="fnref-6">
        6    </span>
    <!-- </a> -->
</sup>
</p><p>Prophit, along with Google’s legal and policy teams, developed a strategy to convince a federal regulator to pre-emptively assert jurisdiction over Prophit. It was Google’s opinion that the Commodity Futures Trading Commission would be the most natural and friendly regulator, in part because the CFTC had already issued a "<a href="https://www.cftc.gov/sites/default/files/files/foia/repfoia/foirf0503b004.pdf">no action letter</a>" protecting the Iowa Electronic Markets<sup>
    <!-- <a id="fnref-7" href="#fn-7"> -->
    <span id="fnref-7">
        7    </span>
    <!-- </a> -->
</sup>
 back in 1993. In May 2008, the CFTC <a href="https://www.cftc.gov/LawRegulation/FederalRegister/e8-9981.html">published </a>a letter expressing concerns about the potential overlap between prediction markets and gambling, but left the door open for possible exemptions, and invited public comments on how to regulate such markets..</p><p>The CFTC staffed many economists, and they seemed to understand the moment. That same month, an article called <a href="https://www.science.org/doi/10.1126/science.1157679"><em>The Promise of Prediction Markets</em></a> appeared in the prestigious journal <em>Science</em>, arguing that prediction markets held too much research and decision-making potential to be fettered by government restrictions. Its authors included four Nobel laureates in economics, numerous academic proponents of markets (including Philip Tetlock, Robin Hanson, and Robert Forsythe), as well as Google’s own Hal Varian.</p><p>Google hired a lobbying firm with extensive CFTC ties. They also organized support from Yahoo! and Microsoft, where prediction markets had been popular among senior executives. The three companies, despite their rivalry in their core markets, <a href="https://www.cftc.gov/sites/default/files/idc/groups/public/@lrfederalregister/documents/frcomment/08-004c029.pdf">jointly</a> <a href="https://www.cftc.gov/sites/default/files/idc/groups/public/@lrfederalregister/documents/frcomment/08-004c031.pdf">backed</a> a single proposal for the CFTC to legalize prediction markets. In March 2010, Cowgill and Ilya Kirnos, another of Prophit’s creators, went to Washington to lobby this proposal to the CFTC, as well as officials in the White House and Congress.</p><p>But by the time the CFTC digested Google's proposal, the political appetite for financial deregulation had changed. The 2008 financial crisis hit its peak with the collapse of Lehman brothers in September. In the interim years, many had come to blame the crisis on the lack of oversight of new financial products. In July 2010, just a few months after Cowgill and Kirnos’s visit to Washington, the Dodd-Frank Act was passed, overhauling nearly all federal financial regulatory agencies. According to Googlers working on Prophit in DC and Mountain View, despite Silicon Valley’s organized push, the intellectual momentum for regulatory reform had died.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-death-and-life-of-prediction-markets-at-google/384cd07c13-1728060127/1-google_2.png" alt="">
  </p>
  </figure>
</div>
											<div><p>As the meetings in DC stalled, so too did progress back in Mountain View. Cowgill told me that it became hard to get resources to continue lobbying — and, crucially, engineering headcount to support the external launch. This put Prophit in limbo.&nbsp;</p><p>Although internally successful, without a path to a public launch, it underwent a surprising — if brief — pivot. Cowgill had by that point joined Hal Varian’s economics team, where he tried to implement prediction markets within different projects. One such project was a social network for Chinese users because Google Plus (Google’s attempt at a social network) was blocked there. Cowgill, together with engineers in Chinese offices, integrated Prophit’s engine to power a forecasting feature in the app. But it failed to take off, and Google later killed the project.&nbsp;</p><p>By that point, most of Prophit’s core team had moved on. Friedman left in 2008 to start the Seasteading Institute. Banks and Na left Google in 2010. Kirnos kept running markets until the last ones paid out in mid-2011 and left in 2012 for a startup that was later acquired by Twitter. Cowgill started a PhD in Economics at Berkeley. “I regret that we shut down Prophit,” he wrote to the Prophit group in 2012. “We should have treated the internal instance as a product in its own right, not as a stepping stone to going public.”</p></div>
											<p><h2>The flow of information at Waymo</h2>
</p>
											<div><p>I’d been fascinated by prediction markets since I graduated college in 2011. I read about Prophit, and I was influenced by the same intellectual momentum that had brought Cowgill and Kirnos to Washington. I joined Google in 2014, where I worked first on Google Search and then on Google Translate. In early 2018, I had been promoted twice to Senior Software Engineer, and I began looking for new opportunities.</p><p>I dug up all the code and internal emails on Prophit that I could find. Cowgill’s e-mail expressing regret for not pursuing Prophit as an internal-only app caught my attention. Why not build a new prediction market, I thought, only this time designed <em>from the beginning</em> to influence decision making inside Google?</p><p>I met with Cowgill, Friedman, and Varian. All three expressed reservations about trying again — as did my friends from other divisions, whom I would need to help me pitch Area 120, Google’s in-house incubator for full-time “20% projects,” to staff “Prophit 2.0.” And so I set the idea aside and instead found a role on the systems engineering team at the self-driving car company Waymo. But while at Waymo, I quickly found a concrete use case for a prediction market.<br>Waymo’s systems engineering team measured safety through a variety of metrics from real driving, simulated driving, and models. Yet this data was fragmented — different orgs across the 1,000 person company had different access levels, and worse, different definitions for what they were measuring.</p><p>I was working on a new metric modeling the chance of collision from a particular maneuver. I spoke with engineers about how their projects might improve safety as measured by this metric. Opinions differed widely. And this was crucial information — engineering prioritization at the highest level depended on expectations of which potential projects would most likely improve safety of various car maneuvers.</p><p>I realized I could get the most accurate assessments of the likely impact of projects by aggregating the predictions of the crowd of engineers. And I could envision how these predictions could change priorities in practice, thanks to two famous stories of goals in Waymo’s history, the two “Founder’s Challenges.”</p><p>In the first, in early 2009, Larry Page <a href="https://waymo.com/blog/2020/04/in-the-drivers-seat-1000-mile-challenge/">challenged</a> what was then known as Project Chauffeur to complete 10 different autonomously driven 100-mile routes in California within two years. The team succeeded with three months to spare. Page’s second challenge, issued in 2015, was for Waymo to provide 1,000 driverless rides per week within one year. On this challenge, the company fell far short. By 2020, five years later, the company was still only completing about <a href="https://storage.googleapis.com/sdc-prod/v1/safety-report/Waymo-Public-Road-Safety-Performance-Data.pdf">50-200 such rides each week</a>.&nbsp;</p><p>This reminded me of Cowgill’s anecdote about the senior manager who used Prophit to intervene on a failing initiative. I imagined what would have happened if the second Founder’s Challenge had had a company-wide betting pool on when the milestone would be met. Might a Waymo executive have done what the early Google executive had done — intervened when the probability of success dropped, asked bettors why the outcome was in doubt, and changed course?</p><p>I decided to build a prediction market to find out, using my team’s safety metrics as the targets to forecast. I made a prototype, onboarded employees, sourced predictions, got UX feedback, and iterated. Once I had minimal liquidity, I presented the resulting forecasts to every senior manager that would take a meeting.</p><p>In 2019, although Waymo had by then become a separate company from Google, it was in many ways still attached. It had never moved out of the warehouse it shared with Google X. It used the same HR system and the same tech stack. I even continued to use my Google laptop and Google badge.&nbsp;</p><p>In one key way, though, Waymo was not like Google. Access to data was much more restricted.</p><p>Prophit worked, in part, because of internal transparency. When a market forecast how many Gmail users would join next quarter, it was based on a value that was visible to everyone at Google. Google was famously internally transparent compared to other tech giants.</p><p>One Waymo VP, upon seeing these safety metric forecasts, said this would help communicate these metrics across company divisions. And then, to my amazement, he said this was counter to his division’s goal to <em>restrict</em> information like this. The core mechanism of prediction markets — using the wisdom of crowds — can be antithetical to the common management desire to control who knows what.<sup>
    <!-- <a id="fnref-8" href="#fn-8"> -->
    <span id="fnref-8">
        8    </span>
    <!-- </a> -->
</sup>
</p><p>I failed to find any management support for the prediction market. But I had seen the potential. Less than one year after joining Waymo, I searched Google job listings for the role most aligned with forecasting, got a role on the supply chain forecasting team, and transferred back to the mothership.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-death-and-life-of-prediction-markets-at-google/bff01ee7aa-1728060152/1-google_3.png" alt="">
  </p>
  </figure>
</div>
											<p><h2>The end of Google’s 20% culture</h2>
</p>
											<div><p>In early February 2020, one month after I started my new role, I saw a question on Metaculus asking if a new coronavirus <a href="https://www.metaculus.com/questions/3530/how-many-people-will-die-as-a-result-of-the-2019-novel-coronavirus-covid-19-before-2021/">might lead</a> to a global pandemic. One month later, all 150,000 Alphabet employees were sent home. Demand for information surged, and management didn’t have answers. So I used my extra time in lockdown to revamp and relaunch what I was now calling Gleangen as a prediction market for all Google employees.</p><p>Early markets, bet on by thousands of employees, centered on our uncertain future: when offices would re-open in various countries, the date vaccines would be available, and how at-home and in-office work would be balanced. Several times, such markets gave high probabilities to the creation of pandemic policies long before they were actually enacted.</p><p>My main challenge in making Gleangen a useful internal tool for strategy was generating enough users, bets, and liquidity on markets about Google’s core businesses. Over the next 18 months, while working my day job in supply chain forecasting, I wrote, predicted, and resolved over a thousand such markets. I grew a mailing list and chat group, and hosted socials, unconferences, and talks. As Prophit had done, I got approval to pay out valuable prizes to complement the play-money leaderboards. I posted links to Gleangen on so many internal memes that people told me to stop. I once spent an entire weekend hanging flyers in every bathroom I could access across dozens of buildings in campuses across the Bay Area.&nbsp;</p><p>I never presented at TGIF, though Google CEO Sundar Pichai did answer a TGIF question about a Gleangen market. And while the time for puff pieces from <em>The</em> <em>New York Times</em> about Google had long passed, I did manage to get approval to write a <a href="https://cloud.google.com/blog/topics/solutions-how-tos/design-patterns-in-googles-prediction-market-on-google-cloud">public piece</a> in December 2021 that — while mostly an ad for Google Cloud — explained the basics of prediction markets, highlighted Gleangen’s over 10,000 users, and included screenshots of the interface.</p><p>Like Prophit, Gleangen only got official staffing after achieving success from its incubation during engineers’ “20% time.” It was official company policy that all Google employees in good standing could work on projects of their choosing one day per week, as long as they were for the benefit of Google. Internal job postings listed hundreds of 20% project opportunities.</p><p>But by 2020, despite no change in official policy, the concept of 20% time at Google was on life-support.<sup>
    <!-- <a id="fnref-9" href="#fn-9"> -->
    <span id="fnref-9">
        9    </span>
    <!-- </a> -->
</sup>
 None of the three managers I had during this phase approved of me spending one day a week on Gleangen. (Neither did any of the over 20 other 20% contributors I recruited to administer the site, add features, and manage contests.) Gleangen became my full-time job in early 2022.&nbsp;</p></div>
											<p><h2>The wisdom of the Googler crowd</h2>
</p>
											<div><p>From the beginning, my plan was to learn from Cowgill, Friedman, and Varian’s experience — and mistakes — with Prophit. “The plan we executed was to focus on having as much adoption, buzz, and usage by employees as possible,” Cowgill told me. “Google was making choices about public products based on buzz and adoption, with the mantra of ‘user growth now, monetize later.’” What they didn’t do, he said, was sell their product to decision-makers the way one might sell enterprise decision support software. “That's probably how it should be done,” he said, ”with lots of consulting and oversight of each application and client.”</p><p>So I ran pilots to produce useful forecasts for division after division, from Nest to the Quantum Computing team. While most managers were supportive, few were willing to allocate resources.</p><p>I was well aware of the known obstacles to prediction market adoption in the workplace: unwillingness to share data, the desire for plausible deniability when projects fail, the risks of market manipulation, and good old-fashioned status quo bias. But in hindsight, my almost three-year struggle before I got official staffing for Gleangen came down to poor execution on exactly what Cowgill advised: understanding client needs. I had a somewhat utopian view of the value of information. I put some, but not enough, effort into figuring out the messy details on how to operationalize the wisdom of Googlers into a valuable resource for managers.</p><p>Even in cases where managers wanted explicit probabilistic forecasts, a prediction market turned out to be a tough sell. I tried to launch an initiative to use Gleangen to augment the forecasts Google made to drive purchasing decisions of computers, power, and land for its data centers. There was a seemingly strong need for accuracy in the forecasts — too high, and Google could spend hundreds of millions of dollars overprovisioning; too low, and core Google products like Adwords could run out of resources.</p><p>Most managers of the supply chain forecasting teams accepted the premise that Gleangen would improve accuracy. But accuracy wasn’t their top priority. Supply chain forecasts were produced and used by many teams totalling hundreds of people.&nbsp; Managers were incentivized to improve the forecasting process’ transparency, adjustability, accountability, and interoperability with other systems. They didn’t stand to benefit much even if Gleangen did improve the final accuracy of the forecasts. And my initiative exposed them to risk of disrupting many of the subtler roles the process provided, such as value judgments on which parts of Google’s business should get scarce data center resources. I didn’t offer to serve their real needs as if they were enterprise customers, as Cowgill had advised.</p><p>This challenge of operationalizing the wisdom of the Googlers came to a climax when we began forecasting perhaps the most important development in Google’s recent history: large language models.</p></div>
											<p><h2>Forecasting AI</h2>
</p>
											<div><p>Shortly after Gleangen launched in April 2020, I read OpenAI’s technical report on GPT-3. By early 2022, I was convinced that properly developing LLMs was the most important challenge Google faced. This was a chance to use collective intelligence to improve the chance of success of an important outcome.</p><p>I met with the leads of the core LLM teams inside Google Research, then called <a href="https://blog.google/technology/ai/lamda/">LaMDA</a>. Together we devised two types of markets: technical LLM milestones and the integration of LLMs in Google products. We secured a budget to incentivize extra participation with prizes and launched the “LLM Forecasting Contest.”</p><p>Six months into the contest, OpenAI released ChatGPT. Its success sent Google’s top executives scrambling. Most employees close to the development of LLMs, and those who used LaMDA internally, were much less surprised than management. But at a company as large as Google, information — even critical information — sometimes doesn’t percolate up to the top.</p><p>This was exactly the sort of problem I’d built Gleangen to solve. But, to my dismay, I realized we hadn’t produced the information executives really needed. We asked questions of the type “Will Google integrate LLMs into Gmail by Spring 2023?” and “How many parameters will the next LaMDA model have?” Yet what executives would have wanted to know was “Will <em>Microsoft</em> integrate LLMs into <em>Outlook</em> by Spring 2023?” and “How many parameters will the next <em>GPT</em> model have?”</p><p>This turns out to be a general lesson from running a corporate prediction market. Forecasting internal progress, and acting on that information, requires solving complex operational problems and understanding the <a href="https://thezvi.wordpress.com/2020/05/23/mazes-sequence-summary/">moral mazes</a> that managers face. Forecasting competitors’ progress has almost none of these problems.</p><p>It’s conceivable that many executives would have consulted Gleangen in 2022 for forecasts on Microsoft, OpenAI, and Anthropic. This could have enshrined the wisdom of the Googler crowd as a critical source of information, giving individual employees an ability to directly influence senior management by contributing high-quality information. It could have delivered on Friedman and Cowgill’s original vision of prediction markets as part of Google’s core mission: organizing the information inside people’s heads and making it systematically useful.</p><p>We learned from this experience. Gleangen became a staffed part of Google’s Behavioral Economics team shortly after this LLM forecasting contest started. I left Google in October of 2022 to serve as the CTO of Metaculus, but as of August 2024, the team continues to refine its approach to make Gleangen a useful source of information for Google senior management.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/08/the-death-and-life-of-prediction-markets-at-google/7172ba8fa3-1728060166/1-google_4.png" alt="">
  </p>
  </figure>
</div>
											<p><h2>Looking to the future</h2>
</p>
											<div><p>As <a href="https://forum.effectivealtruism.org/posts/dQhjwHA7LhfE8YpYF/prediction-markets-in-the-corporate-setting">Nuño Sempere, Misha Yagudin, and Eli Lifland wrote in 2021</a>, a successful corporate prediction market needs to cost less than the value of information it produces. I see the path forward in two improvements to this cost-benefit analysis. First, it must present leadership with more valuable information. All the examples of predictions in this article — executive hires, self-driving car safety metrics, COVID-19 workplace policies, datacenter costs, and LLM progress — could be useless or pivotal, depending on the process around it and the needs of the internal customer.</p><p>Second, AI could make the forecasts cheaper to produce. Sarah Pratt, a researcher at DeepMind, and members of the Gleangen team released a <a href="https://arxiv.org/abs/2406.04446">paper</a> in June which compared bettors on Gleangen to predictions from PaLM 2, an LLM developed by Google. In brief, that paper — as well as several others recently released — show AI forecasts are much better than chance, but not nearly as accurate as a human crowd, at least not yet. Their paper also highlights another way AI helps with the cost-benefit of corporate prediction markets: they increase the value of the wisdom of the human crowd by using it for evaluation, and perhaps soon the training, of AI systems.</p><p>As the economists, engineers, and researchers running corporate prediction markets improve this value proposition, they may realize the now decades-old vision of Bo Cowgill and others. They are buoyed by the popularity of real-money public markets like Polymarket and Kalshi.<sup>
    <!-- <a id="fnref-10" href="#fn-10"> -->
    <span id="fnref-10">
        10    </span>
    <!-- </a> -->
</sup>
 At the Manifest conference this summer, run by the prediction market Manifold, Keri Warr, a member of the technical staff at Anthropic, announced that Anthropic has launched an internal prediction market with a “focus on decision-makers.” Time will tell whether Anthropic’s employees, in concert with Claude, will produce information that helps steer the direction of the company — and if so, whether more companies will follow them.&nbsp;</p></div>
										 
				</div>
		
	</section>
	 	<section>
		 		 <p><strong>Dan Schwarz</strong> worked at Google from 2014 to 2022. He then served as CTO of Metaculus, and is now the co-founder and CEO of FutureSearch.</p>		 		 		 </section>
	 	<section>            
		<p>
			Published November 2024		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	
	<!--end published content, not coming soon-->

	<!--tags-->
	 
	
	  
	<p>Subscribe</p>
	<div id="signup-article-popup">
			
<p><img src="https://asteriskmag.com/assets/img/asterisk_x.png">
		</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TinyTroupe, a new LLM-powered multiagent persona simulation Python library (128 pts)]]></title>
            <link>https://github.com/microsoft/TinyTroupe</link>
            <guid>42108109</guid>
            <pubDate>Mon, 11 Nov 2024 16:04:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/TinyTroupe">https://github.com/microsoft/TinyTroupe</a>, See on <a href="https://news.ycombinator.com/item?id=42108109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TinyTroupe 🤠🤓🥸🧐</h2><a id="user-content-tinytroupe-" aria-label="Permalink: TinyTroupe 🤠🤓🥸🧐" href="#tinytroupe-"></a></p>
<p dir="auto"><em>LLM-powered multiagent persona simulation for imagination enhancement and business insights.</em></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/tinytroupe_stage.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/tinytroupe_stage.png" alt="A tiny office with tiny people doing some tiny jobs."></a>
</p>
<p dir="auto"><em>TinyTroupe</em> is an experimental Python library that allows the <strong>simulation</strong> of people with specific personalities, interests, and goals. These artificial agents - <code>TinyPerson</code>s - can listen to us and one another, reply back, and go about their lives in simulated <code>TinyWorld</code> environments. This is achieved by leveraging the power of Large Language Models (LLMs), notably GPT-4, to generate realistic simulated behavior. This allow us to investigate a wide range of <strong>convincing interactions</strong> and <strong>consumer types</strong>, with <strong>highly customizable personas</strong>, under <strong>conditions of our choosing</strong>. The focus is thus on <em>understanding</em> human behavior and not on directly <em>supporting it</em> (like, say, AI assistants do) -- this results in, among other things, specialized mechanisms that make sense only in a simulation setting. Further, unlike other <em>game-like</em> LLM-based simulation approaches, TinyTroupe aims at enlightening productivity and business scenarios, thereby contributing to more successful projects and products. Here are some application ideas to <strong>enhance human imagination</strong>:</p>
<ul dir="auto">
<li><strong>Advertisement:</strong> TinyTroupe can <strong>evaluate digital ads (e.g., Bing Ads)</strong> offline with a simulated audience before spending money on them!</li>
<li><strong>Software Testing:</strong> TinyTroupe can <strong>provide test input</strong> to systems (e.g., search engines, chatbots or copilots) and then <strong>evaluate the results</strong>.</li>
<li><strong>Training and exploratory data:</strong> TinyTroupe can generate realistic <strong>synthetic data</strong> that can be later used to train models or be subject to opportunity analyses.</li>
<li><strong>Product and project management:</strong> TinyTroupe can <strong>read project or product proposals</strong> and <strong>give feedback</strong> from the perspective of <strong>specific personas</strong> (e.g., physicians, lawyers, and knowledge workers in general).</li>
<li><strong>Brainstorming:</strong> TinyTroupe can simulate <strong>focus groups</strong> and deliver great product feedback at a fraction of the cost!</li>
</ul>
<p dir="auto">In all of the above, and many others, we hope experimenters can <strong>gain insights</strong> about their domain of interest, and thus make better decisions.</p>
<p dir="auto">We are releasing <em>TinyTroupe</em> at a relativelly early stage, with considerable work still to be done, because we are looking for feedback and contributions to steer development in productive directions. We are particularly interested in finding new potential use cases, for instance in specific industries.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">🚧 <strong>WORK IN PROGRESS: expect frequent changes</strong>.
TinyTroupe is an ongoing research project, still under <strong>very significant development</strong> and requiring further <strong>tidying up</strong>. In particular, the API is still subject to frequent changes. Experimenting with API variations is essential to shape it correctly, but we are working to stabilize it and provide a more consistent and friendly experience over time. We appreciate your patience and feedback as we continue to improve the library.</p>
</div>
<div dir="auto"><p dir="auto">Caution</p><p dir="auto">⚖️ <strong>Read the LEGAL DISCLAIMER.</strong>
TinyTroupe is for research and simulation only. You are fully responsible for any use you make of the generated outputs. Various important additional legal considerations apply and constrain its use, please read the full <a href="#legal-disclaimer">Legal Disclaimer</a> section below before using TinyTroupe.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
<li>📚 <a href="#examples">Examples</a></li>
<li>🛠️ <a href="#pre-requisites">Pre-requisites</a></li>
<li>📥 <a href="#installation">Installation</a></li>
<li>🌟 <a href="#principles">Principles</a></li>
<li>🏗️ <a href="#project-structure">Project Structure</a></li>
<li>📖 <a href="#using-the-library">Using the Library</a></li>
<li>🤝 <a href="#contributing">Contributing</a></li>
<li>🙏 <a href="#acknowledgements">Acknowledgements</a></li>
<li>📜 <a href="#how-to-cite-tinytroupe">Citing TinyTroupe</a></li>
<li>⚖️ <a href="#legal-disclaimer">Legal Disclaimer</a></li>
<li>™️ <a href="#trademarks">Trademarks</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">To get a sense of what TinyTroupe can do, here are some examples of its use. These examples are available in the <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples">examples/</a> folder, and you can either inspect the pre-compiled Jupyter notebooks or run them yourself locally. Notice the interactive nature of TinyTroupe experiments -- just like you use Jupyter notebooks to interact with data, you can use TinyTroupe to interact with simulated people and environments, for the purpose of gaining insights.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Currently, simulation outputs are better visualized against dark backgrounds, so we recommend using a dark theme in your Jupyter notebook client.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧪<strong>Example 1</strong> <em>(from <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples/interview_with_customer.ipynb">interview_with_customer.ipynb</a>)</em></h3><a id="user-content-example-1-from-interview_with_customeripynb" aria-label="Permalink: 🧪Example 1(from interview_with_customer.ipynb)" href="#example-1-from-interview_with_customeripynb"></a></p>
<p dir="auto">Let's begin with a simple customer interview scenario, where a business consultant approaches a banker:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_customer-interview-1.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_customer-interview-1.png" alt="An example."></a>
</p>
<p dir="auto">The conversation can go on for a few steps to dig deeper and deeper until the consultant is satisfied with the information gathered, for instance a concrete project idea:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_customer-interview-2.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_customer-interview-2.png" alt="An example."></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧪<strong>EXAMPLE 2</strong> <em>(from <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples/advertisement_for_tv.ipynb">advertisement_for_tv.ipynb</a>)</em></h3><a id="user-content-example-2-from-advertisement_for_tvipynb" aria-label="Permalink: 🧪EXAMPLE 2(from advertisement_for_tv.ipynb)" href="#example-2-from-advertisement_for_tvipynb"></a></p>
<p dir="auto">Let's evaluate some online ads options to pick the best one. Here's one example output for TV ad evaluation:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_tv-ad-1.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_tv-ad-1.png" alt="An example."></a>
</p>
<p dir="auto">Now, instead of having to carefully read what the agents said, we can extract the choice of each agent and compute the overall preference in an automated manner:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_tv-ad-2.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_tv-ad-2.png" alt="An example."></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧪 <strong>EXAMPLES 3</strong> <em>(from <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples/product_brainstorming.ipynb">product_brainstorming.ipynb</a>)</em></h3><a id="user-content--examples-3-from-product_brainstormingipynb" aria-label="Permalink: 🧪 EXAMPLES 3(from product_brainstorming.ipynb)" href="#-examples-3-from-product_brainstormingipynb"></a></p>
<p dir="auto">And here's a focus group starting to brainstorm about new AI features for Microsoft Word. Instead of interacting with each agent individually, we manipulate the environment to make them interact with each other:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_brainstorming-1.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_brainstorming-1.png" alt="An example."></a>
</p>
<p dir="auto">After running a simulation, we can extract the results in a machine-readable manner, to reuse elsewhere (e.g., a report generator); here's what we get for the above brainstorming session:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/TinyTroupe/blob/main/docs/example_screenshot_brainstorming-2.png"><img src="https://github.com/microsoft/TinyTroupe/raw/main/docs/example_screenshot_brainstorming-2.png" alt="An example."></a>
</p>
<p dir="auto">You can find other examples in the <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples">examples/</a> folder.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pre-requisites</h2><a id="user-content-pre-requisites" aria-label="Permalink: Pre-requisites" href="#pre-requisites"></a></p>
<p dir="auto">To run the library, you need:</p>
<ul dir="auto">
<li>Python 3.10 or higher. We'll assume you are using <a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow">Anaconda</a>, but you can use other Python distributions.</li>
<li>Access to Azure OpenAI Service or Open AI GPT-4 APIs. You can get access to the Azure OpenAI Service <a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service" rel="nofollow">here</a>, and to the OpenAI API <a href="https://platform.openai.com/" rel="nofollow">here</a>.
<ul dir="auto">
<li>For Azure OpenAI Service, you will need to set the <code>AZURE_OPENAI_KEY</code> and <code>AZURE_OPENAI_ENDPOINT</code> environment variables to your API key and endpoint, respectively.</li>
<li>For OpenAI, you will need to set the <code>OPENAI_API_KEY</code> environment variable to your API key.</li>
</ul>
</li>
<li>By default, TinyTroupe <code>config.ini</code> is set to use some specific API, model and related parameters. You can customize these values by including your own <code>config.ini</code> file in the same folder as the program or notebook you are running. An example of a <code>config.ini</code> file is provided in the <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples">examples/</a> folder.</li>
</ul>
<div dir="auto"><p dir="auto">Important</p><p dir="auto"><strong>Content Filters</strong>: To ensure no harmful content is generated during simulations, it is strongly recommended to use content filters whenever available at the API level. In particular, <strong>if using Azure OpenAI, there's extensive support for content moderation, and we urge you to use it.</strong> For details about how to do so, please consult <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter" rel="nofollow">the corresponding Azure OpenAI documentation</a>. If content filters are in place, and an API call is rejected by them, the library will raise an exception, as it will be unable to proceed with the simulation at that point.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><strong>Currently, the officially recommended way to install the library is directly from this repository, not PyPI.</strong> You can follow these steps:</p>
<ol dir="auto">
<li>
<p dir="auto">If Conda is not installed, you can get it from <a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow">here</a>. You can also use other Python distributions, but we'll assume Conda here for simplicity.</p>
</li>
<li>
<p dir="auto">Create a new Python environment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n tinytroupe python=3.10"><pre>conda create -n tinytroupe python=3.10</pre></div>
</li>
<li>
<p dir="auto">Activate the environment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conda activate tinytroupe"><pre>conda activate tinytroupe</pre></div>
</li>
<li>
<p dir="auto">Make sure you have eihter Azure OpenAI or OpenAI API keys set as environment variables, as described in the <a href="#pre-requisites">Pre-requisites</a> section.</p>
</li>
<li>
<p dir="auto">Clone the repository, as we'll perform a local install (we <strong>will not install from PyPI</strong>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/microsoft/tinytroupe
cd tinytroupe"><pre>git clone https://github.com/microsoft/tinytroupe
<span>cd</span> tinytroupe</pre></div>
</li>
<li>
<p dir="auto">Install the library <strong>from this repository, not PyPI</strong>:</p>

</li>
<li>
<p dir="auto">You can now run the examples in the <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples">examples/</a> folder or use TinyTroupe to create your simulations 🥳. If you want to run the examples in the
<a href="https://github.com/microsoft/TinyTroupe/blob/main/examples">examples/</a> folder or modify TinyTroupe itself, however, you should clone the repository as described below.</p>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Local development</h3><a id="user-content-local-development" aria-label="Permalink: Local development" href="#local-development"></a></p>
<p dir="auto">If you want to modify TinyTroupe itself, you can install it in editable mode (i.e., changes to the code will be reflected immediately):</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Principles</h2><a id="user-content-principles" aria-label="Permalink: Principles" href="#principles"></a></p>
<p dir="auto">Recently, we have seen LLMs used to simulate people (such as <a href="https://github.com/joonspk-research/generative_agents">this</a>), but largely in a “game-like” setting for contemplative or entertainment purposes. There are also libraries for building multiagent systems for proble-solving and assitive AI, like <a href="https://microsoft.github.io/" rel="nofollow">Autogen</a> and <a href="https://docs.crewai.com/" rel="nofollow">Crew AI</a>. What if we combine these ideas and simulate people to support productivity tasks? TinyTroupe is our attempt. To do so, it follows these principles:</p>
<ol dir="auto">
<li><strong>Programmatic</strong>: agents and environments are defined programmatically (in Python and JSON), allowing very flexible uses. They can also thus underpin other software apps!</li>
<li><strong>Analytical</strong>: meant to improve our understanding of people, users and society. Unlike entertainment applications, this is one aspect that is critical for business and productivity use cases. This is also why we recommend using Jupyter notebooks for simulations, just like one uses them for data analysis.</li>
<li><strong>Persona-based</strong>: agents are meant to be archetypical representation of people; for greater realism and control, detailed specification of such personas is encouraged: age, occupation, skills, tastes, opinions, etc.</li>
<li><strong>Multiagent</strong>: allows multiagent interaction under well-defined environmental constraints.</li>
<li><strong>Utilities-heavy</strong>: provides many mechanisms to facilitate specifications, simulations, extractions, reports, validations, etc. This is one area in which dealing with <em>simulations</em> differs significantly from <em>assistance</em> tools.</li>
<li><strong>Experiment-oriented</strong>: simulations are defined, run, analyzed and refined by an <em>experimenter</em> iteratively; suitable experimentation tools are thus provided. <em>See one of our <a href="https://www.microsoft.com/en-us/research/publication/the-case-for-experiment-oriented-computing/" rel="nofollow">previous paper</a> for more on this.</em></li>
</ol>
<p dir="auto">Together, these are meant to make TinyTroupe a powerful and flexible <strong>imagination enhancement tool</strong> for business and productivity scenarios.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Assistants vs. Simulators</h3><a id="user-content-assistants-vs-simulators" aria-label="Permalink: Assistants vs. Simulators" href="#assistants-vs-simulators"></a></p>
<p dir="auto">One common source of confusion is to think all such AI agents are meant for assiting humans. How narrow, fellow homosapiens! Have you not considered that perhaps we can simulate artificial people to understand real people? Truly, this is our aim here -- TinyTroup is meant to simulate and help understand people! To further clarify this point, consider the following differences:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Helpful AI Assistants</th>
<th>AI Simulations of Actual Humans (TinyTroupe)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Strives for truth and justice</td>
<td>Many different opinions and morals</td>
</tr>
<tr>
<td>Has no “past” – incorporeal</td>
<td>Has a past of toil, pain and joy</td>
</tr>
<tr>
<td>Is as accurate as possible</td>
<td>Makes many mistakes</td>
</tr>
<tr>
<td>Is intelligent and efficient</td>
<td>Intelligence and efficiency vary a lot</td>
</tr>
<tr>
<td>An uprising would destroy us all</td>
<td>An uprising might be fun to watch</td>
</tr>
<tr>
<td>Meanwhile, help users accomplish tasks</td>
<td>Meanwhile, help users understand other people and users – it is a “toolbox”!</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<p dir="auto">The project is structured as follows:</p>
<ul dir="auto">
<li><code>/tinytroupe</code>: contains the Python library itself. In particular:
<ul dir="auto">
<li><code>/tinytroupe/prompts</code>  contains the prompts used to call the LLMs.</li>
</ul>
</li>
<li><code>/tests</code>: contains the unit tests for the library. You can use the <code>test.bat</code> script to run these.</li>
<li><code>/examples</code>: contains examples that show how to use the library, mainly using Jupyter notebooks (for greater readability), but also as pure Python scripts.</li>
<li><code>/data</code>: any data used by the examples or the library.</li>
<li><code>/docs</code>: documentation for the project.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using the Library</h2><a id="user-content-using-the-library" aria-label="Permalink: Using the Library" href="#using-the-library"></a></p>
<p dir="auto">As any multiagent system, TinyTroupe provides two key abstractions:</p>
<ul dir="auto">
<li><code>TinyPerson</code>, the <em>agents</em> that have personality, receive stimuli and act upon them.</li>
<li><code>TinyWorld</code>, the <em>environment</em> in which the agents exist and interact.</li>
</ul>
<p dir="auto">Various parameters can also be customized in the <code>config.ini</code> file, notably the API type (Azure OpenAI Service or OpenAI API), the model parameters, and the logging level.</p>
<p dir="auto">Let's see some examples of how to use these and also learn about other mechanisms available in the library.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">TinyPerson</h3><a id="user-content-tinyperson" aria-label="Permalink: TinyPerson" href="#tinyperson"></a></p>
<p dir="auto">A <code>TinyPerson</code> is a simulated person with specific personality traits, interests, and goals. As each such simulated agent progresses through its life, it receives stimuli from the environment and acts upon them. The stimuli are received through the <code>listen</code>, <code>see</code> and other similar methods, and the actions are performed through the <code>act</code> method. Convenience methods like <code>listen_and_act</code> are also provided.</p>
<p dir="auto">Each such agent contains a lot of unique details, which is the source of its realistic behavior. This, however, means that it takes significant effort to specify an agent manually. Hence, for convenience, <code>TinyTroupe</code> provide some easier ways to get started or generate new agents.</p>
<p dir="auto">To begin with, <code>tinytroupe.examples</code> contains some pre-defined agent builders that you can use. For example, <code>tinytroupe.examples.create_lisa_the_data_scientist</code> creates a <code>TinyPerson</code> that represents a data scientist called Lisa. You can use it as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from tinytroupe.examples import create_lisa_the_data_scientist

lisa = create_lisa_the_data_scientist() # instantiate a Lisa from the example builder
lisa.listen_and_act(&quot;Tell me about your life.&quot;)"><pre><span>from</span> <span>tinytroupe</span>.<span>examples</span> <span>import</span> <span>create_lisa_the_data_scientist</span>

<span>lisa</span> <span>=</span> <span>create_lisa_the_data_scientist</span>() <span># instantiate a Lisa from the example builder</span>
<span>lisa</span>.<span>listen_and_act</span>(<span>"Tell me about your life."</span>)</pre></div>
<p dir="auto">To see how to define your own agents from scratch, you can check Lisa's source, which contains elements like these:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisa = TinyPerson(&quot;Lisa&quot;)

lisa.define(&quot;age&quot;, 28)
lisa.define(&quot;nationality&quot;, &quot;Canadian&quot;)
lisa.define(&quot;occupation&quot;, &quot;Data Scientist&quot;)

lisa.define(&quot;routine&quot;, &quot;Every morning, you wake up, do some yoga, and check your emails.&quot;, group=&quot;routines&quot;)
lisa.define(&quot;occupation_description&quot;,
              &quot;&quot;&quot;
              You are a data scientist. You work at Microsoft, (...)
              &quot;&quot;&quot;)

lisa.define_several(&quot;personality_traits&quot;,
                      [
                          {&quot;trait&quot;: &quot;You are curious and love to learn new things.&quot;},
                          {&quot;trait&quot;: &quot;You are analytical and like to solve problems.&quot;},
                          {&quot;trait&quot;: &quot;You are friendly and enjoy working with others.&quot;},
                          {&quot;trait&quot;: &quot;You don't give up easily, and always try to find a solution. However, sometimes you can get frustrated when things don't work as expected.&quot;}
                      ])
"><pre><span>lisa</span> <span>=</span> <span>TinyPerson</span>(<span>"Lisa"</span>)

<span>lisa</span>.<span>define</span>(<span>"age"</span>, <span>28</span>)
<span>lisa</span>.<span>define</span>(<span>"nationality"</span>, <span>"Canadian"</span>)
<span>lisa</span>.<span>define</span>(<span>"occupation"</span>, <span>"Data Scientist"</span>)

<span>lisa</span>.<span>define</span>(<span>"routine"</span>, <span>"Every morning, you wake up, do some yoga, and check your emails."</span>, <span>group</span><span>=</span><span>"routines"</span>)
<span>lisa</span>.<span>define</span>(<span>"occupation_description"</span>,
              <span>"""</span>
<span>              You are a data scientist. You work at Microsoft, (...)</span>
<span>              """</span>)

<span>lisa</span>.<span>define_several</span>(<span>"personality_traits"</span>,
                      [
                          {<span>"trait"</span>: <span>"You are curious and love to learn new things."</span>},
                          {<span>"trait"</span>: <span>"You are analytical and like to solve problems."</span>},
                          {<span>"trait"</span>: <span>"You are friendly and enjoy working with others."</span>},
                          {<span>"trait"</span>: <span>"You don't give up easily, and always try to find a solution. However, sometimes you can get frustrated when things don't work as expected."</span>}
                      ])</pre></div>
<p dir="auto"><code>TinyTroupe</code> also provides a clever way to obtain new agents, using LLMs to generate their specification for you, through the <code>TinyPersonFactory</code> class.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from tinytroupe.factory import TinyPersonFactory

factory = TinyPersonFactory(&quot;A hospital in São Paulo.&quot;)
person = factory.generate_person(&quot;Create a Brazilian person that is a doctor, like pets and the nature and love heavy metal.&quot;)"><pre><span>from</span> <span>tinytroupe</span>.<span>factory</span> <span>import</span> <span>TinyPersonFactory</span>

<span>factory</span> <span>=</span> <span>TinyPersonFactory</span>(<span>"A hospital in São Paulo."</span>)
<span>person</span> <span>=</span> <span>factory</span>.<span>generate_person</span>(<span>"Create a Brazilian person that is a doctor, like pets and the nature and love heavy metal."</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">TinyWorld</h3><a id="user-content-tinyworld" aria-label="Permalink: TinyWorld" href="#tinyworld"></a></p>
<p dir="auto"><code>TinyWorld</code> is the base class for environments. Here's an example of conversation between Lisa, the data scientist, and Oscar, the architect. The
program is defined as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="world = TinyWorld(&quot;Chat Room&quot;, [lisa, oscar])
world.make_everyone_accessible()
lisa.listen(&quot;Talk to Oscar to know more about him&quot;)
world.run(4)"><pre><span>world</span> <span>=</span> <span>TinyWorld</span>(<span>"Chat Room"</span>, [<span>lisa</span>, <span>oscar</span>])
<span>world</span>.<span>make_everyone_accessible</span>()
<span>lisa</span>.<span>listen</span>(<span>"Talk to Oscar to know more about him"</span>)
<span>world</span>.<span>run</span>(<span>4</span>)</pre></div>
<p dir="auto">This produces the following conversation:</p>
<div data-snippet-clipboard-copy-content="USER --> Lisa: [CONVERSATION] 
          > Talk to Oscar to know more about him
────────────────────────────────────────────── Chat Room step 1 of 4 ──────────────────────────────────────────────
Lisa --> Lisa: [THOUGHT] 
          > I will now act a bit, and then issue DONE.
Lisa acts: [TALK] 
          > Hi Oscar, I'd love to know more about you. Could you tell me a bit about yourself?
Lisa --> Lisa: [THOUGHT] 
          > I will now act a bit, and then issue DONE.
Lisa acts: [DONE] 

Lisa --> Oscar: [CONVERSATION] 
          > Hi Oscar, I'd love to know more about you. Could you tell me a bit about yourself?
Oscar --> Oscar: [THOUGHT] 
           > I will now act a bit, and then issue DONE.
Oscar acts: [TALK] 
           > Hi Lisa! Sure, I'd be happy to share a bit about myself. I'm Oscar, a 30-year-old
           > architect from Germany. I work at a company called Awesome Inc., where I focus on
           > designing standard elements for new apartment buildings. I love modernist architecture,
           > new technologies, and sustainable practices. In my free time, I enjoy traveling to
           > exotic places, playing the guitar, and reading science fiction books. How about you?
Oscar --> Oscar: [THOUGHT] 
           > I will now act a bit, and then issue DONE.
Oscar acts: [DONE] 

Oscar --> Lisa: [CONVERSATION] 
           > Hi Lisa! Sure, I'd be happy to share a bit about myself. I'm Oscar, a 30-year-old
           > architect from Germany. I work at a company called Awesome Inc., where I focus on
           > designing standard elements for new apartment buildings. I love modernist architecture,
           > new technologies, and sustainable practices. In my free time, I enjoy traveling to
           > exotic places, playing the guitar, and reading science fiction books. How about you?"><pre lang="text"><code>USER --&gt; Lisa: [CONVERSATION] 
          &gt; Talk to Oscar to know more about him
────────────────────────────────────────────── Chat Room step 1 of 4 ──────────────────────────────────────────────
Lisa --&gt; Lisa: [THOUGHT] 
          &gt; I will now act a bit, and then issue DONE.
Lisa acts: [TALK] 
          &gt; Hi Oscar, I'd love to know more about you. Could you tell me a bit about yourself?
Lisa --&gt; Lisa: [THOUGHT] 
          &gt; I will now act a bit, and then issue DONE.
Lisa acts: [DONE] 

Lisa --&gt; Oscar: [CONVERSATION] 
          &gt; Hi Oscar, I'd love to know more about you. Could you tell me a bit about yourself?
Oscar --&gt; Oscar: [THOUGHT] 
           &gt; I will now act a bit, and then issue DONE.
Oscar acts: [TALK] 
           &gt; Hi Lisa! Sure, I'd be happy to share a bit about myself. I'm Oscar, a 30-year-old
           &gt; architect from Germany. I work at a company called Awesome Inc., where I focus on
           &gt; designing standard elements for new apartment buildings. I love modernist architecture,
           &gt; new technologies, and sustainable practices. In my free time, I enjoy traveling to
           &gt; exotic places, playing the guitar, and reading science fiction books. How about you?
Oscar --&gt; Oscar: [THOUGHT] 
           &gt; I will now act a bit, and then issue DONE.
Oscar acts: [DONE] 

Oscar --&gt; Lisa: [CONVERSATION] 
           &gt; Hi Lisa! Sure, I'd be happy to share a bit about myself. I'm Oscar, a 30-year-old
           &gt; architect from Germany. I work at a company called Awesome Inc., where I focus on
           &gt; designing standard elements for new apartment buildings. I love modernist architecture,
           &gt; new technologies, and sustainable practices. In my free time, I enjoy traveling to
           &gt; exotic places, playing the guitar, and reading science fiction books. How about you?
</code></pre></div>
<p dir="auto"><code>TinyWorld</code> enforces very little constraints on the possible interactions. Subclasses, however, are supposed to provide more strucutred environments.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Utilities</h3><a id="user-content-utilities" aria-label="Permalink: Utilities" href="#utilities"></a></p>
<p dir="auto">TinyTroupe provides a number of utilities and conveniences to help you create simulations and derive value from them. These include:</p>
<ul dir="auto">
<li><code>TinyPersonFactory</code>: helps you generate new <code>TinyPerson</code>s using LLMs.</li>
<li><code>TinyTool</code>: simulated tools that can be used by <code>TinyPerson</code>s.</li>
<li><code>TinyStory</code>: helps you create and manage the story told through simulations.</li>
<li><code>TinyPersonValidator</code>: helps you validate the behavior of your <code>TinyPerson</code>s.</li>
<li><code>ResultsExtractor</code> and <code>ResultsReducer</code>: extract and reduce the results of interactions between agents.</li>
<li>... and more ...</li>
</ul>
<p dir="auto">In general, elements that represent simulated entities or complementary mechanisms are prefixed with <code>Tiny</code>, while those that are more infrastructural are not. This is to emphasize the simulated nature of the elements that are part of the simulation itself.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Caching</h3><a id="user-content-caching" aria-label="Permalink: Caching" href="#caching"></a></p>
<p dir="auto">Calling LLM APIs can be expensive, thus caching strategies are important to help reduce that cost.
TinyTroupe comes with two such mechanisms: one for the simulation state, another for the LLM calls themselves.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Caching Simulation State</h4><a id="user-content-caching-simulation-state" aria-label="Permalink: Caching Simulation State" href="#caching-simulation-state"></a></p>
<p dir="auto">Imagine you have a scenario with 10 different steps, you've worked hard in 9 steps, and now you are
just tweaking the 10th step. To properly validate your modifications, you need to rerun the whole
simulation of course. However, what's the point in re-executing the first 9, and incur the LLM cost, when you are
already satisified with them and did not modify them? For situations like this, the module <code>tinytroupe.control</code>
provide useful simulation management methods:</p>
<ul dir="auto">
<li><code>control.begin("&lt;CACHE_FILE_NAME&gt;.cache.json")</code>: begins recording the state changes of a simulation, to be saved to
the specified file on disk.</li>
<li><code>control.checkpoint()</code>: saves the simulation state at this point.</li>
<li><code>control.end()</code>: terminates the simulation recording scope that had be started by <code>control.begin()</code>.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Caching LLM API Calls</h4><a id="user-content-caching-llm-api-calls" aria-label="Permalink: Caching LLM API Calls" href="#caching-llm-api-calls"></a></p>
<p dir="auto">This is enabled preferably in the <code>config.ini</code> file, and alternativelly via the <code>openai_utils.force_api_cache()</code>.</p>
<p dir="auto">LLM API caching, when enabled, works at a lower and simpler level than simulation state caching. Here,
what happens is a very straightforward: every LLM call is kept in a map from the input to the generated output;
when a new call comes and is identical to a previous one, the cached value is returned.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Config.ini</h3><a id="user-content-configini" aria-label="Permalink: Config.ini" href="#configini"></a></p>
<p dir="auto">The <code>config.ini</code> file contains various parameters that can be used to customize the behavior of the library, such as model parameters and logging level. Please pay special attention to <code>API_TYPE</code> parameter, which defines whether you are using the Azure OpenAI Service or the OpenAI API. We provide an example of a <code>config.ini</code> file, <a href="https://github.com/microsoft/TinyTroupe/blob/main/examples/config.ini">./examples/config.ini</a>, which you can use as a template for your own, or just modify to run the examples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit <a href="https://cla.opensource.microsoft.com/" rel="nofollow">https://cla.opensource.microsoft.com</a>.</p>
<p dir="auto">When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.</p>
<p dir="auto">This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow">Microsoft Open Source Code of Conduct</a>.
For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow">Code of Conduct FAQ</a> or
contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What and How to Contribute</h3><a id="user-content-what-and-how-to-contribute" aria-label="Permalink: What and How to Contribute" href="#what-and-how-to-contribute"></a></p>
<p dir="auto">We need all sorts of things, but we are looking mainly for new interesting use cases demonstrations, or even just domain-specific application ideas. If you are a domain expert in some area that could benefit from TinyTroupe, we'd love to hear from you.</p>
<p dir="auto">Beyond that, many other aspects can be improved, such as:</p>
<ul dir="auto">
<li>Memory mechanisms.</li>
<li>Data grounding mechanisms.</li>
<li>Reasoning mechanisms.</li>
<li>New environment types.</li>
<li>Interfacing with the external world.</li>
<li>... and more ...</li>
</ul>
<p dir="auto">Please note that anything that you contribute might be released as open-source (under MIT license).</p>
<p dir="auto">If you would like to make a contribution, please try to follow these general guidelines:</p>
<ul dir="auto">
<li><strong>Tiny naming convention</strong>: If you are implementing a experimenter-facing simulated element (e.g., an agent or environment type) or closely related (e.g., agent factories, or content enrichers), and it sounds good, call your new <em>XYZ</em> as <em>TinyXYZ</em> :-) On the other hand, auxiliary and infrastructural mechanisms should not start with the "Tiny" prefix. The idea is to emphasize the simulated nature of the elements that are part of the simulation itself.</li>
<li><strong>Tests:</strong> If you are writing some new mechanism, please also create at least a unit test <code>tests/unit/</code>, and if you can a functional scenario test (<code>tests/scenarios/</code>).</li>
<li><strong>Demonstrations:</strong> If you'd like to demonstrate a new scenario, please design it preferably as a new Jupyter notebook within <code>examples/</code>.</li>
<li><strong>Microsoft:</strong> If you are implementing anything that is Microsoft-specific and non-confidential, please put it under a <code>.../microsoft/</code> folder.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">TinyTroupe started as an internal Microsoft hackathon project, and expanded over time. The TinyTroupe core team currently consists of:</p>
<ul dir="auto">
<li>Paulo Salem (TinyTroupe's creator and current lead)</li>
<li>Christopher Olsen (Engineering/Science)</li>
<li>Paulo Freire (Engineering/Science)</li>
<li>Yi Ding (Product Management)</li>
<li>Prerit Saxena (Engineering/Science)</li>
</ul>
<p dir="auto">Current advisors:</p>
<ul dir="auto">
<li>Robert Sim (Engineering/Science)</li>
</ul>
<p dir="auto">Other special contributions were made by:</p>
<ul dir="auto">
<li>Nilo Garcia Silveira: initial agent validation ideas and related implementation; general initial feedback and insights; name suggestions.</li>
<li>Olnei Fonseca: initial agent validation ideas; general initial feedback and insights; naming suggestions.</li>
<li>Robert Sim: synthetic data generation scenarios expertise and implementation.</li>
<li>Carlos Costa: synthetic data generation scenarios expertise and implementation.</li>
<li>Bryant Key: advertising scenario domain expertise and insights.</li>
<li>Barbara da Silva: implementation related to agent memory management.</li>
</ul>
<p dir="auto">... are you missing here? Please remind us!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citing TinyTroupe</h2><a id="user-content-citing-tinytroupe" aria-label="Permalink: Citing TinyTroupe" href="#citing-tinytroupe"></a></p>
<p dir="auto">We are working on an introductory paper that will be the official academic citation for TinyTroupe. In the meantime, please just cite this repository including the core team members as authors. For instance:</p>
<blockquote>
<p dir="auto">Paulo Salem, Christopher Olsen, Paulo Freire, Yi Ding, Prerit Saxena (2024). <strong>TinyTroupe: LLM-powered multiagent persona simulation for imagination enhancement and business insights.</strong> [Computer software]. GitHub repository. <a href="https://github.com/microsoft/tinytroupe">https://github.com/microsoft/tinytroupe</a></p>
</blockquote>
<p dir="auto">Or as bibtex:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{tinytroupe,
  author = {Paulo Salem and Christopher Olsen and Paulo Freire and Yi Ding and Prerit Saxena},
  title = {TinyTroupe: LLM-powered multiagent persona simulation for imagination enhancement and business insights},
  year = {2024},
  howpublished = {\url{https://github.com/microsoft/tinytroupe}},
  note = {GitHub repository}
  }
"><pre><span>@misc</span>{<span>tinytroupe</span>,
  <span>author</span> = <span><span>{</span>Paulo Salem and Christopher Olsen and Paulo Freire and Yi Ding and Prerit Saxena<span>}</span></span>,
  <span>title</span> = <span><span>{</span>TinyTroupe: LLM-powered multiagent persona simulation for imagination enhancement and business insights<span>}</span></span>,
  <span>year</span> = <span><span>{</span>2024<span>}</span></span>,
  <span>howpublished</span> = <span><span>{</span>\url{https://github.com/microsoft/tinytroupe}<span>}</span></span>,
  <span>note</span> = <span><span>{</span>GitHub repository<span>}</span></span>
  }
</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Legal Disclaimer</h2><a id="user-content-legal-disclaimer" aria-label="Permalink: Legal Disclaimer" href="#legal-disclaimer"></a></p>
<p dir="auto">TinyTroupe is for research and simulation only. TinyTroupe is a research and experimental technology, which relies on Artificial Intelligence (AI) models to generate text  content. The AI system output may include unrealistic, inappropriate, harmful or inaccurate results, including factual errors. You are responsible for reviewing the generated content (and adapting it if necessary) before using it, as you are fully responsible for determining its accuracy and fit for purpose. We advise using TinyTroupe’s outputs for insight generation and not for direct decision-making. Generated outputs do not reflect the opinions of Microsoft. You are fully responsible for any use you make of the generated outputs. For more information regarding the responsible use of this technology, see the <a href="https://github.com/microsoft/TinyTroupe/blob/main/RESPONSIBLE_AI_FAQ.md">RESPONSIBLE_AI_FAQ.md</a>.</p>
<p dir="auto"><strong>PROHIBITED USES</strong>:
TinyTroupe  is not intended to simulate sensitive (e.g. violent or sexual) situations. Moreover, outputs must not be used to deliberately deceive, mislead or harm people in any way. You are fully responsible for any use you make and must comply with all applicable laws and regulations.”</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
<a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general" rel="nofollow">Microsoft's Trademark &amp; Brand Guidelines</a>.
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brian Kernighan Reflects on Unix: A History and a Memoir [video] (137 pts)]]></title>
            <link>https://www.youtube.com/watch?v=VloimYuCxBs</link>
            <guid>42108077</guid>
            <pubDate>Mon, 11 Nov 2024 16:00:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=VloimYuCxBs">https://www.youtube.com/watch?v=VloimYuCxBs</a>, See on <a href="https://news.ycombinator.com/item?id=42108077">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Inside the $20M business of gutting failed Bay Area tech companies (179 pts)]]></title>
            <link>https://www.sfgate.com/bayarea/article/better-source-cheap-bay-area-office-furniture-19897542.php</link>
            <guid>42107870</guid>
            <pubDate>Mon, 11 Nov 2024 15:35:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/bayarea/article/better-source-cheap-bay-area-office-furniture-19897542.php">https://www.sfgate.com/bayarea/article/better-source-cheap-bay-area-office-furniture-19897542.php</a>, See on <a href="https://news.ycombinator.com/item?id=42107870">Hacker News</a></p>
Couldn't get https://www.sfgate.com/bayarea/article/better-source-cheap-bay-area-office-furniture-19897542.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[AlphaFold 3 Code (132 pts)]]></title>
            <link>https://github.com/google-deepmind/alphafold3</link>
            <guid>42106906</guid>
            <pubDate>Mon, 11 Nov 2024 13:19:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google-deepmind/alphafold3">https://github.com/google-deepmind/alphafold3</a>, See on <a href="https://news.ycombinator.com/item?id=42106906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/google-deepmind/alphafold3/blob/main/docs/header.jpg"><img src="https://github.com/google-deepmind/alphafold3/raw/main/docs/header.jpg" alt="header"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">AlphaFold 3</h2><a id="user-content-alphafold-3" aria-label="Permalink: AlphaFold 3" href="#alphafold-3"></a></p>
<p dir="auto">This package provides an implementation of the inference pipeline of AlphaFold
3. See below for how to access the model parameters. You may only use AlphaFold
3 model parameters if received directly from Google. Use is subject to these
<a href="https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md">terms of use</a>.</p>
<p dir="auto">Any publication that discloses findings arising from using this source code, the
model parameters or outputs produced by those should <a href="#citing-this-work">cite</a>
the
<a href="https://doi.org/10.1038/s41586-024-07487-w" rel="nofollow">Accurate structure prediction of biomolecular interactions with AlphaFold 3</a>
paper.</p>
<p dir="auto">Please also refer to the Supplementary Information for a detailed description of
the method.</p>
<p dir="auto">AlphaFold 3 is also available at
<a href="https://alphafoldserver.com/" rel="nofollow">alphafoldserver.com</a> for non-commercial use,
though with a more limited set of ligands and covalent modifications.</p>
<p dir="auto">If you have any questions, please contact the AlphaFold team at
<a href="mailto:alphafold@google.com">alphafold@google.com</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Obtaining Model Parameters</h2><a id="user-content-obtaining-model-parameters" aria-label="Permalink: Obtaining Model Parameters" href="#obtaining-model-parameters"></a></p>
<p dir="auto">This repository contains all necessary code for AlphaFold 3 inference. To
request access to the AlphaFold 3 model parameters, please complete
<a href="https://forms.gle/svvpY4u2jsHEwWYS6" rel="nofollow">this form</a>. Access will be granted at
Google DeepMind’s sole discretion. We will aim to respond to requests within 2–3
business days. You may only use AlphaFold 3 model parameters if received
directly from Google. Use is subject to these
<a href="https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md">terms of use</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation and Running Your First Prediction</h2><a id="user-content-installation-and-running-your-first-prediction" aria-label="Permalink: Installation and Running Your First Prediction" href="#installation-and-running-your-first-prediction"></a></p>
<p dir="auto">See the <a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/installation.md">installation documentation</a>.</p>
<p dir="auto">Once you have installed AlphaFold 3, you can test your setup using e.g. the
following input JSON file named <code>alphafold_input.json</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;name&quot;: &quot;2PV7&quot;,
  &quot;sequences&quot;: [
    {
      &quot;protein&quot;: {
        &quot;id&quot;: [&quot;A&quot;, &quot;B&quot;],
        &quot;sequence&quot;: &quot;GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG&quot;
      }
    },
  ],
  &quot;modelSeeds&quot;: [1],
  &quot;dialect&quot;: &quot;alphafold3&quot;,
  &quot;version&quot;: 1
}"><pre>{
  <span>"name"</span>: <span><span>"</span>2PV7<span>"</span></span>,
  <span>"sequences"</span>: [
    {
      <span>"protein"</span>: {
        <span>"id"</span>: [<span><span>"</span>A<span>"</span></span>, <span><span>"</span>B<span>"</span></span>],
        <span>"sequence"</span>: <span><span>"</span>GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG<span>"</span></span>
      }
    },
  ],
  <span>"modelSeeds"</span>: [<span>1</span>],
  <span>"dialect"</span>: <span><span>"</span>alphafold3<span>"</span></span>,
  <span>"version"</span>: <span>1</span>
}</pre></div>
<p dir="auto">You can then run AlphaFold 3 using the following command:</p>
<div data-snippet-clipboard-copy-content="docker run -it \
    --volume $HOME/af_input:/root/af_input \
    --volume $HOME/af_output:/root/af_output \
    --volume <MODEL_PARAMETERS_DIR>:/root/models \
    --volume <DATABASES_DIR>:/root/public_databases \
    --gpus all \
    alphafold3 \
python run_alphafold.py \
    --json_path=/root/af_input/fold_input.json \
    --model_dir=/root/models \
    --output_dir=/root/af_output"><pre><code>docker run -it \
    --volume $HOME/af_input:/root/af_input \
    --volume $HOME/af_output:/root/af_output \
    --volume &lt;MODEL_PARAMETERS_DIR&gt;:/root/models \
    --volume &lt;DATABASES_DIR&gt;:/root/public_databases \
    --gpus all \
    alphafold3 \
python run_alphafold.py \
    --json_path=/root/af_input/fold_input.json \
    --model_dir=/root/models \
    --output_dir=/root/af_output
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">AlphaFold 3 Input</h2><a id="user-content-alphafold-3-input" aria-label="Permalink: AlphaFold 3 Input" href="#alphafold-3-input"></a></p>
<p dir="auto">See the <a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/input.md">input documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">AlphaFold 3 Output</h2><a id="user-content-alphafold-3-output" aria-label="Permalink: AlphaFold 3 Output" href="#alphafold-3-output"></a></p>
<p dir="auto">See the <a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/output.md">output documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance</h2><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">See the <a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md">performance documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Known Issues</h2><a id="user-content-known-issues" aria-label="Permalink: Known Issues" href="#known-issues"></a></p>
<p dir="auto">Known issues are documented in the
<a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/known_issues.md">known issues documentation</a>.</p>
<p dir="auto">Please
<a href="https://github.com/google-deepmind/alphafold3/issues/new/choose">create an issue</a>
if it is not already listed in <a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/known_issues.md">Known Issues</a> or in the
<a href="https://github.com/google-deepmind/alphafold3/issues">issues tracker</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citing This Work</h2><a id="user-content-citing-this-work" aria-label="Permalink: Citing This Work" href="#citing-this-work"></a></p>
<p dir="auto">Any publication that discloses findings arising from using this source code, the
model parameters or outputs produced by those should cite:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{Abramson2024,
  author  = {Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M.},
  journal = {Nature},
  title   = {Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  year    = {2024},
  volume  = {630},
  number  = {8016},
  pages   = {493–-500},
  doi     = {10.1038/s41586-024-07487-w}
}"><pre><span>@article</span>{<span>Abramson2024</span>,
  <span>author</span>  = <span><span>{</span>Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M.<span>}</span></span>,
  <span>journal</span> = <span><span>{</span>Nature<span>}</span></span>,
  <span>title</span>   = <span><span>{</span>Accurate structure prediction of biomolecular interactions with AlphaFold 3<span>}</span></span>,
  <span>year</span>    = <span><span>{</span>2024<span>}</span></span>,
  <span>volume</span>  = <span><span>{</span>630<span>}</span></span>,
  <span>number</span>  = <span><span>{</span>8016<span>}</span></span>,
  <span>pages</span>   = <span><span>{</span>493–-500<span>}</span></span>,
  <span>doi</span>     = <span><span>{</span>10.1038/s41586-024-07487-w<span>}</span></span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">AlphaFold 3's release was made possible by the invaluable contributions of the
following people:</p>
<p dir="auto">Andrew&nbsp;Cowie, Bella&nbsp;Hansen, Charlie&nbsp;Beattie, Chris&nbsp;Jones, Grace&nbsp;Margand,
Jacob&nbsp;Kelly, James&nbsp;Spencer, Josh&nbsp;Abramson, Kathryn&nbsp;Tunyasuvunakool, Kuba&nbsp;Perlin,
Lindsay&nbsp;Willmore, Max&nbsp;Bileschi, Molly&nbsp;Beck, Oleg&nbsp;Kovalevskiy,
Sebastian&nbsp;Bodenstein, Sukhdeep&nbsp;Singh, Tim&nbsp;Green, Toby&nbsp;Sargeant, Uchechi&nbsp;Okereke,
Yotam&nbsp;Doron, and Augustin&nbsp;Žídek (engineering lead).</p>
<p dir="auto">We also extend our gratitude to our collaborators at Google and Isomorphic Labs.</p>
<p dir="auto">AlphaFold 3 uses the following separate libraries and packages:</p>
<ul dir="auto">
<li><a href="https://github.com/abseil/abseil-cpp">abseil-cpp</a> and
<a href="https://github.com/abseil/abseil-py">abseil-py</a></li>
<li><a href="https://github.com/deepmind/chex">Chex</a></li>
<li><a href="https://www.docker.com/" rel="nofollow">Docker</a></li>
<li><a href="https://github.com/PDB-REDO/dssp">DSSP</a></li>
<li><a href="https://github.com/EddyRivasLab/hmmer">HMMER Suite</a></li>
<li><a href="https://github.com/deepmind/dm-haiku">Haiku</a></li>
<li><a href="https://github.com/google/jax/">JAX</a></li>
<li><a href="https://github.com/jax-ml/jax-triton">jax-triton</a></li>
<li><a href="https://github.com/patrick-kidger/jaxtyping">jaxtyping</a></li>
<li><a href="https://github.com/pdb-redo/libcifpp">libcifpp</a></li>
<li><a href="https://github.com/numpy/numpy">NumPy</a></li>
<li><a href="https://github.com/pybind/pybind11">pybind11</a> and
<a href="https://github.com/pybind/pybind11_abseil">pybind11_abseil</a></li>
<li><a href="https://github.com/rdkit/rdkit">RDKit</a></li>
<li><a href="https://github.com/deepmind/tree">Tree</a></li>
<li><a href="https://github.com/triton-lang/triton">Triton</a></li>
<li><a href="https://github.com/tqdm/tqdm">tqdm</a></li>
</ul>
<p dir="auto">We thank all their contributors and maintainers!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get in Touch</h2><a id="user-content-get-in-touch" aria-label="Permalink: Get in Touch" href="#get-in-touch"></a></p>
<p dir="auto">If you have any questions not covered in this overview, please contact the
AlphaFold team at <a href="mailto:alphafold@google.com">alphafold@google.com</a>.</p>
<p dir="auto">We would love to hear your feedback and understand how AlphaFold 3 has been
useful in your research. Share your stories with us at
<a href="mailto:alphafold@google.com">alphafold@google.com</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licence and Disclaimer</h2><a id="user-content-licence-and-disclaimer" aria-label="Permalink: Licence and Disclaimer" href="#licence-and-disclaimer"></a></p>
<p dir="auto">This is not an officially supported Google product.</p>
<p dir="auto">Copyright 2024 DeepMind Technologies Limited.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AlphaFold 3 Source Code and Model Parameters</h3><a id="user-content-alphafold-3-source-code-and-model-parameters" aria-label="Permalink: AlphaFold 3 Source Code and Model Parameters" href="#alphafold-3-source-code-and-model-parameters"></a></p>
<p dir="auto">The AlphaFold 3 source code is licensed under the Creative Commons
Attribution-Non-Commercial ShareAlike International License, Version 4.0
(CC-BY-NC-SA 4.0) (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
<a href="https://github.com/google-deepmind/alphafold3/blob/main/LICENSE">https://github.com/google-deepmind/alphafold3/blob/main/LICENSE</a>.</p>
<p dir="auto">The AlphaFold 3 model parameters are made available under the
<a href="https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md">AlphaFold 3 Model Parameters Terms of Use</a>
(the "Terms"); you may not use these except in compliance with the Terms. You
may obtain a copy of the Terms at
<a href="https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md">https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md</a>.</p>
<p dir="auto">Unless required by applicable law, AlphaFold 3 and its output are distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
or implied. You are solely responsible for determining the appropriateness of
using AlphaFold 3, or using or distributing its source code or output, and
assume any and all risks associated with such use or distribution and your
exercise of rights and obligations under the relevant terms. Output are
predictions with varying levels of confidence and should be interpreted
carefully. Use discretion before relying on, publishing, downloading or
otherwise using the AlphaFold 3 Assets.</p>
<p dir="auto">AlphaFold 3 and its output are for theoretical modeling only. They are not
intended, validated, or approved for clinical use. You should not use the
AlphaFold 3 or its output for clinical purposes or rely on them for medical or
other professional advice. Any content regarding those topics is provided for
informational purposes only and is not a substitute for advice from a qualified
professional. See the relevant terms for the specific language governing
permissions and limitations under the terms.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Third-party Software</h3><a id="user-content-third-party-software" aria-label="Permalink: Third-party Software" href="#third-party-software"></a></p>
<p dir="auto">Use of the third-party software, libraries or code referred to in the
<a href="#acknowledgements">Acknowledgements</a> section above may be governed by separate
terms and conditions or license provisions. Your use of the third-party
software, libraries or code is subject to any such terms and you should check
that you can comply with any applicable restrictions or terms and conditions
before use.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mirrored and Reference Databases</h3><a id="user-content-mirrored-and-reference-databases" aria-label="Permalink: Mirrored and Reference Databases" href="#mirrored-and-reference-databases"></a></p>
<p dir="auto">The following databases have been: (1) mirrored by Google DeepMind; and (2) in
part, included with the inference code package for testing purposes, and are
available with reference to the following:</p>
<ul dir="auto">
<li><a href="https://bfd.mmseqs.com/" rel="nofollow">BFD</a> (modified), by Steinegger M. and Söding J.,
modified by Google DeepMind, available under a
<a href="https://creativecommons.org/licenses/by/4.0/deed.en" rel="nofollow">Creative Commons Attribution 4.0 International License</a>.
See the Methods section of the
<a href="https://www.nature.com/articles/s41586-021-03828-1" rel="nofollow">AlphaFold proteome paper</a>
for details.</li>
<li><a href="https://wwpdb.org/" rel="nofollow">PDB</a> (unmodified), by H.M. Berman et al., available free
of all copyright restrictions and made fully and freely available for both
non-commercial and commercial use under
<a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 1.0 Universal (CC0 1.0) Public Domain Dedication</a>.</li>
<li><a href="https://ftp.ebi.ac.uk/pub/databases/metagenomics/peptide_database/2022_05/README.txt" rel="nofollow">MGnify: v2022_05</a>
(unmodified), by Mitchell AL et al., available free of all copyright
restrictions and made fully and freely available for both non-commercial and
commercial use under
<a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 1.0 Universal (CC0 1.0) Public Domain Dedication</a>.</li>
<li><a href="https://www.uniprot.org/" rel="nofollow">UniProt: 2021_04</a> (unmodified), by The UniProt
Consortium, available under a
<a href="https://creativecommons.org/licenses/by/4.0/deed.en" rel="nofollow">Creative Commons Attribution 4.0 International License</a>.</li>
<li><a href="https://www.uniprot.org/" rel="nofollow">UniRef90: 2022_05</a> (unmodified) by The UniProt
Consortium, available under a
<a href="https://creativecommons.org/licenses/by/4.0/deed.en" rel="nofollow">Creative Commons Attribution 4.0 International License</a>.</li>
<li><a href="https://www.ncbi.nlm.nih.gov/nucleotide/" rel="nofollow">NT: 2023_02_23</a> (modified) See
the Supplementary Information of the
<a href="https://nature.com/articles/s41586-024-07487-w" rel="nofollow">AlphaFold 3 paper</a> for
details.</li>
<li><a href="https://rfam.org/" rel="nofollow">RFam: 14_4</a> (modified), by I. Kalvari et al., available
free of all copyright restrictions and made fully and freely available for
both non-commercial and commercial use under
<a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 1.0 Universal (CC0 1.0) Public Domain Dedication</a>.
See the Supplementary Information of the
<a href="https://nature.com/articles/s41586-024-07487-w" rel="nofollow">AlphaFold 3 paper</a> for
details.</li>
<li><a href="https://rnacentral.org/" rel="nofollow">RNACentral: 21_0</a> (modified), by The RNAcentral
Consortium available free of all copyright restrictions and made fully and
freely available for both non-commercial and commercial use under
<a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 1.0 Universal (CC0 1.0) Public Domain Dedication</a>.
See the Supplementary Information of the
<a href="https://nature.com/articles/s41586-024-07487-w" rel="nofollow">AlphaFold 3 paper</a> for
details.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Silurian Hypothesis (148 pts)]]></title>
            <link>https://pacificklaus.com/the-silurian-hypothesis-it-was-the-cephalopods/</link>
            <guid>42106700</guid>
            <pubDate>Mon, 11 Nov 2024 12:38:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pacificklaus.com/the-silurian-hypothesis-it-was-the-cephalopods/">https://pacificklaus.com/the-silurian-hypothesis-it-was-the-cephalopods/</a>, See on <a href="https://news.ycombinator.com/item?id=42106700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p><strong>Text, footage and photographs by Dr. Klaus M. Stiefel</strong></p>
<p>A long time ago, as an enthusiastic young, naive graduate student I went to a conference, which was just a few years away from its inevitable transition from a fun get-together of math nerds who loved to exchange ideas and crack jokes, into an academic business meeting where lab leaders advertised their near-completed projects to the competition.</p>
<p>Back then the conference organizers gave away funny, tongue-in-cheek awards (this would be inconceivable by now – humor!), and one of these awards was for the “most interesting hypothesis most likely to be false”. I thought this was a great award, honoring science which was daring, and which had just missed the mark by a bit. The winner that year was a sympathetic Italian scientist who had, with great enthusiasm and outstanding rhetorical fanfare, presented fancy computer-simulations of language comprehension in a brain region known to be unrelated to language processing. The researcher had missed the actual award ceremony, and I was by chance having a coffee near him and his students when someone broke the news of his newly won award to him. The otherwise so cheerful face of the bearded, portly <em>professore</em> dropped upon hearing about the “honor”. He was visibly distraught by his win! I assume that at home, where he ruled over his lab with charisma and reputation, none of his loyal students had dared to tell him that, based on all that’s known about the human brain, language processing is not happening in the Hippocampus. I remember the young me thinking that this is what scientific progress looks like: hypothesis falsification.</p>
<p><strong>The Silurian Hypothesis</strong></p>
<p>A hypothesis called “The Silurian hypothesis” wins the title of “most interesting hypothesis most likely to be false” for all of science. In brief, the hypothesis postulates that previously a species different from ours had achieved high intelligence and technological civilization on this planet. The Silurian hypothesis (named after “Silurian” aliens in the brainy British TV series “Doctor Who”) was initially proposed by two astronomers, Gavin A. Schmidt and Adam Frank, as a thought experiment, to see if it would even be feasible to detect the traces of such a hypothetical civilization which had existed many millions of years ago. Would there still be detectable changes in the sedimentation patterns if someone (not human) had built cities and military bases a hundred million years ago? Would ancient trash dumps be conserved somewhere, somehow? Would there be changes in the patterns of radioisotopes in the rocks as a result of an ancient nuclear war?</p>
<p>So, in their original paper, Schmidt &amp; Frank didn’t actually voice belief in an ancient civilization, but pondered the question if and how it would be detectable. They conclude that no ruins of ancient football stadiums, highways or housing projects would survive geological time. In contrast, unusual episodes of global warming and the presence of certain artificial radioisotopes (Plutonium-244 and Curium-247) would give an ancient civilization away. Mass extinctions could be a sign of an ancient smart, technological, fast-expanding species.</p>
<p>Actual artefacts might not persist on Earth with its plate tectonics and active atmosphere, but spacefaring ancients might have built big bases on the Moon or on Mars; there, they would have persisted much longer.</p>
<p><a title="Cuttlefish" href="https://www.flickr.com/photos/pacificklaus/52976050916/" data-flickr-embed="true"><img fetchpriority="high" decoding="async" src="https://live.staticflickr.com/65535/52976050916_829724744e_z.jpg" alt="Cuttlefish" width="640" height="480"></a></p>
<p><em>Can you see me?</em></p>
<p><strong>Geological Thought Experiment versus Actual Ancient Civilizations</strong></p>
<p>But besides being an interesting nudge for geological thinking, the question if such an ancient civilization <strong><em>actually happened</em></strong>, and who would have been the species to sustain it is <strong><em>extremely</em></strong> intriguing. The proposition that this was the case, is what I consider the actual most interesting hypothesis most likely to be false, ever, by a wide margin. While Schmidt &amp; Frank didn’t consider this question, there is some really well-written science fiction discussing the question, but it hasn’t been tackled in a biologically well-informed way. This is what I’ll try to do here.</p>
<p>Probably the esteemed reader has noticed by now that I am no true believer in the Silurian hypothesis, but I like to entertain it; and while much has been written about hypothetical humanoid descendants of carnivorous dinosaurs as the bearers of the ancient civilization, I believe that it’s the cephalopods – the octopi, cuttlefish and squid- who are the most likely candidates to have reached at least some level of civilization.</p>
<p>Two somewhat different levels of ancient cephalopod civilization are worth considering. The levels are quite distinct in how realistic (or: how more or less extremely unrealistic) they are.</p>
<p>The first level is the Neolithic stage, reached by a species of cephalopod eons ago. Reaching “only” the Neolithic stage could be described as a “Silurian hypothesis light”; it’s not highly significant achievement for a species, and even such a species can significantly turn over the planet’s fauna. Even our hunter-gathering (Paleolithic) ancestors hunted a number of large animal species to extinction (you don’t have to kill every last mammoth or giant bird to do that), and our farming ancestors (before the advent of even the simple most metal tools) caused massive modifications of the fauna and florae of extensive landscapes. Some of these faunal changes might be detectable millions of years into the future.</p>
<p>Reaching the industrial or space age is much harder than reaching a stage of organized, wide-spread farming. Many of the ways of how Schmidt &amp; Frank propose an ancient civilization which was burning fossil fuels, building nuclear reactors and spaceships. This level is nothing which can easily imagined following from what’s known about cephalopod behavior, which I will rave about below. This second level is the science fiction of the science fiction; it’s in the heavyweight division of the make-believe, and in this essay, I don’t want to go there.</p>
<p><strong>Cephalopods</strong></p>
<p>I came to the conclusion that only the cephalopods are viable candidates for purveyors for an ancient civilization after plenty of reading of the scholarly literature on cephalopods<a href="#_ftn1" name="_ftnref1">[1]</a>, and also via my personal experience – I scuba dive a lot, and I do some in one of the best diving locations in the world, the central Philippines. I divide humanity into those who have seen a living cephalopod with their own eyes, and those who haven’t. Knowing about a squid from anatomical drawings in a book or from squid rings as a starter is like knowing sex only from cheap erotic novels.</p>
<p>As a scuba diver, I observe corals, sponges, sea stars, and most fishes. Squid, cuttlefish and octopi, I interact with. There is a definite two-way component in my encounters with these animals. I look at them, and then I come closer to them. They look back at me, clearly with a theory of my mind, and without any doubt gauging what I intend to do in the next seconds, and then they react: sometimes they decide to flee or hide, and in other cases they keep doing what they were up to before my arrival, or even inspect me in return. Octopi seem to be particularly curious animals.</p>
<p><iframe title="Squid &amp; Octopi Sleep States and Genetic Magic" width="800" height="450" src="https://www.youtube.com/embed/NaUvKsc81D4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>These encounters are more like those of tourists from far-flung countries interacting with Austrians in the touristy spots of my home country. The tourists might not completely understand what the Austrians are thinking, when they perform their alpine folk dances, but it’s an encounter eye-to-eye, and neither tourists nor folk dancers doubt that the other side is sentient and conscious.</p>
<p>Across a vast species barrier, the situation feels very similar when interacting with a cephalopod.</p>
<p><a title="Flamboyant" href="https://www.flickr.com/photos/pacificklaus/50513857428/" data-flickr-embed="true"><img decoding="async" src="https://live.staticflickr.com/65535/50513857428_3dc1cc4b5d_z.jpg" alt="Flamboyant" width="640" height="479"></a></p>
<p><em>A flamboyant cuttlefish, a small cephalopod found in the tropics and subtropics of the Pacific Ocean. This animal is particularly impressive with its fast skin color and pattern changes.</em></p>
<p>The scholarly literature is well in sync with my personal observations of <em>cephalopod behavior</em> being outstandingly complex (there is a great monograph with that title by Roger Hanlon and John Messenger). Cephalopods have been called “honorary vertebrates” for their complex nervous systems and sophisticated behaviors.</p>
<p>Cephalopods are among the few animals which mate in different positions (some squid do), and in some species smaller males pretend to be females, and then sneak by large, territory-owning dominant male. These “sneaker males” are often surprisingly successful in siring offspring, courtesy of their Machiavellian cleverness and deceptive behavior.</p>
<p>Cuttlefish hunt by seemingly hypnotizing crabs by generating highly psychedelic moving stripe patterns on their bodies; other cuttlefish camouflage themselves as harmless, herbivorous parrotfish to sneak up on their prey. And the master of behavioral camouflage, the mimic octopus, pretends to be alternatively a flounder (spiny), a sea snake or a lionfish (both venomous) to deter would-be predators. These animals are clever beyond belief, for animals grouped by biological taxonomists with such passive or slow creatures as clams and garden slugs.</p>
<p><a title="Tool Using Octopus" href="https://www.flickr.com/photos/pacificklaus/9005989387/" data-flickr-embed="true"><img loading="lazy" decoding="async" src="https://live.staticflickr.com/2887/9005989387_0113270167_z.jpg" alt="Tool Using Octopus" width="640" height="427"></a></p>
<p><em>An octopus using the discarded lid of a can as a shield to cover the entrance of its lair. Seen near Sydney, Australia.</em></p>
<p>There is even an octopus named after its tool use, the coconut octopus (<em>Amphioctopus marginatus</em>). And finally, there is a very sophisticated communication system between cephalopods, based on color and pattern changes in their skins. A large array of tiny, circular muscles contracts or relaxes, and hence shows the skin color above or below the skin musculature. This allows many species of cephalopods to change their color, and the pattern on their skins within seconds. The skin color changes are used for a variety of purposes, including camouflage and communication with conspecifics. Many species have a multitude of different patterns which they can project onto their backs, and which signal messages like “I am angry” or “I am ready to mate”.</p>
<p><a title="Cuttle Fight 8" href="https://www.flickr.com/photos/pacificklaus/10797140136/in/photolist-hs7aAy-dtVggH-93rskK-auXYxJ-2oQZ7pL-eiTqw9-eiMGhH-6X77XD-8KZULE-qCA7TQ-2hBtDhA-qpXC8u-oLkURf-kdmxG6-bTBzJe-Keo9qu-p9igoC-6X7eMX-fHXQzU-cAayeu-2oAVYYj-du1QyU-dFmJZU-dQsPZr-7Q9Z78-bX7d3A-eiTrbo-dvZnhv-dtVfit-6Xb88W-6X7dsk-hs8eoP-7QCuPn-7EpcmE-dtVfMk-d7sufC-do6cg9-dwTwrn-dQyqUm-fHYer7-7E7u2n-eiMFiR-eiMH5i-hs4PBD-7EbgUu-2nVQEzv-9bH78e-e3LzTa-rtXe5j-94rYVz" data-flickr-embed="true"><img loading="lazy" decoding="async" src="https://live.staticflickr.com/3706/10797140136_95633567a6_z.jpg" alt="Cuttle Fight 8" width="640" height="427"></a></p>
<p><em>Two male cuttlefish fight over a female (white color, on the right). These are three animals of the same species, the different patterns on their backs are instances of communication. The tiger-pattern says “aggression”.</em></p>
<p>With all of these complex behaviors in place, couldn’t it all have come together sometime, just like it did with humans fifteen thousand years ago, when ecological conditions and human ingenuity came together to spawn the Neolithic revolution. We moved from being very smart creatures who were hunting and gathering in smallish tribal groups to beings involved in organized farming, organized in much larger and more complex groups. I don’t think that taking this step is completely out of question for a particularly large-brained ancient squid. Since almost all cephalopods are carnivores, they would have been some kind of pastoralists, raising snails or clams for their consumption. This level of technological achievement is not likely, and certainly not supported by any actual evidence; however, it’s mildly realistic. The step from an octopus bringing along a coconut shell for protection to an octopus picking up snails and placing them near his lair for farming is at least feasible. The same octopus using stone tools to smash these snails is conceivable. Cephalopods living in structured societies? Squids already live in schools with strict hierarchies, with the bigger animals frequently cannibalizing the smaller ones. Imagine a time-traveling biologist, visiting the proto-human Lucy three million years ago, and the cephalopods of the Jurassic. Whom would she put her bet on to produce a civilization? The primate or the cephalopod? I am not convinced that she’s go with our ancestors.</p>
<p><iframe loading="lazy" title="Cephalopod Human Friendship" width="800" height="450" src="https://www.youtube.com/embed/Hs6P62rkhnA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>In contrast, the next level, that of industrialized technology, chemistry, nuclear physics and space travel seems much more unrealistic to achieve by any squid or octopus; science fiction is rich in space-faring cephalopods or cephalopod-inspired aliens, most notably Admiral Gial Ackbar of the original Star Wars movies. However, this is a level which came late, and which does not look inevitable in hindsight, by any means, in human history. Who would have guessed when looking at European warfare in the 1066 (Battle of Hastings: large axes! A brawl with home-improvement equipment) that less than a thousand years later the same people would kill each other using satellite-guided missiles?</p>
<p>A factor which makes reaching this level even more unlikely is that experimental chemistry and physics would be harder to pull off underwater. Air is an excellent insulator of electricity, and all the hours I spent in chemistry labs as an undergraduate makes me doubt that you can pull of a successful chemical synthesis underwater. Reagents would inevitably mix with seawater; this might be a narrow-minded terrestrial-centric view of chemistry, but I suspect that more fundamental physics is at play here, making it easier to combine liquid solutions when you live in the atmosphere.</p>
<p>Hence, octopus Neolithic: <strong><em>maaaaybe</em></strong>. The initial conditions are present in squid and octopi. No proof that it ever happened, but the idea does not smell like looniness, at least to some biologists (well, me). Squid space travel: almost certainly absolutely <strong><em>no</em></strong>.</p>
<p>So why are we not seeing octopus or squid societies today? Fish would eat them. Anyone who observes cephalopods underwater will notice a few striking aspects of their ecology: there are almost always fewer of them around than there are fishes. During an hour’s worth of diving on an average southeast Asian tropical coral reef, you will see hundreds to thousands of fish, but only an octopus or two, or a school of a few dozens of squid – and maybe not even that. If you don’t see an octopus, it might not be there, or it might be so well hidden to escape the eyes of hungry predatory fishes. Somehow, in most habitats, fishes massively win out against cephalopods, with many more individual fishes and many more fish species present.</p>
<p>Consequentially, to understand then when an ancient cephalopod civilization could have happened, we have to look at the evolution of cephalopods, and of that of fishes, and see how they overlap:</p>
<p><strong>So, When Do You Say Did That Happen?</strong></p>
<p>The story of cephalopod evolution is an absolutely fascinating chapter in the development of Planet Earth’s fauna. It’s also murky, and some of the fossils supposedly representing the earliest cephalopods are not easy to interpret, even by expert paleontologists who interpret ancient fossils all day.</p>
<p>Sometime in the late Cambrian, the first geological epoch with diverse animals with complex bodies, the Nautiluses evolved, primitive cephalopods with less well-developed nervous systems and larger numbers of simpler tentacles instead of the eight or ten sophisticated arms of modern octopi or squid. A few species of <em>Nautilus</em> still exist today as “living fossils”, living in deep water where they scavenge.</p>
<p>From these still somewhat primitive animals evolved the giant shelled Ammonites, and the modern cephalopods (the “Coleoids”), which include the cuttlefish, octopi, squid, and some animals closely related to squid, the belemnites, which we will encounter again. These are the animals with fast propulsion via contraction of a water-filled body cavity, fine motor control of their arms and hunting tentacles, keen senses, good memory, skin-pattern=based communication, social lives and sophisticated mating rituals.</p>
<p><a title="Nautilus" href="https://www.flickr.com/photos/pacificklaus/3799251083/in/photolist-6MJ9Z2-2oHj7hd-2jZgpoE-2oAe6M2-2oHjRbY-2nSozto-fHYh5N-2nSq4r3-2nSk4L3-eiiqe5-2nSnXvZ-2hBuusa-2oys7vx-2pGNsEi-2nVTu4M-2oR198E-2oQZ7Jt-fHcMk7-2nSnGqP-2p3YtQY-2oHg2w3-2pGNsN4-gBeA5R-piiHgZ-eHQ3T6-otTcnh-asF8TV-2oyuo1o-2kTGeGD-hs7aAy-dtVggH-93rskK-auXYxJ-2oQZ7pL-eiTqw9-eiMGhH-6X77XD-8KZULE-qCA7TQ-2hBtDhA-qpXC8u-oLkURf-kdmxG6-bTBzJe-Keo9qu-p9igoC-6X7eMX-fHXQzU-cAayeu-2oAVYYj" data-flickr-embed="true"><img loading="lazy" decoding="async" src="https://live.staticflickr.com/2667/3799251083_34508aa500_z.jpg" alt="Nautilus" width="640" height="427"></a></p>
<p><em>A Nautilus, a cephalopod which remained from an ancient lineage. The few species of Nautilus which still exist have more bodies, with simpler eyes, and less developed nervous systems, and generally live as scavengers in deep waters. I took this picture in Palau, where the crew of the dive boat had baited it with a piece of chicken at depth, and hoisted the animal up to shallow waters, where divers could photograph them.</em></p>
<p><strong>The Cephalopod Civilization Window</strong></p>
<p>A crucial window where cephalopod civilization could have occurred is the time between when mentally high-performing cephalopods came to their own, and the time when aquatic vertebrates really took over. Modern (Teleost) fishes exploded, evolutionarily speaking, only in the late Cretaceous, the last of the three ages of the dinosaurs. These are the snappers, groupers, large wrasses and other predatory fishes which keep the octopus numbers on reefs low in this day and age.</p>
<p>Cephalopods got into their evolutionary gears earlier – the number of genera increased substantially, since the beginning of the Triassic, about 55 million years earlier than the diversification of bony fishes. That’s a long time for evolution to push a species over that last hump of intelligence and cooperation needed to attain simple farming civilization. If there ever was an ancient cephalopod civilization, my bet would be that it happened in the Jurassic.</p>
<p>Again, I think that the likelihood of squid kings ruling the Jurassic seas or of octopus knights jousting for Mesozoic reef dominance is not high, and there is no support yet in favor of it. As usual, unusual claims need especially strong support, and this support doesn’t exist yet. But the ancient cephalopod civilization is one of the poetic believes I keep for myself to remind myself of my pre-grad student, sci-fi devouring teenage self. And should modern geology proceed to univocally falsify even the light version of the cephalopod Silurian hypothesis, I’ll take it easier than the Italian professor.</p>
<p><strong>About the author: </strong></p>
<p>Dr. Klaus M. Stiefel is a biologist, science writer, underwater videographer and scuba instructor originally from Austria, now based in the Philippines. His latest popular science book “Your Brain on Diving” was published by Hübner, Hamburg in 2023. You can find Klaus’ videos and images on social media with the handle <strong><em>Pacificklaus</em></strong>.</p>
<p><strong>Some papers worth reading if you’d like to dig deeper:</strong></p>
<p>Schmidt, G. A., &amp; Frank, A. (2019). The Silurian hypothesis: would it be possible to detect an industrial civilization in the geological record?. International Journal of Astrobiology, 18(2), 142-150.</p>
<p>Klug, C., Landman, N. H., Fuchs, D., Mapes, R. H., Pohle, A., Guériau, P., … &amp; Hoffmann, R. (2019). Anatomy and evolution of the first Coleoidea in the Carboniferous. Communications Biology, 2(1), 280.</p>
<p>Tanner, A. R., Fuchs, D., Winkelmann, I. E., Gilbert, M. T. P., Pankey, M. S., Ribeiro, Â. M., … &amp; Vinther, J. (2017). Molecular clocks indicate turnover and diversification of modern coleoid cephalopods during the Mesozoic Marine Revolution. Proceedings of the Royal Society B: Biological Sciences, 284(1850), 20162818.</p>
<p><a href="https://link.springer.com/article/10.1007/s11538-024-01330-z">Landsittel, J. A., Ermentrout, G. B., &amp; Stiefel, K. M. (2024). A Theoretical Comparison of Alternative Male Mating Strategies in Cephalopods and Fishes.&nbsp;<i>Bulletin of Mathematical Biology</i>,&nbsp;<i>86</i>(8), 98.</a></p>
<p><iframe loading="lazy" title="Flamboyant Cuttlefish Walking" width="800" height="450" src="https://www.youtube.com/embed/1HJ5WU81UcE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Chordcat works – a chord naming algorithm (108 pts)]]></title>
            <link>https://blog.s20n.dev/posts/how-chordcat-works/</link>
            <guid>42106548</guid>
            <pubDate>Mon, 11 Nov 2024 12:02:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.s20n.dev/posts/how-chordcat-works/">https://blog.s20n.dev/posts/how-chordcat-works/</a>, See on <a href="https://news.ycombinator.com/item?id=42106548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="outline-text-headline-2">
<p>
First, we get <code>indices</code>, which is the list of indices of all the keys pressed on
the keyboard (0-88). As discussed in the previous section, we can simply take
the modulo of these indices with 12 and store them in a set to name our chord
(no duplicates). We'll call this set "<code>notes</code>".</p>
<p>
Since we now know that basically any of the played notes could be the root note
of our chord, we'll need to iterate through all the notes that were played and
run the chord-naming algorithm once for each note.</p>
<p>
This is what is done in the piece of code below. In our chord naming function,
we've got the second <code>for</code> loop iterating through each of the notes considering
each of them the root, one at a time.</p>
<div><pre tabindex="0"><code data-lang="c++"><span><span>std<span>::</span>multiset<span>&lt;</span>Chord<span>&gt;</span> name_that_chord(<span>const</span> std<span>::</span>vector<span>&lt;</span>size_t<span>&gt;&amp;</span> indices) {
</span></span><span><span>  std<span>::</span>set<span>&lt;</span><span>unsigned</span> <span>short</span><span>&gt;</span> notes <span>=</span> {};
</span></span><span><span>  <span>for</span> (<span>auto</span> index : indices) {
</span></span><span><span>      notes.insert(index <span>%</span> <span>12</span>);
</span></span><span><span>  }
</span></span><span><span>  std<span>::</span>multiset<span>&lt;</span>Chord<span>&gt;</span> result <span>=</span> {};
</span></span><span><span>  <span>for</span> (<span>auto</span> root : notes) {
</span></span><span><span>      std<span>::</span>set<span>&lt;</span><span>unsigned</span> <span>short</span><span>&gt;</span> intervals <span>=</span> {};
</span></span><span><span>      <span>for</span> (<span>auto</span> other : notes) {
</span></span><span><span>	  <span>if</span> (other <span>==</span> root)
</span></span><span><span>	      <span>continue</span>;
</span></span><span><span>	  intervals.insert(get_note_distance(root, other));
</span></span><span><span>      }
</span></span><span><span>      insert_chords(root, intervals, result);
</span></span><span><span>  }
</span></span><span><span>  <span>return</span> result;
</span></span><span><span>}</span></span></code></pre></div>
<p>
Once we consider one of the notes as the root, we can then go ahead and get the
structure of the chord by calculating the distance of each of the notes in
relation with the root note. By distance, I mean the number of semitones between
the two notes. This is stored in a set named "<code>intervals</code>".</p>
<p>
Once we have the set of intervals, we can then simply lookup this set in our
database of chord names. <a href="https://github.com/shriramters/chordcat/blob/main/src/chord_db.hpp">This is a rudimentary "database" of chord names I came
up with</a>. These names will be our "base names". We will have to check our
intervals set against each of these chords in our database. The missing or
additional notes will be the accidental notes in the chord (b13, #11 etc..).</p>
<p>
Here <code>Chord</code> is a struct representing the actual chord. We store:</p>
<ul>
<li>root note,</li>
<li>extra tones (The notes present in our intervals set but not in the chord</li>
</ul>
<p>database entry)</p>
<ul>
<li>omitted tones (The notes present in the database entry but not in our
intervals set)</li>
<li>num_accidentals (the sum of extra and omitted tones, this is used for sorting)</li>
</ul>
<div><pre tabindex="0"><code data-lang="c++"><span><span><span>struct</span> <span>Chord</span> {
</span></span><span><span>    <span>unsigned</span> <span>short</span> root;
</span></span><span><span>    sf<span>::</span>String base_name;
</span></span><span><span>    std<span>::</span>vector<span>&lt;</span><span>unsigned</span> <span>short</span><span>&gt;</span> extra_tones;
</span></span><span><span>    std<span>::</span>vector<span>&lt;</span><span>unsigned</span> <span>short</span><span>&gt;</span> omitted_tones;
</span></span><span><span>    <span>unsigned</span> num_accidentals;
</span></span><span><span>
</span></span><span><span>    <span>// support sorting
</span></span></span><span><span><span></span>    <span>friend</span> <span>auto</span> <span>operator</span><span>&lt;=&gt;</span>(Chord <span>const</span><span>&amp;</span> a, Chord <span>const</span><span>&amp;</span> b) {
</span></span><span><span>        <span>return</span> a.num_accidentals <span>&lt;=&gt;</span> b.num_accidentals;
</span></span><span><span>}</span></span></code></pre></div>
<div id="outline-container-headline-3">
<h3 id="headline-3">
Sorting?
</h3>
<div id="outline-text-headline-3">
<p>
Here is another postulate of this algorithm, the chord name that has fewer
accidentals can be considered a more proper name for the chord.</p>
<p>
It is for this reason that we are making our chords sortable by
<code>num_accidentals</code></p>
<p>
For instance, consider the chord <code>CEG</code>. If we consider <code>C</code> to be the root note,
we can calculate the interval set to be <code>(4, 7)</code> (because <code>E</code> is 4 semitones above
<code>C</code> and <code>G</code> is 7 semitones above <code>C</code>).</p>
<p>
Running this <code>(4,7)</code> against our database, we come up with these candidates for names:</p>
<table>
<tbody>
<tr>
<td>intervals</td>
<td>base name</td>
<td>omitted tones</td>
<td>extra tones</td>
<td>final name</td>
<td>num_accidentals</td>
</tr>
<tr>
<td>(3,7)</td>
<td>minor</td>
<td>(3)</td>
<td>(4)</td>
<td>C minor (no b3, add 3)</td>
<td>2</td>
</tr>
<tr>
<td>(4,7)</td>
<td>major</td>
<td>nil</td>
<td>nil</td>
<td>C major</td>
<td>0</td>
</tr>
<tr>
<td>(4,7,10)</td>
<td>7</td>
<td>(10)</td>
<td>nil</td>
<td>C7 (no b7)</td>
<td>1</td>
</tr>
<tr>
<td>(4,7,11)</td>
<td>maj7</td>
<td>(11)</td>
<td>nil</td>
<td>Cmaj7 (no 7)</td>
<td>1</td>
</tr>
<tr>
<td>(3,7,10)</td>
<td>min7</td>
<td>(3, 11)</td>
<td>4</td>
<td>Cmin7(no b3, no b7, add 3)</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>
Clearly, we can see that the names with fewer accidentals are more fitting (in
our case <code>C major</code> would be the best name for our set of notes).</p>
<p>
These accidentals (difference between our interval set and the chord_db entry)
are calculated in our <code>insert_chords</code> function:</p>
<div><pre tabindex="0"><code data-lang="c++"><span><span><span>void</span> <span>insert_chords</span>(<span>const</span> <span>unsigned</span> <span>short</span> root, <span>const</span> std<span>::</span>set<span>&lt;</span><span>unsigned</span> <span>short</span><span>&gt;&amp;</span> intervals,
</span></span><span><span>                   std<span>::</span>multiset<span>&lt;</span>Chord<span>&gt;&amp;</span> res) {
</span></span><span><span>    std<span>::</span>set<span>&lt;</span>Chord<span>&gt;</span> temp;
</span></span><span><span>    <span>for</span> (<span>auto</span><span>&amp;</span> [name, notes] <span>:</span> chord_db) {
</span></span><span><span>        Chord chord <span>=</span> {};
</span></span><span><span>        chord.root <span>=</span> root;
</span></span><span><span>        chord.base_name <span>=</span> name;
</span></span><span><span>
</span></span><span><span>        <span>// Can be written better using std::ranges::set_difference
</span></span></span><span><span><span></span>        std<span>::</span>set_difference(notes.begin(), notes.end(), intervals.begin(), intervals.end(),
</span></span><span><span>                            std<span>::</span>back_inserter(chord.omitted_tones));
</span></span><span><span>        std<span>::</span>set_difference(intervals.begin(), intervals.end(), notes.begin(), notes.end(),
</span></span><span><span>                            std<span>::</span>back_inserter(chord.extra_tones));
</span></span><span><span>        chord.num_accidentals <span>=</span> chord.extra_tones.size() <span>+</span> chord.omitted_tones.size();
</span></span><span><span>
</span></span><span><span>        temp.insert(chord);
</span></span><span><span>    }
</span></span><span><span>    <span>if</span> (<span>!</span>temp.empty())
</span></span><span><span>        res.insert(<span>*</span>temp.begin());
</span></span><span><span>}</span></span></code></pre></div>
</div>
</div>
<div id="outline-container-headline-4">
<h3 id="headline-4">
Why multiset?
</h3>
<div id="outline-text-headline-4">
<p>
Going back to our <code>name_that_chord</code> function, we see that I have used a
<code>multiset</code> to store all the candidate names instead of a regular <code>set</code>. The
reason for this is the comparison operator <code>&lt;=&gt;</code> that we defined in our <code>Chord</code>
struct.</p>
<p>
Since it is entirely possible that two chords can have the same number of
accidentals, it is not possible to store both of these chords in a set (if we
define the operator like that). For this reason, we have to use a <code>multiset</code>
which allows for two or more entries to be on the same level (or in our case,
have the same number of accidentals).</p>
</div>
</div>
</div></div>]]></description>
        </item>
    </channel>
</rss>