<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 09 Sep 2024 11:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[QUIC Is Not Quick Enough over Fast Internet (365 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/3589334.3645323</link>
            <guid>41484991</guid>
            <pubDate>Mon, 09 Sep 2024 02:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/3589334.3645323">https://dl.acm.org/doi/10.1145/3589334.3645323</a>, See on <a href="https://news.ycombinator.com/item?id=41484991">Hacker News</a></p>
<div id="readability-page-1" class="page"><article xmlns="http://www.w3.org/1999/xhtml" data-design="pill" data-theme="conference-proceedings" data-type="chapter" vocab="http://schema.org/" typeof="Chapter" lang="en" dir="ltr"><header data-extent="frontmatter"></header><section id="abstracts" data-type="main" property="abstract" typeof="Text" role="doc-abstract" data-extent="frontmatter"><h2 property="name">Abstract</h2><p>QUIC is expected to be a game-changer in improving web application performance. In this paper, we conduct a systematic examination of QUIC's performance over high-speed networks. We find that over fast Internet, the UDP+QUIC+HTTP/3 stack suffers a data rate reduction of up to 45.2% compared to the TCP+TLS+HTTP/2 counterpart. Moreover, the performance gap between QUIC and HTTP/2 grows as the underlying bandwidth increases. We observe this issue on lightweight data transfer clients and major web browsers (Chrome, Edge, Firefox, Opera), on different hosts (desktop, mobile), and over diverse networks (wired broadband, cellular). It affects not only file transfers, but also various applications such as video streaming (up to 9.8% video bitrate reduction) and web browsing. Through rigorous packet trace analysis and kernel- and user-space profiling, we identify the root cause to be high receiver-side processing overhead, in particular, excessive data packets and QUIC's user-space ACKs. We make concrete recommendations for mitigating the observed performance issues.</p></section><div id="backmatter" data-extent="backmatter"><section id="supplementary-materials" data-type="supplementary-material"><h2>Supplemental Material</h2><div><ul><li><a href="https://dl.acm.org/doi/suppl/10.1145/3589334.3645323/suppl_file/QUIC%20is%20not%20Quick%20Enough%20over%20Fast%20Internet.mp4" download="QUIC is not Quick Enough over Fast Internet.mp4">Download</a></li><li>75.36 MB</li></ul></div><div><ul><li><a href="https://dl.acm.org/doi/suppl/10.1145/3589334.3645323/suppl_file/rfp0090.mp4" download="rfp0090.mp4">Download</a></li><li>36.53 MB</li></ul></div></section><section id="bibliography" role="doc-bibliography"><h2>References</h2><div role="list"><div role="listitem" data-has="label"><p>[1]</p><div id="ref-00001"><p>1998. cURL - command line tool and library for transferring data with URLs. https://curl.se/.</p></div></div><div role="listitem" data-has="label"><p>[2]</p><div id="ref-00002"><p>2001. Linux Traffic Control (tc). https://man7.org/linux/man-pages/man8/tc.8.html.</p></div></div><div role="listitem" data-has="label"><p>[3]</p><div id="ref-00003"><p>2012. HTTP Archive (HAR) format. https://w3c.github.io/web-performance/specs/HAR/Overview.html.</p></div></div><div role="listitem" data-has="label"><p>[4]</p><div id="ref-00004"><p>2013. Chromium Blog: Experimenting with QUIC. https://blog.chromium.org/2013/06/experimenting-with-quic.html.</p></div></div><div role="listitem" data-has="label"><p>[5]</p><div id="ref-00005"><p>2015. Chromium Blog: A QUIC update on Google's experimental transport. https://blog.chromium.org/2015/04/a-quic-update-on-googles-experimental.html.</p></div></div><div role="listitem" data-has="label"><p>[6]</p><div id="ref-00006"><p>2018. UDP GSO. https://lwn.net/Articles/752956/.</p></div></div><div role="listitem" data-has="label"><p>[7]</p><div id="ref-00007"><p>2020. Accelerating UDP packet transmission for QUIC. https://blog.cloudflare.com/accelerating-udp-packet-transmission-for-quic/.</p></div></div><div role="listitem" data-has="label"><p>[8]</p><div id="ref-00008"><p>2020. Chromium Blog: Chrome is deploying HTTP/3 and IETF QUIC. https://blog.chromium.org/2020/10/chrome-is-deploying-http3-and-ietf-quic.html.</p></div></div><div role="listitem" data-has="label"><p>[9]</p><div id="ref-00009"><p>2020. How Facebook is bringing QUIC to billions. https://engineering.fb.com/ 2020/10/21/networking-traffic/how-facebook-is-bringing-quic-to-billions/.</p></div></div><div role="listitem" data-has="label"><p>[10]</p><div id="ref-00010"><p>2020. QUIC vs TCP: Which is Better? https://www.fastly.com/blog/measuringquic-vs-tcp-computational-efficiency.</p></div></div><div role="listitem" data-has="label"><p>[11]</p><div id="ref-00011"><p>2020. What's the Best Bitrate for the Best Video Quality on YouTube? (1080p, 1440p, 4K). https://www.youtube.com/watch?v=0fz479id_Ic.</p></div></div><div role="listitem" data-has="label"><p>[12]</p><div id="ref-00012"><p>2021. Chrome HAR capturer. https://github.com/cyrus-and/chrome-harcapturer.</p></div></div><div role="listitem" data-has="label"><p>[13]</p><div id="ref-00013"><p>2021. HTTP/2 vs HTTP/3: A comparison. https://ably.com/topic/http-2-vs-http-3.</p></div></div><div role="listitem" data-has="label"><p>[14]</p><div id="ref-00014"><p>2021. HTTP/3 and QUIC: Past, Present, and Future. https://www.akamai.com/blog/performance/http3-and-quic-past-present-and-future.</p></div></div><div role="listitem" data-has="label"><p>[15]</p><div id="ref-00015"><p>2021. Improve UDP performance in RHEL 8.5. https://developers.redhat.com/ articles/2021/11/05/improve-udp-performance-rhel-85.</p></div></div><div role="listitem" data-has="label"><p>[16]</p><div id="ref-00016"><p>2021. Linux Perf. https://man7.org/linux/man-pages/man1/perf.1.html.</p></div></div><div role="listitem" data-has="label"><p>[17]</p><div id="ref-00017"><p>2021. Linux Temporary Filesystem (tmpfs). https://man7.org/linux/man-pages/man5/tmpfs.5.html.</p></div></div><div role="listitem" data-has="label"><p>[18]</p><div id="ref-00018"><p>2021. YouTube 4K bitrates enconding. https://support.google.com/youtube/answer/1722171.</p></div></div><div role="listitem" data-has="label"><p>[19]</p><div id="ref-00019"><p>2022. Catapult -Web Page Replay. https://chromium.googlesource.com/catapult//HEAD/web_page_replay_go/.</p></div></div><div role="listitem" data-has="label"><p>[20]</p><div id="ref-00020"><p>2022. Fiddler - Web Debugging Proxy and Troubleshooting Solutions. https://www.telerik.com/fiddler.</p></div></div><div role="listitem" data-has="label"><p>[21]</p><div id="ref-00021"><p>2022. GitHub - litespeedtech/lsquic: LiteSpeed QUIC and HTTP/3 Library. https://github.com/litespeedtech/lsquic.</p></div></div><div role="listitem" data-has="label"><p>[22]</p><div id="ref-00022"><p>2022. HTTP RFCs have evolved: A Cloudflare view of HTTP usage trends. https://blog.cloudflare.com/cloudflare-view-http3-usage/.</p></div></div><div role="listitem" data-has="label"><p>[23]</p><div id="ref-00023"><p>2022. SiteSucker. https://ricks-apps.com/osx/sitesucker/index.html.</p></div></div><div role="listitem" data-has="label"><p>[24]</p><div id="ref-00024"><p>2023. NGINX QUIC. https://quic.nginx.org/.</p></div></div><div role="listitem" data-has="label"><p>[25]</p><div id="ref-00025"><p>2023. OpenLiteSpeed. https://openlitespeed.org/.</p></div></div><div role="listitem" data-has="label"><p>[26]</p><div id="ref-00026"><p>2023. The Chromium Projects. https://www.chromium.org/Home/.</p></div></div><div role="listitem" data-has="label"><p>[27]</p><div id="ref-00027"><p>2023. The Chromium Projects - Network Service. https://chromium.googlesource.com/chromium/src//HEAD/services/network/.</p></div></div><div role="listitem" data-has="label"><p>[28]</p><div id="ref-00028"><p>2024. QUIC-not-Quick: Artifact Release. https://doi.org/10.5281/zenodo.10679638.</p></div></div><div role="listitem" data-has="label"><p>[29]</p><div id="ref-00029"><p>2024. QUIC-not-Quick GitHub repository. https://github.com/Shawnxm/QUICnot-Quick.</p></div></div><div role="listitem" data-has="label"><p>[30]</p><div id="ref-00030"><p>Mohsen Attaran. 2023. The impact of 5G on the evolution of intelligent automation and industry digitization. Journal of ambient intelligence and humanized computing 14, 5 (2023), 5977--5993.</p></div></div><div role="listitem" data-has="label"><p>[31]</p><div id="ref-00031"><p>Arkaprava Basu, Jayneel Gandhi, Jichuan Chang, Mark D Hill, and Michael M Swift. 2013. Efficient virtual memory for big memory servers. ACM SIGARCH Computer Architecture News 41, 3 (2013), 237--248.</p></div></div><div role="listitem" data-has="label"><p>[32]</p><div id="ref-00032"><p>Mike Belshe, Roberto Peon, and Martin Thomson. 2015. Hypertext transfer protocol version 2 (HTTP/2). RFC 7540, IETF (2015).</p></div></div><div role="listitem" data-has="label"><p>[33]</p><div id="ref-00033"><p>Mike Bishop. 2022. HTTP/3. RFC 9114, IETF (2022).</p></div></div><div role="listitem" data-has="label"><p>[34]</p><div id="ref-00034"><p>Enrico Bocchi, Luca De Cicco, and Dario Rossi. 2016. Measuring the quality of experience of web users. ACM SIGCOMM Computer Communication Review 46, 4 (2016), 8--13.</p></div></div><div role="listitem" data-has="label"><p>[35]</p><div id="ref-00035"><p>Michael Butkiewicz, Harsha V Madhyastha, and Vyas Sekar. 2011. Understanding website complexity: measurements, metrics, and implications. In Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference. 313--328.</p></div></div><div role="listitem" data-has="label"><p>[36]</p><div id="ref-00036"><p>Gaetano Carlucci, Luca De Cicco, and Saverio Mascolo. 2015. HTTP over UDP: an Experimental Investigation of QUIC. In Proceedings of the 30th Annual ACM Symposium on Applied Computing. 609--614.</p></div></div><div role="listitem" data-has="label"><p>[37]</p><div id="ref-00037"><p>Willem de Bruijn and Eric Dumazet. 2018. Optimizing UDP for content delivery: GSO, pacing and zerocopy. In Linux Plumbers Conference.</p></div></div><div role="listitem" data-has="label"><p>[38]</p><div id="ref-00038"><p>Quentin De Coninck and Olivier Bonaventure. 2017. Multipath quic: Design and evaluation. In Proceedings of the 13th international conference on emerging networking experiments and technologies. 160--166.</p></div></div><div role="listitem" data-has="label"><p>[39]</p><div id="ref-00039"><p>Quentin De Coninck and Olivier Bonaventure. 2019. Multipathtester: Comparing mptcp and mpquic in mobile environments. In 2019 Network Traffic Measurement and Analysis Conference (TMA). IEEE, 221--226.</p></div></div><div role="listitem" data-has="label"><p>[40]</p><div id="ref-00040"><p>Quentin De Coninck, François Michel, Maxime Piraux, Florentin Rochet, Thomas Given-Wilson, Axel Legay, Olivier Pereira, and Olivier Bonaventure. 2019. Pluginizing quic. In Proceedings of the ACM Special Interest Group on Data Communication. 59--74.</p></div></div><div role="listitem" data-has="label"><p>[41]</p><div id="ref-00041"><p>Sebastian Endres, Jörg Deutschmann, Kai-Steffen Hielscher, and Reinhard German. 2022. Performance of QUIC implementations over geostationary satellite links. arXiv preprint arXiv:2202.08228 (2022).</p></div></div><div role="listitem" data-has="label"><p>[42]</p><div id="ref-00042"><p>Mathis Engelbart and Jörg Ott. 2021. Congestion control for real-time media over QUIC. In Proceedings of the 2021 Workshop on Evolution, Performance and Interoperability of QUIC. 1--7.</p></div></div><div role="listitem" data-has="label"><p>[43]</p><div id="ref-00043"><p>Godred Fairhurst, Tom Jones, Michael Tüxen, Irene Rüngeler, and Timo Völker. 2020. Packetization Layer Path MTU Discovery for Datagram Transports. RFC 8899, IETF (2020).</p></div></div><div role="listitem" data-has="label"><p>[44]</p><div id="ref-00044"><p>Roy Fielding, Mark Nottingham, and Julian Reschke. 2022. HTTP Semantics. RFC 9110, IETF (2022).</p></div></div><div role="listitem" data-has="label"><p>[45]</p><div id="ref-00045"><p>Anirudh Ganji and Muhammad Shahzad. 2021. Characterizing the Performance of QUIC on Android and Wear OS Devices. In 2021 International Conference on Computer Communications and Networks (ICCCN). IEEE, 1--11.</p></div></div><div role="listitem" data-has="label"><p>[46]</p><div id="ref-00046"><p>Habtegebreil Haile, Karl-Johan Grinnemo, Simone Ferlin, Per Hurtig, and Anna Brunstrom. 2022. Performance of QUIC congestion control algorithms in 5G networks. In Proceedings of the ACM SIGCOMM Workshop on 5G and Beyond Network Measurements, Modeling, and Use Cases. 15--21.</p></div></div><div role="listitem" data-has="label"><p>[47]</p><div id="ref-00047"><p>Fahad Hilal and Oliver Gasser. 2023. Yarrpbox: Detecting Middleboxes at Internet- Scale. Proceedings of the ACM on Networking 1, CoNEXT1 (2023), 1--23.</p></div></div><div role="listitem" data-has="label"><p>[48]</p><div id="ref-00048"><p>Te-Yuan Huang, Ramesh Johari, Nick McKeown, Matthew Trunnell, and Mark Watson. 2014. A buffer-based approach to rate adaptation: Evidence from a large video streaming service. In Proceedings of the 2014 ACM conference on SIGCOMM. 187--198.</p></div></div><div role="listitem" data-has="label"><p>[49]</p><div id="ref-00049"><p>Swett Ian. 2020. As QUIC as TCP, Optimizing QUIC and HTTP/3 CPU Usage - EPIQ 2020. https://conferences.sigcomm.org/sigcomm/2020/workshop-epiq. html.</p></div></div><div role="listitem" data-has="label"><p>[50]</p><div id="ref-00050"><p>Janardhan Iyengar, Ian Swett, and Mirja Kühlewind. 2023. QUIC Acknowledgement Frequency. IETF (2023). https://datatracker.ietf.org/doc/draft-ietf-quicack- frequency/04/ Work in Progress.</p></div></div><div role="listitem" data-has="label"><p>[51]</p><div id="ref-00051"><p>Jana Iyengar and Martin Thomson. 2021. QUIC: A UDP-based multiplexed and secure transport. RFC 9000, IETF (2021).</p></div></div><div role="listitem" data-has="label"><p>[52]</p><div id="ref-00052"><p>Benedikt Jaeger, Johannes Zirngibl, Marcel Kempf, Kevin Ploch, and Georg Carle. 2023. QUIC on the Highway: Evaluating Performance on High-Rate Links. In 2023 IFIP Networking Conference (IFIP Networking). 1--9.</p></div></div><div role="listitem" data-has="label"><p>[53]</p><div id="ref-00053"><p>Arash Molavi Kakhki, Samuel Jero, David Choffnes, Cristina Nita-Rotaru, and Alan Mislove. 2017. Taking a long look at QUIC: an approach for rigorous evaluation of rapidly evolving transport protocols. In proceedings of the 2017 internet measurement conference. 290--303.</p></div></div><div role="listitem" data-has="label"><p>[54]</p><div id="ref-00054"><p>Mike Kosek, Hendrik Cech, Vaibhav Bajpai, and Jörg Ott. 2022. Exploring Proxying QUIC and HTTP/3 for Satellite Communication. In 2022 IFIP Networking Conference (IFIP Networking). IEEE, 1--9.</p></div></div><div role="listitem" data-has="label"><p>[55]</p><div id="ref-00055"><p>Mike Kosek, Luca Schumann, Robin Marx, Trinh Viet Doan, and Vaibhav Bajpai. 2022. DNS privacy with speed? evaluating DNS over QUIC and its impact on web performance. In Proceedings of the 22nd ACM Internet Measurement Conference. 44--50.</p></div></div><div role="listitem" data-has="label"><p>[56]</p><div id="ref-00056"><p>Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles Krasic, Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar, et al. 2017. The quic transport protocol: Design and internet-scale deployment. In Proceedings of the conference of the ACM special interest group on data communication. 183--196.</p></div></div><div role="listitem" data-has="label"><p>[57]</p><div id="ref-00057"><p>Robert Lychev, Samuel Jero, Alexandra Boldyreva, and Cristina Nita-Rotaru. 2015. How secure and quick is QUIC? Provable security and performance analyses. In 2015 IEEE Symposium on Security and Privacy. IEEE, 214--231.</p></div></div><div role="listitem" data-has="label"><p>[58]</p><div id="ref-00058"><p>Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. 2017. Neural adaptive video streaming with pensieve. In Proceedings of the conference of the ACM special interest group on data communication. 197--210.</p></div></div><div role="listitem" data-has="label"><p>[59]</p><div id="ref-00059"><p>Robin Marx, Joris Herbots, Wim Lamotte, and Peter Quax. 2020. Same standards, different decisions: A study of QUIC and HTTP/3 implementation diversity. In Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC. 14--20.</p></div></div><div role="listitem" data-has="label"><p>[60]</p><div id="ref-00060"><p>Péter Megyesi, Zsolt Krämer, and Sándor Molnár. 2016. How quick is QUIC?. In 2016 IEEE International Conference on Communications (ICC). IEEE, 1--6.</p></div></div><div role="listitem" data-has="label"><p>[61]</p><div id="ref-00061"><p>Ayush Mishra, Sherman Lim, and Ben Leong. 2022. Understanding speciation in QUIC congestion control. In Proceedings of the 22nd ACM Internet Measurement Conference. 560--566.</p></div></div><div role="listitem" data-has="label"><p>[62]</p><div id="ref-00062"><p>Arvind Narayanan, Eman Ramadan, Rishabh Mehta, Xinyue Hu, Qingxu Liu, Rostand AK Fezeu, Udhaya Kumar Dayalan, Saurabh Verma, Peiqi Ji, Tao Li, et al. 2020. Lumos5G: Mapping and predicting commercial mmWave 5G throughput. In Proceedings of the ACM Internet Measurement Conference. 176--193.</p></div></div><div role="listitem" data-has="label"><p>[63]</p><div id="ref-00063"><p>Arvind Narayanan, Xumiao Zhang, Ruiyang Zhu, Ahmad Hassan, Shuowei Jin, Xiao Zhu, Xiaoxuan Zhang, Denis Rybkin, Zhengxuan Yang, Zhuoqing Morley Mao, et al. 2021. A variegated look at 5G in the wild: performance, power, andQoE implications. In Proceedings of the 2021 ACM SIGCOMM 2021 Conference. 610--625.</p></div></div><div role="listitem" data-has="label"><p>[64]</p><div id="ref-00064"><p>Louis Navarre, Olivier Pereira, and Olivier Bonaventure. 2023. MCQUIC: Multicast and unicast in a single transport protocol. arXiv preprint arXiv:2309.06633 (2023).</p></div></div><div role="listitem" data-has="label"><p>[65]</p><div id="ref-00065"><p>Marcin Nawrocki, Raphael Hiesgen, Thomas C Schmidt, and Matthias Wählisch. 2021. Quicsand: quantifying quic reconnaissance scans and dos flooding events. In Proceedings of the 21st ACM internet measurement conference. 283--291.</p></div></div><div role="listitem" data-has="label"><p>[66]</p><div id="ref-00066"><p>Marcin Nawrocki, Pouyan Fotouhi Tehrani, Raphael Hiesgen, Jonas Mücke, Thomas C Schmidt, and Matthias Wählisch. 2022. On the interplay between TLS certificates and QUIC performance. In Proceedings of the 18th International Conference on emerging Networking EXperiments and Technologies. 204--213.</p></div></div><div role="listitem" data-has="label"><p>[67]</p><div id="ref-00067"><p>Javad Nejati and Aruna Balasubramanian. 2016. An in-depth study of mobile browser performance. In Proceedings of the 25th International Conference on World Wide Web. 1305--1315.</p></div></div><div role="listitem" data-has="label"><p>[68]</p><div id="ref-00068"><p>Thomas William do Prado Paiva, Simone Ferlin, Anna Brunstrom, Ozgu Alay, and Bruno Yuji Lino Kimura. 2023. A First Look at Adaptive Video Streaming over Multipath QUIC with Shared Bottleneck Detection. In Proceedings of the 14th Conference on ACM Multimedia Systems. 161--172.</p></div></div><div role="listitem" data-has="label"><p>[69]</p><div id="ref-00069"><p>Mirko Palmer, Thorben Krüger, Balakrishnan Chandrasekaran, and Anja Feldmann. 2018. The quic fix for optimal video streaming. In Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC. 43--49.</p></div></div><div role="listitem" data-has="label"><p>[70]</p><div id="ref-00070"><p>Gustavo Pantuza, Marcos AM Vieira, and Luiz FM Vieira. 2021. eQUIC gateway: Maximizing QUIC throughput using a gateway service based on eBPF XDP. In 2021 IEEE Symposium on Computers and Communications (ISCC). IEEE, 1--6.</p></div></div><div role="listitem" data-has="label"><p>[71]</p><div id="ref-00071"><p>Maxime Piraux, Quentin De Coninck, and Olivier Bonaventure. 2018. Observing the evolution of QUIC implementations. In Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC. 8--14.</p></div></div><div role="listitem" data-has="label"><p>[72]</p><div id="ref-00072"><p>Alexander Rabitsch, Per Hurtig, and Anna Brunstrom. 2018. A stream-aware multipath QUIC scheduler for heterogeneous paths. In Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC. 29--35.</p></div></div><div role="listitem" data-has="label"><p>[73]</p><div id="ref-00073"><p>Costin Raiciu, Mark Handley, and Damon Wischik. 2011. Coupled congestion control for multipath transport protocols. RFC 6356, IETF (2011).</p></div></div><div role="listitem" data-has="label"><p>[74]</p><div id="ref-00074"><p>Florentin Rochet, Emery Assogba, Maxime Piraux, Korian Edeline, Benoit Donnet, and Olivier Bonaventure. 2021. TCPLS: modern transport services with TCP and TLS. In Proceedings of the 17th International Conference on emerging Networking EXperiments and Technologies. 45--59.</p></div></div><div role="listitem" data-has="label"><p>[75]</p><div id="ref-00075"><p>Jan Rüth, Ingmar Poese, Christoph Dietzel, and Oliver Hohlfeld. 2018. A First Look at QUIC in the Wild. In International Conference on Passive and Active Network Measurement. Springer, 255--268.</p></div></div><div role="listitem" data-has="label"><p>[76]</p><div id="ref-00076"><p>Jan Rüth, Konrad Wolsing, Klaus Wehrle, and Oliver Hohlfeld. 2019. Perceiving QUIC: Do users notice or even care?. In Proceedings of the 15th International Conference on Emerging Networking Experiments And Technologies. 144--150.</p></div></div><div role="listitem" data-has="label"><p>[77]</p><div id="ref-00077"><p>Marten Seemann and Jana Iyengar. 2020. Automating quic interoperability testing. In Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC. 8--13.</p></div></div><div role="listitem" data-has="label"><p>[78]</p><div id="ref-00078"><p>Tanya Shreedhar, Rohit Panda, Sergey Podanev, and Vaibhav Bajpai. 2021. Evaluating QUIC Performance Over Web, Cloud Storage, and Video Workloads. IEEE Transactions on Network and Service Management 19, 2 (2021), 1366--1381.</p></div></div><div role="listitem" data-has="label"><p>[79]</p><div id="ref-00079"><p>Iraj Sodagar. 2011. The mpeg-dash standard for multimedia streaming over the internet. IEEE multimedia 18, 4 (2011), 62--67.</p></div></div><div role="listitem" data-has="label"><p>[80]</p><div id="ref-00080"><p>Mukesh Soni and Brajendra Singh Rajput. 2021. Security and performance evaluations of QUIC protocol. In Data Science and Intelligent Applications. Springer, 457--462.</p></div></div><div role="listitem" data-has="label"><p>[81]</p><div id="ref-00081"><p>Lizhuang Tan, Wei Su, Yanwen Liu, Xiaochuan Gao, and Wei Zhang. 2021. DCQUIC: Flexible and Reliable Software-defined Data Center Transport. In IEEE INFOCOM 2021-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). IEEE, 1--8.</p></div></div><div role="listitem" data-has="label"><p>[82]</p><div id="ref-00082"><p>JingWang, Yunfeng Gao, and Chenren Xu. 2019. A multipath QUIC scheduler for mobile HTTP/2. In Proceedings of the 3rd Asia-Pacific Workshop on Networking 2019. 43--49.</p></div></div><div role="listitem" data-has="label"><p>[83]</p><div id="ref-00083"><p>Xiao Sophia Wang, Aruna Balasubramanian, Arvind Krishnamurthy, and David Wetherall. 2013. Demystifying Page Load Performance with {WProf}. In 10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13). 473--485.</p></div></div><div role="listitem" data-has="label"><p>[84]</p><div id="ref-00084"><p>Xiao Sophia Wang, Aruna Balasubramanian, Arvind Krishnamurthy, and David Wetherall. 2014. How speedy is {SPDY}?. In 11th usenix symposium on networked systems design and implementation (nsdi 14). 387--399.</p></div></div><div role="listitem" data-has="label"><p>[85]</p><div id="ref-00085"><p>Damon Wischik, Costin Raiciu, Adam Greenhalgh, and Mark Handley. 2011. Design, implementation and evaluation of congestion control for multipath {TCP}. In 8th USENIX Symposium on Networked Systems Design and Implementation (NSDI 11).</p></div></div><div role="listitem" data-has="label"><p>[86]</p><div id="ref-00086"><p>Konrad Wolsing, Jan Rüth, Klaus Wehrle, and Oliver Hohlfeld. 2019. A performance perspective on web optimized protocol stacks: TCP TLS HTTP/2 vs. QUIC. In Proceedings of the Applied Networking Research Workshop. 1--7.</p></div></div><div role="listitem" data-has="label"><p>[87]</p><div id="ref-00087"><p>Shichang Xu, Subhabrata Sen, and Z Morley Mao. 2020. CSI: Inferring mobile ABR video adaptation behavior under HTTPS and QUIC. In Proceedings of the Fifteenth European Conference on Computer Systems. 1--16.</p></div></div><div role="listitem" data-has="label"><p>[88]</p><div id="ref-00088"><p>Yihui Yan and Zhice Yang. 2021. When QUIC's Connection Migration Meets Middleboxes A case study on mobile Wi-Fi hotspot. In 2021 IEEE Global Communications Conference (GLOBECOM). IEEE, 1--6.</p></div></div><div role="listitem" data-has="label"><p>[89]</p><div id="ref-00089"><p>Xiangrui Yang, Lars Eggert, Jörg Ott, Steve Uhlig, Zhigang Sun, and Gianni Antichi. 2020. Making quic quicker with nic offload. In Proceedings of theWorkshop on the Evolution, Performance, and Interoperability of QUIC. 21--27.</p></div></div><div role="listitem" data-has="label"><p>[90]</p><div id="ref-00090"><p>Shou-Cheng Yen, Ching-Ling Fan, and Cheng-Hsin Hsu. 2019. Streaming 360° videos to head-mounted virtual reality using DASH over QUIC transport protocol. In Proceedings of the 24th ACM Workshop on Packet Video. 7--12.</p></div></div><div role="listitem" data-has="label"><p>[91]</p><div id="ref-00091"><p>Alexander Yu and Theophilus A Benson. 2021. Dissecting performance of production QUIC. In Proceedings of the Web Conference 2021. 1157--1168.</p></div></div><div role="listitem" data-has="label"><p>[92]</p><div id="ref-00092"><p>Xumiao Zhang, Xiao Zhu, Yihua Ethan Guo, Feng Qian, and Z Morley Mao. 2019. Poster: characterizing performance and power for mmWave 5G on commodity smartphones. In Proceedings of the 2019 on Wireless of the Students, by the Students, and for the Students Workshop. 14--14.</p></div></div><div role="listitem" data-has="label"><p>[93]</p><div id="ref-00093"><p>Zhilong Zheng, Yunfei Ma, Yanmei Liu, Furong Yang, Zhenyu Li, Yuanbo Zhang, Jiuhai Zhang, Wei Shi, Wentao Chen, Ding Li, et al. 2021. Xlink: Qoe-driven multi-path quic transport in large-scale video services. In Proceedings of the 2021 ACM SIGCOMM 2021 Conference. 418--432.</p></div></div><div role="listitem" data-has="label"><p>[94]</p><div id="ref-00094"><p>Johannes Zirngibl, Philippe Buschmann, Patrick Sattler, Benedikt Jaeger, Juliane Aulbach, and Georg Carle. 2021. It's over 9000: analyzing early QUIC deployments with the standardization on the horizon. In Proceedings of the 21st ACM Internet Measurement Conference. 261--275.</p></div></div></div></section>









    
    
        
    

</div><div><div id="core-collateral-info" role="tabpanel"><header><h2>Information &amp; Contributors</h2></header><section id="tab-information" aria-labelledby="information" role="tabpanel"><h3>Information</h3><section><h4>Published In</h4>



        
        <div><p><img src="https://dl.acm.org/cms/asset/0b935d33-efc6-48f2-9b6e-d8b94bc6fc57/3589334.cover.jpg" data-src="/cms/asset/0b935d33-efc6-48f2-9b6e-d8b94bc6fc57/3589334.cover.jpg" alt="cover image ACM Conferences"></p><div><p>WWW '24: Proceedings of the ACM Web Conference 2024</p><p>May 2024</p><p>4826  pages</p></div></div>
<p>Copyright © 2024 ACM.</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from <a href="https://dl.acm.org/cdn-cgi/l/email-protection" data-cfemail="035366716e6a70706a6c6d704362606e2d6c7164">[email&nbsp;protected]</a>.</p></section><section><h4>Publisher</h4><div><p>Association for Computing Machinery</p><p>New York, NY, United States</p></div></section><section id="core-history"><h4>Publication History</h4><p><b>Published</b>: 13 May 2024</p></section><section><h4>Permissions</h4><p>Request permissions for this article.</p></section><section><h4>Check for updates</h4><a data-target="crossmark" href="#" title="Check for updates on crossmark" data-doi="10.1145/3589334.3645323" data-id="article-info-crossmark"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" height="36px" role="presentation"><rect x="5" y="5" width="90" height="90" rx="2" ry="2"></rect><polygon points="35.95 65.11 64.05 46.38 64.05 23.91 35.95 23.91 35.95 65.11"></polygon><polygon points="64.05 65.11 35.95 46.38 35.95 23.91 64.05 23.91 64.05 65.11"></polygon><path d="M50,19A31,31,0,1,0,81,50,31,31,0,0,0,50,19Zm0,54.41A23.41,23.41,0,1,1,73.41,50,23.41,23.41,0,0,1,50,73.41Z"></path><path d="M67.18,65.86a23.38,23.38,0,0,1-38.9-24.57l-6.49-4.1A31,31,0,0,0,73.69,70Z"></path><defs><linearGradient id="no_text_crossmark" x1="50" y1="15.18" x2="50" y2="94.72" gradientUnits="userSpaceOnUse"><stop stop-color="#fff"></stop><stop offset="1" stop-color="#c4c4c4"></stop></linearGradient></defs></svg></a></section><section><h4>Badges</h4></section><section property="keywords"><h4>Author Tags</h4><ol><li><a href="https://dl.acm.org/keyword/http?expand=all" alt="Search on this keyword">http</a></li><li><a href="https://dl.acm.org/keyword/network+measurement?expand=all" alt="Search on this keyword">network measurement</a></li><li><a href="https://dl.acm.org/keyword/quic?expand=all" alt="Search on this keyword">quic</a></li><li><a href="https://dl.acm.org/keyword/transport?expand=all" alt="Search on this keyword">transport</a></li><li><a href="https://dl.acm.org/keyword/web+performance?expand=all" alt="Search on this keyword">web performance</a></li></ol></section><section><h4>Qualifiers</h4><ul><li>Research-article</li></ul></section><section><h4>Funding Sources</h4><ul><li><a href="http://dx.doi.org/10.13039/https://doi.org/10.13039/100000001">NSF (National Science Foundation)</a></li></ul></section><section><h4>Conference</h4></section>



        
        <div><h4 aria-expanded="true">Acceptance Rates</h4><div><p>Overall Acceptance Rate 1,899 of 8,196 submissions, 23%</p></div></div>




        
        








</section><section id="tab-contributors" aria-labelledby="contributors" role="tabpanel"><h3>Contributors</h3>









    
    
        <div data-widget-def="acmPublicationContributorsWidget" data-widget-id="774172a5-8222-4087-8d6e-7a1a17ded31e"><p><img src="https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif"></p></div>
    

<section><h4>Other Metrics</h4></section></section></div><div id="core-collateral-metrics" role="tabpanel"><header><h2>Bibliometrics &amp; Citations</h2></header><section id="tab-metrics-inner" aria-labelledby="metrics-inner" role="tabpanel"><h3>Bibliometrics</h3><section>



        
            <h4>
                Article Metrics
            </h4>
        
        <div><ul><li></li><li></li></ul><ul><li><span>Downloads (Last 12 months)</span><span>184</span></li><li><span>Downloads (Last 6 weeks)</span><span>48</span></li></ul><p><span>Reflects downloads up to 03 Sep 2024</span></p></div>
</section><section><h4>Other Metrics</h4></section></section><section id="tab-citations" aria-labelledby="citations" role="tabpanel"><h3>Citations</h3></section></div><div id="core-collateral-fulltext-options" role="tabpanel"><header><h2>View Options</h2></header><div tabindex="0"><h3>Get Access</h3><div><div><h4>Login options</h4><div><p>Check if you have access through your login credentials or your institution to get full access on this article.</p><p><a title="Sign in" href="https://dl.acm.org/action/showLogin?redirectUri=%2Fdoi%2F10.1145%2F3589334.3645323">Sign in</a></p></div></div><div><h4>Full Access</h4></div></div></div><!-- Its needed to duplicate this for PB check Collateral.js as well--><div tabindex="-1"><h3>View options</h3><section><h4> <abbr title="Portable Document Format">PDF</abbr></h4><p>View or Download as a PDF file.</p><a href="https://dl.acm.org/doi/pdf/10.1145/3589334.3645323" title="View PDF" data-toggle="tooltip" aria-label="View PDF"><span>PDF</span></a></section><section><h4> <abbr title="Electronic Reader">eReader</abbr></h4><p>View online with <abbr title="Electronic Reader">eReader</abbr>.</p><a href="https://dl.acm.org/doi/epdf/10.1145/3589334.3645323" title="View online with eReader" data-toggle="tooltip" aria-label="View online with eReader"><span>eReader</span></a></section></div></div><p id="core-collateral-media" role="tabpanel"><header><h2>Media</h2></header><section id="tab-figures" aria-labelledby="figures" role="tabpanel"><h3>Figures</h3></section><section id="tab-other" aria-labelledby="other" role="tabpanel"><h3>Other</h3></section></p><p id="core-collateral-tables" role="tabpanel"><header><h2>Tables</h2></header><!-- There is no content. --></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Confirmed: Reflection 70B's official API is a wrapper for Sonnet 3.5 (172 pts)]]></title>
            <link>https://old.reddit.com/r/LocalLLaMA/s/4Ly2yj78aM</link>
            <guid>41484981</guid>
            <pubDate>Mon, 09 Sep 2024 02:30:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LocalLLaMA/s/4Ly2yj78aM">https://old.reddit.com/r/LocalLLaMA/s/4Ly2yj78aM</a>, See on <a href="https://news.ycombinator.com/item?id=41484981">Hacker News</a></p>
<div id="readability-page-1" class="page"><div loid="0000000018f2hb396y.2.1725870602939.Z0FBQUFBQm0zcklLTl92UGV6ckcwelFZbFZwMDZZNFcyTkRYQnVUVDlSVzBTZDRLeU0zTDAwMTV6TWp3SExzWXJuSmEtVXdfRmlaeU82ek5Lcm1VTjZtOVZQdVVtVUFqZzRNeFhjQUhmTzA0TXg3aFBfYk9hMjFMOHNtTGNDMzR0cURwbDE2Q1I4WGE" correlation-id="503a28e7-91b7-4219-80f2-fe9262b03dbf" serverrenderid="fc375fca-75e3-40fe-97b8-ef77f45e136c" update-recaptcha="true" routename="login-standalone" pagetype="login" more-comments-route="/svc/shreddit/events" devicetype="desktop" ctn="CSRF" devvit-allow-navigation="true" referrer="" referrer-type="other" country="CH" disable-send-beacon="true" use-local-storage-events-caching="true" app-name="web3x" microapp-name="monolith" microapp-pool="main" microapp-deployment="production" clienthash="0k78gEXJTP/5cIoG" comments-partial-ssr="">
        <faceplate-server-session timestamp="1725870602952"></faceplate-server-session>
        <slot name="use-app" slot="use-app"></slot>
        <shreddit-good-visit-tracker referrertype="other" pagetype="login"></shreddit-good-visit-tracker>
        <shreddit-async-loader bundlename="screen_reader_alerts">
          <screen-reader-alert-outlet></screen-reader-alert-outlet>
        </shreddit-async-loader>
        
        
        
  <shreddit-async-loader bundlename="reddit_cookie_banner">
    <reddit-cookie-banner>
      <div slot="cookie-banner-text">
        <p>
          Reddit and its partners use cookies and similar technologies to provide you with a better experience.
        </p>
        <p>
          By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.
        </p>
        <p>
          By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.
        </p>
        <p>
          For more information, please see our
              <a target="_blank" href="https://reddit.com/en-us/policies/cookies">Cookie Notice</a>
              and our
              <a target="_blank" href="https://reddit.com/en-us/policies/privacy-policy">Privacy Policy</a>.
        </p>
      </div>
    </reddit-cookie-banner>
  </shreddit-async-loader><!-- routable page start --><shreddit-page-meta>
  <template>
      <shreddit-app-attrs serverrenderid="fc375fca-75e3-40fe-97b8-ef77f45e136c" routename="login-standalone" pagetype="login" referrer-type="other" app-name="web3x" microapp-name="monolith" microapp-pool="main" microapp-deployment="production" correlation-id="503a28e7-91b7-4219-80f2-fe9262b03dbf">
      </shreddit-app-attrs>
      <shreddit-good-visit-tracker-attrs pagetype="login" referrertype="other">
      </shreddit-good-visit-tracker-attrs>
    </template>
  </shreddit-page-meta><alert-controller></alert-controller>
    <header>
      
    </header>
    <faceplate-perfmark name="first-contentful-paint"></faceplate-perfmark>
    
    
  
  
    <shreddit-overlay-display overlay-id="auth-flow">
      
  
    <template slot="auth-flow">
      <shreddit-signup-drawer subredditid="" subredditname="" auth-step="login" redirect-on-close="" transparent-overlay="" blocking="">
        <slot slot="recaptcha" name="recaptcha"></slot>
        <slot slot="register-username" name="register-username"></slot>
        <slot slot="register-password" name="register-password"></slot>
        <slot slot="register-email" name="register-email"></slot>
        <slot slot="password-reset-password" name="password-reset-password"></slot>
        <slot slot="password-reset-password-confirm" name="password-reset-password-confirm"></slot>
      </shreddit-signup-drawer>
    </template>
     
    
  
      
    <span slot="register-username" id="register-username-container"></span>
    <span slot="register-password" id="register-password-container"></span>
    <span slot="register-email" id="register-email-container"></span>
   
    <span slot="password-reset-password" id="password-reset-password-container">
    </span>
    <span slot="password-reset-password-confirm" id="password-reset-password-confirm-container">
    </span>
  
    </shreddit-overlay-display>
    
    
  
  <!-- routable page end --><faceplate-perfmetric-collector endpoint="/svc/shreddit/perfMetrics">
     <data value="first-contentful-paint"></data> <data value="time-to-first-byte"></data> <data value="largest-contentful-paint"></data> <data value="cumulative-layout-shift"></data>
  </faceplate-perfmetric-collector>  <shreddit-navtimings-collector endpoint="/svc/shreddit/perfMetrics">
  </shreddit-navtimings-collector>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ATProto for Distributed System Engineers (171 pts)]]></title>
            <link>https://atproto.com/articles/atproto-for-distsys-engineers</link>
            <guid>41484337</guid>
            <pubDate>Mon, 09 Sep 2024 00:04:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://atproto.com/articles/atproto-for-distsys-engineers">https://atproto.com/articles/atproto-for-distsys-engineers</a>, See on <a href="https://news.ycombinator.com/item?id=41484337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div>
<p><em>Sep 3, 2024</em></p>
<p>AT Protocol is the tech developed at <a href="https://bsky.app/">Bluesky</a> for open social networking. In this article we're going to explore AT Proto from the perspective of distributed backend engineering.</p>
<p>If you've ever built a backend with <a href="https://milinda.pathirage.org/kappa-architecture.com/">stream-processing</a>, then you're familiar with the kind of systems we'll be exploring. If you're not — no worries! We'll step through it.</p>

<p>The classic, happy Web architecture is the “one big SQL database” behind our app server. The app talks to the database and handles requests from the frontend.</p>
<p><img alt="" loading="lazy" width="1169" height="1600" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage1.c6dcf0c4.png&amp;w=1200&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage1.c6dcf0c4.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage1.c6dcf0c4.png&amp;w=3840&amp;q=75"></p>
<p>As our application grows, we hit some performance limits so we toss some caches into the stack.</p>
<p><img alt="" loading="lazy" width="1600" height="1229" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage2.693478de.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage2.693478de.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage2.693478de.png&amp;w=3840&amp;q=75"></p>
<p>Then let's say we scale our database horizontally through sharding and replicas.</p>
<p><img alt="" loading="lazy" width="1600" height="1457" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage3.88182e12.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage3.88182e12.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage3.88182e12.png&amp;w=3840&amp;q=75"></p>
<p>This is pretty good, but we're building a social network with hundreds of millions of users; even this model hits limits. The problem is that our SQL database is “<a href="https://en.wikipedia.org/wiki/Strong_consistency">strongly consistent</a>” which means the state is kept uniformly in sync across the system. Maintaining strong consistency incurs a performance cost which becomes our bottleneck.</p>
<p>If we can relax our system to use “<a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a>,” we can scale much further. We start by switching to a NoSQL cluster.</p>
<p><img alt="" loading="lazy" width="1600" height="1492" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage4.524d9b4a.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage4.524d9b4a.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage4.524d9b4a.png&amp;w=3840&amp;q=75"></p>
<p>This is better for scaling, but without SQL it's becoming harder to build our queries. It turns out that SQL databases have a lot of useful features, like JOIN and aggregation queries. In fact, our NoSQL database is really just a key-value store. Writing features is becoming a pain!</p>
<p>To fix this, we need to write programs which generate precomputed views of our dataset. These views are essentially like cached queries. We even duplicate the canonical data into these views so they're very fast.</p>
<p>We'll call these our View servers.</p>
<p><img alt="" loading="lazy" width="1378" height="1038" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage5.5e756a1a.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage5.5e756a1a.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage5.5e756a1a.png&amp;w=3840&amp;q=75"></p>
<p>Now we notice that keeping our view servers synced with the canonical data in the NoSQL cluster is tricky. Sometimes our view servers crash and miss updates. We need to make sure that our views stay reliably up-to-date.</p>
<p>To solve this, we introduce an event log (such as <a href="https://kafka.apache.org/">Kafka</a>). That log records and broadcasts all the changes to the NoSQL cluster. Our view servers listen to — and replay — that log to ensure they never miss an update, even when they need to restart.</p>
<p><img alt="" loading="lazy" width="1600" height="1183" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage6.9e038bff.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage6.9e038bff.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage6.9e038bff.png&amp;w=3840&amp;q=75"></p>
<p>We've now arrived at a <a href="https://milinda.pathirage.org/kappa-architecture.com/">stream processing architecture</a>, and while there are a lot more details we could cover, this is enough for now.</p>
<p>The good news is that this architecture scales pretty well. We've given up strong consistency and sometimes our read queries lag behind the most up to date version of the data, but the service doesn't drop writes or enter an incorrect state.</p>
<p>In a way, what we've done is custom-built a database by <a href="https://www.youtube.com/watch?v=fU9hR3kiOK0">turning it inside-out</a>. We simplified the canonical storage into a NoSQL cluster, and then built our own querying engine with the view servers. It's a lot less convenient to build with, but it scales.</p>

<p>The goal of AT Protocol is to interconnect applications so that their backends share state, including user accounts and content.</p>
<p>How can we do that? If we look at our diagram, we can see that most of the system is isolated from the outside world, with only the App server providing a public interface.</p>
<p><img alt="" loading="lazy" width="1600" height="1094" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage7.0e152275.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage7.0e152275.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage7.0e152275.png&amp;w=3840&amp;q=75"></p>
<p>Our goal is to break this isolation down so that other people can join our NoSQL cluster, our event log, our view servers, and so on.</p>
<p>Here's how it's going to look:</p>
<p><img alt="" loading="lazy" width="1600" height="1109" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage8.8cde2a8c.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage8.8cde2a8c.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage8.8cde2a8c.png&amp;w=3840&amp;q=75"></p>
<p>Each of these internal services are now external services. They have public APIs which anybody can consume. On top of that, anybody can create their own instances of these services.</p>
<p>Our goal is to make it so anybody can contribute to this decentralized backend. That means that we don't just want one NoSQL cluster, or one View server. We want lots of these servers working together. So really it's more like this:</p>
<p><img alt="" loading="lazy" width="1600" height="925" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage9.a51ae040.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage9.a51ae040.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage9.a51ae040.png&amp;w=3840&amp;q=75"></p>
<p>So how do we make all of these services work together?</p>

<p>We're going to establish a shared data model called the <a href="https://atproto.com/guides/data-repos">“user data repository.”</a></p>
<p><img alt="" loading="lazy" width="438" height="464" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage10.6817a213.png&amp;w=640&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage10.6817a213.png&amp;w=1080&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage10.6817a213.png&amp;w=1080&amp;q=75"></p>
<p>Every data repository contains JSON documents, which we'll call “records”.</p>
<p><img alt="" loading="lazy" width="838" height="554" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage11.4f73b780.png&amp;w=1080&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage11.4f73b780.png&amp;w=1920&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage11.4f73b780.png&amp;w=1920&amp;q=75"></p>
<p>For organizational purposes, we'll bucket these records into “collections.”</p>
<p><img alt="" loading="lazy" width="870" height="570" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage12.bd8affbd.png&amp;w=1080&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage12.bd8affbd.png&amp;w=1920&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage12.bd8affbd.png&amp;w=1920&amp;q=75"></p>
<p>Now we're going to opinionate our NoSQL services so they all use this <a href="https://atproto.com/guides/data-repos">data repository</a> model.</p>
<p><img alt="" loading="lazy" width="1600" height="1010" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage13.88b82924.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage13.88b82924.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage13.88b82924.png&amp;w=3840&amp;q=75"></p>
<p>Remember: the data repo services are still basically NoSQL stores, it's just that they're now organized in a very specific way:</p>
<ol>
<li>Each user has a data repository.</li>
<li>Each repository has collections.</li>
<li>Each collection is an ordered K/V store of JSON documents.</li>
</ol>
<p>Since the data repositories can be hosted by anybody, we need to give them <a href="https://atproto.com/specs/at-uri-scheme">URLs</a>.</p>
<p><img alt="" loading="lazy" width="380" height="354" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage14.47dc55b6.png&amp;w=384&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage14.47dc55b6.png&amp;w=828&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage14.47dc55b6.png&amp;w=828&amp;q=75"></p>
<p>While we're at it, let's create a <a href="https://atproto.com/specs/at-uri-scheme">whole URL scheme</a> for our records too.</p>
<p><img alt="" loading="lazy" width="816" height="600" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage15.b82b14bb.png&amp;w=828&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage15.b82b14bb.png&amp;w=1920&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage15.b82b14bb.png&amp;w=1920&amp;q=75"></p>
<p>Great! Also, since we're going to be syncing these records around the Internet, it would be a good idea to cryptographically sign them so that we know they're authentic.</p>
<p><img alt="" loading="lazy" width="1510" height="964" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage16.1d02511f.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage16.1d02511f.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage16.1d02511f.png&amp;w=3840&amp;q=75"></p>

<p>Now that we've set up our high-scale decentralized backend, let's map out how an application actually works on ATProto.</p>
<p>Since we're making a new app, we're going to want two things: an app server (which hosts our API &amp; frontend) and a view server (which collects data from the network for us). We often bundle the app &amp; view servers, and so we can just call it an “Appview.” Let's start there:</p>
<p><img alt="" loading="lazy" width="1294" height="876" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage17.bdea24e3.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage17.bdea24e3.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage17.bdea24e3.png&amp;w=3840&amp;q=75"></p>
<p>A user logs into our app using OAuth. In the process, they tell us which server hosts their data repository, <em>and</em> they give us permission to read and write to it.</p>
<p><img alt="" loading="lazy" width="1256" height="1338" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage18.5b6c97f8.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage18.5b6c97f8.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage18.5b6c97f8.png&amp;w=3840&amp;q=75"></p>
<p>We're off to a good start — we can read and write JSON documents in the user's repo. If they already have data from other apps (like a profile) we can read that data too. If we were building a singleplayer app, we'd already be done.</p>
<p>But let's chart what happens when we write a JSON document.</p>
<p><img alt="" loading="lazy" width="1600" height="1324" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage19.6cb5a9de.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage19.6cb5a9de.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage19.6cb5a9de.png&amp;w=3840&amp;q=75"></p>
<p>This commits the document to the repo, then fires off a write into the event logs which are listening to the repo.</p>
<p><img alt="" loading="lazy" width="1600" height="827" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage20.032fb864.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage20.032fb864.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage20.032fb864.png&amp;w=3840&amp;q=75"></p>
<p>From there, the event gets sent to any view services that are listening — including our own!</p>
<p><img alt="" loading="lazy" width="1600" height="846" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage21.d3fed181.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage21.d3fed181.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage21.d3fed181.png&amp;w=3840&amp;q=75"></p>
<p>Why are we listening to the event stream if we're the one making the write? Because we're not the only ones making writes! There are lots of user repos generating events, and lots of apps writing to them!</p>
<p><img alt="" loading="lazy" width="950" height="1250" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage22.da5edbc6.png&amp;w=1080&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage22.da5edbc6.png&amp;w=1920&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage22.da5edbc6.png&amp;w=1920&amp;q=75"></p>
<p>So we can see a kind of circular data flow throughout our decentralized backend, with writes being committed to the data repos, then emitted through the event logs into the view servers, where they can be read by our applications.</p>
<p><img alt="" loading="lazy" width="1600" height="1013" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage23.5342b3db.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage23.5342b3db.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage23.5342b3db.png&amp;w=3840&amp;q=75"></p>
<p>And (one hopes) that this network continues to scale: not just to add capacity, but to create a wider variety of applications sharing in this open applications network.</p>
<p><img loading="lazy" width="1504" height="1082" decoding="async" data-nimg="1" srcset="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage24.2111e734.png&amp;w=1920&amp;q=75 1x, https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage24.2111e734.png&amp;w=3840&amp;q=75 2x" src="https://atproto.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fimage24.2111e734.png&amp;w=3840&amp;q=75"></p>

<p>The AT Protocol merges p2p tech with high-scale systems practices. Our founding engineers were core <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> and <a href="https://en.wikipedia.org/wiki/Dat_(software)">Dat</a> engineers, and Martin Kleppmann — the author of <a href="https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/">Data Intensive Applications</a> — is an active technical advisor.</p>
<p>Before Bluesky was started, we established a clear requirement of “no steps backwards.” We wanted the network to feel as convenient and global as every social app before it, while still working as an open network. This is why, when we looked at federation and blockchains, the scaling limits of those architectures stood out to us. Our solution was to take standard practices for high scale backends, and then apply the techniques we used in peer-to-peer systems to create an open network.</p>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux's Bedtime Routine (137 pts)]]></title>
            <link>https://tookmund.com/2024/09/hibernation-preparation</link>
            <guid>41483789</guid>
            <pubDate>Sun, 08 Sep 2024 22:31:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tookmund.com/2024/09/hibernation-preparation">https://tookmund.com/2024/09/hibernation-preparation</a>, See on <a href="https://news.ycombinator.com/item?id=41483789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>How does Linux move from an awake machine to a hibernating one?
How does it then manage to restore all state?
These questions led me to read way too much C in trying to figure out
how this particular hardware/software boundary is navigated.</p>

<p>This investigation will be split into a few parts, with the first one going
from invocation of hibernation to synchronizing all filesystems to disk.</p>

<p>This article has been written using Linux version 6.9.9,
the source of which can be found in many places, but can be navigated
easily through the Bootlin Elixir Cross-Referencer:</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source">https://elixir.bootlin.com/linux/v6.9.9/source</a></p>

<p>Each code snippet will begin with a link to the above giving
the file path and the line number of the beginning of the snippet.</p>

<h2 id="a-starting-point-for-investigation-syspowerstate-and-syspowerdisk">A Starting Point for Investigation: <code>/sys/power/state</code> and <code>/sys/power/disk</code></h2>

<p>These two system files exist to <a href="https://www.kernel.org/doc/html/latest/power/basic-pm-debugging.html">allow debugging of hibernation</a>,
and thus control the exact state used directly.
Writing specific values to the <code>state</code> file controls the exact sleep mode used
and <code>disk</code> controls the specific hibernation mode<sup id="fnref:hibermode" role="doc-noteref"><a href="#fn:hibermode" rel="footnote">1</a></sup>.</p>

<p>This is extremely handy as an entry point to understand how these systems work,
since we can just follow what happens when they are written to.</p>

<h3 id="show-and-store-functions">Show and Store Functions</h3>
<p>These two files are defined using the <code>power_attr</code> macro:</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/power.h#L80">kernel/power/power.h:80</a></p>
<div><pre><code>#define power_attr(_name) \
static struct kobj_attribute _name##_attr = {   \
    .attr   = {             \
        .name = __stringify(_name), \
        .mode = 0644,           \
    },                  \
    .show   = _name##_show,         \
    .store  = _name##_store,        \
}
</code></pre></div>

<p><code>show</code> is called on reads and <code>store</code> on writes.</p>

<p><code>state_show</code> is a little boring for our purposes, as it just prints all the
available sleep states.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L657">kernel/power/main.c:657</a></p>
<div><pre><code>/*
 * state - control system sleep states.
 *
 * show() returns available sleep state labels, which may be "mem", "standby",
 * "freeze" and "disk" (hibernation).
 * See Documentation/admin-guide/pm/sleep-states.rst for a description of
 * what they mean.
 *
 * store() accepts one of those strings, translates it into the proper
 * enumerated value, and initiates a suspend transition.
 */
static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
			  char *buf)
{
	char *s = buf;
#ifdef CONFIG_SUSPEND
	suspend_state_t i;

	for (i = PM_SUSPEND_MIN; i &lt; PM_SUSPEND_MAX; i++)
		if (pm_states[i])
			s += sprintf(s,"%s ", pm_states[i]);

#endif
	if (hibernation_available())
		s += sprintf(s, "disk ");
	if (s != buf)
		/* convert the last space to a newline */
		*(s-1) = '\n';
	return (s - buf);
}
</code></pre></div>

<p><code>state_store</code>, however, provides our entry point.
If the string “disk” is written to the <code>state</code> file, it calls <code>hibernate()</code>.
This is our entry point.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L715">kernel/power/main.c:715</a></p>
<div><pre><code>static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
			   const char *buf, size_t n)
{
	suspend_state_t state;
	int error;

	error = pm_autosleep_lock();
	if (error)
		return error;

	if (pm_autosleep_state() &gt; PM_SUSPEND_ON) {
		error = -EBUSY;
		goto out;
	}

	state = decode_state(buf, n);
	if (state &lt; PM_SUSPEND_MAX) {
		if (state == PM_SUSPEND_MEM)
			state = mem_sleep_current;

		error = pm_suspend(state);
	} else if (state == PM_SUSPEND_MAX) {
		error = hibernate();
	} else {
		error = -EINVAL;
	}

 out:
	pm_autosleep_unlock();
	return error ? error : n;
}
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L688">kernel/power/main.c:688</a></p>
<div><pre><code>static suspend_state_t decode_state(const char *buf, size_t n)
{
#ifdef CONFIG_SUSPEND
	suspend_state_t state;
#endif
	char *p;
	int len;

	p = memchr(buf, '\n', n);
	len = p ? p - buf : n;

	/* Check hibernation first. */
	if (len == 4 &amp;&amp; str_has_prefix(buf, "disk"))
		return PM_SUSPEND_MAX;

#ifdef CONFIG_SUSPEND
	for (state = PM_SUSPEND_MIN; state &lt; PM_SUSPEND_MAX; state++) {
		const char *label = pm_states[state];

		if (label &amp;&amp; len == strlen(label) &amp;&amp; !strncmp(buf, label, len))
			return state;
	}
#endif

	return PM_SUSPEND_ON;
}
</code></pre></div>

<p>Could we have figured this out just via function names?
Sure, but this way we know for sure that nothing else is happening before this
function is called.</p>

<h3 id="autosleep">Autosleep</h3>

<p>Our first detour is into the autosleep system.
When checking the state above, you may notice that
the kernel grabs the <code>pm_autosleep_lock</code> before checking the current
state.</p>

<p>autosleep is a mechanism <a href="https://lwn.net/Articles/479841/">originally from Android</a>
that sends the entire system to either suspend or hibernate whenever it is
not actively working on anything.</p>

<p>This is not enabled for most desktop configurations, since it’s primarily
for mobile systems and inverts the standard suspend and hibernate interactions.</p>

<p>This system is implemented as a workqueue<sup id="fnref:workqueue" role="doc-noteref"><a href="#fn:workqueue" rel="footnote">2</a></sup>
that checks the current number of wakeup events, processes and drivers that
need to run<sup id="fnref:wakeupevent" role="doc-noteref"><a href="#fn:wakeupevent" rel="footnote">3</a></sup>, and if there aren’t any, then the system is put
into the autosleep state, typically suspend. However, it could be hibernate if
configured that way via <code>/sys/power/autosleep</code> in a similar manner to
using <code>/sys/power/state</code> to manually enable hibernation.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L841">kernel/power/main.c:841</a></p>
<div><pre><code>static ssize_t autosleep_store(struct kobject *kobj,
			       struct kobj_attribute *attr,
			       const char *buf, size_t n)
{
	suspend_state_t state = decode_state(buf, n);
	int error;

	if (state == PM_SUSPEND_ON
	    &amp;&amp; strcmp(buf, "off") &amp;&amp; strcmp(buf, "off\n"))
		return -EINVAL;

	if (state == PM_SUSPEND_MEM)
		state = mem_sleep_current;

	error = pm_autosleep_set_state(state);
	return error ? error : n;
}

power_attr(autosleep);
#endif /* CONFIG_PM_AUTOSLEEP */
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/autosleep.c#L24">kernel/power/autosleep.c:24</a></p>
<div><pre><code>static DEFINE_MUTEX(autosleep_lock);
static struct wakeup_source *autosleep_ws;

static void try_to_suspend(struct work_struct *work)
{
	unsigned int initial_count, final_count;

	if (!pm_get_wakeup_count(&amp;initial_count, true))
		goto out;

	mutex_lock(&amp;autosleep_lock);

	if (!pm_save_wakeup_count(initial_count) ||
		system_state != SYSTEM_RUNNING) {
		mutex_unlock(&amp;autosleep_lock);
		goto out;
	}

	if (autosleep_state == PM_SUSPEND_ON) {
		mutex_unlock(&amp;autosleep_lock);
		return;
	}
	if (autosleep_state &gt;= PM_SUSPEND_MAX)
		hibernate();
	else
		pm_suspend(autosleep_state);

	mutex_unlock(&amp;autosleep_lock);

	if (!pm_get_wakeup_count(&amp;final_count, false))
		goto out;

	/*
	 * If the wakeup occurred for an unknown reason, wait to prevent the
	 * system from trying to suspend and waking up in a tight loop.
	 */
	if (final_count == initial_count)
		schedule_timeout_uninterruptible(HZ / 2);

 out:
	queue_up_suspend_work();
}

static DECLARE_WORK(suspend_work, try_to_suspend);

void queue_up_suspend_work(void)
{
	if (autosleep_state &gt; PM_SUSPEND_ON)
		queue_work(autosleep_wq, &amp;suspend_work);
}
</code></pre></div>

<h2 id="the-steps-of-hibernation">The Steps of Hibernation</h2>

<h3 id="hibernation-kernel-config">Hibernation Kernel Config</h3>

<p>It’s important to note that most of the hibernate-specific functions below
do nothing unless you’ve defined <code>CONFIG_HIBERNATION</code> in your Kconfig<sup id="fnref:kconfig" role="doc-noteref"><a href="#fn:kconfig" rel="footnote">4</a></sup>.
As an example, <code>hibernate</code> itself is defined as the following if
<code>CONFIG_HIBERNATE</code> is not set.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/suspend.h#L407">include/linux/suspend.h:407</a></p>
<div><pre><code>static inline int hibernate(void) { return -ENOSYS; }
</code></pre></div>

<h3 id="check-if-hibernation-is-available">Check if Hibernation is Available</h3>
<p>We begin by confirming that we actually can perform hibernation,
via the <code>hibernation_available</code> function.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L742">kernel/power/hibernate.c:742</a></p>
<div><pre><code>if (!hibernation_available()) {
	pm_pr_dbg("Hibernation not available.\n");
	return -EPERM;
}
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L92">kernel/power/hibernate.c:92</a></p>
<div><pre><code>bool hibernation_available(void)
{
	return nohibernate == 0 &amp;&amp;
		!security_locked_down(LOCKDOWN_HIBERNATION) &amp;&amp;
		!secretmem_active() &amp;&amp; !cxl_mem_active();
}
</code></pre></div>

<p><code>nohibernate</code> is controlled by the kernel command line, it’s set via
either <code>nohibernate</code> or <code>hibernate=no</code>.</p>

<p><code>security_locked_down</code> is a hook for Linux Security Modules to prevent
hibernation. This is used to prevent hibernating to an unencrypted storage
device, as specified in the manual page
<a href="https://man7.org/linux/man-pages/man7/kernel_lockdown.7.html"><code>kernel_lockdown(7)</code></a>.
Interestingly, either level of lockdown, integrity or confidentiality,
locks down hibernation because with the ability to hibernate you can extract
bascially anything from memory and even reboot into a modified kernel image.</p>

<p><code>secretmem_active</code> checks whether there is any active use of
<code>memfd_secret</code>, and if so it prevents hibernation.
<code>memfd_secret</code> returns a file descriptor that can be mapped into a process
but is specifically unmapped from the kernel’s memory space.
Hibernating with memory that not even the kernel is supposed to
access would expose that memory to whoever could access the hibernation image.
This particular feature of secret memory was apparently
<a href="https://lwn.net/Articles/865256/">controversial</a>, though not as
controversial as performance concerns around fragmentation when unmapping
kernel memory
(<a href="https://lwn.net/Articles/865256/">which did not end up being a real problem</a>).</p>

<p><code>cxl_mem_active</code> just checks whether any CXL memory is active.
A full explanation is provided in the
<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=9ea4dcf49878bb9546b8fa9319dcbdc9b7ee20f8">commit introducing this check</a>
but there’s also a shortened explanation from <code>cxl_mem_probe</code> that
sets the relevant flag when initializing a CXL memory device.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/cxl/mem.c#L186">drivers/cxl/mem.c:186</a></p>
<div><pre><code>* The kernel may be operating out of CXL memory on this device,
* there is no spec defined way to determine whether this device
* preserves contents over suspend, and there is no simple way
* to arrange for the suspend image to avoid CXL memory which
* would setup a circular dependency between PCI resume and save
* state restoration.
</code></pre></div>

<h3 id="check-compression">Check Compression</h3>

<p>The next check is for whether compression support is enabled, and if so
whether the requested algorithm is enabled.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L747">kernel/power/hibernate.c:747</a></p>
<div><pre><code>/*
 * Query for the compression algorithm support if compression is enabled.
 */
if (!nocompress) {
	strscpy(hib_comp_algo, hibernate_compressor, sizeof(hib_comp_algo));
	if (crypto_has_comp(hib_comp_algo, 0, 0) != 1) {
		pr_err("%s compression is not available\n", hib_comp_algo);
		return -EOPNOTSUPP;
	}
}
</code></pre></div>

<p>The <code>nocompress</code> flag is set via the <code>hibernate</code> command line parameter,
setting <code>hibernate=nocompress</code>.</p>

<p>If compression is enabled, then <code>hibernate_compressor</code> is copied to
<code>hib_comp_algo</code>. This synchronizes the current requested compression
setting (<code>hibernate_compressor</code>) with the current compression setting
(<code>hib_comp_algo</code>).</p>

<p>Both values are character arrays of size <code>CRYPTO_MAX_ALG_NAME</code>
(128 in this kernel).</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L50">kernel/power/hibernate.c:50</a></p>
<div><pre><code>static char hibernate_compressor[CRYPTO_MAX_ALG_NAME] = CONFIG_HIBERNATION_DEF_COMP;

/*
 * Compression/decompression algorithm to be used while saving/loading
 * image to/from disk. This would later be used in 'kernel/power/swap.c'
 * to allocate comp streams.
 */
char hib_comp_algo[CRYPTO_MAX_ALG_NAME];
</code></pre></div>

<p><code>hibernate_compressor</code> defaults to <code>lzo</code> if that algorithm is enabled, otherwise to <code>lz4</code> if
enabled<sup id="fnref:choicedefault" role="doc-noteref"><a href="#fn:choicedefault" rel="footnote">5</a></sup>. It can be overwritten using the <code>hibernate.compressor</code> setting to
either <code>lzo</code> or <code>lz4</code>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/Kconfig#L95">kernel/power/Kconfig:95</a></p>
<div><pre><code>choice
	prompt "Default compressor"
	default HIBERNATION_COMP_LZO
	depends on HIBERNATION

config HIBERNATION_COMP_LZO
	bool "lzo"
	depends on CRYPTO_LZO

config HIBERNATION_COMP_LZ4
	bool "lz4"
	depends on CRYPTO_LZ4

endchoice

config HIBERNATION_DEF_COMP
	string
	default "lzo" if HIBERNATION_COMP_LZO
	default "lz4" if HIBERNATION_COMP_LZ4
	help
	  Default compressor to be used for hibernation.
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L1425">kernel/power/hibernate.c:1425</a></p>
<div><pre><code>static const char * const comp_alg_enabled[] = {
#if IS_ENABLED(CONFIG_CRYPTO_LZO)
	COMPRESSION_ALGO_LZO,
#endif
#if IS_ENABLED(CONFIG_CRYPTO_LZ4)
	COMPRESSION_ALGO_LZ4,
#endif
};

static int hibernate_compressor_param_set(const char *compressor,
		const struct kernel_param *kp)
{
	unsigned int sleep_flags;
	int index, ret;

	sleep_flags = lock_system_sleep();

	index = sysfs_match_string(comp_alg_enabled, compressor);
	if (index &gt;= 0) {
		ret = param_set_copystring(comp_alg_enabled[index], kp);
		if (!ret)
			strscpy(hib_comp_algo, comp_alg_enabled[index],
				sizeof(hib_comp_algo));
	} else {
		ret = index;
	}

	unlock_system_sleep(sleep_flags);

	if (ret)
		pr_debug("Cannot set specified compressor %s\n",
			 compressor);

	return ret;
}
static const struct kernel_param_ops hibernate_compressor_param_ops = {
	.set    = hibernate_compressor_param_set,
	.get    = param_get_string,
};

static struct kparam_string hibernate_compressor_param_string = {
	.maxlen = sizeof(hibernate_compressor),
	.string = hibernate_compressor,
};
</code></pre></div>

<p>We then check whether the requested algorithm is supported via <code>crypto_has_comp</code>.
If not, we bail out of the whole operation with <code>EOPNOTSUPP</code>.</p>

<p>As part of <code>crypto_has_comp</code> we perform any needed initialization of the
algorithm, loading kernel modules and running initialization code as needed<sup id="fnref:larval" role="doc-noteref"><a href="#fn:larval" rel="footnote">6</a></sup>.</p>

<h3 id="grab-locks">Grab Locks</h3>

<p>The next step is to grab the sleep and hibernation locks via
<code>lock_system_sleep</code> and <code>hibernate_acquire</code>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L758">kernel/power/hibernate.c:758</a></p>
<div><pre><code>sleep_flags = lock_system_sleep();
/* The snapshot device should not be opened while we're running */
if (!hibernate_acquire()) {
	error = -EBUSY;
	goto Unlock;
}
</code></pre></div>

<p>First, <code>lock_system_sleep</code> marks the current thread as not freezable, which
will be important later<sup id="fnref:procfreeze" role="doc-noteref"><a href="#fn:procfreeze" rel="footnote">7</a></sup>. It then grabs the <code>system_transistion_mutex</code>,
which locks taking snapshots or modifying how they are taken,
resuming from a hibernation image, entering any suspend state, or rebooting.</p>

<h4 id="the-gfp-mask">The GFP Mask</h4>
<p>The kernel also issues a warning if the <code>gfp</code> mask is changed via either
<code>pm_restore_gfp_mask</code> or <code>pm_restrict_gfp_mask</code>
without holding the <code>system_transistion_mutex</code>.</p>

<p>GFP flags tell the kernel how it is permitted to handle a request for memory.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/gfp_types.h#L12">include/linux/gfp_types.h:12</a></p>
<div><pre><code> * GFP flags are commonly used throughout Linux to indicate how memory
 * should be allocated.  The GFP acronym stands for get_free_pages(),
 * the underlying memory allocation function.  Not every GFP flag is
 * supported by every function which may allocate memory.
</code></pre></div>

<p>In the case of hibernation specifically we care about the <code>IO</code> and <code>FS</code> flags,
which are reclaim operators, ways the system is permitted to attempt to free
up memory in order to satisfy a specific request for memory.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/gfp_types.h#L176">include/linux/gfp_types.h:176</a></p>
<div><pre><code> * Reclaim modifiers
 * -----------------
 * Please note that all the following flags are only applicable to sleepable
 * allocations (e.g. %GFP_NOWAIT and %GFP_ATOMIC will ignore them).
 *
 * %__GFP_IO can start physical IO.
 *
 * %__GFP_FS can call down to the low-level FS. Clearing the flag avoids the
 * allocator recursing into the filesystem which might already be holding
 * locks.
</code></pre></div>

<p><code>gfp_allowed_mask</code> sets which flags are permitted to be set at the current time.</p>

<p>As the comment below outlines, preventing these flags from being set
avoids situations where the kernel needs to do I/O to allocate memory
(e.g. read/writing swap<sup id="fnref:swap" role="doc-noteref"><a href="#fn:swap" rel="footnote">8</a></sup>) but the
devices it needs to read/write to/from are not currently available.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L24">kernel/power/main.c:24</a></p>
<div><pre><code>/*
 * The following functions are used by the suspend/hibernate code to temporarily
 * change gfp_allowed_mask in order to avoid using I/O during memory allocations
 * while devices are suspended.  To avoid races with the suspend/hibernate code,
 * they should always be called with system_transition_mutex held
 * (gfp_allowed_mask also should only be modified with system_transition_mutex
 * held, unless the suspend/hibernate code is guaranteed not to run in parallel
 * with that modification).
 */
static gfp_t saved_gfp_mask;

void pm_restore_gfp_mask(void)
{
	WARN_ON(!mutex_is_locked(&amp;system_transition_mutex));
	if (saved_gfp_mask) {
		gfp_allowed_mask = saved_gfp_mask;
		saved_gfp_mask = 0;
	}
}

void pm_restrict_gfp_mask(void)
{
	WARN_ON(!mutex_is_locked(&amp;system_transition_mutex));
	WARN_ON(saved_gfp_mask);
	saved_gfp_mask = gfp_allowed_mask;
	gfp_allowed_mask &amp;= ~(__GFP_IO | __GFP_FS);
}
</code></pre></div>

<h4 id="sleep-flags">Sleep Flags</h4>
<p>After grabbing the <code>system_transition_mutex</code> the kernel then returns and
captures the previous state of the threads flags in <code>sleep_flags</code>.
This is used later to remove <code>PF_NOFREEZE</code> if it wasn’t previously set on the
current thread.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L52">kernel/power/main.c:52</a></p>
<div><pre><code>unsigned int lock_system_sleep(void)
{
	unsigned int flags = current-&gt;flags;
	current-&gt;flags |= PF_NOFREEZE;
	mutex_lock(&amp;system_transition_mutex);
	return flags;
}
EXPORT_SYMBOL_GPL(lock_system_sleep);
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/sched.h#L1633">include/linux/sched.h:1633</a></p>
<div><pre><code>#define PF_NOFREEZE		0x00008000	/* This thread should not be frozen */
</code></pre></div>

<p>Then we grab the hibernate-specific semaphore to ensure no one can open a
snapshot or resume from it while we perform hibernation.
Additionally this lock is used to prevent <code>hibernate_quiet_exec</code>,
which is used by the <code>nvdimm</code> driver to active its firmware with all
processes and devices frozen, ensuring it is the only thing running at that
time<sup id="fnref:nvdimm" role="doc-noteref"><a href="#fn:nvdimm" rel="footnote">9</a></sup>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L82">kernel/power/hibernate.c:82</a></p>
<div><pre><code>bool hibernate_acquire(void)
{
	return atomic_add_unless(&amp;hibernate_atomic, -1, 0);
}
</code></pre></div>

<h3 id="prepare-console">Prepare Console</h3>
<p>The kernel next calls <code>pm_prepare_console</code>.
This function only does anything if <code>CONFIG_VT_CONSOLE_SLEEP</code> has been set.</p>

<p>This prepares the virtual terminal for a suspend state, switching away to
a console used only for the suspend state if needed.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/console.c#L130">kernel/power/console.c:130</a></p>
<div><pre><code>void pm_prepare_console(void)
{
	if (!pm_vt_switch())
		return;

	orig_fgconsole = vt_move_to_console(SUSPEND_CONSOLE, 1);
	if (orig_fgconsole &lt; 0)
		return;

	orig_kmsg = vt_kmsg_redirect(SUSPEND_CONSOLE);
	return;
}
</code></pre></div>

<p>The first thing is to check whether we actually need to switch the VT</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/console.c#L94">kernel/power/console.c:94</a></p>
<div><pre><code>/*
 * There are three cases when a VT switch on suspend/resume are required:
 *   1) no driver has indicated a requirement one way or another, so preserve
 *      the old behavior
 *   2) console suspend is disabled, we want to see debug messages across
 *      suspend/resume
 *   3) any registered driver indicates it needs a VT switch
 *
 * If none of these conditions is present, meaning we have at least one driver
 * that doesn't need the switch, and none that do, we can avoid it to make
 * resume look a little prettier (and suspend too, but that's usually hidden,
 * e.g. when closing the lid on a laptop).
 */
static bool pm_vt_switch(void)
{
	struct pm_vt_switch *entry;
	bool ret = true;

	mutex_lock(&amp;vt_switch_mutex);
	if (list_empty(&amp;pm_vt_switch_list))
		goto out;

	if (!console_suspend_enabled)
		goto out;

	list_for_each_entry(entry, &amp;pm_vt_switch_list, head) {
		if (entry-&gt;required)
			goto out;
	}

	ret = false;
out:
	mutex_unlock(&amp;vt_switch_mutex);
	return ret;
}
</code></pre></div>

<p>There is an explanation of the conditions under which a switch is performed
in the comment above the function, but we’ll also walk through the steps here.</p>

<p>Firstly we grab the <code>vt_switch_mutex</code> to ensure nothing will modify the list
while we’re looking at it.</p>

<p>We then examine the <code>pm_vt_switch_list</code>.
This list is used to indicate the drivers that require a switch during suspend.
They register this requirement, or the lack thereof, via
<code>pm_vt_switch_required</code>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/console.c#L31">kernel/power/console.c:31</a></p>
<div><pre><code>/**
 * pm_vt_switch_required - indicate VT switch at suspend requirements
 * @dev: device
 * @required: if true, caller needs VT switch at suspend/resume time
 *
 * The different console drivers may or may not require VT switches across
 * suspend/resume, depending on how they handle restoring video state and
 * what may be running.
 *
 * Drivers can indicate support for switchless suspend/resume, which can
 * save time and flicker, by using this routine and passing 'false' as
 * the argument.  If any loaded driver needs VT switching, or the
 * no_console_suspend argument has been passed on the command line, VT
 * switches will occur.
 */
void pm_vt_switch_required(struct device *dev, bool required)
</code></pre></div>

<p>Next, we check <code>console_suspend_enabled</code>. This is set to false
by the kernel parameter <code>no_console_suspend</code>, but defaults to true.</p>

<p>Finally, if there are any entries in the <code>pm_vt_switch_list</code>, then we
check to see if any of them require a VT switch.</p>

<p>Only if none of these conditions apply, then we return false.</p>

<p>If a VT switch is in fact required, then we move first the currently active
virtual terminal/console<sup id="fnref:console" role="doc-noteref"><a href="#fn:console" rel="footnote">10</a></sup> (<code>vt_move_to_console</code>)
and then the current location of kernel messages (<code>vt_kmsg_redirect</code>)
to the <code>SUSPEND_CONSOLE</code>.
The <code>SUSPEND_CONSOLE</code> is the last entry in the list of possible
consoles, and appears to just be a black hole to throw away messages.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/console.c#L16">kernel/power/console.c:16</a></p>
<div><pre><code>#define SUSPEND_CONSOLE	(MAX_NR_CONSOLES-1)
</code></pre></div>

<p>Interestingly, these are separate functions because you can use
<code>TIOCL_SETKMSGREDIRECT</code> (an <code>ioctl</code><sup id="fnref:ioctl" role="doc-noteref"><a href="#fn:ioctl" rel="footnote">11</a></sup>) to send kernel messages to a specific virtual terminal,
but by default its the same as the currently active console.</p>

<p>The locations of the previously active console and the previous kernel
messages location are stored in <code>orig_fgconsole</code> and <code>orig_kmsg</code>, to
restore the state of the console and kernel messages after the machine wakes
up again.
Interestingly, this means <code>orig_fgconsole</code> also ends up storing any errors,
so has to be checked to ensure it’s not less than zero before we try to do
anything with the kernel messages on both suspend and resume.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt_ioctl.c#L1268">drivers/tty/vt/vt_ioctl.c:1268</a></p>
<div><pre><code>/* Perform a kernel triggered VT switch for suspend/resume */

static int disable_vt_switch;

int vt_move_to_console(unsigned int vt, int alloc)
{
	int prev;

	console_lock();
	/* Graphics mode - up to X */
	if (disable_vt_switch) {
		console_unlock();
		return 0;
	}
	prev = fg_console;

	if (alloc &amp;&amp; vc_allocate(vt)) {
		/* we can't have a free VC for now. Too bad,
		 * we don't want to mess the screen for now. */
		console_unlock();
		return -ENOSPC;
	}

	if (set_console(vt)) {
		/*
		 * We're unable to switch to the SUSPEND_CONSOLE.
		 * Let the calling function know so it can decide
		 * what to do.
		 */
		console_unlock();
		return -EIO;
	}
	console_unlock();
	if (vt_waitactive(vt + 1)) {
		pr_debug("Suspend: Can't switch VCs.");
		return -EINTR;
	}
	return prev;
}
</code></pre></div>

<p>Unlike most other locking functions we’ve seen so far, <code>console_lock</code>
needs to be careful to ensure nothing else is panicking and needs to
dump to the console before grabbing the semaphore for the console
and setting a couple flags.</p>

<h4 id="panics">Panics</h4>
<p>Panics are tracked via an atomic integer set to the id of the processor
currently panicking.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/printk/printk.c#L2649">kernel/printk/printk.c:2649</a></p>
<div><pre><code>/**
 * console_lock - block the console subsystem from printing
 *
 * Acquires a lock which guarantees that no consoles will
 * be in or enter their write() callback.
 *
 * Can sleep, returns nothing.
 */
void console_lock(void)
{
	might_sleep();

	/* On panic, the console_lock must be left to the panic cpu. */
	while (other_cpu_in_panic())
		msleep(1000);

	down_console_sem();
	console_locked = 1;
	console_may_schedule = 1;
}
EXPORT_SYMBOL(console_lock);
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/printk/printk.c#L362">kernel/printk/printk.c:362</a></p>
<div><pre><code>/*
 * Return true if a panic is in progress on a remote CPU.
 *
 * On true, the local CPU should immediately release any printing resources
 * that may be needed by the panic CPU.
 */
bool other_cpu_in_panic(void)
{
	return (panic_in_progress() &amp;&amp; !this_cpu_in_panic());
}
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/printk/printk.c#L345">kernel/printk/printk.c:345</a></p>
<div><pre><code>static bool panic_in_progress(void)
{
	return unlikely(atomic_read(&amp;panic_cpu) != PANIC_CPU_INVALID);
}
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/printk/printk.c#L350">kernel/printk/printk.c:350</a></p>
<div><pre><code>/* Return true if a panic is in progress on the current CPU. */
bool this_cpu_in_panic(void)
{
	/*
	 * We can use raw_smp_processor_id() here because it is impossible for
	 * the task to be migrated to the panic_cpu, or away from it. If
	 * panic_cpu has already been set, and we're not currently executing on
	 * that CPU, then we never will be.
	 */
	return unlikely(atomic_read(&amp;panic_cpu) == raw_smp_processor_id());
}
</code></pre></div>

<p><code>console_locked</code> is a debug value, used to indicate that the lock should be
held, and our first indication that this whole virtual terminal system is
more complex than might initially be expected.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/printk/printk.c#L373">kernel/printk/printk.c:373</a></p>
<div><pre><code>/*
 * This is used for debugging the mess that is the VT code by
 * keeping track if we have the console semaphore held. It's
 * definitely not the perfect debug tool (we don't know if _WE_
 * hold it and are racing, but it helps tracking those weird code
 * paths in the console code where we end up in places I want
 * locked without the console semaphore held).
 */
static int console_locked;
</code></pre></div>

<p><code>console_may_schedule</code> is used to see if we are permitted to sleep
and schedule other work while we hold this lock.
As we’ll see later, the virtual terminal subsystem is not re-entrant,
so there’s all sorts of hacks in here to ensure we don’t leave important
code sections that can’t be safely resumed.</p>

<h4 id="disable-vt-switch">Disable VT Switch</h4>
<p>As the comment below lays out, when another program is handling graphical
display anyway, there’s no need to do any of this, so the kernel provides
a switch to turn the whole thing off.
Interestingly, this appears to only be used by three drivers,
so the specific hardware support required must not be particularly common.</p>
<div><pre><code>drivers/gpu/drm/omapdrm/dss
drivers/video/fbdev/geode
drivers/video/fbdev/omap2
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt_ioctl.c#L1308">drivers/tty/vt/vt_ioctl.c:1308</a></p>
<div><pre><code>/*
 * Normally during a suspend, we allocate a new console and switch to it.
 * When we resume, we switch back to the original console.  This switch
 * can be slow, so on systems where the framebuffer can handle restoration
 * of video registers anyways, there's little point in doing the console
 * switch.  This function allows you to disable it by passing it '0'.
 */
void pm_set_vt_switch(int do_switch)
{
	console_lock();
	disable_vt_switch = !do_switch;
	console_unlock();
}
EXPORT_SYMBOL(pm_set_vt_switch);
</code></pre></div>

<p>The rest of the <code>vt_switch_console</code> function is pretty normal,
however, simply allocating space if needed to create the requested
virtual terminal
and then setting the current virtual terminal via <code>set_console</code>.</p>

<h4 id="virtual-terminal-set-console">Virtual Terminal Set Console</h4>
<p>With <code>set_console</code>, we begin (as if we haven’t been already) to enter the
madness that is the virtual terminal subsystem.
As mentioned previously, modifications to its state must be made very
carefully, as other stuff happening at the same time could create complete
messes.</p>

<p>All this to say, calling <code>set_console</code> does not actually perform any
work to change the state of the current console.
Instead it indicates what changes it wants and then schedules that work.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt.c#L3153">drivers/tty/vt/vt.c:3153</a></p>
<div><pre><code>int set_console(int nr)
{
	struct vc_data *vc = vc_cons[fg_console].d;

	if (!vc_cons_allocated(nr) || vt_dont_switch ||
		(vc-&gt;vt_mode.mode == VT_AUTO &amp;&amp; vc-&gt;vc_mode == KD_GRAPHICS)) {

		/*
		 * Console switch will fail in console_callback() or
		 * change_console() so there is no point scheduling
		 * the callback
		 *
		 * Existing set_console() users don't check the return
		 * value so this shouldn't break anything
		 */
		return -EINVAL;
	}

	want_console = nr;
	schedule_console_callback();

	return 0;
}
</code></pre></div>

<p>The check for <code>vc-&gt;vc_mode == KD_GRAPHICS</code> is where most end-user graphical
desktops will bail out of this change, as they’re in graphics mode and don’t
need to switch away to the suspend console.</p>

<p><code>vt_dont_switch</code> is a flag used by the <code>ioctl</code>s<sup id="fnref:ioctl:1" role="doc-noteref"><a href="#fn:ioctl" rel="footnote">11</a></sup> <code>VT_LOCKSWITCH</code> and
<code>VT_UNLOCKSWITCH</code> to prevent the system from switching virtual terminal
devices when the user has explicitly locked it.</p>

<p><code>VT_AUTO</code> is a flag indicating that automatic virtual terminal switching is enabled<sup id="fnref:vtauto" role="doc-noteref"><a href="#fn:vtauto" rel="footnote">12</a></sup>,
and thus deliberate switching to a suspend terminal is not required.</p>

<p>However, if you do run your machine from a virtual terminal, then we
indicate to the system that we want to change to the requested virtual terminal
via the <code>want_console</code> variable
and schedule a callback via <code>schedule_console_callback</code>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt.c#L315">drivers/tty/vt/vt.c:315</a></p>
<div><pre><code>void schedule_console_callback(void)
{
	schedule_work(&amp;console_work);
}
</code></pre></div>

<p><code>console_work</code> is a workqueue<sup id="fnref:workqueue:1" role="doc-noteref"><a href="#fn:workqueue" rel="footnote">2</a></sup> that will execute the given task asynchronously.</p>

<h4 id="console-callback">Console Callback</h4>
<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt.c#L3109">drivers/tty/vt/vt.c:3109</a></p>
<div><pre><code>/*
 * This is the console switching callback.
 *
 * Doing console switching in a process context allows
 * us to do the switches asynchronously (needed when we want
 * to switch due to a keyboard interrupt).  Synchronization
 * with other console code and prevention of re-entrancy is
 * ensured with console_lock.
 */
static void console_callback(struct work_struct *ignored)
{
	console_lock();

	if (want_console &gt;= 0) {
		if (want_console != fg_console &amp;&amp;
		    vc_cons_allocated(want_console)) {
			hide_cursor(vc_cons[fg_console].d);
			change_console(vc_cons[want_console].d);
			/* we only changed when the console had already
			   been allocated - a new console is not created
			   in an interrupt routine */
		}
		want_console = -1;
	}
...
</code></pre></div>

<p><code>console_callback</code> first looks to see if there is a console change wanted
via <code>want_console</code> and then changes to it if it’s not the current console and
has been allocated already.
We do first remove any cursor state with <code>hide_cursor</code>.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/drivers/tty/vt/vt.c#L841">drivers/tty/vt/vt.c:841</a></p>
<div><pre><code>static void hide_cursor(struct vc_data *vc)
{
	if (vc_is_sel(vc))
		clear_selection();

	vc-&gt;vc_sw-&gt;con_cursor(vc, false);
	hide_softcursor(vc);
}
</code></pre></div>

<p>A full dive into the <code>tty</code> driver is a task for another time, but this
should give a general sense of how this system interacts with hibernation.</p>

<h3 id="notify-power-management-call-chain">Notify Power Management Call Chain</h3>
<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/hibernate.c#L767">kernel/power/hibernate.c:767</a></p>
<div><pre><code>pm_notifier_call_chain_robust(PM_HIBERNATION_PREPARE, PM_POST_HIBERNATION)
</code></pre></div>

<p>This will call a chain of power management callbacks, passing first
<code>PM_HIBERNATION_PREPARE</code> and then <code>PM_POST_HIBERNATION</code> on startup or
on error with another callback.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L98">kernel/power/main.c:98</a></p>
<div><pre><code>int pm_notifier_call_chain_robust(unsigned long val_up, unsigned long val_down)
{
	int ret;

	ret = blocking_notifier_call_chain_robust(&amp;pm_chain_head, val_up, val_down, NULL);

	return notifier_to_errno(ret);
}
</code></pre></div>
<p>The power management notifier is a blocking notifier chain, which means it
has the following properties.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/notifier.h#L23">include/linux/notifier.h:23</a></p>
<div><pre><code> *	Blocking notifier chains: Chain callbacks run in process context.
 *		Callouts are allowed to block.
</code></pre></div>
<p>The callback chain is a linked list with each entry containing a priority
and a function to call. The function technically takes in a data value,
but it is always <code>NULL</code> for the power management chain.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/notifier.h#L49">include/linux/notifier.h:49</a></p>
<div><pre><code>struct notifier_block;

typedef	int (*notifier_fn_t)(struct notifier_block *nb,
			unsigned long action, void *data);

struct notifier_block {
	notifier_fn_t notifier_call;
	struct notifier_block __rcu *next;
	int priority;
};
</code></pre></div>

<p>The head of the linked list is protected by a read-write semaphore.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/notifier.h#L65">include/linux/notifier.h:65</a></p>
<div><pre><code>struct blocking_notifier_head {
	struct rw_semaphore rwsem;
	struct notifier_block __rcu *head;
};
</code></pre></div>

<p>Because it is prioritized, appending to the list requires walking it until
an item with lower<sup id="fnref:priority" role="doc-noteref"><a href="#fn:priority" rel="footnote">13</a></sup> priority is found to insert the current item before.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/notifier.c#L252">kernel/notifier.c:252</a></p>
<div><pre><code>/*
 *	Blocking notifier chain routines.  All access to the chain is
 *	synchronized by an rwsem.
 */

static int __blocking_notifier_chain_register(struct blocking_notifier_head *nh,
					      struct notifier_block *n,
					      bool unique_priority)
{
	int ret;

	/*
	 * This code gets used during boot-up, when task switching is
	 * not yet working and interrupts must remain disabled.  At
	 * such times we must not call down_write().
	 */
	if (unlikely(system_state == SYSTEM_BOOTING))
		return notifier_chain_register(&amp;nh-&gt;head, n, unique_priority);

	down_write(&amp;nh-&gt;rwsem);
	ret = notifier_chain_register(&amp;nh-&gt;head, n, unique_priority);
	up_write(&amp;nh-&gt;rwsem);
	return ret;
}
</code></pre></div>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/notifier.c#L20">kernel/notifier.c:20</a></p>
<div><pre><code>/*
 *	Notifier chain core routines.  The exported routines below
 *	are layered on top of these, with appropriate locking added.
 */

static int notifier_chain_register(struct notifier_block **nl,
				   struct notifier_block *n,
				   bool unique_priority)
{
	while ((*nl) != NULL) {
		if (unlikely((*nl) == n)) {
			WARN(1, "notifier callback %ps already registered",
			     n-&gt;notifier_call);
			return -EEXIST;
		}
		if (n-&gt;priority &gt; (*nl)-&gt;priority)
			break;
		if (n-&gt;priority == (*nl)-&gt;priority &amp;&amp; unique_priority)
			return -EBUSY;
		nl = &amp;((*nl)-&gt;next);
	}
	n-&gt;next = *nl;
	rcu_assign_pointer(*nl, n);
	trace_notifier_register((void *)n-&gt;notifier_call);
	return 0;
}
</code></pre></div>

<p>Each callback can return one of a series of options.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/include/linux/notifier.h#L18">include/linux/notifier.h:18</a></p>
<div><pre><code>#define NOTIFY_DONE		0x0000		/* Don't care */
#define NOTIFY_OK		0x0001		/* Suits me */
#define NOTIFY_STOP_MASK	0x8000		/* Don't call further */
#define NOTIFY_BAD		(NOTIFY_STOP_MASK|0x0002)
						/* Bad/Veto action */
</code></pre></div>

<p>When notifying the chain, if a function returns <code>STOP</code> or <code>BAD</code> then
the previous parts of the chain are called again with <code>PM_POST_HIBERNATION</code><sup id="fnref:pmpost" role="doc-noteref"><a href="#fn:pmpost" rel="footnote">14</a></sup>
and an error is returned.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/notifier.c#L107">kernel/notifier.c:107</a></p>
<div><pre><code>/**
 * notifier_call_chain_robust - Inform the registered notifiers about an event
 *                              and rollback on error.
 * @nl:		Pointer to head of the blocking notifier chain
 * @val_up:	Value passed unmodified to the notifier function
 * @val_down:	Value passed unmodified to the notifier function when recovering
 *              from an error on @val_up
 * @v:		Pointer passed unmodified to the notifier function
 *
 * NOTE:	It is important the @nl chain doesn't change between the two
 *		invocations of notifier_call_chain() such that we visit the
 *		exact same notifier callbacks; this rules out any RCU usage.
 *
 * Return:	the return value of the @val_up call.
 */
static int notifier_call_chain_robust(struct notifier_block **nl,
				     unsigned long val_up, unsigned long val_down,
				     void *v)
{
	int ret, nr = 0;

	ret = notifier_call_chain(nl, val_up, v, -1, &amp;nr);
	if (ret &amp; NOTIFY_STOP_MASK)
		notifier_call_chain(nl, val_down, v, nr-1, NULL);

	return ret;
}
</code></pre></div>

<p>Each of these callbacks tends to be quite driver-specific, so we’ll cease
discussion of this here.</p>

<h3 id="sync-filesystems">Sync Filesystems</h3>
<p>The next step is to ensure all filesystems have been synchronized to disk.</p>

<p>This is performed via a simple helper function that times how long the full
synchronize operation, <code>ksys_sync</code> takes.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/kernel/power/main.c#L69">kernel/power/main.c:69</a></p>
<div><pre><code>void ksys_sync_helper(void)
{
	ktime_t start;
	long elapsed_msecs;

	start = ktime_get();
	ksys_sync();
	elapsed_msecs = ktime_to_ms(ktime_sub(ktime_get(), start));
	pr_info("Filesystems sync: %ld.%03ld seconds\n",
		elapsed_msecs / MSEC_PER_SEC, elapsed_msecs % MSEC_PER_SEC);
}
EXPORT_SYMBOL_GPL(ksys_sync_helper);
</code></pre></div>

<p><code>ksys_sync</code> wakes and instructs a set of flusher threads to write out
every filesystem, first their inodes<sup id="fnref:inode" role="doc-noteref"><a href="#fn:inode" rel="footnote">15</a></sup>, then the full filesystem, and
then finally all block devices, to ensure all pages are written out
to disk.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/fs/sync.c#L87">fs/sync.c:87</a></p>
<div><pre><code>/*
 * Sync everything. We start by waking flusher threads so that most of
 * writeback runs on all devices in parallel. Then we sync all inodes reliably
 * which effectively also waits for all flusher threads to finish doing
 * writeback. At this point all data is on disk so metadata should be stable
 * and we tell filesystems to sync their metadata via -&gt;sync_fs() calls.
 * Finally, we writeout all block devices because some filesystems (e.g. ext2)
 * just write metadata (such as inodes or bitmaps) to block device page cache
 * and do not sync it on their own in -&gt;sync_fs().
 */
void ksys_sync(void)
{
	int nowait = 0, wait = 1;

	wakeup_flusher_threads(WB_REASON_SYNC);
	iterate_supers(sync_inodes_one_sb, NULL);
	iterate_supers(sync_fs_one_sb, &amp;nowait);
	iterate_supers(sync_fs_one_sb, &amp;wait);
	sync_bdevs(false);
	sync_bdevs(true);
	if (unlikely(laptop_mode))
		laptop_sync_completion();
}
</code></pre></div>

<p>It follows an interesting pattern of using <code>iterate_supers</code> to run both
<code>sync_inodes_one_sb</code> and then <code>sync_fs_one_sb</code> on each known filesystem<sup id="fnref:superblock" role="doc-noteref"><a href="#fn:superblock" rel="footnote">16</a></sup>.
It also calls both <code>sync_fs_one_sb</code> and <code>sync_bdevs</code> twice, first without waiting
for any operations to complete and then again waiting for completion<sup id="fnref:fscode" role="doc-noteref"><a href="#fn:fscode" rel="footnote">17</a></sup>.</p>

<p>When <code>laptop_mode</code> is enabled the system runs additional filesystem synchronization
operations after the specified delay without any writes.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/mm/page-writeback.c#L111">mm/page-writeback.c:111</a></p>
<div><pre><code>/*
 * Flag that puts the machine in "laptop mode". Doubles as a timeout in jiffies:
 * a full sync is triggered after this time elapses without any disk activity.
 */
int laptop_mode;

EXPORT_SYMBOL(laptop_mode);
</code></pre></div>

<p>However, when running a filesystem synchronization operation, the system will
add an additional timer to schedule more writes after the <code>laptop_mode</code> delay.
We don’t want the state of the system to change at all while performing
hibernation, so we cancel those timers.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/mm/page-writeback.c#L2198">mm/page-writeback.c:2198</a></p>
<div><pre><code>/*
 * We're in laptop mode and we've just synced. The sync's writes will have
 * caused another writeback to be scheduled by laptop_io_completion.
 * Nothing needs to be written back anymore, so we unschedule the writeback.
 */
void laptop_sync_completion(void)
{
	struct backing_dev_info *bdi;

	rcu_read_lock();

	list_for_each_entry_rcu(bdi, &amp;bdi_list, bdi_list)
		del_timer(&amp;bdi-&gt;laptop_mode_wb_timer);

	rcu_read_unlock();
}
</code></pre></div>

<p>As a side note, the <code>ksys_sync</code> function is simply called when the
system call <code>sync</code> is used.</p>

<p><a href="https://elixir.bootlin.com/linux/v6.9.9/source/fs/sync.c#L111">fs/sync.c:111</a></p>
<div><pre><code>SYSCALL_DEFINE0(sync)
{
	ksys_sync();
	return 0;
}
</code></pre></div>

<h2 id="the-end-of-preparation">The End of Preparation</h2>
<p>With that the system has finished preparations for hibernation.
This is a somewhat arbitrary cutoff, but next the system will begin
a full freeze of userspace to then dump memory out to an image and finally
to perform hibernation. All this will be covered in future articles!</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reclaim the Stack (375 pts)]]></title>
            <link>https://reclaim-the-stack.com</link>
            <guid>41483675</guid>
            <pubDate>Sun, 08 Sep 2024 22:11:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reclaim-the-stack.com">https://reclaim-the-stack.com</a>, See on <a href="https://news.ycombinator.com/item?id=41483675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><p><img alt="Reclaim the Stack" loading="lazy" width="250" height="134" decoding="async" data-nimg="1" src="https://reclaim-the-stack.com/reclaim-the-stack.png"></p><p>We spent 7 months building a Kubernetes based platform to replace Heroku for our SaaS product at <a href="https://www.mynewsdesk.com/">mynewsdesk.com</a>. <strong>The results were a 90% reduction in costs and a 30% improvement in performance.</strong> We also significantly improved developer experience with reduced deploy times and faster / more accessible tooling.</p><p>We have now open sourced the entire stack, so you can do the same, but in a few days instead of 7 months. <strong>It's time to Reclaim the Stack!</strong></p><p><a href="https://reclaim-the-stack.com/docs/kubernetes-platform/introduction">Read the Documentation</a><a href="https://discord.gg/v23eA4FMPC">Join the Discord Server</a></p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Charging lithium-ion batteries at high currents first increases lifespan by 50% (196 pts)]]></title>
            <link>https://www.eurekalert.org/news-releases/1056171</link>
            <guid>41483654</guid>
            <pubDate>Sun, 08 Sep 2024 22:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eurekalert.org/news-releases/1056171">https://www.eurekalert.org/news-releases/1056171</a>, See on <a href="https://news.ycombinator.com/item?id=41483654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                                                                                                                                                                        <figure>
                <a href="https://www.eurekalert.org/multimedia/1039782">
                  <p><img src="https://earimediaprodweb.azurewebsites.net/Api/v1/Multimedia/37fffaf4-6518-42b6-a04d-00b87998a56f/Rendition/low-res/Content/Public" alt="Better Batteries">
                  </p>
                </a>
                <figcaption>
                  <p><strong>image:&nbsp;</strong></p><p><strong>Giving lithium-ion batteries their first charge at high currents before they leave the factory is 30 times faster and increases their lifespans by 50%.</strong></p><strong>
</strong>
                  <a href="https://www.eurekalert.org/multimedia/1039782">view <span>more&nbsp;<i></i></span></a>
                  <p>Credit: Greg Stewart/SLAC National Accelerator Laboratory</p>
                </figcaption>
              </figure>
            
                            <p><em>Menlo Park, Calif. —</em>&nbsp;A lithium-ion battery’s very first charge is more momentous than it sounds. It determines how well and how long the battery will work from then on – in particular, how many cycles of charging and discharging it can handle before deteriorating.</p>

<p>In a study published today in&nbsp;<em>Joule</em>, researchers at the SLAC-Stanford Battery Center report that giving&nbsp;<a href="https://www.energy.gov/science/doe-explainsbatteries">batteries</a>&nbsp;this first charge at unusually high currents increased their average lifespan by 50% while decreasing the initial charging time from 10 hours to just 20 minutes.</p>

<p>Just as important, the researchers were able to use scientific&nbsp;<a href="https://www.energy.gov/science/doe-explainsmachine-learning">machine learning</a>&nbsp;to pinpoint specific changes in the battery electrodes that account for this increase in lifespan and performance – invaluable insights for battery manufacturers looking to streamline their processes and improve their products.</p>

<p>The study was carried out by a SLAC/Stanford team led by Professor Will Chueh in collaboration with researchers from the Toyota Research Institute (TRI), the Massachusetts Institute of Technology and the University of Washington. It is part of SLAC's&nbsp;<a href="https://www6.slac.stanford.edu/topics/sustainability">sustainability research</a>&nbsp;and a broader effort to reimagine our energy future leveraging the lab’s unique tools and expertise and partnerships with industry.</p>

<p>“This is an excellent example of how SLAC is doing manufacturing science to make critical technologies for the energy transition more affordable,” Chueh said. “We’re solving a real challenge that industry is facing; critically, we partner with industry from the get-go.”</p>

<p>This was the latest in a&nbsp;<a href="https://www6.slac.stanford.edu/news/2023-09-13-computer-vision-reveals-unprecedented-physical-and-chemical-details-how-lithium-ion">series of studies</a>&nbsp;funded by TRI under a cooperative research agreement with the Department of Energy’s SLAC National Accelerator Laboratory.</p>

<p>The results have practical implications for manufacturing not just lithium-ion&nbsp;<a href="https://www.energy.gov/science/doe-explainsbatteries">batteries</a>&nbsp;for electric vehicles and the electric grid, but for other technologies, too, said Steven Torrisi, a senior research scientist at TRI who collaborated on the research.</p>

<p>“This study is very exciting for us,” he said. “Battery manufacturing is extremely capital, energy and time intensive. It takes a long time to spin up manufacturing of a new battery, and it’s really difficult to optimize the manufacturing process because there are so many factors involved.”</p>

<p>Torrisi said the results of this research “demonstrate a generalizable approach for understanding and optimizing this crucial step in battery manufacturing. Further, we may be able to transfer what we have learned to new processes, facilities, equipment and battery chemistries in the future.”</p>

<p><strong>A “squishy layer” that’s key to battery performance</strong></p>

<p>To understand what happens during the battery’s initial cycling, Chueh’s team builds pouch cells in which the positive and negative electrodes are surrounded by an electrolyte solution where lithium ions move freely.&nbsp;</p>

<p>When a battery charges, lithium ions flow into the negative electrode for storage. When a battery discharges, they flow back out and travel to the positive electrode; this triggers a flow of electrons for powering devices, from electric cars to the electricity grid.</p>

<p>The positive electrode of a newly minted battery is 100% full of lithium, said Xiao Cui, the lead researcher for the battery informatics team in Chueh’s lab. Every time the battery goes through a charge-discharge cycle, some of the lithium is deactivated. Minimizing those losses prolongs the battery’s working lifetime.</p>

<p>Oddly enough, one way to minimize the overall lithium loss is to deliberately lose a large percentage of the initial supply of lithium during the battery’s first charge, Cui said. It’s like making a small investment that yields good returns down the road.</p>

<p>This first-cycle lithium loss is not in vain. The lost lithium becomes part of a squishy layer called the solid electrolyte interphase, or SEI, that forms on the surface of the negative electrode during the first charge. In return, the SEI protects the negative electrode from side reactions that would accelerate the lithium loss and degrade the battery faster over time. Getting the SEI just right is so important that the first charge is known as the formation charge.</p>

<p>“Formation is the final step in the manufacturing process,” Cui said, “so if it fails, all the value and effort invested in the battery up to that point are wasted.”</p>

<p><strong>High charging current boosts battery performance &nbsp;</strong></p>

<p>Manufacturers generally give new&nbsp;<a href="https://www.energy.gov/science/doe-explainsbatteries">batteries</a>&nbsp;their first charge with low currents, on the theory that this will create the most robust SEI layer. But there’s a downside: Charging at low currents is time-consuming and costly and doesn’t necessarily yield optimal results. So, when recent studies suggested that faster charging with higher currents does not degrade battery performance, it was exciting news.</p>

<p>But researchers wanted to dig deeper. The charging current is just one of dozens of factors that go into the formation of SEI during the first charge. Testing all possible combinations of them in the lab to see which one worked best is an overwhelming task.</p>

<p>To whittle the problem down to manageable size, the research team used scientific&nbsp;<a href="https://www.energy.gov/science/doe-explainsmachine-learning">machine learning</a>&nbsp;to identify which factors are most important in achieving good results. To their surprise, just two of them – the temperature and current at which the battery is charged – stood out from all the rest.</p>

<p>Experiments confirmed that charging at high currents has a huge impact, increasing the lifespan of the average test battery by 50%. It also deactivated a much higher percentage of lithium up front – about 30%, compared to 9% with previous methods – but that turned out to have a positive effect.</p>

<p>Removing more lithium ions up front is a bit like scooping water out of a full bucket before carrying it, Cui said. The extra headspace in the bucket decreases the amount of water splashing out along the way. In similar fashion, deactivating more lithium ions during SEI formation frees up headspace in the positive electrode and allows the electrode to cycle in a more efficient way, improving subsequent performance.</p>

<p>“Brute force optimization by trial-and-error is routine in manufacturing– how should we perform the first charge, and what is the winning combination of factors?” Chueh said. “Here, we didn’t just want to identify the best recipe for making a good battery; we wanted to understand how and why it works. This understanding is crucial for finding the best balance between battery performance and manufacturing efficiency.”</p>

<p>This research was funded by the Toyota Research Institute through its Accelerated Materials Design and Discovery program.</p>



<p><em>About SLAC</em></p>

<p><em>SLAC National Accelerator Laboratory explores how the universe works at the biggest, smallest and fastest scales and invents powerful tools used by researchers around the globe. As world leaders in&nbsp;<a href="https://www.energy.gov/science/doe-explainsultrafast-science">ultrafast science</a>&nbsp;and bold explorers of the physics of the universe, we forge new ground in understanding our origins and building a healthier and more sustainable future. Our&nbsp;</em><a href="https://www6.slac.stanford.edu/research"><em>discovery and innovation</em></a><em>&nbsp;help develop new materials and chemical processes and open unprecedented views of the cosmos and life’s most delicate machinery. Building on more than 60 years of visionary research, we help shape the future by advancing areas such as quantum technology, scientific computing and the development of next-generation accelerators.</em></p>

<p><em>SLAC is operated by Stanford University for the U.S. Department of Energy’s&nbsp;</em><a href="https://www.energy.gov/science/office-science"><em>Office of&nbsp;Science</em></a><em>. The Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time.</em></p>

            
                        <hr>
            <hr>
            
                    </div><p><strong>Disclaimer:</strong> AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert system.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI recommends using an ad blocker (2022) (271 pts)]]></title>
            <link>https://www.ic3.gov/Media/Y2022/PSA221221</link>
            <guid>41483581</guid>
            <pubDate>Sun, 08 Sep 2024 21:57:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ic3.gov/Media/Y2022/PSA221221">https://www.ic3.gov/Media/Y2022/PSA221221</a>, See on <a href="https://news.ycombinator.com/item?id=41483581">Hacker News</a></p>
Couldn't get https://www.ic3.gov/Media/Y2022/PSA221221: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Sleep duration, chronotype, health and lifestyle factors affect cognition [pdf] (154 pts)]]></title>
            <link>https://bmjpublichealth.bmj.com/content/bmjph/2/1/e001000.full.pdf</link>
            <guid>41483434</guid>
            <pubDate>Sun, 08 Sep 2024 21:37:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bmjpublichealth.bmj.com/content/bmjph/2/1/e001000.full.pdf">https://bmjpublichealth.bmj.com/content/bmjph/2/1/e001000.full.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41483434">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Fennel Programming Language (170 pts)]]></title>
            <link>https://fennel-lang.org/</link>
            <guid>41483216</guid>
            <pubDate>Sun, 08 Sep 2024 21:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fennel-lang.org/">https://fennel-lang.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41483216">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Fennel is a programming language that brings together  the simplicity, speed, and reach of <a href="https://www.lua.org/">Lua</a>  with the flexibility of a  <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">lisp syntax and macro system.</a></p> <ul><li><b>Full Lua compatibility:</b> Easily call any Lua  function or library from Fennel and vice-versa.</li> <li><b>Zero overhead:</b> Compiled code should be just  as efficient as hand-written Lua.</li> <li><b>Compile-time macros:</b> Ship compiled code with no runtime dependency on Fennel.</li> <li><b>Embeddable:</b> Fennel is a one-file library as  well as an executable. Embed it in other programs to support  runtime extensibility and interactive development.</li></ul> <p>Anywhere you can run Lua code, you can run Fennel code.</p> <ul id="where"><li><a href="https://www.minetest.net/">video</a> <a href="https://love2d.org/">game</a> <a href="https://tic80.com/">dev</a></li> <li><a href="https://awesomewm.org/">window managers</a></li> <li><a href="https://openresty.org/en/">web</a> <a href="https://algernon.roboticoverlords.org/">servers</a></li> <li><a href="https://github.com/pllua/pllua">data</a> <a href="https://redis.io/commands/eval">bases</a></li> <li><a href="https://github.com/fengari-lua/fengari">web</a> <a href="https://github.com/luakit/luakit">browsers</a></li> <li><a href="https://github.com/whitecatboard/Lua-RTOS-ESP32/">cheap microcontrollers</a></li></ul> <pre id="sample"><span>;; Sample: read the state of the keyboard and move the player accordingly
</span>(<span>local</span> <span>dirs</span> {<span>:up</span> [<span>0</span> <span>-1</span>] <span>:down</span> [<span>0</span> <span>1</span>] <span>:left</span> [<span>-1</span> <span>0</span>] <span>:right</span> [<span>1</span> <span>0</span>]})

(<span>each</span> [<span>key</span> [<span>dx</span> <span>dy</span>] (<span>pairs</span> <span>dirs</span>)]
  (<span>when</span> (<span>love.keyboard.isDown</span> <span>key</span>)
    (<span>let</span> [[<span>px</span> <span>py</span>] <span>player</span>
          <span>x</span> (<span>+</span> <span>px</span> (<span>*</span> <span>dx</span> <span>player.speed</span> <span>dt</span>))
          <span>y</span> (<span>+</span> <span>py</span> (<span>*</span> <span>dy</span> <span>player.speed</span> <span>dt</span>))]
      (<span>world:move</span> <span>player</span> <span>x</span> <span>y</span>))))
</pre>
 <p>See the  <a href="https://fennel-lang.org/setup#downloading-fennel">install instructions</a> in the setup guide.</p> <h2>That's too much work!</h2> <p>Fine, you can use Fennel right here without installing  anything:</p> <div><p><label id="fengari-prompt" for="fengari-input">&gt; </label>  </p></div> <p>Curious about how a piece of code compiles? <a href="https://fennel-lang.org/see">See for yourself</a>  with a side-by-side  view how Fennel turns into Lua  <strong>and vice-versa.</strong></p> <h2>Documentation</h2> <a name="docs"></a> <ul><li>The <a href="https://fennel-lang.org/setup">Setup guide</a> will help you install things.</li> <li>The <a href="https://fennel-lang.org/tutorial">Tutorial</a> teaches you the basics of the language.</li> <li>The <a href="https://fennel-lang.org/rationale">Rationale</a> explains the reasoning why Fennel was created.</li> <li>The <a href="https://fennel-lang.org/lua-primer">Lua primer</a> will catch you up if you don't already know Lua.</li> <li>The <a href="https://fennel-lang.org/reference">Reference</a> lists  out all built-in forms and what they're for.</li> <li>The <a href="https://fennel-lang.org/from-clojure">Fennel from Clojure</a> guide helps if you have a background in Clojure.</li> <li>The <a href="https://fennel-lang.org/style">Style Guide</a> advises on how to write clear and consise code.</li> <li>The <a href="https://fennel-lang.org/macros">Macro Guide</a> explains metaprogramming with macros.</li> <li>The <a href="https://fennel-lang.org/api">API listing</a> explains how to embed Fennel into a Lua program.</li> <li>The <a href="https://fennel-lang.org/changelog">Changelog</a> describes how Fennel has evolved with time.</li> <li>The <a href="https://wiki.fennel-lang.org/">wiki</a> has all kinds of things in it.</li></ul> <p>Looking for other versions?  Docs are generated for:</p> <ul id="versions"><li><a href="https://fennel-lang.org/v1.5.1/">v1.5.1</a></li> <li><a href="https://fennel-lang.org/v1.5.0/">v1.5.0</a></li> <li><a href="https://fennel-lang.org/v1.4.2/">v1.4.2</a></li> <li><a href="https://fennel-lang.org/v1.4.1/">v1.4.1</a></li> <li><a href="https://fennel-lang.org/v1.4.0/">v1.4.0</a></li> <li><a href="https://fennel-lang.org/v1.3.1/">v1.3.1</a></li> <li><a href="https://fennel-lang.org/v1.3.0/">v1.3.0</a></li> <li><a href="https://fennel-lang.org/v1.2.1/">v1.2.1</a></li> <li><a href="https://fennel-lang.org/v1.2.0/">v1.2.0</a></li> <li><a href="https://fennel-lang.org/v1.1.0/">v1.1.0</a></li> <li><a href="https://fennel-lang.org/v1.0.0/">v1.0.0</a></li> <li><a href="https://fennel-lang.org/v0.10.0/">v0.10.0</a></li> <li><a href="https://fennel-lang.org/v0.9.1/">v0.9.1</a></li> <li><a href="https://fennel-lang.org/v0.9.0/">v0.9.0</a></li> <li><a href="https://fennel-lang.org/v0.8.1/">v0.8.1</a></li> <li><a href="https://fennel-lang.org/v0.8.0/">v0.8.0</a></li> <li><a href="https://fennel-lang.org/v0.7.0/">v0.7.0</a></li> <li><a href="https://fennel-lang.org/v0.6.0/">v0.6.0</a></li> <li><a href="https://fennel-lang.org/v0.5.0/">v0.5.0</a></li> <li><a href="https://fennel-lang.org/v0.4.3/">v0.4.3</a></li> <li><a href="https://fennel-lang.org/v0.4.2/">v0.4.2</a></li> <li><a href="https://fennel-lang.org/v0.4.1/">v0.4.1</a></li> <li><a href="https://fennel-lang.org/v0.4.0/">v0.4.0</a></li> <li><a href="https://fennel-lang.org/v0.3.2/">v0.3.2</a></li> <li><a href="https://fennel-lang.org/v0.3.1/">v0.3.1</a></li> <li><a href="https://fennel-lang.org/v0.3.0/">v0.3.0</a></li> <li><a href="https://fennel-lang.org/v0.2.1/">v0.2.1</a></li> <li><a href="https://fennel-lang.org/v0.2.0/">v0.2.0</a></li> <li><a href="https://fennel-lang.org/v0.1.1/">v0.1.1</a></li> <li><a href="https://fennel-lang.org/v0.1.0/">v0.1.0</a></li></ul> <h2>Community</h2> <a name="community"></a> <p><a href="https://sr.ht/~technomancy/fennel">Fennel's repository</a> is on Sourcehut, and discussion occurs on  <a href="https://lists.sr.ht/%7Etechnomancy/fennel">the mailing list</a>  and the #fennel channel <a href="https://libera.chat/">on Libera.Chat</a>  and  <a href="https://matrix.to/#/#fennel:matrix.org">on Matrix</a> . There is a  <a href="https://github.com/bakpakin/Fennel">read-only mirror of the repository on GitHub</a>  for those who prefer it.</p> <p>Come meet the Fennel community and make friends at any of our <a href="https://fennel-lang.org/events">community events.</a>  Community interactions are subject to the <a href="https://fennel-lang.org/coc">code of conduct.</a>  We periodically run  <a href="https://fennel-lang.org/survey/">surveys</a>  of the community.</p> <p><a href="https://todo.sr.ht/~technomancy/fennel">Bug reports</a> are tracked in Sourcehut or <a href="https://github.com/bakpakin/Fennel/issues">Github.</a>  See the  <a href="https://fennel-lang.org/security">security page</a>  for details about security issues.</p> <p>There is also <a href="https://wiki.fennel-lang.org/">a wiki</a>  for collecting ideas.  Take a look at the <a href="https://wiki.fennel-lang.org/Codebases">list of codebases</a> written in Fennel if you want to get a  feel for how larger projects look. The <a href="https://wiki.fennel-lang.org/Cookbook">cookbook</a> has smaller self-contained examples.</p> <hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Htmx, Raku and Pico CSS (150 pts)]]></title>
            <link>https://rakujourney.wordpress.com/2024/09/08/htmx-raku-and-pico-css/</link>
            <guid>41482679</guid>
            <pubDate>Sun, 08 Sep 2024 19:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rakujourney.wordpress.com/2024/09/08/htmx-raku-and-pico-css/">https://rakujourney.wordpress.com/2024/09/08/htmx-raku-and-pico-css/</a>, See on <a href="https://news.ycombinator.com/item?id=41482679">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main" role="main">

			
<article id="post-1256">

	

	
	<div>
		
<p>This post is kind of part 3, coming off last week’s thrilling <a href="https://rakujourney.wordpress.com/2024/09/01/htmx-and-raku-cro-ii/">episode</a>.</p>



<p>I am a simple sole, I want to reduce the cognitive load in my web projects. The general idea is to go back to the halcyon early days of the web before Netscape dropped the JS-bomb. You know HTML for the layout and CSS for the style. An elegant division of roles.</p>



<p>When I read about <a href="http://htmx.org/">HTMX</a> it was clear that <a href="http://raku.org/">Raku</a> and <a href="http://cro.raku.org/">Cro</a> are ideal candidates for the back end HTML assembly, defining routes and serving RESTful APIs. As we have seen in the previous posts, HTMX eliminates the need for JS to make dynamic web content. Lovely.</p>



<p>Remember – we are talking simpler ways to build attractive, dynamic, modern websites. While HTMX is well suited to 90% of this, if you are building a webapp like FaceBook or Google Maps, then it’s not for you.</p>







<p>But what to do about style and CSS?</p>



<p>Well HTMX is neutral to CSS … it can be used with Bootstrap, Tailwind, SASS and so on. But many of these CSS tools have evolved to jam more stuff into the HTML tag attributes.</p>



<p>In my mind, the ideal would be something like this for a simple navbar:</p>


<div><pre title="">&lt;nav&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#"&gt;About&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="#"&gt;Services&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="#"&gt;Products&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
</pre></div>


<p>I had heard that <a href="https://picocss.com/">Pico</a> CSS was often used in HTMX projects. And sure enough, the <a href="https://picocss.com/docs/nav">Pico Components</a> have this feel… </p>



<p>Here’s Bootstrap for contrast:</p>


<div><pre title="">&lt;nav class="navbar navbar-expand-lg navbar-light bg-light"&gt;
  &lt;div class="collapse navbar-collapse" id="navbarNav"&gt;
    &lt;ul class="navbar-nav ms-auto"&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="nav-link" href="#"&gt;About&lt;/a&gt;
      &lt;/li&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="nav-link" href="#"&gt;Services&lt;/a&gt;
      &lt;/li&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="nav-link" href="#"&gt;Product&lt;/a&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/nav&gt;
</pre></div>


<p>What about Tailwind, also for contrast:</p>


<div><pre title="">&lt;nav class="bg-gray-100"&gt;
  &lt;div class="flex justify-end"&gt;
    &lt;ul class="flex space-x-3"&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="text-gray-700 hover:text-gray-900" href="#"&gt;About&lt;/a&gt;
      &lt;/li&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="text-gray-700 hover:text-gray-900" href="#"&gt;Services&lt;/a&gt;
      &lt;/li&gt;
      &lt;li class="nav-item"&gt;
        &lt;a class="text-gray-700 hover:text-gray-900" href="#"&gt;Product&lt;/a&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/nav&gt;
</pre></div>


<p>Bootstrap and Tailwind come at the cost of “more stuff in the HTML tags”.</p>



<p>Here’s the Pico CSS example:</p>



<figure><img data-attachment-id="1266" data-permalink="https://rakujourney.wordpress.com/2024/09/08/htmx-raku-and-pico-css/screenshot-2024-09-08-at-09-55-33/" data-orig-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.55.33.png" data-orig-size="1784,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-09-08 at 09.55.33" data-image-description="" data-image-caption="" data-medium-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.55.33.png?w=300" data-large-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.55.33.png?w=782" tabindex="0" role="button" width="1024" height="484" src="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.55.33.png?w=1024" alt=""><figcaption><a href="https://picocss.com/docs/nav">https://picocss.com/docs/nav</a></figcaption></figure>



<p>So for our goals, it looks like Pico CSS is on a good track. Their website says:</p>



<figure><img data-attachment-id="1268" data-permalink="https://rakujourney.wordpress.com/2024/09/08/htmx-raku-and-pico-css/screenshot-2024-09-08-at-09-57-28/" data-orig-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.57.28.png" data-orig-size="1556,746" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-09-08 at 09.57.28" data-image-description="" data-image-caption="" data-medium-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.57.28.png?w=300" data-large-file="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.57.28.png?w=782" tabindex="0" role="button" width="1024" height="490" src="https://rakujourney.wordpress.com/wp-content/uploads/2024/09/screenshot-2024-09-08-at-09.57.28.png?w=1024" alt=""></figure>



<p>What’s that?</p>



<h2>Semantic HTML!</h2>



<p>Looks like my goal all along has been <a href="https://www.semrush.com/blog/semantic-html5-guide/#">Semantic HTML</a> (not that I knew at the time).</p>



<blockquote>
<p>By adding semantic HTML tags to your pages, you provide additional information that helps define the roles and relative importance of the different parts of your page.</p>



<p>(As opposed to non-semantic HTML, which uses tags that don’t directly convey meaning.)</p>
</blockquote>



<p>So having more powerful <em>Semantic</em> HTML is a win.</p>



<figure><img src="https://static.semrush.com/blog/uploads/media/cc/85/cc85d452a743e27f68d426df35e4da7d/EN-Semantic-Search-Non-Semantic.webp" alt=""></figure>



<p>Hopefully the figure above is enough of an eye opener for now. There’s much more <a href="https://en.wikipedia.org/wiki/Semantic_HTML">info</a> out there if you are curious. But obviously read the rest of my post first.</p>



<p><em>[For hardcore aficionados, I plan to look into Web Components in a future post. I also think that Bootstrap and Tailwind and SASS in general are good companions to HTMX and Raku — but my project and this series of posts <strong>starts</strong> by using Pico CSS to minimize the cognitive load on the style side – later we will come back to these other styling tools].</em></p>



<h2>Real Code</h2>



<p>So lets see how this looks in action. All the code for these posts is on <a href="https://github.com/librasteve/raku-HTMX-Examples">GitHub</a> for your perusal and collaboration.</p>



<p>I have been using Pico CSS as part of my project to rebuild the HTMX <a href="https://htmx.org/examples/">examples</a> for Raku / Cro largely by translating the Python / Flask <a href="https://github.com/Konfuzian/htmx-examples-with-flask/tree/main">examples</a>. This post draws on the <a href="https://htmx.org/examples/tabs-hateoas/">Tabs HATEOAS</a> one in particular, since I have in mind that I will want a Tab Component in my toolbag but that Pico CSS does not provide one out of the box. Pico does have <a href="https://picocss.com/docs/accordion">Accordions</a> so there is some prior art for inspiration.</p>



<p>Anywho, here’s the way the final code ended up.</p>



<p>tabs/index.crotmp:</p>


<div><pre title="">&lt;nav&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;a href="#" hx-get="/tabs/tab1" hx-target="#tab"&gt;Tab 1&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;a href="#" hx-get="/tabs/tab2" hx-target="#tab"&gt;Tab 2&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;a href="#" hx-get="/tabs/tab3" hx-target="#tab"&gt;Tab 3&lt;/a&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;div id="tab" hx-get="/tabs/tab1" hx-trigger="load"&gt;&lt;/div&gt;
</pre></div>


<p>/tabs/tab1.crotmp (tab2 and tab 3 are much the same so I won’t bore you)</p>


<div><pre title="">&lt;section&gt;
  &lt;figure&gt;
    &lt;blockquote&gt;
      "When you're new to something, you bring an ignorance that can
      be highly innovative."
      &lt;footer&gt;
        &lt;cite&gt;– Rick Rubin&lt;/cite&gt;
      &lt;/footer&gt;
    &lt;/blockquote&gt;
  &lt;/figure&gt;
&lt;/section&gt;
</pre></div>


<p>/Routes/Examples/Tabs.rakumod to fulfil the <code>hx-get</code> attrs.</p>


<div><pre title="">use Cro::HTTP::Router;
use Cro::WebApp::Template;

sub tabs-routes() is export {

    route {
        template-location 'templates/tabs';

        get -&gt; {
            template 'index.crotmp';
        }

        get -&gt; 'tab1' {
            template 'tab1.crotmp';
        }

        get -&gt; 'tab2' {
            template 'tab2.crotmp';
        }

        get -&gt; 'tab3' {
            template 'tab3.crotmp';
        }
    }
}
</pre></div>


<p>And the proof… oh yeah, Pico has built in dark mode 😉</p>



<figure><div>
<p><iframe title="Tabs" width="782" height="587" src="https://www.youtube.com/embed/QUB0hECEBZI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>



<p>Thanks for tuning in, please feel free to like, share or comment.</p>



<p>You can find me on the <a href="https://raku.org/community/">Raku Discord and IRC Channels</a>.</p>



<p>~librasteve</p>





			
				</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<!-- .entry-auhtor -->
		
</article><!-- #post-${ID} -->

<!-- #comments -->

		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jd – JSON Diff and Patch (129 pts)]]></title>
            <link>https://github.com/josephburnett/jd</link>
            <guid>41482661</guid>
            <pubDate>Sun, 08 Sep 2024 19:48:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/josephburnett/jd">https://github.com/josephburnett/jd</a>, See on <a href="https://news.ycombinator.com/item?id=41482661">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://goreportcard.com/report/josephburnett/jd" rel="nofollow"><img src="https://camo.githubusercontent.com/a954bf3a267f730dfe4082198e3d47ac65467c6b82943c7afd49e0a7c96d35ca/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6a6f736570686275726e6574742f6a64" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/josephburnett/jd"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">JSON diff and patch</h2><a id="user-content-json-diff-and-patch" aria-label="Permalink: JSON diff and patch" href="#json-diff-and-patch"></a></p>
<p dir="auto"><code>jd</code> is a commandline utility and Go library for diffing and patching JSON and YAML values. It supports a native <code>jd</code> format (similar to unified format) as well as JSON Merge Patch (<a href="https://datatracker.ietf.org/doc/html/rfc7386" rel="nofollow">RFC 7386</a>) and a subset of JSON Patch (<a href="https://datatracker.ietf.org/doc/html/rfc6902" rel="nofollow">RFC 6902</a>). Try it out at <a href="http://play.jd-tool.io/" rel="nofollow">http://play.jd-tool.io/</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/josephburnett/jd/blob/master/logo_small.png"><img src="https://github.com/josephburnett/jd/raw/master/logo_small.png" alt="jd logo"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To get the <code>jd</code> commandline utility:</p>
<ul dir="auto">
<li>run <code>brew install jd</code>, or</li>
<li>run <code>go install github.com/josephburnett/jd@latest</code>, or</li>
<li>visit <a href="https://github.com/josephburnett/jd/releases/latest">https://github.com/josephburnett/jd/releases/latest</a> and download the pre-built binary for your architecture/os, or</li>
<li>run in a Docker image <code>jd(){ docker run --rm -i -v $PWD:$PWD -w $PWD josephburnett/jd "$@"; }</code>.</li>
</ul>
<p dir="auto">To use the <code>jd</code> web UI:</p>
<ul dir="auto">
<li>visit <a href="http://play.jd-tool.io/" rel="nofollow">http://play.jd-tool.io/</a>, or</li>
<li>run <code>jd -port 8080</code> and visit <a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Command line usage</h2><a id="user-content-command-line-usage" aria-label="Permalink: Command line usage" href="#command-line-usage"></a></p>
<div data-snippet-clipboard-copy-content="Usage: jd [OPTION]... FILE1 [FILE2]
Diff and patch JSON files.

Prints the diff of FILE1 and FILE2 to STDOUT.
When FILE2 is omitted the second input is read from STDIN.
When patching (-p) FILE1 is a diff.

Options:
  -color     Print color diff.
  -p         Apply patch FILE1 to FILE2 or STDIN.
  -o=FILE3   Write to FILE3 instead of STDOUT.
  -set       Treat arrays as sets.
  -mset      Treat arrays as multisets (bags).
  -setkeys   Keys to identify set objects
  -yaml      Read and write YAML instead of JSON.
  -port=N    Serve web UI on port N
  -f=FORMAT  Produce diff in FORMAT &quot;jd&quot; (default), &quot;patch&quot; (RFC 6902) or
             &quot;merge&quot; (RFC 7386)
  -t=FORMATS Translate FILE1 between FORMATS. Supported formats are &quot;jd&quot;,
             &quot;patch&quot; (RFC 6902), &quot;merge&quot; (RFC 7386), &quot;json&quot; and &quot;yaml&quot;.
             FORMATS are provided as a pair separated by &quot;2&quot;. E.g.
             &quot;yaml2json&quot; or &quot;jd2patch&quot;.

Examples:
  jd a.json b.json
  cat b.json | jd a.json
  jd -o patch a.json b.json; jd patch a.json
  jd -set a.json b.json
  jd -f patch a.json b.json
  jd -f merge a.json b.json"><pre><code>Usage: jd [OPTION]... FILE1 [FILE2]
Diff and patch JSON files.

Prints the diff of FILE1 and FILE2 to STDOUT.
When FILE2 is omitted the second input is read from STDIN.
When patching (-p) FILE1 is a diff.

Options:
  -color     Print color diff.
  -p         Apply patch FILE1 to FILE2 or STDIN.
  -o=FILE3   Write to FILE3 instead of STDOUT.
  -set       Treat arrays as sets.
  -mset      Treat arrays as multisets (bags).
  -setkeys   Keys to identify set objects
  -yaml      Read and write YAML instead of JSON.
  -port=N    Serve web UI on port N
  -f=FORMAT  Produce diff in FORMAT "jd" (default), "patch" (RFC 6902) or
             "merge" (RFC 7386)
  -t=FORMATS Translate FILE1 between FORMATS. Supported formats are "jd",
             "patch" (RFC 6902), "merge" (RFC 7386), "json" and "yaml".
             FORMATS are provided as a pair separated by "2". E.g.
             "yaml2json" or "jd2patch".

Examples:
  jd a.json b.json
  cat b.json | jd a.json
  jd -o patch a.json b.json; jd patch a.json
  jd -set a.json b.json
  jd -f patch a.json b.json
  jd -f merge a.json b.json
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Command Line Option Details</h4><a id="user-content-command-line-option-details" aria-label="Permalink: Command Line Option Details" href="#command-line-option-details"></a></p>
<p dir="auto"><code>setkeys</code> This option determines what keys are used to decide if two objects 'match'. Then the matched objects are compared, which will return a diff if there are differences in the objects themselves, their keys and/or values. You shouldn't expect this option to mask or ignore non-specified keys, it is not intended as a way to 'ignore' some differences between objects.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Library usage</h2><a id="user-content-library-usage" aria-label="Permalink: Library usage" href="#library-usage"></a></p>
<p dir="auto">Note: import only release commits (<code>v1.Y.Z</code>) because <code>master</code> can be unstable.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import (
	&quot;fmt&quot;
	jd &quot;github.com/josephburnett/jd/lib&quot;
)

func ExampleJsonNode_Diff() {
	a, _ := jd.ReadJsonString(`{&quot;foo&quot;:&quot;bar&quot;}`)
	b, _ := jd.ReadJsonString(`{&quot;foo&quot;:&quot;baz&quot;}`)
	fmt.Print(a.Diff(b).Render())
	// Output:
	// @ [&quot;foo&quot;]
	// - &quot;bar&quot;
	// + &quot;baz&quot;
}

func ExampleJsonNode_Patch() {
	a, _ := jd.ReadJsonString(`[&quot;foo&quot;]`)
	diff, _ := jd.ReadDiffString(`` +
		`@ [1]` + &quot;\n&quot; +
		`+ &quot;bar&quot;` + &quot;\n&quot;)
	b, _ := a.Patch(diff)
	fmt.Print(b.Json())
	// Output:
	// [&quot;foo&quot;,&quot;bar&quot;]
}"><pre><span>import</span> (
	<span>"fmt"</span>
	jd <span>"github.com/josephburnett/jd/lib"</span>
)

<span>func</span> <span>ExampleJsonNode_Diff</span>() {
	<span>a</span>, <span>_</span> <span>:=</span> <span>jd</span>.<span>ReadJsonString</span>(<span>`{"foo":"bar"}`</span>)
	<span>b</span>, <span>_</span> <span>:=</span> <span>jd</span>.<span>ReadJsonString</span>(<span>`{"foo":"baz"}`</span>)
	<span>fmt</span>.<span>Print</span>(<span>a</span>.<span>Diff</span>(<span>b</span>).<span>Render</span>())
	<span>// Output:</span>
	<span>// @ ["foo"]</span>
	<span>// - "bar"</span>
	<span>// + "baz"</span>
}

<span>func</span> <span>ExampleJsonNode_Patch</span>() {
	<span>a</span>, <span>_</span> <span>:=</span> <span>jd</span>.<span>ReadJsonString</span>(<span>`["foo"]`</span>)
	<span>diff</span>, <span>_</span> <span>:=</span> <span>jd</span>.<span>ReadDiffString</span>(<span>``</span> <span>+</span>
		<span>`@ [1]`</span> <span>+</span> <span>"<span>\n</span>"</span> <span>+</span>
		<span>`+ "bar"`</span> <span>+</span> <span>"<span>\n</span>"</span>)
	<span>b</span>, <span>_</span> <span>:=</span> <span>a</span>.<span>Patch</span>(<span>diff</span>)
	<span>fmt</span>.<span>Print</span>(<span>b</span>.<span>Json</span>())
	<span>// Output:</span>
	<span>// ["foo","bar"]</span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Diff language</h2><a id="user-content-diff-language" aria-label="Permalink: Diff language" href="#diff-language"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/josephburnett/jd/blob/master/ebnf.png"><img src="https://github.com/josephburnett/jd/raw/master/ebnf.png" alt="Railroad diagram of EBNF"></a></p>
<ul dir="auto">
<li>A diff is zero or more sections</li>
<li>Sections start with a <code>@</code> header and the path to a node</li>
<li>A path is a JSON list of zero or more elements accessing collections</li>
<li>A JSON number element (e.g. <code>0</code>) accesses an array</li>
<li>A JSON string element (e.g. <code>"foo"</code>) accesses an object</li>
<li>An empty JSON object element (<code>{}</code>) accesses an array as a set or multiset</li>
<li>After the path is one or more removals or additions, removals first</li>
<li>Removals start with <code>-</code> and then the JSON value to be removed</li>
<li>Additions start with <code>+</code> and then the JSON value to added</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">EBNF</h3><a id="user-content-ebnf" aria-label="Permalink: EBNF" href="#ebnf"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="Diff ::= ( '@' '[' ( 'JSON String' | 'JSON Number' | 'Empty JSON Object' )* ']' '\n' ( ( '-' 'JSON Value' '\n' )+ | '+' 'JSON Value' '\n' ) ( '+' 'JSON Value' '\n' )* )*"><pre><span>Diff</span> <span>::=</span> ( <span><span>'</span>@<span>'</span></span> <span><span>'</span>[<span>'</span></span> ( <span><span>'</span>JSON String<span>'</span></span> <span>|</span> <span><span>'</span>JSON Number<span>'</span></span> <span>|</span> <span><span>'</span>Empty JSON Object<span>'</span></span> )<span>*</span> <span><span>'</span>]<span>'</span></span> <span><span>'</span>\n<span>'</span></span> ( ( <span><span>'</span>-<span>'</span></span> <span><span>'</span>JSON Value<span>'</span></span> <span><span>'</span>\n<span>'</span></span> )<span>+</span> <span>|</span> <span><span>'</span>+<span>'</span></span> <span><span>'</span>JSON Value<span>'</span></span> <span><span>'</span>\n<span>'</span></span> ) ( <span><span>'</span>+<span>'</span></span> <span><span>'</span>JSON Value<span>'</span></span> <span><span>'</span>\n<span>'</span></span> )<span>*</span> )<span>*</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Examples</h3><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>


<div dir="auto" data-snippet-clipboard-copy-content="@ [&quot;Movies&quot;,67,&quot;Title&quot;]
- &quot;Dr. Strangelove&quot;
+ &quot;Dr. Evil Love&quot;
@ [&quot;Movies&quot;,67,&quot;Actors&quot;,&quot;Dr. Strangelove&quot;]
- &quot;Peter Sellers&quot;
+ &quot;Mike Myers&quot;
@ [&quot;Movies&quot;,102]
+ {&quot;Title&quot;:&quot;Austin Powers&quot;,&quot;Actors&quot;:{&quot;Austin Powers&quot;:&quot;Mike Myers&quot;}}"><pre>@ ["Movies",67,"Title"]
<span><span>-</span> "Dr. Strangelove"</span>
<span><span>+</span> "Dr. Evil Love"</span>
@ ["Movies",67,"Actors","Dr. Strangelove"]
<span><span>-</span> "Peter Sellers"</span>
<span><span>+</span> "Mike Myers"</span>
@ ["Movies",102]
<span><span>+</span> {"Title":"Austin Powers","Actors":{"Austin Powers":"Mike Myers"}}</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@ [&quot;Movies&quot;,67,&quot;Tags&quot;,{}]
- &quot;Romance&quot;
+ &quot;Action&quot;
+ &quot;Comedy&quot;"><pre>@ ["Movies",67,"Tags",{}]
<span><span>-</span> "Romance"</span>
<span><span>+</span> "Action"</span>
<span><span>+</span> "Comedy"</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Cookbook</h2><a id="user-content-cookbook" aria-label="Permalink: Cookbook" href="#cookbook"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Use git diff to produce a structural diff:</h3><a id="user-content-use-git-diff-to-produce-a-structural-diff" aria-label="Permalink: Use git diff to produce a structural diff:" href="#use-git-diff-to-produce-a-structural-diff"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git difftool -yx jd @ -- foo.json
@ [&quot;foo&quot;]
- &quot;bar&quot;
+ &quot;baz&quot;"><pre>git difftool -yx jd @ -- foo.json
@ ["foo"]
<span><span>-</span> "bar"</span>
<span><span>+</span> "baz"</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">See what changes in a Kubernetes Deployment:</h3><a id="user-content-see-what-changes-in-a-kubernetes-deployment" aria-label="Permalink: See what changes in a Kubernetes Deployment:" href="#see-what-changes-in-a-kubernetes-deployment"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="kubectl get deployment example -oyaml > a.yaml
kubectl edit deployment example
# change cpu resource from 100m to 200m
kubectl get deployment example -oyaml | jd -yaml a.yaml"><pre>kubectl get deployment example -oyaml <span>&gt;</span> a.yaml
kubectl edit deployment example
<span><span>#</span> change cpu resource from 100m to 200m</span>
kubectl get deployment example -oyaml <span>|</span> jd -yaml a.yaml</pre></div>
<p dir="auto">output:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@ [&quot;metadata&quot;,&quot;annotations&quot;,&quot;deployment.kubernetes.io/revision&quot;]
- &quot;2&quot;
+ &quot;3&quot;
@ [&quot;metadata&quot;,&quot;generation&quot;]
- 2
+ 3
@ [&quot;metadata&quot;,&quot;resourceVersion&quot;]
- &quot;4661&quot;
+ &quot;5179&quot;
@ [&quot;spec&quot;,&quot;template&quot;,&quot;spec&quot;,&quot;containers&quot;,0,&quot;resources&quot;,&quot;requests&quot;,&quot;cpu&quot;]
- &quot;100m&quot;
+ &quot;200m&quot;
@ [&quot;status&quot;,&quot;conditions&quot;,1,&quot;lastUpdateTime&quot;]
- &quot;2021-12-23T09:40:39Z&quot;
+ &quot;2021-12-23T09:41:49Z&quot;
@ [&quot;status&quot;,&quot;conditions&quot;,1,&quot;message&quot;]
- &quot;ReplicaSet \&quot;nginx-deployment-787d795676\&quot; has successfully progressed.&quot;
+ &quot;ReplicaSet \&quot;nginx-deployment-795c7f5bb\&quot; has successfully progressed.&quot;
@ [&quot;status&quot;,&quot;observedGeneration&quot;]
- 2
+ 3"><pre>@ ["metadata","annotations","deployment.kubernetes.io/revision"]
<span><span>-</span> "2"</span>
<span><span>+</span> "3"</span>
@ ["metadata","generation"]
<span><span>-</span> 2</span>
<span><span>+</span> 3</span>
@ ["metadata","resourceVersion"]
<span><span>-</span> "4661"</span>
<span><span>+</span> "5179"</span>
@ ["spec","template","spec","containers",0,"resources","requests","cpu"]
<span><span>-</span> "100m"</span>
<span><span>+</span> "200m"</span>
@ ["status","conditions",1,"lastUpdateTime"]
<span><span>-</span> "2021-12-23T09:40:39Z"</span>
<span><span>+</span> "2021-12-23T09:41:49Z"</span>
@ ["status","conditions",1,"message"]
<span><span>-</span> "ReplicaSet \"nginx-deployment-787d795676\" has successfully progressed."</span>
<span><span>+</span> "ReplicaSet \"nginx-deployment-795c7f5bb\" has successfully progressed."</span>
@ ["status","observedGeneration"]
<span><span>-</span> 2</span>
<span><span>+</span> 3</span></pre></div>
<p dir="auto">apply these change to another deployment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# edit file &quot;patch&quot; to contain only the hunk updating cpu request
kubectl patch deployment example2 --type json --patch &quot;$(jd -t jd2patch ~/patch)&quot;"><pre><span><span>#</span> edit file "patch" to contain only the hunk updating cpu request</span>
kubectl patch deployment example2 --type json --patch <span><span>"</span><span><span>$(</span>jd -t jd2patch <span>~</span>/patch<span>)</span></span><span>"</span></span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[With more legal action on the horizon, how long before Archive.org closes? (108 pts)]]></title>
            <link>https://lunduke.locals.com/post/6079435/the-internet-archive-loses-appeal-as-expected</link>
            <guid>41482620</guid>
            <pubDate>Sun, 08 Sep 2024 19:42:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lunduke.locals.com/post/6079435/the-internet-archive-loses-appeal-as-expected">https://lunduke.locals.com/post/6079435/the-internet-archive-loses-appeal-as-expected</a>, See on <a href="https://news.ycombinator.com/item?id=41482620">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        The Internet Archive Loses Appeal. As Expected.    </p><div>
        <p dir="ltr">The United States Court of Appeals (Second Circuit) just issued a ruling against the Internet Archive (Archive.org) -- rejecting their appeal, and upholding a previous ruling against them in the<a href="https://lunduke.locals.com/post/5016077/the-internet-archives-digital-lending-puts-the-entire-service-at-risk" target="_blank" rel="noreferrer noopener"> Hachette vs Internet Archive</a> legal battle.</p><p>Make no mistake: This is very bad news for both the Internet Archive, Archive.org users, as well as other archival projects.</p><p><img src="https://media3.locals.com/images/posts/2024-09-05/102127/102127_nexkj7fbyd1uvxr_custom.jpeg" alt="" width="483" height="348"></p><h3>Hachette v. Internet Archive: The Short, Short Version</h3><p dir="ltr">To make sure everyone is up to speed, here is the<a href="https://www.youtube.com/watch?v=5X4HYA-lB-U" target="_blank" rel="noreferrer noopener"> short, short version</a> of this legal battle.</p><p dir="ltr">For many years, the Internet Archive has been creating digital copies of physical books (by scanning them) -- then allowing people to "borrow" those digital versions from Archive.org (in theory limiting the total digital books being "lent out" to the count of the physical books in the Archive's possession).</p><p dir="ltr">They never obtained permissions from the authors or publishers to do any of this.</p><p dir="ltr">In 2020, during the Covid lockdowns, the Internet Archive launched the "National Emergency Library" -- where they removed that "1 physical book : 1 digital book lent out" restriction.&nbsp; Meaning anybody on the Internet could obtain digital scans of physical books... and the Archive could "Lend Out" an unlimited number of digital copies based on a single physical copy.</p><p dir="ltr">Again.&nbsp; No permission was obtained from the writers or publishers.</p><p dir="ltr">Thus -- to the surprise of absolutely nobody -- the "<a href="https://lunduke.locals.com/post/5016077/the-internet-archives-digital-lending-puts-the-entire-service-at-risk" target="_blank" rel="noreferrer noopener">Hachette v. Internet Archive</a>" legal battle began.</p><p dir="ltr">And... The Internet Archive lost.&nbsp; The judge<a href="https://lunduke.locals.com/post/5016077/the-internet-archives-digital-lending-puts-the-entire-service-at-risk" target="_blank" rel="noreferrer noopener"> ruled in favor of the publishers</a> (including Hachette, Wiley, Penguin Random House, &amp; HarperCollins).</p><p>Naturally, Internet Archive appealed that ruling.&nbsp; But, boy-howdy, was their appeal a strange one which was destined to fail.</p><h3>The Strange Appeal of The Internet Archive</h3><p dir="ltr">On April 19th of 2024, the<a href="https://lunduke.locals.com/post/5556650/the-internet-archives-last-ditch-effort-to-save-itself" target="_blank" rel="noreferrer noopener"> Internet Archive filed their final brief</a> in their attempt to appeal this ruling against them.</p><p dir="ltr">In that ruling, one of the Internet Archive's core arguments was that it cost the Internet Archive a lot of money to make so many digital copies of books without permission... so, therefore, the Internet Archive should be allowed to do it.</p><p dir="ltr">That is neither a joke nor an exaggeration.&nbsp; It sounds weird, because it is weird.</p><p dir="ltr">The Internet Archive truly attempted to make the case that spending a lot of money committing a crime... should make that crime legal.&nbsp; (Could you imagine the mafia making that case?&nbsp; Wild.)</p><p dir="ltr">You can<a href="https://lunduke.locals.com/post/5556650/the-internet-archives-last-ditch-effort-to-save-itself" target="_blank" rel="noreferrer noopener"> read the full analysis</a>, by The Lunduke Journal, of the appeal (including the appeal itself) for yourself for more details.</p><p dir="ltr">The reality is... there was never any chance that the Internet Archive's attempted appeal was going to be successful.&nbsp; Their defensive arguments were highly illogical (bordering on flights of fancy), and brought nothing new or noteworthy to the case.&nbsp; This was all painfully obvious.</p><h3>The Lost Appeal</h3><p dir="ltr">On Wednesday, September 4th, 2024, the opinion was handed down from the United States Court of Appeals.</p><p dir="ltr">While the full ruling is roughly 64 pages long, this single paragraph -- from the second page -- summarizes things quite well:</p><blockquote><p>"This appeal presents the following question: <strong>Is it “fair use”</strong> for a nonprofit organization <strong>to scan copyright-protected print books in their entirety, and distribute those digital copies online, in full, for free</strong>, subject to a one-to-one owned-to-loaned ratio between its print copies and the digital copies it makes available at any given time, <strong>all without authorization from the copyright-holding publishers or authors?</strong> Applying the relevant provisions of the Copyright Act as well as binding Supreme Court and Second Circuit precedent, <strong>we conclude the answer is no</strong>. We therefore AFFIRM."</p></blockquote><p dir="ltr">To call out the truly important parts:</p><p dir="ltr">"Question: Is it 'fair use' ... to scan copyright-protected print books in their entirety, and distribute those digital copies online, in full, for free ... all without authorization from the copyright-holding publishers or authors? ... we conclude the answer is no."</p><p dir="ltr">You can<a href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf" target="_blank" rel="noreferrer noopener"> read the entire 64 page ruling</a> for yourself.&nbsp; Heck.&nbsp; You can<a href="https://archive.org/details/hachette-internet-archive-appellate-opinion" target="_blank" rel="noreferrer noopener"> even read it on Archive.org</a>.&nbsp; But that line, right there, sums it all up.</p><p>Naturally, the Internet Archive<a href="https://blog.archive.org/2024/09/04/internet-archive-responds-to-appellate-opinion/" target="_blank" rel="noreferrer noopener"> has issued a statement</a>.&nbsp; Albeit... a short one.</p><blockquote><p>"<strong>We are disappointed in today’s opinion</strong> about the Internet Archive’s digital lending of books that are available electronically elsewhere. We are reviewing the court’s opinion and will continue to defend the rights of libraries to own, lend, and preserve books."</p></blockquote><h3>What Happens Now?</h3><p dir="ltr">The Internet Archive gets sued by some of the biggest book publishers... and loses.</p><p dir="ltr">The Internet Archive appeals... and loses.</p><p dir="ltr">What happens next?&nbsp; Well.&nbsp; Unfortunately -- for both the Internet Archive, and its users -- the future looks rather bleak.</p><p dir="ltr">First and foremost: Has the Internet Archive made, and distributed, digital copies of work you own?&nbsp; This ruling will certainly not hurt your case should you decide to take legal action against Archive.org.</p><p dir="ltr">And -- holy smokes -- the amount of copyrighted material on Archive.org is absolutely massive.</p><p dir="ltr">The<a href="https://archive.org/details/software" target="_blank" rel="noreferrer noopener"> Archive.org software repository</a> alone contains millions of items.&nbsp; With a very large number of them being copyrighted material, posted there without permission of the copyright owner.</p><p dir="ltr">Simply going by the numbers, here's how much material is available on Archive.org (roughly):</p><ul><li>832 Billion archived webpages.</li><li>38 Million printed materials (magazines, books, etc.).</li><li>2.6 Million pieces of software</li><li>11.6 Million videos files.</li><li>15 Million audio files.</li><li>4.7 Million images.</li></ul><p dir="ltr">How many of those items do you think are there without permission (or possibly even knowledge) of the owners or creators?</p><p dir="ltr">Every single one now has an increasingly strong case when looking at potential legal action.</p><p dir="ltr">And it's about to get even worse for the Internet Archive.</p><h3>UMG Recordings v. Internet Archive</h3><p dir="ltr">That's right, the book publishers weren't the only ones taking legal action against Archive.org.&nbsp;</p><p dir="ltr">Universal Music Group and Sony have<a href="https://fingfx.thomsonreuters.com/gfx/legaldocs/jnpwwwejopw/INTERNET%20ARCHVIE%20RECORD%20LABELS%20LAWSUIT%20complaint.pdf" target="_blank" rel="noreferrer noopener"> an ongoing lawsuit against the Internet Archive</a> -- regarding the distribution of 2,749 audio recordings (with potential damages upwards of $412 Million USD).</p><p dir="ltr">Seriously.</p><blockquote><p>"Plaintiffs bring this suit to address Defendants’ <strong>massive ongoing violation</strong> of Plaintiffs’ rights in protected pre-1972 sound recordings. As part of what Defendants have dubbed the “Great 78 Project,” Internet Archive, Blood, and GBLP have <strong>willfully reproduced thousands of Plaintiffs’ protected sound recordings without authorization by copying physical records into digital files. Internet Archive then willfully uploaded, distributed, and digitally transmitted those illegally copied sound recordings millions of times from Internet Archive’s website</strong>."</p></blockquote><p dir="ltr">Sound familiar?&nbsp; Digital copies.&nbsp; No permission from the artists or publishers.&nbsp; Free downloads for everyone.</p><p>Naturally, the Internet Archive attempted to have this suit dismissed... but<a href="https://fingfx.thomsonreuters.com/gfx/legaldocs/zdpxxyqrepx/INTERNET%20ARCHIVE%20RECORD%20LABELS%20LAWSUIT%20mtd.pdf" target="_blank" rel="noreferrer noopener"> their attempt was denied</a> in May of 2024.&nbsp; (Because if there's one constant in life... it's that the Internet Archive always loses in court.)&nbsp; That case is going forward.</p><p><img src="https://media3.locals.com/images/posts/2024-09-05/102127/102127_lni79378fyrnosk_custom.jpeg" alt="" width="536" height="204"></p><p dir="ltr">What happens if the Internet Archive loses this UMG / Sony case?&nbsp; What happens if they are ordered to pay $412 Million in damages?</p><p dir="ltr">To put it simply: Archive.org doesn't have that kind of money.&nbsp; They bring in roughly $20 Million (give or take) per year.&nbsp; That type of legal liability would absolutely destroy the Internet Archive.</p><p><img src="https://media3.locals.com/images/posts/2024-09-05/102127/102127_wwmuc3m8nhgibvl_custom.jpeg" alt="" width="548" height="171"></p><p dir="ltr">And, here's the thing, the Internet Archive is almost assuredly going to lose that lawsuit as well.</p><p dir="ltr">Regardless of what you, I, or anyone else thinks of the Internet Archive -- and, make no mistake, I use that service several times a week (and love it) -- the law here is incredibly clear and well tested.</p><p dir="ltr">The Internet Archive runs one of the largest (if not the largest) website of pirated and stolen digital material on the planet.&nbsp; Sure, it may also provide extremely valuable (and often, very legal) services as well.. but that doesn't make those crimes go away.</p><p dir="ltr">With each legal defeat, the Internet Archive grows increasingly vulnerable to additional attacks.</p><p dir="ltr">Simply being logical about it... it seems highly likely that we'll see additional suits brought against the Internet Archive in the months ahead.&nbsp; Books, music, TV shows, software... Archive.org contains a massive mountain of copyrighted material in all areas.&nbsp; These are suits which the Internet Archive would be almost certain to lose.</p><p dir="ltr">With this reality looming, how long until Archive.org will be forced to shut down entirely?&nbsp; That day is likely not far off... and a sad day it will be.</p><h3 dir="ltr">The Archive Had to Know This Was Coming</h3><p dir="ltr">The truly sad part?&nbsp; The leadership of the Internet Archive had to know exactly what they were doing.</p><p dir="ltr">Every step of the way, it was obvious that they were going to lock horns with publishers (and lose).</p><p dir="ltr">Heck, I<a href="https://lunduke.locals.com/post/5016077/the-internet-archives-digital-lending-puts-the-entire-service-at-risk" target="_blank" rel="noreferrer noopener"> told them</a>. <a href="https://lunduke.locals.com/post/5556650/the-internet-archives-last-ditch-effort-to-save-itself" target="_blank" rel="noreferrer noopener">&nbsp;Repeatedly</a>.</p><p dir="ltr">But, even if The Lunduke Journal hadn't pointed this out... it was a brutally obvious certainty to anyone even mildly familiar with copyright law and the workings of Archive.org.</p><p dir="ltr">Which means: The Internet Archive knowingly put their entire service at risk (including the Wayback Machine, the massive archive or pre-copyright audio recordings, etc.) because they wanted to publish copyrighted material against the wishes of the authors or publishers.</p><p dir="ltr">Despite this, they continue to push a public perception campaign where they pretend that publishers and authors are burning their own books.&nbsp; When the reality is... the books are still available a wide variety of ways.&nbsp; Archive.org simply got in trouble for copying and distributing them without permission.</p><p><img src="https://media3.locals.com/images/posts/2024-09-05/102127/102127_cjj1eu9eameysfk_custom.jpeg" alt="" width="573" height="203"></p><p dir="ltr">Something I find truly fascinating about all of this, is that The Lunduke Journal will -- as usual -- get yelled at (rather extensively) for this article.&nbsp; For simply pointing out the current reality of copyright law and how the Internet Archive has, knowingly, violated it.</p><p dir="ltr">People love Archive.org.&nbsp; Heck, I love Archive.org.</p><p dir="ltr">And people are allowing their love for that website to convince them that anyone being critical of it... must, necessarily, be bad and evil.&nbsp; An enemy.</p><p dir="ltr">But it is not The Lunduke Journal who is putting The Internet Archive in danger of being shut down.</p><p dir="ltr">Neither is it Sony, Hachette, Random House, or HarperCollins who are putting The Internet Archive in danger.</p><p dir="ltr">No, sir.</p><p dir="ltr">The only one putting The Internet Archive in danger... is The Internet Archive.</p><div>
    <p><img src="https://media3.locals.com/images/avatars/102127/102127_pavt7hft2xvhhod_thumb.png" alt="community logo">
    </p>
    <p>
        Join the Lunduke Community
    </p>
    <p>
        To read more articles like this, sign up and join my community today
    </p>
    
</div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[White House asks agencies to step up internet routing security efforts (118 pts)]]></title>
            <link>https://www.reuters.com/world/us/white-house-asks-agencies-step-up-internet-routing-security-efforts-2024-09-03/</link>
            <guid>41482087</guid>
            <pubDate>Sun, 08 Sep 2024 18:25:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/us/white-house-asks-agencies-step-up-internet-routing-security-efforts-2024-09-03/">https://www.reuters.com/world/us/white-house-asks-agencies-step-up-internet-routing-security-efforts-2024-09-03/</a>, See on <a href="https://news.ycombinator.com/item?id=41482087">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/us/white-house-asks-agencies-step-up-internet-routing-security-efforts-2024-09-03/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Core: New way to develop video games (250 pts)]]></title>
            <link>https://github.com/damn/core</link>
            <guid>41482060</guid>
            <pubDate>Sun, 08 Sep 2024 18:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/damn/core">https://github.com/damn/core</a>, See on <a href="https://news.ycombinator.com/item?id=41482060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">core</h2><a id="user-content-core" aria-label="Permalink: core" href="#core"></a></p>
<p dir="auto">Core is an experimental new way to write videogames.</p>
<p dir="auto">It uses a simple component system, where components are just clojure vectors of <code>[keyword value]</code> and the different entities are clojure maps.</p>
<p dir="auto">Side effects in the game are just components like <code>[:tx/foo param]</code> named 'tx=transaction' similar to the datomic structure.</p>
<p dir="auto">The whole game state is stored in one atom: <code>app/state</code> and entities are again atoms inside the main atom (like in our universe).</p>
<p dir="auto">The whole content of the application is stored in one <code>resources/properties.edn</code> and uses malli-schemas for validation and can be edited with a GUI as seen in the screenshot below.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/842388/365458510-1c7451d0-57f0-48c9-bee3-8eedf332910f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU4MzEzMDIsIm5iZiI6MTcyNTgzMTAwMiwicGF0aCI6Ii84NDIzODgvMzY1NDU4NTEwLTFjNzQ1MWQwLTU3ZjAtNDhjOS1iZWUzLThlZWRmMzMyOTEwZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkwOFQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYjIxNjFiYzJmMjY2MjY3YWUzZDFlMmZlNGE4N2MyNmI4NTNiY2QzMTkwMDZhYzQ3ZGRmNzI5NmI0MTcxMjQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.yF1HOGqfRE9ineDeinS4emwUsDpgmlkXHU6v3anJydI"><img width="1680" alt="screenshot" src="https://private-user-images.githubusercontent.com/842388/365458510-1c7451d0-57f0-48c9-bee3-8eedf332910f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU4MzEzMDIsIm5iZiI6MTcyNTgzMTAwMiwicGF0aCI6Ii84NDIzODgvMzY1NDU4NTEwLTFjNzQ1MWQwLTU3ZjAtNDhjOS1iZWUzLThlZWRmMzMyOTEwZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkwOFQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYjIxNjFiYzJmMjY2MjY3YWUzZDFlMmZlNGE4N2MyNmI4NTNiY2QzMTkwMDZhYzQ3ZGRmNzI5NmI0MTcxMjQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.yF1HOGqfRE9ineDeinS4emwUsDpgmlkXHU6v3anJydI"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/842388/365458920-aee42c1d-4b34-4efc-b40a-21fd0fd9e3c9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU4MzEzMDIsIm5iZiI6MTcyNTgzMTAwMiwicGF0aCI6Ii84NDIzODgvMzY1NDU4OTIwLWFlZTQyYzFkLTRiMzQtNGVmYy1iNDBhLTIxZmQwZmQ5ZTNjOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkwOFQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMzJiNzNkOGUwZWEzMjQyM2FmODhjZTE0ZTYyZmJkYzk2YjgyZjMxNGYxNzM4Yjc5MjZlMDZjZTMzYmU3OWMxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ehjsymwI04Gj940bQZbx6FDHiVVQ4uKhMg26gQq9Rks"><img width="1432" alt="Screenshot 2024-09-08 at 11 53 59 PM" src="https://private-user-images.githubusercontent.com/842388/365458920-aee42c1d-4b34-4efc-b40a-21fd0fd9e3c9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU4MzEzMDIsIm5iZiI6MTcyNTgzMTAwMiwicGF0aCI6Ii84NDIzODgvMzY1NDU4OTIwLWFlZTQyYzFkLTRiMzQtNGVmYy1iNDBhLTIxZmQwZmQ5ZTNjOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkwOFQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMzJiNzNkOGUwZWEzMjQyM2FmODhjZTE0ZTYyZmJkYzk2YjgyZjMxNGYxNzM4Yjc5MjZlMDZjZTMzYmU3OWMxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ehjsymwI04Gj940bQZbx6FDHiVVQ4uKhMg26gQq9Rks"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to start developing</h2><a id="user-content-how-to-start-developing" aria-label="Permalink: How to start developing" href="#how-to-start-developing"></a></p>
<ul dir="auto">
<li>Starts an NREPL-Server</li>
<li>On application close (ESC in the main menu), clojure.tools.namespace will do  refresh on any changed files and restart the app.</li>
<li>On any error the JVM does not have to be restarted, you can fix the error and call <code>dev-loop/restart!'</code> I have bound it on my VIM to F5 with:
<code>nmap &lt;F5&gt; :Eval (do (in-ns 'dev-loop)(restart!))</code></li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Code Licensed under MIT License.</h2><a id="user-content-code-licensed-under-mit-license" aria-label="Permalink: Code Licensed under MIT License." href="#code-licensed-under-mit-license"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Asset license</h2><a id="user-content-asset-license" aria-label="Permalink: Asset license" href="#asset-license"></a></p>
<p dir="auto">The assets used are proprietary and not open source.</p>
<ul dir="auto">
<li>Tilesets by <a href="https://winlu.itch.io/" rel="nofollow">https://winlu.itch.io/</a></li>
<li>Creatures, Items, Skill-Icons,FX and other assets by <a href="https://www.oryxdesignlab.com/" rel="nofollow">https://www.oryxdesignlab.com</a></li>
<li>Cursors from Leonid Deburger <a href="https://deburger.itch.io/" rel="nofollow">https://deburger.itch.io/</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Serving AI from the Basement – 192GB of VRAM Setup (280 pts)]]></title>
            <link>https://ahmadosman.com/blog/serving-ai-from-basement/</link>
            <guid>41481852</guid>
            <pubDate>Sun, 08 Sep 2024 17:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ahmadosman.com/blog/serving-ai-from-basement/">https://ahmadosman.com/blog/serving-ai-from-basement/</a>, See on <a href="https://news.ycombinator.com/item?id=41481852">Hacker News</a></p>
Couldn't get https://ahmadosman.com/blog/serving-ai-from-basement/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The muscular imagination of Iain M. Banks: a future you might want (213 pts)]]></title>
            <link>https://www.robinsloan.com/moonbound/muscular-imagination/</link>
            <guid>41481821</guid>
            <pubDate>Sun, 08 Sep 2024 17:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.robinsloan.com/moonbound/muscular-imagination/">https://www.robinsloan.com/moonbound/muscular-imagination/</a>, See on <a href="https://news.ycombinator.com/item?id=41481821">Hacker News</a></p>
Couldn't get https://www.robinsloan.com/moonbound/muscular-imagination/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA["Unstripping" binaries: Restoring debugging information in GDB with Pwndbg (139 pts)]]></title>
            <link>https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/</link>
            <guid>41481682</guid>
            <pubDate>Sun, 08 Sep 2024 17:23:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/">https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/</a>, See on <a href="https://news.ycombinator.com/item?id=41481682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

			
				
<article id="post-108110">
	<!-- .entry-header -->

	<div>
		<p><em>By Jason An</em></p>
<p>GDB loses significant functionality when debugging binaries that lack debugging symbols (also known as “stripped binaries”). Function and variable names become meaningless addresses; setting breakpoints requires tracking down relevant function addresses from an external source; and printing out structured values involves staring at a memory dump trying to manually discern field boundaries.</p>
<p>That’s why this summer at Trail of Bits, I extended <a href="https://github.com/pwndbg/pwndbg">Pwndbg</a>—a plugin for GDB maintained by my mentor, <a href="https://disconnect3d.pl/">Dominik Czarnota</a>—with two new features to bring the stripped debugging experience closer to what you’d expect from a debugger in an IDE. Pwndbg now integrates Binary Ninja for enhanced GDB+Pwndbg intelligence and enables dumping Go structures for improved Go binary debugging.</p>
<h3>Binary Ninja integration</h3>
<p>To help improve GDB+Pwndbg intelligence during debugging, I integrated Pwndbg with <a href="https://binary.ninja/">Binary Ninja</a>, a popular decompiler with a versatile scripting API, by installing an XML-RPC server inside Binary Ninja, and then querying it from Pwndbg. This allows Pwndbg to access Binary Ninja’s analysis database, which is used for syncing symbols, function signatures, stack variable offsets, and more, recovering much of the debugging experience.</p>
<div id="attachment_108114"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-108114" data-attachment-id="108114" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_1-4/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1.png" data-orig-size="818,174" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_1" data-image-description="" data-image-caption="<p>Figure 1: Pwndbg showing symbols and argument names synced from Binary Ninja in a stripped binary</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1-300x64.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1.png" alt="" width="818" height="174" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1.png 818w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1-300x64.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_1-768x163.png 768w" sizes="(max-width: 818px) 100vw, 818px"></p><p id="caption-attachment-108114">Figure 1: Pwndbg showing symbols and argument names synced from Binary Ninja in a stripped binary</p></div>
<p>For the decompilation, I pulled the tokens from Binary Ninja instead of serializing them to text first. This allows for fully syntax-highlighted decompilation, configurable to use any of <a href="https://docs.binary.ninja/dev/bnil-overview.html">Binary Ninja’s 3 IL levels</a>. The decompilation is shown directly in the Pwndbg context, with the current line highlighted, just like in the assembly view.</p>
<div id="attachment_108115"><p><img decoding="async" aria-describedby="caption-attachment-108115" data-attachment-id="108115" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_2-4/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2.png" data-orig-size="1229,423" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_2" data-image-description="" data-image-caption="<p>Figure 2: Decompilation pulled from Binary Ninja and displayed in Pwndbg</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2-300x103.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2.png" alt="" width="1229" height="423" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2.png 1229w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2-300x103.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_2-768x264.png 768w" sizes="(max-width: 1229px) 100vw, 1229px"></p><p id="caption-attachment-108115">Figure 2: Decompilation pulled from Binary Ninja and displayed in Pwndbg</p></div>
<p>I also implemented a feature to display the current program counter (PC) register as an arrow inside Binary Ninja and a feature to set breakpoints from within Binary Ninja to reduce the amount of switching to and from Pwndbg involved.</p>
<div id="attachment_108117"><p><img decoding="async" aria-describedby="caption-attachment-108117" data-attachment-id="108117" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_3-4/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3.png" data-orig-size="1547,290" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_3" data-image-description="" data-image-caption="<p>Figure 3: Binary Ninja displaying icons for the current PC and breakpoints</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3-300x56.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3.png" alt="" width="1547" height="290" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3.png 1547w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3-300x56.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3-768x144.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_3-1536x288.png 1536w" sizes="(max-width: 1547px) 100vw, 1547px"></p><p id="caption-attachment-108117">Figure 3: Binary Ninja displaying icons for the current PC and breakpoints</p></div>
<p>The most involved component of the integration is syncing stack variable names. Anywhere a stack address appears in Pwndbg, like in the register view, stack view, or function argument previews, the integration will check if it’s a named stack variable in Binary Ninja. If it is, it will show the proper label. It will even check parent stack frames so that variables from the caller will still be labeled properly.</p>
<div id="attachment_108118"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108118" data-attachment-id="108118" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_4-3/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4.png" data-orig-size="1875,719" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_4" data-image-description="" data-image-caption="<p>Figure 4: A demonstration of how stack variable labeling is displayed</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-300x115.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-1650x633.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-1650x633.png" alt="" width="690" height="265" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-1650x633.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-300x115.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-768x295.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4-1536x589.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_4.png 1875w" sizes="(max-width: 690px) 100vw, 690px"></p><p id="caption-attachment-108118">Figure 4: A demonstration of how stack variable labeling is displayed</p></div>
<p>The main difficulty in implementing this feature came from the fact that Binary Ninja only provides stack variables as an offset from the stack frame base, so the frame base needs to be deduced in order to compute absolute addresses. Most architectures, like x86, have a frame pointer register that points to the frame base, but most architectures, including x86, <a href="https://stackoverflow.com/q/14666665">don’t actually <em>need</em> the frame pointer</a>, so compilers are free to use it like any other register.</p>
<p>Fortunately, Binary Ninja has constant value propagation, so it can tell if registers are a predictable offset from the frame base. So, my implementation will first check if the frame pointer is actually the frame base, and if it’s not, it will see if the stack pointer advanced a predictable amount (which is usually true with modern compilers); otherwise, it will check every other general-purpose register to try to find one with a consistent offset. Technically, this approach won’t work all the time, but in practice, it should almost never fail.</p>
<h3>Go debugging</h3>
<p>A common pain point when debugging executables compiled from non-C programming languages (and sometimes even C) is that they tend to have complex memory layouts that make it hard to dump values. A benign example is dumping a <a href="https://go.dev/blog/slices-intro">slice in Go</a>, which requires one command to dump the pointer and length, and another to examine the slice contents. Dumping a map, on the other hand, can require over ten commands for a small map, and hundreds for larger ones, which is completely impractical for a human.</p>
<p>That’s why I created the <code>go-dump</code> command. Using <a href="https://github.com/golang/go/tree/master/src/runtime">the Go compiler’s source code</a> as a reference, I implemented dumping for all of Go’s built-in types, including integers, strings, complex numbers, pointers, slices, arrays, and maps. The built-in types are notated just like they are in Go, so you don’t need to learn any new syntax to use the command properly.</p>
<div id="attachment_108121"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108121" data-attachment-id="108121" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_5-3/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5.png" data-orig-size="794,81" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_5" data-image-description="" data-image-caption="<p>Figure 5: Dumping a simple map type using the go-dump command</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5-300x31.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5.png" alt="" width="794" height="81" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5.png 794w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5-300x31.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_5-768x78.png 768w" sizes="(max-width: 794px) 100vw, 794px"></p><p id="caption-attachment-108121">Figure 5: Dumping a simple map type using the go-dump command</p></div>
<p>The <code>go-dump</code> command is also capable of parsing and dumping arbitrarily nested types so that every type can be dumped with just one command.</p>
<div id="attachment_108122"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108122" data-attachment-id="108122" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_6-2/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6.png" data-orig-size="608,65" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_6" data-image-description="" data-image-caption="<p>Figure 6: Dumping a more complex slice of map types using the go-dump command</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6-300x32.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6.png" alt="" width="608" height="65" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6.png 608w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_6-300x32.png 300w" sizes="(max-width: 608px) 100vw, 608px"></p><p id="caption-attachment-108122">Figure 6: Dumping a more complex slice of map types using the go-dump command</p></div>
<h3>Parsing Go’s runtime types</h3>
<p>While Go-specific dumping is much nicer than manual memory dumping, it still poses many usability concerns. You need to know the full type of the value you’re dumping, which can be hard to determine and usually involves a lot of guesswork, especially when dealing with structs that have many fields or nested structs. Even if you have deduced the full type, some things are still unknowable because they have no effect on compilation, like struct field names and type names for user-defined types.</p>
<p>Conveniently, the Go compiler emits a runtime type object for <strong>every</strong> type used in the program (to be used with <a href="https://pkg.go.dev/reflect">the <code>reflect</code> package</a>), which contains struct layouts for arbitrarily nested structs, type names, size, alignment, and more. These type objects can also be matched up to values of that type, as interface values store a pointer to the type object along with a pointer to the data, and heap-allocated values have their type object passed into their allocation function (usually <code>runtime.newobject</code>).</p>
<p>I wrote a parser capable of recursively extracting this information in order to process type information for arbitrarily nested types. This parser is exposed via the <code>go-type</code> command, which displays information about a runtime type given its address. For structs, this information includes the type, name, and offset of every field.</p>
<div id="attachment_108125"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108125" data-attachment-id="108125" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_7-2/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7.png" data-orig-size="643,595" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_7" data-image-description="" data-image-caption="<p>Figure 7: Examining a struct type that consists of an int and a string</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7-300x278.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7-300x278.png" alt="" width="300" height="278" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7-300x278.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_7.png 643w" sizes="(max-width: 300px) 100vw, 300px"></p><p id="caption-attachment-108125">Figure 7: Examining a struct type that consists of an int and a string</p></div>
<p>This can be used to dump values in two ways. The first, easier way only works for interface values, since the type pointer is stored along with the data pointer, making it easy to automatically retrieve. These can be dumped using Go’s any type for empty interfaces (ones with no methods), and the <code>interface</code> type for non-empty interfaces. When dumping, the command will automatically retrieve and parse the type, leading to a seamless dump without having to enter any type information.</p>
<div id="attachment_108126"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108126" data-attachment-id="108126" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_8-2/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8.png" data-orig-size="1388,84" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_8" data-image-description="" data-image-caption="<p>Figure 8: Dumping an interface value without specifying any type information</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8-300x18.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8.png" alt="" width="1388" height="84" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8.png 1388w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8-300x18.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_8-768x46.png 768w" sizes="(max-width: 1388px) 100vw, 1388px"></p><p id="caption-attachment-108126">Figure 8: Dumping an interface value without specifying any type information</p></div>
<p>The second way works for all values but requires you to find and specify the pointer to the type for the value. In many cases, it is as easy as looking for the pointer passed into the function that allocated the value, but for global variables or variables whose allocation may be hard to find, some guesswork may be involved in finding the type. However, this method is generally still easier than trying to manually deduce the type layout and is capable of dumping even the most complex types. I tested it on a few large struct types in a stripped build of the Go compiler, which is one of the largest and most complex open-source Go codebases, and it was able to dump all of them with no problem.</p>
<div id="attachment_108128"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-108128" data-attachment-id="108128" data-permalink="https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/figure_9-2/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9.png" data-orig-size="1792,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_9" data-image-description="" data-image-caption="<p>Figure 9: Dumping a complex structure in the Go compiler only specifying a type address, using the -p flag for pretty printing</p>
" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-300x176.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-1650x967.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-1650x967.png" alt="" width="690" height="404" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-1650x967.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-300x176.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-768x450.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9-1536x900.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/09/figure_9.png 1792w" sizes="(max-width: 690px) 100vw, 690px"></p><p id="caption-attachment-108128">Figure 9: Dumping a complex structure in the Go compiler only specifying a type address, using the -p flag for pretty printing</p></div>
<h3>Recap and looking forward</h3>
<p>This summer, I enhanced Pwndbg so it can be integrated with Binary Ninja to access its rich debugging information. I also added the <code>go-dump</code> command for dumping Go values. All of this is available on the Pwndbg dev branch and its latest release.</p>
<p>Moving forward, there’s even more that can be done to improve the debugging experience. I developed my Binary Ninja integration with a modular design so that it would be easy to add support for more decompilers in the future. I think it would be amazing to fully support <a href="https://ghidra-sre.org/">Ghidra</a> (the current integration only syncs decompilation), as Ghidra is a free and open-source decompiler, making it accessible to everyone who wants to use the functionality.</p>
<p>In terms of Go debugging, work can be done to add better support for displaying and working with goroutines, which is currently one of the major advantages of <a href="https://github.com/go-delve/delve">the Delve debugger</a> (a debugger specialized for debugging Go) over GDB/Pwndbg. For example, Delve is capable of listing every goroutine and the instruction that created them and it also has a command to switch between goroutines.</p>
<h3>Acknowledgments</h3>
<p>Working at Trail of Bits this summer has been an absolutely amazing experience, and I would like to thank them for giving me the opportunity to work on Pwndbg. In particular, I would like to thank my manager, Dominik Czarnota, for being incredibly responsive about reviewing my code and giving me feedback and ideas about my work, and the Pwndbg community, as they have been incredibly helpful with answering any questions I had during the development process.</p>

			</div><!-- .entry-content -->

	
</article><!-- #post-108110 -->
						<!-- #nav-below -->
		
					<!-- #comments .comments-area -->

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Graphics Tricks from Boomers (120 pts)]]></title>
            <link>https://arnaud-carre.github.io/2024-09-08-4ktribute/</link>
            <guid>41481323</guid>
            <pubDate>Sun, 08 Sep 2024 16:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arnaud-carre.github.io/2024-09-08-4ktribute/">https://arnaud-carre.github.io/2024-09-08-4ktribute/</a>, See on <a href="https://news.ycombinator.com/item?id=41481323">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="main">
        <p>Recently I released a 4096 bytes Atari intro, featuring some bandwidth impossible sprites drawing in fullscreen. I hope technical inner details could please any graphics enthusiasts, and not only boomers :)</p>

<h2 id="audience">Audience</h2>

<p>This post is made for anyone interested in oldskool graphics, but also for all retro computers technical details lovers. I will talk about STE blitter, and also how the ATARI famous “fullscreen mode” is working. Some assembly language concepts may be required for the last parts.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<p>I’ll try to split the post into several dedicated parts, so you can pick-up your favourite one!</p>

<ol>
  <li>Atari STE specifications and memory bandwidth limit</li>
  <li>How the high level algorithm work</li>
  <li>Atari famous “Fullscreen”</li>
  <li>Using blitter in Fullscreen</li>
  <li>Final words</li>
</ol>

<h2 id="atari-ste-specifications">Atari STE specifications</h2>
<p>Atari STE is a 8Mhz Motorola 68000 powered machine from the very end of the 80’. It features a 320x200 resolution. It can display up to 16 colors simultaneously. So the frame buffer is exactly 32000 bytes, or 31.25KiB.  ( 4bits per pixel, using a weird bit-plane layout ). Most Atari come with 1MiB of RAM. (that’s not a typo, 1MiB RAM was luxury back in time)</p>

<p>In computer graphics during the 1990s, a common term was “sprite.” A sprite is a 2D bitmap that can be drawn anywhere on the screen. Typically, the term “sprite” refers to a “hardware sprite,” which is a bitmap displayed on the screen without being stored in the frame buffer memory. This approach is very fast because it eliminates the need to read from or write to the frame buffer. However, the Atari does not support hardware sprites. To move small bitmaps around the screen on an Atari, you need to “blit” them into the frame buffer. This means copying the bitmap into the frame buffer, erasing it in the next frame, and then blitting it again at a new position.</p>

<p>These types of graphics are known as “bobs,” short for “Blittable Objects.”</p>

<h2 id="speed-of-light">Speed of light</h2>

<p>To understand the speed of an Atari machine, let’s examine some fast Atari blitter sprite code. In terms of 16-color bobs, the fastest example I know is a demo by Anima, which shows 24 bobs of 32x32 pixels each, running at 50Hz. Our bob is 64x64 pixels, which has four times the area of a 32x32 bob. This generally means it would be about four times slower (though the exact calculation is more complex, this is a reasonable approximation). So, the maximum speed for 64x64 bobs would be 24/4 = 6 bobs on screen. However, our intro displays 16 of them, and in fullscreen! Here is the video of our 4096 bytes demo:</p>

<p><a href="https://youtu.be/d6hCFlM-RUM?t=17"><img src="https://arnaud-carre.github.io/assets/img/4ktribute/vid_4ktribute.jpg" alt="4k Tribute"></a></p>

<p><a href="https://www.pouet.net/prod.php?which=97530" target="_blank">( You can download the 4KiB intro here )</a></p>

<p>Given the memory bandwidth, this should be impossible! That’s exactly the reaction any demo coder wants from the audience: “How is that even possible?”</p>

<p>Like everything in the demoscene, there is a trick to it…</p>

<h2 id="how-the-high-level-algorithm-work">How the high level algorithm work</h2>

<h2 id="history">History</h2>

<p>If you’re not from 90 you can’t imagine the amount of bitmap tricks used by pioneers. One of them is the stroboscopic effect. Just loop over 4 or more screens (you just change the frame buffer address) and you can get complex animation on screen for free. Of course the small amount of memory makes the animation loop pretty quick.</p>

<p>Here is an example of stroboscopic effect: All moving Atari logos in this video don’t cost anything. It’s a 8 frames looping animation. You get the feeling logos are scrolling smoothly. (Syntax Terror by Delta Force)</p>

<p><a href="https://youtu.be/dkXabJG0RLw?t=5980"><img src="https://arnaud-carre.github.io/assets/img/4ktribute/vid_syntax.jpg" alt="Syntax Terror"></a></p>

<h2 id="unlimited-bobs">Unlimited Bobs</h2>
<p>Relying on this stroboscopic effect, some Amiga freaks invented the so-called “unlimited bobs” technique. Just loop 4 or more screens. Each frame, draw a single bob. Don’t even clear it. In the next frame, draw another one, one step ahead.</p>

<p>When looking at the demo you have the feeling of an infinite amount of bobs drawn on screen. Obviously there is just a single one drawn each frame. Even if it’s a funny demo effect, <strong>it doesn’t fool the audience for long</strong>. After a while you’ll notice the screen has been filled with the same bob and the stroboscopic effect starts to kill your eyes.</p>

<p>Here is an exemple of unlimited bobs (Dark Side of the Spoon by ULM, Atari)</p>

<p><a href="https://youtu.be/nqHK4IQhtVo?t=4109"><img src="https://arnaud-carre.github.io/assets/img/4ktribute/vid_ulm.jpg" alt="Dark Side of the Spoon"></a></p>

<h2 id="the-trick-limited-bobs">The trick: Limited Bobs</h2>

<p>Now let’s say I want 4 bobs on screen. Let’s use the unlimited bobs technique. (ie just display a single bob per frame, and use stroboscopic fx for movement illusion).</p>

<p>After 4 frames we have 4 bobs on screen. And now what if I can erase the oldest bob? It’s not as easy as it sounds because the erasing shape could be anything. The oldest bob is “under” all the others, so we have to erase the underlying part only. Let’s hand draw something to see what we should achieve</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/anm5.gif" alt=" Alt Text"></p>

<p>How to only clear the visible part of the very last bob? (The one under all the others)</p>

<p>Here is the trick:</p>

<p>In a off-screen buffer:</p>

<ol>
  <li>Clear the area of the oldest bob in the offscreen buffer</li>
  <li>For N limited bob demo, draw the N-1 other bobs in this offscreen buffer, using OR</li>
  <li>Now the oldest bob offscreen area is a 1 color “mask”!</li>
  <li>You can apply this mask to the real screen, at the oldest bob location</li>
  <li>Compute the next coord of the new bob for the new frame</li>
  <li>Draw this new bob as a classic masked 16 colors bob</li>
</ol>

<p>Here is outstanding quality hand drawing of the algorithm:</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/clearmask.gif" alt=" Alt Text"></p>

<p>Then you just use this 1 color mask to clear the oldest bob on the screen by just applying a AND blit.</p>

<h2 id="why-is-it-faster-bitplans">Why is it faster? Bitplans!</h2>

<p>At the end we draw N bobs! ( N-1 at stage 2, and 1 at stage 6 ). So why the hell is it faster than just drawing N bobs?</p>

<p>Atari is a 16 colors, paletted machine. It means pixels are just indices in a palette ( exactly like 256 colors PNG file, or GIF file). You need 4 bits to encode a 16 colors  index. Atari engineers could have encoded 2 pixels in a byte. But they choose the “bitplan” encoding scheme. If you’re not used to it, it’s quite confusing at first.</p>

<p>Each bitplan is a memory area that contains a single bit of the pixel index. Like, bitplan 0 contains all bits “0” of all the pixel indices. Bitplan 1 contains all bits 1, etc. As an exemple, the very first 2 bytes (16 bits) of bitplan 0 contain the bits “0” of the 16 first pixels of the screen.</p>

<p>When blitting a 16 colors bob, you have to run 4 complete blit operations. ( 1 per bitplan ).
If you want to blit a 8 colors bob, you just need to 3 blit operations ( 8 colors means 3bits per pixel, so 3 bitplans only to fill)</p>

<p>Here is the trick: As the N-1 bobs are drawn in the offscreen buffer to create a 1 color mask, you only need a single blit operation! So the (N-1) single color bob OR drawing in offscreen buffer is 4 times faster than drawing 4bitplans bobs!</p>

<h2 id="atari-famous-fullscreen">Atari famous “Fullscreen”</h2>

<p>Back in time you can connect your Atari or Amiga to any CRT TV. And various TVs had various image position &amp; scale setup. To guarantee graphics are visible, the 320x200 Atari image is in the middle of a very large “border”. You can notice the large white border all around:</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/st_screen.jpg" alt="Alt Text"></p>

<p>The Atari video chip, in charge of generating the video signal, is called “Shifter”. It supports only 3 screen resolutions:</p>

<ol>
  <li>Low re: 320x200, 16 colors</li>
  <li>Medium res: 640x200, 4 colors</li>
  <li>High res: 640x400, monochrome (need a specific 70hz monitor)</li>
</ol>

<p>And two refresh rates:</p>

<ol>
  <li>50hz ( Europe )</li>
  <li>60hz ( U.S )</li>
</ol>

<p>The Shifter is quite basic and not programmable. There is <strong>no way</strong> to display graphics bitmap into this large safety border. It’s just <strong>not possible</strong>. Even Atari hardware engineers that created the video chip didn’t even think about it.</p>

<p>If something is not possible you can imagine freaks from the demoscene will try to break the limits :) In late 80, some pioneer demo crews like Level16, Sync, ST-Connexion and others did the impossible! They displayed bitmap graphics in the safety zone! How the hell does it work?</p>

<h2 id="fooling-the-hardware-with-smart-software">Fooling the hardware with smart software</h2>

<p>A classic scanline signal is made of 3 parts:</p>

<ol>
  <li>Start of the left safety border, no bitmap graphics is displayed</li>
  <li>Few cycles later, start of actual screen bitmap graphics decoding and display image</li>
  <li>When 320 pixels are displayed, stop bitmap decoding, and start of the right safety border</li>
</ol>

<p>Depending on the screen resolution and refresh rate, the shifter doesn’t build the exact same video signal. For instance, a low res 50Hz scanline is 512 cycles long, but a 60hz is 508 cycles. In high res, a scanline takes 224 cycles only.</p>

<p>To build the video signal each frame, the Shifter video chip is running a state machine. While generating the video signal, this state machine will tell the chip when to display the safety border, when to start to decode graphics, and when to stop to decode graphics.</p>

<p>Obviously this internal state machine isn’t documented. But thanks to the reverse engineering work or many people in the 90’ ( Alien, Troed, LjBK and others ) I can show you a high level view of the internal state machine of the video chip hardware:</p>

<div><pre><code><span>If</span> <span>res</span><span>=</span><span>high</span> <span>and</span> <span>time</span><span>=</span><span>0</span> <span>then</span> <span>start</span> <span>bitmap</span> <span>decoding</span>
<span>If</span> <span>rate</span><span>=</span><span>60</span> <span>and</span> <span>time</span><span>=</span><span>52</span> <span>then</span> <span>start</span> <span>bitmap</span> <span>decoding</span>
<span>If</span> <span>rate</span><span>=</span><span>50</span> <span>and</span> <span>time</span><span>=</span><span>56</span> <span>then</span> <span>start</span> <span>bitmap</span> <span>decoding</span>
<span>If</span> <span>res</span><span>=</span><span>high</span> <span>and</span> <span>time</span><span>=</span><span>160</span> <span>then</span> <span>stop</span> <span>bitmap</span> <span>decoding</span>
<span>If</span> <span>rate</span><span>=</span><span>60</span> <span>and</span> <span>time</span><span>=</span><span>372</span> <span>then</span> <span>stop</span> <span>bitmap</span> <span>decoding</span>
<span>If</span> <span>rate</span><span>=</span><span>50</span> <span>and</span> <span>time</span><span>=</span><span>376</span> <span>then</span> <span>stop</span> <span>bitmap</span> <span>decoding</span>
</code></pre></div>

<p><strong>Note:</strong> “time” here is the cycle position within a scanline (so modulo 512 cycles). When the video signal goes to the next scanline, the “time” var used here goes back to 0</p>

<p>This state machine is hardcoded in the chip, you can’t change it at all. But what if you can change the video rate and resolution like a maniac at very specific points during each scanline?</p>

<p>Look at the internal state machine that is ending a standard low res 50hz line:</p>
<div><pre><code><span>If</span> <span>rate</span><span>=</span><span>50</span> <span>and</span> <span>time</span><span>=</span><span>376</span> <span>then</span> <span>stop</span> <span>bitmap</span> <span>decoding</span>
</code></pre></div>

<p>What if at the exact cycle 376 position you force the rate to 60Hz? The hardware will “skip” the “if” statement, and continue to decode the bitmap graphics! As you skipped the state where the chip stops to decode the graphics line, you just opened the right safe zone border! Of course, you have to go back to 50hz as soon as you can to avoid distorting the signal too much.</p>

<p>Now what if you set the resolution to high at cycle 0? The internal state machine will start the graphics decoding. Your monitor is unable to display a high res image? No problem, just go back to low res at the next cycle and you’re good!</p>

<p>So here is a 68000 assembly code that is fooling the shifter hardware to get rid of left and right safety borders, just for one rasterline</p>

<div><pre><code>	<span>move</span><span>.</span><span>w</span>	<span>a4</span><span>,(</span><span>a4</span><span>)</span>		<span>// cycle 0: set the chip res to high to fool state machine!</span>
	<span>nop</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a4</span><span>)</span>		<span>// cycle 12: go back to low res to avoid any image distortion</span>
	<span>nop</span>
	<span>nop</span>
	<span>...</span>
	<span>...</span>		<span>// wait during exactly 364 cycles (until cycle 376)</span>

	<span>...</span>
	<span>nop</span>
	<span>nop</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a5</span><span>)</span>		<span>// cycle 376: set the rate to 60hz to fool state machine!</span>
	<span>move</span><span>.</span><span>w</span>	<span>a5</span><span>,(</span><span>a5</span><span>)</span>		<span>// cycle 384: get back to 50hz to avoid distortion</span>
	<span>nop</span>
	<span>...</span>					<span>// wait during exactly 112 cycles (for next scanline)</span>
	<span>nop</span>
</code></pre></div>
<p><em>Note: registers a4,d6 and a5 are pre-loaded with Atari specific address and values to change resolution and refresh rate</em></p>

<p>Of course you have to repeat this code snippet for every scanline you want to remove left and right border!</p>

<p><strong>Note:</strong> Same kind of trick allows you to get rid of the top and bottom safety empty borders. At the end, you get a new screen resolution of about 416x274 visible pixels instead of the classic 320x200!</p>

<p>To get an idea of the new resolution here is a picture of a fullscreen demo. A white rectangle has been drawn to show approximately a standard Atari 320x200 resolution.</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/st_full.jpg" alt="Alt Text"></p>

<p><strong>Note:</strong> As the CPU should stay in sync with the video decoding, it’s often called “racing the beam” technique. (reference to old CRT monitors where an electron beam was really moving from left to right during each scanline). When you repeat the code snippet above 274 times, almost <strong>all</strong> your time frame is wasted to fool the video chip. If you want to run your own code, you have to put it within all the “nops” instructions.</p>

<h2 id="how-to-render-bobs-in-the-middle-of-that-mess">How to render bobs in the middle of that mess?</h2>

<p>Any atari fullscreen fx should execute this code for each of 274 visible scanlines! Without missing a single cycle! For your own demo code, you only have two free slices of 364 and 112 cycles per scanline! You have to cut and divide your work into plenty of 364 and 112 cycle pieces! Your code should take the same time (no dynamic branch). If one single cycle is missing, the complete screen display is fucked up!</p>

<p>Regarding the extended fullscreen resolution, the screen buffer size is now 60KiB! Around twice bigger than normal. If you want to animate stuff on screen, it means you have to move twice as much memory!</p>

<p>That’s why doing a demo in fullscreen on Atari is <strong>really challenging!</strong></p>

<h2 id="using-blitter-in-fullscreen">Using blitter in Fullscreen</h2>

<p>Atari STE has a custom chip called “Blitter”. This chip can do in hardware what the “bit blit” algorithm from the 70s does. Common use is to move or combine bitmap graphics. Basically it can operate bitmap graphics from rectangular areas. It can also do bit shifting, and various bit operations (or, and, xor, not, etc.). Atari STE blitter is much simpler than Amiga blitter (1 source instead of 3, not line drawing, no xor filling ) but still efficient. In the early days, people considered STE blitter almost useless. The amount of registers to set up before blitting is huge, so it wasn’t very efficient for small bitmaps. ( setup time was longer than proper blit operation).</p>

<p>Anyway STE Blitter can be a very efficient friend when used properly. Let’s see how a STE blitter 16 colors masked bob classic code works.</p>

<h2 id="drawing-a-bob">Drawing a Bob</h2>

<p>A blitter only operates on words of 16 bits. Bitplan layout makes everything aligned to 16 pixels. As we want to draw bobs at any horizontal position (and not only 16 pixels aligned) we could use the blitter “shift”. And because of that we should also use one additional 16 pixels column. The final bob screen area will be 80x64 pixels</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/5words.gif" alt=" Alt Text"></p>

<h2 id="blitter-cost">Blitter cost</h2>

<p>What’s the cost of a blit OR operation on an 80x64 and 1 bitplan area? Let’s count the amount of 16bits words in the bob single bitplan mask: 5*64=320 words. Atari memory access timing is very easy: each word read or write is 4 cycles.</p>

<p>As we use a OR operation, the blitter have to do 3 memory access per bob bitmap word:</p>
<ol>
  <li>Read the bob source data word from memory to internal register</li>
  <li>Read the background data word from memory and OR it into internal register</li>
  <li>Write the result back to the destination memory</li>
</ol>

<p>Those 3 access takes 3*4=12 cycles. So the total cost is 5*64*12=3840 cycles. As a comparison, the electron beam takes 512 cycles to scan a line. So this 1 bitplan bob OR on screen is taking 7.5 scanlines of time. (Back in time we used to count timing in “scanlines”).</p>

<h2 id="blitter-and-fullscreen">Blitter and fullscreen</h2>

<p>Earlier we saw that we should slice all our code into small pieces of <strong>364</strong> and <strong>112</strong> cycles. When Atari blitter is running, the CPU is halted ( they don’t run in parallel ). So we have to “slice” the bob drawing into several small blitter commands. We could slice the bob in Y lines. The 1 bitplan OR takes 12*5=60 cycles for a 5 words bob line. The minimal blitter setup and run code is taking 28 cycles:</p>

<div><pre><code>	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>n</span><span>,(</span><span>a2</span><span>)</span>	  <span>// set n number of lines to blit ( 12 cycles )</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>		<span>// start the blit operation ( 16 cycles )</span>
</code></pre></div>
<p>How many bob lines can we blit in the longest slice of 364 cycles?</p>

<p>(364-28)/60 = 5.6 lines. As you can only blit an integer number of lines, we can run the blitter for 5 bob lines. It will cost 5*60+28=328 cycles over our 364 cycles slice.</p>

<p>Applying the same for the second slice of 112 cycles we got</p>

<p>(112-28)/60 = 1.4 so 1 single bob line. We can use this fullscreen code block to blit 6 lines of the 1 bitplan bob during one scanline.</p>

<div><pre><code>	<span>move</span><span>.</span><span>w</span>	<span>a4</span><span>,(</span><span>a4</span><span>)</span>		<span>// open left border</span>
	<span>nop</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a4</span><span>)</span>		<span>// back to low res</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>5</span><span>,(</span><span>a2</span><span>)</span>		<span>// blitter line count set to 5 (80x5 pixels)</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>		<span>// run the blitter </span>
	<span>nop</span>					<span>// 9 nops (wait for 36 cycles)</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a5</span><span>)</span>		<span>// cycle 376: open right border</span>
	<span>move</span><span>.</span><span>w</span>	<span>a5</span><span>,(</span><span>a5</span><span>)</span>		<span>// back to 50hz</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>1</span><span>,(</span><span>a2</span><span>)</span>		<span>// set next blitter line count (for 80x5 pixels)</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>		<span>// run the blitter </span>
	<span>nop</span>					<span>// 6 nops (wait 24 cycles)</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
	<span>nop</span>
</code></pre></div>

<p>To draw our 64 lines height bob, we need to repeat this fullscreen code block 11 times. 10 first are drawing 60 lines of the bob, and the last code block should just set up blitter to draw the 4 last bob lines. So the real amount of time we spent to draw the bob is 11 scanlines of 512 cycles each = 5636 cycles.</p>

<h2 id="optimise-use-the-vertical-blitter">Optimise, use the vertical blitter!</h2>

<p>So we need 11 raster lines of time to draw the 64 lines bob in 1 bitplan. Can we do better? Yes! The first idea is to restart the blitter as soon as the previous work is done. Like, after drawing 5 lines, we could start the blitter to start “half of a bob line” maybe, to fill the time slice more efficiently? Unfortunately you can’t do that. Blitting a “part of the bob line” would imply you to set up tons of different blitter registers, such as line width, source line stride, dest line stride. It’s not worth it.</p>

<p>Around 2015 I did a lot of blitter in fullscreen <a href="https://www.pouet.net/prod.php?which=66702" target="_blank">for the -We Were @- demo</a>. And I figured out an efficient technique to better fill the fullscreen time slices with the blitter. I called this technique “vertical blitter”. The idea is to draw the bob using vertical blocks of 16*N pixels. By doing this, the granularity of a blitter command will be 12 cycles (instead of 60 cycles for a complete bob line of 5 words).</p>

<p>The bob is drawn on screen using various size of vertical 16xN pixels strips:</p>

<p><img src="https://arnaud-carre.github.io/assets/img/4ktribute/vertical_blit.gif" alt=" Alt Text"></p>

<p>Let’s rewrite the code using this technique. Now the blitter is setup to run on blocks of 16xN pixels, vertically</p>

<div><pre><code>	<span>move</span><span>.</span><span>w</span>	<span>a4</span><span>,(</span><span>a4</span><span>)</span>		<span>// open left border</span>
	<span>nop</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a4</span><span>)</span>		<span>// back to low res</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>28</span><span>,(</span><span>a2</span><span>)</span>	<span>// blitter line count set to 28 (16x28 pixels)</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>		<span>// run the blitter </span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a5</span><span>)</span>		<span>// cycle 376: open right border</span>
	<span>move</span><span>.</span><span>w</span>	<span>a5</span><span>,(</span><span>a5</span><span>)</span>		<span>// back to 50hz</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>7</span><span>,(</span><span>a2</span><span>)</span>		<span>// set next blitter line count (for 16x7 pixels)</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>		<span>// run the blitter </span>
</code></pre></div>

<p>In one raster line of time we draw a vertical bob column of 16*(28+7) pixels.</p>

<p>Devil is in details, once we have drawn a 16*64 pixels bob we have to reset the blitter destination address to proceed to the next bob column. So we need few instructions in between, and it will mess up the fullscreen timing a bit. Writing that kind of code manually is painful</p>

<h2 id="generating-code">Generating code!</h2>

<p>If you look at my 4KiB intro, there is also a colourful background. It’s done by changing the background color every 3 scanlines. Again, it means you have to add an instruction every 3 scanlines to change the background color. And it will change all other blitter commands. Last but not least, the high level algorithm requires to change the blitter setup during the frame ( to clear the oldest mask bob, then to draw 1 bitplan bob, then to apply the mask into a 4 bitplans background. Then draw the final fully masked 4 bitplan bob)</p>

<p>To do this, I did a C program to generate a 68000 assembly code, doing all the nasty timing computation for me. It generates a 4000 lines assembly source file with the right blitter commands, at the right place in between the fullscreen resolution &amp; refresh rate change. Here are just a few lines of the generated source code so you can get how every cycle is counted. Also how the fullscreen hardware fooling code should explicitly fall at 0 and 376 cycle. If only one is missing, you won’t see anything on screen but garbage.</p>

<div><pre><code>	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>7</span><span>,(</span><span>a2</span><span>)</span>	<span>// set blitter line count to 7	// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>	<span>// run blitter	// [100 cycle]</span>
<span>// Raster line 42 [0]</span>
	<span>move</span><span>.</span><span>w</span>	<span>a4</span><span>,(</span><span>a4</span><span>)</span>	<span>// cycle 0: set high res, open left border	// [8 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a4</span><span>)</span>	<span>// back to low res	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>28</span><span>,(</span><span>a2</span><span>)</span>	<span>// set blitter line count to 28	// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>	<span>// run blitter	// [352 cycle]</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a5</span><span>)</span>	<span>// cycle 376, set 60hz to open right border	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>a5</span><span>,(</span><span>a5</span><span>)</span>	<span>// back to 50hz	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>5</span><span>,(</span><span>a2</span><span>)</span>	<span>// set blitter line count to 5	// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>	<span>// run blitter	// [76 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>(</span><span>a1</span><span>)</span><span>+</span><span>,</span><span>$</span><span>ffff8240</span><span>.</span><span>w</span>	<span>// change background color	// [16 cycle]</span>
<span>// Raster line 43 [0]</span>
	<span>move</span><span>.</span><span>w</span>	<span>a4</span><span>,(</span><span>a4</span><span>)</span>	<span>// cycle 0: set high res, open left border	// [8 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a4</span><span>)</span>	<span>// back to low res	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>23</span><span>,(</span><span>a2</span><span>)</span>	<span>// set blitter line count to 23	// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>d7</span><span>,(</span><span>a3</span><span>)</span>	<span>// run blitter	// [292 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>(</span><span>a0</span><span>)</span><span>+</span><span>,</span><span>d1</span>		<span>// dst	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>(</span><span>a0</span><span>)</span><span>+</span><span>,</span><span>d0</span>		<span>// src	// [8 cycle]</span>
	<span>// bitplan #0</span>
	<span>move</span><span>.</span><span>w</span>	<span>d0</span><span>,</span><span>$</span><span>ffff8a26</span><span>.</span><span>w</span>	<span>// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>d1</span><span>,</span><span>$</span><span>ffff8a34</span><span>.</span><span>w</span>	<span>// [12 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>#</span><span>8</span><span>,(</span><span>a2</span><span>)</span>	<span>// set blitter line count to 8	// [12 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>nop</span>	<span>// [4 cycle]</span>
	<span>move</span><span>.</span><span>b</span>	<span>d6</span><span>,(</span><span>a5</span><span>)</span>	<span>// cycle 376, set 60hz to open right border	// [8 cycle]</span>
	<span>move</span><span>.</span><span>w</span>	<span>a5</span><span>,(</span><span>a5</span><span>)</span>	<span>// back to 50hz	// [8 cycle]</span>
</code></pre></div>

<p>This is just a small part. If you’re curious, the complete assembly source code for blitter rendering this 4KiB intro can be seen here:</p>

<p><a href="https://github.com/arnaud-carre/arnaud-carre.github.io/blob/main/assets/img/4ktribute/fullscreenCode.asm" target="_blank">Have a look at the generated 4000 lines fullscreen blitter code</a></p>

<h2 id="final-words">Final words</h2>

<p>This post is long enough to stop here. I hope you enjoyed reading it, and maybe learned something as a bonus!</p>

<p>I may do a second post to talk about</p>
<ul>
  <li>How to fit the 2 minutes music into the 4KiB intro</li>
  <li>How to fit the code (esp the 4000 lines assembly source) in 4KiB</li>
  <li>Some words about best practice to please your face exe packer</li>
</ul>

<p>Knowing good tricks on old machines sometimes could inspire you to invent some new techniques on modern hardware!</p>

<p><a href="https://twitter.com/leonard_coder" target="_blank">Follow me on Twitter</a></p>

      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Companies need junior devs (123 pts)]]></title>
            <link>https://softwaredoug.com/blog/2024/09/07/your-team-needs-juniors</link>
            <guid>41481279</guid>
            <pubDate>Sun, 08 Sep 2024 16:22:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://softwaredoug.com/blog/2024/09/07/your-team-needs-juniors">https://softwaredoug.com/blog/2024/09/07/your-team-needs-juniors</a>, See on <a href="https://news.ycombinator.com/item?id=41481279">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	  <p>Getting coffee with a bunch of local tech leaders, I surprised myself with how stridently I argued why companies should hire junior engineers.</p>

<p>Lately, BigTech only wants <a href="https://technical.ly/professional-development/why-is-it-so-hard-to-find-entry-level-software-engineering-jobs/">elite squads of Staff devs</a> that can “hit the ground running” on the big (often AI) initiative. It’s been remarked (<a href="https://www.reddit.com/r/cscareerquestions/comments/11zhlir/ai_will_replace_most_of_the_junior_dev_jobs/">over</a> and <a href="https://forum.freecodecamp.org/t/the-future-of-junior-developers-after-ai-revolution/611977">over</a>) that AI will completely replace junior developers. Juniors, after all, exist to do “code monkey” work, easily replaced with an LLM.</p>

<p>However, that misses the mark on why we have junior employees. Coaching junior employees becomes its own force multiplier for innovating at scale. It’s not about the added labor, it’s about a psychologically safe culture that values teaching and learning, and the innovation that this unlocks.</p>

<h2 id="junior-talent-forces-your-team-to-teach-coach-collaborate">Junior Talent forces your team to teach, coach, collaborate</h2>

<p>What does it say about an organization that “ships”, but doesn’t collaborate?</p>

<p>In their article <a href="https://hbr.org/2007/07/the-knowledge-creating-company">The Knowledge-Creating Company</a>, Nonaka and Takeuchi argue that Japanese companies out innovated Western counterparts in the 80s/90s because of their focus on knowledge:</p>

<blockquote>
  <p>few managers grasp the true nature of the knowledge-creating company—let alone know how to manage it. The reason: They misunderstand what knowledge is and what companies must do to exploit it.</p>
</blockquote>

<p>Western companies, they argue, see the “assembly line” of a knowledge firm. They see the outputs: KPIs, OKRs, Quarterly results. If you only think in terms of the assembly line, you will only seek units of input that increase those outputs (ie expert employees that ‘hit the ground running’ to churn out higher metrics).</p>

<p>However, as Nonaka and Takeuchi remark:</p>

<blockquote>
  <p>Making personal knowledge available to others is the central activity of the knowledge-creating company.</p>
</blockquote>

<p>Innovative companies prioritize teaching, spreading, sharing knowledge. Ingraining knowledge into the company’s DNA matters more than a single developer shipping that next brilliant new feature.</p>

<p>Further, it turns out –  <strong>knowledge discovery IS innovation</strong>.</p>

<p>Teaching helps not just the juniors, but the seniors too. The <a href="https://effectiviology.com/protege-effect-learn-by-teaching/#Benefits_of_teaching_others">“Protege effect”</a> is a well studied phenomenon where the teacher’s knowledge deepens when required to teach. Juniors force-multiply seniors, not by writing code, but just by forcing seniors to teach and rethink their knowledge.</p>

<p>Redundancy - overlap in focus area - undergirds this whole process. Again from  Nonaka and Takeuchi:</p>

<blockquote>
  <p>Redundancy is important because it encourages frequent dialogue and communication. This helps create a “common cognitive ground” among employees and thus facilitates the transfer of tacit knowledge</p>
</blockquote>

<p>Juniors become this redundancy. They absorb company tribal knowledge, reprocess it, internalize it, translate it to explicit knowledge. It helps seniors become aware of their assumptions, question them, refine them. To act as a Socratic dialog to ensure you’re actually on the right path. Such redundancy extends beyond innovating, to the simple team needs of fixing bugs and being on-call at 3AM so your senior devs don’t collapse from burnout.</p>

<h2 id="generalists-innovate-better-than-specialists">Generalists innovate better than specialists</h2>

<p>As argued in the book Range - <a href="https://www.amazon.com/Range-Generalists-Triumph-Specialized-World/dp/0735214484">generalists often bring innovative ideas to the table</a>. The Wright Brothers are a classic example of non-expert, tinkering bicycle mechanics that end up inventing a flying machine. NoSQL databases come from distributed systems tinkerers, not relational database experts.</p>

<p>Junior employees come prepared with that Socratic dialog: to ask dumb questions and seek their answers. Often, it turns out, experts – through ego or blindness - don’t see obvious solutions. They don’t question tacit assumptions. Juniors on the other hand eagerly crash into, and sometimes through, problems seniors have convinced themselves are too hard. Juniors try “dumb” things that often fail, but sometimes show how blinded experts have become from their long held assumptions.</p>

<p>Some of the great ideas come from junior employees:</p>

<ul>
  <li>Jack Dorsey had the idea for Twitter as a junior employee of a podcast company</li>
  <li>Post-it notes were invented by junior employees Spencer Silver and Art Fry at 3M</li>
  <li>Firefox was a side project of Blake Ross while working at Netscape</li>
</ul>

<p>Juniors come from more diverse backgrounds than seniors (in every sense of the word). Leading to ways of thinking and perspectives that seniors totally miss.</p>

<h2 id="juniors-mean-psychological-safety-means-more-innovation">Juniors mean psychological safety means more innovation</h2>

<p>The term <a href="https://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Group_Performance/Edmondson%20Psychological%20safety.pdf">psychological safety</a> in organizational literature stems from a 1999 paper by Amy Edmonson</p>

<p>The fundamental quote, in the abstract:</p>

<blockquote>
  <p>Team psychological safety is associated with learning behavior, team efficacy is not</p>
</blockquote>

<p>(efficacy == perceived competence)</p>

<p>Creating environments where coaching is the norm, lead to increased psychological safety. Team members readily admit mistakes, and report errors.</p>

<p>In short, cultures of learning beget psychological safety. Psychological safety begets learning. Learning and innovation go hand in hand.</p>

<p>This is somehat in contrast to group cohesiveness, a tightly related long-term group of colleagues. Such cohesiveness can:</p>

<blockquote>
  <p>reduce willingness to disagree and challenge others’ views, such as in the phenomenon of groupthink, implying a lack of interpersonal risk taking.</p>
</blockquote>

<p>A stable team of long-term colleagues falls into groupthink and loses some ability to innovate. They sometimes form an immune system to outside ideas and experience. Onboarding anyone, especially juniors may seem like an annoying chore, as the colleagues don’t enjoy teaching and learning. We’ve all met that entrenched employee living in their knowledge silo, not excited to open their work up to others. They lose that “learning behavior” muscle.</p>

<p>“Learning behaviors”, crucially, include the ability to experiment - something I hear endlessly that more teams wish they had. This translates trying new approaches, running more A/B tests, being willing to try product directions that don’t work out (but sometimes do). Founders often talk about “failing fast”, but founders/managers/etc can also be their own worse enemy: wanting only the experts who already have all the answers, rather that juniors hungry to find new answers.</p>

<h2 id="your-org-suffers-from-not-hiring-juniors">Your org suffers from not hiring juniors</h2>

<p>Many of these themes begin to overlap: hire juniors that want to learn. Hire seniors that want to teach. Those who can’t teach, maybe shouldn’t be allowed to “do”.</p>

<p>I see a team much like a health University research lab. The platonic idea senior is open-minded and eager to be challenged. Eager to unlearn their expertise to find a new path. Along with juniors who come in enthusiastic to absorb knowledge like a sponge, asking naive questions that draw out new ideas and shake foundations.</p>

<p>That’s what it feels like to be on a high-performing team. Individuals open to ideas, eager to share credit, and avoid blame. Shipping constantly, sharing wins and learnings, and believing in the team.</p>

<p>Or at least, in my opinion, that’s 50% of the puzzle. The other 50% requires an interface to the “outside world” that protects this team, sells its internal chaos as a cohesive narrative, and works with investors and stakeholders to translate messy experiments into a glorious tale of progress. Sadly, many executives mistake this outer chrome of leadership for the entire system, ignoring the internal combustion engine of teaching and learning that makes it run.</p>

<p>If this isn’t your culture, I’m glad to grab a coffee to talk about what I’ve seen (and where I’ve failed!)</p>

      


	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lurker's Guide to Babylon5 (110 pts)]]></title>
            <link>http://www.midwinter.com/lurk/</link>
            <guid>41480145</guid>
            <pubDate>Sun, 08 Sep 2024 12:59:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.midwinter.com/lurk/">http://www.midwinter.com/lurk/</a>, See on <a href="https://news.ycombinator.com/item?id=41480145">Hacker News</a></p>
<div id="readability-page-1" class="page"><div size="-1">

<p>
Maintained by
<a href="http://www.facebook.com/sgrimm">Steven Grimm</a>.
<br>
"Babylon 5," the Babylon 5 logo, all publicity photos and images from the
series are copyright © and trademark ™ 1992-1998, PTN Consortium
and Warner Bros.

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Have ‘hobby’ apps become the new social networks? (200 pts)]]></title>
            <link>https://www.theguardian.com/technology/article/2024/sep/08/goodbye-tinder-hello-strava-have-hobby-apps-become-the-new-social-networks</link>
            <guid>41479785</guid>
            <pubDate>Sun, 08 Sep 2024 11:32:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/article/2024/sep/08/goodbye-tinder-hello-strava-have-hobby-apps-become-the-new-social-networks">https://www.theguardian.com/technology/article/2024/sep/08/goodbye-tinder-hello-strava-have-hobby-apps-become-the-new-social-networks</a>, See on <a href="https://news.ycombinator.com/item?id=41479785">Hacker News</a></p>
Couldn't get https://www.theguardian.com/technology/article/2024/sep/08/goodbye-tinder-hello-strava-have-hobby-apps-become-the-new-social-networks: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>